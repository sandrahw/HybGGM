SBATCH job
Started 12/11/2024 09:25:29
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
expandable_segments:True
UNet2 with 1 10 0.0001 2 360 start at Tue Nov 12 09:25:29 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 0.9121710062026978
train loss item: 2.361032485961914
train loss item: 0.5908730030059814
train loss item: 1.2434922456741333
train loss item: 0.8365021347999573
train loss item: 0.5948132276535034
train loss item: 0.5484413504600525
train loss item: 1.2568069696426392
train loss item: 0.4701719582080841
train loss item: 0.49126583337783813
train loss item: 0.5907455086708069
train loss item: 0.4010674059391022
train loss item: 0.3736041486263275
train loss item: 0.7809377312660217
train loss item: 0.509601891040802
train loss item: 1.0467482805252075
train loss item: 0.38424307107925415
train loss item: 0.5152631402015686
train loss item: 0.5292810797691345
train loss item: 0.407499760389328
train loss item: 0.3384734094142914
train loss item: 0.33425581455230713
train loss item: 1.4463419914245605
train loss item: 1.2463154792785645
train loss item: 0.7553142309188843
train loss item: 0.43640974164009094
train loss item: 0.37979209423065186
train loss item: 0.43813005089759827
train loss item: 0.28189951181411743
train loss item: 1.0697678327560425
train loss item: 2.858053207397461
train loss item: 0.7476573586463928
train loss item: 0.26521676778793335
train loss item: 0.5216339826583862
train loss item: 0.5793464183807373
train loss item: 2.6721296310424805
train loss item: 0.6262391209602356
train loss item: 0.4187734127044678
train loss item: 0.5651669502258301
train loss item: 0.44667813181877136
train loss item: 0.28570106625556946
train loss item: 0.3944515585899353
train loss item: 0.3284895420074463
train loss item: 0.337677538394928
train loss item: 0.7978792190551758
train loss item: 0.3569549322128296
train loss item: 0.2912555932998657
train loss item: 0.454662024974823
train loss item: 0.3029745817184448
train loss item: 0.25580763816833496
train loss item: 0.3692210614681244
train loss item: 1.0773347616195679
train loss item: 0.26498883962631226
train loss item: 0.25303590297698975
train loss item: 2.452367067337036
train loss item: 0.2578674852848053
train loss item: 0.3483966290950775
train loss item: 0.3164193332195282
train loss item: 0.2925061285495758
train loss item: 0.2450268268585205
train loss item: 1.0275503396987915
train loss item: 2.277750015258789
train loss item: 0.26835423707962036
train loss item: 0.3801731467247009
train loss item: 0.23931489884853363
train loss item: 0.7239580750465393
train loss item: 0.445193350315094
train loss item: 0.303986132144928
train loss item: 0.324326753616333
train loss item: 0.3634343445301056
train loss item: 0.28776270151138306
train loss item: 0.27615952491760254
train loss item: 0.2999342083930969
train loss item: 0.3200346827507019
train loss item: 0.22308796644210815
train loss item: 0.18532486259937286
train loss item: 0.9706341028213501
train loss item: 1.4912152290344238
train loss item: 0.19212085008621216
train loss item: 0.2843157649040222
train loss item: 0.2530641257762909
train loss item: 0.2367672324180603
train loss item: 0.2718278169631958
train loss item: 0.6453335285186768
train loss item: 0.3626972436904907
train loss item: 0.680824339389801
train loss item: 4.3681488037109375
train loss item: 0.2382141500711441
train loss item: 0.3801846206188202
test loss item: 0.21100924909114838
test loss item: 0.1905904859304428
test loss item: 0.493234783411026
test loss item: 0.2629840075969696
test loss item: 0.30734843015670776
test loss item: 0.23107047379016876
test loss item: 1.272710919380188
test loss item: 0.3848780691623688
test loss item: 0.22346585988998413
test loss item: 0.381833016872406
test loss item: 0.8189902305603027
test loss item: 0.2084769308567047
test loss item: 0.21908438205718994
test loss item: 0.33655762672424316
test loss item: 0.23035652935504913
test loss item: 0.1612349897623062
test loss item: 0.26569706201553345
test loss item: 0.4498690366744995
test loss item: 0.5908847451210022
test loss item: 0.26883623003959656
test loss item: 0.7079334855079651
test loss item: 0.34440669417381287
test loss item: 0.30552637577056885
test loss item: 0.2102038860321045
test loss item: 0.23730531334877014
test loss item: 0.2640498876571655
test loss item: 0.3360220491886139
test loss item: 0.2627532482147217
test loss item: 0.3543626070022583
test loss item: 0.36366814374923706
test loss item: 0.6721838712692261
test loss item: 0.1511075347661972
test loss item: 0.20101863145828247
test loss item: 0.5464137196540833
test loss item: 0.4172126054763794
test loss item: 0.5716060996055603
test loss item: 0.70134437084198
test loss item: 1.356266975402832
test loss item: 0.47007670998573303
test loss item: 0.29342812299728394
test loss item: 0.2850244343280792
test loss item: 0.24279940128326416
test loss item: 0.3389380872249603
test loss item: 0.21887172758579254
test loss item: 0.5867714881896973
test loss item: 0.37481752038002014
test loss item: 0.3145896792411804
test loss item: 0.29516535997390747
test loss item: 0.4280039966106415
test loss item: 0.6496374011039734
test loss item: 0.31711316108703613
test loss item: 0.20819510519504547
test loss item: 0.23961491882801056
test loss item: 0.23810023069381714
test loss item: 0.3062787652015686
test loss item: 0.754949152469635
test loss item: 0.5467913150787354
test loss item: 0.27358928322792053
test loss item: 0.2504788339138031
test loss item: 0.23311938345432281
test loss item: 0.45070433616638184
test loss item: 0.2125469595193863
test loss item: 0.2315702736377716
test loss item: 0.2604731023311615
test loss item: 0.696123480796814
test loss item: 0.3371492326259613
test loss item: 0.3023376166820526
test loss item: 0.2690799832344055
test loss item: 0.5280156135559082
test loss item: 0.428323894739151
test loss item: 0.16557703912258148
test loss item: 0.7224841713905334
test loss item: 0.28124964237213135
test loss item: 0.3354153633117676
test loss item: 0.1801617592573166
test loss item: 0.22270898520946503
test loss item: 0.21052978932857513
test loss item: 1.345981240272522
test loss item: 0.4439548850059509
test loss item: 0.261204332113266
test loss item: 0.15042409300804138
test loss item: 0.8808879852294922
test loss item: 0.7729071974754333
test loss item: 0.9290870428085327
test loss item: 0.25774550437927246
test loss item: 0.24865679442882538
test loss item: 0.1663329303264618
test loss item: 0.16702459752559662
test loss item: 0.20241861045360565
Epoch [1/10], Training Loss: 0.6660, Testing Loss: 0.3937
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/10
train loss item: 0.48500680923461914
train loss item: 1.1864590644836426
train loss item: 0.3508640229701996
train loss item: 0.5151530504226685
train loss item: 1.8454673290252686
train loss item: 0.37411361932754517
train loss item: 0.26874735951423645
train loss item: 0.7689760327339172
train loss item: 0.21163707971572876
train loss item: 0.3168288469314575
train loss item: 0.3959479033946991
train loss item: 0.27108681201934814
train loss item: 0.1811189204454422
train loss item: 0.5443882346153259
train loss item: 0.3077506124973297
train loss item: 0.787498414516449
train loss item: 0.14723119139671326
train loss item: 0.2873050570487976
train loss item: 0.33562010526657104
train loss item: 0.3018501400947571
train loss item: 0.2441416084766388
train loss item: 0.1842338591814041
train loss item: 0.9704393744468689
train loss item: 1.043884515762329
train loss item: 0.5557245016098022
train loss item: 0.3019523024559021
train loss item: 0.28606241941452026
train loss item: 0.3080558180809021
train loss item: 0.19289523363113403
train loss item: 0.6662306189537048
train loss item: 2.1989352703094482
train loss item: 0.600832998752594
train loss item: 0.20529243350028992
train loss item: 0.4043195843696594
train loss item: 0.26840314269065857
train loss item: 2.191783905029297
train loss item: 0.5457374453544617
train loss item: 0.48889845609664917
train loss item: 0.5570715069770813
train loss item: 0.36063817143440247
train loss item: 0.32198330760002136
train loss item: 0.3245721459388733
train loss item: 0.3126809895038605
train loss item: 0.2532402575016022
train loss item: 0.6258190274238586
train loss item: 0.21640613675117493
train loss item: 0.14717531204223633
train loss item: 0.37694770097732544
train loss item: 0.21109218895435333
train loss item: 0.18790778517723083
train loss item: 0.27791184186935425
train loss item: 0.9104347229003906
train loss item: 0.1188352033495903
train loss item: 0.20859506726264954
train loss item: 2.113276243209839
train loss item: 0.19718770682811737
train loss item: 0.3474990129470825
train loss item: 0.2297925502061844
train loss item: 0.19623008370399475
train loss item: 0.16100898385047913
train loss item: 0.755406379699707
train loss item: 1.9041850566864014
train loss item: 0.23504287004470825
train loss item: 0.34660056233406067
train loss item: 0.17821645736694336
train loss item: 0.5193289518356323
train loss item: 0.4283766448497772
train loss item: 0.24446611106395721
train loss item: 0.30278101563453674
train loss item: 0.3167077898979187
train loss item: 0.2663639187812805
train loss item: 0.19255146384239197
train loss item: 0.20296163856983185
train loss item: 0.27306029200553894
train loss item: 0.16356468200683594
train loss item: 0.13581477105617523
train loss item: 0.7882338762283325
train loss item: 1.2669059038162231
train loss item: 0.10500571876764297
train loss item: 0.23480942845344543
train loss item: 0.15628831088542938
train loss item: 0.19977013766765594
train loss item: 0.23715628683567047
train loss item: 0.49897128343582153
train loss item: 0.3223642110824585
train loss item: 0.5064004063606262
train loss item: 3.836564779281616
train loss item: 0.1922953575849533
train loss item: 0.3331531584262848
test loss item: 0.16456946730613708
test loss item: 0.11038728058338165
test loss item: 0.41948583722114563
test loss item: 0.20428384840488434
test loss item: 0.21386538445949554
test loss item: 0.12129561603069305
test loss item: 1.1379759311676025
test loss item: 0.42230767011642456
test loss item: 0.17199808359146118
test loss item: 0.31706321239471436
test loss item: 0.6662368178367615
test loss item: 0.1533002108335495
test loss item: 0.16496215760707855
test loss item: 0.2558002173900604
test loss item: 0.15268272161483765
test loss item: 0.11311981081962585
test loss item: 0.23457683622837067
test loss item: 0.37272506952285767
test loss item: 0.5599627494812012
test loss item: 0.2108278125524521
test loss item: 0.6021773219108582
test loss item: 0.30609267950057983
test loss item: 0.22708241641521454
test loss item: 0.1507413536310196
test loss item: 0.19595392048358917
test loss item: 0.20579475164413452
test loss item: 0.2658422589302063
test loss item: 0.17071907222270966
test loss item: 0.27401527762413025
test loss item: 0.29511889815330505
test loss item: 0.5428682565689087
test loss item: 0.10044039040803909
test loss item: 0.13385009765625
test loss item: 0.4724656045436859
test loss item: 0.33872246742248535
test loss item: 0.3904491066932678
test loss item: 0.6551851034164429
test loss item: 1.0588656663894653
test loss item: 0.3864870071411133
test loss item: 0.22728078067302704
test loss item: 0.25358232855796814
test loss item: 0.1645478755235672
test loss item: 0.29995766282081604
test loss item: 0.17277176678180695
test loss item: 0.4874116778373718
test loss item: 0.32642003893852234
test loss item: 0.23674285411834717
test loss item: 0.2063627988100052
test loss item: 0.36967185139656067
test loss item: 0.5366275906562805
test loss item: 0.2455424666404724
test loss item: 0.14099395275115967
test loss item: 0.19800561666488647
test loss item: 0.1570899337530136
test loss item: 0.24934060871601105
test loss item: 0.6377779245376587
test loss item: 0.4665624499320984
test loss item: 0.2056286484003067
test loss item: 0.20034603774547577
test loss item: 0.1855689436197281
test loss item: 0.38074633479118347
test loss item: 0.1928337663412094
test loss item: 0.17647764086723328
test loss item: 0.22014030814170837
test loss item: 0.5952824354171753
test loss item: 0.2790825068950653
test loss item: 0.2577891945838928
test loss item: 0.22083067893981934
test loss item: 0.45469313859939575
test loss item: 0.372977614402771
test loss item: 0.09554248303174973
test loss item: 0.6771318912506104
test loss item: 0.23136042058467865
test loss item: 0.2950713336467743
test loss item: 0.12782225012779236
test loss item: 0.1396246701478958
test loss item: 0.15078453719615936
test loss item: 1.0145968198776245
test loss item: 0.3603816330432892
test loss item: 0.16605304181575775
test loss item: 0.08830113708972931
test loss item: 0.7166067361831665
test loss item: 0.6842418313026428
test loss item: 0.703576385974884
test loss item: 0.19565007090568542
test loss item: 0.1880267858505249
test loss item: 0.10575206577777863
test loss item: 0.12133488804101944
test loss item: 0.16646070778369904
Epoch [2/10], Training Loss: 0.5094, Testing Loss: 0.3178
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/10
train loss item: 0.41057389974594116
train loss item: 0.9392258524894714
train loss item: 0.22056832909584045
train loss item: 0.43680208921432495
train loss item: 0.6556686758995056
train loss item: 0.30349549651145935
train loss item: 0.2789488136768341
train loss item: 0.5759757161140442
train loss item: 0.21900008618831635
train loss item: 0.2762719392776489
train loss item: 0.3241414725780487
train loss item: 0.25244632363319397
train loss item: 0.14802424609661102
train loss item: 0.4438804090023041
train loss item: 0.22367443144321442
train loss item: 0.6498077511787415
train loss item: 0.10418679565191269
train loss item: 0.24753674864768982
train loss item: 0.271727979183197
train loss item: 0.2491001933813095
train loss item: 0.2201738804578781
train loss item: 0.16697193682193756
train loss item: 0.8138332962989807
train loss item: 0.832940936088562
train loss item: 0.5344581007957458
train loss item: 0.2553643584251404
train loss item: 0.23663429915905
train loss item: 0.24703827500343323
train loss item: 0.106563501060009
train loss item: 0.5640798807144165
train loss item: 1.7679976224899292
train loss item: 0.5301427245140076
train loss item: 0.1523536741733551
train loss item: 0.3506092429161072
train loss item: 0.2269054800271988
train loss item: 1.9261847734451294
train loss item: 0.5025743842124939
train loss item: 0.4173262119293213
train loss item: 0.612385094165802
train loss item: 0.27643051743507385
train loss item: 0.2588752210140228
train loss item: 0.2402261644601822
train loss item: 0.3003993630409241
train loss item: 0.20986206829547882
train loss item: 0.5492078065872192
train loss item: 0.16295021772384644
train loss item: 0.11572805792093277
train loss item: 0.3610960841178894
train loss item: 0.18830306828022003
train loss item: 0.15522484481334686
train loss item: 0.25792670249938965
train loss item: 0.8181875348091125
train loss item: 0.09539136290550232
train loss item: 0.17696301639080048
train loss item: 1.9070606231689453
train loss item: 0.170675590634346
train loss item: 0.28691366314888
train loss item: 0.20082181692123413
train loss item: 0.1609772890806198
train loss item: 0.1317761093378067
train loss item: 0.6230367422103882
train loss item: 1.7065331935882568
train loss item: 0.20592091977596283
train loss item: 0.33050400018692017
train loss item: 0.15625238418579102
train loss item: 0.5017097592353821
train loss item: 0.43653878569602966
train loss item: 0.22097647190093994
train loss item: 0.2648906111717224
train loss item: 0.29357579350471497
train loss item: 0.24327246844768524
train loss item: 0.15217532217502594
train loss item: 0.1687525063753128
train loss item: 0.2407342791557312
train loss item: 0.1157328262925148
train loss item: 0.11458990722894669
train loss item: 0.6786723136901855
train loss item: 1.1846877336502075
train loss item: 0.09225727617740631
train loss item: 0.20939737558364868
train loss item: 0.13876096904277802
train loss item: 0.1612091213464737
train loss item: 0.22264538705348969
train loss item: 0.42996418476104736
train loss item: 0.3240766227245331
train loss item: 0.4125942885875702
train loss item: 3.5785934925079346
train loss item: 0.14885194599628448
train loss item: 0.3150218427181244
test loss item: 0.16498811542987823
test loss item: 0.11600631475448608
test loss item: 0.3680499494075775
test loss item: 0.19585846364498138
test loss item: 0.20214354991912842
test loss item: 0.12462395429611206
test loss item: 1.0673556327819824
test loss item: 0.4267731308937073
test loss item: 0.16261166334152222
test loss item: 0.27788877487182617
test loss item: 0.5889781713485718
test loss item: 0.14192666113376617
test loss item: 0.1640489101409912
test loss item: 0.23899605870246887
test loss item: 0.15037652850151062
test loss item: 0.10529238730669022
test loss item: 0.21675445139408112
test loss item: 0.31497448682785034
test loss item: 0.536879301071167
test loss item: 0.20804831385612488
test loss item: 0.5074040293693542
test loss item: 0.29394447803497314
test loss item: 0.21730881929397583
test loss item: 0.1496402621269226
test loss item: 0.16933496296405792
test loss item: 0.2033127099275589
test loss item: 0.24408596754074097
test loss item: 0.1658170521259308
test loss item: 0.2517901659011841
test loss item: 0.26298534870147705
test loss item: 0.48619210720062256
test loss item: 0.09431294351816177
test loss item: 0.13469067215919495
test loss item: 0.4063783884048462
test loss item: 0.2847801744937897
test loss item: 0.3589833378791809
test loss item: 0.6201183199882507
test loss item: 0.9135726094245911
test loss item: 0.3269723355770111
test loss item: 0.2146047055721283
test loss item: 0.23267878592014313
test loss item: 0.19084778428077698
test loss item: 0.2560923099517822
test loss item: 0.15717189013957977
test loss item: 0.40955156087875366
test loss item: 0.30948200821876526
test loss item: 0.2351771593093872
test loss item: 0.21544206142425537
test loss item: 0.33024609088897705
test loss item: 0.47751888632774353
test loss item: 0.21951842308044434
test loss item: 0.1381026953458786
test loss item: 0.1801338940858841
test loss item: 0.1368313431739807
test loss item: 0.2214929312467575
test loss item: 0.5475833415985107
test loss item: 0.4356391131877899
test loss item: 0.20974023640155792
test loss item: 0.1905653327703476
test loss item: 0.17301692068576813
test loss item: 0.32186779379844666
test loss item: 0.19388088583946228
test loss item: 0.1754915565252304
test loss item: 0.20177891850471497
test loss item: 0.5454671382904053
test loss item: 0.26212915778160095
test loss item: 0.24920544028282166
test loss item: 0.20816993713378906
test loss item: 0.40145620703697205
test loss item: 0.36376145482063293
test loss item: 0.10478593409061432
test loss item: 0.647621214389801
test loss item: 0.2223510891199112
test loss item: 0.27984219789505005
test loss item: 0.13160434365272522
test loss item: 0.15958917140960693
test loss item: 0.15141436457633972
test loss item: 0.8801490664482117
test loss item: 0.31721606850624084
test loss item: 0.16654878854751587
test loss item: 0.09368784725666046
test loss item: 0.6575867533683777
test loss item: 0.634811282157898
test loss item: 0.6204633116722107
test loss item: 0.1728341430425644
test loss item: 0.1753714382648468
test loss item: 0.09615317732095718
test loss item: 0.09753245860338211
test loss item: 0.1807059645652771
Epoch [3/10], Training Loss: 0.4314, Testing Loss: 0.2928
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/10
train loss item: 0.35598820447921753
train loss item: 0.8042619824409485
train loss item: 0.20258288085460663
train loss item: 0.3679743707180023
train loss item: 0.3493640124797821
train loss item: 0.2614400386810303
train loss item: 0.2123015820980072
train loss item: 0.49573248624801636
train loss item: 0.12789037823677063
train loss item: 0.22288234531879425
train loss item: 0.2549700140953064
train loss item: 0.2291392683982849
train loss item: 0.1250050812959671
train loss item: 0.38927099108695984
train loss item: 0.1970185786485672
train loss item: 0.5646058320999146
train loss item: 0.08877763152122498
train loss item: 0.20903925597667694
train loss item: 0.22932535409927368
train loss item: 0.23731489479541779
train loss item: 0.1798063963651657
train loss item: 0.15170565247535706
train loss item: 0.6788648366928101
train loss item: 0.7174670100212097
train loss item: 0.40623781085014343
train loss item: 0.21019499003887177
train loss item: 0.18434979021549225
train loss item: 0.20658157765865326
train loss item: 0.0767621323466301
train loss item: 0.484586626291275
train loss item: 1.5610963106155396
train loss item: 0.4576701819896698
train loss item: 0.11579523980617523
train loss item: 0.32334160804748535
train loss item: 0.1675577461719513
train loss item: 1.7904075384140015
train loss item: 0.4623925983905792
train loss item: 0.3854462206363678
train loss item: 0.519524097442627
train loss item: 0.22983407974243164
train loss item: 0.25588035583496094
train loss item: 0.20621319115161896
train loss item: 0.28468814492225647
train loss item: 0.18225841224193573
train loss item: 0.5219123959541321
train loss item: 0.1323309987783432
train loss item: 0.10669330507516861
train loss item: 0.34430891275405884
train loss item: 0.18780651688575745
train loss item: 0.1343318372964859
train loss item: 0.2666662931442261
train loss item: 0.7907475233078003
train loss item: 0.0894383043050766
train loss item: 0.16132991015911102
train loss item: 1.8235493898391724
train loss item: 0.15067575871944427
train loss item: 0.24774223566055298
train loss item: 0.18197417259216309
train loss item: 0.1380002647638321
train loss item: 0.13140511512756348
train loss item: 0.5338607430458069
train loss item: 1.5581157207489014
train loss item: 0.19453473389148712
train loss item: 0.3236832320690155
train loss item: 0.15777035057544708
train loss item: 0.4651155173778534
train loss item: 0.41722169518470764
train loss item: 0.2116740345954895
train loss item: 0.23992526531219482
train loss item: 0.26229363679885864
train loss item: 0.2425377070903778
train loss item: 0.13498054444789886
train loss item: 0.15224233269691467
train loss item: 0.22560636699199677
train loss item: 0.09823179244995117
train loss item: 0.10817596316337585
train loss item: 0.5941234827041626
train loss item: 1.1474241018295288
train loss item: 0.07439909130334854
train loss item: 0.18922768533229828
train loss item: 0.13035689294338226
train loss item: 0.15190459787845612
train loss item: 0.2061934918165207
train loss item: 0.3775103986263275
train loss item: 0.3153328597545624
train loss item: 0.35125240683555603
train loss item: 3.4140055179595947
train loss item: 0.12561409175395966
train loss item: 0.2921113967895508
test loss item: 0.14565269649028778
test loss item: 0.09972818195819855
test loss item: 0.31904807686805725
test loss item: 0.17741473019123077
test loss item: 0.17818129062652588
test loss item: 0.1090296283364296
test loss item: 0.9717305302619934
test loss item: 0.3816626965999603
test loss item: 0.1452505886554718
test loss item: 0.2422090768814087
test loss item: 0.5103796124458313
test loss item: 0.12755726277828217
test loss item: 0.14440789818763733
test loss item: 0.2017776519060135
test loss item: 0.1303005814552307
test loss item: 0.08662473410367966
test loss item: 0.18547125160694122
test loss item: 0.2678360939025879
test loss item: 0.48603954911231995
test loss item: 0.17721052467823029
test loss item: 0.42158231139183044
test loss item: 0.26450249552726746
test loss item: 0.18629325926303864
test loss item: 0.13067232072353363
test loss item: 0.1426168531179428
test loss item: 0.19152763485908508
test loss item: 0.20925676822662354
test loss item: 0.14573708176612854
test loss item: 0.21618017554283142
test loss item: 0.22732073068618774
test loss item: 0.41734644770622253
test loss item: 0.07876484841108322
test loss item: 0.11808403581380844
test loss item: 0.3473883271217346
test loss item: 0.23896190524101257
test loss item: 0.33106085658073425
test loss item: 0.5586614608764648
test loss item: 0.7654697895050049
test loss item: 0.27772554755210876
test loss item: 0.19078901410102844
test loss item: 0.2128448337316513
test loss item: 0.15439927577972412
test loss item: 0.22256439924240112
test loss item: 0.1414870321750641
test loss item: 0.33886849880218506
test loss item: 0.2580082416534424
test loss item: 0.19026507437229156
test loss item: 0.18398751318454742
test loss item: 0.2912936806678772
test loss item: 0.4199453592300415
test loss item: 0.19200272858142853
test loss item: 0.12052552402019501
test loss item: 0.1610703319311142
test loss item: 0.12301196902990341
test loss item: 0.19241128861904144
test loss item: 0.4637324810028076
test loss item: 0.39481818675994873
test loss item: 0.16888964176177979
test loss item: 0.16964846849441528
test loss item: 0.1543264091014862
test loss item: 0.2779274880886078
test loss item: 0.16815245151519775
test loss item: 0.15325114130973816
test loss item: 0.1821765899658203
test loss item: 0.4927235543727875
test loss item: 0.24160215258598328
test loss item: 0.222931370139122
test loss item: 0.18811367452144623
test loss item: 0.34758302569389343
test loss item: 0.32354772090911865
test loss item: 0.08773090690374374
test loss item: 0.5885575413703918
test loss item: 0.1844480335712433
test loss item: 0.24837709963321686
test loss item: 0.11248736828565598
test loss item: 0.12719129025936127
test loss item: 0.13286513090133667
test loss item: 0.7408822774887085
test loss item: 0.26143887639045715
test loss item: 0.14205902814865112
test loss item: 0.08329802006483078
test loss item: 0.5837969779968262
test loss item: 0.5615742802619934
test loss item: 0.5285375714302063
test loss item: 0.1554044932126999
test loss item: 0.1572323888540268
test loss item: 0.08322959393262863
test loss item: 0.07697780430316925
test loss item: 0.17034783959388733
Epoch [4/10], Training Loss: 0.3850, Testing Loss: 0.2553
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/10
train loss item: 0.32581350207328796
train loss item: 0.68785560131073
train loss item: 0.1689162701368332
train loss item: 0.30728569626808167
train loss item: 0.3112659454345703
train loss item: 0.23388192057609558
train loss item: 0.197120800614357
train loss item: 0.4242609739303589
train loss item: 0.1765977442264557
train loss item: 0.22172120213508606
train loss item: 0.23896799981594086
train loss item: 0.21106785535812378
train loss item: 0.12419063597917557
train loss item: 0.35141801834106445
train loss item: 0.1784149706363678
train loss item: 0.4844543933868408
train loss item: 0.07442507147789001
train loss item: 0.20637254416942596
train loss item: 0.22465862333774567
train loss item: 0.2201792299747467
train loss item: 0.15568211674690247
train loss item: 0.14188474416732788
train loss item: 0.6201402544975281
train loss item: 0.6293896436691284
train loss item: 0.35873788595199585
train loss item: 0.19969846308231354
train loss item: 0.15493755042552948
train loss item: 0.20293501019477844
train loss item: 0.07407943159341812
train loss item: 0.4112387001514435
train loss item: 1.4342401027679443
train loss item: 0.3921287953853607
train loss item: 0.10434434562921524
train loss item: 0.2508352994918823
train loss item: 0.16025130450725555
train loss item: 1.702993392944336
train loss item: 0.448997437953949
train loss item: 0.34260207414627075
train loss item: 0.49870890378952026
train loss item: 0.2139338254928589
train loss item: 0.19328752160072327
train loss item: 0.177623450756073
train loss item: 0.2676558792591095
train loss item: 0.17365793883800507
train loss item: 0.4857686161994934
train loss item: 0.12671495974063873
train loss item: 0.09315690398216248
train loss item: 0.32812294363975525
train loss item: 0.17049795389175415
train loss item: 0.12038741260766983
train loss item: 0.255161851644516
train loss item: 0.7218571901321411
train loss item: 0.07501495629549026
train loss item: 0.13650180399417877
train loss item: 1.7010846138000488
train loss item: 0.13872185349464417
train loss item: 0.21724967658519745
train loss item: 0.16614073514938354
train loss item: 0.11914478242397308
train loss item: 0.12481243908405304
train loss item: 0.4534313678741455
train loss item: 1.4495065212249756
train loss item: 0.16432514786720276
train loss item: 0.3039627969264984
train loss item: 0.13752558827400208
train loss item: 0.45714709162712097
train loss item: 0.37004485726356506
train loss item: 0.19577527046203613
train loss item: 0.2399950921535492
train loss item: 0.2392459511756897
train loss item: 0.22770865261554718
train loss item: 0.13366557657718658
train loss item: 0.13317476212978363
train loss item: 0.2134573608636856
train loss item: 0.09006661176681519
train loss item: 0.10644204914569855
train loss item: 0.5051339864730835
train loss item: 1.0949790477752686
train loss item: 0.07362128049135208
train loss item: 0.18072354793548584
train loss item: 0.11900542676448822
train loss item: 0.13871333003044128
train loss item: 0.18242621421813965
train loss item: 0.34184423089027405
train loss item: 0.31136271357536316
train loss item: 0.2932506203651428
train loss item: 3.2745420932769775
train loss item: 0.11492627114057541
train loss item: 0.2705959975719452
test loss item: 0.13768187165260315
test loss item: 0.1059664711356163
test loss item: 0.31977277994155884
test loss item: 0.1687592715024948
test loss item: 0.1725543588399887
test loss item: 0.10796795785427094
test loss item: 0.9562724828720093
test loss item: 0.3778120279312134
test loss item: 0.14335952699184418
test loss item: 0.2224271446466446
test loss item: 0.5199857354164124
test loss item: 0.12026584893465042
test loss item: 0.13627663254737854
test loss item: 0.18220320343971252
test loss item: 0.13214784860610962
test loss item: 0.08959469944238663
test loss item: 0.17356204986572266
test loss item: 0.23714660108089447
test loss item: 0.46339094638824463
test loss item: 0.16378749907016754
test loss item: 0.36057114601135254
test loss item: 0.25362586975097656
test loss item: 0.17910833656787872
test loss item: 0.12696781754493713
test loss item: 0.12797391414642334
test loss item: 0.17536401748657227
test loss item: 0.19205935299396515
test loss item: 0.1396714299917221
test loss item: 0.2049058973789215
test loss item: 0.20779721438884735
test loss item: 0.4235039949417114
test loss item: 0.07797933369874954
test loss item: 0.11733958125114441
test loss item: 0.3171128034591675
test loss item: 0.22205139696598053
test loss item: 0.30162060260772705
test loss item: 0.5310007929801941
test loss item: 0.8034690022468567
test loss item: 0.24970003962516785
test loss item: 0.17983902990818024
test loss item: 0.20100010931491852
test loss item: 0.151836559176445
test loss item: 0.1871679127216339
test loss item: 0.1350000500679016
test loss item: 0.2863185703754425
test loss item: 0.2409902960062027
test loss item: 0.18057507276535034
test loss item: 0.1689620167016983
test loss item: 0.27554890513420105
test loss item: 0.4104178845882416
test loss item: 0.17607620358467102
test loss item: 0.11413232982158661
test loss item: 0.14997464418411255
test loss item: 0.1134142130613327
test loss item: 0.1721152514219284
test loss item: 0.46589237451553345
test loss item: 0.37748727202415466
test loss item: 0.15686176717281342
test loss item: 0.16111646592617035
test loss item: 0.14196616411209106
test loss item: 0.24335387349128723
test loss item: 0.1659802943468094
test loss item: 0.14308996498584747
test loss item: 0.16723257303237915
test loss item: 0.5097565054893494
test loss item: 0.22614407539367676
test loss item: 0.205703005194664
test loss item: 0.17838770151138306
test loss item: 0.3284565508365631
test loss item: 0.3089136779308319
test loss item: 0.09263037145137787
test loss item: 0.5735708475112915
test loss item: 0.16399429738521576
test loss item: 0.23387542366981506
test loss item: 0.11196247488260269
test loss item: 0.13189364969730377
test loss item: 0.1301286220550537
test loss item: 0.8231484293937683
test loss item: 0.24050746858119965
test loss item: 0.13361811637878418
test loss item: 0.08650367707014084
test loss item: 0.585909903049469
test loss item: 0.5388631224632263
test loss item: 0.569173276424408
test loss item: 0.14117766916751862
test loss item: 0.14822301268577576
test loss item: 0.08463791012763977
test loss item: 0.07698342204093933
test loss item: 0.1599806547164917
Epoch [5/10], Training Loss: 0.3537, Testing Loss: 0.2460
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/10
train loss item: 0.29320305585861206
train loss item: 0.5805436968803406
train loss item: 0.14905251562595367
train loss item: 0.2696644961833954
train loss item: 0.3526644706726074
train loss item: 0.20412614941596985
train loss item: 0.17097285389900208
train loss item: 0.3893434703350067
train loss item: 0.11060600727796555
train loss item: 0.183033749461174
train loss item: 0.19801367819309235
train loss item: 0.1877201348543167
train loss item: 0.11137298494577408
train loss item: 0.3192380368709564
train loss item: 0.1562434881925583
train loss item: 0.4516353905200958
train loss item: 0.07345494627952576
train loss item: 0.1695288121700287
train loss item: 0.21061256527900696
train loss item: 0.20932209491729736
train loss item: 0.17414578795433044
train loss item: 0.11421645432710648
train loss item: 0.5337414741516113
train loss item: 0.5032087564468384
train loss item: 0.31887197494506836
train loss item: 0.2126837521791458
train loss item: 0.1517699807882309
train loss item: 0.17568644881248474
train loss item: 0.062321364879608154
train loss item: 0.3854527175426483
train loss item: 1.3103365898132324
train loss item: 0.36351656913757324
train loss item: 0.0981878712773323
train loss item: 0.2768467664718628
train loss item: 0.13831759989261627
train loss item: 1.6364707946777344
train loss item: 0.40737658739089966
train loss item: 0.33419039845466614
train loss item: 0.3907160460948944
train loss item: 0.18263813853263855
train loss item: 0.1967734843492508
train loss item: 0.17326509952545166
train loss item: 0.2670568525791168
train loss item: 0.1632065623998642
train loss item: 0.46508556604385376
train loss item: 0.11305629462003708
train loss item: 0.08695494383573532
train loss item: 0.31322571635246277
train loss item: 0.15751515328884125
train loss item: 0.1157083809375763
train loss item: 0.2415366768836975
train loss item: 0.6862843632698059
train loss item: 0.0901777520775795
train loss item: 0.12894639372825623
train loss item: 1.6379867792129517
train loss item: 0.1284150779247284
train loss item: 0.2076406031847
train loss item: 0.16328901052474976
train loss item: 0.1148693636059761
train loss item: 0.11874019354581833
train loss item: 0.41115501523017883
train loss item: 1.3698383569717407
train loss item: 0.17907081544399261
train loss item: 0.2948562204837799
train loss item: 0.1353941559791565
train loss item: 0.3976072669029236
train loss item: 0.33196479082107544
train loss item: 0.1802922636270523
train loss item: 0.22621162235736847
train loss item: 0.2157512605190277
train loss item: 0.18949832022190094
train loss item: 0.12313772737979889
train loss item: 0.11549437046051025
train loss item: 0.19016426801681519
train loss item: 0.08416938781738281
train loss item: 0.09861043840646744
train loss item: 0.432945191860199
train loss item: 1.058131217956543
train loss item: 0.07063532620668411
train loss item: 0.1679442822933197
train loss item: 0.10572709143161774
train loss item: 0.13583625853061676
train loss item: 0.1750384271144867
train loss item: 0.32985660433769226
train loss item: 0.30972784757614136
train loss item: 0.24969516694545746
train loss item: 3.162214517593384
train loss item: 0.11106190085411072
train loss item: 0.2436966598033905
test loss item: 0.13393378257751465
test loss item: 0.10357894748449326
test loss item: 0.2958117127418518
test loss item: 0.16854976117610931
test loss item: 0.1688220053911209
test loss item: 0.1133871003985405
test loss item: 0.9990813136100769
test loss item: 0.39635494351387024
test loss item: 0.13704971969127655
test loss item: 0.20606768131256104
test loss item: 0.47104525566101074
test loss item: 0.1191643476486206
test loss item: 0.13038741052150726
test loss item: 0.17485173046588898
test loss item: 0.12715749442577362
test loss item: 0.0812983587384224
test loss item: 0.17023028433322906
test loss item: 0.21570591628551483
test loss item: 0.4580610990524292
test loss item: 0.15953487157821655
test loss item: 0.32708415389060974
test loss item: 0.25699982047080994
test loss item: 0.17102180421352386
test loss item: 0.12885412573814392
test loss item: 0.11782849580049515
test loss item: 0.16604000329971313
test loss item: 0.18112468719482422
test loss item: 0.1402529925107956
test loss item: 0.1970791220664978
test loss item: 0.19204473495483398
test loss item: 0.4119473397731781
test loss item: 0.07461952418088913
test loss item: 0.11945777386426926
test loss item: 0.28864821791648865
test loss item: 0.2030782401561737
test loss item: 0.28864234685897827
test loss item: 0.5294782519340515
test loss item: 0.7002312541007996
test loss item: 0.2344382256269455
test loss item: 0.18493503332138062
test loss item: 0.2028270661830902
test loss item: 0.14217793941497803
test loss item: 0.16722866892814636
test loss item: 0.13906803727149963
test loss item: 0.2565750181674957
test loss item: 0.23521862924098969
test loss item: 0.16720357537269592
test loss item: 0.15829229354858398
test loss item: 0.2653719186782837
test loss item: 0.37332406640052795
test loss item: 0.16804450750350952
test loss item: 0.10924287140369415
test loss item: 0.14410527050495148
test loss item: 0.11569545418024063
test loss item: 0.15690861642360687
test loss item: 0.4290822744369507
test loss item: 0.3617810606956482
test loss item: 0.1514548510313034
test loss item: 0.15716642141342163
test loss item: 0.13262292742729187
test loss item: 0.21600255370140076
test loss item: 0.1671982705593109
test loss item: 0.13945800065994263
test loss item: 0.15862970054149628
test loss item: 0.502632200717926
test loss item: 0.22253470122814178
test loss item: 0.1988542228937149
test loss item: 0.17304226756095886
test loss item: 0.29881998896598816
test loss item: 0.3042055070400238
test loss item: 0.08175045251846313
test loss item: 0.5960285663604736
test loss item: 0.15617534518241882
test loss item: 0.23675446212291718
test loss item: 0.10468503832817078
test loss item: 0.12289951741695404
test loss item: 0.13091862201690674
test loss item: 0.7389742732048035
test loss item: 0.22676850855350494
test loss item: 0.13411317765712738
test loss item: 0.07874544709920883
test loss item: 0.5552128553390503
test loss item: 0.5290501713752747
test loss item: 0.5114342570304871
test loss item: 0.13149520754814148
test loss item: 0.13825589418411255
test loss item: 0.07461167871952057
test loss item: 0.07025996595621109
test loss item: 0.1460951566696167
Epoch [6/10], Training Loss: 0.3284, Testing Loss: 0.2351
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/10
train loss item: 0.2690553069114685
train loss item: 0.49744337797164917
train loss item: 0.13738177716732025
train loss item: 0.2517392039299011
train loss item: 0.4249652922153473
train loss item: 0.18617942929267883
train loss item: 0.16257934272289276
train loss item: 0.3538842797279358
train loss item: 0.14375701546669006
train loss item: 0.17670544981956482
train loss item: 0.19733184576034546
train loss item: 0.17067871987819672
train loss item: 0.11193565279245377
train loss item: 0.320523738861084
train loss item: 0.15368053317070007
train loss item: 0.41376933455467224
train loss item: 0.06317641586065292
train loss item: 0.1736326664686203
train loss item: 0.21353700757026672
train loss item: 0.1905270367860794
train loss item: 0.13855664432048798
train loss item: 0.1220477893948555
train loss item: 0.4792018234729767
train loss item: 0.49927785992622375
train loss item: 0.29672831296920776
train loss item: 0.18822531402111053
train loss item: 0.12336472421884537
train loss item: 0.1793680191040039
train loss item: 0.08580301702022552
train loss item: 0.3248717486858368
train loss item: 1.2291922569274902
train loss item: 0.33194682002067566
train loss item: 0.097310870885849
train loss item: 0.19097164273262024
train loss item: 0.13795098662376404
train loss item: 1.5682363510131836
train loss item: 0.40128469467163086
train loss item: 0.2984718978404999
train loss item: 0.3751593232154846
train loss item: 0.1798751801252365
train loss item: 0.14379937946796417
train loss item: 0.15079541504383087
train loss item: 0.25121989846229553
train loss item: 0.1555170863866806
train loss item: 0.4381895065307617
train loss item: 0.10837026685476303
train loss item: 0.08130300045013428
train loss item: 0.3129991590976715
train loss item: 0.15698666870594025
train loss item: 0.10446800291538239
train loss item: 0.23250925540924072
train loss item: 0.6412122249603271
train loss item: 0.07863409072160721
train loss item: 0.11463811993598938
train loss item: 1.5247571468353271
train loss item: 0.12457915395498276
train loss item: 0.18448799848556519
train loss item: 0.14954979717731476
train loss item: 0.10339120030403137
train loss item: 0.11032659560441971
train loss item: 0.3600628077983856
train loss item: 1.2641246318817139
train loss item: 0.15158332884311676
train loss item: 0.2950957715511322
train loss item: 0.12259450554847717
train loss item: 0.37809208035469055
train loss item: 0.33744993805885315
train loss item: 0.1742953062057495
train loss item: 0.22065968811511993
train loss item: 0.2067362368106842
train loss item: 0.18696272373199463
train loss item: 0.1116843894124031
train loss item: 0.11276288330554962
train loss item: 0.18292659521102905
train loss item: 0.07894188165664673
train loss item: 0.0948614776134491
train loss item: 0.3748113214969635
train loss item: 1.0598634481430054
train loss item: 0.06856154650449753
train loss item: 0.1671118289232254
train loss item: 0.10189405083656311
train loss item: 0.12024785578250885
train loss item: 0.15847009420394897
train loss item: 0.3238813579082489
train loss item: 0.28711453080177307
train loss item: 0.23167690634727478
train loss item: 3.051436185836792
train loss item: 0.10099801421165466
train loss item: 0.2268325835466385
test loss item: 0.1240791380405426
test loss item: 0.09598342329263687
test loss item: 0.3296798765659332
test loss item: 0.15440692007541656
test loss item: 0.15695174038410187
test loss item: 0.0931185707449913
test loss item: 0.9716061353683472
test loss item: 0.37875816226005554
test loss item: 0.1354641169309616
test loss item: 0.20517221093177795
test loss item: 0.5277541279792786
test loss item: 0.10979904979467392
test loss item: 0.1292227804660797
test loss item: 0.15989349782466888
test loss item: 0.12087912857532501
test loss item: 0.07911522686481476
test loss item: 0.1619492918252945
test loss item: 0.21053652465343475
test loss item: 0.4381956458091736
test loss item: 0.1525784581899643
test loss item: 0.3099415600299835
test loss item: 0.24550046026706696
test loss item: 0.15422160923480988
test loss item: 0.11701967567205429
test loss item: 0.11377236992120743
test loss item: 0.15866532921791077
test loss item: 0.1708991527557373
test loss item: 0.12285982817411423
test loss item: 0.18496085703372955
test loss item: 0.18587857484817505
test loss item: 0.45008084177970886
test loss item: 0.06995292007923126
test loss item: 0.10863617807626724
test loss item: 0.29045212268829346
test loss item: 0.20906654000282288
test loss item: 0.27688485383987427
test loss item: 0.5065251588821411
test loss item: 0.8468614816665649
test loss item: 0.22955481708049774
test loss item: 0.16804856061935425
test loss item: 0.19102701544761658
test loss item: 0.1340673416852951
test loss item: 0.15875059366226196
test loss item: 0.13062721490859985
test loss item: 0.23830854892730713
test loss item: 0.228145033121109
test loss item: 0.15104658901691437
test loss item: 0.1508326381444931
test loss item: 0.2701716423034668
test loss item: 0.39219194650650024
test loss item: 0.15956753492355347
test loss item: 0.10371711105108261
test loss item: 0.13894405961036682
test loss item: 0.10433509945869446
test loss item: 0.152035653591156
test loss item: 0.48530706763267517
test loss item: 0.3605579733848572
test loss item: 0.1352187693119049
test loss item: 0.14961308240890503
test loss item: 0.1307988315820694
test loss item: 0.20720332860946655
test loss item: 0.16371262073516846
test loss item: 0.1335718035697937
test loss item: 0.15119688212871552
test loss item: 0.5494830012321472
test loss item: 0.20674240589141846
test loss item: 0.18994416296482086
test loss item: 0.16364529728889465
test loss item: 0.3120814263820648
test loss item: 0.2889366149902344
test loss item: 0.08081785589456558
test loss item: 0.5699342489242554
test loss item: 0.14091269671916962
test loss item: 0.22418774664402008
test loss item: 0.10134685784578323
test loss item: 0.10969043523073196
test loss item: 0.11909951269626617
test loss item: 0.9325453639030457
test loss item: 0.22462445497512817
test loss item: 0.11650845408439636
test loss item: 0.07579264044761658
test loss item: 0.589994490146637
test loss item: 0.5174623727798462
test loss item: 0.624301016330719
test loss item: 0.12471108138561249
test loss item: 0.13341917097568512
test loss item: 0.07084465026855469
test loss item: 0.06542738527059555
test loss item: 0.1530046910047531
Epoch [7/10], Training Loss: 0.3099, Testing Loss: 0.2355
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/10
train loss item: 0.2528838515281677
train loss item: 0.427629292011261
train loss item: 0.12645593285560608
train loss item: 0.2237349897623062
train loss item: 0.20248228311538696
train loss item: 0.1702497899532318
train loss item: 0.15236905217170715
train loss item: 0.323435515165329
train loss item: 0.08630666136741638
train loss item: 0.13210713863372803
train loss item: 0.15939323604106903
train loss item: 0.15978282690048218
train loss item: 0.10087749361991882
train loss item: 0.28691884875297546
train loss item: 0.1444740742444992
train loss item: 0.3982611298561096
train loss item: 0.05664179101586342
train loss item: 0.14752742648124695
train loss item: 0.17748518288135529
train loss item: 0.17338378727436066
train loss item: 0.13567906618118286
train loss item: 0.10308843851089478
train loss item: 0.43387317657470703
train loss item: 0.40207719802856445
train loss item: 0.2729128301143646
train loss item: 0.1728721261024475
train loss item: 0.11465610563755035
train loss item: 0.15900446474552155
train loss item: 0.06491198390722275
train loss item: 0.30267369747161865
train loss item: 1.0976018905639648
train loss item: 0.3256727457046509
train loss item: 0.08617018908262253
train loss item: 0.17329692840576172
train loss item: 0.11731186509132385
train loss item: 1.5082688331604004
train loss item: 0.34731221199035645
train loss item: 0.28172770142555237
train loss item: 0.2630724310874939
train loss item: 0.16403090953826904
train loss item: 0.14118212461471558
train loss item: 0.14349167048931122
train loss item: 0.23966936767101288
train loss item: 0.14428740739822388
train loss item: 0.4161389172077179
train loss item: 0.09893588721752167
train loss item: 0.07732409983873367
train loss item: 0.27518850564956665
train loss item: 0.1405133455991745
train loss item: 0.09741561114788055
train loss item: 0.196659117937088
train loss item: 0.5679452419281006
train loss item: 0.07137337327003479
train loss item: 0.10261611640453339
train loss item: 1.4224164485931396
train loss item: 0.11362934112548828
train loss item: 0.16704009473323822
train loss item: 0.14542832970619202
train loss item: 0.0990021675825119
train loss item: 0.10960327833890915
train loss item: 0.30949684977531433
train loss item: 1.1684331893920898
train loss item: 0.14756785333156586
train loss item: 0.2709764838218689
train loss item: 0.10073646903038025
train loss item: 0.3099285066127777
train loss item: 0.28105005621910095
train loss item: 0.15291036665439606
train loss item: 0.23596982657909393
train loss item: 0.1867050975561142
train loss item: 0.15436257421970367
train loss item: 0.10321608930826187
train loss item: 0.10721120238304138
train loss item: 0.1671491116285324
train loss item: 0.07340051233768463
train loss item: 0.08864691108465195
train loss item: 0.3378825783729553
train loss item: 1.0037657022476196
train loss item: 0.06352069228887558
train loss item: 0.15329252183437347
train loss item: 0.09475479274988174
train loss item: 0.11597327888011932
train loss item: 0.14219924807548523
train loss item: 0.32690712809562683
train loss item: 0.3063502013683319
train loss item: 0.21125416457653046
train loss item: 2.968294382095337
train loss item: 0.09563782811164856
train loss item: 0.21589359641075134
test loss item: 0.12377011030912399
test loss item: 0.09392551332712173
test loss item: 0.3073958158493042
test loss item: 0.15461768209934235
test loss item: 0.15371038019657135
test loss item: 0.09528287500143051
test loss item: 1.122927188873291
test loss item: 0.45025989413261414
test loss item: 0.1317608803510666
test loss item: 0.20129232108592987
test loss item: 0.5079737901687622
test loss item: 0.10797584801912308
test loss item: 0.13423164188861847
test loss item: 0.17538900673389435
test loss item: 0.11646212637424469
test loss item: 0.081511490046978
test loss item: 0.18026195466518402
test loss item: 0.20049840211868286
test loss item: 0.47689536213874817
test loss item: 0.17939233779907227
test loss item: 0.2899298071861267
test loss item: 0.26904165744781494
test loss item: 0.16154201328754425
test loss item: 0.12209343910217285
test loss item: 0.112668976187706
test loss item: 0.15499094128608704
test loss item: 0.18019868433475494
test loss item: 0.12267591804265976
test loss item: 0.1854882538318634
test loss item: 0.18535886704921722
test loss item: 0.4805345833301544
test loss item: 0.07008466869592667
test loss item: 0.1108919084072113
test loss item: 0.2729020416736603
test loss item: 0.19522209465503693
test loss item: 0.2839915454387665
test loss item: 0.5511936545372009
test loss item: 0.7989203929901123
test loss item: 0.22439782321453094
test loss item: 0.17739441990852356
test loss item: 0.20299023389816284
test loss item: 0.1449023336172104
test loss item: 0.15464884042739868
test loss item: 0.14160771667957306
test loss item: 0.22527235746383667
test loss item: 0.2625231146812439
test loss item: 0.16464851796627045
test loss item: 0.1791514903306961
test loss item: 0.27174463868141174
test loss item: 0.395827054977417
test loss item: 0.151327446103096
test loss item: 0.11023924499750137
test loss item: 0.14175568521022797
test loss item: 0.10700935870409012
test loss item: 0.14263315498828888
test loss item: 0.448329359292984
test loss item: 0.3782813251018524
test loss item: 0.1491878181695938
test loss item: 0.15602174401283264
test loss item: 0.1258062720298767
test loss item: 0.19416671991348267
test loss item: 0.1889554262161255
test loss item: 0.1425967961549759
test loss item: 0.14826279878616333
test loss item: 0.548929750919342
test loss item: 0.20515012741088867
test loss item: 0.20123693346977234
test loss item: 0.16850784420967102
test loss item: 0.2965027391910553
test loss item: 0.3226521909236908
test loss item: 0.08138863742351532
test loss item: 0.6634848117828369
test loss item: 0.1616768091917038
test loss item: 0.24932676553726196
test loss item: 0.11300212144851685
test loss item: 0.12182901799678802
test loss item: 0.123351089656353
test loss item: 0.9022581577301025
test loss item: 0.2335069626569748
test loss item: 0.12146558612585068
test loss item: 0.07504896819591522
test loss item: 0.6226820945739746
test loss item: 0.5609545111656189
test loss item: 0.6104802489280701
test loss item: 0.12414433807134628
test loss item: 0.1436799317598343
test loss item: 0.0712922215461731
test loss item: 0.06640568375587463
test loss item: 0.14032141864299774
Epoch [8/10], Training Loss: 0.2819, Testing Loss: 0.2427
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/10
train loss item: 0.2374982386827469
train loss item: 0.40055015683174133
train loss item: 0.1167987808585167
train loss item: 0.20894436538219452
train loss item: 0.20831595361232758
train loss item: 0.15450617671012878
train loss item: 0.13914388418197632
train loss item: 0.29502251744270325
train loss item: 0.07055243104696274
train loss item: 0.1269502192735672
train loss item: 0.1549794226884842
train loss item: 0.1482437402009964
train loss item: 0.09766502678394318
train loss item: 0.28848928213119507
train loss item: 0.13821254670619965
train loss item: 0.33291715383529663
train loss item: 0.05164565145969391
train loss item: 0.14712253212928772
train loss item: 0.16956134140491486
train loss item: 0.15950541198253632
train loss item: 0.13811035454273224
train loss item: 0.10271681100130081
train loss item: 0.3731910288333893
train loss item: 0.33081719279289246
train loss item: 0.2717144191265106
train loss item: 0.16518329083919525
train loss item: 0.10985120385885239
train loss item: 0.15054567158222198
train loss item: 0.05647026374936104
train loss item: 0.278583824634552
train loss item: 0.9928182363510132
train loss item: 0.3021385967731476
train loss item: 0.08487557619810104
train loss item: 0.18241804838180542
train loss item: 0.10720616579055786
train loss item: 1.4582912921905518
train loss item: 0.3089795410633087
train loss item: 0.25437527894973755
train loss item: 0.23665231466293335
train loss item: 0.1484738439321518
train loss item: 0.1301424652338028
train loss item: 0.13487185537815094
train loss item: 0.23341356217861176
train loss item: 0.12759675085544586
train loss item: 0.4039498269557953
train loss item: 0.09271305054426193
train loss item: 0.07573790103197098
train loss item: 0.24997766315937042
train loss item: 0.1282196342945099
train loss item: 0.09311742335557938
train loss item: 0.1627413034439087
train loss item: 0.49946674704551697
train loss item: 0.07010894268751144
train loss item: 0.09899761527776718
train loss item: 1.3499504327774048
train loss item: 0.10299330204725266
train loss item: 0.16261199116706848
train loss item: 0.14151550829410553
train loss item: 0.10643008351325989
train loss item: 0.10094919800758362
train loss item: 0.27501288056373596
train loss item: 1.0887137651443481
train loss item: 0.133083313703537
train loss item: 0.24906140565872192
train loss item: 0.09427778422832489
train loss item: 0.27248242497444153
train loss item: 0.2652284801006317
train loss item: 0.1499801129102707
train loss item: 0.24217376112937927
train loss item: 0.17603272199630737
train loss item: 0.14766594767570496
train loss item: 0.09693893045186996
train loss item: 0.10185074061155319
train loss item: 0.17322713136672974
train loss item: 0.06485071033239365
train loss item: 0.085330069065094
train loss item: 0.3007562756538391
train loss item: 0.9958276748657227
train loss item: 0.05872207507491112
train loss item: 0.14242765307426453
train loss item: 0.09104056656360626
train loss item: 0.10478385537862778
train loss item: 0.14052598178386688
train loss item: 0.33270928263664246
train loss item: 0.31591475009918213
train loss item: 0.2072223722934723
train loss item: 2.8470962047576904
train loss item: 0.09075410664081573
train loss item: 0.20944857597351074
test loss item: 0.11752871423959732
test loss item: 0.09182057529687881
test loss item: 0.29529035091400146
test loss item: 0.14318953454494476
test loss item: 0.15031376481056213
test loss item: 0.09799589961767197
test loss item: 1.0472569465637207
test loss item: 0.3987392783164978
test loss item: 0.12727373838424683
test loss item: 0.1934366524219513
test loss item: 0.5006910562515259
test loss item: 0.1041373685002327
test loss item: 0.13850176334381104
test loss item: 0.16605418920516968
test loss item: 0.11387866735458374
test loss item: 0.07570847868919373
test loss item: 0.1663714498281479
test loss item: 0.18857838213443756
test loss item: 0.43425002694129944
test loss item: 0.174860879778862
test loss item: 0.2728215456008911
test loss item: 0.24111559987068176
test loss item: 0.15811090171337128
test loss item: 0.11536365747451782
test loss item: 0.10739501565694809
test loss item: 0.14489220082759857
test loss item: 0.17107750475406647
test loss item: 0.12392605096101761
test loss item: 0.1785450577735901
test loss item: 0.17465659976005554
test loss item: 0.45631077885627747
test loss item: 0.06582332402467728
test loss item: 0.10643463581800461
test loss item: 0.2519518733024597
test loss item: 0.18493729829788208
test loss item: 0.26571354269981384
test loss item: 0.5050450563430786
test loss item: 0.7821879982948303
test loss item: 0.21318525075912476
test loss item: 0.16431808471679688
test loss item: 0.18485672771930695
test loss item: 0.14410348236560822
test loss item: 0.14815595746040344
test loss item: 0.12964467704296112
test loss item: 0.21620550751686096
test loss item: 0.24399058520793915
test loss item: 0.16311639547348022
test loss item: 0.17248189449310303
test loss item: 0.2586667537689209
test loss item: 0.3766801357269287
test loss item: 0.15007002651691437
test loss item: 0.10966090112924576
test loss item: 0.13336706161499023
test loss item: 0.09943293780088425
test loss item: 0.13590018451213837
test loss item: 0.4349435865879059
test loss item: 0.350372314453125
test loss item: 0.1545528769493103
test loss item: 0.1473197042942047
test loss item: 0.13028179109096527
test loss item: 0.17932754755020142
test loss item: 0.17200344800949097
test loss item: 0.13518501818180084
test loss item: 0.1476583480834961
test loss item: 0.5236534476280212
test loss item: 0.18911051750183105
test loss item: 0.18631568551063538
test loss item: 0.1575469821691513
test loss item: 0.27883872389793396
test loss item: 0.2929254472255707
test loss item: 0.07636252790689468
test loss item: 0.6049450039863586
test loss item: 0.16479258239269257
test loss item: 0.22637203335762024
test loss item: 0.11133286356925964
test loss item: 0.12095407396554947
test loss item: 0.11609098315238953
test loss item: 0.8848876953125
test loss item: 0.22911210358142853
test loss item: 0.12256568670272827
test loss item: 0.06844776123762131
test loss item: 0.5914137959480286
test loss item: 0.5214745402336121
test loss item: 0.605495810508728
test loss item: 0.12331819534301758
test loss item: 0.14070098102092743
test loss item: 0.06434572488069534
test loss item: 0.06002252921462059
test loss item: 0.13141047954559326
Epoch [9/10], Training Loss: 0.2654, Testing Loss: 0.2306
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/10
train loss item: 0.2224770486354828
train loss item: 0.33948302268981934
train loss item: 0.11266041547060013
train loss item: 0.20600837469100952
train loss item: 0.24760283529758453
train loss item: 0.148628830909729
train loss item: 0.13050943613052368
train loss item: 0.2748238444328308
train loss item: 0.08970768004655838
train loss item: 0.14229294657707214
train loss item: 0.16967962682247162
train loss item: 0.1406877040863037
train loss item: 0.09367577731609344
train loss item: 0.26688891649246216
train loss item: 0.14788508415222168
train loss item: 0.3633423149585724
train loss item: 0.054096173495054245
train loss item: 0.15215586125850677
train loss item: 0.18558858335018158
train loss item: 0.14733709394931793
train loss item: 0.12050636112689972
train loss item: 0.10671630501747131
train loss item: 0.4023003876209259
train loss item: 0.32062825560569763
train loss item: 0.2547696828842163
train loss item: 0.13957040011882782
train loss item: 0.10235916078090668
train loss item: 0.13882741332054138
train loss item: 0.05283390358090401
train loss item: 0.2613881230354309
train loss item: 0.8940519094467163
train loss item: 0.33742108941078186
train loss item: 0.07859686017036438
train loss item: 0.15325893461704254
train loss item: 0.10878139734268188
train loss item: 1.4156290292739868
train loss item: 0.27310019731521606
train loss item: 0.22267073392868042
train loss item: 0.19430802762508392
train loss item: 0.13923613727092743
train loss item: 0.11413094401359558
train loss item: 0.13665072619915009
train loss item: 0.22726953029632568
train loss item: 0.13315676152706146
train loss item: 0.3761923313140869
train loss item: 0.09159670770168304
train loss item: 0.07237442582845688
train loss item: 0.2465955764055252
train loss item: 0.12601684033870697
train loss item: 0.09542570263147354
train loss item: 0.16662156581878662
train loss item: 0.4658965468406677
train loss item: 0.06943871825933456
train loss item: 0.1085200384259224
train loss item: 1.2868480682373047
train loss item: 0.11286081373691559
train loss item: 0.14979678392410278
train loss item: 0.13292023539543152
train loss item: 0.08918994665145874
train loss item: 0.10227891802787781
train loss item: 0.24986106157302856
train loss item: 1.0204546451568604
train loss item: 0.11855567991733551
train loss item: 0.24014396965503693
train loss item: 0.09053007513284683
train loss item: 0.2444775402545929
train loss item: 0.23655569553375244
train loss item: 0.147705078125
train loss item: 0.22596906125545502
train loss item: 0.1679989993572235
train loss item: 0.14017267525196075
train loss item: 0.10119324177503586
train loss item: 0.09853264689445496
train loss item: 0.15963682532310486
train loss item: 0.0639081820845604
train loss item: 0.07993842661380768
train loss item: 0.26140156388282776
train loss item: 0.9708443880081177
train loss item: 0.059662509709596634
train loss item: 0.13848324120044708
train loss item: 0.0855073407292366
train loss item: 0.10294497013092041
train loss item: 0.13824476301670074
train loss item: 0.2877553105354309
train loss item: 0.2565600872039795
train loss item: 0.18964047729969025
train loss item: 2.7744739055633545
train loss item: 0.08931254595518112
train loss item: 0.18855759501457214
test loss item: 0.11829967796802521
test loss item: 0.08338980376720428
test loss item: 0.29378288984298706
test loss item: 0.14336305856704712
test loss item: 0.14508706331253052
test loss item: 0.0945182517170906
test loss item: 1.158809781074524
test loss item: 0.4142834544181824
test loss item: 0.12232186645269394
test loss item: 0.18815013766288757
test loss item: 0.4790390133857727
test loss item: 0.10422325879335403
test loss item: 0.1319609135389328
test loss item: 0.21331489086151123
test loss item: 0.10766774415969849
test loss item: 0.06507077068090439
test loss item: 0.1745334416627884
test loss item: 0.18229785561561584
test loss item: 0.44365108013153076
test loss item: 0.18600229918956757
test loss item: 0.2550666928291321
test loss item: 0.2547212541103363
test loss item: 0.1745637059211731
test loss item: 0.11900981515645981
test loss item: 0.10457000881433487
test loss item: 0.1502959430217743
test loss item: 0.1752479374408722
test loss item: 0.11905123293399811
test loss item: 0.17733284831047058
test loss item: 0.17403775453567505
test loss item: 0.47759926319122314
test loss item: 0.0581916980445385
test loss item: 0.10588912665843964
test loss item: 0.24195174872875214
test loss item: 0.17933224141597748
test loss item: 0.26883208751678467
test loss item: 0.5255251526832581
test loss item: 0.7685022950172424
test loss item: 0.2127605825662613
test loss item: 0.17337951064109802
test loss item: 0.19568705558776855
test loss item: 0.16011551022529602
test loss item: 0.1398768573999405
test loss item: 0.13690005242824554
test loss item: 0.21500509977340698
test loss item: 0.25618603825569153
test loss item: 0.17292505502700806
test loss item: 0.192815899848938
test loss item: 0.25271451473236084
test loss item: 0.3749125301837921
test loss item: 0.14378392696380615
test loss item: 0.10721465945243835
test loss item: 0.1358165591955185
test loss item: 0.10015669465065002
test loss item: 0.13273173570632935
test loss item: 0.4172884225845337
test loss item: 0.34987694025039673
test loss item: 0.16792477667331696
test loss item: 0.14878971874713898
test loss item: 0.12010055780410767
test loss item: 0.17388758063316345
test loss item: 0.17819362878799438
test loss item: 0.14374589920043945
test loss item: 0.14304018020629883
test loss item: 0.5193951725959778
test loss item: 0.18952620029449463
test loss item: 0.1962553858757019
test loss item: 0.15952980518341064
test loss item: 0.2703341543674469
test loss item: 0.29049742221832275
test loss item: 0.06770110875368118
test loss item: 0.6508193016052246
test loss item: 0.18757691979408264
test loss item: 0.24750028550624847
test loss item: 0.1099463477730751
test loss item: 0.13150368630886078
test loss item: 0.11963138729333878
test loss item: 0.869256317615509
test loss item: 0.2560209631919861
test loss item: 0.12410102039575577
test loss item: 0.062423430383205414
test loss item: 0.6114076375961304
test loss item: 0.5431535243988037
test loss item: 0.5935313701629639
test loss item: 0.1280086487531662
test loss item: 0.14130890369415283
test loss item: 0.0553220696747303
test loss item: 0.05115294083952904
test loss item: 0.14682699739933014
Epoch [10/10], Training Loss: 0.2538, Testing Loss: 0.2342
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
loss item: 0.190536230802536
loss item: 0.123973049223423
loss item: 0.897817850112915
loss item: 0.37180307507514954
loss item: 0.37768808007240295
loss item: 0.24534058570861816
loss item: 0.15056276321411133
loss item: 0.5307381749153137
loss item: 0.15458278357982635
loss item: 0.14918552339076996
loss item: 0.6368359327316284
loss item: 0.049626272171735764
loss item: 0.612224280834198
loss item: 0.13686583936214447
loss item: 0.14312492311000824
loss item: 0.15939795970916748
loss item: 0.2236396223306656
loss item: 0.25523093342781067
loss item: 0.5350481867790222
loss item: 0.2506589889526367
loss item: 0.1694447249174118
loss item: 0.17708300054073334
loss item: 0.18588756024837494
loss item: 0.17368611693382263
loss item: 0.14552463591098785
loss item: 0.4555828869342804
loss item: 0.6398293375968933
loss item: 0.11592672765254974
loss item: 0.09703876078128815
loss item: 0.24530461430549622
loss item: 0.7041833996772766
loss item: 0.8848617076873779
loss item: 0.09788763523101807
loss item: 0.37824010848999023
loss item: 0.11832936108112335
loss item: 0.15883874893188477
loss item: 0.18316540122032166
loss item: 0.15886303782463074
loss item: 0.28514334559440613
loss item: 0.4394828975200653
loss item: 0.5761812329292297
loss item: 0.19621746242046356
loss item: 0.1317235827445984
loss item: 0.05253142863512039
Val Loss: 0.2947
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.0001 2 360 done at Tue Nov 12 09:28:27 CET 2024
UNet2 with 1 10 0.0005 2 360 start at Tue Nov 12 09:28:27 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 0.9121710062026978
train loss item: 2.170234203338623
train loss item: 0.5969551205635071
train loss item: 1.0422260761260986
train loss item: 1.5058915615081787
train loss item: 0.5180912613868713
train loss item: 0.49037230014801025
train loss item: 1.20503830909729
train loss item: 0.3879775404930115
train loss item: 0.5143818259239197
train loss item: 0.5442823171615601
train loss item: 0.36353808641433716
train loss item: 0.29374197125434875
train loss item: 0.721674382686615
train loss item: 0.36487895250320435
train loss item: 1.0422148704528809
train loss item: 0.3247540593147278
train loss item: 0.384751558303833
train loss item: 0.43143996596336365
train loss item: 0.3903164863586426
train loss item: 0.29459139704704285
train loss item: 0.29048487544059753
train loss item: 1.4911901950836182
train loss item: 1.181415319442749
train loss item: 0.7108883857727051
train loss item: 0.34139105677604675
train loss item: 0.26552310585975647
train loss item: 0.2971615195274353
train loss item: 0.22646090388298035
train loss item: 0.9468911290168762
train loss item: 2.5608320236206055
train loss item: 0.6372052431106567
train loss item: 0.31347858905792236
train loss item: 0.43792685866355896
train loss item: 0.38778653740882874
train loss item: 2.403876781463623
train loss item: 0.5180559158325195
train loss item: 0.454937607049942
train loss item: 0.48163050413131714
train loss item: 0.3169960379600525
train loss item: 0.2842999994754791
train loss item: 0.3337368071079254
train loss item: 0.34325841069221497
train loss item: 0.279103547334671
train loss item: 0.7303104996681213
train loss item: 0.1806126981973648
train loss item: 0.15928435325622559
train loss item: 0.5602288246154785
train loss item: 0.2483481913805008
train loss item: 0.18493935465812683
train loss item: 0.46334409713745117
train loss item: 1.1570740938186646
train loss item: 0.17289067804813385
train loss item: 0.21393296122550964
train loss item: 2.263690710067749
train loss item: 0.20760658383369446
train loss item: 0.3315351903438568
train loss item: 0.26603835821151733
train loss item: 0.22858698666095734
train loss item: 0.19368278980255127
train loss item: 0.973995566368103
train loss item: 2.126312017440796
train loss item: 0.24449199438095093
train loss item: 0.3856185972690582
train loss item: 0.19268381595611572
train loss item: 0.6291232705116272
train loss item: 0.40863367915153503
train loss item: 0.21679054200649261
train loss item: 0.2938111126422882
train loss item: 0.30855199694633484
train loss item: 0.27151304483413696
train loss item: 0.13652412593364716
train loss item: 0.38320818543434143
train loss item: 0.30155375599861145
train loss item: 0.10533125698566437
train loss item: 0.13810761272907257
train loss item: 0.8903178572654724
train loss item: 1.3625606298446655
train loss item: 0.09041062742471695
train loss item: 0.23317070305347443
train loss item: 0.1384125053882599
train loss item: 0.19903598725795746
train loss item: 0.20897766947746277
train loss item: 0.5486323237419128
train loss item: 0.3172820210456848
train loss item: 0.5693963766098022
train loss item: 4.145247459411621
train loss item: 0.18814411759376526
train loss item: 0.5067338347434998
test loss item: 0.18382667005062103
test loss item: 0.1365739405155182
test loss item: 0.41083237528800964
test loss item: 0.20865187048912048
test loss item: 0.23717115819454193
test loss item: 0.14262163639068604
test loss item: 1.1516164541244507
test loss item: 0.35866788029670715
test loss item: 0.17445608973503113
test loss item: 0.3129975199699402
test loss item: 0.6522586345672607
test loss item: 0.14945241808891296
test loss item: 0.171150341629982
test loss item: 0.34414222836494446
test loss item: 0.1705307960510254
test loss item: 0.10266879945993423
test loss item: 0.23076732456684113
test loss item: 0.3608337640762329
test loss item: 0.544313371181488
test loss item: 0.25117790699005127
test loss item: 0.5959290862083435
test loss item: 0.2902483344078064
test loss item: 0.24555017054080963
test loss item: 0.1689915955066681
test loss item: 0.18852053582668304
test loss item: 0.21177612245082855
test loss item: 0.2947025001049042
test loss item: 0.1973285973072052
test loss item: 0.2959226965904236
test loss item: 0.29615315794944763
test loss item: 0.536732017993927
test loss item: 0.08419773727655411
test loss item: 0.15306773781776428
test loss item: 0.46644914150238037
test loss item: 0.32823216915130615
test loss item: 0.41984784603118896
test loss item: 0.6306807398796082
test loss item: 1.0158989429473877
test loss item: 0.3773774802684784
test loss item: 0.23498357832431793
test loss item: 0.25026214122772217
test loss item: 0.19293440878391266
test loss item: 0.2925140857696533
test loss item: 0.158233180642128
test loss item: 0.5004450082778931
test loss item: 0.33732032775878906
test loss item: 0.26091742515563965
test loss item: 0.263500452041626
test loss item: 0.34794875979423523
test loss item: 0.5313205122947693
test loss item: 0.2480410784482956
test loss item: 0.13761262595653534
test loss item: 0.18840177357196808
test loss item: 0.14149489998817444
test loss item: 0.2472057044506073
test loss item: 0.6557876467704773
test loss item: 0.4453950822353363
test loss item: 0.24746428430080414
test loss item: 0.19734199345111847
test loss item: 0.1877332180738449
test loss item: 0.37474972009658813
test loss item: 0.1691061109304428
test loss item: 0.19565612077713013
test loss item: 0.22545501589775085
test loss item: 0.6118927597999573
test loss item: 0.2756834328174591
test loss item: 0.2549784481525421
test loss item: 0.2315780222415924
test loss item: 0.4494320750236511
test loss item: 0.3653990924358368
test loss item: 0.11065135896205902
test loss item: 0.6585938930511475
test loss item: 0.3180546462535858
test loss item: 0.30787891149520874
test loss item: 0.13355079293251038
test loss item: 0.1778392493724823
test loss item: 0.17012012004852295
test loss item: 0.9754599928855896
test loss item: 0.44219520688056946
test loss item: 0.19612756371498108
test loss item: 0.10388363897800446
test loss item: 0.666232705116272
test loss item: 0.6712315082550049
test loss item: 0.6759641170501709
test loss item: 0.19929556548595428
test loss item: 0.18416278064250946
test loss item: 0.09515104442834854
test loss item: 0.07982451468706131
test loss item: 0.18442845344543457
Epoch [1/10], Training Loss: 0.6076, Testing Loss: 0.3221
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/10
train loss item: 0.4450467824935913
train loss item: 0.9824851155281067
train loss item: 0.21558232605457306
train loss item: 0.42215126752853394
train loss item: 0.6178328394889832
train loss item: 0.28241294622421265
train loss item: 0.30494824051856995
train loss item: 0.6950170993804932
train loss item: 0.1655249297618866
train loss item: 0.33107244968414307
train loss item: 0.28655171394348145
train loss item: 0.26815223693847656
train loss item: 0.13096314668655396
train loss item: 0.4538443088531494
train loss item: 0.27114224433898926
train loss item: 0.9579570889472961
train loss item: 0.09154451638460159
train loss item: 0.2752035856246948
train loss item: 0.30435267090797424
train loss item: 0.32244816422462463
train loss item: 0.2022254765033722
train loss item: 0.26377323269844055
train loss item: 1.119254469871521
train loss item: 0.8012851476669312
train loss item: 0.6551558375358582
train loss item: 0.23846478760242462
train loss item: 0.19877980649471283
train loss item: 0.2451377660036087
train loss item: 0.1369827836751938
train loss item: 0.572328507900238
train loss item: 1.978947639465332
train loss item: 0.565528154373169
train loss item: 0.1641027182340622
train loss item: 0.34206950664520264
train loss item: 0.1470012068748474
train loss item: 2.097047805786133
train loss item: 0.6329845786094666
train loss item: 0.4981410503387451
train loss item: 0.6575279831886292
train loss item: 0.24326637387275696
train loss item: 0.24258162081241608
train loss item: 0.3306500017642975
train loss item: 0.3179427981376648
train loss item: 0.25048205256462097
train loss item: 0.7904554009437561
train loss item: 0.16197244822978973
train loss item: 0.14376601576805115
train loss item: 0.3770570158958435
train loss item: 0.24924957752227783
train loss item: 0.19223685562610626
train loss item: 0.28537946939468384
train loss item: 1.1084059476852417
train loss item: 0.10132535547018051
train loss item: 0.1369573473930359
train loss item: 2.324069023132324
train loss item: 0.20837727189064026
train loss item: 0.3174915313720703
train loss item: 0.28133657574653625
train loss item: 0.19239932298660278
train loss item: 0.1410199999809265
train loss item: 0.681387186050415
train loss item: 1.9687566757202148
train loss item: 0.2386859804391861
train loss item: 0.3375028371810913
train loss item: 0.16946417093276978
train loss item: 0.5486193299293518
train loss item: 0.35398101806640625
train loss item: 0.20696553587913513
train loss item: 0.430447518825531
train loss item: 0.30450165271759033
train loss item: 0.1973540484905243
train loss item: 0.12412653863430023
train loss item: 0.264680951833725
train loss item: 0.24869383871555328
train loss item: 0.07241223007440567
train loss item: 0.10423339903354645
train loss item: 0.6838665008544922
train loss item: 1.1029239892959595
train loss item: 0.11991212517023087
train loss item: 0.34055137634277344
train loss item: 0.2376936376094818
train loss item: 0.22207514941692352
train loss item: 0.19671185314655304
train loss item: 0.43061715364456177
train loss item: 0.3548765480518341
train loss item: 0.4760364294052124
train loss item: 3.758190393447876
train loss item: 0.20226047933101654
train loss item: 0.3746556341648102
test loss item: 0.19860294461250305
test loss item: 0.16763918101787567
test loss item: 0.3776116669178009
test loss item: 0.2312430739402771
test loss item: 0.23198853433132172
test loss item: 0.16190336644649506
test loss item: 1.7505863904953003
test loss item: 0.8248295187950134
test loss item: 0.20095330476760864
test loss item: 0.3044755160808563
test loss item: 0.5963309407234192
test loss item: 0.1799955666065216
test loss item: 0.22195079922676086
test loss item: 0.2653982937335968
test loss item: 0.19353701174259186
test loss item: 0.13066476583480835
test loss item: 0.2951430082321167
test loss item: 0.2901497483253479
test loss item: 0.8098485469818115
test loss item: 0.3268722593784332
test loss item: 0.45391082763671875
test loss item: 0.40904268622398376
test loss item: 0.25762489438056946
test loss item: 0.21307724714279175
test loss item: 0.17604738473892212
test loss item: 0.23431158065795898
test loss item: 0.31705668568611145
test loss item: 0.20268899202346802
test loss item: 0.30793607234954834
test loss item: 0.28738275170326233
test loss item: 0.6604254245758057
test loss item: 0.11647699773311615
test loss item: 0.1937674731016159
test loss item: 0.38305869698524475
test loss item: 0.26640674471855164
test loss item: 0.48732510209083557
test loss item: 0.9094134569168091
test loss item: 0.8626341223716736
test loss item: 0.3273560404777527
test loss item: 0.2847084105014801
test loss item: 0.278881311416626
test loss item: 0.2099149525165558
test loss item: 0.2599063217639923
test loss item: 0.19041453301906586
test loss item: 0.3781915009021759
test loss item: 0.47249093651771545
test loss item: 0.2731265127658844
test loss item: 0.2991393208503723
test loss item: 0.3833793103694916
test loss item: 0.6031829714775085
test loss item: 0.2429240345954895
test loss item: 0.1715661585330963
test loss item: 0.1906546801328659
test loss item: 0.14224794507026672
test loss item: 0.21324504911899567
test loss item: 0.5300920605659485
test loss item: 0.6109102964401245
test loss item: 0.23838183283805847
test loss item: 0.237455815076828
test loss item: 0.20286518335342407
test loss item: 0.30572667717933655
test loss item: 0.3051105737686157
test loss item: 0.23982074856758118
test loss item: 0.24700404703617096
test loss item: 0.7333677411079407
test loss item: 0.281881719827652
test loss item: 0.323552668094635
test loss item: 0.2532437741756439
test loss item: 0.38946694135665894
test loss item: 0.5930938124656677
test loss item: 0.12627960741519928
test loss item: 1.1162447929382324
test loss item: 0.2930023670196533
test loss item: 0.41839808225631714
test loss item: 0.1805458664894104
test loss item: 0.1960008293390274
test loss item: 0.21575488150119781
test loss item: 0.8007816076278687
test loss item: 0.34831586480140686
test loss item: 0.20295676589012146
test loss item: 0.12327347695827484
test loss item: 0.8743233680725098
test loss item: 0.8888064026832581
test loss item: 0.6278346180915833
test loss item: 0.22114606201648712
test loss item: 0.2312389463186264
test loss item: 0.11335611343383789
test loss item: 0.11128176003694534
test loss item: 0.1671617478132248
Epoch [2/10], Training Loss: 0.4774, Testing Loss: 0.3614
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/10
train loss item: 0.38973310589790344
train loss item: 0.962831974029541
train loss item: 0.2257280945777893
train loss item: 0.39786016941070557
train loss item: 0.3033396303653717
train loss item: 0.22412295639514923
train loss item: 0.1730143129825592
train loss item: 0.5492135882377625
train loss item: 0.16046284139156342
train loss item: 0.24987687170505524
train loss item: 0.2951280474662781
train loss item: 0.2154567539691925
train loss item: 0.11340955644845963
train loss item: 0.38544753193855286
train loss item: 0.2479952871799469
train loss item: 0.5814380645751953
train loss item: 0.06240956112742424
train loss item: 0.2345605343580246
train loss item: 0.24789609014987946
train loss item: 0.284737229347229
train loss item: 0.20858030021190643
train loss item: 0.1913047581911087
train loss item: 0.5606221556663513
train loss item: 0.6167322993278503
train loss item: 0.4534231722354889
train loss item: 0.22152921557426453
train loss item: 0.1968296319246292
train loss item: 0.23196372389793396
train loss item: 0.08845347911119461
train loss item: 0.533560574054718
train loss item: 1.6304466724395752
train loss item: 0.445546418428421
train loss item: 0.1249990239739418
train loss item: 0.28321075439453125
train loss item: 0.10605650395154953
train loss item: 1.905516505241394
train loss item: 0.48714926838874817
train loss item: 0.3565372824668884
train loss item: 0.5079442262649536
train loss item: 0.1747109591960907
train loss item: 0.19162829220294952
train loss item: 0.28207963705062866
train loss item: 0.33359429240226746
train loss item: 0.21607887744903564
train loss item: 0.7087498903274536
train loss item: 0.15903741121292114
train loss item: 0.1305241882801056
train loss item: 0.5008075833320618
train loss item: 0.2014252245426178
train loss item: 0.12284860014915466
train loss item: 0.32262328267097473
train loss item: 1.0107548236846924
train loss item: 0.06589873135089874
train loss item: 0.18449075520038605
train loss item: 1.892109990119934
train loss item: 0.16044487059116364
train loss item: 0.22927556931972504
train loss item: 0.18706855177879333
train loss item: 0.17526745796203613
train loss item: 0.09595169872045517
train loss item: 0.6438320875167847
train loss item: 1.7525357007980347
train loss item: 0.16533923149108887
train loss item: 0.326094388961792
train loss item: 0.12513422966003418
train loss item: 0.37169259786605835
train loss item: 0.3780488073825836
train loss item: 0.14991970360279083
train loss item: 0.34156277775764465
train loss item: 0.25614476203918457
train loss item: 0.22481834888458252
train loss item: 0.106841541826725
train loss item: 0.146328404545784
train loss item: 0.2284623384475708
train loss item: 0.08163304626941681
train loss item: 0.09982149302959442
train loss item: 0.4963840842247009
train loss item: 1.0956441164016724
train loss item: 0.11939243227243423
train loss item: 0.20589585602283478
train loss item: 0.18293018639087677
train loss item: 0.19615966081619263
train loss item: 0.21735478937625885
train loss item: 0.3943558931350708
train loss item: 0.3952179253101349
train loss item: 0.3338661789894104
train loss item: 3.356621503829956
train loss item: 0.13862977921962738
train loss item: 0.3322161138057709
test loss item: 0.2357233315706253
test loss item: 0.12224382162094116
test loss item: 0.3366797864437103
test loss item: 0.2022504359483719
test loss item: 0.1962735652923584
test loss item: 0.1540890485048294
test loss item: 1.5304021835327148
test loss item: 0.5346867442131042
test loss item: 0.16943030059337616
test loss item: 0.24887891113758087
test loss item: 0.5265551209449768
test loss item: 0.15484286844730377
test loss item: 0.19578316807746887
test loss item: 0.5511397123336792
test loss item: 0.14466997981071472
test loss item: 0.08225420117378235
test loss item: 0.2665351927280426
test loss item: 0.24092034995555878
test loss item: 0.5896663665771484
test loss item: 0.3382899761199951
test loss item: 0.3562913239002228
test loss item: 0.34012410044670105
test loss item: 0.39423689246177673
test loss item: 0.18663717806339264
test loss item: 0.1339767575263977
test loss item: 0.22958111763000488
test loss item: 0.30059272050857544
test loss item: 0.17733702063560486
test loss item: 0.2783944010734558
test loss item: 0.2602711617946625
test loss item: 0.5581129789352417
test loss item: 0.0803426057100296
test loss item: 0.16662649810314178
test loss item: 0.2917434871196747
test loss item: 0.2219845950603485
test loss item: 0.37289994955062866
test loss item: 0.6973702907562256
test loss item: 0.7881031036376953
test loss item: 0.2719917893409729
test loss item: 0.2544759511947632
test loss item: 0.2548745274543762
test loss item: 0.3624008595943451
test loss item: 0.2002364546060562
test loss item: 0.1782834529876709
test loss item: 0.3861173987388611
test loss item: 0.4087575078010559
test loss item: 0.384825199842453
test loss item: 0.3668269217014313
test loss item: 0.292622447013855
test loss item: 0.4744592308998108
test loss item: 0.21224838495254517
test loss item: 0.18967925012111664
test loss item: 0.17851608991622925
test loss item: 0.1377674788236618
test loss item: 0.19652384519577026
test loss item: 0.4296087324619293
test loss item: 0.4515147805213928
test loss item: 0.37149935960769653
test loss item: 0.23075100779533386
test loss item: 0.16033795475959778
test loss item: 0.23390592634677887
test loss item: 0.23445174098014832
test loss item: 0.27567893266677856
test loss item: 0.20886369049549103
test loss item: 0.5995132923126221
test loss item: 0.24867822229862213
test loss item: 0.30342820286750793
test loss item: 0.2174699902534485
test loss item: 0.28447839617729187
test loss item: 0.3809455633163452
test loss item: 0.08075584471225739
test loss item: 0.8982266783714294
test loss item: 0.45710811018943787
test loss item: 0.42396801710128784
test loss item: 0.18412521481513977
test loss item: 0.3200153708457947
test loss item: 0.18819200992584229
test loss item: 0.7700259685516357
test loss item: 0.5689490437507629
test loss item: 0.24971751868724823
test loss item: 0.0896703228354454
test loss item: 0.7487494349479675
test loss item: 0.6999984383583069
test loss item: 0.5846561193466187
test loss item: 0.26152050495147705
test loss item: 0.22341984510421753
test loss item: 0.07608854025602341
test loss item: 0.06809332221746445
test loss item: 0.22198233008384705
Epoch [3/10], Training Loss: 0.4007, Testing Loss: 0.3276
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/10
train loss item: 0.30188924074172974
train loss item: 0.7359023094177246
train loss item: 0.22139397263526917
train loss item: 0.2632397711277008
train loss item: 0.30720850825309753
train loss item: 0.20169687271118164
train loss item: 0.19678451120853424
train loss item: 0.4718441367149353
train loss item: 0.11791804432868958
train loss item: 0.18766212463378906
train loss item: 0.1974048912525177
train loss item: 0.1702798753976822
train loss item: 0.10563228279352188
train loss item: 0.3803000748157501
train loss item: 0.19350972771644592
train loss item: 0.512162983417511
train loss item: 0.07337002456188202
train loss item: 0.16044948995113373
train loss item: 0.22858047485351562
train loss item: 0.198069229722023
train loss item: 0.14832089841365814
train loss item: 0.11870917677879333
train loss item: 0.6211161017417908
train loss item: 0.5854637026786804
train loss item: 0.43456506729125977
train loss item: 0.18959490954875946
train loss item: 0.1214519739151001
train loss item: 0.1789051592350006
train loss item: 0.08676064759492874
train loss item: 0.3124096989631653
train loss item: 1.2388684749603271
train loss item: 0.6585726141929626
train loss item: 0.10945712774991989
train loss item: 0.19693715870380402
train loss item: 0.11325451731681824
train loss item: 1.7327842712402344
train loss item: 0.35835495591163635
train loss item: 0.26887279748916626
train loss item: 0.2869821786880493
train loss item: 0.20208460092544556
train loss item: 0.17955832183361053
train loss item: 0.21974436938762665
train loss item: 0.26068782806396484
train loss item: 0.15225322544574738
train loss item: 0.45804017782211304
train loss item: 0.09115089476108551
train loss item: 0.07979317009449005
train loss item: 0.30913814902305603
train loss item: 0.14546902477741241
train loss item: 0.16005277633666992
train loss item: 0.18137779831886292
train loss item: 0.5510744452476501
train loss item: 0.07234867662191391
train loss item: 0.13205961883068085
train loss item: 1.536494493484497
train loss item: 0.12552987039089203
train loss item: 0.1811203509569168
train loss item: 0.12800326943397522
train loss item: 0.12297999858856201
train loss item: 0.1280650794506073
train loss item: 0.32614782452583313
train loss item: 1.366019606590271
train loss item: 0.11132433265447617
train loss item: 0.28222042322158813
train loss item: 0.10837530344724655
train loss item: 0.3541455566883087
train loss item: 0.29666197299957275
train loss item: 0.13588641583919525
train loss item: 0.32518574595451355
train loss item: 0.20332001149654388
train loss item: 0.1714216023683548
train loss item: 0.11118603497743607
train loss item: 0.19826658070087433
train loss item: 0.1931086927652359
train loss item: 0.06407307088375092
train loss item: 0.11572521179914474
train loss item: 0.4524994492530823
train loss item: 1.0491267442703247
train loss item: 0.07417601346969604
train loss item: 0.2122175395488739
train loss item: 0.11623495817184448
train loss item: 0.19236987829208374
train loss item: 0.1460619419813156
train loss item: 0.44869324564933777
train loss item: 0.2683336138725281
train loss item: 0.21894073486328125
train loss item: 3.13515305519104
train loss item: 0.14630362391471863
train loss item: 0.22743500769138336
test loss item: 0.15796661376953125
test loss item: 0.10089419782161713
test loss item: 0.47785428166389465
test loss item: 0.18094928562641144
test loss item: 0.1842438131570816
test loss item: 0.09784842282533646
test loss item: 1.8177101612091064
test loss item: 0.7232916355133057
test loss item: 0.19340316951274872
test loss item: 0.2866206467151642
test loss item: 0.7911630868911743
test loss item: 0.12759758532047272
test loss item: 0.17946889996528625
test loss item: 0.2689952552318573
test loss item: 0.13238732516765594
test loss item: 0.09001730382442474
test loss item: 0.26892679929733276
test loss item: 0.2744421362876892
test loss item: 0.7028907537460327
test loss item: 0.28726258873939514
test loss item: 0.3994845151901245
test loss item: 0.38342878222465515
test loss item: 0.2501713037490845
test loss item: 0.1592433601617813
test loss item: 0.13999980688095093
test loss item: 0.19122138619422913
test loss item: 0.25996696949005127
test loss item: 0.13844554126262665
test loss item: 0.2523357570171356
test loss item: 0.2498805820941925
test loss item: 0.7851254940032959
test loss item: 0.07226786762475967
test loss item: 0.1312382072210312
test loss item: 0.3548513352870941
test loss item: 0.2806259095668793
test loss item: 0.3913733661174774
test loss item: 0.8282175660133362
test loss item: 1.3055803775787354
test loss item: 0.31071245670318604
test loss item: 0.24234020709991455
test loss item: 0.2712748944759369
test loss item: 0.191110298037529
test loss item: 0.22453589737415314
test loss item: 0.18877704441547394
test loss item: 0.31872156262397766
test loss item: 0.4089086353778839
test loss item: 0.23962631821632385
test loss item: 0.26535147428512573
test loss item: 0.38357260823249817
test loss item: 0.646457850933075
test loss item: 0.19099612534046173
test loss item: 0.13748601078987122
test loss item: 0.18724919855594635
test loss item: 0.12100420147180557
test loss item: 0.188573956489563
test loss item: 0.6925323009490967
test loss item: 0.5670812726020813
test loss item: 0.19244951009750366
test loss item: 0.2036101073026657
test loss item: 0.15440115332603455
test loss item: 0.2575732469558716
test loss item: 0.2717863619327545
test loss item: 0.2079562395811081
test loss item: 0.20432358980178833
test loss item: 0.8179131746292114
test loss item: 0.2387838512659073
test loss item: 0.294543594121933
test loss item: 0.22394590079784393
test loss item: 0.3617265522480011
test loss item: 0.4911554753780365
test loss item: 0.08195216208696365
test loss item: 1.078870415687561
test loss item: 0.28423675894737244
test loss item: 0.3899293839931488
test loss item: 0.15475842356681824
test loss item: 0.1698804646730423
test loss item: 0.16256949305534363
test loss item: 1.3574399948120117
test loss item: 0.3633885085582733
test loss item: 0.1577959656715393
test loss item: 0.06614798307418823
test loss item: 1.021561861038208
test loss item: 0.8716553449630737
test loss item: 0.977820634841919
test loss item: 0.19915449619293213
test loss item: 0.19512847065925598
test loss item: 0.060291629284620285
test loss item: 0.06537129729986191
test loss item: 0.13091856241226196
Epoch [4/10], Training Loss: 0.3309, Testing Loss: 0.3528
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/10
train loss item: 0.30876392126083374
train loss item: 0.798743486404419
train loss item: 0.1466309279203415
train loss item: 0.26477497816085815
train loss item: 0.2775145173072815
train loss item: 0.16874192655086517
train loss item: 0.10298900306224823
train loss item: 0.3225151598453522
train loss item: 0.09951147437095642
train loss item: 0.21607831120491028
train loss item: 0.22030004858970642
train loss item: 0.19161024689674377
train loss item: 0.09188918024301529
train loss item: 0.2958415746688843
train loss item: 0.15136849880218506
train loss item: 0.5231916308403015
train loss item: 0.0785447508096695
train loss item: 0.20142802596092224
train loss item: 0.22451381385326385
train loss item: 0.2336554080247879
train loss item: 0.16799846291542053
train loss item: 0.15681277215480804
train loss item: 0.5091790556907654
train loss item: 0.39574143290519714
train loss item: 0.3284384608268738
train loss item: 0.15654955804347992
train loss item: 0.1276269257068634
train loss item: 0.18329556286334991
train loss item: 0.062443289905786514
train loss item: 0.39322683215141296
train loss item: 1.0935899019241333
train loss item: 0.5144051313400269
train loss item: 0.11490015685558319
train loss item: 0.2486310601234436
train loss item: 0.09568172693252563
train loss item: 1.5532777309417725
train loss item: 0.47664207220077515
train loss item: 0.3295429050922394
train loss item: 0.38812682032585144
train loss item: 0.17344458401203156
train loss item: 0.1632068008184433
train loss item: 0.27988651394844055
train loss item: 0.314984530210495
train loss item: 0.19462262094020844
train loss item: 0.6323772072792053
train loss item: 0.11303577572107315
train loss item: 0.082303486764431
train loss item: 0.5407932996749878
train loss item: 0.19223493337631226
train loss item: 0.1117454469203949
train loss item: 0.41157856583595276
train loss item: 1.2437630891799927
train loss item: 0.08182712644338608
train loss item: 0.24041825532913208
train loss item: 1.5919889211654663
train loss item: 0.14515456557273865
train loss item: 0.2113550305366516
train loss item: 0.1703301966190338
train loss item: 0.15415500104427338
train loss item: 0.08222673088312149
train loss item: 0.7614142298698425
train loss item: 1.3164666891098022
train loss item: 0.13320091366767883
train loss item: 0.22600385546684265
train loss item: 0.11719205975532532
train loss item: 0.3320624530315399
train loss item: 0.2856105864048004
train loss item: 0.20074397325515747
train loss item: 0.17533966898918152
train loss item: 0.20678302645683289
train loss item: 0.1738305538892746
train loss item: 0.10046520829200745
train loss item: 0.14805422723293304
train loss item: 0.21190793812274933
train loss item: 0.07256069779396057
train loss item: 0.08601905405521393
train loss item: 0.3641852140426636
train loss item: 1.1792025566101074
train loss item: 0.11194700747728348
train loss item: 0.16881226003170013
train loss item: 0.16833685338497162
train loss item: 0.15865465998649597
train loss item: 0.2197062224149704
train loss item: 0.3866024911403656
train loss item: 0.3743588924407959
train loss item: 0.22932472825050354
train loss item: 3.02262282371521
train loss item: 0.1425369679927826
train loss item: 0.2276652753353119
test loss item: 0.15937328338623047
test loss item: 0.0998629480600357
test loss item: 0.3559282720088959
test loss item: 0.17844152450561523
test loss item: 0.17283205687999725
test loss item: 0.11006734520196915
test loss item: 1.4120233058929443
test loss item: 0.49045366048812866
test loss item: 0.16333389282226562
test loss item: 0.22650296986103058
test loss item: 0.6162997484207153
test loss item: 0.13809296488761902
test loss item: 0.15214915573596954
test loss item: 0.27502262592315674
test loss item: 0.12907588481903076
test loss item: 0.06877302378416061
test loss item: 0.2135535478591919
test loss item: 0.22157827019691467
test loss item: 0.5499988198280334
test loss item: 0.23034662008285522
test loss item: 0.28923970460891724
test loss item: 0.2975213825702667
test loss item: 0.23077905178070068
test loss item: 0.14712922275066376
test loss item: 0.11927217245101929
test loss item: 0.1891576051712036
test loss item: 0.21197251975536346
test loss item: 0.1369839906692505
test loss item: 0.2209225445985794
test loss item: 0.2076273113489151
test loss item: 0.5951418280601501
test loss item: 0.06271064281463623
test loss item: 0.13158607482910156
test loss item: 0.28677842020988464
test loss item: 0.21693436801433563
test loss item: 0.320677250623703
test loss item: 0.6509897708892822
test loss item: 0.9661182761192322
test loss item: 0.24845516681671143
test loss item: 0.20785649120807648
test loss item: 0.21866652369499207
test loss item: 0.2260182946920395
test loss item: 0.1971810907125473
test loss item: 0.16176478564739227
test loss item: 0.2534262239933014
test loss item: 0.30705830454826355
test loss item: 0.23702673614025116
test loss item: 0.21773198246955872
test loss item: 0.2789459824562073
test loss item: 0.4888911247253418
test loss item: 0.16090774536132812
test loss item: 0.12704350054264069
test loss item: 0.1597982943058014
test loss item: 0.1390191614627838
test loss item: 0.1687808483839035
test loss item: 0.5242500305175781
test loss item: 0.43118563294410706
test loss item: 0.17374102771282196
test loss item: 0.17599348723888397
test loss item: 0.1476341187953949
test loss item: 0.21779023110866547
test loss item: 0.18291792273521423
test loss item: 0.20166848599910736
test loss item: 0.1720677614212036
test loss item: 0.5892134308815002
test loss item: 0.23195570707321167
test loss item: 0.2268012911081314
test loss item: 0.19175517559051514
test loss item: 0.2847616672515869
test loss item: 0.36454102396965027
test loss item: 0.07991635799407959
test loss item: 0.7971625328063965
test loss item: 0.2709095776081085
test loss item: 0.3204149901866913
test loss item: 0.13741111755371094
test loss item: 0.19239959120750427
test loss item: 0.14652103185653687
test loss item: 0.9715666770935059
test loss item: 0.31322917342185974
test loss item: 0.16768330335617065
test loss item: 0.0706145167350769
test loss item: 0.7706530094146729
test loss item: 0.6792054772377014
test loss item: 0.7011962532997131
test loss item: 0.16419580578804016
test loss item: 0.17890922725200653
test loss item: 0.05811399221420288
test loss item: 0.048298098146915436
test loss item: 0.18673491477966309
Epoch [5/10], Training Loss: 0.3444, Testing Loss: 0.2856
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/10
train loss item: 0.2917080819606781
train loss item: 0.7164972424507141
train loss item: 0.13147953152656555
train loss item: 0.27987632155418396
train loss item: 0.2843770384788513
train loss item: 0.16761453449726105
train loss item: 0.18670527637004852
train loss item: 0.30425891280174255
train loss item: 0.07394283264875412
train loss item: 0.1759185492992401
train loss item: 0.13590191304683685
train loss item: 0.14009998738765717
train loss item: 0.10980413854122162
train loss item: 0.2860727310180664
train loss item: 0.1465505063533783
train loss item: 0.4652364253997803
train loss item: 0.07492024451494217
train loss item: 0.13807737827301025
train loss item: 0.18985773622989655
train loss item: 0.16900129616260529
train loss item: 0.13784809410572052
train loss item: 0.0889962762594223
train loss item: 0.5139876008033752
train loss item: 0.3397894501686096
train loss item: 0.33003753423690796
train loss item: 0.13210749626159668
train loss item: 0.12008575350046158
train loss item: 0.1398990899324417
train loss item: 0.06145325303077698
train loss item: 0.3475208878517151
train loss item: 0.9327907562255859
train loss item: 0.6409381628036499
train loss item: 0.09340706467628479
train loss item: 0.1679791361093521
train loss item: 0.09055642038583755
train loss item: 1.4838801622390747
train loss item: 0.32300716638565063
train loss item: 0.2521241009235382
train loss item: 0.2714345157146454
train loss item: 0.18323397636413574
train loss item: 0.166553795337677
train loss item: 0.1785275787115097
train loss item: 0.24153459072113037
train loss item: 0.1433839052915573
train loss item: 0.35480931401252747
train loss item: 0.08396313339471817
train loss item: 0.06536415964365005
train loss item: 0.2773841619491577
train loss item: 0.1251276731491089
train loss item: 0.1365462988615036
train loss item: 0.14717444777488708
train loss item: 0.624744713306427
train loss item: 0.09118638932704926
train loss item: 0.12883266806602478
train loss item: 1.2921864986419678
train loss item: 0.09209629893302917
train loss item: 0.1720963418483734
train loss item: 0.12160768359899521
train loss item: 0.08742205053567886
train loss item: 0.09876390546560287
train loss item: 0.2677594721317291
train loss item: 1.1173241138458252
train loss item: 0.1364602893590927
train loss item: 0.3317979872226715
train loss item: 0.08516701310873032
train loss item: 0.32608267664909363
train loss item: 0.36743441224098206
train loss item: 0.12936784327030182
train loss item: 0.3030230700969696
train loss item: 0.19296792149543762
train loss item: 0.14675557613372803
train loss item: 0.08043692260980606
train loss item: 0.1650424599647522
train loss item: 0.18903164565563202
train loss item: 0.06022094562649727
train loss item: 0.10737326741218567
train loss item: 0.40374940633773804
train loss item: 0.9546975493431091
train loss item: 0.061884235590696335
train loss item: 0.21071948111057281
train loss item: 0.10144209861755371
train loss item: 0.1573868989944458
train loss item: 0.15529625117778778
train loss item: 0.38876670598983765
train loss item: 0.2260516732931137
train loss item: 0.2730070650577545
train loss item: 2.808455228805542
train loss item: 0.12663443386554718
train loss item: 0.30171656608581543
test loss item: 0.16291023790836334
test loss item: 0.1316870152950287
test loss item: 0.3362586796283722
test loss item: 0.16390013694763184
test loss item: 0.17450806498527527
test loss item: 0.11724290996789932
test loss item: 1.4796808958053589
test loss item: 0.5737841725349426
test loss item: 0.17808249592781067
test loss item: 0.2403831034898758
test loss item: 0.547875165939331
test loss item: 0.13837219774723053
test loss item: 0.21409356594085693
test loss item: 0.24027550220489502
test loss item: 0.1435481458902359
test loss item: 0.11822059005498886
test loss item: 0.24261727929115295
test loss item: 0.19831304252147675
test loss item: 0.5944935083389282
test loss item: 0.31974151730537415
test loss item: 0.28238704800605774
test loss item: 0.30169665813446045
test loss item: 0.2560037076473236
test loss item: 0.16345110535621643
test loss item: 0.1258791983127594
test loss item: 0.2054007351398468
test loss item: 0.27207669615745544
test loss item: 0.14851060509681702
test loss item: 0.23286229372024536
test loss item: 0.23042412102222443
test loss item: 0.5712546110153198
test loss item: 0.09682918339967728
test loss item: 0.14571547508239746
test loss item: 0.25883856415748596
test loss item: 0.19890688359737396
test loss item: 0.39480358362197876
test loss item: 0.6646092534065247
test loss item: 0.8090161681175232
test loss item: 0.23292215168476105
test loss item: 0.22034317255020142
test loss item: 0.22941870987415314
test loss item: 0.24336983263492584
test loss item: 0.20039378106594086
test loss item: 0.1642916202545166
test loss item: 0.23945172131061554
test loss item: 0.37840455770492554
test loss item: 0.2680114805698395
test loss item: 0.36549627780914307
test loss item: 0.2880374491214752
test loss item: 0.46363934874534607
test loss item: 0.1835060566663742
test loss item: 0.19311228394508362
test loss item: 0.17013147473335266
test loss item: 0.11956838518381119
test loss item: 0.17896594107151031
test loss item: 0.44195756316185
test loss item: 0.46528106927871704
test loss item: 0.18840336799621582
test loss item: 0.1985771507024765
test loss item: 0.1844901293516159
test loss item: 0.19149208068847656
test loss item: 0.21866105496883392
test loss item: 0.22055545449256897
test loss item: 0.20588934421539307
test loss item: 0.6184965968132019
test loss item: 0.19368413090705872
test loss item: 0.2691214382648468
test loss item: 0.21284855902194977
test loss item: 0.27421262860298157
test loss item: 0.4281408190727234
test loss item: 0.11771370470523834
test loss item: 0.8910461068153381
test loss item: 0.2904866635799408
test loss item: 0.3527377247810364
test loss item: 0.18256451189517975
test loss item: 0.22044122219085693
test loss item: 0.16440220177173615
test loss item: 0.8562572002410889
test loss item: 0.3048493564128876
test loss item: 0.17089883983135223
test loss item: 0.08924304693937302
test loss item: 0.742188572883606
test loss item: 0.6790769100189209
test loss item: 0.6293515563011169
test loss item: 0.1977211982011795
test loss item: 0.21315394341945648
test loss item: 0.08538328856229782
test loss item: 0.0882125124335289
test loss item: 0.11919327825307846
Epoch [6/10], Training Loss: 0.2913, Testing Loss: 0.2980
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/10
train loss item: 0.23642845451831818
train loss item: 0.6114261746406555
train loss item: 0.11677771061658859
train loss item: 0.30851274728775024
train loss item: 0.2074654996395111
train loss item: 0.15800844132900238
train loss item: 0.13778066635131836
train loss item: 0.2566604018211365
train loss item: 0.07851286977529526
train loss item: 0.1385602504014969
train loss item: 0.18616917729377747
train loss item: 0.14761871099472046
train loss item: 0.12545357644557953
train loss item: 0.3064710795879364
train loss item: 0.10190275311470032
train loss item: 0.3700750768184662
train loss item: 0.07921835035085678
train loss item: 0.1408969759941101
train loss item: 0.1782124638557434
train loss item: 0.18238042294979095
train loss item: 0.15545529127120972
train loss item: 0.10131403803825378
train loss item: 0.34511399269104004
train loss item: 0.33312222361564636
train loss item: 0.2412489801645279
train loss item: 0.1431073695421219
train loss item: 0.07144945859909058
train loss item: 0.2087114155292511
train loss item: 0.0827544778585434
train loss item: 0.3110613226890564
train loss item: 0.992316722869873
train loss item: 0.26410606503486633
train loss item: 0.08212482184171677
train loss item: 0.1356925219297409
train loss item: 0.10399218648672104
train loss item: 1.314005970954895
train loss item: 0.48527073860168457
train loss item: 0.3418334424495697
train loss item: 0.44083473086357117
train loss item: 0.13098931312561035
train loss item: 0.14885874092578888
train loss item: 0.24474021792411804
train loss item: 0.2567680776119232
train loss item: 0.18650200963020325
train loss item: 0.6664311289787292
train loss item: 0.11030696332454681
train loss item: 0.08061691373586655
train loss item: 0.3693235218524933
train loss item: 0.20380334556102753
train loss item: 0.11517776548862457
train loss item: 0.2107396125793457
train loss item: 0.8914800882339478
train loss item: 0.07098550349473953
train loss item: 0.10645077377557755
train loss item: 1.6246569156646729
train loss item: 0.1819508820772171
train loss item: 0.22665850818157196
train loss item: 0.18103565275669098
train loss item: 0.1662583202123642
train loss item: 0.13912077248096466
train loss item: 0.3666037619113922
train loss item: 1.0293904542922974
train loss item: 0.17090129852294922
train loss item: 0.2652342915534973
train loss item: 0.09085126221179962
train loss item: 0.28558576107025146
train loss item: 0.18048377335071564
train loss item: 0.12966099381446838
train loss item: 0.3150474429130554
train loss item: 0.18686586618423462
train loss item: 0.15360203385353088
train loss item: 0.09262467175722122
train loss item: 0.16439072787761688
train loss item: 0.14909562468528748
train loss item: 0.06858280301094055
train loss item: 0.08041397482156754
train loss item: 0.2994934916496277
train loss item: 0.8260104060173035
train loss item: 0.07220504432916641
train loss item: 0.18387876451015472
train loss item: 0.10946645587682724
train loss item: 0.16744039952754974
train loss item: 0.1588444858789444
train loss item: 0.4008985459804535
train loss item: 0.30262821912765503
train loss item: 0.2772354185581207
train loss item: 2.6872615814208984
train loss item: 0.09592457115650177
train loss item: 0.24442119896411896
test loss item: 0.19728083908557892
test loss item: 0.08782434463500977
test loss item: 0.2865208387374878
test loss item: 0.18069463968276978
test loss item: 0.15201792120933533
test loss item: 0.11487402021884918
test loss item: 1.9393181800842285
test loss item: 0.633217453956604
test loss item: 0.13507890701293945
test loss item: 0.20377226173877716
test loss item: 0.46524474024772644
test loss item: 0.13970428705215454
test loss item: 0.15076982975006104
test loss item: 0.43086421489715576
test loss item: 0.11186408251523972
test loss item: 0.057719647884368896
test loss item: 0.2589209973812103
test loss item: 0.19761241972446442
test loss item: 0.6222745776176453
test loss item: 0.2935413420200348
test loss item: 0.2904277741909027
test loss item: 0.3634813129901886
test loss item: 0.3222728371620178
test loss item: 0.17449651658535004
test loss item: 0.12335861474275589
test loss item: 0.22707946598529816
test loss item: 0.252035528421402
test loss item: 0.13504719734191895
test loss item: 0.2588658630847931
test loss item: 0.2132701426744461
test loss item: 0.6695393323898315
test loss item: 0.055996134877204895
test loss item: 0.14027190208435059
test loss item: 0.236637681722641
test loss item: 0.18302561342716217
test loss item: 0.4131903648376465
test loss item: 0.7532121539115906
test loss item: 0.608383297920227
test loss item: 0.26336559653282166
test loss item: 0.2737135887145996
test loss item: 0.28324124217033386
test loss item: 0.3028049170970917
test loss item: 0.14034363627433777
test loss item: 0.20313236117362976
test loss item: 0.30835166573524475
test loss item: 0.3806639015674591
test loss item: 0.32128822803497314
test loss item: 0.29561352729797363
test loss item: 0.2665465772151947
test loss item: 0.46266064047813416
test loss item: 0.16761162877082825
test loss item: 0.1418953537940979
test loss item: 0.18194836378097534
test loss item: 0.13025358319282532
test loss item: 0.16455575823783875
test loss item: 0.3493400812149048
test loss item: 0.48989230394363403
test loss item: 0.3108590245246887
test loss item: 0.19962872564792633
test loss item: 0.12639375030994415
test loss item: 0.166263148188591
test loss item: 0.2318428009748459
test loss item: 0.25177255272865295
test loss item: 0.1970125436782837
test loss item: 0.6107296347618103
test loss item: 0.2315664291381836
test loss item: 0.2766656279563904
test loss item: 0.22740262746810913
test loss item: 0.22180667519569397
test loss item: 0.40796101093292236
test loss item: 0.05932817608118057
test loss item: 1.1007517576217651
test loss item: 0.3719383478164673
test loss item: 0.4449438750743866
test loss item: 0.14768455922603607
test loss item: 0.2649192810058594
test loss item: 0.1787884682416916
test loss item: 0.6276689767837524
test loss item: 0.4563030004501343
test loss item: 0.20541158318519592
test loss item: 0.06781718134880066
test loss item: 0.8353351950645447
test loss item: 0.78038090467453
test loss item: 0.5194879174232483
test loss item: 0.21696949005126953
test loss item: 0.19533129036426544
test loss item: 0.055366117507219315
test loss item: 0.046035587787628174
test loss item: 0.19582557678222656
Epoch [7/10], Training Loss: 0.2931, Testing Loss: 0.3083
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/10
train loss item: 0.22049765288829803
train loss item: 0.5859778523445129
train loss item: 0.16289068758487701
train loss item: 0.28753578662872314
train loss item: 0.2663949429988861
train loss item: 0.1471584588289261
train loss item: 0.10576729476451874
train loss item: 0.5483301281929016
train loss item: 0.10709960758686066
train loss item: 0.21180902421474457
train loss item: 0.28622570633888245
train loss item: 0.1461382955312729
train loss item: 0.08172829449176788
train loss item: 0.31885984539985657
train loss item: 0.13059677183628082
train loss item: 0.32261931896209717
train loss item: 0.06185338273644447
train loss item: 0.12313506752252579
train loss item: 0.30748677253723145
train loss item: 0.19046518206596375
train loss item: 0.1508050262928009
train loss item: 0.06630118191242218
train loss item: 0.4601221978664398
train loss item: 0.39790472388267517
train loss item: 0.21642182767391205
train loss item: 0.21676155924797058
train loss item: 0.0832328051328659
train loss item: 0.15331366658210754
train loss item: 0.046637196093797684
train loss item: 0.3811744749546051
train loss item: 1.3000259399414062
train loss item: 0.32662075757980347
train loss item: 0.08836961537599564
train loss item: 0.2459234893321991
train loss item: 0.08655335754156113
train loss item: 1.2566885948181152
train loss item: 0.49425458908081055
train loss item: 0.3562023937702179
train loss item: 0.5695052742958069
train loss item: 0.25854307413101196
train loss item: 0.19059772789478302
train loss item: 0.18427731096744537
train loss item: 0.2573634386062622
train loss item: 0.16950106620788574
train loss item: 0.5306909680366516
train loss item: 0.0861043855547905
train loss item: 0.06407719105482101
train loss item: 0.32005739212036133
train loss item: 0.17531944811344147
train loss item: 0.12523186206817627
train loss item: 0.15436244010925293
train loss item: 0.6811726689338684
train loss item: 0.07526696473360062
train loss item: 0.16409023106098175
train loss item: 1.3971736431121826
train loss item: 0.11955282092094421
train loss item: 0.22035211324691772
train loss item: 0.12851466238498688
train loss item: 0.12186507135629654
train loss item: 0.11547775566577911
train loss item: 0.28252390027046204
train loss item: 0.9774957299232483
train loss item: 0.16108104586601257
train loss item: 0.25798583030700684
train loss item: 0.1410081833600998
train loss item: 0.2626829743385315
train loss item: 0.1784377247095108
train loss item: 0.14775416254997253
train loss item: 0.32357245683670044
train loss item: 0.18242265284061432
train loss item: 0.15950678288936615
train loss item: 0.10883340984582901
train loss item: 0.14049790799617767
train loss item: 0.16159076988697052
train loss item: 0.059981390833854675
train loss item: 0.07945573329925537
train loss item: 0.2882903814315796
train loss item: 0.8447588682174683
train loss item: 0.06608883291482925
train loss item: 0.16093508899211884
train loss item: 0.07790642231702805
train loss item: 0.12051970511674881
train loss item: 0.17716693878173828
train loss item: 0.4557928144931793
train loss item: 0.3844212293624878
train loss item: 0.23792032897472382
train loss item: 2.5815610885620117
train loss item: 0.11406875401735306
train loss item: 0.19860254228115082
test loss item: 0.1529030203819275
test loss item: 0.09998752921819687
test loss item: 0.3464123010635376
test loss item: 0.17188185453414917
test loss item: 0.16672013700008392
test loss item: 0.11919562518596649
test loss item: 1.8083631992340088
test loss item: 0.6050646305084229
test loss item: 0.1478196680545807
test loss item: 0.2202664613723755
test loss item: 0.5395500063896179
test loss item: 0.1294899880886078
test loss item: 0.14855866134166718
test loss item: 0.27637141942977905
test loss item: 0.12128302454948425
test loss item: 0.06471636891365051
test loss item: 0.26104915142059326
test loss item: 0.2179134637117386
test loss item: 0.5916587710380554
test loss item: 0.2735198438167572
test loss item: 0.30764642357826233
test loss item: 0.36145979166030884
test loss item: 0.2519563138484955
test loss item: 0.1746942102909088
test loss item: 0.1284617930650711
test loss item: 0.22489561140537262
test loss item: 0.23965178430080414
test loss item: 0.1460568904876709
test loss item: 0.2519727647304535
test loss item: 0.21493113040924072
test loss item: 0.6745867133140564
test loss item: 0.05489293858408928
test loss item: 0.1436416208744049
test loss item: 0.25849294662475586
test loss item: 0.21590399742126465
test loss item: 0.3265584707260132
test loss item: 0.7209525108337402
test loss item: 0.8123244047164917
test loss item: 0.27471107244491577
test loss item: 0.26671749353408813
test loss item: 0.2766426205635071
test loss item: 0.215915709733963
test loss item: 0.148620143532753
test loss item: 0.20078600943088531
test loss item: 0.2628563642501831
test loss item: 0.37335315346717834
test loss item: 0.23775418102741241
test loss item: 0.25688233971595764
test loss item: 0.29321810603141785
test loss item: 0.48121342062950134
test loss item: 0.16955424845218658
test loss item: 0.14130724966526031
test loss item: 0.19413435459136963
test loss item: 0.12250674515962601
test loss item: 0.18483878672122955
test loss item: 0.45819324254989624
test loss item: 0.45825761556625366
test loss item: 0.1785736382007599
test loss item: 0.20099863409996033
test loss item: 0.1344885677099228
test loss item: 0.1794498860836029
test loss item: 0.24312566220760345
test loss item: 0.23261189460754395
test loss item: 0.19195780158042908
test loss item: 0.6664904952049255
test loss item: 0.21223555505275726
test loss item: 0.28488656878471375
test loss item: 0.22523963451385498
test loss item: 0.24930483102798462
test loss item: 0.3845141530036926
test loss item: 0.06485873460769653
test loss item: 1.0456485748291016
test loss item: 0.29792875051498413
test loss item: 0.42311912775039673
test loss item: 0.14412380754947662
test loss item: 0.19107362627983093
test loss item: 0.177922785282135
test loss item: 0.8716745972633362
test loss item: 0.3459792137145996
test loss item: 0.1741134524345398
test loss item: 0.06528681516647339
test loss item: 0.8357605934143066
test loss item: 0.7468024492263794
test loss item: 0.6508201360702515
test loss item: 0.21833279728889465
test loss item: 0.18090470135211945
test loss item: 0.052669458091259
test loss item: 0.04380989819765091
test loss item: 0.1576373279094696
Epoch [8/10], Training Loss: 0.2964, Testing Loss: 0.3041
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/10
train loss item: 0.2419966757297516
train loss item: 0.5365004539489746
train loss item: 0.11577986925840378
train loss item: 0.22616221010684967
train loss item: 0.1262909173965454
train loss item: 0.13671191036701202
train loss item: 0.0924627035856247
train loss item: 0.2431391477584839
train loss item: 0.07346247881650925
train loss item: 0.1228218600153923
train loss item: 0.1616969108581543
train loss item: 0.12617318332195282
train loss item: 0.07462260872125626
train loss item: 0.2690737247467041
train loss item: 0.10194303095340729
train loss item: 0.2740916311740875
train loss item: 0.06181475147604942
train loss item: 0.10286026448011398
train loss item: 0.17018456757068634
train loss item: 0.14918629825115204
train loss item: 0.1365470141172409
train loss item: 0.06488648056983948
train loss item: 0.4123314321041107
train loss item: 0.3102053105831146
train loss item: 0.2100813388824463
train loss item: 0.12446913123130798
train loss item: 0.07638414949178696
train loss item: 0.15282613039016724
train loss item: 0.04843476414680481
train loss item: 0.37728190422058105
train loss item: 0.9780248403549194
train loss item: 0.2992061972618103
train loss item: 0.0819917544722557
train loss item: 0.1635037660598755
train loss item: 0.09805136173963547
train loss item: 1.1838546991348267
train loss item: 0.2528859078884125
train loss item: 0.3033710718154907
train loss item: 0.34106916189193726
train loss item: 0.2065534144639969
train loss item: 0.1671988070011139
train loss item: 0.16682417690753937
train loss item: 0.23498152196407318
train loss item: 0.1546565741300583
train loss item: 0.4361913800239563
train loss item: 0.0820150077342987
train loss item: 0.05822638422250748
train loss item: 0.2520652115345001
train loss item: 0.15215513110160828
train loss item: 0.10550374537706375
train loss item: 0.13489730656147003
train loss item: 0.5191693305969238
train loss item: 0.08769318461418152
train loss item: 0.13132143020629883
train loss item: 1.0467091798782349
train loss item: 0.08898348361253738
train loss item: 0.1837337613105774
train loss item: 0.11605241894721985
train loss item: 0.10152699053287506
train loss item: 0.10121393203735352
train loss item: 0.2818751633167267
train loss item: 0.7694605588912964
train loss item: 0.10490056127309799
train loss item: 0.18371796607971191
train loss item: 0.07745184004306793
train loss item: 0.2329491674900055
train loss item: 0.192063570022583
train loss item: 0.11005941778421402
train loss item: 0.2846924960613251
train loss item: 0.13408932089805603
train loss item: 0.09559139609336853
train loss item: 0.09608405828475952
train loss item: 0.10870886594057083
train loss item: 0.12569266557693481
train loss item: 0.06682699918746948
train loss item: 0.0876355990767479
train loss item: 0.2808050215244293
train loss item: 0.7616645693778992
train loss item: 0.05041808634996414
train loss item: 0.15996120870113373
train loss item: 0.0960361510515213
train loss item: 0.09999557584524155
train loss item: 0.1317289173603058
train loss item: 0.41948845982551575
train loss item: 0.3284982442855835
train loss item: 0.22730782628059387
train loss item: 2.449130058288574
train loss item: 0.0803440734744072
train loss item: 0.17254860699176788
test loss item: 0.1281537562608719
test loss item: 0.07008583098649979
test loss item: 0.3504422605037689
test loss item: 0.15222913026809692
test loss item: 0.14800098538398743
test loss item: 0.08326750248670578
test loss item: 1.7728780508041382
test loss item: 0.6419951319694519
test loss item: 0.14041152596473694
test loss item: 0.21616187691688538
test loss item: 0.5378171801567078
test loss item: 0.1139649897813797
test loss item: 0.14937078952789307
test loss item: 0.2274664342403412
test loss item: 0.10440336167812347
test loss item: 0.05461540445685387
test loss item: 0.2461981326341629
test loss item: 0.20580041408538818
test loss item: 0.6109062433242798
test loss item: 0.2630102038383484
test loss item: 0.3521655797958374
test loss item: 0.35522887110710144
test loss item: 0.22532570362091064
test loss item: 0.15292170643806458
test loss item: 0.11887702345848083
test loss item: 0.17476460337638855
test loss item: 0.2218804657459259
test loss item: 0.11596132069826126
test loss item: 0.22602948546409607
test loss item: 0.19083958864212036
test loss item: 0.6807311773300171
test loss item: 0.052562370896339417
test loss item: 0.12099797278642654
test loss item: 0.2611100673675537
test loss item: 0.20763103663921356
test loss item: 0.3508034944534302
test loss item: 0.7244864702224731
test loss item: 0.8263524174690247
test loss item: 0.2647746801376343
test loss item: 0.24184109270572662
test loss item: 0.2555787265300751
test loss item: 0.17541426420211792
test loss item: 0.15052133798599243
test loss item: 0.18450438976287842
test loss item: 0.28200000524520874
test loss item: 0.3693874776363373
test loss item: 0.21239116787910461
test loss item: 0.24282370507717133
test loss item: 0.3060855269432068
test loss item: 0.481405109167099
test loss item: 0.1587420403957367
test loss item: 0.11907210946083069
test loss item: 0.165733203291893
test loss item: 0.10704873502254486
test loss item: 0.15151095390319824
test loss item: 0.46849989891052246
test loss item: 0.48042598366737366
test loss item: 0.1798318475484848
test loss item: 0.182612806558609
test loss item: 0.11743686348199844
test loss item: 0.15856939554214478
test loss item: 0.2485342174768448
test loss item: 0.19908221065998077
test loss item: 0.17596082389354706
test loss item: 0.6853188872337341
test loss item: 0.19337968528270721
test loss item: 0.2638535797595978
test loss item: 0.2050429880619049
test loss item: 0.2693631052970886
test loss item: 0.42760229110717773
test loss item: 0.050103042274713516
test loss item: 1.0392444133758545
test loss item: 0.2692849040031433
test loss item: 0.3972293436527252
test loss item: 0.13345177471637726
test loss item: 0.15504895150661469
test loss item: 0.15600621700286865
test loss item: 0.9218890070915222
test loss item: 0.3024044632911682
test loss item: 0.14134760200977325
test loss item: 0.049744825810194016
test loss item: 0.8350850939750671
test loss item: 0.7472962737083435
test loss item: 0.6688566207885742
test loss item: 0.17933374643325806
test loss item: 0.1641400307416916
test loss item: 0.045671164989471436
test loss item: 0.0444897897541523
test loss item: 0.1218777522444725
Epoch [9/10], Training Loss: 0.2445, Testing Loss: 0.2935
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/10
train loss item: 0.206228569149971
train loss item: 0.49478110671043396
train loss item: 0.09272352606058121
train loss item: 0.22243531048297882
train loss item: 0.19625169038772583
train loss item: 0.1521158665418625
train loss item: 0.08723419159650803
train loss item: 0.22830389440059662
train loss item: 0.07036270946264267
train loss item: 0.15169212222099304
train loss item: 0.20166665315628052
train loss item: 0.11882169544696808
train loss item: 0.0752955824136734
train loss item: 0.2862299680709839
train loss item: 0.11533485352993011
train loss item: 0.23958274722099304
train loss item: 0.052134595811367035
train loss item: 0.10304943472146988
train loss item: 0.20852430164813995
train loss item: 0.16666476428508759
train loss item: 0.13567472994327545
train loss item: 0.07476091384887695
train loss item: 0.3251969516277313
train loss item: 0.35185080766677856
train loss item: 0.19292578101158142
train loss item: 0.11453232169151306
train loss item: 0.0697084590792656
train loss item: 0.12065647542476654
train loss item: 0.05295652523636818
train loss item: 0.3482625186443329
train loss item: 0.8224490880966187
train loss item: 0.2647131383419037
train loss item: 0.06957712024450302
train loss item: 0.17017364501953125
train loss item: 0.09610757976770401
train loss item: 1.071749210357666
train loss item: 0.21929921209812164
train loss item: 0.2941388487815857
train loss item: 0.3364157974720001
train loss item: 0.20316913723945618
train loss item: 0.17039059102535248
train loss item: 0.16272228956222534
train loss item: 0.2473621964454651
train loss item: 0.14734205603599548
train loss item: 0.41640228033065796
train loss item: 0.07140637934207916
train loss item: 0.06473581492900848
train loss item: 0.3393242657184601
train loss item: 0.15014755725860596
train loss item: 0.08986348658800125
train loss item: 0.16996513307094574
train loss item: 0.5761714577674866
train loss item: 0.0812893956899643
train loss item: 0.11372409015893936
train loss item: 0.9481659531593323
train loss item: 0.11357077956199646
train loss item: 0.18908020853996277
train loss item: 0.11592675745487213
train loss item: 0.12216278165578842
train loss item: 0.10178498923778534
train loss item: 0.27420639991760254
train loss item: 0.6744824647903442
train loss item: 0.09494097530841827
train loss item: 0.19157040119171143
train loss item: 0.07117465883493423
train loss item: 0.1899111568927765
train loss item: 0.1869058459997177
train loss item: 0.1297197788953781
train loss item: 0.2826390266418457
train loss item: 0.12904393672943115
train loss item: 0.09578840434551239
train loss item: 0.09955790638923645
train loss item: 0.09066516906023026
train loss item: 0.12273485958576202
train loss item: 0.054058682173490524
train loss item: 0.07948827743530273
train loss item: 0.26590538024902344
train loss item: 0.7040834426879883
train loss item: 0.04554302617907524
train loss item: 0.14806164801120758
train loss item: 0.08231613039970398
train loss item: 0.08518297970294952
train loss item: 0.11977273225784302
train loss item: 0.3733292818069458
train loss item: 0.29767459630966187
train loss item: 0.2957868278026581
train loss item: 2.383212089538574
train loss item: 0.08736629039049149
train loss item: 0.13981851935386658
test loss item: 0.13108763098716736
test loss item: 0.06826060265302658
test loss item: 0.3537612557411194
test loss item: 0.15740330517292023
test loss item: 0.14192791283130646
test loss item: 0.08342359215021133
test loss item: 1.8209093809127808
test loss item: 0.6312081813812256
test loss item: 0.14016346633434296
test loss item: 0.2143571525812149
test loss item: 0.5488119125366211
test loss item: 0.11733125895261765
test loss item: 0.1368931382894516
test loss item: 0.2623635232448578
test loss item: 0.10233656316995621
test loss item: 0.05276860296726227
test loss item: 0.2529563307762146
test loss item: 0.19742818176746368
test loss item: 0.5958837866783142
test loss item: 0.2619989514350891
test loss item: 0.3286401927471161
test loss item: 0.36382758617401123
test loss item: 0.22763603925704956
test loss item: 0.15531089901924133
test loss item: 0.12307708710432053
test loss item: 0.18310250341892242
test loss item: 0.22539550065994263
test loss item: 0.11221995949745178
test loss item: 0.23643836379051208
test loss item: 0.192268505692482
test loss item: 0.6980499029159546
test loss item: 0.0470288023352623
test loss item: 0.11990389972925186
test loss item: 0.26162412762641907
test loss item: 0.204112708568573
test loss item: 0.33779284358024597
test loss item: 0.7231641411781311
test loss item: 0.8478413820266724
test loss item: 0.27174440026283264
test loss item: 0.253848135471344
test loss item: 0.269727885723114
test loss item: 0.17896434664726257
test loss item: 0.14249539375305176
test loss item: 0.19547642767429352
test loss item: 0.27491769194602966
test loss item: 0.372214674949646
test loss item: 0.2094932645559311
test loss item: 0.22590412199497223
test loss item: 0.3028523623943329
test loss item: 0.48482394218444824
test loss item: 0.15526306629180908
test loss item: 0.10295826196670532
test loss item: 0.1717471480369568
test loss item: 0.11384014785289764
test loss item: 0.14718890190124512
test loss item: 0.4711464047431946
test loss item: 0.4707070589065552
test loss item: 0.18038588762283325
test loss item: 0.18188582360744476
test loss item: 0.10888805985450745
test loss item: 0.16507293283939362
test loss item: 0.2471906691789627
test loss item: 0.20112986862659454
test loss item: 0.18063268065452576
test loss item: 0.6802865862846375
test loss item: 0.20306891202926636
test loss item: 0.26739612221717834
test loss item: 0.21373941004276276
test loss item: 0.26238396763801575
test loss item: 0.3937948942184448
test loss item: 0.054097019135951996
test loss item: 1.0534484386444092
test loss item: 0.2801845371723175
test loss item: 0.4163300693035126
test loss item: 0.1286054402589798
test loss item: 0.15616698563098907
test loss item: 0.16017486155033112
test loss item: 0.9332191944122314
test loss item: 0.3284926414489746
test loss item: 0.14207378029823303
test loss item: 0.05073152482509613
test loss item: 0.8453572988510132
test loss item: 0.7547177672386169
test loss item: 0.6779764294624329
test loss item: 0.18743665516376495
test loss item: 0.16887277364730835
test loss item: 0.045090507715940475
test loss item: 0.042304787784814835
test loss item: 0.14459529519081116
Epoch [10/10], Training Loss: 0.2358, Testing Loss: 0.2958
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
loss item: 0.24590326845645905
loss item: 0.1629374921321869
loss item: 0.9796351194381714
loss item: 0.45697149634361267
loss item: 0.5490306615829468
loss item: 0.399656742811203
loss item: 0.14236313104629517
loss item: 0.7910221815109253
loss item: 0.19856393337249756
loss item: 0.1568710058927536
loss item: 1.0186078548431396
loss item: 0.03340493515133858
loss item: 0.887047529220581
loss item: 0.16206896305084229
loss item: 0.17161975800991058
loss item: 0.16406428813934326
loss item: 0.3301212191581726
loss item: 0.30707818269729614
loss item: 0.7234527468681335
loss item: 0.37322184443473816
loss item: 0.21305611729621887
loss item: 0.22663667798042297
loss item: 0.2825436592102051
loss item: 0.23261232674121857
loss item: 0.1890936642885208
loss item: 0.6298019886016846
loss item: 0.7782456278800964
loss item: 0.10961240530014038
loss item: 0.08240455389022827
loss item: 0.3985651135444641
loss item: 1.049535870552063
loss item: 1.0974558591842651
loss item: 0.09899301826953888
loss item: 0.5407270193099976
loss item: 0.1328652799129486
loss item: 0.18214289844036102
loss item: 0.18995988368988037
loss item: 0.21721035242080688
loss item: 0.4099058210849762
loss item: 0.6520776152610779
loss item: 0.726865291595459
loss item: 0.29860278964042664
loss item: 0.1821890026330948
loss item: 0.03891543671488762
Val Loss: 0.3912
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.0005 2 360 done at Tue Nov 12 09:30:56 CET 2024
UNet2 with 1 10 0.001 2 360 start at Tue Nov 12 09:30:56 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 10, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 0.9121710062026978
train loss item: 2.1258654594421387
train loss item: 0.7656190395355225
train loss item: 1.100437045097351
train loss item: 2.1631789207458496
train loss item: 0.6007260680198669
train loss item: 0.6121547222137451
train loss item: 1.1712100505828857
train loss item: 0.3923240602016449
train loss item: 0.585159182548523
train loss item: 0.5905365347862244
train loss item: 0.3662756681442261
train loss item: 0.2392287701368332
train loss item: 0.7452740669250488
train loss item: 0.3706638514995575
train loss item: 1.076843023300171
train loss item: 0.3176692724227905
train loss item: 0.3876906931400299
train loss item: 0.4380272924900055
train loss item: 0.3998122811317444
train loss item: 0.28461408615112305
train loss item: 0.28989002108573914
train loss item: 1.4297986030578613
train loss item: 1.2458375692367554
train loss item: 0.7810567021369934
train loss item: 0.3620368540287018
train loss item: 0.3075741231441498
train loss item: 0.2973628044128418
train loss item: 0.20465140044689178
train loss item: 1.1250691413879395
train loss item: 2.6976158618927
train loss item: 0.6823355555534363
train loss item: 0.32735753059387207
train loss item: 0.5191559791564941
train loss item: 0.39297470450401306
train loss item: 2.5494320392608643
train loss item: 0.5253247618675232
train loss item: 0.3948175609111786
train loss item: 0.5120791792869568
train loss item: 0.3301679491996765
train loss item: 0.2458365261554718
train loss item: 0.3248426914215088
train loss item: 0.3641613721847534
train loss item: 0.2319786548614502
train loss item: 0.6995223760604858
train loss item: 0.2514076232910156
train loss item: 0.21891114115715027
train loss item: 0.49499350786209106
train loss item: 0.3015252351760864
train loss item: 0.21804651618003845
train loss item: 0.4015234112739563
train loss item: 1.126977562904358
train loss item: 0.16852876543998718
train loss item: 0.20971401035785675
train loss item: 2.4145195484161377
train loss item: 0.23036234080791473
train loss item: 0.3066193461418152
train loss item: 0.2792584002017975
train loss item: 0.2303459197282791
train loss item: 0.15960665047168732
train loss item: 1.0253320932388306
train loss item: 2.2420740127563477
train loss item: 0.28447070717811584
train loss item: 0.4374005198478699
train loss item: 0.20419026911258698
train loss item: 0.7708473801612854
train loss item: 0.47442442178726196
train loss item: 0.23222716152668
train loss item: 0.35465168952941895
train loss item: 0.35609129071235657
train loss item: 0.26264721155166626
train loss item: 0.17640453577041626
train loss item: 0.4031560719013214
train loss item: 0.32627877593040466
train loss item: 0.15429958701133728
train loss item: 0.1423220932483673
train loss item: 0.9998055696487427
train loss item: 1.4292393922805786
train loss item: 0.1378229409456253
train loss item: 0.34643471240997314
train loss item: 0.15509024262428284
train loss item: 0.17755380272865295
train loss item: 0.24281640350818634
train loss item: 0.5816525816917419
train loss item: 0.39295297861099243
train loss item: 0.64891117811203
train loss item: 4.20023250579834
train loss item: 0.21325857937335968
train loss item: 0.6316530108451843
test loss item: 0.18573616445064545
test loss item: 0.11039507389068604
test loss item: 0.47446414828300476
test loss item: 0.21506178379058838
test loss item: 0.2324116975069046
test loss item: 0.12542012333869934
test loss item: 1.373991847038269
test loss item: 0.4523073732852936
test loss item: 0.19234715402126312
test loss item: 0.36099186539649963
test loss item: 0.709503173828125
test loss item: 0.1455998718738556
test loss item: 0.1777210384607315
test loss item: 0.36248624324798584
test loss item: 0.16839507222175598
test loss item: 0.07317930459976196
test loss item: 0.27593159675598145
test loss item: 0.42546015977859497
test loss item: 0.6373082399368286
test loss item: 0.28225329518318176
test loss item: 0.7065306305885315
test loss item: 0.3206615149974823
test loss item: 0.3108065128326416
test loss item: 0.17070086300373077
test loss item: 0.20971150696277618
test loss item: 0.27909114956855774
test loss item: 0.3343096673488617
test loss item: 0.1875535398721695
test loss item: 0.3149206340312958
test loss item: 0.3434613347053528
test loss item: 0.624456524848938
test loss item: 0.06111176684498787
test loss item: 0.15173649787902832
test loss item: 0.5297618508338928
test loss item: 0.38473543524742126
test loss item: 0.46958616375923157
test loss item: 0.7320057153701782
test loss item: 1.112637996673584
test loss item: 0.433261513710022
test loss item: 0.2553984522819519
test loss item: 0.27558115124702454
test loss item: 0.1847885400056839
test loss item: 0.3568969666957855
test loss item: 0.1688612401485443
test loss item: 0.5815560221672058
test loss item: 0.40351372957229614
test loss item: 0.30278921127319336
test loss item: 0.2927902936935425
test loss item: 0.38657346367836
test loss item: 0.622253954410553
test loss item: 0.2801019847393036
test loss item: 0.1462196260690689
test loss item: 0.23224709928035736
test loss item: 0.12738361954689026
test loss item: 0.3159025013446808
test loss item: 0.746019184589386
test loss item: 0.5049576163291931
test loss item: 0.29097527265548706
test loss item: 0.22575561702251434
test loss item: 0.2249361127614975
test loss item: 0.4290810823440552
test loss item: 0.1866779923439026
test loss item: 0.25087499618530273
test loss item: 0.25192567706108093
test loss item: 0.7237311005592346
test loss item: 0.2963245213031769
test loss item: 0.3128970265388489
test loss item: 0.2469007670879364
test loss item: 0.4840162694454193
test loss item: 0.41413629055023193
test loss item: 0.0728050023317337
test loss item: 0.840832531452179
test loss item: 0.3359127342700958
test loss item: 0.3533949553966522
test loss item: 0.15103302896022797
test loss item: 0.17004652321338654
test loss item: 0.16946670413017273
test loss item: 1.0761560201644897
test loss item: 0.4618690609931946
test loss item: 0.19068297743797302
test loss item: 0.08925171941518784
test loss item: 0.7471039891242981
test loss item: 0.7751322388648987
test loss item: 0.7345174551010132
test loss item: 0.28912729024887085
test loss item: 0.22510449588298798
test loss item: 0.07566671818494797
test loss item: 0.059314023703336716
test loss item: 0.16778980195522308
Epoch [1/10], Training Loss: 0.6461, Testing Loss: 0.3614
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/10
train loss item: 0.48665037751197815
train loss item: 1.1615359783172607
train loss item: 0.27293288707733154
train loss item: 0.5829629302024841
train loss item: 0.49121662974357605
train loss item: 0.30032771825790405
train loss item: 0.49080514907836914
train loss item: 0.697040855884552
train loss item: 0.24364978075027466
train loss item: 0.36693501472473145
train loss item: 0.32848209142684937
train loss item: 0.28080955147743225
train loss item: 0.1381971687078476
train loss item: 0.4501991868019104
train loss item: 0.27488595247268677
train loss item: 0.7843855023384094
train loss item: 0.09665995836257935
train loss item: 0.2814568877220154
train loss item: 0.3409649431705475
train loss item: 0.3013257384300232
train loss item: 0.2096235156059265
train loss item: 0.13291700184345245
train loss item: 1.0211668014526367
train loss item: 0.8384483456611633
train loss item: 0.6219689846038818
train loss item: 0.2613876163959503
train loss item: 0.18609194457530975
train loss item: 0.26740261912345886
train loss item: 0.15649399161338806
train loss item: 0.6646139025688171
train loss item: 2.1474833488464355
train loss item: 0.62767094373703
train loss item: 0.15585872530937195
train loss item: 0.37342655658721924
train loss item: 0.1427515149116516
train loss item: 2.0818710327148438
train loss item: 0.6713902950286865
train loss item: 0.5651168823242188
train loss item: 0.728975236415863
train loss item: 0.2976408004760742
train loss item: 0.23928357660770416
train loss item: 0.33928191661834717
train loss item: 0.3826754689216614
train loss item: 0.26387959718704224
train loss item: 0.8121520280838013
train loss item: 0.13374173641204834
train loss item: 0.17160259187221527
train loss item: 0.5792803168296814
train loss item: 0.2960369288921356
train loss item: 0.18335272371768951
train loss item: 0.4162694811820984
train loss item: 1.2744544744491577
train loss item: 0.07771602272987366
train loss item: 0.13509595394134521
train loss item: 2.4734129905700684
train loss item: 0.20549899339675903
train loss item: 0.28258854150772095
train loss item: 0.2546379268169403
train loss item: 0.22661451995372772
train loss item: 0.1906350553035736
train loss item: 0.8574021458625793
train loss item: 2.1517767906188965
train loss item: 0.2441401183605194
train loss item: 0.3639388084411621
train loss item: 0.17409786581993103
train loss item: 0.5436062216758728
train loss item: 0.3908716142177582
train loss item: 0.19505375623703003
train loss item: 0.3971502482891083
train loss item: 0.3207044303417206
train loss item: 0.2358579784631729
train loss item: 0.12035752832889557
train loss item: 0.19457724690437317
train loss item: 0.25068381428718567
train loss item: 0.07541542500257492
train loss item: 0.10324722528457642
train loss item: 0.7521311640739441
train loss item: 1.2019109725952148
train loss item: 0.13115519285202026
train loss item: 0.33383774757385254
train loss item: 0.1980239599943161
train loss item: 0.19759082794189453
train loss item: 0.20953501760959625
train loss item: 0.5021787285804749
train loss item: 0.31964850425720215
train loss item: 0.527762770652771
train loss item: 3.9315314292907715
train loss item: 0.17098289728164673
train loss item: 0.4442448019981384
test loss item: 0.21006281673908234
test loss item: 0.1423376351594925
test loss item: 0.43189454078674316
test loss item: 0.22836622595787048
test loss item: 0.24500957131385803
test loss item: 0.1480274498462677
test loss item: 1.5753326416015625
test loss item: 0.6171939969062805
test loss item: 0.19679374992847443
test loss item: 0.3430742025375366
test loss item: 0.5991901755332947
test loss item: 0.1830114722251892
test loss item: 0.22857216000556946
test loss item: 0.39370158314704895
test loss item: 0.17477838695049286
test loss item: 0.11177512258291245
test loss item: 0.3173048794269562
test loss item: 0.3803214430809021
test loss item: 0.681397557258606
test loss item: 0.35152676701545715
test loss item: 0.6338116526603699
test loss item: 0.38562995195388794
test loss item: 0.3705214560031891
test loss item: 0.19429898262023926
test loss item: 0.200543612241745
test loss item: 0.23529987037181854
test loss item: 0.3429310917854309
test loss item: 0.20665951073169708
test loss item: 0.3480721116065979
test loss item: 0.3213827311992645
test loss item: 0.6112701892852783
test loss item: 0.09204819053411484
test loss item: 0.1658197045326233
test loss item: 0.48093992471694946
test loss item: 0.3291372060775757
test loss item: 0.4394116997718811
test loss item: 0.8037817478179932
test loss item: 0.9103074669837952
test loss item: 0.39086413383483887
test loss item: 0.28869134187698364
test loss item: 0.2925489842891693
test loss item: 0.2698843479156494
test loss item: 0.342507541179657
test loss item: 0.20273543894290924
test loss item: 0.5248063802719116
test loss item: 0.47074079513549805
test loss item: 0.3648636043071747
test loss item: 0.3097497224807739
test loss item: 0.39487820863723755
test loss item: 0.5497589111328125
test loss item: 0.28673073649406433
test loss item: 0.15686699748039246
test loss item: 0.22900094091892242
test loss item: 0.15457342565059662
test loss item: 0.2775312662124634
test loss item: 0.5800526142120361
test loss item: 0.5446460843086243
test loss item: 0.2876228392124176
test loss item: 0.24055223166942596
test loss item: 0.23177987337112427
test loss item: 0.38563603162765503
test loss item: 0.2658858299255371
test loss item: 0.2523871660232544
test loss item: 0.27479374408721924
test loss item: 0.6772077083587646
test loss item: 0.3026731312274933
test loss item: 0.34983155131340027
test loss item: 0.26626333594322205
test loss item: 0.4295552372932434
test loss item: 0.43224048614501953
test loss item: 0.11084449291229248
test loss item: 0.9608939290046692
test loss item: 0.4131729006767273
test loss item: 0.4579004943370819
test loss item: 0.18160149455070496
test loss item: 0.2601177990436554
test loss item: 0.1957016885280609
test loss item: 0.8623129725456238
test loss item: 0.4785661995410919
test loss item: 0.22922058403491974
test loss item: 0.0930333361029625
test loss item: 0.7702300548553467
test loss item: 0.8023293614387512
test loss item: 0.6212027072906494
test loss item: 0.25932395458221436
test loss item: 0.23144811391830444
test loss item: 0.08218587189912796
test loss item: 0.0803365558385849
test loss item: 0.16108648478984833
Epoch [2/10], Training Loss: 0.5056, Testing Loss: 0.3698
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/10
train loss item: 0.40431681275367737
train loss item: 0.9510575532913208
train loss item: 0.27253180742263794
train loss item: 0.4078327715396881
train loss item: 0.33667638897895813
train loss item: 0.26616939902305603
train loss item: 0.34476032853126526
train loss item: 0.6230496168136597
train loss item: 0.15810996294021606
train loss item: 0.2924773395061493
train loss item: 0.3582819700241089
train loss item: 0.23785194754600525
train loss item: 0.10616779327392578
train loss item: 0.4532085955142975
train loss item: 0.23287665843963623
train loss item: 0.634672224521637
train loss item: 0.06615922600030899
train loss item: 0.2761218547821045
train loss item: 0.2787648141384125
train loss item: 0.2777956426143646
train loss item: 0.19797994196414948
train loss item: 0.18029166758060455
train loss item: 0.7308247685432434
train loss item: 0.8075000047683716
train loss item: 0.4558870494365692
train loss item: 0.3066309094429016
train loss item: 0.20444701611995697
train loss item: 0.24018095433712006
train loss item: 0.06978444755077362
train loss item: 0.5963158011436462
train loss item: 1.797213077545166
train loss item: 0.4466153383255005
train loss item: 0.11431712657213211
train loss item: 0.30259013175964355
train loss item: 0.10058853775262833
train loss item: 1.8615950345993042
train loss item: 0.5981590747833252
train loss item: 0.5257294774055481
train loss item: 0.6821022033691406
train loss item: 0.22152315080165863
train loss item: 0.20006245374679565
train loss item: 0.34193870425224304
train loss item: 0.3807806968688965
train loss item: 0.28866374492645264
train loss item: 0.7851067185401917
train loss item: 0.160965234041214
train loss item: 0.12154196202754974
train loss item: 0.5586856603622437
train loss item: 0.29676195979118347
train loss item: 0.18665017187595367
train loss item: 0.39012184739112854
train loss item: 1.2390329837799072
train loss item: 0.10969952493906021
train loss item: 0.17861421406269073
train loss item: 2.199936628341675
train loss item: 0.1546437293291092
train loss item: 0.22260597348213196
train loss item: 0.2400335818529129
train loss item: 0.17156507074832916
train loss item: 0.15966323018074036
train loss item: 0.7490745782852173
train loss item: 1.6288939714431763
train loss item: 0.22739648818969727
train loss item: 0.36549654603004456
train loss item: 0.18399208784103394
train loss item: 0.5185285806655884
train loss item: 0.3856385350227356
train loss item: 0.16695541143417358
train loss item: 0.3736265003681183
train loss item: 0.28584668040275574
train loss item: 0.24164298176765442
train loss item: 0.11541582643985748
train loss item: 0.28054529428482056
train loss item: 0.2937539219856262
train loss item: 0.0734165608882904
train loss item: 0.10841704905033112
train loss item: 0.860194742679596
train loss item: 1.291494607925415
train loss item: 0.07048190385103226
train loss item: 0.23353353142738342
train loss item: 0.1588250696659088
train loss item: 0.13658559322357178
train loss item: 0.21414276957511902
train loss item: 0.41752204298973083
train loss item: 0.37362056970596313
train loss item: 0.45214200019836426
train loss item: 3.5229780673980713
train loss item: 0.15353475511074066
train loss item: 0.5436218976974487
test loss item: 0.16337335109710693
test loss item: 0.12232816964387894
test loss item: 0.38695472478866577
test loss item: 0.18987947702407837
test loss item: 0.20392148196697235
test loss item: 0.11583805829286575
test loss item: 1.6741338968276978
test loss item: 0.6663385033607483
test loss item: 0.1986963152885437
test loss item: 0.3375275433063507
test loss item: 0.6163406372070312
test loss item: 0.13147974014282227
test loss item: 0.22459344565868378
test loss item: 0.31330740451812744
test loss item: 0.15271888673305511
test loss item: 0.09522467106580734
test loss item: 0.27250170707702637
test loss item: 0.32020172476768494
test loss item: 0.7188824415206909
test loss item: 0.33266109228134155
test loss item: 0.4841320812702179
test loss item: 0.3726230561733246
test loss item: 0.2549353241920471
test loss item: 0.15972846746444702
test loss item: 0.17803677916526794
test loss item: 0.214985191822052
test loss item: 0.32379254698753357
test loss item: 0.17033933103084564
test loss item: 0.2730075418949127
test loss item: 0.35309073328971863
test loss item: 0.6473550200462341
test loss item: 0.07711856812238693
test loss item: 0.13628531992435455
test loss item: 0.39945676922798157
test loss item: 0.29354918003082275
test loss item: 0.486021488904953
test loss item: 0.8210583925247192
test loss item: 0.9351065754890442
test loss item: 0.3425940275192261
test loss item: 0.2434391975402832
test loss item: 0.2722919285297394
test loss item: 0.18158051371574402
test loss item: 0.27514708042144775
test loss item: 0.17082488536834717
test loss item: 0.4058611989021301
test loss item: 0.44085365533828735
test loss item: 0.24374061822891235
test loss item: 0.39666643738746643
test loss item: 0.36835816502571106
test loss item: 0.588074266910553
test loss item: 0.22897085547447205
test loss item: 0.2426464706659317
test loss item: 0.19743968546390533
test loss item: 0.1122957319021225
test loss item: 0.22329628467559814
test loss item: 0.5876825451850891
test loss item: 0.5704299211502075
test loss item: 0.1928173303604126
test loss item: 0.2190772294998169
test loss item: 0.1775171011686325
test loss item: 0.34909874200820923
test loss item: 0.2696938216686249
test loss item: 0.20131930708885193
test loss item: 0.23531906306743622
test loss item: 0.7090719938278198
test loss item: 0.2535879611968994
test loss item: 0.32185328006744385
test loss item: 0.24589137732982635
test loss item: 0.370713472366333
test loss item: 0.5115177631378174
test loss item: 0.09999260306358337
test loss item: 1.0374881029129028
test loss item: 0.28287434577941895
test loss item: 0.37179750204086304
test loss item: 0.16662126779556274
test loss item: 0.1729808896780014
test loss item: 0.16829556226730347
test loss item: 0.9036120176315308
test loss item: 0.38485896587371826
test loss item: 0.16632553935050964
test loss item: 0.07877703011035919
test loss item: 0.8477071523666382
test loss item: 0.8401127457618713
test loss item: 0.6795732975006104
test loss item: 0.22487564384937286
test loss item: 0.20171505212783813
test loss item: 0.06708744168281555
test loss item: 0.06505702435970306
test loss item: 0.13323993980884552
Epoch [3/10], Training Loss: 0.4521, Testing Loss: 0.3467
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/10
train loss item: 0.4026936888694763
train loss item: 0.932007908821106
train loss item: 0.2073158323764801
train loss item: 0.3953281044960022
train loss item: 0.2808475196361542
train loss item: 0.22582007944583893
train loss item: 0.25516796112060547
train loss item: 0.48603031039237976
train loss item: 0.1248018890619278
train loss item: 0.22975730895996094
train loss item: 0.29003313183784485
train loss item: 0.23676207661628723
train loss item: 0.11435948312282562
train loss item: 0.3737010061740875
train loss item: 0.23646928369998932
train loss item: 0.6303900480270386
train loss item: 0.06410516053438187
train loss item: 0.21501168608665466
train loss item: 0.28950047492980957
train loss item: 0.25381699204444885
train loss item: 0.1686660498380661
train loss item: 0.11912376433610916
train loss item: 0.7424846887588501
train loss item: 0.6060930490493774
train loss item: 0.4128679633140564
train loss item: 0.22368480265140533
train loss item: 0.160282164812088
train loss item: 0.2082388997077942
train loss item: 0.08773377537727356
train loss item: 0.4481845498085022
train loss item: 1.590124249458313
train loss item: 0.5201963782310486
train loss item: 0.12274891883134842
train loss item: 0.2773289084434509
train loss item: 0.11800087988376617
train loss item: 1.679360270500183
train loss item: 0.48908519744873047
train loss item: 0.3746160566806793
train loss item: 0.3098801374435425
train loss item: 0.17172583937644958
train loss item: 0.1604207158088684
train loss item: 0.26338866353034973
train loss item: 0.3128451406955719
train loss item: 0.22770264744758606
train loss item: 0.6357381939888
train loss item: 0.10528311133384705
train loss item: 0.10703711211681366
train loss item: 0.3746113181114197
train loss item: 0.18241074681282043
train loss item: 0.2035401612520218
train loss item: 0.25165680050849915
train loss item: 0.8216364979743958
train loss item: 0.07912547141313553
train loss item: 0.1272871345281601
train loss item: 1.6295762062072754
train loss item: 0.1739395409822464
train loss item: 0.254442036151886
train loss item: 0.22294391691684723
train loss item: 0.11960458010435104
train loss item: 0.1284250020980835
train loss item: 0.529671847820282
train loss item: 1.513680338859558
train loss item: 0.17424920201301575
train loss item: 0.3672032952308655
train loss item: 0.13865409791469574
train loss item: 0.44052785634994507
train loss item: 0.4400733709335327
train loss item: 0.16348092257976532
train loss item: 0.43731847405433655
train loss item: 0.30160701274871826
train loss item: 0.24192851781845093
train loss item: 0.10278540104627609
train loss item: 0.19409982860088348
train loss item: 0.25174474716186523
train loss item: 0.06204777956008911
train loss item: 0.09537258744239807
train loss item: 0.5493372678756714
train loss item: 1.197182536125183
train loss item: 0.08754781633615494
train loss item: 0.2386907935142517
train loss item: 0.10810710489749908
train loss item: 0.18347086012363434
train loss item: 0.2087378054857254
train loss item: 0.35202494263648987
train loss item: 0.38611534237861633
train loss item: 0.3632870614528656
train loss item: 3.196484327316284
train loss item: 0.13359983265399933
train loss item: 0.3829326927661896
test loss item: 0.1643076390028
test loss item: 0.11959642916917801
test loss item: 0.35509464144706726
test loss item: 0.18919609487056732
test loss item: 0.18284744024276733
test loss item: 0.1100734993815422
test loss item: 1.9001684188842773
test loss item: 0.7392232418060303
test loss item: 0.19258010387420654
test loss item: 0.29522207379341125
test loss item: 0.5660588145256042
test loss item: 0.14380528032779694
test loss item: 0.21101760864257812
test loss item: 0.282146692276001
test loss item: 0.13525789976119995
test loss item: 0.10148810595273972
test loss item: 0.2891584038734436
test loss item: 0.2541123330593109
test loss item: 0.7366359829902649
test loss item: 0.34246352314949036
test loss item: 0.3714790344238281
test loss item: 0.40260234475135803
test loss item: 0.2328355312347412
test loss item: 0.1726139634847641
test loss item: 0.15802110731601715
test loss item: 0.2046997845172882
test loss item: 0.3172381818294525
test loss item: 0.15334555506706238
test loss item: 0.2620719373226166
test loss item: 0.2943442463874817
test loss item: 0.6989959478378296
test loss item: 0.08035016804933548
test loss item: 0.14283610880374908
test loss item: 0.3405335247516632
test loss item: 0.23293302953243256
test loss item: 0.4284932315349579
test loss item: 0.8549873232841492
test loss item: 0.8174155354499817
test loss item: 0.296234130859375
test loss item: 0.26029524207115173
test loss item: 0.28312501311302185
test loss item: 0.16441872715950012
test loss item: 0.24966101348400116
test loss item: 0.19154919683933258
test loss item: 0.31551024317741394
test loss item: 0.45528924465179443
test loss item: 0.22361956536769867
test loss item: 0.3686404526233673
test loss item: 0.3492124080657959
test loss item: 0.5626037120819092
test loss item: 0.19631676375865936
test loss item: 0.1952626258134842
test loss item: 0.18562370538711548
test loss item: 0.12496219575405121
test loss item: 0.18684767186641693
test loss item: 0.4905315637588501
test loss item: 0.5535308122634888
test loss item: 0.21055608987808228
test loss item: 0.21603330969810486
test loss item: 0.16372129321098328
test loss item: 0.2824082672595978
test loss item: 0.28990745544433594
test loss item: 0.20661994814872742
test loss item: 0.22992196679115295
test loss item: 0.7026017308235168
test loss item: 0.24473972618579865
test loss item: 0.32555317878723145
test loss item: 0.24870677292346954
test loss item: 0.3156742453575134
test loss item: 0.51814866065979
test loss item: 0.1002998948097229
test loss item: 1.160264015197754
test loss item: 0.2799358069896698
test loss item: 0.4140484929084778
test loss item: 0.17925241589546204
test loss item: 0.15918783843517303
test loss item: 0.17987167835235596
test loss item: 0.8123794794082642
test loss item: 0.3551606237888336
test loss item: 0.1602254956960678
test loss item: 0.08341857045888901
test loss item: 0.8874430060386658
test loss item: 0.8717962503433228
test loss item: 0.626115083694458
test loss item: 0.21296875178813934
test loss item: 0.2113729566335678
test loss item: 0.08066504448652267
test loss item: 0.07658101618289948
test loss item: 0.11342373490333557
Epoch [4/10], Training Loss: 0.3854, Testing Loss: 0.3376
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/10
train loss item: 0.38815298676490784
train loss item: 0.8437963128089905
train loss item: 0.18484166264533997
train loss item: 0.3176180422306061
train loss item: 0.3029039204120636
train loss item: 0.20797066390514374
train loss item: 0.2339087277650833
train loss item: 0.45675164461135864
train loss item: 0.13850827515125275
train loss item: 0.2450139820575714
train loss item: 0.32176733016967773
train loss item: 0.21275149285793304
train loss item: 0.1052074134349823
train loss item: 0.4343673288822174
train loss item: 0.20955900847911835
train loss item: 0.43117132782936096
train loss item: 0.0741044208407402
train loss item: 0.163816899061203
train loss item: 0.2816649377346039
train loss item: 0.2437783181667328
train loss item: 0.16622503101825714
train loss item: 0.11751003563404083
train loss item: 0.5580093264579773
train loss item: 0.5152767896652222
train loss item: 0.3675912022590637
train loss item: 0.19425800442695618
train loss item: 0.13175827264785767
train loss item: 0.20380856096744537
train loss item: 0.06573139131069183
train loss item: 0.35562148690223694
train loss item: 1.273242712020874
train loss item: 0.5719687342643738
train loss item: 0.12985944747924805
train loss item: 0.2580487132072449
train loss item: 0.1340484768152237
train loss item: 1.5583516359329224
train loss item: 0.37193456292152405
train loss item: 0.38543063402175903
train loss item: 0.291443407535553
train loss item: 0.16730453073978424
train loss item: 0.15997062623500824
train loss item: 0.23682883381843567
train loss item: 0.28255587816238403
train loss item: 0.16661465167999268
train loss item: 0.461301326751709
train loss item: 0.09136656671762466
train loss item: 0.11434662342071533
train loss item: 0.2479904145002365
train loss item: 0.14807942509651184
train loss item: 0.1698984056711197
train loss item: 0.24104097485542297
train loss item: 0.5828565955162048
train loss item: 0.0623154453933239
train loss item: 0.1049003154039383
train loss item: 1.3892947435379028
train loss item: 0.14323844015598297
train loss item: 0.2145889848470688
train loss item: 0.18537156283855438
train loss item: 0.11722509562969208
train loss item: 0.14316676557064056
train loss item: 0.4656302034854889
train loss item: 1.1813143491744995
train loss item: 0.13542316854000092
train loss item: 0.26234978437423706
train loss item: 0.10408952832221985
train loss item: 0.49433469772338867
train loss item: 0.344838410615921
train loss item: 0.13239046931266785
train loss item: 0.3812115490436554
train loss item: 0.2662462592124939
train loss item: 0.2704869508743286
train loss item: 0.0895189568400383
train loss item: 0.21283331513404846
train loss item: 0.2569955587387085
train loss item: 0.08398512005805969
train loss item: 0.09035051614046097
train loss item: 0.519722044467926
train loss item: 1.3740484714508057
train loss item: 0.0639837458729744
train loss item: 0.17852318286895752
train loss item: 0.11642272025346756
train loss item: 0.19639770686626434
train loss item: 0.18684305250644684
train loss item: 0.3782520294189453
train loss item: 0.3172415792942047
train loss item: 0.2971554100513458
train loss item: 2.8296117782592773
train loss item: 0.15670345723628998
train loss item: 0.24792318046092987
test loss item: 0.15296126902103424
test loss item: 0.133498877286911
test loss item: 0.5416911244392395
test loss item: 0.17583446204662323
test loss item: 0.24417896568775177
test loss item: 0.1356334388256073
test loss item: 1.6203373670578003
test loss item: 0.6536034345626831
test loss item: 0.2148706465959549
test loss item: 0.3315224051475525
test loss item: 0.7940971255302429
test loss item: 0.11568624526262283
test loss item: 0.1703909933567047
test loss item: 0.283413827419281
test loss item: 0.17327620089054108
test loss item: 0.09742289036512375
test loss item: 0.24205976724624634
test loss item: 0.3748929500579834
test loss item: 0.6532902717590332
test loss item: 0.23739616572856903
test loss item: 0.5894289612770081
test loss item: 0.3522759974002838
test loss item: 0.2821444869041443
test loss item: 0.16816142201423645
test loss item: 0.1634429693222046
test loss item: 0.18791314959526062
test loss item: 0.2603372037410736
test loss item: 0.19019441306591034
test loss item: 0.27667662501335144
test loss item: 0.2905448079109192
test loss item: 0.7623375058174133
test loss item: 0.08625738322734833
test loss item: 0.14936690032482147
test loss item: 0.4502280354499817
test loss item: 0.3648596704006195
test loss item: 0.3934861421585083
test loss item: 0.7697432041168213
test loss item: 1.3764163255691528
test loss item: 0.37091127038002014
test loss item: 0.23443453013896942
test loss item: 0.2534203827381134
test loss item: 0.16776782274246216
test loss item: 0.29350313544273376
test loss item: 0.1678258329629898
test loss item: 0.46769821643829346
test loss item: 0.36048319935798645
test loss item: 0.24840250611305237
test loss item: 0.22709369659423828
test loss item: 0.42671817541122437
test loss item: 0.6347745060920715
test loss item: 0.2529308795928955
test loss item: 0.1432102471590042
test loss item: 0.20327366888523102
test loss item: 0.10147520154714584
test loss item: 0.2603684067726135
test loss item: 0.7536219954490662
test loss item: 0.5653480887413025
test loss item: 0.22747743129730225
test loss item: 0.2093188315629959
test loss item: 0.16334861516952515
test loss item: 0.36046841740608215
test loss item: 0.25572800636291504
test loss item: 0.18247990310192108
test loss item: 0.19053910672664642
test loss item: 0.8394208550453186
test loss item: 0.21365472674369812
test loss item: 0.291299968957901
test loss item: 0.21796050667762756
test loss item: 0.4261665940284729
test loss item: 0.45089131593704224
test loss item: 0.10117828100919724
test loss item: 0.9675623178482056
test loss item: 0.2954248785972595
test loss item: 0.33475542068481445
test loss item: 0.14859122037887573
test loss item: 0.16152185201644897
test loss item: 0.17340564727783203
test loss item: 1.4589473009109497
test loss item: 0.3804328143596649
test loss item: 0.1726102977991104
test loss item: 0.09172948449850082
test loss item: 0.9717326760292053
test loss item: 0.8093504309654236
test loss item: 1.005246639251709
test loss item: 0.20225432515144348
test loss item: 0.1860290765762329
test loss item: 0.0845339447259903
test loss item: 0.07696401327848434
test loss item: 0.12775856256484985
Epoch [5/10], Training Loss: 0.3428, Testing Loss: 0.3637
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/10
train loss item: 0.2966400980949402
train loss item: 0.7064111232757568
train loss item: 0.17244380712509155
train loss item: 0.22092680633068085
train loss item: 0.26735296845436096
train loss item: 0.20832860469818115
train loss item: 0.19632261991500854
train loss item: 0.41463419795036316
train loss item: 0.08258358389139175
train loss item: 0.18865859508514404
train loss item: 0.1947103887796402
train loss item: 0.16171953082084656
train loss item: 0.10916435718536377
train loss item: 0.38482865691185
train loss item: 0.20788024365901947
train loss item: 0.4171532094478607
train loss item: 0.07160428911447525
train loss item: 0.13298927247524261
train loss item: 0.22969624400138855
train loss item: 0.19324223697185516
train loss item: 0.1370564103126526
train loss item: 0.12295227497816086
train loss item: 0.4115223288536072
train loss item: 0.44671711325645447
train loss item: 0.3645278215408325
train loss item: 0.1977793425321579
train loss item: 0.12074501812458038
train loss item: 0.18587146699428558
train loss item: 0.08143913000822067
train loss item: 0.3468596041202545
train loss item: 1.05681574344635
train loss item: 0.5029738545417786
train loss item: 0.10994357615709305
train loss item: 0.2022722065448761
train loss item: 0.10949057340621948
train loss item: 1.3182978630065918
train loss item: 0.46265605092048645
train loss item: 0.426204651594162
train loss item: 0.25317108631134033
train loss item: 0.16699466109275818
train loss item: 0.1925140768289566
train loss item: 0.2607722282409668
train loss item: 0.3693748414516449
train loss item: 0.2142953723669052
train loss item: 0.47418078780174255
train loss item: 0.10861608386039734
train loss item: 0.09215383231639862
train loss item: 0.5615369081497192
train loss item: 0.18792594969272614
train loss item: 0.13373219966888428
train loss item: 0.3465467393398285
train loss item: 0.9312170743942261
train loss item: 0.10152140259742737
train loss item: 0.1659417748451233
train loss item: 1.2698392868041992
train loss item: 0.13139460980892181
train loss item: 0.19345058500766754
train loss item: 0.174875408411026
train loss item: 0.11806090921163559
train loss item: 0.12149514257907867
train loss item: 0.45965078473091125
train loss item: 1.0966691970825195
train loss item: 0.10502481460571289
train loss item: 0.2423139065504074
train loss item: 0.09054524451494217
train loss item: 0.4516296684741974
train loss item: 0.2999398112297058
train loss item: 0.13568346202373505
train loss item: 0.2527514696121216
train loss item: 0.17794908583164215
train loss item: 0.17705468833446503
train loss item: 0.08958589285612106
train loss item: 0.18631494045257568
train loss item: 0.19684471189975739
train loss item: 0.08837073296308517
train loss item: 0.10396703332662582
train loss item: 0.3369823694229126
train loss item: 0.9925078749656677
train loss item: 0.08941922336816788
train loss item: 0.18899859488010406
train loss item: 0.11899619549512863
train loss item: 0.13424941897392273
train loss item: 0.15335029363632202
train loss item: 0.356353223323822
train loss item: 0.35139477252960205
train loss item: 0.28941962122917175
train loss item: 2.5638787746429443
train loss item: 0.1067916750907898
train loss item: 0.3483065962791443
test loss item: 0.17343640327453613
test loss item: 0.12675398588180542
test loss item: 0.3089121878147125
test loss item: 0.18620844185352325
test loss item: 0.17388062179088593
test loss item: 0.12049859762191772
test loss item: 1.8897866010665894
test loss item: 0.6998200416564941
test loss item: 0.16522185504436493
test loss item: 0.22745496034622192
test loss item: 0.49880826473236084
test loss item: 0.13479354977607727
test loss item: 0.17148184776306152
test loss item: 0.3276500105857849
test loss item: 0.14264565706253052
test loss item: 0.12216123193502426
test loss item: 0.27646616101264954
test loss item: 0.18621045351028442
test loss item: 0.6756297945976257
test loss item: 0.2862773835659027
test loss item: 0.28828340768814087
test loss item: 0.3936742842197418
test loss item: 0.2604156732559204
test loss item: 0.17184969782829285
test loss item: 0.14294713735580444
test loss item: 0.19398978352546692
test loss item: 0.25740060210227966
test loss item: 0.14781159162521362
test loss item: 0.24506627023220062
test loss item: 0.2323032021522522
test loss item: 0.6875342726707458
test loss item: 0.10216844081878662
test loss item: 0.14368796348571777
test loss item: 0.25951072573661804
test loss item: 0.18635571002960205
test loss item: 0.3708893358707428
test loss item: 0.7915622591972351
test loss item: 0.7009811401367188
test loss item: 0.2576678693294525
test loss item: 0.2570381462574005
test loss item: 0.2883356809616089
test loss item: 0.21200643479824066
test loss item: 0.1624681055545807
test loss item: 0.20841099321842194
test loss item: 0.2657875716686249
test loss item: 0.395454466342926
test loss item: 0.23885320127010345
test loss item: 0.3042204678058624
test loss item: 0.3117564022541046
test loss item: 0.4960673451423645
test loss item: 0.155413419008255
test loss item: 0.1637117862701416
test loss item: 0.18012161552906036
test loss item: 0.1350460946559906
test loss item: 0.13842490315437317
test loss item: 0.40645071864128113
test loss item: 0.4898627698421478
test loss item: 0.19697482883930206
test loss item: 0.20224402844905853
test loss item: 0.11943034827709198
test loss item: 0.18085291981697083
test loss item: 0.28379395604133606
test loss item: 0.21275106072425842
test loss item: 0.19711926579475403
test loss item: 0.6475985646247864
test loss item: 0.23453229665756226
test loss item: 0.28077223896980286
test loss item: 0.24205367267131805
test loss item: 0.26058825850486755
test loss item: 0.4560842216014862
test loss item: 0.12534219026565552
test loss item: 1.1192772388458252
test loss item: 0.3009231984615326
test loss item: 0.4043594300746918
test loss item: 0.1782899647951126
test loss item: 0.19953130185604095
test loss item: 0.1812257468700409
test loss item: 0.7605152130126953
test loss item: 0.3561897575855255
test loss item: 0.16937647759914398
test loss item: 0.10452942550182343
test loss item: 0.83476322889328
test loss item: 0.800007164478302
test loss item: 0.575590193271637
test loss item: 0.2033567577600479
test loss item: 0.21216891705989838
test loss item: 0.10144896060228348
test loss item: 0.10175994038581848
test loss item: 0.1104954406619072
Epoch [6/10], Training Loss: 0.3170, Testing Loss: 0.3134
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/10
train loss item: 0.29462775588035583
train loss item: 0.6790745854377747
train loss item: 0.16626638174057007
train loss item: 0.3189024329185486
train loss item: 0.16653040051460266
train loss item: 0.16099488735198975
train loss item: 0.1660338193178177
train loss item: 0.4153306484222412
train loss item: 0.16996081173419952
train loss item: 0.2018970102071762
train loss item: 0.22501499950885773
train loss item: 0.1571733057498932
train loss item: 0.09697192907333374
train loss item: 0.34369564056396484
train loss item: 0.1697763353586197
train loss item: 0.4066774547100067
train loss item: 0.05788402631878853
train loss item: 0.12781855463981628
train loss item: 0.2377227246761322
train loss item: 0.15513812005519867
train loss item: 0.13318905234336853
train loss item: 0.10050293058156967
train loss item: 0.43736010789871216
train loss item: 0.3840285539627075
train loss item: 0.30919960141181946
train loss item: 0.15081098675727844
train loss item: 0.10159330070018768
train loss item: 0.1971329152584076
train loss item: 0.08115514367818832
train loss item: 0.32921868562698364
train loss item: 1.0890275239944458
train loss item: 0.3467690348625183
train loss item: 0.13572515547275543
train loss item: 0.18733586370944977
train loss item: 0.1148998960852623
train loss item: 1.1531163454055786
train loss item: 0.43655359745025635
train loss item: 0.3566433787345886
train loss item: 0.28132155537605286
train loss item: 0.14848263561725616
train loss item: 0.16165435314178467
train loss item: 0.18671093881130219
train loss item: 0.2817522883415222
train loss item: 0.16286690533161163
train loss item: 0.38074690103530884
train loss item: 0.08309394121170044
train loss item: 0.08952390402555466
train loss item: 0.24935606122016907
train loss item: 0.11975234746932983
train loss item: 0.12155871838331223
train loss item: 0.1968076080083847
train loss item: 0.4274197816848755
train loss item: 0.052215248346328735
train loss item: 0.10862865298986435
train loss item: 1.014438509941101
train loss item: 0.11378800123929977
train loss item: 0.14909280836582184
train loss item: 0.1287958025932312
train loss item: 0.09014911949634552
train loss item: 0.13793815672397614
train loss item: 0.3561669588088989
train loss item: 0.8323434591293335
train loss item: 0.11281774938106537
train loss item: 0.19333116710186005
train loss item: 0.08043437451124191
train loss item: 0.38584521412849426
train loss item: 0.21088629961013794
train loss item: 0.11294996738433838
train loss item: 0.3566722869873047
train loss item: 0.24891112744808197
train loss item: 0.2052064687013626
train loss item: 0.08390989899635315
train loss item: 0.1482195407152176
train loss item: 0.21374602615833282
train loss item: 0.06553962081670761
train loss item: 0.08378811925649643
train loss item: 0.25369495153427124
train loss item: 1.1347510814666748
train loss item: 0.0718509629368782
train loss item: 0.1631438136100769
train loss item: 0.08375727385282516
train loss item: 0.20321820676326752
train loss item: 0.17922091484069824
train loss item: 0.35987669229507446
train loss item: 0.3653695285320282
train loss item: 0.3142188489437103
train loss item: 2.3146281242370605
train loss item: 0.12207164615392685
train loss item: 0.2760896384716034
test loss item: 0.1453768014907837
test loss item: 0.09231063723564148
test loss item: 0.2479974925518036
test loss item: 0.17501002550125122
test loss item: 0.14231760799884796
test loss item: 0.10727867484092712
test loss item: 1.7594728469848633
test loss item: 0.636850893497467
test loss item: 0.1425212323665619
test loss item: 0.19684886932373047
test loss item: 0.401621550321579
test loss item: 0.1261463612318039
test loss item: 0.1466275006532669
test loss item: 0.2707878649234772
test loss item: 0.11553776264190674
test loss item: 0.06909937411546707
test loss item: 0.24745482206344604
test loss item: 0.1632659137248993
test loss item: 0.600810706615448
test loss item: 0.23184359073638916
test loss item: 0.21618527173995972
test loss item: 0.3621177673339844
test loss item: 0.21191704273223877
test loss item: 0.15941636264324188
test loss item: 0.1380138099193573
test loss item: 0.19860637187957764
test loss item: 0.20749124884605408
test loss item: 0.12355104833841324
test loss item: 0.21478216350078583
test loss item: 0.20920966565608978
test loss item: 0.6192141175270081
test loss item: 0.0683601126074791
test loss item: 0.13470180332660675
test loss item: 0.21108806133270264
test loss item: 0.15212500095367432
test loss item: 0.3159962296485901
test loss item: 0.7149578332901001
test loss item: 0.5046953558921814
test loss item: 0.2383423000574112
test loss item: 0.24974820017814636
test loss item: 0.2753691077232361
test loss item: 0.1702248752117157
test loss item: 0.12692011892795563
test loss item: 0.20442891120910645
test loss item: 0.21050004661083221
test loss item: 0.3256027400493622
test loss item: 0.18596258759498596
test loss item: 0.2172820121049881
test loss item: 0.25931039452552795
test loss item: 0.4275354743003845
test loss item: 0.1393415778875351
test loss item: 0.14696656167507172
test loss item: 0.18113590776920319
test loss item: 0.13142815232276917
test loss item: 0.1455615609884262
test loss item: 0.2934522330760956
test loss item: 0.4367029070854187
test loss item: 0.15511085093021393
test loss item: 0.1865266114473343
test loss item: 0.1170395091176033
test loss item: 0.15467889606952667
test loss item: 0.24754489958286285
test loss item: 0.20686954259872437
test loss item: 0.1936112642288208
test loss item: 0.543822169303894
test loss item: 0.22166594862937927
test loss item: 0.2596612870693207
test loss item: 0.22163324058055878
test loss item: 0.18989352881908417
test loss item: 0.4074214696884155
test loss item: 0.06871207058429718
test loss item: 1.030224084854126
test loss item: 0.2425115555524826
test loss item: 0.37941235303878784
test loss item: 0.14527130126953125
test loss item: 0.1535644233226776
test loss item: 0.1642804592847824
test loss item: 0.5087347030639648
test loss item: 0.27847328782081604
test loss item: 0.14712338149547577
test loss item: 0.07406401634216309
test loss item: 0.7482435703277588
test loss item: 0.7308602333068848
test loss item: 0.43534547090530396
test loss item: 0.2069229930639267
test loss item: 0.17001676559448242
test loss item: 0.06339754909276962
test loss item: 0.052917737513780594
test loss item: 0.1383247822523117
Epoch [7/10], Training Loss: 0.2807, Testing Loss: 0.2696
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/10
train loss item: 0.31069251894950867
train loss item: 0.7722635865211487
train loss item: 0.12710480391979218
train loss item: 0.21756930649280548
train loss item: 0.13696850836277008
train loss item: 0.15410040318965912
train loss item: 0.11986466497182846
train loss item: 0.42325055599212646
train loss item: 0.136404350399971
train loss item: 0.20203295350074768
train loss item: 0.2060369849205017
train loss item: 0.15326526761054993
train loss item: 0.08329859375953674
train loss item: 0.29131123423576355
train loss item: 0.13991299271583557
train loss item: 0.35766202211380005
train loss item: 0.07341598719358444
train loss item: 0.12611234188079834
train loss item: 0.23659773170948029
train loss item: 0.15525762736797333
train loss item: 0.14444571733474731
train loss item: 0.07275515049695969
train loss item: 0.5744139552116394
train loss item: 0.3829052746295929
train loss item: 0.2984805107116699
train loss item: 0.13340073823928833
train loss item: 0.09067174792289734
train loss item: 0.16617614030838013
train loss item: 0.08425361663103104
train loss item: 0.4149567782878876
train loss item: 1.3582420349121094
train loss item: 0.41123294830322266
train loss item: 0.07685495913028717
train loss item: 0.1942749172449112
train loss item: 0.11782577633857727
train loss item: 0.9866397976875305
train loss item: 0.4881340563297272
train loss item: 0.42846691608428955
train loss item: 0.35904619097709656
train loss item: 0.29717159271240234
train loss item: 0.16936206817626953
train loss item: 0.18755482137203217
train loss item: 0.30044811964035034
train loss item: 0.19395844638347626
train loss item: 0.5037084817886353
train loss item: 0.08421222120523453
train loss item: 0.08010432869195938
train loss item: 0.3591594994068146
train loss item: 0.19450396299362183
train loss item: 0.1333082765340805
train loss item: 0.21064655482769012
train loss item: 0.6656306385993958
train loss item: 0.06939983367919922
train loss item: 0.10687088966369629
train loss item: 1.0439733266830444
train loss item: 0.12037786096334457
train loss item: 0.2039838433265686
train loss item: 0.15937480330467224
train loss item: 0.10497070103883743
train loss item: 0.13532589375972748
train loss item: 0.3480584919452667
train loss item: 0.7972911596298218
train loss item: 0.12441647052764893
train loss item: 0.24232923984527588
train loss item: 0.10003252327442169
train loss item: 0.35832569003105164
train loss item: 0.1980256587266922
train loss item: 0.11341467499732971
train loss item: 0.34525641798973083
train loss item: 0.20631934702396393
train loss item: 0.17724008858203888
train loss item: 0.09701143205165863
train loss item: 0.15594878792762756
train loss item: 0.18328556418418884
train loss item: 0.07500807195901871
train loss item: 0.08691959828138351
train loss item: 0.25821229815483093
train loss item: 0.9037817716598511
train loss item: 0.06551700085401535
train loss item: 0.1847357302904129
train loss item: 0.08870939910411835
train loss item: 0.17041881382465363
train loss item: 0.14617988467216492
train loss item: 0.42374616861343384
train loss item: 0.43878209590911865
train loss item: 0.23396258056163788
train loss item: 2.175541877746582
train loss item: 0.08576354384422302
train loss item: 0.2222008854150772
test loss item: 0.16456356644630432
test loss item: 0.09363246709108353
test loss item: 0.3359835743904114
test loss item: 0.19370782375335693
test loss item: 0.15255238115787506
test loss item: 0.11404088884592056
test loss item: 2.032405138015747
test loss item: 0.7554088234901428
test loss item: 0.16638325154781342
test loss item: 0.23082104325294495
test loss item: 0.5472571849822998
test loss item: 0.15199719369411469
test loss item: 0.17085032165050507
test loss item: 0.31615132093429565
test loss item: 0.11943305283784866
test loss item: 0.07181056588888168
test loss item: 0.29062214493751526
test loss item: 0.1896476149559021
test loss item: 0.7040677666664124
test loss item: 0.29567787051200867
test loss item: 0.23765283823013306
test loss item: 0.41858649253845215
test loss item: 0.2496233880519867
test loss item: 0.18094515800476074
test loss item: 0.15973713994026184
test loss item: 0.21969881653785706
test loss item: 0.2581101953983307
test loss item: 0.13383795320987701
test loss item: 0.24227271974086761
test loss item: 0.23878684639930725
test loss item: 0.7632843852043152
test loss item: 0.06320954859256744
test loss item: 0.14528341591358185
test loss item: 0.2540087103843689
test loss item: 0.18953274190425873
test loss item: 0.3949945271015167
test loss item: 0.8256194591522217
test loss item: 0.8103769421577454
test loss item: 0.2864249050617218
test loss item: 0.2850705087184906
test loss item: 0.31597235798835754
test loss item: 0.2107844203710556
test loss item: 0.1440175473690033
test loss item: 0.24111458659172058
test loss item: 0.22885611653327942
test loss item: 0.40132033824920654
test loss item: 0.22345933318138123
test loss item: 0.2954838275909424
test loss item: 0.31987571716308594
test loss item: 0.5424673557281494
test loss item: 0.15629304945468903
test loss item: 0.16457845270633698
test loss item: 0.20400099456310272
test loss item: 0.16054949164390564
test loss item: 0.15024833381175995
test loss item: 0.4411274790763855
test loss item: 0.532743513584137
test loss item: 0.1832277476787567
test loss item: 0.2105928510427475
test loss item: 0.12125303596258163
test loss item: 0.18265943229198456
test loss item: 0.29190975427627563
test loss item: 0.23593051731586456
test loss item: 0.21721360087394714
test loss item: 0.6987817287445068
test loss item: 0.24500900506973267
test loss item: 0.3093580901622772
test loss item: 0.2514782249927521
test loss item: 0.24168971180915833
test loss item: 0.5117028951644897
test loss item: 0.07434140890836716
test loss item: 1.197977900505066
test loss item: 0.29569897055625916
test loss item: 0.453182578086853
test loss item: 0.1659366339445114
test loss item: 0.18599693477153778
test loss item: 0.18638697266578674
test loss item: 0.8567608594894409
test loss item: 0.359792560338974
test loss item: 0.16972686350345612
test loss item: 0.07635605335235596
test loss item: 0.9207428097724915
test loss item: 0.8503413200378418
test loss item: 0.6621202230453491
test loss item: 0.22165146470069885
test loss item: 0.19662491977214813
test loss item: 0.06393681466579437
test loss item: 0.058254893869161606
test loss item: 0.1548684686422348
Epoch [8/10], Training Loss: 0.2869, Testing Loss: 0.3263
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/10
train loss item: 0.24746443331241608
train loss item: 0.6722326278686523
train loss item: 0.13063696026802063
train loss item: 0.2518001198768616
train loss item: 0.13588643074035645
train loss item: 0.14563049376010895
train loss item: 0.12381193786859512
train loss item: 0.22769200801849365
train loss item: 0.1043793335556984
train loss item: 0.20028166472911835
train loss item: 0.2702518701553345
train loss item: 0.1661255657672882
train loss item: 0.10503794252872467
train loss item: 0.37849944829940796
train loss item: 0.16011367738246918
train loss item: 0.31739407777786255
train loss item: 0.05545293167233467
train loss item: 0.1694737821817398
train loss item: 0.1530696600675583
train loss item: 0.17461375892162323
train loss item: 0.13227997720241547
train loss item: 0.07521091401576996
train loss item: 0.45326635241508484
train loss item: 0.4576914310455322
train loss item: 0.2461480349302292
train loss item: 0.18453557789325714
train loss item: 0.08785209059715271
train loss item: 0.12407597154378891
train loss item: 0.0562705397605896
train loss item: 0.33268675208091736
train loss item: 1.1739189624786377
train loss item: 0.32223445177078247
train loss item: 0.08905168622732162
train loss item: 0.21286369860172272
train loss item: 0.07282494753599167
train loss item: 0.9111947417259216
train loss item: 0.37557223439216614
train loss item: 0.38519302010536194
train loss item: 0.2753826975822449
train loss item: 0.2792118489742279
train loss item: 0.16586264967918396
train loss item: 0.22735098004341125
train loss item: 0.3236597776412964
train loss item: 0.201341912150383
train loss item: 0.37737831473350525
train loss item: 0.08840272575616837
train loss item: 0.07185392081737518
train loss item: 0.4562358856201172
train loss item: 0.21034257113933563
train loss item: 0.12223532795906067
train loss item: 0.2807832956314087
train loss item: 0.7161772847175598
train loss item: 0.0746019184589386
train loss item: 0.1190595030784607
train loss item: 0.8727970123291016
train loss item: 0.08895771205425262
train loss item: 0.15009669959545135
train loss item: 0.1364525556564331
train loss item: 0.10762695223093033
train loss item: 0.12519770860671997
train loss item: 0.3014889657497406
train loss item: 0.6740025877952576
train loss item: 0.13016323745250702
train loss item: 0.22770023345947266
train loss item: 0.10484259575605392
train loss item: 0.30574700236320496
train loss item: 0.16447488963603973
train loss item: 0.12154155969619751
train loss item: 0.2763780951499939
train loss item: 0.15878920257091522
train loss item: 0.13352768123149872
train loss item: 0.07129999995231628
train loss item: 0.14932700991630554
train loss item: 0.16822578012943268
train loss item: 0.06660662591457367
train loss item: 0.09052344411611557
train loss item: 0.24872329831123352
train loss item: 0.9201434254646301
train loss item: 0.07342415302991867
train loss item: 0.15574979782104492
train loss item: 0.09181369096040726
train loss item: 0.13834935426712036
train loss item: 0.16081777215003967
train loss item: 0.3546416163444519
train loss item: 0.3899003863334656
train loss item: 0.28962451219558716
train loss item: 2.0611276626586914
train loss item: 0.10272564738988876
train loss item: 0.1888909935951233
test loss item: 0.18310385942459106
test loss item: 0.11812178045511246
test loss item: 0.3707675039768219
test loss item: 0.19772842526435852
test loss item: 0.1774994283914566
test loss item: 0.1326485276222229
test loss item: 1.9071484804153442
test loss item: 0.672950029373169
test loss item: 0.17514410614967346
test loss item: 0.2395128756761551
test loss item: 0.5833399891853333
test loss item: 0.1598035842180252
test loss item: 0.18104270100593567
test loss item: 0.38654088973999023
test loss item: 0.1444021463394165
test loss item: 0.08891566842794418
test loss item: 0.28571781516075134
test loss item: 0.2088095247745514
test loss item: 0.6389663219451904
test loss item: 0.2952723205089569
test loss item: 0.2853880822658539
test loss item: 0.39412665367126465
test loss item: 0.2932760417461395
test loss item: 0.18706518411636353
test loss item: 0.16403236985206604
test loss item: 0.21611826121807098
test loss item: 0.2635415494441986
test loss item: 0.15387429296970367
test loss item: 0.25795692205429077
test loss item: 0.24970678985118866
test loss item: 0.7364728450775146
test loss item: 0.08620108664035797
test loss item: 0.15695783495903015
test loss item: 0.2775980532169342
test loss item: 0.21883194148540497
test loss item: 0.34511637687683105
test loss item: 0.7773826718330383
test loss item: 0.9106215834617615
test loss item: 0.29505813121795654
test loss item: 0.2780449092388153
test loss item: 0.3100707530975342
test loss item: 0.23698818683624268
test loss item: 0.15804919600486755
test loss item: 0.23559176921844482
test loss item: 0.2814303934574127
test loss item: 0.3765534460544586
test loss item: 0.2539342939853668
test loss item: 0.31246060132980347
test loss item: 0.3190489709377289
test loss item: 0.5120628476142883
test loss item: 0.18527890741825104
test loss item: 0.1803133338689804
test loss item: 0.20403125882148743
test loss item: 0.1586523950099945
test loss item: 0.16392208635807037
test loss item: 0.4980792999267578
test loss item: 0.48623955249786377
test loss item: 0.2273540049791336
test loss item: 0.21665246784687042
test loss item: 0.13074450194835663
test loss item: 0.19643534719944
test loss item: 0.2738639712333679
test loss item: 0.24025322496891022
test loss item: 0.22615604102611542
test loss item: 0.7137235403060913
test loss item: 0.24486781656742096
test loss item: 0.3000200092792511
test loss item: 0.25065112113952637
test loss item: 0.2766183316707611
test loss item: 0.419027715921402
test loss item: 0.08881818503141403
test loss item: 1.105368733406067
test loss item: 0.3477405309677124
test loss item: 0.4389042258262634
test loss item: 0.17312802374362946
test loss item: 0.217777281999588
test loss item: 0.19354024529457092
test loss item: 1.00545334815979
test loss item: 0.4291948676109314
test loss item: 0.18672232329845428
test loss item: 0.08874081820249557
test loss item: 0.889136552810669
test loss item: 0.7980656623840332
test loss item: 0.7358264327049255
test loss item: 0.2387523204088211
test loss item: 0.19565264880657196
test loss item: 0.07430136948823929
test loss item: 0.07115153223276138
test loss item: 0.13664306700229645
Epoch [9/10], Training Loss: 0.2660, Testing Loss: 0.3337
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/10
train loss item: 0.23389679193496704
train loss item: 0.6644536852836609
train loss item: 0.14344598352909088
train loss item: 0.26150837540626526
train loss item: 0.13333503901958466
train loss item: 0.14298130571842194
train loss item: 0.1004064530134201
train loss item: 0.23125210404396057
train loss item: 0.07828350365161896
train loss item: 0.18499711155891418
train loss item: 0.23493602871894836
train loss item: 0.1472126692533493
train loss item: 0.0894208550453186
train loss item: 0.3828592598438263
train loss item: 0.15785324573516846
train loss item: 0.4308154881000519
train loss item: 0.056338656693696976
train loss item: 0.1378604918718338
train loss item: 0.18864133954048157
train loss item: 0.18779157102108002
train loss item: 0.10403038561344147
train loss item: 0.09664016216993332
train loss item: 0.570580005645752
train loss item: 0.2868679165840149
train loss item: 0.2766973078250885
train loss item: 0.1759471893310547
train loss item: 0.08628754317760468
train loss item: 0.12410856783390045
train loss item: 0.06654073297977448
train loss item: 0.2727832496166229
train loss item: 0.8483908772468567
train loss item: 0.34925100207328796
train loss item: 0.08664136379957199
train loss item: 0.1669187843799591
train loss item: 0.08352695405483246
train loss item: 0.7441481947898865
train loss item: 0.34178653359413147
train loss item: 0.3387190103530884
train loss item: 0.21667803823947906
train loss item: 0.17401428520679474
train loss item: 0.16644054651260376
train loss item: 0.2217690646648407
train loss item: 0.30561867356300354
train loss item: 0.18763190507888794
train loss item: 0.3189585506916046
train loss item: 0.08398352563381195
train loss item: 0.07233481109142303
train loss item: 0.419024795293808
train loss item: 0.1901855766773224
train loss item: 0.11255252361297607
train loss item: 0.2297987937927246
train loss item: 0.6116355657577515
train loss item: 0.09713465720415115
train loss item: 0.12781138718128204
train loss item: 0.6475275158882141
train loss item: 0.08994562178850174
train loss item: 0.16527922451496124
train loss item: 0.1548183560371399
train loss item: 0.1160004660487175
train loss item: 0.11458853632211685
train loss item: 0.3179948627948761
train loss item: 0.6022362112998962
train loss item: 0.10885939002037048
train loss item: 0.2532917261123657
train loss item: 0.09486362338066101
train loss item: 0.26217204332351685
train loss item: 0.2057313472032547
train loss item: 0.10986006259918213
train loss item: 0.2481609582901001
train loss item: 0.14608103036880493
train loss item: 0.11365832388401031
train loss item: 0.08163218200206757
train loss item: 0.12390048056840897
train loss item: 0.10597337037324905
train loss item: 0.09421712905168533
train loss item: 0.10684844106435776
train loss item: 0.21396474540233612
train loss item: 1.0922901630401611
train loss item: 0.07798589020967484
train loss item: 0.18177878856658936
train loss item: 0.12744839489459991
train loss item: 0.14963464438915253
train loss item: 0.13397075235843658
train loss item: 0.3206985592842102
train loss item: 0.3014315962791443
train loss item: 0.2518998980522156
train loss item: 1.7920620441436768
train loss item: 0.10046350955963135
train loss item: 0.18386104702949524
test loss item: 0.18525339663028717
test loss item: 0.07713756710290909
test loss item: 0.5153390765190125
test loss item: 0.19838963449001312
test loss item: 0.18733248114585876
test loss item: 0.12042161077260971
test loss item: 1.5632095336914062
test loss item: 0.5512701869010925
test loss item: 0.19895130395889282
test loss item: 0.29340097308158875
test loss item: 0.7488066554069519
test loss item: 0.14538036286830902
test loss item: 0.16487228870391846
test loss item: 0.34885266423225403
test loss item: 0.13461366295814514
test loss item: 0.06715453416109085
test loss item: 0.2930694818496704
test loss item: 0.3135601282119751
test loss item: 0.5509366989135742
test loss item: 0.27949458360671997
test loss item: 0.46699970960617065
test loss item: 0.35845670104026794
test loss item: 0.3045025169849396
test loss item: 0.16416729986667633
test loss item: 0.18710318207740784
test loss item: 0.18135491013526917
test loss item: 0.26634299755096436
test loss item: 0.1357552707195282
test loss item: 0.25596392154693604
test loss item: 0.251010537147522
test loss item: 0.737194299697876
test loss item: 0.07871777564287186
test loss item: 0.1435997635126114
test loss item: 0.3969615697860718
test loss item: 0.31264516711235046
test loss item: 0.3420734405517578
test loss item: 0.6621840000152588
test loss item: 1.2803469896316528
test loss item: 0.34962186217308044
test loss item: 0.24801474809646606
test loss item: 0.2823614478111267
test loss item: 0.24670293927192688
test loss item: 0.2528615891933441
test loss item: 0.23998600244522095
test loss item: 0.38459116220474243
test loss item: 0.3656097948551178
test loss item: 0.2821677029132843
test loss item: 0.26323747634887695
test loss item: 0.39280062913894653
test loss item: 0.5819666385650635
test loss item: 0.21840354800224304
test loss item: 0.14288246631622314
test loss item: 0.21999043226242065
test loss item: 0.18888172507286072
test loss item: 0.21366959810256958
test loss item: 0.6995115280151367
test loss item: 0.4672476351261139
test loss item: 0.22274714708328247
test loss item: 0.21980364620685577
test loss item: 0.130956768989563
test loss item: 0.2961083948612213
test loss item: 0.26977071166038513
test loss item: 0.2267715334892273
test loss item: 0.1911608874797821
test loss item: 0.7982361912727356
test loss item: 0.254095196723938
test loss item: 0.29530051350593567
test loss item: 0.2182626575231552
test loss item: 0.36804473400115967
test loss item: 0.3849552571773529
test loss item: 0.059983864426612854
test loss item: 0.9148067831993103
test loss item: 0.36032986640930176
test loss item: 0.4109553098678589
test loss item: 0.18778659403324127
test loss item: 0.22327016294002533
test loss item: 0.16307438910007477
test loss item: 1.3840655088424683
test loss item: 0.42236360907554626
test loss item: 0.18999184668064117
test loss item: 0.07343307137489319
test loss item: 0.90543133020401
test loss item: 0.7283285856246948
test loss item: 0.9597517848014832
test loss item: 0.20944461226463318
test loss item: 0.22988641262054443
test loss item: 0.07279027998447418
test loss item: 0.06948041170835495
test loss item: 0.12506453692913055
Epoch [10/10], Training Loss: 0.2465, Testing Loss: 0.3491
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
loss item: 0.28474438190460205
loss item: 0.20743632316589355
loss item: 1.4482215642929077
loss item: 0.6721096038818359
loss item: 0.5145315527915955
loss item: 0.3926340937614441
loss item: 0.1376274973154068
loss item: 0.7053890824317932
loss item: 0.21797260642051697
loss item: 0.18500301241874695
loss item: 0.8915790915489197
loss item: 0.04760169982910156
loss item: 0.7816333174705505
loss item: 0.2114643007516861
loss item: 0.23772242665290833
loss item: 0.242791548371315
loss item: 0.33607620000839233
loss item: 0.4799288511276245
loss item: 0.789668083190918
loss item: 0.4413527250289917
loss item: 0.2924688160419464
loss item: 0.26085785031318665
loss item: 0.33148694038391113
loss item: 0.27162355184555054
loss item: 0.22172722220420837
loss item: 0.6014005541801453
loss item: 0.9754801988601685
loss item: 0.12417653203010559
loss item: 0.10048189014196396
loss item: 0.42779064178466797
loss item: 0.887281596660614
loss item: 1.357799768447876
loss item: 0.13166044652462006
loss item: 0.48848965764045715
loss item: 0.1393885463476181
loss item: 0.2719463109970093
loss item: 0.2989000976085663
loss item: 0.25613415241241455
loss item: 0.38164055347442627
loss item: 0.6022099256515503
loss item: 0.8768401145935059
loss item: 0.3676452934741974
loss item: 0.18898537755012512
loss item: 0.056121576577425
Val Loss: 0.4350
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 10, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.001 2 360 done at Tue Nov 12 09:33:24 CET 2024
UNet2 with 1 10 0.005 2 360 start at Tue Nov 12 09:33:24 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 10, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 0.9121710062026978
train loss item: 2.3596537113189697
train loss item: 0.6951392889022827
train loss item: 1.2938249111175537
train loss item: 1.4231724739074707
train loss item: 0.5039922595024109
train loss item: 0.43074434995651245
train loss item: 1.4261348247528076
train loss item: 0.28414613008499146
train loss item: 0.5675510168075562
train loss item: 0.6910601854324341
train loss item: 0.42026352882385254
train loss item: 0.1324857473373413
train loss item: 0.8068372011184692
train loss item: 0.3840419054031372
train loss item: 1.257371425628662
train loss item: 0.08779767155647278
train loss item: 0.49915456771850586
train loss item: 0.6628166437149048
train loss item: 0.5061546564102173
train loss item: 0.40896642208099365
train loss item: 0.18529468774795532
train loss item: 1.878562569618225
train loss item: 1.4219703674316406
train loss item: 0.9907299280166626
train loss item: 0.4101291298866272
train loss item: 0.286479115486145
train loss item: 0.47881534695625305
train loss item: 0.19234693050384521
train loss item: 1.4333579540252686
train loss item: 3.288198947906494
train loss item: 0.9111039042472839
train loss item: 0.137279212474823
train loss item: 0.7027220129966736
train loss item: 0.20527304708957672
train loss item: 2.921581983566284
train loss item: 0.7213185429573059
train loss item: 0.5303860306739807
train loss item: 0.7365942597389221
train loss item: 0.36719605326652527
train loss item: 0.31795549392700195
train loss item: 0.3771492540836334
train loss item: 0.4621357321739197
train loss item: 0.2473013550043106
train loss item: 0.7756121754646301
train loss item: 0.32356515526771545
train loss item: 0.17513719201087952
train loss item: 0.6990630626678467
train loss item: 0.31837934255599976
train loss item: 0.16912858188152313
train loss item: 0.5299562811851501
train loss item: 1.499110460281372
train loss item: 0.0681602880358696
train loss item: 0.2920112609863281
train loss item: 2.7292673587799072
train loss item: 0.29725366830825806
train loss item: 0.3225564956665039
train loss item: 0.3299453556537628
train loss item: 0.24271030724048615
train loss item: 0.17768913507461548
train loss item: 1.4162005186080933
train loss item: 2.4564168453216553
train loss item: 0.3873443305492401
train loss item: 0.625148594379425
train loss item: 0.23776280879974365
train loss item: 0.930720865726471
train loss item: 0.43830034136772156
train loss item: 0.2984105348587036
train loss item: 0.4311758875846863
train loss item: 0.45804911851882935
train loss item: 0.3682411313056946
train loss item: 0.5147370100021362
train loss item: 0.3530140519142151
train loss item: 0.41604140400886536
train loss item: 0.1211424469947815
train loss item: 0.13685491681098938
train loss item: 1.329099178314209
train loss item: 1.9581820964813232
train loss item: 0.1391196846961975
train loss item: 0.5035191774368286
train loss item: 0.2037416398525238
train loss item: 0.3330010771751404
train loss item: 0.2958652079105377
train loss item: 1.196373462677002
train loss item: 0.6154637932777405
train loss item: 1.0099682807922363
train loss item: 4.918233394622803
train loss item: 0.20143809914588928
train loss item: 0.4690376818180084
test loss item: 0.2219582051038742
test loss item: 0.18020641803741455
test loss item: 0.8305428624153137
test loss item: 0.29015976190567017
test loss item: 0.44809016585350037
test loss item: 0.3841785490512848
test loss item: 2.8382318019866943
test loss item: 0.9022160172462463
test loss item: 0.3301982283592224
test loss item: 0.5667122006416321
test loss item: 1.2469464540481567
test loss item: 0.22060108184814453
test loss item: 0.26215502619743347
test loss item: 0.4469398558139801
test loss item: 0.2549419701099396
test loss item: 0.10355199128389359
test loss item: 0.4048226773738861
test loss item: 0.6440994143486023
test loss item: 0.9782863855361938
test loss item: 0.41897228360176086
test loss item: 0.9918761253356934
test loss item: 0.5558953285217285
test loss item: 0.39206233620643616
test loss item: 0.2843523323535919
test loss item: 0.29935961961746216
test loss item: 0.3395402729511261
test loss item: 0.46730926632881165
test loss item: 0.4087378680706024
test loss item: 0.5005202293395996
test loss item: 0.4869081377983093
test loss item: 1.272813320159912
test loss item: 0.0923331081867218
test loss item: 0.2386859506368637
test loss item: 0.7520583271980286
test loss item: 0.6116223335266113
test loss item: 0.6288796067237854
test loss item: 1.2259260416030884
test loss item: 2.087797164916992
test loss item: 0.7095513343811035
test loss item: 0.5002447366714478
test loss item: 0.43840017914772034
test loss item: 0.232686847448349
test loss item: 0.4752911329269409
test loss item: 0.2972860634326935
test loss item: 0.8312079310417175
test loss item: 0.6241165399551392
test loss item: 0.37898731231689453
test loss item: 0.3276004195213318
test loss item: 0.6847848892211914
test loss item: 1.0320032835006714
test loss item: 0.46428340673446655
test loss item: 0.1756659746170044
test loss item: 0.36126548051834106
test loss item: 0.17397168278694153
test loss item: 0.4399870038032532
test loss item: 1.2349635362625122
test loss item: 0.8089830279350281
test loss item: 0.34216636419296265
test loss item: 0.33153754472732544
test loss item: 0.3150654733181
test loss item: 0.6090577244758606
test loss item: 0.3494621813297272
test loss item: 0.30517345666885376
test loss item: 0.3546837270259857
test loss item: 1.2856695652008057
test loss item: 0.36005106568336487
test loss item: 0.46664392948150635
test loss item: 0.37960925698280334
test loss item: 0.7078253626823425
test loss item: 0.6229697465896606
test loss item: 0.13950969278812408
test loss item: 1.6218185424804688
test loss item: 0.40837159752845764
test loss item: 0.6003850102424622
test loss item: 0.21454794704914093
test loss item: 0.23020243644714355
test loss item: 0.28600776195526123
test loss item: 2.1255815029144287
test loss item: 0.634545087814331
test loss item: 0.40892294049263
test loss item: 0.14562171697616577
test loss item: 1.483009696006775
test loss item: 1.3324593305587769
test loss item: 1.4933563470840454
test loss item: 0.3548557460308075
test loss item: 0.295806884765625
test loss item: 0.13297221064567566
test loss item: 0.0987270325422287
test loss item: 0.21032162010669708
Epoch [1/10], Training Loss: 0.7491, Testing Loss: 0.5893
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/10
train loss item: 0.5202454328536987
train loss item: 1.5883634090423584
train loss item: 0.497993528842926
train loss item: 0.6793892979621887
train loss item: 0.8560302257537842
train loss item: 0.43026456236839294
train loss item: 0.4020290672779083
train loss item: 0.9720221757888794
train loss item: 0.19187189638614655
train loss item: 0.4412691593170166
train loss item: 0.4472671151161194
train loss item: 0.40259650349617004
train loss item: 0.12438526749610901
train loss item: 0.6006274819374084
train loss item: 0.35987281799316406
train loss item: 1.1746416091918945
train loss item: 0.09646846354007721
train loss item: 0.454369455575943
train loss item: 0.5142753720283508
train loss item: 0.42070335149765015
train loss item: 0.35345950722694397
train loss item: 0.19133871793746948
train loss item: 1.6305735111236572
train loss item: 1.1478272676467896
train loss item: 0.8611868619918823
train loss item: 0.32433584332466125
train loss item: 0.274985134601593
train loss item: 0.3265416622161865
train loss item: 0.09623387455940247
train loss item: 1.0850087404251099
train loss item: 2.6649010181427
train loss item: 0.6644923090934753
train loss item: 0.17125748097896576
train loss item: 0.4613787531852722
train loss item: 0.23047718405723572
train loss item: 2.4294028282165527
train loss item: 0.618015706539154
train loss item: 0.5975621342658997
train loss item: 0.6129162907600403
train loss item: 0.2766493558883667
train loss item: 0.19486738741397858
train loss item: 0.42431560158729553
train loss item: 0.36129313707351685
train loss item: 0.326534628868103
train loss item: 0.9694086909294128
train loss item: 0.19816818833351135
train loss item: 0.1670057624578476
train loss item: 0.535385012626648
train loss item: 0.345824658870697
train loss item: 0.2181480973958969
train loss item: 0.3927725553512573
train loss item: 1.3726980686187744
train loss item: 0.10167425870895386
train loss item: 0.24732093513011932
train loss item: 2.681530237197876
train loss item: 0.251911997795105
train loss item: 0.4266429543495178
train loss item: 0.30946847796440125
train loss item: 0.20116759836673737
train loss item: 0.14426513016223907
train loss item: 1.1352858543395996
train loss item: 2.296191692352295
train loss item: 0.4044857621192932
train loss item: 0.5181435942649841
train loss item: 0.2885459363460541
train loss item: 0.814670741558075
train loss item: 0.45427295565605164
train loss item: 0.24297881126403809
train loss item: 0.405108779668808
train loss item: 0.4397752583026886
train loss item: 0.3088932931423187
train loss item: 0.13236850500106812
train loss item: 0.3402555286884308
train loss item: 0.3749471604824066
train loss item: 0.11623818427324295
train loss item: 0.15245972573757172
train loss item: 1.1686662435531616
train loss item: 1.4485774040222168
train loss item: 0.12536732852458954
train loss item: 0.389710396528244
train loss item: 0.1605888307094574
train loss item: 0.22646893560886383
train loss item: 0.28121575713157654
train loss item: 0.704188346862793
train loss item: 0.4369463324546814
train loss item: 0.841219961643219
train loss item: 4.46937370300293
train loss item: 0.17095257341861725
train loss item: 0.5888984799385071
test loss item: 0.19769255816936493
test loss item: 0.0942649096250534
test loss item: 0.6723519563674927
test loss item: 0.22790086269378662
test loss item: 0.277523398399353
test loss item: 0.12169263511896133
test loss item: 2.117636203765869
test loss item: 0.6954542398452759
test loss item: 0.26292651891708374
test loss item: 0.47967493534088135
test loss item: 1.081426978111267
test loss item: 0.1724182516336441
test loss item: 0.22273018956184387
test loss item: 0.4699592590332031
test loss item: 0.18151436746120453
test loss item: 0.07213879376649857
test loss item: 0.3515373766422272
test loss item: 0.5452346801757812
test loss item: 0.8478008508682251
test loss item: 0.38725021481513977
test loss item: 0.8558072447776794
test loss item: 0.4213946759700775
test loss item: 0.36695459485054016
test loss item: 0.19527073204517365
test loss item: 0.2558869421482086
test loss item: 0.27263879776000977
test loss item: 0.43619051575660706
test loss item: 0.2155897170305252
test loss item: 0.40131741762161255
test loss item: 0.4422595798969269
test loss item: 0.9593598246574402
test loss item: 0.05677281692624092
test loss item: 0.16253340244293213
test loss item: 0.6515146493911743
test loss item: 0.5107977986335754
test loss item: 0.5289648175239563
test loss item: 1.0168377161026
test loss item: 1.7878464460372925
test loss item: 0.5852097868919373
test loss item: 0.31551387906074524
test loss item: 0.3545512557029724
test loss item: 0.21288084983825684
test loss item: 0.41116949915885925
test loss item: 0.21858486533164978
test loss item: 0.7293254733085632
test loss item: 0.568227231502533
test loss item: 0.3336043059825897
test loss item: 0.3612881302833557
test loss item: 0.5520521998405457
test loss item: 0.8769135475158691
test loss item: 0.36052098870277405
test loss item: 0.163754403591156
test loss item: 0.2718210518360138
test loss item: 0.12377573549747467
test loss item: 0.34418946504592896
test loss item: 1.0379128456115723
test loss item: 0.6825181245803833
test loss item: 0.28922039270401
test loss item: 0.27751609683036804
test loss item: 0.23164941370487213
test loss item: 0.530247151851654
test loss item: 0.2786214053630829
test loss item: 0.25093621015548706
test loss item: 0.3104541599750519
test loss item: 1.017695426940918
test loss item: 0.31171780824661255
test loss item: 0.3992001414299011
test loss item: 0.31043270230293274
test loss item: 0.6117001175880432
test loss item: 0.54750657081604
test loss item: 0.07124567031860352
test loss item: 1.2598762512207031
test loss item: 0.40247833728790283
test loss item: 0.46082761883735657
test loss item: 0.18239380419254303
test loss item: 0.20163115859031677
test loss item: 0.19967348873615265
test loss item: 1.7460614442825317
test loss item: 0.622539222240448
test loss item: 0.21185313165187836
test loss item: 0.07482673972845078
test loss item: 1.1851370334625244
test loss item: 1.0874840021133423
test loss item: 1.2100516557693481
test loss item: 0.3177059292793274
test loss item: 0.25603145360946655
test loss item: 0.053947992622852325
test loss item: 0.046831440180540085
test loss item: 0.15674622356891632
Epoch [2/10], Training Loss: 0.6236, Testing Loss: 0.4790
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/10
train loss item: 0.49028417468070984
train loss item: 1.3115317821502686
train loss item: 0.39279410243034363
train loss item: 0.6456537842750549
train loss item: 0.465495765209198
train loss item: 0.3933671712875366
train loss item: 0.32648375630378723
train loss item: 0.7854472994804382
train loss item: 0.21777796745300293
train loss item: 0.33937060832977295
train loss item: 0.4432004392147064
train loss item: 0.4394850730895996
train loss item: 0.11775092035531998
train loss item: 0.539486289024353
train loss item: 0.3084419071674347
train loss item: 0.7759978771209717
train loss item: 0.10391057282686234
train loss item: 0.370320588350296
train loss item: 0.4265836775302887
train loss item: 0.3654240667819977
train loss item: 0.26950278878211975
train loss item: 0.18585674464702606
train loss item: 1.081381916999817
train loss item: 1.061638593673706
train loss item: 0.6936229467391968
train loss item: 0.34483766555786133
train loss item: 0.2925300598144531
train loss item: 0.3445080816745758
train loss item: 0.12254957109689713
train loss item: 0.7838624119758606
train loss item: 2.363412380218506
train loss item: 0.7274218797683716
train loss item: 0.12609991431236267
train loss item: 0.4490307867527008
train loss item: 0.13747958838939667
train loss item: 2.209709644317627
train loss item: 0.6788873672485352
train loss item: 0.5553525686264038
train loss item: 0.791489839553833
train loss item: 0.3154582679271698
train loss item: 0.23276060819625854
train loss item: 0.3659941554069519
train loss item: 0.3914089798927307
train loss item: 0.2991100549697876
train loss item: 0.8604167699813843
train loss item: 0.14656716585159302
train loss item: 0.14077314734458923
train loss item: 0.5139577388763428
train loss item: 0.35866042971611023
train loss item: 0.1874372661113739
train loss item: 0.4193404018878937
train loss item: 1.281272292137146
train loss item: 0.07926522940397263
train loss item: 0.24637846648693085
train loss item: 2.4829025268554688
train loss item: 0.25373953580856323
train loss item: 0.40718111395835876
train loss item: 0.2751636505126953
train loss item: 0.18783019483089447
train loss item: 0.1169891506433487
train loss item: 0.9700027108192444
train loss item: 2.0544557571411133
train loss item: 0.3362148702144623
train loss item: 0.5342836380004883
train loss item: 0.3059868812561035
train loss item: 0.773044764995575
train loss item: 0.5659810304641724
train loss item: 0.23036304116249084
train loss item: 0.40304967761039734
train loss item: 0.4529935419559479
train loss item: 0.313376784324646
train loss item: 0.14639060199260712
train loss item: 0.339115172624588
train loss item: 0.39757630228996277
train loss item: 0.0981898233294487
train loss item: 0.14713843166828156
train loss item: 1.2282283306121826
train loss item: 1.325297474861145
train loss item: 0.08313537389039993
train loss item: 0.39787110686302185
train loss item: 0.1820702701807022
train loss item: 0.23459705710411072
train loss item: 0.32694414258003235
train loss item: 0.6765772104263306
train loss item: 0.5157465934753418
train loss item: 0.99424147605896
train loss item: 4.605356693267822
train loss item: 0.287929892539978
train loss item: 0.43526536226272583
test loss item: 0.23402291536331177
test loss item: 0.09711204469203949
test loss item: 1.0367672443389893
test loss item: 0.2616322636604309
test loss item: 0.3511967957019806
test loss item: 0.17220932245254517
test loss item: 2.125265121459961
test loss item: 0.76502525806427
test loss item: 0.4095436930656433
test loss item: 0.6428482532501221
test loss item: 1.5001180171966553
test loss item: 0.18883852660655975
test loss item: 0.24032075703144073
test loss item: 0.49721840023994446
test loss item: 0.23130810260772705
test loss item: 0.06418707966804504
test loss item: 0.4085688292980194
test loss item: 0.720257580280304
test loss item: 0.897205114364624
test loss item: 0.42820456624031067
test loss item: 1.0863351821899414
test loss item: 0.47444427013397217
test loss item: 0.4241888225078583
test loss item: 0.22415444254875183
test loss item: 0.31206241250038147
test loss item: 0.2946537137031555
test loss item: 0.5082997679710388
test loss item: 0.2617953419685364
test loss item: 0.47532522678375244
test loss item: 0.5327207446098328
test loss item: 1.254262089729309
test loss item: 0.06734172254800797
test loss item: 0.19337117671966553
test loss item: 0.8416019678115845
test loss item: 0.7052162885665894
test loss item: 0.6594303846359253
test loss item: 1.097493290901184
test loss item: 2.627600908279419
test loss item: 0.7366380095481873
test loss item: 0.33963823318481445
test loss item: 0.36891990900039673
test loss item: 0.2895925045013428
test loss item: 0.543578028678894
test loss item: 0.26385411620140076
test loss item: 0.8945998549461365
test loss item: 0.6361622214317322
test loss item: 0.4230213463306427
test loss item: 0.3634369969367981
test loss item: 0.7734684348106384
test loss item: 1.1762841939926147
test loss item: 0.4732299745082855
test loss item: 0.16771475970745087
test loss item: 0.3451259732246399
test loss item: 0.1899220049381256
test loss item: 0.4573378562927246
test loss item: 1.5093867778778076
test loss item: 0.8202298879623413
test loss item: 0.3621230721473694
test loss item: 0.3376314043998718
test loss item: 0.26512008905410767
test loss item: 0.7129887938499451
test loss item: 0.35359689593315125
test loss item: 0.30325305461883545
test loss item: 0.3115994930267334
test loss item: 1.401402235031128
test loss item: 0.3442620038986206
test loss item: 0.48202624917030334
test loss item: 0.31288373470306396
test loss item: 0.7647578120231628
test loss item: 0.6287472248077393
test loss item: 0.06255970150232315
test loss item: 1.2563743591308594
test loss item: 0.482867568731308
test loss item: 0.5167818665504456
test loss item: 0.22670501470565796
test loss item: 0.2645435333251953
test loss item: 0.216311976313591
test loss item: 2.6130781173706055
test loss item: 0.7325003743171692
test loss item: 0.27393028140068054
test loss item: 0.09091046452522278
test loss item: 1.5705578327178955
test loss item: 1.2662791013717651
test loss item: 1.8538211584091187
test loss item: 0.3213949203491211
test loss item: 0.31530776619911194
test loss item: 0.08047979325056076
test loss item: 0.0684698149561882
test loss item: 0.22111044824123383
Epoch [3/10], Training Loss: 0.5776, Testing Loss: 0.5966
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/10
train loss item: 0.5021392107009888
train loss item: 1.4020358324050903
train loss item: 0.2827751338481903
train loss item: 0.7027196884155273
train loss item: 0.9253207445144653
train loss item: 0.41154807806015015
train loss item: 0.40359655022621155
train loss item: 0.8218976855278015
train loss item: 0.18198658525943756
train loss item: 0.46982574462890625
train loss item: 0.5131447315216064
train loss item: 0.4556555151939392
train loss item: 0.1281735748052597
train loss item: 0.5544214844703674
train loss item: 0.38070741295814514
train loss item: 1.0628888607025146
train loss item: 0.06040704622864723
train loss item: 0.42288821935653687
train loss item: 0.48815733194351196
train loss item: 0.39996299147605896
train loss item: 0.2998802065849304
train loss item: 0.23294617235660553
train loss item: 1.2832715511322021
train loss item: 1.136642575263977
train loss item: 0.7670120000839233
train loss item: 0.3832380771636963
train loss item: 0.4265728294849396
train loss item: 0.4032289683818817
train loss item: 0.09519117325544357
train loss item: 0.779981255531311
train loss item: 2.2796053886413574
train loss item: 0.6658167839050293
train loss item: 0.14021223783493042
train loss item: 0.45156142115592957
train loss item: 0.18829071521759033
train loss item: 2.0786449909210205
train loss item: 0.8042514324188232
train loss item: 0.682248592376709
train loss item: 0.840590238571167
train loss item: 0.3404703736305237
train loss item: 0.21892841160297394
train loss item: 0.4109167456626892
train loss item: 0.44205620884895325
train loss item: 0.28155583143234253
train loss item: 0.9193791151046753
train loss item: 0.16633743047714233
train loss item: 0.15630805492401123
train loss item: 0.5433482527732849
train loss item: 0.35004597902297974
train loss item: 0.19135256111621857
train loss item: 0.4216080904006958
train loss item: 0.9644942879676819
train loss item: 0.0944901555776596
train loss item: 0.2031380534172058
train loss item: 2.087280750274658
train loss item: 0.24727149307727814
train loss item: 0.3913778066635132
train loss item: 0.2610117495059967
train loss item: 0.21332596242427826
train loss item: 0.12194395065307617
train loss item: 0.9223904013633728
train loss item: 1.9245713949203491
train loss item: 0.2970227003097534
train loss item: 0.5195898413658142
train loss item: 0.20456328988075256
train loss item: 0.7501165270805359
train loss item: 0.5125088095664978
train loss item: 0.24515289068222046
train loss item: 0.476132333278656
train loss item: 0.46479934453964233
train loss item: 0.3591982424259186
train loss item: 0.13813771307468414
train loss item: 0.3039652705192566
train loss item: 0.3725322484970093
train loss item: 0.0954902321100235
train loss item: 0.1471400260925293
train loss item: 1.0198431015014648
train loss item: 1.3626396656036377
train loss item: 0.09680171310901642
train loss item: 0.29796886444091797
train loss item: 0.16755181550979614
train loss item: 0.20642131567001343
train loss item: 0.2909388542175293
train loss item: 0.547890305519104
train loss item: 0.547717809677124
train loss item: 0.6686052083969116
train loss item: 3.799309730529785
train loss item: 0.17852364480495453
train loss item: 0.5676175951957703
test loss item: 0.22876130044460297
test loss item: 0.1925920844078064
test loss item: 0.6096324920654297
test loss item: 0.2843373119831085
test loss item: 0.4044888913631439
test loss item: 0.353555828332901
test loss item: 2.0460212230682373
test loss item: 0.831891655921936
test loss item: 0.25466403365135193
test loss item: 0.47491419315338135
test loss item: 0.9572746157646179
test loss item: 0.17033234238624573
test loss item: 0.2690514326095581
test loss item: 0.39276883006095886
test loss item: 0.25733068585395813
test loss item: 0.08704730123281479
test loss item: 0.39657631516456604
test loss item: 0.5401631593704224
test loss item: 0.9256654381752014
test loss item: 0.4304342269897461
test loss item: 0.8297269344329834
test loss item: 0.47496065497398376
test loss item: 0.4684136211872101
test loss item: 0.31661078333854675
test loss item: 0.26519492268562317
test loss item: 0.35327717661857605
test loss item: 0.4436260759830475
test loss item: 0.38905444741249084
test loss item: 0.44000133872032166
test loss item: 0.4675567150115967
test loss item: 0.8935151100158691
test loss item: 0.10401853173971176
test loss item: 0.28489717841148376
test loss item: 0.628192663192749
test loss item: 0.4906228482723236
test loss item: 0.5699187517166138
test loss item: 1.056497573852539
test loss item: 1.5257805585861206
test loss item: 0.5554651021957397
test loss item: 0.4400100111961365
test loss item: 0.36560243368148804
test loss item: 0.39962461590766907
test loss item: 0.4003780782222748
test loss item: 0.24112391471862793
test loss item: 0.6942936778068542
test loss item: 0.6473431587219238
test loss item: 0.501295268535614
test loss item: 0.4208645820617676
test loss item: 0.544355571269989
test loss item: 0.8297122120857239
test loss item: 0.35588154196739197
test loss item: 0.2584889829158783
test loss item: 0.2910763621330261
test loss item: 0.15435147285461426
test loss item: 0.3592945635318756
test loss item: 0.9324249625205994
test loss item: 0.7086411714553833
test loss item: 0.3055453598499298
test loss item: 0.33318519592285156
test loss item: 0.24370405077934265
test loss item: 0.5090181827545166
test loss item: 0.3669542670249939
test loss item: 0.32692089676856995
test loss item: 0.3012235462665558
test loss item: 0.9966466426849365
test loss item: 0.31743958592414856
test loss item: 0.4512905776500702
test loss item: 0.3324224352836609
test loss item: 0.5683555603027344
test loss item: 0.6347696781158447
test loss item: 0.17376384139060974
test loss item: 1.2921924591064453
test loss item: 0.377658486366272
test loss item: 0.48855453729629517
test loss item: 0.25200581550598145
test loss item: 0.4136265814304352
test loss item: 0.29729965329170227
test loss item: 1.4890213012695312
test loss item: 0.5281075239181519
test loss item: 0.3861309885978699
test loss item: 0.17762959003448486
test loss item: 1.1090573072433472
test loss item: 1.1014866828918457
test loss item: 1.027674674987793
test loss item: 0.2951967716217041
test loss item: 0.32918107509613037
test loss item: 0.13681660592556
test loss item: 0.07730206102132797
test loss item: 0.2770659923553467
Epoch [4/10], Training Loss: 0.5733, Testing Loss: 0.5070
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/10
train loss item: 0.48602986335754395
train loss item: 1.333953857421875
train loss item: 0.28156399726867676
train loss item: 0.6068131923675537
train loss item: 0.44320768117904663
train loss item: 0.3614659011363983
train loss item: 0.31360429525375366
train loss item: 0.7171801924705505
train loss item: 0.15187199413776398
train loss item: 0.30019310116767883
train loss item: 0.40707433223724365
train loss item: 0.29506146907806396
train loss item: 0.10837208479642868
train loss item: 0.5220437049865723
train loss item: 0.26147541403770447
train loss item: 0.6877620220184326
train loss item: 0.07297038286924362
train loss item: 0.3638119399547577
train loss item: 0.38641026616096497
train loss item: 0.33382782340049744
train loss item: 0.23918208479881287
train loss item: 0.1752690076828003
train loss item: 0.973395824432373
train loss item: 0.9286071062088013
train loss item: 0.638412356376648
train loss item: 0.24044714868068695
train loss item: 0.2529298961162567
train loss item: 0.29502803087234497
train loss item: 0.10129999369382858
train loss item: 0.6776465773582458
train loss item: 1.7907018661499023
train loss item: 0.7767718434333801
train loss item: 0.2212078720331192
train loss item: 0.41091376543045044
train loss item: 0.133914977312088
train loss item: 1.7703841924667358
train loss item: 0.8056597709655762
train loss item: 0.5334590077400208
train loss item: 0.6710484027862549
train loss item: 0.28273409605026245
train loss item: 0.2101016640663147
train loss item: 0.3625372052192688
train loss item: 0.39074641466140747
train loss item: 0.2726905643939972
train loss item: 0.841188907623291
train loss item: 0.13405807316303253
train loss item: 0.131875678896904
train loss item: 0.6133467555046082
train loss item: 0.35045212507247925
train loss item: 0.1714107245206833
train loss item: 0.4941314458847046
train loss item: 1.2023556232452393
train loss item: 0.07101334631443024
train loss item: 0.18202953040599823
train loss item: 1.9251779317855835
train loss item: 0.2390000969171524
train loss item: 0.333469420671463
train loss item: 0.2956734895706177
train loss item: 0.21844951808452606
train loss item: 0.15239162743091583
train loss item: 1.0345207452774048
train loss item: 1.6909229755401611
train loss item: 0.27491334080696106
train loss item: 0.4340212345123291
train loss item: 0.2247297167778015
train loss item: 0.7020635604858398
train loss item: 0.6914637684822083
train loss item: 0.2610158920288086
train loss item: 0.3718174397945404
train loss item: 0.4037328362464905
train loss item: 0.292216420173645
train loss item: 0.12692590057849884
train loss item: 0.28203192353248596
train loss item: 0.3673930764198303
train loss item: 0.07950851321220398
train loss item: 0.1273401379585266
train loss item: 1.0057584047317505
train loss item: 1.2828257083892822
train loss item: 0.07772001624107361
train loss item: 0.2843998968601227
train loss item: 0.11754105985164642
train loss item: 0.21676601469516754
train loss item: 0.2720753848552704
train loss item: 0.513117253780365
train loss item: 0.5915540456771851
train loss item: 0.624801516532898
train loss item: 3.3155555725097656
train loss item: 0.1508142352104187
train loss item: 0.506514847278595
test loss item: 0.22383758425712585
test loss item: 0.10122334212064743
test loss item: 0.5543126463890076
test loss item: 0.2636622488498688
test loss item: 0.2594273090362549
test loss item: 0.1805235892534256
test loss item: 1.9042832851409912
test loss item: 0.6523539423942566
test loss item: 0.2200760543346405
test loss item: 0.41441550850868225
test loss item: 0.8232730031013489
test loss item: 0.19732944667339325
test loss item: 0.23155143857002258
test loss item: 0.4242210388183594
test loss item: 0.17109039425849915
test loss item: 0.0637625977396965
test loss item: 0.384880930185318
test loss item: 0.47447338700294495
test loss item: 0.7842504978179932
test loss item: 0.37362971901893616
test loss item: 0.7478837370872498
test loss item: 0.44880032539367676
test loss item: 0.3389993906021118
test loss item: 0.22332286834716797
test loss item: 0.26773592829704285
test loss item: 0.2921796441078186
test loss item: 0.3963527977466583
test loss item: 0.22616900503635406
test loss item: 0.36650583148002625
test loss item: 0.4099002480506897
test loss item: 0.7908022999763489
test loss item: 0.07494983822107315
test loss item: 0.19521236419677734
test loss item: 0.5779657363891602
test loss item: 0.4314515292644501
test loss item: 0.46482810378074646
test loss item: 0.9279231429100037
test loss item: 1.3153088092803955
test loss item: 0.5005946159362793
test loss item: 0.3286193311214447
test loss item: 0.37252652645111084
test loss item: 0.27336812019348145
test loss item: 0.3538101613521576
test loss item: 0.26992666721343994
test loss item: 0.6267985105514526
test loss item: 0.5462682843208313
test loss item: 0.3583196699619293
test loss item: 0.3437707722187042
test loss item: 0.4673413336277008
test loss item: 0.6894915699958801
test loss item: 0.2991043031215668
test loss item: 0.21351222693920135
test loss item: 0.2779155671596527
test loss item: 0.20154377818107605
test loss item: 0.31217095255851746
test loss item: 0.8149411082267761
test loss item: 0.6035475134849548
test loss item: 0.28396978974342346
test loss item: 0.29878008365631104
test loss item: 0.21433952450752258
test loss item: 0.44585365056991577
test loss item: 0.31126850843429565
test loss item: 0.29898205399513245
test loss item: 0.3111124336719513
test loss item: 0.8801639676094055
test loss item: 0.3454177975654602
test loss item: 0.40018680691719055
test loss item: 0.31567564606666565
test loss item: 0.5159564018249512
test loss item: 0.4837987422943115
test loss item: 0.07037461549043655
test loss item: 1.1461952924728394
test loss item: 0.3952668309211731
test loss item: 0.48352277278900146
test loss item: 0.21889840066432953
test loss item: 0.2503947913646698
test loss item: 0.2153567522764206
test loss item: 1.3052102327346802
test loss item: 0.5531340837478638
test loss item: 0.25842010974884033
test loss item: 0.09510491788387299
test loss item: 0.9688894152641296
test loss item: 0.973979651927948
test loss item: 0.8782515525817871
test loss item: 0.2793658971786499
test loss item: 0.27570533752441406
test loss item: 0.0821133479475975
test loss item: 0.06928380578756332
test loss item: 0.19190242886543274
Epoch [5/10], Training Loss: 0.5087, Testing Loss: 0.4367
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/10
train loss item: 0.4300716519355774
train loss item: 1.2640435695648193
train loss item: 0.2533445358276367
train loss item: 0.6705136299133301
train loss item: 0.4189329445362091
train loss item: 0.3508652150630951
train loss item: 0.30102652311325073
train loss item: 0.8390786051750183
train loss item: 0.18592223525047302
train loss item: 0.39629629254341125
train loss item: 0.5570724606513977
train loss item: 0.27649205923080444
train loss item: 0.11372947692871094
train loss item: 0.6625910997390747
train loss item: 0.295180082321167
train loss item: 0.7447018623352051
train loss item: 0.06017201021313667
train loss item: 0.3249080181121826
train loss item: 0.3784900903701782
train loss item: 0.32053685188293457
train loss item: 0.2502790093421936
train loss item: 0.17495915293693542
train loss item: 0.8950791358947754
train loss item: 0.969197690486908
train loss item: 0.621118426322937
train loss item: 0.24585124850273132
train loss item: 0.22325463593006134
train loss item: 0.2526489496231079
train loss item: 0.06206170469522476
train loss item: 0.6424688696861267
train loss item: 1.6440699100494385
train loss item: 0.7524213790893555
train loss item: 0.13799795508384705
train loss item: 0.369232177734375
train loss item: 0.15302559733390808
train loss item: 1.5837188959121704
train loss item: 0.8019135594367981
train loss item: 0.483897864818573
train loss item: 0.4982016086578369
train loss item: 0.2561938166618347
train loss item: 0.19363677501678467
train loss item: 0.3690783679485321
train loss item: 0.335333913564682
train loss item: 0.2811272144317627
train loss item: 0.8118041157722473
train loss item: 0.1377112865447998
train loss item: 0.1463586837053299
train loss item: 0.4039442539215088
train loss item: 0.3253737688064575
train loss item: 0.20114873349666595
train loss item: 0.3585105240345001
train loss item: 1.0002375841140747
train loss item: 0.06338192522525787
train loss item: 0.19984225928783417
train loss item: 1.8003393411636353
train loss item: 0.1998046487569809
train loss item: 0.3629535138607025
train loss item: 0.26198893785476685
train loss item: 0.18824347853660583
train loss item: 0.14850829541683197
train loss item: 0.7465896010398865
train loss item: 1.3984392881393433
train loss item: 0.28325268626213074
train loss item: 0.5545751452445984
train loss item: 0.1884678453207016
train loss item: 0.6292052268981934
train loss item: 0.6255313158035278
train loss item: 0.2105501890182495
train loss item: 0.3999882936477661
train loss item: 0.38424935936927795
train loss item: 0.266610324382782
train loss item: 0.12451397627592087
train loss item: 0.3084001839160919
train loss item: 0.36424511671066284
train loss item: 0.10845480859279633
train loss item: 0.1705329418182373
train loss item: 0.987506091594696
train loss item: 1.1628057956695557
train loss item: 0.08550529181957245
train loss item: 0.2909635901451111
train loss item: 0.15275128185749054
train loss item: 0.18898840248584747
train loss item: 0.27425795793533325
train loss item: 0.47881975769996643
train loss item: 0.6513606905937195
train loss item: 0.6915993690490723
train loss item: 3.051983118057251
train loss item: 0.16804514825344086
train loss item: 0.5024146437644958
test loss item: 0.29181331396102905
test loss item: 0.14615629613399506
test loss item: 0.5625156164169312
test loss item: 0.3152744472026825
test loss item: 0.28028374910354614
test loss item: 0.23158183693885803
test loss item: 2.0832340717315674
test loss item: 0.8051947355270386
test loss item: 0.27629995346069336
test loss item: 0.4678952693939209
test loss item: 0.8109197616577148
test loss item: 0.24338024854660034
test loss item: 0.33133548498153687
test loss item: 0.513717532157898
test loss item: 0.19876155257225037
test loss item: 0.08499906212091446
test loss item: 0.4768035113811493
test loss item: 0.5003407001495361
test loss item: 0.8733910918235779
test loss item: 0.49279090762138367
test loss item: 0.732357382774353
test loss item: 0.5419308543205261
test loss item: 0.4643322825431824
test loss item: 0.27357909083366394
test loss item: 0.31829777359962463
test loss item: 0.36902281641960144
test loss item: 0.45698392391204834
test loss item: 0.2568146288394928
test loss item: 0.3836074769496918
test loss item: 0.4884847104549408
test loss item: 0.8359982967376709
test loss item: 0.09410465508699417
test loss item: 0.24845725297927856
test loss item: 0.5729253888130188
test loss item: 0.43551886081695557
test loss item: 0.5370563864707947
test loss item: 1.0058826208114624
test loss item: 1.2405544519424438
test loss item: 0.5038764476776123
test loss item: 0.3647698760032654
test loss item: 0.41638320684432983
test loss item: 0.42712870240211487
test loss item: 0.39812397956848145
test loss item: 0.34363067150115967
test loss item: 0.6279906034469604
test loss item: 0.6526355147361755
test loss item: 0.4834761917591095
test loss item: 0.4928068220615387
test loss item: 0.5191934108734131
test loss item: 0.7598298192024231
test loss item: 0.33730217814445496
test loss item: 0.34348028898239136
test loss item: 0.34383946657180786
test loss item: 0.28023239970207214
test loss item: 0.35867905616760254
test loss item: 0.7476557493209839
test loss item: 0.6716766357421875
test loss item: 0.3769041895866394
test loss item: 0.3904019594192505
test loss item: 0.26543572545051575
test loss item: 0.47699683904647827
test loss item: 0.4276728332042694
test loss item: 0.4139665961265564
test loss item: 0.34563350677490234
test loss item: 0.8785943388938904
test loss item: 0.392165869474411
test loss item: 0.5134329199790955
test loss item: 0.35011720657348633
test loss item: 0.4839220643043518
test loss item: 0.5952311754226685
test loss item: 0.08797676861286163
test loss item: 1.29764723777771
test loss item: 0.5149677991867065
test loss item: 0.6037817597389221
test loss item: 0.31520628929138184
test loss item: 0.37994301319122314
test loss item: 0.2584935426712036
test loss item: 1.1725274324417114
test loss item: 0.6203373074531555
test loss item: 0.3341832160949707
test loss item: 0.11438693851232529
test loss item: 1.0580649375915527
test loss item: 1.0551127195358276
test loss item: 0.8773736953735352
test loss item: 0.37359485030174255
test loss item: 0.3822794258594513
test loss item: 0.10529989749193192
test loss item: 0.09191145747900009
test loss item: 0.28030627965927124
Epoch [6/10], Training Loss: 0.4843, Testing Loss: 0.4961
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/10
train loss item: 0.44445550441741943
train loss item: 1.196074366569519
train loss item: 0.30134186148643494
train loss item: 0.6610447764396667
train loss item: 0.38494575023651123
train loss item: 0.32845404744148254
train loss item: 0.2896731197834015
train loss item: 0.584921658039093
train loss item: 0.15775281190872192
train loss item: 0.28238359093666077
train loss item: 0.3986347019672394
train loss item: 0.26916834712028503
train loss item: 0.11387396603822708
train loss item: 0.5474922060966492
train loss item: 0.2727534770965576
train loss item: 0.6056960821151733
train loss item: 0.06403099000453949
train loss item: 0.3320988714694977
train loss item: 0.35081517696380615
train loss item: 0.32113951444625854
train loss item: 0.23093314468860626
train loss item: 0.11412037909030914
train loss item: 0.8642737865447998
train loss item: 0.7655686736106873
train loss item: 0.5431575179100037
train loss item: 0.306413859128952
train loss item: 0.19230729341506958
train loss item: 0.23323602974414825
train loss item: 0.07991701364517212
train loss item: 0.5786377787590027
train loss item: 1.6732547283172607
train loss item: 0.6923893690109253
train loss item: 0.12480732798576355
train loss item: 0.33961915969848633
train loss item: 0.11168789118528366
train loss item: 1.4027258157730103
train loss item: 0.6257273554801941
train loss item: 0.46021604537963867
train loss item: 0.4841446578502655
train loss item: 0.31407150626182556
train loss item: 0.20463566482067108
train loss item: 0.3522668182849884
train loss item: 0.37489017844200134
train loss item: 0.25784197449684143
train loss item: 0.71037757396698
train loss item: 0.11012575030326843
train loss item: 0.12177683413028717
train loss item: 0.4670328199863434
train loss item: 0.3217305541038513
train loss item: 0.17216263711452484
train loss item: 0.39080214500427246
train loss item: 0.9401257038116455
train loss item: 0.07197105884552002
train loss item: 0.19589146971702576
train loss item: 1.4776074886322021
train loss item: 0.19057287275791168
train loss item: 0.3963850438594818
train loss item: 0.2379113882780075
train loss item: 0.17826944589614868
train loss item: 0.14396661520004272
train loss item: 0.7210185527801514
train loss item: 1.1686186790466309
train loss item: 0.2603455185890198
train loss item: 0.5337030291557312
train loss item: 0.20192059874534607
train loss item: 0.5993326306343079
train loss item: 0.5374658703804016
train loss item: 0.20077279210090637
train loss item: 0.40343615412712097
train loss item: 0.3575380742549896
train loss item: 0.24846871197223663
train loss item: 0.11114462465047836
train loss item: 0.25054460763931274
train loss item: 0.32031625509262085
train loss item: 0.09629762917757034
train loss item: 0.15393273532390594
train loss item: 0.8551462292671204
train loss item: 1.024643063545227
train loss item: 0.08428531885147095
train loss item: 0.3813588619232178
train loss item: 0.13117773830890656
train loss item: 0.2320852428674698
train loss item: 0.244232177734375
train loss item: 0.39694905281066895
train loss item: 0.547921895980835
train loss item: 0.5507187247276306
train loss item: 2.544010877609253
train loss item: 0.13975313305854797
train loss item: 0.4954184293746948
test loss item: 0.2962472140789032
test loss item: 0.18500465154647827
test loss item: 0.5940998196601868
test loss item: 0.3225993812084198
test loss item: 0.3082989752292633
test loss item: 0.2549231946468353
test loss item: 2.2884795665740967
test loss item: 0.9002432823181152
test loss item: 0.3216497302055359
test loss item: 0.5439707636833191
test loss item: 0.7541329860687256
test loss item: 0.2688247859477997
test loss item: 0.4029238820075989
test loss item: 0.6178768277168274
test loss item: 0.23473943769931793
test loss item: 0.08563386648893356
test loss item: 0.49148786067962646
test loss item: 0.5494091510772705
test loss item: 0.9265947937965393
test loss item: 0.5860951542854309
test loss item: 0.7589212656021118
test loss item: 0.5673730969429016
test loss item: 0.5019135475158691
test loss item: 0.29474979639053345
test loss item: 0.319225013256073
test loss item: 0.44688916206359863
test loss item: 0.5288384556770325
test loss item: 0.28684693574905396
test loss item: 0.4187181890010834
test loss item: 0.5746849775314331
test loss item: 0.8961597681045532
test loss item: 0.0890699103474617
test loss item: 0.26492658257484436
test loss item: 0.5848624110221863
test loss item: 0.47865796089172363
test loss item: 0.6502783298492432
test loss item: 1.0848026275634766
test loss item: 1.1215890645980835
test loss item: 0.5491598844528198
test loss item: 0.3945144712924957
test loss item: 0.4295493960380554
test loss item: 0.4435052275657654
test loss item: 0.4648485481739044
test loss item: 0.34785550832748413
test loss item: 0.6799997091293335
test loss item: 0.7105928659439087
test loss item: 0.5130943059921265
test loss item: 0.6575382947921753
test loss item: 0.5574197769165039
test loss item: 0.783821702003479
test loss item: 0.46677637100219727
test loss item: 0.43060562014579773
test loss item: 0.40395426750183105
test loss item: 0.28118354082107544
test loss item: 0.46702152490615845
test loss item: 0.741968035697937
test loss item: 0.7028012275695801
test loss item: 0.4921262264251709
test loss item: 0.43896016478538513
test loss item: 0.36293578147888184
test loss item: 0.5695857405662537
test loss item: 0.44798776507377625
test loss item: 0.4652719497680664
test loss item: 0.38893765211105347
test loss item: 0.9332055449485779
test loss item: 0.38961169123649597
test loss item: 0.5794054269790649
test loss item: 0.3723520040512085
test loss item: 0.47064173221588135
test loss item: 0.659311830997467
test loss item: 0.09551449865102768
test loss item: 1.426967740058899
test loss item: 0.5790250301361084
test loss item: 0.6513593792915344
test loss item: 0.34560778737068176
test loss item: 0.39561519026756287
test loss item: 0.2833142876625061
test loss item: 1.0839093923568726
test loss item: 0.7047312259674072
test loss item: 0.3489598333835602
test loss item: 0.10795216262340546
test loss item: 1.099047303199768
test loss item: 1.1458063125610352
test loss item: 0.8673787713050842
test loss item: 0.4735127091407776
test loss item: 0.4119732081890106
test loss item: 0.09640944004058838
test loss item: 0.08415107429027557
test loss item: 0.27505162358283997
Epoch [7/10], Training Loss: 0.4399, Testing Loss: 0.5379
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/10
train loss item: 0.4690641760826111
train loss item: 1.370843768119812
train loss item: 0.33906254172325134
train loss item: 0.6310698390007019
train loss item: 0.37503278255462646
train loss item: 0.37732088565826416
train loss item: 0.2934585213661194
train loss item: 0.7067073583602905
train loss item: 0.1925668716430664
train loss item: 0.37078243494033813
train loss item: 0.509731650352478
train loss item: 0.2693367600440979
train loss item: 0.13452497124671936
train loss item: 0.6687837243080139
train loss item: 0.32628270983695984
train loss item: 0.5695708394050598
train loss item: 0.06259627640247345
train loss item: 0.37037205696105957
train loss item: 0.35759562253952026
train loss item: 0.2613115906715393
train loss item: 0.23524600267410278
train loss item: 0.12728853523731232
train loss item: 0.8458204865455627
train loss item: 0.8515357375144958
train loss item: 0.5354660749435425
train loss item: 0.1858229786157608
train loss item: 0.2000306099653244
train loss item: 0.2145002782344818
train loss item: 0.04925678297877312
train loss item: 0.5224248766899109
train loss item: 1.3690091371536255
train loss item: 0.7756256461143494
train loss item: 0.17583271861076355
train loss item: 0.33368217945098877
train loss item: 0.11360208690166473
train loss item: 1.2340900897979736
train loss item: 0.659313976764679
train loss item: 0.4805321991443634
train loss item: 0.4125087559223175
train loss item: 0.26992470026016235
train loss item: 0.1815582662820816
train loss item: 0.311013787984848
train loss item: 0.33454301953315735
train loss item: 0.2472938746213913
train loss item: 0.6052659153938293
train loss item: 0.12290994822978973
train loss item: 0.11766999214887619
train loss item: 0.39428767561912537
train loss item: 0.2791212797164917
train loss item: 0.16540628671646118
train loss item: 0.34267452359199524
train loss item: 0.8927373886108398
train loss item: 0.08900678902864456
train loss item: 0.17248576879501343
train loss item: 1.1685435771942139
train loss item: 0.20822730660438538
train loss item: 0.4424988925457001
train loss item: 0.2119615525007248
train loss item: 0.14401598274707794
train loss item: 0.10733173042535782
train loss item: 0.662929892539978
train loss item: 1.1072558164596558
train loss item: 0.22056375443935394
train loss item: 0.4845208525657654
train loss item: 0.16145993769168854
train loss item: 0.5377627611160278
train loss item: 0.500778079032898
train loss item: 0.1910535842180252
train loss item: 0.35832345485687256
train loss item: 0.3153858780860901
train loss item: 0.23926378786563873
train loss item: 0.11486254632472992
train loss item: 0.2071431279182434
train loss item: 0.2925991117954254
train loss item: 0.11343211680650711
train loss item: 0.13531138002872467
train loss item: 0.6896268129348755
train loss item: 1.0016021728515625
train loss item: 0.08443136513233185
train loss item: 0.28996893763542175
train loss item: 0.13920217752456665
train loss item: 0.18742170929908752
train loss item: 0.2237304151058197
train loss item: 0.40799689292907715
train loss item: 0.516615092754364
train loss item: 0.5236713290214539
train loss item: 2.152217388153076
train loss item: 0.1237364262342453
train loss item: 0.4269510805606842
test loss item: 0.2567932605743408
test loss item: 0.15761049091815948
test loss item: 0.5037261247634888
test loss item: 0.28755679726600647
test loss item: 0.2799733281135559
test loss item: 0.2226824313402176
test loss item: 2.1670100688934326
test loss item: 0.7983096241950989
test loss item: 0.25100791454315186
test loss item: 0.4357367157936096
test loss item: 0.6541020274162292
test loss item: 0.23016734421253204
test loss item: 0.30277976393699646
test loss item: 0.4904247224330902
test loss item: 0.20367814600467682
test loss item: 0.09016114473342896
test loss item: 0.42522889375686646
test loss item: 0.47748976945877075
test loss item: 0.8310874700546265
test loss item: 0.4600565731525421
test loss item: 0.6939845681190491
test loss item: 0.5127993822097778
test loss item: 0.4229692220687866
test loss item: 0.25995388627052307
test loss item: 0.27470603585243225
test loss item: 0.3801916539669037
test loss item: 0.43125125765800476
test loss item: 0.25557640194892883
test loss item: 0.38432759046554565
test loss item: 0.45384252071380615
test loss item: 0.8206896185874939
test loss item: 0.08280728757381439
test loss item: 0.22916240990161896
test loss item: 0.5244811773300171
test loss item: 0.41453447937965393
test loss item: 0.5124036073684692
test loss item: 0.9803028702735901
test loss item: 0.9642666578292847
test loss item: 0.4859732985496521
test loss item: 0.3627009391784668
test loss item: 0.3904828429222107
test loss item: 0.37790361046791077
test loss item: 0.3817921280860901
test loss item: 0.30606842041015625
test loss item: 0.5996156334877014
test loss item: 0.6003375053405762
test loss item: 0.4361158311367035
test loss item: 0.4732668399810791
test loss item: 0.4692555367946625
test loss item: 0.6891291737556458
test loss item: 0.37084266543388367
test loss item: 0.3076935410499573
test loss item: 0.3376193940639496
test loss item: 0.24078120291233063
test loss item: 0.38281193375587463
test loss item: 0.6496930122375488
test loss item: 0.6182107329368591
test loss item: 0.3799244463443756
test loss item: 0.36443161964416504
test loss item: 0.28534725308418274
test loss item: 0.4684639573097229
test loss item: 0.3784245550632477
test loss item: 0.38511332869529724
test loss item: 0.327300488948822
test loss item: 0.8369375467300415
test loss item: 0.3546932339668274
test loss item: 0.4802832007408142
test loss item: 0.3356372117996216
test loss item: 0.42487016320228577
test loss item: 0.555466890335083
test loss item: 0.10445588082075119
test loss item: 1.3153855800628662
test loss item: 0.4786612093448639
test loss item: 0.5853992700576782
test loss item: 0.2791902422904968
test loss item: 0.33464714884757996
test loss item: 0.25238972902297974
test loss item: 0.9297845959663391
test loss item: 0.573838472366333
test loss item: 0.30514857172966003
test loss item: 0.11132800579071045
test loss item: 0.9930948615074158
test loss item: 1.0298348665237427
test loss item: 0.7273204326629639
test loss item: 0.37451088428497314
test loss item: 0.3491256833076477
test loss item: 0.10328185558319092
test loss item: 0.08650226145982742
test loss item: 0.28411224484443665
Epoch [8/10], Training Loss: 0.4179, Testing Loss: 0.4652
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/10
train loss item: 0.3943084180355072
train loss item: 1.2518301010131836
train loss item: 0.2417733371257782
train loss item: 0.5033578276634216
train loss item: 0.31762465834617615
train loss item: 0.30651310086250305
train loss item: 0.2719748020172119
train loss item: 0.49678751826286316
train loss item: 0.14055512845516205
train loss item: 0.2502962648868561
train loss item: 0.3384595215320587
train loss item: 0.21768838167190552
train loss item: 0.10802147537469864
train loss item: 0.5206465125083923
train loss item: 0.22832664847373962
train loss item: 0.5531049370765686
train loss item: 0.07221700251102448
train loss item: 0.33692964911460876
train loss item: 0.32066312432289124
train loss item: 0.29065757989883423
train loss item: 0.20987290143966675
train loss item: 0.10496153682470322
train loss item: 0.8737314939498901
train loss item: 0.6202548742294312
train loss item: 0.5031731724739075
train loss item: 0.1902940422296524
train loss item: 0.1990508884191513
train loss item: 0.18747586011886597
train loss item: 0.08616480231285095
train loss item: 0.4545786380767822
train loss item: 1.3357439041137695
train loss item: 0.6800063252449036
train loss item: 0.14511138200759888
train loss item: 0.29686275124549866
train loss item: 0.13443797826766968
train loss item: 1.1794207096099854
train loss item: 0.49578624963760376
train loss item: 0.44220465421676636
train loss item: 0.3789566159248352
train loss item: 0.3019673824310303
train loss item: 0.22432221472263336
train loss item: 0.319710373878479
train loss item: 0.37649762630462646
train loss item: 0.24996329843997955
train loss item: 0.5574735999107361
train loss item: 0.13155370950698853
train loss item: 0.12359916418790817
train loss item: 0.41753652691841125
train loss item: 0.24487647414207458
train loss item: 0.16097494959831238
train loss item: 0.34911730885505676
train loss item: 0.7844935059547424
train loss item: 0.07732833921909332
train loss item: 0.17402642965316772
train loss item: 0.8306376338005066
train loss item: 0.2039181888103485
train loss item: 0.48135289549827576
train loss item: 0.19480495154857635
train loss item: 0.14029325544834137
train loss item: 0.09558185189962387
train loss item: 0.6558430194854736
train loss item: 0.9901688694953918
train loss item: 0.178696408867836
train loss item: 0.4276404082775116
train loss item: 0.15233182907104492
train loss item: 0.5161534547805786
train loss item: 0.42756152153015137
train loss item: 0.1913672834634781
train loss item: 0.3697536587715149
train loss item: 0.3045537769794464
train loss item: 0.23685811460018158
train loss item: 0.13889606297016144
train loss item: 0.17531685531139374
train loss item: 0.2842349112033844
train loss item: 0.10026045143604279
train loss item: 0.13180258870124817
train loss item: 0.5807970762252808
train loss item: 1.1195266246795654
train loss item: 0.07228309661149979
train loss item: 0.24628476798534393
train loss item: 0.13208618760108948
train loss item: 0.17380771040916443
train loss item: 0.19949181377887726
train loss item: 0.40946468710899353
train loss item: 0.3933228552341461
train loss item: 0.4673115611076355
train loss item: 1.9249519109725952
train loss item: 0.10517001897096634
train loss item: 0.4247356951236725
test loss item: 0.2204207479953766
test loss item: 0.12424349784851074
test loss item: 0.4377097189426422
test loss item: 0.2515019476413727
test loss item: 0.22747795283794403
test loss item: 0.1653396487236023
test loss item: 1.9440281391143799
test loss item: 0.7012624740600586
test loss item: 0.21113066375255585
test loss item: 0.3685648441314697
test loss item: 0.5838293433189392
test loss item: 0.19564618170261383
test loss item: 0.2406734675168991
test loss item: 0.4197448492050171
test loss item: 0.16835032403469086
test loss item: 0.08144384622573853
test loss item: 0.35634589195251465
test loss item: 0.406818151473999
test loss item: 0.7374441623687744
test loss item: 0.38563090562820435
test loss item: 0.6313338875770569
test loss item: 0.44727596640586853
test loss item: 0.358994722366333
test loss item: 0.22699229419231415
test loss item: 0.22718161344528198
test loss item: 0.32386988401412964
test loss item: 0.3754996657371521
test loss item: 0.20187275111675262
test loss item: 0.336020827293396
test loss item: 0.37438440322875977
test loss item: 0.7395486831665039
test loss item: 0.0772009864449501
test loss item: 0.19681890308856964
test loss item: 0.46572744846343994
test loss item: 0.356590211391449
test loss item: 0.4568166136741638
test loss item: 0.8710479140281677
test loss item: 0.8426154851913452
test loss item: 0.42564958333969116
test loss item: 0.3154803216457367
test loss item: 0.34118926525115967
test loss item: 0.3044590950012207
test loss item: 0.3218909204006195
test loss item: 0.2561221420764923
test loss item: 0.5347146987915039
test loss item: 0.5165683031082153
test loss item: 0.3623445928096771
test loss item: 0.38730573654174805
test loss item: 0.40712982416152954
test loss item: 0.6189296841621399
test loss item: 0.3098899722099304
test loss item: 0.23484206199645996
test loss item: 0.27424341440200806
test loss item: 0.19664782285690308
test loss item: 0.3191346228122711
test loss item: 0.5909035801887512
test loss item: 0.5499278903007507
test loss item: 0.31522467732429504
test loss item: 0.30291709303855896
test loss item: 0.22689715027809143
test loss item: 0.40138375759124756
test loss item: 0.31830039620399475
test loss item: 0.3241020739078522
test loss item: 0.2808609902858734
test loss item: 0.7436649799346924
test loss item: 0.31405654549598694
test loss item: 0.4037174880504608
test loss item: 0.290264368057251
test loss item: 0.37645331025123596
test loss item: 0.4984920024871826
test loss item: 0.08656774461269379
test loss item: 1.1674731969833374
test loss item: 0.419001042842865
test loss item: 0.5134468078613281
test loss item: 0.22083322703838348
test loss item: 0.2707971930503845
test loss item: 0.22019171714782715
test loss item: 0.8035420775413513
test loss item: 0.507011890411377
test loss item: 0.24383126199245453
test loss item: 0.09940210729837418
test loss item: 0.8895789980888367
test loss item: 0.9265362620353699
test loss item: 0.6298977136611938
test loss item: 0.3124161958694458
test loss item: 0.28668269515037537
test loss item: 0.09571012854576111
test loss item: 0.08296304941177368
test loss item: 0.23552587628364563
Epoch [9/10], Training Loss: 0.3781, Testing Loss: 0.4024
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/10
train loss item: 0.36878710985183716
train loss item: 1.1763375997543335
train loss item: 0.21575602889060974
train loss item: 0.4448288381099701
train loss item: 0.3368370831012726
train loss item: 0.2958010733127594
train loss item: 0.24419847130775452
train loss item: 0.551024317741394
train loss item: 0.154616117477417
train loss item: 0.29211241006851196
train loss item: 0.4009685218334198
train loss item: 0.20642174780368805
train loss item: 0.10886412113904953
train loss item: 0.5505256056785583
train loss item: 0.25262555480003357
train loss item: 0.5175904631614685
train loss item: 0.05777578055858612
train loss item: 0.3303355276584625
train loss item: 0.30565008521080017
train loss item: 0.2700704336166382
train loss item: 0.23120786249637604
train loss item: 0.10362990200519562
train loss item: 0.8113481998443604
train loss item: 0.5591221451759338
train loss item: 0.4598255455493927
train loss item: 0.19131170213222504
train loss item: 0.16942310333251953
train loss item: 0.1938268542289734
train loss item: 0.06184440106153488
train loss item: 0.45426642894744873
train loss item: 1.2089669704437256
train loss item: 0.6438276767730713
train loss item: 0.08453910052776337
train loss item: 0.2876169979572296
train loss item: 0.11484619230031967
train loss item: 1.1217713356018066
train loss item: 0.5655614137649536
train loss item: 0.47476041316986084
train loss item: 0.33075210452079773
train loss item: 0.28030452132225037
train loss item: 0.20698845386505127
train loss item: 0.3047412037849426
train loss item: 0.34826725721359253
train loss item: 0.25430336594581604
train loss item: 0.6151103973388672
train loss item: 0.12027926743030548
train loss item: 0.12578274309635162
train loss item: 0.37028443813323975
train loss item: 0.26226845383644104
train loss item: 0.17602413892745972
train loss item: 0.27000075578689575
train loss item: 0.8621054291725159
train loss item: 0.0642240047454834
train loss item: 0.1927359253168106
train loss item: 1.0703378915786743
train loss item: 0.171883225440979
train loss item: 0.42034947872161865
train loss item: 0.2148023098707199
train loss item: 0.16113224625587463
train loss item: 0.11904363334178925
train loss item: 0.5377424955368042
train loss item: 1.0143924951553345
train loss item: 0.19995950162410736
train loss item: 0.3869819641113281
train loss item: 0.13324472308158875
train loss item: 0.48113787174224854
train loss item: 0.3302311599254608
train loss item: 0.16948848962783813
train loss item: 0.3092219829559326
train loss item: 0.2528246343135834
train loss item: 0.20946331322193146
train loss item: 0.10001591593027115
train loss item: 0.17831844091415405
train loss item: 0.24189244210720062
train loss item: 0.07724722474813461
train loss item: 0.11520673334598541
train loss item: 0.5836808681488037
train loss item: 0.8585512638092041
train loss item: 0.07447987794876099
train loss item: 0.3069455325603485
train loss item: 0.11994390189647675
train loss item: 0.1438131481409073
train loss item: 0.18901099264621735
train loss item: 0.3486930727958679
train loss item: 0.4438842535018921
train loss item: 0.4163747727870941
train loss item: 1.8966126441955566
train loss item: 0.1123899295926094
train loss item: 0.4075483977794647
test loss item: 0.21484242379665375
test loss item: 0.12628278136253357
test loss item: 0.47858038544654846
test loss item: 0.24873511493206024
test loss item: 0.21585822105407715
test loss item: 0.15981148183345795
test loss item: 2.091974973678589
test loss item: 0.8710073828697205
test loss item: 0.26112282276153564
test loss item: 0.42725706100463867
test loss item: 0.6413074731826782
test loss item: 0.1753314733505249
test loss item: 0.2865150272846222
test loss item: 0.4109778106212616
test loss item: 0.16679063439369202
test loss item: 0.07774188369512558
test loss item: 0.38298314809799194
test loss item: 0.4081336259841919
test loss item: 0.8623019456863403
test loss item: 0.423302561044693
test loss item: 0.5651770234107971
test loss item: 0.49523627758026123
test loss item: 0.3205699026584625
test loss item: 0.22970856726169586
test loss item: 0.22877700626850128
test loss item: 0.32366329431533813
test loss item: 0.4091174006462097
test loss item: 0.1992020457983017
test loss item: 0.32715409994125366
test loss item: 0.4480556547641754
test loss item: 0.8053573966026306
test loss item: 0.0771641656756401
test loss item: 0.20011018216609955
test loss item: 0.4603038728237152
test loss item: 0.3625778555870056
test loss item: 0.5532498359680176
test loss item: 0.9983686804771423
test loss item: 0.9241281747817993
test loss item: 0.42515021562576294
test loss item: 0.31712543964385986
test loss item: 0.3505900204181671
test loss item: 0.28294309973716736
test loss item: 0.34527072310447693
test loss item: 0.26400408148765564
test loss item: 0.48273369669914246
test loss item: 0.5673304200172424
test loss item: 0.33956262469291687
test loss item: 0.4624353051185608
test loss item: 0.46624618768692017
test loss item: 0.6990091800689697
test loss item: 0.3322218060493469
test loss item: 0.3107130825519562
test loss item: 0.294273316860199
test loss item: 0.1858646720647812
test loss item: 0.32647863030433655
test loss item: 0.6384111046791077
test loss item: 0.6361135244369507
test loss item: 0.3011924624443054
test loss item: 0.3273474872112274
test loss item: 0.2347787320613861
test loss item: 0.4569457173347473
test loss item: 0.38290584087371826
test loss item: 0.3255096971988678
test loss item: 0.26828521490097046
test loss item: 0.8207732439041138
test loss item: 0.3084791898727417
test loss item: 0.4488021731376648
test loss item: 0.2870396673679352
test loss item: 0.35647422075271606
test loss item: 0.6207966208457947
test loss item: 0.07183729857206345
test loss item: 1.3017041683197021
test loss item: 0.39851537346839905
test loss item: 0.5202128887176514
test loss item: 0.24250733852386475
test loss item: 0.2557038366794586
test loss item: 0.22344070672988892
test loss item: 0.8488708734512329
test loss item: 0.47000956535339355
test loss item: 0.22942163050174713
test loss item: 0.09332186728715897
test loss item: 0.9849663972854614
test loss item: 1.0423580408096313
test loss item: 0.7146645188331604
test loss item: 0.3125433623790741
test loss item: 0.29582542181015015
test loss item: 0.09069182723760605
test loss item: 0.08584767580032349
test loss item: 0.18225927650928497
Epoch [10/10], Training Loss: 0.3640, Testing Loss: 0.4280
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
loss item: 0.37283962965011597
loss item: 0.24567638337612152
loss item: 1.0176490545272827
loss item: 0.864284336566925
loss item: 0.7493422627449036
loss item: 0.5081790685653687
loss item: 0.1506120264530182
loss item: 0.9846572875976562
loss item: 0.3325721025466919
loss item: 0.22101223468780518
loss item: 1.265721321105957
loss item: 0.08730559051036835
loss item: 1.2148667573928833
loss item: 0.28467580676078796
loss item: 0.33049798011779785
loss item: 0.30030983686447144
loss item: 0.4754806160926819
loss item: 0.6766722202301025
loss item: 0.8918502330780029
loss item: 0.5862811207771301
loss item: 0.37308940291404724
loss item: 0.40964275598526
loss item: 0.4187912344932556
loss item: 0.397490918636322
loss item: 0.34005817770957947
loss item: 0.8653343319892883
loss item: 0.95145183801651
loss item: 0.1624179482460022
loss item: 0.13129200041294098
loss item: 0.5718845725059509
loss item: 1.2578223943710327
loss item: 1.0873925685882568
loss item: 0.28201207518577576
loss item: 0.7811214327812195
loss item: 0.2455214112997055
loss item: 0.307351678609848
loss item: 0.4366874098777771
loss item: 0.33586451411247253
loss item: 0.5871099829673767
loss item: 0.8646718263626099
loss item: 0.8942165970802307
loss item: 0.39311686158180237
loss item: 0.23020325601100922
loss item: 0.07347733527421951
Val Loss: 0.5445
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 10, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.005 2 360 done at Tue Nov 12 09:35:56 CET 2024
UNet2 with 1 10 0.0001 4 360 start at Tue Nov 12 09:35:56 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.6336421966552734
train loss item: 1.1108150482177734
train loss item: 0.6386311054229736
train loss item: 1.194264531135559
train loss item: 0.5417352318763733
train loss item: 0.5596734285354614
train loss item: 0.6423448920249939
train loss item: 0.840389609336853
train loss item: 0.516490638256073
train loss item: 0.5425041317939758
train loss item: 0.38656359910964966
train loss item: 1.3202400207519531
train loss item: 0.5797537565231323
train loss item: 0.4730110168457031
train loss item: 0.8736816644668579
train loss item: 2.072476387023926
train loss item: 0.6429057121276855
train loss item: 2.485495090484619
train loss item: 0.4917813241481781
train loss item: 0.4936889708042145
train loss item: 0.4070166349411011
train loss item: 0.3808233439922333
train loss item: 0.6257745027542114
train loss item: 0.42149874567985535
train loss item: 0.3764941394329071
train loss item: 0.8154841661453247
train loss item: 0.3215309977531433
train loss item: 1.8327252864837646
train loss item: 0.4126252233982086
train loss item: 0.32324883341789246
train loss item: 1.6522047519683838
train loss item: 0.39049842953681946
train loss item: 0.5390455722808838
train loss item: 0.41372454166412354
train loss item: 0.4230559170246124
train loss item: 0.3145202100276947
train loss item: 0.3597916066646576
train loss item: 0.3155818283557892
train loss item: 1.1574903726577759
train loss item: 0.2918848991394043
train loss item: 0.2487623244524002
train loss item: 0.5042638778686523
train loss item: 0.5764230489730835
train loss item: 3.096247673034668
train loss item: 0.3796599209308624
test loss item: 0.19254712760448456
test loss item: 0.5322990417480469
test loss item: 0.27953314781188965
test loss item: 1.0018279552459717
test loss item: 0.3794468939304352
test loss item: 0.7656427025794983
test loss item: 0.21222026646137238
test loss item: 0.202741801738739
test loss item: 0.42609620094299316
test loss item: 0.4844416677951813
test loss item: 0.540101170539856
test loss item: 0.3132360577583313
test loss item: 0.2739086449146271
test loss item: 0.3122216463088989
test loss item: 0.3926287889480591
test loss item: 0.7177404165267944
test loss item: 0.5661835670471191
test loss item: 0.5591747164726257
test loss item: 1.1336504220962524
test loss item: 0.47167396545410156
test loss item: 0.3113957345485687
test loss item: 0.34059053659439087
test loss item: 0.5480929613113403
test loss item: 0.31760090589523315
test loss item: 0.6265824437141418
test loss item: 0.27403774857521057
test loss item: 0.2855880856513977
test loss item: 0.7560979723930359
test loss item: 0.6133039593696594
test loss item: 0.2586955726146698
test loss item: 0.4102960228919983
test loss item: 0.27191323041915894
test loss item: 0.7541375756263733
test loss item: 0.3337915539741516
test loss item: 0.5460705161094666
test loss item: 0.6468589305877686
test loss item: 0.40331289172172546
test loss item: 0.1907721906900406
test loss item: 1.349961280822754
test loss item: 0.26866015791893005
test loss item: 0.8250028491020203
test loss item: 1.006622314453125
test loss item: 0.26233527064323425
test loss item: 0.1525888890028
test loss item: 0.2591479420661926
Epoch [1/10], Training Loss: 0.7693, Testing Loss: 0.4838
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/10
train loss item: 0.8530784845352173
train loss item: 0.4625650942325592
train loss item: 0.3809688687324524
train loss item: 0.5835763216018677
train loss item: 0.2991321384906769
train loss item: 0.35864973068237305
train loss item: 0.3826286196708679
train loss item: 0.5319647789001465
train loss item: 0.2997666001319885
train loss item: 0.3559068441390991
train loss item: 0.28267526626586914
train loss item: 0.8010956048965454
train loss item: 0.43608972430229187
train loss item: 0.32831594347953796
train loss item: 0.5846399664878845
train loss item: 1.4322606325149536
train loss item: 0.38311606645584106
train loss item: 1.8654735088348389
train loss item: 0.435563862323761
train loss item: 0.39391812682151794
train loss item: 0.26817646622657776
train loss item: 0.28279995918273926
train loss item: 0.436543732881546
train loss item: 0.31909412145614624
train loss item: 0.2407585233449936
train loss item: 0.649221658706665
train loss item: 0.2089318037033081
train loss item: 1.4434759616851807
train loss item: 0.3099333643913269
train loss item: 0.20974814891815186
train loss item: 1.349700927734375
train loss item: 0.32061582803726196
train loss item: 0.40310314297676086
train loss item: 0.35192814469337463
train loss item: 0.3204593062400818
train loss item: 0.2591325044631958
train loss item: 0.3048819899559021
train loss item: 0.22847671806812286
train loss item: 0.9508203268051147
train loss item: 0.27142608165740967
train loss item: 0.19510751962661743
train loss item: 0.3813060522079468
train loss item: 0.4492320716381073
train loss item: 2.600039005279541
train loss item: 0.35590770840644836
test loss item: 0.1924028843641281
test loss item: 0.38901200890541077
test loss item: 0.21826393902301788
test loss item: 0.7553784847259521
test loss item: 0.30172598361968994
test loss item: 0.5766850113868713
test loss item: 0.17969641089439392
test loss item: 0.2035469114780426
test loss item: 0.3262111246585846
test loss item: 0.41878992319107056
test loss item: 0.43651410937309265
test loss item: 0.2396809607744217
test loss item: 0.22214895486831665
test loss item: 0.26224586367607117
test loss item: 0.32335275411605835
test loss item: 0.507458508014679
test loss item: 0.45063671469688416
test loss item: 0.45962539315223694
test loss item: 0.8126094341278076
test loss item: 0.3641131520271301
test loss item: 0.2598801851272583
test loss item: 0.30639076232910156
test loss item: 0.4210054874420166
test loss item: 0.2530648410320282
test loss item: 0.45969319343566895
test loss item: 0.2280336171388626
test loss item: 0.26939958333969116
test loss item: 0.5392659306526184
test loss item: 0.517770528793335
test loss item: 0.21934156119823456
test loss item: 0.34101319313049316
test loss item: 0.21918857097625732
test loss item: 0.5810450911521912
test loss item: 0.26746615767478943
test loss item: 0.42877864837646484
test loss item: 0.4954307973384857
test loss item: 0.3076644241809845
test loss item: 0.16605477035045624
test loss item: 0.8322762846946716
test loss item: 0.21045993268489838
test loss item: 0.5955309271812439
test loss item: 0.7164821028709412
test loss item: 0.21455755829811096
test loss item: 0.1829734593629837
test loss item: 0.23580966889858246
Epoch [2/10], Training Loss: 0.5458, Testing Loss: 0.3757
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/10
train loss item: 0.6598713397979736
train loss item: 0.4232446849346161
train loss item: 0.2901347875595093
train loss item: 0.4724433422088623
train loss item: 0.2490486353635788
train loss item: 0.2853403389453888
train loss item: 0.3308391571044922
train loss item: 0.4407189190387726
train loss item: 0.23018403351306915
train loss item: 0.31086409091949463
train loss item: 0.22126378118991852
train loss item: 0.64383465051651
train loss item: 0.3296438753604889
train loss item: 0.24782025814056396
train loss item: 0.43594369292259216
train loss item: 1.1538946628570557
train loss item: 0.33476313948631287
train loss item: 1.5579376220703125
train loss item: 0.43418073654174805
train loss item: 0.37340864539146423
train loss item: 0.22276949882507324
train loss item: 0.24664263427257538
train loss item: 0.3776668310165405
train loss item: 0.27741819620132446
train loss item: 0.19357553124427795
train loss item: 0.6395742893218994
train loss item: 0.1662517786026001
train loss item: 1.2544194459915161
train loss item: 0.24450421333312988
train loss item: 0.16649506986141205
train loss item: 1.2141917943954468
train loss item: 0.2717919945716858
train loss item: 0.32139265537261963
train loss item: 0.31059080362319946
train loss item: 0.3024057447910309
train loss item: 0.23042164742946625
train loss item: 0.2689515948295593
train loss item: 0.18069873750209808
train loss item: 0.8145211935043335
train loss item: 0.24411973357200623
train loss item: 0.15811559557914734
train loss item: 0.3099927306175232
train loss item: 0.3743237257003784
train loss item: 2.2548959255218506
train loss item: 0.3455474078655243
test loss item: 0.1567484587430954
test loss item: 0.32524338364601135
test loss item: 0.18354667723178864
test loss item: 0.6443492770195007
test loss item: 0.248031884431839
test loss item: 0.48228785395622253
test loss item: 0.1571148782968521
test loss item: 0.15591980516910553
test loss item: 0.2755969166755676
test loss item: 0.36114421486854553
test loss item: 0.3683328330516815
test loss item: 0.19906823337078094
test loss item: 0.1932804435491562
test loss item: 0.21959657967090607
test loss item: 0.2695635259151459
test loss item: 0.4195825755596161
test loss item: 0.37004873156547546
test loss item: 0.3853686451911926
test loss item: 0.6814380884170532
test loss item: 0.30140599608421326
test loss item: 0.2276572585105896
test loss item: 0.24772590398788452
test loss item: 0.3485667109489441
test loss item: 0.21713702380657196
test loss item: 0.38144251704216003
test loss item: 0.19126345217227936
test loss item: 0.22153939306735992
test loss item: 0.4535500109195709
test loss item: 0.43874040246009827
test loss item: 0.18656742572784424
test loss item: 0.2786179184913635
test loss item: 0.19131726026535034
test loss item: 0.5063855051994324
test loss item: 0.22844058275222778
test loss item: 0.36884254217147827
test loss item: 0.41617342829704285
test loss item: 0.26360324025154114
test loss item: 0.1388445347547531
test loss item: 0.7032617926597595
test loss item: 0.1841839849948883
test loss item: 0.5050525069236755
test loss item: 0.6139421463012695
test loss item: 0.18758070468902588
test loss item: 0.1349361389875412
test loss item: 0.21195200085639954
Epoch [3/10], Training Loss: 0.4626, Testing Loss: 0.3166
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/10
train loss item: 0.5618870258331299
train loss item: 0.3722328245639801
train loss item: 0.2490004301071167
train loss item: 0.4106227159500122
train loss item: 0.21585331857204437
train loss item: 0.23959307372570038
train loss item: 0.3030990660190582
train loss item: 0.41610923409461975
train loss item: 0.19181565940380096
train loss item: 0.2672255039215088
train loss item: 0.19824333488941193
train loss item: 0.5656682848930359
train loss item: 0.28306129574775696
train loss item: 0.20236040651798248
train loss item: 0.38575372099876404
train loss item: 0.9758630990982056
train loss item: 0.30334147810935974
train loss item: 1.3312838077545166
train loss item: 0.4402458965778351
train loss item: 0.36445504426956177
train loss item: 0.21548692882061005
train loss item: 0.2280951291322708
train loss item: 0.3320624828338623
train loss item: 0.22963036596775055
train loss item: 0.17212408781051636
train loss item: 0.5709607601165771
train loss item: 0.1486683487892151
train loss item: 1.1131006479263306
train loss item: 0.22239600121974945
train loss item: 0.1416970193386078
train loss item: 1.081766963005066
train loss item: 0.2511066794395447
train loss item: 0.2881886065006256
train loss item: 0.2728324234485626
train loss item: 0.2696932852268219
train loss item: 0.20192497968673706
train loss item: 0.23364686965942383
train loss item: 0.15686996281147003
train loss item: 0.7055091857910156
train loss item: 0.23961731791496277
train loss item: 0.1528039127588272
train loss item: 0.2644255757331848
train loss item: 0.3651811182498932
train loss item: 2.0158777236938477
train loss item: 0.3106262981891632
test loss item: 0.14340484142303467
test loss item: 0.30663344264030457
test loss item: 0.17964254319667816
test loss item: 0.5757611989974976
test loss item: 0.2274440973997116
test loss item: 0.42666706442832947
test loss item: 0.14615949988365173
test loss item: 0.13580358028411865
test loss item: 0.24561995267868042
test loss item: 0.32771116495132446
test loss item: 0.33906301856040955
test loss item: 0.18428988754749298
test loss item: 0.17388392984867096
test loss item: 0.20481479167938232
test loss item: 0.24307343363761902
test loss item: 0.3703857958316803
test loss item: 0.3368488848209381
test loss item: 0.33273741602897644
test loss item: 0.6039667129516602
test loss item: 0.27708303928375244
test loss item: 0.20756562054157257
test loss item: 0.22960279881954193
test loss item: 0.30724990367889404
test loss item: 0.20498403906822205
test loss item: 0.35021117329597473
test loss item: 0.17306102812290192
test loss item: 0.21332448720932007
test loss item: 0.4067201018333435
test loss item: 0.3879269063472748
test loss item: 0.16979791224002838
test loss item: 0.25095072388648987
test loss item: 0.17552438378334045
test loss item: 0.4471025764942169
test loss item: 0.20794320106506348
test loss item: 0.33272111415863037
test loss item: 0.3695046007633209
test loss item: 0.2523035705089569
test loss item: 0.13593003153800964
test loss item: 0.5824683904647827
test loss item: 0.18316017091274261
test loss item: 0.4357914924621582
test loss item: 0.5340243577957153
test loss item: 0.17386946082115173
test loss item: 0.11617188155651093
test loss item: 0.1767515391111374
Epoch [4/10], Training Loss: 0.4103, Testing Loss: 0.2846
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/10
train loss item: 0.5013740062713623
train loss item: 0.31032848358154297
train loss item: 0.22424444556236267
train loss item: 0.3636402487754822
train loss item: 0.20785178244113922
train loss item: 0.21106576919555664
train loss item: 0.2755098342895508
train loss item: 0.41011419892311096
train loss item: 0.1712239533662796
train loss item: 0.2496809959411621
train loss item: 0.1869724541902542
train loss item: 0.5059334635734558
train loss item: 0.2949138283729553
train loss item: 0.17667461931705475
train loss item: 0.34406930208206177
train loss item: 0.8494293093681335
train loss item: 0.2649646997451782
train loss item: 1.1987065076828003
train loss item: 0.431135356426239
train loss item: 0.3233742415904999
train loss item: 0.21564146876335144
train loss item: 0.21672971546649933
train loss item: 0.30766192078590393
train loss item: 0.19931910932064056
train loss item: 0.1563977152109146
train loss item: 0.5174603462219238
train loss item: 0.1394663006067276
train loss item: 0.9935267567634583
train loss item: 0.20669110119342804
train loss item: 0.12679420411586761
train loss item: 0.9841118454933167
train loss item: 0.22322897613048553
train loss item: 0.25033268332481384
train loss item: 0.2367764115333557
train loss item: 0.23951266705989838
train loss item: 0.18053515255451202
train loss item: 0.2114439308643341
train loss item: 0.1395351141691208
train loss item: 0.6312664151191711
train loss item: 0.22452309727668762
train loss item: 0.1439131647348404
train loss item: 0.23302431404590607
train loss item: 0.37349188327789307
train loss item: 1.8478450775146484
train loss item: 0.2762938439846039
test loss item: 0.13432292640209198
test loss item: 0.2698875963687897
test loss item: 0.16619634628295898
test loss item: 0.5098472833633423
test loss item: 0.21033135056495667
test loss item: 0.3878975212574005
test loss item: 0.14286909997463226
test loss item: 0.11820726096630096
test loss item: 0.21723394095897675
test loss item: 0.29824623465538025
test loss item: 0.283408522605896
test loss item: 0.1756659895181656
test loss item: 0.15902754664421082
test loss item: 0.18850457668304443
test loss item: 0.22202034294605255
test loss item: 0.3362136483192444
test loss item: 0.2843731939792633
test loss item: 0.2979661822319031
test loss item: 0.5561423301696777
test loss item: 0.23569442331790924
test loss item: 0.18900063633918762
test loss item: 0.17881880700588226
test loss item: 0.2702197730541229
test loss item: 0.19903084635734558
test loss item: 0.3218778371810913
test loss item: 0.16384385526180267
test loss item: 0.16468198597431183
test loss item: 0.3754085600376129
test loss item: 0.3472352623939514
test loss item: 0.15991036593914032
test loss item: 0.22524623572826385
test loss item: 0.16352002322673798
test loss item: 0.38411054015159607
test loss item: 0.18911604583263397
test loss item: 0.3091127574443817
test loss item: 0.32292452454566956
test loss item: 0.24100777506828308
test loss item: 0.13480062782764435
test loss item: 0.5450472235679626
test loss item: 0.17032469809055328
test loss item: 0.38677623867988586
test loss item: 0.4849449396133423
test loss item: 0.16099335253238678
test loss item: 0.09332399815320969
test loss item: 0.16240699589252472
Epoch [5/10], Training Loss: 0.3728, Testing Loss: 0.2564
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/10
train loss item: 0.44988641142845154
train loss item: 0.27093246579170227
train loss item: 0.2079661637544632
train loss item: 0.30964550375938416
train loss item: 0.18559907376766205
train loss item: 0.1912204921245575
train loss item: 0.2342289537191391
train loss item: 0.3920990228652954
train loss item: 0.16300596296787262
train loss item: 0.23888932168483734
train loss item: 0.19406132400035858
train loss item: 0.47086137533187866
train loss item: 0.2553054094314575
train loss item: 0.15356262028217316
train loss item: 0.32063063979148865
train loss item: 0.7193990349769592
train loss item: 0.24301914870738983
train loss item: 1.0767515897750854
train loss item: 0.40787607431411743
train loss item: 0.2844446301460266
train loss item: 0.20614826679229736
train loss item: 0.1920308768749237
train loss item: 0.2868853211402893
train loss item: 0.17821799218654633
train loss item: 0.1461944580078125
train loss item: 0.4629668891429901
train loss item: 0.122275210916996
train loss item: 0.8946674466133118
train loss item: 0.19240275025367737
train loss item: 0.11612949520349503
train loss item: 0.8758742213249207
train loss item: 0.21149420738220215
train loss item: 0.23510947823524475
train loss item: 0.23900988698005676
train loss item: 0.22558818757534027
train loss item: 0.17874161899089813
train loss item: 0.19237491488456726
train loss item: 0.12507560849189758
train loss item: 0.582118034362793
train loss item: 0.2024574726819992
train loss item: 0.13249118626117706
train loss item: 0.22354823350906372
train loss item: 0.3388078808784485
train loss item: 1.7159408330917358
train loss item: 0.24550417065620422
test loss item: 0.1340607851743698
test loss item: 0.24220483005046844
test loss item: 0.15514422953128815
test loss item: 0.46529293060302734
test loss item: 0.19514508545398712
test loss item: 0.37693244218826294
test loss item: 0.13948598504066467
test loss item: 0.11864413321018219
test loss item: 0.18864358961582184
test loss item: 0.28757810592651367
test loss item: 0.2520495355129242
test loss item: 0.18057270348072052
test loss item: 0.14638762176036835
test loss item: 0.17855148017406464
test loss item: 0.20451349020004272
test loss item: 0.322742223739624
test loss item: 0.24768340587615967
test loss item: 0.2818211317062378
test loss item: 0.519569993019104
test loss item: 0.2082609087228775
test loss item: 0.1820547878742218
test loss item: 0.15688611567020416
test loss item: 0.24433763325214386
test loss item: 0.20277173817157745
test loss item: 0.3024589419364929
test loss item: 0.1549171656370163
test loss item: 0.14670492708683014
test loss item: 0.348246306180954
test loss item: 0.3248414099216461
test loss item: 0.1501992791891098
test loss item: 0.202958345413208
test loss item: 0.15449988842010498
test loss item: 0.3527458906173706
test loss item: 0.176020085811615
test loss item: 0.30298298597335815
test loss item: 0.2940640449523926
test loss item: 0.23462460935115814
test loss item: 0.13591225445270538
test loss item: 0.5034810900688171
test loss item: 0.16166161000728607
test loss item: 0.371254026889801
test loss item: 0.4629242718219757
test loss item: 0.15182191133499146
test loss item: 0.08983635157346725
test loss item: 0.14914385974407196
Epoch [6/10], Training Loss: 0.3398, Testing Loss: 0.2401
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/10
train loss item: 0.41454997658729553
train loss item: 0.26804354786872864
train loss item: 0.1916729360818863
train loss item: 0.27374932169914246
train loss item: 0.17591224610805511
train loss item: 0.1756320297718048
train loss item: 0.2303774505853653
train loss item: 0.36749327182769775
train loss item: 0.1398715227842331
train loss item: 0.22419755160808563
train loss item: 0.18504679203033447
train loss item: 0.45341071486473083
train loss item: 0.2481386363506317
train loss item: 0.14237727224826813
train loss item: 0.30714333057403564
train loss item: 0.6249163150787354
train loss item: 0.19745318591594696
train loss item: 0.9597494602203369
train loss item: 0.3917326033115387
train loss item: 0.2718021273612976
train loss item: 0.20099900662899017
train loss item: 0.17240512371063232
train loss item: 0.2829882502555847
train loss item: 0.1633988469839096
train loss item: 0.14148171246051788
train loss item: 0.4645848572254181
train loss item: 0.11329657584428787
train loss item: 0.8131594061851501
train loss item: 0.18404170870780945
train loss item: 0.10973693430423737
train loss item: 0.8055751323699951
train loss item: 0.19485902786254883
train loss item: 0.20967580378055573
train loss item: 0.21634873747825623
train loss item: 0.21603897213935852
train loss item: 0.169912651181221
train loss item: 0.18605192005634308
train loss item: 0.12169608473777771
train loss item: 0.5088026523590088
train loss item: 0.18436655402183533
train loss item: 0.11889767646789551
train loss item: 0.2062525749206543
train loss item: 0.34538379311561584
train loss item: 1.6342169046401978
train loss item: 0.21319052577018738
test loss item: 0.13626126945018768
test loss item: 0.22541064023971558
test loss item: 0.15676189959049225
test loss item: 0.43823498487472534
test loss item: 0.18042749166488647
test loss item: 0.338851660490036
test loss item: 0.1396511197090149
test loss item: 0.12104396522045135
test loss item: 0.17659509181976318
test loss item: 0.27170777320861816
test loss item: 0.24022959172725677
test loss item: 0.18207883834838867
test loss item: 0.13782164454460144
test loss item: 0.17194350063800812
test loss item: 0.19489185512065887
test loss item: 0.29474011063575745
test loss item: 0.22981835901737213
test loss item: 0.2642546594142914
test loss item: 0.47157400846481323
test loss item: 0.19928225874900818
test loss item: 0.18244311213493347
test loss item: 0.15014441311359406
test loss item: 0.2294088751077652
test loss item: 0.20566432178020477
test loss item: 0.2749324142932892
test loss item: 0.150980144739151
test loss item: 0.14523237943649292
test loss item: 0.3148833215236664
test loss item: 0.30023783445358276
test loss item: 0.14690694212913513
test loss item: 0.18690435588359833
test loss item: 0.15010209381580353
test loss item: 0.3357245624065399
test loss item: 0.1681685745716095
test loss item: 0.2854636013507843
test loss item: 0.2780090570449829
test loss item: 0.22907018661499023
test loss item: 0.14284847676753998
test loss item: 0.4634464383125305
test loss item: 0.1644568145275116
test loss item: 0.33590593934059143
test loss item: 0.4184356927871704
test loss item: 0.14570340514183044
test loss item: 0.08862804621458054
test loss item: 0.15084011852741241
Epoch [7/10], Training Loss: 0.3160, Testing Loss: 0.2270
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/10
train loss item: 0.36784061789512634
train loss item: 0.24950067698955536
train loss item: 0.18349333107471466
train loss item: 0.2408403605222702
train loss item: 0.1685318499803543
train loss item: 0.16613341867923737
train loss item: 0.21648409962654114
train loss item: 0.337696373462677
train loss item: 0.1253076046705246
train loss item: 0.20154008269309998
train loss item: 0.16166839003562927
train loss item: 0.4234488904476166
train loss item: 0.22996783256530762
train loss item: 0.13502463698387146
train loss item: 0.29763707518577576
train loss item: 0.5143784284591675
train loss item: 0.1808212250471115
train loss item: 0.8667436838150024
train loss item: 0.38528600335121155
train loss item: 0.24839942157268524
train loss item: 0.19692890346050262
train loss item: 0.16079145669937134
train loss item: 0.25983643531799316
train loss item: 0.15004892647266388
train loss item: 0.1256919950246811
train loss item: 0.4373195767402649
train loss item: 0.1183590218424797
train loss item: 0.7142419219017029
train loss item: 0.16697648167610168
train loss item: 0.10748367011547089
train loss item: 0.7046895027160645
train loss item: 0.17807410657405853
train loss item: 0.18322856724262238
train loss item: 0.20024827122688293
train loss item: 0.19781407713890076
train loss item: 0.1543402522802353
train loss item: 0.17256595194339752
train loss item: 0.10739023983478546
train loss item: 0.4688865542411804
train loss item: 0.16113485395908356
train loss item: 0.11181340366601944
train loss item: 0.19108273088932037
train loss item: 0.3211846351623535
train loss item: 1.501360297203064
train loss item: 0.2077721506357193
test loss item: 0.1177375316619873
test loss item: 0.21245895326137543
test loss item: 0.13517913222312927
test loss item: 0.3906194865703583
test loss item: 0.16884319484233856
test loss item: 0.3053142726421356
test loss item: 0.13909098505973816
test loss item: 0.10500095784664154
test loss item: 0.16523024439811707
test loss item: 0.24618013203144073
test loss item: 0.2233904004096985
test loss item: 0.17857451736927032
test loss item: 0.13167832791805267
test loss item: 0.15475240349769592
test loss item: 0.1777571588754654
test loss item: 0.2635396718978882
test loss item: 0.21417200565338135
test loss item: 0.23878416419029236
test loss item: 0.42573976516723633
test loss item: 0.18484432995319366
test loss item: 0.17094393074512482
test loss item: 0.1413283497095108
test loss item: 0.2129966765642166
test loss item: 0.19221976399421692
test loss item: 0.2563619613647461
test loss item: 0.14486943185329437
test loss item: 0.1353897601366043
test loss item: 0.27811160683631897
test loss item: 0.2652778923511505
test loss item: 0.1432388871908188
test loss item: 0.17704151570796967
test loss item: 0.14219816029071808
test loss item: 0.3038955330848694
test loss item: 0.15733391046524048
test loss item: 0.25734812021255493
test loss item: 0.24675698578357697
test loss item: 0.22132423520088196
test loss item: 0.13157080113887787
test loss item: 0.44050583243370056
test loss item: 0.1442861407995224
test loss item: 0.29807960987091064
test loss item: 0.3811245560646057
test loss item: 0.1400591880083084
test loss item: 0.07555555552244186
test loss item: 0.166922926902771
Epoch [8/10], Training Loss: 0.2889, Testing Loss: 0.2090
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/10
train loss item: 0.3302418291568756
train loss item: 0.22403936088085175
train loss item: 0.17211875319480896
train loss item: 0.21256420016288757
train loss item: 0.14980654418468475
train loss item: 0.15224815905094147
train loss item: 0.2266535460948944
train loss item: 0.3215705454349518
train loss item: 0.11121034622192383
train loss item: 0.18310467898845673
train loss item: 0.14648160338401794
train loss item: 0.40348565578460693
train loss item: 0.20336025953292847
train loss item: 0.12599597871303558
train loss item: 0.2718138098716736
train loss item: 0.4219495356082916
train loss item: 0.1730349063873291
train loss item: 0.7368584275245667
train loss item: 0.3975406587123871
train loss item: 0.23392324149608612
train loss item: 0.1839410662651062
train loss item: 0.15467926859855652
train loss item: 0.24628481268882751
train loss item: 0.14221394062042236
train loss item: 0.12027032673358917
train loss item: 0.40926358103752136
train loss item: 0.11785285919904709
train loss item: 0.5831753015518188
train loss item: 0.15283595025539398
train loss item: 0.09802483767271042
train loss item: 0.5840398669242859
train loss item: 0.1682746559381485
train loss item: 0.1680750846862793
train loss item: 0.20082467794418335
train loss item: 0.1791709065437317
train loss item: 0.14952269196510315
train loss item: 0.16032204031944275
train loss item: 0.09691616147756577
train loss item: 0.42502012848854065
train loss item: 0.14469069242477417
train loss item: 0.12223520874977112
train loss item: 0.1792389154434204
train loss item: 0.2772405743598938
train loss item: 1.3736014366149902
train loss item: 0.2033366858959198
test loss item: 0.11311081051826477
test loss item: 0.18484236299991608
test loss item: 0.12169858068227768
test loss item: 0.3644486665725708
test loss item: 0.14850309491157532
test loss item: 0.264989972114563
test loss item: 0.12849077582359314
test loss item: 0.09587249904870987
test loss item: 0.14719507098197937
test loss item: 0.22648239135742188
test loss item: 0.201063871383667
test loss item: 0.18377240002155304
test loss item: 0.11817418038845062
test loss item: 0.1362069696187973
test loss item: 0.15790009498596191
test loss item: 0.22952765226364136
test loss item: 0.1827385127544403
test loss item: 0.21693433821201324
test loss item: 0.37003934383392334
test loss item: 0.16175462305545807
test loss item: 0.17315290868282318
test loss item: 0.12692485749721527
test loss item: 0.1909516453742981
test loss item: 0.2015809416770935
test loss item: 0.22216390073299408
test loss item: 0.12948067486286163
test loss item: 0.12217728793621063
test loss item: 0.22750894725322723
test loss item: 0.2427314966917038
test loss item: 0.13007718324661255
test loss item: 0.15684086084365845
test loss item: 0.13163825869560242
test loss item: 0.2710028886795044
test loss item: 0.14216072857379913
test loss item: 0.2362583875656128
test loss item: 0.22690033912658691
test loss item: 0.20303773880004883
test loss item: 0.13828402757644653
test loss item: 0.3551681935787201
test loss item: 0.1375318467617035
test loss item: 0.27216798067092896
test loss item: 0.3282991051673889
test loss item: 0.13064239919185638
test loss item: 0.0715370699763298
test loss item: 0.14215025305747986
Epoch [9/10], Training Loss: 0.2631, Testing Loss: 0.1881
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/10
train loss item: 0.29187530279159546
train loss item: 0.2128784954547882
train loss item: 0.16123956441879272
train loss item: 0.19921891391277313
train loss item: 0.1401684433221817
train loss item: 0.14485691487789154
train loss item: 0.22190387547016144
train loss item: 0.29056307673454285
train loss item: 0.10331331938505173
train loss item: 0.1700706034898758
train loss item: 0.13084116578102112
train loss item: 0.3605635166168213
train loss item: 0.1915607452392578
train loss item: 0.1213129460811615
train loss item: 0.2429976910352707
train loss item: 0.3962511718273163
train loss item: 0.16313625872135162
train loss item: 0.6621583700180054
train loss item: 0.3682883679866791
train loss item: 0.20311768352985382
train loss item: 0.16183900833129883
train loss item: 0.16023753583431244
train loss item: 0.22252614796161652
train loss item: 0.13650193810462952
train loss item: 0.11743287742137909
train loss item: 0.36222130060195923
train loss item: 0.10197269916534424
train loss item: 0.5320253372192383
train loss item: 0.15651357173919678
train loss item: 0.09390117973089218
train loss item: 0.509249210357666
train loss item: 0.16178938746452332
train loss item: 0.15966235101222992
train loss item: 0.20981435477733612
train loss item: 0.17002639174461365
train loss item: 0.13701122999191284
train loss item: 0.14898106455802917
train loss item: 0.09256220608949661
train loss item: 0.41766098141670227
train loss item: 0.13805781304836273
train loss item: 0.11330712586641312
train loss item: 0.18175268173217773
train loss item: 0.22302955389022827
train loss item: 1.3010591268539429
train loss item: 0.21258075535297394
test loss item: 0.1093963086605072
test loss item: 0.17352086305618286
test loss item: 0.12075795233249664
test loss item: 0.3295615613460541
test loss item: 0.13816601037979126
test loss item: 0.24634750187397003
test loss item: 0.12015548348426819
test loss item: 0.10266722738742828
test loss item: 0.1322946399450302
test loss item: 0.19731055200099945
test loss item: 0.18664567172527313
test loss item: 0.15989863872528076
test loss item: 0.11059729754924774
test loss item: 0.1278533935546875
test loss item: 0.14528538286685944
test loss item: 0.20872630178928375
test loss item: 0.1673319786787033
test loss item: 0.20088325440883636
test loss item: 0.33287179470062256
test loss item: 0.14958986639976501
test loss item: 0.15235669910907745
test loss item: 0.11917900294065475
test loss item: 0.17352333664894104
test loss item: 0.16684050858020782
test loss item: 0.20281395316123962
test loss item: 0.12076814472675323
test loss item: 0.11703765392303467
test loss item: 0.20908759534358978
test loss item: 0.2333499789237976
test loss item: 0.1230529248714447
test loss item: 0.1407739818096161
test loss item: 0.12020409107208252
test loss item: 0.26270776987075806
test loss item: 0.13510505855083466
test loss item: 0.2119898647069931
test loss item: 0.20782150328159332
test loss item: 0.17220282554626465
test loss item: 0.11520545929670334
test loss item: 0.3323996961116791
test loss item: 0.12296420335769653
test loss item: 0.2553800344467163
test loss item: 0.3013341426849365
test loss item: 0.12131894379854202
test loss item: 0.08406568318605423
test loss item: 0.13791051506996155
Epoch [10/10], Training Loss: 0.2444, Testing Loss: 0.1733
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
loss item: 0.1351475566625595
loss item: 0.3686352074146271
loss item: 0.19349494576454163
loss item: 0.22445499897003174
loss item: 0.1269577443599701
loss item: 0.2700647711753845
loss item: 0.19999898970127106
loss item: 0.17698262631893158
loss item: 0.17599616944789886
loss item: 0.2544126510620117
loss item: 0.1526876837015152
loss item: 0.1266118437051773
loss item: 0.21061758697032928
loss item: 0.20291821658611298
loss item: 0.15740419924259186
loss item: 0.36931565403938293
loss item: 0.174296036362648
loss item: 0.12151739001274109
loss item: 0.13963915407657623
loss item: 0.20941637456417084
loss item: 0.2701199948787689
loss item: 0.09874119609594345
Val Loss: 0.1982
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.0001 4 360 done at Tue Nov 12 09:38:42 CET 2024
UNet2 with 1 10 0.0005 4 360 start at Tue Nov 12 09:38:42 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.6336421966552734
train loss item: 0.9993661046028137
train loss item: 0.595187783241272
train loss item: 0.9349422454833984
train loss item: 0.420171320438385
train loss item: 0.43110084533691406
train loss item: 0.4865673780441284
train loss item: 0.7318769693374634
train loss item: 0.33974796533584595
train loss item: 0.3741704523563385
train loss item: 0.3689255118370056
train loss item: 1.1589950323104858
train loss item: 0.5373875498771667
train loss item: 0.34425392746925354
train loss item: 0.6828771233558655
train loss item: 1.6828837394714355
train loss item: 0.49172812700271606
train loss item: 1.9094692468643188
train loss item: 0.6189807057380676
train loss item: 0.6172576546669006
train loss item: 0.5751233696937561
train loss item: 0.3494304418563843
train loss item: 0.46517854928970337
train loss item: 0.2958175539970398
train loss item: 0.24401570856571198
train loss item: 0.8013125061988831
train loss item: 0.2470400482416153
train loss item: 1.7671763896942139
train loss item: 0.2696566581726074
train loss item: 0.2147693783044815
train loss item: 1.5447440147399902
train loss item: 0.39145776629447937
train loss item: 0.42256706953048706
train loss item: 0.47760188579559326
train loss item: 0.3703896701335907
train loss item: 0.31359994411468506
train loss item: 0.32691898941993713
train loss item: 0.15602192282676697
train loss item: 1.1286150217056274
train loss item: 0.3056598901748657
train loss item: 0.26400911808013916
train loss item: 0.47334399819374084
train loss item: 0.44159236550331116
train loss item: 2.875567674636841
train loss item: 0.44896361231803894
test loss item: 0.18260884284973145
test loss item: 0.37658047676086426
test loss item: 0.21447274088859558
test loss item: 0.8869276642799377
test loss item: 0.2703791856765747
test loss item: 0.5653818249702454
test loss item: 0.17298828065395355
test loss item: 0.16976198554039001
test loss item: 0.3151813745498657
test loss item: 0.4063761830329895
test loss item: 0.4782122075557709
test loss item: 0.24083423614501953
test loss item: 0.21599040925502777
test loss item: 0.2523772418498993
test loss item: 0.30982324481010437
test loss item: 0.5589002966880798
test loss item: 0.45664331316947937
test loss item: 0.3833664059638977
test loss item: 0.8046218156814575
test loss item: 0.36945685744285583
test loss item: 0.26711544394493103
test loss item: 0.32015877962112427
test loss item: 0.41130152344703674
test loss item: 0.25871169567108154
test loss item: 0.4566580057144165
test loss item: 0.21447890996932983
test loss item: 0.29934096336364746
test loss item: 0.5387488603591919
test loss item: 0.46469613909721375
test loss item: 0.21642421185970306
test loss item: 0.31394293904304504
test loss item: 0.22205500304698944
test loss item: 0.5734866261482239
test loss item: 0.26601606607437134
test loss item: 0.4046967923641205
test loss item: 0.5527810454368591
test loss item: 0.30840063095092773
test loss item: 0.1677815020084381
test loss item: 0.8059555888175964
test loss item: 0.21964682638645172
test loss item: 0.5953294634819031
test loss item: 0.7180091738700867
test loss item: 0.21305808424949646
test loss item: 0.151900514960289
test loss item: 0.20145545899868011
Epoch [1/10], Training Loss: 0.6784, Testing Loss: 0.3732
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/10
train loss item: 0.6763551831245422
train loss item: 0.5072659254074097
train loss item: 0.31016770005226135
train loss item: 0.4932032525539398
train loss item: 0.28396549820899963
train loss item: 0.31024402379989624
train loss item: 0.3571765422821045
train loss item: 0.5308289527893066
train loss item: 0.23511645197868347
train loss item: 0.3242553174495697
train loss item: 0.1966618150472641
train loss item: 0.7715167999267578
train loss item: 0.34185728430747986
train loss item: 0.2585991621017456
train loss item: 0.48500949144363403
train loss item: 1.257409930229187
train loss item: 0.4677455425262451
train loss item: 1.4938323497772217
train loss item: 0.6211795806884766
train loss item: 0.697333037853241
train loss item: 0.39729008078575134
train loss item: 0.388002872467041
train loss item: 0.36994507908821106
train loss item: 0.3004932999610901
train loss item: 0.22935816645622253
train loss item: 0.7564562559127808
train loss item: 0.20619870722293854
train loss item: 1.5096603631973267
train loss item: 0.2950872778892517
train loss item: 0.16978172957897186
train loss item: 1.348725438117981
train loss item: 0.2653981149196625
train loss item: 0.36940357089042664
train loss item: 0.3703857362270355
train loss item: 0.3254009783267975
train loss item: 0.2764299511909485
train loss item: 0.2899024486541748
train loss item: 0.1495000720024109
train loss item: 0.9525243639945984
train loss item: 0.20779015123844147
train loss item: 0.16544437408447266
train loss item: 0.3925164043903351
train loss item: 0.3590438663959503
train loss item: 2.3288955688476562
train loss item: 0.3717213273048401
test loss item: 0.18622981011867523
test loss item: 0.3428483307361603
test loss item: 0.2298201024532318
test loss item: 0.6105896830558777
test loss item: 0.2833128273487091
test loss item: 0.4750601649284363
test loss item: 0.22305072844028473
test loss item: 0.17117653787136078
test loss item: 0.2590787410736084
test loss item: 0.3393717110157013
test loss item: 0.35265687108039856
test loss item: 0.206001877784729
test loss item: 0.20493285357952118
test loss item: 0.26435914635658264
test loss item: 0.3022944927215576
test loss item: 0.42907315492630005
test loss item: 0.38119131326675415
test loss item: 0.36955583095550537
test loss item: 0.6738674640655518
test loss item: 0.3190270960330963
test loss item: 0.19770286977291107
test loss item: 0.23967595398426056
test loss item: 0.3485738933086395
test loss item: 0.22463522851467133
test loss item: 0.41886553168296814
test loss item: 0.25472524762153625
test loss item: 0.22606755793094635
test loss item: 0.5007068514823914
test loss item: 0.3823719322681427
test loss item: 0.24185961484909058
test loss item: 0.2930935025215149
test loss item: 0.2187051773071289
test loss item: 0.5284643173217773
test loss item: 0.23644667863845825
test loss item: 0.36500951647758484
test loss item: 0.38949742913246155
test loss item: 0.2604151964187622
test loss item: 0.1401842087507248
test loss item: 0.7367886304855347
test loss item: 0.21407701075077057
test loss item: 0.48207220435142517
test loss item: 0.6250508427619934
test loss item: 0.19647076725959778
test loss item: 0.12782102823257446
test loss item: 0.18004202842712402
Epoch [2/10], Training Loss: 0.5203, Testing Loss: 0.3256
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/10
train loss item: 0.5393073558807373
train loss item: 0.37026771903038025
train loss item: 0.24788515269756317
train loss item: 0.41281819343566895
train loss item: 0.2681031823158264
train loss item: 0.24137426912784576
train loss item: 0.3125859797000885
train loss item: 0.387481153011322
train loss item: 0.19752901792526245
train loss item: 0.323188841342926
train loss item: 0.22378413379192352
train loss item: 0.570470929145813
train loss item: 0.3141983151435852
train loss item: 0.20689930021762848
train loss item: 0.40412047505378723
train loss item: 0.9049418568611145
train loss item: 0.27877381443977356
train loss item: 1.2179837226867676
train loss item: 0.6031314134597778
train loss item: 0.4819824993610382
train loss item: 0.23484845459461212
train loss item: 0.2489413470029831
train loss item: 0.3137591481208801
train loss item: 0.22292646765708923
train loss item: 0.16673439741134644
train loss item: 0.5971180200576782
train loss item: 0.1543111354112625
train loss item: 1.2026201486587524
train loss item: 0.2473420649766922
train loss item: 0.1368510127067566
train loss item: 1.0238720178604126
train loss item: 0.2703191041946411
train loss item: 0.31447339057922363
train loss item: 0.40621447563171387
train loss item: 0.2848120331764221
train loss item: 0.2473238706588745
train loss item: 0.22256380319595337
train loss item: 0.11141793429851532
train loss item: 0.8421390056610107
train loss item: 0.17228589951992035
train loss item: 0.13960134983062744
train loss item: 0.3064326047897339
train loss item: 0.3814127445220947
train loss item: 2.0761661529541016
train loss item: 0.29822099208831787
test loss item: 0.146224707365036
test loss item: 0.3002369999885559
test loss item: 0.22586296498775482
test loss item: 0.5330710411071777
test loss item: 0.26874497532844543
test loss item: 0.38916587829589844
test loss item: 0.18889181315898895
test loss item: 0.14602574706077576
test loss item: 0.23958048224449158
test loss item: 0.31441178917884827
test loss item: 0.3237226903438568
test loss item: 0.20532336831092834
test loss item: 0.17143487930297852
test loss item: 0.2344226837158203
test loss item: 0.2810314893722534
test loss item: 0.35330167412757874
test loss item: 0.33411887288093567
test loss item: 0.3375808298587799
test loss item: 0.5875075459480286
test loss item: 0.2796597182750702
test loss item: 0.16130013763904572
test loss item: 0.20683622360229492
test loss item: 0.325713187456131
test loss item: 0.2040078490972519
test loss item: 0.39006444811820984
test loss item: 0.2501714825630188
test loss item: 0.17708425223827362
test loss item: 0.42995700240135193
test loss item: 0.3500179052352905
test loss item: 0.2126748412847519
test loss item: 0.2761983275413513
test loss item: 0.17448557913303375
test loss item: 0.41602736711502075
test loss item: 0.20407144725322723
test loss item: 0.3154667317867279
test loss item: 0.33925923705101013
test loss item: 0.2375837117433548
test loss item: 0.1135871484875679
test loss item: 0.5986781120300293
test loss item: 0.19461461901664734
test loss item: 0.4081859886646271
test loss item: 0.5371807217597961
test loss item: 0.18453830480575562
test loss item: 0.08251414448022842
test loss item: 0.14483410120010376
Epoch [3/10], Training Loss: 0.4251, Testing Loss: 0.2843
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/10
train loss item: 0.4897162914276123
train loss item: 0.31413033604621887
train loss item: 0.20648349821567535
train loss item: 0.3144131302833557
train loss item: 0.1956438422203064
train loss item: 0.19273518025875092
train loss item: 0.2651529014110565
train loss item: 0.3908151388168335
train loss item: 0.14927053451538086
train loss item: 0.2569388151168823
train loss item: 0.16874898970127106
train loss item: 0.47656917572021484
train loss item: 0.24369961023330688
train loss item: 0.17415961623191833
train loss item: 0.31812718510627747
train loss item: 0.7173968553543091
train loss item: 0.25664207339286804
train loss item: 1.0270237922668457
train loss item: 0.6272668838500977
train loss item: 0.450464129447937
train loss item: 0.19669915735721588
train loss item: 0.18399785459041595
train loss item: 0.27988311648368835
train loss item: 0.18423420190811157
train loss item: 0.15186072885990143
train loss item: 0.5366824865341187
train loss item: 0.13888053596019745
train loss item: 1.0072901248931885
train loss item: 0.21672020852565765
train loss item: 0.1150289848446846
train loss item: 0.8523637056350708
train loss item: 0.26492443680763245
train loss item: 0.2583729326725006
train loss item: 0.27793997526168823
train loss item: 0.278328537940979
train loss item: 0.1758606880903244
train loss item: 0.17133638262748718
train loss item: 0.10860730707645416
train loss item: 0.7406320571899414
train loss item: 0.13871027529239655
train loss item: 0.11138875037431717
train loss item: 0.21881966292858124
train loss item: 0.41013458371162415
train loss item: 1.7850593328475952
train loss item: 0.3595987856388092
test loss item: 0.17625464498996735
test loss item: 0.2644307613372803
test loss item: 0.287316232919693
test loss item: 0.43765518069267273
test loss item: 0.23692159354686737
test loss item: 0.35572633147239685
test loss item: 0.16550743579864502
test loss item: 0.17594894766807556
test loss item: 0.2056770771741867
test loss item: 0.26752668619155884
test loss item: 0.2609396278858185
test loss item: 0.20183952152729034
test loss item: 0.15445998311042786
test loss item: 0.25819599628448486
test loss item: 0.26541656255722046
test loss item: 0.30201852321624756
test loss item: 0.2786847651004791
test loss item: 0.30218836665153503
test loss item: 0.488050252199173
test loss item: 0.2763323485851288
test loss item: 0.1487741768360138
test loss item: 0.1687401980161667
test loss item: 0.24797189235687256
test loss item: 0.16547518968582153
test loss item: 0.32480767369270325
test loss item: 0.2160690724849701
test loss item: 0.17131231725215912
test loss item: 0.3734331429004669
test loss item: 0.3096332550048828
test loss item: 0.19569915533065796
test loss item: 0.2329225093126297
test loss item: 0.15789364278316498
test loss item: 0.36115169525146484
test loss item: 0.18553893268108368
test loss item: 0.2545834481716156
test loss item: 0.26789912581443787
test loss item: 0.20070189237594604
test loss item: 0.11962175369262695
test loss item: 0.4453712999820709
test loss item: 0.2536574900150299
test loss item: 0.34859004616737366
test loss item: 0.4426787495613098
test loss item: 0.1755906045436859
test loss item: 0.09417106211185455
test loss item: 0.173434317111969
Epoch [4/10], Training Loss: 0.3644, Testing Loss: 0.2533
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/10
train loss item: 0.37009596824645996
train loss item: 0.2531362473964691
train loss item: 0.1522209197282791
train loss item: 0.2980888783931732
train loss item: 0.19421829283237457
train loss item: 0.19021964073181152
train loss item: 0.20453685522079468
train loss item: 0.43769630789756775
train loss item: 0.14116603136062622
train loss item: 0.2747739851474762
train loss item: 0.1614067554473877
train loss item: 0.4163457751274109
train loss item: 0.18245656788349152
train loss item: 0.17019231617450714
train loss item: 0.30869799852371216
train loss item: 0.5902789235115051
train loss item: 0.22806796431541443
train loss item: 0.8547470569610596
train loss item: 0.4695347845554352
train loss item: 0.27664703130722046
train loss item: 0.1420029252767563
train loss item: 0.2111431062221527
train loss item: 0.22597302496433258
train loss item: 0.19986818730831146
train loss item: 0.1279294490814209
train loss item: 0.5150712728500366
train loss item: 0.11983919143676758
train loss item: 0.7616610527038574
train loss item: 0.16498444974422455
train loss item: 0.09749317914247513
train loss item: 0.6706580519676208
train loss item: 0.2301790714263916
train loss item: 0.2482648491859436
train loss item: 0.3263269066810608
train loss item: 0.2514510452747345
train loss item: 0.14863720536231995
train loss item: 0.15236027538776398
train loss item: 0.09234657883644104
train loss item: 0.8302199244499207
train loss item: 0.1565205454826355
train loss item: 0.10602571070194244
train loss item: 0.2870694398880005
train loss item: 0.33907565474510193
train loss item: 1.642812728881836
train loss item: 0.32124772667884827
test loss item: 0.14779426157474518
test loss item: 0.22123053669929504
test loss item: 0.2003275752067566
test loss item: 0.4665570855140686
test loss item: 0.190566286444664
test loss item: 0.3184684216976166
test loss item: 0.12331170588731766
test loss item: 0.13545353710651398
test loss item: 0.16447392106056213
test loss item: 0.24017180502414703
test loss item: 0.2010878622531891
test loss item: 0.15544576942920685
test loss item: 0.13019196689128876
test loss item: 0.19522252678871155
test loss item: 0.19547909498214722
test loss item: 0.2928146719932556
test loss item: 0.20355944335460663
test loss item: 0.24650365114212036
test loss item: 0.4299388825893402
test loss item: 0.20777378976345062
test loss item: 0.1553778499364853
test loss item: 0.14263759553432465
test loss item: 0.17981594800949097
test loss item: 0.1380906105041504
test loss item: 0.2680199444293976
test loss item: 0.1568726748228073
test loss item: 0.14690271019935608
test loss item: 0.2941405177116394
test loss item: 0.2599181830883026
test loss item: 0.14649231731891632
test loss item: 0.18106940388679504
test loss item: 0.13466012477874756
test loss item: 0.3194475769996643
test loss item: 0.15155170857906342
test loss item: 0.21468546986579895
test loss item: 0.2817840874195099
test loss item: 0.1729176789522171
test loss item: 0.11792728304862976
test loss item: 0.37450480461120605
test loss item: 0.18684622645378113
test loss item: 0.3380759060382843
test loss item: 0.39764976501464844
test loss item: 0.14572279155254364
test loss item: 0.10850152373313904
test loss item: 0.18361926078796387
Epoch [5/10], Training Loss: 0.3232, Testing Loss: 0.2147
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/10
train loss item: 0.3704867362976074
train loss item: 0.28612861037254333
train loss item: 0.18314382433891296
train loss item: 0.2349981963634491
train loss item: 0.19215382635593414
train loss item: 0.16335855424404144
train loss item: 0.2739008069038391
train loss item: 0.5320641398429871
train loss item: 0.16620898246765137
train loss item: 0.21116818487644196
train loss item: 0.15984420478343964
train loss item: 0.6287740468978882
train loss item: 0.17890961468219757
train loss item: 0.14989367127418518
train loss item: 0.2616206109523773
train loss item: 0.43685394525527954
train loss item: 0.33246326446533203
train loss item: 0.6694057583808899
train loss item: 0.6557824611663818
train loss item: 0.41367748379707336
train loss item: 0.3033978044986725
train loss item: 0.26000887155532837
train loss item: 0.22557979822158813
train loss item: 0.18964402377605438
train loss item: 0.1539917290210724
train loss item: 0.563402533531189
train loss item: 0.1766425222158432
train loss item: 0.8635500073432922
train loss item: 0.2371762990951538
train loss item: 0.14641742408275604
train loss item: 0.807615339756012
train loss item: 0.2647928297519684
train loss item: 0.3737647533416748
train loss item: 0.27593234181404114
train loss item: 0.23315444588661194
train loss item: 0.16843488812446594
train loss item: 0.20727890729904175
train loss item: 0.09448844939470291
train loss item: 0.5830731987953186
train loss item: 0.20598545670509338
train loss item: 0.11026939749717712
train loss item: 0.22345198690891266
train loss item: 0.2790948450565338
train loss item: 1.4111433029174805
train loss item: 0.2504265308380127
test loss item: 0.14158995449543
test loss item: 0.24673286080360413
test loss item: 0.18141010403633118
test loss item: 0.5417452454566956
test loss item: 0.2125459760427475
test loss item: 0.36206915974617004
test loss item: 0.15803442895412445
test loss item: 0.14793188869953156
test loss item: 0.18241530656814575
test loss item: 0.28453540802001953
test loss item: 0.2322719544172287
test loss item: 0.15479758381843567
test loss item: 0.13954728841781616
test loss item: 0.18997319042682648
test loss item: 0.2184808999300003
test loss item: 0.31171488761901855
test loss item: 0.2107406109571457
test loss item: 0.2505902051925659
test loss item: 0.4913616478443146
test loss item: 0.20709750056266785
test loss item: 0.14556875824928284
test loss item: 0.14553408324718475
test loss item: 0.24313688278198242
test loss item: 0.1449020951986313
test loss item: 0.30432918667793274
test loss item: 0.16619333624839783
test loss item: 0.1546631157398224
test loss item: 0.32621628046035767
test loss item: 0.2883223593235016
test loss item: 0.17558147013187408
test loss item: 0.2044137567281723
test loss item: 0.1619306057691574
test loss item: 0.3802317976951599
test loss item: 0.1983601301908493
test loss item: 0.22601144015789032
test loss item: 0.3693528473377228
test loss item: 0.24109488725662231
test loss item: 0.11179845780134201
test loss item: 0.4230360686779022
test loss item: 0.15579074621200562
test loss item: 0.3773745000362396
test loss item: 0.4341104030609131
test loss item: 0.15852157771587372
test loss item: 0.0983748733997345
test loss item: 0.11923921853303909
Epoch [6/10], Training Loss: 0.3358, Testing Loss: 0.2360
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/10
train loss item: 0.2629103660583496
train loss item: 0.19943471252918243
train loss item: 0.14744463562965393
train loss item: 0.19292187690734863
train loss item: 0.16797985136508942
train loss item: 0.16578581929206848
train loss item: 0.27998772263526917
train loss item: 0.27342721819877625
train loss item: 0.11192652583122253
train loss item: 0.16936306655406952
train loss item: 0.1379067301750183
train loss item: 0.33625441789627075
train loss item: 0.17126595973968506
train loss item: 0.12481985986232758
train loss item: 0.24340549111366272
train loss item: 0.40787988901138306
train loss item: 0.22290873527526855
train loss item: 0.5980804562568665
train loss item: 0.49156203866004944
train loss item: 0.19003070890903473
train loss item: 0.13895244896411896
train loss item: 0.1516721546649933
train loss item: 0.2506973445415497
train loss item: 0.16957662999629974
train loss item: 0.09974518418312073
train loss item: 0.351901650428772
train loss item: 0.10629034787416458
train loss item: 0.5380032658576965
train loss item: 0.14812630414962769
train loss item: 0.08572030067443848
train loss item: 0.4765778183937073
train loss item: 0.22669461369514465
train loss item: 0.15618982911109924
train loss item: 0.195711150765419
train loss item: 0.17145413160324097
train loss item: 0.11921054124832153
train loss item: 0.1359882354736328
train loss item: 0.07826507091522217
train loss item: 0.6462913751602173
train loss item: 0.1130099818110466
train loss item: 0.09457623213529587
train loss item: 0.18846562504768372
train loss item: 0.31950974464416504
train loss item: 1.1430742740631104
train loss item: 0.2951463758945465
test loss item: 0.13386604189872742
test loss item: 0.25746360421180725
test loss item: 0.19813765585422516
test loss item: 0.33553290367126465
test loss item: 0.1862456500530243
test loss item: 0.3608108460903168
test loss item: 0.1282568722963333
test loss item: 0.13319776952266693
test loss item: 0.16646666824817657
test loss item: 0.20235849916934967
test loss item: 0.20200257003307343
test loss item: 0.17641529440879822
test loss item: 0.11876370012760162
test loss item: 0.18151158094406128
test loss item: 0.19618384540081024
test loss item: 0.2955976128578186
test loss item: 0.2265481799840927
test loss item: 0.23804786801338196
test loss item: 0.47061917185783386
test loss item: 0.20147112011909485
test loss item: 0.13817958533763885
test loss item: 0.12833282351493835
test loss item: 0.1984097957611084
test loss item: 0.1683875024318695
test loss item: 0.2719263732433319
test loss item: 0.15478570759296417
test loss item: 0.13764020800590515
test loss item: 0.35045844316482544
test loss item: 0.2449112832546234
test loss item: 0.14869581162929535
test loss item: 0.17273464798927307
test loss item: 0.12807150185108185
test loss item: 0.3687584400177002
test loss item: 0.15199874341487885
test loss item: 0.21165800094604492
test loss item: 0.20402313768863678
test loss item: 0.18909026682376862
test loss item: 0.12388072162866592
test loss item: 0.5676348805427551
test loss item: 0.17909620702266693
test loss item: 0.33363914489746094
test loss item: 0.44237571954727173
test loss item: 0.14734408259391785
test loss item: 0.07340683043003082
test loss item: 0.13038522005081177
Epoch [7/10], Training Loss: 0.2510, Testing Loss: 0.2172
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/10
train loss item: 0.261271208524704
train loss item: 0.19946733117103577
train loss item: 0.13846908509731293
train loss item: 0.23080991208553314
train loss item: 0.14915619790554047
train loss item: 0.1354983001947403
train loss item: 0.17040547728538513
train loss item: 0.41830599308013916
train loss item: 0.11529459059238434
train loss item: 0.22823210060596466
train loss item: 0.1444873809814453
train loss item: 0.4246535003185272
train loss item: 0.17093877494335175
train loss item: 0.11525049805641174
train loss item: 0.21981707215309143
train loss item: 0.37918001413345337
train loss item: 0.1784096658229828
train loss item: 0.46972939372062683
train loss item: 0.48255565762519836
train loss item: 0.30452319979667664
train loss item: 0.17718620598316193
train loss item: 0.22294877469539642
train loss item: 0.2254335582256317
train loss item: 0.18030160665512085
train loss item: 0.11810288578271866
train loss item: 0.46292972564697266
train loss item: 0.12823040783405304
train loss item: 0.6725529432296753
train loss item: 0.19556865096092224
train loss item: 0.09984441846609116
train loss item: 0.5914117693901062
train loss item: 0.17095665633678436
train loss item: 0.19879624247550964
train loss item: 0.24814732372760773
train loss item: 0.20532777905464172
train loss item: 0.17032459378242493
train loss item: 0.15104998648166656
train loss item: 0.0796000212430954
train loss item: 0.5874409079551697
train loss item: 0.13659706711769104
train loss item: 0.12615148723125458
train loss item: 0.2257031351327896
train loss item: 0.31328535079956055
train loss item: 1.0885984897613525
train loss item: 0.21511626243591309
test loss item: 0.099223293364048
test loss item: 0.19534100592136383
test loss item: 0.11527284234762192
test loss item: 0.3693181872367859
test loss item: 0.17608459293842316
test loss item: 0.2841672897338867
test loss item: 0.1574288159608841
test loss item: 0.0913684219121933
test loss item: 0.13171130418777466
test loss item: 0.2121117115020752
test loss item: 0.16687197983264923
test loss item: 0.12103884667158127
test loss item: 0.10755971819162369
test loss item: 0.13216347992420197
test loss item: 0.15815754234790802
test loss item: 0.2404954433441162
test loss item: 0.16534125804901123
test loss item: 0.2105712592601776
test loss item: 0.3670577108860016
test loss item: 0.148954838514328
test loss item: 0.13027502596378326
test loss item: 0.12000345438718796
test loss item: 0.1709456443786621
test loss item: 0.13999730348587036
test loss item: 0.24044042825698853
test loss item: 0.1517016887664795
test loss item: 0.10972090810537338
test loss item: 0.2573085427284241
test loss item: 0.20665784180164337
test loss item: 0.14804939925670624
test loss item: 0.15782050788402557
test loss item: 0.13269680738449097
test loss item: 0.26501983404159546
test loss item: 0.13778454065322876
test loss item: 0.19326500594615936
test loss item: 0.22619971632957458
test loss item: 0.16177313029766083
test loss item: 0.09897489100694656
test loss item: 0.30543944239616394
test loss item: 0.10999572277069092
test loss item: 0.27164092659950256
test loss item: 0.3355948328971863
test loss item: 0.12139030545949936
test loss item: 0.0515238419175148
test loss item: 0.14429138600826263
Epoch [8/10], Training Loss: 0.2651, Testing Loss: 0.1786
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/10
train loss item: 0.31130707263946533
train loss item: 0.19139131903648376
train loss item: 0.1378507763147354
train loss item: 0.16726019978523254
train loss item: 0.1710727959871292
train loss item: 0.14385272562503815
train loss item: 0.2261064350605011
train loss item: 0.3310890197753906
train loss item: 0.1353982537984848
train loss item: 0.16871792078018188
train loss item: 0.1534840166568756
train loss item: 0.4770488142967224
train loss item: 0.1700722873210907
train loss item: 0.12079021334648132
train loss item: 0.19702786207199097
train loss item: 0.38499152660369873
train loss item: 0.28098732233047485
train loss item: 0.41071441769599915
train loss item: 0.5539953708648682
train loss item: 0.2916272282600403
train loss item: 0.2139626443386078
train loss item: 0.11973587423563004
train loss item: 0.2160974144935608
train loss item: 0.14040014147758484
train loss item: 0.10926470905542374
train loss item: 0.3920300304889679
train loss item: 0.12671782076358795
train loss item: 0.6348101496696472
train loss item: 0.1870463639497757
train loss item: 0.09222724288702011
train loss item: 0.503287672996521
train loss item: 0.18054485321044922
train loss item: 0.14654888212680817
train loss item: 0.17320828139781952
train loss item: 0.1877397745847702
train loss item: 0.11144924908876419
train loss item: 0.1660364717245102
train loss item: 0.08838730305433273
train loss item: 0.5646113157272339
train loss item: 0.12188975512981415
train loss item: 0.09115153551101685
train loss item: 0.1946977823972702
train loss item: 0.3388516306877136
train loss item: 0.9566274881362915
train loss item: 0.24464763700962067
test loss item: 0.13326241075992584
test loss item: 0.31829920411109924
test loss item: 0.19143584370613098
test loss item: 0.37147244811058044
test loss item: 0.23801560699939728
test loss item: 0.46999096870422363
test loss item: 0.1352572739124298
test loss item: 0.13993728160858154
test loss item: 0.19075030088424683
test loss item: 0.2018410861492157
test loss item: 0.23167838156223297
test loss item: 0.16494831442832947
test loss item: 0.12706877291202545
test loss item: 0.18761396408081055
test loss item: 0.21666759252548218
test loss item: 0.3945191204547882
test loss item: 0.27623701095581055
test loss item: 0.3067295551300049
test loss item: 0.6068421006202698
test loss item: 0.2256857454776764
test loss item: 0.12315766513347626
test loss item: 0.15525434911251068
test loss item: 0.2234184592962265
test loss item: 0.15347017347812653
test loss item: 0.34987592697143555
test loss item: 0.18062762916088104
test loss item: 0.14522291719913483
test loss item: 0.46203944087028503
test loss item: 0.2829326093196869
test loss item: 0.15702447295188904
test loss item: 0.2253122627735138
test loss item: 0.12112388014793396
test loss item: 0.4420587122440338
test loss item: 0.1560841202735901
test loss item: 0.2548307180404663
test loss item: 0.21000824868679047
test loss item: 0.17675213515758514
test loss item: 0.11647606641054153
test loss item: 0.7637439966201782
test loss item: 0.16115356981754303
test loss item: 0.4219945967197418
test loss item: 0.5840011835098267
test loss item: 0.1443052440881729
test loss item: 0.09107307344675064
test loss item: 0.12010380625724792
Epoch [9/10], Training Loss: 0.2517, Testing Loss: 0.2522
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/10
train loss item: 0.315762460231781
train loss item: 0.21976874768733978
train loss item: 0.13234320282936096
train loss item: 0.22612839937210083
train loss item: 0.18335960805416107
train loss item: 0.17845892906188965
train loss item: 0.30827003717422485
train loss item: 0.34008726477622986
train loss item: 0.12574402987957
train loss item: 0.19080013036727905
train loss item: 0.13382311165332794
train loss item: 0.6459591388702393
train loss item: 0.20973524451255798
train loss item: 0.16793206334114075
train loss item: 0.20440512895584106
train loss item: 0.5592594146728516
train loss item: 0.19054029881954193
train loss item: 0.3956698179244995
train loss item: 0.6296862363815308
train loss item: 0.49519601464271545
train loss item: 0.37678614258766174
train loss item: 0.23240099847316742
train loss item: 0.43937647342681885
train loss item: 0.21625465154647827
train loss item: 0.1162428930401802
train loss item: 0.3237399458885193
train loss item: 0.1317378729581833
train loss item: 0.7038212418556213
train loss item: 0.2089279443025589
train loss item: 0.12856723368167877
train loss item: 0.8555094599723816
train loss item: 0.23031416535377502
train loss item: 0.30953437089920044
train loss item: 0.19941964745521545
train loss item: 0.1902802735567093
train loss item: 0.14783398807048798
train loss item: 0.20809222757816315
train loss item: 0.1068788468837738
train loss item: 0.4610536992549896
train loss item: 0.245075061917305
train loss item: 0.13859762251377106
train loss item: 0.21106185019016266
train loss item: 0.4795286953449249
train loss item: 0.8410758972167969
train loss item: 0.19869187474250793
test loss item: 0.2174210101366043
test loss item: 0.2725529074668884
test loss item: 0.2549459934234619
test loss item: 0.6419954299926758
test loss item: 0.264100581407547
test loss item: 0.3672637343406677
test loss item: 0.19655576348304749
test loss item: 0.22868479788303375
test loss item: 0.21134327352046967
test loss item: 0.2954942286014557
test loss item: 0.26472190022468567
test loss item: 0.20256811380386353
test loss item: 0.18483352661132812
test loss item: 0.2521101236343384
test loss item: 0.27470216155052185
test loss item: 0.40336617827415466
test loss item: 0.25973621010780334
test loss item: 0.3080412447452545
test loss item: 0.4901212453842163
test loss item: 0.26929935812950134
test loss item: 0.1713801473379135
test loss item: 0.17738287150859833
test loss item: 0.26212364435195923
test loss item: 0.17499086260795593
test loss item: 0.33807533979415894
test loss item: 0.23002572357654572
test loss item: 0.1818200796842575
test loss item: 0.36567437648773193
test loss item: 0.3200864791870117
test loss item: 0.2182134985923767
test loss item: 0.25765904784202576
test loss item: 0.18829287588596344
test loss item: 0.3600148558616638
test loss item: 0.22274662554264069
test loss item: 0.2871955335140228
test loss item: 0.4353511333465576
test loss item: 0.26374658942222595
test loss item: 0.17020471394062042
test loss item: 0.4131988286972046
test loss item: 0.20628224313259125
test loss item: 0.4082085192203522
test loss item: 0.4620025157928467
test loss item: 0.1860796958208084
test loss item: 0.17612016201019287
test loss item: 0.12444421648979187
Epoch [10/10], Training Loss: 0.3012, Testing Loss: 0.2769
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
loss item: 0.22583182156085968
loss item: 0.5185311436653137
loss item: 0.3200705349445343
loss item: 0.382322758436203
loss item: 0.2119891196489334
loss item: 0.5314956307411194
loss item: 0.34622177481651306
loss item: 0.22021818161010742
loss item: 0.34976041316986084
loss item: 0.38900259137153625
loss item: 0.19787190854549408
loss item: 0.18943440914154053
loss item: 0.34143930673599243
loss item: 0.31697073578834534
loss item: 0.24581079185009003
loss item: 0.5590280294418335
loss item: 0.2945275604724884
loss item: 0.18616747856140137
loss item: 0.23131148517131805
loss item: 0.3594389855861664
loss item: 0.3974417746067047
loss item: 0.22046726942062378
Val Loss: 0.3198
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.0005 4 360 done at Tue Nov 12 09:41:12 CET 2024
UNet2 with 1 10 0.001 4 360 start at Tue Nov 12 09:41:12 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 10, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.6336421966552734
train loss item: 1.0241367816925049
train loss item: 0.6707100868225098
train loss item: 1.052453875541687
train loss item: 0.4325838088989258
train loss item: 0.45004919171333313
train loss item: 0.48263299465179443
train loss item: 0.7821451425552368
train loss item: 0.29314959049224854
train loss item: 0.4130592346191406
train loss item: 0.32709062099456787
train loss item: 1.3081952333450317
train loss item: 0.5725193619728088
train loss item: 0.3602299988269806
train loss item: 0.812736451625824
train loss item: 1.7246522903442383
train loss item: 0.5814995169639587
train loss item: 1.933405876159668
train loss item: 0.5622901916503906
train loss item: 0.5134773850440979
train loss item: 0.3968896269798279
train loss item: 0.3826901912689209
train loss item: 0.572571337223053
train loss item: 0.48281049728393555
train loss item: 0.28770947456359863
train loss item: 0.9830145835876465
train loss item: 0.17388230562210083
train loss item: 1.8055871725082397
train loss item: 0.27561211585998535
train loss item: 0.2561942934989929
train loss item: 1.6007624864578247
train loss item: 0.3905438482761383
train loss item: 0.5161809325218201
train loss item: 0.5474753975868225
train loss item: 0.36473026871681213
train loss item: 0.3366314768791199
train loss item: 0.3277329206466675
train loss item: 0.1944217085838318
train loss item: 1.2737903594970703
train loss item: 0.39583051204681396
train loss item: 0.27123531699180603
train loss item: 0.6088969707489014
train loss item: 0.5795220732688904
train loss item: 3.0486552715301514
train loss item: 0.3784008324146271
test loss item: 0.1844942420721054
test loss item: 0.4128219783306122
test loss item: 0.24026422202587128
test loss item: 1.1967934370040894
test loss item: 0.3261007070541382
test loss item: 0.6026497483253479
test loss item: 0.2619163990020752
test loss item: 0.1796243041753769
test loss item: 0.35363373160362244
test loss item: 0.4982045292854309
test loss item: 0.5070556402206421
test loss item: 0.3189913034439087
test loss item: 0.24735687673091888
test loss item: 0.3047749102115631
test loss item: 0.3753136992454529
test loss item: 0.7178504467010498
test loss item: 0.4652574062347412
test loss item: 0.45430421829223633
test loss item: 0.9248380064964294
test loss item: 0.4073701798915863
test loss item: 0.3169515132904053
test loss item: 0.2971665561199188
test loss item: 0.4936496913433075
test loss item: 0.37831950187683105
test loss item: 0.5440714955329895
test loss item: 0.3012947738170624
test loss item: 0.27315953373908997
test loss item: 0.6145839095115662
test loss item: 0.5141955614089966
test loss item: 0.24796162545681
test loss item: 0.3549409806728363
test loss item: 0.2525677978992462
test loss item: 0.6577371954917908
test loss item: 0.3196444511413574
test loss item: 0.4574073553085327
test loss item: 0.7410372495651245
test loss item: 0.39276254177093506
test loss item: 0.2423807680606842
test loss item: 0.9230947494506836
test loss item: 0.24159370362758636
test loss item: 0.6859398484230042
test loss item: 0.8447154760360718
test loss item: 0.26676276326179504
test loss item: 0.13432051241397858
test loss item: 0.2641008198261261
Epoch [1/10], Training Loss: 0.7196, Testing Loss: 0.4387
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/10
train loss item: 0.7582639455795288
train loss item: 0.5910776257514954
train loss item: 0.4969259798526764
train loss item: 0.5332295894622803
train loss item: 0.36325517296791077
train loss item: 0.3494485914707184
train loss item: 0.39720264077186584
train loss item: 0.5960111021995544
train loss item: 0.2659851610660553
train loss item: 0.3563295900821686
train loss item: 0.2327636033296585
train loss item: 0.9502861499786377
train loss item: 0.43850061297416687
train loss item: 0.32240673899650574
train loss item: 0.5752795338630676
train loss item: 1.332024335861206
train loss item: 0.43880146741867065
train loss item: 1.5925759077072144
train loss item: 0.7923399806022644
train loss item: 0.8012042045593262
train loss item: 0.5420367121696472
train loss item: 0.4565233588218689
train loss item: 0.4026448428630829
train loss item: 0.3233100175857544
train loss item: 0.2211102694272995
train loss item: 0.8527234792709351
train loss item: 0.20186269283294678
train loss item: 1.5608386993408203
train loss item: 0.3502146303653717
train loss item: 0.18707996606826782
train loss item: 1.5060603618621826
train loss item: 0.3520696759223938
train loss item: 0.4665796756744385
train loss item: 0.4176289737224579
train loss item: 0.4178161919116974
train loss item: 0.326056569814682
train loss item: 0.3468465507030487
train loss item: 0.10509197413921356
train loss item: 1.0316097736358643
train loss item: 0.23766133189201355
train loss item: 0.17554643750190735
train loss item: 0.4467804431915283
train loss item: 0.4113500714302063
train loss item: 2.473480701446533
train loss item: 0.40614479780197144
test loss item: 0.16071002185344696
test loss item: 0.39313262701034546
test loss item: 0.23595385253429413
test loss item: 0.7451122403144836
test loss item: 0.3502325117588043
test loss item: 0.525374710559845
test loss item: 0.260591059923172
test loss item: 0.15700353682041168
test loss item: 0.3289121985435486
test loss item: 0.40450260043144226
test loss item: 0.4155293107032776
test loss item: 0.2364223301410675
test loss item: 0.22345107793807983
test loss item: 0.2731945216655731
test loss item: 0.35201528668403625
test loss item: 0.489972859621048
test loss item: 0.46126291155815125
test loss item: 0.4114452302455902
test loss item: 0.7907271385192871
test loss item: 0.3574060797691345
test loss item: 0.21143122017383575
test loss item: 0.29464203119277954
test loss item: 0.4250290095806122
test loss item: 0.2713918387889862
test loss item: 0.4899404048919678
test loss item: 0.30553799867630005
test loss item: 0.22880898416042328
test loss item: 0.5591841340065002
test loss item: 0.4274536669254303
test loss item: 0.27993232011795044
test loss item: 0.3678373098373413
test loss item: 0.2401629537343979
test loss item: 0.5270328521728516
test loss item: 0.26906782388687134
test loss item: 0.4335390627384186
test loss item: 0.4729878604412079
test loss item: 0.30102577805519104
test loss item: 0.14824528992176056
test loss item: 0.8045731782913208
test loss item: 0.21533069014549255
test loss item: 0.5074570178985596
test loss item: 0.690883457660675
test loss item: 0.22556616365909576
test loss item: 0.06974131613969803
test loss item: 0.13377968966960907
Epoch [2/10], Training Loss: 0.5867, Testing Loss: 0.3661
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/10
train loss item: 0.6569054126739502
train loss item: 0.45908448100090027
train loss item: 0.30858343839645386
train loss item: 0.503585696220398
train loss item: 0.20400957763195038
train loss item: 0.3009120225906372
train loss item: 0.32600677013397217
train loss item: 0.4639342725276947
train loss item: 0.1995484083890915
train loss item: 0.324881911277771
train loss item: 0.21174149215221405
train loss item: 0.7569984793663025
train loss item: 0.3522612750530243
train loss item: 0.21977509558200836
train loss item: 0.4903251528739929
train loss item: 1.1341159343719482
train loss item: 0.30607089400291443
train loss item: 1.383758783340454
train loss item: 0.6250470280647278
train loss item: 0.49409615993499756
train loss item: 0.31296053528785706
train loss item: 0.3010641932487488
train loss item: 0.34526315331459045
train loss item: 0.29056188464164734
train loss item: 0.2011161893606186
train loss item: 0.7640334963798523
train loss item: 0.15611793100833893
train loss item: 1.2474092245101929
train loss item: 0.2351001501083374
train loss item: 0.1384143978357315
train loss item: 1.162762999534607
train loss item: 0.3086768686771393
train loss item: 0.39650899171829224
train loss item: 0.484634131193161
train loss item: 0.38629549741744995
train loss item: 0.2709228992462158
train loss item: 0.2698284685611725
train loss item: 0.10340185463428497
train loss item: 1.039395809173584
train loss item: 0.20091594755649567
train loss item: 0.15157297253608704
train loss item: 0.3982321321964264
train loss item: 0.440316766500473
train loss item: 2.230140447616577
train loss item: 0.3458942472934723
test loss item: 0.14856019616127014
test loss item: 0.33808428049087524
test loss item: 0.19586585462093353
test loss item: 0.7325286865234375
test loss item: 0.28273871541023254
test loss item: 0.4754360318183899
test loss item: 0.20606659352779388
test loss item: 0.14296184480190277
test loss item: 0.2876807153224945
test loss item: 0.37385696172714233
test loss item: 0.38901475071907043
test loss item: 0.23583008348941803
test loss item: 0.18410858511924744
test loss item: 0.23453758656978607
test loss item: 0.30328238010406494
test loss item: 0.44746652245521545
test loss item: 0.39157232642173767
test loss item: 0.3656146824359894
test loss item: 0.7203139066696167
test loss item: 0.30995309352874756
test loss item: 0.20970779657363892
test loss item: 0.23775742948055267
test loss item: 0.39871272444725037
test loss item: 0.2737673223018646
test loss item: 0.4194757342338562
test loss item: 0.2655319273471832
test loss item: 0.1883847862482071
test loss item: 0.5032730102539062
test loss item: 0.4010279178619385
test loss item: 0.21972212195396423
test loss item: 0.29511523246765137
test loss item: 0.19503556191921234
test loss item: 0.4985000491142273
test loss item: 0.2284877449274063
test loss item: 0.363256573677063
test loss item: 0.4474424123764038
test loss item: 0.2693040668964386
test loss item: 0.16023977100849152
test loss item: 0.6786589026451111
test loss item: 0.18742311000823975
test loss item: 0.4664582312107086
test loss item: 0.6287912130355835
test loss item: 0.1968974620103836
test loss item: 0.07915804535150528
test loss item: 0.09978855401277542
Epoch [3/10], Training Loss: 0.4867, Testing Loss: 0.3262
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/10
train loss item: 0.5846463441848755
train loss item: 0.46709364652633667
train loss item: 0.28866732120513916
train loss item: 0.38409408926963806
train loss item: 0.2060285359621048
train loss item: 0.22247622907161713
train loss item: 0.2832382023334503
train loss item: 0.4702717065811157
train loss item: 0.18137365579605103
train loss item: 0.28913965821266174
train loss item: 0.2043216973543167
train loss item: 0.6464518308639526
train loss item: 0.2878282070159912
train loss item: 0.24124747514724731
train loss item: 0.36096057295799255
train loss item: 0.8703286051750183
train loss item: 0.2203783541917801
train loss item: 1.1851563453674316
train loss item: 0.5838367938995361
train loss item: 0.44526389241218567
train loss item: 0.25277382135391235
train loss item: 0.24237991869449615
train loss item: 0.3101827800273895
train loss item: 0.2497691512107849
train loss item: 0.17877978086471558
train loss item: 0.6733039021492004
train loss item: 0.1273578703403473
train loss item: 1.049696445465088
train loss item: 0.23817545175552368
train loss item: 0.1300685703754425
train loss item: 0.9740211367607117
train loss item: 0.31113722920417786
train loss item: 0.3159659206867218
train loss item: 0.46787795424461365
train loss item: 0.2775630056858063
train loss item: 0.19834938645362854
train loss item: 0.21410180628299713
train loss item: 0.10573571175336838
train loss item: 1.0175604820251465
train loss item: 0.2257736474275589
train loss item: 0.17291687428951263
train loss item: 0.3634456694126129
train loss item: 0.441344290971756
train loss item: 2.121882438659668
train loss item: 0.32812121510505676
test loss item: 0.12478938698768616
test loss item: 0.3011118471622467
test loss item: 0.14192920923233032
test loss item: 0.630023717880249
test loss item: 0.23513418436050415
test loss item: 0.4910232722759247
test loss item: 0.15377771854400635
test loss item: 0.10398860275745392
test loss item: 0.22903139889240265
test loss item: 0.3499266505241394
test loss item: 0.3094177842140198
test loss item: 0.16115058958530426
test loss item: 0.15386931598186493
test loss item: 0.18828681111335754
test loss item: 0.23641295731067657
test loss item: 0.41571044921875
test loss item: 0.309392511844635
test loss item: 0.3198678493499756
test loss item: 0.7020140290260315
test loss item: 0.24777376651763916
test loss item: 0.16521765291690826
test loss item: 0.1826513558626175
test loss item: 0.30408164858818054
test loss item: 0.18195202946662903
test loss item: 0.3825698494911194
test loss item: 0.17259466648101807
test loss item: 0.15670301020145416
test loss item: 0.4717332422733307
test loss item: 0.40463998913764954
test loss item: 0.1730196177959442
test loss item: 0.23353876173496246
test loss item: 0.16331298649311066
test loss item: 0.4717002809047699
test loss item: 0.1917625218629837
test loss item: 0.33267685770988464
test loss item: 0.38712865114212036
test loss item: 0.23611922562122345
test loss item: 0.11025822907686234
test loss item: 0.6963543891906738
test loss item: 0.14861270785331726
test loss item: 0.47640663385391235
test loss item: 0.6013250946998596
test loss item: 0.16767430305480957
test loss item: 0.06437309086322784
test loss item: 0.10673460364341736
Epoch [4/10], Training Loss: 0.4314, Testing Loss: 0.2842
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/10
train loss item: 0.5118881464004517
train loss item: 0.3984571397304535
train loss item: 0.25530698895454407
train loss item: 0.33681821823120117
train loss item: 0.22769978642463684
train loss item: 0.22091111540794373
train loss item: 0.2868576645851135
train loss item: 0.46445000171661377
train loss item: 0.1531766951084137
train loss item: 0.2311016321182251
train loss item: 0.18453653156757355
train loss item: 0.5342930555343628
train loss item: 0.24380940198898315
train loss item: 0.1606401652097702
train loss item: 0.365777850151062
train loss item: 0.6723116040229797
train loss item: 0.19890637695789337
train loss item: 0.9866223931312561
train loss item: 0.5037716627120972
train loss item: 0.2820667028427124
train loss item: 0.16388794779777527
train loss item: 0.1771187037229538
train loss item: 0.26311975717544556
train loss item: 0.20108281075954437
train loss item: 0.15467777848243713
train loss item: 0.6240071654319763
train loss item: 0.11860055476427078
train loss item: 0.8337778449058533
train loss item: 0.19584006071090698
train loss item: 0.15960951149463654
train loss item: 0.9115292429924011
train loss item: 0.24686142802238464
train loss item: 0.24098895490169525
train loss item: 0.4093363881111145
train loss item: 0.26009929180145264
train loss item: 0.20790132880210876
train loss item: 0.18673284351825714
train loss item: 0.09641703963279724
train loss item: 0.9139260649681091
train loss item: 0.1645147055387497
train loss item: 0.13643929362297058
train loss item: 0.31835994124412537
train loss item: 0.3392528295516968
train loss item: 1.6414583921432495
train loss item: 0.2887672483921051
test loss item: 0.19550161063671112
test loss item: 0.2994236946105957
test loss item: 0.22994257509708405
test loss item: 0.48043790459632874
test loss item: 0.24603867530822754
test loss item: 0.4786829948425293
test loss item: 0.14122365415096283
test loss item: 0.20259366929531097
test loss item: 0.21829749643802643
test loss item: 0.2829376757144928
test loss item: 0.27735963463783264
test loss item: 0.20171071588993073
test loss item: 0.17650413513183594
test loss item: 0.24259249866008759
test loss item: 0.26757004857063293
test loss item: 0.40002796053886414
test loss item: 0.29948973655700684
test loss item: 0.30129939317703247
test loss item: 0.621826171875
test loss item: 0.2662537097930908
test loss item: 0.16527876257896423
test loss item: 0.1690477579832077
test loss item: 0.2929086685180664
test loss item: 0.18293209373950958
test loss item: 0.3507876992225647
test loss item: 0.2001214176416397
test loss item: 0.18503925204277039
test loss item: 0.45668745040893555
test loss item: 0.3384855389595032
test loss item: 0.20276853442192078
test loss item: 0.23671270906925201
test loss item: 0.1778458207845688
test loss item: 0.4239494502544403
test loss item: 0.2108328491449356
test loss item: 0.28574711084365845
test loss item: 0.30879294872283936
test loss item: 0.23775243759155273
test loss item: 0.14558373391628265
test loss item: 0.6663407683372498
test loss item: 0.19756272435188293
test loss item: 0.4354705214500427
test loss item: 0.5613390803337097
test loss item: 0.19301073253154755
test loss item: 0.14697960019111633
test loss item: 0.14542344212532043
Epoch [5/10], Training Loss: 0.3661, Testing Loss: 0.2833
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/10
train loss item: 0.46084246039390564
train loss item: 0.29124993085861206
train loss item: 0.17856591939926147
train loss item: 0.3340012729167938
train loss item: 0.22900518774986267
train loss item: 0.19307877123355865
train loss item: 0.24505753815174103
train loss item: 0.42446383833885193
train loss item: 0.1825067698955536
train loss item: 0.2907450199127197
train loss item: 0.1385476440191269
train loss item: 0.45174428820610046
train loss item: 0.2000202089548111
train loss item: 0.15788567066192627
train loss item: 0.3391754627227783
train loss item: 0.6018105149269104
train loss item: 0.18050283193588257
train loss item: 0.7680143117904663
train loss item: 0.3596782982349396
train loss item: 0.229379802942276
train loss item: 0.1296491175889969
train loss item: 0.2428605854511261
train loss item: 0.3597387969493866
train loss item: 0.23036834597587585
train loss item: 0.1584877073764801
train loss item: 0.5805739164352417
train loss item: 0.13082480430603027
train loss item: 0.7857862114906311
train loss item: 0.20420008897781372
train loss item: 0.13103193044662476
train loss item: 0.7884742021560669
train loss item: 0.2919475734233856
train loss item: 0.22753193974494934
train loss item: 0.30056917667388916
train loss item: 0.2467338889837265
train loss item: 0.16434571146965027
train loss item: 0.17150531709194183
train loss item: 0.11826249212026596
train loss item: 0.8173943161964417
train loss item: 0.12529797852039337
train loss item: 0.10768253356218338
train loss item: 0.24191530048847198
train loss item: 0.3802388310432434
train loss item: 1.415191650390625
train loss item: 0.32344722747802734
test loss item: 0.12564949691295624
test loss item: 0.33286014199256897
test loss item: 0.1822153627872467
test loss item: 0.46736693382263184
test loss item: 0.25457534193992615
test loss item: 0.5187902450561523
test loss item: 0.11510709673166275
test loss item: 0.11669038981199265
test loss item: 0.2097650170326233
test loss item: 0.2631450295448303
test loss item: 0.2606631815433502
test loss item: 0.1569305807352066
test loss item: 0.13217826187610626
test loss item: 0.1985919326543808
test loss item: 0.22844645380973816
test loss item: 0.43893304467201233
test loss item: 0.29101502895355225
test loss item: 0.3037087917327881
test loss item: 0.68746417760849
test loss item: 0.24219143390655518
test loss item: 0.14910094439983368
test loss item: 0.17314724624156952
test loss item: 0.24455060064792633
test loss item: 0.15600252151489258
test loss item: 0.38665303587913513
test loss item: 0.16750457882881165
test loss item: 0.15908794105052948
test loss item: 0.5058937072753906
test loss item: 0.33754149079322815
test loss item: 0.15233653783798218
test loss item: 0.23772276937961578
test loss item: 0.13408736884593964
test loss item: 0.4802306592464447
test loss item: 0.17284780740737915
test loss item: 0.2769239544868469
test loss item: 0.2602335214614868
test loss item: 0.19464950263500214
test loss item: 0.10740289092063904
test loss item: 0.79021155834198
test loss item: 0.17324848473072052
test loss item: 0.46452808380126953
test loss item: 0.6338961720466614
test loss item: 0.1439511477947235
test loss item: 0.0722859650850296
test loss item: 0.11821331083774567
Epoch [6/10], Training Loss: 0.3318, Testing Loss: 0.2715
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/10
train loss item: 0.376660019159317
train loss item: 0.24376419186592102
train loss item: 0.13689376413822174
train loss item: 0.20972086489200592
train loss item: 0.17026224732398987
train loss item: 0.18103577196598053
train loss item: 0.2528071701526642
train loss item: 0.5167192220687866
train loss item: 0.1290530413389206
train loss item: 0.1838465929031372
train loss item: 0.14821279048919678
train loss item: 0.45167532563209534
train loss item: 0.18343250453472137
train loss item: 0.20404094457626343
train loss item: 0.24509121477603912
train loss item: 0.39217740297317505
train loss item: 0.2073289304971695
train loss item: 0.6280363202095032
train loss item: 0.3093501627445221
train loss item: 0.23424379527568817
train loss item: 0.15071195363998413
train loss item: 0.17596974968910217
train loss item: 0.22452561557292938
train loss item: 0.18186475336551666
train loss item: 0.12111040204763412
train loss item: 0.5241692662239075
train loss item: 0.08185189217329025
train loss item: 0.5103247761726379
train loss item: 0.1247827336192131
train loss item: 0.09612944722175598
train loss item: 0.4892878830432892
train loss item: 0.2991751432418823
train loss item: 0.17058515548706055
train loss item: 0.2798886001110077
train loss item: 0.2042241096496582
train loss item: 0.11829137057065964
train loss item: 0.12844321131706238
train loss item: 0.07338695973157883
train loss item: 0.8722028732299805
train loss item: 0.1286972314119339
train loss item: 0.09892301261425018
train loss item: 0.26654741168022156
train loss item: 0.2561940550804138
train loss item: 1.0929689407348633
train loss item: 0.2655448019504547
test loss item: 0.10664857923984528
test loss item: 0.21219684183597565
test loss item: 0.12509772181510925
test loss item: 0.40784454345703125
test loss item: 0.14164793491363525
test loss item: 0.3534127175807953
test loss item: 0.09452932327985764
test loss item: 0.10085093230009079
test loss item: 0.1323399543762207
test loss item: 0.20507846772670746
test loss item: 0.183808833360672
test loss item: 0.1027052029967308
test loss item: 0.09573038667440414
test loss item: 0.12664085626602173
test loss item: 0.1471935212612152
test loss item: 0.30260518193244934
test loss item: 0.17380067706108093
test loss item: 0.18729478120803833
test loss item: 0.4774356782436371
test loss item: 0.1500357985496521
test loss item: 0.11258912086486816
test loss item: 0.10533970594406128
test loss item: 0.17010442912578583
test loss item: 0.10794766992330551
test loss item: 0.22841128706932068
test loss item: 0.09933117032051086
test loss item: 0.10489995777606964
test loss item: 0.30186277627944946
test loss item: 0.2494138479232788
test loss item: 0.10640663653612137
test loss item: 0.12618505954742432
test loss item: 0.105065256357193
test loss item: 0.3580602705478668
test loss item: 0.12384460866451263
test loss item: 0.1998225301504135
test loss item: 0.22850409150123596
test loss item: 0.13898079097270966
test loss item: 0.08182110637426376
test loss item: 0.5862157940864563
test loss item: 0.11730889230966568
test loss item: 0.331183522939682
test loss item: 0.4312663674354553
test loss item: 0.10398340225219727
test loss item: 0.06809762865304947
test loss item: 0.08894895762205124
Epoch [7/10], Training Loss: 0.2742, Testing Loss: 0.1889
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/10
train loss item: 0.47564172744750977
train loss item: 0.3108649253845215
train loss item: 0.15812623500823975
train loss item: 0.49305179715156555
train loss item: 0.22650647163391113
train loss item: 0.26103413105010986
train loss item: 0.33352386951446533
train loss item: 0.5514872670173645
train loss item: 0.14265896379947662
train loss item: 0.22635720670223236
train loss item: 0.1573348343372345
train loss item: 0.6616557240486145
train loss item: 0.25196799635887146
train loss item: 0.23330503702163696
train loss item: 0.2504222095012665
train loss item: 0.4495373070240021
train loss item: 0.24330569803714752
train loss item: 0.44384336471557617
train loss item: 0.36229053139686584
train loss item: 0.25172895193099976
train loss item: 0.2108772248029709
train loss item: 0.26541027426719666
train loss item: 0.19484172761440277
train loss item: 0.23356854915618896
train loss item: 0.15433581173419952
train loss item: 0.5755647420883179
train loss item: 0.10028862953186035
train loss item: 0.5470557808876038
train loss item: 0.15949547290802002
train loss item: 0.1263604760169983
train loss item: 0.5686193704605103
train loss item: 0.22944849729537964
train loss item: 0.15575672686100006
train loss item: 0.26284706592559814
train loss item: 0.1974862515926361
train loss item: 0.14595502614974976
train loss item: 0.15681175887584686
train loss item: 0.10057811439037323
train loss item: 0.7494060397148132
train loss item: 0.13394752144813538
train loss item: 0.10798189043998718
train loss item: 0.3014478087425232
train loss item: 0.2115813046693802
train loss item: 0.9815070033073425
train loss item: 0.28765273094177246
test loss item: 0.12319251894950867
test loss item: 0.2054954171180725
test loss item: 0.1338830292224884
test loss item: 0.4217035472393036
test loss item: 0.15540358424186707
test loss item: 0.3416826128959656
test loss item: 0.12794877588748932
test loss item: 0.1065998449921608
test loss item: 0.15956725180149078
test loss item: 0.23369377851486206
test loss item: 0.2132510095834732
test loss item: 0.1726071983575821
test loss item: 0.13850463926792145
test loss item: 0.15051297843456268
test loss item: 0.1636924296617508
test loss item: 0.29668885469436646
test loss item: 0.1870776265859604
test loss item: 0.20285998284816742
test loss item: 0.4579201340675354
test loss item: 0.16932110488414764
test loss item: 0.15794633328914642
test loss item: 0.13530731201171875
test loss item: 0.21804949641227722
test loss item: 0.19199229776859283
test loss item: 0.2405354380607605
test loss item: 0.1355658620595932
test loss item: 0.13040190935134888
test loss item: 0.28449246287345886
test loss item: 0.25010085105895996
test loss item: 0.1327090859413147
test loss item: 0.1429571956396103
test loss item: 0.14515537023544312
test loss item: 0.3163157105445862
test loss item: 0.15747064352035522
test loss item: 0.20128174126148224
test loss item: 0.24429981410503387
test loss item: 0.20202577114105225
test loss item: 0.12836556136608124
test loss item: 0.5160160660743713
test loss item: 0.14934924244880676
test loss item: 0.3076390027999878
test loss item: 0.3983064889907837
test loss item: 0.13633328676223755
test loss item: 0.0751756802201271
test loss item: 0.12885721027851105
Epoch [8/10], Training Loss: 0.3032, Testing Loss: 0.2064
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/10
train loss item: 0.46993744373321533
train loss item: 0.34759071469306946
train loss item: 0.1880125254392624
train loss item: 0.2218480408191681
train loss item: 0.17517074942588806
train loss item: 0.1848209798336029
train loss item: 0.2653789818286896
train loss item: 0.4205528497695923
train loss item: 0.10969223082065582
train loss item: 0.19098621606826782
train loss item: 0.1755891740322113
train loss item: 0.599787175655365
train loss item: 0.19126486778259277
train loss item: 0.12355265021324158
train loss item: 0.2056228369474411
train loss item: 0.463957816362381
train loss item: 0.2596435844898224
train loss item: 0.4401898682117462
train loss item: 0.47354793548583984
train loss item: 0.31300485134124756
train loss item: 0.21919400990009308
train loss item: 0.14787206053733826
train loss item: 0.2116064876317978
train loss item: 0.17094433307647705
train loss item: 0.13635827600955963
train loss item: 0.6081914305686951
train loss item: 0.11429645866155624
train loss item: 0.722362756729126
train loss item: 0.17983026802539825
train loss item: 0.11891281604766846
train loss item: 0.637667715549469
train loss item: 0.1952071189880371
train loss item: 0.21268296241760254
train loss item: 0.33164355158805847
train loss item: 0.19408273696899414
train loss item: 0.17708390951156616
train loss item: 0.24461431801319122
train loss item: 0.09954483807086945
train loss item: 0.5654346346855164
train loss item: 0.16124317049980164
train loss item: 0.11305233091115952
train loss item: 0.297902375459671
train loss item: 0.23655971884727478
train loss item: 0.863521158695221
train loss item: 0.2339879870414734
test loss item: 0.1076713353395462
test loss item: 0.2058778703212738
test loss item: 0.14750944077968597
test loss item: 0.4583144783973694
test loss item: 0.1727057695388794
test loss item: 0.34688451886177063
test loss item: 0.14901164174079895
test loss item: 0.0935012698173523
test loss item: 0.15795588493347168
test loss item: 0.26541420817375183
test loss item: 0.18743383884429932
test loss item: 0.13666610419750214
test loss item: 0.11802523583173752
test loss item: 0.16714759171009064
test loss item: 0.1778729110956192
test loss item: 0.3028632402420044
test loss item: 0.18828357756137848
test loss item: 0.20542630553245544
test loss item: 0.46201232075691223
test loss item: 0.16893543303012848
test loss item: 0.12987928092479706
test loss item: 0.1328919380903244
test loss item: 0.21145497262477875
test loss item: 0.14892934262752533
test loss item: 0.2626493275165558
test loss item: 0.1354244202375412
test loss item: 0.11998416483402252
test loss item: 0.3011123538017273
test loss item: 0.2451857030391693
test loss item: 0.14186401665210724
test loss item: 0.16784261167049408
test loss item: 0.1329984813928604
test loss item: 0.3328916132450104
test loss item: 0.17122752964496613
test loss item: 0.2264377474784851
test loss item: 0.29886162281036377
test loss item: 0.20291775465011597
test loss item: 0.11088887602090836
test loss item: 0.4576551914215088
test loss item: 0.14581988751888275
test loss item: 0.3400142788887024
test loss item: 0.41176795959472656
test loss item: 0.13997285068035126
test loss item: 0.059987735003232956
test loss item: 0.12953203916549683
Epoch [9/10], Training Loss: 0.2892, Testing Loss: 0.2084
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/10
train loss item: 0.3850264847278595
train loss item: 0.199227973818779
train loss item: 0.1443118155002594
train loss item: 0.18646594882011414
train loss item: 0.18763965368270874
train loss item: 0.20796555280685425
train loss item: 0.3070656359195709
train loss item: 0.26665884256362915
train loss item: 0.08799506723880768
train loss item: 0.17614473402500153
train loss item: 0.09917756170034409
train loss item: 0.5777916312217712
train loss item: 0.1801963597536087
train loss item: 0.15518011152744293
train loss item: 0.208848237991333
train loss item: 0.39145633578300476
train loss item: 0.2122974842786789
train loss item: 0.3576621115207672
train loss item: 0.5816726684570312
train loss item: 0.2663452923297882
train loss item: 0.17600277066230774
train loss item: 0.18779335916042328
train loss item: 0.2593153417110443
train loss item: 0.164068341255188
train loss item: 0.12364210933446884
train loss item: 0.4199938178062439
train loss item: 0.09292686730623245
train loss item: 0.4777231216430664
train loss item: 0.13718217611312866
train loss item: 0.09670646488666534
train loss item: 0.4257116913795471
train loss item: 0.2437710464000702
train loss item: 0.1690315157175064
train loss item: 0.22117428481578827
train loss item: 0.19159837067127228
train loss item: 0.14777591824531555
train loss item: 0.14770475029945374
train loss item: 0.09477974474430084
train loss item: 0.6215625405311584
train loss item: 0.11394143849611282
train loss item: 0.08499576151371002
train loss item: 0.2474530041217804
train loss item: 0.30662864446640015
train loss item: 0.7631977796554565
train loss item: 0.20806412398815155
test loss item: 0.11708606034517288
test loss item: 0.20358900725841522
test loss item: 0.12651784718036652
test loss item: 0.46778860688209534
test loss item: 0.1557428538799286
test loss item: 0.338223934173584
test loss item: 0.11767251789569855
test loss item: 0.09538006782531738
test loss item: 0.16636522114276886
test loss item: 0.2599972188472748
test loss item: 0.20828668773174286
test loss item: 0.16071942448616028
test loss item: 0.11259719729423523
test loss item: 0.15256398916244507
test loss item: 0.16976581513881683
test loss item: 0.2763344943523407
test loss item: 0.1669529378414154
test loss item: 0.21661362051963806
test loss item: 0.4452143907546997
test loss item: 0.1675305813550949
test loss item: 0.15962748229503632
test loss item: 0.12482929229736328
test loss item: 0.22735907137393951
test loss item: 0.17029966413974762
test loss item: 0.2536432445049286
test loss item: 0.12221615761518478
test loss item: 0.12535659968852997
test loss item: 0.27721935510635376
test loss item: 0.2874854505062103
test loss item: 0.11662551760673523
test loss item: 0.16043849289417267
test loss item: 0.13525624573230743
test loss item: 0.3483205735683441
test loss item: 0.16813763976097107
test loss item: 0.20879904925823212
test loss item: 0.31848591566085815
test loss item: 0.2301386296749115
test loss item: 0.1297474503517151
test loss item: 0.4714335501194
test loss item: 0.15074913203716278
test loss item: 0.3424518406391144
test loss item: 0.40516069531440735
test loss item: 0.13574092090129852
test loss item: 0.06283742189407349
test loss item: 0.10882475972175598
Epoch [10/10], Training Loss: 0.2512, Testing Loss: 0.2081
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
loss item: 0.15109649300575256
loss item: 0.5153834819793701
loss item: 0.24555815756320953
loss item: 0.2661939859390259
loss item: 0.1323104351758957
loss item: 0.4060992896556854
loss item: 0.27968886494636536
loss item: 0.15119275450706482
loss item: 0.2478310614824295
loss item: 0.35861051082611084
loss item: 0.17167621850967407
loss item: 0.18018071353435516
loss item: 0.2799842059612274
loss item: 0.29540517926216125
loss item: 0.20621603727340698
loss item: 0.48937976360321045
loss item: 0.22451332211494446
loss item: 0.12947048246860504
loss item: 0.1601317673921585
loss item: 0.2583135664463043
loss item: 0.3585546910762787
loss item: 0.11164619028568268
Val Loss: 0.2554
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 10, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.001 4 360 done at Tue Nov 12 09:43:52 CET 2024
UNet2 with 1 10 0.005 4 360 start at Tue Nov 12 09:43:52 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 10, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.6336421966552734
train loss item: 1.347577691078186
train loss item: 1.2426575422286987
train loss item: 1.403577446937561
train loss item: 0.49251851439476013
train loss item: 0.45189368724823
train loss item: 0.523338794708252
train loss item: 0.8533712029457092
train loss item: 0.4423550069332123
train loss item: 0.49863359332084656
train loss item: 0.28157615661621094
train loss item: 1.4692952632904053
train loss item: 0.6577840447425842
train loss item: 0.43952804803848267
train loss item: 1.1109474897384644
train loss item: 2.2161989212036133
train loss item: 0.6377905011177063
train loss item: 2.557669162750244
train loss item: 0.5520955920219421
train loss item: 0.5395609736442566
train loss item: 0.3840208053588867
train loss item: 0.47386613488197327
train loss item: 0.5512625575065613
train loss item: 0.5325104594230652
train loss item: 0.3741435110569
train loss item: 1.080769658088684
train loss item: 0.32202449440956116
train loss item: 1.9903427362442017
train loss item: 0.39721742272377014
train loss item: 0.18291355669498444
train loss item: 1.9903628826141357
train loss item: 0.585350751876831
train loss item: 0.6599414944648743
train loss item: 0.43473342061042786
train loss item: 0.5474609732627869
train loss item: 0.346159964799881
train loss item: 0.35071614384651184
train loss item: 0.28084033727645874
train loss item: 1.416642427444458
train loss item: 0.27042609453201294
train loss item: 0.35390377044677734
train loss item: 0.630920946598053
train loss item: 0.6428886651992798
train loss item: 3.4514591693878174
train loss item: 0.4955306947231293
test loss item: 0.18652459979057312
test loss item: 0.5123259425163269
test loss item: 0.23698683083057404
test loss item: 1.199652075767517
test loss item: 0.37343162298202515
test loss item: 0.839149534702301
test loss item: 0.20760200917720795
test loss item: 0.15818800032138824
test loss item: 0.4415561258792877
test loss item: 0.5559232234954834
test loss item: 0.5511224865913391
test loss item: 0.28916239738464355
test loss item: 0.28136152029037476
test loss item: 0.31867167353630066
test loss item: 0.4116658568382263
test loss item: 0.7880279421806335
test loss item: 0.5528665781021118
test loss item: 0.5054436326026917
test loss item: 1.2191683053970337
test loss item: 0.482201486825943
test loss item: 0.33643874526023865
test loss item: 0.3294539451599121
test loss item: 0.5891830921173096
test loss item: 0.3420000672340393
test loss item: 0.6437329649925232
test loss item: 0.27744820713996887
test loss item: 0.27574583888053894
test loss item: 0.8090168833732605
test loss item: 0.6069300174713135
test loss item: 0.26123201847076416
test loss item: 0.40436360239982605
test loss item: 0.2860547602176666
test loss item: 0.8523262739181519
test loss item: 0.34835126996040344
test loss item: 0.5599121451377869
test loss item: 0.7706369757652283
test loss item: 0.4201832413673401
test loss item: 0.2194983810186386
test loss item: 1.3796803951263428
test loss item: 0.2588309645652771
test loss item: 0.8224002718925476
test loss item: 1.0600274801254272
test loss item: 0.25890272855758667
test loss item: 0.1164037212729454
test loss item: 0.19492024183273315
Epoch [1/10], Training Loss: 0.8466, Testing Loss: 0.5008
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/10
train loss item: 0.945400595664978
train loss item: 0.5656852722167969
train loss item: 0.4969066083431244
train loss item: 0.7138389945030212
train loss item: 0.41676419973373413
train loss item: 0.4335280954837799
train loss item: 0.4800505042076111
train loss item: 0.6254915595054626
train loss item: 0.27953222393989563
train loss item: 0.4126567244529724
train loss item: 0.21374163031578064
train loss item: 1.1867620944976807
train loss item: 0.5342413187026978
train loss item: 0.4554866850376129
train loss item: 0.8397504687309265
train loss item: 1.7313896417617798
train loss item: 0.4293855130672455
train loss item: 2.138850688934326
train loss item: 0.5286787748336792
train loss item: 0.5112156271934509
train loss item: 0.3450028598308563
train loss item: 0.3460937440395355
train loss item: 0.4993901550769806
train loss item: 0.32863542437553406
train loss item: 0.24903453886508942
train loss item: 0.8569633960723877
train loss item: 0.1590740978717804
train loss item: 1.8313250541687012
train loss item: 0.31091275811195374
train loss item: 0.16525501012802124
train loss item: 1.720314383506775
train loss item: 0.42017778754234314
train loss item: 0.5331020951271057
train loss item: 0.42986661195755005
train loss item: 0.41625896096229553
train loss item: 0.2995673418045044
train loss item: 0.3341169059276581
train loss item: 0.11984185129404068
train loss item: 1.2438786029815674
train loss item: 0.2610898017883301
train loss item: 0.22758682072162628
train loss item: 0.5644232034683228
train loss item: 0.5763090252876282
train loss item: 2.96242356300354
train loss item: 0.4432523250579834
test loss item: 0.16126231849193573
test loss item: 0.49072882533073425
test loss item: 0.2205481082201004
test loss item: 1.1506656408309937
test loss item: 0.3921148180961609
test loss item: 0.8079535365104675
test loss item: 0.23131026327610016
test loss item: 0.13870981335639954
test loss item: 0.43551120162010193
test loss item: 0.5888134241104126
test loss item: 0.544439971446991
test loss item: 0.2559468448162079
test loss item: 0.2746877670288086
test loss item: 0.32591214776039124
test loss item: 0.4170214831829071
test loss item: 0.7459545135498047
test loss item: 0.5304632186889648
test loss item: 0.5088574290275574
test loss item: 1.2048120498657227
test loss item: 0.4579828679561615
test loss item: 0.2913540303707123
test loss item: 0.3125852048397064
test loss item: 0.6091951727867126
test loss item: 0.31842416524887085
test loss item: 0.664040207862854
test loss item: 0.28352099657058716
test loss item: 0.2550370395183563
test loss item: 0.7749406695365906
test loss item: 0.6107324957847595
test loss item: 0.25903379917144775
test loss item: 0.4217155873775482
test loss item: 0.2799800932407379
test loss item: 0.7853072881698608
test loss item: 0.3575451076030731
test loss item: 0.5457370281219482
test loss item: 0.7555294632911682
test loss item: 0.420271098613739
test loss item: 0.1938873529434204
test loss item: 1.2912393808364868
test loss item: 0.23956875503063202
test loss item: 0.81330406665802
test loss item: 1.0305527448654175
test loss item: 0.26021909713745117
test loss item: 0.08182741701602936
test loss item: 0.12967297434806824
Epoch [2/10], Training Loss: 0.6574, Testing Loss: 0.4860
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/10
train loss item: 0.8472827076911926
train loss item: 0.6106647849082947
train loss item: 0.44940295815467834
train loss item: 0.644042432308197
train loss item: 0.31033170223236084
train loss item: 0.38958609104156494
train loss item: 0.41482388973236084
train loss item: 0.46685659885406494
train loss item: 0.25299182534217834
train loss item: 0.35189634561538696
train loss item: 0.2326698899269104
train loss item: 1.0513217449188232
train loss item: 0.45542073249816895
train loss item: 0.2806621193885803
train loss item: 0.654719352722168
train loss item: 1.4262546300888062
train loss item: 0.3385307192802429
train loss item: 1.780143141746521
train loss item: 0.7078552842140198
train loss item: 0.6721284985542297
train loss item: 0.31872767210006714
train loss item: 0.33787035942077637
train loss item: 0.43650752305984497
train loss item: 0.3212485611438751
train loss item: 0.23101668059825897
train loss item: 0.7423748970031738
train loss item: 0.15144890546798706
train loss item: 1.5260906219482422
train loss item: 0.32508742809295654
train loss item: 0.18050996959209442
train loss item: 1.4484329223632812
train loss item: 0.46051931381225586
train loss item: 0.522236168384552
train loss item: 0.4930451512336731
train loss item: 0.4201532006263733
train loss item: 0.2729872167110443
train loss item: 0.33013755083084106
train loss item: 0.11035403609275818
train loss item: 1.1148489713668823
train loss item: 0.2707400918006897
train loss item: 0.22322282195091248
train loss item: 0.5041843056678772
train loss item: 0.5557368397712708
train loss item: 2.7770726680755615
train loss item: 0.41871771216392517
test loss item: 0.1802605390548706
test loss item: 0.504517674446106
test loss item: 0.2730792164802551
test loss item: 1.075114369392395
test loss item: 0.4271893799304962
test loss item: 0.7942330837249756
test loss item: 0.2535458505153656
test loss item: 0.17768509685993195
test loss item: 0.4210967421531677
test loss item: 0.5447808504104614
test loss item: 0.5118012428283691
test loss item: 0.27079010009765625
test loss item: 0.27578604221343994
test loss item: 0.3414904475212097
test loss item: 0.43427151441574097
test loss item: 0.7314468622207642
test loss item: 0.5431112051010132
test loss item: 0.5198567509651184
test loss item: 1.17726731300354
test loss item: 0.46724966168403625
test loss item: 0.2785700559616089
test loss item: 0.3122018277645111
test loss item: 0.5717281699180603
test loss item: 0.311200350522995
test loss item: 0.6698199510574341
test loss item: 0.31621822714805603
test loss item: 0.26298436522483826
test loss item: 0.7895907163619995
test loss item: 0.575943112373352
test loss item: 0.2909041941165924
test loss item: 0.4256826937198639
test loss item: 0.27490904927253723
test loss item: 0.7381288409233093
test loss item: 0.34564247727394104
test loss item: 0.5422050356864929
test loss item: 0.7022069692611694
test loss item: 0.3799048066139221
test loss item: 0.19399434328079224
test loss item: 1.2392605543136597
test loss item: 0.26511427760124207
test loss item: 0.7768603563308716
test loss item: 1.0065412521362305
test loss item: 0.26264670491218567
test loss item: 0.09411763399839401
test loss item: 0.1608969122171402
Epoch [3/10], Training Loss: 0.5962, Testing Loss: 0.4825
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/10
train loss item: 0.8090807199478149
train loss item: 0.5690974593162537
train loss item: 0.40838858485221863
train loss item: 0.6001176238059998
train loss item: 0.28542542457580566
train loss item: 0.36870741844177246
train loss item: 0.40422549843788147
train loss item: 0.4469160735607147
train loss item: 0.24582251906394958
train loss item: 0.34188446402549744
train loss item: 0.21352605521678925
train loss item: 0.9234427809715271
train loss item: 0.42073431611061096
train loss item: 0.2652519643306732
train loss item: 0.6126670241355896
train loss item: 1.3028028011322021
train loss item: 0.32369956374168396
train loss item: 1.5854545831680298
train loss item: 0.8190464973449707
train loss item: 0.7207515835762024
train loss item: 0.34192925691604614
train loss item: 0.3292854428291321
train loss item: 0.40694233775138855
train loss item: 0.31155484914779663
train loss item: 0.23373834788799286
train loss item: 0.6925632357597351
train loss item: 0.1406780481338501
train loss item: 1.406319499015808
train loss item: 0.32040905952453613
train loss item: 0.19390727579593658
train loss item: 1.3186147212982178
train loss item: 0.42854219675064087
train loss item: 0.4895843267440796
train loss item: 0.4435997009277344
train loss item: 0.3945150375366211
train loss item: 0.24754463136196136
train loss item: 0.3291766047477722
train loss item: 0.13003401458263397
train loss item: 1.0130952596664429
train loss item: 0.2768600881099701
train loss item: 0.19242867827415466
train loss item: 0.47701987624168396
train loss item: 0.5291575789451599
train loss item: 2.5110244750976562
train loss item: 0.383695513010025
test loss item: 0.1619199812412262
test loss item: 0.44015011191368103
test loss item: 0.2177913635969162
test loss item: 1.2038090229034424
test loss item: 0.3648519814014435
test loss item: 0.7160108685493469
test loss item: 0.2592621445655823
test loss item: 0.15363512933254242
test loss item: 0.4027279019355774
test loss item: 0.5901955962181091
test loss item: 0.5210987329483032
test loss item: 0.24701179563999176
test loss item: 0.2573278546333313
test loss item: 0.3091728091239929
test loss item: 0.39390063285827637
test loss item: 0.7035701870918274
test loss item: 0.49562230706214905
test loss item: 0.47318899631500244
test loss item: 1.1034667491912842
test loss item: 0.41788968443870544
test loss item: 0.27474531531333923
test loss item: 0.2902994155883789
test loss item: 0.5850714445114136
test loss item: 0.2975107431411743
test loss item: 0.6150050163269043
test loss item: 0.2682058811187744
test loss item: 0.22692205011844635
test loss item: 0.6817983984947205
test loss item: 0.5976828932762146
test loss item: 0.26410427689552307
test loss item: 0.38909992575645447
test loss item: 0.2774963676929474
test loss item: 0.7313579320907593
test loss item: 0.34846413135528564
test loss item: 0.5332461595535278
test loss item: 0.8059496283531189
test loss item: 0.40858110785484314
test loss item: 0.18411460518836975
test loss item: 1.100257158279419
test loss item: 0.22328689694404602
test loss item: 0.7847654819488525
test loss item: 0.9487593173980713
test loss item: 0.241329163312912
test loss item: 0.08484473079442978
test loss item: 0.13726384937763214
Epoch [4/10], Training Loss: 0.5602, Testing Loss: 0.4607
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/10
train loss item: 0.7939813733100891
train loss item: 0.5870384573936462
train loss item: 0.40169617533683777
train loss item: 0.5484129786491394
train loss item: 0.2943485677242279
train loss item: 0.3320987820625305
train loss item: 0.3582610785961151
train loss item: 0.4270992875099182
train loss item: 0.23144365847110748
train loss item: 0.3207961618900299
train loss item: 0.17521385848522186
train loss item: 0.8768212795257568
train loss item: 0.39664143323898315
train loss item: 0.22368909418582916
train loss item: 0.5020948052406311
train loss item: 1.1488237380981445
train loss item: 0.342511922121048
train loss item: 1.4312740564346313
train loss item: 0.7971140146255493
train loss item: 0.6120758652687073
train loss item: 0.2298477292060852
train loss item: 0.27724507451057434
train loss item: 0.4276661276817322
train loss item: 0.3090161085128784
train loss item: 0.198374405503273
train loss item: 0.6910200119018555
train loss item: 0.1618068367242813
train loss item: 1.207358717918396
train loss item: 0.27897390723228455
train loss item: 0.17236106097698212
train loss item: 1.1014404296875
train loss item: 0.433631032705307
train loss item: 0.4285750985145569
train loss item: 0.5375449061393738
train loss item: 0.35157454013824463
train loss item: 0.2356889545917511
train loss item: 0.3230947256088257
train loss item: 0.11718650907278061
train loss item: 1.1036293506622314
train loss item: 0.22381098568439484
train loss item: 0.19120992720127106
train loss item: 0.46107274293899536
train loss item: 0.6597883105278015
train loss item: 2.5488739013671875
train loss item: 0.4447628855705261
test loss item: 0.21019500494003296
test loss item: 0.45396074652671814
test loss item: 0.2469397634267807
test loss item: 0.8688377737998962
test loss item: 0.35180479288101196
test loss item: 0.7061207890510559
test loss item: 0.21992692351341248
test loss item: 0.19687776267528534
test loss item: 0.37795397639274597
test loss item: 0.47033554315567017
test loss item: 0.4607613682746887
test loss item: 0.27084165811538696
test loss item: 0.24185776710510254
test loss item: 0.3152433931827545
test loss item: 0.37390726804733276
test loss item: 0.6184032559394836
test loss item: 0.4741443693637848
test loss item: 0.4307726323604584
test loss item: 1.0020742416381836
test loss item: 0.3992624580860138
test loss item: 0.27911651134490967
test loss item: 0.2733513414859772
test loss item: 0.514079749584198
test loss item: 0.31297504901885986
test loss item: 0.5580347180366516
test loss item: 0.25938618183135986
test loss item: 0.22726120054721832
test loss item: 0.6655758619308472
test loss item: 0.5165843963623047
test loss item: 0.2306268811225891
test loss item: 0.36289873719215393
test loss item: 0.25129541754722595
test loss item: 0.6405119895935059
test loss item: 0.3162073791027069
test loss item: 0.44570866227149963
test loss item: 0.5699805617332458
test loss item: 0.368742972612381
test loss item: 0.21327565610408783
test loss item: 1.0572994947433472
test loss item: 0.2619453966617584
test loss item: 0.6680194139480591
test loss item: 0.8670331239700317
test loss item: 0.23616822063922882
test loss item: 0.15715660154819489
test loss item: 0.1409444808959961
Epoch [5/10], Training Loss: 0.5315, Testing Loss: 0.4241
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/10
train loss item: 0.6722326874732971
train loss item: 0.6472647190093994
train loss item: 0.3674473464488983
train loss item: 0.5457723140716553
train loss item: 0.3013373911380768
train loss item: 0.3446873724460602
train loss item: 0.40469682216644287
train loss item: 0.48261162638664246
train loss item: 0.21648581326007843
train loss item: 0.3097626268863678
train loss item: 0.1766408234834671
train loss item: 0.7924415469169617
train loss item: 0.3743273615837097
train loss item: 0.24916814267635345
train loss item: 0.536395251750946
train loss item: 1.0040340423583984
train loss item: 0.27670302987098694
train loss item: 1.2049758434295654
train loss item: 0.8741863369941711
train loss item: 0.60051429271698
train loss item: 0.2985740303993225
train loss item: 0.27831676602363586
train loss item: 0.3834359347820282
train loss item: 0.2688014507293701
train loss item: 0.21656470000743866
train loss item: 0.6637131571769714
train loss item: 0.13752591609954834
train loss item: 1.215593695640564
train loss item: 0.24030710756778717
train loss item: 0.15147344768047333
train loss item: 1.0973873138427734
train loss item: 0.3600108027458191
train loss item: 0.4203082025051117
train loss item: 0.5157877206802368
train loss item: 0.37288257479667664
train loss item: 0.2113913595676422
train loss item: 0.29018718004226685
train loss item: 0.10508165508508682
train loss item: 0.953016996383667
train loss item: 0.19498303532600403
train loss item: 0.15724119544029236
train loss item: 0.3779267370700836
train loss item: 0.45830103754997253
train loss item: 1.9161124229431152
train loss item: 0.47565776109695435
test loss item: 0.17044244706630707
test loss item: 0.39845678210258484
test loss item: 0.19931359589099884
test loss item: 0.799482524394989
test loss item: 0.28499147295951843
test loss item: 0.5951049327850342
test loss item: 0.18521039187908173
test loss item: 0.1326655000448227
test loss item: 0.3584539592266083
test loss item: 0.4295026361942291
test loss item: 0.4583287835121155
test loss item: 0.25140830874443054
test loss item: 0.22953855991363525
test loss item: 0.26608267426490784
test loss item: 0.32275328040122986
test loss item: 0.5512738823890686
test loss item: 0.4549865126609802
test loss item: 0.38628271222114563
test loss item: 0.8753800392150879
test loss item: 0.360739529132843
test loss item: 0.27483218908309937
test loss item: 0.2631319463253021
test loss item: 0.4798237979412079
test loss item: 0.29522237181663513
test loss item: 0.47779014706611633
test loss item: 0.21502654254436493
test loss item: 0.21805916726589203
test loss item: 0.6000245809555054
test loss item: 0.465888112783432
test loss item: 0.20673370361328125
test loss item: 0.3215444087982178
test loss item: 0.23377498984336853
test loss item: 0.6345674991607666
test loss item: 0.2851347327232361
test loss item: 0.4409381151199341
test loss item: 0.5179892182350159
test loss item: 0.3486470580101013
test loss item: 0.20293709635734558
test loss item: 1.0244683027267456
test loss item: 0.23432783782482147
test loss item: 0.596384584903717
test loss item: 0.778014600276947
test loss item: 0.22138498723506927
test loss item: 0.12569454312324524
test loss item: 0.27469542622566223
Epoch [6/10], Training Loss: 0.4921, Testing Loss: 0.3877
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/10
train loss item: 0.6834952235221863
train loss item: 0.5108019709587097
train loss item: 0.29087987542152405
train loss item: 0.4806845188140869
train loss item: 0.304002970457077
train loss item: 0.3033292591571808
train loss item: 0.31130433082580566
train loss item: 0.4769441485404968
train loss item: 0.20422956347465515
train loss item: 0.28319859504699707
train loss item: 0.19576238095760345
train loss item: 0.681144118309021
train loss item: 0.3279729187488556
train loss item: 0.21476371586322784
train loss item: 0.46284958720207214
train loss item: 0.9002544283866882
train loss item: 0.2511739134788513
train loss item: 0.9676511883735657
train loss item: 0.6782336235046387
train loss item: 0.39863476157188416
train loss item: 0.23711882531642914
train loss item: 0.28847143054008484
train loss item: 0.33246126770973206
train loss item: 0.28792375326156616
train loss item: 0.18497583270072937
train loss item: 0.572139322757721
train loss item: 0.12339083105325699
train loss item: 0.8942172527313232
train loss item: 0.23832207918167114
train loss item: 0.18110999464988708
train loss item: 0.8381558656692505
train loss item: 0.34240245819091797
train loss item: 0.36235150694847107
train loss item: 0.4912140965461731
train loss item: 0.3161610960960388
train loss item: 0.2086329460144043
train loss item: 0.25971633195877075
train loss item: 0.12963244318962097
train loss item: 0.9323926568031311
train loss item: 0.2117735892534256
train loss item: 0.19237594306468964
train loss item: 0.3639521300792694
train loss item: 0.4831444323062897
train loss item: 1.653002142906189
train loss item: 0.412399023771286
test loss item: 0.16370932757854462
test loss item: 0.356836199760437
test loss item: 0.2377030849456787
test loss item: 0.8060991764068604
test loss item: 0.2861695885658264
test loss item: 0.5518744587898254
test loss item: 0.18577973544597626
test loss item: 0.145443856716156
test loss item: 0.3114122748374939
test loss item: 0.4363095164299011
test loss item: 0.39468586444854736
test loss item: 0.25270381569862366
test loss item: 0.21111337840557098
test loss item: 0.2711045444011688
test loss item: 0.3129524886608124
test loss item: 0.49469226598739624
test loss item: 0.3996514081954956
test loss item: 0.38837239146232605
test loss item: 0.8176052570343018
test loss item: 0.33260378241539
test loss item: 0.23500877618789673
test loss item: 0.22460907697677612
test loss item: 0.4297024607658386
test loss item: 0.2771562933921814
test loss item: 0.4704809784889221
test loss item: 0.21560658514499664
test loss item: 0.18135115504264832
test loss item: 0.5265294313430786
test loss item: 0.47292980551719666
test loss item: 0.20578834414482117
test loss item: 0.3074435591697693
test loss item: 0.20501190423965454
test loss item: 0.54923415184021
test loss item: 0.26409631967544556
test loss item: 0.4148637354373932
test loss item: 0.5244768261909485
test loss item: 0.30222079157829285
test loss item: 0.19094829261302948
test loss item: 0.8015830516815186
test loss item: 0.23871107399463654
test loss item: 0.5544226169586182
test loss item: 0.7028189897537231
test loss item: 0.20554739236831665
test loss item: 0.09685264527797699
test loss item: 0.21613264083862305
Epoch [7/10], Training Loss: 0.4325, Testing Loss: 0.3593
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/10
train loss item: 0.6159584522247314
train loss item: 0.3726058006286621
train loss item: 0.29230403900146484
train loss item: 0.4982207417488098
train loss item: 0.2291695475578308
train loss item: 0.26635345816612244
train loss item: 0.3388930559158325
train loss item: 0.45322468876838684
train loss item: 0.17693468928337097
train loss item: 0.2666698694229126
train loss item: 0.16499948501586914
train loss item: 0.7147325277328491
train loss item: 0.3136114478111267
train loss item: 0.2128148376941681
train loss item: 0.39765995740890503
train loss item: 0.7444828152656555
train loss item: 0.28488707542419434
train loss item: 0.7810381650924683
train loss item: 0.7685247659683228
train loss item: 0.3851138949394226
train loss item: 0.219159796833992
train loss item: 0.31499266624450684
train loss item: 0.330311119556427
train loss item: 0.2897900342941284
train loss item: 0.18503890931606293
train loss item: 0.5276561975479126
train loss item: 0.12511757016181946
train loss item: 0.6662341952323914
train loss item: 0.222976416349411
train loss item: 0.1700279414653778
train loss item: 0.7432228922843933
train loss item: 0.32953017950057983
train loss item: 0.292040079832077
train loss item: 0.42485490441322327
train loss item: 0.2984802722930908
train loss item: 0.1798573136329651
train loss item: 0.23677001893520355
train loss item: 0.09849874675273895
train loss item: 0.857044517993927
train loss item: 0.19253231585025787
train loss item: 0.15604683756828308
train loss item: 0.31781643629074097
train loss item: 0.46174755692481995
train loss item: 1.1914072036743164
train loss item: 0.3786194920539856
test loss item: 0.15831129252910614
test loss item: 0.3774109184741974
test loss item: 0.2193676382303238
test loss item: 0.6748121380805969
test loss item: 0.2741066813468933
test loss item: 0.5670682787895203
test loss item: 0.1665019690990448
test loss item: 0.14350613951683044
test loss item: 0.2988987863063812
test loss item: 0.3639279901981354
test loss item: 0.3631017506122589
test loss item: 0.2366778552532196
test loss item: 0.1938260793685913
test loss item: 0.25208768248558044
test loss item: 0.2930682301521301
test loss item: 0.4837612509727478
test loss item: 0.3903307020664215
test loss item: 0.34869852662086487
test loss item: 0.8113980293273926
test loss item: 0.3098466694355011
test loss item: 0.22486045956611633
test loss item: 0.21598409116268158
test loss item: 0.376176118850708
test loss item: 0.25621020793914795
test loss item: 0.4567394256591797
test loss item: 0.18878866732120514
test loss item: 0.18272823095321655
test loss item: 0.5550397038459778
test loss item: 0.419770747423172
test loss item: 0.18496114015579224
test loss item: 0.2867168188095093
test loss item: 0.19031065702438354
test loss item: 0.5554680824279785
test loss item: 0.24998778104782104
test loss item: 0.3666864037513733
test loss item: 0.42145437002182007
test loss item: 0.27817466855049133
test loss item: 0.18267394602298737
test loss item: 0.8872026801109314
test loss item: 0.22020380198955536
test loss item: 0.5397693514823914
test loss item: 0.7100871801376343
test loss item: 0.18756283819675446
test loss item: 0.08638442307710648
test loss item: 0.1778154969215393
Epoch [8/10], Training Loss: 0.3886, Testing Loss: 0.3406
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/10
train loss item: 0.5726674795150757
train loss item: 0.3511415421962738
train loss item: 0.26425859332084656
train loss item: 0.3773975372314453
train loss item: 0.2558417320251465
train loss item: 0.2604404091835022
train loss item: 0.28481072187423706
train loss item: 0.571817934513092
train loss item: 0.19668880105018616
train loss item: 0.2797573208808899
train loss item: 0.12524208426475525
train loss item: 0.6214509010314941
train loss item: 0.2812715768814087
train loss item: 0.2491178959608078
train loss item: 0.3601458966732025
train loss item: 0.7780765295028687
train loss item: 0.34482312202453613
train loss item: 0.6546589136123657
train loss item: 0.3933270573616028
train loss item: 0.2662087678909302
train loss item: 0.18778644502162933
train loss item: 0.2706407606601715
train loss item: 0.2762241065502167
train loss item: 0.26728716492652893
train loss item: 0.155086487531662
train loss item: 0.6334497332572937
train loss item: 0.10690432041883469
train loss item: 0.7557992339134216
train loss item: 0.2062920778989792
train loss item: 0.14183087646961212
train loss item: 0.7444945573806763
train loss item: 0.24572184681892395
train loss item: 0.3002210259437561
train loss item: 0.40610745549201965
train loss item: 0.28048020601272583
train loss item: 0.1841522604227066
train loss item: 0.21003012359142303
train loss item: 0.08807791024446487
train loss item: 0.8122351169586182
train loss item: 0.18065157532691956
train loss item: 0.12171285599470139
train loss item: 0.3911166489124298
train loss item: 0.41494596004486084
train loss item: 0.9855477809906006
train loss item: 0.3442762494087219
test loss item: 0.1526055783033371
test loss item: 0.3603709936141968
test loss item: 0.2319965660572052
test loss item: 0.6919817328453064
test loss item: 0.27569544315338135
test loss item: 0.5399787425994873
test loss item: 0.15210582315921783
test loss item: 0.14879944920539856
test loss item: 0.2775164842605591
test loss item: 0.325853168964386
test loss item: 0.3588808476924896
test loss item: 0.20250678062438965
test loss item: 0.17610694468021393
test loss item: 0.24663114547729492
test loss item: 0.2914465069770813
test loss item: 0.48760175704956055
test loss item: 0.38641905784606934
test loss item: 0.34905102849006653
test loss item: 0.7776722311973572
test loss item: 0.31279808282852173
test loss item: 0.17525386810302734
test loss item: 0.2075054943561554
test loss item: 0.35771968960762024
test loss item: 0.20555701851844788
test loss item: 0.4404856562614441
test loss item: 0.20427300035953522
test loss item: 0.17318086326122284
test loss item: 0.5410112738609314
test loss item: 0.3895481824874878
test loss item: 0.18665865063667297
test loss item: 0.28055915236473083
test loss item: 0.17060621082782745
test loss item: 0.5157884359359741
test loss item: 0.21346744894981384
test loss item: 0.3483826518058777
test loss item: 0.4029048979282379
test loss item: 0.24745364487171173
test loss item: 0.12093694508075714
test loss item: 0.818690836429596
test loss item: 0.21500037610530853
test loss item: 0.5141912698745728
test loss item: 0.6884729266166687
test loss item: 0.16786672174930573
test loss item: 0.07280046492815018
test loss item: 0.11660254746675491
Epoch [9/10], Training Loss: 0.3600, Testing Loss: 0.3227
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/10
train loss item: 0.6020269393920898
train loss item: 0.39847317337989807
train loss item: 0.24624276161193848
train loss item: 0.3701951801776886
train loss item: 0.23843127489089966
train loss item: 0.2669205665588379
train loss item: 0.35048267245292664
train loss item: 0.5872641205787659
train loss item: 0.22119779884815216
train loss item: 0.325479656457901
train loss item: 0.1657361090183258
train loss item: 0.7607239484786987
train loss item: 0.28758808970451355
train loss item: 0.22616659104824066
train loss item: 0.4163755774497986
train loss item: 0.679554283618927
train loss item: 0.31096145510673523
train loss item: 0.6030941605567932
train loss item: 0.6540489792823792
train loss item: 0.35537421703338623
train loss item: 0.24654889106750488
train loss item: 0.22990305721759796
train loss item: 0.2814757823944092
train loss item: 0.25349095463752747
train loss item: 0.17466750741004944
train loss item: 0.6605897545814514
train loss item: 0.11553570628166199
train loss item: 0.7396854162216187
train loss item: 0.2285119742155075
train loss item: 0.15545375645160675
train loss item: 0.8671631217002869
train loss item: 0.2861252427101135
train loss item: 0.3788702189922333
train loss item: 0.3102132976055145
train loss item: 0.2742173671722412
train loss item: 0.2545589506626129
train loss item: 0.27447256445884705
train loss item: 0.12026022374629974
train loss item: 0.6659929156303406
train loss item: 0.1677320897579193
train loss item: 0.10894176363945007
train loss item: 0.4394310414791107
train loss item: 0.3823707699775696
train loss item: 0.8869583010673523
train loss item: 0.2836077809333801
test loss item: 0.1746119111776352
test loss item: 0.2904742360115051
test loss item: 0.27779680490493774
test loss item: 0.6217815279960632
test loss item: 0.21827837824821472
test loss item: 0.4182421863079071
test loss item: 0.15391410887241364
test loss item: 0.16428209841251373
test loss item: 0.25035661458969116
test loss item: 0.3168385922908783
test loss item: 0.32131320238113403
test loss item: 0.22838300466537476
test loss item: 0.18252380192279816
test loss item: 0.2624492645263672
test loss item: 0.2782309651374817
test loss item: 0.37127071619033813
test loss item: 0.32707923650741577
test loss item: 0.266091912984848
test loss item: 0.6065648198127747
test loss item: 0.3074501156806946
test loss item: 0.20776589214801788
test loss item: 0.18681807816028595
test loss item: 0.3325122892856598
test loss item: 0.22529590129852295
test loss item: 0.3359275162220001
test loss item: 0.17777742445468903
test loss item: 0.17283155024051666
test loss item: 0.40435221791267395
test loss item: 0.3282018303871155
test loss item: 0.18606719374656677
test loss item: 0.23077870905399323
test loss item: 0.1905394345521927
test loss item: 0.4621371924877167
test loss item: 0.22808708250522614
test loss item: 0.29805752635002136
test loss item: 0.41056519746780396
test loss item: 0.2756608724594116
test loss item: 0.16249322891235352
test loss item: 0.60407555103302
test loss item: 0.2646363079547882
test loss item: 0.42142489552497864
test loss item: 0.5253686308860779
test loss item: 0.17305231094360352
test loss item: 0.09823846071958542
test loss item: 0.1757839471101761
Epoch [10/10], Training Loss: 0.3745, Testing Loss: 0.2915
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
loss item: 0.2647237181663513
loss item: 0.7631338834762573
loss item: 0.3070218861103058
loss item: 0.3334755599498749
loss item: 0.1506931185722351
loss item: 0.4812363088130951
loss item: 0.3268410861492157
loss item: 0.304599791765213
loss item: 0.3934396505355835
loss item: 0.4513406455516815
loss item: 0.21783077716827393
loss item: 0.17696844041347504
loss item: 0.35976114869117737
loss item: 0.3673264980316162
loss item: 0.2701767683029175
loss item: 0.6604085564613342
loss item: 0.23866544663906097
loss item: 0.1713944971561432
loss item: 0.22381280362606049
loss item: 0.29815787076950073
loss item: 0.430630624294281
loss item: 0.23854224383831024
Val Loss: 0.3377
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 10, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.005 4 360 done at Tue Nov 12 09:46:26 CET 2024
UNet2 with 1 10 0.0001 8 360 start at Tue Nov 12 09:46:26 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.4765785932540894
train loss item: 1.083484411239624
train loss item: 0.5838243365287781
train loss item: 0.812828540802002
train loss item: 0.5618910789489746
train loss item: 1.078084111213684
train loss item: 0.5615077018737793
train loss item: 1.6320184469223022
train loss item: 1.8999967575073242
train loss item: 0.5566858649253845
train loss item: 0.39754918217658997
train loss item: 0.5428510904312134
train loss item: 0.641681432723999
train loss item: 1.4390499591827393
train loss item: 0.44381245970726013
train loss item: 1.109988808631897
train loss item: 0.5536924004554749
train loss item: 0.5271103978157043
train loss item: 0.5418879389762878
train loss item: 0.7999544143676758
train loss item: 0.41836076974868774
train loss item: 1.768530249595642
train loss item: 0.45973601937294006
test loss item: 0.6564205288887024
test loss item: 1.1753612756729126
test loss item: 0.9327887892723083
test loss item: 0.23601214587688446
test loss item: 0.6325896978378296
test loss item: 0.6444830894470215
test loss item: 0.36974871158599854
test loss item: 0.9694143533706665
test loss item: 0.7612301707267761
test loss item: 1.3546137809753418
test loss item: 0.406040221452713
test loss item: 0.6077709197998047
test loss item: 0.7900437116622925
test loss item: 0.9120163321495056
test loss item: 0.5920053124427795
test loss item: 0.4564494788646698
test loss item: 0.9680256247520447
test loss item: 0.9331833124160767
test loss item: 0.4089297652244568
test loss item: 2.0261149406433105
test loss item: 1.6520882844924927
test loss item: 0.2741067111492157
test loss item: 0.1968715488910675
Epoch [1/10], Training Loss: 0.8648, Testing Loss: 0.7807
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/10
train loss item: 0.7417500615119934
train loss item: 0.5656790137290955
train loss item: 0.365988552570343
train loss item: 0.44126635789871216
train loss item: 0.3789122998714447
train loss item: 0.618120551109314
train loss item: 0.3926723301410675
train loss item: 1.0211806297302246
train loss item: 1.2836291790008545
train loss item: 0.4075939655303955
train loss item: 0.29767176508903503
train loss item: 0.37050122022628784
train loss item: 0.4769611656665802
train loss item: 1.0178533792495728
train loss item: 0.3016112744808197
train loss item: 0.8293887972831726
train loss item: 0.4290391504764557
train loss item: 0.3414711356163025
train loss item: 0.33933156728744507
train loss item: 0.6073342561721802
train loss item: 0.329913467168808
train loss item: 1.4259922504425049
train loss item: 0.4048585593700409
test loss item: 0.3749174177646637
test loss item: 0.5841132402420044
test loss item: 0.5142123103141785
test loss item: 0.21610724925994873
test loss item: 0.4151616096496582
test loss item: 0.428355872631073
test loss item: 0.2773471176624298
test loss item: 0.4989481270313263
test loss item: 0.5812373161315918
test loss item: 0.7112188339233398
test loss item: 0.32378068566322327
test loss item: 0.416506290435791
test loss item: 0.4621787965297699
test loss item: 0.5079854130744934
test loss item: 0.42758679389953613
test loss item: 0.32240381836891174
test loss item: 0.4743603765964508
test loss item: 0.5154066681861877
test loss item: 0.27740713953971863
test loss item: 0.8332746028900146
test loss item: 0.8047391176223755
test loss item: 0.22709102928638458
test loss item: 0.23143629729747772
Epoch [2/10], Training Loss: 0.5821, Testing Loss: 0.4533
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/10
train loss item: 0.5836189985275269
train loss item: 0.460042804479599
train loss item: 0.322931706905365
train loss item: 0.3822566568851471
train loss item: 0.3139364719390869
train loss item: 0.5080469846725464
train loss item: 0.33512434363365173
train loss item: 0.8311465382575989
train loss item: 1.0217022895812988
train loss item: 0.35656672716140747
train loss item: 0.26793476939201355
train loss item: 0.32368218898773193
train loss item: 0.440357506275177
train loss item: 0.7826980352401733
train loss item: 0.2696899175643921
train loss item: 0.6817733645439148
train loss item: 0.3956076502799988
train loss item: 0.30178457498550415
train loss item: 0.2923298180103302
train loss item: 0.5213814973831177
train loss item: 0.29002702236175537
train loss item: 1.2048746347427368
train loss item: 0.36062705516815186
test loss item: 0.3052310347557068
test loss item: 0.5369422435760498
test loss item: 0.42228224873542786
test loss item: 0.20859259366989136
test loss item: 0.3693908751010895
test loss item: 0.3489859402179718
test loss item: 0.2530066967010498
test loss item: 0.43169352412223816
test loss item: 0.4590947926044464
test loss item: 0.572840690612793
test loss item: 0.27380311489105225
test loss item: 0.3643897771835327
test loss item: 0.3962213695049286
test loss item: 0.41734927892684937
test loss item: 0.36088645458221436
test loss item: 0.28456392884254456
test loss item: 0.40941131114959717
test loss item: 0.4483882188796997
test loss item: 0.26715075969696045
test loss item: 0.6281399726867676
test loss item: 0.670803427696228
test loss item: 0.21077226102352142
test loss item: 0.2520347833633423
Epoch [3/10], Training Loss: 0.4890, Testing Loss: 0.3866
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/10
train loss item: 0.5281833410263062
train loss item: 0.4317452907562256
train loss item: 0.29037660360336304
train loss item: 0.3437061905860901
train loss item: 0.27024078369140625
train loss item: 0.46432939171791077
train loss item: 0.2984854578971863
train loss item: 0.7213901281356812
train loss item: 0.8398179411888123
train loss item: 0.32816269993782043
train loss item: 0.24559886753559113
train loss item: 0.3110804557800293
train loss item: 0.4126107394695282
train loss item: 0.6318047642707825
train loss item: 0.2331475168466568
train loss item: 0.5893158316612244
train loss item: 0.3473173975944519
train loss item: 0.2793399691581726
train loss item: 0.24662169814109802
train loss item: 0.47092384099960327
train loss item: 0.25547516345977783
train loss item: 1.0721052885055542
train loss item: 0.31800419092178345
test loss item: 0.28926870226860046
test loss item: 0.5087223649024963
test loss item: 0.37412479519844055
test loss item: 0.2075520157814026
test loss item: 0.3454647958278656
test loss item: 0.3141767382621765
test loss item: 0.24933460354804993
test loss item: 0.39173218607902527
test loss item: 0.40807682275772095
test loss item: 0.5108515024185181
test loss item: 0.2517012357711792
test loss item: 0.3276495635509491
test loss item: 0.3641481399536133
test loss item: 0.3769974112510681
test loss item: 0.32736289501190186
test loss item: 0.2654727101325989
test loss item: 0.3831939995288849
test loss item: 0.41253769397735596
test loss item: 0.25438034534454346
test loss item: 0.5344184637069702
test loss item: 0.5921187400817871
test loss item: 0.211030051112175
test loss item: 0.3621618449687958
Epoch [4/10], Training Loss: 0.4317, Testing Loss: 0.3592
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/10
train loss item: 0.47892698645591736
train loss item: 0.39972272515296936
train loss item: 0.2865172326564789
train loss item: 0.3277915418148041
train loss item: 0.24260197579860687
train loss item: 0.42092201113700867
train loss item: 0.27311697602272034
train loss item: 0.6216449737548828
train loss item: 0.6964719295501709
train loss item: 0.30150866508483887
train loss item: 0.22281934320926666
train loss item: 0.2823345363140106
train loss item: 0.38671550154685974
train loss item: 0.5315948128700256
train loss item: 0.22176602482795715
train loss item: 0.5175883769989014
train loss item: 0.3155915141105652
train loss item: 0.2645622193813324
train loss item: 0.2243748903274536
train loss item: 0.4247480034828186
train loss item: 0.24222224950790405
train loss item: 0.9605743288993835
train loss item: 0.2864496111869812
test loss item: 0.2681131362915039
test loss item: 0.451811820268631
test loss item: 0.33482876420021057
test loss item: 0.19554294645786285
test loss item: 0.30788442492485046
test loss item: 0.2816539704799652
test loss item: 0.22538264095783234
test loss item: 0.3471445143222809
test loss item: 0.3609934449195862
test loss item: 0.45546281337738037
test loss item: 0.22189854085445404
test loss item: 0.2940639853477478
test loss item: 0.3267595171928406
test loss item: 0.33665940165519714
test loss item: 0.2960127294063568
test loss item: 0.23934830725193024
test loss item: 0.347905695438385
test loss item: 0.3671259582042694
test loss item: 0.2324514538049698
test loss item: 0.4746415913105011
test loss item: 0.5223944783210754
test loss item: 0.191764235496521
test loss item: 0.286038875579834
Epoch [5/10], Training Loss: 0.3883, Testing Loss: 0.3203
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/10
train loss item: 0.435422420501709
train loss item: 0.36739614605903625
train loss item: 0.2692262828350067
train loss item: 0.31787559390068054
train loss item: 0.22158408164978027
train loss item: 0.39404919743537903
train loss item: 0.24779339134693146
train loss item: 0.5712112188339233
train loss item: 0.6255072951316833
train loss item: 0.28577330708503723
train loss item: 0.22145067155361176
train loss item: 0.2787756025791168
train loss item: 0.3726474642753601
train loss item: 0.44578418135643005
train loss item: 0.2032674103975296
train loss item: 0.45304372906684875
train loss item: 0.30671411752700806
train loss item: 0.26673218607902527
train loss item: 0.21435992419719696
train loss item: 0.4000987708568573
train loss item: 0.24644064903259277
train loss item: 0.888120174407959
train loss item: 0.27682244777679443
test loss item: 0.2834940552711487
test loss item: 0.4554317891597748
test loss item: 0.36500316858291626
test loss item: 0.18664152920246124
test loss item: 0.293560653924942
test loss item: 0.26825252175331116
test loss item: 0.22290758788585663
test loss item: 0.3665391504764557
test loss item: 0.3571268916130066
test loss item: 0.4943573474884033
test loss item: 0.21391956508159637
test loss item: 0.2641841769218445
test loss item: 0.3290248215198517
test loss item: 0.3599393665790558
test loss item: 0.2939949035644531
test loss item: 0.23176777362823486
test loss item: 0.3627004325389862
test loss item: 0.3647245168685913
test loss item: 0.22026026248931885
test loss item: 0.6238955855369568
test loss item: 0.5884270668029785
test loss item: 0.18897327780723572
test loss item: 0.29573673009872437
Epoch [6/10], Training Loss: 0.3613, Testing Loss: 0.3318
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/10
train loss item: 0.3825624883174896
train loss item: 0.3148273527622223
train loss item: 0.2603245675563812
train loss item: 0.30860137939453125
train loss item: 0.20929054915905
train loss item: 0.3598375916481018
train loss item: 0.23363979160785675
train loss item: 0.4887494444847107
train loss item: 0.5538703799247742
train loss item: 0.26717397570610046
train loss item: 0.18641993403434753
train loss item: 0.2340330332517624
train loss item: 0.32728111743927
train loss item: 0.39788299798965454
train loss item: 0.1802392601966858
train loss item: 0.40818336606025696
train loss item: 0.27619147300720215
train loss item: 0.2598611116409302
train loss item: 0.20155298709869385
train loss item: 0.3630409240722656
train loss item: 0.24135839939117432
train loss item: 0.8075783252716064
train loss item: 0.27323487401008606
test loss item: 0.26877105236053467
test loss item: 0.44425004720687866
test loss item: 0.35942625999450684
test loss item: 0.16721484065055847
test loss item: 0.2811721861362457
test loss item: 0.26967039704322815
test loss item: 0.19808104634284973
test loss item: 0.3552539348602295
test loss item: 0.3388080596923828
test loss item: 0.49028724431991577
test loss item: 0.2230607122182846
test loss item: 0.2547677457332611
test loss item: 0.30006441473960876
test loss item: 0.348059743642807
test loss item: 0.27975305914878845
test loss item: 0.21007217466831207
test loss item: 0.37165385484695435
test loss item: 0.36671143770217896
test loss item: 0.22466892004013062
test loss item: 0.6670399308204651
test loss item: 0.5989232063293457
test loss item: 0.1703696846961975
test loss item: 0.2291974127292633
Epoch [7/10], Training Loss: 0.3276, Testing Loss: 0.3225
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/10
train loss item: 0.35498693585395813
train loss item: 0.27661773562431335
train loss item: 0.2507956624031067
train loss item: 0.2905431389808655
train loss item: 0.19189584255218506
train loss item: 0.3691663146018982
train loss item: 0.263126015663147
train loss item: 0.4863158166408539
train loss item: 0.526951253414154
train loss item: 0.277037650346756
train loss item: 0.18981313705444336
train loss item: 0.26853320002555847
train loss item: 0.34457796812057495
train loss item: 0.35030633211135864
train loss item: 0.16632866859436035
train loss item: 0.3841131031513214
train loss item: 0.25254303216934204
train loss item: 0.24747836589813232
train loss item: 0.1979285180568695
train loss item: 0.37553420662879944
train loss item: 0.2490677535533905
train loss item: 0.7715502977371216
train loss item: 0.2680889964103699
test loss item: 0.2663212716579437
test loss item: 0.42561075091362
test loss item: 0.37544798851013184
test loss item: 0.13880577683448792
test loss item: 0.25617116689682007
test loss item: 0.2324955016374588
test loss item: 0.16949903964996338
test loss item: 0.36494341492652893
test loss item: 0.31659290194511414
test loss item: 0.5230133533477783
test loss item: 0.18099114298820496
test loss item: 0.2141830325126648
test loss item: 0.2983261048793793
test loss item: 0.35991957783699036
test loss item: 0.2703776955604553
test loss item: 0.18631304800510406
test loss item: 0.38154688477516174
test loss item: 0.36037954688072205
test loss item: 0.1726294308900833
test loss item: 0.798258364200592
test loss item: 0.6579353213310242
test loss item: 0.1453174352645874
test loss item: 0.15778020024299622
Epoch [8/10], Training Loss: 0.3197, Testing Loss: 0.3153
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/10
train loss item: 0.32561632990837097
train loss item: 0.2447439730167389
train loss item: 0.24230165779590607
train loss item: 0.2652389407157898
train loss item: 0.19050459563732147
train loss item: 0.31225723028182983
train loss item: 0.2519325911998749
train loss item: 0.4136081337928772
train loss item: 0.44616204500198364
train loss item: 0.22507734596729279
train loss item: 0.16776694357395172
train loss item: 0.220158189535141
train loss item: 0.2912244498729706
train loss item: 0.3106955587863922
train loss item: 0.1553719937801361
train loss item: 0.3373541831970215
train loss item: 0.24508671462535858
train loss item: 0.2344696968793869
train loss item: 0.18031184375286102
train loss item: 0.3375830352306366
train loss item: 0.2286861091852188
train loss item: 0.7292516827583313
train loss item: 0.2499716877937317
test loss item: 0.22020649909973145
test loss item: 0.4375167489051819
test loss item: 0.358296275138855
test loss item: 0.12402510643005371
test loss item: 0.24307824671268463
test loss item: 0.20646925270557404
test loss item: 0.1556151807308197
test loss item: 0.3582001328468323
test loss item: 0.26221930980682373
test loss item: 0.49292004108428955
test loss item: 0.16699953377246857
test loss item: 0.20187635719776154
test loss item: 0.27578145265579224
test loss item: 0.3084455728530884
test loss item: 0.25128501653671265
test loss item: 0.1677224487066269
test loss item: 0.3451710641384125
test loss item: 0.3445272445678711
test loss item: 0.16494855284690857
test loss item: 0.7660565376281738
test loss item: 0.6412145495414734
test loss item: 0.13417299091815948
test loss item: 0.16471776366233826
Epoch [9/10], Training Loss: 0.2872, Testing Loss: 0.2953
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/10
train loss item: 0.28392836451530457
train loss item: 0.209515780210495
train loss item: 0.19540072977542877
train loss item: 0.23469007015228271
train loss item: 0.16688749194145203
train loss item: 0.2732012867927551
train loss item: 0.2021365612745285
train loss item: 0.35319235920906067
train loss item: 0.3911067247390747
train loss item: 0.21470654010772705
train loss item: 0.15046168863773346
train loss item: 0.2067679464817047
train loss item: 0.2693334221839905
train loss item: 0.2631031274795532
train loss item: 0.14134299755096436
train loss item: 0.2913076877593994
train loss item: 0.2116931825876236
train loss item: 0.20072545111179352
train loss item: 0.16184565424919128
train loss item: 0.3039773106575012
train loss item: 0.20623347163200378
train loss item: 0.6457330584526062
train loss item: 0.23005300760269165
test loss item: 0.16960111260414124
test loss item: 0.38934972882270813
test loss item: 0.24446910619735718
test loss item: 0.12984755635261536
test loss item: 0.23816046118736267
test loss item: 0.2001281976699829
test loss item: 0.14955294132232666
test loss item: 0.2680019736289978
test loss item: 0.2271704375743866
test loss item: 0.3401469886302948
test loss item: 0.16321809589862823
test loss item: 0.20453977584838867
test loss item: 0.22165893018245697
test loss item: 0.20569393038749695
test loss item: 0.2201698273420334
test loss item: 0.16511590778827667
test loss item: 0.2610361576080322
test loss item: 0.316177099943161
test loss item: 0.17664416134357452
test loss item: 0.3924379050731659
test loss item: 0.42043545842170715
test loss item: 0.1349729597568512
test loss item: 0.13761888444423676
Epoch [10/10], Training Loss: 0.2525, Testing Loss: 0.2337
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
loss item: 0.3326685130596161
loss item: 0.29523301124572754
loss item: 0.27067437767982483
loss item: 0.25426098704338074
loss item: 0.30103105306625366
loss item: 0.16986411809921265
loss item: 0.28874409198760986
loss item: 0.44036269187927246
loss item: 0.20618824660778046
loss item: 0.26222947239875793
loss item: 0.3033929765224457
Val Loss: 0.2841
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.0001 8 360 done at Tue Nov 12 09:48:57 CET 2024
UNet2 with 1 10 0.0005 8 360 start at Tue Nov 12 09:48:57 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.4765785932540894
train loss item: 0.904321551322937
train loss item: 0.506412148475647
train loss item: 0.6584682464599609
train loss item: 0.4671843647956848
train loss item: 0.8639015555381775
train loss item: 0.43315255641937256
train loss item: 1.1930599212646484
train loss item: 1.2821385860443115
train loss item: 0.7095414996147156
train loss item: 0.9180285334587097
train loss item: 0.7061329483985901
train loss item: 0.5991091728210449
train loss item: 1.0077309608459473
train loss item: 0.429999977350235
train loss item: 0.9447888135910034
train loss item: 0.4559365510940552
train loss item: 0.4064919650554657
train loss item: 0.331018328666687
train loss item: 0.807661235332489
train loss item: 0.41120532155036926
train loss item: 1.6168450117111206
train loss item: 0.4986988306045532
test loss item: 0.5259818434715271
test loss item: 0.8812240958213806
test loss item: 0.7652322053909302
test loss item: 0.22267933189868927
test loss item: 0.5283342003822327
test loss item: 0.5128481388092041
test loss item: 0.3455928862094879
test loss item: 0.7488954067230225
test loss item: 0.6395062208175659
test loss item: 1.0549241304397583
test loss item: 0.3595289885997772
test loss item: 0.49711906909942627
test loss item: 0.6538893580436707
test loss item: 0.7323530316352844
test loss item: 0.4788155257701874
test loss item: 0.40056443214416504
test loss item: 0.7099559903144836
test loss item: 0.7090582847595215
test loss item: 0.3339361548423767
test loss item: 1.4124622344970703
test loss item: 1.240813970565796
test loss item: 0.2627544403076172
test loss item: 0.2596072852611542
Epoch [1/10], Training Loss: 0.7665, Testing Loss: 0.6207
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/10
train loss item: 0.646149218082428
train loss item: 0.43746787309646606
train loss item: 0.34368908405303955
train loss item: 0.43127045035362244
train loss item: 0.38523024320602417
train loss item: 0.5840773582458496
train loss item: 0.3757498562335968
train loss item: 0.9363458156585693
train loss item: 1.1803456544876099
train loss item: 0.4603957533836365
train loss item: 0.3437851071357727
train loss item: 0.39224717020988464
train loss item: 0.47737228870391846
train loss item: 0.7694383859634399
train loss item: 0.2511711120605469
train loss item: 0.7730098366737366
train loss item: 0.41317009925842285
train loss item: 0.31543684005737305
train loss item: 0.22735552489757538
train loss item: 0.6817494034767151
train loss item: 0.27873894572257996
train loss item: 1.3096625804901123
train loss item: 0.38925567269325256
test loss item: 0.3233293294906616
test loss item: 0.6724013686180115
test loss item: 0.4798464775085449
test loss item: 0.20409585535526276
test loss item: 0.40932393074035645
test loss item: 0.35491448640823364
test loss item: 0.26095739006996155
test loss item: 0.48254141211509705
test loss item: 0.5102272033691406
test loss item: 0.6587272882461548
test loss item: 0.2686009407043457
test loss item: 0.34191209077835083
test loss item: 0.43898606300354004
test loss item: 0.45015519857406616
test loss item: 0.41564303636550903
test loss item: 0.2971726059913635
test loss item: 0.44371727108955383
test loss item: 0.5497668385505676
test loss item: 0.2395653873682022
test loss item: 0.6804041266441345
test loss item: 0.7888192534446716
test loss item: 0.20539237558841705
test loss item: 0.2737824022769928
Epoch [2/10], Training Loss: 0.5393, Testing Loss: 0.4239
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/10
train loss item: 0.5702334046363831
train loss item: 0.47487086057662964
train loss item: 0.32472917437553406
train loss item: 0.32024380564689636
train loss item: 0.27235034108161926
train loss item: 0.4972633421421051
train loss item: 0.3153633773326874
train loss item: 0.7744437456130981
train loss item: 0.7985025644302368
train loss item: 0.34334683418273926
train loss item: 0.22557611763477325
train loss item: 0.26109716296195984
train loss item: 0.3857494592666626
train loss item: 0.6142398118972778
train loss item: 0.17273133993148804
train loss item: 0.5602481961250305
train loss item: 0.348443865776062
train loss item: 0.28703176975250244
train loss item: 0.23071928322315216
train loss item: 0.5566060543060303
train loss item: 0.24255461990833282
train loss item: 0.9719066023826599
train loss item: 0.2893982231616974
test loss item: 0.24595551192760468
test loss item: 0.4175114631652832
test loss item: 0.35275670886039734
test loss item: 0.138462096452713
test loss item: 0.29462167620658875
test loss item: 0.2717451751232147
test loss item: 0.20182305574417114
test loss item: 0.33898451924324036
test loss item: 0.3379646837711334
test loss item: 0.47094467282295227
test loss item: 0.21542342007160187
test loss item: 0.2665894031524658
test loss item: 0.3020532429218292
test loss item: 0.3278811275959015
test loss item: 0.27052125334739685
test loss item: 0.22377516329288483
test loss item: 0.3571309745311737
test loss item: 0.3484717905521393
test loss item: 0.19307176768779755
test loss item: 0.6104274988174438
test loss item: 0.5661630034446716
test loss item: 0.15907268226146698
test loss item: 0.1896510273218155
Epoch [3/10], Training Loss: 0.4277, Testing Loss: 0.3087
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/10
train loss item: 0.45562443137168884
train loss item: 0.34325286746025085
train loss item: 0.2426314800977707
train loss item: 0.30251944065093994
train loss item: 0.21644629538059235
train loss item: 0.36790886521339417
train loss item: 0.27396655082702637
train loss item: 0.46329668164253235
train loss item: 0.5496596693992615
train loss item: 0.5395334362983704
train loss item: 0.34572988748550415
train loss item: 0.31916847825050354
train loss item: 0.33370691537857056
train loss item: 0.634696364402771
train loss item: 0.21721574664115906
train loss item: 0.6400171518325806
train loss item: 0.251498281955719
train loss item: 0.24310185015201569
train loss item: 0.19374173879623413
train loss item: 0.47896608710289
train loss item: 0.2271011471748352
train loss item: 0.7794975638389587
train loss item: 0.3810238540172577
test loss item: 0.25956106185913086
test loss item: 0.4672168791294098
test loss item: 0.38382381200790405
test loss item: 0.14306063950061798
test loss item: 0.3136252760887146
test loss item: 0.26761990785598755
test loss item: 0.1824907660484314
test loss item: 0.37867939472198486
test loss item: 0.3529466986656189
test loss item: 0.5340526700019836
test loss item: 0.22433942556381226
test loss item: 0.25278693437576294
test loss item: 0.2946244180202484
test loss item: 0.35582098364830017
test loss item: 0.31025710701942444
test loss item: 0.19843709468841553
test loss item: 0.4273230731487274
test loss item: 0.4160490334033966
test loss item: 0.1942237913608551
test loss item: 0.7960453033447266
test loss item: 0.6904809474945068
test loss item: 0.16237911581993103
test loss item: 0.28418511152267456
Epoch [4/10], Training Loss: 0.3826, Testing Loss: 0.3430
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/10
train loss item: 0.4627298414707184
train loss item: 0.3363535404205322
train loss item: 0.2185729593038559
train loss item: 0.295855849981308
train loss item: 0.2240525335073471
train loss item: 0.4647134244441986
train loss item: 0.2707350552082062
train loss item: 0.5724075436592102
train loss item: 0.518492579460144
train loss item: 0.47081467509269714
train loss item: 0.3736874759197235
train loss item: 0.4487855136394501
train loss item: 0.4400726556777954
train loss item: 0.3375642001628876
train loss item: 0.17595160007476807
train loss item: 0.4535883069038391
train loss item: 0.2087043970823288
train loss item: 0.20798560976982117
train loss item: 0.15593762695789337
train loss item: 0.5299893021583557
train loss item: 0.23609915375709534
train loss item: 0.8019330501556396
train loss item: 0.2711491286754608
test loss item: 0.18252615630626678
test loss item: 0.46297597885131836
test loss item: 0.24526987969875336
test loss item: 0.1252317875623703
test loss item: 0.2680961489677429
test loss item: 0.22057005763053894
test loss item: 0.15055762231349945
test loss item: 0.28010109066963196
test loss item: 0.24049600958824158
test loss item: 0.3725349009037018
test loss item: 0.1762317419052124
test loss item: 0.20063196122646332
test loss item: 0.222720205783844
test loss item: 0.21716803312301636
test loss item: 0.24353894591331482
test loss item: 0.168294757604599
test loss item: 0.27396321296691895
test loss item: 0.3572766184806824
test loss item: 0.17331121861934662
test loss item: 0.3779497742652893
test loss item: 0.45298081636428833
test loss item: 0.13635887205600739
test loss item: 0.3105308413505554
Epoch [5/10], Training Loss: 0.3685, Testing Loss: 0.2548
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/10
train loss item: 0.3525557219982147
train loss item: 0.28993070125579834
train loss item: 0.21043084561824799
train loss item: 0.20681120455265045
train loss item: 0.15451326966285706
train loss item: 0.34986069798469543
train loss item: 0.24790212512016296
train loss item: 0.5114298462867737
train loss item: 0.3958980441093445
train loss item: 0.2890373468399048
train loss item: 0.1805766522884369
train loss item: 0.22035284340381622
train loss item: 0.2923964560031891
train loss item: 0.24060599505901337
train loss item: 0.12315607070922852
train loss item: 0.30887746810913086
train loss item: 0.2096823900938034
train loss item: 0.18589869141578674
train loss item: 0.133903369307518
train loss item: 0.4328691065311432
train loss item: 0.17694121599197388
train loss item: 0.6586924195289612
train loss item: 0.19366076588630676
test loss item: 0.15426699817180634
test loss item: 0.3476596474647522
test loss item: 0.19176852703094482
test loss item: 0.12025521695613861
test loss item: 0.1895514875650406
test loss item: 0.1676361858844757
test loss item: 0.12871108949184418
test loss item: 0.211562842130661
test loss item: 0.18419715762138367
test loss item: 0.2757470905780792
test loss item: 0.13334710896015167
test loss item: 0.1483461707830429
test loss item: 0.16972962021827698
test loss item: 0.1708116978406906
test loss item: 0.18277688324451447
test loss item: 0.1331593245267868
test loss item: 0.21081140637397766
test loss item: 0.25380590558052063
test loss item: 0.12946122884750366
test loss item: 0.27220287919044495
test loss item: 0.3130112290382385
test loss item: 0.10718534886837006
test loss item: 0.19671761989593506
Epoch [6/10], Training Loss: 0.2768, Testing Loss: 0.1910
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/10
train loss item: 0.32555872201919556
train loss item: 0.21497906744480133
train loss item: 0.14866745471954346
train loss item: 0.18701061606407166
train loss item: 0.14049728214740753
train loss item: 0.25934746861457825
train loss item: 0.19468316435813904
train loss item: 0.30709290504455566
train loss item: 0.2554112374782562
train loss item: 0.311885267496109
train loss item: 0.1575358659029007
train loss item: 0.17992499470710754
train loss item: 0.23951144516468048
train loss item: 0.20659896731376648
train loss item: 0.1405148059129715
train loss item: 0.3030441105365753
train loss item: 0.1768285632133484
train loss item: 0.1733575165271759
train loss item: 0.13984131813049316
train loss item: 0.3352847099304199
train loss item: 0.15127824246883392
train loss item: 0.5354752540588379
train loss item: 0.1760980486869812
test loss item: 0.13826042413711548
test loss item: 0.2958555519580841
test loss item: 0.18446896970272064
test loss item: 0.11005322635173798
test loss item: 0.16363711655139923
test loss item: 0.153920978307724
test loss item: 0.11578797549009323
test loss item: 0.19334232807159424
test loss item: 0.16785477101802826
test loss item: 0.24696201086044312
test loss item: 0.1185421422123909
test loss item: 0.14619840681552887
test loss item: 0.167436882853508
test loss item: 0.16374850273132324
test loss item: 0.16671258211135864
test loss item: 0.1215277761220932
test loss item: 0.2063816636800766
test loss item: 0.2263036072254181
test loss item: 0.11752420663833618
test loss item: 0.28625771403312683
test loss item: 0.30209454894065857
test loss item: 0.10535407811403275
test loss item: 0.12601099908351898
Epoch [7/10], Training Loss: 0.2287, Testing Loss: 0.1750
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/10
train loss item: 0.3012543320655823
train loss item: 0.20037749409675598
train loss item: 0.15124835073947906
train loss item: 0.19189628958702087
train loss item: 0.1498374044895172
train loss item: 0.23290376365184784
train loss item: 0.1782134622335434
train loss item: 0.2549075484275818
train loss item: 0.2470044642686844
train loss item: 0.3479762077331543
train loss item: 0.17558394372463226
train loss item: 0.1654239296913147
train loss item: 0.2178492695093155
train loss item: 0.20187196135520935
train loss item: 0.14818845689296722
train loss item: 0.37684640288352966
train loss item: 0.15558870136737823
train loss item: 0.13934096693992615
train loss item: 0.12192875891923904
train loss item: 0.33646222949028015
train loss item: 0.17282699048519135
train loss item: 0.4316958487033844
train loss item: 0.1981968730688095
test loss item: 0.1437983363866806
test loss item: 0.24322709441184998
test loss item: 0.18382255733013153
test loss item: 0.0959974005818367
test loss item: 0.16204187273979187
test loss item: 0.14360186457633972
test loss item: 0.11268126219511032
test loss item: 0.1833123415708542
test loss item: 0.1660611927509308
test loss item: 0.23899421095848083
test loss item: 0.13025082647800446
test loss item: 0.13067510724067688
test loss item: 0.1573084145784378
test loss item: 0.1725132316350937
test loss item: 0.15371856093406677
test loss item: 0.12092222273349762
test loss item: 0.2014172077178955
test loss item: 0.19604329764842987
test loss item: 0.12494060397148132
test loss item: 0.3224906921386719
test loss item: 0.30743852257728577
test loss item: 0.11089477688074112
test loss item: 0.24979451298713684
Epoch [8/10], Training Loss: 0.2216, Testing Loss: 0.1762
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/10
train loss item: 0.3338316082954407
train loss item: 0.17771737277507782
train loss item: 0.1588924676179886
train loss item: 0.22411374747753143
train loss item: 0.17408092319965363
train loss item: 0.3877794146537781
train loss item: 0.21395277976989746
train loss item: 0.4650765061378479
train loss item: 0.2452603280544281
train loss item: 0.36681416630744934
train loss item: 0.2549988329410553
train loss item: 0.31607404351234436
train loss item: 0.257192999124527
train loss item: 0.3181667923927307
train loss item: 0.13541674613952637
train loss item: 0.34534984827041626
train loss item: 0.1687154471874237
train loss item: 0.16515670716762543
train loss item: 0.11993734538555145
train loss item: 0.39822518825531006
train loss item: 0.21850204467773438
train loss item: 0.5533841252326965
train loss item: 0.23953178524971008
test loss item: 0.1624395102262497
test loss item: 0.39077064394950867
test loss item: 0.20271635055541992
test loss item: 0.11896762996912003
test loss item: 0.2104427069425583
test loss item: 0.18920981884002686
test loss item: 0.16872777044773102
test loss item: 0.2503719627857208
test loss item: 0.20184193551540375
test loss item: 0.29027339816093445
test loss item: 0.16368892788887024
test loss item: 0.16960984468460083
test loss item: 0.21503379940986633
test loss item: 0.226335346698761
test loss item: 0.201276496052742
test loss item: 0.16468001902103424
test loss item: 0.25499337911605835
test loss item: 0.29053565859794617
test loss item: 0.1668405830860138
test loss item: 0.3116277754306793
test loss item: 0.36191806197166443
test loss item: 0.16376323997974396
test loss item: 0.3213746249675751
Epoch [9/10], Training Loss: 0.2712, Testing Loss: 0.2260
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/10
train loss item: 0.338926762342453
train loss item: 0.3018026053905487
train loss item: 0.22104722261428833
train loss item: 0.19400654733181
train loss item: 0.13727746903896332
train loss item: 0.3550010621547699
train loss item: 0.25028884410858154
train loss item: 0.5497902035713196
train loss item: 0.3238041400909424
train loss item: 0.16600939631462097
train loss item: 0.11922754347324371
train loss item: 0.1483672559261322
train loss item: 0.26534372568130493
train loss item: 0.23212747275829315
train loss item: 0.15061210095882416
train loss item: 0.2416793704032898
train loss item: 0.21183577179908752
train loss item: 0.13064569234848022
train loss item: 0.10517460852861404
train loss item: 0.49265915155410767
train loss item: 0.28493258357048035
train loss item: 0.7507374882698059
train loss item: 0.19929036498069763
test loss item: 0.17714014649391174
test loss item: 0.2566101551055908
test loss item: 0.23043875396251678
test loss item: 0.12219168990850449
test loss item: 0.1868738979101181
test loss item: 0.19066382944583893
test loss item: 0.14038875699043274
test loss item: 0.20967550575733185
test loss item: 0.17486175894737244
test loss item: 0.28723111748695374
test loss item: 0.1477000117301941
test loss item: 0.19551393389701843
test loss item: 0.19757981598377228
test loss item: 0.2059766948223114
test loss item: 0.17611373960971832
test loss item: 0.13474905490875244
test loss item: 0.24453771114349365
test loss item: 0.2106400728225708
test loss item: 0.18395757675170898
test loss item: 0.4013921916484833
test loss item: 0.3440716862678528
test loss item: 0.13483305275440216
test loss item: 0.12343262135982513
Epoch [10/10], Training Loss: 0.2683, Testing Loss: 0.2033
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
loss item: 0.3194289803504944
loss item: 0.21108272671699524
loss item: 0.1949305683374405
loss item: 0.19054293632507324
loss item: 0.2738131284713745
loss item: 0.18311674892902374
loss item: 0.24130426347255707
loss item: 0.364424467086792
loss item: 0.14868426322937012
loss item: 0.18655045330524445
loss item: 0.2993568778038025
Val Loss: 0.2376
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.0005 8 360 done at Tue Nov 12 09:51:27 CET 2024
UNet2 with 1 10 0.001 8 360 start at Tue Nov 12 09:51:27 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 10, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.4765785932540894
train loss item: 0.9321662187576294
train loss item: 0.5705680251121521
train loss item: 0.7235683798789978
train loss item: 0.48982417583465576
train loss item: 0.9598066806793213
train loss item: 0.43659016489982605
train loss item: 1.2260032892227173
train loss item: 1.3787102699279785
train loss item: 0.7917293310165405
train loss item: 0.9322169423103333
train loss item: 0.6345696449279785
train loss item: 0.7560602426528931
train loss item: 1.1498932838439941
train loss item: 0.3278881013393402
train loss item: 1.077573299407959
train loss item: 0.4689684212207794
train loss item: 0.5166193246841431
train loss item: 0.35709214210510254
train loss item: 0.9266363382339478
train loss item: 0.5574327707290649
train loss item: 1.6715219020843506
train loss item: 0.486640065908432
test loss item: 0.8900920748710632
test loss item: 1.806649923324585
test loss item: 1.2828243970870972
test loss item: 0.5111333131790161
test loss item: 1.2371248006820679
test loss item: 1.0926077365875244
test loss item: 0.56679368019104
test loss item: 1.1501104831695557
test loss item: 1.7554935216903687
test loss item: 1.8484928607940674
test loss item: 0.9038143157958984
test loss item: 0.8129539489746094
test loss item: 0.9455756545066833
test loss item: 1.179633617401123
test loss item: 1.4823050498962402
test loss item: 0.475413054227829
test loss item: 1.2059890031814575
test loss item: 1.6585445404052734
test loss item: 0.64629727602005
test loss item: 1.6239275932312012
test loss item: 2.2568092346191406
test loss item: 0.4669654071331024
test loss item: 0.6569624543190002
Epoch [1/10], Training Loss: 0.8195, Testing Loss: 1.1503
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/10
train loss item: 0.7198851704597473
train loss item: 0.5766774415969849
train loss item: 0.3693244457244873
train loss item: 0.47380316257476807
train loss item: 0.37415528297424316
train loss item: 0.7435067892074585
train loss item: 0.3544085621833801
train loss item: 1.0596643686294556
train loss item: 1.232591152191162
train loss item: 0.4808028042316437
train loss item: 0.39889079332351685
train loss item: 0.43824806809425354
train loss item: 0.5386667251586914
train loss item: 0.8641173839569092
train loss item: 0.2591363787651062
train loss item: 0.8595077991485596
train loss item: 0.4677795469760895
train loss item: 0.3627093434333801
train loss item: 0.262126088142395
train loss item: 0.8070115447044373
train loss item: 0.3673115074634552
train loss item: 1.401215672492981
train loss item: 0.39585059881210327
test loss item: 0.33737945556640625
test loss item: 0.6803757548332214
test loss item: 0.5224807858467102
test loss item: 0.15958459675312042
test loss item: 0.438453733921051
test loss item: 0.39053747057914734
test loss item: 0.2568058669567108
test loss item: 0.5029212236404419
test loss item: 0.5168474316596985
test loss item: 0.7240390181541443
test loss item: 0.30944234132766724
test loss item: 0.359069287776947
test loss item: 0.4218577444553375
test loss item: 0.48717018961906433
test loss item: 0.405526340007782
test loss item: 0.29365992546081543
test loss item: 0.48906639218330383
test loss item: 0.5646036863327026
test loss item: 0.24367626011371613
test loss item: 0.8112217783927917
test loss item: 0.8648074269294739
test loss item: 0.19702045619487762
test loss item: 0.2881266176700592
Epoch [2/10], Training Loss: 0.6003, Testing Loss: 0.4463
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/10
train loss item: 0.5857239365577698
train loss item: 0.47913631796836853
train loss item: 0.34196391701698303
train loss item: 0.3625548481941223
train loss item: 0.322047621011734
train loss item: 0.5890762805938721
train loss item: 0.33007514476776123
train loss item: 0.892874002456665
train loss item: 0.9750428795814514
train loss item: 0.40374162793159485
train loss item: 0.23625467717647552
train loss item: 0.311131089925766
train loss item: 0.43381816148757935
train loss item: 0.7189918160438538
train loss item: 0.20671994984149933
train loss item: 0.7044638991355896
train loss item: 0.41628825664520264
train loss item: 0.3068786859512329
train loss item: 0.21826574206352234
train loss item: 0.6536188125610352
train loss item: 0.30149081349372864
train loss item: 1.1437581777572632
train loss item: 0.32628604769706726
test loss item: 0.3164239227771759
test loss item: 0.5652851462364197
test loss item: 0.46206268668174744
test loss item: 0.17671112716197968
test loss item: 0.3733791708946228
test loss item: 0.359761118888855
test loss item: 0.2469884306192398
test loss item: 0.4529210925102234
test loss item: 0.4714938700199127
test loss item: 0.6134920120239258
test loss item: 0.29506415128707886
test loss item: 0.3338986933231354
test loss item: 0.3973461091518402
test loss item: 0.4507129192352295
test loss item: 0.3469497561454773
test loss item: 0.29272007942199707
test loss item: 0.42597338557243347
test loss item: 0.45541080832481384
test loss item: 0.23441563546657562
test loss item: 0.7079593539237976
test loss item: 0.7161606550216675
test loss item: 0.1908903419971466
test loss item: 0.2717518210411072
Epoch [3/10], Training Loss: 0.4896, Testing Loss: 0.3982
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/10
train loss item: 0.5228458642959595
train loss item: 0.42947816848754883
train loss item: 0.2872880697250366
train loss item: 0.35001304745674133
train loss item: 0.2899131774902344
train loss item: 0.4791066348552704
train loss item: 0.2831111550331116
train loss item: 0.6694863438606262
train loss item: 0.6924212574958801
train loss item: 0.6254570484161377
train loss item: 0.3395339846611023
train loss item: 0.3599051237106323
train loss item: 0.38609570264816284
train loss item: 0.6901715993881226
train loss item: 0.2499030977487564
train loss item: 0.7642113566398621
train loss item: 0.2852863073348999
train loss item: 0.2560964524745941
train loss item: 0.2003164440393448
train loss item: 0.5541471838951111
train loss item: 0.25212961435317993
train loss item: 0.8862177729606628
train loss item: 0.37143927812576294
test loss item: 0.2705531716346741
test loss item: 0.48720142245292664
test loss item: 0.423031747341156
test loss item: 0.13735458254814148
test loss item: 0.32907983660697937
test loss item: 0.276557058095932
test loss item: 0.20864078402519226
test loss item: 0.4274965524673462
test loss item: 0.35954558849334717
test loss item: 0.6025698781013489
test loss item: 0.21676217019557953
test loss item: 0.290805846452713
test loss item: 0.32221370935440063
test loss item: 0.37713536620140076
test loss item: 0.3080090880393982
test loss item: 0.22687669098377228
test loss item: 0.4496840238571167
test loss item: 0.40885546803474426
test loss item: 0.20672093331813812
test loss item: 0.9701879620552063
test loss item: 0.7683491706848145
test loss item: 0.1755107194185257
test loss item: 0.36274436116218567
Epoch [4/10], Training Loss: 0.4445, Testing Loss: 0.3742
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/10
train loss item: 0.5384072065353394
train loss item: 0.3676510751247406
train loss item: 0.24895644187927246
train loss item: 0.327865332365036
train loss item: 0.26798781752586365
train loss item: 0.505597710609436
train loss item: 0.29630738496780396
train loss item: 0.5945239067077637
train loss item: 0.5812534093856812
train loss item: 0.6535705924034119
train loss item: 0.4561678469181061
train loss item: 0.5079673528671265
train loss item: 0.367435485124588
train loss item: 0.4734421372413635
train loss item: 0.2440497875213623
train loss item: 0.6802853345870972
train loss item: 0.30604639649391174
train loss item: 0.2915448248386383
train loss item: 0.18607120215892792
train loss item: 0.5552102327346802
train loss item: 0.1966606080532074
train loss item: 0.7755084037780762
train loss item: 0.35261452198028564
test loss item: 0.25693389773368835
test loss item: 0.6362634301185608
test loss item: 0.3662925064563751
test loss item: 0.15442082285881042
test loss item: 0.3417651653289795
test loss item: 0.28926190733909607
test loss item: 0.22710475325584412
test loss item: 0.4193858802318573
test loss item: 0.3435114622116089
test loss item: 0.5583738684654236
test loss item: 0.2087879180908203
test loss item: 0.2760846018791199
test loss item: 0.3190973997116089
test loss item: 0.33902156352996826
test loss item: 0.3174228072166443
test loss item: 0.22639739513397217
test loss item: 0.4182337522506714
test loss item: 0.4764458239078522
test loss item: 0.21202200651168823
test loss item: 0.7432581186294556
test loss item: 0.6825604438781738
test loss item: 0.18403932452201843
test loss item: 0.28034594655036926
Epoch [5/10], Training Loss: 0.4250, Testing Loss: 0.3599
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/10
train loss item: 0.5585629940032959
train loss item: 0.5344494581222534
train loss item: 0.34899744391441345
train loss item: 0.3082354962825775
train loss item: 0.22890688478946686
train loss item: 0.5598739385604858
train loss item: 0.3085964322090149
train loss item: 0.8056288361549377
train loss item: 0.5848270654678345
train loss item: 0.35226064920425415
train loss item: 0.1975589543581009
train loss item: 0.23452666401863098
train loss item: 0.32209163904190063
train loss item: 0.3375929296016693
train loss item: 0.20615604519844055
train loss item: 0.44287624955177307
train loss item: 0.2652926743030548
train loss item: 0.21315178275108337
train loss item: 0.16516441106796265
train loss item: 0.53762286901474
train loss item: 0.2580186724662781
train loss item: 0.6853154897689819
train loss item: 0.284938782453537
test loss item: 0.2315720021724701
test loss item: 0.4646412432193756
test loss item: 0.3032532334327698
test loss item: 0.13924439251422882
test loss item: 0.26666226983070374
test loss item: 0.2470569610595703
test loss item: 0.20609250664710999
test loss item: 0.3299613296985626
test loss item: 0.2876373827457428
test loss item: 0.4399486482143402
test loss item: 0.1940801590681076
test loss item: 0.2270563393831253
test loss item: 0.24952436983585358
test loss item: 0.28514406085014343
test loss item: 0.24138768017292023
test loss item: 0.19574418663978577
test loss item: 0.33208319544792175
test loss item: 0.340351939201355
test loss item: 0.18697066605091095
test loss item: 0.6058893203735352
test loss item: 0.5246335864067078
test loss item: 0.15954670310020447
test loss item: 0.15267521142959595
Epoch [6/10], Training Loss: 0.3800, Testing Loss: 0.2874
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/10
train loss item: 0.4021523594856262
train loss item: 0.3162161409854889
train loss item: 0.2723442614078522
train loss item: 0.3268522322177887
train loss item: 0.21911470592021942
train loss item: 0.41691023111343384
train loss item: 0.24997203052043915
train loss item: 0.5287351012229919
train loss item: 0.37710750102996826
train loss item: 0.47766461968421936
train loss item: 0.18727412819862366
train loss item: 0.1878996044397354
train loss item: 0.29421746730804443
train loss item: 0.3607800006866455
train loss item: 0.20136696100234985
train loss item: 0.39274635910987854
train loss item: 0.25384244322776794
train loss item: 0.20083652436733246
train loss item: 0.19266709685325623
train loss item: 0.4614376425743103
train loss item: 0.20531418919563293
train loss item: 0.5728633403778076
train loss item: 0.22268982231616974
test loss item: 0.19615289568901062
test loss item: 0.481764018535614
test loss item: 0.2989967167377472
test loss item: 0.11951272934675217
test loss item: 0.25567924976348877
test loss item: 0.20863138139247894
test loss item: 0.16439186036586761
test loss item: 0.31888848543167114
test loss item: 0.2509861886501312
test loss item: 0.430711954832077
test loss item: 0.17473486065864563
test loss item: 0.2152552306652069
test loss item: 0.24665547907352448
test loss item: 0.2540634870529175
test loss item: 0.22932513058185577
test loss item: 0.18319068849086761
test loss item: 0.3293408155441284
test loss item: 0.34540244936943054
test loss item: 0.1596243679523468
test loss item: 0.6464223861694336
test loss item: 0.5668483972549438
test loss item: 0.13962748646736145
test loss item: 0.2536185383796692
Epoch [7/10], Training Loss: 0.3183, Testing Loss: 0.2813
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/10
train loss item: 0.4189450740814209
train loss item: 0.30522671341896057
train loss item: 0.20396777987480164
train loss item: 0.2514228820800781
train loss item: 0.17994077503681183
train loss item: 0.3347015976905823
train loss item: 0.20005646347999573
train loss item: 0.3385167717933655
train loss item: 0.278639018535614
train loss item: 0.4125658869743347
train loss item: 0.17626959085464478
train loss item: 0.1907232254743576
train loss item: 0.25492557883262634
train loss item: 0.25476789474487305
train loss item: 0.13487157225608826
train loss item: 0.33062511682510376
train loss item: 0.21381478011608124
train loss item: 0.1730651557445526
train loss item: 0.17049281299114227
train loss item: 0.34431037306785583
train loss item: 0.18457676470279694
train loss item: 0.5556100010871887
train loss item: 0.22263680398464203
test loss item: 0.19097179174423218
test loss item: 0.286514014005661
test loss item: 0.2705909013748169
test loss item: 0.12387676537036896
test loss item: 0.20824222266674042
test loss item: 0.18826885521411896
test loss item: 0.14587140083312988
test loss item: 0.25525540113449097
test loss item: 0.21356524527072906
test loss item: 0.3744790852069855
test loss item: 0.13932961225509644
test loss item: 0.1927987039089203
test loss item: 0.22258500754833221
test loss item: 0.24290576577186584
test loss item: 0.205287903547287
test loss item: 0.16104045510292053
test loss item: 0.2880701422691345
test loss item: 0.23833085596561432
test loss item: 0.15873445570468903
test loss item: 0.5707091689109802
test loss item: 0.46413731575012207
test loss item: 0.12349166721105576
test loss item: 0.1659897118806839
Epoch [8/10], Training Loss: 0.2666, Testing Loss: 0.2361
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/10
train loss item: 0.3802889585494995
train loss item: 0.27206093072891235
train loss item: 0.16991247236728668
train loss item: 0.29638752341270447
train loss item: 0.23741382360458374
train loss item: 0.5567935705184937
train loss item: 0.24496160447597504
train loss item: 0.7605146765708923
train loss item: 0.38512521982192993
train loss item: 0.48402002453804016
train loss item: 0.3905779719352722
train loss item: 0.5678982734680176
train loss item: 0.4188593327999115
train loss item: 0.31763923168182373
train loss item: 0.20315849781036377
train loss item: 0.5621485710144043
train loss item: 0.25946202874183655
train loss item: 0.17660945653915405
train loss item: 0.16251502931118011
train loss item: 0.46363019943237305
train loss item: 0.20161591470241547
train loss item: 0.7525853514671326
train loss item: 0.26906776428222656
test loss item: 0.1697181761264801
test loss item: 0.3958494961261749
test loss item: 0.23475107550621033
test loss item: 0.14532159268856049
test loss item: 0.20542488992214203
test loss item: 0.1956602931022644
test loss item: 0.15181979537010193
test loss item: 0.26134949922561646
test loss item: 0.22014988958835602
test loss item: 0.31401947140693665
test loss item: 0.1515907645225525
test loss item: 0.18914474546909332
test loss item: 0.221982941031456
test loss item: 0.21134255826473236
test loss item: 0.20458614826202393
test loss item: 0.17503401637077332
test loss item: 0.2530139982700348
test loss item: 0.2789519429206848
test loss item: 0.15887142717838287
test loss item: 0.30555540323257446
test loss item: 0.3827064037322998
test loss item: 0.12580417096614838
test loss item: 0.20688292384147644
Epoch [9/10], Training Loss: 0.3710, Testing Loss: 0.2243
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/10
train loss item: 0.3346715271472931
train loss item: 0.2929723262786865
train loss item: 0.2416636347770691
train loss item: 0.19509001076221466
train loss item: 0.156550794839859
train loss item: 0.40651288628578186
train loss item: 0.20927360653877258
train loss item: 0.45220455527305603
train loss item: 0.3544653058052063
train loss item: 0.30481040477752686
train loss item: 0.1297157257795334
train loss item: 0.1752721071243286
train loss item: 0.2897919714450836
train loss item: 0.3201410472393036
train loss item: 0.12874630093574524
train loss item: 0.2718420624732971
train loss item: 0.19182844460010529
train loss item: 0.14839163422584534
train loss item: 0.1459731012582779
train loss item: 0.3529197871685028
train loss item: 0.16293473541736603
train loss item: 0.5676361918449402
train loss item: 0.21354849636554718
test loss item: 0.13014233112335205
test loss item: 0.3868257701396942
test loss item: 0.2147640436887741
test loss item: 0.08463709056377411
test loss item: 0.1947013884782791
test loss item: 0.15652233362197876
test loss item: 0.10899405926465988
test loss item: 0.2535930275917053
test loss item: 0.17891110479831696
test loss item: 0.3057962954044342
test loss item: 0.11475161463022232
test loss item: 0.1364891678094864
test loss item: 0.18655724823474884
test loss item: 0.17882861196994781
test loss item: 0.18416240811347961
test loss item: 0.12706705927848816
test loss item: 0.2034531980752945
test loss item: 0.27732229232788086
test loss item: 0.11255377531051636
test loss item: 0.33339723944664
test loss item: 0.3978010416030884
test loss item: 0.09949417412281036
test loss item: 0.11371277272701263
Epoch [10/10], Training Loss: 0.2629, Testing Loss: 0.1948
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
loss item: 0.288013219833374
loss item: 0.283623069524765
loss item: 0.24634744226932526
loss item: 0.241807758808136
loss item: 0.26077014207839966
loss item: 0.12481449544429779
loss item: 0.2660036087036133
loss item: 0.4174130856990814
loss item: 0.16110403835773468
loss item: 0.25586119294166565
loss item: 0.29606038331985474
Val Loss: 0.2583
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 10, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.001 8 360 done at Tue Nov 12 09:53:57 CET 2024
UNet2 with 1 10 0.005 8 360 start at Tue Nov 12 09:53:57 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 10, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.4765785932540894
train loss item: 1.488364577293396
train loss item: 1.227317452430725
train loss item: 0.9579159021377563
train loss item: 0.47981324791908264
train loss item: 1.0573915243148804
train loss item: 0.5085159540176392
train loss item: 1.6343568563461304
train loss item: 1.794062614440918
train loss item: 0.5039210319519043
train loss item: 0.5952209830284119
train loss item: 0.4662436246871948
train loss item: 0.6920085549354553
train loss item: 1.3686498403549194
train loss item: 0.4267558455467224
train loss item: 1.2039326429367065
train loss item: 0.47162064909935
train loss item: 0.5360599756240845
train loss item: 0.42717626690864563
train loss item: 1.0362893342971802
train loss item: 0.5555956363677979
train loss item: 1.9805022478103638
train loss item: 0.4602459967136383
test loss item: 0.6217797994613647
test loss item: 2.0337860584259033
test loss item: 1.213813066482544
test loss item: 0.38870155811309814
test loss item: 1.382132887840271
test loss item: 0.8165193200111389
test loss item: 0.5437419414520264
test loss item: 1.2737616300582886
test loss item: 1.3834030628204346
test loss item: 1.8372173309326172
test loss item: 0.592004120349884
test loss item: 0.9243448972702026
test loss item: 1.0557352304458618
test loss item: 1.036850929260254
test loss item: 1.3563196659088135
test loss item: 0.5631416440010071
test loss item: 1.1755098104476929
test loss item: 1.8684247732162476
test loss item: 0.6068812608718872
test loss item: 1.7190667390823364
test loss item: 2.2971298694610596
test loss item: 0.43986159563064575
test loss item: 0.6305710077285767
Epoch [1/10], Training Loss: 0.9282, Testing Loss: 1.1200
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/10
train loss item: 0.8817241191864014
train loss item: 0.6220057606697083
train loss item: 0.37252718210220337
train loss item: 0.48133644461631775
train loss item: 0.4621841609477997
train loss item: 0.7980542778968811
train loss item: 0.4550514817237854
train loss item: 1.257053017616272
train loss item: 1.5772531032562256
train loss item: 0.45303359627723694
train loss item: 0.451168030500412
train loss item: 0.4531153738498688
train loss item: 0.6032328009605408
train loss item: 1.275573492050171
train loss item: 0.3529285490512848
train loss item: 1.1563992500305176
train loss item: 0.4298779368400574
train loss item: 0.4244886636734009
train loss item: 0.2824743092060089
train loss item: 1.0078117847442627
train loss item: 0.5240007042884827
train loss item: 1.708648920059204
train loss item: 0.42949140071868896
test loss item: 0.442624032497406
test loss item: 0.8245567083358765
test loss item: 0.6602063179016113
test loss item: 0.20956861972808838
test loss item: 0.5388758182525635
test loss item: 0.4418867528438568
test loss item: 0.32372337579727173
test loss item: 0.6586329936981201
test loss item: 0.5979886054992676
test loss item: 0.9395972490310669
test loss item: 0.3086383044719696
test loss item: 0.4864426851272583
test loss item: 0.577355682849884
test loss item: 0.6563327312469482
test loss item: 0.4668954908847809
test loss item: 0.3657890260219574
test loss item: 0.6423410177230835
test loss item: 0.7166123986244202
test loss item: 0.2991071045398712
test loss item: 1.170305848121643
test loss item: 1.0574113130569458
test loss item: 0.21842075884342194
test loss item: 0.3052617013454437
Epoch [2/10], Training Loss: 0.7156, Testing Loss: 0.5612
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/10
train loss item: 0.7431809902191162
train loss item: 0.6191406846046448
train loss item: 0.43029603362083435
train loss item: 0.42559051513671875
train loss item: 0.4080215394496918
train loss item: 0.7563353776931763
train loss item: 0.3635371923446655
train loss item: 1.1390384435653687
train loss item: 1.3282111883163452
train loss item: 0.44343921542167664
train loss item: 0.3567367494106293
train loss item: 0.4475926160812378
train loss item: 0.5829280018806458
train loss item: 1.0786911249160767
train loss item: 0.330636203289032
train loss item: 1.0156275033950806
train loss item: 0.42239853739738464
train loss item: 0.3858896791934967
train loss item: 0.25743162631988525
train loss item: 0.9137788414955139
train loss item: 0.42193618416786194
train loss item: 1.4729211330413818
train loss item: 0.40966910123825073
test loss item: 0.3893614411354065
test loss item: 1.0323541164398193
test loss item: 0.72443687915802
test loss item: 0.23743866384029388
test loss item: 0.7091763019561768
test loss item: 0.42930880188941956
test loss item: 0.34910112619400024
test loss item: 0.7346993088722229
test loss item: 0.7086458802223206
test loss item: 1.0439419746398926
test loss item: 0.3099004924297333
test loss item: 0.5220818519592285
test loss item: 0.648734986782074
test loss item: 0.6613513827323914
test loss item: 0.6533994674682617
test loss item: 0.378279447555542
test loss item: 0.6705164313316345
test loss item: 0.9307916164398193
test loss item: 0.30650296807289124
test loss item: 1.1147801876068115
test loss item: 1.2291043996810913
test loss item: 0.23978836834430695
test loss item: 0.4042002558708191
Epoch [3/10], Training Loss: 0.6414, Testing Loss: 0.6273
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/10
train loss item: 0.7174620628356934
train loss item: 0.626370906829834
train loss item: 0.40952324867248535
train loss item: 0.4464689791202545
train loss item: 0.3397260308265686
train loss item: 0.7972732782363892
train loss item: 0.37226226925849915
train loss item: 1.0186164379119873
train loss item: 1.087173581123352
train loss item: 0.5898532271385193
train loss item: 0.43383219838142395
train loss item: 0.518644392490387
train loss item: 0.5865426063537598
train loss item: 0.9519888162612915
train loss item: 0.26932379603385925
train loss item: 1.0012365579605103
train loss item: 0.42180994153022766
train loss item: 0.3636658489704132
train loss item: 0.24974589049816132
train loss item: 0.869410514831543
train loss item: 0.39114290475845337
train loss item: 1.308923363685608
train loss item: 0.4488106369972229
test loss item: 0.46738114953041077
test loss item: 1.05255126953125
test loss item: 0.7785388231277466
test loss item: 0.22049495577812195
test loss item: 0.761809229850769
test loss item: 0.47466912865638733
test loss item: 0.34532245993614197
test loss item: 0.7612624764442444
test loss item: 0.7938814759254456
test loss item: 1.1449915170669556
test loss item: 0.3093205988407135
test loss item: 0.5632598400115967
test loss item: 0.6869807839393616
test loss item: 0.7593849897384644
test loss item: 0.7014322280883789
test loss item: 0.3816555142402649
test loss item: 0.7469164133071899
test loss item: 0.996607780456543
test loss item: 0.2980276644229889
test loss item: 1.279030680656433
test loss item: 1.3300002813339233
test loss item: 0.23272831737995148
test loss item: 0.23110859096050262
Epoch [4/10], Training Loss: 0.6183, Testing Loss: 0.6660
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/10
train loss item: 0.7039119601249695
train loss item: 0.574923574924469
train loss item: 0.3799315392971039
train loss item: 0.47770166397094727
train loss item: 0.35004091262817383
train loss item: 0.7785196900367737
train loss item: 0.383879691362381
train loss item: 0.9350206255912781
train loss item: 0.9613019824028015
train loss item: 0.5624580383300781
train loss item: 0.33632874488830566
train loss item: 0.4587704837322235
train loss item: 0.5480469465255737
train loss item: 0.8911879062652588
train loss item: 0.2724534571170807
train loss item: 0.914302408695221
train loss item: 0.4085254371166229
train loss item: 0.3735141158103943
train loss item: 0.2646847069263458
train loss item: 0.8681567311286926
train loss item: 0.3723757565021515
train loss item: 1.1929198503494263
train loss item: 0.43668046593666077
test loss item: 0.37410157918930054
test loss item: 0.9319489002227783
test loss item: 0.6321455240249634
test loss item: 0.1855507344007492
test loss item: 0.5884519815444946
test loss item: 0.4237440228462219
test loss item: 0.3056093156337738
test loss item: 0.6545339822769165
test loss item: 0.5989649295806885
test loss item: 0.9356948733329773
test loss item: 0.27890706062316895
test loss item: 0.4743272066116333
test loss item: 0.5543439388275146
test loss item: 0.5956098437309265
test loss item: 0.531182050704956
test loss item: 0.33013099431991577
test loss item: 0.6357483267784119
test loss item: 0.7942562699317932
test loss item: 0.27731576561927795
test loss item: 1.1459107398986816
test loss item: 1.1016350984573364
test loss item: 0.20692336559295654
test loss item: 0.20810559391975403
Epoch [5/10], Training Loss: 0.5846, Testing Loss: 0.5550
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/10
train loss item: 0.7258139848709106
train loss item: 0.5964581966400146
train loss item: 0.4212470054626465
train loss item: 0.45946282148361206
train loss item: 0.33255571126937866
train loss item: 0.8159078359603882
train loss item: 0.37336626648902893
train loss item: 1.3230717182159424
train loss item: 1.182820439338684
train loss item: 0.4841574728488922
train loss item: 0.32276782393455505
train loss item: 0.4924411177635193
train loss item: 0.6536904573440552
train loss item: 0.8118979334831238
train loss item: 0.27969956398010254
train loss item: 0.8857945799827576
train loss item: 0.4237791895866394
train loss item: 0.3810163736343384
train loss item: 0.2570098042488098
train loss item: 0.8441897630691528
train loss item: 0.39039427042007446
train loss item: 1.2285592555999756
train loss item: 0.4488706588745117
test loss item: 0.39778944849967957
test loss item: 0.9530107378959656
test loss item: 0.6834079623222351
test loss item: 0.21911463141441345
test loss item: 0.6431211233139038
test loss item: 0.4831697642803192
test loss item: 0.3239939510822296
test loss item: 0.6917904615402222
test loss item: 0.6468290090560913
test loss item: 1.0052273273468018
test loss item: 0.3000010848045349
test loss item: 0.5213977098464966
test loss item: 0.578122615814209
test loss item: 0.6294636726379395
test loss item: 0.5888211131095886
test loss item: 0.3422567844390869
test loss item: 0.7158852219581604
test loss item: 0.8656120896339417
test loss item: 0.3080834448337555
test loss item: 1.3518414497375488
test loss item: 1.221479058265686
test loss item: 0.22763673961162567
test loss item: 0.3262714743614197
Epoch [6/10], Training Loss: 0.6146, Testing Loss: 0.6098
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/10
train loss item: 0.7267663478851318
train loss item: 0.5698537230491638
train loss item: 0.3592057526111603
train loss item: 0.43740877509117126
train loss item: 0.35417819023132324
train loss item: 0.7272497415542603
train loss item: 0.35835132002830505
train loss item: 0.9326810836791992
train loss item: 0.9248903393745422
train loss item: 0.6234329342842102
train loss item: 0.36931127309799194
train loss item: 0.493334025144577
train loss item: 0.5250651836395264
train loss item: 0.7816253304481506
train loss item: 0.25263822078704834
train loss item: 0.8849621415138245
train loss item: 0.42843177914619446
train loss item: 0.4001248776912689
train loss item: 0.27313631772994995
train loss item: 0.8361257910728455
train loss item: 0.3223380744457245
train loss item: 1.1158024072647095
train loss item: 0.44738849997520447
test loss item: 0.35534361004829407
test loss item: 0.8205820322036743
test loss item: 0.5750560164451599
test loss item: 0.23612353205680847
test loss item: 0.5341339707374573
test loss item: 0.4210301637649536
test loss item: 0.33473560214042664
test loss item: 0.6047075986862183
test loss item: 0.5386766195297241
test loss item: 0.8434469699859619
test loss item: 0.28982749581336975
test loss item: 0.48102158308029175
test loss item: 0.5347752571105957
test loss item: 0.5691784620285034
test loss item: 0.4893149733543396
test loss item: 0.3581183850765228
test loss item: 0.6084527373313904
test loss item: 0.6960432529449463
test loss item: 0.30789896845817566
test loss item: 1.0774197578430176
test loss item: 0.9705296754837036
test loss item: 0.25533992052078247
test loss item: 0.12977609038352966
Epoch [7/10], Training Loss: 0.5715, Testing Loss: 0.5231
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/10
train loss item: 0.7272899746894836
train loss item: 0.5872588753700256
train loss item: 0.38175132870674133
train loss item: 0.4086724817752838
train loss item: 0.3289783000946045
train loss item: 0.7345446944236755
train loss item: 0.3569645285606384
train loss item: 0.9701979160308838
train loss item: 0.8142133951187134
train loss item: 0.4673137366771698
train loss item: 0.32667258381843567
train loss item: 0.42710763216018677
train loss item: 0.5883377194404602
train loss item: 0.6467156410217285
train loss item: 0.2946280837059021
train loss item: 0.8614826798439026
train loss item: 0.4490787088871002
train loss item: 0.2939826548099518
train loss item: 0.2462325543165207
train loss item: 0.8020029664039612
train loss item: 0.3233439028263092
train loss item: 0.9952220320701599
train loss item: 0.4318726062774658
test loss item: 0.34055477380752563
test loss item: 0.8369766473770142
test loss item: 0.6396313905715942
test loss item: 0.20721422135829926
test loss item: 0.6207358241081238
test loss item: 0.385470449924469
test loss item: 0.32290613651275635
test loss item: 0.6486676335334778
test loss item: 0.6326549649238586
test loss item: 0.9069697260856628
test loss item: 0.2713780999183655
test loss item: 0.4668465554714203
test loss item: 0.5623326897621155
test loss item: 0.6086522936820984
test loss item: 0.5785622000694275
test loss item: 0.34528642892837524
test loss item: 0.6217582821846008
test loss item: 0.8041443228721619
test loss item: 0.26715347170829773
test loss item: 1.1012139320373535
test loss item: 1.1010611057281494
test loss item: 0.2463863044977188
test loss item: 0.16404548287391663
Epoch [8/10], Training Loss: 0.5419, Testing Loss: 0.5513
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/10
train loss item: 0.7703940868377686
train loss item: 0.5334939360618591
train loss item: 0.3502785861492157
train loss item: 0.37166568636894226
train loss item: 0.3334176540374756
train loss item: 0.6909460425376892
train loss item: 0.3532652258872986
train loss item: 1.1528801918029785
train loss item: 1.1219911575317383
train loss item: 0.37457677721977234
train loss item: 0.2805066406726837
train loss item: 0.40913480520248413
train loss item: 0.6329443454742432
train loss item: 0.5845546126365662
train loss item: 0.2534327805042267
train loss item: 0.7026832103729248
train loss item: 0.4263654351234436
train loss item: 0.33342379331588745
train loss item: 0.28184860944747925
train loss item: 0.7777411341667175
train loss item: 0.31234097480773926
train loss item: 1.240585446357727
train loss item: 0.35906389355659485
test loss item: 0.38935062289237976
test loss item: 0.7134092450141907
test loss item: 0.6531888842582703
test loss item: 0.23014195263385773
test loss item: 0.5027258992195129
test loss item: 0.35743141174316406
test loss item: 0.3176245391368866
test loss item: 0.6231414079666138
test loss item: 0.574480414390564
test loss item: 0.8561421632766724
test loss item: 0.2829223573207855
test loss item: 0.3987257182598114
test loss item: 0.5682259202003479
test loss item: 0.6067259311676025
test loss item: 0.4729430377483368
test loss item: 0.3445263206958771
test loss item: 0.4997222423553467
test loss item: 0.6403508186340332
test loss item: 0.255167692899704
test loss item: 0.9317166209220886
test loss item: 1.013117790222168
test loss item: 0.23527471721172333
test loss item: 0.26719924807548523
Epoch [9/10], Training Loss: 0.5499, Testing Loss: 0.5102
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/10
train loss item: 0.6217573285102844
train loss item: 0.5123216509819031
train loss item: 0.3515888750553131
train loss item: 0.4296025335788727
train loss item: 0.3172314167022705
train loss item: 0.6446788907051086
train loss item: 0.3274358808994293
train loss item: 0.7559594511985779
train loss item: 0.7494234442710876
train loss item: 0.37548062205314636
train loss item: 0.23544816672801971
train loss item: 0.34681645035743713
train loss item: 0.436846524477005
train loss item: 0.5363389849662781
train loss item: 0.21451492607593536
train loss item: 0.6683383584022522
train loss item: 0.4061759114265442
train loss item: 0.3436148166656494
train loss item: 0.2299022674560547
train loss item: 0.7213573455810547
train loss item: 0.26962706446647644
train loss item: 0.842467188835144
train loss item: 0.3741322457790375
test loss item: 0.2845813035964966
test loss item: 0.5847358703613281
test loss item: 0.4401687681674957
test loss item: 0.15670783817768097
test loss item: 0.39349016547203064
test loss item: 0.33488333225250244
test loss item: 0.23750367760658264
test loss item: 0.44855281710624695
test loss item: 0.4153664708137512
test loss item: 0.63017338514328
test loss item: 0.23151730000972748
test loss item: 0.35347431898117065
test loss item: 0.3843998312950134
test loss item: 0.42891648411750793
test loss item: 0.33463162183761597
test loss item: 0.26053428649902344
test loss item: 0.4134325385093689
test loss item: 0.5011799335479736
test loss item: 0.23628869652748108
test loss item: 0.7150332927703857
test loss item: 0.6951538324356079
test loss item: 0.16753438115119934
test loss item: 0.17316603660583496
Epoch [10/10], Training Loss: 0.4657, Testing Loss: 0.3835
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
loss item: 0.7067322134971619
loss item: 0.43991467356681824
loss item: 0.36220288276672363
loss item: 0.41301819682121277
loss item: 0.5793180465698242
loss item: 0.2647506296634674
loss item: 0.49518275260925293
loss item: 0.7037320137023926
loss item: 0.26705631613731384
loss item: 0.3992477059364319
loss item: 0.5325415730476379
Val Loss: 0.4694
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 10, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.005 8 360 done at Tue Nov 12 09:56:27 CET 2024
UNet2 with 1 10 0.0001 16 360 start at Tue Nov 12 09:56:27 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.347920298576355
train loss item: 0.7567220330238342
train loss item: 0.9415144324302673
train loss item: 1.2658209800720215
train loss item: 1.3252041339874268
train loss item: 0.5795272588729858
train loss item: 1.2090576887130737
train loss item: 0.9306648969650269
train loss item: 0.5281984210014343
train loss item: 0.7622933983802795
train loss item: 1.252486228942871
train loss item: 0.5241486430168152
test loss item: 1.1635373830795288
test loss item: 0.8743120431900024
test loss item: 0.7483742833137512
test loss item: 0.7974737882614136
test loss item: 1.2985048294067383
test loss item: 0.570023238658905
test loss item: 0.9929193258285522
test loss item: 0.6190888285636902
test loss item: 1.1566652059555054
test loss item: 1.6485538482666016
test loss item: 1.5251150131225586
test loss item: 0.20283658802509308
Epoch [1/10], Training Loss: 0.9520, Testing Loss: 0.9665
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/10
train loss item: 0.7401988506317139
train loss item: 0.4863934814929962
train loss item: 0.599054217338562
train loss item: 0.754587709903717
train loss item: 0.8665329813957214
train loss item: 0.4313562214374542
train loss item: 0.7822306156158447
train loss item: 0.6246208548545837
train loss item: 0.5153311491012573
train loss item: 0.6471831202507019
train loss item: 0.9335834980010986
train loss item: 0.43342021107673645
test loss item: 0.880848228931427
test loss item: 0.6917149424552917
test loss item: 0.6116279363632202
test loss item: 0.6236787438392639
test loss item: 1.0314371585845947
test loss item: 0.4742750823497772
test loss item: 0.7905266880989075
test loss item: 0.5056158304214478
test loss item: 0.8801586627960205
test loss item: 1.2333225011825562
test loss item: 1.1637259721755981
test loss item: 0.24054406583309174
Epoch [2/10], Training Loss: 0.6512, Testing Loss: 0.7606
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/10
train loss item: 0.5782200694084167
train loss item: 0.4201120138168335
train loss item: 0.4758269190788269
train loss item: 0.6368111968040466
train loss item: 0.7149839401245117
train loss item: 0.3648892939090729
train loss item: 0.6342721581459045
train loss item: 0.5283299684524536
train loss item: 0.4298100471496582
train loss item: 0.5449725985527039
train loss item: 0.7565566897392273
train loss item: 0.395431786775589
test loss item: 0.5319501757621765
test loss item: 0.4183981120586395
test loss item: 0.4346845746040344
test loss item: 0.38244473934173584
test loss item: 0.6375440359115601
test loss item: 0.36071017384529114
test loss item: 0.4719291627407074
test loss item: 0.36257457733154297
test loss item: 0.5221804976463318
test loss item: 0.5786992311477661
test loss item: 0.621884822845459
test loss item: 0.25444474816322327
Epoch [3/10], Training Loss: 0.5400, Testing Loss: 0.4648
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/10
train loss item: 0.5396005511283875
train loss item: 0.41185733675956726
train loss item: 0.43653613328933716
train loss item: 0.5439848899841309
train loss item: 0.6010032892227173
train loss item: 0.3382870554924011
train loss item: 0.5531575083732605
train loss item: 0.48223984241485596
train loss item: 0.34177836775779724
train loss item: 0.4872194826602936
train loss item: 0.7226658463478088
train loss item: 0.36409419775009155
test loss item: 0.41494104266166687
test loss item: 0.33787810802459717
test loss item: 0.36477580666542053
test loss item: 0.31292518973350525
test loss item: 0.5127039551734924
test loss item: 0.30048948526382446
test loss item: 0.3697968125343323
test loss item: 0.31895679235458374
test loss item: 0.4262077510356903
test loss item: 0.48441505432128906
test loss item: 0.5073458552360535
test loss item: 0.29376649856567383
Epoch [4/10], Training Loss: 0.4852, Testing Loss: 0.3870
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/10
train loss item: 0.4667614996433258
train loss item: 0.35602954030036926
train loss item: 0.3905697464942932
train loss item: 0.4654618501663208
train loss item: 0.5137914419174194
train loss item: 0.33662980794906616
train loss item: 0.4598850905895233
train loss item: 0.4228249192237854
train loss item: 0.3118244409561157
train loss item: 0.4222519099712372
train loss item: 0.6273717284202576
train loss item: 0.3169131278991699
test loss item: 0.36404329538345337
test loss item: 0.31014958024024963
test loss item: 0.322428822517395
test loss item: 0.28472375869750977
test loss item: 0.46169647574424744
test loss item: 0.2684535086154938
test loss item: 0.3343240022659302
test loss item: 0.2909172475337982
test loss item: 0.37892231345176697
test loss item: 0.44105374813079834
test loss item: 0.45781704783439636
test loss item: 0.21189063787460327
Epoch [5/10], Training Loss: 0.4242, Testing Loss: 0.3439
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/10
train loss item: 0.42646029591560364
train loss item: 0.321542888879776
train loss item: 0.3541386127471924
train loss item: 0.4172070026397705
train loss item: 0.4470345377922058
train loss item: 0.2825626730918884
train loss item: 0.40221458673477173
train loss item: 0.37018683552742004
train loss item: 0.2941639721393585
train loss item: 0.39619678258895874
train loss item: 0.5370286107063293
train loss item: 0.2920563817024231
test loss item: 0.34206172823905945
test loss item: 0.306392103433609
test loss item: 0.28875958919525146
test loss item: 0.27712246775627136
test loss item: 0.4421752691268921
test loss item: 0.24570424854755402
test loss item: 0.31886026263237
test loss item: 0.2724485993385315
test loss item: 0.3653445243835449
test loss item: 0.4829641878604889
test loss item: 0.4696064293384552
test loss item: 0.20959006249904633
Epoch [6/10], Training Loss: 0.3784, Testing Loss: 0.3351
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/10
train loss item: 0.42065373063087463
train loss item: 0.299028605222702
train loss item: 0.3209518790245056
train loss item: 0.3806475102901459
train loss item: 0.4044487476348877
train loss item: 0.2597898244857788
train loss item: 0.35629788041114807
train loss item: 0.3363831639289856
train loss item: 0.27083784341812134
train loss item: 0.3857123851776123
train loss item: 0.46953722834587097
train loss item: 0.27001869678497314
test loss item: 0.33257701992988586
test loss item: 0.2954329252243042
test loss item: 0.27253323793411255
test loss item: 0.26488226652145386
test loss item: 0.41732773184776306
test loss item: 0.2333609163761139
test loss item: 0.30824270844459534
test loss item: 0.2565782368183136
test loss item: 0.3576570153236389
test loss item: 0.45231354236602783
test loss item: 0.449957937002182
test loss item: 0.1894015222787857
Epoch [7/10], Training Loss: 0.3479, Testing Loss: 0.3192
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/10
train loss item: 0.41220542788505554
train loss item: 0.2868652939796448
train loss item: 0.3081567883491516
train loss item: 0.34732961654663086
train loss item: 0.3768295645713806
train loss item: 0.24169519543647766
train loss item: 0.3249988853931427
train loss item: 0.31343603134155273
train loss item: 0.26336759328842163
train loss item: 0.3831824064254761
train loss item: 0.427778035402298
train loss item: 0.25177326798439026
test loss item: 0.3221997916698456
test loss item: 0.2877434492111206
test loss item: 0.2592628002166748
test loss item: 0.2517662048339844
test loss item: 0.4032743275165558
test loss item: 0.21948684751987457
test loss item: 0.30327266454696655
test loss item: 0.24405038356781006
test loss item: 0.3536774218082428
test loss item: 0.43759816884994507
test loss item: 0.4363326132297516
test loss item: 0.1839670091867447
Epoch [8/10], Training Loss: 0.3281, Testing Loss: 0.3086
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/10
train loss item: 0.3800511360168457
train loss item: 0.2699737548828125
train loss item: 0.2907028794288635
train loss item: 0.32575881481170654
train loss item: 0.35931819677352905
train loss item: 0.23939499258995056
train loss item: 0.30068299174308777
train loss item: 0.30091995000839233
train loss item: 0.2408865988254547
train loss item: 0.37569931149482727
train loss item: 0.40296605229377747
train loss item: 0.24435988068580627
test loss item: 0.2964315116405487
test loss item: 0.27875208854675293
test loss item: 0.24245423078536987
test loss item: 0.2369583249092102
test loss item: 0.378653347492218
test loss item: 0.20512571930885315
test loss item: 0.28901663422584534
test loss item: 0.2355102151632309
test loss item: 0.32526904344558716
test loss item: 0.37884244322776794
test loss item: 0.4079797863960266
test loss item: 0.18805299699306488
Epoch [9/10], Training Loss: 0.3109, Testing Loss: 0.2886
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/10
train loss item: 0.34666603803634644
train loss item: 0.24981653690338135
train loss item: 0.26727473735809326
train loss item: 0.308357834815979
train loss item: 0.35065439343452454
train loss item: 0.2388707846403122
train loss item: 0.28532567620277405
train loss item: 0.2903541028499603
train loss item: 0.21650585532188416
train loss item: 0.35096192359924316
train loss item: 0.3800894320011139
train loss item: 0.2308773249387741
test loss item: 0.3177933394908905
test loss item: 0.32816585898399353
test loss item: 0.25826120376586914
test loss item: 0.2616356909275055
test loss item: 0.4336276948451996
test loss item: 0.21133142709732056
test loss item: 0.33978986740112305
test loss item: 0.26333531737327576
test loss item: 0.36563414335250854
test loss item: 0.4255470037460327
test loss item: 0.48174020648002625
test loss item: 0.18677788972854614
Epoch [10/10], Training Loss: 0.2930, Testing Loss: 0.3228
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
loss item: 0.44292333722114563
loss item: 0.28597337007522583
loss item: 0.3299502730369568
loss item: 0.4755955934524536
loss item: 0.2974289059638977
loss item: 0.44221511483192444
Val Loss: 0.3790
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.0001 16 360 done at Tue Nov 12 09:58:53 CET 2024
UNet2 with 1 10 0.0005 16 360 start at Tue Nov 12 09:58:53 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.347920298576355
train loss item: 0.7266309261322021
train loss item: 0.7740239500999451
train loss item: 1.0496364831924438
train loss item: 1.0384632349014282
train loss item: 0.6429359912872314
train loss item: 0.7671623826026917
train loss item: 0.6212307810783386
train loss item: 0.664842963218689
train loss item: 0.7059001922607422
train loss item: 0.9865418672561646
train loss item: 0.5210573077201843
test loss item: 1.0750242471694946
test loss item: 0.8186753392219543
test loss item: 0.6963887810707092
test loss item: 0.7405107021331787
test loss item: 1.2123366594314575
test loss item: 0.5293529033660889
test loss item: 0.9360984563827515
test loss item: 0.5811087489128113
test loss item: 1.0645079612731934
test loss item: 1.5043264627456665
test loss item: 1.4069602489471436
test loss item: 0.1715167760848999
Epoch [1/10], Training Loss: 0.8205, Testing Loss: 0.8947
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/10
train loss item: 0.5976001024246216
train loss item: 0.404432475566864
train loss item: 0.46110159158706665
train loss item: 0.6248660087585449
train loss item: 0.6578819751739502
train loss item: 0.4129352867603302
train loss item: 0.5289116501808167
train loss item: 0.466266930103302
train loss item: 0.5522606372833252
train loss item: 0.5483872890472412
train loss item: 0.72178715467453
train loss item: 0.3981081545352936
test loss item: 0.6951031684875488
test loss item: 0.6855345964431763
test loss item: 0.5552680492401123
test loss item: 0.5515146255493164
test loss item: 0.9765982627868652
test loss item: 0.4372808635234833
test loss item: 0.7715692520141602
test loss item: 0.5051904916763306
test loss item: 0.7599215507507324
test loss item: 0.9974735379219055
test loss item: 1.0572090148925781
test loss item: 0.17621488869190216
Epoch [2/10], Training Loss: 0.5312, Testing Loss: 0.6807
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/10
train loss item: 0.5564646124839783
train loss item: 0.36679497361183167
train loss item: 0.46974292397499084
train loss item: 0.6266964077949524
train loss item: 0.6239770650863647
train loss item: 0.2967890799045563
train loss item: 0.5078396201133728
train loss item: 0.45546892285346985
train loss item: 0.4670780897140503
train loss item: 0.6057668328285217
train loss item: 0.5718547105789185
train loss item: 0.4719809889793396
test loss item: 0.601479709148407
test loss item: 0.36655980348587036
test loss item: 0.4381048381328583
test loss item: 0.3487030863761902
test loss item: 0.6187194585800171
test loss item: 0.3015715777873993
test loss item: 0.4195058047771454
test loss item: 0.394687682390213
test loss item: 0.5801385641098022
test loss item: 0.4605366289615631
test loss item: 0.6481929421424866
test loss item: 0.18259242177009583
Epoch [3/10], Training Loss: 0.5017, Testing Loss: 0.4467
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/10
train loss item: 0.5266653895378113
train loss item: 0.40741994976997375
train loss item: 0.38162708282470703
train loss item: 0.5175790786743164
train loss item: 0.6108929514884949
train loss item: 0.2500734329223633
train loss item: 0.48713406920433044
train loss item: 0.4424532949924469
train loss item: 0.3712909519672394
train loss item: 0.623035192489624
train loss item: 0.5140435695648193
train loss item: 0.3840923011302948
test loss item: 0.4136197865009308
test loss item: 0.43308714032173157
test loss item: 0.3077199161052704
test loss item: 0.3446415066719055
test loss item: 0.6317203044891357
test loss item: 0.255999892950058
test loss item: 0.43539324402809143
test loss item: 0.3177187740802765
test loss item: 0.49354106187820435
test loss item: 0.8454915285110474
test loss item: 0.7373334169387817
test loss item: 0.191436767578125
Epoch [4/10], Training Loss: 0.4597, Testing Loss: 0.4506
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/10
train loss item: 0.5377596020698547
train loss item: 0.3803800344467163
train loss item: 0.34885427355766296
train loss item: 0.427085816860199
train loss item: 0.5748775005340576
train loss item: 0.32408496737480164
train loss item: 0.5103691816329956
train loss item: 0.4194781184196472
train loss item: 0.2533554136753082
train loss item: 0.45544153451919556
train loss item: 0.5112985968589783
train loss item: 0.2702866196632385
test loss item: 0.4278124272823334
test loss item: 0.47967442870140076
test loss item: 0.31891247630119324
test loss item: 0.38489314913749695
test loss item: 0.6725550293922424
test loss item: 0.29462677240371704
test loss item: 0.46586382389068604
test loss item: 0.3320733308792114
test loss item: 0.5183951258659363
test loss item: 0.9548979997634888
test loss item: 0.8068073987960815
test loss item: 0.3174644410610199
Epoch [5/10], Training Loss: 0.4178, Testing Loss: 0.4978
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/10
train loss item: 0.5181736946105957
train loss item: 0.42800554633140564
train loss item: 0.3661326766014099
train loss item: 0.37522920966148376
train loss item: 0.44005200266838074
train loss item: 0.25558826327323914
train loss item: 0.4663074016571045
train loss item: 0.43790823221206665
train loss item: 0.2666897773742676
train loss item: 0.45322006940841675
train loss item: 0.5259264707565308
train loss item: 0.2524566352367401
test loss item: 0.35432830452919006
test loss item: 0.36713945865631104
test loss item: 0.2747046649456024
test loss item: 0.2919839322566986
test loss item: 0.508633553981781
test loss item: 0.24852685630321503
test loss item: 0.36112189292907715
test loss item: 0.26502853631973267
test loss item: 0.4139389991760254
test loss item: 0.6986818909645081
test loss item: 0.6084767580032349
test loss item: 0.17104218900203705
Epoch [6/10], Training Loss: 0.3988, Testing Loss: 0.3803
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/10
train loss item: 0.3896583318710327
train loss item: 0.3583512008190155
train loss item: 0.3266514539718628
train loss item: 0.38524550199508667
train loss item: 0.3888172209262848
train loss item: 0.26679396629333496
train loss item: 0.3344147205352783
train loss item: 0.3553667962551117
train loss item: 0.25212931632995605
train loss item: 0.4066944718360901
train loss item: 0.5139721632003784
train loss item: 0.24402335286140442
test loss item: 0.320365309715271
test loss item: 0.23007917404174805
test loss item: 0.22358520328998566
test loss item: 0.22027122974395752
test loss item: 0.333446741104126
test loss item: 0.18483924865722656
test loss item: 0.23355881869792938
test loss item: 0.20403698086738586
test loss item: 0.2984307110309601
test loss item: 0.3766147792339325
test loss item: 0.3809087574481964
test loss item: 0.16893626749515533
Epoch [7/10], Training Loss: 0.3518, Testing Loss: 0.2646
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/10
train loss item: 0.2900797724723816
train loss item: 0.2899520695209503
train loss item: 0.26401472091674805
train loss item: 0.334107905626297
train loss item: 0.3422606885433197
train loss item: 0.2412721812725067
train loss item: 0.2969804108142853
train loss item: 0.29403671622276306
train loss item: 0.1964939683675766
train loss item: 0.3482327461242676
train loss item: 0.42467162013053894
train loss item: 0.22400808334350586
test loss item: 0.3730446994304657
test loss item: 0.26055100560188293
test loss item: 0.2354128360748291
test loss item: 0.24335168302059174
test loss item: 0.4050275981426239
test loss item: 0.19336602091789246
test loss item: 0.27145475149154663
test loss item: 0.24156953394412994
test loss item: 0.3427569270133972
test loss item: 0.3999805450439453
test loss item: 0.4496302008628845
test loss item: 0.1622830629348755
Epoch [8/10], Training Loss: 0.2955, Testing Loss: 0.2982
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/10
train loss item: 0.29819455742836
train loss item: 0.26895251870155334
train loss item: 0.21893127262592316
train loss item: 0.284771203994751
train loss item: 0.294852614402771
train loss item: 0.17855922877788544
train loss item: 0.2619316577911377
train loss item: 0.24963027238845825
train loss item: 0.20194394886493683
train loss item: 0.3032286465167999
train loss item: 0.3323025703430176
train loss item: 0.1965257078409195
test loss item: 0.4559842050075531
test loss item: 0.26058152318000793
test loss item: 0.24353660643100739
test loss item: 0.27119266986846924
test loss item: 0.3834061920642853
test loss item: 0.19106425344944
test loss item: 0.2751503586769104
test loss item: 0.21089468896389008
test loss item: 0.4002637267112732
test loss item: 0.4550880193710327
test loss item: 0.4866703152656555
test loss item: 0.15700039267539978
Epoch [9/10], Training Loss: 0.2575, Testing Loss: 0.3159
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/10
train loss item: 0.3313371241092682
train loss item: 0.28802111744880676
train loss item: 0.21137720346450806
train loss item: 0.23959366977214813
train loss item: 0.2594589293003082
train loss item: 0.16060705482959747
train loss item: 0.2623469829559326
train loss item: 0.261530339717865
train loss item: 0.20206382870674133
train loss item: 0.3684733808040619
train loss item: 0.31196293234825134
train loss item: 0.18311436474323273
test loss item: 0.3636276423931122
test loss item: 0.2488427609205246
test loss item: 0.2089160978794098
test loss item: 0.23157237470149994
test loss item: 0.3532368242740631
test loss item: 0.16674131155014038
test loss item: 0.24989157915115356
test loss item: 0.19827574491500854
test loss item: 0.3395673334598541
test loss item: 0.43683499097824097
test loss item: 0.4441869854927063
test loss item: 0.14056706428527832
Epoch [10/10], Training Loss: 0.2567, Testing Loss: 0.2819
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
loss item: 0.4027578830718994
loss item: 0.2650989890098572
loss item: 0.26212796568870544
loss item: 0.49172425270080566
loss item: 0.24260999262332916
loss item: 0.37824591994285583
Val Loss: 0.3404
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.0005 16 360 done at Tue Nov 12 10:01:15 CET 2024
UNet2 with 1 10 0.001 16 360 start at Tue Nov 12 10:01:15 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 10, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.347920298576355
train loss item: 0.8370859026908875
train loss item: 0.8084253072738647
train loss item: 1.0543510913848877
train loss item: 1.0508748292922974
train loss item: 0.6788036227226257
train loss item: 0.7902345657348633
train loss item: 0.6473392248153687
train loss item: 0.6429446935653687
train loss item: 0.6882081031799316
train loss item: 1.0367460250854492
train loss item: 0.5191578269004822
test loss item: 0.9778003692626953
test loss item: 0.7433786392211914
test loss item: 0.6972929835319519
test loss item: 0.6537982225418091
test loss item: 1.131282091140747
test loss item: 0.519782304763794
test loss item: 0.8478103876113892
test loss item: 0.5860170722007751
test loss item: 0.9901925325393677
test loss item: 1.297985553741455
test loss item: 1.2556926012039185
test loss item: 0.17182914912700653
Epoch [1/10], Training Loss: 0.8418, Testing Loss: 0.8227
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/10
train loss item: 0.6870045065879822
train loss item: 0.437121719121933
train loss item: 0.5212539434432983
train loss item: 0.6843154430389404
train loss item: 0.7345481514930725
train loss item: 0.512938380241394
train loss item: 0.6113349199295044
train loss item: 0.5482794642448425
train loss item: 0.6063655614852905
train loss item: 0.7168950438499451
train loss item: 0.8421348929405212
train loss item: 0.512139081954956
test loss item: 0.8918981552124023
test loss item: 0.7481124401092529
test loss item: 0.7143771052360535
test loss item: 0.6122287511825562
test loss item: 1.1233980655670166
test loss item: 0.4065004587173462
test loss item: 0.7986811399459839
test loss item: 0.6681426167488098
test loss item: 0.9690775275230408
test loss item: 0.8580244779586792
test loss item: 1.2461336851119995
test loss item: 0.19154666364192963
Epoch [2/10], Training Loss: 0.6179, Testing Loss: 0.7690
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/10
train loss item: 0.613661527633667
train loss item: 0.3876442015171051
train loss item: 0.5079360604286194
train loss item: 0.6969730854034424
train loss item: 0.7612075805664062
train loss item: 0.34873825311660767
train loss item: 0.5601683855056763
train loss item: 0.47940751910209656
train loss item: 0.49898993968963623
train loss item: 0.7060378789901733
train loss item: 0.6820985674858093
train loss item: 0.4819062054157257
test loss item: 0.5004900097846985
test loss item: 0.41489967703819275
test loss item: 0.41026756167411804
test loss item: 0.3806145191192627
test loss item: 0.6262808442115784
test loss item: 0.31133750081062317
test loss item: 0.46288323402404785
test loss item: 0.3499935269355774
test loss item: 0.5363754630088806
test loss item: 0.6676885485649109
test loss item: 0.6843309998512268
test loss item: 0.22901223599910736
Epoch [3/10], Training Loss: 0.5604, Testing Loss: 0.4645
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/10
train loss item: 0.546330451965332
train loss item: 0.3251984119415283
train loss item: 0.41699960827827454
train loss item: 0.6140895485877991
train loss item: 0.7110395431518555
train loss item: 0.285971999168396
train loss item: 0.5470634698867798
train loss item: 0.44887563586235046
train loss item: 0.38121354579925537
train loss item: 0.616769552230835
train loss item: 0.604049563407898
train loss item: 0.38655224442481995
test loss item: 0.45867496728897095
test loss item: 0.41642317175865173
test loss item: 0.3588094115257263
test loss item: 0.3668524920940399
test loss item: 0.6289511919021606
test loss item: 0.2742162048816681
test loss item: 0.46091228723526
test loss item: 0.31385862827301025
test loss item: 0.5181570053100586
test loss item: 0.798516571521759
test loss item: 0.71230149269104
test loss item: 0.1940988451242447
Epoch [4/10], Training Loss: 0.4903, Testing Loss: 0.4585
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/10
train loss item: 0.5705771446228027
train loss item: 0.38813474774360657
train loss item: 0.40440067648887634
train loss item: 0.5409359931945801
train loss item: 0.6260098218917847
train loss item: 0.25902798771858215
train loss item: 0.5231205224990845
train loss item: 0.457897424697876
train loss item: 0.34611424803733826
train loss item: 0.6021536588668823
train loss item: 0.572413444519043
train loss item: 0.3504672348499298
test loss item: 0.43738314509391785
test loss item: 0.4616278409957886
test loss item: 0.30745837092399597
test loss item: 0.37562763690948486
test loss item: 0.6606745719909668
test loss item: 0.245477095246315
test loss item: 0.4786258041858673
test loss item: 0.3009518086910248
test loss item: 0.4934687912464142
test loss item: 0.9134602546691895
test loss item: 0.7783374190330505
test loss item: 0.1953534334897995
Epoch [5/10], Training Loss: 0.4701, Testing Loss: 0.4707
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/10
train loss item: 0.5306140780448914
train loss item: 0.404539555311203
train loss item: 0.3953021168708801
train loss item: 0.47662824392318726
train loss item: 0.5741168260574341
train loss item: 0.27004164457321167
train loss item: 0.5187265276908875
train loss item: 0.47141313552856445
train loss item: 0.2612839639186859
train loss item: 0.5263849496841431
train loss item: 0.5454187989234924
train loss item: 0.3349376916885376
test loss item: 0.5808173418045044
test loss item: 0.5291622281074524
test loss item: 0.3615439236164093
test loss item: 0.4391302168369293
test loss item: 0.7497478723526001
test loss item: 0.2648063004016876
test loss item: 0.5461210608482361
test loss item: 0.35485032200813293
test loss item: 0.5854452252388
test loss item: 0.9823623299598694
test loss item: 0.9200889468193054
test loss item: 0.18086408078670502
Epoch [6/10], Training Loss: 0.4425, Testing Loss: 0.5412
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/10
train loss item: 0.5485209226608276
train loss item: 0.42131683230400085
train loss item: 0.3515545129776001
train loss item: 0.4201355278491974
train loss item: 0.5138422846794128
train loss item: 0.2468743920326233
train loss item: 0.4660016894340515
train loss item: 0.45813512802124023
train loss item: 0.29082855582237244
train loss item: 0.569748044013977
train loss item: 0.49976375699043274
train loss item: 0.30982232093811035
test loss item: 0.44801175594329834
test loss item: 0.44548383355140686
test loss item: 0.3117457628250122
test loss item: 0.3642146587371826
test loss item: 0.6183643341064453
test loss item: 0.22815892100334167
test loss item: 0.4583989679813385
test loss item: 0.3081454038619995
test loss item: 0.47969818115234375
test loss item: 0.7825171947479248
test loss item: 0.7431410551071167
test loss item: 0.1632446050643921
Epoch [7/10], Training Loss: 0.4247, Testing Loss: 0.4459
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/10
train loss item: 0.5111298561096191
train loss item: 0.43715018033981323
train loss item: 0.3500712215900421
train loss item: 0.3360290825366974
train loss item: 0.49091699719429016
train loss item: 0.30034351348876953
train loss item: 0.45800310373306274
train loss item: 0.4246000349521637
train loss item: 0.2300773561000824
train loss item: 0.5420607924461365
train loss item: 0.43600305914878845
train loss item: 0.3060809075832367
test loss item: 0.49206408858299255
test loss item: 0.5972764492034912
test loss item: 0.3494582176208496
test loss item: 0.44817814230918884
test loss item: 0.8030426502227783
test loss item: 0.2667052447795868
test loss item: 0.6053668260574341
test loss item: 0.3881642818450928
test loss item: 0.5984923243522644
test loss item: 1.0664254426956177
test loss item: 0.9821213483810425
test loss item: 0.16873690485954285
Epoch [8/10], Training Loss: 0.4019, Testing Loss: 0.5638
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/10
train loss item: 0.4918334186077118
train loss item: 0.3641921281814575
train loss item: 0.3128960132598877
train loss item: 0.32590168714523315
train loss item: 0.4262162744998932
train loss item: 0.2840878963470459
train loss item: 0.41964489221572876
train loss item: 0.41278818249702454
train loss item: 0.21011501550674438
train loss item: 0.4610602557659149
train loss item: 0.39802923798561096
train loss item: 0.22589319944381714
test loss item: 0.4289657175540924
test loss item: 0.4702092111110687
test loss item: 0.30574843287467957
test loss item: 0.36977875232696533
test loss item: 0.6457378268241882
test loss item: 0.22876080870628357
test loss item: 0.4843390882015228
test loss item: 0.30492493510246277
test loss item: 0.498197078704834
test loss item: 0.8597763776779175
test loss item: 0.795756459236145
test loss item: 0.12968245148658752
Epoch [9/10], Training Loss: 0.3611, Testing Loss: 0.4602
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/10
train loss item: 0.4792887568473816
train loss item: 0.38106417655944824
train loss item: 0.3331315815448761
train loss item: 0.31095901131629944
train loss item: 0.35327792167663574
train loss item: 0.26468899846076965
train loss item: 0.43810415267944336
train loss item: 0.43464234471321106
train loss item: 0.1933470368385315
train loss item: 0.45436325669288635
train loss item: 0.45448604226112366
train loss item: 0.20138409733772278
test loss item: 0.378557413816452
test loss item: 0.3190152049064636
test loss item: 0.2637653350830078
test loss item: 0.2725422978401184
test loss item: 0.4659784138202667
test loss item: 0.19039663672447205
test loss item: 0.3344622850418091
test loss item: 0.2634918987751007
test loss item: 0.3954746723175049
test loss item: 0.5872600078582764
test loss item: 0.5481988191604614
test loss item: 0.18809859454631805
Epoch [10/10], Training Loss: 0.3582, Testing Loss: 0.3506
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
loss item: 0.522643506526947
loss item: 0.32006287574768066
loss item: 0.33234289288520813
loss item: 0.6041151881217957
loss item: 0.3054106831550598
loss item: 0.4953122138977051
Val Loss: 0.4300
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 10, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.001 16 360 done at Tue Nov 12 10:03:41 CET 2024
UNet2 with 1 10 0.005 16 360 start at Tue Nov 12 10:03:41 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 10, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
train loss item: 1.347920298576355
train loss item: 1.5687456130981445
train loss item: 1.631877064704895
train loss item: 1.4319086074829102
train loss item: 1.4138485193252563
train loss item: 0.546890914440155
train loss item: 1.3041961193084717
train loss item: 1.0380523204803467
train loss item: 0.5293318033218384
train loss item: 0.9218611121177673
train loss item: 1.3710566759109497
train loss item: 0.6858503222465515
test loss item: 3.2003939151763916
test loss item: 2.154862403869629
test loss item: 2.522993803024292
test loss item: 2.072277545928955
test loss item: 3.261380672454834
test loss item: 1.5580440759658813
test loss item: 2.3153131008148193
test loss item: 2.2654213905334473
test loss item: 3.346027135848999
test loss item: 2.5312631130218506
test loss item: 3.6369071006774902
test loss item: 0.8985705375671387
Epoch [1/10], Training Loss: 1.1493, Testing Loss: 2.4803
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/10
train loss item: 0.7554489970207214
train loss item: 0.5311941504478455
train loss item: 0.6179863810539246
train loss item: 0.8203991651535034
train loss item: 0.9779049754142761
train loss item: 0.4623931050300598
train loss item: 0.8516811728477478
train loss item: 0.6761479377746582
train loss item: 0.5962315201759338
train loss item: 0.8352209329605103
train loss item: 1.0741273164749146
train loss item: 0.5220564603805542
test loss item: 7.790459156036377
test loss item: 3.576235055923462
test loss item: 5.013566970825195
test loss item: 3.944175958633423
test loss item: 6.5662665367126465
test loss item: 2.6617796421051025
test loss item: 3.747519016265869
test loss item: 4.292668342590332
test loss item: 7.04976749420166
test loss item: 4.14107084274292
test loss item: 7.614866733551025
test loss item: 2.846034288406372
Epoch [2/10], Training Loss: 0.7267, Testing Loss: 4.9370
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/10
train loss item: 0.6863020062446594
train loss item: 0.4426109492778778
train loss item: 0.5799510478973389
train loss item: 0.7794153094291687
train loss item: 0.8928535580635071
train loss item: 0.4278809726238251
train loss item: 0.7807832360267639
train loss item: 0.6580387949943542
train loss item: 0.5662275552749634
train loss item: 0.7435731291770935
train loss item: 1.0109055042266846
train loss item: 0.5526444315910339
test loss item: 1.330809473991394
test loss item: 0.8935152292251587
test loss item: 1.0789555311203003
test loss item: 0.7761048674583435
test loss item: 1.531236171722412
test loss item: 0.6736292243003845
test loss item: 0.9920744299888611
test loss item: 0.9261553287506104
test loss item: 1.3865399360656738
test loss item: 1.3352049589157104
test loss item: 1.6601319313049316
test loss item: 0.309951514005661
Epoch [3/10], Training Loss: 0.6768, Testing Loss: 1.0745
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/10
train loss item: 0.6887794733047485
train loss item: 0.49422547221183777
train loss item: 0.5770339369773865
train loss item: 0.7572455406188965
train loss item: 0.8831947445869446
train loss item: 0.4058489203453064
train loss item: 0.7843759059906006
train loss item: 0.6657115817070007
train loss item: 0.43560850620269775
train loss item: 0.7632137537002563
train loss item: 0.9187833666801453
train loss item: 0.4459364414215088
test loss item: 0.7054656744003296
test loss item: 0.6305694580078125
test loss item: 0.48126721382141113
test loss item: 0.5342040061950684
test loss item: 0.9173663258552551
test loss item: 0.39502623677253723
test loss item: 0.699359655380249
test loss item: 0.43536514043807983
test loss item: 0.7231936454772949
test loss item: 1.195124626159668
test loss item: 1.0048640966415405
test loss item: 0.3020661771297455
Epoch [4/10], Training Loss: 0.6517, Testing Loss: 0.6687
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/10
train loss item: 0.6609570384025574
train loss item: 0.4887945055961609
train loss item: 0.5706380009651184
train loss item: 0.7161975502967834
train loss item: 0.8125241994857788
train loss item: 0.37361499667167664
train loss item: 0.7603998184204102
train loss item: 0.6537167429924011
train loss item: 0.3848836123943329
train loss item: 0.7090879082679749
train loss item: 0.8640277981758118
train loss item: 0.46717530488967896
test loss item: 0.7143515944480896
test loss item: 0.6800945401191711
test loss item: 0.5133504867553711
test loss item: 0.5548902750015259
test loss item: 0.9800561666488647
test loss item: 0.3815513253211975
test loss item: 0.7185341715812683
test loss item: 0.4738336503505707
test loss item: 0.7692980766296387
test loss item: 1.2288355827331543
test loss item: 1.107201099395752
test loss item: 0.18293917179107666
Epoch [5/10], Training Loss: 0.6218, Testing Loss: 0.6921
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/10
train loss item: 0.6935371160507202
train loss item: 0.5232334733009338
train loss item: 0.5809929370880127
train loss item: 0.6600165367126465
train loss item: 0.740502119064331
train loss item: 0.3897272050380707
train loss item: 0.7430079579353333
train loss item: 0.6598523855209351
train loss item: 0.36883315443992615
train loss item: 0.6696416139602661
train loss item: 0.8549189567565918
train loss item: 0.41099363565444946
test loss item: 0.6205070614814758
test loss item: 0.5668800473213196
test loss item: 0.4473553001880646
test loss item: 0.4805130660533905
test loss item: 0.8150489926338196
test loss item: 0.3519774079322815
test loss item: 0.5836055278778076
test loss item: 0.39054054021835327
test loss item: 0.642426073551178
test loss item: 1.0142884254455566
test loss item: 0.9220860004425049
test loss item: 0.14466796815395355
Epoch [6/10], Training Loss: 0.6079, Testing Loss: 0.5817
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/10
train loss item: 0.6616132855415344
train loss item: 0.448541522026062
train loss item: 0.5705880522727966
train loss item: 0.6463158130645752
train loss item: 0.6811172962188721
train loss item: 0.37774163484573364
train loss item: 0.6869930624961853
train loss item: 0.622336745262146
train loss item: 0.3628271520137787
train loss item: 0.6563182473182678
train loss item: 0.8082332015037537
train loss item: 0.4208752512931824
test loss item: 0.5947079062461853
test loss item: 0.4916192889213562
test loss item: 0.4303413927555084
test loss item: 0.43888986110687256
test loss item: 0.727758526802063
test loss item: 0.34286263585090637
test loss item: 0.5219079256057739
test loss item: 0.36402422189712524
test loss item: 0.606358528137207
test loss item: 0.8999432921409607
test loss item: 0.7942491769790649
test loss item: 0.14240488409996033
Epoch [7/10], Training Loss: 0.5786, Testing Loss: 0.5296
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/10
train loss item: 0.6446191668510437
train loss item: 0.39430809020996094
train loss item: 0.5219672322273254
train loss item: 0.6501003503799438
train loss item: 0.6541334390640259
train loss item: 0.3448999524116516
train loss item: 0.6329718232154846
train loss item: 0.5855112075805664
train loss item: 0.36855870485305786
train loss item: 0.6449117660522461
train loss item: 0.7566896677017212
train loss item: 0.4003913402557373
test loss item: 0.5671632885932922
test loss item: 0.4763503968715668
test loss item: 0.41602852940559387
test loss item: 0.4268138110637665
test loss item: 0.701973557472229
test loss item: 0.3386044204235077
test loss item: 0.505382776260376
test loss item: 0.34729254245758057
test loss item: 0.56548672914505
test loss item: 0.8388271331787109
test loss item: 0.7582160830497742
test loss item: 0.1849266141653061
Epoch [8/10], Training Loss: 0.5499, Testing Loss: 0.5106
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/10
train loss item: 0.6501380205154419
train loss item: 0.4137910008430481
train loss item: 0.5094935297966003
train loss item: 0.6232690215110779
train loss item: 0.6280271410942078
train loss item: 0.3216910660266876
train loss item: 0.6164563298225403
train loss item: 0.5669658184051514
train loss item: 0.3618095815181732
train loss item: 0.6310023069381714
train loss item: 0.7021150588989258
train loss item: 0.37488463521003723
test loss item: 0.5576760172843933
test loss item: 0.4387529492378235
test loss item: 0.42650163173675537
test loss item: 0.40698879957199097
test loss item: 0.662597119808197
test loss item: 0.3334234654903412
test loss item: 0.4835571348667145
test loss item: 0.3523702323436737
test loss item: 0.5577371716499329
test loss item: 0.7216888070106506
test loss item: 0.6958555579185486
test loss item: 0.1581973433494568
Epoch [9/10], Training Loss: 0.5333, Testing Loss: 0.4829
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/10
train loss item: 0.6146268248558044
train loss item: 0.4009389877319336
train loss item: 0.5048874616622925
train loss item: 0.6117563843727112
train loss item: 0.5628377199172974
train loss item: 0.2973169982433319
train loss item: 0.5528077483177185
train loss item: 0.5378864407539368
train loss item: 0.3709028363227844
train loss item: 0.6384808421134949
train loss item: 0.6483501195907593
train loss item: 0.3773448169231415
test loss item: 0.49395743012428284
test loss item: 0.4037442207336426
test loss item: 0.39273738861083984
test loss item: 0.3740706741809845
test loss item: 0.5978658199310303
test loss item: 0.3202199935913086
test loss item: 0.44236990809440613
test loss item: 0.3208899199962616
test loss item: 0.4954734146595001
test loss item: 0.6402389407157898
test loss item: 0.6175023317337036
test loss item: 0.144777312874794
Epoch [10/10], Training Loss: 0.5098, Testing Loss: 0.4370
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
loss item: 0.6553405523300171
loss item: 0.40326786041259766
loss item: 0.4954259395599365
loss item: 0.7035301327705383
loss item: 0.3477024435997009
loss item: 0.5612760782241821
Val Loss: 0.5278
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 10, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 10 0.005 16 360 done at Tue Nov 12 10:06:07 CET 2024
UNet2 with 1 10 0.0001 32 360 start at Tue Nov 12 10:06:07 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.0001 32 360 done at Tue Nov 12 10:06:14 CET 2024
UNet2 with 1 10 0.0005 32 360 start at Tue Nov 12 10:06:14 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.0005 32 360 done at Tue Nov 12 10:06:23 CET 2024
UNet2 with 1 10 0.001 32 360 start at Tue Nov 12 10:06:23 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 10, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.001 32 360 done at Tue Nov 12 10:06:30 CET 2024
UNet2 with 1 10 0.005 32 360 start at Tue Nov 12 10:06:30 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 10, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.005 32 360 done at Tue Nov 12 10:06:38 CET 2024
UNet2 with 1 10 0.0001 64 360 start at Tue Nov 12 10:06:38 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.0001 64 360 done at Tue Nov 12 10:06:45 CET 2024
UNet2 with 1 10 0.0005 64 360 start at Tue Nov 12 10:06:45 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.0005 64 360 done at Tue Nov 12 10:06:53 CET 2024
UNet2 with 1 10 0.001 64 360 start at Tue Nov 12 10:06:53 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 10, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.001 64 360 done at Tue Nov 12 10:07:00 CET 2024
UNet2 with 1 10 0.005 64 360 start at Tue Nov 12 10:07:00 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 10, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.005 64 360 done at Tue Nov 12 10:07:08 CET 2024
UNet2 with 1 10 0.0001 128 360 start at Tue Nov 12 10:07:08 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 10, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.0001 128 360 done at Tue Nov 12 10:07:16 CET 2024
UNet2 with 1 10 0.0005 128 360 start at Tue Nov 12 10:07:16 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 10, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.0005 128 360 done at Tue Nov 12 10:07:26 CET 2024
UNet2 with 1 10 0.001 128 360 start at Tue Nov 12 10:07:26 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 10, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.001 128 360 done at Tue Nov 12 10:07:34 CET 2024
UNet2 with 1 10 0.005 128 360 start at Tue Nov 12 10:07:34 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 10, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/10
UNet2 with 1 10 0.005 128 360 done at Tue Nov 12 10:07:41 CET 2024
UNet2 with 1 50 0.0001 2 360 start at Tue Nov 12 10:07:41 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 0.9121710062026978
train loss item: 2.361032485961914
train loss item: 0.5908730030059814
train loss item: 1.2434922456741333
train loss item: 0.8365021347999573
train loss item: 0.5948132276535034
train loss item: 0.5484413504600525
train loss item: 1.2568069696426392
train loss item: 0.4701719582080841
train loss item: 0.49126583337783813
train loss item: 0.5907455086708069
train loss item: 0.4010674059391022
train loss item: 0.3736041486263275
train loss item: 0.7809377312660217
train loss item: 0.509601891040802
train loss item: 1.0467482805252075
train loss item: 0.38424307107925415
train loss item: 0.5152631402015686
train loss item: 0.5292810797691345
train loss item: 0.407499760389328
train loss item: 0.3384734094142914
train loss item: 0.33425581455230713
train loss item: 1.4463419914245605
train loss item: 1.2463154792785645
train loss item: 0.7553142309188843
train loss item: 0.43640974164009094
train loss item: 0.37979209423065186
train loss item: 0.43813005089759827
train loss item: 0.28189951181411743
train loss item: 1.0697678327560425
train loss item: 2.858053207397461
train loss item: 0.7476573586463928
train loss item: 0.26521676778793335
train loss item: 0.5216339826583862
train loss item: 0.5793464183807373
train loss item: 2.6721296310424805
train loss item: 0.6262391209602356
train loss item: 0.4187734127044678
train loss item: 0.5651669502258301
train loss item: 0.44667813181877136
train loss item: 0.28570106625556946
train loss item: 0.3944515585899353
train loss item: 0.3284895420074463
train loss item: 0.337677538394928
train loss item: 0.7978792190551758
train loss item: 0.3569549322128296
train loss item: 0.2912555932998657
train loss item: 0.454662024974823
train loss item: 0.3029745817184448
train loss item: 0.25580763816833496
train loss item: 0.3692210614681244
train loss item: 1.0773347616195679
train loss item: 0.26498883962631226
train loss item: 0.25303590297698975
train loss item: 2.452367067337036
train loss item: 0.2578674852848053
train loss item: 0.3483966290950775
train loss item: 0.3164193332195282
train loss item: 0.2925061285495758
train loss item: 0.2450268268585205
train loss item: 1.0275503396987915
train loss item: 2.277750015258789
train loss item: 0.26835423707962036
train loss item: 0.3801731467247009
train loss item: 0.23931489884853363
train loss item: 0.7239580750465393
train loss item: 0.445193350315094
train loss item: 0.303986132144928
train loss item: 0.324326753616333
train loss item: 0.3634343445301056
train loss item: 0.28776270151138306
train loss item: 0.27615952491760254
train loss item: 0.2999342083930969
train loss item: 0.3200346827507019
train loss item: 0.22308796644210815
train loss item: 0.18532486259937286
train loss item: 0.9706341028213501
train loss item: 1.4912152290344238
train loss item: 0.19212085008621216
train loss item: 0.2843157649040222
train loss item: 0.2530641257762909
train loss item: 0.2367672324180603
train loss item: 0.2718278169631958
train loss item: 0.6453335285186768
train loss item: 0.3626972436904907
train loss item: 0.680824339389801
train loss item: 4.3681488037109375
train loss item: 0.2382141500711441
train loss item: 0.3801846206188202
test loss item: 0.21100924909114838
test loss item: 0.1905904859304428
test loss item: 0.493234783411026
test loss item: 0.2629840075969696
test loss item: 0.30734843015670776
test loss item: 0.23107047379016876
test loss item: 1.272710919380188
test loss item: 0.3848780691623688
test loss item: 0.22346585988998413
test loss item: 0.381833016872406
test loss item: 0.8189902305603027
test loss item: 0.2084769308567047
test loss item: 0.21908438205718994
test loss item: 0.33655762672424316
test loss item: 0.23035652935504913
test loss item: 0.1612349897623062
test loss item: 0.26569706201553345
test loss item: 0.4498690366744995
test loss item: 0.5908847451210022
test loss item: 0.26883623003959656
test loss item: 0.7079334855079651
test loss item: 0.34440669417381287
test loss item: 0.30552637577056885
test loss item: 0.2102038860321045
test loss item: 0.23730531334877014
test loss item: 0.2640498876571655
test loss item: 0.3360220491886139
test loss item: 0.2627532482147217
test loss item: 0.3543626070022583
test loss item: 0.36366814374923706
test loss item: 0.6721838712692261
test loss item: 0.1511075347661972
test loss item: 0.20101863145828247
test loss item: 0.5464137196540833
test loss item: 0.4172126054763794
test loss item: 0.5716060996055603
test loss item: 0.70134437084198
test loss item: 1.356266975402832
test loss item: 0.47007670998573303
test loss item: 0.29342812299728394
test loss item: 0.2850244343280792
test loss item: 0.24279940128326416
test loss item: 0.3389380872249603
test loss item: 0.21887172758579254
test loss item: 0.5867714881896973
test loss item: 0.37481752038002014
test loss item: 0.3145896792411804
test loss item: 0.29516535997390747
test loss item: 0.4280039966106415
test loss item: 0.6496374011039734
test loss item: 0.31711316108703613
test loss item: 0.20819510519504547
test loss item: 0.23961491882801056
test loss item: 0.23810023069381714
test loss item: 0.3062787652015686
test loss item: 0.754949152469635
test loss item: 0.5467913150787354
test loss item: 0.27358928322792053
test loss item: 0.2504788339138031
test loss item: 0.23311938345432281
test loss item: 0.45070433616638184
test loss item: 0.2125469595193863
test loss item: 0.2315702736377716
test loss item: 0.2604731023311615
test loss item: 0.696123480796814
test loss item: 0.3371492326259613
test loss item: 0.3023376166820526
test loss item: 0.2690799832344055
test loss item: 0.5280156135559082
test loss item: 0.428323894739151
test loss item: 0.16557703912258148
test loss item: 0.7224841713905334
test loss item: 0.28124964237213135
test loss item: 0.3354153633117676
test loss item: 0.1801617592573166
test loss item: 0.22270898520946503
test loss item: 0.21052978932857513
test loss item: 1.345981240272522
test loss item: 0.4439548850059509
test loss item: 0.261204332113266
test loss item: 0.15042409300804138
test loss item: 0.8808879852294922
test loss item: 0.7729071974754333
test loss item: 0.9290870428085327
test loss item: 0.25774550437927246
test loss item: 0.24865679442882538
test loss item: 0.1663329303264618
test loss item: 0.16702459752559662
test loss item: 0.20241861045360565
Epoch [1/50], Training Loss: 0.6660, Testing Loss: 0.3937
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/50
train loss item: 0.48500680923461914
train loss item: 1.1864590644836426
train loss item: 0.3508640229701996
train loss item: 0.5151530504226685
train loss item: 1.8454673290252686
train loss item: 0.37411361932754517
train loss item: 0.26874735951423645
train loss item: 0.7689760327339172
train loss item: 0.21163707971572876
train loss item: 0.3168288469314575
train loss item: 0.3959479033946991
train loss item: 0.27108681201934814
train loss item: 0.1811189204454422
train loss item: 0.5443882346153259
train loss item: 0.3077506124973297
train loss item: 0.787498414516449
train loss item: 0.14723119139671326
train loss item: 0.2873050570487976
train loss item: 0.33562010526657104
train loss item: 0.3018501400947571
train loss item: 0.2441416084766388
train loss item: 0.1842338591814041
train loss item: 0.9704393744468689
train loss item: 1.043884515762329
train loss item: 0.5557245016098022
train loss item: 0.3019523024559021
train loss item: 0.28606241941452026
train loss item: 0.3080558180809021
train loss item: 0.19289523363113403
train loss item: 0.6662306189537048
train loss item: 2.1989352703094482
train loss item: 0.600832998752594
train loss item: 0.20529243350028992
train loss item: 0.4043195843696594
train loss item: 0.26840314269065857
train loss item: 2.191783905029297
train loss item: 0.5457374453544617
train loss item: 0.48889845609664917
train loss item: 0.5570715069770813
train loss item: 0.36063817143440247
train loss item: 0.32198330760002136
train loss item: 0.3245721459388733
train loss item: 0.3126809895038605
train loss item: 0.2532402575016022
train loss item: 0.6258190274238586
train loss item: 0.21640613675117493
train loss item: 0.14717531204223633
train loss item: 0.37694770097732544
train loss item: 0.21109218895435333
train loss item: 0.18790778517723083
train loss item: 0.27791184186935425
train loss item: 0.9104347229003906
train loss item: 0.1188352033495903
train loss item: 0.20859506726264954
train loss item: 2.113276243209839
train loss item: 0.19718770682811737
train loss item: 0.3474990129470825
train loss item: 0.2297925502061844
train loss item: 0.19623008370399475
train loss item: 0.16100898385047913
train loss item: 0.755406379699707
train loss item: 1.9041850566864014
train loss item: 0.23504287004470825
train loss item: 0.34660056233406067
train loss item: 0.17821645736694336
train loss item: 0.5193289518356323
train loss item: 0.4283766448497772
train loss item: 0.24446611106395721
train loss item: 0.30278101563453674
train loss item: 0.3167077898979187
train loss item: 0.2663639187812805
train loss item: 0.19255146384239197
train loss item: 0.20296163856983185
train loss item: 0.27306029200553894
train loss item: 0.16356468200683594
train loss item: 0.13581477105617523
train loss item: 0.7882338762283325
train loss item: 1.2669059038162231
train loss item: 0.10500571876764297
train loss item: 0.23480942845344543
train loss item: 0.15628831088542938
train loss item: 0.19977013766765594
train loss item: 0.23715628683567047
train loss item: 0.49897128343582153
train loss item: 0.3223642110824585
train loss item: 0.5064004063606262
train loss item: 3.836564779281616
train loss item: 0.1922953575849533
train loss item: 0.3331531584262848
test loss item: 0.16456946730613708
test loss item: 0.11038728058338165
test loss item: 0.41948583722114563
test loss item: 0.20428384840488434
test loss item: 0.21386538445949554
test loss item: 0.12129561603069305
test loss item: 1.1379759311676025
test loss item: 0.42230767011642456
test loss item: 0.17199808359146118
test loss item: 0.31706321239471436
test loss item: 0.6662368178367615
test loss item: 0.1533002108335495
test loss item: 0.16496215760707855
test loss item: 0.2558002173900604
test loss item: 0.15268272161483765
test loss item: 0.11311981081962585
test loss item: 0.23457683622837067
test loss item: 0.37272506952285767
test loss item: 0.5599627494812012
test loss item: 0.2108278125524521
test loss item: 0.6021773219108582
test loss item: 0.30609267950057983
test loss item: 0.22708241641521454
test loss item: 0.1507413536310196
test loss item: 0.19595392048358917
test loss item: 0.20579475164413452
test loss item: 0.2658422589302063
test loss item: 0.17071907222270966
test loss item: 0.27401527762413025
test loss item: 0.29511889815330505
test loss item: 0.5428682565689087
test loss item: 0.10044039040803909
test loss item: 0.13385009765625
test loss item: 0.4724656045436859
test loss item: 0.33872246742248535
test loss item: 0.3904491066932678
test loss item: 0.6551851034164429
test loss item: 1.0588656663894653
test loss item: 0.3864870071411133
test loss item: 0.22728078067302704
test loss item: 0.25358232855796814
test loss item: 0.1645478755235672
test loss item: 0.29995766282081604
test loss item: 0.17277176678180695
test loss item: 0.4874116778373718
test loss item: 0.32642003893852234
test loss item: 0.23674285411834717
test loss item: 0.2063627988100052
test loss item: 0.36967185139656067
test loss item: 0.5366275906562805
test loss item: 0.2455424666404724
test loss item: 0.14099395275115967
test loss item: 0.19800561666488647
test loss item: 0.1570899337530136
test loss item: 0.24934060871601105
test loss item: 0.6377779245376587
test loss item: 0.4665624499320984
test loss item: 0.2056286484003067
test loss item: 0.20034603774547577
test loss item: 0.1855689436197281
test loss item: 0.38074633479118347
test loss item: 0.1928337663412094
test loss item: 0.17647764086723328
test loss item: 0.22014030814170837
test loss item: 0.5952824354171753
test loss item: 0.2790825068950653
test loss item: 0.2577891945838928
test loss item: 0.22083067893981934
test loss item: 0.45469313859939575
test loss item: 0.372977614402771
test loss item: 0.09554248303174973
test loss item: 0.6771318912506104
test loss item: 0.23136042058467865
test loss item: 0.2950713336467743
test loss item: 0.12782225012779236
test loss item: 0.1396246701478958
test loss item: 0.15078453719615936
test loss item: 1.0145968198776245
test loss item: 0.3603816330432892
test loss item: 0.16605304181575775
test loss item: 0.08830113708972931
test loss item: 0.7166067361831665
test loss item: 0.6842418313026428
test loss item: 0.703576385974884
test loss item: 0.19565007090568542
test loss item: 0.1880267858505249
test loss item: 0.10575206577777863
test loss item: 0.12133488804101944
test loss item: 0.16646070778369904
Epoch [2/50], Training Loss: 0.5094, Testing Loss: 0.3178
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/50
train loss item: 0.41057389974594116
train loss item: 0.9392258524894714
train loss item: 0.22056832909584045
train loss item: 0.43680208921432495
train loss item: 0.6556686758995056
train loss item: 0.30349549651145935
train loss item: 0.2789488136768341
train loss item: 0.5759757161140442
train loss item: 0.21900008618831635
train loss item: 0.2762719392776489
train loss item: 0.3241414725780487
train loss item: 0.25244632363319397
train loss item: 0.14802424609661102
train loss item: 0.4438804090023041
train loss item: 0.22367443144321442
train loss item: 0.6498077511787415
train loss item: 0.10418679565191269
train loss item: 0.24753674864768982
train loss item: 0.271727979183197
train loss item: 0.2491001933813095
train loss item: 0.2201738804578781
train loss item: 0.16697193682193756
train loss item: 0.8138332962989807
train loss item: 0.832940936088562
train loss item: 0.5344581007957458
train loss item: 0.2553643584251404
train loss item: 0.23663429915905
train loss item: 0.24703827500343323
train loss item: 0.106563501060009
train loss item: 0.5640798807144165
train loss item: 1.7679976224899292
train loss item: 0.5301427245140076
train loss item: 0.1523536741733551
train loss item: 0.3506092429161072
train loss item: 0.2269054800271988
train loss item: 1.9261847734451294
train loss item: 0.5025743842124939
train loss item: 0.4173262119293213
train loss item: 0.612385094165802
train loss item: 0.27643051743507385
train loss item: 0.2588752210140228
train loss item: 0.2402261644601822
train loss item: 0.3003993630409241
train loss item: 0.20986206829547882
train loss item: 0.5492078065872192
train loss item: 0.16295021772384644
train loss item: 0.11572805792093277
train loss item: 0.3610960841178894
train loss item: 0.18830306828022003
train loss item: 0.15522484481334686
train loss item: 0.25792670249938965
train loss item: 0.8181875348091125
train loss item: 0.09539136290550232
train loss item: 0.17696301639080048
train loss item: 1.9070606231689453
train loss item: 0.170675590634346
train loss item: 0.28691366314888
train loss item: 0.20082181692123413
train loss item: 0.1609772890806198
train loss item: 0.1317761093378067
train loss item: 0.6230367422103882
train loss item: 1.7065331935882568
train loss item: 0.20592091977596283
train loss item: 0.33050400018692017
train loss item: 0.15625238418579102
train loss item: 0.5017097592353821
train loss item: 0.43653878569602966
train loss item: 0.22097647190093994
train loss item: 0.2648906111717224
train loss item: 0.29357579350471497
train loss item: 0.24327246844768524
train loss item: 0.15217532217502594
train loss item: 0.1687525063753128
train loss item: 0.2407342791557312
train loss item: 0.1157328262925148
train loss item: 0.11458990722894669
train loss item: 0.6786723136901855
train loss item: 1.1846877336502075
train loss item: 0.09225727617740631
train loss item: 0.20939737558364868
train loss item: 0.13876096904277802
train loss item: 0.1612091213464737
train loss item: 0.22264538705348969
train loss item: 0.42996418476104736
train loss item: 0.3240766227245331
train loss item: 0.4125942885875702
train loss item: 3.5785934925079346
train loss item: 0.14885194599628448
train loss item: 0.3150218427181244
test loss item: 0.16498811542987823
test loss item: 0.11600631475448608
test loss item: 0.3680499494075775
test loss item: 0.19585846364498138
test loss item: 0.20214354991912842
test loss item: 0.12462395429611206
test loss item: 1.0673556327819824
test loss item: 0.4267731308937073
test loss item: 0.16261166334152222
test loss item: 0.27788877487182617
test loss item: 0.5889781713485718
test loss item: 0.14192666113376617
test loss item: 0.1640489101409912
test loss item: 0.23899605870246887
test loss item: 0.15037652850151062
test loss item: 0.10529238730669022
test loss item: 0.21675445139408112
test loss item: 0.31497448682785034
test loss item: 0.536879301071167
test loss item: 0.20804831385612488
test loss item: 0.5074040293693542
test loss item: 0.29394447803497314
test loss item: 0.21730881929397583
test loss item: 0.1496402621269226
test loss item: 0.16933496296405792
test loss item: 0.2033127099275589
test loss item: 0.24408596754074097
test loss item: 0.1658170521259308
test loss item: 0.2517901659011841
test loss item: 0.26298534870147705
test loss item: 0.48619210720062256
test loss item: 0.09431294351816177
test loss item: 0.13469067215919495
test loss item: 0.4063783884048462
test loss item: 0.2847801744937897
test loss item: 0.3589833378791809
test loss item: 0.6201183199882507
test loss item: 0.9135726094245911
test loss item: 0.3269723355770111
test loss item: 0.2146047055721283
test loss item: 0.23267878592014313
test loss item: 0.19084778428077698
test loss item: 0.2560923099517822
test loss item: 0.15717189013957977
test loss item: 0.40955156087875366
test loss item: 0.30948200821876526
test loss item: 0.2351771593093872
test loss item: 0.21544206142425537
test loss item: 0.33024609088897705
test loss item: 0.47751888632774353
test loss item: 0.21951842308044434
test loss item: 0.1381026953458786
test loss item: 0.1801338940858841
test loss item: 0.1368313431739807
test loss item: 0.2214929312467575
test loss item: 0.5475833415985107
test loss item: 0.4356391131877899
test loss item: 0.20974023640155792
test loss item: 0.1905653327703476
test loss item: 0.17301692068576813
test loss item: 0.32186779379844666
test loss item: 0.19388088583946228
test loss item: 0.1754915565252304
test loss item: 0.20177891850471497
test loss item: 0.5454671382904053
test loss item: 0.26212915778160095
test loss item: 0.24920544028282166
test loss item: 0.20816993713378906
test loss item: 0.40145620703697205
test loss item: 0.36376145482063293
test loss item: 0.10478593409061432
test loss item: 0.647621214389801
test loss item: 0.2223510891199112
test loss item: 0.27984219789505005
test loss item: 0.13160434365272522
test loss item: 0.15958917140960693
test loss item: 0.15141436457633972
test loss item: 0.8801490664482117
test loss item: 0.31721606850624084
test loss item: 0.16654878854751587
test loss item: 0.09368784725666046
test loss item: 0.6575867533683777
test loss item: 0.634811282157898
test loss item: 0.6204633116722107
test loss item: 0.1728341430425644
test loss item: 0.1753714382648468
test loss item: 0.09615317732095718
test loss item: 0.09753245860338211
test loss item: 0.1807059645652771
Epoch [3/50], Training Loss: 0.4314, Testing Loss: 0.2928
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/50
train loss item: 0.35598820447921753
train loss item: 0.8042619824409485
train loss item: 0.20258288085460663
train loss item: 0.3679743707180023
train loss item: 0.3493640124797821
train loss item: 0.2614400386810303
train loss item: 0.2123015820980072
train loss item: 0.49573248624801636
train loss item: 0.12789037823677063
train loss item: 0.22288234531879425
train loss item: 0.2549700140953064
train loss item: 0.2291392683982849
train loss item: 0.1250050812959671
train loss item: 0.38927099108695984
train loss item: 0.1970185786485672
train loss item: 0.5646058320999146
train loss item: 0.08877763152122498
train loss item: 0.20903925597667694
train loss item: 0.22932535409927368
train loss item: 0.23731489479541779
train loss item: 0.1798063963651657
train loss item: 0.15170565247535706
train loss item: 0.6788648366928101
train loss item: 0.7174670100212097
train loss item: 0.40623781085014343
train loss item: 0.21019499003887177
train loss item: 0.18434979021549225
train loss item: 0.20658157765865326
train loss item: 0.0767621323466301
train loss item: 0.484586626291275
train loss item: 1.5610963106155396
train loss item: 0.4576701819896698
train loss item: 0.11579523980617523
train loss item: 0.32334160804748535
train loss item: 0.1675577461719513
train loss item: 1.7904075384140015
train loss item: 0.4623925983905792
train loss item: 0.3854462206363678
train loss item: 0.519524097442627
train loss item: 0.22983407974243164
train loss item: 0.25588035583496094
train loss item: 0.20621319115161896
train loss item: 0.28468814492225647
train loss item: 0.18225841224193573
train loss item: 0.5219123959541321
train loss item: 0.1323309987783432
train loss item: 0.10669330507516861
train loss item: 0.34430891275405884
train loss item: 0.18780651688575745
train loss item: 0.1343318372964859
train loss item: 0.2666662931442261
train loss item: 0.7907475233078003
train loss item: 0.0894383043050766
train loss item: 0.16132991015911102
train loss item: 1.8235493898391724
train loss item: 0.15067575871944427
train loss item: 0.24774223566055298
train loss item: 0.18197417259216309
train loss item: 0.1380002647638321
train loss item: 0.13140511512756348
train loss item: 0.5338607430458069
train loss item: 1.5581157207489014
train loss item: 0.19453473389148712
train loss item: 0.3236832320690155
train loss item: 0.15777035057544708
train loss item: 0.4651155173778534
train loss item: 0.41722169518470764
train loss item: 0.2116740345954895
train loss item: 0.23992526531219482
train loss item: 0.26229363679885864
train loss item: 0.2425377070903778
train loss item: 0.13498054444789886
train loss item: 0.15224233269691467
train loss item: 0.22560636699199677
train loss item: 0.09823179244995117
train loss item: 0.10817596316337585
train loss item: 0.5941234827041626
train loss item: 1.1474241018295288
train loss item: 0.07439909130334854
train loss item: 0.18922768533229828
train loss item: 0.13035689294338226
train loss item: 0.15190459787845612
train loss item: 0.2061934918165207
train loss item: 0.3775103986263275
train loss item: 0.3153328597545624
train loss item: 0.35125240683555603
train loss item: 3.4140055179595947
train loss item: 0.12561409175395966
train loss item: 0.2921113967895508
test loss item: 0.14565269649028778
test loss item: 0.09972818195819855
test loss item: 0.31904807686805725
test loss item: 0.17741473019123077
test loss item: 0.17818129062652588
test loss item: 0.1090296283364296
test loss item: 0.9717305302619934
test loss item: 0.3816626965999603
test loss item: 0.1452505886554718
test loss item: 0.2422090768814087
test loss item: 0.5103796124458313
test loss item: 0.12755726277828217
test loss item: 0.14440789818763733
test loss item: 0.2017776519060135
test loss item: 0.1303005814552307
test loss item: 0.08662473410367966
test loss item: 0.18547125160694122
test loss item: 0.2678360939025879
test loss item: 0.48603954911231995
test loss item: 0.17721052467823029
test loss item: 0.42158231139183044
test loss item: 0.26450249552726746
test loss item: 0.18629325926303864
test loss item: 0.13067232072353363
test loss item: 0.1426168531179428
test loss item: 0.19152763485908508
test loss item: 0.20925676822662354
test loss item: 0.14573708176612854
test loss item: 0.21618017554283142
test loss item: 0.22732073068618774
test loss item: 0.41734644770622253
test loss item: 0.07876484841108322
test loss item: 0.11808403581380844
test loss item: 0.3473883271217346
test loss item: 0.23896190524101257
test loss item: 0.33106085658073425
test loss item: 0.5586614608764648
test loss item: 0.7654697895050049
test loss item: 0.27772554755210876
test loss item: 0.19078901410102844
test loss item: 0.2128448337316513
test loss item: 0.15439927577972412
test loss item: 0.22256439924240112
test loss item: 0.1414870321750641
test loss item: 0.33886849880218506
test loss item: 0.2580082416534424
test loss item: 0.19026507437229156
test loss item: 0.18398751318454742
test loss item: 0.2912936806678772
test loss item: 0.4199453592300415
test loss item: 0.19200272858142853
test loss item: 0.12052552402019501
test loss item: 0.1610703319311142
test loss item: 0.12301196902990341
test loss item: 0.19241128861904144
test loss item: 0.4637324810028076
test loss item: 0.39481818675994873
test loss item: 0.16888964176177979
test loss item: 0.16964846849441528
test loss item: 0.1543264091014862
test loss item: 0.2779274880886078
test loss item: 0.16815245151519775
test loss item: 0.15325114130973816
test loss item: 0.1821765899658203
test loss item: 0.4927235543727875
test loss item: 0.24160215258598328
test loss item: 0.222931370139122
test loss item: 0.18811367452144623
test loss item: 0.34758302569389343
test loss item: 0.32354772090911865
test loss item: 0.08773090690374374
test loss item: 0.5885575413703918
test loss item: 0.1844480335712433
test loss item: 0.24837709963321686
test loss item: 0.11248736828565598
test loss item: 0.12719129025936127
test loss item: 0.13286513090133667
test loss item: 0.7408822774887085
test loss item: 0.26143887639045715
test loss item: 0.14205902814865112
test loss item: 0.08329802006483078
test loss item: 0.5837969779968262
test loss item: 0.5615742802619934
test loss item: 0.5285375714302063
test loss item: 0.1554044932126999
test loss item: 0.1572323888540268
test loss item: 0.08322959393262863
test loss item: 0.07697780430316925
test loss item: 0.17034783959388733
Epoch [4/50], Training Loss: 0.3850, Testing Loss: 0.2553
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/50
train loss item: 0.32581350207328796
train loss item: 0.68785560131073
train loss item: 0.1689162701368332
train loss item: 0.30728569626808167
train loss item: 0.3112659454345703
train loss item: 0.23388192057609558
train loss item: 0.197120800614357
train loss item: 0.4242609739303589
train loss item: 0.1765977442264557
train loss item: 0.22172120213508606
train loss item: 0.23896799981594086
train loss item: 0.21106785535812378
train loss item: 0.12419063597917557
train loss item: 0.35141801834106445
train loss item: 0.1784149706363678
train loss item: 0.4844543933868408
train loss item: 0.07442507147789001
train loss item: 0.20637254416942596
train loss item: 0.22465862333774567
train loss item: 0.2201792299747467
train loss item: 0.15568211674690247
train loss item: 0.14188474416732788
train loss item: 0.6201402544975281
train loss item: 0.6293896436691284
train loss item: 0.35873788595199585
train loss item: 0.19969846308231354
train loss item: 0.15493755042552948
train loss item: 0.20293501019477844
train loss item: 0.07407943159341812
train loss item: 0.4112387001514435
train loss item: 1.4342401027679443
train loss item: 0.3921287953853607
train loss item: 0.10434434562921524
train loss item: 0.2508352994918823
train loss item: 0.16025130450725555
train loss item: 1.702993392944336
train loss item: 0.448997437953949
train loss item: 0.34260207414627075
train loss item: 0.49870890378952026
train loss item: 0.2139338254928589
train loss item: 0.19328752160072327
train loss item: 0.177623450756073
train loss item: 0.2676558792591095
train loss item: 0.17365793883800507
train loss item: 0.4857686161994934
train loss item: 0.12671495974063873
train loss item: 0.09315690398216248
train loss item: 0.32812294363975525
train loss item: 0.17049795389175415
train loss item: 0.12038741260766983
train loss item: 0.255161851644516
train loss item: 0.7218571901321411
train loss item: 0.07501495629549026
train loss item: 0.13650180399417877
train loss item: 1.7010846138000488
train loss item: 0.13872185349464417
train loss item: 0.21724967658519745
train loss item: 0.16614073514938354
train loss item: 0.11914478242397308
train loss item: 0.12481243908405304
train loss item: 0.4534313678741455
train loss item: 1.4495065212249756
train loss item: 0.16432514786720276
train loss item: 0.3039627969264984
train loss item: 0.13752558827400208
train loss item: 0.45714709162712097
train loss item: 0.37004485726356506
train loss item: 0.19577527046203613
train loss item: 0.2399950921535492
train loss item: 0.2392459511756897
train loss item: 0.22770865261554718
train loss item: 0.13366557657718658
train loss item: 0.13317476212978363
train loss item: 0.2134573608636856
train loss item: 0.09006661176681519
train loss item: 0.10644204914569855
train loss item: 0.5051339864730835
train loss item: 1.0949790477752686
train loss item: 0.07362128049135208
train loss item: 0.18072354793548584
train loss item: 0.11900542676448822
train loss item: 0.13871333003044128
train loss item: 0.18242621421813965
train loss item: 0.34184423089027405
train loss item: 0.31136271357536316
train loss item: 0.2932506203651428
train loss item: 3.2745420932769775
train loss item: 0.11492627114057541
train loss item: 0.2705959975719452
test loss item: 0.13768187165260315
test loss item: 0.1059664711356163
test loss item: 0.31977277994155884
test loss item: 0.1687592715024948
test loss item: 0.1725543588399887
test loss item: 0.10796795785427094
test loss item: 0.9562724828720093
test loss item: 0.3778120279312134
test loss item: 0.14335952699184418
test loss item: 0.2224271446466446
test loss item: 0.5199857354164124
test loss item: 0.12026584893465042
test loss item: 0.13627663254737854
test loss item: 0.18220320343971252
test loss item: 0.13214784860610962
test loss item: 0.08959469944238663
test loss item: 0.17356204986572266
test loss item: 0.23714660108089447
test loss item: 0.46339094638824463
test loss item: 0.16378749907016754
test loss item: 0.36057114601135254
test loss item: 0.25362586975097656
test loss item: 0.17910833656787872
test loss item: 0.12696781754493713
test loss item: 0.12797391414642334
test loss item: 0.17536401748657227
test loss item: 0.19205935299396515
test loss item: 0.1396714299917221
test loss item: 0.2049058973789215
test loss item: 0.20779721438884735
test loss item: 0.4235039949417114
test loss item: 0.07797933369874954
test loss item: 0.11733958125114441
test loss item: 0.3171128034591675
test loss item: 0.22205139696598053
test loss item: 0.30162060260772705
test loss item: 0.5310007929801941
test loss item: 0.8034690022468567
test loss item: 0.24970003962516785
test loss item: 0.17983902990818024
test loss item: 0.20100010931491852
test loss item: 0.151836559176445
test loss item: 0.1871679127216339
test loss item: 0.1350000500679016
test loss item: 0.2863185703754425
test loss item: 0.2409902960062027
test loss item: 0.18057507276535034
test loss item: 0.1689620167016983
test loss item: 0.27554890513420105
test loss item: 0.4104178845882416
test loss item: 0.17607620358467102
test loss item: 0.11413232982158661
test loss item: 0.14997464418411255
test loss item: 0.1134142130613327
test loss item: 0.1721152514219284
test loss item: 0.46589237451553345
test loss item: 0.37748727202415466
test loss item: 0.15686176717281342
test loss item: 0.16111646592617035
test loss item: 0.14196616411209106
test loss item: 0.24335387349128723
test loss item: 0.1659802943468094
test loss item: 0.14308996498584747
test loss item: 0.16723257303237915
test loss item: 0.5097565054893494
test loss item: 0.22614407539367676
test loss item: 0.205703005194664
test loss item: 0.17838770151138306
test loss item: 0.3284565508365631
test loss item: 0.3089136779308319
test loss item: 0.09263037145137787
test loss item: 0.5735708475112915
test loss item: 0.16399429738521576
test loss item: 0.23387542366981506
test loss item: 0.11196247488260269
test loss item: 0.13189364969730377
test loss item: 0.1301286220550537
test loss item: 0.8231484293937683
test loss item: 0.24050746858119965
test loss item: 0.13361811637878418
test loss item: 0.08650367707014084
test loss item: 0.585909903049469
test loss item: 0.5388631224632263
test loss item: 0.569173276424408
test loss item: 0.14117766916751862
test loss item: 0.14822301268577576
test loss item: 0.08463791012763977
test loss item: 0.07698342204093933
test loss item: 0.1599806547164917
Epoch [5/50], Training Loss: 0.3537, Testing Loss: 0.2460
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/50
train loss item: 0.29320305585861206
train loss item: 0.5805436968803406
train loss item: 0.14905251562595367
train loss item: 0.2696644961833954
train loss item: 0.3526644706726074
train loss item: 0.20412614941596985
train loss item: 0.17097285389900208
train loss item: 0.3893434703350067
train loss item: 0.11060600727796555
train loss item: 0.183033749461174
train loss item: 0.19801367819309235
train loss item: 0.1877201348543167
train loss item: 0.11137298494577408
train loss item: 0.3192380368709564
train loss item: 0.1562434881925583
train loss item: 0.4516353905200958
train loss item: 0.07345494627952576
train loss item: 0.1695288121700287
train loss item: 0.21061256527900696
train loss item: 0.20932209491729736
train loss item: 0.17414578795433044
train loss item: 0.11421645432710648
train loss item: 0.5337414741516113
train loss item: 0.5032087564468384
train loss item: 0.31887197494506836
train loss item: 0.2126837521791458
train loss item: 0.1517699807882309
train loss item: 0.17568644881248474
train loss item: 0.062321364879608154
train loss item: 0.3854527175426483
train loss item: 1.3103365898132324
train loss item: 0.36351656913757324
train loss item: 0.0981878712773323
train loss item: 0.2768467664718628
train loss item: 0.13831759989261627
train loss item: 1.6364707946777344
train loss item: 0.40737658739089966
train loss item: 0.33419039845466614
train loss item: 0.3907160460948944
train loss item: 0.18263813853263855
train loss item: 0.1967734843492508
train loss item: 0.17326509952545166
train loss item: 0.2670568525791168
train loss item: 0.1632065623998642
train loss item: 0.46508556604385376
train loss item: 0.11305629462003708
train loss item: 0.08695494383573532
train loss item: 0.31322571635246277
train loss item: 0.15751515328884125
train loss item: 0.1157083809375763
train loss item: 0.2415366768836975
train loss item: 0.6862843632698059
train loss item: 0.0901777520775795
train loss item: 0.12894639372825623
train loss item: 1.6379867792129517
train loss item: 0.1284150779247284
train loss item: 0.2076406031847
train loss item: 0.16328901052474976
train loss item: 0.1148693636059761
train loss item: 0.11874019354581833
train loss item: 0.41115501523017883
train loss item: 1.3698383569717407
train loss item: 0.17907081544399261
train loss item: 0.2948562204837799
train loss item: 0.1353941559791565
train loss item: 0.3976072669029236
train loss item: 0.33196479082107544
train loss item: 0.1802922636270523
train loss item: 0.22621162235736847
train loss item: 0.2157512605190277
train loss item: 0.18949832022190094
train loss item: 0.12313772737979889
train loss item: 0.11549437046051025
train loss item: 0.19016426801681519
train loss item: 0.08416938781738281
train loss item: 0.09861043840646744
train loss item: 0.432945191860199
train loss item: 1.058131217956543
train loss item: 0.07063532620668411
train loss item: 0.1679442822933197
train loss item: 0.10572709143161774
train loss item: 0.13583625853061676
train loss item: 0.1750384271144867
train loss item: 0.32985660433769226
train loss item: 0.30972784757614136
train loss item: 0.24969516694545746
train loss item: 3.162214517593384
train loss item: 0.11106190085411072
train loss item: 0.2436966598033905
test loss item: 0.13393378257751465
test loss item: 0.10357894748449326
test loss item: 0.2958117127418518
test loss item: 0.16854976117610931
test loss item: 0.1688220053911209
test loss item: 0.1133871003985405
test loss item: 0.9990813136100769
test loss item: 0.39635494351387024
test loss item: 0.13704971969127655
test loss item: 0.20606768131256104
test loss item: 0.47104525566101074
test loss item: 0.1191643476486206
test loss item: 0.13038741052150726
test loss item: 0.17485173046588898
test loss item: 0.12715749442577362
test loss item: 0.0812983587384224
test loss item: 0.17023028433322906
test loss item: 0.21570591628551483
test loss item: 0.4580610990524292
test loss item: 0.15953487157821655
test loss item: 0.32708415389060974
test loss item: 0.25699982047080994
test loss item: 0.17102180421352386
test loss item: 0.12885412573814392
test loss item: 0.11782849580049515
test loss item: 0.16604000329971313
test loss item: 0.18112468719482422
test loss item: 0.1402529925107956
test loss item: 0.1970791220664978
test loss item: 0.19204473495483398
test loss item: 0.4119473397731781
test loss item: 0.07461952418088913
test loss item: 0.11945777386426926
test loss item: 0.28864821791648865
test loss item: 0.2030782401561737
test loss item: 0.28864234685897827
test loss item: 0.5294782519340515
test loss item: 0.7002312541007996
test loss item: 0.2344382256269455
test loss item: 0.18493503332138062
test loss item: 0.2028270661830902
test loss item: 0.14217793941497803
test loss item: 0.16722866892814636
test loss item: 0.13906803727149963
test loss item: 0.2565750181674957
test loss item: 0.23521862924098969
test loss item: 0.16720357537269592
test loss item: 0.15829229354858398
test loss item: 0.2653719186782837
test loss item: 0.37332406640052795
test loss item: 0.16804450750350952
test loss item: 0.10924287140369415
test loss item: 0.14410527050495148
test loss item: 0.11569545418024063
test loss item: 0.15690861642360687
test loss item: 0.4290822744369507
test loss item: 0.3617810606956482
test loss item: 0.1514548510313034
test loss item: 0.15716642141342163
test loss item: 0.13262292742729187
test loss item: 0.21600255370140076
test loss item: 0.1671982705593109
test loss item: 0.13945800065994263
test loss item: 0.15862970054149628
test loss item: 0.502632200717926
test loss item: 0.22253470122814178
test loss item: 0.1988542228937149
test loss item: 0.17304226756095886
test loss item: 0.29881998896598816
test loss item: 0.3042055070400238
test loss item: 0.08175045251846313
test loss item: 0.5960285663604736
test loss item: 0.15617534518241882
test loss item: 0.23675446212291718
test loss item: 0.10468503832817078
test loss item: 0.12289951741695404
test loss item: 0.13091862201690674
test loss item: 0.7389742732048035
test loss item: 0.22676850855350494
test loss item: 0.13411317765712738
test loss item: 0.07874544709920883
test loss item: 0.5552128553390503
test loss item: 0.5290501713752747
test loss item: 0.5114342570304871
test loss item: 0.13149520754814148
test loss item: 0.13825589418411255
test loss item: 0.07461167871952057
test loss item: 0.07025996595621109
test loss item: 0.1460951566696167
Epoch [6/50], Training Loss: 0.3284, Testing Loss: 0.2351
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/50
train loss item: 0.2690553069114685
train loss item: 0.49744337797164917
train loss item: 0.13738177716732025
train loss item: 0.2517392039299011
train loss item: 0.4249652922153473
train loss item: 0.18617942929267883
train loss item: 0.16257934272289276
train loss item: 0.3538842797279358
train loss item: 0.14375701546669006
train loss item: 0.17670544981956482
train loss item: 0.19733184576034546
train loss item: 0.17067871987819672
train loss item: 0.11193565279245377
train loss item: 0.320523738861084
train loss item: 0.15368053317070007
train loss item: 0.41376933455467224
train loss item: 0.06317641586065292
train loss item: 0.1736326664686203
train loss item: 0.21353700757026672
train loss item: 0.1905270367860794
train loss item: 0.13855664432048798
train loss item: 0.1220477893948555
train loss item: 0.4792018234729767
train loss item: 0.49927785992622375
train loss item: 0.29672831296920776
train loss item: 0.18822531402111053
train loss item: 0.12336472421884537
train loss item: 0.1793680191040039
train loss item: 0.08580301702022552
train loss item: 0.3248717486858368
train loss item: 1.2291922569274902
train loss item: 0.33194682002067566
train loss item: 0.097310870885849
train loss item: 0.19097164273262024
train loss item: 0.13795098662376404
train loss item: 1.5682363510131836
train loss item: 0.40128469467163086
train loss item: 0.2984718978404999
train loss item: 0.3751593232154846
train loss item: 0.1798751801252365
train loss item: 0.14379937946796417
train loss item: 0.15079541504383087
train loss item: 0.25121989846229553
train loss item: 0.1555170863866806
train loss item: 0.4381895065307617
train loss item: 0.10837026685476303
train loss item: 0.08130300045013428
train loss item: 0.3129991590976715
train loss item: 0.15698666870594025
train loss item: 0.10446800291538239
train loss item: 0.23250925540924072
train loss item: 0.6412122249603271
train loss item: 0.07863409072160721
train loss item: 0.11463811993598938
train loss item: 1.5247571468353271
train loss item: 0.12457915395498276
train loss item: 0.18448799848556519
train loss item: 0.14954979717731476
train loss item: 0.10339120030403137
train loss item: 0.11032659560441971
train loss item: 0.3600628077983856
train loss item: 1.2641246318817139
train loss item: 0.15158332884311676
train loss item: 0.2950957715511322
train loss item: 0.12259450554847717
train loss item: 0.37809208035469055
train loss item: 0.33744993805885315
train loss item: 0.1742953062057495
train loss item: 0.22065968811511993
train loss item: 0.2067362368106842
train loss item: 0.18696272373199463
train loss item: 0.1116843894124031
train loss item: 0.11276288330554962
train loss item: 0.18292659521102905
train loss item: 0.07894188165664673
train loss item: 0.0948614776134491
train loss item: 0.3748113214969635
train loss item: 1.0598634481430054
train loss item: 0.06856154650449753
train loss item: 0.1671118289232254
train loss item: 0.10189405083656311
train loss item: 0.12024785578250885
train loss item: 0.15847009420394897
train loss item: 0.3238813579082489
train loss item: 0.28711453080177307
train loss item: 0.23167690634727478
train loss item: 3.051436185836792
train loss item: 0.10099801421165466
train loss item: 0.2268325835466385
test loss item: 0.1240791380405426
test loss item: 0.09598342329263687
test loss item: 0.3296798765659332
test loss item: 0.15440692007541656
test loss item: 0.15695174038410187
test loss item: 0.0931185707449913
test loss item: 0.9716061353683472
test loss item: 0.37875816226005554
test loss item: 0.1354641169309616
test loss item: 0.20517221093177795
test loss item: 0.5277541279792786
test loss item: 0.10979904979467392
test loss item: 0.1292227804660797
test loss item: 0.15989349782466888
test loss item: 0.12087912857532501
test loss item: 0.07911522686481476
test loss item: 0.1619492918252945
test loss item: 0.21053652465343475
test loss item: 0.4381956458091736
test loss item: 0.1525784581899643
test loss item: 0.3099415600299835
test loss item: 0.24550046026706696
test loss item: 0.15422160923480988
test loss item: 0.11701967567205429
test loss item: 0.11377236992120743
test loss item: 0.15866532921791077
test loss item: 0.1708991527557373
test loss item: 0.12285982817411423
test loss item: 0.18496085703372955
test loss item: 0.18587857484817505
test loss item: 0.45008084177970886
test loss item: 0.06995292007923126
test loss item: 0.10863617807626724
test loss item: 0.29045212268829346
test loss item: 0.20906654000282288
test loss item: 0.27688485383987427
test loss item: 0.5065251588821411
test loss item: 0.8468614816665649
test loss item: 0.22955481708049774
test loss item: 0.16804856061935425
test loss item: 0.19102701544761658
test loss item: 0.1340673416852951
test loss item: 0.15875059366226196
test loss item: 0.13062721490859985
test loss item: 0.23830854892730713
test loss item: 0.228145033121109
test loss item: 0.15104658901691437
test loss item: 0.1508326381444931
test loss item: 0.2701716423034668
test loss item: 0.39219194650650024
test loss item: 0.15956753492355347
test loss item: 0.10371711105108261
test loss item: 0.13894405961036682
test loss item: 0.10433509945869446
test loss item: 0.152035653591156
test loss item: 0.48530706763267517
test loss item: 0.3605579733848572
test loss item: 0.1352187693119049
test loss item: 0.14961308240890503
test loss item: 0.1307988315820694
test loss item: 0.20720332860946655
test loss item: 0.16371262073516846
test loss item: 0.1335718035697937
test loss item: 0.15119688212871552
test loss item: 0.5494830012321472
test loss item: 0.20674240589141846
test loss item: 0.18994416296482086
test loss item: 0.16364529728889465
test loss item: 0.3120814263820648
test loss item: 0.2889366149902344
test loss item: 0.08081785589456558
test loss item: 0.5699342489242554
test loss item: 0.14091269671916962
test loss item: 0.22418774664402008
test loss item: 0.10134685784578323
test loss item: 0.10969043523073196
test loss item: 0.11909951269626617
test loss item: 0.9325453639030457
test loss item: 0.22462445497512817
test loss item: 0.11650845408439636
test loss item: 0.07579264044761658
test loss item: 0.589994490146637
test loss item: 0.5174623727798462
test loss item: 0.624301016330719
test loss item: 0.12471108138561249
test loss item: 0.13341917097568512
test loss item: 0.07084465026855469
test loss item: 0.06542738527059555
test loss item: 0.1530046910047531
Epoch [7/50], Training Loss: 0.3099, Testing Loss: 0.2355
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/50
train loss item: 0.2528838515281677
train loss item: 0.427629292011261
train loss item: 0.12645593285560608
train loss item: 0.2237349897623062
train loss item: 0.20248228311538696
train loss item: 0.1702497899532318
train loss item: 0.15236905217170715
train loss item: 0.323435515165329
train loss item: 0.08630666136741638
train loss item: 0.13210713863372803
train loss item: 0.15939323604106903
train loss item: 0.15978282690048218
train loss item: 0.10087749361991882
train loss item: 0.28691884875297546
train loss item: 0.1444740742444992
train loss item: 0.3982611298561096
train loss item: 0.05664179101586342
train loss item: 0.14752742648124695
train loss item: 0.17748518288135529
train loss item: 0.17338378727436066
train loss item: 0.13567906618118286
train loss item: 0.10308843851089478
train loss item: 0.43387317657470703
train loss item: 0.40207719802856445
train loss item: 0.2729128301143646
train loss item: 0.1728721261024475
train loss item: 0.11465610563755035
train loss item: 0.15900446474552155
train loss item: 0.06491198390722275
train loss item: 0.30267369747161865
train loss item: 1.0976018905639648
train loss item: 0.3256727457046509
train loss item: 0.08617018908262253
train loss item: 0.17329692840576172
train loss item: 0.11731186509132385
train loss item: 1.5082688331604004
train loss item: 0.34731221199035645
train loss item: 0.28172770142555237
train loss item: 0.2630724310874939
train loss item: 0.16403090953826904
train loss item: 0.14118212461471558
train loss item: 0.14349167048931122
train loss item: 0.23966936767101288
train loss item: 0.14428740739822388
train loss item: 0.4161389172077179
train loss item: 0.09893588721752167
train loss item: 0.07732409983873367
train loss item: 0.27518850564956665
train loss item: 0.1405133455991745
train loss item: 0.09741561114788055
train loss item: 0.196659117937088
train loss item: 0.5679452419281006
train loss item: 0.07137337327003479
train loss item: 0.10261611640453339
train loss item: 1.4224164485931396
train loss item: 0.11362934112548828
train loss item: 0.16704009473323822
train loss item: 0.14542832970619202
train loss item: 0.0990021675825119
train loss item: 0.10960327833890915
train loss item: 0.30949684977531433
train loss item: 1.1684331893920898
train loss item: 0.14756785333156586
train loss item: 0.2709764838218689
train loss item: 0.10073646903038025
train loss item: 0.3099285066127777
train loss item: 0.28105005621910095
train loss item: 0.15291036665439606
train loss item: 0.23596982657909393
train loss item: 0.1867050975561142
train loss item: 0.15436257421970367
train loss item: 0.10321608930826187
train loss item: 0.10721120238304138
train loss item: 0.1671491116285324
train loss item: 0.07340051233768463
train loss item: 0.08864691108465195
train loss item: 0.3378825783729553
train loss item: 1.0037657022476196
train loss item: 0.06352069228887558
train loss item: 0.15329252183437347
train loss item: 0.09475479274988174
train loss item: 0.11597327888011932
train loss item: 0.14219924807548523
train loss item: 0.32690712809562683
train loss item: 0.3063502013683319
train loss item: 0.21125416457653046
train loss item: 2.968294382095337
train loss item: 0.09563782811164856
train loss item: 0.21589359641075134
test loss item: 0.12377011030912399
test loss item: 0.09392551332712173
test loss item: 0.3073958158493042
test loss item: 0.15461768209934235
test loss item: 0.15371038019657135
test loss item: 0.09528287500143051
test loss item: 1.122927188873291
test loss item: 0.45025989413261414
test loss item: 0.1317608803510666
test loss item: 0.20129232108592987
test loss item: 0.5079737901687622
test loss item: 0.10797584801912308
test loss item: 0.13423164188861847
test loss item: 0.17538900673389435
test loss item: 0.11646212637424469
test loss item: 0.081511490046978
test loss item: 0.18026195466518402
test loss item: 0.20049840211868286
test loss item: 0.47689536213874817
test loss item: 0.17939233779907227
test loss item: 0.2899298071861267
test loss item: 0.26904165744781494
test loss item: 0.16154201328754425
test loss item: 0.12209343910217285
test loss item: 0.112668976187706
test loss item: 0.15499094128608704
test loss item: 0.18019868433475494
test loss item: 0.12267591804265976
test loss item: 0.1854882538318634
test loss item: 0.18535886704921722
test loss item: 0.4805345833301544
test loss item: 0.07008466869592667
test loss item: 0.1108919084072113
test loss item: 0.2729020416736603
test loss item: 0.19522209465503693
test loss item: 0.2839915454387665
test loss item: 0.5511936545372009
test loss item: 0.7989203929901123
test loss item: 0.22439782321453094
test loss item: 0.17739441990852356
test loss item: 0.20299023389816284
test loss item: 0.1449023336172104
test loss item: 0.15464884042739868
test loss item: 0.14160771667957306
test loss item: 0.22527235746383667
test loss item: 0.2625231146812439
test loss item: 0.16464851796627045
test loss item: 0.1791514903306961
test loss item: 0.27174463868141174
test loss item: 0.395827054977417
test loss item: 0.151327446103096
test loss item: 0.11023924499750137
test loss item: 0.14175568521022797
test loss item: 0.10700935870409012
test loss item: 0.14263315498828888
test loss item: 0.448329359292984
test loss item: 0.3782813251018524
test loss item: 0.1491878181695938
test loss item: 0.15602174401283264
test loss item: 0.1258062720298767
test loss item: 0.19416671991348267
test loss item: 0.1889554262161255
test loss item: 0.1425967961549759
test loss item: 0.14826279878616333
test loss item: 0.548929750919342
test loss item: 0.20515012741088867
test loss item: 0.20123693346977234
test loss item: 0.16850784420967102
test loss item: 0.2965027391910553
test loss item: 0.3226521909236908
test loss item: 0.08138863742351532
test loss item: 0.6634848117828369
test loss item: 0.1616768091917038
test loss item: 0.24932676553726196
test loss item: 0.11300212144851685
test loss item: 0.12182901799678802
test loss item: 0.123351089656353
test loss item: 0.9022581577301025
test loss item: 0.2335069626569748
test loss item: 0.12146558612585068
test loss item: 0.07504896819591522
test loss item: 0.6226820945739746
test loss item: 0.5609545111656189
test loss item: 0.6104802489280701
test loss item: 0.12414433807134628
test loss item: 0.1436799317598343
test loss item: 0.0712922215461731
test loss item: 0.06640568375587463
test loss item: 0.14032141864299774
Epoch [8/50], Training Loss: 0.2819, Testing Loss: 0.2427
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/50
train loss item: 0.2374982386827469
train loss item: 0.40055015683174133
train loss item: 0.1167987808585167
train loss item: 0.20894436538219452
train loss item: 0.20831595361232758
train loss item: 0.15450617671012878
train loss item: 0.13914388418197632
train loss item: 0.29502251744270325
train loss item: 0.07055243104696274
train loss item: 0.1269502192735672
train loss item: 0.1549794226884842
train loss item: 0.1482437402009964
train loss item: 0.09766502678394318
train loss item: 0.28848928213119507
train loss item: 0.13821254670619965
train loss item: 0.33291715383529663
train loss item: 0.05164565145969391
train loss item: 0.14712253212928772
train loss item: 0.16956134140491486
train loss item: 0.15950541198253632
train loss item: 0.13811035454273224
train loss item: 0.10271681100130081
train loss item: 0.3731910288333893
train loss item: 0.33081719279289246
train loss item: 0.2717144191265106
train loss item: 0.16518329083919525
train loss item: 0.10985120385885239
train loss item: 0.15054567158222198
train loss item: 0.05647026374936104
train loss item: 0.278583824634552
train loss item: 0.9928182363510132
train loss item: 0.3021385967731476
train loss item: 0.08487557619810104
train loss item: 0.18241804838180542
train loss item: 0.10720616579055786
train loss item: 1.4582912921905518
train loss item: 0.3089795410633087
train loss item: 0.25437527894973755
train loss item: 0.23665231466293335
train loss item: 0.1484738439321518
train loss item: 0.1301424652338028
train loss item: 0.13487185537815094
train loss item: 0.23341356217861176
train loss item: 0.12759675085544586
train loss item: 0.4039498269557953
train loss item: 0.09271305054426193
train loss item: 0.07573790103197098
train loss item: 0.24997766315937042
train loss item: 0.1282196342945099
train loss item: 0.09311742335557938
train loss item: 0.1627413034439087
train loss item: 0.49946674704551697
train loss item: 0.07010894268751144
train loss item: 0.09899761527776718
train loss item: 1.3499504327774048
train loss item: 0.10299330204725266
train loss item: 0.16261199116706848
train loss item: 0.14151550829410553
train loss item: 0.10643008351325989
train loss item: 0.10094919800758362
train loss item: 0.27501288056373596
train loss item: 1.0887137651443481
train loss item: 0.133083313703537
train loss item: 0.24906140565872192
train loss item: 0.09427778422832489
train loss item: 0.27248242497444153
train loss item: 0.2652284801006317
train loss item: 0.1499801129102707
train loss item: 0.24217376112937927
train loss item: 0.17603272199630737
train loss item: 0.14766594767570496
train loss item: 0.09693893045186996
train loss item: 0.10185074061155319
train loss item: 0.17322713136672974
train loss item: 0.06485071033239365
train loss item: 0.085330069065094
train loss item: 0.3007562756538391
train loss item: 0.9958276748657227
train loss item: 0.05872207507491112
train loss item: 0.14242765307426453
train loss item: 0.09104056656360626
train loss item: 0.10478385537862778
train loss item: 0.14052598178386688
train loss item: 0.33270928263664246
train loss item: 0.31591475009918213
train loss item: 0.2072223722934723
train loss item: 2.8470962047576904
train loss item: 0.09075410664081573
train loss item: 0.20944857597351074
test loss item: 0.11752871423959732
test loss item: 0.09182057529687881
test loss item: 0.29529035091400146
test loss item: 0.14318953454494476
test loss item: 0.15031376481056213
test loss item: 0.09799589961767197
test loss item: 1.0472569465637207
test loss item: 0.3987392783164978
test loss item: 0.12727373838424683
test loss item: 0.1934366524219513
test loss item: 0.5006910562515259
test loss item: 0.1041373685002327
test loss item: 0.13850176334381104
test loss item: 0.16605418920516968
test loss item: 0.11387866735458374
test loss item: 0.07570847868919373
test loss item: 0.1663714498281479
test loss item: 0.18857838213443756
test loss item: 0.43425002694129944
test loss item: 0.174860879778862
test loss item: 0.2728215456008911
test loss item: 0.24111559987068176
test loss item: 0.15811090171337128
test loss item: 0.11536365747451782
test loss item: 0.10739501565694809
test loss item: 0.14489220082759857
test loss item: 0.17107750475406647
test loss item: 0.12392605096101761
test loss item: 0.1785450577735901
test loss item: 0.17465659976005554
test loss item: 0.45631077885627747
test loss item: 0.06582332402467728
test loss item: 0.10643463581800461
test loss item: 0.2519518733024597
test loss item: 0.18493729829788208
test loss item: 0.26571354269981384
test loss item: 0.5050450563430786
test loss item: 0.7821879982948303
test loss item: 0.21318525075912476
test loss item: 0.16431808471679688
test loss item: 0.18485672771930695
test loss item: 0.14410348236560822
test loss item: 0.14815595746040344
test loss item: 0.12964467704296112
test loss item: 0.21620550751686096
test loss item: 0.24399058520793915
test loss item: 0.16311639547348022
test loss item: 0.17248189449310303
test loss item: 0.2586667537689209
test loss item: 0.3766801357269287
test loss item: 0.15007002651691437
test loss item: 0.10966090112924576
test loss item: 0.13336706161499023
test loss item: 0.09943293780088425
test loss item: 0.13590018451213837
test loss item: 0.4349435865879059
test loss item: 0.350372314453125
test loss item: 0.1545528769493103
test loss item: 0.1473197042942047
test loss item: 0.13028179109096527
test loss item: 0.17932754755020142
test loss item: 0.17200344800949097
test loss item: 0.13518501818180084
test loss item: 0.1476583480834961
test loss item: 0.5236534476280212
test loss item: 0.18911051750183105
test loss item: 0.18631568551063538
test loss item: 0.1575469821691513
test loss item: 0.27883872389793396
test loss item: 0.2929254472255707
test loss item: 0.07636252790689468
test loss item: 0.6049450039863586
test loss item: 0.16479258239269257
test loss item: 0.22637203335762024
test loss item: 0.11133286356925964
test loss item: 0.12095407396554947
test loss item: 0.11609098315238953
test loss item: 0.8848876953125
test loss item: 0.22911210358142853
test loss item: 0.12256568670272827
test loss item: 0.06844776123762131
test loss item: 0.5914137959480286
test loss item: 0.5214745402336121
test loss item: 0.605495810508728
test loss item: 0.12331819534301758
test loss item: 0.14070098102092743
test loss item: 0.06434572488069534
test loss item: 0.06002252921462059
test loss item: 0.13141047954559326
Epoch [9/50], Training Loss: 0.2654, Testing Loss: 0.2306
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/50
train loss item: 0.2224770486354828
train loss item: 0.33948302268981934
train loss item: 0.11266041547060013
train loss item: 0.20600837469100952
train loss item: 0.24760283529758453
train loss item: 0.148628830909729
train loss item: 0.13050943613052368
train loss item: 0.2748238444328308
train loss item: 0.08970768004655838
train loss item: 0.14229294657707214
train loss item: 0.16967962682247162
train loss item: 0.1406877040863037
train loss item: 0.09367577731609344
train loss item: 0.26688891649246216
train loss item: 0.14788508415222168
train loss item: 0.3633423149585724
train loss item: 0.054096173495054245
train loss item: 0.15215586125850677
train loss item: 0.18558858335018158
train loss item: 0.14733709394931793
train loss item: 0.12050636112689972
train loss item: 0.10671630501747131
train loss item: 0.4023003876209259
train loss item: 0.32062825560569763
train loss item: 0.2547696828842163
train loss item: 0.13957040011882782
train loss item: 0.10235916078090668
train loss item: 0.13882741332054138
train loss item: 0.05283390358090401
train loss item: 0.2613881230354309
train loss item: 0.8940519094467163
train loss item: 0.33742108941078186
train loss item: 0.07859686017036438
train loss item: 0.15325893461704254
train loss item: 0.10878139734268188
train loss item: 1.4156290292739868
train loss item: 0.27310019731521606
train loss item: 0.22267073392868042
train loss item: 0.19430802762508392
train loss item: 0.13923613727092743
train loss item: 0.11413094401359558
train loss item: 0.13665072619915009
train loss item: 0.22726953029632568
train loss item: 0.13315676152706146
train loss item: 0.3761923313140869
train loss item: 0.09159670770168304
train loss item: 0.07237442582845688
train loss item: 0.2465955764055252
train loss item: 0.12601684033870697
train loss item: 0.09542570263147354
train loss item: 0.16662156581878662
train loss item: 0.4658965468406677
train loss item: 0.06943871825933456
train loss item: 0.1085200384259224
train loss item: 1.2868480682373047
train loss item: 0.11286081373691559
train loss item: 0.14979678392410278
train loss item: 0.13292023539543152
train loss item: 0.08918994665145874
train loss item: 0.10227891802787781
train loss item: 0.24986106157302856
train loss item: 1.0204546451568604
train loss item: 0.11855567991733551
train loss item: 0.24014396965503693
train loss item: 0.09053007513284683
train loss item: 0.2444775402545929
train loss item: 0.23655569553375244
train loss item: 0.147705078125
train loss item: 0.22596906125545502
train loss item: 0.1679989993572235
train loss item: 0.14017267525196075
train loss item: 0.10119324177503586
train loss item: 0.09853264689445496
train loss item: 0.15963682532310486
train loss item: 0.0639081820845604
train loss item: 0.07993842661380768
train loss item: 0.26140156388282776
train loss item: 0.9708443880081177
train loss item: 0.059662509709596634
train loss item: 0.13848324120044708
train loss item: 0.0855073407292366
train loss item: 0.10294497013092041
train loss item: 0.13824476301670074
train loss item: 0.2877553105354309
train loss item: 0.2565600872039795
train loss item: 0.18964047729969025
train loss item: 2.7744739055633545
train loss item: 0.08931254595518112
train loss item: 0.18855759501457214
test loss item: 0.11829967796802521
test loss item: 0.08338980376720428
test loss item: 0.29378288984298706
test loss item: 0.14336305856704712
test loss item: 0.14508706331253052
test loss item: 0.0945182517170906
test loss item: 1.158809781074524
test loss item: 0.4142834544181824
test loss item: 0.12232186645269394
test loss item: 0.18815013766288757
test loss item: 0.4790390133857727
test loss item: 0.10422325879335403
test loss item: 0.1319609135389328
test loss item: 0.21331489086151123
test loss item: 0.10766774415969849
test loss item: 0.06507077068090439
test loss item: 0.1745334416627884
test loss item: 0.18229785561561584
test loss item: 0.44365108013153076
test loss item: 0.18600229918956757
test loss item: 0.2550666928291321
test loss item: 0.2547212541103363
test loss item: 0.1745637059211731
test loss item: 0.11900981515645981
test loss item: 0.10457000881433487
test loss item: 0.1502959430217743
test loss item: 0.1752479374408722
test loss item: 0.11905123293399811
test loss item: 0.17733284831047058
test loss item: 0.17403775453567505
test loss item: 0.47759926319122314
test loss item: 0.0581916980445385
test loss item: 0.10588912665843964
test loss item: 0.24195174872875214
test loss item: 0.17933224141597748
test loss item: 0.26883208751678467
test loss item: 0.5255251526832581
test loss item: 0.7685022950172424
test loss item: 0.2127605825662613
test loss item: 0.17337951064109802
test loss item: 0.19568705558776855
test loss item: 0.16011551022529602
test loss item: 0.1398768573999405
test loss item: 0.13690005242824554
test loss item: 0.21500509977340698
test loss item: 0.25618603825569153
test loss item: 0.17292505502700806
test loss item: 0.192815899848938
test loss item: 0.25271451473236084
test loss item: 0.3749125301837921
test loss item: 0.14378392696380615
test loss item: 0.10721465945243835
test loss item: 0.1358165591955185
test loss item: 0.10015669465065002
test loss item: 0.13273173570632935
test loss item: 0.4172884225845337
test loss item: 0.34987694025039673
test loss item: 0.16792477667331696
test loss item: 0.14878971874713898
test loss item: 0.12010055780410767
test loss item: 0.17388758063316345
test loss item: 0.17819362878799438
test loss item: 0.14374589920043945
test loss item: 0.14304018020629883
test loss item: 0.5193951725959778
test loss item: 0.18952620029449463
test loss item: 0.1962553858757019
test loss item: 0.15952980518341064
test loss item: 0.2703341543674469
test loss item: 0.29049742221832275
test loss item: 0.06770110875368118
test loss item: 0.6508193016052246
test loss item: 0.18757691979408264
test loss item: 0.24750028550624847
test loss item: 0.1099463477730751
test loss item: 0.13150368630886078
test loss item: 0.11963138729333878
test loss item: 0.869256317615509
test loss item: 0.2560209631919861
test loss item: 0.12410102039575577
test loss item: 0.062423430383205414
test loss item: 0.6114076375961304
test loss item: 0.5431535243988037
test loss item: 0.5935313701629639
test loss item: 0.1280086487531662
test loss item: 0.14130890369415283
test loss item: 0.0553220696747303
test loss item: 0.05115294083952904
test loss item: 0.14682699739933014
Epoch [10/50], Training Loss: 0.2538, Testing Loss: 0.2342
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 11/50
train loss item: 0.21223869919776917
train loss item: 0.3244521915912628
train loss item: 0.11482927203178406
train loss item: 0.17946307361125946
train loss item: 0.2527591586112976
train loss item: 0.14693492650985718
train loss item: 0.1267046183347702
train loss item: 0.27284348011016846
train loss item: 0.07475080341100693
train loss item: 0.14769141376018524
train loss item: 0.16473159193992615
train loss item: 0.13688373565673828
train loss item: 0.09205754101276398
train loss item: 0.26811137795448303
train loss item: 0.10702762752771378
train loss item: 0.28783008456230164
train loss item: 0.05958198755979538
train loss item: 0.12757155299186707
train loss item: 0.23502524197101593
train loss item: 0.14687560498714447
train loss item: 0.14425607025623322
train loss item: 0.0825117975473404
train loss item: 0.37044721841812134
train loss item: 0.29537153244018555
train loss item: 0.24645866453647614
train loss item: 0.13128989934921265
train loss item: 0.11279089003801346
train loss item: 0.14879584312438965
train loss item: 0.05228910595178604
train loss item: 0.3083121180534363
train loss item: 1.0306668281555176
train loss item: 0.27633073925971985
train loss item: 0.08160711824893951
train loss item: 0.1698530912399292
train loss item: 0.10492950677871704
train loss item: 1.3693110942840576
train loss item: 0.3349650502204895
train loss item: 0.28044864535331726
train loss item: 0.37729328870773315
train loss item: 0.15986427664756775
train loss item: 0.15762513875961304
train loss item: 0.14589598774909973
train loss item: 0.24656575918197632
train loss item: 0.15027397871017456
train loss item: 0.41482827067375183
train loss item: 0.09040084481239319
train loss item: 0.07982239872217178
train loss item: 0.2839852273464203
train loss item: 0.1442011147737503
train loss item: 0.09822510182857513
train loss item: 0.2028578668832779
train loss item: 0.6575304865837097
train loss item: 0.07636724412441254
train loss item: 0.0874837189912796
train loss item: 1.341731309890747
train loss item: 0.09924513101577759
train loss item: 0.15341925621032715
train loss item: 0.14538033306598663
train loss item: 0.09853915870189667
train loss item: 0.09506746381521225
train loss item: 0.3051479756832123
train loss item: 0.9843966960906982
train loss item: 0.143375426530838
train loss item: 0.24843080341815948
train loss item: 0.10069958120584488
train loss item: 0.3287099599838257
train loss item: 0.23643577098846436
train loss item: 0.12624184787273407
train loss item: 0.20303355157375336
train loss item: 0.15616631507873535
train loss item: 0.13151592016220093
train loss item: 0.08965231478214264
train loss item: 0.10011640936136246
train loss item: 0.16307874023914337
train loss item: 0.06568154692649841
train loss item: 0.08310294896364212
train loss item: 0.2711026072502136
train loss item: 0.9979864954948425
train loss item: 0.057013291865587234
train loss item: 0.1425853818655014
train loss item: 0.08841359615325928
train loss item: 0.10227120667695999
train loss item: 0.13613493740558624
train loss item: 0.30599576234817505
train loss item: 0.25457850098609924
train loss item: 0.1788700371980667
train loss item: 2.745734691619873
train loss item: 0.08500977605581284
train loss item: 0.17123118042945862
test loss item: 0.10855044424533844
test loss item: 0.0760752484202385
test loss item: 0.3076637089252472
test loss item: 0.13912299275398254
test loss item: 0.14452068507671356
test loss item: 0.08786674588918686
test loss item: 1.0761258602142334
test loss item: 0.34842154383659363
test loss item: 0.1281607747077942
test loss item: 0.19679193198680878
test loss item: 0.4915064871311188
test loss item: 0.09938139468431473
test loss item: 0.11971504986286163
test loss item: 0.14829418063163757
test loss item: 0.10333328694105148
test loss item: 0.05659165233373642
test loss item: 0.15375018119812012
test loss item: 0.19584748148918152
test loss item: 0.405619740486145
test loss item: 0.1380193829536438
test loss item: 0.29414841532707214
test loss item: 0.23365721106529236
test loss item: 0.1427411437034607
test loss item: 0.10734778642654419
test loss item: 0.09969690442085266
test loss item: 0.14215628802776337
test loss item: 0.15206563472747803
test loss item: 0.11594691127538681
test loss item: 0.16910988092422485
test loss item: 0.1691478043794632
test loss item: 0.4589157998561859
test loss item: 0.054491836577653885
test loss item: 0.09526047855615616
test loss item: 0.261737585067749
test loss item: 0.19203710556030273
test loss item: 0.24992701411247253
test loss item: 0.4914349317550659
test loss item: 0.7763419151306152
test loss item: 0.22298578917980194
test loss item: 0.1631840169429779
test loss item: 0.18935200572013855
test loss item: 0.11513759940862656
test loss item: 0.1619023233652115
test loss item: 0.1298253983259201
test loss item: 0.23033425211906433
test loss item: 0.2092607617378235
test loss item: 0.13522665202617645
test loss item: 0.12233942002058029
test loss item: 0.25540226697921753
test loss item: 0.3597210645675659
test loss item: 0.15658138692378998
test loss item: 0.08628059923648834
test loss item: 0.13581986725330353
test loss item: 0.09492498636245728
test loss item: 0.14287808537483215
test loss item: 0.4394254982471466
test loss item: 0.3244549334049225
test loss item: 0.12108355760574341
test loss item: 0.13503426313400269
test loss item: 0.12526606023311615
test loss item: 0.20019148290157318
test loss item: 0.14539475739002228
test loss item: 0.12117817997932434
test loss item: 0.13832658529281616
test loss item: 0.5058000683784485
test loss item: 0.1898854523897171
test loss item: 0.16801142692565918
test loss item: 0.15242615342140198
test loss item: 0.2718750536441803
test loss item: 0.25936609506607056
test loss item: 0.05868144705891609
test loss item: 0.5832683444023132
test loss item: 0.14001818001270294
test loss item: 0.2144431322813034
test loss item: 0.08648860454559326
test loss item: 0.08727673441171646
test loss item: 0.10804476588964462
test loss item: 0.8451748490333557
test loss item: 0.20773477852344513
test loss item: 0.1100638210773468
test loss item: 0.056521911174058914
test loss item: 0.5789527893066406
test loss item: 0.5180620551109314
test loss item: 0.5862385630607605
test loss item: 0.11100219190120697
test loss item: 0.11995712667703629
test loss item: 0.051307033747434616
test loss item: 0.050161994993686676
test loss item: 0.13783876597881317
Epoch [11/50], Training Loss: 0.2621, Testing Loss: 0.2201
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 12/50
train loss item: 0.22468329966068268
train loss item: 0.29172050952911377
train loss item: 0.109076127409935
train loss item: 0.1830865740776062
train loss item: 0.2579250633716583
train loss item: 0.150493785738945
train loss item: 0.13335570693016052
train loss item: 0.27096953988075256
train loss item: 0.1107698604464531
train loss item: 0.16772158443927765
train loss item: 0.16643904149532318
train loss item: 0.13377979397773743
train loss item: 0.09533828496932983
train loss item: 0.2541322708129883
train loss item: 0.12642523646354675
train loss item: 0.35706403851509094
train loss item: 0.048044875264167786
train loss item: 0.12656477093696594
train loss item: 0.16597288846969604
train loss item: 0.13151666522026062
train loss item: 0.11891823261976242
train loss item: 0.1013093814253807
train loss item: 0.3481013774871826
train loss item: 0.33873897790908813
train loss item: 0.2372656613588333
train loss item: 0.15288768708705902
train loss item: 0.10854941606521606
train loss item: 0.1369587928056717
train loss item: 0.06475364416837692
train loss item: 0.2683142125606537
train loss item: 0.7940463423728943
train loss item: 0.2479202151298523
train loss item: 0.07653217762708664
train loss item: 0.13065120577812195
train loss item: 0.09752275049686432
train loss item: 1.3259578943252563
train loss item: 0.2322586327791214
train loss item: 0.20911146700382233
train loss item: 0.1959962099790573
train loss item: 0.1305008977651596
train loss item: 0.10201618075370789
train loss item: 0.12888872623443604
train loss item: 0.20548033714294434
train loss item: 0.11784987896680832
train loss item: 0.35489940643310547
train loss item: 0.08422846347093582
train loss item: 0.07047102600336075
train loss item: 0.20489689707756042
train loss item: 0.11906884610652924
train loss item: 0.08523698151111603
train loss item: 0.1216849535703659
train loss item: 0.38455015420913696
train loss item: 0.06534310430288315
train loss item: 0.08871705830097198
train loss item: 1.1696377992630005
train loss item: 0.10284338146448135
train loss item: 0.13455216586589813
train loss item: 0.12416356056928635
train loss item: 0.0826694667339325
train loss item: 0.09327507764101028
train loss item: 0.26697587966918945
train loss item: 0.8933480978012085
train loss item: 0.10679660737514496
train loss item: 0.18742501735687256
train loss item: 0.08277464658021927
train loss item: 0.20160357654094696
train loss item: 0.2028944492340088
train loss item: 0.12305229157209396
train loss item: 0.20959295332431793
train loss item: 0.14659501612186432
train loss item: 0.12037345767021179
train loss item: 0.08881060034036636
train loss item: 0.08786062896251678
train loss item: 0.14387093484401703
train loss item: 0.059201665222644806
train loss item: 0.07371257990598679
train loss item: 0.24306657910346985
train loss item: 0.938014030456543
train loss item: 0.060621220618486404
train loss item: 0.11990903317928314
train loss item: 0.08107765018939972
train loss item: 0.10645408183336258
train loss item: 0.11889956146478653
train loss item: 0.2844012975692749
train loss item: 0.2567436099052429
train loss item: 0.16375575959682465
train loss item: 2.6493940353393555
train loss item: 0.08508091419935226
train loss item: 0.1617281287908554
test loss item: 0.09849172830581665
test loss item: 0.07250455021858215
test loss item: 0.35252615809440613
test loss item: 0.12906351685523987
test loss item: 0.14852778613567352
test loss item: 0.07995779067277908
test loss item: 1.0960747003555298
test loss item: 0.36675989627838135
test loss item: 0.13136157393455505
test loss item: 0.20515388250350952
test loss item: 0.547374427318573
test loss item: 0.09291038662195206
test loss item: 0.11507517844438553
test loss item: 0.13429148495197296
test loss item: 0.10521075874567032
test loss item: 0.054708294570446014
test loss item: 0.15735654532909393
test loss item: 0.21619147062301636
test loss item: 0.3978227376937866
test loss item: 0.14284296333789825
test loss item: 0.3253588378429413
test loss item: 0.23942746222019196
test loss item: 0.1398354172706604
test loss item: 0.10562163591384888
test loss item: 0.10570911318063736
test loss item: 0.13373036682605743
test loss item: 0.15522705018520355
test loss item: 0.11123964935541153
test loss item: 0.17341312766075134
test loss item: 0.16907833516597748
test loss item: 0.5161167979240417
test loss item: 0.05218450352549553
test loss item: 0.09230794757604599
test loss item: 0.28086555004119873
test loss item: 0.21763597428798676
test loss item: 0.24290119111537933
test loss item: 0.4807488024234772
test loss item: 0.9229027628898621
test loss item: 0.23811586201190948
test loss item: 0.16250239312648773
test loss item: 0.1846160888671875
test loss item: 0.10365794599056244
test loss item: 0.1652747541666031
test loss item: 0.1298544555902481
test loss item: 0.24834081530570984
test loss item: 0.22170966863632202
test loss item: 0.1302991807460785
test loss item: 0.11953523755073547
test loss item: 0.2776755094528198
test loss item: 0.3987005949020386
test loss item: 0.1542389988899231
test loss item: 0.08144448697566986
test loss item: 0.13871140778064728
test loss item: 0.09276604652404785
test loss item: 0.15158911049365997
test loss item: 0.5048313140869141
test loss item: 0.33679360151290894
test loss item: 0.12189251184463501
test loss item: 0.13615141808986664
test loss item: 0.12155364453792572
test loss item: 0.2039969116449356
test loss item: 0.16433005034923553
test loss item: 0.12317544221878052
test loss item: 0.13103584945201874
test loss item: 0.5723392367362976
test loss item: 0.17453184723854065
test loss item: 0.1764359474182129
test loss item: 0.1467808037996292
test loss item: 0.29990553855895996
test loss item: 0.2677747309207916
test loss item: 0.051784854382276535
test loss item: 0.6024872064590454
test loss item: 0.1353614628314972
test loss item: 0.2285713404417038
test loss item: 0.08514030277729034
test loss item: 0.07674847543239594
test loss item: 0.10581637173891068
test loss item: 1.0384039878845215
test loss item: 0.22016678750514984
test loss item: 0.10636214166879654
test loss item: 0.05313000828027725
test loss item: 0.6435731649398804
test loss item: 0.5237695574760437
test loss item: 0.7046911120414734
test loss item: 0.11343711614608765
test loss item: 0.1227969080209732
test loss item: 0.05125783383846283
test loss item: 0.04963332787156105
test loss item: 0.13233307003974915
Epoch [12/50], Training Loss: 0.2351, Testing Loss: 0.2318
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 13/50
train loss item: 0.2126547396183014
train loss item: 0.296790212392807
train loss item: 0.09692897647619247
train loss item: 0.17008854448795319
train loss item: 0.20293083786964417
train loss item: 0.1373317688703537
train loss item: 0.09610360860824585
train loss item: 0.20656068623065948
train loss item: 0.06425091624259949
train loss item: 0.1170898899435997
train loss item: 0.12934714555740356
train loss item: 0.12622173130512238
train loss item: 0.08436930179595947
train loss item: 0.2335635870695114
train loss item: 0.10037755966186523
train loss item: 0.2598382830619812
train loss item: 0.049846623092889786
train loss item: 0.10880313813686371
train loss item: 0.14678460359573364
train loss item: 0.12017418444156647
train loss item: 0.1355786919593811
train loss item: 0.07663208991289139
train loss item: 0.29040926694869995
train loss item: 0.23851265013217926
train loss item: 0.21639224886894226
train loss item: 0.12747734785079956
train loss item: 0.10577964782714844
train loss item: 0.1326858252286911
train loss item: 0.041899994015693665
train loss item: 0.28502002358436584
train loss item: 0.7352991700172424
train loss item: 0.22399328649044037
train loss item: 0.07233221083879471
train loss item: 0.13455957174301147
train loss item: 0.08990475535392761
train loss item: 1.2757781744003296
train loss item: 0.29194095730781555
train loss item: 0.24966534972190857
train loss item: 0.2642163634300232
train loss item: 0.13342280685901642
train loss item: 0.1400618851184845
train loss item: 0.12726426124572754
train loss item: 0.22047671675682068
train loss item: 0.12855041027069092
train loss item: 0.37427467107772827
train loss item: 0.08074799180030823
train loss item: 0.07173469662666321
train loss item: 0.27045655250549316
train loss item: 0.1251111626625061
train loss item: 0.09044300764799118
train loss item: 0.17951899766921997
train loss item: 0.5965969562530518
train loss item: 0.07151838392019272
train loss item: 0.08060596138238907
train loss item: 1.253484845161438
train loss item: 0.09146534651517868
train loss item: 0.1379511058330536
train loss item: 0.12364228814840317
train loss item: 0.09602560847997665
train loss item: 0.08987844735383987
train loss item: 0.30691683292388916
train loss item: 0.8860422968864441
train loss item: 0.12250900268554688
train loss item: 0.24067172408103943
train loss item: 0.0967230498790741
train loss item: 0.3210037052631378
train loss item: 0.2571762204170227
train loss item: 0.12605680525302887
train loss item: 0.17764510214328766
train loss item: 0.14477969706058502
train loss item: 0.12187501043081284
train loss item: 0.0866430401802063
train loss item: 0.10544084012508392
train loss item: 0.1728353202342987
train loss item: 0.05728136748075485
train loss item: 0.08031482994556427
train loss item: 0.23855555057525635
train loss item: 1.0140351057052612
train loss item: 0.04852762073278427
train loss item: 0.1653859168291092
train loss item: 0.07979445904493332
train loss item: 0.1095958948135376
train loss item: 0.11833590269088745
train loss item: 0.26497000455856323
train loss item: 0.2107275277376175
train loss item: 0.22008515894412994
train loss item: 2.587785482406616
train loss item: 0.08386074006557465
train loss item: 0.17281880974769592
test loss item: 0.1027061715722084
test loss item: 0.07496171444654465
test loss item: 0.2768186032772064
test loss item: 0.12841999530792236
test loss item: 0.1339874416589737
test loss item: 0.08442186564207077
test loss item: 0.8842857480049133
test loss item: 0.292523592710495
test loss item: 0.11989615112543106
test loss item: 0.1788843721151352
test loss item: 0.4784987270832062
test loss item: 0.10252595692873001
test loss item: 0.12343770265579224
test loss item: 0.1301257461309433
test loss item: 0.10130275040864944
test loss item: 0.05627540871500969
test loss item: 0.1450510174036026
test loss item: 0.1657947152853012
test loss item: 0.35889771580696106
test loss item: 0.13923074305057526
test loss item: 0.23977433145046234
test loss item: 0.2069079428911209
test loss item: 0.11591174453496933
test loss item: 0.09803857654333115
test loss item: 0.09489849209785461
test loss item: 0.1285879760980606
test loss item: 0.1420622318983078
test loss item: 0.110913947224617
test loss item: 0.1600705236196518
test loss item: 0.15377695858478546
test loss item: 0.4160901606082916
test loss item: 0.05198730155825615
test loss item: 0.0888509601354599
test loss item: 0.22391870617866516
test loss item: 0.167329803109169
test loss item: 0.22412653267383575
test loss item: 0.42400220036506653
test loss item: 0.7605762481689453
test loss item: 0.19508096575737
test loss item: 0.1470833569765091
test loss item: 0.16620881855487823
test loss item: 0.1032353937625885
test loss item: 0.1404769867658615
test loss item: 0.1172129213809967
test loss item: 0.19394657015800476
test loss item: 0.20289172232151031
test loss item: 0.11469319462776184
test loss item: 0.11726212501525879
test loss item: 0.22828829288482666
test loss item: 0.33230772614479065
test loss item: 0.1436127871274948
test loss item: 0.08236797899007797
test loss item: 0.12276476621627808
test loss item: 0.09082283824682236
test loss item: 0.12422355264425278
test loss item: 0.40278998017311096
test loss item: 0.29690220952033997
test loss item: 0.11198782920837402
test loss item: 0.12396706640720367
test loss item: 0.12598541378974915
test loss item: 0.1675192266702652
test loss item: 0.13632267713546753
test loss item: 0.11172447353601456
test loss item: 0.14409300684928894
test loss item: 0.4655377268791199
test loss item: 0.17657504975795746
test loss item: 0.15494322776794434
test loss item: 0.14353299140930176
test loss item: 0.24898888170719147
test loss item: 0.2335725873708725
test loss item: 0.0625641718506813
test loss item: 0.4918627440929413
test loss item: 0.11600209027528763
test loss item: 0.18992066383361816
test loss item: 0.08559077233076096
test loss item: 0.07455462217330933
test loss item: 0.09902578592300415
test loss item: 0.857123076915741
test loss item: 0.18827427923679352
test loss item: 0.10524052381515503
test loss item: 0.05713256075978279
test loss item: 0.5348691344261169
test loss item: 0.4472251534461975
test loss item: 0.5823870897293091
test loss item: 0.10182955116033554
test loss item: 0.11539088934659958
test loss item: 0.04874345287680626
test loss item: 0.04669621214270592
test loss item: 0.1286083310842514
Epoch [13/50], Training Loss: 0.2365, Testing Loss: 0.2010
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 14/50
train loss item: 0.215829998254776
train loss item: 0.367873877286911
train loss item: 0.1011868268251419
train loss item: 0.21159781515598297
train loss item: 0.20171846449375153
train loss item: 0.14479026198387146
train loss item: 0.1211094781756401
train loss item: 0.2372179627418518
train loss item: 0.09297411143779755
train loss item: 0.1512659639120102
train loss item: 0.17770273983478546
train loss item: 0.13814350962638855
train loss item: 0.08618824183940887
train loss item: 0.24720588326454163
train loss item: 0.1243082657456398
train loss item: 0.3944122791290283
train loss item: 0.047563474625349045
train loss item: 0.1146184578537941
train loss item: 0.1489555537700653
train loss item: 0.1327885091304779
train loss item: 0.1156444251537323
train loss item: 0.08132752776145935
train loss item: 0.43352586030960083
train loss item: 0.3311544954776764
train loss item: 0.23455014824867249
train loss item: 0.12908004224300385
train loss item: 0.12363909929990768
train loss item: 0.11721878498792648
train loss item: 0.06187869980931282
train loss item: 0.2585524916648865
train loss item: 0.9541265964508057
train loss item: 0.2676592767238617
train loss item: 0.07763002067804337
train loss item: 0.15654973685741425
train loss item: 0.1062193512916565
train loss item: 1.2675565481185913
train loss item: 0.2411733716726303
train loss item: 0.237028568983078
train loss item: 0.17146794497966766
train loss item: 0.11740336567163467
train loss item: 0.1087573915719986
train loss item: 0.12091934680938721
train loss item: 0.19711340963840485
train loss item: 0.12464521825313568
train loss item: 0.30421996116638184
train loss item: 0.08251341432332993
train loss item: 0.06310416013002396
train loss item: 0.21681033074855804
train loss item: 0.1289728730916977
train loss item: 0.085083968937397
train loss item: 0.13733412325382233
train loss item: 0.4364702105522156
train loss item: 0.06604237109422684
train loss item: 0.09993105381727219
train loss item: 1.112534523010254
train loss item: 0.11488144844770432
train loss item: 0.13551266491413116
train loss item: 0.12289639562368393
train loss item: 0.07834010571241379
train loss item: 0.09280182421207428
train loss item: 0.21315553784370422
train loss item: 0.8001510500907898
train loss item: 0.11132930964231491
train loss item: 0.21614910662174225
train loss item: 0.08688509464263916
train loss item: 0.22876675426959991
train loss item: 0.20988576114177704
train loss item: 0.13627134263515472
train loss item: 0.20108847320079803
train loss item: 0.14298132061958313
train loss item: 0.11772985011339188
train loss item: 0.08644919097423553
train loss item: 0.09379780292510986
train loss item: 0.1588720679283142
train loss item: 0.05540262535214424
train loss item: 0.07555150240659714
train loss item: 0.26896265149116516
train loss item: 0.9654219746589661
train loss item: 0.051466647535562515
train loss item: 0.1495470255613327
train loss item: 0.07605359703302383
train loss item: 0.09803296625614166
train loss item: 0.126610666513443
train loss item: 0.2643050253391266
train loss item: 0.20209503173828125
train loss item: 0.24873004853725433
train loss item: 2.5686657428741455
train loss item: 0.08286221325397491
train loss item: 0.15191709995269775
test loss item: 0.09629218280315399
test loss item: 0.07361733913421631
test loss item: 0.30118516087532043
test loss item: 0.12263757735490799
test loss item: 0.1375991851091385
test loss item: 0.08369871228933334
test loss item: 0.8675807118415833
test loss item: 0.29420924186706543
test loss item: 0.12359602004289627
test loss item: 0.18712051212787628
test loss item: 0.49835941195487976
test loss item: 0.09321322292089462
test loss item: 0.11738184839487076
test loss item: 0.15247036516666412
test loss item: 0.10129962116479874
test loss item: 0.054284751415252686
test loss item: 0.14170221984386444
test loss item: 0.17993450164794922
test loss item: 0.3475014865398407
test loss item: 0.13823848962783813
test loss item: 0.26815810799598694
test loss item: 0.20151309669017792
test loss item: 0.13485348224639893
test loss item: 0.09881996363401413
test loss item: 0.0938248559832573
test loss item: 0.1250881403684616
test loss item: 0.14589959383010864
test loss item: 0.1125703975558281
test loss item: 0.16308070719242096
test loss item: 0.15756899118423462
test loss item: 0.4341455101966858
test loss item: 0.05034511163830757
test loss item: 0.08982619643211365
test loss item: 0.23226627707481384
test loss item: 0.18414464592933655
test loss item: 0.2174118161201477
test loss item: 0.4159373939037323
test loss item: 0.8120023012161255
test loss item: 0.20606644451618195
test loss item: 0.14231395721435547
test loss item: 0.15849409997463226
test loss item: 0.11511588841676712
test loss item: 0.13751283288002014
test loss item: 0.1115596666932106
test loss item: 0.2177562564611435
test loss item: 0.2052454799413681
test loss item: 0.12952788174152374
test loss item: 0.12301037460565567
test loss item: 0.23801466822624207
test loss item: 0.3483876585960388
test loss item: 0.145018070936203
test loss item: 0.08110015094280243
test loss item: 0.1248675063252449
test loss item: 0.0861237496137619
test loss item: 0.13352443277835846
test loss item: 0.43725961446762085
test loss item: 0.2928948998451233
test loss item: 0.1301802545785904
test loss item: 0.12489338964223862
test loss item: 0.1216759905219078
test loss item: 0.17634572088718414
test loss item: 0.13911522924900055
test loss item: 0.11200844496488571
test loss item: 0.13421086966991425
test loss item: 0.4914209246635437
test loss item: 0.16735997796058655
test loss item: 0.16041740775108337
test loss item: 0.1349347084760666
test loss item: 0.2565322816371918
test loss item: 0.23145268857479095
test loss item: 0.05918426066637039
test loss item: 0.4791739583015442
test loss item: 0.1301535964012146
test loss item: 0.18729010224342346
test loss item: 0.08479055017232895
test loss item: 0.0882081538438797
test loss item: 0.09785201400518417
test loss item: 0.9135007858276367
test loss item: 0.21002794802188873
test loss item: 0.10781167447566986
test loss item: 0.05461728200316429
test loss item: 0.5484275817871094
test loss item: 0.4482770264148712
test loss item: 0.6202942132949829
test loss item: 0.10767941176891327
test loss item: 0.1158541589975357
test loss item: 0.0511067658662796
test loss item: 0.04805825650691986
test loss item: 0.1332525610923767
Epoch [14/50], Training Loss: 0.2355, Testing Loss: 0.2062
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 15/50
train loss item: 0.1890632063150406
train loss item: 0.2394534945487976
train loss item: 0.09861279278993607
train loss item: 0.15636217594146729
train loss item: 0.23138314485549927
train loss item: 0.14608317613601685
train loss item: 0.08809265494346619
train loss item: 0.19462427496910095
train loss item: 0.06169714778661728
train loss item: 0.11153953522443771
train loss item: 0.13579636812210083
train loss item: 0.11399897187948227
train loss item: 0.08024930953979492
train loss item: 0.2277338057756424
train loss item: 0.10204840451478958
train loss item: 0.29614686965942383
train loss item: 0.04459339380264282
train loss item: 0.0976577177643776
train loss item: 0.14319263398647308
train loss item: 0.12812860310077667
train loss item: 0.1252831071615219
train loss item: 0.07137304544448853
train loss item: 0.24382877349853516
train loss item: 0.21027804911136627
train loss item: 0.18701264262199402
train loss item: 0.13289813697338104
train loss item: 0.09943293780088425
train loss item: 0.11201101541519165
train loss item: 0.04776351526379585
train loss item: 0.2579476535320282
train loss item: 0.6288654208183289
train loss item: 0.19978736340999603
train loss item: 0.06597399711608887
train loss item: 0.140274778008461
train loss item: 0.07903973758220673
train loss item: 1.2056708335876465
train loss item: 0.2685023248195648
train loss item: 0.22696460783481598
train loss item: 0.22957360744476318
train loss item: 0.13059267401695251
train loss item: 0.1083620935678482
train loss item: 0.1201312467455864
train loss item: 0.16477838158607483
train loss item: 0.11378680169582367
train loss item: 0.3206159174442291
train loss item: 0.0797075554728508
train loss item: 0.06625685840845108
train loss item: 0.17076148092746735
train loss item: 0.11542821675539017
train loss item: 0.0837586373090744
train loss item: 0.10633087903261185
train loss item: 0.4220867156982422
train loss item: 0.05763685330748558
train loss item: 0.07353968918323517
train loss item: 1.054965615272522
train loss item: 0.08460956066846848
train loss item: 0.11281464248895645
train loss item: 0.12289999425411224
train loss item: 0.08328840881586075
train loss item: 0.092157281935215
train loss item: 0.2513910233974457
train loss item: 0.7611485123634338
train loss item: 0.10792810469865799
train loss item: 0.17183853685855865
train loss item: 0.08453351259231567
train loss item: 0.19861845672130585
train loss item: 0.19080272316932678
train loss item: 0.11320316046476364
train loss item: 0.17450407147407532
train loss item: 0.1369086354970932
train loss item: 0.11380288004875183
train loss item: 0.07883460819721222
train loss item: 0.08434006571769714
train loss item: 0.14775946736335754
train loss item: 0.05986513942480087
train loss item: 0.07346917688846588
train loss item: 0.30911070108413696
train loss item: 0.9564226865768433
train loss item: 0.043965164572000504
train loss item: 0.15537051856517792
train loss item: 0.07986585795879364
train loss item: 0.09841299057006836
train loss item: 0.12028561532497406
train loss item: 0.2530345916748047
train loss item: 0.19884048402309418
train loss item: 0.23564688861370087
train loss item: 2.643127918243408
train loss item: 0.07811550050973892
train loss item: 0.1349310427904129
test loss item: 0.10711661726236343
test loss item: 0.0779111236333847
test loss item: 0.2848261892795563
test loss item: 0.13159431517124176
test loss item: 0.14577458798885345
test loss item: 0.09964946657419205
test loss item: 0.8212110996246338
test loss item: 0.27287930250167847
test loss item: 0.12366491556167603
test loss item: 0.18521536886692047
test loss item: 0.46349021792411804
test loss item: 0.08999266475439072
test loss item: 0.11371617764234543
test loss item: 0.13546983897686005
test loss item: 0.10727051645517349
test loss item: 0.051198139786720276
test loss item: 0.14427781105041504
test loss item: 0.1822221577167511
test loss item: 0.3318164646625519
test loss item: 0.13082736730575562
test loss item: 0.2774239480495453
test loss item: 0.20265774428844452
test loss item: 0.12491893023252487
test loss item: 0.10935740172863007
test loss item: 0.09397429972887039
test loss item: 0.12744836509227753
test loss item: 0.1466434895992279
test loss item: 0.12384960055351257
test loss item: 0.16797062754631042
test loss item: 0.15607444941997528
test loss item: 0.4099128842353821
test loss item: 0.04829235002398491
test loss item: 0.10030960291624069
test loss item: 0.22604162991046906
test loss item: 0.18076741695404053
test loss item: 0.21167400479316711
test loss item: 0.39914682507514954
test loss item: 0.7365186810493469
test loss item: 0.20769481360912323
test loss item: 0.15378756821155548
test loss item: 0.1637001484632492
test loss item: 0.10649154335260391
test loss item: 0.13785679638385773
test loss item: 0.11860712617635727
test loss item: 0.22503983974456787
test loss item: 0.2005273699760437
test loss item: 0.12220675498247147
test loss item: 0.11347952485084534
test loss item: 0.23433120548725128
test loss item: 0.3260098695755005
test loss item: 0.1507946401834488
test loss item: 0.07903928309679031
test loss item: 0.13026411831378937
test loss item: 0.08939694613218307
test loss item: 0.13511833548545837
test loss item: 0.4101211428642273
test loss item: 0.27944591641426086
test loss item: 0.11125083267688751
test loss item: 0.12927071750164032
test loss item: 0.12019423395395279
test loss item: 0.17428544163703918
test loss item: 0.13637392222881317
test loss item: 0.11571245640516281
test loss item: 0.12799036502838135
test loss item: 0.4601176381111145
test loss item: 0.1753125786781311
test loss item: 0.15829865634441376
test loss item: 0.13243262469768524
test loss item: 0.24369771778583527
test loss item: 0.22248435020446777
test loss item: 0.054332755506038666
test loss item: 0.4484666883945465
test loss item: 0.12458597123622894
test loss item: 0.18909765779972076
test loss item: 0.08239822834730148
test loss item: 0.07832997292280197
test loss item: 0.10480546951293945
test loss item: 0.8227677345275879
test loss item: 0.19287367165088654
test loss item: 0.12003372609615326
test loss item: 0.0571836493909359
test loss item: 0.5064350366592407
test loss item: 0.43209508061408997
test loss item: 0.5671458840370178
test loss item: 0.1083354502916336
test loss item: 0.11294692009687424
test loss item: 0.057888150215148926
test loss item: 0.05355123430490494
test loss item: 0.13301053643226624
Epoch [15/50], Training Loss: 0.2153, Testing Loss: 0.1998
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 16/50
train loss item: 0.21172870695590973
train loss item: 0.2310255765914917
train loss item: 0.10046184062957764
train loss item: 0.16126605868339539
train loss item: 0.21171382069587708
train loss item: 0.15210013091564178
train loss item: 0.1009925901889801
train loss item: 0.2137065976858139
train loss item: 0.09927255660295486
train loss item: 0.13733923435211182
train loss item: 0.12427274882793427
train loss item: 0.11668681353330612
train loss item: 0.08720147609710693
train loss item: 0.23597197234630585
train loss item: 0.10995958745479584
train loss item: 0.2675464451313019
train loss item: 0.045676715672016144
train loss item: 0.09796960651874542
train loss item: 0.1421547681093216
train loss item: 0.1118927001953125
train loss item: 0.10413718968629837
train loss item: 0.08307152986526489
train loss item: 0.23963336646556854
train loss item: 0.3202199339866638
train loss item: 0.2213791012763977
train loss item: 0.11565227061510086
train loss item: 0.0984494611620903
train loss item: 0.11916932463645935
train loss item: 0.05360681563615799
train loss item: 0.2357141524553299
train loss item: 0.5570819973945618
train loss item: 0.21329864859580994
train loss item: 0.07032111287117004
train loss item: 0.12102360278367996
train loss item: 0.08046448230743408
train loss item: 1.1551570892333984
train loss item: 0.21823175251483917
train loss item: 0.17387233674526215
train loss item: 0.18919667601585388
train loss item: 0.108880914747715
train loss item: 0.10637851059436798
train loss item: 0.11088927090167999
train loss item: 0.1669798046350479
train loss item: 0.10817886888980865
train loss item: 0.2803921699523926
train loss item: 0.0765705481171608
train loss item: 0.07850553095340729
train loss item: 0.1560387760400772
train loss item: 0.1043466106057167
train loss item: 0.08420214056968689
train loss item: 0.10577140003442764
train loss item: 0.40300649404525757
train loss item: 0.060265373438596725
train loss item: 0.0827590599656105
train loss item: 1.0144175291061401
train loss item: 0.1056288406252861
train loss item: 0.1270105391740799
train loss item: 0.12606365978717804
train loss item: 0.07118072360754013
train loss item: 0.09590461105108261
train loss item: 0.21228912472724915
train loss item: 0.7389470934867859
train loss item: 0.09299425780773163
train loss item: 0.15703941881656647
train loss item: 0.07991687953472137
train loss item: 0.22850093245506287
train loss item: 0.16792388260364532
train loss item: 0.11661752313375473
train loss item: 0.17831628024578094
train loss item: 0.14844872057437897
train loss item: 0.10485555976629257
train loss item: 0.07895171642303467
train loss item: 0.07235067337751389
train loss item: 0.14312276244163513
train loss item: 0.05002843216061592
train loss item: 0.06955784559249878
train loss item: 0.2015535682439804
train loss item: 0.9036312699317932
train loss item: 0.04563843831419945
train loss item: 0.11867062002420425
train loss item: 0.07603129744529724
train loss item: 0.08521944284439087
train loss item: 0.11463838070631027
train loss item: 0.29279762506484985
train loss item: 0.21680903434753418
train loss item: 0.15516991913318634
train loss item: 2.434069871902466
train loss item: 0.08689813315868378
train loss item: 0.1236947774887085
test loss item: 0.09493935108184814
test loss item: 0.07022562623023987
test loss item: 0.3637320399284363
test loss item: 0.12581707537174225
test loss item: 0.14445285499095917
test loss item: 0.07406634837388992
test loss item: 1.1329538822174072
test loss item: 0.3852105736732483
test loss item: 0.14019891619682312
test loss item: 0.21290379762649536
test loss item: 0.5688414573669434
test loss item: 0.0922500267624855
test loss item: 0.11904925853013992
test loss item: 0.15803636610507965
test loss item: 0.1039532721042633
test loss item: 0.053526636213064194
test loss item: 0.1620330512523651
test loss item: 0.21542680263519287
test loss item: 0.4092215597629547
test loss item: 0.1545744091272354
test loss item: 0.3350587487220764
test loss item: 0.23701180517673492
test loss item: 0.1517142355442047
test loss item: 0.10420913994312286
test loss item: 0.10454824566841125
test loss item: 0.12942299246788025
test loss item: 0.16274525225162506
test loss item: 0.10777795314788818
test loss item: 0.18107597529888153
test loss item: 0.17085015773773193
test loss item: 0.5341140627861023
test loss item: 0.04670565202832222
test loss item: 0.0899665504693985
test loss item: 0.27627137303352356
test loss item: 0.22244150936603546
test loss item: 0.24510785937309265
test loss item: 0.4963003695011139
test loss item: 0.9462641477584839
test loss item: 0.2464396357536316
test loss item: 0.1607074737548828
test loss item: 0.18205925822257996
test loss item: 0.1122233048081398
test loss item: 0.15933585166931152
test loss item: 0.12853440642356873
test loss item: 0.26095202565193176
test loss item: 0.2382340431213379
test loss item: 0.1385425180196762
test loss item: 0.12747585773468018
test loss item: 0.2859950363636017
test loss item: 0.4173485338687897
test loss item: 0.16075775027275085
test loss item: 0.07920254021883011
test loss item: 0.13928797841072083
test loss item: 0.0903661698102951
test loss item: 0.15332695841789246
test loss item: 0.5207998752593994
test loss item: 0.34537217020988464
test loss item: 0.13180232048034668
test loss item: 0.1352662742137909
test loss item: 0.12217684835195541
test loss item: 0.20188909769058228
test loss item: 0.1658376157283783
test loss item: 0.12272148579359055
test loss item: 0.139038547873497
test loss item: 0.5914942622184753
test loss item: 0.17205211520195007
test loss item: 0.18423013389110565
test loss item: 0.14832837879657745
test loss item: 0.28920963406562805
test loss item: 0.2786824405193329
test loss item: 0.05262947082519531
test loss item: 0.6317517757415771
test loss item: 0.14551864564418793
test loss item: 0.2304188311100006
test loss item: 0.08949090540409088
test loss item: 0.08696100860834122
test loss item: 0.10449864715337753
test loss item: 1.0537748336791992
test loss item: 0.23840397596359253
test loss item: 0.10483796149492264
test loss item: 0.04970584437251091
test loss item: 0.6651912331581116
test loss item: 0.5413632392883301
test loss item: 0.7240590453147888
test loss item: 0.12224134802818298
test loss item: 0.12358161807060242
test loss item: 0.04779067263007164
test loss item: 0.044977691024541855
test loss item: 0.1315491944551468
Epoch [16/50], Training Loss: 0.2067, Testing Loss: 0.2375
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 17/50
train loss item: 0.17511926591396332
train loss item: 0.3074810802936554
train loss item: 0.0902220830321312
train loss item: 0.23807168006896973
train loss item: 0.1965664178133011
train loss item: 0.12809817492961884
train loss item: 0.09686792641878128
train loss item: 0.2167985737323761
train loss item: 0.062256913632154465
train loss item: 0.10077076405286789
train loss item: 0.13684292137622833
train loss item: 0.11607541888952255
train loss item: 0.08721869438886642
train loss item: 0.20996493101119995
train loss item: 0.09994859248399734
train loss item: 0.3071237802505493
train loss item: 0.05157972872257233
train loss item: 0.10094106197357178
train loss item: 0.11211533844470978
train loss item: 0.10187263786792755
train loss item: 0.13438186049461365
train loss item: 0.07673598825931549
train loss item: 0.32430824637413025
train loss item: 0.2319413721561432
train loss item: 0.19280467927455902
train loss item: 0.12011222541332245
train loss item: 0.10188474506139755
train loss item: 0.10202689468860626
train loss item: 0.04487915337085724
train loss item: 0.23980197310447693
train loss item: 0.7342220544815063
train loss item: 0.25299394130706787
train loss item: 0.06866821646690369
train loss item: 0.12883038818836212
train loss item: 0.08879861980676651
train loss item: 1.145774245262146
train loss item: 0.21040095388889313
train loss item: 0.21242687106132507
train loss item: 0.19758254289627075
train loss item: 0.11205637454986572
train loss item: 0.10423164814710617
train loss item: 0.11860296130180359
train loss item: 0.17311781644821167
train loss item: 0.12373924255371094
train loss item: 0.27195560932159424
train loss item: 0.07890275865793228
train loss item: 0.06009460985660553
train loss item: 0.21223466098308563
train loss item: 0.12092522531747818
train loss item: 0.0852636769413948
train loss item: 0.1428641676902771
train loss item: 0.45524799823760986
train loss item: 0.05673561617732048
train loss item: 0.08331615477800369
train loss item: 0.9807355403900146
train loss item: 0.09172933548688889
train loss item: 0.1557459980249405
train loss item: 0.1105344370007515
train loss item: 0.07963404059410095
train loss item: 0.0962928757071495
train loss item: 0.2219424992799759
train loss item: 0.65591961145401
train loss item: 0.10570768266916275
train loss item: 0.21070699393749237
train loss item: 0.078380286693573
train loss item: 0.20353712141513824
train loss item: 0.17949993908405304
train loss item: 0.1237250417470932
train loss item: 0.17105494439601898
train loss item: 0.13885599374771118
train loss item: 0.10233848541975021
train loss item: 0.08321166038513184
train loss item: 0.07550137490034103
train loss item: 0.13949845731258392
train loss item: 0.050566185265779495
train loss item: 0.06951642781496048
train loss item: 0.2549494504928589
train loss item: 0.8911684155464172
train loss item: 0.04743824899196625
train loss item: 0.13946232199668884
train loss item: 0.08312863111495972
train loss item: 0.09485729038715363
train loss item: 0.1160338968038559
train loss item: 0.23368901014328003
train loss item: 0.177603080868721
train loss item: 0.2211737483739853
train loss item: 2.383310317993164
train loss item: 0.07969706505537033
train loss item: 0.13491939008235931
test loss item: 0.10202744603157043
test loss item: 0.07270120829343796
test loss item: 0.3212750554084778
test loss item: 0.12165839970111847
test loss item: 0.1341845542192459
test loss item: 0.08114075660705566
test loss item: 0.8550618290901184
test loss item: 0.2948249280452728
test loss item: 0.1280849725008011
test loss item: 0.19484077394008636
test loss item: 0.5107011198997498
test loss item: 0.08736706525087357
test loss item: 0.12240786850452423
test loss item: 0.18493159115314484
test loss item: 0.10355168581008911
test loss item: 0.05583416670560837
test loss item: 0.15098129212856293
test loss item: 0.1892755627632141
test loss item: 0.3348160684108734
test loss item: 0.15038688480854034
test loss item: 0.2888113558292389
test loss item: 0.20465216040611267
test loss item: 0.1528710126876831
test loss item: 0.10276719182729721
test loss item: 0.09780404716730118
test loss item: 0.12482292205095291
test loss item: 0.15400201082229614
test loss item: 0.10640808194875717
test loss item: 0.16866721212863922
test loss item: 0.16071370244026184
test loss item: 0.45048433542251587
test loss item: 0.054139696061611176
test loss item: 0.09367506951093674
test loss item: 0.23946167528629303
test loss item: 0.1952345073223114
test loss item: 0.2177136391401291
test loss item: 0.40762969851493835
test loss item: 0.8447896242141724
test loss item: 0.21651746332645416
test loss item: 0.1429026573896408
test loss item: 0.15970897674560547
test loss item: 0.13439106941223145
test loss item: 0.13606256246566772
test loss item: 0.11505410075187683
test loss item: 0.2374744564294815
test loss item: 0.22026659548282623
test loss item: 0.152640700340271
test loss item: 0.14176850020885468
test loss item: 0.248908132314682
test loss item: 0.35782819986343384
test loss item: 0.14801594614982605
test loss item: 0.08736739307641983
test loss item: 0.1298646479845047
test loss item: 0.085669606924057
test loss item: 0.13916780054569244
test loss item: 0.4594321548938751
test loss item: 0.29232993721961975
test loss item: 0.15534564852714539
test loss item: 0.1310456097126007
test loss item: 0.12127678096294403
test loss item: 0.1793416291475296
test loss item: 0.14748533070087433
test loss item: 0.12112148851156235
test loss item: 0.13288041949272156
test loss item: 0.4991506338119507
test loss item: 0.16208085417747498
test loss item: 0.1693965345621109
test loss item: 0.1322033405303955
test loss item: 0.2596478760242462
test loss item: 0.2253188043832779
test loss item: 0.06386217474937439
test loss item: 0.4708082973957062
test loss item: 0.1526641547679901
test loss item: 0.19575467705726624
test loss item: 0.09464982151985168
test loss item: 0.11189781129360199
test loss item: 0.09923092275857925
test loss item: 0.9385945796966553
test loss item: 0.23539584875106812
test loss item: 0.11186249554157257
test loss item: 0.05763619765639305
test loss item: 0.5511259436607361
test loss item: 0.4452483654022217
test loss item: 0.638683557510376
test loss item: 0.10985207557678223
test loss item: 0.12414348870515823
test loss item: 0.05860411748290062
test loss item: 0.053958941251039505
test loss item: 0.1268572062253952
Epoch [17/50], Training Loss: 0.2104, Testing Loss: 0.2128
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 18/50
train loss item: 0.16402862966060638
train loss item: 0.20943018794059753
train loss item: 0.09757866710424423
train loss item: 0.1479482203722
train loss item: 0.1572284996509552
train loss item: 0.13684996962547302
train loss item: 0.10049614310264587
train loss item: 0.17970940470695496
train loss item: 0.05180879682302475
train loss item: 0.0921546220779419
train loss item: 0.1154436469078064
train loss item: 0.10828914493322372
train loss item: 0.0721953809261322
train loss item: 0.21460013091564178
train loss item: 0.08962970972061157
train loss item: 0.23162463307380676
train loss item: 0.04202316701412201
train loss item: 0.08795493841171265
train loss item: 0.11796031147241592
train loss item: 0.1163855567574501
train loss item: 0.09568910300731659
train loss item: 0.06501759588718414
train loss item: 0.20738163590431213
train loss item: 0.19105075299739838
train loss item: 0.19787739217281342
train loss item: 0.0953654870390892
train loss item: 0.08106952905654907
train loss item: 0.10596006363630295
train loss item: 0.0603320337831974
train loss item: 0.2586592137813568
train loss item: 0.4875819981098175
train loss item: 0.2061130702495575
train loss item: 0.06597517430782318
train loss item: 0.1090359166264534
train loss item: 0.07904373109340668
train loss item: 1.0868839025497437
train loss item: 0.21115443110466003
train loss item: 0.18377582728862762
train loss item: 0.18831801414489746
train loss item: 0.11175099015235901
train loss item: 0.09609771519899368
train loss item: 0.10785754770040512
train loss item: 0.14469420909881592
train loss item: 0.10748802870512009
train loss item: 0.25852423906326294
train loss item: 0.07363521307706833
train loss item: 0.058989301323890686
train loss item: 0.13690274953842163
train loss item: 0.10204414278268814
train loss item: 0.07486240565776825
train loss item: 0.08899806439876556
train loss item: 0.35945892333984375
train loss item: 0.05315013974905014
train loss item: 0.06766434758901596
train loss item: 0.9328452944755554
train loss item: 0.08203740417957306
train loss item: 0.09600299596786499
train loss item: 0.09956736117601395
train loss item: 0.06875735521316528
train loss item: 0.0922146588563919
train loss item: 0.19602786004543304
train loss item: 0.6064815521240234
train loss item: 0.08823733776807785
train loss item: 0.13556641340255737
train loss item: 0.07846730202436447
train loss item: 0.17953231930732727
train loss item: 0.15565602481365204
train loss item: 0.11252635717391968
train loss item: 0.16161136329174042
train loss item: 0.11753861606121063
train loss item: 0.09133648127317429
train loss item: 0.08377842605113983
train loss item: 0.07473022490739822
train loss item: 0.13283421099185944
train loss item: 0.04851599782705307
train loss item: 0.06691916286945343
train loss item: 0.22272373735904694
train loss item: 0.8186876773834229
train loss item: 0.04396098852157593
train loss item: 0.10855019092559814
train loss item: 0.0729123204946518
train loss item: 0.08482435345649719
train loss item: 0.10392175614833832
train loss item: 0.2334601730108261
train loss item: 0.19738103449344635
train loss item: 0.16577179729938507
train loss item: 2.3178160190582275
train loss item: 0.07172628492116928
train loss item: 0.11548202484846115
test loss item: 0.09696302562952042
test loss item: 0.07692952454090118
test loss item: 0.3176649510860443
test loss item: 0.1252514123916626
test loss item: 0.14260773360729218
test loss item: 0.08607833832502365
test loss item: 1.0648150444030762
test loss item: 0.3492661416530609
test loss item: 0.1313234120607376
test loss item: 0.19704581797122955
test loss item: 0.49996569752693176
test loss item: 0.08992629498243332
test loss item: 0.1153835579752922
test loss item: 0.17393746972084045
test loss item: 0.10604684799909592
test loss item: 0.053704969584941864
test loss item: 0.15370595455169678
test loss item: 0.19600935280323029
test loss item: 0.3703484833240509
test loss item: 0.14682869613170624
test loss item: 0.31197938323020935
test loss item: 0.2212233543395996
test loss item: 0.14522938430309296
test loss item: 0.10950666666030884
test loss item: 0.09910739213228226
test loss item: 0.12749433517456055
test loss item: 0.15530261397361755
test loss item: 0.11491942405700684
test loss item: 0.17874231934547424
test loss item: 0.16063794493675232
test loss item: 0.4821024239063263
test loss item: 0.048896048218011856
test loss item: 0.09720274060964584
test loss item: 0.24357710778713226
test loss item: 0.20024551451206207
test loss item: 0.22399476170539856
test loss item: 0.457983136177063
test loss item: 0.8013566732406616
test loss item: 0.23092111945152283
test loss item: 0.1605754792690277
test loss item: 0.17325399816036224
test loss item: 0.11339239776134491
test loss item: 0.14385737478733063
test loss item: 0.12268804758787155
test loss item: 0.25299108028411865
test loss item: 0.22176769375801086
test loss item: 0.13548149168491364
test loss item: 0.12563686072826385
test loss item: 0.2537778317928314
test loss item: 0.36693641543388367
test loss item: 0.1563725620508194
test loss item: 0.07865440100431442
test loss item: 0.132537841796875
test loss item: 0.08941347151994705
test loss item: 0.14326685667037964
test loss item: 0.45387083292007446
test loss item: 0.3067772686481476
test loss item: 0.12264981865882874
test loss item: 0.1303800642490387
test loss item: 0.118670254945755
test loss item: 0.18364952504634857
test loss item: 0.15011267364025116
test loss item: 0.12201538681983948
test loss item: 0.13507892191410065
test loss item: 0.5153769254684448
test loss item: 0.16552157700061798
test loss item: 0.17183257639408112
test loss item: 0.14253570139408112
test loss item: 0.2525632679462433
test loss item: 0.2474461942911148
test loss item: 0.05784808471798897
test loss item: 0.5838156938552856
test loss item: 0.15061220526695251
test loss item: 0.2183564454317093
test loss item: 0.08929693698883057
test loss item: 0.09087596088647842
test loss item: 0.10801034420728683
test loss item: 0.8824291825294495
test loss item: 0.22505956888198853
test loss item: 0.1136813834309578
test loss item: 0.05689995735883713
test loss item: 0.5834245681762695
test loss item: 0.5009907484054565
test loss item: 0.6175106167793274
test loss item: 0.11732949316501617
test loss item: 0.1182425245642662
test loss item: 0.0596429742872715
test loss item: 0.05206354334950447
test loss item: 0.1309141218662262
Epoch [18/50], Training Loss: 0.1866, Testing Loss: 0.2197
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 19/50
train loss item: 0.15827636420726776
train loss item: 0.23390451073646545
train loss item: 0.08695173263549805
train loss item: 0.14486342668533325
train loss item: 0.16645200550556183
train loss item: 0.12891621887683868
train loss item: 0.08330088108778
train loss item: 0.18479572236537933
train loss item: 0.07287134230136871
train loss item: 0.09215573221445084
train loss item: 0.10087696462869644
train loss item: 0.10222819447517395
train loss item: 0.08088471740484238
train loss item: 0.21604396402835846
train loss item: 0.10412700474262238
train loss item: 0.20500433444976807
train loss item: 0.04502858221530914
train loss item: 0.08707790076732635
train loss item: 0.13367222249507904
train loss item: 0.09457582235336304
train loss item: 0.10039067268371582
train loss item: 0.0746847614645958
train loss item: 0.20734065771102905
train loss item: 0.24314510822296143
train loss item: 0.17844951152801514
train loss item: 0.100153848528862
train loss item: 0.10154983401298523
train loss item: 0.10280836373567581
train loss item: 0.054795682430267334
train loss item: 0.24085403978824615
train loss item: 0.3809290826320648
train loss item: 0.22655291855335236
train loss item: 0.07176414877176285
train loss item: 0.11452671140432358
train loss item: 0.08479419350624084
train loss item: 1.0327799320220947
train loss item: 0.2196691781282425
train loss item: 0.2052190899848938
train loss item: 0.20272104442119598
train loss item: 0.10742656886577606
train loss item: 0.09727174043655396
train loss item: 0.10826591402292252
train loss item: 0.162422314286232
train loss item: 0.1175675019621849
train loss item: 0.257514089345932
train loss item: 0.08789268136024475
train loss item: 0.09289289265871048
train loss item: 0.23268550634384155
train loss item: 0.10850641876459122
train loss item: 0.0925975814461708
train loss item: 0.14876800775527954
train loss item: 0.5090715289115906
train loss item: 0.05961834266781807
train loss item: 0.10560943186283112
train loss item: 0.9015029668807983
train loss item: 0.10104852169752121
train loss item: 0.20054201781749725
train loss item: 0.12278339266777039
train loss item: 0.09593726694583893
train loss item: 0.10397922247648239
train loss item: 0.2609882354736328
train loss item: 0.5879340171813965
train loss item: 0.10337689518928528
train loss item: 0.19669950008392334
train loss item: 0.07646271586418152
train loss item: 0.2238496094942093
train loss item: 0.16509880125522614
train loss item: 0.1398099660873413
train loss item: 0.14187128841876984
train loss item: 0.15048962831497192
train loss item: 0.11488135159015656
train loss item: 0.09014186263084412
train loss item: 0.07619864493608475
train loss item: 0.16052541136741638
train loss item: 0.051838796585798264
train loss item: 0.07110533863306046
train loss item: 0.1852114051580429
train loss item: 0.8636706471443176
train loss item: 0.05233801528811455
train loss item: 0.14613725244998932
train loss item: 0.07402444630861282
train loss item: 0.1110839694738388
train loss item: 0.10412733256816864
train loss item: 0.300873726606369
train loss item: 0.15953703224658966
train loss item: 0.16089072823524475
train loss item: 2.2608144283294678
train loss item: 0.0955103263258934
train loss item: 0.11340790241956711
test loss item: 0.09021559357643127
test loss item: 0.07549773901700974
test loss item: 0.3992939889431
test loss item: 0.11793721467256546
test loss item: 0.15131103992462158
test loss item: 0.07708828151226044
test loss item: 0.9935464859008789
test loss item: 0.3301663100719452
test loss item: 0.14935749769210815
test loss item: 0.22902238368988037
test loss item: 0.6056647896766663
test loss item: 0.09451042860746384
test loss item: 0.127447709441185
test loss item: 0.15074126422405243
test loss item: 0.10960185527801514
test loss item: 0.05773438885807991
test loss item: 0.1523015797138214
test loss item: 0.2376033067703247
test loss item: 0.35761457681655884
test loss item: 0.1460990160703659
test loss item: 0.3757779002189636
test loss item: 0.21411241590976715
test loss item: 0.1426939070224762
test loss item: 0.10149029642343521
test loss item: 0.10961780697107315
test loss item: 0.1264854222536087
test loss item: 0.163521409034729
test loss item: 0.11099709570407867
test loss item: 0.18347351253032684
test loss item: 0.17766083776950836
test loss item: 0.5359585285186768
test loss item: 0.04945532605051994
test loss item: 0.09160924702882767
test loss item: 0.3012130558490753
test loss item: 0.24787411093711853
test loss item: 0.23823648691177368
test loss item: 0.44468578696250916
test loss item: 1.0383490324020386
test loss item: 0.2620543837547302
test loss item: 0.152654230594635
test loss item: 0.16932572424411774
test loss item: 0.10032705962657928
test loss item: 0.17582443356513977
test loss item: 0.11863092333078384
test loss item: 0.29275381565093994
test loss item: 0.22241972386837006
test loss item: 0.13519790768623352
test loss item: 0.11455529928207397
test loss item: 0.3003736138343811
test loss item: 0.42517176270484924
test loss item: 0.17921634018421173
test loss item: 0.08055444806814194
test loss item: 0.1403549164533615
test loss item: 0.08390318602323532
test loss item: 0.1681739240884781
test loss item: 0.5687081813812256
test loss item: 0.3314017653465271
test loss item: 0.12591858208179474
test loss item: 0.1312187761068344
test loss item: 0.1344991773366928
test loss item: 0.22974245250225067
test loss item: 0.14953716099262238
test loss item: 0.11533765494823456
test loss item: 0.1491232067346573
test loss item: 0.6071947813034058
test loss item: 0.15701034665107727
test loss item: 0.17678596079349518
test loss item: 0.144084632396698
test loss item: 0.3151743412017822
test loss item: 0.25025278329849243
test loss item: 0.05828716978430748
test loss item: 0.5482344627380371
test loss item: 0.14434035122394562
test loss item: 0.2073003202676773
test loss item: 0.08784975856542587
test loss item: 0.08045163005590439
test loss item: 0.10049392282962799
test loss item: 1.1577428579330444
test loss item: 0.24617253243923187
test loss item: 0.10429512709379196
test loss item: 0.0544862262904644
test loss item: 0.6615460515022278
test loss item: 0.49997350573539734
test loss item: 0.7855074405670166
test loss item: 0.11445997655391693
test loss item: 0.12589967250823975
test loss item: 0.05695252865552902
test loss item: 0.05377373844385147
test loss item: 0.11599196493625641
Epoch [19/50], Training Loss: 0.1968, Testing Loss: 0.2384
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 20/50
train loss item: 0.1527215838432312
train loss item: 0.3200642466545105
train loss item: 0.08941063284873962
train loss item: 0.29752519726753235
train loss item: 0.1260184347629547
train loss item: 0.11904498189687729
train loss item: 0.08372533321380615
train loss item: 0.265701562166214
train loss item: 0.058965910226106644
train loss item: 0.10576572269201279
train loss item: 0.1544792801141739
train loss item: 0.12565821409225464
train loss item: 0.07431097328662872
train loss item: 0.2109784185886383
train loss item: 0.09264329075813293
train loss item: 0.39848315715789795
train loss item: 0.05023212730884552
train loss item: 0.09432181715965271
train loss item: 0.11034030467271805
train loss item: 0.1030246689915657
train loss item: 0.11804889142513275
train loss item: 0.06931863725185394
train loss item: 0.4892114996910095
train loss item: 0.24756769835948944
train loss item: 0.19166257977485657
train loss item: 0.10194072872400284
train loss item: 0.0978371724486351
train loss item: 0.10120972245931625
train loss item: 0.05248188599944115
train loss item: 0.2629182040691376
train loss item: 0.9749171733856201
train loss item: 0.24000170826911926
train loss item: 0.07605338096618652
train loss item: 0.16155754029750824
train loss item: 0.1069609746336937
train loss item: 1.1615092754364014
train loss item: 0.21459375321865082
train loss item: 0.2998104989528656
train loss item: 0.23422257602214813
train loss item: 0.12173271179199219
train loss item: 0.09511309117078781
train loss item: 0.11379442363977432
train loss item: 0.17356745898723602
train loss item: 0.11819218844175339
train loss item: 0.28112468123435974
train loss item: 0.0688168928027153
train loss item: 0.06619083881378174
train loss item: 0.21184003353118896
train loss item: 0.12450859695672989
train loss item: 0.07306608557701111
train loss item: 0.13771429657936096
train loss item: 0.4618077874183655
train loss item: 0.05818094685673714
train loss item: 0.0659351795911789
train loss item: 0.9666261076927185
train loss item: 0.0863124206662178
train loss item: 0.13336056470870972
train loss item: 0.11875197291374207
train loss item: 0.07741774618625641
train loss item: 0.08853776007890701
train loss item: 0.2083439826965332
train loss item: 0.6338465213775635
train loss item: 0.1092459112405777
train loss item: 0.22556211054325104
train loss item: 0.07356833666563034
train loss item: 0.2441626340150833
train loss item: 0.19314272701740265
train loss item: 0.10349993407726288
train loss item: 0.15003429353237152
train loss item: 0.12725427746772766
train loss item: 0.11413134634494781
train loss item: 0.08855102211236954
train loss item: 0.09946101158857346
train loss item: 0.16461734473705292
train loss item: 0.05110123008489609
train loss item: 0.0741567313671112
train loss item: 0.26054006814956665
train loss item: 0.908391535282135
train loss item: 0.042987484484910965
train loss item: 0.1766023337841034
train loss item: 0.06602972745895386
train loss item: 0.10148553550243378
train loss item: 0.09165113419294357
train loss item: 0.2464010864496231
train loss item: 0.1489943116903305
train loss item: 0.1662253588438034
train loss item: 2.2598445415496826
train loss item: 0.07225785404443741
train loss item: 0.12797953188419342
test loss item: 0.09026946127414703
test loss item: 0.06554917991161346
test loss item: 0.35318800806999207
test loss item: 0.11346326023340225
test loss item: 0.12602545320987701
test loss item: 0.06723758578300476
test loss item: 0.7730892300605774
test loss item: 0.22270993888378143
test loss item: 0.12776638567447662
test loss item: 0.19199518859386444
test loss item: 0.5476982593536377
test loss item: 0.08032868802547455
test loss item: 0.10046009719371796
test loss item: 0.11904877424240112
test loss item: 0.09565340727567673
test loss item: 0.05962706357240677
test loss item: 0.1299591362476349
test loss item: 0.19627250730991364
test loss item: 0.29958629608154297
test loss item: 0.1144222766160965
test loss item: 0.30462437868118286
test loss item: 0.17220956087112427
test loss item: 0.11283574253320694
test loss item: 0.09322435408830643
test loss item: 0.09364459663629532
test loss item: 0.11060289293527603
test loss item: 0.14382801949977875
test loss item: 0.0897555872797966
test loss item: 0.1480698585510254
test loss item: 0.1530189961194992
test loss item: 0.44652020931243896
test loss item: 0.05310552567243576
test loss item: 0.0883367657661438
test loss item: 0.258101224899292
test loss item: 0.21427220106124878
test loss item: 0.20947127044200897
test loss item: 0.3637063503265381
test loss item: 0.9265236854553223
test loss item: 0.21584445238113403
test loss item: 0.12446413189172745
test loss item: 0.1481802612543106
test loss item: 0.08888579905033112
test loss item: 0.140440434217453
test loss item: 0.10359437763690948
test loss item: 0.23178496956825256
test loss item: 0.1842031478881836
test loss item: 0.10568904131650925
test loss item: 0.11117836087942123
test loss item: 0.24396918714046478
test loss item: 0.3606891334056854
test loss item: 0.13821345567703247
test loss item: 0.07684370875358582
test loss item: 0.12342802435159683
test loss item: 0.08097536116838455
test loss item: 0.14097219705581665
test loss item: 0.5109635591506958
test loss item: 0.2815869450569153
test loss item: 0.09568893164396286
test loss item: 0.11044953763484955
test loss item: 0.1082761213183403
test loss item: 0.18795138597488403
test loss item: 0.11313720047473907
test loss item: 0.09660884737968445
test loss item: 0.12178892642259598
test loss item: 0.537911057472229
test loss item: 0.15298733115196228
test loss item: 0.1419784128665924
test loss item: 0.12086048722267151
test loss item: 0.2731645107269287
test loss item: 0.21290536224842072
test loss item: 0.05326661467552185
test loss item: 0.4075528681278229
test loss item: 0.11343187838792801
test loss item: 0.15775902569293976
test loss item: 0.07961345463991165
test loss item: 0.0762612372636795
test loss item: 0.08900127559900284
test loss item: 1.0180821418762207
test loss item: 0.21612486243247986
test loss item: 0.08874166756868362
test loss item: 0.059731949120759964
test loss item: 0.5620107650756836
test loss item: 0.42258042097091675
test loss item: 0.6905816197395325
test loss item: 0.0927654430270195
test loss item: 0.1052396148443222
test loss item: 0.07684173434972763
test loss item: 0.07516404986381531
test loss item: 0.11739572882652283
Epoch [20/50], Training Loss: 0.2158, Testing Loss: 0.2027
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 21/50
train loss item: 0.19281147420406342
train loss item: 0.24248415231704712
train loss item: 0.10624107718467712
train loss item: 0.16461800038814545
train loss item: 0.13982625305652618
train loss item: 0.12022412568330765
train loss item: 0.09147283434867859
train loss item: 0.191533625125885
train loss item: 0.05296703800559044
train loss item: 0.11374031007289886
train loss item: 0.11512380838394165
train loss item: 0.09937292337417603
train loss item: 0.08425292372703552
train loss item: 0.19989345967769623
train loss item: 0.08692970871925354
train loss item: 0.3125917911529541
train loss item: 0.048000045120716095
train loss item: 0.09262148290872574
train loss item: 0.11380257457494736
train loss item: 0.1373402625322342
train loss item: 0.09901033341884613
train loss item: 0.0668426901102066
train loss item: 0.27224844694137573
train loss item: 0.15923915803432465
train loss item: 0.16707086563110352
train loss item: 0.12071499973535538
train loss item: 0.10197889059782028
train loss item: 0.11092965304851532
train loss item: 0.05254954844713211
train loss item: 0.29792359471321106
train loss item: 0.7319762110710144
train loss item: 0.21373465657234192
train loss item: 0.06896518915891647
train loss item: 0.11331760138273239
train loss item: 0.0857379287481308
train loss item: 0.9874370098114014
train loss item: 0.21242305636405945
train loss item: 0.23357254266738892
train loss item: 0.3156895041465759
train loss item: 0.1351242959499359
train loss item: 0.09640023112297058
train loss item: 0.11190339177846909
train loss item: 0.1477859914302826
train loss item: 0.11119748651981354
train loss item: 0.2664298117160797
train loss item: 0.06698659807443619
train loss item: 0.061592455953359604
train loss item: 0.16532394289970398
train loss item: 0.1179216131567955
train loss item: 0.06923835724592209
train loss item: 0.11499981582164764
train loss item: 0.3486921489238739
train loss item: 0.054121267050504684
train loss item: 0.07023457437753677
train loss item: 0.8361313343048096
train loss item: 0.07950401306152344
train loss item: 0.12148193269968033
train loss item: 0.10126347839832306
train loss item: 0.0768512636423111
train loss item: 0.0879335030913353
train loss item: 0.19068892300128937
train loss item: 0.5305615067481995
train loss item: 0.0995618999004364
train loss item: 0.1544608324766159
train loss item: 0.07097163051366806
train loss item: 0.15789616107940674
train loss item: 0.14488300681114197
train loss item: 0.10016746073961258
train loss item: 0.12407545745372772
train loss item: 0.12406478822231293
train loss item: 0.10687130689620972
train loss item: 0.07566343992948532
train loss item: 0.0736672654747963
train loss item: 0.1364007443189621
train loss item: 0.04987090453505516
train loss item: 0.0674499049782753
train loss item: 0.3039526343345642
train loss item: 0.8037228584289551
train loss item: 0.04430167376995087
train loss item: 0.1475583165884018
train loss item: 0.07101757824420929
train loss item: 0.09614669531583786
train loss item: 0.09819070249795914
train loss item: 0.2258555144071579
train loss item: 0.1477442979812622
train loss item: 0.18938632309436798
train loss item: 2.1906275749206543
train loss item: 0.07082386314868927
train loss item: 0.10632891952991486
test loss item: 0.09411919862031937
test loss item: 0.06556056439876556
test loss item: 0.32320666313171387
test loss item: 0.12009823322296143
test loss item: 0.12762463092803955
test loss item: 0.0738954246044159
test loss item: 0.9007960557937622
test loss item: 0.2911161482334137
test loss item: 0.1268773078918457
test loss item: 0.1935545653104782
test loss item: 0.5053649544715881
test loss item: 0.0810418650507927
test loss item: 0.1042853370308876
test loss item: 0.14598925411701202
test loss item: 0.09556055814027786
test loss item: 0.052837684750556946
test loss item: 0.1441667377948761
test loss item: 0.19143083691596985
test loss item: 0.3270130455493927
test loss item: 0.1252342015504837
test loss item: 0.3044230341911316
test loss item: 0.20220570266246796
test loss item: 0.12417856603860855
test loss item: 0.10133815556764603
test loss item: 0.09624740481376648
test loss item: 0.11645298451185226
test loss item: 0.14696182310581207
test loss item: 0.09688316285610199
test loss item: 0.15808072686195374
test loss item: 0.15476925671100616
test loss item: 0.4561508595943451
test loss item: 0.04749252647161484
test loss item: 0.09195523709058762
test loss item: 0.2443680763244629
test loss item: 0.19903242588043213
test loss item: 0.21357664465904236
test loss item: 0.40449258685112
test loss item: 0.8327623009681702
test loss item: 0.22092434763908386
test loss item: 0.14259636402130127
test loss item: 0.1614355444908142
test loss item: 0.09789998829364777
test loss item: 0.14242008328437805
test loss item: 0.11795151233673096
test loss item: 0.24343429505825043
test loss item: 0.2016889899969101
test loss item: 0.12183568626642227
test loss item: 0.11104701459407806
test loss item: 0.24524357914924622
test loss item: 0.35215649008750916
test loss item: 0.15120714902877808
test loss item: 0.07325395196676254
test loss item: 0.13099835813045502
test loss item: 0.08677815645933151
test loss item: 0.1408609300851822
test loss item: 0.46470317244529724
test loss item: 0.2835422158241272
test loss item: 0.10700027644634247
test loss item: 0.12381497025489807
test loss item: 0.1127525046467781
test loss item: 0.1842801570892334
test loss item: 0.13622042536735535
test loss item: 0.11105889827013016
test loss item: 0.12307090312242508
test loss item: 0.5094338059425354
test loss item: 0.16042384505271912
test loss item: 0.15266384184360504
test loss item: 0.12768544256687164
test loss item: 0.25533434748649597
test loss item: 0.22651895880699158
test loss item: 0.049393802881240845
test loss item: 0.48920947313308716
test loss item: 0.12763240933418274
test loss item: 0.18752498924732208
test loss item: 0.08195798844099045
test loss item: 0.08145157247781754
test loss item: 0.09647808223962784
test loss item: 0.9185895919799805
test loss item: 0.20565928518772125
test loss item: 0.09985433518886566
test loss item: 0.05809378996491432
test loss item: 0.5524559020996094
test loss item: 0.45255061984062195
test loss item: 0.6334043741226196
test loss item: 0.10138460993766785
test loss item: 0.10951843857765198
test loss item: 0.06644600629806519
test loss item: 0.06308668106794357
test loss item: 0.118233323097229
Epoch [21/50], Training Loss: 0.1917, Testing Loss: 0.2067
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 22/50
train loss item: 0.14890582859516144
train loss item: 0.19979031383991241
train loss item: 0.08192097395658493
train loss item: 0.1527116745710373
train loss item: 0.14797814190387726
train loss item: 0.135580375790596
train loss item: 0.08016309887170792
train loss item: 0.24711813032627106
train loss item: 0.06811525672674179
train loss item: 0.10381712019443512
train loss item: 0.09834492951631546
train loss item: 0.0950620099902153
train loss item: 0.07739761471748352
train loss item: 0.2174617201089859
train loss item: 0.10831392556428909
train loss item: 0.214199960231781
train loss item: 0.046967942267656326
train loss item: 0.12222672253847122
train loss item: 0.13102398812770844
train loss item: 0.08898033946752548
train loss item: 0.12373831123113632
train loss item: 0.057915057986974716
train loss item: 0.22332659363746643
train loss item: 0.24819715321063995
train loss item: 0.200128436088562
train loss item: 0.09544608741998672
train loss item: 0.07856176048517227
train loss item: 0.10713132470846176
train loss item: 0.05628504231572151
train loss item: 0.2305794507265091
train loss item: 0.3751309812068939
train loss item: 0.21766704320907593
train loss item: 0.07865100353956223
train loss item: 0.1285650134086609
train loss item: 0.08515049517154694
train loss item: 0.9386415481567383
train loss item: 0.23511184751987457
train loss item: 0.21522001922130585
train loss item: 0.1562938392162323
train loss item: 0.10040852427482605
train loss item: 0.08913658559322357
train loss item: 0.09490229189395905
train loss item: 0.13388875126838684
train loss item: 0.09562502801418304
train loss item: 0.22259867191314697
train loss item: 0.06993260979652405
train loss item: 0.0689227283000946
train loss item: 0.1380372941493988
train loss item: 0.10049675405025482
train loss item: 0.07050846517086029
train loss item: 0.1049865186214447
train loss item: 0.33396726846694946
train loss item: 0.05489085987210274
train loss item: 0.0690569058060646
train loss item: 0.8000507950782776
train loss item: 0.10383781045675278
train loss item: 0.11780330538749695
train loss item: 0.10331344604492188
train loss item: 0.06534377485513687
train loss item: 0.09012465178966522
train loss item: 0.16964581608772278
train loss item: 0.4735524654388428
train loss item: 0.08613743633031845
train loss item: 0.1387217491865158
train loss item: 0.07456868141889572
train loss item: 0.1822081357240677
train loss item: 0.13648389279842377
train loss item: 0.11056884378194809
train loss item: 0.12760715186595917
train loss item: 0.12296741455793381
train loss item: 0.09481561183929443
train loss item: 0.08807685971260071
train loss item: 0.06672346591949463
train loss item: 0.12440889328718185
train loss item: 0.04591817408800125
train loss item: 0.06439235806465149
train loss item: 0.1747753769159317
train loss item: 0.7760055661201477
train loss item: 0.04151163995265961
train loss item: 0.11017883569002151
train loss item: 0.06366907805204391
train loss item: 0.0867842584848404
train loss item: 0.0874348133802414
train loss item: 0.21805298328399658
train loss item: 0.14146459102630615
train loss item: 0.14505691826343536
train loss item: 2.1055829524993896
train loss item: 0.07881630212068558
train loss item: 0.10432320833206177
test loss item: 0.09176786988973618
test loss item: 0.07907422631978989
test loss item: 0.3965409994125366
test loss item: 0.11748477071523666
test loss item: 0.15864922106266022
test loss item: 0.08786353468894958
test loss item: 1.0070909261703491
test loss item: 0.3242752254009247
test loss item: 0.14855006337165833
test loss item: 0.2281511127948761
test loss item: 0.5863711833953857
test loss item: 0.08499044924974442
test loss item: 0.11348558962345123
test loss item: 0.1630782037973404
test loss item: 0.11106762290000916
test loss item: 0.06073547527194023
test loss item: 0.14627407491207123
test loss item: 0.24786891043186188
test loss item: 0.3493945002555847
test loss item: 0.13600414991378784
test loss item: 0.4072399139404297
test loss item: 0.20802155137062073
test loss item: 0.15707404911518097
test loss item: 0.10250139981508255
test loss item: 0.10919123142957687
test loss item: 0.11894121766090393
test loss item: 0.16150543093681335
test loss item: 0.11813491582870483
test loss item: 0.1850748360157013
test loss item: 0.17410622537136078
test loss item: 0.528076171875
test loss item: 0.05117194727063179
test loss item: 0.09214282035827637
test loss item: 0.3059292435646057
test loss item: 0.2544437646865845
test loss item: 0.23636290431022644
test loss item: 0.4427729547023773
test loss item: 0.9975634813308716
test loss item: 0.26665008068084717
test loss item: 0.1531136929988861
test loss item: 0.16328564286231995
test loss item: 0.09651373326778412
test loss item: 0.18393872678279877
test loss item: 0.11506769061088562
test loss item: 0.3186096251010895
test loss item: 0.2118527740240097
test loss item: 0.14309236407279968
test loss item: 0.11268569529056549
test loss item: 0.29704612493515015
test loss item: 0.4116440713405609
test loss item: 0.18644505739212036
test loss item: 0.07432358711957932
test loss item: 0.13926303386688232
test loss item: 0.08483421057462692
test loss item: 0.17488586902618408
test loss item: 0.5639650821685791
test loss item: 0.3200269341468811
test loss item: 0.13686072826385498
test loss item: 0.13220416009426117
test loss item: 0.125906839966774
test loss item: 0.23240254819393158
test loss item: 0.14095263183116913
test loss item: 0.11106818914413452
test loss item: 0.1345556229352951
test loss item: 0.6036826372146606
test loss item: 0.15526430308818817
test loss item: 0.16945137083530426
test loss item: 0.13796845078468323
test loss item: 0.30809715390205383
test loss item: 0.24510714411735535
test loss item: 0.06296510994434357
test loss item: 0.5455877780914307
test loss item: 0.16131822764873505
test loss item: 0.2014799863100052
test loss item: 0.09098132699728012
test loss item: 0.08732252568006516
test loss item: 0.10107102990150452
test loss item: 1.1045708656311035
test loss item: 0.245956689119339
test loss item: 0.11255544424057007
test loss item: 0.06638874858617783
test loss item: 0.6410332322120667
test loss item: 0.5057010650634766
test loss item: 0.7558287978172302
test loss item: 0.11835617572069168
test loss item: 0.11692115664482117
test loss item: 0.07398315519094467
test loss item: 0.06338014453649521
test loss item: 0.11125127971172333
Epoch [22/50], Training Loss: 0.1762, Testing Loss: 0.2372
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 23/50
train loss item: 0.14319415390491486
train loss item: 0.19260720908641815
train loss item: 0.0807110145688057
train loss item: 0.18117649853229523
train loss item: 0.14926202595233917
train loss item: 0.11611593514680862
train loss item: 0.09842626005411148
train loss item: 0.22747308015823364
train loss item: 0.0629965141415596
train loss item: 0.1104515790939331
train loss item: 0.12136571109294891
train loss item: 0.09687932580709457
train loss item: 0.06977084279060364
train loss item: 0.17637798190116882
train loss item: 0.09358823299407959
train loss item: 0.3001490831375122
train loss item: 0.04732193797826767
train loss item: 0.09010288864374161
train loss item: 0.12731367349624634
train loss item: 0.08449462056159973
train loss item: 0.11403568089008331
train loss item: 0.06455639749765396
train loss item: 0.22754909098148346
train loss item: 0.2000322937965393
train loss item: 0.1637369841337204
train loss item: 0.08728449791669846
train loss item: 0.07870852947235107
train loss item: 0.09525356441736221
train loss item: 0.04559539631009102
train loss item: 0.24876587092876434
train loss item: 0.3950861692428589
train loss item: 0.20490692555904388
train loss item: 0.06602094322443008
train loss item: 0.1259695589542389
train loss item: 0.07339488714933395
train loss item: 0.9180137515068054
train loss item: 0.16344712674617767
train loss item: 0.16466350853443146
train loss item: 0.15637251734733582
train loss item: 0.09992432594299316
train loss item: 0.07716027647256851
train loss item: 0.09882722049951553
train loss item: 0.1226179227232933
train loss item: 0.08769088238477707
train loss item: 0.21256349980831146
train loss item: 0.06724955886602402
train loss item: 0.05416419357061386
train loss item: 0.11245273053646088
train loss item: 0.089556485414505
train loss item: 0.07357151061296463
train loss item: 0.09372550249099731
train loss item: 0.3333500623703003
train loss item: 0.05128925293684006
train loss item: 0.06216990947723389
train loss item: 0.7611236572265625
train loss item: 0.09289994835853577
train loss item: 0.10528232902288437
train loss item: 0.10041353851556778
train loss item: 0.07454473525285721
train loss item: 0.09340980648994446
train loss item: 0.18688881397247314
train loss item: 0.4450734853744507
train loss item: 0.08330558240413666
train loss item: 0.1214013546705246
train loss item: 0.06877153366804123
train loss item: 0.15487077832221985
train loss item: 0.15129566192626953
train loss item: 0.09951885789632797
train loss item: 0.11787080019712448
train loss item: 0.13563621044158936
train loss item: 0.09738568961620331
train loss item: 0.06914966553449631
train loss item: 0.06789351999759674
train loss item: 0.11992016434669495
train loss item: 0.04756375029683113
train loss item: 0.06322970986366272
train loss item: 0.21210850775241852
train loss item: 0.7591753005981445
train loss item: 0.05175303295254707
train loss item: 0.12093869596719742
train loss item: 0.0610027052462101
train loss item: 0.09706909954547882
train loss item: 0.07604657113552094
train loss item: 0.23075196146965027
train loss item: 0.13907408714294434
train loss item: 0.12934976816177368
train loss item: 2.0482239723205566
train loss item: 0.07223653793334961
train loss item: 0.10754828155040741
test loss item: 0.09362801164388657
test loss item: 0.06327463686466217
test loss item: 0.3683127760887146
test loss item: 0.11827598512172699
test loss item: 0.14121170341968536
test loss item: 0.07629646360874176
test loss item: 1.0364705324172974
test loss item: 0.3512451946735382
test loss item: 0.13535362482070923
test loss item: 0.21023236215114594
test loss item: 0.5392427444458008
test loss item: 0.08118179440498352
test loss item: 0.10635137557983398
test loss item: 0.15793056786060333
test loss item: 0.10137435048818588
test loss item: 0.049519818276166916
test loss item: 0.15794111788272858
test loss item: 0.22914135456085205
test loss item: 0.3649093210697174
test loss item: 0.14464908838272095
test loss item: 0.3654778301715851
test loss item: 0.22504675388336182
test loss item: 0.14412710070610046
test loss item: 0.10455404222011566
test loss item: 0.10525164753198624
test loss item: 0.12464883923530579
test loss item: 0.1604352444410324
test loss item: 0.10245287418365479
test loss item: 0.17554576694965363
test loss item: 0.166422501206398
test loss item: 0.5081188678741455
test loss item: 0.04407869651913643
test loss item: 0.09176571667194366
test loss item: 0.2872382402420044
test loss item: 0.23309694230556488
test loss item: 0.22946713864803314
test loss item: 0.4519232511520386
test loss item: 0.9089640378952026
test loss item: 0.24901296198368073
test loss item: 0.15974535048007965
test loss item: 0.16982188820838928
test loss item: 0.10195960849523544
test loss item: 0.16479265689849854
test loss item: 0.12287305295467377
test loss item: 0.2828370928764343
test loss item: 0.23077653348445892
test loss item: 0.13681010901927948
test loss item: 0.12060262262821198
test loss item: 0.2810707688331604
test loss item: 0.39261364936828613
test loss item: 0.15794162452220917
test loss item: 0.07320919632911682
test loss item: 0.1379811018705368
test loss item: 0.08593831211328506
test loss item: 0.15839314460754395
test loss item: 0.5148986577987671
test loss item: 0.31725630164146423
test loss item: 0.1202336773276329
test loss item: 0.13365502655506134
test loss item: 0.11376795172691345
test loss item: 0.2114540934562683
test loss item: 0.15476642549037933
test loss item: 0.12145436555147171
test loss item: 0.12878192961215973
test loss item: 0.5649636387825012
test loss item: 0.15804335474967957
test loss item: 0.17711997032165527
test loss item: 0.13738872110843658
test loss item: 0.2888014614582062
test loss item: 0.2560621500015259
test loss item: 0.04873163625597954
test loss item: 0.5774869918823242
test loss item: 0.14715899527072906
test loss item: 0.2212376743555069
test loss item: 0.08434297889471054
test loss item: 0.0823482945561409
test loss item: 0.1017695814371109
test loss item: 1.0017895698547363
test loss item: 0.2322467416524887
test loss item: 0.10428841412067413
test loss item: 0.05468130111694336
test loss item: 0.6173256635665894
test loss item: 0.5007847547531128
test loss item: 0.6876994371414185
test loss item: 0.11140982806682587
test loss item: 0.12011753767728806
test loss item: 0.05676545202732086
test loss item: 0.052659958600997925
test loss item: 0.11833131313323975
Epoch [23/50], Training Loss: 0.1704, Testing Loss: 0.2281
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 24/50
train loss item: 0.12640179693698883
train loss item: 0.2087373286485672
train loss item: 0.07438095659017563
train loss item: 0.19225212931632996
train loss item: 0.12593066692352295
train loss item: 0.10953840613365173
train loss item: 0.074263796210289
train loss item: 0.1683800369501114
train loss item: 0.046047717332839966
train loss item: 0.09363365918397903
train loss item: 0.11395661532878876
train loss item: 0.10135866701602936
train loss item: 0.06600926071405411
train loss item: 0.15524224936962128
train loss item: 0.07910973578691483
train loss item: 0.21623705327510834
train loss item: 0.04552784562110901
train loss item: 0.09543430060148239
train loss item: 0.11104576289653778
train loss item: 0.09273654222488403
train loss item: 0.11337023973464966
train loss item: 0.05628761649131775
train loss item: 0.193311408162117
train loss item: 0.1500566154718399
train loss item: 0.14503568410873413
train loss item: 0.08877845853567123
train loss item: 0.07452421635389328
train loss item: 0.11042238771915436
train loss item: 0.04207519441843033
train loss item: 0.2464127540588379
train loss item: 0.544380247592926
train loss item: 0.17355093359947205
train loss item: 0.0650784820318222
train loss item: 0.11574406921863556
train loss item: 0.07400315999984741
train loss item: 0.8635215759277344
train loss item: 0.20760555565357208
train loss item: 0.1836131364107132
train loss item: 0.1974605917930603
train loss item: 0.12427306920289993
train loss item: 0.09138956665992737
train loss item: 0.11380346864461899
train loss item: 0.14378146827220917
train loss item: 0.101064033806324
train loss item: 0.2684113383293152
train loss item: 0.06994832307100296
train loss item: 0.07051323354244232
train loss item: 0.14988134801387787
train loss item: 0.1123797595500946
train loss item: 0.07109372317790985
train loss item: 0.09407944977283478
train loss item: 0.34938880801200867
train loss item: 0.05630740150809288
train loss item: 0.07349485158920288
train loss item: 0.6982879042625427
train loss item: 0.07810521125793457
train loss item: 0.10794668644666672
train loss item: 0.09877961128950119
train loss item: 0.06952420622110367
train loss item: 0.08795103430747986
train loss item: 0.21972981095314026
train loss item: 0.4021749198436737
train loss item: 0.09876633435487747
train loss item: 0.15488986670970917
train loss item: 0.06849558651447296
train loss item: 0.15404927730560303
train loss item: 0.17115740478038788
train loss item: 0.09500377625226974
train loss item: 0.14196152985095978
train loss item: 0.10295511782169342
train loss item: 0.11386123299598694
train loss item: 0.08315002918243408
train loss item: 0.06743375211954117
train loss item: 0.1080310195684433
train loss item: 0.05058891326189041
train loss item: 0.0660831555724144
train loss item: 0.19813446700572968
train loss item: 0.7264655828475952
train loss item: 0.04004129767417908
train loss item: 0.11420049518346786
train loss item: 0.07116582244634628
train loss item: 0.0851704552769661
train loss item: 0.0771804228425026
train loss item: 0.2099476456642151
train loss item: 0.14618009328842163
train loss item: 0.20436254143714905
train loss item: 2.001056671142578
train loss item: 0.07202596217393875
train loss item: 0.12265851348638535
test loss item: 0.08677498996257782
test loss item: 0.06912492960691452
test loss item: 0.4218963086605072
test loss item: 0.11301400512456894
test loss item: 0.1608816236257553
test loss item: 0.07149245589971542
test loss item: 1.1585527658462524
test loss item: 0.3730762004852295
test loss item: 0.16248080134391785
test loss item: 0.25339940190315247
test loss item: 0.6291850209236145
test loss item: 0.07921066880226135
test loss item: 0.11545559018850327
test loss item: 0.17117196321487427
test loss item: 0.11782639473676682
test loss item: 0.04727546125650406
test loss item: 0.1458299160003662
test loss item: 0.28010815382003784
test loss item: 0.3823509216308594
test loss item: 0.13518844544887543
test loss item: 0.460959255695343
test loss item: 0.2262686938047409
test loss item: 0.16759517788887024
test loss item: 0.09442189335823059
test loss item: 0.11408089846372604
test loss item: 0.12253027409315109
test loss item: 0.17043109238147736
test loss item: 0.11302109062671661
test loss item: 0.1925455927848816
test loss item: 0.1954832673072815
test loss item: 0.5958478450775146
test loss item: 0.0427393801510334
test loss item: 0.08070001006126404
test loss item: 0.3329484164714813
test loss item: 0.2777784466743469
test loss item: 0.274095743894577
test loss item: 0.49184247851371765
test loss item: 1.0781131982803345
test loss item: 0.29589927196502686
test loss item: 0.15463224053382874
test loss item: 0.1708701103925705
test loss item: 0.09016507118940353
test loss item: 0.22172480821609497
test loss item: 0.12341444194316864
test loss item: 0.3689977824687958
test loss item: 0.20484982430934906
test loss item: 0.16206997632980347
test loss item: 0.12137421220541
test loss item: 0.3168964684009552
test loss item: 0.4588637351989746
test loss item: 0.22432991862297058
test loss item: 0.07842867821455002
test loss item: 0.1563090831041336
test loss item: 0.08702881634235382
test loss item: 0.20378515124320984
test loss item: 0.6080583930015564
test loss item: 0.3494749069213867
test loss item: 0.19419097900390625
test loss item: 0.14085881412029266
test loss item: 0.14049503207206726
test loss item: 0.26963144540786743
test loss item: 0.1423015296459198
test loss item: 0.10811755806207657
test loss item: 0.13041327893733978
test loss item: 0.6366650462150574
test loss item: 0.15560874342918396
test loss item: 0.16868256032466888
test loss item: 0.1377941220998764
test loss item: 0.32169845700263977
test loss item: 0.2815452814102173
test loss item: 0.04337726905941963
test loss item: 0.6211268901824951
test loss item: 0.1836702674627304
test loss item: 0.2089075744152069
test loss item: 0.08105332404375076
test loss item: 0.073115773499012
test loss item: 0.09530579298734665
test loss item: 1.1783521175384521
test loss item: 0.25451919436454773
test loss item: 0.09863246232271194
test loss item: 0.04286617785692215
test loss item: 0.7066425681114197
test loss item: 0.5747305154800415
test loss item: 0.8145034909248352
test loss item: 0.12070772796869278
test loss item: 0.11939100176095963
test loss item: 0.045863863080739975
test loss item: 0.044445574283599854
test loss item: 0.10567831248044968
Epoch [24/50], Training Loss: 0.1701, Testing Loss: 0.2544
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 25/50
train loss item: 0.18456509709358215
train loss item: 0.5058474540710449
train loss item: 0.08792674541473389
train loss item: 0.1681753545999527
train loss item: 0.11880222707986832
train loss item: 0.10816740989685059
train loss item: 0.07361849397420883
train loss item: 0.352373868227005
train loss item: 0.0646866112947464
train loss item: 0.12260184437036514
train loss item: 0.1539887636899948
train loss item: 0.09886974841356277
train loss item: 0.07219687104225159
train loss item: 0.16709496080875397
train loss item: 0.10069537162780762
train loss item: 0.1829042285680771
train loss item: 0.039576008915901184
train loss item: 0.07761250436306
train loss item: 0.12772369384765625
train loss item: 0.0831783339381218
train loss item: 0.08223289251327515
train loss item: 0.05543588846921921
train loss item: 0.1988777369260788
train loss item: 0.19479253888130188
train loss item: 0.15369102358818054
train loss item: 0.0761834979057312
train loss item: 0.08250127732753754
train loss item: 0.09235882014036179
train loss item: 0.04738583788275719
train loss item: 0.23850978910923004
train loss item: 0.28422313928604126
train loss item: 0.21848635375499725
train loss item: 0.07037859410047531
train loss item: 0.11709257960319519
train loss item: 0.07692539691925049
train loss item: 0.8950580954551697
train loss item: 0.17802931368350983
train loss item: 0.15852494537830353
train loss item: 0.15991371870040894
train loss item: 0.10539181530475616
train loss item: 0.07412552088499069
train loss item: 0.08323090523481369
train loss item: 0.11322607845067978
train loss item: 0.09609900414943695
train loss item: 0.2196916788816452
train loss item: 0.07200770080089569
train loss item: 0.08274903893470764
train loss item: 0.10786332935094833
train loss item: 0.08357709646224976
train loss item: 0.07403065264225006
train loss item: 0.09656453132629395
train loss item: 0.2852330803871155
train loss item: 0.05644204095005989
train loss item: 0.06273243576288223
train loss item: 0.7325578331947327
train loss item: 0.07806694507598877
train loss item: 0.08852501213550568
train loss item: 0.09593997150659561
train loss item: 0.06250906735658646
train loss item: 0.0796598419547081
train loss item: 0.17599855363368988
train loss item: 0.3605818748474121
train loss item: 0.08650317788124084
train loss item: 0.12432650476694107
train loss item: 0.07149795442819595
train loss item: 0.24524377286434174
train loss item: 0.1579209864139557
train loss item: 0.09212233126163483
train loss item: 0.11320673674345016
train loss item: 0.10513316839933395
train loss item: 0.0916263684630394
train loss item: 0.07539153844118118
train loss item: 0.07480045408010483
train loss item: 0.14181916415691376
train loss item: 0.044309165328741074
train loss item: 0.0639597475528717
train loss item: 0.20945623517036438
train loss item: 0.7416404485702515
train loss item: 0.04192415252327919
train loss item: 0.1340421885251999
train loss item: 0.05918734893202782
train loss item: 0.08386021107435226
train loss item: 0.07543635368347168
train loss item: 0.21177957952022552
train loss item: 0.14366598427295685
train loss item: 0.2369878739118576
train loss item: 1.9637683629989624
train loss item: 0.06178582087159157
train loss item: 0.11097245663404465
test loss item: 0.08770354092121124
test loss item: 0.05673906207084656
test loss item: 0.33417630195617676
test loss item: 0.11035500466823578
test loss item: 0.12726937234401703
test loss item: 0.061810579150915146
test loss item: 0.9497482776641846
test loss item: 0.2787630558013916
test loss item: 0.1222415566444397
test loss item: 0.18700505793094635
test loss item: 0.5267153382301331
test loss item: 0.0746617391705513
test loss item: 0.09236004948616028
test loss item: 0.13752929866313934
test loss item: 0.09145088493824005
test loss item: 0.04674850404262543
test loss item: 0.1400274634361267
test loss item: 0.19900164008140564
test loss item: 0.3234134614467621
test loss item: 0.12271855771541595
test loss item: 0.3209298849105835
test loss item: 0.19141274690628052
test loss item: 0.12384437769651413
test loss item: 0.08978942036628723
test loss item: 0.09512399137020111
test loss item: 0.11493046581745148
test loss item: 0.14758194983005524
test loss item: 0.08873506635427475
test loss item: 0.158710315823555
test loss item: 0.15504184365272522
test loss item: 0.46757757663726807
test loss item: 0.041705504059791565
test loss item: 0.07996297627687454
test loss item: 0.2598513662815094
test loss item: 0.20804791152477264
test loss item: 0.20513524115085602
test loss item: 0.40442460775375366
test loss item: 0.8871987462043762
test loss item: 0.2251385748386383
test loss item: 0.14015495777130127
test loss item: 0.15926234424114227
test loss item: 0.08679166436195374
test loss item: 0.14646954834461212
test loss item: 0.11056225746870041
test loss item: 0.25291872024536133
test loss item: 0.19918836653232574
test loss item: 0.1157444417476654
test loss item: 0.10481086373329163
test loss item: 0.24378150701522827
test loss item: 0.367124080657959
test loss item: 0.1401771456003189
test loss item: 0.06736762821674347
test loss item: 0.12370990961790085
test loss item: 0.07948331534862518
test loss item: 0.14165614545345306
test loss item: 0.48721060156822205
test loss item: 0.2879621088504791
test loss item: 0.10636088997125626
test loss item: 0.11736931651830673
test loss item: 0.09794344007968903
test loss item: 0.18679143488407135
test loss item: 0.12548664212226868
test loss item: 0.10333487391471863
test loss item: 0.12158115953207016
test loss item: 0.5251365900039673
test loss item: 0.15469521284103394
test loss item: 0.15705803036689758
test loss item: 0.1297764778137207
test loss item: 0.265796035528183
test loss item: 0.21602877974510193
test loss item: 0.03957870975136757
test loss item: 0.5155026912689209
test loss item: 0.12436328083276749
test loss item: 0.19031639397144318
test loss item: 0.07195527106523514
test loss item: 0.06765273958444595
test loss item: 0.08972320705652237
test loss item: 0.9750146865844727
test loss item: 0.2182772159576416
test loss item: 0.08820756524801254
test loss item: 0.04876067861914635
test loss item: 0.5821065306663513
test loss item: 0.4571473300457001
test loss item: 0.6643699407577515
test loss item: 0.10499333590269089
test loss item: 0.105842724442482
test loss item: 0.04837445914745331
test loss item: 0.04516054317355156
test loss item: 0.10975417494773865
Epoch [25/50], Training Loss: 0.1699, Testing Loss: 0.2072
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.1736449897289276
loss item: 0.10621494799852371
loss item: 1.0051759481430054
loss item: 0.4776678681373596
loss item: 0.2866295576095581
loss item: 0.18531279265880585
loss item: 0.10572293400764465
loss item: 0.4227024018764496
loss item: 0.10118666291236877
loss item: 0.09879206866025925
loss item: 0.4956504702568054
loss item: 0.03454211726784706
loss item: 0.43597814440727234
loss item: 0.11068452149629593
loss item: 0.15428778529167175
loss item: 0.1195409893989563
loss item: 0.16372300684452057
loss item: 0.33181872963905334
loss item: 0.5203383564949036
loss item: 0.2128572314977646
loss item: 0.16695475578308105
loss item: 0.09962993860244751
loss item: 0.12537486851215363
loss item: 0.11705609411001205
loss item: 0.14171606302261353
loss item: 0.36031532287597656
loss item: 0.6423415541648865
loss item: 0.08407345414161682
loss item: 0.06921972334384918
loss item: 0.16805310547351837
loss item: 0.5475948452949524
loss item: 0.9400992393493652
loss item: 0.0871560126543045
loss item: 0.27195313572883606
loss item: 0.08864274621009827
loss item: 0.07078208029270172
loss item: 0.18516647815704346
loss item: 0.1134558767080307
loss item: 0.21536487340927124
loss item: 0.35527631640434265
loss item: 0.5793418884277344
loss item: 0.10451672971248627
loss item: 0.09457170218229294
loss item: 0.033540647476911545
Val Loss: 0.2547
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.0001 2 360 done at Tue Nov 12 10:13:54 CET 2024
UNet2 with 1 50 0.0005 2 360 start at Tue Nov 12 10:13:54 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 0.9121710062026978
train loss item: 2.170234203338623
train loss item: 0.5969551205635071
train loss item: 1.0422260761260986
train loss item: 1.5058915615081787
train loss item: 0.5180912613868713
train loss item: 0.49037230014801025
train loss item: 1.20503830909729
train loss item: 0.3879775404930115
train loss item: 0.5143818259239197
train loss item: 0.5442823171615601
train loss item: 0.36353808641433716
train loss item: 0.29374197125434875
train loss item: 0.721674382686615
train loss item: 0.36487895250320435
train loss item: 1.0422148704528809
train loss item: 0.3247540593147278
train loss item: 0.384751558303833
train loss item: 0.43143996596336365
train loss item: 0.3903164863586426
train loss item: 0.29459139704704285
train loss item: 0.29048487544059753
train loss item: 1.4911901950836182
train loss item: 1.181415319442749
train loss item: 0.7108883857727051
train loss item: 0.34139105677604675
train loss item: 0.26552310585975647
train loss item: 0.2971615195274353
train loss item: 0.22646090388298035
train loss item: 0.9468911290168762
train loss item: 2.5608320236206055
train loss item: 0.6372052431106567
train loss item: 0.31347858905792236
train loss item: 0.43792685866355896
train loss item: 0.38778653740882874
train loss item: 2.403876781463623
train loss item: 0.5180559158325195
train loss item: 0.454937607049942
train loss item: 0.48163050413131714
train loss item: 0.3169960379600525
train loss item: 0.2842999994754791
train loss item: 0.3337368071079254
train loss item: 0.34325841069221497
train loss item: 0.279103547334671
train loss item: 0.7303104996681213
train loss item: 0.1806126981973648
train loss item: 0.15928435325622559
train loss item: 0.5602288246154785
train loss item: 0.2483481913805008
train loss item: 0.18493935465812683
train loss item: 0.46334409713745117
train loss item: 1.1570740938186646
train loss item: 0.17289067804813385
train loss item: 0.21393296122550964
train loss item: 2.263690710067749
train loss item: 0.20760658383369446
train loss item: 0.3315351903438568
train loss item: 0.26603835821151733
train loss item: 0.22858698666095734
train loss item: 0.19368278980255127
train loss item: 0.973995566368103
train loss item: 2.126312017440796
train loss item: 0.24449199438095093
train loss item: 0.3856185972690582
train loss item: 0.19268381595611572
train loss item: 0.6291232705116272
train loss item: 0.40863367915153503
train loss item: 0.21679054200649261
train loss item: 0.2938111126422882
train loss item: 0.30855199694633484
train loss item: 0.27151304483413696
train loss item: 0.13652412593364716
train loss item: 0.38320818543434143
train loss item: 0.30155375599861145
train loss item: 0.10533125698566437
train loss item: 0.13810761272907257
train loss item: 0.8903178572654724
train loss item: 1.3625606298446655
train loss item: 0.09041062742471695
train loss item: 0.23317070305347443
train loss item: 0.1384125053882599
train loss item: 0.19903598725795746
train loss item: 0.20897766947746277
train loss item: 0.5486323237419128
train loss item: 0.3172820210456848
train loss item: 0.5693963766098022
train loss item: 4.145247459411621
train loss item: 0.18814411759376526
train loss item: 0.5067338347434998
test loss item: 0.18382667005062103
test loss item: 0.1365739405155182
test loss item: 0.41083237528800964
test loss item: 0.20865187048912048
test loss item: 0.23717115819454193
test loss item: 0.14262163639068604
test loss item: 1.1516164541244507
test loss item: 0.35866788029670715
test loss item: 0.17445608973503113
test loss item: 0.3129975199699402
test loss item: 0.6522586345672607
test loss item: 0.14945241808891296
test loss item: 0.171150341629982
test loss item: 0.34414222836494446
test loss item: 0.1705307960510254
test loss item: 0.10266879945993423
test loss item: 0.23076732456684113
test loss item: 0.3608337640762329
test loss item: 0.544313371181488
test loss item: 0.25117790699005127
test loss item: 0.5959290862083435
test loss item: 0.2902483344078064
test loss item: 0.24555017054080963
test loss item: 0.1689915955066681
test loss item: 0.18852053582668304
test loss item: 0.21177612245082855
test loss item: 0.2947025001049042
test loss item: 0.1973285973072052
test loss item: 0.2959226965904236
test loss item: 0.29615315794944763
test loss item: 0.536732017993927
test loss item: 0.08419773727655411
test loss item: 0.15306773781776428
test loss item: 0.46644914150238037
test loss item: 0.32823216915130615
test loss item: 0.41984784603118896
test loss item: 0.6306807398796082
test loss item: 1.0158989429473877
test loss item: 0.3773774802684784
test loss item: 0.23498357832431793
test loss item: 0.25026214122772217
test loss item: 0.19293440878391266
test loss item: 0.2925140857696533
test loss item: 0.158233180642128
test loss item: 0.5004450082778931
test loss item: 0.33732032775878906
test loss item: 0.26091742515563965
test loss item: 0.263500452041626
test loss item: 0.34794875979423523
test loss item: 0.5313205122947693
test loss item: 0.2480410784482956
test loss item: 0.13761262595653534
test loss item: 0.18840177357196808
test loss item: 0.14149489998817444
test loss item: 0.2472057044506073
test loss item: 0.6557876467704773
test loss item: 0.4453950822353363
test loss item: 0.24746428430080414
test loss item: 0.19734199345111847
test loss item: 0.1877332180738449
test loss item: 0.37474972009658813
test loss item: 0.1691061109304428
test loss item: 0.19565612077713013
test loss item: 0.22545501589775085
test loss item: 0.6118927597999573
test loss item: 0.2756834328174591
test loss item: 0.2549784481525421
test loss item: 0.2315780222415924
test loss item: 0.4494320750236511
test loss item: 0.3653990924358368
test loss item: 0.11065135896205902
test loss item: 0.6585938930511475
test loss item: 0.3180546462535858
test loss item: 0.30787891149520874
test loss item: 0.13355079293251038
test loss item: 0.1778392493724823
test loss item: 0.17012012004852295
test loss item: 0.9754599928855896
test loss item: 0.44219520688056946
test loss item: 0.19612756371498108
test loss item: 0.10388363897800446
test loss item: 0.666232705116272
test loss item: 0.6712315082550049
test loss item: 0.6759641170501709
test loss item: 0.19929556548595428
test loss item: 0.18416278064250946
test loss item: 0.09515104442834854
test loss item: 0.07982451468706131
test loss item: 0.18442845344543457
Epoch [1/50], Training Loss: 0.6076, Testing Loss: 0.3221
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/50
train loss item: 0.4450467824935913
train loss item: 0.9824851155281067
train loss item: 0.21558232605457306
train loss item: 0.42215126752853394
train loss item: 0.6178328394889832
train loss item: 0.28241294622421265
train loss item: 0.30494824051856995
train loss item: 0.6950170993804932
train loss item: 0.1655249297618866
train loss item: 0.33107244968414307
train loss item: 0.28655171394348145
train loss item: 0.26815223693847656
train loss item: 0.13096314668655396
train loss item: 0.4538443088531494
train loss item: 0.27114224433898926
train loss item: 0.9579570889472961
train loss item: 0.09154451638460159
train loss item: 0.2752035856246948
train loss item: 0.30435267090797424
train loss item: 0.32244816422462463
train loss item: 0.2022254765033722
train loss item: 0.26377323269844055
train loss item: 1.119254469871521
train loss item: 0.8012851476669312
train loss item: 0.6551558375358582
train loss item: 0.23846478760242462
train loss item: 0.19877980649471283
train loss item: 0.2451377660036087
train loss item: 0.1369827836751938
train loss item: 0.572328507900238
train loss item: 1.978947639465332
train loss item: 0.565528154373169
train loss item: 0.1641027182340622
train loss item: 0.34206950664520264
train loss item: 0.1470012068748474
train loss item: 2.097047805786133
train loss item: 0.6329845786094666
train loss item: 0.4981410503387451
train loss item: 0.6575279831886292
train loss item: 0.24326637387275696
train loss item: 0.24258162081241608
train loss item: 0.3306500017642975
train loss item: 0.3179427981376648
train loss item: 0.25048205256462097
train loss item: 0.7904554009437561
train loss item: 0.16197244822978973
train loss item: 0.14376601576805115
train loss item: 0.3770570158958435
train loss item: 0.24924957752227783
train loss item: 0.19223685562610626
train loss item: 0.28537946939468384
train loss item: 1.1084059476852417
train loss item: 0.10132535547018051
train loss item: 0.1369573473930359
train loss item: 2.324069023132324
train loss item: 0.20837727189064026
train loss item: 0.3174915313720703
train loss item: 0.28133657574653625
train loss item: 0.19239932298660278
train loss item: 0.1410199999809265
train loss item: 0.681387186050415
train loss item: 1.9687566757202148
train loss item: 0.2386859804391861
train loss item: 0.3375028371810913
train loss item: 0.16946417093276978
train loss item: 0.5486193299293518
train loss item: 0.35398101806640625
train loss item: 0.20696553587913513
train loss item: 0.430447518825531
train loss item: 0.30450165271759033
train loss item: 0.1973540484905243
train loss item: 0.12412653863430023
train loss item: 0.264680951833725
train loss item: 0.24869383871555328
train loss item: 0.07241223007440567
train loss item: 0.10423339903354645
train loss item: 0.6838665008544922
train loss item: 1.1029239892959595
train loss item: 0.11991212517023087
train loss item: 0.34055137634277344
train loss item: 0.2376936376094818
train loss item: 0.22207514941692352
train loss item: 0.19671185314655304
train loss item: 0.43061715364456177
train loss item: 0.3548765480518341
train loss item: 0.4760364294052124
train loss item: 3.758190393447876
train loss item: 0.20226047933101654
train loss item: 0.3746556341648102
test loss item: 0.19860294461250305
test loss item: 0.16763918101787567
test loss item: 0.3776116669178009
test loss item: 0.2312430739402771
test loss item: 0.23198853433132172
test loss item: 0.16190336644649506
test loss item: 1.7505863904953003
test loss item: 0.8248295187950134
test loss item: 0.20095330476760864
test loss item: 0.3044755160808563
test loss item: 0.5963309407234192
test loss item: 0.1799955666065216
test loss item: 0.22195079922676086
test loss item: 0.2653982937335968
test loss item: 0.19353701174259186
test loss item: 0.13066476583480835
test loss item: 0.2951430082321167
test loss item: 0.2901497483253479
test loss item: 0.8098485469818115
test loss item: 0.3268722593784332
test loss item: 0.45391082763671875
test loss item: 0.40904268622398376
test loss item: 0.25762489438056946
test loss item: 0.21307724714279175
test loss item: 0.17604738473892212
test loss item: 0.23431158065795898
test loss item: 0.31705668568611145
test loss item: 0.20268899202346802
test loss item: 0.30793607234954834
test loss item: 0.28738275170326233
test loss item: 0.6604254245758057
test loss item: 0.11647699773311615
test loss item: 0.1937674731016159
test loss item: 0.38305869698524475
test loss item: 0.26640674471855164
test loss item: 0.48732510209083557
test loss item: 0.9094134569168091
test loss item: 0.8626341223716736
test loss item: 0.3273560404777527
test loss item: 0.2847084105014801
test loss item: 0.278881311416626
test loss item: 0.2099149525165558
test loss item: 0.2599063217639923
test loss item: 0.19041453301906586
test loss item: 0.3781915009021759
test loss item: 0.47249093651771545
test loss item: 0.2731265127658844
test loss item: 0.2991393208503723
test loss item: 0.3833793103694916
test loss item: 0.6031829714775085
test loss item: 0.2429240345954895
test loss item: 0.1715661585330963
test loss item: 0.1906546801328659
test loss item: 0.14224794507026672
test loss item: 0.21324504911899567
test loss item: 0.5300920605659485
test loss item: 0.6109102964401245
test loss item: 0.23838183283805847
test loss item: 0.237455815076828
test loss item: 0.20286518335342407
test loss item: 0.30572667717933655
test loss item: 0.3051105737686157
test loss item: 0.23982074856758118
test loss item: 0.24700404703617096
test loss item: 0.7333677411079407
test loss item: 0.281881719827652
test loss item: 0.323552668094635
test loss item: 0.2532437741756439
test loss item: 0.38946694135665894
test loss item: 0.5930938124656677
test loss item: 0.12627960741519928
test loss item: 1.1162447929382324
test loss item: 0.2930023670196533
test loss item: 0.41839808225631714
test loss item: 0.1805458664894104
test loss item: 0.1960008293390274
test loss item: 0.21575488150119781
test loss item: 0.8007816076278687
test loss item: 0.34831586480140686
test loss item: 0.20295676589012146
test loss item: 0.12327347695827484
test loss item: 0.8743233680725098
test loss item: 0.8888064026832581
test loss item: 0.6278346180915833
test loss item: 0.22114606201648712
test loss item: 0.2312389463186264
test loss item: 0.11335611343383789
test loss item: 0.11128176003694534
test loss item: 0.1671617478132248
Epoch [2/50], Training Loss: 0.4774, Testing Loss: 0.3614
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/50
train loss item: 0.38973310589790344
train loss item: 0.962831974029541
train loss item: 0.2257280945777893
train loss item: 0.39786016941070557
train loss item: 0.3033396303653717
train loss item: 0.22412295639514923
train loss item: 0.1730143129825592
train loss item: 0.5492135882377625
train loss item: 0.16046284139156342
train loss item: 0.24987687170505524
train loss item: 0.2951280474662781
train loss item: 0.2154567539691925
train loss item: 0.11340955644845963
train loss item: 0.38544753193855286
train loss item: 0.2479952871799469
train loss item: 0.5814380645751953
train loss item: 0.06240956112742424
train loss item: 0.2345605343580246
train loss item: 0.24789609014987946
train loss item: 0.284737229347229
train loss item: 0.20858030021190643
train loss item: 0.1913047581911087
train loss item: 0.5606221556663513
train loss item: 0.6167322993278503
train loss item: 0.4534231722354889
train loss item: 0.22152921557426453
train loss item: 0.1968296319246292
train loss item: 0.23196372389793396
train loss item: 0.08845347911119461
train loss item: 0.533560574054718
train loss item: 1.6304466724395752
train loss item: 0.445546418428421
train loss item: 0.1249990239739418
train loss item: 0.28321075439453125
train loss item: 0.10605650395154953
train loss item: 1.905516505241394
train loss item: 0.48714926838874817
train loss item: 0.3565372824668884
train loss item: 0.5079442262649536
train loss item: 0.1747109591960907
train loss item: 0.19162829220294952
train loss item: 0.28207963705062866
train loss item: 0.33359429240226746
train loss item: 0.21607887744903564
train loss item: 0.7087498903274536
train loss item: 0.15903741121292114
train loss item: 0.1305241882801056
train loss item: 0.5008075833320618
train loss item: 0.2014252245426178
train loss item: 0.12284860014915466
train loss item: 0.32262328267097473
train loss item: 1.0107548236846924
train loss item: 0.06589873135089874
train loss item: 0.18449075520038605
train loss item: 1.892109990119934
train loss item: 0.16044487059116364
train loss item: 0.22927556931972504
train loss item: 0.18706855177879333
train loss item: 0.17526745796203613
train loss item: 0.09595169872045517
train loss item: 0.6438320875167847
train loss item: 1.7525357007980347
train loss item: 0.16533923149108887
train loss item: 0.326094388961792
train loss item: 0.12513422966003418
train loss item: 0.37169259786605835
train loss item: 0.3780488073825836
train loss item: 0.14991970360279083
train loss item: 0.34156277775764465
train loss item: 0.25614476203918457
train loss item: 0.22481834888458252
train loss item: 0.106841541826725
train loss item: 0.146328404545784
train loss item: 0.2284623384475708
train loss item: 0.08163304626941681
train loss item: 0.09982149302959442
train loss item: 0.4963840842247009
train loss item: 1.0956441164016724
train loss item: 0.11939243227243423
train loss item: 0.20589585602283478
train loss item: 0.18293018639087677
train loss item: 0.19615966081619263
train loss item: 0.21735478937625885
train loss item: 0.3943558931350708
train loss item: 0.3952179253101349
train loss item: 0.3338661789894104
train loss item: 3.356621503829956
train loss item: 0.13862977921962738
train loss item: 0.3322161138057709
test loss item: 0.2357233315706253
test loss item: 0.12224382162094116
test loss item: 0.3366797864437103
test loss item: 0.2022504359483719
test loss item: 0.1962735652923584
test loss item: 0.1540890485048294
test loss item: 1.5304021835327148
test loss item: 0.5346867442131042
test loss item: 0.16943030059337616
test loss item: 0.24887891113758087
test loss item: 0.5265551209449768
test loss item: 0.15484286844730377
test loss item: 0.19578316807746887
test loss item: 0.5511397123336792
test loss item: 0.14466997981071472
test loss item: 0.08225420117378235
test loss item: 0.2665351927280426
test loss item: 0.24092034995555878
test loss item: 0.5896663665771484
test loss item: 0.3382899761199951
test loss item: 0.3562913239002228
test loss item: 0.34012410044670105
test loss item: 0.39423689246177673
test loss item: 0.18663717806339264
test loss item: 0.1339767575263977
test loss item: 0.22958111763000488
test loss item: 0.30059272050857544
test loss item: 0.17733702063560486
test loss item: 0.2783944010734558
test loss item: 0.2602711617946625
test loss item: 0.5581129789352417
test loss item: 0.0803426057100296
test loss item: 0.16662649810314178
test loss item: 0.2917434871196747
test loss item: 0.2219845950603485
test loss item: 0.37289994955062866
test loss item: 0.6973702907562256
test loss item: 0.7881031036376953
test loss item: 0.2719917893409729
test loss item: 0.2544759511947632
test loss item: 0.2548745274543762
test loss item: 0.3624008595943451
test loss item: 0.2002364546060562
test loss item: 0.1782834529876709
test loss item: 0.3861173987388611
test loss item: 0.4087575078010559
test loss item: 0.384825199842453
test loss item: 0.3668269217014313
test loss item: 0.292622447013855
test loss item: 0.4744592308998108
test loss item: 0.21224838495254517
test loss item: 0.18967925012111664
test loss item: 0.17851608991622925
test loss item: 0.1377674788236618
test loss item: 0.19652384519577026
test loss item: 0.4296087324619293
test loss item: 0.4515147805213928
test loss item: 0.37149935960769653
test loss item: 0.23075100779533386
test loss item: 0.16033795475959778
test loss item: 0.23390592634677887
test loss item: 0.23445174098014832
test loss item: 0.27567893266677856
test loss item: 0.20886369049549103
test loss item: 0.5995132923126221
test loss item: 0.24867822229862213
test loss item: 0.30342820286750793
test loss item: 0.2174699902534485
test loss item: 0.28447839617729187
test loss item: 0.3809455633163452
test loss item: 0.08075584471225739
test loss item: 0.8982266783714294
test loss item: 0.45710811018943787
test loss item: 0.42396801710128784
test loss item: 0.18412521481513977
test loss item: 0.3200153708457947
test loss item: 0.18819200992584229
test loss item: 0.7700259685516357
test loss item: 0.5689490437507629
test loss item: 0.24971751868724823
test loss item: 0.0896703228354454
test loss item: 0.7487494349479675
test loss item: 0.6999984383583069
test loss item: 0.5846561193466187
test loss item: 0.26152050495147705
test loss item: 0.22341984510421753
test loss item: 0.07608854025602341
test loss item: 0.06809332221746445
test loss item: 0.22198233008384705
Epoch [3/50], Training Loss: 0.4007, Testing Loss: 0.3276
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/50
train loss item: 0.30188924074172974
train loss item: 0.7359023094177246
train loss item: 0.22139397263526917
train loss item: 0.2632397711277008
train loss item: 0.30720850825309753
train loss item: 0.20169687271118164
train loss item: 0.19678451120853424
train loss item: 0.4718441367149353
train loss item: 0.11791804432868958
train loss item: 0.18766212463378906
train loss item: 0.1974048912525177
train loss item: 0.1702798753976822
train loss item: 0.10563228279352188
train loss item: 0.3803000748157501
train loss item: 0.19350972771644592
train loss item: 0.512162983417511
train loss item: 0.07337002456188202
train loss item: 0.16044948995113373
train loss item: 0.22858047485351562
train loss item: 0.198069229722023
train loss item: 0.14832089841365814
train loss item: 0.11870917677879333
train loss item: 0.6211161017417908
train loss item: 0.5854637026786804
train loss item: 0.43456506729125977
train loss item: 0.18959490954875946
train loss item: 0.1214519739151001
train loss item: 0.1789051592350006
train loss item: 0.08676064759492874
train loss item: 0.3124096989631653
train loss item: 1.2388684749603271
train loss item: 0.6585726141929626
train loss item: 0.10945712774991989
train loss item: 0.19693715870380402
train loss item: 0.11325451731681824
train loss item: 1.7327842712402344
train loss item: 0.35835495591163635
train loss item: 0.26887279748916626
train loss item: 0.2869821786880493
train loss item: 0.20208460092544556
train loss item: 0.17955832183361053
train loss item: 0.21974436938762665
train loss item: 0.26068782806396484
train loss item: 0.15225322544574738
train loss item: 0.45804017782211304
train loss item: 0.09115089476108551
train loss item: 0.07979317009449005
train loss item: 0.30913814902305603
train loss item: 0.14546902477741241
train loss item: 0.16005277633666992
train loss item: 0.18137779831886292
train loss item: 0.5510744452476501
train loss item: 0.07234867662191391
train loss item: 0.13205961883068085
train loss item: 1.536494493484497
train loss item: 0.12552987039089203
train loss item: 0.1811203509569168
train loss item: 0.12800326943397522
train loss item: 0.12297999858856201
train loss item: 0.1280650794506073
train loss item: 0.32614782452583313
train loss item: 1.366019606590271
train loss item: 0.11132433265447617
train loss item: 0.28222042322158813
train loss item: 0.10837530344724655
train loss item: 0.3541455566883087
train loss item: 0.29666197299957275
train loss item: 0.13588641583919525
train loss item: 0.32518574595451355
train loss item: 0.20332001149654388
train loss item: 0.1714216023683548
train loss item: 0.11118603497743607
train loss item: 0.19826658070087433
train loss item: 0.1931086927652359
train loss item: 0.06407307088375092
train loss item: 0.11572521179914474
train loss item: 0.4524994492530823
train loss item: 1.0491267442703247
train loss item: 0.07417601346969604
train loss item: 0.2122175395488739
train loss item: 0.11623495817184448
train loss item: 0.19236987829208374
train loss item: 0.1460619419813156
train loss item: 0.44869324564933777
train loss item: 0.2683336138725281
train loss item: 0.21894073486328125
train loss item: 3.13515305519104
train loss item: 0.14630362391471863
train loss item: 0.22743500769138336
test loss item: 0.15796661376953125
test loss item: 0.10089419782161713
test loss item: 0.47785428166389465
test loss item: 0.18094928562641144
test loss item: 0.1842438131570816
test loss item: 0.09784842282533646
test loss item: 1.8177101612091064
test loss item: 0.7232916355133057
test loss item: 0.19340316951274872
test loss item: 0.2866206467151642
test loss item: 0.7911630868911743
test loss item: 0.12759758532047272
test loss item: 0.17946889996528625
test loss item: 0.2689952552318573
test loss item: 0.13238732516765594
test loss item: 0.09001730382442474
test loss item: 0.26892679929733276
test loss item: 0.2744421362876892
test loss item: 0.7028907537460327
test loss item: 0.28726258873939514
test loss item: 0.3994845151901245
test loss item: 0.38342878222465515
test loss item: 0.2501713037490845
test loss item: 0.1592433601617813
test loss item: 0.13999980688095093
test loss item: 0.19122138619422913
test loss item: 0.25996696949005127
test loss item: 0.13844554126262665
test loss item: 0.2523357570171356
test loss item: 0.2498805820941925
test loss item: 0.7851254940032959
test loss item: 0.07226786762475967
test loss item: 0.1312382072210312
test loss item: 0.3548513352870941
test loss item: 0.2806259095668793
test loss item: 0.3913733661174774
test loss item: 0.8282175660133362
test loss item: 1.3055803775787354
test loss item: 0.31071245670318604
test loss item: 0.24234020709991455
test loss item: 0.2712748944759369
test loss item: 0.191110298037529
test loss item: 0.22453589737415314
test loss item: 0.18877704441547394
test loss item: 0.31872156262397766
test loss item: 0.4089086353778839
test loss item: 0.23962631821632385
test loss item: 0.26535147428512573
test loss item: 0.38357260823249817
test loss item: 0.646457850933075
test loss item: 0.19099612534046173
test loss item: 0.13748601078987122
test loss item: 0.18724919855594635
test loss item: 0.12100420147180557
test loss item: 0.188573956489563
test loss item: 0.6925323009490967
test loss item: 0.5670812726020813
test loss item: 0.19244951009750366
test loss item: 0.2036101073026657
test loss item: 0.15440115332603455
test loss item: 0.2575732469558716
test loss item: 0.2717863619327545
test loss item: 0.2079562395811081
test loss item: 0.20432358980178833
test loss item: 0.8179131746292114
test loss item: 0.2387838512659073
test loss item: 0.294543594121933
test loss item: 0.22394590079784393
test loss item: 0.3617265522480011
test loss item: 0.4911554753780365
test loss item: 0.08195216208696365
test loss item: 1.078870415687561
test loss item: 0.28423675894737244
test loss item: 0.3899293839931488
test loss item: 0.15475842356681824
test loss item: 0.1698804646730423
test loss item: 0.16256949305534363
test loss item: 1.3574399948120117
test loss item: 0.3633885085582733
test loss item: 0.1577959656715393
test loss item: 0.06614798307418823
test loss item: 1.021561861038208
test loss item: 0.8716553449630737
test loss item: 0.977820634841919
test loss item: 0.19915449619293213
test loss item: 0.19512847065925598
test loss item: 0.060291629284620285
test loss item: 0.06537129729986191
test loss item: 0.13091856241226196
Epoch [4/50], Training Loss: 0.3309, Testing Loss: 0.3528
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/50
train loss item: 0.30876392126083374
train loss item: 0.798743486404419
train loss item: 0.1466309279203415
train loss item: 0.26477497816085815
train loss item: 0.2775145173072815
train loss item: 0.16874192655086517
train loss item: 0.10298900306224823
train loss item: 0.3225151598453522
train loss item: 0.09951147437095642
train loss item: 0.21607831120491028
train loss item: 0.22030004858970642
train loss item: 0.19161024689674377
train loss item: 0.09188918024301529
train loss item: 0.2958415746688843
train loss item: 0.15136849880218506
train loss item: 0.5231916308403015
train loss item: 0.0785447508096695
train loss item: 0.20142802596092224
train loss item: 0.22451381385326385
train loss item: 0.2336554080247879
train loss item: 0.16799846291542053
train loss item: 0.15681277215480804
train loss item: 0.5091790556907654
train loss item: 0.39574143290519714
train loss item: 0.3284384608268738
train loss item: 0.15654955804347992
train loss item: 0.1276269257068634
train loss item: 0.18329556286334991
train loss item: 0.062443289905786514
train loss item: 0.39322683215141296
train loss item: 1.0935899019241333
train loss item: 0.5144051313400269
train loss item: 0.11490015685558319
train loss item: 0.2486310601234436
train loss item: 0.09568172693252563
train loss item: 1.5532777309417725
train loss item: 0.47664207220077515
train loss item: 0.3295429050922394
train loss item: 0.38812682032585144
train loss item: 0.17344458401203156
train loss item: 0.1632068008184433
train loss item: 0.27988651394844055
train loss item: 0.314984530210495
train loss item: 0.19462262094020844
train loss item: 0.6323772072792053
train loss item: 0.11303577572107315
train loss item: 0.082303486764431
train loss item: 0.5407932996749878
train loss item: 0.19223493337631226
train loss item: 0.1117454469203949
train loss item: 0.41157856583595276
train loss item: 1.2437630891799927
train loss item: 0.08182712644338608
train loss item: 0.24041825532913208
train loss item: 1.5919889211654663
train loss item: 0.14515456557273865
train loss item: 0.2113550305366516
train loss item: 0.1703301966190338
train loss item: 0.15415500104427338
train loss item: 0.08222673088312149
train loss item: 0.7614142298698425
train loss item: 1.3164666891098022
train loss item: 0.13320091366767883
train loss item: 0.22600385546684265
train loss item: 0.11719205975532532
train loss item: 0.3320624530315399
train loss item: 0.2856105864048004
train loss item: 0.20074397325515747
train loss item: 0.17533966898918152
train loss item: 0.20678302645683289
train loss item: 0.1738305538892746
train loss item: 0.10046520829200745
train loss item: 0.14805422723293304
train loss item: 0.21190793812274933
train loss item: 0.07256069779396057
train loss item: 0.08601905405521393
train loss item: 0.3641852140426636
train loss item: 1.1792025566101074
train loss item: 0.11194700747728348
train loss item: 0.16881226003170013
train loss item: 0.16833685338497162
train loss item: 0.15865465998649597
train loss item: 0.2197062224149704
train loss item: 0.3866024911403656
train loss item: 0.3743588924407959
train loss item: 0.22932472825050354
train loss item: 3.02262282371521
train loss item: 0.1425369679927826
train loss item: 0.2276652753353119
test loss item: 0.15937328338623047
test loss item: 0.0998629480600357
test loss item: 0.3559282720088959
test loss item: 0.17844152450561523
test loss item: 0.17283205687999725
test loss item: 0.11006734520196915
test loss item: 1.4120233058929443
test loss item: 0.49045366048812866
test loss item: 0.16333389282226562
test loss item: 0.22650296986103058
test loss item: 0.6162997484207153
test loss item: 0.13809296488761902
test loss item: 0.15214915573596954
test loss item: 0.27502262592315674
test loss item: 0.12907588481903076
test loss item: 0.06877302378416061
test loss item: 0.2135535478591919
test loss item: 0.22157827019691467
test loss item: 0.5499988198280334
test loss item: 0.23034662008285522
test loss item: 0.28923970460891724
test loss item: 0.2975213825702667
test loss item: 0.23077905178070068
test loss item: 0.14712922275066376
test loss item: 0.11927217245101929
test loss item: 0.1891576051712036
test loss item: 0.21197251975536346
test loss item: 0.1369839906692505
test loss item: 0.2209225445985794
test loss item: 0.2076273113489151
test loss item: 0.5951418280601501
test loss item: 0.06271064281463623
test loss item: 0.13158607482910156
test loss item: 0.28677842020988464
test loss item: 0.21693436801433563
test loss item: 0.320677250623703
test loss item: 0.6509897708892822
test loss item: 0.9661182761192322
test loss item: 0.24845516681671143
test loss item: 0.20785649120807648
test loss item: 0.21866652369499207
test loss item: 0.2260182946920395
test loss item: 0.1971810907125473
test loss item: 0.16176478564739227
test loss item: 0.2534262239933014
test loss item: 0.30705830454826355
test loss item: 0.23702673614025116
test loss item: 0.21773198246955872
test loss item: 0.2789459824562073
test loss item: 0.4888911247253418
test loss item: 0.16090774536132812
test loss item: 0.12704350054264069
test loss item: 0.1597982943058014
test loss item: 0.1390191614627838
test loss item: 0.1687808483839035
test loss item: 0.5242500305175781
test loss item: 0.43118563294410706
test loss item: 0.17374102771282196
test loss item: 0.17599348723888397
test loss item: 0.1476341187953949
test loss item: 0.21779023110866547
test loss item: 0.18291792273521423
test loss item: 0.20166848599910736
test loss item: 0.1720677614212036
test loss item: 0.5892134308815002
test loss item: 0.23195570707321167
test loss item: 0.2268012911081314
test loss item: 0.19175517559051514
test loss item: 0.2847616672515869
test loss item: 0.36454102396965027
test loss item: 0.07991635799407959
test loss item: 0.7971625328063965
test loss item: 0.2709095776081085
test loss item: 0.3204149901866913
test loss item: 0.13741111755371094
test loss item: 0.19239959120750427
test loss item: 0.14652103185653687
test loss item: 0.9715666770935059
test loss item: 0.31322917342185974
test loss item: 0.16768330335617065
test loss item: 0.0706145167350769
test loss item: 0.7706530094146729
test loss item: 0.6792054772377014
test loss item: 0.7011962532997131
test loss item: 0.16419580578804016
test loss item: 0.17890922725200653
test loss item: 0.05811399221420288
test loss item: 0.048298098146915436
test loss item: 0.18673491477966309
Epoch [5/50], Training Loss: 0.3444, Testing Loss: 0.2856
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/50
train loss item: 0.2917080819606781
train loss item: 0.7164972424507141
train loss item: 0.13147953152656555
train loss item: 0.27987632155418396
train loss item: 0.2843770384788513
train loss item: 0.16761453449726105
train loss item: 0.18670527637004852
train loss item: 0.30425891280174255
train loss item: 0.07394283264875412
train loss item: 0.1759185492992401
train loss item: 0.13590191304683685
train loss item: 0.14009998738765717
train loss item: 0.10980413854122162
train loss item: 0.2860727310180664
train loss item: 0.1465505063533783
train loss item: 0.4652364253997803
train loss item: 0.07492024451494217
train loss item: 0.13807737827301025
train loss item: 0.18985773622989655
train loss item: 0.16900129616260529
train loss item: 0.13784809410572052
train loss item: 0.0889962762594223
train loss item: 0.5139876008033752
train loss item: 0.3397894501686096
train loss item: 0.33003753423690796
train loss item: 0.13210749626159668
train loss item: 0.12008575350046158
train loss item: 0.1398990899324417
train loss item: 0.06145325303077698
train loss item: 0.3475208878517151
train loss item: 0.9327907562255859
train loss item: 0.6409381628036499
train loss item: 0.09340706467628479
train loss item: 0.1679791361093521
train loss item: 0.09055642038583755
train loss item: 1.4838801622390747
train loss item: 0.32300716638565063
train loss item: 0.2521241009235382
train loss item: 0.2714345157146454
train loss item: 0.18323397636413574
train loss item: 0.166553795337677
train loss item: 0.1785275787115097
train loss item: 0.24153459072113037
train loss item: 0.1433839052915573
train loss item: 0.35480931401252747
train loss item: 0.08396313339471817
train loss item: 0.06536415964365005
train loss item: 0.2773841619491577
train loss item: 0.1251276731491089
train loss item: 0.1365462988615036
train loss item: 0.14717444777488708
train loss item: 0.624744713306427
train loss item: 0.09118638932704926
train loss item: 0.12883266806602478
train loss item: 1.2921864986419678
train loss item: 0.09209629893302917
train loss item: 0.1720963418483734
train loss item: 0.12160768359899521
train loss item: 0.08742205053567886
train loss item: 0.09876390546560287
train loss item: 0.2677594721317291
train loss item: 1.1173241138458252
train loss item: 0.1364602893590927
train loss item: 0.3317979872226715
train loss item: 0.08516701310873032
train loss item: 0.32608267664909363
train loss item: 0.36743441224098206
train loss item: 0.12936784327030182
train loss item: 0.3030230700969696
train loss item: 0.19296792149543762
train loss item: 0.14675557613372803
train loss item: 0.08043692260980606
train loss item: 0.1650424599647522
train loss item: 0.18903164565563202
train loss item: 0.06022094562649727
train loss item: 0.10737326741218567
train loss item: 0.40374940633773804
train loss item: 0.9546975493431091
train loss item: 0.061884235590696335
train loss item: 0.21071948111057281
train loss item: 0.10144209861755371
train loss item: 0.1573868989944458
train loss item: 0.15529625117778778
train loss item: 0.38876670598983765
train loss item: 0.2260516732931137
train loss item: 0.2730070650577545
train loss item: 2.808455228805542
train loss item: 0.12663443386554718
train loss item: 0.30171656608581543
test loss item: 0.16291023790836334
test loss item: 0.1316870152950287
test loss item: 0.3362586796283722
test loss item: 0.16390013694763184
test loss item: 0.17450806498527527
test loss item: 0.11724290996789932
test loss item: 1.4796808958053589
test loss item: 0.5737841725349426
test loss item: 0.17808249592781067
test loss item: 0.2403831034898758
test loss item: 0.547875165939331
test loss item: 0.13837219774723053
test loss item: 0.21409356594085693
test loss item: 0.24027550220489502
test loss item: 0.1435481458902359
test loss item: 0.11822059005498886
test loss item: 0.24261727929115295
test loss item: 0.19831304252147675
test loss item: 0.5944935083389282
test loss item: 0.31974151730537415
test loss item: 0.28238704800605774
test loss item: 0.30169665813446045
test loss item: 0.2560037076473236
test loss item: 0.16345110535621643
test loss item: 0.1258791983127594
test loss item: 0.2054007351398468
test loss item: 0.27207669615745544
test loss item: 0.14851060509681702
test loss item: 0.23286229372024536
test loss item: 0.23042412102222443
test loss item: 0.5712546110153198
test loss item: 0.09682918339967728
test loss item: 0.14571547508239746
test loss item: 0.25883856415748596
test loss item: 0.19890688359737396
test loss item: 0.39480358362197876
test loss item: 0.6646092534065247
test loss item: 0.8090161681175232
test loss item: 0.23292215168476105
test loss item: 0.22034317255020142
test loss item: 0.22941870987415314
test loss item: 0.24336983263492584
test loss item: 0.20039378106594086
test loss item: 0.1642916202545166
test loss item: 0.23945172131061554
test loss item: 0.37840455770492554
test loss item: 0.2680114805698395
test loss item: 0.36549627780914307
test loss item: 0.2880374491214752
test loss item: 0.46363934874534607
test loss item: 0.1835060566663742
test loss item: 0.19311228394508362
test loss item: 0.17013147473335266
test loss item: 0.11956838518381119
test loss item: 0.17896594107151031
test loss item: 0.44195756316185
test loss item: 0.46528106927871704
test loss item: 0.18840336799621582
test loss item: 0.1985771507024765
test loss item: 0.1844901293516159
test loss item: 0.19149208068847656
test loss item: 0.21866105496883392
test loss item: 0.22055545449256897
test loss item: 0.20588934421539307
test loss item: 0.6184965968132019
test loss item: 0.19368413090705872
test loss item: 0.2691214382648468
test loss item: 0.21284855902194977
test loss item: 0.27421262860298157
test loss item: 0.4281408190727234
test loss item: 0.11771370470523834
test loss item: 0.8910461068153381
test loss item: 0.2904866635799408
test loss item: 0.3527377247810364
test loss item: 0.18256451189517975
test loss item: 0.22044122219085693
test loss item: 0.16440220177173615
test loss item: 0.8562572002410889
test loss item: 0.3048493564128876
test loss item: 0.17089883983135223
test loss item: 0.08924304693937302
test loss item: 0.742188572883606
test loss item: 0.6790769100189209
test loss item: 0.6293515563011169
test loss item: 0.1977211982011795
test loss item: 0.21315394341945648
test loss item: 0.08538328856229782
test loss item: 0.0882125124335289
test loss item: 0.11919327825307846
Epoch [6/50], Training Loss: 0.2913, Testing Loss: 0.2980
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/50
train loss item: 0.23642845451831818
train loss item: 0.6114261746406555
train loss item: 0.11677771061658859
train loss item: 0.30851274728775024
train loss item: 0.2074654996395111
train loss item: 0.15800844132900238
train loss item: 0.13778066635131836
train loss item: 0.2566604018211365
train loss item: 0.07851286977529526
train loss item: 0.1385602504014969
train loss item: 0.18616917729377747
train loss item: 0.14761871099472046
train loss item: 0.12545357644557953
train loss item: 0.3064710795879364
train loss item: 0.10190275311470032
train loss item: 0.3700750768184662
train loss item: 0.07921835035085678
train loss item: 0.1408969759941101
train loss item: 0.1782124638557434
train loss item: 0.18238042294979095
train loss item: 0.15545529127120972
train loss item: 0.10131403803825378
train loss item: 0.34511399269104004
train loss item: 0.33312222361564636
train loss item: 0.2412489801645279
train loss item: 0.1431073695421219
train loss item: 0.07144945859909058
train loss item: 0.2087114155292511
train loss item: 0.0827544778585434
train loss item: 0.3110613226890564
train loss item: 0.992316722869873
train loss item: 0.26410606503486633
train loss item: 0.08212482184171677
train loss item: 0.1356925219297409
train loss item: 0.10399218648672104
train loss item: 1.314005970954895
train loss item: 0.48527073860168457
train loss item: 0.3418334424495697
train loss item: 0.44083473086357117
train loss item: 0.13098931312561035
train loss item: 0.14885874092578888
train loss item: 0.24474021792411804
train loss item: 0.2567680776119232
train loss item: 0.18650200963020325
train loss item: 0.6664311289787292
train loss item: 0.11030696332454681
train loss item: 0.08061691373586655
train loss item: 0.3693235218524933
train loss item: 0.20380334556102753
train loss item: 0.11517776548862457
train loss item: 0.2107396125793457
train loss item: 0.8914800882339478
train loss item: 0.07098550349473953
train loss item: 0.10645077377557755
train loss item: 1.6246569156646729
train loss item: 0.1819508820772171
train loss item: 0.22665850818157196
train loss item: 0.18103565275669098
train loss item: 0.1662583202123642
train loss item: 0.13912077248096466
train loss item: 0.3666037619113922
train loss item: 1.0293904542922974
train loss item: 0.17090129852294922
train loss item: 0.2652342915534973
train loss item: 0.09085126221179962
train loss item: 0.28558576107025146
train loss item: 0.18048377335071564
train loss item: 0.12966099381446838
train loss item: 0.3150474429130554
train loss item: 0.18686586618423462
train loss item: 0.15360203385353088
train loss item: 0.09262467175722122
train loss item: 0.16439072787761688
train loss item: 0.14909562468528748
train loss item: 0.06858280301094055
train loss item: 0.08041397482156754
train loss item: 0.2994934916496277
train loss item: 0.8260104060173035
train loss item: 0.07220504432916641
train loss item: 0.18387876451015472
train loss item: 0.10946645587682724
train loss item: 0.16744039952754974
train loss item: 0.1588444858789444
train loss item: 0.4008985459804535
train loss item: 0.30262821912765503
train loss item: 0.2772354185581207
train loss item: 2.6872615814208984
train loss item: 0.09592457115650177
train loss item: 0.24442119896411896
test loss item: 0.19728083908557892
test loss item: 0.08782434463500977
test loss item: 0.2865208387374878
test loss item: 0.18069463968276978
test loss item: 0.15201792120933533
test loss item: 0.11487402021884918
test loss item: 1.9393181800842285
test loss item: 0.633217453956604
test loss item: 0.13507890701293945
test loss item: 0.20377226173877716
test loss item: 0.46524474024772644
test loss item: 0.13970428705215454
test loss item: 0.15076982975006104
test loss item: 0.43086421489715576
test loss item: 0.11186408251523972
test loss item: 0.057719647884368896
test loss item: 0.2589209973812103
test loss item: 0.19761241972446442
test loss item: 0.6222745776176453
test loss item: 0.2935413420200348
test loss item: 0.2904277741909027
test loss item: 0.3634813129901886
test loss item: 0.3222728371620178
test loss item: 0.17449651658535004
test loss item: 0.12335861474275589
test loss item: 0.22707946598529816
test loss item: 0.252035528421402
test loss item: 0.13504719734191895
test loss item: 0.2588658630847931
test loss item: 0.2132701426744461
test loss item: 0.6695393323898315
test loss item: 0.055996134877204895
test loss item: 0.14027190208435059
test loss item: 0.236637681722641
test loss item: 0.18302561342716217
test loss item: 0.4131903648376465
test loss item: 0.7532121539115906
test loss item: 0.608383297920227
test loss item: 0.26336559653282166
test loss item: 0.2737135887145996
test loss item: 0.28324124217033386
test loss item: 0.3028049170970917
test loss item: 0.14034363627433777
test loss item: 0.20313236117362976
test loss item: 0.30835166573524475
test loss item: 0.3806639015674591
test loss item: 0.32128822803497314
test loss item: 0.29561352729797363
test loss item: 0.2665465772151947
test loss item: 0.46266064047813416
test loss item: 0.16761162877082825
test loss item: 0.1418953537940979
test loss item: 0.18194836378097534
test loss item: 0.13025358319282532
test loss item: 0.16455575823783875
test loss item: 0.3493400812149048
test loss item: 0.48989230394363403
test loss item: 0.3108590245246887
test loss item: 0.19962872564792633
test loss item: 0.12639375030994415
test loss item: 0.166263148188591
test loss item: 0.2318428009748459
test loss item: 0.25177255272865295
test loss item: 0.1970125436782837
test loss item: 0.6107296347618103
test loss item: 0.2315664291381836
test loss item: 0.2766656279563904
test loss item: 0.22740262746810913
test loss item: 0.22180667519569397
test loss item: 0.40796101093292236
test loss item: 0.05932817608118057
test loss item: 1.1007517576217651
test loss item: 0.3719383478164673
test loss item: 0.4449438750743866
test loss item: 0.14768455922603607
test loss item: 0.2649192810058594
test loss item: 0.1787884682416916
test loss item: 0.6276689767837524
test loss item: 0.4563030004501343
test loss item: 0.20541158318519592
test loss item: 0.06781718134880066
test loss item: 0.8353351950645447
test loss item: 0.78038090467453
test loss item: 0.5194879174232483
test loss item: 0.21696949005126953
test loss item: 0.19533129036426544
test loss item: 0.055366117507219315
test loss item: 0.046035587787628174
test loss item: 0.19582557678222656
Epoch [7/50], Training Loss: 0.2931, Testing Loss: 0.3083
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/50
train loss item: 0.22049765288829803
train loss item: 0.5859778523445129
train loss item: 0.16289068758487701
train loss item: 0.28753578662872314
train loss item: 0.2663949429988861
train loss item: 0.1471584588289261
train loss item: 0.10576729476451874
train loss item: 0.5483301281929016
train loss item: 0.10709960758686066
train loss item: 0.21180902421474457
train loss item: 0.28622570633888245
train loss item: 0.1461382955312729
train loss item: 0.08172829449176788
train loss item: 0.31885984539985657
train loss item: 0.13059677183628082
train loss item: 0.32261931896209717
train loss item: 0.06185338273644447
train loss item: 0.12313506752252579
train loss item: 0.30748677253723145
train loss item: 0.19046518206596375
train loss item: 0.1508050262928009
train loss item: 0.06630118191242218
train loss item: 0.4601221978664398
train loss item: 0.39790472388267517
train loss item: 0.21642182767391205
train loss item: 0.21676155924797058
train loss item: 0.0832328051328659
train loss item: 0.15331366658210754
train loss item: 0.046637196093797684
train loss item: 0.3811744749546051
train loss item: 1.3000259399414062
train loss item: 0.32662075757980347
train loss item: 0.08836961537599564
train loss item: 0.2459234893321991
train loss item: 0.08655335754156113
train loss item: 1.2566885948181152
train loss item: 0.49425458908081055
train loss item: 0.3562023937702179
train loss item: 0.5695052742958069
train loss item: 0.25854307413101196
train loss item: 0.19059772789478302
train loss item: 0.18427731096744537
train loss item: 0.2573634386062622
train loss item: 0.16950106620788574
train loss item: 0.5306909680366516
train loss item: 0.0861043855547905
train loss item: 0.06407719105482101
train loss item: 0.32005739212036133
train loss item: 0.17531944811344147
train loss item: 0.12523186206817627
train loss item: 0.15436244010925293
train loss item: 0.6811726689338684
train loss item: 0.07526696473360062
train loss item: 0.16409023106098175
train loss item: 1.3971736431121826
train loss item: 0.11955282092094421
train loss item: 0.22035211324691772
train loss item: 0.12851466238498688
train loss item: 0.12186507135629654
train loss item: 0.11547775566577911
train loss item: 0.28252390027046204
train loss item: 0.9774957299232483
train loss item: 0.16108104586601257
train loss item: 0.25798583030700684
train loss item: 0.1410081833600998
train loss item: 0.2626829743385315
train loss item: 0.1784377247095108
train loss item: 0.14775416254997253
train loss item: 0.32357245683670044
train loss item: 0.18242265284061432
train loss item: 0.15950678288936615
train loss item: 0.10883340984582901
train loss item: 0.14049790799617767
train loss item: 0.16159076988697052
train loss item: 0.059981390833854675
train loss item: 0.07945573329925537
train loss item: 0.2882903814315796
train loss item: 0.8447588682174683
train loss item: 0.06608883291482925
train loss item: 0.16093508899211884
train loss item: 0.07790642231702805
train loss item: 0.12051970511674881
train loss item: 0.17716693878173828
train loss item: 0.4557928144931793
train loss item: 0.3844212293624878
train loss item: 0.23792032897472382
train loss item: 2.5815610885620117
train loss item: 0.11406875401735306
train loss item: 0.19860254228115082
test loss item: 0.1529030203819275
test loss item: 0.09998752921819687
test loss item: 0.3464123010635376
test loss item: 0.17188185453414917
test loss item: 0.16672013700008392
test loss item: 0.11919562518596649
test loss item: 1.8083631992340088
test loss item: 0.6050646305084229
test loss item: 0.1478196680545807
test loss item: 0.2202664613723755
test loss item: 0.5395500063896179
test loss item: 0.1294899880886078
test loss item: 0.14855866134166718
test loss item: 0.27637141942977905
test loss item: 0.12128302454948425
test loss item: 0.06471636891365051
test loss item: 0.26104915142059326
test loss item: 0.2179134637117386
test loss item: 0.5916587710380554
test loss item: 0.2735198438167572
test loss item: 0.30764642357826233
test loss item: 0.36145979166030884
test loss item: 0.2519563138484955
test loss item: 0.1746942102909088
test loss item: 0.1284617930650711
test loss item: 0.22489561140537262
test loss item: 0.23965178430080414
test loss item: 0.1460568904876709
test loss item: 0.2519727647304535
test loss item: 0.21493113040924072
test loss item: 0.6745867133140564
test loss item: 0.05489293858408928
test loss item: 0.1436416208744049
test loss item: 0.25849294662475586
test loss item: 0.21590399742126465
test loss item: 0.3265584707260132
test loss item: 0.7209525108337402
test loss item: 0.8123244047164917
test loss item: 0.27471107244491577
test loss item: 0.26671749353408813
test loss item: 0.2766426205635071
test loss item: 0.215915709733963
test loss item: 0.148620143532753
test loss item: 0.20078600943088531
test loss item: 0.2628563642501831
test loss item: 0.37335315346717834
test loss item: 0.23775418102741241
test loss item: 0.25688233971595764
test loss item: 0.29321810603141785
test loss item: 0.48121342062950134
test loss item: 0.16955424845218658
test loss item: 0.14130724966526031
test loss item: 0.19413435459136963
test loss item: 0.12250674515962601
test loss item: 0.18483878672122955
test loss item: 0.45819324254989624
test loss item: 0.45825761556625366
test loss item: 0.1785736382007599
test loss item: 0.20099863409996033
test loss item: 0.1344885677099228
test loss item: 0.1794498860836029
test loss item: 0.24312566220760345
test loss item: 0.23261189460754395
test loss item: 0.19195780158042908
test loss item: 0.6664904952049255
test loss item: 0.21223555505275726
test loss item: 0.28488656878471375
test loss item: 0.22523963451385498
test loss item: 0.24930483102798462
test loss item: 0.3845141530036926
test loss item: 0.06485873460769653
test loss item: 1.0456485748291016
test loss item: 0.29792875051498413
test loss item: 0.42311912775039673
test loss item: 0.14412380754947662
test loss item: 0.19107362627983093
test loss item: 0.177922785282135
test loss item: 0.8716745972633362
test loss item: 0.3459792137145996
test loss item: 0.1741134524345398
test loss item: 0.06528681516647339
test loss item: 0.8357605934143066
test loss item: 0.7468024492263794
test loss item: 0.6508201360702515
test loss item: 0.21833279728889465
test loss item: 0.18090470135211945
test loss item: 0.052669458091259
test loss item: 0.04380989819765091
test loss item: 0.1576373279094696
Epoch [8/50], Training Loss: 0.2964, Testing Loss: 0.3041
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/50
train loss item: 0.2419966757297516
train loss item: 0.5365004539489746
train loss item: 0.11577986925840378
train loss item: 0.22616221010684967
train loss item: 0.1262909173965454
train loss item: 0.13671191036701202
train loss item: 0.0924627035856247
train loss item: 0.2431391477584839
train loss item: 0.07346247881650925
train loss item: 0.1228218600153923
train loss item: 0.1616969108581543
train loss item: 0.12617318332195282
train loss item: 0.07462260872125626
train loss item: 0.2690737247467041
train loss item: 0.10194303095340729
train loss item: 0.2740916311740875
train loss item: 0.06181475147604942
train loss item: 0.10286026448011398
train loss item: 0.17018456757068634
train loss item: 0.14918629825115204
train loss item: 0.1365470141172409
train loss item: 0.06488648056983948
train loss item: 0.4123314321041107
train loss item: 0.3102053105831146
train loss item: 0.2100813388824463
train loss item: 0.12446913123130798
train loss item: 0.07638414949178696
train loss item: 0.15282613039016724
train loss item: 0.04843476414680481
train loss item: 0.37728190422058105
train loss item: 0.9780248403549194
train loss item: 0.2992061972618103
train loss item: 0.0819917544722557
train loss item: 0.1635037660598755
train loss item: 0.09805136173963547
train loss item: 1.1838546991348267
train loss item: 0.2528859078884125
train loss item: 0.3033710718154907
train loss item: 0.34106916189193726
train loss item: 0.2065534144639969
train loss item: 0.1671988070011139
train loss item: 0.16682417690753937
train loss item: 0.23498152196407318
train loss item: 0.1546565741300583
train loss item: 0.4361913800239563
train loss item: 0.0820150077342987
train loss item: 0.05822638422250748
train loss item: 0.2520652115345001
train loss item: 0.15215513110160828
train loss item: 0.10550374537706375
train loss item: 0.13489730656147003
train loss item: 0.5191693305969238
train loss item: 0.08769318461418152
train loss item: 0.13132143020629883
train loss item: 1.0467091798782349
train loss item: 0.08898348361253738
train loss item: 0.1837337613105774
train loss item: 0.11605241894721985
train loss item: 0.10152699053287506
train loss item: 0.10121393203735352
train loss item: 0.2818751633167267
train loss item: 0.7694605588912964
train loss item: 0.10490056127309799
train loss item: 0.18371796607971191
train loss item: 0.07745184004306793
train loss item: 0.2329491674900055
train loss item: 0.192063570022583
train loss item: 0.11005941778421402
train loss item: 0.2846924960613251
train loss item: 0.13408932089805603
train loss item: 0.09559139609336853
train loss item: 0.09608405828475952
train loss item: 0.10870886594057083
train loss item: 0.12569266557693481
train loss item: 0.06682699918746948
train loss item: 0.0876355990767479
train loss item: 0.2808050215244293
train loss item: 0.7616645693778992
train loss item: 0.05041808634996414
train loss item: 0.15996120870113373
train loss item: 0.0960361510515213
train loss item: 0.09999557584524155
train loss item: 0.1317289173603058
train loss item: 0.41948845982551575
train loss item: 0.3284982442855835
train loss item: 0.22730782628059387
train loss item: 2.449130058288574
train loss item: 0.0803440734744072
train loss item: 0.17254860699176788
test loss item: 0.1281537562608719
test loss item: 0.07008583098649979
test loss item: 0.3504422605037689
test loss item: 0.15222913026809692
test loss item: 0.14800098538398743
test loss item: 0.08326750248670578
test loss item: 1.7728780508041382
test loss item: 0.6419951319694519
test loss item: 0.14041152596473694
test loss item: 0.21616187691688538
test loss item: 0.5378171801567078
test loss item: 0.1139649897813797
test loss item: 0.14937078952789307
test loss item: 0.2274664342403412
test loss item: 0.10440336167812347
test loss item: 0.05461540445685387
test loss item: 0.2461981326341629
test loss item: 0.20580041408538818
test loss item: 0.6109062433242798
test loss item: 0.2630102038383484
test loss item: 0.3521655797958374
test loss item: 0.35522887110710144
test loss item: 0.22532570362091064
test loss item: 0.15292170643806458
test loss item: 0.11887702345848083
test loss item: 0.17476460337638855
test loss item: 0.2218804657459259
test loss item: 0.11596132069826126
test loss item: 0.22602948546409607
test loss item: 0.19083958864212036
test loss item: 0.6807311773300171
test loss item: 0.052562370896339417
test loss item: 0.12099797278642654
test loss item: 0.2611100673675537
test loss item: 0.20763103663921356
test loss item: 0.3508034944534302
test loss item: 0.7244864702224731
test loss item: 0.8263524174690247
test loss item: 0.2647746801376343
test loss item: 0.24184109270572662
test loss item: 0.2555787265300751
test loss item: 0.17541426420211792
test loss item: 0.15052133798599243
test loss item: 0.18450438976287842
test loss item: 0.28200000524520874
test loss item: 0.3693874776363373
test loss item: 0.21239116787910461
test loss item: 0.24282370507717133
test loss item: 0.3060855269432068
test loss item: 0.481405109167099
test loss item: 0.1587420403957367
test loss item: 0.11907210946083069
test loss item: 0.165733203291893
test loss item: 0.10704873502254486
test loss item: 0.15151095390319824
test loss item: 0.46849989891052246
test loss item: 0.48042598366737366
test loss item: 0.1798318475484848
test loss item: 0.182612806558609
test loss item: 0.11743686348199844
test loss item: 0.15856939554214478
test loss item: 0.2485342174768448
test loss item: 0.19908221065998077
test loss item: 0.17596082389354706
test loss item: 0.6853188872337341
test loss item: 0.19337968528270721
test loss item: 0.2638535797595978
test loss item: 0.2050429880619049
test loss item: 0.2693631052970886
test loss item: 0.42760229110717773
test loss item: 0.050103042274713516
test loss item: 1.0392444133758545
test loss item: 0.2692849040031433
test loss item: 0.3972293436527252
test loss item: 0.13345177471637726
test loss item: 0.15504895150661469
test loss item: 0.15600621700286865
test loss item: 0.9218890070915222
test loss item: 0.3024044632911682
test loss item: 0.14134760200977325
test loss item: 0.049744825810194016
test loss item: 0.8350850939750671
test loss item: 0.7472962737083435
test loss item: 0.6688566207885742
test loss item: 0.17933374643325806
test loss item: 0.1641400307416916
test loss item: 0.045671164989471436
test loss item: 0.0444897897541523
test loss item: 0.1218777522444725
Epoch [9/50], Training Loss: 0.2445, Testing Loss: 0.2935
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/50
train loss item: 0.206228569149971
train loss item: 0.49478110671043396
train loss item: 0.09272352606058121
train loss item: 0.22243531048297882
train loss item: 0.19625169038772583
train loss item: 0.1521158665418625
train loss item: 0.08723419159650803
train loss item: 0.22830389440059662
train loss item: 0.07036270946264267
train loss item: 0.15169212222099304
train loss item: 0.20166665315628052
train loss item: 0.11882169544696808
train loss item: 0.0752955824136734
train loss item: 0.2862299680709839
train loss item: 0.11533485352993011
train loss item: 0.23958274722099304
train loss item: 0.052134595811367035
train loss item: 0.10304943472146988
train loss item: 0.20852430164813995
train loss item: 0.16666476428508759
train loss item: 0.13567472994327545
train loss item: 0.07476091384887695
train loss item: 0.3251969516277313
train loss item: 0.35185080766677856
train loss item: 0.19292578101158142
train loss item: 0.11453232169151306
train loss item: 0.0697084590792656
train loss item: 0.12065647542476654
train loss item: 0.05295652523636818
train loss item: 0.3482625186443329
train loss item: 0.8224490880966187
train loss item: 0.2647131383419037
train loss item: 0.06957712024450302
train loss item: 0.17017364501953125
train loss item: 0.09610757976770401
train loss item: 1.071749210357666
train loss item: 0.21929921209812164
train loss item: 0.2941388487815857
train loss item: 0.3364157974720001
train loss item: 0.20316913723945618
train loss item: 0.17039059102535248
train loss item: 0.16272228956222534
train loss item: 0.2473621964454651
train loss item: 0.14734205603599548
train loss item: 0.41640228033065796
train loss item: 0.07140637934207916
train loss item: 0.06473581492900848
train loss item: 0.3393242657184601
train loss item: 0.15014755725860596
train loss item: 0.08986348658800125
train loss item: 0.16996513307094574
train loss item: 0.5761714577674866
train loss item: 0.0812893956899643
train loss item: 0.11372409015893936
train loss item: 0.9481659531593323
train loss item: 0.11357077956199646
train loss item: 0.18908020853996277
train loss item: 0.11592675745487213
train loss item: 0.12216278165578842
train loss item: 0.10178498923778534
train loss item: 0.27420639991760254
train loss item: 0.6744824647903442
train loss item: 0.09494097530841827
train loss item: 0.19157040119171143
train loss item: 0.07117465883493423
train loss item: 0.1899111568927765
train loss item: 0.1869058459997177
train loss item: 0.1297197788953781
train loss item: 0.2826390266418457
train loss item: 0.12904393672943115
train loss item: 0.09578840434551239
train loss item: 0.09955790638923645
train loss item: 0.09066516906023026
train loss item: 0.12273485958576202
train loss item: 0.054058682173490524
train loss item: 0.07948827743530273
train loss item: 0.26590538024902344
train loss item: 0.7040834426879883
train loss item: 0.04554302617907524
train loss item: 0.14806164801120758
train loss item: 0.08231613039970398
train loss item: 0.08518297970294952
train loss item: 0.11977273225784302
train loss item: 0.3733292818069458
train loss item: 0.29767459630966187
train loss item: 0.2957868278026581
train loss item: 2.383212089538574
train loss item: 0.08736629039049149
train loss item: 0.13981851935386658
test loss item: 0.13108763098716736
test loss item: 0.06826060265302658
test loss item: 0.3537612557411194
test loss item: 0.15740330517292023
test loss item: 0.14192791283130646
test loss item: 0.08342359215021133
test loss item: 1.8209093809127808
test loss item: 0.6312081813812256
test loss item: 0.14016346633434296
test loss item: 0.2143571525812149
test loss item: 0.5488119125366211
test loss item: 0.11733125895261765
test loss item: 0.1368931382894516
test loss item: 0.2623635232448578
test loss item: 0.10233656316995621
test loss item: 0.05276860296726227
test loss item: 0.2529563307762146
test loss item: 0.19742818176746368
test loss item: 0.5958837866783142
test loss item: 0.2619989514350891
test loss item: 0.3286401927471161
test loss item: 0.36382758617401123
test loss item: 0.22763603925704956
test loss item: 0.15531089901924133
test loss item: 0.12307708710432053
test loss item: 0.18310250341892242
test loss item: 0.22539550065994263
test loss item: 0.11221995949745178
test loss item: 0.23643836379051208
test loss item: 0.192268505692482
test loss item: 0.6980499029159546
test loss item: 0.0470288023352623
test loss item: 0.11990389972925186
test loss item: 0.26162412762641907
test loss item: 0.204112708568573
test loss item: 0.33779284358024597
test loss item: 0.7231641411781311
test loss item: 0.8478413820266724
test loss item: 0.27174440026283264
test loss item: 0.253848135471344
test loss item: 0.269727885723114
test loss item: 0.17896434664726257
test loss item: 0.14249539375305176
test loss item: 0.19547642767429352
test loss item: 0.27491769194602966
test loss item: 0.372214674949646
test loss item: 0.2094932645559311
test loss item: 0.22590412199497223
test loss item: 0.3028523623943329
test loss item: 0.48482394218444824
test loss item: 0.15526306629180908
test loss item: 0.10295826196670532
test loss item: 0.1717471480369568
test loss item: 0.11384014785289764
test loss item: 0.14718890190124512
test loss item: 0.4711464047431946
test loss item: 0.4707070589065552
test loss item: 0.18038588762283325
test loss item: 0.18188582360744476
test loss item: 0.10888805985450745
test loss item: 0.16507293283939362
test loss item: 0.2471906691789627
test loss item: 0.20112986862659454
test loss item: 0.18063268065452576
test loss item: 0.6802865862846375
test loss item: 0.20306891202926636
test loss item: 0.26739612221717834
test loss item: 0.21373941004276276
test loss item: 0.26238396763801575
test loss item: 0.3937948942184448
test loss item: 0.054097019135951996
test loss item: 1.0534484386444092
test loss item: 0.2801845371723175
test loss item: 0.4163300693035126
test loss item: 0.1286054402589798
test loss item: 0.15616698563098907
test loss item: 0.16017486155033112
test loss item: 0.9332191944122314
test loss item: 0.3284926414489746
test loss item: 0.14207378029823303
test loss item: 0.05073152482509613
test loss item: 0.8453572988510132
test loss item: 0.7547177672386169
test loss item: 0.6779764294624329
test loss item: 0.18743665516376495
test loss item: 0.16887277364730835
test loss item: 0.045090507715940475
test loss item: 0.042304787784814835
test loss item: 0.14459529519081116
Epoch [10/50], Training Loss: 0.2358, Testing Loss: 0.2958
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 11/50
train loss item: 0.21263597905635834
train loss item: 0.5121203064918518
train loss item: 0.1083182692527771
train loss item: 0.20309093594551086
train loss item: 0.12274979799985886
train loss item: 0.14424565434455872
train loss item: 0.09393052011728287
train loss item: 0.20281824469566345
train loss item: 0.05341019108891487
train loss item: 0.11676721274852753
train loss item: 0.16775822639465332
train loss item: 0.11330010741949081
train loss item: 0.06661110371351242
train loss item: 0.2827741205692291
train loss item: 0.10497891157865524
train loss item: 0.26420435309410095
train loss item: 0.044715095311403275
train loss item: 0.10468612611293793
train loss item: 0.12352808564901352
train loss item: 0.14481136202812195
train loss item: 0.13694719970226288
train loss item: 0.06607052683830261
train loss item: 0.2887785732746124
train loss item: 0.2540797293186188
train loss item: 0.19809739291667938
train loss item: 0.14391963183879852
train loss item: 0.07822918891906738
train loss item: 0.09191678464412689
train loss item: 0.04118559882044792
train loss item: 0.3154025673866272
train loss item: 0.7878845930099487
train loss item: 0.2433708757162094
train loss item: 0.07240711152553558
train loss item: 0.1545579582452774
train loss item: 0.07662185281515121
train loss item: 0.9719760417938232
train loss item: 0.2305735945701599
train loss item: 0.264175146818161
train loss item: 0.3154183626174927
train loss item: 0.15996922552585602
train loss item: 0.1987714022397995
train loss item: 0.1928189992904663
train loss item: 0.293905645608902
train loss item: 0.19919320940971375
train loss item: 0.4123716354370117
train loss item: 0.07290066033601761
train loss item: 0.0910959392786026
train loss item: 0.4687874913215637
train loss item: 0.17943790555000305
train loss item: 0.10325879603624344
train loss item: 0.27923229336738586
train loss item: 0.7811842560768127
train loss item: 0.0803903341293335
train loss item: 0.14225558936595917
train loss item: 0.9346196055412292
train loss item: 0.1304534524679184
train loss item: 0.19010378420352936
train loss item: 0.1417733132839203
train loss item: 0.10440955311059952
train loss item: 0.09681246429681778
train loss item: 0.25924158096313477
train loss item: 0.5776193737983704
train loss item: 0.11964220553636551
train loss item: 0.19337281584739685
train loss item: 0.09711579978466034
train loss item: 0.4306049644947052
train loss item: 0.1843077838420868
train loss item: 0.11374912410974503
train loss item: 0.26375341415405273
train loss item: 0.1474398374557495
train loss item: 0.1353817880153656
train loss item: 0.10540414601564407
train loss item: 0.11677287518978119
train loss item: 0.16178260743618011
train loss item: 0.05227043479681015
train loss item: 0.06687988340854645
train loss item: 0.24496068060398102
train loss item: 0.8337935209274292
train loss item: 0.054546602070331573
train loss item: 0.14301304519176483
train loss item: 0.10193595290184021
train loss item: 0.15389245748519897
train loss item: 0.12318271398544312
train loss item: 0.5807610750198364
train loss item: 0.3266814351081848
train loss item: 0.39892488718032837
train loss item: 2.1515891551971436
train loss item: 0.11691462248563766
train loss item: 0.2006549835205078
test loss item: 0.1457493007183075
test loss item: 0.10759910941123962
test loss item: 0.6390538215637207
test loss item: 0.1703810691833496
test loss item: 0.2395026534795761
test loss item: 0.11400911211967468
test loss item: 2.0388972759246826
test loss item: 0.6638120412826538
test loss item: 0.23522602021694183
test loss item: 0.3596581816673279
test loss item: 0.9230725765228271
test loss item: 0.13550026714801788
test loss item: 0.1720253974199295
test loss item: 0.2603509724140167
test loss item: 0.166624054312706
test loss item: 0.07225856184959412
test loss item: 0.26371529698371887
test loss item: 0.4032561779022217
test loss item: 0.6488907933235168
test loss item: 0.2766711711883545
test loss item: 0.6647763848304749
test loss item: 0.38429147005081177
test loss item: 0.29973486065864563
test loss item: 0.17632390558719635
test loss item: 0.16948267817497253
test loss item: 0.19750964641571045
test loss item: 0.279826283454895
test loss item: 0.17690922319889069
test loss item: 0.3120010197162628
test loss item: 0.2701711058616638
test loss item: 0.9379291534423828
test loss item: 0.06633785367012024
test loss item: 0.1408442109823227
test loss item: 0.48494061827659607
test loss item: 0.41299229860305786
test loss item: 0.3850891888141632
test loss item: 0.8138962984085083
test loss item: 1.5975263118743896
test loss item: 0.4376817047595978
test loss item: 0.28161197900772095
test loss item: 0.2857089638710022
test loss item: 0.18350853025913239
test loss item: 0.29377833008766174
test loss item: 0.20319364964962006
test loss item: 0.5151960253715515
test loss item: 0.3960404098033905
test loss item: 0.2723522186279297
test loss item: 0.21420814096927643
test loss item: 0.4771449863910675
test loss item: 0.7140097618103027
test loss item: 0.28776586055755615
test loss item: 0.10184413939714432
test loss item: 0.22224107384681702
test loss item: 0.12429890781641006
test loss item: 0.2768399715423584
test loss item: 0.90592360496521
test loss item: 0.5577138662338257
test loss item: 0.23642928898334503
test loss item: 0.21238307654857635
test loss item: 0.1838378608226776
test loss item: 0.36513641476631165
test loss item: 0.2564018666744232
test loss item: 0.20852869749069214
test loss item: 0.21404238045215607
test loss item: 1.0197606086730957
test loss item: 0.21275287866592407
test loss item: 0.3068534731864929
test loss item: 0.2369641810655594
test loss item: 0.47739776968955994
test loss item: 0.44858095049858093
test loss item: 0.0737990215420723
test loss item: 1.1547765731811523
test loss item: 0.33042922616004944
test loss item: 0.44122302532196045
test loss item: 0.13493172824382782
test loss item: 0.17193196713924408
test loss item: 0.18286773562431335
test loss item: 1.7389274835586548
test loss item: 0.42731887102127075
test loss item: 0.17458336055278778
test loss item: 0.0644616037607193
test loss item: 1.1402785778045654
test loss item: 0.9163548350334167
test loss item: 1.2112048864364624
test loss item: 0.21908313035964966
test loss item: 0.18672744929790497
test loss item: 0.05799488723278046
test loss item: 0.05661090463399887
test loss item: 0.11930709332227707
Epoch [11/50], Training Loss: 0.2430, Testing Loss: 0.4016
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 12/50
train loss item: 0.3369159400463104
train loss item: 0.8973458409309387
train loss item: 0.14532291889190674
train loss item: 0.3746832609176636
train loss item: 0.1679268330335617
train loss item: 0.15389440953731537
train loss item: 0.11417913436889648
train loss item: 0.5163671374320984
train loss item: 0.14347410202026367
train loss item: 0.2709548771381378
train loss item: 0.40105828642845154
train loss item: 0.16201260685920715
train loss item: 0.07928168773651123
train loss item: 0.27845534682273865
train loss item: 0.12709230184555054
train loss item: 0.30009910464286804
train loss item: 0.06252552568912506
train loss item: 0.1258075088262558
train loss item: 0.22254841029644012
train loss item: 0.12650029361248016
train loss item: 0.11573778092861176
train loss item: 0.09656839817762375
train loss item: 0.32113710045814514
train loss item: 0.5637792944908142
train loss item: 0.23215503990650177
train loss item: 0.15586526691913605
train loss item: 0.09546525776386261
train loss item: 0.1255180984735489
train loss item: 0.0830058678984642
train loss item: 0.3610224425792694
train loss item: 0.6823268532752991
train loss item: 0.30937400460243225
train loss item: 0.07823609560728073
train loss item: 0.18129831552505493
train loss item: 0.13777819275856018
train loss item: 0.9499320387840271
train loss item: 0.23575767874717712
train loss item: 0.2362300455570221
train loss item: 0.2637382745742798
train loss item: 0.1118226870894432
train loss item: 0.0987260565161705
train loss item: 0.16879914700984955
train loss item: 0.21679846942424774
train loss item: 0.14482378959655762
train loss item: 0.366876482963562
train loss item: 0.08441051840782166
train loss item: 0.06557741016149521
train loss item: 0.2601793110370636
train loss item: 0.12072160840034485
train loss item: 0.10058260709047318
train loss item: 0.15520142018795013
train loss item: 0.6042941212654114
train loss item: 0.06897511333227158
train loss item: 0.08855026960372925
train loss item: 0.826399564743042
train loss item: 0.07869221270084381
train loss item: 0.12992875277996063
train loss item: 0.12056334316730499
train loss item: 0.08470859378576279
train loss item: 0.08822444826364517
train loss item: 0.2821686863899231
train loss item: 0.5823673605918884
train loss item: 0.10548245906829834
train loss item: 0.19907425343990326
train loss item: 0.09084581583738327
train loss item: 0.3613039255142212
train loss item: 0.18778327107429504
train loss item: 0.1537594497203827
train loss item: 0.24396221339702606
train loss item: 0.1394142359495163
train loss item: 0.10606225579977036
train loss item: 0.07448725402355194
train loss item: 0.08244312554597855
train loss item: 0.17037931084632874
train loss item: 0.059878673404455185
train loss item: 0.08187519013881683
train loss item: 0.21989980340003967
train loss item: 1.0093728303909302
train loss item: 0.0452331006526947
train loss item: 0.14428307116031647
train loss item: 0.07925768941640854
train loss item: 0.08786574751138687
train loss item: 0.11674920469522476
train loss item: 0.5052424073219299
train loss item: 0.27298516035079956
train loss item: 0.20645642280578613
train loss item: 2.0211002826690674
train loss item: 0.06953809410333633
train loss item: 0.16073447465896606
test loss item: 0.1299131065607071
test loss item: 0.07732722908258438
test loss item: 0.45633959770202637
test loss item: 0.15329299867153168
test loss item: 0.16756142675876617
test loss item: 0.09435337036848068
test loss item: 1.627776026725769
test loss item: 0.48978519439697266
test loss item: 0.1630641371011734
test loss item: 0.24454568326473236
test loss item: 0.6801672577857971
test loss item: 0.11459793150424957
test loss item: 0.14343155920505524
test loss item: 0.22579994797706604
test loss item: 0.1195954754948616
test loss item: 0.0539344847202301
test loss item: 0.22553513944149017
test loss item: 0.26013028621673584
test loss item: 0.5099751353263855
test loss item: 0.23697121441364288
test loss item: 0.4168517291545868
test loss item: 0.31029418110847473
test loss item: 0.23300586640834808
test loss item: 0.14941199123859406
test loss item: 0.1265784502029419
test loss item: 0.18282029032707214
test loss item: 0.2191699892282486
test loss item: 0.12321919947862625
test loss item: 0.22847728431224823
test loss item: 0.20277705788612366
test loss item: 0.7106884717941284
test loss item: 0.04528915509581566
test loss item: 0.12275848537683487
test loss item: 0.3347338140010834
test loss item: 0.2776491641998291
test loss item: 0.27426639199256897
test loss item: 0.6342920064926147
test loss item: 1.1415517330169678
test loss item: 0.308248370885849
test loss item: 0.2306385636329651
test loss item: 0.2429814487695694
test loss item: 0.1900930255651474
test loss item: 0.1856892704963684
test loss item: 0.17489346861839294
test loss item: 0.32346391677856445
test loss item: 0.3237870931625366
test loss item: 0.2180178463459015
test loss item: 0.21575792133808136
test loss item: 0.33478057384490967
test loss item: 0.5146995186805725
test loss item: 0.17469654977321625
test loss item: 0.1191781535744667
test loss item: 0.17038413882255554
test loss item: 0.1098870038986206
test loss item: 0.18474578857421875
test loss item: 0.6340591311454773
test loss item: 0.4183190166950226
test loss item: 0.16777640581130981
test loss item: 0.17770697176456451
test loss item: 0.12429369986057281
test loss item: 0.2262038141489029
test loss item: 0.20259404182434082
test loss item: 0.19312924146652222
test loss item: 0.16912434995174408
test loss item: 0.7533867359161377
test loss item: 0.19387726485729218
test loss item: 0.2536012828350067
test loss item: 0.19641193747520447
test loss item: 0.3404681086540222
test loss item: 0.32676810026168823
test loss item: 0.05756640061736107
test loss item: 0.9054065942764282
test loss item: 0.26167115569114685
test loss item: 0.3660774827003479
test loss item: 0.1284051388502121
test loss item: 0.1625063121318817
test loss item: 0.15182606875896454
test loss item: 1.2603884935379028
test loss item: 0.34783095121383667
test loss item: 0.14649778604507446
test loss item: 0.062067724764347076
test loss item: 0.8551487922668457
test loss item: 0.692622721195221
test loss item: 0.8712504506111145
test loss item: 0.18147927522659302
test loss item: 0.1629476547241211
test loss item: 0.04951920360326767
test loss item: 0.03939785435795784
test loss item: 0.15804843604564667
Epoch [12/50], Training Loss: 0.2480, Testing Loss: 0.3053
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 13/50
train loss item: 0.18581971526145935
train loss item: 0.32269421219825745
train loss item: 0.09889144450426102
train loss item: 0.20571814477443695
train loss item: 0.15680259466171265
train loss item: 0.11995875090360641
train loss item: 0.06879294663667679
train loss item: 0.18695057928562164
train loss item: 0.06258952617645264
train loss item: 0.10682964324951172
train loss item: 0.1145019680261612
train loss item: 0.1096557080745697
train loss item: 0.08873774111270905
train loss item: 0.2583290636539459
train loss item: 0.10256818681955338
train loss item: 0.3159264326095581
train loss item: 0.04664619639515877
train loss item: 0.08531004190444946
train loss item: 0.13120368123054504
train loss item: 0.15801389515399933
train loss item: 0.07211940735578537
train loss item: 0.059631798416376114
train loss item: 0.37057164311408997
train loss item: 0.4672548174858093
train loss item: 0.21528960764408112
train loss item: 0.13287796080112457
train loss item: 0.0767800584435463
train loss item: 0.09801900386810303
train loss item: 0.04180300235748291
train loss item: 0.31703245639801025
train loss item: 0.7013304829597473
train loss item: 0.24123390018939972
train loss item: 0.07040467858314514
train loss item: 0.1394529938697815
train loss item: 0.09578806161880493
train loss item: 0.8510229587554932
train loss item: 0.2577570676803589
train loss item: 0.2495458871126175
train loss item: 0.43825241923332214
train loss item: 0.20330490171909332
train loss item: 0.11294660717248917
train loss item: 0.13362695276737213
train loss item: 0.2045673131942749
train loss item: 0.13589395582675934
train loss item: 0.389672189950943
train loss item: 0.07867415994405746
train loss item: 0.063569076359272
train loss item: 0.2779868543148041
train loss item: 0.12988057732582092
train loss item: 0.08067053556442261
train loss item: 0.15391921997070312
train loss item: 0.4653211832046509
train loss item: 0.06752881407737732
train loss item: 0.11646902561187744
train loss item: 0.7918145656585693
train loss item: 0.07678475230932236
train loss item: 0.1413162350654602
train loss item: 0.10843607038259506
train loss item: 0.08626099675893784
train loss item: 0.08909531682729721
train loss item: 0.24999761581420898
train loss item: 0.505868136882782
train loss item: 0.11806695908308029
train loss item: 0.18083544075489044
train loss item: 0.07949894666671753
train loss item: 0.19213350117206573
train loss item: 0.14267778396606445
train loss item: 0.11723233759403229
train loss item: 0.2357175499200821
train loss item: 0.11534593999385834
train loss item: 0.09033478051424026
train loss item: 0.09116782248020172
train loss item: 0.0965796411037445
train loss item: 0.12244849652051926
train loss item: 0.0592980794608593
train loss item: 0.0641174390912056
train loss item: 0.22606408596038818
train loss item: 0.8029623031616211
train loss item: 0.04949941858649254
train loss item: 0.10947045683860779
train loss item: 0.06140121445059776
train loss item: 0.09947189688682556
train loss item: 0.13952748477458954
train loss item: 0.4225080609321594
train loss item: 0.3044416606426239
train loss item: 0.27781984210014343
train loss item: 1.9796521663665771
train loss item: 0.09472798556089401
train loss item: 0.13267339766025543
test loss item: 0.15677978098392487
test loss item: 0.06960944831371307
test loss item: 0.4180431067943573
test loss item: 0.16623911261558533
test loss item: 0.1557881385087967
test loss item: 0.10005689412355423
test loss item: 1.6091655492782593
test loss item: 0.5360268354415894
test loss item: 0.1536010503768921
test loss item: 0.23727211356163025
test loss item: 0.605448842048645
test loss item: 0.12064462900161743
test loss item: 0.16264639794826508
test loss item: 0.31056827306747437
test loss item: 0.11102723330259323
test loss item: 0.05026300996541977
test loss item: 0.2601909935474396
test loss item: 0.24082109332084656
test loss item: 0.5294787287712097
test loss item: 0.28694745898246765
test loss item: 0.3856079578399658
test loss item: 0.33616623282432556
test loss item: 0.2647886574268341
test loss item: 0.16432088613510132
test loss item: 0.13785803318023682
test loss item: 0.19384479522705078
test loss item: 0.24638329446315765
test loss item: 0.12446676194667816
test loss item: 0.23757478594779968
test loss item: 0.22133129835128784
test loss item: 0.6660335659980774
test loss item: 0.05019904673099518
test loss item: 0.1368875950574875
test loss item: 0.30153435468673706
test loss item: 0.25058987736701965
test loss item: 0.3072667717933655
test loss item: 0.6543126106262207
test loss item: 1.0000905990600586
test loss item: 0.29281219840049744
test loss item: 0.24164432287216187
test loss item: 0.26078200340270996
test loss item: 0.23554305732250214
test loss item: 0.16264967620372772
test loss item: 0.1944500058889389
test loss item: 0.32374945282936096
test loss item: 0.37772634625434875
test loss item: 0.2618291974067688
test loss item: 0.2851003110408783
test loss item: 0.3255879878997803
test loss item: 0.47512006759643555
test loss item: 0.16592897474765778
test loss item: 0.157791867852211
test loss item: 0.18044020235538483
test loss item: 0.12659375369548798
test loss item: 0.17263509333133698
test loss item: 0.5525190234184265
test loss item: 0.43319714069366455
test loss item: 0.2058248519897461
test loss item: 0.20095252990722656
test loss item: 0.11365282535552979
test loss item: 0.1953948736190796
test loss item: 0.23684698343276978
test loss item: 0.22583812475204468
test loss item: 0.1759578436613083
test loss item: 0.7139058709144592
test loss item: 0.207880437374115
test loss item: 0.2799359858036041
test loss item: 0.20488408207893372
test loss item: 0.309048593044281
test loss item: 0.33737078309059143
test loss item: 0.04775382950901985
test loss item: 0.92629075050354
test loss item: 0.3235366642475128
test loss item: 0.40090855956077576
test loss item: 0.15961210429668427
test loss item: 0.2081684023141861
test loss item: 0.16240626573562622
test loss item: 1.1264221668243408
test loss item: 0.3963126242160797
test loss item: 0.1699056774377823
test loss item: 0.05933724716305733
test loss item: 0.8219209909439087
test loss item: 0.6878991723060608
test loss item: 0.7885838747024536
test loss item: 0.1968638151884079
test loss item: 0.19709788262844086
test loss item: 0.05941806733608246
test loss item: 0.055264391005039215
test loss item: 0.15233993530273438
Epoch [13/50], Training Loss: 0.2123, Testing Loss: 0.3094
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 14/50
train loss item: 0.17540530860424042
train loss item: 0.5622621774673462
train loss item: 0.09796924889087677
train loss item: 0.23161934316158295
train loss item: 0.10624895244836807
train loss item: 0.13810265064239502
train loss item: 0.0755564272403717
train loss item: 0.22297008335590363
train loss item: 0.05453519895672798
train loss item: 0.1020900085568428
train loss item: 0.13419994711875916
train loss item: 0.11697882413864136
train loss item: 0.061697058379650116
train loss item: 0.23747920989990234
train loss item: 0.08397655934095383
train loss item: 0.3415820598602295
train loss item: 0.04528744891285896
train loss item: 0.11157649010419846
train loss item: 0.14815768599510193
train loss item: 0.16574901342391968
train loss item: 0.11608828604221344
train loss item: 0.07002557069063187
train loss item: 0.4560035765171051
train loss item: 0.22844822704792023
train loss item: 0.20201656222343445
train loss item: 0.11633643507957458
train loss item: 0.06700644642114639
train loss item: 0.07496707886457443
train loss item: 0.03707646578550339
train loss item: 0.28784820437431335
train loss item: 0.6788228750228882
train loss item: 0.24608033895492554
train loss item: 0.05685477703809738
train loss item: 0.15013273060321808
train loss item: 0.08522766083478928
train loss item: 0.7631323933601379
train loss item: 0.20031516253948212
train loss item: 0.28014901280403137
train loss item: 0.28032445907592773
train loss item: 0.17417192459106445
train loss item: 0.16252101957798004
train loss item: 0.17166125774383545
train loss item: 0.2391941249370575
train loss item: 0.1730841100215912
train loss item: 0.2843415141105652
train loss item: 0.06943291425704956
train loss item: 0.06022780388593674
train loss item: 0.34018734097480774
train loss item: 0.15601029992103577
train loss item: 0.0994257852435112
train loss item: 0.18856625258922577
train loss item: 0.42991533875465393
train loss item: 0.07635471969842911
train loss item: 0.1550244837999344
train loss item: 0.6594140529632568
train loss item: 0.10568294674158096
train loss item: 0.1470322608947754
train loss item: 0.10145425796508789
train loss item: 0.09993980824947357
train loss item: 0.08437245339155197
train loss item: 0.3495241105556488
train loss item: 0.4717610478401184
train loss item: 0.08172499388456345
train loss item: 0.17524848878383636
train loss item: 0.07830671221017838
train loss item: 0.26224619150161743
train loss item: 0.17643731832504272
train loss item: 0.1516214907169342
train loss item: 0.2400367558002472
train loss item: 0.13257348537445068
train loss item: 0.11096557229757309
train loss item: 0.07637607306241989
train loss item: 0.09821466356515884
train loss item: 0.13106723129749298
train loss item: 0.05591060221195221
train loss item: 0.07228397578001022
train loss item: 0.22720733284950256
train loss item: 0.7566789984703064
train loss item: 0.04896397888660431
train loss item: 0.137783020734787
train loss item: 0.08863963931798935
train loss item: 0.10511662065982819
train loss item: 0.11771475523710251
train loss item: 0.36392274498939514
train loss item: 0.2185547947883606
train loss item: 0.36193838715553284
train loss item: 1.8498138189315796
train loss item: 0.08705256134271622
train loss item: 0.12018638104200363
test loss item: 0.11746461689472198
test loss item: 0.08636346459388733
test loss item: 0.5794714093208313
test loss item: 0.14445005357265472
test loss item: 0.21344155073165894
test loss item: 0.09271546453237534
test loss item: 1.7253538370132446
test loss item: 0.5678208470344543
test loss item: 0.20242621004581451
test loss item: 0.312836229801178
test loss item: 0.8297480940818787
test loss item: 0.12031185626983643
test loss item: 0.157122403383255
test loss item: 0.21217559278011322
test loss item: 0.14748845994472504
test loss item: 0.05977283790707588
test loss item: 0.23023751378059387
test loss item: 0.36068105697631836
test loss item: 0.5538947582244873
test loss item: 0.24028830230236053
test loss item: 0.603883683681488
test loss item: 0.3281324803829193
test loss item: 0.2602267861366272
test loss item: 0.15092188119888306
test loss item: 0.15131965279579163
test loss item: 0.1734263002872467
test loss item: 0.2342565804719925
test loss item: 0.15096478164196014
test loss item: 0.2668987810611725
test loss item: 0.23386457562446594
test loss item: 0.8230060338973999
test loss item: 0.05588322505354881
test loss item: 0.12048517167568207
test loss item: 0.4408573806285858
test loss item: 0.3702126145362854
test loss item: 0.328309029340744
test loss item: 0.6992154717445374
test loss item: 1.4486221075057983
test loss item: 0.38633304834365845
test loss item: 0.23697318136692047
test loss item: 0.24491514265537262
test loss item: 0.15347827970981598
test loss item: 0.2662445902824402
test loss item: 0.17485813796520233
test loss item: 0.4608733057975769
test loss item: 0.3374772071838379
test loss item: 0.23117589950561523
test loss item: 0.18924912810325623
test loss item: 0.4263530969619751
test loss item: 0.611354649066925
test loss item: 0.25014162063598633
test loss item: 0.09578821063041687
test loss item: 0.1922367960214615
test loss item: 0.10672285407781601
test loss item: 0.245163694024086
test loss item: 0.8124287724494934
test loss item: 0.4926261007785797
test loss item: 0.1952344924211502
test loss item: 0.18985818326473236
test loss item: 0.16117572784423828
test loss item: 0.3201977014541626
test loss item: 0.21948249638080597
test loss item: 0.18348188698291779
test loss item: 0.18112556636333466
test loss item: 0.9112957715988159
test loss item: 0.18231599032878876
test loss item: 0.26676371693611145
test loss item: 0.20412901043891907
test loss item: 0.43929430842399597
test loss item: 0.3814271092414856
test loss item: 0.07272832840681076
test loss item: 0.9657779335975647
test loss item: 0.2881140410900116
test loss item: 0.3754717707633972
test loss item: 0.12350244075059891
test loss item: 0.13911934196949005
test loss item: 0.15515410900115967
test loss item: 1.6075843572616577
test loss item: 0.37754014134407043
test loss item: 0.14470821619033813
test loss item: 0.06235029175877571
test loss item: 1.0018726587295532
test loss item: 0.7830324172973633
test loss item: 1.1020811796188354
test loss item: 0.18846125900745392
test loss item: 0.16563014686107635
test loss item: 0.047313109040260315
test loss item: 0.045260246843099594
test loss item: 0.11154487729072571
Epoch [14/50], Training Loss: 0.2105, Testing Loss: 0.3517
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 15/50
train loss item: 0.19193392992019653
train loss item: 0.5216715335845947
train loss item: 0.11166802048683167
train loss item: 0.2071392834186554
train loss item: 0.15884622931480408
train loss item: 0.1351694017648697
train loss item: 0.09137404710054398
train loss item: 0.5881514549255371
train loss item: 0.08639159798622131
train loss item: 0.15673404932022095
train loss item: 0.2135341614484787
train loss item: 0.1060415729880333
train loss item: 0.09921980649232864
train loss item: 0.283218115568161
train loss item: 0.1341715008020401
train loss item: 0.25924739241600037
train loss item: 0.04939786344766617
train loss item: 0.0888596624135971
train loss item: 0.22976897656917572
train loss item: 0.11971818655729294
train loss item: 0.10750740021467209
train loss item: 0.10611727088689804
train loss item: 0.2323426604270935
train loss item: 0.49643030762672424
train loss item: 0.20912228524684906
train loss item: 0.15336287021636963
train loss item: 0.08502378314733505
train loss item: 0.11386077105998993
train loss item: 0.07268127799034119
train loss item: 0.21422240138053894
train loss item: 0.29662254452705383
train loss item: 0.3231997489929199
train loss item: 0.07489785552024841
train loss item: 0.1618475764989853
train loss item: 0.14453493058681488
train loss item: 0.7583467960357666
train loss item: 0.2999447286128998
train loss item: 0.26818832755088806
train loss item: 0.24971891939640045
train loss item: 0.10583176463842392
train loss item: 0.08863194286823273
train loss item: 0.14472417533397675
train loss item: 0.21682554483413696
train loss item: 0.1398964822292328
train loss item: 0.2979702949523926
train loss item: 0.07452433556318283
train loss item: 0.08419676125049591
train loss item: 0.3610650897026062
train loss item: 0.12897667288780212
train loss item: 0.07904747128486633
train loss item: 0.2344786822795868
train loss item: 0.6128124594688416
train loss item: 0.08019988983869553
train loss item: 0.10686077922582626
train loss item: 0.6153455972671509
train loss item: 0.09588324278593063
train loss item: 0.1532706469297409
train loss item: 0.11505896598100662
train loss item: 0.09258662909269333
train loss item: 0.08095231652259827
train loss item: 0.19616052508354187
train loss item: 0.39800840616226196
train loss item: 0.08288996666669846
train loss item: 0.18025949597358704
train loss item: 0.08489544689655304
train loss item: 0.2701391875743866
train loss item: 0.13118374347686768
train loss item: 0.1111956536769867
train loss item: 0.15115584433078766
train loss item: 0.1165817528963089
train loss item: 0.11128006875514984
train loss item: 0.06969726085662842
train loss item: 0.10285484045743942
train loss item: 0.14330419898033142
train loss item: 0.04688118025660515
train loss item: 0.06564690172672272
train loss item: 0.2585957646369934
train loss item: 0.9009904265403748
train loss item: 0.04105572775006294
train loss item: 0.12481535226106644
train loss item: 0.06571365147829056
train loss item: 0.0800449401140213
train loss item: 0.10750224441289902
train loss item: 0.46809908747673035
train loss item: 0.24005314707756042
train loss item: 0.3040081560611725
train loss item: 1.7363221645355225
train loss item: 0.06437903642654419
train loss item: 0.15206725895404816
test loss item: 0.10241414606571198
test loss item: 0.07358820736408234
test loss item: 0.5639832615852356
test loss item: 0.13631229102611542
test loss item: 0.20205770432949066
test loss item: 0.0837562084197998
test loss item: 1.4839824438095093
test loss item: 0.5824692249298096
test loss item: 0.19027234613895416
test loss item: 0.2963264584541321
test loss item: 0.8388510942459106
test loss item: 0.10604945570230484
test loss item: 0.13418157398700714
test loss item: 0.16399794816970825
test loss item: 0.1380937546491623
test loss item: 0.04924445599317551
test loss item: 0.20815825462341309
test loss item: 0.3504924476146698
test loss item: 0.5615507960319519
test loss item: 0.20377923548221588
test loss item: 0.5770186185836792
test loss item: 0.2912476062774658
test loss item: 0.22321771085262299
test loss item: 0.13014213740825653
test loss item: 0.14116159081459045
test loss item: 0.1622767299413681
test loss item: 0.21894364058971405
test loss item: 0.1330539584159851
test loss item: 0.2418445646762848
test loss item: 0.22457203269004822
test loss item: 0.7672476172447205
test loss item: 0.04747634753584862
test loss item: 0.10862801223993301
test loss item: 0.43234190344810486
test loss item: 0.36036282777786255
test loss item: 0.3446562588214874
test loss item: 0.6747632622718811
test loss item: 1.460300326347351
test loss item: 0.3625645935535431
test loss item: 0.21047574281692505
test loss item: 0.22405600547790527
test loss item: 0.11286433786153793
test loss item: 0.26049110293388367
test loss item: 0.15441042184829712
test loss item: 0.43561622500419617
test loss item: 0.30244511365890503
test loss item: 0.19739414751529694
test loss item: 0.15419018268585205
test loss item: 0.4043601453304291
test loss item: 0.6051411628723145
test loss item: 0.22564370930194855
test loss item: 0.08569980412721634
test loss item: 0.17811799049377441
test loss item: 0.09099249541759491
test loss item: 0.2339307814836502
test loss item: 0.8183290362358093
test loss item: 0.5091531276702881
test loss item: 0.17517933249473572
test loss item: 0.17383131384849548
test loss item: 0.14352987706661224
test loss item: 0.31309470534324646
test loss item: 0.19801923632621765
test loss item: 0.15439584851264954
test loss item: 0.1670900583267212
test loss item: 0.8798739910125732
test loss item: 0.1787911206483841
test loss item: 0.23824217915534973
test loss item: 0.18611282110214233
test loss item: 0.4296364486217499
test loss item: 0.4101649522781372
test loss item: 0.05583139881491661
test loss item: 0.8571043014526367
test loss item: 0.22726213932037354
test loss item: 0.3104473352432251
test loss item: 0.10724136233329773
test loss item: 0.10191362351179123
test loss item: 0.13388541340827942
test loss item: 1.5987268686294556
test loss item: 0.344326376914978
test loss item: 0.11957590281963348
test loss item: 0.056528300046920776
test loss item: 0.9585010409355164
test loss item: 0.7230724692344666
test loss item: 1.0917614698410034
test loss item: 0.1584455370903015
test loss item: 0.14679130911827087
test loss item: 0.049586355686187744
test loss item: 0.04286041110754013
test loss item: 0.10655845701694489
Epoch [15/50], Training Loss: 0.2125, Testing Loss: 0.3305
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.2719478905200958
loss item: 0.13573123514652252
loss item: 1.6610571146011353
loss item: 0.7738875150680542
loss item: 0.514004111289978
loss item: 0.30038926005363464
loss item: 0.14207600057125092
loss item: 0.6708181500434875
loss item: 0.16263531148433685
loss item: 0.14223256707191467
loss item: 0.8152409195899963
loss item: 0.045735083520412445
loss item: 0.8184831738471985
loss item: 0.16629190742969513
loss item: 0.2773703634738922
loss item: 0.217802956700325
loss item: 0.2680933177471161
loss item: 0.5485212206840515
loss item: 0.8415499925613403
loss item: 0.3161366581916809
loss item: 0.30577218532562256
loss item: 0.1504906862974167
loss item: 0.20535527169704437
loss item: 0.19191710650920868
loss item: 0.19572113454341888
loss item: 0.641125500202179
loss item: 1.1092805862426758
loss item: 0.10982585698366165
loss item: 0.10653451085090637
loss item: 0.2863885164260864
loss item: 0.842646062374115
loss item: 1.4976710081100464
loss item: 0.1328638643026352
loss item: 0.4798799455165863
loss item: 0.1244383156299591
loss item: 0.10739867389202118
loss item: 0.30979353189468384
loss item: 0.17560921609401703
loss item: 0.3750399053096771
loss item: 0.6234184503555298
loss item: 0.9587020874023438
loss item: 0.17324580252170563
loss item: 0.1425834596157074
loss item: 0.0403955839574337
Val Loss: 0.4176
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.0005 2 360 done at Tue Nov 12 10:17:39 CET 2024
UNet2 with 1 50 0.001 2 360 start at Tue Nov 12 10:17:39 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 50, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 0.9121710062026978
train loss item: 2.1258654594421387
train loss item: 0.7656190395355225
train loss item: 1.100437045097351
train loss item: 2.1631789207458496
train loss item: 0.6007260680198669
train loss item: 0.6121547222137451
train loss item: 1.1712100505828857
train loss item: 0.3923240602016449
train loss item: 0.585159182548523
train loss item: 0.5905365347862244
train loss item: 0.3662756681442261
train loss item: 0.2392287701368332
train loss item: 0.7452740669250488
train loss item: 0.3706638514995575
train loss item: 1.076843023300171
train loss item: 0.3176692724227905
train loss item: 0.3876906931400299
train loss item: 0.4380272924900055
train loss item: 0.3998122811317444
train loss item: 0.28461408615112305
train loss item: 0.28989002108573914
train loss item: 1.4297986030578613
train loss item: 1.2458375692367554
train loss item: 0.7810567021369934
train loss item: 0.3620368540287018
train loss item: 0.3075741231441498
train loss item: 0.2973628044128418
train loss item: 0.20465140044689178
train loss item: 1.1250691413879395
train loss item: 2.6976158618927
train loss item: 0.6823355555534363
train loss item: 0.32735753059387207
train loss item: 0.5191559791564941
train loss item: 0.39297470450401306
train loss item: 2.5494320392608643
train loss item: 0.5253247618675232
train loss item: 0.3948175609111786
train loss item: 0.5120791792869568
train loss item: 0.3301679491996765
train loss item: 0.2458365261554718
train loss item: 0.3248426914215088
train loss item: 0.3641613721847534
train loss item: 0.2319786548614502
train loss item: 0.6995223760604858
train loss item: 0.2514076232910156
train loss item: 0.21891114115715027
train loss item: 0.49499350786209106
train loss item: 0.3015252351760864
train loss item: 0.21804651618003845
train loss item: 0.4015234112739563
train loss item: 1.126977562904358
train loss item: 0.16852876543998718
train loss item: 0.20971401035785675
train loss item: 2.4145195484161377
train loss item: 0.23036234080791473
train loss item: 0.3066193461418152
train loss item: 0.2792584002017975
train loss item: 0.2303459197282791
train loss item: 0.15960665047168732
train loss item: 1.0253320932388306
train loss item: 2.2420740127563477
train loss item: 0.28447070717811584
train loss item: 0.4374005198478699
train loss item: 0.20419026911258698
train loss item: 0.7708473801612854
train loss item: 0.47442442178726196
train loss item: 0.23222716152668
train loss item: 0.35465168952941895
train loss item: 0.35609129071235657
train loss item: 0.26264721155166626
train loss item: 0.17640453577041626
train loss item: 0.4031560719013214
train loss item: 0.32627877593040466
train loss item: 0.15429958701133728
train loss item: 0.1423220932483673
train loss item: 0.9998055696487427
train loss item: 1.4292393922805786
train loss item: 0.1378229409456253
train loss item: 0.34643471240997314
train loss item: 0.15509024262428284
train loss item: 0.17755380272865295
train loss item: 0.24281640350818634
train loss item: 0.5816525816917419
train loss item: 0.39295297861099243
train loss item: 0.64891117811203
train loss item: 4.20023250579834
train loss item: 0.21325857937335968
train loss item: 0.6316530108451843
test loss item: 0.18573616445064545
test loss item: 0.11039507389068604
test loss item: 0.47446414828300476
test loss item: 0.21506178379058838
test loss item: 0.2324116975069046
test loss item: 0.12542012333869934
test loss item: 1.373991847038269
test loss item: 0.4523073732852936
test loss item: 0.19234715402126312
test loss item: 0.36099186539649963
test loss item: 0.709503173828125
test loss item: 0.1455998718738556
test loss item: 0.1777210384607315
test loss item: 0.36248624324798584
test loss item: 0.16839507222175598
test loss item: 0.07317930459976196
test loss item: 0.27593159675598145
test loss item: 0.42546015977859497
test loss item: 0.6373082399368286
test loss item: 0.28225329518318176
test loss item: 0.7065306305885315
test loss item: 0.3206615149974823
test loss item: 0.3108065128326416
test loss item: 0.17070086300373077
test loss item: 0.20971150696277618
test loss item: 0.27909114956855774
test loss item: 0.3343096673488617
test loss item: 0.1875535398721695
test loss item: 0.3149206340312958
test loss item: 0.3434613347053528
test loss item: 0.624456524848938
test loss item: 0.06111176684498787
test loss item: 0.15173649787902832
test loss item: 0.5297618508338928
test loss item: 0.38473543524742126
test loss item: 0.46958616375923157
test loss item: 0.7320057153701782
test loss item: 1.112637996673584
test loss item: 0.433261513710022
test loss item: 0.2553984522819519
test loss item: 0.27558115124702454
test loss item: 0.1847885400056839
test loss item: 0.3568969666957855
test loss item: 0.1688612401485443
test loss item: 0.5815560221672058
test loss item: 0.40351372957229614
test loss item: 0.30278921127319336
test loss item: 0.2927902936935425
test loss item: 0.38657346367836
test loss item: 0.622253954410553
test loss item: 0.2801019847393036
test loss item: 0.1462196260690689
test loss item: 0.23224709928035736
test loss item: 0.12738361954689026
test loss item: 0.3159025013446808
test loss item: 0.746019184589386
test loss item: 0.5049576163291931
test loss item: 0.29097527265548706
test loss item: 0.22575561702251434
test loss item: 0.2249361127614975
test loss item: 0.4290810823440552
test loss item: 0.1866779923439026
test loss item: 0.25087499618530273
test loss item: 0.25192567706108093
test loss item: 0.7237311005592346
test loss item: 0.2963245213031769
test loss item: 0.3128970265388489
test loss item: 0.2469007670879364
test loss item: 0.4840162694454193
test loss item: 0.41413629055023193
test loss item: 0.0728050023317337
test loss item: 0.840832531452179
test loss item: 0.3359127342700958
test loss item: 0.3533949553966522
test loss item: 0.15103302896022797
test loss item: 0.17004652321338654
test loss item: 0.16946670413017273
test loss item: 1.0761560201644897
test loss item: 0.4618690609931946
test loss item: 0.19068297743797302
test loss item: 0.08925171941518784
test loss item: 0.7471039891242981
test loss item: 0.7751322388648987
test loss item: 0.7345174551010132
test loss item: 0.28912729024887085
test loss item: 0.22510449588298798
test loss item: 0.07566671818494797
test loss item: 0.059314023703336716
test loss item: 0.16778980195522308
Epoch [1/50], Training Loss: 0.6461, Testing Loss: 0.3614
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/50
train loss item: 0.48665037751197815
train loss item: 1.1615359783172607
train loss item: 0.27293288707733154
train loss item: 0.5829629302024841
train loss item: 0.49121662974357605
train loss item: 0.30032771825790405
train loss item: 0.49080514907836914
train loss item: 0.697040855884552
train loss item: 0.24364978075027466
train loss item: 0.36693501472473145
train loss item: 0.32848209142684937
train loss item: 0.28080955147743225
train loss item: 0.1381971687078476
train loss item: 0.4501991868019104
train loss item: 0.27488595247268677
train loss item: 0.7843855023384094
train loss item: 0.09665995836257935
train loss item: 0.2814568877220154
train loss item: 0.3409649431705475
train loss item: 0.3013257384300232
train loss item: 0.2096235156059265
train loss item: 0.13291700184345245
train loss item: 1.0211668014526367
train loss item: 0.8384483456611633
train loss item: 0.6219689846038818
train loss item: 0.2613876163959503
train loss item: 0.18609194457530975
train loss item: 0.26740261912345886
train loss item: 0.15649399161338806
train loss item: 0.6646139025688171
train loss item: 2.1474833488464355
train loss item: 0.62767094373703
train loss item: 0.15585872530937195
train loss item: 0.37342655658721924
train loss item: 0.1427515149116516
train loss item: 2.0818710327148438
train loss item: 0.6713902950286865
train loss item: 0.5651168823242188
train loss item: 0.728975236415863
train loss item: 0.2976408004760742
train loss item: 0.23928357660770416
train loss item: 0.33928191661834717
train loss item: 0.3826754689216614
train loss item: 0.26387959718704224
train loss item: 0.8121520280838013
train loss item: 0.13374173641204834
train loss item: 0.17160259187221527
train loss item: 0.5792803168296814
train loss item: 0.2960369288921356
train loss item: 0.18335272371768951
train loss item: 0.4162694811820984
train loss item: 1.2744544744491577
train loss item: 0.07771602272987366
train loss item: 0.13509595394134521
train loss item: 2.4734129905700684
train loss item: 0.20549899339675903
train loss item: 0.28258854150772095
train loss item: 0.2546379268169403
train loss item: 0.22661451995372772
train loss item: 0.1906350553035736
train loss item: 0.8574021458625793
train loss item: 2.1517767906188965
train loss item: 0.2441401183605194
train loss item: 0.3639388084411621
train loss item: 0.17409786581993103
train loss item: 0.5436062216758728
train loss item: 0.3908716142177582
train loss item: 0.19505375623703003
train loss item: 0.3971502482891083
train loss item: 0.3207044303417206
train loss item: 0.2358579784631729
train loss item: 0.12035752832889557
train loss item: 0.19457724690437317
train loss item: 0.25068381428718567
train loss item: 0.07541542500257492
train loss item: 0.10324722528457642
train loss item: 0.7521311640739441
train loss item: 1.2019109725952148
train loss item: 0.13115519285202026
train loss item: 0.33383774757385254
train loss item: 0.1980239599943161
train loss item: 0.19759082794189453
train loss item: 0.20953501760959625
train loss item: 0.5021787285804749
train loss item: 0.31964850425720215
train loss item: 0.527762770652771
train loss item: 3.9315314292907715
train loss item: 0.17098289728164673
train loss item: 0.4442448019981384
test loss item: 0.21006281673908234
test loss item: 0.1423376351594925
test loss item: 0.43189454078674316
test loss item: 0.22836622595787048
test loss item: 0.24500957131385803
test loss item: 0.1480274498462677
test loss item: 1.5753326416015625
test loss item: 0.6171939969062805
test loss item: 0.19679374992847443
test loss item: 0.3430742025375366
test loss item: 0.5991901755332947
test loss item: 0.1830114722251892
test loss item: 0.22857216000556946
test loss item: 0.39370158314704895
test loss item: 0.17477838695049286
test loss item: 0.11177512258291245
test loss item: 0.3173048794269562
test loss item: 0.3803214430809021
test loss item: 0.681397557258606
test loss item: 0.35152676701545715
test loss item: 0.6338116526603699
test loss item: 0.38562995195388794
test loss item: 0.3705214560031891
test loss item: 0.19429898262023926
test loss item: 0.200543612241745
test loss item: 0.23529987037181854
test loss item: 0.3429310917854309
test loss item: 0.20665951073169708
test loss item: 0.3480721116065979
test loss item: 0.3213827311992645
test loss item: 0.6112701892852783
test loss item: 0.09204819053411484
test loss item: 0.1658197045326233
test loss item: 0.48093992471694946
test loss item: 0.3291372060775757
test loss item: 0.4394116997718811
test loss item: 0.8037817478179932
test loss item: 0.9103074669837952
test loss item: 0.39086413383483887
test loss item: 0.28869134187698364
test loss item: 0.2925489842891693
test loss item: 0.2698843479156494
test loss item: 0.342507541179657
test loss item: 0.20273543894290924
test loss item: 0.5248063802719116
test loss item: 0.47074079513549805
test loss item: 0.3648636043071747
test loss item: 0.3097497224807739
test loss item: 0.39487820863723755
test loss item: 0.5497589111328125
test loss item: 0.28673073649406433
test loss item: 0.15686699748039246
test loss item: 0.22900094091892242
test loss item: 0.15457342565059662
test loss item: 0.2775312662124634
test loss item: 0.5800526142120361
test loss item: 0.5446460843086243
test loss item: 0.2876228392124176
test loss item: 0.24055223166942596
test loss item: 0.23177987337112427
test loss item: 0.38563603162765503
test loss item: 0.2658858299255371
test loss item: 0.2523871660232544
test loss item: 0.27479374408721924
test loss item: 0.6772077083587646
test loss item: 0.3026731312274933
test loss item: 0.34983155131340027
test loss item: 0.26626333594322205
test loss item: 0.4295552372932434
test loss item: 0.43224048614501953
test loss item: 0.11084449291229248
test loss item: 0.9608939290046692
test loss item: 0.4131729006767273
test loss item: 0.4579004943370819
test loss item: 0.18160149455070496
test loss item: 0.2601177990436554
test loss item: 0.1957016885280609
test loss item: 0.8623129725456238
test loss item: 0.4785661995410919
test loss item: 0.22922058403491974
test loss item: 0.0930333361029625
test loss item: 0.7702300548553467
test loss item: 0.8023293614387512
test loss item: 0.6212027072906494
test loss item: 0.25932395458221436
test loss item: 0.23144811391830444
test loss item: 0.08218587189912796
test loss item: 0.0803365558385849
test loss item: 0.16108648478984833
Epoch [2/50], Training Loss: 0.5056, Testing Loss: 0.3698
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/50
train loss item: 0.40431681275367737
train loss item: 0.9510575532913208
train loss item: 0.27253180742263794
train loss item: 0.4078327715396881
train loss item: 0.33667638897895813
train loss item: 0.26616939902305603
train loss item: 0.34476032853126526
train loss item: 0.6230496168136597
train loss item: 0.15810996294021606
train loss item: 0.2924773395061493
train loss item: 0.3582819700241089
train loss item: 0.23785194754600525
train loss item: 0.10616779327392578
train loss item: 0.4532085955142975
train loss item: 0.23287665843963623
train loss item: 0.634672224521637
train loss item: 0.06615922600030899
train loss item: 0.2761218547821045
train loss item: 0.2787648141384125
train loss item: 0.2777956426143646
train loss item: 0.19797994196414948
train loss item: 0.18029166758060455
train loss item: 0.7308247685432434
train loss item: 0.8075000047683716
train loss item: 0.4558870494365692
train loss item: 0.3066309094429016
train loss item: 0.20444701611995697
train loss item: 0.24018095433712006
train loss item: 0.06978444755077362
train loss item: 0.5963158011436462
train loss item: 1.797213077545166
train loss item: 0.4466153383255005
train loss item: 0.11431712657213211
train loss item: 0.30259013175964355
train loss item: 0.10058853775262833
train loss item: 1.8615950345993042
train loss item: 0.5981590747833252
train loss item: 0.5257294774055481
train loss item: 0.6821022033691406
train loss item: 0.22152315080165863
train loss item: 0.20006245374679565
train loss item: 0.34193870425224304
train loss item: 0.3807806968688965
train loss item: 0.28866374492645264
train loss item: 0.7851067185401917
train loss item: 0.160965234041214
train loss item: 0.12154196202754974
train loss item: 0.5586856603622437
train loss item: 0.29676195979118347
train loss item: 0.18665017187595367
train loss item: 0.39012184739112854
train loss item: 1.2390329837799072
train loss item: 0.10969952493906021
train loss item: 0.17861421406269073
train loss item: 2.199936628341675
train loss item: 0.1546437293291092
train loss item: 0.22260597348213196
train loss item: 0.2400335818529129
train loss item: 0.17156507074832916
train loss item: 0.15966323018074036
train loss item: 0.7490745782852173
train loss item: 1.6288939714431763
train loss item: 0.22739648818969727
train loss item: 0.36549654603004456
train loss item: 0.18399208784103394
train loss item: 0.5185285806655884
train loss item: 0.3856385350227356
train loss item: 0.16695541143417358
train loss item: 0.3736265003681183
train loss item: 0.28584668040275574
train loss item: 0.24164298176765442
train loss item: 0.11541582643985748
train loss item: 0.28054529428482056
train loss item: 0.2937539219856262
train loss item: 0.0734165608882904
train loss item: 0.10841704905033112
train loss item: 0.860194742679596
train loss item: 1.291494607925415
train loss item: 0.07048190385103226
train loss item: 0.23353353142738342
train loss item: 0.1588250696659088
train loss item: 0.13658559322357178
train loss item: 0.21414276957511902
train loss item: 0.41752204298973083
train loss item: 0.37362056970596313
train loss item: 0.45214200019836426
train loss item: 3.5229780673980713
train loss item: 0.15353475511074066
train loss item: 0.5436218976974487
test loss item: 0.16337335109710693
test loss item: 0.12232816964387894
test loss item: 0.38695472478866577
test loss item: 0.18987947702407837
test loss item: 0.20392148196697235
test loss item: 0.11583805829286575
test loss item: 1.6741338968276978
test loss item: 0.6663385033607483
test loss item: 0.1986963152885437
test loss item: 0.3375275433063507
test loss item: 0.6163406372070312
test loss item: 0.13147974014282227
test loss item: 0.22459344565868378
test loss item: 0.31330740451812744
test loss item: 0.15271888673305511
test loss item: 0.09522467106580734
test loss item: 0.27250170707702637
test loss item: 0.32020172476768494
test loss item: 0.7188824415206909
test loss item: 0.33266109228134155
test loss item: 0.4841320812702179
test loss item: 0.3726230561733246
test loss item: 0.2549353241920471
test loss item: 0.15972846746444702
test loss item: 0.17803677916526794
test loss item: 0.214985191822052
test loss item: 0.32379254698753357
test loss item: 0.17033933103084564
test loss item: 0.2730075418949127
test loss item: 0.35309073328971863
test loss item: 0.6473550200462341
test loss item: 0.07711856812238693
test loss item: 0.13628531992435455
test loss item: 0.39945676922798157
test loss item: 0.29354918003082275
test loss item: 0.486021488904953
test loss item: 0.8210583925247192
test loss item: 0.9351065754890442
test loss item: 0.3425940275192261
test loss item: 0.2434391975402832
test loss item: 0.2722919285297394
test loss item: 0.18158051371574402
test loss item: 0.27514708042144775
test loss item: 0.17082488536834717
test loss item: 0.4058611989021301
test loss item: 0.44085365533828735
test loss item: 0.24374061822891235
test loss item: 0.39666643738746643
test loss item: 0.36835816502571106
test loss item: 0.588074266910553
test loss item: 0.22897085547447205
test loss item: 0.2426464706659317
test loss item: 0.19743968546390533
test loss item: 0.1122957319021225
test loss item: 0.22329628467559814
test loss item: 0.5876825451850891
test loss item: 0.5704299211502075
test loss item: 0.1928173303604126
test loss item: 0.2190772294998169
test loss item: 0.1775171011686325
test loss item: 0.34909874200820923
test loss item: 0.2696938216686249
test loss item: 0.20131930708885193
test loss item: 0.23531906306743622
test loss item: 0.7090719938278198
test loss item: 0.2535879611968994
test loss item: 0.32185328006744385
test loss item: 0.24589137732982635
test loss item: 0.370713472366333
test loss item: 0.5115177631378174
test loss item: 0.09999260306358337
test loss item: 1.0374881029129028
test loss item: 0.28287434577941895
test loss item: 0.37179750204086304
test loss item: 0.16662126779556274
test loss item: 0.1729808896780014
test loss item: 0.16829556226730347
test loss item: 0.9036120176315308
test loss item: 0.38485896587371826
test loss item: 0.16632553935050964
test loss item: 0.07877703011035919
test loss item: 0.8477071523666382
test loss item: 0.8401127457618713
test loss item: 0.6795732975006104
test loss item: 0.22487564384937286
test loss item: 0.20171505212783813
test loss item: 0.06708744168281555
test loss item: 0.06505702435970306
test loss item: 0.13323993980884552
Epoch [3/50], Training Loss: 0.4521, Testing Loss: 0.3467
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/50
train loss item: 0.4026936888694763
train loss item: 0.932007908821106
train loss item: 0.2073158323764801
train loss item: 0.3953281044960022
train loss item: 0.2808475196361542
train loss item: 0.22582007944583893
train loss item: 0.25516796112060547
train loss item: 0.48603031039237976
train loss item: 0.1248018890619278
train loss item: 0.22975730895996094
train loss item: 0.29003313183784485
train loss item: 0.23676207661628723
train loss item: 0.11435948312282562
train loss item: 0.3737010061740875
train loss item: 0.23646928369998932
train loss item: 0.6303900480270386
train loss item: 0.06410516053438187
train loss item: 0.21501168608665466
train loss item: 0.28950047492980957
train loss item: 0.25381699204444885
train loss item: 0.1686660498380661
train loss item: 0.11912376433610916
train loss item: 0.7424846887588501
train loss item: 0.6060930490493774
train loss item: 0.4128679633140564
train loss item: 0.22368480265140533
train loss item: 0.160282164812088
train loss item: 0.2082388997077942
train loss item: 0.08773377537727356
train loss item: 0.4481845498085022
train loss item: 1.590124249458313
train loss item: 0.5201963782310486
train loss item: 0.12274891883134842
train loss item: 0.2773289084434509
train loss item: 0.11800087988376617
train loss item: 1.679360270500183
train loss item: 0.48908519744873047
train loss item: 0.3746160566806793
train loss item: 0.3098801374435425
train loss item: 0.17172583937644958
train loss item: 0.1604207158088684
train loss item: 0.26338866353034973
train loss item: 0.3128451406955719
train loss item: 0.22770264744758606
train loss item: 0.6357381939888
train loss item: 0.10528311133384705
train loss item: 0.10703711211681366
train loss item: 0.3746113181114197
train loss item: 0.18241074681282043
train loss item: 0.2035401612520218
train loss item: 0.25165680050849915
train loss item: 0.8216364979743958
train loss item: 0.07912547141313553
train loss item: 0.1272871345281601
train loss item: 1.6295762062072754
train loss item: 0.1739395409822464
train loss item: 0.254442036151886
train loss item: 0.22294391691684723
train loss item: 0.11960458010435104
train loss item: 0.1284250020980835
train loss item: 0.529671847820282
train loss item: 1.513680338859558
train loss item: 0.17424920201301575
train loss item: 0.3672032952308655
train loss item: 0.13865409791469574
train loss item: 0.44052785634994507
train loss item: 0.4400733709335327
train loss item: 0.16348092257976532
train loss item: 0.43731847405433655
train loss item: 0.30160701274871826
train loss item: 0.24192851781845093
train loss item: 0.10278540104627609
train loss item: 0.19409982860088348
train loss item: 0.25174474716186523
train loss item: 0.06204777956008911
train loss item: 0.09537258744239807
train loss item: 0.5493372678756714
train loss item: 1.197182536125183
train loss item: 0.08754781633615494
train loss item: 0.2386907935142517
train loss item: 0.10810710489749908
train loss item: 0.18347086012363434
train loss item: 0.2087378054857254
train loss item: 0.35202494263648987
train loss item: 0.38611534237861633
train loss item: 0.3632870614528656
train loss item: 3.196484327316284
train loss item: 0.13359983265399933
train loss item: 0.3829326927661896
test loss item: 0.1643076390028
test loss item: 0.11959642916917801
test loss item: 0.35509464144706726
test loss item: 0.18919609487056732
test loss item: 0.18284744024276733
test loss item: 0.1100734993815422
test loss item: 1.9001684188842773
test loss item: 0.7392232418060303
test loss item: 0.19258010387420654
test loss item: 0.29522207379341125
test loss item: 0.5660588145256042
test loss item: 0.14380528032779694
test loss item: 0.21101760864257812
test loss item: 0.282146692276001
test loss item: 0.13525789976119995
test loss item: 0.10148810595273972
test loss item: 0.2891584038734436
test loss item: 0.2541123330593109
test loss item: 0.7366359829902649
test loss item: 0.34246352314949036
test loss item: 0.3714790344238281
test loss item: 0.40260234475135803
test loss item: 0.2328355312347412
test loss item: 0.1726139634847641
test loss item: 0.15802110731601715
test loss item: 0.2046997845172882
test loss item: 0.3172381818294525
test loss item: 0.15334555506706238
test loss item: 0.2620719373226166
test loss item: 0.2943442463874817
test loss item: 0.6989959478378296
test loss item: 0.08035016804933548
test loss item: 0.14283610880374908
test loss item: 0.3405335247516632
test loss item: 0.23293302953243256
test loss item: 0.4284932315349579
test loss item: 0.8549873232841492
test loss item: 0.8174155354499817
test loss item: 0.296234130859375
test loss item: 0.26029524207115173
test loss item: 0.28312501311302185
test loss item: 0.16441872715950012
test loss item: 0.24966101348400116
test loss item: 0.19154919683933258
test loss item: 0.31551024317741394
test loss item: 0.45528924465179443
test loss item: 0.22361956536769867
test loss item: 0.3686404526233673
test loss item: 0.3492124080657959
test loss item: 0.5626037120819092
test loss item: 0.19631676375865936
test loss item: 0.1952626258134842
test loss item: 0.18562370538711548
test loss item: 0.12496219575405121
test loss item: 0.18684767186641693
test loss item: 0.4905315637588501
test loss item: 0.5535308122634888
test loss item: 0.21055608987808228
test loss item: 0.21603330969810486
test loss item: 0.16372129321098328
test loss item: 0.2824082672595978
test loss item: 0.28990745544433594
test loss item: 0.20661994814872742
test loss item: 0.22992196679115295
test loss item: 0.7026017308235168
test loss item: 0.24473972618579865
test loss item: 0.32555317878723145
test loss item: 0.24870677292346954
test loss item: 0.3156742453575134
test loss item: 0.51814866065979
test loss item: 0.1002998948097229
test loss item: 1.160264015197754
test loss item: 0.2799358069896698
test loss item: 0.4140484929084778
test loss item: 0.17925241589546204
test loss item: 0.15918783843517303
test loss item: 0.17987167835235596
test loss item: 0.8123794794082642
test loss item: 0.3551606237888336
test loss item: 0.1602254956960678
test loss item: 0.08341857045888901
test loss item: 0.8874430060386658
test loss item: 0.8717962503433228
test loss item: 0.626115083694458
test loss item: 0.21296875178813934
test loss item: 0.2113729566335678
test loss item: 0.08066504448652267
test loss item: 0.07658101618289948
test loss item: 0.11342373490333557
Epoch [4/50], Training Loss: 0.3854, Testing Loss: 0.3376
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/50
train loss item: 0.38815298676490784
train loss item: 0.8437963128089905
train loss item: 0.18484166264533997
train loss item: 0.3176180422306061
train loss item: 0.3029039204120636
train loss item: 0.20797066390514374
train loss item: 0.2339087277650833
train loss item: 0.45675164461135864
train loss item: 0.13850827515125275
train loss item: 0.2450139820575714
train loss item: 0.32176733016967773
train loss item: 0.21275149285793304
train loss item: 0.1052074134349823
train loss item: 0.4343673288822174
train loss item: 0.20955900847911835
train loss item: 0.43117132782936096
train loss item: 0.0741044208407402
train loss item: 0.163816899061203
train loss item: 0.2816649377346039
train loss item: 0.2437783181667328
train loss item: 0.16622503101825714
train loss item: 0.11751003563404083
train loss item: 0.5580093264579773
train loss item: 0.5152767896652222
train loss item: 0.3675912022590637
train loss item: 0.19425800442695618
train loss item: 0.13175827264785767
train loss item: 0.20380856096744537
train loss item: 0.06573139131069183
train loss item: 0.35562148690223694
train loss item: 1.273242712020874
train loss item: 0.5719687342643738
train loss item: 0.12985944747924805
train loss item: 0.2580487132072449
train loss item: 0.1340484768152237
train loss item: 1.5583516359329224
train loss item: 0.37193456292152405
train loss item: 0.38543063402175903
train loss item: 0.291443407535553
train loss item: 0.16730453073978424
train loss item: 0.15997062623500824
train loss item: 0.23682883381843567
train loss item: 0.28255587816238403
train loss item: 0.16661465167999268
train loss item: 0.461301326751709
train loss item: 0.09136656671762466
train loss item: 0.11434662342071533
train loss item: 0.2479904145002365
train loss item: 0.14807942509651184
train loss item: 0.1698984056711197
train loss item: 0.24104097485542297
train loss item: 0.5828565955162048
train loss item: 0.0623154453933239
train loss item: 0.1049003154039383
train loss item: 1.3892947435379028
train loss item: 0.14323844015598297
train loss item: 0.2145889848470688
train loss item: 0.18537156283855438
train loss item: 0.11722509562969208
train loss item: 0.14316676557064056
train loss item: 0.4656302034854889
train loss item: 1.1813143491744995
train loss item: 0.13542316854000092
train loss item: 0.26234978437423706
train loss item: 0.10408952832221985
train loss item: 0.49433469772338867
train loss item: 0.344838410615921
train loss item: 0.13239046931266785
train loss item: 0.3812115490436554
train loss item: 0.2662462592124939
train loss item: 0.2704869508743286
train loss item: 0.0895189568400383
train loss item: 0.21283331513404846
train loss item: 0.2569955587387085
train loss item: 0.08398512005805969
train loss item: 0.09035051614046097
train loss item: 0.519722044467926
train loss item: 1.3740484714508057
train loss item: 0.0639837458729744
train loss item: 0.17852318286895752
train loss item: 0.11642272025346756
train loss item: 0.19639770686626434
train loss item: 0.18684305250644684
train loss item: 0.3782520294189453
train loss item: 0.3172415792942047
train loss item: 0.2971554100513458
train loss item: 2.8296117782592773
train loss item: 0.15670345723628998
train loss item: 0.24792318046092987
test loss item: 0.15296126902103424
test loss item: 0.133498877286911
test loss item: 0.5416911244392395
test loss item: 0.17583446204662323
test loss item: 0.24417896568775177
test loss item: 0.1356334388256073
test loss item: 1.6203373670578003
test loss item: 0.6536034345626831
test loss item: 0.2148706465959549
test loss item: 0.3315224051475525
test loss item: 0.7940971255302429
test loss item: 0.11568624526262283
test loss item: 0.1703909933567047
test loss item: 0.283413827419281
test loss item: 0.17327620089054108
test loss item: 0.09742289036512375
test loss item: 0.24205976724624634
test loss item: 0.3748929500579834
test loss item: 0.6532902717590332
test loss item: 0.23739616572856903
test loss item: 0.5894289612770081
test loss item: 0.3522759974002838
test loss item: 0.2821444869041443
test loss item: 0.16816142201423645
test loss item: 0.1634429693222046
test loss item: 0.18791314959526062
test loss item: 0.2603372037410736
test loss item: 0.19019441306591034
test loss item: 0.27667662501335144
test loss item: 0.2905448079109192
test loss item: 0.7623375058174133
test loss item: 0.08625738322734833
test loss item: 0.14936690032482147
test loss item: 0.4502280354499817
test loss item: 0.3648596704006195
test loss item: 0.3934861421585083
test loss item: 0.7697432041168213
test loss item: 1.3764163255691528
test loss item: 0.37091127038002014
test loss item: 0.23443453013896942
test loss item: 0.2534203827381134
test loss item: 0.16776782274246216
test loss item: 0.29350313544273376
test loss item: 0.1678258329629898
test loss item: 0.46769821643829346
test loss item: 0.36048319935798645
test loss item: 0.24840250611305237
test loss item: 0.22709369659423828
test loss item: 0.42671817541122437
test loss item: 0.6347745060920715
test loss item: 0.2529308795928955
test loss item: 0.1432102471590042
test loss item: 0.20327366888523102
test loss item: 0.10147520154714584
test loss item: 0.2603684067726135
test loss item: 0.7536219954490662
test loss item: 0.5653480887413025
test loss item: 0.22747743129730225
test loss item: 0.2093188315629959
test loss item: 0.16334861516952515
test loss item: 0.36046841740608215
test loss item: 0.25572800636291504
test loss item: 0.18247990310192108
test loss item: 0.19053910672664642
test loss item: 0.8394208550453186
test loss item: 0.21365472674369812
test loss item: 0.291299968957901
test loss item: 0.21796050667762756
test loss item: 0.4261665940284729
test loss item: 0.45089131593704224
test loss item: 0.10117828100919724
test loss item: 0.9675623178482056
test loss item: 0.2954248785972595
test loss item: 0.33475542068481445
test loss item: 0.14859122037887573
test loss item: 0.16152185201644897
test loss item: 0.17340564727783203
test loss item: 1.4589473009109497
test loss item: 0.3804328143596649
test loss item: 0.1726102977991104
test loss item: 0.09172948449850082
test loss item: 0.9717326760292053
test loss item: 0.8093504309654236
test loss item: 1.005246639251709
test loss item: 0.20225432515144348
test loss item: 0.1860290765762329
test loss item: 0.0845339447259903
test loss item: 0.07696401327848434
test loss item: 0.12775856256484985
Epoch [5/50], Training Loss: 0.3428, Testing Loss: 0.3637
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/50
train loss item: 0.2966400980949402
train loss item: 0.7064111232757568
train loss item: 0.17244380712509155
train loss item: 0.22092680633068085
train loss item: 0.26735296845436096
train loss item: 0.20832860469818115
train loss item: 0.19632261991500854
train loss item: 0.41463419795036316
train loss item: 0.08258358389139175
train loss item: 0.18865859508514404
train loss item: 0.1947103887796402
train loss item: 0.16171953082084656
train loss item: 0.10916435718536377
train loss item: 0.38482865691185
train loss item: 0.20788024365901947
train loss item: 0.4171532094478607
train loss item: 0.07160428911447525
train loss item: 0.13298927247524261
train loss item: 0.22969624400138855
train loss item: 0.19324223697185516
train loss item: 0.1370564103126526
train loss item: 0.12295227497816086
train loss item: 0.4115223288536072
train loss item: 0.44671711325645447
train loss item: 0.3645278215408325
train loss item: 0.1977793425321579
train loss item: 0.12074501812458038
train loss item: 0.18587146699428558
train loss item: 0.08143913000822067
train loss item: 0.3468596041202545
train loss item: 1.05681574344635
train loss item: 0.5029738545417786
train loss item: 0.10994357615709305
train loss item: 0.2022722065448761
train loss item: 0.10949057340621948
train loss item: 1.3182978630065918
train loss item: 0.46265605092048645
train loss item: 0.426204651594162
train loss item: 0.25317108631134033
train loss item: 0.16699466109275818
train loss item: 0.1925140768289566
train loss item: 0.2607722282409668
train loss item: 0.3693748414516449
train loss item: 0.2142953723669052
train loss item: 0.47418078780174255
train loss item: 0.10861608386039734
train loss item: 0.09215383231639862
train loss item: 0.5615369081497192
train loss item: 0.18792594969272614
train loss item: 0.13373219966888428
train loss item: 0.3465467393398285
train loss item: 0.9312170743942261
train loss item: 0.10152140259742737
train loss item: 0.1659417748451233
train loss item: 1.2698392868041992
train loss item: 0.13139460980892181
train loss item: 0.19345058500766754
train loss item: 0.174875408411026
train loss item: 0.11806090921163559
train loss item: 0.12149514257907867
train loss item: 0.45965078473091125
train loss item: 1.0966691970825195
train loss item: 0.10502481460571289
train loss item: 0.2423139065504074
train loss item: 0.09054524451494217
train loss item: 0.4516296684741974
train loss item: 0.2999398112297058
train loss item: 0.13568346202373505
train loss item: 0.2527514696121216
train loss item: 0.17794908583164215
train loss item: 0.17705468833446503
train loss item: 0.08958589285612106
train loss item: 0.18631494045257568
train loss item: 0.19684471189975739
train loss item: 0.08837073296308517
train loss item: 0.10396703332662582
train loss item: 0.3369823694229126
train loss item: 0.9925078749656677
train loss item: 0.08941922336816788
train loss item: 0.18899859488010406
train loss item: 0.11899619549512863
train loss item: 0.13424941897392273
train loss item: 0.15335029363632202
train loss item: 0.356353223323822
train loss item: 0.35139477252960205
train loss item: 0.28941962122917175
train loss item: 2.5638787746429443
train loss item: 0.1067916750907898
train loss item: 0.3483065962791443
test loss item: 0.17343640327453613
test loss item: 0.12675398588180542
test loss item: 0.3089121878147125
test loss item: 0.18620844185352325
test loss item: 0.17388062179088593
test loss item: 0.12049859762191772
test loss item: 1.8897866010665894
test loss item: 0.6998200416564941
test loss item: 0.16522185504436493
test loss item: 0.22745496034622192
test loss item: 0.49880826473236084
test loss item: 0.13479354977607727
test loss item: 0.17148184776306152
test loss item: 0.3276500105857849
test loss item: 0.14264565706253052
test loss item: 0.12216123193502426
test loss item: 0.27646616101264954
test loss item: 0.18621045351028442
test loss item: 0.6756297945976257
test loss item: 0.2862773835659027
test loss item: 0.28828340768814087
test loss item: 0.3936742842197418
test loss item: 0.2604156732559204
test loss item: 0.17184969782829285
test loss item: 0.14294713735580444
test loss item: 0.19398978352546692
test loss item: 0.25740060210227966
test loss item: 0.14781159162521362
test loss item: 0.24506627023220062
test loss item: 0.2323032021522522
test loss item: 0.6875342726707458
test loss item: 0.10216844081878662
test loss item: 0.14368796348571777
test loss item: 0.25951072573661804
test loss item: 0.18635571002960205
test loss item: 0.3708893358707428
test loss item: 0.7915622591972351
test loss item: 0.7009811401367188
test loss item: 0.2576678693294525
test loss item: 0.2570381462574005
test loss item: 0.2883356809616089
test loss item: 0.21200643479824066
test loss item: 0.1624681055545807
test loss item: 0.20841099321842194
test loss item: 0.2657875716686249
test loss item: 0.395454466342926
test loss item: 0.23885320127010345
test loss item: 0.3042204678058624
test loss item: 0.3117564022541046
test loss item: 0.4960673451423645
test loss item: 0.155413419008255
test loss item: 0.1637117862701416
test loss item: 0.18012161552906036
test loss item: 0.1350460946559906
test loss item: 0.13842490315437317
test loss item: 0.40645071864128113
test loss item: 0.4898627698421478
test loss item: 0.19697482883930206
test loss item: 0.20224402844905853
test loss item: 0.11943034827709198
test loss item: 0.18085291981697083
test loss item: 0.28379395604133606
test loss item: 0.21275106072425842
test loss item: 0.19711926579475403
test loss item: 0.6475985646247864
test loss item: 0.23453229665756226
test loss item: 0.28077223896980286
test loss item: 0.24205367267131805
test loss item: 0.26058825850486755
test loss item: 0.4560842216014862
test loss item: 0.12534219026565552
test loss item: 1.1192772388458252
test loss item: 0.3009231984615326
test loss item: 0.4043594300746918
test loss item: 0.1782899647951126
test loss item: 0.19953130185604095
test loss item: 0.1812257468700409
test loss item: 0.7605152130126953
test loss item: 0.3561897575855255
test loss item: 0.16937647759914398
test loss item: 0.10452942550182343
test loss item: 0.83476322889328
test loss item: 0.800007164478302
test loss item: 0.575590193271637
test loss item: 0.2033567577600479
test loss item: 0.21216891705989838
test loss item: 0.10144896060228348
test loss item: 0.10175994038581848
test loss item: 0.1104954406619072
Epoch [6/50], Training Loss: 0.3170, Testing Loss: 0.3134
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/50
train loss item: 0.29462775588035583
train loss item: 0.6790745854377747
train loss item: 0.16626638174057007
train loss item: 0.3189024329185486
train loss item: 0.16653040051460266
train loss item: 0.16099488735198975
train loss item: 0.1660338193178177
train loss item: 0.4153306484222412
train loss item: 0.16996081173419952
train loss item: 0.2018970102071762
train loss item: 0.22501499950885773
train loss item: 0.1571733057498932
train loss item: 0.09697192907333374
train loss item: 0.34369564056396484
train loss item: 0.1697763353586197
train loss item: 0.4066774547100067
train loss item: 0.05788402631878853
train loss item: 0.12781855463981628
train loss item: 0.2377227246761322
train loss item: 0.15513812005519867
train loss item: 0.13318905234336853
train loss item: 0.10050293058156967
train loss item: 0.43736010789871216
train loss item: 0.3840285539627075
train loss item: 0.30919960141181946
train loss item: 0.15081098675727844
train loss item: 0.10159330070018768
train loss item: 0.1971329152584076
train loss item: 0.08115514367818832
train loss item: 0.32921868562698364
train loss item: 1.0890275239944458
train loss item: 0.3467690348625183
train loss item: 0.13572515547275543
train loss item: 0.18733586370944977
train loss item: 0.1148998960852623
train loss item: 1.1531163454055786
train loss item: 0.43655359745025635
train loss item: 0.3566433787345886
train loss item: 0.28132155537605286
train loss item: 0.14848263561725616
train loss item: 0.16165435314178467
train loss item: 0.18671093881130219
train loss item: 0.2817522883415222
train loss item: 0.16286690533161163
train loss item: 0.38074690103530884
train loss item: 0.08309394121170044
train loss item: 0.08952390402555466
train loss item: 0.24935606122016907
train loss item: 0.11975234746932983
train loss item: 0.12155871838331223
train loss item: 0.1968076080083847
train loss item: 0.4274197816848755
train loss item: 0.052215248346328735
train loss item: 0.10862865298986435
train loss item: 1.014438509941101
train loss item: 0.11378800123929977
train loss item: 0.14909280836582184
train loss item: 0.1287958025932312
train loss item: 0.09014911949634552
train loss item: 0.13793815672397614
train loss item: 0.3561669588088989
train loss item: 0.8323434591293335
train loss item: 0.11281774938106537
train loss item: 0.19333116710186005
train loss item: 0.08043437451124191
train loss item: 0.38584521412849426
train loss item: 0.21088629961013794
train loss item: 0.11294996738433838
train loss item: 0.3566722869873047
train loss item: 0.24891112744808197
train loss item: 0.2052064687013626
train loss item: 0.08390989899635315
train loss item: 0.1482195407152176
train loss item: 0.21374602615833282
train loss item: 0.06553962081670761
train loss item: 0.08378811925649643
train loss item: 0.25369495153427124
train loss item: 1.1347510814666748
train loss item: 0.0718509629368782
train loss item: 0.1631438136100769
train loss item: 0.08375727385282516
train loss item: 0.20321820676326752
train loss item: 0.17922091484069824
train loss item: 0.35987669229507446
train loss item: 0.3653695285320282
train loss item: 0.3142188489437103
train loss item: 2.3146281242370605
train loss item: 0.12207164615392685
train loss item: 0.2760896384716034
test loss item: 0.1453768014907837
test loss item: 0.09231063723564148
test loss item: 0.2479974925518036
test loss item: 0.17501002550125122
test loss item: 0.14231760799884796
test loss item: 0.10727867484092712
test loss item: 1.7594728469848633
test loss item: 0.636850893497467
test loss item: 0.1425212323665619
test loss item: 0.19684886932373047
test loss item: 0.401621550321579
test loss item: 0.1261463612318039
test loss item: 0.1466275006532669
test loss item: 0.2707878649234772
test loss item: 0.11553776264190674
test loss item: 0.06909937411546707
test loss item: 0.24745482206344604
test loss item: 0.1632659137248993
test loss item: 0.600810706615448
test loss item: 0.23184359073638916
test loss item: 0.21618527173995972
test loss item: 0.3621177673339844
test loss item: 0.21191704273223877
test loss item: 0.15941636264324188
test loss item: 0.1380138099193573
test loss item: 0.19860637187957764
test loss item: 0.20749124884605408
test loss item: 0.12355104833841324
test loss item: 0.21478216350078583
test loss item: 0.20920966565608978
test loss item: 0.6192141175270081
test loss item: 0.0683601126074791
test loss item: 0.13470180332660675
test loss item: 0.21108806133270264
test loss item: 0.15212500095367432
test loss item: 0.3159962296485901
test loss item: 0.7149578332901001
test loss item: 0.5046953558921814
test loss item: 0.2383423000574112
test loss item: 0.24974820017814636
test loss item: 0.2753691077232361
test loss item: 0.1702248752117157
test loss item: 0.12692011892795563
test loss item: 0.20442891120910645
test loss item: 0.21050004661083221
test loss item: 0.3256027400493622
test loss item: 0.18596258759498596
test loss item: 0.2172820121049881
test loss item: 0.25931039452552795
test loss item: 0.4275354743003845
test loss item: 0.1393415778875351
test loss item: 0.14696656167507172
test loss item: 0.18113590776920319
test loss item: 0.13142815232276917
test loss item: 0.1455615609884262
test loss item: 0.2934522330760956
test loss item: 0.4367029070854187
test loss item: 0.15511085093021393
test loss item: 0.1865266114473343
test loss item: 0.1170395091176033
test loss item: 0.15467889606952667
test loss item: 0.24754489958286285
test loss item: 0.20686954259872437
test loss item: 0.1936112642288208
test loss item: 0.543822169303894
test loss item: 0.22166594862937927
test loss item: 0.2596612870693207
test loss item: 0.22163324058055878
test loss item: 0.18989352881908417
test loss item: 0.4074214696884155
test loss item: 0.06871207058429718
test loss item: 1.030224084854126
test loss item: 0.2425115555524826
test loss item: 0.37941235303878784
test loss item: 0.14527130126953125
test loss item: 0.1535644233226776
test loss item: 0.1642804592847824
test loss item: 0.5087347030639648
test loss item: 0.27847328782081604
test loss item: 0.14712338149547577
test loss item: 0.07406401634216309
test loss item: 0.7482435703277588
test loss item: 0.7308602333068848
test loss item: 0.43534547090530396
test loss item: 0.2069229930639267
test loss item: 0.17001676559448242
test loss item: 0.06339754909276962
test loss item: 0.052917737513780594
test loss item: 0.1383247822523117
Epoch [7/50], Training Loss: 0.2807, Testing Loss: 0.2696
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/50
train loss item: 0.31069251894950867
train loss item: 0.7722635865211487
train loss item: 0.12710480391979218
train loss item: 0.21756930649280548
train loss item: 0.13696850836277008
train loss item: 0.15410040318965912
train loss item: 0.11986466497182846
train loss item: 0.42325055599212646
train loss item: 0.136404350399971
train loss item: 0.20203295350074768
train loss item: 0.2060369849205017
train loss item: 0.15326526761054993
train loss item: 0.08329859375953674
train loss item: 0.29131123423576355
train loss item: 0.13991299271583557
train loss item: 0.35766202211380005
train loss item: 0.07341598719358444
train loss item: 0.12611234188079834
train loss item: 0.23659773170948029
train loss item: 0.15525762736797333
train loss item: 0.14444571733474731
train loss item: 0.07275515049695969
train loss item: 0.5744139552116394
train loss item: 0.3829052746295929
train loss item: 0.2984805107116699
train loss item: 0.13340073823928833
train loss item: 0.09067174792289734
train loss item: 0.16617614030838013
train loss item: 0.08425361663103104
train loss item: 0.4149567782878876
train loss item: 1.3582420349121094
train loss item: 0.41123294830322266
train loss item: 0.07685495913028717
train loss item: 0.1942749172449112
train loss item: 0.11782577633857727
train loss item: 0.9866397976875305
train loss item: 0.4881340563297272
train loss item: 0.42846691608428955
train loss item: 0.35904619097709656
train loss item: 0.29717159271240234
train loss item: 0.16936206817626953
train loss item: 0.18755482137203217
train loss item: 0.30044811964035034
train loss item: 0.19395844638347626
train loss item: 0.5037084817886353
train loss item: 0.08421222120523453
train loss item: 0.08010432869195938
train loss item: 0.3591594994068146
train loss item: 0.19450396299362183
train loss item: 0.1333082765340805
train loss item: 0.21064655482769012
train loss item: 0.6656306385993958
train loss item: 0.06939983367919922
train loss item: 0.10687088966369629
train loss item: 1.0439733266830444
train loss item: 0.12037786096334457
train loss item: 0.2039838433265686
train loss item: 0.15937480330467224
train loss item: 0.10497070103883743
train loss item: 0.13532589375972748
train loss item: 0.3480584919452667
train loss item: 0.7972911596298218
train loss item: 0.12441647052764893
train loss item: 0.24232923984527588
train loss item: 0.10003252327442169
train loss item: 0.35832569003105164
train loss item: 0.1980256587266922
train loss item: 0.11341467499732971
train loss item: 0.34525641798973083
train loss item: 0.20631934702396393
train loss item: 0.17724008858203888
train loss item: 0.09701143205165863
train loss item: 0.15594878792762756
train loss item: 0.18328556418418884
train loss item: 0.07500807195901871
train loss item: 0.08691959828138351
train loss item: 0.25821229815483093
train loss item: 0.9037817716598511
train loss item: 0.06551700085401535
train loss item: 0.1847357302904129
train loss item: 0.08870939910411835
train loss item: 0.17041881382465363
train loss item: 0.14617988467216492
train loss item: 0.42374616861343384
train loss item: 0.43878209590911865
train loss item: 0.23396258056163788
train loss item: 2.175541877746582
train loss item: 0.08576354384422302
train loss item: 0.2222008854150772
test loss item: 0.16456356644630432
test loss item: 0.09363246709108353
test loss item: 0.3359835743904114
test loss item: 0.19370782375335693
test loss item: 0.15255238115787506
test loss item: 0.11404088884592056
test loss item: 2.032405138015747
test loss item: 0.7554088234901428
test loss item: 0.16638325154781342
test loss item: 0.23082104325294495
test loss item: 0.5472571849822998
test loss item: 0.15199719369411469
test loss item: 0.17085032165050507
test loss item: 0.31615132093429565
test loss item: 0.11943305283784866
test loss item: 0.07181056588888168
test loss item: 0.29062214493751526
test loss item: 0.1896476149559021
test loss item: 0.7040677666664124
test loss item: 0.29567787051200867
test loss item: 0.23765283823013306
test loss item: 0.41858649253845215
test loss item: 0.2496233880519867
test loss item: 0.18094515800476074
test loss item: 0.15973713994026184
test loss item: 0.21969881653785706
test loss item: 0.2581101953983307
test loss item: 0.13383795320987701
test loss item: 0.24227271974086761
test loss item: 0.23878684639930725
test loss item: 0.7632843852043152
test loss item: 0.06320954859256744
test loss item: 0.14528341591358185
test loss item: 0.2540087103843689
test loss item: 0.18953274190425873
test loss item: 0.3949945271015167
test loss item: 0.8256194591522217
test loss item: 0.8103769421577454
test loss item: 0.2864249050617218
test loss item: 0.2850705087184906
test loss item: 0.31597235798835754
test loss item: 0.2107844203710556
test loss item: 0.1440175473690033
test loss item: 0.24111458659172058
test loss item: 0.22885611653327942
test loss item: 0.40132033824920654
test loss item: 0.22345933318138123
test loss item: 0.2954838275909424
test loss item: 0.31987571716308594
test loss item: 0.5424673557281494
test loss item: 0.15629304945468903
test loss item: 0.16457845270633698
test loss item: 0.20400099456310272
test loss item: 0.16054949164390564
test loss item: 0.15024833381175995
test loss item: 0.4411274790763855
test loss item: 0.532743513584137
test loss item: 0.1832277476787567
test loss item: 0.2105928510427475
test loss item: 0.12125303596258163
test loss item: 0.18265943229198456
test loss item: 0.29190975427627563
test loss item: 0.23593051731586456
test loss item: 0.21721360087394714
test loss item: 0.6987817287445068
test loss item: 0.24500900506973267
test loss item: 0.3093580901622772
test loss item: 0.2514782249927521
test loss item: 0.24168971180915833
test loss item: 0.5117028951644897
test loss item: 0.07434140890836716
test loss item: 1.197977900505066
test loss item: 0.29569897055625916
test loss item: 0.453182578086853
test loss item: 0.1659366339445114
test loss item: 0.18599693477153778
test loss item: 0.18638697266578674
test loss item: 0.8567608594894409
test loss item: 0.359792560338974
test loss item: 0.16972686350345612
test loss item: 0.07635605335235596
test loss item: 0.9207428097724915
test loss item: 0.8503413200378418
test loss item: 0.6621202230453491
test loss item: 0.22165146470069885
test loss item: 0.19662491977214813
test loss item: 0.06393681466579437
test loss item: 0.058254893869161606
test loss item: 0.1548684686422348
Epoch [8/50], Training Loss: 0.2869, Testing Loss: 0.3263
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/50
train loss item: 0.24746443331241608
train loss item: 0.6722326278686523
train loss item: 0.13063696026802063
train loss item: 0.2518001198768616
train loss item: 0.13588643074035645
train loss item: 0.14563049376010895
train loss item: 0.12381193786859512
train loss item: 0.22769200801849365
train loss item: 0.1043793335556984
train loss item: 0.20028166472911835
train loss item: 0.2702518701553345
train loss item: 0.1661255657672882
train loss item: 0.10503794252872467
train loss item: 0.37849944829940796
train loss item: 0.16011367738246918
train loss item: 0.31739407777786255
train loss item: 0.05545293167233467
train loss item: 0.1694737821817398
train loss item: 0.1530696600675583
train loss item: 0.17461375892162323
train loss item: 0.13227997720241547
train loss item: 0.07521091401576996
train loss item: 0.45326635241508484
train loss item: 0.4576914310455322
train loss item: 0.2461480349302292
train loss item: 0.18453557789325714
train loss item: 0.08785209059715271
train loss item: 0.12407597154378891
train loss item: 0.0562705397605896
train loss item: 0.33268675208091736
train loss item: 1.1739189624786377
train loss item: 0.32223445177078247
train loss item: 0.08905168622732162
train loss item: 0.21286369860172272
train loss item: 0.07282494753599167
train loss item: 0.9111947417259216
train loss item: 0.37557223439216614
train loss item: 0.38519302010536194
train loss item: 0.2753826975822449
train loss item: 0.2792118489742279
train loss item: 0.16586264967918396
train loss item: 0.22735098004341125
train loss item: 0.3236597776412964
train loss item: 0.201341912150383
train loss item: 0.37737831473350525
train loss item: 0.08840272575616837
train loss item: 0.07185392081737518
train loss item: 0.4562358856201172
train loss item: 0.21034257113933563
train loss item: 0.12223532795906067
train loss item: 0.2807832956314087
train loss item: 0.7161772847175598
train loss item: 0.0746019184589386
train loss item: 0.1190595030784607
train loss item: 0.8727970123291016
train loss item: 0.08895771205425262
train loss item: 0.15009669959545135
train loss item: 0.1364525556564331
train loss item: 0.10762695223093033
train loss item: 0.12519770860671997
train loss item: 0.3014889657497406
train loss item: 0.6740025877952576
train loss item: 0.13016323745250702
train loss item: 0.22770023345947266
train loss item: 0.10484259575605392
train loss item: 0.30574700236320496
train loss item: 0.16447488963603973
train loss item: 0.12154155969619751
train loss item: 0.2763780951499939
train loss item: 0.15878920257091522
train loss item: 0.13352768123149872
train loss item: 0.07129999995231628
train loss item: 0.14932700991630554
train loss item: 0.16822578012943268
train loss item: 0.06660662591457367
train loss item: 0.09052344411611557
train loss item: 0.24872329831123352
train loss item: 0.9201434254646301
train loss item: 0.07342415302991867
train loss item: 0.15574979782104492
train loss item: 0.09181369096040726
train loss item: 0.13834935426712036
train loss item: 0.16081777215003967
train loss item: 0.3546416163444519
train loss item: 0.3899003863334656
train loss item: 0.28962451219558716
train loss item: 2.0611276626586914
train loss item: 0.10272564738988876
train loss item: 0.1888909935951233
test loss item: 0.18310385942459106
test loss item: 0.11812178045511246
test loss item: 0.3707675039768219
test loss item: 0.19772842526435852
test loss item: 0.1774994283914566
test loss item: 0.1326485276222229
test loss item: 1.9071484804153442
test loss item: 0.672950029373169
test loss item: 0.17514410614967346
test loss item: 0.2395128756761551
test loss item: 0.5833399891853333
test loss item: 0.1598035842180252
test loss item: 0.18104270100593567
test loss item: 0.38654088973999023
test loss item: 0.1444021463394165
test loss item: 0.08891566842794418
test loss item: 0.28571781516075134
test loss item: 0.2088095247745514
test loss item: 0.6389663219451904
test loss item: 0.2952723205089569
test loss item: 0.2853880822658539
test loss item: 0.39412665367126465
test loss item: 0.2932760417461395
test loss item: 0.18706518411636353
test loss item: 0.16403236985206604
test loss item: 0.21611826121807098
test loss item: 0.2635415494441986
test loss item: 0.15387429296970367
test loss item: 0.25795692205429077
test loss item: 0.24970678985118866
test loss item: 0.7364728450775146
test loss item: 0.08620108664035797
test loss item: 0.15695783495903015
test loss item: 0.2775980532169342
test loss item: 0.21883194148540497
test loss item: 0.34511637687683105
test loss item: 0.7773826718330383
test loss item: 0.9106215834617615
test loss item: 0.29505813121795654
test loss item: 0.2780449092388153
test loss item: 0.3100707530975342
test loss item: 0.23698818683624268
test loss item: 0.15804919600486755
test loss item: 0.23559176921844482
test loss item: 0.2814303934574127
test loss item: 0.3765534460544586
test loss item: 0.2539342939853668
test loss item: 0.31246060132980347
test loss item: 0.3190489709377289
test loss item: 0.5120628476142883
test loss item: 0.18527890741825104
test loss item: 0.1803133338689804
test loss item: 0.20403125882148743
test loss item: 0.1586523950099945
test loss item: 0.16392208635807037
test loss item: 0.4980792999267578
test loss item: 0.48623955249786377
test loss item: 0.2273540049791336
test loss item: 0.21665246784687042
test loss item: 0.13074450194835663
test loss item: 0.19643534719944
test loss item: 0.2738639712333679
test loss item: 0.24025322496891022
test loss item: 0.22615604102611542
test loss item: 0.7137235403060913
test loss item: 0.24486781656742096
test loss item: 0.3000200092792511
test loss item: 0.25065112113952637
test loss item: 0.2766183316707611
test loss item: 0.419027715921402
test loss item: 0.08881818503141403
test loss item: 1.105368733406067
test loss item: 0.3477405309677124
test loss item: 0.4389042258262634
test loss item: 0.17312802374362946
test loss item: 0.217777281999588
test loss item: 0.19354024529457092
test loss item: 1.00545334815979
test loss item: 0.4291948676109314
test loss item: 0.18672232329845428
test loss item: 0.08874081820249557
test loss item: 0.889136552810669
test loss item: 0.7980656623840332
test loss item: 0.7358264327049255
test loss item: 0.2387523204088211
test loss item: 0.19565264880657196
test loss item: 0.07430136948823929
test loss item: 0.07115153223276138
test loss item: 0.13664306700229645
Epoch [9/50], Training Loss: 0.2660, Testing Loss: 0.3337
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/50
train loss item: 0.23389679193496704
train loss item: 0.6644536852836609
train loss item: 0.14344598352909088
train loss item: 0.26150837540626526
train loss item: 0.13333503901958466
train loss item: 0.14298130571842194
train loss item: 0.1004064530134201
train loss item: 0.23125210404396057
train loss item: 0.07828350365161896
train loss item: 0.18499711155891418
train loss item: 0.23493602871894836
train loss item: 0.1472126692533493
train loss item: 0.0894208550453186
train loss item: 0.3828592598438263
train loss item: 0.15785324573516846
train loss item: 0.4308154881000519
train loss item: 0.056338656693696976
train loss item: 0.1378604918718338
train loss item: 0.18864133954048157
train loss item: 0.18779157102108002
train loss item: 0.10403038561344147
train loss item: 0.09664016216993332
train loss item: 0.570580005645752
train loss item: 0.2868679165840149
train loss item: 0.2766973078250885
train loss item: 0.1759471893310547
train loss item: 0.08628754317760468
train loss item: 0.12410856783390045
train loss item: 0.06654073297977448
train loss item: 0.2727832496166229
train loss item: 0.8483908772468567
train loss item: 0.34925100207328796
train loss item: 0.08664136379957199
train loss item: 0.1669187843799591
train loss item: 0.08352695405483246
train loss item: 0.7441481947898865
train loss item: 0.34178653359413147
train loss item: 0.3387190103530884
train loss item: 0.21667803823947906
train loss item: 0.17401428520679474
train loss item: 0.16644054651260376
train loss item: 0.2217690646648407
train loss item: 0.30561867356300354
train loss item: 0.18763190507888794
train loss item: 0.3189585506916046
train loss item: 0.08398352563381195
train loss item: 0.07233481109142303
train loss item: 0.419024795293808
train loss item: 0.1901855766773224
train loss item: 0.11255252361297607
train loss item: 0.2297987937927246
train loss item: 0.6116355657577515
train loss item: 0.09713465720415115
train loss item: 0.12781138718128204
train loss item: 0.6475275158882141
train loss item: 0.08994562178850174
train loss item: 0.16527922451496124
train loss item: 0.1548183560371399
train loss item: 0.1160004660487175
train loss item: 0.11458853632211685
train loss item: 0.3179948627948761
train loss item: 0.6022362112998962
train loss item: 0.10885939002037048
train loss item: 0.2532917261123657
train loss item: 0.09486362338066101
train loss item: 0.26217204332351685
train loss item: 0.2057313472032547
train loss item: 0.10986006259918213
train loss item: 0.2481609582901001
train loss item: 0.14608103036880493
train loss item: 0.11365832388401031
train loss item: 0.08163218200206757
train loss item: 0.12390048056840897
train loss item: 0.10597337037324905
train loss item: 0.09421712905168533
train loss item: 0.10684844106435776
train loss item: 0.21396474540233612
train loss item: 1.0922901630401611
train loss item: 0.07798589020967484
train loss item: 0.18177878856658936
train loss item: 0.12744839489459991
train loss item: 0.14963464438915253
train loss item: 0.13397075235843658
train loss item: 0.3206985592842102
train loss item: 0.3014315962791443
train loss item: 0.2518998980522156
train loss item: 1.7920620441436768
train loss item: 0.10046350955963135
train loss item: 0.18386104702949524
test loss item: 0.18525339663028717
test loss item: 0.07713756710290909
test loss item: 0.5153390765190125
test loss item: 0.19838963449001312
test loss item: 0.18733248114585876
test loss item: 0.12042161077260971
test loss item: 1.5632095336914062
test loss item: 0.5512701869010925
test loss item: 0.19895130395889282
test loss item: 0.29340097308158875
test loss item: 0.7488066554069519
test loss item: 0.14538036286830902
test loss item: 0.16487228870391846
test loss item: 0.34885266423225403
test loss item: 0.13461366295814514
test loss item: 0.06715453416109085
test loss item: 0.2930694818496704
test loss item: 0.3135601282119751
test loss item: 0.5509366989135742
test loss item: 0.27949458360671997
test loss item: 0.46699970960617065
test loss item: 0.35845670104026794
test loss item: 0.3045025169849396
test loss item: 0.16416729986667633
test loss item: 0.18710318207740784
test loss item: 0.18135491013526917
test loss item: 0.26634299755096436
test loss item: 0.1357552707195282
test loss item: 0.25596392154693604
test loss item: 0.251010537147522
test loss item: 0.737194299697876
test loss item: 0.07871777564287186
test loss item: 0.1435997635126114
test loss item: 0.3969615697860718
test loss item: 0.31264516711235046
test loss item: 0.3420734405517578
test loss item: 0.6621840000152588
test loss item: 1.2803469896316528
test loss item: 0.34962186217308044
test loss item: 0.24801474809646606
test loss item: 0.2823614478111267
test loss item: 0.24670293927192688
test loss item: 0.2528615891933441
test loss item: 0.23998600244522095
test loss item: 0.38459116220474243
test loss item: 0.3656097948551178
test loss item: 0.2821677029132843
test loss item: 0.26323747634887695
test loss item: 0.39280062913894653
test loss item: 0.5819666385650635
test loss item: 0.21840354800224304
test loss item: 0.14288246631622314
test loss item: 0.21999043226242065
test loss item: 0.18888172507286072
test loss item: 0.21366959810256958
test loss item: 0.6995115280151367
test loss item: 0.4672476351261139
test loss item: 0.22274714708328247
test loss item: 0.21980364620685577
test loss item: 0.130956768989563
test loss item: 0.2961083948612213
test loss item: 0.26977071166038513
test loss item: 0.2267715334892273
test loss item: 0.1911608874797821
test loss item: 0.7982361912727356
test loss item: 0.254095196723938
test loss item: 0.29530051350593567
test loss item: 0.2182626575231552
test loss item: 0.36804473400115967
test loss item: 0.3849552571773529
test loss item: 0.059983864426612854
test loss item: 0.9148067831993103
test loss item: 0.36032986640930176
test loss item: 0.4109553098678589
test loss item: 0.18778659403324127
test loss item: 0.22327016294002533
test loss item: 0.16307438910007477
test loss item: 1.3840655088424683
test loss item: 0.42236360907554626
test loss item: 0.18999184668064117
test loss item: 0.07343307137489319
test loss item: 0.90543133020401
test loss item: 0.7283285856246948
test loss item: 0.9597517848014832
test loss item: 0.20944461226463318
test loss item: 0.22988641262054443
test loss item: 0.07279027998447418
test loss item: 0.06948041170835495
test loss item: 0.12506453692913055
Epoch [10/50], Training Loss: 0.2465, Testing Loss: 0.3491
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 11/50
train loss item: 0.24692943692207336
train loss item: 0.4923757016658783
train loss item: 0.12047514319419861
train loss item: 0.25849562883377075
train loss item: 0.1341867744922638
train loss item: 0.15141402184963226
train loss item: 0.16545577347278595
train loss item: 0.4398009777069092
train loss item: 0.08053632825613022
train loss item: 0.15259931981563568
train loss item: 0.19952154159545898
train loss item: 0.14127561450004578
train loss item: 0.10301612317562103
train loss item: 0.3856988251209259
train loss item: 0.15846101939678192
train loss item: 0.25709083676338196
train loss item: 0.046808067709207535
train loss item: 0.08946908265352249
train loss item: 0.19387036561965942
train loss item: 0.13754916191101074
train loss item: 0.09972137957811356
train loss item: 0.0928572416305542
train loss item: 0.3168012797832489
train loss item: 0.3084787428379059
train loss item: 0.2185843586921692
train loss item: 0.1483522653579712
train loss item: 0.0682535171508789
train loss item: 0.11662130802869797
train loss item: 0.06481263041496277
train loss item: 0.22596754133701324
train loss item: 0.470603883266449
train loss item: 0.43517258763313293
train loss item: 0.07569665461778641
train loss item: 0.20184704661369324
train loss item: 0.08244837075471878
train loss item: 0.6804948449134827
train loss item: 0.3461282551288605
train loss item: 0.33864134550094604
train loss item: 0.22372817993164062
train loss item: 0.1430119425058365
train loss item: 0.17234234511852264
train loss item: 0.19954751431941986
train loss item: 0.3113647401332855
train loss item: 0.1794363558292389
train loss item: 0.30246296525001526
train loss item: 0.08009515702724457
train loss item: 0.07807645201683044
train loss item: 0.38038527965545654
train loss item: 0.1568242609500885
train loss item: 0.09445995092391968
train loss item: 0.19839422404766083
train loss item: 0.40478968620300293
train loss item: 0.06293138861656189
train loss item: 0.11273130774497986
train loss item: 0.5831560492515564
train loss item: 0.08808407932519913
train loss item: 0.15965448319911957
train loss item: 0.11408717185258865
train loss item: 0.12082824110984802
train loss item: 0.138172447681427
train loss item: 0.296372652053833
train loss item: 0.5277395844459534
train loss item: 0.08974532783031464
train loss item: 0.18543455004692078
train loss item: 0.06217925623059273
train loss item: 0.26630541682243347
train loss item: 0.13598616421222687
train loss item: 0.10796664655208588
train loss item: 0.28481024503707886
train loss item: 0.1811244785785675
train loss item: 0.11589144170284271
train loss item: 0.08287850767374039
train loss item: 0.09758760780096054
train loss item: 0.16697034239768982
train loss item: 0.07166005671024323
train loss item: 0.08704912662506104
train loss item: 0.2087489664554596
train loss item: 0.8262407183647156
train loss item: 0.06563889235258102
train loss item: 0.14375892281532288
train loss item: 0.06587498635053635
train loss item: 0.12310941517353058
train loss item: 0.15808868408203125
train loss item: 0.434347927570343
train loss item: 0.45442938804626465
train loss item: 0.3287867307662964
train loss item: 1.6234337091445923
train loss item: 0.07720128446817398
train loss item: 0.160840705037117
test loss item: 0.15963232517242432
test loss item: 0.08425410091876984
test loss item: 0.36364591121673584
test loss item: 0.1916750818490982
test loss item: 0.15070118010044098
test loss item: 0.12071714550256729
test loss item: 1.7540943622589111
test loss item: 0.6268022656440735
test loss item: 0.16209881007671356
test loss item: 0.22762589156627655
test loss item: 0.5611861348152161
test loss item: 0.16071531176567078
test loss item: 0.18705835938453674
test loss item: 0.30651530623435974
test loss item: 0.11902941018342972
test loss item: 0.058627765625715256
test loss item: 0.2883020043373108
test loss item: 0.2006353735923767
test loss item: 0.5848140120506287
test loss item: 0.2885509431362152
test loss item: 0.2831462621688843
test loss item: 0.37404704093933105
test loss item: 0.25157544016838074
test loss item: 0.1690463274717331
test loss item: 0.17572535574436188
test loss item: 0.222237229347229
test loss item: 0.24900098145008087
test loss item: 0.12645985186100006
test loss item: 0.22978948056697845
test loss item: 0.24191798269748688
test loss item: 0.6882944703102112
test loss item: 0.06069258227944374
test loss item: 0.14231961965560913
test loss item: 0.2631068825721741
test loss item: 0.2043582648038864
test loss item: 0.32895001769065857
test loss item: 0.6994800567626953
test loss item: 0.8885957598686218
test loss item: 0.2789517939090729
test loss item: 0.2604033648967743
test loss item: 0.2954980432987213
test loss item: 0.2184649407863617
test loss item: 0.15097510814666748
test loss item: 0.24326688051223755
test loss item: 0.26202961802482605
test loss item: 0.3725023865699768
test loss item: 0.22753794491291046
test loss item: 0.2852920591831207
test loss item: 0.3123219311237335
test loss item: 0.4842938482761383
test loss item: 0.16223081946372986
test loss item: 0.1917300969362259
test loss item: 0.20917218923568726
test loss item: 0.17929808795452118
test loss item: 0.16811993718147278
test loss item: 0.4738435447216034
test loss item: 0.461637943983078
test loss item: 0.193158358335495
test loss item: 0.21643054485321045
test loss item: 0.12907283008098602
test loss item: 0.16435061395168304
test loss item: 0.2743893265724182
test loss item: 0.23519127070903778
test loss item: 0.21475911140441895
test loss item: 0.7028520703315735
test loss item: 0.24245186150074005
test loss item: 0.30693018436431885
test loss item: 0.23796524107456207
test loss item: 0.26221904158592224
test loss item: 0.4080236256122589
test loss item: 0.06307747215032578
test loss item: 1.030863642692566
test loss item: 0.29600200057029724
test loss item: 0.418874591588974
test loss item: 0.17908625304698944
test loss item: 0.18669834733009338
test loss item: 0.17153064906597137
test loss item: 1.03052818775177
test loss item: 0.3658478260040283
test loss item: 0.16693200170993805
test loss item: 0.06892195343971252
test loss item: 0.8485868573188782
test loss item: 0.7250383496284485
test loss item: 0.7438780665397644
test loss item: 0.2320478856563568
test loss item: 0.2127697467803955
test loss item: 0.056941259652376175
test loss item: 0.05143307149410248
test loss item: 0.16314272582530975
Epoch [11/50], Training Loss: 0.2245, Testing Loss: 0.3150
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 12/50
train loss item: 0.23176446557044983
train loss item: 0.6954120397567749
train loss item: 0.1051778718829155
train loss item: 0.17027242481708527
train loss item: 0.10521789640188217
train loss item: 0.131994366645813
train loss item: 0.09783081710338593
train loss item: 0.199549600481987
train loss item: 0.08406926691532135
train loss item: 0.1403457671403885
train loss item: 0.15431879460811615
train loss item: 0.13663721084594727
train loss item: 0.08562958240509033
train loss item: 0.29084861278533936
train loss item: 0.13461002707481384
train loss item: 0.3565678596496582
train loss item: 0.046511828899383545
train loss item: 0.12904435396194458
train loss item: 0.12907952070236206
train loss item: 0.16813924908638
train loss item: 0.09212593734264374
train loss item: 0.09431895613670349
train loss item: 0.5798218846321106
train loss item: 0.3473588228225708
train loss item: 0.227395161986351
train loss item: 0.1644456386566162
train loss item: 0.07918020337820053
train loss item: 0.10837187618017197
train loss item: 0.05611337348818779
train loss item: 0.30686822533607483
train loss item: 1.2110722064971924
train loss item: 0.3193047046661377
train loss item: 0.09918000549077988
train loss item: 0.1732243299484253
train loss item: 0.11592230200767517
train loss item: 0.5627307295799255
train loss item: 0.3911363184452057
train loss item: 0.365578293800354
train loss item: 0.31549838185310364
train loss item: 0.2494126558303833
train loss item: 0.1691395789384842
train loss item: 0.2322482019662857
train loss item: 0.31812208890914917
train loss item: 0.2128089964389801
train loss item: 0.366759717464447
train loss item: 0.0873691514134407
train loss item: 0.08745168149471283
train loss item: 0.49946480989456177
train loss item: 0.2100602090358734
train loss item: 0.11480561643838882
train loss item: 0.3714398145675659
train loss item: 0.9677728414535522
train loss item: 0.09532059729099274
train loss item: 0.13763202726840973
train loss item: 0.738945484161377
train loss item: 0.12671418488025665
train loss item: 0.13870035111904144
train loss item: 0.15037955343723297
train loss item: 0.13147605955600739
train loss item: 0.12152788788080215
train loss item: 0.3891908824443817
train loss item: 0.5815969109535217
train loss item: 0.1502525806427002
train loss item: 0.21044552326202393
train loss item: 0.1449669450521469
train loss item: 0.4411897659301758
train loss item: 0.1786240190267563
train loss item: 0.13554999232292175
train loss item: 0.23453259468078613
train loss item: 0.13277305662631989
train loss item: 0.10586796700954437
train loss item: 0.06728805601596832
train loss item: 0.14223532378673553
train loss item: 0.20016224682331085
train loss item: 0.0742967277765274
train loss item: 0.08898496627807617
train loss item: 0.3150179088115692
train loss item: 1.0095123052597046
train loss item: 0.06331290304660797
train loss item: 0.14944997429847717
train loss item: 0.07829412817955017
train loss item: 0.10760483145713806
train loss item: 0.12223100662231445
train loss item: 0.3789306581020355
train loss item: 0.30854037404060364
train loss item: 0.24739506840705872
train loss item: 1.4755958318710327
train loss item: 0.11979437619447708
train loss item: 0.21295496821403503
test loss item: 0.1360386610031128
test loss item: 0.10236606746912003
test loss item: 0.4935370683670044
test loss item: 0.17449267208576202
test loss item: 0.19361364841461182
test loss item: 0.11716407537460327
test loss item: 1.7274413108825684
test loss item: 0.5966460108757019
test loss item: 0.17849047482013702
test loss item: 0.27582645416259766
test loss item: 0.7324752807617188
test loss item: 0.11619627475738525
test loss item: 0.13981270790100098
test loss item: 0.18935588002204895
test loss item: 0.15327274799346924
test loss item: 0.062282949686050415
test loss item: 0.23926185071468353
test loss item: 0.31521302461624146
test loss item: 0.5885077714920044
test loss item: 0.22342000901699066
test loss item: 0.5112713575363159
test loss item: 0.3480880856513977
test loss item: 0.23271650075912476
test loss item: 0.17373238503932953
test loss item: 0.14667533338069916
test loss item: 0.23364605009555817
test loss item: 0.22203189134597778
test loss item: 0.14208222925662994
test loss item: 0.2393772453069687
test loss item: 0.2290012240409851
test loss item: 0.7651889324188232
test loss item: 0.06269178539514542
test loss item: 0.1553933471441269
test loss item: 0.3838439881801605
test loss item: 0.32065045833587646
test loss item: 0.31679877638816833
test loss item: 0.710730791091919
test loss item: 1.2521449327468872
test loss item: 0.34440985321998596
test loss item: 0.25381237268447876
test loss item: 0.25648602843284607
test loss item: 0.15436774492263794
test loss item: 0.22433267533779144
test loss item: 0.1897253692150116
test loss item: 0.39399978518486023
test loss item: 0.34087496995925903
test loss item: 0.20171184837818146
test loss item: 0.17886187136173248
test loss item: 0.380891352891922
test loss item: 0.5675431489944458
test loss item: 0.22228696942329407
test loss item: 0.11468107253313065
test loss item: 0.20719251036643982
test loss item: 0.12182775139808655
test loss item: 0.2519178092479706
test loss item: 0.6879953742027283
test loss item: 0.48045629262924194
test loss item: 0.18471871316432953
test loss item: 0.21569131314754486
test loss item: 0.15930259227752686
test loss item: 0.27495628595352173
test loss item: 0.2466518133878708
test loss item: 0.23539495468139648
test loss item: 0.17293982207775116
test loss item: 0.8327963948249817
test loss item: 0.20748694241046906
test loss item: 0.28903284668922424
test loss item: 0.20226745307445526
test loss item: 0.38022342324256897
test loss item: 0.3976250886917114
test loss item: 0.055218424648046494
test loss item: 1.0022649765014648
test loss item: 0.25042709708213806
test loss item: 0.3817117512226105
test loss item: 0.12348761409521103
test loss item: 0.1266127973794937
test loss item: 0.16898536682128906
test loss item: 1.3879235982894897
test loss item: 0.32630833983421326
test loss item: 0.14844253659248352
test loss item: 0.07705257087945938
test loss item: 0.9426482915878296
test loss item: 0.7634084224700928
test loss item: 0.956031322479248
test loss item: 0.23353911936283112
test loss item: 0.15906843543052673
test loss item: 0.07522308826446533
test loss item: 0.05940818786621094
test loss item: 0.19316111505031586
Epoch [12/50], Training Loss: 0.2539, Testing Loss: 0.3371
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 13/50
train loss item: 0.21771058440208435
train loss item: 0.43539637327194214
train loss item: 0.11492655426263809
train loss item: 0.16325508058071136
train loss item: 0.11612852662801743
train loss item: 0.15541338920593262
train loss item: 0.1262352019548416
train loss item: 0.39171016216278076
train loss item: 0.07072782516479492
train loss item: 0.1510666310787201
train loss item: 0.149689719080925
train loss item: 0.13477672636508942
train loss item: 0.09876309335231781
train loss item: 0.3168158531188965
train loss item: 0.14018163084983826
train loss item: 0.25114330649375916
train loss item: 0.05859201028943062
train loss item: 0.10006225854158401
train loss item: 0.21887090802192688
train loss item: 0.13724768161773682
train loss item: 0.09244368970394135
train loss item: 0.09860293567180634
train loss item: 0.23336532711982727
train loss item: 0.30506569147109985
train loss item: 0.25658637285232544
train loss item: 0.14970742166042328
train loss item: 0.06547129899263382
train loss item: 0.13854224979877472
train loss item: 0.0543159618973732
train loss item: 0.3014557361602783
train loss item: 0.3881876766681671
train loss item: 0.3297916352748871
train loss item: 0.05923115089535713
train loss item: 0.1366703361272812
train loss item: 0.11984729021787643
train loss item: 0.5238679647445679
train loss item: 0.4428534209728241
train loss item: 0.4151557981967926
train loss item: 0.24441100656986237
train loss item: 0.14083677530288696
train loss item: 0.16839003562927246
train loss item: 0.17275774478912354
train loss item: 0.29021427035331726
train loss item: 0.200368732213974
train loss item: 0.2952028512954712
train loss item: 0.08763039857149124
train loss item: 0.08461236208677292
train loss item: 0.47570136189460754
train loss item: 0.17740969359874725
train loss item: 0.11146688461303711
train loss item: 0.32229122519493103
train loss item: 0.7616666555404663
train loss item: 0.06899667531251907
train loss item: 0.11465087532997131
train loss item: 0.6102120280265808
train loss item: 0.11427821964025497
train loss item: 0.14609040319919586
train loss item: 0.12576532363891602
train loss item: 0.11829321831464767
train loss item: 0.12743735313415527
train loss item: 0.43363094329833984
train loss item: 0.5494062900543213
train loss item: 0.1095196083188057
train loss item: 0.1699594408273697
train loss item: 0.13134649395942688
train loss item: 0.3390687108039856
train loss item: 0.18697525560855865
train loss item: 0.16118934750556946
train loss item: 0.15953896939754486
train loss item: 0.12454628944396973
train loss item: 0.09016264230012894
train loss item: 0.06508441269397736
train loss item: 0.11784226447343826
train loss item: 0.2133072465658188
train loss item: 0.09221870452165604
train loss item: 0.10464926064014435
train loss item: 0.3522138297557831
train loss item: 1.0607366561889648
train loss item: 0.0553295873105526
train loss item: 0.19328951835632324
train loss item: 0.055688027292490005
train loss item: 0.0884908065199852
train loss item: 0.09878119826316833
train loss item: 0.34998559951782227
train loss item: 0.3163440227508545
train loss item: 0.24817737936973572
train loss item: 1.3317431211471558
train loss item: 0.06494046747684479
train loss item: 0.185164213180542
test loss item: 0.12528985738754272
test loss item: 0.07786860316991806
test loss item: 0.4661005437374115
test loss item: 0.15236714482307434
test loss item: 0.1673877239227295
test loss item: 0.0902276262640953
test loss item: 1.4480907917022705
test loss item: 0.46097058057785034
test loss item: 0.16140994429588318
test loss item: 0.24318328499794006
test loss item: 0.7001270651817322
test loss item: 0.10088426619768143
test loss item: 0.12122299522161484
test loss item: 0.1768382042646408
test loss item: 0.124311663210392
test loss item: 0.06340856850147247
test loss item: 0.22898000478744507
test loss item: 0.2737937271595001
test loss item: 0.4953633248806
test loss item: 0.20588523149490356
test loss item: 0.44145217537879944
test loss item: 0.3037492334842682
test loss item: 0.1946256160736084
test loss item: 0.14771676063537598
test loss item: 0.13384458422660828
test loss item: 0.16474328935146332
test loss item: 0.2126467227935791
test loss item: 0.11398304253816605
test loss item: 0.22079384326934814
test loss item: 0.20571032166481018
test loss item: 0.6681832075119019
test loss item: 0.06615600734949112
test loss item: 0.1281159520149231
test loss item: 0.3498665690422058
test loss item: 0.28480175137519836
test loss item: 0.26065772771835327
test loss item: 0.6027362942695618
test loss item: 1.2107871770858765
test loss item: 0.29856204986572266
test loss item: 0.22364681959152222
test loss item: 0.24229738116264343
test loss item: 0.1162278950214386
test loss item: 0.20200888812541962
test loss item: 0.17511004209518433
test loss item: 0.3409038484096527
test loss item: 0.31810978055000305
test loss item: 0.17539572715759277
test loss item: 0.16168443858623505
test loss item: 0.34216588735580444
test loss item: 0.5056378245353699
test loss item: 0.17956840991973877
test loss item: 0.09672373533248901
test loss item: 0.17269311845302582
test loss item: 0.10073859989643097
test loss item: 0.18720974028110504
test loss item: 0.6492849588394165
test loss item: 0.4108675718307495
test loss item: 0.16356851160526276
test loss item: 0.17858906090259552
test loss item: 0.10832864046096802
test loss item: 0.24827724695205688
test loss item: 0.2151564210653305
test loss item: 0.16079698503017426
test loss item: 0.1690002977848053
test loss item: 0.7722184658050537
test loss item: 0.19397862255573273
test loss item: 0.24470731616020203
test loss item: 0.192879781126976
test loss item: 0.35408586263656616
test loss item: 0.32243382930755615
test loss item: 0.05255028232932091
test loss item: 0.8353014588356018
test loss item: 0.20577427744865417
test loss item: 0.3285713195800781
test loss item: 0.11447534710168839
test loss item: 0.10906518995761871
test loss item: 0.14766322076320648
test loss item: 1.3583273887634277
test loss item: 0.30559951066970825
test loss item: 0.11688492447137833
test loss item: 0.0686262771487236
test loss item: 0.8571158051490784
test loss item: 0.6507377028465271
test loss item: 0.9254705309867859
test loss item: 0.1565963476896286
test loss item: 0.15170235931873322
test loss item: 0.07120748609304428
test loss item: 0.06708226352930069
test loss item: 0.10748298466205597
Epoch [13/50], Training Loss: 0.2255, Testing Loss: 0.2972
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 14/50
train loss item: 0.22879812121391296
train loss item: 0.28945422172546387
train loss item: 0.08119107037782669
train loss item: 0.1748272180557251
train loss item: 0.133629709482193
train loss item: 0.13637831807136536
train loss item: 0.08279833942651749
train loss item: 0.4362037479877472
train loss item: 0.06082773953676224
train loss item: 0.12982745468616486
train loss item: 0.13587455451488495
train loss item: 0.12797094881534576
train loss item: 0.08356161415576935
train loss item: 0.3053017556667328
train loss item: 0.1407175213098526
train loss item: 0.3586984872817993
train loss item: 0.05080442130565643
train loss item: 0.08856088668107986
train loss item: 0.18033543229103088
train loss item: 0.17485712468624115
train loss item: 0.08408791571855545
train loss item: 0.11688409745693207
train loss item: 0.22816824913024902
train loss item: 0.37104105949401855
train loss item: 0.22210045158863068
train loss item: 0.1449749767780304
train loss item: 0.10590548813343048
train loss item: 0.12647265195846558
train loss item: 0.0597744956612587
train loss item: 0.2566951811313629
train loss item: 0.546040415763855
train loss item: 0.1999342441558838
train loss item: 0.08000301569700241
train loss item: 0.17551198601722717
train loss item: 0.0796084925532341
train loss item: 0.4867728650569916
train loss item: 0.36364179849624634
train loss item: 0.33092784881591797
train loss item: 0.3577861487865448
train loss item: 0.13979946076869965
train loss item: 0.13780266046524048
train loss item: 0.12969331443309784
train loss item: 0.2306957244873047
train loss item: 0.1735578030347824
train loss item: 0.3775078356266022
train loss item: 0.0733359232544899
train loss item: 0.05107566714286804
train loss item: 0.2921631336212158
train loss item: 0.13932107388973236
train loss item: 0.07289185374975204
train loss item: 0.1473466157913208
train loss item: 0.4347417652606964
train loss item: 0.04752852022647858
train loss item: 0.08627757430076599
train loss item: 0.47227731347084045
train loss item: 0.08283409476280212
train loss item: 0.13548186421394348
train loss item: 0.125528946518898
train loss item: 0.07919502258300781
train loss item: 0.10568689554929733
train loss item: 0.2672470808029175
train loss item: 0.5391870141029358
train loss item: 0.09376993030309677
train loss item: 0.16577468812465668
train loss item: 0.07932665199041367
train loss item: 0.19900000095367432
train loss item: 0.1401287466287613
train loss item: 0.09093033522367477
train loss item: 0.21620021760463715
train loss item: 0.1098528578877449
train loss item: 0.09462641179561615
train loss item: 0.05409843474626541
train loss item: 0.0688445195555687
train loss item: 0.11330104619264603
train loss item: 0.05579535290598869
train loss item: 0.07429704815149307
train loss item: 0.1918061226606369
train loss item: 0.8659849166870117
train loss item: 0.042791418731212616
train loss item: 0.1321452558040619
train loss item: 0.07041346281766891
train loss item: 0.08424749970436096
train loss item: 0.10022414475679398
train loss item: 0.31905126571655273
train loss item: 0.2752280831336975
train loss item: 0.18334178626537323
train loss item: 1.2298328876495361
train loss item: 0.05414307489991188
train loss item: 0.16578415036201477
test loss item: 0.14469526708126068
test loss item: 0.06982094049453735
test loss item: 0.38013598322868347
test loss item: 0.16806723177433014
test loss item: 0.14253069460391998
test loss item: 0.09585759788751602
test loss item: 1.6494773626327515
test loss item: 0.5770508646965027
test loss item: 0.15106390416622162
test loss item: 0.22318428754806519
test loss item: 0.5433123707771301
test loss item: 0.12352965772151947
test loss item: 0.13912463188171387
test loss item: 0.2599703371524811
test loss item: 0.11068271845579147
test loss item: 0.06490682810544968
test loss item: 0.26464372873306274
test loss item: 0.22632896900177002
test loss item: 0.5417923331260681
test loss item: 0.25136351585388184
test loss item: 0.364712655544281
test loss item: 0.35435086488723755
test loss item: 0.21663294732570648
test loss item: 0.1674596071243286
test loss item: 0.14464052021503448
test loss item: 0.1904117465019226
test loss item: 0.23097698390483856
test loss item: 0.11368316411972046
test loss item: 0.22466762363910675
test loss item: 0.20523813366889954
test loss item: 0.6572105288505554
test loss item: 0.07149510085582733
test loss item: 0.13802731037139893
test loss item: 0.28753530979156494
test loss item: 0.22865258157253265
test loss item: 0.27444231510162354
test loss item: 0.6608221530914307
test loss item: 0.8843079209327698
test loss item: 0.2808067500591278
test loss item: 0.2525315582752228
test loss item: 0.27195942401885986
test loss item: 0.15838158130645752
test loss item: 0.15870806574821472
test loss item: 0.20964963734149933
test loss item: 0.30456632375717163
test loss item: 0.3669816851615906
test loss item: 0.19883985817432404
test loss item: 0.21692444384098053
test loss item: 0.31995710730552673
test loss item: 0.46399345993995667
test loss item: 0.17056649923324585
test loss item: 0.1175498440861702
test loss item: 0.18767504394054413
test loss item: 0.1336476057767868
test loss item: 0.1665256917476654
test loss item: 0.49082502722740173
test loss item: 0.41949039697647095
test loss item: 0.17533570528030396
test loss item: 0.19969791173934937
test loss item: 0.10871350020170212
test loss item: 0.19359177350997925
test loss item: 0.2612570524215698
test loss item: 0.20765458047389984
test loss item: 0.17815729975700378
test loss item: 0.6765593886375427
test loss item: 0.21062031388282776
test loss item: 0.2814938724040985
test loss item: 0.20883485674858093
test loss item: 0.28032663464546204
test loss item: 0.36428308486938477
test loss item: 0.05838021636009216
test loss item: 0.9724555611610413
test loss item: 0.2610195577144623
test loss item: 0.3956594169139862
test loss item: 0.1418217569589615
test loss item: 0.14730800688266754
test loss item: 0.1663622260093689
test loss item: 0.9983164668083191
test loss item: 0.3230994939804077
test loss item: 0.1406686007976532
test loss item: 0.08088099956512451
test loss item: 0.8002238869667053
test loss item: 0.6961257457733154
test loss item: 0.7066823840141296
test loss item: 0.19031353294849396
test loss item: 0.17256321012973785
test loss item: 0.07496318966150284
test loss item: 0.07386181503534317
test loss item: 0.11590823531150818
Epoch [14/50], Training Loss: 0.1949, Testing Loss: 0.2955
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 15/50
train loss item: 0.1872558742761612
train loss item: 0.5628393292427063
train loss item: 0.10940367728471756
train loss item: 0.17034591734409332
train loss item: 0.14835615456104279
train loss item: 0.13607557117938995
train loss item: 0.08175952732563019
train loss item: 0.18240053951740265
train loss item: 0.07703321427106857
train loss item: 0.12740731239318848
train loss item: 0.12345851212739944
train loss item: 0.13402846455574036
train loss item: 0.07808335870504379
train loss item: 0.3031596839427948
train loss item: 0.12634553015232086
train loss item: 0.2892032563686371
train loss item: 0.040134675800800323
train loss item: 0.09061085432767868
train loss item: 0.2052665501832962
train loss item: 0.1240113154053688
train loss item: 0.07302819192409515
train loss item: 0.126677006483078
train loss item: 0.3670872151851654
train loss item: 0.24978241324424744
train loss item: 0.2248891144990921
train loss item: 0.12749908864498138
train loss item: 0.06831296533346176
train loss item: 0.092568039894104
train loss item: 0.05040441453456879
train loss item: 0.24781113862991333
train loss item: 0.3992539942264557
train loss item: 0.22650061547756195
train loss item: 0.07699742168188095
train loss item: 0.15720029175281525
train loss item: 0.07773035019636154
train loss item: 0.4400211572647095
train loss item: 0.16289669275283813
train loss item: 0.26435840129852295
train loss item: 0.17251066863536835
train loss item: 0.1125364825129509
train loss item: 0.15348762273788452
train loss item: 0.1423032283782959
train loss item: 0.22689062356948853
train loss item: 0.134139284491539
train loss item: 0.2845548093318939
train loss item: 0.07116568088531494
train loss item: 0.05322924256324768
train loss item: 0.20580726861953735
train loss item: 0.11156119406223297
train loss item: 0.07165137678384781
train loss item: 0.11978355050086975
train loss item: 0.3753785789012909
train loss item: 0.04817787930369377
train loss item: 0.09856744855642319
train loss item: 0.3426455855369568
train loss item: 0.0968327447772026
train loss item: 0.1406569480895996
train loss item: 0.11464565247297287
train loss item: 0.07205168902873993
train loss item: 0.0990978330373764
train loss item: 0.26238372921943665
train loss item: 0.3774847090244293
train loss item: 0.0832851380109787
train loss item: 0.15723204612731934
train loss item: 0.09246662259101868
train loss item: 0.2979279160499573
train loss item: 0.16116555035114288
train loss item: 0.13051848113536835
train loss item: 0.19934126734733582
train loss item: 0.12045005708932877
train loss item: 0.10035338997840881
train loss item: 0.06009545549750328
train loss item: 0.08243297040462494
train loss item: 0.15028677880764008
train loss item: 0.05336588993668556
train loss item: 0.06797569245100021
train loss item: 0.20024913549423218
train loss item: 0.8735904097557068
train loss item: 0.051740579307079315
train loss item: 0.1270514875650406
train loss item: 0.06887353956699371
train loss item: 0.11450013518333435
train loss item: 0.10860452800989151
train loss item: 0.3274519443511963
train loss item: 0.3264579176902771
train loss item: 0.1879800707101822
train loss item: 1.04713773727417
train loss item: 0.059314195066690445
train loss item: 0.15320944786071777
test loss item: 0.17579518258571625
test loss item: 0.13597364723682404
test loss item: 0.447582483291626
test loss item: 0.20030727982521057
test loss item: 0.19412411749362946
test loss item: 0.15560629963874817
test loss item: 1.6697322130203247
test loss item: 0.585983395576477
test loss item: 0.17964158952236176
test loss item: 0.24917097389698029
test loss item: 0.6561000943183899
test loss item: 0.13688230514526367
test loss item: 0.1512060910463333
test loss item: 0.23415493965148926
test loss item: 0.17404121160507202
test loss item: 0.09961975365877151
test loss item: 0.2689240872859955
test loss item: 0.2699939012527466
test loss item: 0.5564002990722656
test loss item: 0.2599831223487854
test loss item: 0.4208436608314514
test loss item: 0.3545278310775757
test loss item: 0.23498034477233887
test loss item: 0.20898960530757904
test loss item: 0.16245056688785553
test loss item: 0.19967833161354065
test loss item: 0.2599014341831207
test loss item: 0.15782645344734192
test loss item: 0.2552470564842224
test loss item: 0.22839047014713287
test loss item: 0.7084547281265259
test loss item: 0.09677809476852417
test loss item: 0.19387145340442657
test loss item: 0.33688658475875854
test loss item: 0.2773226499557495
test loss item: 0.2922898232936859
test loss item: 0.6741085648536682
test loss item: 1.106997013092041
test loss item: 0.3115253150463104
test loss item: 0.2787680923938751
test loss item: 0.27311742305755615
test loss item: 0.17171062529087067
test loss item: 0.19161005318164825
test loss item: 0.21288497745990753
test loss item: 0.3357484042644501
test loss item: 0.3737269341945648
test loss item: 0.2120605856180191
test loss item: 0.22279171645641327
test loss item: 0.3526124358177185
test loss item: 0.5186507105827332
test loss item: 0.18503788113594055
test loss item: 0.14411786198616028
test loss item: 0.1953863650560379
test loss item: 0.14534682035446167
test loss item: 0.1933605670928955
test loss item: 0.5973883867263794
test loss item: 0.4584371745586395
test loss item: 0.1731480360031128
test loss item: 0.223002627491951
test loss item: 0.11533617973327637
test loss item: 0.2390507459640503
test loss item: 0.2700779139995575
test loss item: 0.21481971442699432
test loss item: 0.18002845346927643
test loss item: 0.7709319591522217
test loss item: 0.2181163728237152
test loss item: 0.296244353055954
test loss item: 0.2116936594247818
test loss item: 0.32779577374458313
test loss item: 0.37772616744041443
test loss item: 0.08870405703783035
test loss item: 0.9771232008934021
test loss item: 0.26609987020492554
test loss item: 0.4027053415775299
test loss item: 0.15877652168273926
test loss item: 0.16395558416843414
test loss item: 0.20288747549057007
test loss item: 1.2469414472579956
test loss item: 0.3372592329978943
test loss item: 0.17070409655570984
test loss item: 0.12003102153539658
test loss item: 0.8816145658493042
test loss item: 0.7191604375839233
test loss item: 0.8631319999694824
test loss item: 0.2073940485715866
test loss item: 0.19066302478313446
test loss item: 0.11914043873548508
test loss item: 0.11097951233386993
test loss item: 0.1516726016998291
Epoch [15/50], Training Loss: 0.1800, Testing Loss: 0.3297
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 16/50
train loss item: 0.19280515611171722
train loss item: 0.38552170991897583
train loss item: 0.08935292065143585
train loss item: 0.14607271552085876
train loss item: 0.09226153045892715
train loss item: 0.11498887836933136
train loss item: 0.0841159075498581
train loss item: 0.16784347593784332
train loss item: 0.06457589566707611
train loss item: 0.10788829624652863
train loss item: 0.11617820709943771
train loss item: 0.11659625172615051
train loss item: 0.07531096786260605
train loss item: 0.26270273327827454
train loss item: 0.11617416888475418
train loss item: 0.21014784276485443
train loss item: 0.039363179355859756
train loss item: 0.08177506178617477
train loss item: 0.15083704888820648
train loss item: 0.12300799041986465
train loss item: 0.07944516092538834
train loss item: 0.10012339800596237
train loss item: 0.2000391036272049
train loss item: 0.3601855933666229
train loss item: 0.1877739429473877
train loss item: 0.11678671836853027
train loss item: 0.06439884752035141
train loss item: 0.11973842978477478
train loss item: 0.041176971048116684
train loss item: 0.24014852941036224
train loss item: 0.5522999167442322
train loss item: 0.20123670995235443
train loss item: 0.06865991652011871
train loss item: 0.13415957987308502
train loss item: 0.09098482131958008
train loss item: 0.4076278805732727
train loss item: 0.3285706639289856
train loss item: 0.31641897559165955
train loss item: 0.35052940249443054
train loss item: 0.19466164708137512
train loss item: 0.1546216607093811
train loss item: 0.16449542343616486
train loss item: 0.2515221834182739
train loss item: 0.18088841438293457
train loss item: 0.3342660069465637
train loss item: 0.07977975159883499
train loss item: 0.04923221468925476
train loss item: 0.3614136576652527
train loss item: 0.17587421834468842
train loss item: 0.09884560853242874
train loss item: 0.23735156655311584
train loss item: 0.5261152982711792
train loss item: 0.06109509989619255
train loss item: 0.10956878215074539
train loss item: 0.40645626187324524
train loss item: 0.08048495650291443
train loss item: 0.15435537695884705
train loss item: 0.10556968301534653
train loss item: 0.07374395430088043
train loss item: 0.1078430563211441
train loss item: 0.2476850152015686
train loss item: 0.5597000122070312
train loss item: 0.09315028041601181
train loss item: 0.16725702583789825
train loss item: 0.08163528144359589
train loss item: 0.21172887086868286
train loss item: 0.13897088170051575
train loss item: 0.10216466337442398
train loss item: 0.21129903197288513
train loss item: 0.10234946757555008
train loss item: 0.09739665687084198
train loss item: 0.06544660776853561
train loss item: 0.06997387856245041
train loss item: 0.1336987167596817
train loss item: 0.06294289976358414
train loss item: 0.07461799681186676
train loss item: 0.24162425100803375
train loss item: 0.861598789691925
train loss item: 0.03911803290247917
train loss item: 0.1002512201666832
train loss item: 0.06527011096477509
train loss item: 0.09402694553136826
train loss item: 0.10519416630268097
train loss item: 0.3461727797985077
train loss item: 0.26062390208244324
train loss item: 0.1724972426891327
train loss item: 1.1045173406600952
train loss item: 0.0609392486512661
train loss item: 0.1524270921945572
test loss item: 0.14151589572429657
test loss item: 0.08686712384223938
test loss item: 0.42063775658607483
test loss item: 0.1687876582145691
test loss item: 0.158615380525589
test loss item: 0.1114475354552269
test loss item: 1.622194766998291
test loss item: 0.567914605140686
test loss item: 0.16127055883407593
test loss item: 0.24112679064273834
test loss item: 0.6313102841377258
test loss item: 0.11785615235567093
test loss item: 0.1412852704524994
test loss item: 0.2260676771402359
test loss item: 0.1273188441991806
test loss item: 0.06865131855010986
test loss item: 0.25695034861564636
test loss item: 0.24886450171470642
test loss item: 0.5422293543815613
test loss item: 0.2424812912940979
test loss item: 0.3858117461204529
test loss item: 0.3432169258594513
test loss item: 0.22624367475509644
test loss item: 0.16940341889858246
test loss item: 0.14690947532653809
test loss item: 0.19480857253074646
test loss item: 0.22855140268802643
test loss item: 0.1228526160120964
test loss item: 0.22214971482753754
test loss item: 0.2148241549730301
test loss item: 0.6885913014411926
test loss item: 0.06701206415891647
test loss item: 0.14620018005371094
test loss item: 0.32152387499809265
test loss item: 0.25353366136550903
test loss item: 0.2848935127258301
test loss item: 0.6573166251182556
test loss item: 1.056634783744812
test loss item: 0.29174625873565674
test loss item: 0.24381151795387268
test loss item: 0.2594679594039917
test loss item: 0.16433672606945038
test loss item: 0.19070960581302643
test loss item: 0.2029111087322235
test loss item: 0.3083634078502655
test loss item: 0.3514479696750641
test loss item: 0.20204845070838928
test loss item: 0.20277145504951477
test loss item: 0.3377191722393036
test loss item: 0.5026373267173767
test loss item: 0.18248817324638367
test loss item: 0.12091655284166336
test loss item: 0.1912260204553604
test loss item: 0.132064551115036
test loss item: 0.1903129369020462
test loss item: 0.5683922171592712
test loss item: 0.4347774088382721
test loss item: 0.17551541328430176
test loss item: 0.20290425419807434
test loss item: 0.1196831539273262
test loss item: 0.2385374903678894
test loss item: 0.2562638819217682
test loss item: 0.20748592913150787
test loss item: 0.16411751508712769
test loss item: 0.7157629132270813
test loss item: 0.20454244315624237
test loss item: 0.2831862270832062
test loss item: 0.1979437917470932
test loss item: 0.30799323320388794
test loss item: 0.38250869512557983
test loss item: 0.06532522290945053
test loss item: 0.9464700818061829
test loss item: 0.25555184483528137
test loss item: 0.3808729648590088
test loss item: 0.14415684342384338
test loss item: 0.15251009166240692
test loss item: 0.1669650822877884
test loss item: 1.1686733961105347
test loss item: 0.31415075063705444
test loss item: 0.1441906988620758
test loss item: 0.09174223244190216
test loss item: 0.8481190800666809
test loss item: 0.7081415057182312
test loss item: 0.8158591389656067
test loss item: 0.20260800421237946
test loss item: 0.1740265190601349
test loss item: 0.08540958166122437
test loss item: 0.07425901293754578
test loss item: 0.14024288952350616
Epoch [16/50], Training Loss: 0.1869, Testing Loss: 0.3082
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 17/50
train loss item: 0.17914627492427826
train loss item: 0.42025840282440186
train loss item: 0.09859857708215714
train loss item: 0.17777323722839355
train loss item: 0.09240857511758804
train loss item: 0.13101866841316223
train loss item: 0.07073551416397095
train loss item: 0.3132063150405884
train loss item: 0.08463778346776962
train loss item: 0.10527125746011734
train loss item: 0.1194673627614975
train loss item: 0.11839081346988678
train loss item: 0.08001377433538437
train loss item: 0.3108116388320923
train loss item: 0.1234082505106926
train loss item: 0.28708094358444214
train loss item: 0.03972700983285904
train loss item: 0.07093863189220428
train loss item: 0.23951397836208344
train loss item: 0.10714052617549896
train loss item: 0.0711335837841034
train loss item: 0.10759245604276657
train loss item: 0.2724388837814331
train loss item: 0.30036842823028564
train loss item: 0.21096791326999664
train loss item: 0.14811725914478302
train loss item: 0.06713297218084335
train loss item: 0.10844463109970093
train loss item: 0.049594197422266006
train loss item: 0.2214198261499405
train loss item: 0.3154359757900238
train loss item: 0.22607415914535522
train loss item: 0.07028058916330338
train loss item: 0.12380637973546982
train loss item: 0.06178418919444084
train loss item: 0.38843539357185364
train loss item: 0.19602975249290466
train loss item: 0.24655044078826904
train loss item: 0.18434806168079376
train loss item: 0.14834074676036835
train loss item: 0.15353070199489594
train loss item: 0.18015293776988983
train loss item: 0.2224758416414261
train loss item: 0.13750720024108887
train loss item: 0.29258811473846436
train loss item: 0.09433892369270325
train loss item: 0.053185731172561646
train loss item: 0.19527097046375275
train loss item: 0.11393529176712036
train loss item: 0.07285985350608826
train loss item: 0.11108636856079102
train loss item: 0.3207958936691284
train loss item: 0.053682707250118256
train loss item: 0.098020538687706
train loss item: 0.359958678483963
train loss item: 0.11304797977209091
train loss item: 0.13896872103214264
train loss item: 0.10310912132263184
train loss item: 0.06539302319288254
train loss item: 0.0866013765335083
train loss item: 0.2659611701965332
train loss item: 0.34998446702957153
train loss item: 0.08316586166620255
train loss item: 0.15614406764507294
train loss item: 0.10207389295101166
train loss item: 0.30958250164985657
train loss item: 0.18686969578266144
train loss item: 0.13906913995742798
train loss item: 0.15940488874912262
train loss item: 0.10474904626607895
train loss item: 0.0882035493850708
train loss item: 0.05885683372616768
train loss item: 0.08239255845546722
train loss item: 0.1646765023469925
train loss item: 0.06089917570352554
train loss item: 0.06989892572164536
train loss item: 0.22549955546855927
train loss item: 0.8490105271339417
train loss item: 0.037867628037929535
train loss item: 0.12186969071626663
train loss item: 0.05645420402288437
train loss item: 0.08930954337120056
train loss item: 0.10798168182373047
train loss item: 0.3845902383327484
train loss item: 0.37987080216407776
train loss item: 0.1927134245634079
train loss item: 0.9139693975448608
train loss item: 0.056529466062784195
train loss item: 0.14894644916057587
test loss item: 0.1650734841823578
test loss item: 0.1132141575217247
test loss item: 0.4481979012489319
test loss item: 0.18894219398498535
test loss item: 0.18316298723220825
test loss item: 0.13818620145320892
test loss item: 1.5936332941055298
test loss item: 0.5583417415618896
test loss item: 0.17179931700229645
test loss item: 0.24980752170085907
test loss item: 0.6483649015426636
test loss item: 0.13168026506900787
test loss item: 0.15533114969730377
test loss item: 0.26724696159362793
test loss item: 0.15287421643733978
test loss item: 0.0718202069401741
test loss item: 0.27495190501213074
test loss item: 0.2689310908317566
test loss item: 0.5324448943138123
test loss item: 0.2726992666721344
test loss item: 0.4070756435394287
test loss item: 0.35133928060531616
test loss item: 0.25174880027770996
test loss item: 0.1924632340669632
test loss item: 0.15882983803749084
test loss item: 0.20100754499435425
test loss item: 0.2567216455936432
test loss item: 0.14417393505573273
test loss item: 0.24961957335472107
test loss item: 0.23206041753292084
test loss item: 0.6917446255683899
test loss item: 0.067453533411026
test loss item: 0.173970565199852
test loss item: 0.3424072563648224
test loss item: 0.26926788687705994
test loss item: 0.2847915589809418
test loss item: 0.6446840763092041
test loss item: 1.104648232460022
test loss item: 0.3079705536365509
test loss item: 0.26801663637161255
test loss item: 0.27118831872940063
test loss item: 0.194939523935318
test loss item: 0.195784792304039
test loss item: 0.21529719233512878
test loss item: 0.32551103830337524
test loss item: 0.37935537099838257
test loss item: 0.2285914570093155
test loss item: 0.23361867666244507
test loss item: 0.35748451948165894
test loss item: 0.5191375613212585
test loss item: 0.17549027502536774
test loss item: 0.13899041712284088
test loss item: 0.1970866322517395
test loss item: 0.14656013250350952
test loss item: 0.1885770857334137
test loss item: 0.5968165993690491
test loss item: 0.4402461647987366
test loss item: 0.16630049049854279
test loss item: 0.2184542715549469
test loss item: 0.11681023985147476
test loss item: 0.24672815203666687
test loss item: 0.27019232511520386
test loss item: 0.22233104705810547
test loss item: 0.18110033869743347
test loss item: 0.7437442541122437
test loss item: 0.21524710953235626
test loss item: 0.3054564893245697
test loss item: 0.21068844199180603
test loss item: 0.3279708921909332
test loss item: 0.37424972653388977
test loss item: 0.06819026917219162
test loss item: 0.9394587278366089
test loss item: 0.28612539172172546
test loss item: 0.4129341244697571
test loss item: 0.16146442294120789
test loss item: 0.17561817169189453
test loss item: 0.18590614199638367
test loss item: 1.2369797229766846
test loss item: 0.35713645815849304
test loss item: 0.17138245701789856
test loss item: 0.09229213744401932
test loss item: 0.8647435307502747
test loss item: 0.6926484704017639
test loss item: 0.8562744855880737
test loss item: 0.2157578319311142
test loss item: 0.19971215724945068
test loss item: 0.08897782862186432
test loss item: 0.07543394714593887
test loss item: 0.15511606633663177
Epoch [17/50], Training Loss: 0.1753, Testing Loss: 0.3239
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.2752629220485687
loss item: 0.1911391168832779
loss item: 1.2763817310333252
loss item: 0.5657000541687012
loss item: 0.4915601909160614
loss item: 0.39522841572761536
loss item: 0.12880918383598328
loss item: 0.7001072764396667
loss item: 0.2182370126247406
loss item: 0.1496203988790512
loss item: 0.9035441279411316
loss item: 0.07489189505577087
loss item: 0.7798736691474915
loss item: 0.18412040174007416
loss item: 0.20488493144512177
loss item: 0.18636463582515717
loss item: 0.3303954303264618
loss item: 0.404796302318573
loss item: 0.747265100479126
loss item: 0.40698525309562683
loss item: 0.25075986981391907
loss item: 0.2401188313961029
loss item: 0.300721138715744
loss item: 0.2626732885837555
loss item: 0.21335667371749878
loss item: 0.5849506258964539
loss item: 0.8783235549926758
loss item: 0.12755218148231506
loss item: 0.12308068573474884
loss item: 0.4085859954357147
loss item: 0.9008670449256897
loss item: 1.2574583292007446
loss item: 0.13206824660301208
loss item: 0.4792412519454956
loss item: 0.15498948097229004
loss item: 0.19901567697525024
loss item: 0.24684542417526245
loss item: 0.23901700973510742
loss item: 0.38250643014907837
loss item: 0.5913411378860474
loss item: 0.7910870313644409
loss item: 0.31175997853279114
loss item: 0.20504426956176758
loss item: 0.0706518366932869
Val Loss: 0.4083
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 50, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.001 2 360 done at Tue Nov 12 10:21:55 CET 2024
UNet2 with 1 50 0.005 2 360 start at Tue Nov 12 10:21:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 50, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 0.9121710062026978
train loss item: 2.3596537113189697
train loss item: 0.6951392889022827
train loss item: 1.2938249111175537
train loss item: 1.4231724739074707
train loss item: 0.5039922595024109
train loss item: 0.43074434995651245
train loss item: 1.4261348247528076
train loss item: 0.28414613008499146
train loss item: 0.5675510168075562
train loss item: 0.6910601854324341
train loss item: 0.42026352882385254
train loss item: 0.1324857473373413
train loss item: 0.8068372011184692
train loss item: 0.3840419054031372
train loss item: 1.257371425628662
train loss item: 0.08779767155647278
train loss item: 0.49915456771850586
train loss item: 0.6628166437149048
train loss item: 0.5061546564102173
train loss item: 0.40896642208099365
train loss item: 0.18529468774795532
train loss item: 1.878562569618225
train loss item: 1.4219703674316406
train loss item: 0.9907299280166626
train loss item: 0.4101291298866272
train loss item: 0.286479115486145
train loss item: 0.47881534695625305
train loss item: 0.19234693050384521
train loss item: 1.4333579540252686
train loss item: 3.288198947906494
train loss item: 0.9111039042472839
train loss item: 0.137279212474823
train loss item: 0.7027220129966736
train loss item: 0.20527304708957672
train loss item: 2.921581983566284
train loss item: 0.7213185429573059
train loss item: 0.5303860306739807
train loss item: 0.7365942597389221
train loss item: 0.36719605326652527
train loss item: 0.31795549392700195
train loss item: 0.3771492540836334
train loss item: 0.4621357321739197
train loss item: 0.2473013550043106
train loss item: 0.7756121754646301
train loss item: 0.32356515526771545
train loss item: 0.17513719201087952
train loss item: 0.6990630626678467
train loss item: 0.31837934255599976
train loss item: 0.16912858188152313
train loss item: 0.5299562811851501
train loss item: 1.499110460281372
train loss item: 0.0681602880358696
train loss item: 0.2920112609863281
train loss item: 2.7292673587799072
train loss item: 0.29725366830825806
train loss item: 0.3225564956665039
train loss item: 0.3299453556537628
train loss item: 0.24271030724048615
train loss item: 0.17768913507461548
train loss item: 1.4162005186080933
train loss item: 2.4564168453216553
train loss item: 0.3873443305492401
train loss item: 0.625148594379425
train loss item: 0.23776280879974365
train loss item: 0.930720865726471
train loss item: 0.43830034136772156
train loss item: 0.2984105348587036
train loss item: 0.4311758875846863
train loss item: 0.45804911851882935
train loss item: 0.3682411313056946
train loss item: 0.5147370100021362
train loss item: 0.3530140519142151
train loss item: 0.41604140400886536
train loss item: 0.1211424469947815
train loss item: 0.13685491681098938
train loss item: 1.329099178314209
train loss item: 1.9581820964813232
train loss item: 0.1391196846961975
train loss item: 0.5035191774368286
train loss item: 0.2037416398525238
train loss item: 0.3330010771751404
train loss item: 0.2958652079105377
train loss item: 1.196373462677002
train loss item: 0.6154637932777405
train loss item: 1.0099682807922363
train loss item: 4.918233394622803
train loss item: 0.20143809914588928
train loss item: 0.4690376818180084
test loss item: 0.2219582051038742
test loss item: 0.18020641803741455
test loss item: 0.8305428624153137
test loss item: 0.29015976190567017
test loss item: 0.44809016585350037
test loss item: 0.3841785490512848
test loss item: 2.8382318019866943
test loss item: 0.9022160172462463
test loss item: 0.3301982283592224
test loss item: 0.5667122006416321
test loss item: 1.2469464540481567
test loss item: 0.22060108184814453
test loss item: 0.26215502619743347
test loss item: 0.4469398558139801
test loss item: 0.2549419701099396
test loss item: 0.10355199128389359
test loss item: 0.4048226773738861
test loss item: 0.6440994143486023
test loss item: 0.9782863855361938
test loss item: 0.41897228360176086
test loss item: 0.9918761253356934
test loss item: 0.5558953285217285
test loss item: 0.39206233620643616
test loss item: 0.2843523323535919
test loss item: 0.29935961961746216
test loss item: 0.3395402729511261
test loss item: 0.46730926632881165
test loss item: 0.4087378680706024
test loss item: 0.5005202293395996
test loss item: 0.4869081377983093
test loss item: 1.272813320159912
test loss item: 0.0923331081867218
test loss item: 0.2386859506368637
test loss item: 0.7520583271980286
test loss item: 0.6116223335266113
test loss item: 0.6288796067237854
test loss item: 1.2259260416030884
test loss item: 2.087797164916992
test loss item: 0.7095513343811035
test loss item: 0.5002447366714478
test loss item: 0.43840017914772034
test loss item: 0.232686847448349
test loss item: 0.4752911329269409
test loss item: 0.2972860634326935
test loss item: 0.8312079310417175
test loss item: 0.6241165399551392
test loss item: 0.37898731231689453
test loss item: 0.3276004195213318
test loss item: 0.6847848892211914
test loss item: 1.0320032835006714
test loss item: 0.46428340673446655
test loss item: 0.1756659746170044
test loss item: 0.36126548051834106
test loss item: 0.17397168278694153
test loss item: 0.4399870038032532
test loss item: 1.2349635362625122
test loss item: 0.8089830279350281
test loss item: 0.34216636419296265
test loss item: 0.33153754472732544
test loss item: 0.3150654733181
test loss item: 0.6090577244758606
test loss item: 0.3494621813297272
test loss item: 0.30517345666885376
test loss item: 0.3546837270259857
test loss item: 1.2856695652008057
test loss item: 0.36005106568336487
test loss item: 0.46664392948150635
test loss item: 0.37960925698280334
test loss item: 0.7078253626823425
test loss item: 0.6229697465896606
test loss item: 0.13950969278812408
test loss item: 1.6218185424804688
test loss item: 0.40837159752845764
test loss item: 0.6003850102424622
test loss item: 0.21454794704914093
test loss item: 0.23020243644714355
test loss item: 0.28600776195526123
test loss item: 2.1255815029144287
test loss item: 0.634545087814331
test loss item: 0.40892294049263
test loss item: 0.14562171697616577
test loss item: 1.483009696006775
test loss item: 1.3324593305587769
test loss item: 1.4933563470840454
test loss item: 0.3548557460308075
test loss item: 0.295806884765625
test loss item: 0.13297221064567566
test loss item: 0.0987270325422287
test loss item: 0.21032162010669708
Epoch [1/50], Training Loss: 0.7491, Testing Loss: 0.5893
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/50
train loss item: 0.5202454328536987
train loss item: 1.5883634090423584
train loss item: 0.497993528842926
train loss item: 0.6793892979621887
train loss item: 0.8560302257537842
train loss item: 0.43026456236839294
train loss item: 0.4020290672779083
train loss item: 0.9720221757888794
train loss item: 0.19187189638614655
train loss item: 0.4412691593170166
train loss item: 0.4472671151161194
train loss item: 0.40259650349617004
train loss item: 0.12438526749610901
train loss item: 0.6006274819374084
train loss item: 0.35987281799316406
train loss item: 1.1746416091918945
train loss item: 0.09646846354007721
train loss item: 0.454369455575943
train loss item: 0.5142753720283508
train loss item: 0.42070335149765015
train loss item: 0.35345950722694397
train loss item: 0.19133871793746948
train loss item: 1.6305735111236572
train loss item: 1.1478272676467896
train loss item: 0.8611868619918823
train loss item: 0.32433584332466125
train loss item: 0.274985134601593
train loss item: 0.3265416622161865
train loss item: 0.09623387455940247
train loss item: 1.0850087404251099
train loss item: 2.6649010181427
train loss item: 0.6644923090934753
train loss item: 0.17125748097896576
train loss item: 0.4613787531852722
train loss item: 0.23047718405723572
train loss item: 2.4294028282165527
train loss item: 0.618015706539154
train loss item: 0.5975621342658997
train loss item: 0.6129162907600403
train loss item: 0.2766493558883667
train loss item: 0.19486738741397858
train loss item: 0.42431560158729553
train loss item: 0.36129313707351685
train loss item: 0.326534628868103
train loss item: 0.9694086909294128
train loss item: 0.19816818833351135
train loss item: 0.1670057624578476
train loss item: 0.535385012626648
train loss item: 0.345824658870697
train loss item: 0.2181480973958969
train loss item: 0.3927725553512573
train loss item: 1.3726980686187744
train loss item: 0.10167425870895386
train loss item: 0.24732093513011932
train loss item: 2.681530237197876
train loss item: 0.251911997795105
train loss item: 0.4266429543495178
train loss item: 0.30946847796440125
train loss item: 0.20116759836673737
train loss item: 0.14426513016223907
train loss item: 1.1352858543395996
train loss item: 2.296191692352295
train loss item: 0.4044857621192932
train loss item: 0.5181435942649841
train loss item: 0.2885459363460541
train loss item: 0.814670741558075
train loss item: 0.45427295565605164
train loss item: 0.24297881126403809
train loss item: 0.405108779668808
train loss item: 0.4397752583026886
train loss item: 0.3088932931423187
train loss item: 0.13236850500106812
train loss item: 0.3402555286884308
train loss item: 0.3749471604824066
train loss item: 0.11623818427324295
train loss item: 0.15245972573757172
train loss item: 1.1686662435531616
train loss item: 1.4485774040222168
train loss item: 0.12536732852458954
train loss item: 0.389710396528244
train loss item: 0.1605888307094574
train loss item: 0.22646893560886383
train loss item: 0.28121575713157654
train loss item: 0.704188346862793
train loss item: 0.4369463324546814
train loss item: 0.841219961643219
train loss item: 4.46937370300293
train loss item: 0.17095257341861725
train loss item: 0.5888984799385071
test loss item: 0.19769255816936493
test loss item: 0.0942649096250534
test loss item: 0.6723519563674927
test loss item: 0.22790086269378662
test loss item: 0.277523398399353
test loss item: 0.12169263511896133
test loss item: 2.117636203765869
test loss item: 0.6954542398452759
test loss item: 0.26292651891708374
test loss item: 0.47967493534088135
test loss item: 1.081426978111267
test loss item: 0.1724182516336441
test loss item: 0.22273018956184387
test loss item: 0.4699592590332031
test loss item: 0.18151436746120453
test loss item: 0.07213879376649857
test loss item: 0.3515373766422272
test loss item: 0.5452346801757812
test loss item: 0.8478008508682251
test loss item: 0.38725021481513977
test loss item: 0.8558072447776794
test loss item: 0.4213946759700775
test loss item: 0.36695459485054016
test loss item: 0.19527073204517365
test loss item: 0.2558869421482086
test loss item: 0.27263879776000977
test loss item: 0.43619051575660706
test loss item: 0.2155897170305252
test loss item: 0.40131741762161255
test loss item: 0.4422595798969269
test loss item: 0.9593598246574402
test loss item: 0.05677281692624092
test loss item: 0.16253340244293213
test loss item: 0.6515146493911743
test loss item: 0.5107977986335754
test loss item: 0.5289648175239563
test loss item: 1.0168377161026
test loss item: 1.7878464460372925
test loss item: 0.5852097868919373
test loss item: 0.31551387906074524
test loss item: 0.3545512557029724
test loss item: 0.21288084983825684
test loss item: 0.41116949915885925
test loss item: 0.21858486533164978
test loss item: 0.7293254733085632
test loss item: 0.568227231502533
test loss item: 0.3336043059825897
test loss item: 0.3612881302833557
test loss item: 0.5520521998405457
test loss item: 0.8769135475158691
test loss item: 0.36052098870277405
test loss item: 0.163754403591156
test loss item: 0.2718210518360138
test loss item: 0.12377573549747467
test loss item: 0.34418946504592896
test loss item: 1.0379128456115723
test loss item: 0.6825181245803833
test loss item: 0.28922039270401
test loss item: 0.27751609683036804
test loss item: 0.23164941370487213
test loss item: 0.530247151851654
test loss item: 0.2786214053630829
test loss item: 0.25093621015548706
test loss item: 0.3104541599750519
test loss item: 1.017695426940918
test loss item: 0.31171780824661255
test loss item: 0.3992001414299011
test loss item: 0.31043270230293274
test loss item: 0.6117001175880432
test loss item: 0.54750657081604
test loss item: 0.07124567031860352
test loss item: 1.2598762512207031
test loss item: 0.40247833728790283
test loss item: 0.46082761883735657
test loss item: 0.18239380419254303
test loss item: 0.20163115859031677
test loss item: 0.19967348873615265
test loss item: 1.7460614442825317
test loss item: 0.622539222240448
test loss item: 0.21185313165187836
test loss item: 0.07482673972845078
test loss item: 1.1851370334625244
test loss item: 1.0874840021133423
test loss item: 1.2100516557693481
test loss item: 0.3177059292793274
test loss item: 0.25603145360946655
test loss item: 0.053947992622852325
test loss item: 0.046831440180540085
test loss item: 0.15674622356891632
Epoch [2/50], Training Loss: 0.6236, Testing Loss: 0.4790
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/50
train loss item: 0.49028417468070984
train loss item: 1.3115317821502686
train loss item: 0.39279410243034363
train loss item: 0.6456537842750549
train loss item: 0.465495765209198
train loss item: 0.3933671712875366
train loss item: 0.32648375630378723
train loss item: 0.7854472994804382
train loss item: 0.21777796745300293
train loss item: 0.33937060832977295
train loss item: 0.4432004392147064
train loss item: 0.4394850730895996
train loss item: 0.11775092035531998
train loss item: 0.539486289024353
train loss item: 0.3084419071674347
train loss item: 0.7759978771209717
train loss item: 0.10391057282686234
train loss item: 0.370320588350296
train loss item: 0.4265836775302887
train loss item: 0.3654240667819977
train loss item: 0.26950278878211975
train loss item: 0.18585674464702606
train loss item: 1.081381916999817
train loss item: 1.061638593673706
train loss item: 0.6936229467391968
train loss item: 0.34483766555786133
train loss item: 0.2925300598144531
train loss item: 0.3445080816745758
train loss item: 0.12254957109689713
train loss item: 0.7838624119758606
train loss item: 2.363412380218506
train loss item: 0.7274218797683716
train loss item: 0.12609991431236267
train loss item: 0.4490307867527008
train loss item: 0.13747958838939667
train loss item: 2.209709644317627
train loss item: 0.6788873672485352
train loss item: 0.5553525686264038
train loss item: 0.791489839553833
train loss item: 0.3154582679271698
train loss item: 0.23276060819625854
train loss item: 0.3659941554069519
train loss item: 0.3914089798927307
train loss item: 0.2991100549697876
train loss item: 0.8604167699813843
train loss item: 0.14656716585159302
train loss item: 0.14077314734458923
train loss item: 0.5139577388763428
train loss item: 0.35866042971611023
train loss item: 0.1874372661113739
train loss item: 0.4193404018878937
train loss item: 1.281272292137146
train loss item: 0.07926522940397263
train loss item: 0.24637846648693085
train loss item: 2.4829025268554688
train loss item: 0.25373953580856323
train loss item: 0.40718111395835876
train loss item: 0.2751636505126953
train loss item: 0.18783019483089447
train loss item: 0.1169891506433487
train loss item: 0.9700027108192444
train loss item: 2.0544557571411133
train loss item: 0.3362148702144623
train loss item: 0.5342836380004883
train loss item: 0.3059868812561035
train loss item: 0.773044764995575
train loss item: 0.5659810304641724
train loss item: 0.23036304116249084
train loss item: 0.40304967761039734
train loss item: 0.4529935419559479
train loss item: 0.313376784324646
train loss item: 0.14639060199260712
train loss item: 0.339115172624588
train loss item: 0.39757630228996277
train loss item: 0.0981898233294487
train loss item: 0.14713843166828156
train loss item: 1.2282283306121826
train loss item: 1.325297474861145
train loss item: 0.08313537389039993
train loss item: 0.39787110686302185
train loss item: 0.1820702701807022
train loss item: 0.23459705710411072
train loss item: 0.32694414258003235
train loss item: 0.6765772104263306
train loss item: 0.5157465934753418
train loss item: 0.99424147605896
train loss item: 4.605356693267822
train loss item: 0.287929892539978
train loss item: 0.43526536226272583
test loss item: 0.23402291536331177
test loss item: 0.09711204469203949
test loss item: 1.0367672443389893
test loss item: 0.2616322636604309
test loss item: 0.3511967957019806
test loss item: 0.17220932245254517
test loss item: 2.125265121459961
test loss item: 0.76502525806427
test loss item: 0.4095436930656433
test loss item: 0.6428482532501221
test loss item: 1.5001180171966553
test loss item: 0.18883852660655975
test loss item: 0.24032075703144073
test loss item: 0.49721840023994446
test loss item: 0.23130810260772705
test loss item: 0.06418707966804504
test loss item: 0.4085688292980194
test loss item: 0.720257580280304
test loss item: 0.897205114364624
test loss item: 0.42820456624031067
test loss item: 1.0863351821899414
test loss item: 0.47444427013397217
test loss item: 0.4241888225078583
test loss item: 0.22415444254875183
test loss item: 0.31206241250038147
test loss item: 0.2946537137031555
test loss item: 0.5082997679710388
test loss item: 0.2617953419685364
test loss item: 0.47532522678375244
test loss item: 0.5327207446098328
test loss item: 1.254262089729309
test loss item: 0.06734172254800797
test loss item: 0.19337117671966553
test loss item: 0.8416019678115845
test loss item: 0.7052162885665894
test loss item: 0.6594303846359253
test loss item: 1.097493290901184
test loss item: 2.627600908279419
test loss item: 0.7366380095481873
test loss item: 0.33963823318481445
test loss item: 0.36891990900039673
test loss item: 0.2895925045013428
test loss item: 0.543578028678894
test loss item: 0.26385411620140076
test loss item: 0.8945998549461365
test loss item: 0.6361622214317322
test loss item: 0.4230213463306427
test loss item: 0.3634369969367981
test loss item: 0.7734684348106384
test loss item: 1.1762841939926147
test loss item: 0.4732299745082855
test loss item: 0.16771475970745087
test loss item: 0.3451259732246399
test loss item: 0.1899220049381256
test loss item: 0.4573378562927246
test loss item: 1.5093867778778076
test loss item: 0.8202298879623413
test loss item: 0.3621230721473694
test loss item: 0.3376314043998718
test loss item: 0.26512008905410767
test loss item: 0.7129887938499451
test loss item: 0.35359689593315125
test loss item: 0.30325305461883545
test loss item: 0.3115994930267334
test loss item: 1.401402235031128
test loss item: 0.3442620038986206
test loss item: 0.48202624917030334
test loss item: 0.31288373470306396
test loss item: 0.7647578120231628
test loss item: 0.6287472248077393
test loss item: 0.06255970150232315
test loss item: 1.2563743591308594
test loss item: 0.482867568731308
test loss item: 0.5167818665504456
test loss item: 0.22670501470565796
test loss item: 0.2645435333251953
test loss item: 0.216311976313591
test loss item: 2.6130781173706055
test loss item: 0.7325003743171692
test loss item: 0.27393028140068054
test loss item: 0.09091046452522278
test loss item: 1.5705578327178955
test loss item: 1.2662791013717651
test loss item: 1.8538211584091187
test loss item: 0.3213949203491211
test loss item: 0.31530776619911194
test loss item: 0.08047979325056076
test loss item: 0.0684698149561882
test loss item: 0.22111044824123383
Epoch [3/50], Training Loss: 0.5776, Testing Loss: 0.5966
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/50
train loss item: 0.5021392107009888
train loss item: 1.4020358324050903
train loss item: 0.2827751338481903
train loss item: 0.7027196884155273
train loss item: 0.9253207445144653
train loss item: 0.41154807806015015
train loss item: 0.40359655022621155
train loss item: 0.8218976855278015
train loss item: 0.18198658525943756
train loss item: 0.46982574462890625
train loss item: 0.5131447315216064
train loss item: 0.4556555151939392
train loss item: 0.1281735748052597
train loss item: 0.5544214844703674
train loss item: 0.38070741295814514
train loss item: 1.0628888607025146
train loss item: 0.06040704622864723
train loss item: 0.42288821935653687
train loss item: 0.48815733194351196
train loss item: 0.39996299147605896
train loss item: 0.2998802065849304
train loss item: 0.23294617235660553
train loss item: 1.2832715511322021
train loss item: 1.136642575263977
train loss item: 0.7670120000839233
train loss item: 0.3832380771636963
train loss item: 0.4265728294849396
train loss item: 0.4032289683818817
train loss item: 0.09519117325544357
train loss item: 0.779981255531311
train loss item: 2.2796053886413574
train loss item: 0.6658167839050293
train loss item: 0.14021223783493042
train loss item: 0.45156142115592957
train loss item: 0.18829071521759033
train loss item: 2.0786449909210205
train loss item: 0.8042514324188232
train loss item: 0.682248592376709
train loss item: 0.840590238571167
train loss item: 0.3404703736305237
train loss item: 0.21892841160297394
train loss item: 0.4109167456626892
train loss item: 0.44205620884895325
train loss item: 0.28155583143234253
train loss item: 0.9193791151046753
train loss item: 0.16633743047714233
train loss item: 0.15630805492401123
train loss item: 0.5433482527732849
train loss item: 0.35004597902297974
train loss item: 0.19135256111621857
train loss item: 0.4216080904006958
train loss item: 0.9644942879676819
train loss item: 0.0944901555776596
train loss item: 0.2031380534172058
train loss item: 2.087280750274658
train loss item: 0.24727149307727814
train loss item: 0.3913778066635132
train loss item: 0.2610117495059967
train loss item: 0.21332596242427826
train loss item: 0.12194395065307617
train loss item: 0.9223904013633728
train loss item: 1.9245713949203491
train loss item: 0.2970227003097534
train loss item: 0.5195898413658142
train loss item: 0.20456328988075256
train loss item: 0.7501165270805359
train loss item: 0.5125088095664978
train loss item: 0.24515289068222046
train loss item: 0.476132333278656
train loss item: 0.46479934453964233
train loss item: 0.3591982424259186
train loss item: 0.13813771307468414
train loss item: 0.3039652705192566
train loss item: 0.3725322484970093
train loss item: 0.0954902321100235
train loss item: 0.1471400260925293
train loss item: 1.0198431015014648
train loss item: 1.3626396656036377
train loss item: 0.09680171310901642
train loss item: 0.29796886444091797
train loss item: 0.16755181550979614
train loss item: 0.20642131567001343
train loss item: 0.2909388542175293
train loss item: 0.547890305519104
train loss item: 0.547717809677124
train loss item: 0.6686052083969116
train loss item: 3.799309730529785
train loss item: 0.17852364480495453
train loss item: 0.5676175951957703
test loss item: 0.22876130044460297
test loss item: 0.1925920844078064
test loss item: 0.6096324920654297
test loss item: 0.2843373119831085
test loss item: 0.4044888913631439
test loss item: 0.353555828332901
test loss item: 2.0460212230682373
test loss item: 0.831891655921936
test loss item: 0.25466403365135193
test loss item: 0.47491419315338135
test loss item: 0.9572746157646179
test loss item: 0.17033234238624573
test loss item: 0.2690514326095581
test loss item: 0.39276883006095886
test loss item: 0.25733068585395813
test loss item: 0.08704730123281479
test loss item: 0.39657631516456604
test loss item: 0.5401631593704224
test loss item: 0.9256654381752014
test loss item: 0.4304342269897461
test loss item: 0.8297269344329834
test loss item: 0.47496065497398376
test loss item: 0.4684136211872101
test loss item: 0.31661078333854675
test loss item: 0.26519492268562317
test loss item: 0.35327717661857605
test loss item: 0.4436260759830475
test loss item: 0.38905444741249084
test loss item: 0.44000133872032166
test loss item: 0.4675567150115967
test loss item: 0.8935151100158691
test loss item: 0.10401853173971176
test loss item: 0.28489717841148376
test loss item: 0.628192663192749
test loss item: 0.4906228482723236
test loss item: 0.5699187517166138
test loss item: 1.056497573852539
test loss item: 1.5257805585861206
test loss item: 0.5554651021957397
test loss item: 0.4400100111961365
test loss item: 0.36560243368148804
test loss item: 0.39962461590766907
test loss item: 0.4003780782222748
test loss item: 0.24112391471862793
test loss item: 0.6942936778068542
test loss item: 0.6473431587219238
test loss item: 0.501295268535614
test loss item: 0.4208645820617676
test loss item: 0.544355571269989
test loss item: 0.8297122120857239
test loss item: 0.35588154196739197
test loss item: 0.2584889829158783
test loss item: 0.2910763621330261
test loss item: 0.15435147285461426
test loss item: 0.3592945635318756
test loss item: 0.9324249625205994
test loss item: 0.7086411714553833
test loss item: 0.3055453598499298
test loss item: 0.33318519592285156
test loss item: 0.24370405077934265
test loss item: 0.5090181827545166
test loss item: 0.3669542670249939
test loss item: 0.32692089676856995
test loss item: 0.3012235462665558
test loss item: 0.9966466426849365
test loss item: 0.31743958592414856
test loss item: 0.4512905776500702
test loss item: 0.3324224352836609
test loss item: 0.5683555603027344
test loss item: 0.6347696781158447
test loss item: 0.17376384139060974
test loss item: 1.2921924591064453
test loss item: 0.377658486366272
test loss item: 0.48855453729629517
test loss item: 0.25200581550598145
test loss item: 0.4136265814304352
test loss item: 0.29729965329170227
test loss item: 1.4890213012695312
test loss item: 0.5281075239181519
test loss item: 0.3861309885978699
test loss item: 0.17762959003448486
test loss item: 1.1090573072433472
test loss item: 1.1014866828918457
test loss item: 1.027674674987793
test loss item: 0.2951967716217041
test loss item: 0.32918107509613037
test loss item: 0.13681660592556
test loss item: 0.07730206102132797
test loss item: 0.2770659923553467
Epoch [4/50], Training Loss: 0.5733, Testing Loss: 0.5070
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/50
train loss item: 0.48602986335754395
train loss item: 1.333953857421875
train loss item: 0.28156399726867676
train loss item: 0.6068131923675537
train loss item: 0.44320768117904663
train loss item: 0.3614659011363983
train loss item: 0.31360429525375366
train loss item: 0.7171801924705505
train loss item: 0.15187199413776398
train loss item: 0.30019310116767883
train loss item: 0.40707433223724365
train loss item: 0.29506146907806396
train loss item: 0.10837208479642868
train loss item: 0.5220437049865723
train loss item: 0.26147541403770447
train loss item: 0.6877620220184326
train loss item: 0.07297038286924362
train loss item: 0.3638119399547577
train loss item: 0.38641026616096497
train loss item: 0.33382782340049744
train loss item: 0.23918208479881287
train loss item: 0.1752690076828003
train loss item: 0.973395824432373
train loss item: 0.9286071062088013
train loss item: 0.638412356376648
train loss item: 0.24044714868068695
train loss item: 0.2529298961162567
train loss item: 0.29502803087234497
train loss item: 0.10129999369382858
train loss item: 0.6776465773582458
train loss item: 1.7907018661499023
train loss item: 0.7767718434333801
train loss item: 0.2212078720331192
train loss item: 0.41091376543045044
train loss item: 0.133914977312088
train loss item: 1.7703841924667358
train loss item: 0.8056597709655762
train loss item: 0.5334590077400208
train loss item: 0.6710484027862549
train loss item: 0.28273409605026245
train loss item: 0.2101016640663147
train loss item: 0.3625372052192688
train loss item: 0.39074641466140747
train loss item: 0.2726905643939972
train loss item: 0.841188907623291
train loss item: 0.13405807316303253
train loss item: 0.131875678896904
train loss item: 0.6133467555046082
train loss item: 0.35045212507247925
train loss item: 0.1714107245206833
train loss item: 0.4941314458847046
train loss item: 1.2023556232452393
train loss item: 0.07101334631443024
train loss item: 0.18202953040599823
train loss item: 1.9251779317855835
train loss item: 0.2390000969171524
train loss item: 0.333469420671463
train loss item: 0.2956734895706177
train loss item: 0.21844951808452606
train loss item: 0.15239162743091583
train loss item: 1.0345207452774048
train loss item: 1.6909229755401611
train loss item: 0.27491334080696106
train loss item: 0.4340212345123291
train loss item: 0.2247297167778015
train loss item: 0.7020635604858398
train loss item: 0.6914637684822083
train loss item: 0.2610158920288086
train loss item: 0.3718174397945404
train loss item: 0.4037328362464905
train loss item: 0.292216420173645
train loss item: 0.12692590057849884
train loss item: 0.28203192353248596
train loss item: 0.3673930764198303
train loss item: 0.07950851321220398
train loss item: 0.1273401379585266
train loss item: 1.0057584047317505
train loss item: 1.2828257083892822
train loss item: 0.07772001624107361
train loss item: 0.2843998968601227
train loss item: 0.11754105985164642
train loss item: 0.21676601469516754
train loss item: 0.2720753848552704
train loss item: 0.513117253780365
train loss item: 0.5915540456771851
train loss item: 0.624801516532898
train loss item: 3.3155555725097656
train loss item: 0.1508142352104187
train loss item: 0.506514847278595
test loss item: 0.22383758425712585
test loss item: 0.10122334212064743
test loss item: 0.5543126463890076
test loss item: 0.2636622488498688
test loss item: 0.2594273090362549
test loss item: 0.1805235892534256
test loss item: 1.9042832851409912
test loss item: 0.6523539423942566
test loss item: 0.2200760543346405
test loss item: 0.41441550850868225
test loss item: 0.8232730031013489
test loss item: 0.19732944667339325
test loss item: 0.23155143857002258
test loss item: 0.4242210388183594
test loss item: 0.17109039425849915
test loss item: 0.0637625977396965
test loss item: 0.384880930185318
test loss item: 0.47447338700294495
test loss item: 0.7842504978179932
test loss item: 0.37362971901893616
test loss item: 0.7478837370872498
test loss item: 0.44880032539367676
test loss item: 0.3389993906021118
test loss item: 0.22332286834716797
test loss item: 0.26773592829704285
test loss item: 0.2921796441078186
test loss item: 0.3963527977466583
test loss item: 0.22616900503635406
test loss item: 0.36650583148002625
test loss item: 0.4099002480506897
test loss item: 0.7908022999763489
test loss item: 0.07494983822107315
test loss item: 0.19521236419677734
test loss item: 0.5779657363891602
test loss item: 0.4314515292644501
test loss item: 0.46482810378074646
test loss item: 0.9279231429100037
test loss item: 1.3153088092803955
test loss item: 0.5005946159362793
test loss item: 0.3286193311214447
test loss item: 0.37252652645111084
test loss item: 0.27336812019348145
test loss item: 0.3538101613521576
test loss item: 0.26992666721343994
test loss item: 0.6267985105514526
test loss item: 0.5462682843208313
test loss item: 0.3583196699619293
test loss item: 0.3437707722187042
test loss item: 0.4673413336277008
test loss item: 0.6894915699958801
test loss item: 0.2991043031215668
test loss item: 0.21351222693920135
test loss item: 0.2779155671596527
test loss item: 0.20154377818107605
test loss item: 0.31217095255851746
test loss item: 0.8149411082267761
test loss item: 0.6035475134849548
test loss item: 0.28396978974342346
test loss item: 0.29878008365631104
test loss item: 0.21433952450752258
test loss item: 0.44585365056991577
test loss item: 0.31126850843429565
test loss item: 0.29898205399513245
test loss item: 0.3111124336719513
test loss item: 0.8801639676094055
test loss item: 0.3454177975654602
test loss item: 0.40018680691719055
test loss item: 0.31567564606666565
test loss item: 0.5159564018249512
test loss item: 0.4837987422943115
test loss item: 0.07037461549043655
test loss item: 1.1461952924728394
test loss item: 0.3952668309211731
test loss item: 0.48352277278900146
test loss item: 0.21889840066432953
test loss item: 0.2503947913646698
test loss item: 0.2153567522764206
test loss item: 1.3052102327346802
test loss item: 0.5531340837478638
test loss item: 0.25842010974884033
test loss item: 0.09510491788387299
test loss item: 0.9688894152641296
test loss item: 0.973979651927948
test loss item: 0.8782515525817871
test loss item: 0.2793658971786499
test loss item: 0.27570533752441406
test loss item: 0.0821133479475975
test loss item: 0.06928380578756332
test loss item: 0.19190242886543274
Epoch [5/50], Training Loss: 0.5087, Testing Loss: 0.4367
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/50
train loss item: 0.4300716519355774
train loss item: 1.2640435695648193
train loss item: 0.2533445358276367
train loss item: 0.6705136299133301
train loss item: 0.4189329445362091
train loss item: 0.3508652150630951
train loss item: 0.30102652311325073
train loss item: 0.8390786051750183
train loss item: 0.18592223525047302
train loss item: 0.39629629254341125
train loss item: 0.5570724606513977
train loss item: 0.27649205923080444
train loss item: 0.11372947692871094
train loss item: 0.6625910997390747
train loss item: 0.295180082321167
train loss item: 0.7447018623352051
train loss item: 0.06017201021313667
train loss item: 0.3249080181121826
train loss item: 0.3784900903701782
train loss item: 0.32053685188293457
train loss item: 0.2502790093421936
train loss item: 0.17495915293693542
train loss item: 0.8950791358947754
train loss item: 0.969197690486908
train loss item: 0.621118426322937
train loss item: 0.24585124850273132
train loss item: 0.22325463593006134
train loss item: 0.2526489496231079
train loss item: 0.06206170469522476
train loss item: 0.6424688696861267
train loss item: 1.6440699100494385
train loss item: 0.7524213790893555
train loss item: 0.13799795508384705
train loss item: 0.369232177734375
train loss item: 0.15302559733390808
train loss item: 1.5837188959121704
train loss item: 0.8019135594367981
train loss item: 0.483897864818573
train loss item: 0.4982016086578369
train loss item: 0.2561938166618347
train loss item: 0.19363677501678467
train loss item: 0.3690783679485321
train loss item: 0.335333913564682
train loss item: 0.2811272144317627
train loss item: 0.8118041157722473
train loss item: 0.1377112865447998
train loss item: 0.1463586837053299
train loss item: 0.4039442539215088
train loss item: 0.3253737688064575
train loss item: 0.20114873349666595
train loss item: 0.3585105240345001
train loss item: 1.0002375841140747
train loss item: 0.06338192522525787
train loss item: 0.19984225928783417
train loss item: 1.8003393411636353
train loss item: 0.1998046487569809
train loss item: 0.3629535138607025
train loss item: 0.26198893785476685
train loss item: 0.18824347853660583
train loss item: 0.14850829541683197
train loss item: 0.7465896010398865
train loss item: 1.3984392881393433
train loss item: 0.28325268626213074
train loss item: 0.5545751452445984
train loss item: 0.1884678453207016
train loss item: 0.6292052268981934
train loss item: 0.6255313158035278
train loss item: 0.2105501890182495
train loss item: 0.3999882936477661
train loss item: 0.38424935936927795
train loss item: 0.266610324382782
train loss item: 0.12451397627592087
train loss item: 0.3084001839160919
train loss item: 0.36424511671066284
train loss item: 0.10845480859279633
train loss item: 0.1705329418182373
train loss item: 0.987506091594696
train loss item: 1.1628057956695557
train loss item: 0.08550529181957245
train loss item: 0.2909635901451111
train loss item: 0.15275128185749054
train loss item: 0.18898840248584747
train loss item: 0.27425795793533325
train loss item: 0.47881975769996643
train loss item: 0.6513606905937195
train loss item: 0.6915993690490723
train loss item: 3.051983118057251
train loss item: 0.16804514825344086
train loss item: 0.5024146437644958
test loss item: 0.29181331396102905
test loss item: 0.14615629613399506
test loss item: 0.5625156164169312
test loss item: 0.3152744472026825
test loss item: 0.28028374910354614
test loss item: 0.23158183693885803
test loss item: 2.0832340717315674
test loss item: 0.8051947355270386
test loss item: 0.27629995346069336
test loss item: 0.4678952693939209
test loss item: 0.8109197616577148
test loss item: 0.24338024854660034
test loss item: 0.33133548498153687
test loss item: 0.513717532157898
test loss item: 0.19876155257225037
test loss item: 0.08499906212091446
test loss item: 0.4768035113811493
test loss item: 0.5003407001495361
test loss item: 0.8733910918235779
test loss item: 0.49279090762138367
test loss item: 0.732357382774353
test loss item: 0.5419308543205261
test loss item: 0.4643322825431824
test loss item: 0.27357909083366394
test loss item: 0.31829777359962463
test loss item: 0.36902281641960144
test loss item: 0.45698392391204834
test loss item: 0.2568146288394928
test loss item: 0.3836074769496918
test loss item: 0.4884847104549408
test loss item: 0.8359982967376709
test loss item: 0.09410465508699417
test loss item: 0.24845725297927856
test loss item: 0.5729253888130188
test loss item: 0.43551886081695557
test loss item: 0.5370563864707947
test loss item: 1.0058826208114624
test loss item: 1.2405544519424438
test loss item: 0.5038764476776123
test loss item: 0.3647698760032654
test loss item: 0.41638320684432983
test loss item: 0.42712870240211487
test loss item: 0.39812397956848145
test loss item: 0.34363067150115967
test loss item: 0.6279906034469604
test loss item: 0.6526355147361755
test loss item: 0.4834761917591095
test loss item: 0.4928068220615387
test loss item: 0.5191934108734131
test loss item: 0.7598298192024231
test loss item: 0.33730217814445496
test loss item: 0.34348028898239136
test loss item: 0.34383946657180786
test loss item: 0.28023239970207214
test loss item: 0.35867905616760254
test loss item: 0.7476557493209839
test loss item: 0.6716766357421875
test loss item: 0.3769041895866394
test loss item: 0.3904019594192505
test loss item: 0.26543572545051575
test loss item: 0.47699683904647827
test loss item: 0.4276728332042694
test loss item: 0.4139665961265564
test loss item: 0.34563350677490234
test loss item: 0.8785943388938904
test loss item: 0.392165869474411
test loss item: 0.5134329199790955
test loss item: 0.35011720657348633
test loss item: 0.4839220643043518
test loss item: 0.5952311754226685
test loss item: 0.08797676861286163
test loss item: 1.29764723777771
test loss item: 0.5149677991867065
test loss item: 0.6037817597389221
test loss item: 0.31520628929138184
test loss item: 0.37994301319122314
test loss item: 0.2584935426712036
test loss item: 1.1725274324417114
test loss item: 0.6203373074531555
test loss item: 0.3341832160949707
test loss item: 0.11438693851232529
test loss item: 1.0580649375915527
test loss item: 1.0551127195358276
test loss item: 0.8773736953735352
test loss item: 0.37359485030174255
test loss item: 0.3822794258594513
test loss item: 0.10529989749193192
test loss item: 0.09191145747900009
test loss item: 0.28030627965927124
Epoch [6/50], Training Loss: 0.4843, Testing Loss: 0.4961
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/50
train loss item: 0.44445550441741943
train loss item: 1.196074366569519
train loss item: 0.30134186148643494
train loss item: 0.6610447764396667
train loss item: 0.38494575023651123
train loss item: 0.32845404744148254
train loss item: 0.2896731197834015
train loss item: 0.584921658039093
train loss item: 0.15775281190872192
train loss item: 0.28238359093666077
train loss item: 0.3986347019672394
train loss item: 0.26916834712028503
train loss item: 0.11387396603822708
train loss item: 0.5474922060966492
train loss item: 0.2727534770965576
train loss item: 0.6056960821151733
train loss item: 0.06403099000453949
train loss item: 0.3320988714694977
train loss item: 0.35081517696380615
train loss item: 0.32113951444625854
train loss item: 0.23093314468860626
train loss item: 0.11412037909030914
train loss item: 0.8642737865447998
train loss item: 0.7655686736106873
train loss item: 0.5431575179100037
train loss item: 0.306413859128952
train loss item: 0.19230729341506958
train loss item: 0.23323602974414825
train loss item: 0.07991701364517212
train loss item: 0.5786377787590027
train loss item: 1.6732547283172607
train loss item: 0.6923893690109253
train loss item: 0.12480732798576355
train loss item: 0.33961915969848633
train loss item: 0.11168789118528366
train loss item: 1.4027258157730103
train loss item: 0.6257273554801941
train loss item: 0.46021604537963867
train loss item: 0.4841446578502655
train loss item: 0.31407150626182556
train loss item: 0.20463566482067108
train loss item: 0.3522668182849884
train loss item: 0.37489017844200134
train loss item: 0.25784197449684143
train loss item: 0.71037757396698
train loss item: 0.11012575030326843
train loss item: 0.12177683413028717
train loss item: 0.4670328199863434
train loss item: 0.3217305541038513
train loss item: 0.17216263711452484
train loss item: 0.39080214500427246
train loss item: 0.9401257038116455
train loss item: 0.07197105884552002
train loss item: 0.19589146971702576
train loss item: 1.4776074886322021
train loss item: 0.19057287275791168
train loss item: 0.3963850438594818
train loss item: 0.2379113882780075
train loss item: 0.17826944589614868
train loss item: 0.14396661520004272
train loss item: 0.7210185527801514
train loss item: 1.1686186790466309
train loss item: 0.2603455185890198
train loss item: 0.5337030291557312
train loss item: 0.20192059874534607
train loss item: 0.5993326306343079
train loss item: 0.5374658703804016
train loss item: 0.20077279210090637
train loss item: 0.40343615412712097
train loss item: 0.3575380742549896
train loss item: 0.24846871197223663
train loss item: 0.11114462465047836
train loss item: 0.25054460763931274
train loss item: 0.32031625509262085
train loss item: 0.09629762917757034
train loss item: 0.15393273532390594
train loss item: 0.8551462292671204
train loss item: 1.024643063545227
train loss item: 0.08428531885147095
train loss item: 0.3813588619232178
train loss item: 0.13117773830890656
train loss item: 0.2320852428674698
train loss item: 0.244232177734375
train loss item: 0.39694905281066895
train loss item: 0.547921895980835
train loss item: 0.5507187247276306
train loss item: 2.544010877609253
train loss item: 0.13975313305854797
train loss item: 0.4954184293746948
test loss item: 0.2962472140789032
test loss item: 0.18500465154647827
test loss item: 0.5940998196601868
test loss item: 0.3225993812084198
test loss item: 0.3082989752292633
test loss item: 0.2549231946468353
test loss item: 2.2884795665740967
test loss item: 0.9002432823181152
test loss item: 0.3216497302055359
test loss item: 0.5439707636833191
test loss item: 0.7541329860687256
test loss item: 0.2688247859477997
test loss item: 0.4029238820075989
test loss item: 0.6178768277168274
test loss item: 0.23473943769931793
test loss item: 0.08563386648893356
test loss item: 0.49148786067962646
test loss item: 0.5494091510772705
test loss item: 0.9265947937965393
test loss item: 0.5860951542854309
test loss item: 0.7589212656021118
test loss item: 0.5673730969429016
test loss item: 0.5019135475158691
test loss item: 0.29474979639053345
test loss item: 0.319225013256073
test loss item: 0.44688916206359863
test loss item: 0.5288384556770325
test loss item: 0.28684693574905396
test loss item: 0.4187181890010834
test loss item: 0.5746849775314331
test loss item: 0.8961597681045532
test loss item: 0.0890699103474617
test loss item: 0.26492658257484436
test loss item: 0.5848624110221863
test loss item: 0.47865796089172363
test loss item: 0.6502783298492432
test loss item: 1.0848026275634766
test loss item: 1.1215890645980835
test loss item: 0.5491598844528198
test loss item: 0.3945144712924957
test loss item: 0.4295493960380554
test loss item: 0.4435052275657654
test loss item: 0.4648485481739044
test loss item: 0.34785550832748413
test loss item: 0.6799997091293335
test loss item: 0.7105928659439087
test loss item: 0.5130943059921265
test loss item: 0.6575382947921753
test loss item: 0.5574197769165039
test loss item: 0.783821702003479
test loss item: 0.46677637100219727
test loss item: 0.43060562014579773
test loss item: 0.40395426750183105
test loss item: 0.28118354082107544
test loss item: 0.46702152490615845
test loss item: 0.741968035697937
test loss item: 0.7028012275695801
test loss item: 0.4921262264251709
test loss item: 0.43896016478538513
test loss item: 0.36293578147888184
test loss item: 0.5695857405662537
test loss item: 0.44798776507377625
test loss item: 0.4652719497680664
test loss item: 0.38893765211105347
test loss item: 0.9332055449485779
test loss item: 0.38961169123649597
test loss item: 0.5794054269790649
test loss item: 0.3723520040512085
test loss item: 0.47064173221588135
test loss item: 0.659311830997467
test loss item: 0.09551449865102768
test loss item: 1.426967740058899
test loss item: 0.5790250301361084
test loss item: 0.6513593792915344
test loss item: 0.34560778737068176
test loss item: 0.39561519026756287
test loss item: 0.2833142876625061
test loss item: 1.0839093923568726
test loss item: 0.7047312259674072
test loss item: 0.3489598333835602
test loss item: 0.10795216262340546
test loss item: 1.099047303199768
test loss item: 1.1458063125610352
test loss item: 0.8673787713050842
test loss item: 0.4735127091407776
test loss item: 0.4119732081890106
test loss item: 0.09640944004058838
test loss item: 0.08415107429027557
test loss item: 0.27505162358283997
Epoch [7/50], Training Loss: 0.4399, Testing Loss: 0.5379
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/50
train loss item: 0.4690641760826111
train loss item: 1.370843768119812
train loss item: 0.33906254172325134
train loss item: 0.6310698390007019
train loss item: 0.37503278255462646
train loss item: 0.37732088565826416
train loss item: 0.2934585213661194
train loss item: 0.7067073583602905
train loss item: 0.1925668716430664
train loss item: 0.37078243494033813
train loss item: 0.509731650352478
train loss item: 0.2693367600440979
train loss item: 0.13452497124671936
train loss item: 0.6687837243080139
train loss item: 0.32628270983695984
train loss item: 0.5695708394050598
train loss item: 0.06259627640247345
train loss item: 0.37037205696105957
train loss item: 0.35759562253952026
train loss item: 0.2613115906715393
train loss item: 0.23524600267410278
train loss item: 0.12728853523731232
train loss item: 0.8458204865455627
train loss item: 0.8515357375144958
train loss item: 0.5354660749435425
train loss item: 0.1858229786157608
train loss item: 0.2000306099653244
train loss item: 0.2145002782344818
train loss item: 0.04925678297877312
train loss item: 0.5224248766899109
train loss item: 1.3690091371536255
train loss item: 0.7756256461143494
train loss item: 0.17583271861076355
train loss item: 0.33368217945098877
train loss item: 0.11360208690166473
train loss item: 1.2340900897979736
train loss item: 0.659313976764679
train loss item: 0.4805321991443634
train loss item: 0.4125087559223175
train loss item: 0.26992470026016235
train loss item: 0.1815582662820816
train loss item: 0.311013787984848
train loss item: 0.33454301953315735
train loss item: 0.2472938746213913
train loss item: 0.6052659153938293
train loss item: 0.12290994822978973
train loss item: 0.11766999214887619
train loss item: 0.39428767561912537
train loss item: 0.2791212797164917
train loss item: 0.16540628671646118
train loss item: 0.34267452359199524
train loss item: 0.8927373886108398
train loss item: 0.08900678902864456
train loss item: 0.17248576879501343
train loss item: 1.1685435771942139
train loss item: 0.20822730660438538
train loss item: 0.4424988925457001
train loss item: 0.2119615525007248
train loss item: 0.14401598274707794
train loss item: 0.10733173042535782
train loss item: 0.662929892539978
train loss item: 1.1072558164596558
train loss item: 0.22056375443935394
train loss item: 0.4845208525657654
train loss item: 0.16145993769168854
train loss item: 0.5377627611160278
train loss item: 0.500778079032898
train loss item: 0.1910535842180252
train loss item: 0.35832345485687256
train loss item: 0.3153858780860901
train loss item: 0.23926378786563873
train loss item: 0.11486254632472992
train loss item: 0.2071431279182434
train loss item: 0.2925991117954254
train loss item: 0.11343211680650711
train loss item: 0.13531138002872467
train loss item: 0.6896268129348755
train loss item: 1.0016021728515625
train loss item: 0.08443136513233185
train loss item: 0.28996893763542175
train loss item: 0.13920217752456665
train loss item: 0.18742170929908752
train loss item: 0.2237304151058197
train loss item: 0.40799689292907715
train loss item: 0.516615092754364
train loss item: 0.5236713290214539
train loss item: 2.152217388153076
train loss item: 0.1237364262342453
train loss item: 0.4269510805606842
test loss item: 0.2567932605743408
test loss item: 0.15761049091815948
test loss item: 0.5037261247634888
test loss item: 0.28755679726600647
test loss item: 0.2799733281135559
test loss item: 0.2226824313402176
test loss item: 2.1670100688934326
test loss item: 0.7983096241950989
test loss item: 0.25100791454315186
test loss item: 0.4357367157936096
test loss item: 0.6541020274162292
test loss item: 0.23016734421253204
test loss item: 0.30277976393699646
test loss item: 0.4904247224330902
test loss item: 0.20367814600467682
test loss item: 0.09016114473342896
test loss item: 0.42522889375686646
test loss item: 0.47748976945877075
test loss item: 0.8310874700546265
test loss item: 0.4600565731525421
test loss item: 0.6939845681190491
test loss item: 0.5127993822097778
test loss item: 0.4229692220687866
test loss item: 0.25995388627052307
test loss item: 0.27470603585243225
test loss item: 0.3801916539669037
test loss item: 0.43125125765800476
test loss item: 0.25557640194892883
test loss item: 0.38432759046554565
test loss item: 0.45384252071380615
test loss item: 0.8206896185874939
test loss item: 0.08280728757381439
test loss item: 0.22916240990161896
test loss item: 0.5244811773300171
test loss item: 0.41453447937965393
test loss item: 0.5124036073684692
test loss item: 0.9803028702735901
test loss item: 0.9642666578292847
test loss item: 0.4859732985496521
test loss item: 0.3627009391784668
test loss item: 0.3904828429222107
test loss item: 0.37790361046791077
test loss item: 0.3817921280860901
test loss item: 0.30606842041015625
test loss item: 0.5996156334877014
test loss item: 0.6003375053405762
test loss item: 0.4361158311367035
test loss item: 0.4732668399810791
test loss item: 0.4692555367946625
test loss item: 0.6891291737556458
test loss item: 0.37084266543388367
test loss item: 0.3076935410499573
test loss item: 0.3376193940639496
test loss item: 0.24078120291233063
test loss item: 0.38281193375587463
test loss item: 0.6496930122375488
test loss item: 0.6182107329368591
test loss item: 0.3799244463443756
test loss item: 0.36443161964416504
test loss item: 0.28534725308418274
test loss item: 0.4684639573097229
test loss item: 0.3784245550632477
test loss item: 0.38511332869529724
test loss item: 0.327300488948822
test loss item: 0.8369375467300415
test loss item: 0.3546932339668274
test loss item: 0.4802832007408142
test loss item: 0.3356372117996216
test loss item: 0.42487016320228577
test loss item: 0.555466890335083
test loss item: 0.10445588082075119
test loss item: 1.3153855800628662
test loss item: 0.4786612093448639
test loss item: 0.5853992700576782
test loss item: 0.2791902422904968
test loss item: 0.33464714884757996
test loss item: 0.25238972902297974
test loss item: 0.9297845959663391
test loss item: 0.573838472366333
test loss item: 0.30514857172966003
test loss item: 0.11132800579071045
test loss item: 0.9930948615074158
test loss item: 1.0298348665237427
test loss item: 0.7273204326629639
test loss item: 0.37451088428497314
test loss item: 0.3491256833076477
test loss item: 0.10328185558319092
test loss item: 0.08650226145982742
test loss item: 0.28411224484443665
Epoch [8/50], Training Loss: 0.4179, Testing Loss: 0.4652
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/50
train loss item: 0.3943084180355072
train loss item: 1.2518301010131836
train loss item: 0.2417733371257782
train loss item: 0.5033578276634216
train loss item: 0.31762465834617615
train loss item: 0.30651310086250305
train loss item: 0.2719748020172119
train loss item: 0.49678751826286316
train loss item: 0.14055512845516205
train loss item: 0.2502962648868561
train loss item: 0.3384595215320587
train loss item: 0.21768838167190552
train loss item: 0.10802147537469864
train loss item: 0.5206465125083923
train loss item: 0.22832664847373962
train loss item: 0.5531049370765686
train loss item: 0.07221700251102448
train loss item: 0.33692964911460876
train loss item: 0.32066312432289124
train loss item: 0.29065757989883423
train loss item: 0.20987290143966675
train loss item: 0.10496153682470322
train loss item: 0.8737314939498901
train loss item: 0.6202548742294312
train loss item: 0.5031731724739075
train loss item: 0.1902940422296524
train loss item: 0.1990508884191513
train loss item: 0.18747586011886597
train loss item: 0.08616480231285095
train loss item: 0.4545786380767822
train loss item: 1.3357439041137695
train loss item: 0.6800063252449036
train loss item: 0.14511138200759888
train loss item: 0.29686275124549866
train loss item: 0.13443797826766968
train loss item: 1.1794207096099854
train loss item: 0.49578624963760376
train loss item: 0.44220465421676636
train loss item: 0.3789566159248352
train loss item: 0.3019673824310303
train loss item: 0.22432221472263336
train loss item: 0.319710373878479
train loss item: 0.37649762630462646
train loss item: 0.24996329843997955
train loss item: 0.5574735999107361
train loss item: 0.13155370950698853
train loss item: 0.12359916418790817
train loss item: 0.41753652691841125
train loss item: 0.24487647414207458
train loss item: 0.16097494959831238
train loss item: 0.34911730885505676
train loss item: 0.7844935059547424
train loss item: 0.07732833921909332
train loss item: 0.17402642965316772
train loss item: 0.8306376338005066
train loss item: 0.2039181888103485
train loss item: 0.48135289549827576
train loss item: 0.19480495154857635
train loss item: 0.14029325544834137
train loss item: 0.09558185189962387
train loss item: 0.6558430194854736
train loss item: 0.9901688694953918
train loss item: 0.178696408867836
train loss item: 0.4276404082775116
train loss item: 0.15233182907104492
train loss item: 0.5161534547805786
train loss item: 0.42756152153015137
train loss item: 0.1913672834634781
train loss item: 0.3697536587715149
train loss item: 0.3045537769794464
train loss item: 0.23685811460018158
train loss item: 0.13889606297016144
train loss item: 0.17531685531139374
train loss item: 0.2842349112033844
train loss item: 0.10026045143604279
train loss item: 0.13180258870124817
train loss item: 0.5807970762252808
train loss item: 1.1195266246795654
train loss item: 0.07228309661149979
train loss item: 0.24628476798534393
train loss item: 0.13208618760108948
train loss item: 0.17380771040916443
train loss item: 0.19949181377887726
train loss item: 0.40946468710899353
train loss item: 0.3933228552341461
train loss item: 0.4673115611076355
train loss item: 1.9249519109725952
train loss item: 0.10517001897096634
train loss item: 0.4247356951236725
test loss item: 0.2204207479953766
test loss item: 0.12424349784851074
test loss item: 0.4377097189426422
test loss item: 0.2515019476413727
test loss item: 0.22747795283794403
test loss item: 0.1653396487236023
test loss item: 1.9440281391143799
test loss item: 0.7012624740600586
test loss item: 0.21113066375255585
test loss item: 0.3685648441314697
test loss item: 0.5838293433189392
test loss item: 0.19564618170261383
test loss item: 0.2406734675168991
test loss item: 0.4197448492050171
test loss item: 0.16835032403469086
test loss item: 0.08144384622573853
test loss item: 0.35634589195251465
test loss item: 0.406818151473999
test loss item: 0.7374441623687744
test loss item: 0.38563090562820435
test loss item: 0.6313338875770569
test loss item: 0.44727596640586853
test loss item: 0.358994722366333
test loss item: 0.22699229419231415
test loss item: 0.22718161344528198
test loss item: 0.32386988401412964
test loss item: 0.3754996657371521
test loss item: 0.20187275111675262
test loss item: 0.336020827293396
test loss item: 0.37438440322875977
test loss item: 0.7395486831665039
test loss item: 0.0772009864449501
test loss item: 0.19681890308856964
test loss item: 0.46572744846343994
test loss item: 0.356590211391449
test loss item: 0.4568166136741638
test loss item: 0.8710479140281677
test loss item: 0.8426154851913452
test loss item: 0.42564958333969116
test loss item: 0.3154803216457367
test loss item: 0.34118926525115967
test loss item: 0.3044590950012207
test loss item: 0.3218909204006195
test loss item: 0.2561221420764923
test loss item: 0.5347146987915039
test loss item: 0.5165683031082153
test loss item: 0.3623445928096771
test loss item: 0.38730573654174805
test loss item: 0.40712982416152954
test loss item: 0.6189296841621399
test loss item: 0.3098899722099304
test loss item: 0.23484206199645996
test loss item: 0.27424341440200806
test loss item: 0.19664782285690308
test loss item: 0.3191346228122711
test loss item: 0.5909035801887512
test loss item: 0.5499278903007507
test loss item: 0.31522467732429504
test loss item: 0.30291709303855896
test loss item: 0.22689715027809143
test loss item: 0.40138375759124756
test loss item: 0.31830039620399475
test loss item: 0.3241020739078522
test loss item: 0.2808609902858734
test loss item: 0.7436649799346924
test loss item: 0.31405654549598694
test loss item: 0.4037174880504608
test loss item: 0.290264368057251
test loss item: 0.37645331025123596
test loss item: 0.4984920024871826
test loss item: 0.08656774461269379
test loss item: 1.1674731969833374
test loss item: 0.419001042842865
test loss item: 0.5134468078613281
test loss item: 0.22083322703838348
test loss item: 0.2707971930503845
test loss item: 0.22019171714782715
test loss item: 0.8035420775413513
test loss item: 0.507011890411377
test loss item: 0.24383126199245453
test loss item: 0.09940210729837418
test loss item: 0.8895789980888367
test loss item: 0.9265362620353699
test loss item: 0.6298977136611938
test loss item: 0.3124161958694458
test loss item: 0.28668269515037537
test loss item: 0.09571012854576111
test loss item: 0.08296304941177368
test loss item: 0.23552587628364563
Epoch [9/50], Training Loss: 0.3781, Testing Loss: 0.4024
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/50
train loss item: 0.36878710985183716
train loss item: 1.1763375997543335
train loss item: 0.21575602889060974
train loss item: 0.4448288381099701
train loss item: 0.3368370831012726
train loss item: 0.2958010733127594
train loss item: 0.24419847130775452
train loss item: 0.551024317741394
train loss item: 0.154616117477417
train loss item: 0.29211241006851196
train loss item: 0.4009685218334198
train loss item: 0.20642174780368805
train loss item: 0.10886412113904953
train loss item: 0.5505256056785583
train loss item: 0.25262555480003357
train loss item: 0.5175904631614685
train loss item: 0.05777578055858612
train loss item: 0.3303355276584625
train loss item: 0.30565008521080017
train loss item: 0.2700704336166382
train loss item: 0.23120786249637604
train loss item: 0.10362990200519562
train loss item: 0.8113481998443604
train loss item: 0.5591221451759338
train loss item: 0.4598255455493927
train loss item: 0.19131170213222504
train loss item: 0.16942310333251953
train loss item: 0.1938268542289734
train loss item: 0.06184440106153488
train loss item: 0.45426642894744873
train loss item: 1.2089669704437256
train loss item: 0.6438276767730713
train loss item: 0.08453910052776337
train loss item: 0.2876169979572296
train loss item: 0.11484619230031967
train loss item: 1.1217713356018066
train loss item: 0.5655614137649536
train loss item: 0.47476041316986084
train loss item: 0.33075210452079773
train loss item: 0.28030452132225037
train loss item: 0.20698845386505127
train loss item: 0.3047412037849426
train loss item: 0.34826725721359253
train loss item: 0.25430336594581604
train loss item: 0.6151103973388672
train loss item: 0.12027926743030548
train loss item: 0.12578274309635162
train loss item: 0.37028443813323975
train loss item: 0.26226845383644104
train loss item: 0.17602413892745972
train loss item: 0.27000075578689575
train loss item: 0.8621054291725159
train loss item: 0.0642240047454834
train loss item: 0.1927359253168106
train loss item: 1.0703378915786743
train loss item: 0.171883225440979
train loss item: 0.42034947872161865
train loss item: 0.2148023098707199
train loss item: 0.16113224625587463
train loss item: 0.11904363334178925
train loss item: 0.5377424955368042
train loss item: 1.0143924951553345
train loss item: 0.19995950162410736
train loss item: 0.3869819641113281
train loss item: 0.13324472308158875
train loss item: 0.48113787174224854
train loss item: 0.3302311599254608
train loss item: 0.16948848962783813
train loss item: 0.3092219829559326
train loss item: 0.2528246343135834
train loss item: 0.20946331322193146
train loss item: 0.10001591593027115
train loss item: 0.17831844091415405
train loss item: 0.24189244210720062
train loss item: 0.07724722474813461
train loss item: 0.11520673334598541
train loss item: 0.5836808681488037
train loss item: 0.8585512638092041
train loss item: 0.07447987794876099
train loss item: 0.3069455325603485
train loss item: 0.11994390189647675
train loss item: 0.1438131481409073
train loss item: 0.18901099264621735
train loss item: 0.3486930727958679
train loss item: 0.4438842535018921
train loss item: 0.4163747727870941
train loss item: 1.8966126441955566
train loss item: 0.1123899295926094
train loss item: 0.4075483977794647
test loss item: 0.21484242379665375
test loss item: 0.12628278136253357
test loss item: 0.47858038544654846
test loss item: 0.24873511493206024
test loss item: 0.21585822105407715
test loss item: 0.15981148183345795
test loss item: 2.091974973678589
test loss item: 0.8710073828697205
test loss item: 0.26112282276153564
test loss item: 0.42725706100463867
test loss item: 0.6413074731826782
test loss item: 0.1753314733505249
test loss item: 0.2865150272846222
test loss item: 0.4109778106212616
test loss item: 0.16679063439369202
test loss item: 0.07774188369512558
test loss item: 0.38298314809799194
test loss item: 0.4081336259841919
test loss item: 0.8623019456863403
test loss item: 0.423302561044693
test loss item: 0.5651770234107971
test loss item: 0.49523627758026123
test loss item: 0.3205699026584625
test loss item: 0.22970856726169586
test loss item: 0.22877700626850128
test loss item: 0.32366329431533813
test loss item: 0.4091174006462097
test loss item: 0.1992020457983017
test loss item: 0.32715409994125366
test loss item: 0.4480556547641754
test loss item: 0.8053573966026306
test loss item: 0.0771641656756401
test loss item: 0.20011018216609955
test loss item: 0.4603038728237152
test loss item: 0.3625778555870056
test loss item: 0.5532498359680176
test loss item: 0.9983686804771423
test loss item: 0.9241281747817993
test loss item: 0.42515021562576294
test loss item: 0.31712543964385986
test loss item: 0.3505900204181671
test loss item: 0.28294309973716736
test loss item: 0.34527072310447693
test loss item: 0.26400408148765564
test loss item: 0.48273369669914246
test loss item: 0.5673304200172424
test loss item: 0.33956262469291687
test loss item: 0.4624353051185608
test loss item: 0.46624618768692017
test loss item: 0.6990091800689697
test loss item: 0.3322218060493469
test loss item: 0.3107130825519562
test loss item: 0.294273316860199
test loss item: 0.1858646720647812
test loss item: 0.32647863030433655
test loss item: 0.6384111046791077
test loss item: 0.6361135244369507
test loss item: 0.3011924624443054
test loss item: 0.3273474872112274
test loss item: 0.2347787320613861
test loss item: 0.4569457173347473
test loss item: 0.38290584087371826
test loss item: 0.3255096971988678
test loss item: 0.26828521490097046
test loss item: 0.8207732439041138
test loss item: 0.3084791898727417
test loss item: 0.4488021731376648
test loss item: 0.2870396673679352
test loss item: 0.35647422075271606
test loss item: 0.6207966208457947
test loss item: 0.07183729857206345
test loss item: 1.3017041683197021
test loss item: 0.39851537346839905
test loss item: 0.5202128887176514
test loss item: 0.24250733852386475
test loss item: 0.2557038366794586
test loss item: 0.22344070672988892
test loss item: 0.8488708734512329
test loss item: 0.47000956535339355
test loss item: 0.22942163050174713
test loss item: 0.09332186728715897
test loss item: 0.9849663972854614
test loss item: 1.0423580408096313
test loss item: 0.7146645188331604
test loss item: 0.3125433623790741
test loss item: 0.29582542181015015
test loss item: 0.09069182723760605
test loss item: 0.08584767580032349
test loss item: 0.18225927650928497
Epoch [10/50], Training Loss: 0.3640, Testing Loss: 0.4280
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 11/50
train loss item: 0.3516409993171692
train loss item: 1.201147437095642
train loss item: 0.23994331061840057
train loss item: 0.5591029524803162
train loss item: 0.3794388175010681
train loss item: 0.29282987117767334
train loss item: 0.23817101120948792
train loss item: 0.5576915740966797
train loss item: 0.16893020272254944
train loss item: 0.3322283625602722
train loss item: 0.4590919315814972
train loss item: 0.21242864429950714
train loss item: 0.12817014753818512
train loss item: 0.6465445160865784
train loss item: 0.3061198890209198
train loss item: 0.5243459343910217
train loss item: 0.054712485522031784
train loss item: 0.2549760937690735
train loss item: 0.30863717198371887
train loss item: 0.19922983646392822
train loss item: 0.19130975008010864
train loss item: 0.10671661794185638
train loss item: 0.6655517220497131
train loss item: 0.7042142152786255
train loss item: 0.44304925203323364
train loss item: 0.13085633516311646
train loss item: 0.175633504986763
train loss item: 0.17624531686306
train loss item: 0.07130968570709229
train loss item: 0.40509000420570374
train loss item: 0.921065092086792
train loss item: 0.578025758266449
train loss item: 0.1708349585533142
train loss item: 0.3160601854324341
train loss item: 0.07947178184986115
train loss item: 0.9091742634773254
train loss item: 0.4133121371269226
train loss item: 0.4598950743675232
train loss item: 0.34545108675956726
train loss item: 0.2828223407268524
train loss item: 0.14905411005020142
train loss item: 0.21740491688251495
train loss item: 0.27699628472328186
train loss item: 0.17909517884254456
train loss item: 0.47550565004348755
train loss item: 0.08089124411344528
train loss item: 0.11064223200082779
train loss item: 0.25688743591308594
train loss item: 0.20177561044692993
train loss item: 0.13420560956001282
train loss item: 0.21870703995227814
train loss item: 0.5677627921104431
train loss item: 0.06442371010780334
train loss item: 0.14693422615528107
train loss item: 0.7360521554946899
train loss item: 0.13771553337574005
train loss item: 0.3373256325721741
train loss item: 0.20731544494628906
train loss item: 0.12942995131015778
train loss item: 0.10982415825128555
train loss item: 0.4982871413230896
train loss item: 0.8386845588684082
train loss item: 0.16438832879066467
train loss item: 0.37143492698669434
train loss item: 0.11477769911289215
train loss item: 0.39779096841812134
train loss item: 0.6552861332893372
train loss item: 0.1361151486635208
train loss item: 0.3262101113796234
train loss item: 0.27677059173583984
train loss item: 0.21917171776294708
train loss item: 0.08271881192922592
train loss item: 0.1982654631137848
train loss item: 0.25965800881385803
train loss item: 0.09097577631473541
train loss item: 0.12616805732250214
train loss item: 0.5393236875534058
train loss item: 0.9164692163467407
train loss item: 0.08801324665546417
train loss item: 0.2518012821674347
train loss item: 0.12071328610181808
train loss item: 0.17008225619792938
train loss item: 0.17531894147396088
train loss item: 0.4390203356742859
train loss item: 0.4528355598449707
train loss item: 0.42771753668785095
train loss item: 1.430991768836975
train loss item: 0.11251663416624069
train loss item: 0.3676459789276123
test loss item: 0.2733357548713684
test loss item: 0.15208448469638824
test loss item: 0.42200490832328796
test loss item: 0.28144019842147827
test loss item: 0.26927244663238525
test loss item: 0.2424914687871933
test loss item: 2.0768954753875732
test loss item: 0.795715868473053
test loss item: 0.2300272136926651
test loss item: 0.3807864487171173
test loss item: 0.5343923568725586
test loss item: 0.22723378241062164
test loss item: 0.2884429395198822
test loss item: 0.5109472870826721
test loss item: 0.1909208446741104
test loss item: 0.06529062986373901
test loss item: 0.3996813893318176
test loss item: 0.4001736640930176
test loss item: 0.7935696244239807
test loss item: 0.4438507556915283
test loss item: 0.539728045463562
test loss item: 0.4966568946838379
test loss item: 0.4782503545284271
test loss item: 0.259046733379364
test loss item: 0.23673811554908752
test loss item: 0.3682284951210022
test loss item: 0.39221838116645813
test loss item: 0.2577313482761383
test loss item: 0.3518717288970947
test loss item: 0.4112435281276703
test loss item: 0.7470362782478333
test loss item: 0.06025756895542145
test loss item: 0.23060840368270874
test loss item: 0.41930538415908813
test loss item: 0.3359430730342865
test loss item: 0.4596863389015198
test loss item: 0.9314870834350586
test loss item: 0.7035000324249268
test loss item: 0.40896356105804443
test loss item: 0.35917314887046814
test loss item: 0.3614037036895752
test loss item: 0.44090020656585693
test loss item: 0.32526907324790955
test loss item: 0.2949352264404297
test loss item: 0.48846274614334106
test loss item: 0.5605757832527161
test loss item: 0.4811924695968628
test loss item: 0.4545227289199829
test loss item: 0.41561439633369446
test loss item: 0.6076411604881287
test loss item: 0.31660592555999756
test loss item: 0.3044164478778839
test loss item: 0.3174501061439514
test loss item: 0.2340197116136551
test loss item: 0.3459879159927368
test loss item: 0.4733836054801941
test loss item: 0.5686827898025513
test loss item: 0.37904781103134155
test loss item: 0.35233116149902344
test loss item: 0.2610552906990051
test loss item: 0.3881884515285492
test loss item: 0.37522971630096436
test loss item: 0.3937428295612335
test loss item: 0.28696587681770325
test loss item: 0.7534306049346924
test loss item: 0.33989816904067993
test loss item: 0.4542030990123749
test loss item: 0.30633872747421265
test loss item: 0.3230188488960266
test loss item: 0.531600296497345
test loss item: 0.10149317979812622
test loss item: 1.2562055587768555
test loss item: 0.49826180934906006
test loss item: 0.5784661769866943
test loss item: 0.2808033227920532
test loss item: 0.3988070487976074
test loss item: 0.24780753254890442
test loss item: 0.6768083572387695
test loss item: 0.5641013383865356
test loss item: 0.32720494270324707
test loss item: 0.11465073376893997
test loss item: 0.9293727874755859
test loss item: 0.9536556005477905
test loss item: 0.5937883853912354
test loss item: 0.3741113841533661
test loss item: 0.35229167342185974
test loss item: 0.09643923491239548
test loss item: 0.06111721694469452
test loss item: 0.30220261216163635
Epoch [11/50], Training Loss: 0.3365, Testing Loss: 0.4300
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 12/50
train loss item: 0.318637877702713
train loss item: 1.1446057558059692
train loss item: 0.24441656470298767
train loss item: 0.43739497661590576
train loss item: 0.28658393025398254
train loss item: 0.24937263131141663
train loss item: 0.2252013236284256
train loss item: 0.41495928168296814
train loss item: 0.10861784964799881
train loss item: 0.22003062069416046
train loss item: 0.28034526109695435
train loss item: 0.17518939077854156
train loss item: 0.08583085238933563
train loss item: 0.48764750361442566
train loss item: 0.22358311712741852
train loss item: 0.5058114528656006
train loss item: 0.07784561812877655
train loss item: 0.38028228282928467
train loss item: 0.2858195900917053
train loss item: 0.2014017254114151
train loss item: 0.20406530797481537
train loss item: 0.12491460144519806
train loss item: 0.8435080647468567
train loss item: 0.5856256484985352
train loss item: 0.4806426167488098
train loss item: 0.13591182231903076
train loss item: 0.14522697031497955
train loss item: 0.16856014728546143
train loss item: 0.05926134064793587
train loss item: 0.39923959970474243
train loss item: 1.2476084232330322
train loss item: 0.6598173975944519
train loss item: 0.11028368026018143
train loss item: 0.42748281359672546
train loss item: 0.11150426417589188
train loss item: 0.8034762144088745
train loss item: 0.4103754162788391
train loss item: 0.4066591262817383
train loss item: 0.342950701713562
train loss item: 0.2908951938152313
train loss item: 0.24863070249557495
train loss item: 0.2858581244945526
train loss item: 0.4185601472854614
train loss item: 0.2813757658004761
train loss item: 0.47809430956840515
train loss item: 0.13935348391532898
train loss item: 0.1318097710609436
train loss item: 0.5793885588645935
train loss item: 0.27474620938301086
train loss item: 0.14173904061317444
train loss item: 0.4409271776676178
train loss item: 1.0888311862945557
train loss item: 0.06874044239521027
train loss item: 0.19118686020374298
train loss item: 0.6813395619392395
train loss item: 0.22477830946445465
train loss item: 0.3538033962249756
train loss item: 0.2141517996788025
train loss item: 0.1646910011768341
train loss item: 0.10130057483911514
train loss item: 0.8427532315254211
train loss item: 0.7913386225700378
train loss item: 0.2046675831079483
train loss item: 0.2820344865322113
train loss item: 0.15011394023895264
train loss item: 0.4297925531864166
train loss item: 0.3176676332950592
train loss item: 0.16713592410087585
train loss item: 0.25844287872314453
train loss item: 0.20665553212165833
train loss item: 0.17373235523700714
train loss item: 0.08717573434114456
train loss item: 0.16682197153568268
train loss item: 0.21926580369472504
train loss item: 0.07842610031366348
train loss item: 0.109316386282444
train loss item: 0.6065323948860168
train loss item: 0.8510445952415466
train loss item: 0.06471731513738632
train loss item: 0.2590792775154114
train loss item: 0.07278728485107422
train loss item: 0.12045217305421829
train loss item: 0.14970695972442627
train loss item: 0.36046114563941956
train loss item: 0.3079228699207306
train loss item: 0.3731951415538788
train loss item: 1.5809905529022217
train loss item: 0.10661996155977249
train loss item: 0.40498974919319153
test loss item: 0.19222895801067352
test loss item: 0.14337073266506195
test loss item: 0.38957467675209045
test loss item: 0.21392633020877838
test loss item: 0.2347114384174347
test loss item: 0.17028112709522247
test loss item: 1.5736446380615234
test loss item: 0.5895957350730896
test loss item: 0.215876966714859
test loss item: 0.37257522344589233
test loss item: 0.5028024911880493
test loss item: 0.1667214184999466
test loss item: 0.2358415424823761
test loss item: 0.3559458255767822
test loss item: 0.1790776550769806
test loss item: 0.09903771430253983
test loss item: 0.2802101969718933
test loss item: 0.416454017162323
test loss item: 0.6339200735092163
test loss item: 0.3202405869960785
test loss item: 0.5899062156677246
test loss item: 0.353939950466156
test loss item: 0.3380764126777649
test loss item: 0.20046837627887726
test loss item: 0.19344483315944672
test loss item: 0.30865493416786194
test loss item: 0.33334463834762573
test loss item: 0.21317608654499054
test loss item: 0.30932366847991943
test loss item: 0.3689471483230591
test loss item: 0.6103731393814087
test loss item: 0.09721767157316208
test loss item: 0.18509763479232788
test loss item: 0.42158839106559753
test loss item: 0.352631539106369
test loss item: 0.4442368149757385
test loss item: 0.7593390941619873
test loss item: 0.7005831599235535
test loss item: 0.3919951319694519
test loss item: 0.2522567808628082
test loss item: 0.2618401050567627
test loss item: 0.2872113883495331
test loss item: 0.3510647416114807
test loss item: 0.1938813179731369
test loss item: 0.5098052024841309
test loss item: 0.4029577672481537
test loss item: 0.34509968757629395
test loss item: 0.36309704184532166
test loss item: 0.36787697672843933
test loss item: 0.5543680191040039
test loss item: 0.345573753118515
test loss item: 0.2497391402721405
test loss item: 0.27710938453674316
test loss item: 0.1556738317012787
test loss item: 0.3540950119495392
test loss item: 0.5308516621589661
test loss item: 0.46551182866096497
test loss item: 0.2976935803890228
test loss item: 0.28041043877601624
test loss item: 0.25718337297439575
test loss item: 0.43464595079421997
test loss item: 0.2617886960506439
test loss item: 0.27012428641319275
test loss item: 0.22851461172103882
test loss item: 0.6104266047477722
test loss item: 0.2555275559425354
test loss item: 0.3543696701526642
test loss item: 0.2265658974647522
test loss item: 0.30031442642211914
test loss item: 0.4377051889896393
test loss item: 0.09426981210708618
test loss item: 0.940663754940033
test loss item: 0.3588665723800659
test loss item: 0.3710077404975891
test loss item: 0.20345690846443176
test loss item: 0.2698589861392975
test loss item: 0.19517342746257782
test loss item: 0.6530492901802063
test loss item: 0.35961413383483887
test loss item: 0.21754209697246552
test loss item: 0.10604681074619293
test loss item: 0.736163318157196
test loss item: 0.8190256953239441
test loss item: 0.5414702296257019
test loss item: 0.2860914170742035
test loss item: 0.27189379930496216
test loss item: 0.1039949432015419
test loss item: 0.10450989007949829
test loss item: 0.1938287913799286
Epoch [12/50], Training Loss: 0.3434, Testing Loss: 0.3569
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 13/50
train loss item: 0.33129727840423584
train loss item: 0.9997149109840393
train loss item: 0.21371065080165863
train loss item: 0.3767351806163788
train loss item: 0.25306814908981323
train loss item: 0.22630108892917633
train loss item: 0.23450639843940735
train loss item: 0.4015365242958069
train loss item: 0.13999943435192108
train loss item: 0.27346479892730713
train loss item: 0.3580811619758606
train loss item: 0.1971462219953537
train loss item: 0.09402801096439362
train loss item: 0.5317664742469788
train loss item: 0.2703207731246948
train loss item: 0.4701194763183594
train loss item: 0.04668707028031349
train loss item: 0.20773273706436157
train loss item: 0.27877214550971985
train loss item: 0.20459096133708954
train loss item: 0.14312341809272766
train loss item: 0.10213758796453476
train loss item: 0.5534709692001343
train loss item: 0.43283915519714355
train loss item: 0.38100752234458923
train loss item: 0.15521275997161865
train loss item: 0.13771915435791016
train loss item: 0.14530853927135468
train loss item: 0.05245557054877281
train loss item: 0.3519633710384369
train loss item: 0.7048084139823914
train loss item: 0.4351513981819153
train loss item: 0.1390647441148758
train loss item: 0.2052299529314041
train loss item: 0.07566659152507782
train loss item: 0.7835164666175842
train loss item: 0.3105607032775879
train loss item: 0.39337489008903503
train loss item: 0.26320788264274597
train loss item: 0.19296905398368835
train loss item: 0.1653692126274109
train loss item: 0.1877816766500473
train loss item: 0.29439452290534973
train loss item: 0.1744249016046524
train loss item: 0.39429038763046265
train loss item: 0.0691315084695816
train loss item: 0.07783379405736923
train loss item: 0.3002392053604126
train loss item: 0.14925532042980194
train loss item: 0.10666514188051224
train loss item: 0.20137491822242737
train loss item: 0.5146510601043701
train loss item: 0.044546689838171005
train loss item: 0.1570366621017456
train loss item: 0.5121350288391113
train loss item: 0.18984416127204895
train loss item: 0.38213643431663513
train loss item: 0.16193260252475739
train loss item: 0.1096283569931984
train loss item: 0.10584934800863266
train loss item: 0.4363635778427124
train loss item: 0.6641638278961182
train loss item: 0.13822738826274872
train loss item: 0.28772401809692383
train loss item: 0.11517298221588135
train loss item: 0.3399234116077423
train loss item: 0.2815433442592621
train loss item: 0.1686324179172516
train loss item: 0.3118778467178345
train loss item: 0.21918989717960358
train loss item: 0.1777353435754776
train loss item: 0.0999298095703125
train loss item: 0.12240813672542572
train loss item: 0.17501141130924225
train loss item: 0.0900561660528183
train loss item: 0.11938337236642838
train loss item: 0.3852049708366394
train loss item: 0.6177728772163391
train loss item: 0.07459402084350586
train loss item: 0.3411518633365631
train loss item: 0.11362604796886444
train loss item: 0.15428988635540009
train loss item: 0.1666763722896576
train loss item: 0.35002401471138
train loss item: 0.3767087161540985
train loss item: 0.37642550468444824
train loss item: 1.3713458776474
train loss item: 0.10918675363063812
train loss item: 0.312358021736145
test loss item: 0.2422332614660263
test loss item: 0.14215312898159027
test loss item: 0.4014225900173187
test loss item: 0.2725621163845062
test loss item: 0.216861292719841
test loss item: 0.1861467957496643
test loss item: 1.9822262525558472
test loss item: 0.7868183255195618
test loss item: 0.24746696650981903
test loss item: 0.381171315908432
test loss item: 0.5422638058662415
test loss item: 0.22570623457431793
test loss item: 0.2868424952030182
test loss item: 0.45588043332099915
test loss item: 0.18015648424625397
test loss item: 0.09087184816598892
test loss item: 0.37079522013664246
test loss item: 0.37325963377952576
test loss item: 0.7880491614341736
test loss item: 0.4192088842391968
test loss item: 0.4961617588996887
test loss item: 0.46805956959724426
test loss item: 0.37052249908447266
test loss item: 0.24273909628391266
test loss item: 0.22998274862766266
test loss item: 0.329215943813324
test loss item: 0.3848085403442383
test loss item: 0.20814020931720734
test loss item: 0.31651830673217773
test loss item: 0.3965017795562744
test loss item: 0.7326781153678894
test loss item: 0.10028354823589325
test loss item: 0.21951249241828918
test loss item: 0.38977763056755066
test loss item: 0.3164695203304291
test loss item: 0.5196441411972046
test loss item: 0.9086683392524719
test loss item: 0.6942379474639893
test loss item: 0.3908590078353882
test loss item: 0.32055285573005676
test loss item: 0.3455088138580322
test loss item: 0.3370985686779022
test loss item: 0.32027000188827515
test loss item: 0.28523215651512146
test loss item: 0.4521616995334625
test loss item: 0.5164726972579956
test loss item: 0.3730386197566986
test loss item: 0.44958004355430603
test loss item: 0.40472742915153503
test loss item: 0.6226271390914917
test loss item: 0.32104167342185974
test loss item: 0.2935582399368286
test loss item: 0.2952655851840973
test loss item: 0.23781836032867432
test loss item: 0.3163268268108368
test loss item: 0.5016356110572815
test loss item: 0.5726982355117798
test loss item: 0.34210750460624695
test loss item: 0.3259667754173279
test loss item: 0.24973715841770172
test loss item: 0.38719913363456726
test loss item: 0.357831209897995
test loss item: 0.3372289836406708
test loss item: 0.2904375493526459
test loss item: 0.7196665406227112
test loss item: 0.33467960357666016
test loss item: 0.42808160185813904
test loss item: 0.287231981754303
test loss item: 0.2766640782356262
test loss item: 0.600835382938385
test loss item: 0.09001987427473068
test loss item: 1.2101370096206665
test loss item: 0.42818230390548706
test loss item: 0.5132758021354675
test loss item: 0.25646716356277466
test loss item: 0.2992647886276245
test loss item: 0.23471003770828247
test loss item: 0.6036587953567505
test loss item: 0.4745427966117859
test loss item: 0.2566227912902832
test loss item: 0.1195027232170105
test loss item: 0.9104523658752441
test loss item: 0.9472076296806335
test loss item: 0.593033492565155
test loss item: 0.326215922832489
test loss item: 0.31728672981262207
test loss item: 0.11136329174041748
test loss item: 0.10426148772239685
test loss item: 0.2422892451286316
Epoch [13/50], Training Loss: 0.2794, Testing Loss: 0.4073
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 14/50
train loss item: 0.29536378383636475
train loss item: 1.0266008377075195
train loss item: 0.2416808307170868
train loss item: 0.4712778329849243
train loss item: 0.2816067636013031
train loss item: 0.22256717085838318
train loss item: 0.2105690836906433
train loss item: 0.3358517587184906
train loss item: 0.13705092668533325
train loss item: 0.2854313552379608
train loss item: 0.3938833475112915
train loss item: 0.19127589464187622
train loss item: 0.09862038493156433
train loss item: 0.5857881903648376
train loss item: 0.2721717953681946
train loss item: 0.5544509291648865
train loss item: 0.0435786247253418
train loss item: 0.1997734159231186
train loss item: 0.28754451870918274
train loss item: 0.1631728857755661
train loss item: 0.15244540572166443
train loss item: 0.12327562272548676
train loss item: 0.5864306092262268
train loss item: 0.7030378580093384
train loss item: 0.36912548542022705
train loss item: 0.15896287560462952
train loss item: 0.16390447318553925
train loss item: 0.1950402408838272
train loss item: 0.07802194356918335
train loss item: 0.3479628562927246
train loss item: 1.0240167379379272
train loss item: 0.4276982545852661
train loss item: 0.1596965789794922
train loss item: 0.20694613456726074
train loss item: 0.09666904807090759
train loss item: 0.9603357315063477
train loss item: 0.4408138394355774
train loss item: 0.43013039231300354
train loss item: 0.3055254817008972
train loss item: 0.2271418273448944
train loss item: 0.1419747918844223
train loss item: 0.20518575608730316
train loss item: 0.28364723920822144
train loss item: 0.21260780096054077
train loss item: 0.46071505546569824
train loss item: 0.09546293318271637
train loss item: 0.09521100670099258
train loss item: 0.33282914757728577
train loss item: 0.19846585392951965
train loss item: 0.1359979212284088
train loss item: 0.2350052446126938
train loss item: 0.7723526954650879
train loss item: 0.07479821145534515
train loss item: 0.12368158251047134
train loss item: 0.7759438753128052
train loss item: 0.12827356159687042
train loss item: 0.3175370991230011
train loss item: 0.17535126209259033
train loss item: 0.12226687371730804
train loss item: 0.10426902770996094
train loss item: 0.4140704870223999
train loss item: 1.0556013584136963
train loss item: 0.18282225728034973
train loss item: 0.3072420060634613
train loss item: 0.10996603965759277
train loss item: 0.3114738166332245
train loss item: 0.21489524841308594
train loss item: 0.1499783992767334
train loss item: 0.34737053513526917
train loss item: 0.24365638196468353
train loss item: 0.18152661621570587
train loss item: 0.07670807838439941
train loss item: 0.12549355626106262
train loss item: 0.19504958391189575
train loss item: 0.08154816180467606
train loss item: 0.09918345510959625
train loss item: 0.4166429042816162
train loss item: 0.8322312235832214
train loss item: 0.06479673832654953
train loss item: 0.246726393699646
train loss item: 0.14438731968402863
train loss item: 0.1794065535068512
train loss item: 0.18121978640556335
train loss item: 0.26890936493873596
train loss item: 0.4086291491985321
train loss item: 0.25086596608161926
train loss item: 1.413312315940857
train loss item: 0.10846136510372162
train loss item: 0.28361642360687256
test loss item: 0.18608126044273376
test loss item: 0.1126682236790657
test loss item: 0.2996617257595062
test loss item: 0.21027661859989166
test loss item: 0.16469474136829376
test loss item: 0.1370953619480133
test loss item: 1.3456614017486572
test loss item: 0.5307509899139404
test loss item: 0.1742895096540451
test loss item: 0.2790956497192383
test loss item: 0.4074774384498596
test loss item: 0.17212805151939392
test loss item: 0.22500422596931458
test loss item: 0.3011307120323181
test loss item: 0.13827994465827942
test loss item: 0.08431638777256012
test loss item: 0.2763593792915344
test loss item: 0.27114781737327576
test loss item: 0.5560455918312073
test loss item: 0.2950194180011749
test loss item: 0.3369966149330139
test loss item: 0.33608612418174744
test loss item: 0.25073477625846863
test loss item: 0.18463411927223206
test loss item: 0.18311773240566254
test loss item: 0.2912135124206543
test loss item: 0.283197283744812
test loss item: 0.15710151195526123
test loss item: 0.22784408926963806
test loss item: 0.3059382438659668
test loss item: 0.4921945631504059
test loss item: 0.09518337994813919
test loss item: 0.17267344892024994
test loss item: 0.2931827902793884
test loss item: 0.22926920652389526
test loss item: 0.4090108275413513
test loss item: 0.6364297270774841
test loss item: 0.5366259217262268
test loss item: 0.2809559404850006
test loss item: 0.23262685537338257
test loss item: 0.26374486088752747
test loss item: 0.27577441930770874
test loss item: 0.2381889373064041
test loss item: 0.21147441864013672
test loss item: 0.29854366183280945
test loss item: 0.3708484172821045
test loss item: 0.26284903287887573
test loss item: 0.3205834627151489
test loss item: 0.291806161403656
test loss item: 0.46935537457466125
test loss item: 0.22174474596977234
test loss item: 0.23302826285362244
test loss item: 0.22265011072158813
test loss item: 0.172349214553833
test loss item: 0.2333243042230606
test loss item: 0.3674697279930115
test loss item: 0.4333743453025818
test loss item: 0.21352644264698029
test loss item: 0.23953217267990112
test loss item: 0.1911741942167282
test loss item: 0.29965195059776306
test loss item: 0.2581864893436432
test loss item: 0.24577230215072632
test loss item: 0.22736646234989166
test loss item: 0.5118943452835083
test loss item: 0.2585594356060028
test loss item: 0.3193657696247101
test loss item: 0.22103117406368256
test loss item: 0.2350127249956131
test loss item: 0.38356924057006836
test loss item: 0.07855504751205444
test loss item: 0.8221140503883362
test loss item: 0.2928920090198517
test loss item: 0.3578743040561676
test loss item: 0.19320784509181976
test loss item: 0.2175140380859375
test loss item: 0.17843632400035858
test loss item: 0.5049043297767639
test loss item: 0.30178382992744446
test loss item: 0.18660986423492432
test loss item: 0.10393760353326797
test loss item: 0.6505456566810608
test loss item: 0.6507561206817627
test loss item: 0.4463253617286682
test loss item: 0.22950412333011627
test loss item: 0.2936309278011322
test loss item: 0.09798891842365265
test loss item: 0.09426061064004898
test loss item: 0.2819440960884094
Epoch [14/50], Training Loss: 0.3072, Testing Loss: 0.2986
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 15/50
train loss item: 0.28157997131347656
train loss item: 0.614370584487915
train loss item: 0.19323688745498657
train loss item: 0.32163283228874207
train loss item: 0.22640106081962585
train loss item: 0.22774077951908112
train loss item: 0.22244217991828918
train loss item: 0.5046005249023438
train loss item: 0.11248230189085007
train loss item: 0.2252214103937149
train loss item: 0.256856232881546
train loss item: 0.16103875637054443
train loss item: 0.08507596701383591
train loss item: 0.48567503690719604
train loss item: 0.24567720293998718
train loss item: 0.4722442328929901
train loss item: 0.05499917268753052
train loss item: 0.1716080904006958
train loss item: 0.2694978415966034
train loss item: 0.1493184119462967
train loss item: 0.14689795672893524
train loss item: 0.12322339415550232
train loss item: 0.48665517568588257
train loss item: 0.5148816704750061
train loss item: 0.3446958363056183
train loss item: 0.18043804168701172
train loss item: 0.12596885859966278
train loss item: 0.16325008869171143
train loss item: 0.048742372542619705
train loss item: 0.3134616017341614
train loss item: 0.964735746383667
train loss item: 0.4094257056713104
train loss item: 0.11318252980709076
train loss item: 0.17872929573059082
train loss item: 0.09898339956998825
train loss item: 0.6528072953224182
train loss item: 0.3693495988845825
train loss item: 0.40857475996017456
train loss item: 0.2487892359495163
train loss item: 0.19947664439678192
train loss item: 0.18250834941864014
train loss item: 0.2104180008172989
train loss item: 0.33016154170036316
train loss item: 0.21418775618076324
train loss item: 0.39209824800491333
train loss item: 0.08253051340579987
train loss item: 0.08163260668516159
train loss item: 0.3737960755825043
train loss item: 0.18897227942943573
train loss item: 0.10337524861097336
train loss item: 0.2626296877861023
train loss item: 0.6102070808410645
train loss item: 0.055917225778102875
train loss item: 0.1497916579246521
train loss item: 0.4633446931838989
train loss item: 0.14872920513153076
train loss item: 0.33841484785079956
train loss item: 0.1387798935174942
train loss item: 0.11066649109125137
train loss item: 0.09340839087963104
train loss item: 0.4072830379009247
train loss item: 0.8021167516708374
train loss item: 0.15852712094783783
train loss item: 0.2836247384548187
train loss item: 0.09645512700080872
train loss item: 0.28455376625061035
train loss item: 0.1993224024772644
train loss item: 0.16307011246681213
train loss item: 0.3202333450317383
train loss item: 0.21445299685001373
train loss item: 0.16376318037509918
train loss item: 0.08817725628614426
train loss item: 0.1211373582482338
train loss item: 0.1614314615726471
train loss item: 0.07449759542942047
train loss item: 0.10522924363613129
train loss item: 0.37264278531074524
train loss item: 0.6700818538665771
train loss item: 0.06570130586624146
train loss item: 0.3166355490684509
train loss item: 0.11208757758140564
train loss item: 0.15959009528160095
train loss item: 0.1644025295972824
train loss item: 0.28499889373779297
train loss item: 0.40543901920318604
train loss item: 0.2677260637283325
train loss item: 1.37565016746521
train loss item: 0.09292874485254288
train loss item: 0.2516884207725525
test loss item: 0.2021852284669876
test loss item: 0.1240730732679367
test loss item: 0.3291606307029724
test loss item: 0.2363474816083908
test loss item: 0.1843348741531372
test loss item: 0.16100859642028809
test loss item: 1.68124520778656
test loss item: 0.6901073455810547
test loss item: 0.20518092811107635
test loss item: 0.30652916431427
test loss item: 0.44759753346443176
test loss item: 0.2023928463459015
test loss item: 0.23530375957489014
test loss item: 0.332461953163147
test loss item: 0.15546853840351105
test loss item: 0.08797654509544373
test loss item: 0.317321240901947
test loss item: 0.29971078038215637
test loss item: 0.6642113924026489
test loss item: 0.3344034254550934
test loss item: 0.3685306906700134
test loss item: 0.4098605513572693
test loss item: 0.2924712300300598
test loss item: 0.2126038819551468
test loss item: 0.20354901254177094
test loss item: 0.2846205234527588
test loss item: 0.31185290217399597
test loss item: 0.17934328317642212
test loss item: 0.266507625579834
test loss item: 0.3142855167388916
test loss item: 0.6205723285675049
test loss item: 0.09852592647075653
test loss item: 0.19304873049259186
test loss item: 0.31611886620521545
test loss item: 0.253266304731369
test loss item: 0.4111863672733307
test loss item: 0.7697519659996033
test loss item: 0.5468342900276184
test loss item: 0.3242066502571106
test loss item: 0.2841288447380066
test loss item: 0.30500662326812744
test loss item: 0.26099222898483276
test loss item: 0.25959786772727966
test loss item: 0.25211167335510254
test loss item: 0.33183732628822327
test loss item: 0.42081692814826965
test loss item: 0.28760290145874023
test loss item: 0.3264176845550537
test loss item: 0.3511732816696167
test loss item: 0.5350735187530518
test loss item: 0.26030296087265015
test loss item: 0.21905837953090668
test loss item: 0.26101306080818176
test loss item: 0.20138892531394958
test loss item: 0.2651142477989197
test loss item: 0.42745184898376465
test loss item: 0.4894134998321533
test loss item: 0.22743183374404907
test loss item: 0.2756374478340149
test loss item: 0.22272059321403503
test loss item: 0.3057996332645416
test loss item: 0.3182883858680725
test loss item: 0.28279703855514526
test loss item: 0.2601887285709381
test loss item: 0.6106211543083191
test loss item: 0.290437251329422
test loss item: 0.36601847410202026
test loss item: 0.25264307856559753
test loss item: 0.2360139936208725
test loss item: 0.4918749928474426
test loss item: 0.08811480551958084
test loss item: 1.0355015993118286
test loss item: 0.32566991448402405
test loss item: 0.44176769256591797
test loss item: 0.2149195522069931
test loss item: 0.23703452944755554
test loss item: 0.20738071203231812
test loss item: 0.5067458152770996
test loss item: 0.3419218063354492
test loss item: 0.2083796113729477
test loss item: 0.11858568340539932
test loss item: 0.7720366716384888
test loss item: 0.7894129753112793
test loss item: 0.4811401665210724
test loss item: 0.27848005294799805
test loss item: 0.2609419524669647
test loss item: 0.10945252329111099
test loss item: 0.09969551116228104
test loss item: 0.19022968411445618
Epoch [15/50], Training Loss: 0.2707, Testing Loss: 0.3389
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 16/50
train loss item: 0.28206706047058105
train loss item: 0.7164016366004944
train loss item: 0.16717223823070526
train loss item: 0.3535502851009369
train loss item: 0.19204077124595642
train loss item: 0.2007530778646469
train loss item: 0.18582771718502045
train loss item: 0.330049604177475
train loss item: 0.11353000998497009
train loss item: 0.18451112508773804
train loss item: 0.26127490401268005
train loss item: 0.14673109352588654
train loss item: 0.07295162975788116
train loss item: 0.4579986333847046
train loss item: 0.23541422188282013
train loss item: 0.3315236270427704
train loss item: 0.049495209008455276
train loss item: 0.2051338255405426
train loss item: 0.24136894941329956
train loss item: 0.1553475260734558
train loss item: 0.14175006747245789
train loss item: 0.09322606027126312
train loss item: 0.420878142118454
train loss item: 0.42562928795814514
train loss item: 0.3035496771335602
train loss item: 0.12435479462146759
train loss item: 0.1254986673593521
train loss item: 0.162246435880661
train loss item: 0.05090617015957832
train loss item: 0.3082575500011444
train loss item: 0.6974407434463501
train loss item: 0.3704908490180969
train loss item: 0.10743345320224762
train loss item: 0.16990208625793457
train loss item: 0.0644209012389183
train loss item: 0.7547347545623779
train loss item: 0.32226285338401794
train loss item: 0.3690475821495056
train loss item: 0.23795579373836517
train loss item: 0.179817333817482
train loss item: 0.15758037567138672
train loss item: 0.19203738868236542
train loss item: 0.2808782160282135
train loss item: 0.18320970237255096
train loss item: 0.387305349111557
train loss item: 0.09424052387475967
train loss item: 0.07804389297962189
train loss item: 0.21140415966510773
train loss item: 0.14053380489349365
train loss item: 0.11859752982854843
train loss item: 0.16668222844600677
train loss item: 0.535613477230072
train loss item: 0.05994803458452225
train loss item: 0.1275293529033661
train loss item: 0.4701504409313202
train loss item: 0.13193130493164062
train loss item: 0.2632907032966614
train loss item: 0.12542396783828735
train loss item: 0.078042171895504
train loss item: 0.08412493020296097
train loss item: 0.4007568359375
train loss item: 0.5190532803535461
train loss item: 0.1542411595582962
train loss item: 0.30124473571777344
train loss item: 0.10241521149873734
train loss item: 0.2879505455493927
train loss item: 0.19662564992904663
train loss item: 0.1459038257598877
train loss item: 0.32724064588546753
train loss item: 0.23272854089736938
train loss item: 0.17609499394893646
train loss item: 0.07990258932113647
train loss item: 0.0945497378706932
train loss item: 0.18606135249137878
train loss item: 0.06293761730194092
train loss item: 0.08412231504917145
train loss item: 0.3166799545288086
train loss item: 0.7933341860771179
train loss item: 0.05368904024362564
train loss item: 0.21700696647167206
train loss item: 0.11293603479862213
train loss item: 0.11082957684993744
train loss item: 0.16655515134334564
train loss item: 0.28583940863609314
train loss item: 0.38372430205345154
train loss item: 0.21795019507408142
train loss item: 0.9770107865333557
train loss item: 0.07550337165594101
train loss item: 0.24066679179668427
test loss item: 0.17618925869464874
test loss item: 0.10630370676517487
test loss item: 0.27692103385925293
test loss item: 0.2044932246208191
test loss item: 0.15678724646568298
test loss item: 0.13940073549747467
test loss item: 1.4862792491912842
test loss item: 0.6030991077423096
test loss item: 0.16350701451301575
test loss item: 0.2524121105670929
test loss item: 0.3910384178161621
test loss item: 0.16074073314666748
test loss item: 0.20636582374572754
test loss item: 0.28716516494750977
test loss item: 0.13139036297798157
test loss item: 0.06921689957380295
test loss item: 0.281629353761673
test loss item: 0.24342666566371918
test loss item: 0.578521728515625
test loss item: 0.29341286420822144
test loss item: 0.25700047612190247
test loss item: 0.35921379923820496
test loss item: 0.2710017263889313
test loss item: 0.1836032122373581
test loss item: 0.167626291513443
test loss item: 0.25593599677085876
test loss item: 0.26390159130096436
test loss item: 0.15196862816810608
test loss item: 0.22206337749958038
test loss item: 0.27168017625808716
test loss item: 0.5345225930213928
test loss item: 0.07275637239217758
test loss item: 0.1687682867050171
test loss item: 0.24954868853092194
test loss item: 0.20186099410057068
test loss item: 0.3329774737358093
test loss item: 0.6712881922721863
test loss item: 0.4845421314239502
test loss item: 0.26186561584472656
test loss item: 0.24543355405330658
test loss item: 0.264483779668808
test loss item: 0.26625001430511475
test loss item: 0.20515333116054535
test loss item: 0.21871113777160645
test loss item: 0.24237433075904846
test loss item: 0.3736971914768219
test loss item: 0.27811992168426514
test loss item: 0.2965143322944641
test loss item: 0.2954099178314209
test loss item: 0.44593656063079834
test loss item: 0.20778824388980865
test loss item: 0.20528778433799744
test loss item: 0.2262248396873474
test loss item: 0.17185448110103607
test loss item: 0.22068506479263306
test loss item: 0.31532421708106995
test loss item: 0.4223614037036896
test loss item: 0.19750677049160004
test loss item: 0.24444212019443512
test loss item: 0.1824345588684082
test loss item: 0.24113662540912628
test loss item: 0.28041183948516846
test loss item: 0.25525885820388794
test loss item: 0.2097342163324356
test loss item: 0.5341310501098633
test loss item: 0.2496909648180008
test loss item: 0.3252612054347992
test loss item: 0.2148980349302292
test loss item: 0.19984170794487
test loss item: 0.40652334690093994
test loss item: 0.06625878810882568
test loss item: 0.9128981232643127
test loss item: 0.28778064250946045
test loss item: 0.3893905282020569
test loss item: 0.19380128383636475
test loss item: 0.2411591112613678
test loss item: 0.1778949350118637
test loss item: 0.4960194528102875
test loss item: 0.2861383855342865
test loss item: 0.18670882284641266
test loss item: 0.0930844098329544
test loss item: 0.6795920133590698
test loss item: 0.6775140166282654
test loss item: 0.42962080240249634
test loss item: 0.23753613233566284
test loss item: 0.24052222073078156
test loss item: 0.08636786788702011
test loss item: 0.07597390562295914
test loss item: 0.19423598051071167
Epoch [16/50], Training Loss: 0.2416, Testing Loss: 0.2920
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 17/50
train loss item: 0.24595345556735992
train loss item: 0.587264358997345
train loss item: 0.14314718544483185
train loss item: 0.24590304493904114
train loss item: 0.18664570152759552
train loss item: 0.17642225325107574
train loss item: 0.17903658747673035
train loss item: 0.3632439076900482
train loss item: 0.09460283815860748
train loss item: 0.17275086045265198
train loss item: 0.2092898041009903
train loss item: 0.12866705656051636
train loss item: 0.06548581272363663
train loss item: 0.4354759752750397
train loss item: 0.2151232659816742
train loss item: 0.4055232107639313
train loss item: 0.06207789108157158
train loss item: 0.19198238849639893
train loss item: 0.23277276754379272
train loss item: 0.13220950961112976
train loss item: 0.11798477917909622
train loss item: 0.1038656234741211
train loss item: 0.47328880429267883
train loss item: 0.38400810956954956
train loss item: 0.3420170545578003
train loss item: 0.12901976704597473
train loss item: 0.13097885251045227
train loss item: 0.1281188279390335
train loss item: 0.05368328467011452
train loss item: 0.34520530700683594
train loss item: 0.77229243516922
train loss item: 0.43687522411346436
train loss item: 0.08713509887456894
train loss item: 0.16802339255809784
train loss item: 0.07883148640394211
train loss item: 0.5474579930305481
train loss item: 0.27545225620269775
train loss item: 0.3406592011451721
train loss item: 0.24994955956935883
train loss item: 0.20118644833564758
train loss item: 0.172715425491333
train loss item: 0.19845934212207794
train loss item: 0.3081894516944885
train loss item: 0.17324402928352356
train loss item: 0.37011629343032837
train loss item: 0.07482363283634186
train loss item: 0.06962072849273682
train loss item: 0.26906949281692505
train loss item: 0.1488388627767563
train loss item: 0.07540171593427658
train loss item: 0.17030300199985504
train loss item: 0.3721020519733429
train loss item: 0.05474551022052765
train loss item: 0.1498209685087204
train loss item: 0.4341371953487396
train loss item: 0.19694583117961884
train loss item: 0.3577963411808014
train loss item: 0.1387547105550766
train loss item: 0.11074566096067429
train loss item: 0.08701229095458984
train loss item: 0.33336442708969116
train loss item: 0.5071816444396973
train loss item: 0.15955428779125214
train loss item: 0.26006948947906494
train loss item: 0.0834803581237793
train loss item: 0.2661775052547455
train loss item: 0.2151232659816742
train loss item: 0.17056363821029663
train loss item: 0.3400475084781647
train loss item: 0.25466907024383545
train loss item: 0.19999690353870392
train loss item: 0.1289781928062439
train loss item: 0.11611063778400421
train loss item: 0.21628788113594055
train loss item: 0.058273956179618835
train loss item: 0.07605351507663727
train loss item: 0.2696651518344879
train loss item: 0.8383260369300842
train loss item: 0.052430152893066406
train loss item: 0.22117933630943298
train loss item: 0.08656827360391617
train loss item: 0.09219338744878769
train loss item: 0.14867252111434937
train loss item: 0.28928032517433167
train loss item: 0.4418174624443054
train loss item: 0.24371784925460815
train loss item: 0.7166187763214111
train loss item: 0.07408425956964493
train loss item: 0.3041769564151764
test loss item: 0.15868443250656128
test loss item: 0.13878309726715088
test loss item: 0.2667474150657654
test loss item: 0.190524622797966
test loss item: 0.18541714549064636
test loss item: 0.17535300552845
test loss item: 1.2897518873214722
test loss item: 0.5435221195220947
test loss item: 0.17553626000881195
test loss item: 0.2639276385307312
test loss item: 0.40216970443725586
test loss item: 0.13036972284317017
test loss item: 0.19795431196689606
test loss item: 0.21136842668056488
test loss item: 0.1654869019985199
test loss item: 0.10550552606582642
test loss item: 0.23377373814582825
test loss item: 0.2570611238479614
test loss item: 0.5340431928634644
test loss item: 0.2706867456436157
test loss item: 0.2487642616033554
test loss item: 0.3058631122112274
test loss item: 0.3090234398841858
test loss item: 0.19513076543807983
test loss item: 0.14944422245025635
test loss item: 0.2588578164577484
test loss item: 0.266156405210495
test loss item: 0.1774301528930664
test loss item: 0.21816493570804596
test loss item: 0.27617278695106506
test loss item: 0.5090100765228271
test loss item: 0.1139313280582428
test loss item: 0.18644195795059204
test loss item: 0.23938767611980438
test loss item: 0.2162439376115799
test loss item: 0.3680970072746277
test loss item: 0.6055574417114258
test loss item: 0.5220557451248169
test loss item: 0.2511496841907501
test loss item: 0.2463383823633194
test loss item: 0.2274267077445984
test loss item: 0.2812972962856293
test loss item: 0.21853910386562347
test loss item: 0.17424584925174713
test loss item: 0.22591407597064972
test loss item: 0.33730819821357727
test loss item: 0.31311625242233276
test loss item: 0.30563613772392273
test loss item: 0.2851225435733795
test loss item: 0.44927915930747986
test loss item: 0.226158007979393
test loss item: 0.21374814212322235
test loss item: 0.2284158170223236
test loss item: 0.12868642807006836
test loss item: 0.2539636492729187
test loss item: 0.3704017996788025
test loss item: 0.40357035398483276
test loss item: 0.15544933080673218
test loss item: 0.23598478734493256
test loss item: 0.2012784779071808
test loss item: 0.27755531668663025
test loss item: 0.25466957688331604
test loss item: 0.23180148005485535
test loss item: 0.18082433938980103
test loss item: 0.49943679571151733
test loss item: 0.21137654781341553
test loss item: 0.31340861320495605
test loss item: 0.18409854173660278
test loss item: 0.1898944228887558
test loss item: 0.42677393555641174
test loss item: 0.09906933456659317
test loss item: 0.8057054281234741
test loss item: 0.21739114820957184
test loss item: 0.3206138610839844
test loss item: 0.17607299983501434
test loss item: 0.2896590530872345
test loss item: 0.1894271969795227
test loss item: 0.5111510157585144
test loss item: 0.20503607392311096
test loss item: 0.1748952567577362
test loss item: 0.12474262714385986
test loss item: 0.6151308417320251
test loss item: 0.6276789307594299
test loss item: 0.4367186427116394
test loss item: 0.2477293163537979
test loss item: 0.21054910123348236
test loss item: 0.1193954348564148
test loss item: 0.1161632239818573
test loss item: 0.160695880651474
Epoch [17/50], Training Loss: 0.2352, Testing Loss: 0.2833
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 18/50
train loss item: 0.2563544809818268
train loss item: 0.6102410554885864
train loss item: 0.13997846841812134
train loss item: 0.27318498492240906
train loss item: 0.14492712914943695
train loss item: 0.17774520814418793
train loss item: 0.18111348152160645
train loss item: 0.27117279171943665
train loss item: 0.11766164004802704
train loss item: 0.19528912007808685
train loss item: 0.2559701204299927
train loss item: 0.14584125578403473
train loss item: 0.07286904752254486
train loss item: 0.4240075647830963
train loss item: 0.1921335905790329
train loss item: 0.44260677695274353
train loss item: 0.04872597008943558
train loss item: 0.14412711560726166
train loss item: 0.17441798746585846
train loss item: 0.13538584113121033
train loss item: 0.09820404648780823
train loss item: 0.10440867394208908
train loss item: 0.5281165242195129
train loss item: 0.22832517325878143
train loss item: 0.277924507856369
train loss item: 0.18613716959953308
train loss item: 0.09514756500720978
train loss item: 0.12119349837303162
train loss item: 0.0573711171746254
train loss item: 0.4077591300010681
train loss item: 0.724250078201294
train loss item: 0.28236424922943115
train loss item: 0.07244518399238586
train loss item: 0.23997123539447784
train loss item: 0.043641965836286545
train loss item: 0.7349328398704529
train loss item: 0.3891735374927521
train loss item: 0.4790348410606384
train loss item: 0.43880775570869446
train loss item: 0.3638405501842499
train loss item: 0.1865396499633789
train loss item: 0.2887691855430603
train loss item: 0.31084197759628296
train loss item: 0.19533628225326538
train loss item: 0.37186020612716675
train loss item: 0.10664955526590347
train loss item: 0.08726029098033905
train loss item: 0.3384762704372406
train loss item: 0.21344564855098724
train loss item: 0.1303280144929886
train loss item: 0.22824738919734955
train loss item: 0.5723860859870911
train loss item: 0.06970036029815674
train loss item: 0.20177626609802246
train loss item: 0.5382452607154846
train loss item: 0.18270546197891235
train loss item: 0.2523999512195587
train loss item: 0.1302744299173355
train loss item: 0.13068558275699615
train loss item: 0.09202626347541809
train loss item: 0.34849023818969727
train loss item: 0.5262206196784973
train loss item: 0.20052795112133026
train loss item: 0.3214479684829712
train loss item: 0.12100657820701599
train loss item: 0.27171266078948975
train loss item: 0.4405094087123871
train loss item: 0.16429179906845093
train loss item: 0.2900833189487457
train loss item: 0.19806057214736938
train loss item: 0.16121165454387665
train loss item: 0.09246506541967392
train loss item: 0.11724866181612015
train loss item: 0.16929705440998077
train loss item: 0.08416885882616043
train loss item: 0.10292137414216995
train loss item: 0.2827035188674927
train loss item: 0.7459436058998108
train loss item: 0.06682782620191574
train loss item: 0.23155508935451508
train loss item: 0.11400432139635086
train loss item: 0.14561401307582855
train loss item: 0.15216444432735443
train loss item: 0.41602185368537903
train loss item: 0.6023497581481934
train loss item: 0.2175217568874359
train loss item: 0.8844995498657227
train loss item: 0.09582604467868805
train loss item: 0.18521273136138916
test loss item: 0.18042637407779694
test loss item: 0.10219239443540573
test loss item: 0.2678214907646179
test loss item: 0.20966008305549622
test loss item: 0.1704324185848236
test loss item: 0.1761881709098816
test loss item: 1.7256213426589966
test loss item: 0.709500253200531
test loss item: 0.15050309896469116
test loss item: 0.22428342700004578
test loss item: 0.44516709446907043
test loss item: 0.15844161808490753
test loss item: 0.18154551088809967
test loss item: 0.2649393379688263
test loss item: 0.13058462738990784
test loss item: 0.06764490157365799
test loss item: 0.29682326316833496
test loss item: 0.2055620700120926
test loss item: 0.6572617888450623
test loss item: 0.2946476340293884
test loss item: 0.20945368707180023
test loss item: 0.3985351622104645
test loss item: 0.27632611989974976
test loss item: 0.19718429446220398
test loss item: 0.16050627827644348
test loss item: 0.24976299703121185
test loss item: 0.25665807723999023
test loss item: 0.16201409697532654
test loss item: 0.23256631195545197
test loss item: 0.24828436970710754
test loss item: 0.6149173974990845
test loss item: 0.07728094607591629
test loss item: 0.17576035857200623
test loss item: 0.23543162643909454
test loss item: 0.1709149330854416
test loss item: 0.32522568106651306
test loss item: 0.7590634226799011
test loss item: 0.5844346284866333
test loss item: 0.2519903779029846
test loss item: 0.29046574234962463
test loss item: 0.28617191314697266
test loss item: 0.26001566648483276
test loss item: 0.1609519124031067
test loss item: 0.22923001646995544
test loss item: 0.2001114785671234
test loss item: 0.4137459099292755
test loss item: 0.2706425189971924
test loss item: 0.2605612277984619
test loss item: 0.30147311091423035
test loss item: 0.47961342334747314
test loss item: 0.1604110449552536
test loss item: 0.1757071316242218
test loss item: 0.21320436894893646
test loss item: 0.16540449857711792
test loss item: 0.18279936909675598
test loss item: 0.2972370386123657
test loss item: 0.47417500615119934
test loss item: 0.18034832179546356
test loss item: 0.23987755179405212
test loss item: 0.1453835666179657
test loss item: 0.18323028087615967
test loss item: 0.3074391782283783
test loss item: 0.2591848075389862
test loss item: 0.2077852487564087
test loss item: 0.6071006059646606
test loss item: 0.2557579278945923
test loss item: 0.3315126299858093
test loss item: 0.22935529053211212
test loss item: 0.19565613567829132
test loss item: 0.46133172512054443
test loss item: 0.07600196450948715
test loss item: 1.0640560388565063
test loss item: 0.27830058336257935
test loss item: 0.4379708170890808
test loss item: 0.18442097306251526
test loss item: 0.23770904541015625
test loss item: 0.191101536154747
test loss item: 0.6032776236534119
test loss item: 0.30266842246055603
test loss item: 0.20764587819576263
test loss item: 0.10790076106786728
test loss item: 0.7868863940238953
test loss item: 0.7560699582099915
test loss item: 0.4907737076282501
test loss item: 0.2347748577594757
test loss item: 0.22508785128593445
test loss item: 0.09888536483049393
test loss item: 0.07672721147537231
test loss item: 0.20747409760951996
Epoch [18/50], Training Loss: 0.2545, Testing Loss: 0.3056
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 19/50
train loss item: 0.2561708390712738
train loss item: 0.5527520775794983
train loss item: 0.13017071783542633
train loss item: 0.25227779150009155
train loss item: 0.1687733381986618
train loss item: 0.1610960066318512
train loss item: 0.14905095100402832
train loss item: 0.5237956047058105
train loss item: 0.07113067060709
train loss item: 0.11491796374320984
train loss item: 0.1689889132976532
train loss item: 0.12404822558164597
train loss item: 0.0692804753780365
train loss item: 0.40939202904701233
train loss item: 0.23308831453323364
train loss item: 0.33987557888031006
train loss item: 0.05377363786101341
train loss item: 0.185257688164711
train loss item: 0.22181618213653564
train loss item: 0.09890013933181763
train loss item: 0.12281467765569687
train loss item: 0.09791507571935654
train loss item: 0.4090460240840912
train loss item: 0.3354650139808655
train loss item: 0.27872511744499207
train loss item: 0.12056682258844376
train loss item: 0.10542742908000946
train loss item: 0.1348690539598465
train loss item: 0.04807867854833603
train loss item: 0.21784783899784088
train loss item: 0.46066805720329285
train loss item: 0.5176537036895752
train loss item: 0.08340909332036972
train loss item: 0.15786561369895935
train loss item: 0.06245775148272514
train loss item: 0.7077229022979736
train loss item: 0.274220734834671
train loss item: 0.2798900604248047
train loss item: 0.2544454038143158
train loss item: 0.2010178416967392
train loss item: 0.16872721910476685
train loss item: 0.24806198477745056
train loss item: 0.33417731523513794
train loss item: 0.19671039283275604
train loss item: 0.43779152631759644
train loss item: 0.08217211812734604
train loss item: 0.06927721202373505
train loss item: 0.34398525953292847
train loss item: 0.17718210816383362
train loss item: 0.09079936146736145
train loss item: 0.25583603978157043
train loss item: 0.4621528685092926
train loss item: 0.06629273295402527
train loss item: 0.13529019057750702
train loss item: 0.44397062063217163
train loss item: 0.12152902781963348
train loss item: 0.31492823362350464
train loss item: 0.10869565606117249
train loss item: 0.13332460820674896
train loss item: 0.11359133571386337
train loss item: 0.2945774793624878
train loss item: 0.5554704070091248
train loss item: 0.14230303466320038
train loss item: 0.1993945986032486
train loss item: 0.07984845340251923
train loss item: 0.2508462965488434
train loss item: 0.24032306671142578
train loss item: 0.15038847923278809
train loss item: 0.36660510301589966
train loss item: 0.2609763741493225
train loss item: 0.2163572907447815
train loss item: 0.1428380310535431
train loss item: 0.14753761887550354
train loss item: 0.2588229775428772
train loss item: 0.04871370643377304
train loss item: 0.08147793263196945
train loss item: 0.3110622465610504
train loss item: 1.0463593006134033
train loss item: 0.05998416244983673
train loss item: 0.18308797478675842
train loss item: 0.07090561836957932
train loss item: 0.10231557488441467
train loss item: 0.11708317697048187
train loss item: 0.32754868268966675
train loss item: 0.4048103988170624
train loss item: 0.2197033166885376
train loss item: 0.4789099097251892
train loss item: 0.06757669895887375
train loss item: 0.3110354542732239
test loss item: 0.11522111296653748
test loss item: 0.07103869318962097
test loss item: 0.29024985432624817
test loss item: 0.1476014256477356
test loss item: 0.12757425010204315
test loss item: 0.09384746104478836
test loss item: 1.2629390954971313
test loss item: 0.4993520975112915
test loss item: 0.13213782012462616
test loss item: 0.2100461721420288
test loss item: 0.4849715828895569
test loss item: 0.10047487169504166
test loss item: 0.16359303891658783
test loss item: 0.18795540928840637
test loss item: 0.09191754460334778
test loss item: 0.051184650510549545
test loss item: 0.22132326662540436
test loss item: 0.18932302296161652
test loss item: 0.5086714029312134
test loss item: 0.23605187237262726
test loss item: 0.19721536338329315
test loss item: 0.28669339418411255
test loss item: 0.1772577315568924
test loss item: 0.1317516714334488
test loss item: 0.11184801161289215
test loss item: 0.19540704786777496
test loss item: 0.21153464913368225
test loss item: 0.11171513050794601
test loss item: 0.16935385763645172
test loss item: 0.220027357339859
test loss item: 0.4870321750640869
test loss item: 0.04601622372865677
test loss item: 0.1177331879734993
test loss item: 0.20849043130874634
test loss item: 0.17773185670375824
test loss item: 0.270635187625885
test loss item: 0.5842199325561523
test loss item: 0.751474142074585
test loss item: 0.20241840183734894
test loss item: 0.18483975529670715
test loss item: 0.2086692750453949
test loss item: 0.15624874830245972
test loss item: 0.12945839762687683
test loss item: 0.15001219511032104
test loss item: 0.16206225752830505
test loss item: 0.3304281234741211
test loss item: 0.17481042444705963
test loss item: 0.2304389774799347
test loss item: 0.26974034309387207
test loss item: 0.40391018986701965
test loss item: 0.145276740193367
test loss item: 0.1579822599887848
test loss item: 0.15958690643310547
test loss item: 0.09579920023679733
test loss item: 0.15501125156879425
test loss item: 0.3815044164657593
test loss item: 0.38618025183677673
test loss item: 0.1423027515411377
test loss item: 0.19287827610969543
test loss item: 0.12095673382282257
test loss item: 0.16960859298706055
test loss item: 0.23823551833629608
test loss item: 0.18691858649253845
test loss item: 0.16928964853286743
test loss item: 0.5422224998474121
test loss item: 0.19065815210342407
test loss item: 0.2751607596874237
test loss item: 0.17431551218032837
test loss item: 0.21907800436019897
test loss item: 0.34906962513923645
test loss item: 0.04499632492661476
test loss item: 0.7662131190299988
test loss item: 0.19853058457374573
test loss item: 0.3019721806049347
test loss item: 0.14359690248966217
test loss item: 0.139555424451828
test loss item: 0.13082446157932281
test loss item: 0.8159998655319214
test loss item: 0.23634301126003265
test loss item: 0.12809793651103973
test loss item: 0.05511694401502609
test loss item: 0.6544970273971558
test loss item: 0.5805450677871704
test loss item: 0.5729017853736877
test loss item: 0.1777910590171814
test loss item: 0.17261555790901184
test loss item: 0.05100727081298828
test loss item: 0.04361063241958618
test loss item: 0.12136506289243698
Epoch [19/50], Training Loss: 0.2314, Testing Loss: 0.2476
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 20/50
train loss item: 0.2347777932882309
train loss item: 0.42044782638549805
train loss item: 0.14777474105358124
train loss item: 0.23129874467849731
train loss item: 0.1517406404018402
train loss item: 0.14511895179748535
train loss item: 0.18661031126976013
train loss item: 0.2598097622394562
train loss item: 0.08472482860088348
train loss item: 0.1648557484149933
train loss item: 0.17372897267341614
train loss item: 0.1411508172750473
train loss item: 0.07654552161693573
train loss item: 0.34950241446495056
train loss item: 0.20621219277381897
train loss item: 0.404773473739624
train loss item: 0.033756885677576065
train loss item: 0.11590371280908585
train loss item: 0.21298013627529144
train loss item: 0.13771656155586243
train loss item: 0.09853652119636536
train loss item: 0.08228228241205215
train loss item: 0.4539388418197632
train loss item: 0.23853975534439087
train loss item: 0.2891016900539398
train loss item: 0.12886959314346313
train loss item: 0.09226202219724655
train loss item: 0.17017687857151031
train loss item: 0.05562272295355797
train loss item: 0.3114446997642517
train loss item: 0.5220332741737366
train loss item: 0.3427136540412903
train loss item: 0.0764593780040741
train loss item: 0.1866142302751541
train loss item: 0.07830885052680969
train loss item: 0.7951930165290833
train loss item: 0.33632397651672363
train loss item: 0.32257550954818726
train loss item: 0.24635642766952515
train loss item: 0.1857399344444275
train loss item: 0.16357479989528656
train loss item: 0.17208722233772278
train loss item: 0.2985570728778839
train loss item: 0.18190646171569824
train loss item: 0.4257495105266571
train loss item: 0.08522765338420868
train loss item: 0.07276198267936707
train loss item: 0.3184245228767395
train loss item: 0.14267519116401672
train loss item: 0.08230771124362946
train loss item: 0.23489168286323547
train loss item: 0.6512664556503296
train loss item: 0.06298969686031342
train loss item: 0.10297595709562302
train loss item: 0.641771674156189
train loss item: 0.11856549978256226
train loss item: 0.27315399050712585
train loss item: 0.11249472945928574
train loss item: 0.10580375045537949
train loss item: 0.11418524384498596
train loss item: 0.28772133588790894
train loss item: 0.6150215864181519
train loss item: 0.17065775394439697
train loss item: 0.23925060033798218
train loss item: 0.07978608459234238
train loss item: 0.2511436939239502
train loss item: 0.2138500213623047
train loss item: 0.10954070091247559
train loss item: 0.2734397351741791
train loss item: 0.20329028367996216
train loss item: 0.1670001894235611
train loss item: 0.10808634012937546
train loss item: 0.10971250385046005
train loss item: 0.22472313046455383
train loss item: 0.0467480793595314
train loss item: 0.06823945045471191
train loss item: 0.34715938568115234
train loss item: 0.9748224020004272
train loss item: 0.05762322619557381
train loss item: 0.1370968222618103
train loss item: 0.07328632473945618
train loss item: 0.08851109445095062
train loss item: 0.14466984570026398
train loss item: 0.2233235090970993
train loss item: 0.3662950098514557
train loss item: 0.1775393933057785
train loss item: 0.6167740821838379
train loss item: 0.07973463088274002
train loss item: 0.3098863363265991
test loss item: 0.09794791787862778
test loss item: 0.06385356932878494
test loss item: 0.1856594681739807
test loss item: 0.12697187066078186
test loss item: 0.11066967993974686
test loss item: 0.10008030384778976
test loss item: 1.1203536987304688
test loss item: 0.3605942726135254
test loss item: 0.08432643115520477
test loss item: 0.13102936744689941
test loss item: 0.3421342074871063
test loss item: 0.08160349726676941
test loss item: 0.08391954749822617
test loss item: 0.1056617796421051
test loss item: 0.08466845005750656
test loss item: 0.04963650181889534
test loss item: 0.1490563303232193
test loss item: 0.14232966303825378
test loss item: 0.39282628893852234
test loss item: 0.10754305124282837
test loss item: 0.18244607746601105
test loss item: 0.21911443769931793
test loss item: 0.17289364337921143
test loss item: 0.10655289143323898
test loss item: 0.08843527734279633
test loss item: 0.15742303431034088
test loss item: 0.11499199271202087
test loss item: 0.09941171109676361
test loss item: 0.13475576043128967
test loss item: 0.1315697878599167
test loss item: 0.3910566568374634
test loss item: 0.054158423095941544
test loss item: 0.09626680612564087
test loss item: 0.1580348163843155
test loss item: 0.12919136881828308
test loss item: 0.17949922382831573
test loss item: 0.47827330231666565
test loss item: 0.4948681592941284
test loss item: 0.1624748706817627
test loss item: 0.16633324325084686
test loss item: 0.1727914661169052
test loss item: 0.15362825989723206
test loss item: 0.09487093240022659
test loss item: 0.12497422844171524
test loss item: 0.14611667394638062
test loss item: 0.18101200461387634
test loss item: 0.16957491636276245
test loss item: 0.08470135182142258
test loss item: 0.16302482783794403
test loss item: 0.29188257455825806
test loss item: 0.11153508722782135
test loss item: 0.08557434380054474
test loss item: 0.13038058578968048
test loss item: 0.09095261245965958
test loss item: 0.13003657758235931
test loss item: 0.25348541140556335
test loss item: 0.271091103553772
test loss item: 0.1276451051235199
test loss item: 0.12681996822357178
test loss item: 0.09376131743192673
test loss item: 0.11366917937994003
test loss item: 0.1363901048898697
test loss item: 0.1281231790781021
test loss item: 0.11535286158323288
test loss item: 0.38340049982070923
test loss item: 0.1700349599123001
test loss item: 0.16408690810203552
test loss item: 0.13673712313175201
test loss item: 0.1478578746318817
test loss item: 0.2499324083328247
test loss item: 0.052016481757164
test loss item: 0.6359221339225769
test loss item: 0.12067924439907074
test loss item: 0.20872175693511963
test loss item: 0.08600049465894699
test loss item: 0.15111149847507477
test loss item: 0.10816836357116699
test loss item: 0.5021504163742065
test loss item: 0.11946331709623337
test loss item: 0.10702337324619293
test loss item: 0.0698588564991951
test loss item: 0.516084611415863
test loss item: 0.4943130612373352
test loss item: 0.36656126379966736
test loss item: 0.12044328451156616
test loss item: 0.12067140638828278
test loss item: 0.06522943079471588
test loss item: 0.054139528423547745
test loss item: 0.13538099825382233
Epoch [20/50], Training Loss: 0.2249, Testing Loss: 0.1845
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 21/50
train loss item: 0.24438337981700897
train loss item: 0.5199728012084961
train loss item: 0.08991364389657974
train loss item: 0.19303593039512634
train loss item: 0.16735874116420746
train loss item: 0.1532081812620163
train loss item: 0.175204798579216
train loss item: 0.2137664407491684
train loss item: 0.0816703587770462
train loss item: 0.12816214561462402
train loss item: 0.11951127648353577
train loss item: 0.11855792254209518
train loss item: 0.10095060616731644
train loss item: 0.28191709518432617
train loss item: 0.16208583116531372
train loss item: 0.47689127922058105
train loss item: 0.052688125520944595
train loss item: 0.10001375526189804
train loss item: 0.14636580646038055
train loss item: 0.08948981016874313
train loss item: 0.08227013051509857
train loss item: 0.09182807058095932
train loss item: 0.6065729856491089
train loss item: 0.20270761847496033
train loss item: 0.24200023710727692
train loss item: 0.18099458515644073
train loss item: 0.1222837045788765
train loss item: 0.13034002482891083
train loss item: 0.07117302715778351
train loss item: 0.28296053409576416
train loss item: 0.44938352704048157
train loss item: 0.33915671706199646
train loss item: 0.08242177963256836
train loss item: 0.19833102822303772
train loss item: 0.0892554223537445
train loss item: 0.682448148727417
train loss item: 0.19840534031391144
train loss item: 0.2754918336868286
train loss item: 0.2488192468881607
train loss item: 0.16675110161304474
train loss item: 0.1641124039888382
train loss item: 0.15884524583816528
train loss item: 0.26501888036727905
train loss item: 0.17336280643939972
train loss item: 0.30365848541259766
train loss item: 0.1013897955417633
train loss item: 0.07815732806921005
train loss item: 0.22168850898742676
train loss item: 0.13090309500694275
train loss item: 0.07606584578752518
train loss item: 0.16459272801876068
train loss item: 0.4408819377422333
train loss item: 0.056066595017910004
train loss item: 0.12070156633853912
train loss item: 0.36328285932540894
train loss item: 0.12521834671497345
train loss item: 0.32400229573249817
train loss item: 0.09759002178907394
train loss item: 0.12210292369127274
train loss item: 0.09033583849668503
train loss item: 0.2832685112953186
train loss item: 0.47904539108276367
train loss item: 0.167043536901474
train loss item: 0.2709501385688782
train loss item: 0.07894626259803772
train loss item: 0.2593339681625366
train loss item: 0.17877629399299622
train loss item: 0.13555395603179932
train loss item: 0.27710822224617004
train loss item: 0.18927352130413055
train loss item: 0.16043983399868011
train loss item: 0.10061657428741455
train loss item: 0.1145860105752945
train loss item: 0.20258021354675293
train loss item: 0.04447750747203827
train loss item: 0.06521879881620407
train loss item: 0.34421542286872864
train loss item: 0.9536685347557068
train loss item: 0.04349560663104057
train loss item: 0.13474500179290771
train loss item: 0.08904615044593811
train loss item: 0.08623479306697845
train loss item: 0.12615635991096497
train loss item: 0.260578453540802
train loss item: 0.3612058758735657
train loss item: 0.19901983439922333
train loss item: 0.635992169380188
train loss item: 0.08272390067577362
train loss item: 0.3986249268054962
test loss item: 0.08898357301950455
test loss item: 0.08891518414020538
test loss item: 0.19353821873664856
test loss item: 0.12178180366754532
test loss item: 0.13422276079654694
test loss item: 0.10766633599996567
test loss item: 1.0469685792922974
test loss item: 0.3830905854701996
test loss item: 0.10885344445705414
test loss item: 0.18441976606845856
test loss item: 0.33350932598114014
test loss item: 0.0722862184047699
test loss item: 0.13309064507484436
test loss item: 0.15029878914356232
test loss item: 0.1138870120048523
test loss item: 0.05782246217131615
test loss item: 0.14608368277549744
test loss item: 0.199327751994133
test loss item: 0.39552825689315796
test loss item: 0.16357719898223877
test loss item: 0.22554604709148407
test loss item: 0.20473067462444305
test loss item: 0.15801186859607697
test loss item: 0.12151242792606354
test loss item: 0.090163953602314
test loss item: 0.2048480361700058
test loss item: 0.16762685775756836
test loss item: 0.12210144102573395
test loss item: 0.16804443299770355
test loss item: 0.1914130002260208
test loss item: 0.3757423460483551
test loss item: 0.05954024940729141
test loss item: 0.11360659450292587
test loss item: 0.18473729491233826
test loss item: 0.1670244336128235
test loss item: 0.24831025302410126
test loss item: 0.47323840856552124
test loss item: 0.4581690728664398
test loss item: 0.19624213874340057
test loss item: 0.1669241189956665
test loss item: 0.1586800366640091
test loss item: 0.13595528900623322
test loss item: 0.16214391589164734
test loss item: 0.10641264170408249
test loss item: 0.20079252123832703
test loss item: 0.2076258361339569
test loss item: 0.15723635256290436
test loss item: 0.18331000208854675
test loss item: 0.2034832239151001
test loss item: 0.3315550982952118
test loss item: 0.19303342700004578
test loss item: 0.1380367875099182
test loss item: 0.17642709612846375
test loss item: 0.07101438194513321
test loss item: 0.20634691417217255
test loss item: 0.2802978754043579
test loss item: 0.2955411374568939
test loss item: 0.12532462179660797
test loss item: 0.1588725596666336
test loss item: 0.16045524179935455
test loss item: 0.20362244546413422
test loss item: 0.15590204298496246
test loss item: 0.147856667637825
test loss item: 0.12330924719572067
test loss item: 0.39338016510009766
test loss item: 0.14908204972743988
test loss item: 0.23073408007621765
test loss item: 0.13202396035194397
test loss item: 0.14992722868919373
test loss item: 0.2773679196834564
test loss item: 0.05964710935950279
test loss item: 0.6219220757484436
test loss item: 0.14612191915512085
test loss item: 0.20452602207660675
test loss item: 0.10407330095767975
test loss item: 0.12999361753463745
test loss item: 0.12350385636091232
test loss item: 0.47914445400238037
test loss item: 0.13077667355537415
test loss item: 0.10678984224796295
test loss item: 0.07502365857362747
test loss item: 0.4894583821296692
test loss item: 0.4875625669956207
test loss item: 0.36196669936180115
test loss item: 0.17975817620754242
test loss item: 0.14032389223575592
test loss item: 0.06907527893781662
test loss item: 0.058246344327926636
test loss item: 0.12835216522216797
Epoch [21/50], Training Loss: 0.2097, Testing Loss: 0.2026
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 22/50
train loss item: 0.24152497947216034
train loss item: 0.5612674951553345
train loss item: 0.1358329951763153
train loss item: 0.3042532205581665
train loss item: 0.17859648168087006
train loss item: 0.16609731316566467
train loss item: 0.1949157565832138
train loss item: 0.331466943025589
train loss item: 0.11883840709924698
train loss item: 0.23801961541175842
train loss item: 0.2968667447566986
train loss item: 0.1441354602575302
train loss item: 0.07838303595781326
train loss item: 0.42312338948249817
train loss item: 0.21758988499641418
train loss item: 0.4092477262020111
train loss item: 0.03233907371759415
train loss item: 0.09221433848142624
train loss item: 0.16113005578517914
train loss item: 0.11127582937479019
train loss item: 0.08786771446466446
train loss item: 0.08807696402072906
train loss item: 0.4484962522983551
train loss item: 0.23351292312145233
train loss item: 0.22082416713237762
train loss item: 0.1431022584438324
train loss item: 0.11000382155179977
train loss item: 0.10873854160308838
train loss item: 0.03635330870747566
train loss item: 0.3083557188510895
train loss item: 0.5154487490653992
train loss item: 0.26029303669929504
train loss item: 0.07015489786863327
train loss item: 0.31881120800971985
train loss item: 0.054647523909807205
train loss item: 0.9049579501152039
train loss item: 0.32859259843826294
train loss item: 0.31557783484458923
train loss item: 0.3600953221321106
train loss item: 0.18327248096466064
train loss item: 0.14574941992759705
train loss item: 0.1780179738998413
train loss item: 0.2952437102794647
train loss item: 0.17085596919059753
train loss item: 0.2844424545764923
train loss item: 0.09919258207082748
train loss item: 0.0639910101890564
train loss item: 0.2325562685728073
train loss item: 0.12307461351156235
train loss item: 0.07879197597503662
train loss item: 0.1626100242137909
train loss item: 0.35136309266090393
train loss item: 0.05581716448068619
train loss item: 0.13521218299865723
train loss item: 0.32746338844299316
train loss item: 0.10590612143278122
train loss item: 0.2279948741197586
train loss item: 0.10425252467393875
train loss item: 0.10642889142036438
train loss item: 0.09858189523220062
train loss item: 0.3693414330482483
train loss item: 0.5762741565704346
train loss item: 0.1397736370563507
train loss item: 0.34261006116867065
train loss item: 0.09087371081113815
train loss item: 0.2647181749343872
train loss item: 0.4926997125148773
train loss item: 0.21931669116020203
train loss item: 0.2571471631526947
train loss item: 0.21866485476493835
train loss item: 0.18982437252998352
train loss item: 0.1433788239955902
train loss item: 0.10795720666646957
train loss item: 0.2444712072610855
train loss item: 0.04712865501642227
train loss item: 0.08021537214517593
train loss item: 0.33135470747947693
train loss item: 0.9744576811790466
train loss item: 0.08185390383005142
train loss item: 0.180464968085289
train loss item: 0.09886831045150757
train loss item: 0.12769578397274017
train loss item: 0.15766888856887817
train loss item: 0.26204243302345276
train loss item: 0.3603009581565857
train loss item: 0.31835585832595825
train loss item: 0.4866141676902771
train loss item: 0.12829042971134186
train loss item: 0.19996459782123566
test loss item: 0.10292060673236847
test loss item: 0.07301824539899826
test loss item: 0.32926419377326965
test loss item: 0.14900754392147064
test loss item: 0.13551859557628632
test loss item: 0.09897338598966599
test loss item: 1.5159655809402466
test loss item: 0.5504326224327087
test loss item: 0.1298856884241104
test loss item: 0.20348943769931793
test loss item: 0.5701873898506165
test loss item: 0.09712789207696915
test loss item: 0.13682496547698975
test loss item: 0.17058350145816803
test loss item: 0.10346849262714386
test loss item: 0.05472135171294212
test loss item: 0.2106972634792328
test loss item: 0.19329190254211426
test loss item: 0.5438176393508911
test loss item: 0.20488251745700836
test loss item: 0.344061017036438
test loss item: 0.304758220911026
test loss item: 0.18942907452583313
test loss item: 0.1316317915916443
test loss item: 0.1061972826719284
test loss item: 0.16198809444904327
test loss item: 0.18802368640899658
test loss item: 0.10945545136928558
test loss item: 0.18874351680278778
test loss item: 0.1956716924905777
test loss item: 0.6046099066734314
test loss item: 0.04570584371685982
test loss item: 0.11304022371768951
test loss item: 0.25571125745773315
test loss item: 0.19759966433048248
test loss item: 0.2698206603527069
test loss item: 0.6477752923965454
test loss item: 0.8919418454170227
test loss item: 0.2315370738506317
test loss item: 0.20631955564022064
test loss item: 0.21926893293857574
test loss item: 0.1411174237728119
test loss item: 0.1436915099620819
test loss item: 0.15844838321208954
test loss item: 0.27010825276374817
test loss item: 0.30425018072128296
test loss item: 0.18283532559871674
test loss item: 0.1744513064622879
test loss item: 0.2750408351421356
test loss item: 0.4560587406158447
test loss item: 0.15663261711597443
test loss item: 0.11769460886716843
test loss item: 0.14483356475830078
test loss item: 0.109473317861557
test loss item: 0.15430374443531036
test loss item: 0.47233834862709045
test loss item: 0.41083329916000366
test loss item: 0.19615833461284637
test loss item: 0.16953690350055695
test loss item: 0.0970868393778801
test loss item: 0.16794972121715546
test loss item: 0.21805799007415771
test loss item: 0.1646297425031662
test loss item: 0.15800850093364716
test loss item: 0.6077945232391357
test loss item: 0.19943587481975555
test loss item: 0.2408425211906433
test loss item: 0.1795097440481186
test loss item: 0.23790988326072693
test loss item: 0.3615538775920868
test loss item: 0.05596011504530907
test loss item: 0.8857186436653137
test loss item: 0.21513819694519043
test loss item: 0.3108351230621338
test loss item: 0.12345485389232635
test loss item: 0.13075071573257446
test loss item: 0.13403752446174622
test loss item: 0.934432327747345
test loss item: 0.25244036316871643
test loss item: 0.11927157640457153
test loss item: 0.05289024859666824
test loss item: 0.7523261904716492
test loss item: 0.6743457317352295
test loss item: 0.6667462587356567
test loss item: 0.15100803971290588
test loss item: 0.14995837211608887
test loss item: 0.05070817098021507
test loss item: 0.04301156848669052
test loss item: 0.11741867661476135
Epoch [22/50], Training Loss: 0.2289, Testing Loss: 0.2659
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 23/50
train loss item: 0.2325042486190796
train loss item: 0.34497296810150146
train loss item: 0.11004489660263062
train loss item: 0.2759237587451935
train loss item: 0.16142423450946808
train loss item: 0.21462610363960266
train loss item: 0.12838925421237946
train loss item: 0.6029290556907654
train loss item: 0.06469778716564178
train loss item: 0.1082204058766365
train loss item: 0.13903012871742249
train loss item: 0.12367135286331177
train loss item: 0.07363130152225494
train loss item: 0.3626927435398102
train loss item: 0.19880901277065277
train loss item: 0.41698139905929565
train loss item: 0.03938663750886917
train loss item: 0.09769458323717117
train loss item: 0.1985049694776535
train loss item: 0.08442825824022293
train loss item: 0.0843607634305954
train loss item: 0.07043860852718353
train loss item: 0.2893068790435791
train loss item: 0.33897069096565247
train loss item: 0.24321241676807404
train loss item: 0.19667688012123108
train loss item: 0.195807084441185
train loss item: 0.1461917608976364
train loss item: 0.07332170009613037
train loss item: 0.2234308272600174
train loss item: 0.4915672540664673
train loss item: 0.4622757136821747
train loss item: 0.12049267441034317
train loss item: 0.1661979854106903
train loss item: 0.07642249017953873
train loss item: 0.7449474930763245
train loss item: 0.3280024528503418
train loss item: 0.28356611728668213
train loss item: 0.20273807644844055
train loss item: 0.16664178669452667
train loss item: 0.15568725764751434
train loss item: 0.20126228034496307
train loss item: 0.3065781593322754
train loss item: 0.19989454746246338
train loss item: 0.3949832320213318
train loss item: 0.07678211480379105
train loss item: 0.07535400986671448
train loss item: 0.35685640573501587
train loss item: 0.1730063110589981
train loss item: 0.10203220695257187
train loss item: 0.2891489267349243
train loss item: 0.5263710618019104
train loss item: 0.07496689260005951
train loss item: 0.08104437589645386
train loss item: 0.4234602153301239
train loss item: 0.09810619801282883
train loss item: 0.2680504024028778
train loss item: 0.09669734537601471
train loss item: 0.08264341950416565
train loss item: 0.09078008681535721
train loss item: 0.23544494807720184
train loss item: 0.46373242139816284
train loss item: 0.16475847363471985
train loss item: 0.2840999960899353
train loss item: 0.08998546749353409
train loss item: 0.30678486824035645
train loss item: 0.25225159525871277
train loss item: 0.09166254103183746
train loss item: 0.2157069444656372
train loss item: 0.15749303996562958
train loss item: 0.12725314497947693
train loss item: 0.08896608650684357
train loss item: 0.10396227985620499
train loss item: 0.20527908205986023
train loss item: 0.04590710997581482
train loss item: 0.07005388289690018
train loss item: 0.29052790999412537
train loss item: 0.9529971480369568
train loss item: 0.045722126960754395
train loss item: 0.13427682220935822
train loss item: 0.06007690355181694
train loss item: 0.0769229382276535
train loss item: 0.11420832574367523
train loss item: 0.23164905607700348
train loss item: 0.2838638424873352
train loss item: 0.21511000394821167
train loss item: 0.3471820056438446
train loss item: 0.0705610066652298
train loss item: 0.23024792969226837
test loss item: 0.07884026318788528
test loss item: 0.06605015695095062
test loss item: 0.29410824179649353
test loss item: 0.1142081692814827
test loss item: 0.1221473217010498
test loss item: 0.06643087416887283
test loss item: 1.208720088005066
test loss item: 0.3729057013988495
test loss item: 0.11627615243196487
test loss item: 0.1773035228252411
test loss item: 0.48543083667755127
test loss item: 0.07072500139474869
test loss item: 0.09427149593830109
test loss item: 0.13374941051006317
test loss item: 0.08844266831874847
test loss item: 0.05566063150763512
test loss item: 0.1521497219800949
test loss item: 0.185594379901886
test loss item: 0.41349196434020996
test loss item: 0.12881669402122498
test loss item: 0.25945690274238586
test loss item: 0.22254790365695953
test loss item: 0.1359318494796753
test loss item: 0.09033858776092529
test loss item: 0.0933132991194725
test loss item: 0.12414781749248505
test loss item: 0.13824045658111572
test loss item: 0.09524380415678024
test loss item: 0.15384402871131897
test loss item: 0.1536121368408203
test loss item: 0.489778995513916
test loss item: 0.04629242792725563
test loss item: 0.07444386184215546
test loss item: 0.22618481516838074
test loss item: 0.18697012960910797
test loss item: 0.2097511887550354
test loss item: 0.5081478357315063
test loss item: 0.788769543170929
test loss item: 0.20127761363983154
test loss item: 0.15404610335826874
test loss item: 0.18215827643871307
test loss item: 0.10001061111688614
test loss item: 0.13287554681301117
test loss item: 0.12092920392751694
test loss item: 0.2032317817211151
test loss item: 0.20178374648094177
test loss item: 0.12406444549560547
test loss item: 0.11122475564479828
test loss item: 0.2225484549999237
test loss item: 0.37426239252090454
test loss item: 0.12029005587100983
test loss item: 0.07918732613325119
test loss item: 0.12312281131744385
test loss item: 0.07710757106542587
test loss item: 0.1255323588848114
test loss item: 0.42651695013046265
test loss item: 0.31419602036476135
test loss item: 0.12737323343753815
test loss item: 0.1241077184677124
test loss item: 0.08541674166917801
test loss item: 0.16829611361026764
test loss item: 0.13560421764850616
test loss item: 0.10937651991844177
test loss item: 0.13194116950035095
test loss item: 0.4846954941749573
test loss item: 0.16067782044410706
test loss item: 0.1675662100315094
test loss item: 0.15153156220912933
test loss item: 0.22274231910705566
test loss item: 0.2763611972332001
test loss item: 0.052509624511003494
test loss item: 0.6831199526786804
test loss item: 0.13035136461257935
test loss item: 0.2163768708705902
test loss item: 0.08450506627559662
test loss item: 0.08429228514432907
test loss item: 0.09988630563020706
test loss item: 0.8059337735176086
test loss item: 0.18871891498565674
test loss item: 0.09183436632156372
test loss item: 0.04042184725403786
test loss item: 0.6228823065757751
test loss item: 0.5420925617218018
test loss item: 0.5675719380378723
test loss item: 0.11246290802955627
test loss item: 0.10576143860816956
test loss item: 0.03879402205348015
test loss item: 0.03841261565685272
test loss item: 0.1099247857928276
Epoch [23/50], Training Loss: 0.2125, Testing Loss: 0.2110
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 24/50
train loss item: 0.21517550945281982
train loss item: 0.2476046085357666
train loss item: 0.10078810900449753
train loss item: 0.1971379965543747
train loss item: 0.1066313236951828
train loss item: 0.1219857782125473
train loss item: 0.12457942217588425
train loss item: 0.2637861669063568
train loss item: 0.05546468123793602
train loss item: 0.09034396708011627
train loss item: 0.10927250236272812
train loss item: 0.09675730764865875
train loss item: 0.07418373227119446
train loss item: 0.3099333643913269
train loss item: 0.1694551706314087
train loss item: 0.4145424962043762
train loss item: 0.0431198887526989
train loss item: 0.08943311870098114
train loss item: 0.15168118476867676
train loss item: 0.08978047221899033
train loss item: 0.07472328841686249
train loss item: 0.07120536267757416
train loss item: 0.369149774312973
train loss item: 0.21689701080322266
train loss item: 0.19406326115131378
train loss item: 0.1785721331834793
train loss item: 0.1599748283624649
train loss item: 0.13296622037887573
train loss item: 0.0758884996175766
train loss item: 0.2638050615787506
train loss item: 0.3430410325527191
train loss item: 0.37883827090263367
train loss item: 0.08330709487199783
train loss item: 0.15102584660053253
train loss item: 0.06327763944864273
train loss item: 0.530898928642273
train loss item: 0.17709872126579285
train loss item: 0.2589089274406433
train loss item: 0.21934975683689117
train loss item: 0.14600913226604462
train loss item: 0.15225782990455627
train loss item: 0.15614423155784607
train loss item: 0.2779754102230072
train loss item: 0.16426829993724823
train loss item: 0.32153141498565674
train loss item: 0.07259154319763184
train loss item: 0.07024277746677399
train loss item: 0.24756383895874023
train loss item: 0.12280335277318954
train loss item: 0.08307787775993347
train loss item: 0.17817357182502747
train loss item: 0.36624661087989807
train loss item: 0.05487030744552612
train loss item: 0.0920645073056221
train loss item: 0.5647215247154236
train loss item: 0.09821246564388275
train loss item: 0.28205960988998413
train loss item: 0.0760943740606308
train loss item: 0.11344197392463684
train loss item: 0.10238731652498245
train loss item: 0.2629648447036743
train loss item: 0.45311135053634644
train loss item: 0.1489529013633728
train loss item: 0.2459835410118103
train loss item: 0.09183316677808762
train loss item: 0.15496587753295898
train loss item: 0.1845370978116989
train loss item: 0.11424646526575089
train loss item: 0.2247479408979416
train loss item: 0.14793744683265686
train loss item: 0.11399112641811371
train loss item: 0.060828037559986115
train loss item: 0.098382867872715
train loss item: 0.1407012790441513
train loss item: 0.04388488829135895
train loss item: 0.05864676460623741
train loss item: 0.27312400937080383
train loss item: 0.8392207622528076
train loss item: 0.046329814940690994
train loss item: 0.1464242786169052
train loss item: 0.09398157894611359
train loss item: 0.09489409625530243
train loss item: 0.1491929143667221
train loss item: 0.2180747240781784
train loss item: 0.3360542953014374
train loss item: 0.17896924912929535
train loss item: 0.3964848220348358
train loss item: 0.0558590441942215
train loss item: 0.24480585753917694
test loss item: 0.070556640625
test loss item: 0.06849212199449539
test loss item: 0.2038782238960266
test loss item: 0.10460426658391953
test loss item: 0.10150419175624847
test loss item: 0.06741204857826233
test loss item: 1.1441621780395508
test loss item: 0.37739434838294983
test loss item: 0.08073173463344574
test loss item: 0.1409132182598114
test loss item: 0.3532662093639374
test loss item: 0.060233939439058304
test loss item: 0.09174232929944992
test loss item: 0.10795702785253525
test loss item: 0.08266644179821014
test loss item: 0.05524574965238571
test loss item: 0.14693205058574677
test loss item: 0.13993299007415771
test loss item: 0.3850749135017395
test loss item: 0.11773509532213211
test loss item: 0.17952483892440796
test loss item: 0.21084272861480713
test loss item: 0.11839164793491364
test loss item: 0.09378587454557419
test loss item: 0.08578738570213318
test loss item: 0.12128745764493942
test loss item: 0.11857322603464127
test loss item: 0.0870220959186554
test loss item: 0.13002288341522217
test loss item: 0.13644462823867798
test loss item: 0.42166846990585327
test loss item: 0.04688592627644539
test loss item: 0.0818517804145813
test loss item: 0.17312109470367432
test loss item: 0.13401412963867188
test loss item: 0.1949097216129303
test loss item: 0.4706774353981018
test loss item: 0.5463768243789673
test loss item: 0.16101498901844025
test loss item: 0.14352267980575562
test loss item: 0.16472677886486053
test loss item: 0.1016644686460495
test loss item: 0.10479588061571121
test loss item: 0.11782196164131165
test loss item: 0.1438237428665161
test loss item: 0.18907013535499573
test loss item: 0.119008868932724
test loss item: 0.10893483459949493
test loss item: 0.17846503853797913
test loss item: 0.31820014119148254
test loss item: 0.10201758146286011
test loss item: 0.08244691789150238
test loss item: 0.11597039550542831
test loss item: 0.08116200566291809
test loss item: 0.1066138818860054
test loss item: 0.2875671684741974
test loss item: 0.2802625894546509
test loss item: 0.135025754570961
test loss item: 0.11802037805318832
test loss item: 0.08328302204608917
test loss item: 0.13179971277713776
test loss item: 0.13557448983192444
test loss item: 0.11044847965240479
test loss item: 0.10799731314182281
test loss item: 0.37913963198661804
test loss item: 0.14187709987163544
test loss item: 0.15467672049999237
test loss item: 0.1313953697681427
test loss item: 0.1577426642179489
test loss item: 0.2569080591201782
test loss item: 0.051064539700746536
test loss item: 0.6606372594833374
test loss item: 0.1107996329665184
test loss item: 0.20072485506534576
test loss item: 0.08696721494197845
test loss item: 0.09106335043907166
test loss item: 0.09892760217189789
test loss item: 0.543717086315155
test loss item: 0.12622876465320587
test loss item: 0.08482792228460312
test loss item: 0.043531544506549835
test loss item: 0.5251007676124573
test loss item: 0.5005066394805908
test loss item: 0.39031532406806946
test loss item: 0.09554659575223923
test loss item: 0.10648053884506226
test loss item: 0.043944261968135834
test loss item: 0.0415046401321888
test loss item: 0.10114462673664093
Epoch [24/50], Training Loss: 0.1840, Testing Loss: 0.1810
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 25/50
train loss item: 0.21916033327579498
train loss item: 0.37672558426856995
train loss item: 0.08786582946777344
train loss item: 0.20198741555213928
train loss item: 0.12505662441253662
train loss item: 0.15443462133407593
train loss item: 0.15746591985225677
train loss item: 0.20371508598327637
train loss item: 0.06870749592781067
train loss item: 0.13952404260635376
train loss item: 0.11417996883392334
train loss item: 0.13135214149951935
train loss item: 0.0669325664639473
train loss item: 0.2220495343208313
train loss item: 0.12537948787212372
train loss item: 0.3199763000011444
train loss item: 0.044787079095840454
train loss item: 0.09573160111904144
train loss item: 0.21241377294063568
train loss item: 0.10745586454868317
train loss item: 0.09297588467597961
train loss item: 0.057725939899683
train loss item: 0.3327532112598419
train loss item: 0.23173120617866516
train loss item: 0.24804769456386566
train loss item: 0.1134907454252243
train loss item: 0.07460595667362213
train loss item: 0.14673733711242676
train loss item: 0.0630902573466301
train loss item: 0.3463904857635498
train loss item: 0.706031322479248
train loss item: 0.3120073080062866
train loss item: 0.12357960641384125
train loss item: 0.14645157754421234
train loss item: 0.12820333242416382
train loss item: 1.0752995014190674
train loss item: 0.3900008797645569
train loss item: 0.3356040120124817
train loss item: 0.23364762961864471
train loss item: 0.2291766256093979
train loss item: 0.1311381757259369
train loss item: 0.16645166277885437
train loss item: 0.2560262680053711
train loss item: 0.15855653584003448
train loss item: 0.32661187648773193
train loss item: 0.06942614912986755
train loss item: 0.061784688383340836
train loss item: 0.33239254355430603
train loss item: 0.16992175579071045
train loss item: 0.08782880753278732
train loss item: 0.275234580039978
train loss item: 0.6192988753318787
train loss item: 0.06996454298496246
train loss item: 0.08606451749801636
train loss item: 0.3962506055831909
train loss item: 0.11766267567873001
train loss item: 0.2177063673734665
train loss item: 0.10683836042881012
train loss item: 0.07820165902376175
train loss item: 0.08542120456695557
train loss item: 0.2939949631690979
train loss item: 0.6126641035079956
train loss item: 0.15346543490886688
train loss item: 0.25518372654914856
train loss item: 0.08516981452703476
train loss item: 0.26394569873809814
train loss item: 0.17985548079013824
train loss item: 0.08593165129423141
train loss item: 0.18502511084079742
train loss item: 0.14536882936954498
train loss item: 0.12958332896232605
train loss item: 0.0714663565158844
train loss item: 0.09813649952411652
train loss item: 0.18331629037857056
train loss item: 0.04942996799945831
train loss item: 0.07492194324731827
train loss item: 0.4043092131614685
train loss item: 0.9333402514457703
train loss item: 0.044558197259902954
train loss item: 0.11729839444160461
train loss item: 0.07923857867717743
train loss item: 0.07831680774688721
train loss item: 0.11666463315486908
train loss item: 0.198913112282753
train loss item: 0.2634732127189636
train loss item: 0.18344374001026154
train loss item: 0.6571829915046692
train loss item: 0.06193028390407562
train loss item: 0.2590661942958832
test loss item: 0.10223917663097382
test loss item: 0.07928945869207382
test loss item: 0.18810805678367615
test loss item: 0.12927226722240448
test loss item: 0.13525663316249847
test loss item: 0.12817387282848358
test loss item: 1.0901644229888916
test loss item: 0.34334561228752136
test loss item: 0.08956560492515564
test loss item: 0.1391144096851349
test loss item: 0.33895301818847656
test loss item: 0.08703436702489853
test loss item: 0.10043422877788544
test loss item: 0.1720200777053833
test loss item: 0.1040690690279007
test loss item: 0.0540803037583828
test loss item: 0.15460535883903503
test loss item: 0.14820997416973114
test loss item: 0.37816861271858215
test loss item: 0.1301121562719345
test loss item: 0.16962286829948425
test loss item: 0.21437221765518188
test loss item: 0.22390154004096985
test loss item: 0.11758564412593842
test loss item: 0.09498131275177002
test loss item: 0.15671966969966888
test loss item: 0.12821264564990997
test loss item: 0.12002980709075928
test loss item: 0.15326155722141266
test loss item: 0.14591854810714722
test loss item: 0.3863392472267151
test loss item: 0.055692024528980255
test loss item: 0.10901793837547302
test loss item: 0.17209918797016144
test loss item: 0.13068006932735443
test loss item: 0.18492861092090607
test loss item: 0.4621913433074951
test loss item: 0.48877570033073425
test loss item: 0.17071157693862915
test loss item: 0.18082983791828156
test loss item: 0.1792610138654709
test loss item: 0.19866976141929626
test loss item: 0.10870549082756042
test loss item: 0.13276031613349915
test loss item: 0.15922269225120544
test loss item: 0.17950330674648285
test loss item: 0.20933586359024048
test loss item: 0.1185140609741211
test loss item: 0.1681666523218155
test loss item: 0.2874731421470642
test loss item: 0.11586068570613861
test loss item: 0.09717577695846558
test loss item: 0.13608168065547943
test loss item: 0.09572995454072952
test loss item: 0.12873569130897522
test loss item: 0.2536683976650238
test loss item: 0.2657831609249115
test loss item: 0.10413321852684021
test loss item: 0.13482806086540222
test loss item: 0.1015230342745781
test loss item: 0.12910331785678864
test loss item: 0.13955579698085785
test loss item: 0.13439887762069702
test loss item: 0.13031497597694397
test loss item: 0.38610830903053284
test loss item: 0.16502808034420013
test loss item: 0.17737194895744324
test loss item: 0.14674240350723267
test loss item: 0.1536833792924881
test loss item: 0.2359343022108078
test loss item: 0.0638631284236908
test loss item: 0.6211229562759399
test loss item: 0.14905616641044617
test loss item: 0.21893708407878876
test loss item: 0.09930367767810822
test loss item: 0.1957225650548935
test loss item: 0.11789542436599731
test loss item: 0.5032100677490234
test loss item: 0.16661854088306427
test loss item: 0.12999343872070312
test loss item: 0.07329941540956497
test loss item: 0.5054218769073486
test loss item: 0.4797323942184448
test loss item: 0.3680376708507538
test loss item: 0.14443624019622803
test loss item: 0.13167433440685272
test loss item: 0.06977248191833496
test loss item: 0.052479978650808334
test loss item: 0.1543620079755783
Epoch [25/50], Training Loss: 0.2094, Testing Loss: 0.1930
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 26/50
train loss item: 0.24758586287498474
train loss item: 0.492806613445282
train loss item: 0.10419214516878128
train loss item: 0.20047400891780853
train loss item: 0.1140817403793335
train loss item: 0.1329406201839447
train loss item: 0.11156824976205826
train loss item: 0.18150529265403748
train loss item: 0.054872769862413406
train loss item: 0.1025284007191658
train loss item: 0.12023422122001648
train loss item: 0.11297962069511414
train loss item: 0.050135545432567596
train loss item: 0.24597230553627014
train loss item: 0.11741526424884796
train loss item: 0.38766688108444214
train loss item: 0.035983894020318985
train loss item: 0.0941709578037262
train loss item: 0.19683603942394257
train loss item: 0.10637880116701126
train loss item: 0.09491788595914841
train loss item: 0.06174570322036743
train loss item: 0.46263980865478516
train loss item: 0.1824893057346344
train loss item: 0.23719201982021332
train loss item: 0.132632315158844
train loss item: 0.08831943571567535
train loss item: 0.1264541894197464
train loss item: 0.054083582013845444
train loss item: 0.3326343894004822
train loss item: 0.5497695207595825
train loss item: 0.3205164968967438
train loss item: 0.09254314750432968
train loss item: 0.13363303244113922
train loss item: 0.08654797822237015
train loss item: 0.8298277854919434
train loss item: 0.24833421409130096
train loss item: 0.2959176003932953
train loss item: 0.22709105908870697
train loss item: 0.166951984167099
train loss item: 0.14505267143249512
train loss item: 0.16436374187469482
train loss item: 0.2526773512363434
train loss item: 0.16080613434314728
train loss item: 0.28638383746147156
train loss item: 0.06902492046356201
train loss item: 0.08077782392501831
train loss item: 0.2361505925655365
train loss item: 0.15265175700187683
train loss item: 0.07494745403528214
train loss item: 0.2238743007183075
train loss item: 0.41555964946746826
train loss item: 0.05229810252785683
train loss item: 0.0905667245388031
train loss item: 0.254719078540802
train loss item: 0.13323071599006653
train loss item: 0.19063085317611694
train loss item: 0.11088451743125916
train loss item: 0.0772252008318901
train loss item: 0.07614913582801819
train loss item: 0.3128581643104553
train loss item: 0.3581160604953766
train loss item: 0.17346306145191193
train loss item: 0.35550326108932495
train loss item: 0.09310691803693771
train loss item: 0.3155202567577362
train loss item: 0.22360838949680328
train loss item: 0.11603443324565887
train loss item: 0.17243169248104095
train loss item: 0.15507787466049194
train loss item: 0.11894682794809341
train loss item: 0.07707478851079941
train loss item: 0.07644300162792206
train loss item: 0.20181797444820404
train loss item: 0.04974188283085823
train loss item: 0.07314972579479218
train loss item: 0.3052188456058502
train loss item: 0.9671284556388855
train loss item: 0.04449761286377907
train loss item: 0.16274353861808777
train loss item: 0.08096779137849808
train loss item: 0.11985398083925247
train loss item: 0.1143946498632431
train loss item: 0.23657898604869843
train loss item: 0.1631374955177307
train loss item: 0.20919592678546906
train loss item: 0.29176872968673706
train loss item: 0.05286020785570145
train loss item: 0.25398728251457214
test loss item: 0.07200866937637329
test loss item: 0.055741917341947556
test loss item: 0.3221522569656372
test loss item: 0.10879328846931458
test loss item: 0.11720795929431915
test loss item: 0.058264296501874924
test loss item: 1.0462130308151245
test loss item: 0.3571455776691437
test loss item: 0.11651843786239624
test loss item: 0.17676803469657898
test loss item: 0.4728507399559021
test loss item: 0.0661734864115715
test loss item: 0.09958270192146301
test loss item: 0.10914882272481918
test loss item: 0.08673858642578125
test loss item: 0.044178083539009094
test loss item: 0.1450808048248291
test loss item: 0.19011759757995605
test loss item: 0.36455219984054565
test loss item: 0.1293579339981079
test loss item: 0.31545934081077576
test loss item: 0.21774598956108093
test loss item: 0.14211004972457886
test loss item: 0.08764304965734482
test loss item: 0.09053905308246613
test loss item: 0.11616410315036774
test loss item: 0.1289445012807846
test loss item: 0.08938417583703995
test loss item: 0.14091327786445618
test loss item: 0.1471787393093109
test loss item: 0.4608716666698456
test loss item: 0.038223348557949066
test loss item: 0.07441765815019608
test loss item: 0.23408037424087524
test loss item: 0.20000135898590088
test loss item: 0.19114483892917633
test loss item: 0.4513065218925476
test loss item: 0.7984701991081238
test loss item: 0.20415371656417847
test loss item: 0.14347174763679504
test loss item: 0.16452020406723022
test loss item: 0.08252954483032227
test loss item: 0.12516173720359802
test loss item: 0.11889331042766571
test loss item: 0.23324717581272125
test loss item: 0.19354164600372314
test loss item: 0.12462113052606583
test loss item: 0.10897935926914215
test loss item: 0.24278531968593597
test loss item: 0.3581189811229706
test loss item: 0.1311473399400711
test loss item: 0.08192425221204758
test loss item: 0.12035099416971207
test loss item: 0.08243513852357864
test loss item: 0.13504210114479065
test loss item: 0.44101426005363464
test loss item: 0.30262425541877747
test loss item: 0.1540507823228836
test loss item: 0.12770789861679077
test loss item: 0.07940724492073059
test loss item: 0.1574772149324417
test loss item: 0.15248247981071472
test loss item: 0.10750538110733032
test loss item: 0.11567681282758713
test loss item: 0.5146833062171936
test loss item: 0.15349450707435608
test loss item: 0.17515000700950623
test loss item: 0.13347265124320984
test loss item: 0.23524945974349976
test loss item: 0.23448768258094788
test loss item: 0.04130546748638153
test loss item: 0.6068596243858337
test loss item: 0.14714914560317993
test loss item: 0.21171578764915466
test loss item: 0.08468930423259735
test loss item: 0.07191359251737595
test loss item: 0.0932697206735611
test loss item: 0.861537754535675
test loss item: 0.19438469409942627
test loss item: 0.08073125779628754
test loss item: 0.036971744149923325
test loss item: 0.5826690793037415
test loss item: 0.47295424342155457
test loss item: 0.5923003554344177
test loss item: 0.1077420711517334
test loss item: 0.10624538362026215
test loss item: 0.03755859285593033
test loss item: 0.03727888688445091
test loss item: 0.08685451745986938
Epoch [26/50], Training Loss: 0.1917, Testing Loss: 0.2051
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 27/50
train loss item: 0.2224777191877365
train loss item: 0.3090437054634094
train loss item: 0.14015358686447144
train loss item: 0.21022962033748627
train loss item: 0.18421578407287598
train loss item: 0.11975708603858948
train loss item: 0.12702420353889465
train loss item: 0.1523798406124115
train loss item: 0.06772097200155258
train loss item: 0.1571698635816574
train loss item: 0.15803517401218414
train loss item: 0.09331563115119934
train loss item: 0.0638662651181221
train loss item: 0.27766433358192444
train loss item: 0.13301104307174683
train loss item: 0.45960626006126404
train loss item: 0.03880865126848221
train loss item: 0.09471365064382553
train loss item: 0.17020666599273682
train loss item: 0.11105532199144363
train loss item: 0.09049755334854126
train loss item: 0.06557300686836243
train loss item: 0.4085342586040497
train loss item: 0.26706427335739136
train loss item: 0.18141505122184753
train loss item: 0.17361947894096375
train loss item: 0.15677854418754578
train loss item: 0.14797882735729218
train loss item: 0.06110122427344322
train loss item: 0.3111918270587921
train loss item: 0.4100698232650757
train loss item: 0.30511197447776794
train loss item: 0.09878043085336685
train loss item: 0.19355984032154083
train loss item: 0.08930166810750961
train loss item: 0.3711448311805725
train loss item: 0.3255545496940613
train loss item: 0.3641803562641144
train loss item: 0.22238829731941223
train loss item: 0.2136278748512268
train loss item: 0.13771922886371613
train loss item: 0.19937153160572052
train loss item: 0.27950796484947205
train loss item: 0.1817278116941452
train loss item: 0.3282095193862915
train loss item: 0.07627812772989273
train loss item: 0.07541695982217789
train loss item: 0.25332924723625183
train loss item: 0.1394895315170288
train loss item: 0.09150432050228119
train loss item: 0.23974686861038208
train loss item: 0.45146995782852173
train loss item: 0.08144168555736542
train loss item: 0.0948786661028862
train loss item: 0.2883144021034241
train loss item: 0.09322541207075119
train loss item: 0.1745663732290268
train loss item: 0.0899980366230011
train loss item: 0.08059804141521454
train loss item: 0.08555736392736435
train loss item: 0.22998280823230743
train loss item: 0.45816075801849365
train loss item: 0.15982043743133545
train loss item: 0.29455289244651794
train loss item: 0.07425419986248016
train loss item: 0.16769634187221527
train loss item: 0.18599389493465424
train loss item: 0.08214428275823593
train loss item: 0.1681337207555771
train loss item: 0.12596909701824188
train loss item: 0.1023310124874115
train loss item: 0.04700852930545807
train loss item: 0.07939505577087402
train loss item: 0.15804409980773926
train loss item: 0.04957171902060509
train loss item: 0.06120546907186508
train loss item: 0.3855818212032318
train loss item: 0.9548314809799194
train loss item: 0.04347217455506325
train loss item: 0.12051093578338623
train loss item: 0.07135485857725143
train loss item: 0.08220568299293518
train loss item: 0.12164490669965744
train loss item: 0.19347773492336273
train loss item: 0.2577226758003235
train loss item: 0.17969045042991638
train loss item: 0.7593804001808167
train loss item: 0.05870535224676132
train loss item: 0.2536834478378296
test loss item: 0.08259523659944534
test loss item: 0.06962152570486069
test loss item: 0.20782601833343506
test loss item: 0.12064007669687271
test loss item: 0.11432094126939774
test loss item: 0.10551226884126663
test loss item: 1.1354103088378906
test loss item: 0.34239527583122253
test loss item: 0.07977978140115738
test loss item: 0.12403285503387451
test loss item: 0.3817085325717926
test loss item: 0.06692936271429062
test loss item: 0.07455714792013168
test loss item: 0.08173930644989014
test loss item: 0.09291341155767441
test loss item: 0.0502508282661438
test loss item: 0.1360248178243637
test loss item: 0.120338074862957
test loss item: 0.36383056640625
test loss item: 0.09578529745340347
test loss item: 0.15249164402484894
test loss item: 0.20364691317081451
test loss item: 0.13792461156845093
test loss item: 0.10526572167873383
test loss item: 0.08205558359622955
test loss item: 0.131087988615036
test loss item: 0.10353932529687881
test loss item: 0.09783428907394409
test loss item: 0.1338789165019989
test loss item: 0.11641981452703476
test loss item: 0.42238640785217285
test loss item: 0.05299893021583557
test loss item: 0.09630704671144485
test loss item: 0.1641741544008255
test loss item: 0.12547294795513153
test loss item: 0.16062772274017334
test loss item: 0.456255167722702
test loss item: 0.5952404737472534
test loss item: 0.1591074913740158
test loss item: 0.1654880791902542
test loss item: 0.16649332642555237
test loss item: 0.12984389066696167
test loss item: 0.08334904909133911
test loss item: 0.12163484841585159
test loss item: 0.1171610951423645
test loss item: 0.15885597467422485
test loss item: 0.12975628674030304
test loss item: 0.07700783014297485
test loss item: 0.15961961448192596
test loss item: 0.2930537462234497
test loss item: 0.09318957477807999
test loss item: 0.07097940146923065
test loss item: 0.11696226894855499
test loss item: 0.09686402231454849
test loss item: 0.1123436838388443
test loss item: 0.3037796914577484
test loss item: 0.26550793647766113
test loss item: 0.10188236832618713
test loss item: 0.10692048817873001
test loss item: 0.08035630732774734
test loss item: 0.10395722091197968
test loss item: 0.11931008100509644
test loss item: 0.11406875401735306
test loss item: 0.10370081663131714
test loss item: 0.4120308458805084
test loss item: 0.16089604794979095
test loss item: 0.14584513008594513
test loss item: 0.12991759181022644
test loss item: 0.1609199345111847
test loss item: 0.22770747542381287
test loss item: 0.05616071820259094
test loss item: 0.631898045539856
test loss item: 0.10163285583257675
test loss item: 0.19787098467350006
test loss item: 0.0748177170753479
test loss item: 0.11931107938289642
test loss item: 0.10669167339801788
test loss item: 0.625768780708313
test loss item: 0.13141341507434845
test loss item: 0.10473450273275375
test loss item: 0.07004254311323166
test loss item: 0.5307969450950623
test loss item: 0.47980067133903503
test loss item: 0.4376840591430664
test loss item: 0.11464520543813705
test loss item: 0.09407204389572144
test loss item: 0.07174274325370789
test loss item: 0.05997368320822716
test loss item: 0.13905927538871765
Epoch [27/50], Training Loss: 0.1923, Testing Loss: 0.1811
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 28/50
train loss item: 0.23161840438842773
train loss item: 0.3852843940258026
train loss item: 0.08971788734197617
train loss item: 0.17783209681510925
train loss item: 0.13380134105682373
train loss item: 0.11152388155460358
train loss item: 0.1182989552617073
train loss item: 0.14251676201820374
train loss item: 0.0531572662293911
train loss item: 0.11414448171854019
train loss item: 0.10770919173955917
train loss item: 0.0931505560874939
train loss item: 0.061946798115968704
train loss item: 0.2489665150642395
train loss item: 0.12629111111164093
train loss item: 0.3930888772010803
train loss item: 0.032568156719207764
train loss item: 0.07421774417161942
train loss item: 0.12181048095226288
train loss item: 0.0836128517985344
train loss item: 0.09834953397512436
train loss item: 0.06332416832447052
train loss item: 0.3989333510398865
train loss item: 0.16562090814113617
train loss item: 0.2203814685344696
train loss item: 0.14724469184875488
train loss item: 0.10907168686389923
train loss item: 0.1197260394692421
train loss item: 0.07240023463964462
train loss item: 0.2939770817756653
train loss item: 0.31683585047721863
train loss item: 0.28112635016441345
train loss item: 0.10661424696445465
train loss item: 0.17851974070072174
train loss item: 0.08666160702705383
train loss item: 0.44914039969444275
train loss item: 0.2903209626674652
train loss item: 0.3019687235355377
train loss item: 0.2650146782398224
train loss item: 0.19208037853240967
train loss item: 0.1401727795600891
train loss item: 0.19008439779281616
train loss item: 0.27466297149658203
train loss item: 0.18787749111652374
train loss item: 0.2924968898296356
train loss item: 0.11080694198608398
train loss item: 0.07443308085203171
train loss item: 0.2264251857995987
train loss item: 0.13823285698890686
train loss item: 0.08327046781778336
train loss item: 0.21136227250099182
train loss item: 0.34643247723579407
train loss item: 0.060622379183769226
train loss item: 0.12669743597507477
train loss item: 0.3364371359348297
train loss item: 0.12413189560174942
train loss item: 0.1631990522146225
train loss item: 0.13401885330677032
train loss item: 0.09797663986682892
train loss item: 0.0831863284111023
train loss item: 0.45708924531936646
train loss item: 0.8916293978691101
train loss item: 0.15760080516338348
train loss item: 0.32533589005470276
train loss item: 0.11432304978370667
train loss item: 0.2888267934322357
train loss item: 0.2969050705432892
train loss item: 0.18165433406829834
train loss item: 0.16531403362751007
train loss item: 0.17595437169075012
train loss item: 0.18117977678775787
train loss item: 0.08064202964305878
train loss item: 0.10159847885370255
train loss item: 0.20660719275474548
train loss item: 0.05924665555357933
train loss item: 0.08264635503292084
train loss item: 0.3177128732204437
train loss item: 0.9797439575195312
train loss item: 0.061268746852874756
train loss item: 0.2054145187139511
train loss item: 0.0939248576760292
train loss item: 0.15564972162246704
train loss item: 0.14034929871559143
train loss item: 0.2474164217710495
train loss item: 0.16583074629306793
train loss item: 0.3032260537147522
train loss item: 0.39339479804039
train loss item: 0.1012006551027298
train loss item: 0.14010365307331085
test loss item: 0.0958809107542038
test loss item: 0.07582954317331314
test loss item: 0.41911080479621887
test loss item: 0.14894872903823853
test loss item: 0.16315822303295135
test loss item: 0.08477149903774261
test loss item: 1.4407501220703125
test loss item: 0.4796335697174072
test loss item: 0.16464942693710327
test loss item: 0.26011669635772705
test loss item: 0.5985059142112732
test loss item: 0.106805220246315
test loss item: 0.14797839522361755
test loss item: 0.19631004333496094
test loss item: 0.12088309228420258
test loss item: 0.05445108562707901
test loss item: 0.2066706120967865
test loss item: 0.2775014638900757
test loss item: 0.5035446882247925
test loss item: 0.1957608163356781
test loss item: 0.4824161231517792
test loss item: 0.2986811399459839
test loss item: 0.2151312232017517
test loss item: 0.1189262643456459
test loss item: 0.12175564467906952
test loss item: 0.1564931422472
test loss item: 0.19843068718910217
test loss item: 0.1251712590456009
test loss item: 0.21566349267959595
test loss item: 0.21819785237312317
test loss item: 0.607620358467102
test loss item: 0.04619283974170685
test loss item: 0.09593559801578522
test loss item: 0.3369370102882385
test loss item: 0.2766248881816864
test loss item: 0.27421820163726807
test loss item: 0.6251578330993652
test loss item: 0.9876105189323425
test loss item: 0.29647499322891235
test loss item: 0.20388151705265045
test loss item: 0.2240688055753708
test loss item: 0.1153084933757782
test loss item: 0.21760185062885284
test loss item: 0.16482454538345337
test loss item: 0.37821418046951294
test loss item: 0.29489025473594666
test loss item: 0.19698309898376465
test loss item: 0.15780483186244965
test loss item: 0.33829566836357117
test loss item: 0.4726604223251343
test loss item: 0.23823456466197968
test loss item: 0.10068891197443008
test loss item: 0.16663037240505219
test loss item: 0.11861635744571686
test loss item: 0.20393772423267365
test loss item: 0.5675232410430908
test loss item: 0.3927660584449768
test loss item: 0.25732433795928955
test loss item: 0.1772964894771576
test loss item: 0.13792820274829865
test loss item: 0.2625097930431366
test loss item: 0.20132969319820404
test loss item: 0.14276085793972015
test loss item: 0.17450182139873505
test loss item: 0.6676614284515381
test loss item: 0.20924168825149536
test loss item: 0.23663382232189178
test loss item: 0.1877015382051468
test loss item: 0.3104071021080017
test loss item: 0.3152927756309509
test loss item: 0.05673309788107872
test loss item: 0.8335888981819153
test loss item: 0.23421961069107056
test loss item: 0.3036489188671112
test loss item: 0.11166557669639587
test loss item: 0.10662616044282913
test loss item: 0.12643282115459442
test loss item: 1.0483053922653198
test loss item: 0.2758054733276367
test loss item: 0.11052609235048294
test loss item: 0.043782688677310944
test loss item: 0.7550514340400696
test loss item: 0.6540296673774719
test loss item: 0.7382120490074158
test loss item: 0.15026403963565826
test loss item: 0.14638449251651764
test loss item: 0.04116072505712509
test loss item: 0.03865118324756622
test loss item: 0.10620735585689545
Epoch [28/50], Training Loss: 0.1970, Testing Loss: 0.2826
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 29/50
train loss item: 0.2131069451570511
train loss item: 0.279079794883728
train loss item: 0.09062474220991135
train loss item: 0.19810058176517487
train loss item: 0.19286558032035828
train loss item: 0.1929914504289627
train loss item: 0.0866468995809555
train loss item: 0.3102884292602539
train loss item: 0.06773380935192108
train loss item: 0.13456743955612183
train loss item: 0.160040020942688
train loss item: 0.14352865517139435
train loss item: 0.06306013464927673
train loss item: 0.3473356068134308
train loss item: 0.1681530624628067
train loss item: 0.38462159037590027
train loss item: 0.04472345486283302
train loss item: 0.1453867107629776
train loss item: 0.150289848446846
train loss item: 0.09596811980009079
train loss item: 0.12764491140842438
train loss item: 0.06107960268855095
train loss item: 0.2039051502943039
train loss item: 0.24405834078788757
train loss item: 0.19946277141571045
train loss item: 0.15065133571624756
train loss item: 0.1554495394229889
train loss item: 0.13606476783752441
train loss item: 0.06297570466995239
train loss item: 0.26499390602111816
train loss item: 0.29576051235198975
train loss item: 0.3483208119869232
train loss item: 0.09760339558124542
train loss item: 0.17647668719291687
train loss item: 0.11548037081956863
train loss item: 0.4754873812198639
train loss item: 0.24730218946933746
train loss item: 0.24272024631500244
train loss item: 0.22131416201591492
train loss item: 0.10916738212108612
train loss item: 0.11197160929441452
train loss item: 0.13820387423038483
train loss item: 0.22282974421977997
train loss item: 0.13702982664108276
train loss item: 0.2519894242286682
train loss item: 0.059606991708278656
train loss item: 0.06005218252539635
train loss item: 0.22549742460250854
train loss item: 0.11183738708496094
train loss item: 0.06834699958562851
train loss item: 0.17249535024166107
train loss item: 0.3807922601699829
train loss item: 0.05632946267724037
train loss item: 0.08491231501102448
train loss item: 0.33723312616348267
train loss item: 0.09743931889533997
train loss item: 0.1582672894001007
train loss item: 0.10174611955881119
train loss item: 0.08252181112766266
train loss item: 0.06898349523544312
train loss item: 0.3217497766017914
train loss item: 0.39849990606307983
train loss item: 0.11835235357284546
train loss item: 0.24962782859802246
train loss item: 0.08206911385059357
train loss item: 0.17959633469581604
train loss item: 0.34946537017822266
train loss item: 0.15703195333480835
train loss item: 0.14711864292621613
train loss item: 0.12025559693574905
train loss item: 0.14455333352088928
train loss item: 0.08044486492872238
train loss item: 0.07831676304340363
train loss item: 0.16542544960975647
train loss item: 0.04736139997839928
train loss item: 0.0751245766878128
train loss item: 0.2446468323469162
train loss item: 0.8240227699279785
train loss item: 0.06252329051494598
train loss item: 0.14775779843330383
train loss item: 0.08577354997396469
train loss item: 0.09808798879384995
train loss item: 0.10503511875867844
train loss item: 0.33886462450027466
train loss item: 0.2562122046947479
train loss item: 0.25111380219459534
train loss item: 0.31241723895072937
train loss item: 0.06444160640239716
train loss item: 0.15162605047225952
test loss item: 0.09000110626220703
test loss item: 0.07527651637792587
test loss item: 0.3701171576976776
test loss item: 0.12995167076587677
test loss item: 0.1475745588541031
test loss item: 0.09693554788827896
test loss item: 1.519590973854065
test loss item: 0.5321676731109619
test loss item: 0.14385464787483215
test loss item: 0.2177785038948059
test loss item: 0.5747449398040771
test loss item: 0.08879585564136505
test loss item: 0.12531791627407074
test loss item: 0.16303974390029907
test loss item: 0.11048135161399841
test loss item: 0.057807572185993195
test loss item: 0.19635802507400513
test loss item: 0.21987499296665192
test loss item: 0.5120801329612732
test loss item: 0.1845831722021103
test loss item: 0.3349246382713318
test loss item: 0.2964024841785431
test loss item: 0.18901805579662323
test loss item: 0.11864345520734787
test loss item: 0.11517990380525589
test loss item: 0.1398162543773651
test loss item: 0.17362427711486816
test loss item: 0.11227129399776459
test loss item: 0.1930931657552719
test loss item: 0.18537330627441406
test loss item: 0.6316050291061401
test loss item: 0.04615774005651474
test loss item: 0.09512712061405182
test loss item: 0.279666006565094
test loss item: 0.2292429655790329
test loss item: 0.26350778341293335
test loss item: 0.6293965578079224
test loss item: 0.955977737903595
test loss item: 0.25723767280578613
test loss item: 0.2062135934829712
test loss item: 0.2167450487613678
test loss item: 0.13435810804367065
test loss item: 0.15497633814811707
test loss item: 0.15557272732257843
test loss item: 0.26079317927360535
test loss item: 0.27376753091812134
test loss item: 0.1682184338569641
test loss item: 0.14309895038604736
test loss item: 0.2927301526069641
test loss item: 0.47558414936065674
test loss item: 0.15701855719089508
test loss item: 0.09134255349636078
test loss item: 0.14844481647014618
test loss item: 0.09247364103794098
test loss item: 0.15000252425670624
test loss item: 0.527077853679657
test loss item: 0.40150126814842224
test loss item: 0.15385614335536957
test loss item: 0.15246540307998657
test loss item: 0.1032290980219841
test loss item: 0.1959265023469925
test loss item: 0.2000654637813568
test loss item: 0.14286328852176666
test loss item: 0.1509101241827011
test loss item: 0.6254095435142517
test loss item: 0.1736832708120346
test loss item: 0.21931926906108856
test loss item: 0.17680078744888306
test loss item: 0.2697480618953705
test loss item: 0.3376794159412384
test loss item: 0.061362359672784805
test loss item: 0.8774884939193726
test loss item: 0.18688294291496277
test loss item: 0.3057135045528412
test loss item: 0.10729449987411499
test loss item: 0.12420269101858139
test loss item: 0.12646488845348358
test loss item: 0.994072437286377
test loss item: 0.2531081438064575
test loss item: 0.11400805413722992
test loss item: 0.048794496804475784
test loss item: 0.7638463973999023
test loss item: 0.6682902574539185
test loss item: 0.7066938877105713
test loss item: 0.1459263116121292
test loss item: 0.13092230260372162
test loss item: 0.04653158783912659
test loss item: 0.03634677454829216
test loss item: 0.11225073784589767
Epoch [29/50], Training Loss: 0.1797, Testing Loss: 0.2648
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 30/50
train loss item: 0.198426753282547
train loss item: 0.3175378739833832
train loss item: 0.09093392640352249
train loss item: 0.2049599289894104
train loss item: 0.10558211803436279
train loss item: 0.17639432847499847
train loss item: 0.08294527232646942
train loss item: 0.2928007245063782
train loss item: 0.05655679479241371
train loss item: 0.08742856234312057
train loss item: 0.11334840953350067
train loss item: 0.0988936722278595
train loss item: 0.05933142453432083
train loss item: 0.3078415095806122
train loss item: 0.16176737844944
train loss item: 0.4301687180995941
train loss item: 0.045795489102602005
train loss item: 0.15224748849868774
train loss item: 0.18882125616073608
train loss item: 0.09209709614515305
train loss item: 0.1163749024271965
train loss item: 0.04959873482584953
train loss item: 0.2514377236366272
train loss item: 0.222852885723114
train loss item: 0.21357674896717072
train loss item: 0.15999996662139893
train loss item: 0.16752155125141144
train loss item: 0.1599525660276413
train loss item: 0.07803614437580109
train loss item: 0.2937702536582947
train loss item: 0.32711929082870483
train loss item: 0.38898375630378723
train loss item: 0.10042792558670044
train loss item: 0.14160986244678497
train loss item: 0.08024962991476059
train loss item: 0.3551921248435974
train loss item: 0.22368425130844116
train loss item: 0.23963503539562225
train loss item: 0.23602186143398285
train loss item: 0.11184612661600113
train loss item: 0.11835355311632156
train loss item: 0.1464734524488449
train loss item: 0.2352110892534256
train loss item: 0.13589191436767578
train loss item: 0.24962006509304047
train loss item: 0.061326511204242706
train loss item: 0.05327337607741356
train loss item: 0.24521464109420776
train loss item: 0.12036975473165512
train loss item: 0.07156393676996231
train loss item: 0.16865961253643036
train loss item: 0.3975735306739807
train loss item: 0.056420911103487015
train loss item: 0.08215927332639694
train loss item: 0.23312298953533173
train loss item: 0.07831630855798721
train loss item: 0.15345920622348785
train loss item: 0.08066585659980774
train loss item: 0.08209532499313354
train loss item: 0.06543000787496567
train loss item: 0.2917090058326721
train loss item: 0.40738582611083984
train loss item: 0.14032170176506042
train loss item: 0.27114564180374146
train loss item: 0.10976181924343109
train loss item: 0.23168525099754333
train loss item: 0.36202943325042725
train loss item: 0.14495806396007538
train loss item: 0.12844057381153107
train loss item: 0.14724895358085632
train loss item: 0.13995376229286194
train loss item: 0.08202555030584335
train loss item: 0.08352907747030258
train loss item: 0.1783456951379776
train loss item: 0.0495876707136631
train loss item: 0.08132067322731018
train loss item: 0.2626279890537262
train loss item: 0.9479894042015076
train loss item: 0.07053638994693756
train loss item: 0.17264914512634277
train loss item: 0.08604561537504196
train loss item: 0.1266418695449829
train loss item: 0.12832413613796234
train loss item: 0.22678352892398834
train loss item: 0.20676137506961823
train loss item: 0.27301132678985596
train loss item: 0.3472852408885956
train loss item: 0.08194748312234879
train loss item: 0.15145017206668854
test loss item: 0.08427855372428894
test loss item: 0.0863189771771431
test loss item: 0.4692244827747345
test loss item: 0.1254204660654068
test loss item: 0.1806294023990631
test loss item: 0.09321489930152893
test loss item: 1.349247694015503
test loss item: 0.466987669467926
test loss item: 0.1810595691204071
test loss item: 0.27452945709228516
test loss item: 0.6738887429237366
test loss item: 0.09852459281682968
test loss item: 0.14465010166168213
test loss item: 0.17315803468227386
test loss item: 0.12859037518501282
test loss item: 0.06680864840745926
test loss item: 0.1876722127199173
test loss item: 0.30402785539627075
test loss item: 0.4746414124965668
test loss item: 0.1910293698310852
test loss item: 0.4964843690395355
test loss item: 0.27369076013565063
test loss item: 0.22277258336544037
test loss item: 0.11156162619590759
test loss item: 0.12704996764659882
test loss item: 0.14350461959838867
test loss item: 0.19533732533454895
test loss item: 0.1370830535888672
test loss item: 0.21576854586601257
test loss item: 0.212791308760643
test loss item: 0.6462715268135071
test loss item: 0.05511156842112541
test loss item: 0.08989362418651581
test loss item: 0.3630349040031433
test loss item: 0.3087630867958069
test loss item: 0.28606125712394714
test loss item: 0.591003954410553
test loss item: 1.153605580329895
test loss item: 0.3129828870296478
test loss item: 0.18947415053844452
test loss item: 0.20187576115131378
test loss item: 0.1133732944726944
test loss item: 0.22589778900146484
test loss item: 0.14473316073417664
test loss item: 0.3818320631980896
test loss item: 0.2720324993133545
test loss item: 0.1920752227306366
test loss item: 0.15149815380573273
test loss item: 0.36045747995376587
test loss item: 0.5233033299446106
test loss item: 0.2294992357492447
test loss item: 0.09165508300065994
test loss item: 0.16395771503448486
test loss item: 0.08947749435901642
test loss item: 0.20939628779888153
test loss item: 0.6561110615730286
test loss item: 0.40298622846603394
test loss item: 0.2245371788740158
test loss item: 0.16603268682956696
test loss item: 0.14097167551517487
test loss item: 0.2823139727115631
test loss item: 0.19421438872814178
test loss item: 0.13159355521202087
test loss item: 0.16189564764499664
test loss item: 0.7097501158714294
test loss item: 0.16911661624908447
test loss item: 0.22861044108867645
test loss item: 0.17483335733413696
test loss item: 0.34699705243110657
test loss item: 0.32475823163986206
test loss item: 0.07282435148954391
test loss item: 0.7837940454483032
test loss item: 0.2250126451253891
test loss item: 0.28531140089035034
test loss item: 0.10815642774105072
test loss item: 0.10931726545095444
test loss item: 0.1208900585770607
test loss item: 1.2229901552200317
test loss item: 0.2955336570739746
test loss item: 0.11612135171890259
test loss item: 0.05140990763902664
test loss item: 0.7904008626937866
test loss item: 0.643398106098175
test loss item: 0.8517197370529175
test loss item: 0.1540207415819168
test loss item: 0.14061619341373444
test loss item: 0.048479098826646805
test loss item: 0.04715102165937424
test loss item: 0.10202357172966003
Epoch [30/50], Training Loss: 0.1792, Testing Loss: 0.2890
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 31/50
train loss item: 0.20466966927051544
train loss item: 0.2936355769634247
train loss item: 0.09206966310739517
train loss item: 0.1971258819103241
train loss item: 0.08836568892002106
train loss item: 0.15018725395202637
train loss item: 0.07626324892044067
train loss item: 0.22104065120220184
train loss item: 0.05291398614645004
train loss item: 0.08968574553728104
train loss item: 0.09837545454502106
train loss item: 0.0996733009815216
train loss item: 0.058751482516527176
train loss item: 0.28640714287757874
train loss item: 0.14584270119667053
train loss item: 0.4534522593021393
train loss item: 0.04142498970031738
train loss item: 0.11531208455562592
train loss item: 0.14574754238128662
train loss item: 0.09159065037965775
train loss item: 0.10040785372257233
train loss item: 0.04994834586977959
train loss item: 0.3179762661457062
train loss item: 0.18802830576896667
train loss item: 0.17914995551109314
train loss item: 0.14069926738739014
train loss item: 0.16428042948246002
train loss item: 0.15175661444664001
train loss item: 0.08115249127149582
train loss item: 0.3044716417789459
train loss item: 0.33079251646995544
train loss item: 0.35816770792007446
train loss item: 0.10311069339513779
train loss item: 0.16397878527641296
train loss item: 0.10419868677854538
train loss item: 0.35934895277023315
train loss item: 0.26971912384033203
train loss item: 0.2722606360912323
train loss item: 0.19934971630573273
train loss item: 0.1258658468723297
train loss item: 0.11785608530044556
train loss item: 0.1824967861175537
train loss item: 0.2329593449831009
train loss item: 0.15845362842082977
train loss item: 0.33983349800109863
train loss item: 0.06528837233781815
train loss item: 0.05721311643719673
train loss item: 0.22882753610610962
train loss item: 0.11330144107341766
train loss item: 0.08557925373315811
train loss item: 0.18247710168361664
train loss item: 0.4121735692024231
train loss item: 0.07233479619026184
train loss item: 0.07922651618719101
train loss item: 0.27833646535873413
train loss item: 0.07943247258663177
train loss item: 0.19905877113342285
train loss item: 0.0807085782289505
train loss item: 0.0954778715968132
train loss item: 0.08196888118982315
train loss item: 0.18198640644550323
train loss item: 0.41865232586860657
train loss item: 0.11001000553369522
train loss item: 0.21191368997097015
train loss item: 0.10983490198850632
train loss item: 0.14709463715553284
train loss item: 0.19813819229602814
train loss item: 0.10107261687517166
train loss item: 0.13441604375839233
train loss item: 0.10311061143875122
train loss item: 0.09316488355398178
train loss item: 0.051315635442733765
train loss item: 0.09456169605255127
train loss item: 0.1200808435678482
train loss item: 0.04451746493577957
train loss item: 0.06109263747930527
train loss item: 0.2886093556880951
train loss item: 0.813720703125
train loss item: 0.050963591784238815
train loss item: 0.11449182033538818
train loss item: 0.08742592483758926
train loss item: 0.10067582875490189
train loss item: 0.12116216123104095
train loss item: 0.20213519036769867
train loss item: 0.3006977438926697
train loss item: 0.21103915572166443
train loss item: 0.7755454778671265
train loss item: 0.062439773231744766
train loss item: 0.17271456122398376
test loss item: 0.09862414747476578
test loss item: 0.08131347596645355
test loss item: 0.24222391843795776
test loss item: 0.13942331075668335
test loss item: 0.1280076652765274
test loss item: 0.1209869384765625
test loss item: 1.290778398513794
test loss item: 0.43385931849479675
test loss item: 0.09814286977052689
test loss item: 0.15042202174663544
test loss item: 0.41711583733558655
test loss item: 0.08084926009178162
test loss item: 0.08251949399709702
test loss item: 0.1188974604010582
test loss item: 0.10689922422170639
test loss item: 0.048890452831983566
test loss item: 0.17008931934833527
test loss item: 0.14605726301670074
test loss item: 0.4319208860397339
test loss item: 0.13286615908145905
test loss item: 0.19545137882232666
test loss item: 0.2523384988307953
test loss item: 0.16375544667243958
test loss item: 0.12972989678382874
test loss item: 0.10284356772899628
test loss item: 0.13333392143249512
test loss item: 0.1393006294965744
test loss item: 0.11020520329475403
test loss item: 0.16112905740737915
test loss item: 0.13918951153755188
test loss item: 0.500751793384552
test loss item: 0.05345599725842476
test loss item: 0.11614019423723221
test loss item: 0.20554229617118835
test loss item: 0.14737682044506073
test loss item: 0.20625916123390198
test loss item: 0.5278703570365906
test loss item: 0.6619644165039062
test loss item: 0.19274666905403137
test loss item: 0.20162682235240936
test loss item: 0.1978643834590912
test loss item: 0.14965565502643585
test loss item: 0.10933885723352432
test loss item: 0.15032410621643066
test loss item: 0.1577005237340927
test loss item: 0.21090824902057648
test loss item: 0.1541653573513031
test loss item: 0.10116796940565109
test loss item: 0.20031984150409698
test loss item: 0.35286378860473633
test loss item: 0.10180416703224182
test loss item: 0.07524002343416214
test loss item: 0.13354545831680298
test loss item: 0.10801880806684494
test loss item: 0.1099662110209465
test loss item: 0.34448739886283875
test loss item: 0.3191124200820923
test loss item: 0.12028536945581436
test loss item: 0.12771901488304138
test loss item: 0.07755601406097412
test loss item: 0.13976219296455383
test loss item: 0.15825983881950378
test loss item: 0.12845292687416077
test loss item: 0.12370015680789948
test loss item: 0.45944374799728394
test loss item: 0.17726483941078186
test loss item: 0.1674487143754959
test loss item: 0.15308542549610138
test loss item: 0.19017904996871948
test loss item: 0.28381049633026123
test loss item: 0.05797921121120453
test loss item: 0.741743266582489
test loss item: 0.12676426768302917
test loss item: 0.2603638470172882
test loss item: 0.09317705780267715
test loss item: 0.13699549436569214
test loss item: 0.12950393557548523
test loss item: 0.6892128586769104
test loss item: 0.17601333558559418
test loss item: 0.12243565171957016
test loss item: 0.07800386101007462
test loss item: 0.6089861392974854
test loss item: 0.5522835850715637
test loss item: 0.4867404103279114
test loss item: 0.11852280050516129
test loss item: 0.11194941401481628
test loss item: 0.07640203088521957
test loss item: 0.056502800434827805
test loss item: 0.16226935386657715
Epoch [31/50], Training Loss: 0.1752, Testing Loss: 0.2127
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 32/50
train loss item: 0.21800963580608368
train loss item: 0.26281604170799255
train loss item: 0.08701062202453613
train loss item: 0.15248501300811768
train loss item: 0.14418092370033264
train loss item: 0.12092749029397964
train loss item: 0.1004260778427124
train loss item: 0.17584899067878723
train loss item: 0.05146734416484833
train loss item: 0.10058541595935822
train loss item: 0.12645553052425385
train loss item: 0.09491217136383057
train loss item: 0.0645274892449379
train loss item: 0.24216283857822418
train loss item: 0.13768167793750763
train loss item: 0.30496296286582947
train loss item: 0.041115082800388336
train loss item: 0.07912012189626694
train loss item: 0.1413252055644989
train loss item: 0.07894821465015411
train loss item: 0.10996701568365097
train loss item: 0.05862179026007652
train loss item: 0.24883173406124115
train loss item: 0.22520755231380463
train loss item: 0.21984456479549408
train loss item: 0.10190176963806152
train loss item: 0.08296418935060501
train loss item: 0.1135663315653801
train loss item: 0.05691586062312126
train loss item: 0.26111286878585815
train loss item: 0.30932480096817017
train loss item: 0.314698189496994
train loss item: 0.09274505078792572
train loss item: 0.14163361489772797
train loss item: 0.0797666683793068
train loss item: 0.3510775864124298
train loss item: 0.194871187210083
train loss item: 0.23791691660881042
train loss item: 0.2058596909046173
train loss item: 0.13315720856189728
train loss item: 0.12117012590169907
train loss item: 0.13213856518268585
train loss item: 0.2205342799425125
train loss item: 0.1310131698846817
train loss item: 0.2613547742366791
train loss item: 0.06979384273290634
train loss item: 0.054987214505672455
train loss item: 0.1842406541109085
train loss item: 0.0984383374452591
train loss item: 0.06245480105280876
train loss item: 0.1351241022348404
train loss item: 0.3055199086666107
train loss item: 0.050791703164577484
train loss item: 0.08521407842636108
train loss item: 0.3431963324546814
train loss item: 0.10028434544801712
train loss item: 0.1666216403245926
train loss item: 0.11231502145528793
train loss item: 0.09227234870195389
train loss item: 0.07707992941141129
train loss item: 0.4116472005844116
train loss item: 0.837974488735199
train loss item: 0.1379736363887787
train loss item: 0.2479410171508789
train loss item: 0.12984773516654968
train loss item: 0.21826103329658508
train loss item: 0.23621836304664612
train loss item: 0.13691140711307526
train loss item: 0.1332918256521225
train loss item: 0.1529656946659088
train loss item: 0.1307770311832428
train loss item: 0.08193348348140717
train loss item: 0.08542072772979736
train loss item: 0.16316275298595428
train loss item: 0.04666435346007347
train loss item: 0.07424736768007278
train loss item: 0.2685706317424774
train loss item: 0.9178304076194763
train loss item: 0.07983323186635971
train loss item: 0.16995097696781158
train loss item: 0.08202486485242844
train loss item: 0.12522035837173462
train loss item: 0.10934069752693176
train loss item: 0.18929824233055115
train loss item: 0.16831988096237183
train loss item: 0.24263866245746613
train loss item: 0.37824898958206177
train loss item: 0.05939483642578125
train loss item: 0.21070197224617004
test loss item: 0.08518567681312561
test loss item: 0.0854308009147644
test loss item: 0.19926606118679047
test loss item: 0.13033729791641235
test loss item: 0.12610138952732086
test loss item: 0.10855795443058014
test loss item: 1.1391571760177612
test loss item: 0.3785550892353058
test loss item: 0.08977814018726349
test loss item: 0.1444185972213745
test loss item: 0.33760663866996765
test loss item: 0.0790332704782486
test loss item: 0.10636570304632187
test loss item: 0.11976596713066101
test loss item: 0.10716072469949722
test loss item: 0.04788335785269737
test loss item: 0.16743813455104828
test loss item: 0.1324012577533722
test loss item: 0.3969470262527466
test loss item: 0.14824888110160828
test loss item: 0.1818908154964447
test loss item: 0.2324448972940445
test loss item: 0.1646323800086975
test loss item: 0.12469258904457092
test loss item: 0.08570671081542969
test loss item: 0.13675539195537567
test loss item: 0.14040511846542358
test loss item: 0.11296996474266052
test loss item: 0.16502892971038818
test loss item: 0.14569729566574097
test loss item: 0.4054758548736572
test loss item: 0.04129474610090256
test loss item: 0.11241164803504944
test loss item: 0.16750887036323547
test loss item: 0.12492692470550537
test loss item: 0.18235507607460022
test loss item: 0.47737303376197815
test loss item: 0.47610151767730713
test loss item: 0.1622086614370346
test loss item: 0.18580123782157898
test loss item: 0.18383122980594635
test loss item: 0.1466851383447647
test loss item: 0.09841378033161163
test loss item: 0.13468095660209656
test loss item: 0.14942307770252228
test loss item: 0.2253326028585434
test loss item: 0.15716804563999176
test loss item: 0.11499302834272385
test loss item: 0.18537761270999908
test loss item: 0.3014739453792572
test loss item: 0.11234527826309204
test loss item: 0.08523281663656235
test loss item: 0.12300775945186615
test loss item: 0.08998475223779678
test loss item: 0.10540741682052612
test loss item: 0.2569134831428528
test loss item: 0.28313368558883667
test loss item: 0.12293720990419388
test loss item: 0.13169294595718384
test loss item: 0.09014859795570374
test loss item: 0.12876488268375397
test loss item: 0.15650105476379395
test loss item: 0.12580811977386475
test loss item: 0.13546596467494965
test loss item: 0.40701064467430115
test loss item: 0.1641419678926468
test loss item: 0.18003499507904053
test loss item: 0.15198618173599243
test loss item: 0.15209661424160004
test loss item: 0.25264742970466614
test loss item: 0.05760485306382179
test loss item: 0.6721863746643066
test loss item: 0.13355456292629242
test loss item: 0.24633754789829254
test loss item: 0.09494830667972565
test loss item: 0.13486197590827942
test loss item: 0.12460120767354965
test loss item: 0.4895699620246887
test loss item: 0.1741943508386612
test loss item: 0.11179947853088379
test loss item: 0.06141116842627525
test loss item: 0.5182504057884216
test loss item: 0.48406824469566345
test loss item: 0.363441526889801
test loss item: 0.12599864602088928
test loss item: 0.11297639459371567
test loss item: 0.05729633942246437
test loss item: 0.036448054015636444
test loss item: 0.1371590793132782
Epoch [32/50], Training Loss: 0.1719, Testing Loss: 0.1915
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 33/50
train loss item: 0.21643546223640442
train loss item: 0.40808260440826416
train loss item: 0.08912383019924164
train loss item: 0.2512553334236145
train loss item: 0.08817402273416519
train loss item: 0.1387692242860794
train loss item: 0.08055566251277924
train loss item: 0.24818572402000427
train loss item: 0.057436227798461914
train loss item: 0.11719650030136108
train loss item: 0.12558098137378693
train loss item: 0.1062697023153305
train loss item: 0.0536879301071167
train loss item: 0.20603877305984497
train loss item: 0.1263086348772049
train loss item: 0.38079482316970825
train loss item: 0.04173562303185463
train loss item: 0.065086230635643
train loss item: 0.18646390736103058
train loss item: 0.10013678669929504
train loss item: 0.10049968212842941
train loss item: 0.04805915802717209
train loss item: 0.39518681168556213
train loss item: 0.20867633819580078
train loss item: 0.23760324716567993
train loss item: 0.10725026577711105
train loss item: 0.06368434429168701
train loss item: 0.13844092190265656
train loss item: 0.05636842921376228
train loss item: 0.33402323722839355
train loss item: 0.8926448225975037
train loss item: 0.32744666934013367
train loss item: 0.12474509328603745
train loss item: 0.16574382781982422
train loss item: 0.11548972874879837
train loss item: 0.7782346606254578
train loss item: 0.37480175495147705
train loss item: 0.34753283858299255
train loss item: 0.20762193202972412
train loss item: 0.198884516954422
train loss item: 0.11276548355817795
train loss item: 0.12476952373981476
train loss item: 0.2156219482421875
train loss item: 0.1576181948184967
train loss item: 0.319983571767807
train loss item: 0.08151306957006454
train loss item: 0.08107129484415054
train loss item: 0.2851952910423279
train loss item: 0.1550116389989853
train loss item: 0.08343004435300827
train loss item: 0.2882593870162964
train loss item: 0.651773989200592
train loss item: 0.06592258810997009
train loss item: 0.07942797243595123
train loss item: 0.40432944893836975
train loss item: 0.1257341355085373
train loss item: 0.21318471431732178
train loss item: 0.12726788222789764
train loss item: 0.0741691142320633
train loss item: 0.08974523842334747
train loss item: 0.340744286775589
train loss item: 0.631361722946167
train loss item: 0.13467799127101898
train loss item: 0.2296362668275833
train loss item: 0.10785325616598129
train loss item: 0.1743392050266266
train loss item: 0.20821766555309296
train loss item: 0.08478284627199173
train loss item: 0.11967137455940247
train loss item: 0.1018901914358139
train loss item: 0.09985356032848358
train loss item: 0.049647752195596695
train loss item: 0.09141354262828827
train loss item: 0.16481268405914307
train loss item: 0.04519833251833916
train loss item: 0.06421135365962982
train loss item: 0.3165992200374603
train loss item: 0.9073591232299805
train loss item: 0.061435237526893616
train loss item: 0.18417055904865265
train loss item: 0.09739653766155243
train loss item: 0.09611155092716217
train loss item: 0.1176275759935379
train loss item: 0.21366481482982635
train loss item: 0.22443583607673645
train loss item: 0.24147643148899078
train loss item: 0.4968206286430359
train loss item: 0.06506036221981049
train loss item: 0.19207718968391418
test loss item: 0.0979401096701622
test loss item: 0.08674472570419312
test loss item: 0.2480236291885376
test loss item: 0.1301034539937973
test loss item: 0.13964931666851044
test loss item: 0.1401793509721756
test loss item: 1.0916314125061035
test loss item: 0.3260480761528015
test loss item: 0.10895264893770218
test loss item: 0.16462890803813934
test loss item: 0.41691267490386963
test loss item: 0.07763098180294037
test loss item: 0.07958830893039703
test loss item: 0.10923796892166138
test loss item: 0.10846693068742752
test loss item: 0.0603201799094677
test loss item: 0.13821272552013397
test loss item: 0.1653873473405838
test loss item: 0.3647029995918274
test loss item: 0.1259535253047943
test loss item: 0.23240849375724792
test loss item: 0.20876255631446838
test loss item: 0.19374585151672363
test loss item: 0.12008341401815414
test loss item: 0.09471231698989868
test loss item: 0.11686063557863235
test loss item: 0.14521420001983643
test loss item: 0.12213564664125443
test loss item: 0.1477746218442917
test loss item: 0.14516544342041016
test loss item: 0.4481605589389801
test loss item: 0.06979968398809433
test loss item: 0.11282707750797272
test loss item: 0.20933806896209717
test loss item: 0.16446886956691742
test loss item: 0.20728051662445068
test loss item: 0.44298553466796875
test loss item: 0.6600082516670227
test loss item: 0.1879851520061493
test loss item: 0.1917891949415207
test loss item: 0.17114967107772827
test loss item: 0.1585683971643448
test loss item: 0.13594146072864532
test loss item: 0.1274251937866211
test loss item: 0.1795235574245453
test loss item: 0.18098753690719604
test loss item: 0.17567957937717438
test loss item: 0.12391496449708939
test loss item: 0.19218671321868896
test loss item: 0.32856088876724243
test loss item: 0.12567010521888733
test loss item: 0.08481042832136154
test loss item: 0.12295277416706085
test loss item: 0.09621042758226395
test loss item: 0.12188748270273209
test loss item: 0.36226412653923035
test loss item: 0.26788777112960815
test loss item: 0.1353922039270401
test loss item: 0.1194358617067337
test loss item: 0.08519468456506729
test loss item: 0.17465871572494507
test loss item: 0.12725912034511566
test loss item: 0.10118045657873154
test loss item: 0.11331791430711746
test loss item: 0.42585161328315735
test loss item: 0.16410481929779053
test loss item: 0.14378048479557037
test loss item: 0.1336188018321991
test loss item: 0.19211187958717346
test loss item: 0.27018070220947266
test loss item: 0.0670485720038414
test loss item: 0.6132462620735168
test loss item: 0.12133657932281494
test loss item: 0.21790039539337158
test loss item: 0.08661927282810211
test loss item: 0.1595211923122406
test loss item: 0.12103156745433807
test loss item: 0.6731928586959839
test loss item: 0.17492403090000153
test loss item: 0.13114692270755768
test loss item: 0.0941765233874321
test loss item: 0.5433024764060974
test loss item: 0.4846276342868805
test loss item: 0.47847288846969604
test loss item: 0.12538360059261322
test loss item: 0.10113254934549332
test loss item: 0.09366387873888016
test loss item: 0.07202431559562683
test loss item: 0.15152154862880707
Epoch [33/50], Training Loss: 0.2012, Testing Loss: 0.2029
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 34/50
train loss item: 0.24262307584285736
train loss item: 0.2660713493824005
train loss item: 0.09009871631860733
train loss item: 0.24337385594844818
train loss item: 0.11847513914108276
train loss item: 0.1662069708108902
train loss item: 0.08685919642448425
train loss item: 0.1353387087583542
train loss item: 0.0730503648519516
train loss item: 0.11956895142793655
train loss item: 0.12571588158607483
train loss item: 0.1549483686685562
train loss item: 0.048727549612522125
train loss item: 0.25694411993026733
train loss item: 0.12329626828432083
train loss item: 0.3254374861717224
train loss item: 0.046293944120407104
train loss item: 0.07801252603530884
train loss item: 0.188332661986351
train loss item: 0.10663875192403793
train loss item: 0.13617263734340668
train loss item: 0.06995514035224915
train loss item: 0.23435774445533752
train loss item: 0.1978423148393631
train loss item: 0.18981754779815674
train loss item: 0.10965405404567719
train loss item: 0.08378887921571732
train loss item: 0.13698157668113708
train loss item: 0.05613114684820175
train loss item: 0.27044522762298584
train loss item: 0.6043357849121094
train loss item: 0.28919491171836853
train loss item: 0.12110189348459244
train loss item: 0.16328448057174683
train loss item: 0.09307202696800232
train loss item: 0.6612449288368225
train loss item: 0.3056783378124237
train loss item: 0.27738139033317566
train loss item: 0.19660110771656036
train loss item: 0.18264880776405334
train loss item: 0.1160423532128334
train loss item: 0.11261908710002899
train loss item: 0.208200603723526
train loss item: 0.1424390822649002
train loss item: 0.3143642246723175
train loss item: 0.06920044869184494
train loss item: 0.07254789024591446
train loss item: 0.21309903264045715
train loss item: 0.14377065002918243
train loss item: 0.07648719847202301
train loss item: 0.22834813594818115
train loss item: 0.47274893522262573
train loss item: 0.05747603625059128
train loss item: 0.08174210786819458
train loss item: 0.33069878816604614
train loss item: 0.0818508043885231
train loss item: 0.17506179213523865
train loss item: 0.09383952617645264
train loss item: 0.07883520424365997
train loss item: 0.08413325995206833
train loss item: 0.2020927220582962
train loss item: 0.6900960206985474
train loss item: 0.1264180988073349
train loss item: 0.2330208420753479
train loss item: 0.0902220830321312
train loss item: 0.13808472454547882
train loss item: 0.21650686860084534
train loss item: 0.07520772516727448
train loss item: 0.11882203817367554
train loss item: 0.08412627130746841
train loss item: 0.08342786878347397
train loss item: 0.044113632291555405
train loss item: 0.06204954534769058
train loss item: 0.11748793721199036
train loss item: 0.0486191101372242
train loss item: 0.0588054396212101
train loss item: 0.2973484992980957
train loss item: 0.8687699437141418
train loss item: 0.04218043386936188
train loss item: 0.12187014520168304
train loss item: 0.07745940238237381
train loss item: 0.07146169990301132
train loss item: 0.09939414262771606
train loss item: 0.17620277404785156
train loss item: 0.2530566453933716
train loss item: 0.17100153863430023
train loss item: 0.34125009179115295
train loss item: 0.050476912409067154
train loss item: 0.19573259353637695
test loss item: 0.08873776346445084
test loss item: 0.07628822326660156
test loss item: 0.2883429229259491
test loss item: 0.12236437201499939
test loss item: 0.14258918166160583
test loss item: 0.13434915244579315
test loss item: 1.1242910623550415
test loss item: 0.34406358003616333
test loss item: 0.11902645975351334
test loss item: 0.1848074346780777
test loss item: 0.43260443210601807
test loss item: 0.06914085149765015
test loss item: 0.08732720464468002
test loss item: 0.1209247037768364
test loss item: 0.10428760945796967
test loss item: 0.05967235192656517
test loss item: 0.13376875221729279
test loss item: 0.19433186948299408
test loss item: 0.3647661805152893
test loss item: 0.11130261421203613
test loss item: 0.3009662926197052
test loss item: 0.21181398630142212
test loss item: 0.22801150381565094
test loss item: 0.10332518070936203
test loss item: 0.09852289408445358
test loss item: 0.10777835547924042
test loss item: 0.13556964695453644
test loss item: 0.11759350448846817
test loss item: 0.14542052149772644
test loss item: 0.15186917781829834
test loss item: 0.47031694650650024
test loss item: 0.06400204449892044
test loss item: 0.09385351836681366
test loss item: 0.23321405053138733
test loss item: 0.19520995020866394
test loss item: 0.2123100906610489
test loss item: 0.45941996574401855
test loss item: 0.7054433822631836
test loss item: 0.2122054398059845
test loss item: 0.18160304427146912
test loss item: 0.16742227971553802
test loss item: 0.18579845130443573
test loss item: 0.15023508667945862
test loss item: 0.1254338026046753
test loss item: 0.233912393450737
test loss item: 0.1666109561920166
test loss item: 0.21941736340522766
test loss item: 0.11510931700468063
test loss item: 0.22495976090431213
test loss item: 0.33828431367874146
test loss item: 0.15945076942443848
test loss item: 0.08014994114637375
test loss item: 0.12913328409194946
test loss item: 0.09249750524759293
test loss item: 0.1413308084011078
test loss item: 0.40593695640563965
test loss item: 0.2769046723842621
test loss item: 0.17949415743350983
test loss item: 0.12293470650911331
test loss item: 0.09660499542951584
test loss item: 0.19626101851463318
test loss item: 0.12776221334934235
test loss item: 0.09463156759738922
test loss item: 0.10871656984090805
test loss item: 0.46088555455207825
test loss item: 0.16215936839580536
test loss item: 0.13939368724822998
test loss item: 0.1292700469493866
test loss item: 0.2191818654537201
test loss item: 0.2590402364730835
test loss item: 0.060299329459667206
test loss item: 0.6171855926513672
test loss item: 0.13542857766151428
test loss item: 0.20342375338077545
test loss item: 0.08428067713975906
test loss item: 0.19521914422512054
test loss item: 0.10572334378957748
test loss item: 0.7298663258552551
test loss item: 0.17081516981124878
test loss item: 0.12491434812545776
test loss item: 0.08122333884239197
test loss item: 0.5503886938095093
test loss item: 0.49716854095458984
test loss item: 0.5138972997665405
test loss item: 0.1048077642917633
test loss item: 0.0970853790640831
test loss item: 0.08775315433740616
test loss item: 0.07373858988285065
test loss item: 0.13391365110874176
Epoch [34/50], Training Loss: 0.1762, Testing Loss: 0.2113
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.18360450863838196
loss item: 0.11378119885921478
loss item: 0.7732493877410889
loss item: 0.39385971426963806
loss item: 0.376323938369751
loss item: 0.20087546110153198
loss item: 0.09465619176626205
loss item: 0.4832707941532135
loss item: 0.09844407439231873
loss item: 0.1067473441362381
loss item: 0.5909653902053833
loss item: 0.05410582199692726
loss item: 0.5232440233230591
loss item: 0.10001982748508453
loss item: 0.2561292350292206
loss item: 0.2660951614379883
loss item: 0.18664394319057465
loss item: 0.2860138416290283
loss item: 0.4615509510040283
loss item: 0.18914709985256195
loss item: 0.1680774986743927
loss item: 0.091843381524086
loss item: 0.11929000914096832
loss item: 0.11766696721315384
loss item: 0.11177924275398254
loss item: 0.3936399817466736
loss item: 0.5398112535476685
loss item: 0.10450177639722824
loss item: 0.08564317971467972
loss item: 0.23000174760818481
loss item: 0.6532405614852905
loss item: 0.7625669836997986
loss item: 0.09457258880138397
loss item: 0.2950652837753296
loss item: 0.08937880396842957
loss item: 0.19169865548610687
loss item: 0.19091211259365082
loss item: 0.11019188910722733
loss item: 0.2502352297306061
loss item: 0.38780081272125244
loss item: 0.5414071679115295
loss item: 0.19552569091320038
loss item: 0.14639554917812347
loss item: 0.058557331562042236
Val Loss: 0.2652
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 50, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.005 2 360 done at Tue Nov 12 10:30:24 CET 2024
UNet2 with 1 50 0.0001 4 360 start at Tue Nov 12 10:30:24 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.6336421966552734
train loss item: 1.1108150482177734
train loss item: 0.6386311054229736
train loss item: 1.194264531135559
train loss item: 0.5417352318763733
train loss item: 0.5596734285354614
train loss item: 0.6423448920249939
train loss item: 0.840389609336853
train loss item: 0.516490638256073
train loss item: 0.5425041317939758
train loss item: 0.38656359910964966
train loss item: 1.3202400207519531
train loss item: 0.5797537565231323
train loss item: 0.4730110168457031
train loss item: 0.8736816644668579
train loss item: 2.072476387023926
train loss item: 0.6429057121276855
train loss item: 2.485495090484619
train loss item: 0.4917813241481781
train loss item: 0.4936889708042145
train loss item: 0.4070166349411011
train loss item: 0.3808233439922333
train loss item: 0.6257745027542114
train loss item: 0.42149874567985535
train loss item: 0.3764941394329071
train loss item: 0.8154841661453247
train loss item: 0.3215309977531433
train loss item: 1.8327252864837646
train loss item: 0.4126252233982086
train loss item: 0.32324883341789246
train loss item: 1.6522047519683838
train loss item: 0.39049842953681946
train loss item: 0.5390455722808838
train loss item: 0.41372454166412354
train loss item: 0.4230559170246124
train loss item: 0.3145202100276947
train loss item: 0.3597916066646576
train loss item: 0.3155818283557892
train loss item: 1.1574903726577759
train loss item: 0.2918848991394043
train loss item: 0.2487623244524002
train loss item: 0.5042638778686523
train loss item: 0.5764230489730835
train loss item: 3.096247673034668
train loss item: 0.3796599209308624
test loss item: 0.19254712760448456
test loss item: 0.5322990417480469
test loss item: 0.27953314781188965
test loss item: 1.0018279552459717
test loss item: 0.3794468939304352
test loss item: 0.7656427025794983
test loss item: 0.21222026646137238
test loss item: 0.202741801738739
test loss item: 0.42609620094299316
test loss item: 0.4844416677951813
test loss item: 0.540101170539856
test loss item: 0.3132360577583313
test loss item: 0.2739086449146271
test loss item: 0.3122216463088989
test loss item: 0.3926287889480591
test loss item: 0.7177404165267944
test loss item: 0.5661835670471191
test loss item: 0.5591747164726257
test loss item: 1.1336504220962524
test loss item: 0.47167396545410156
test loss item: 0.3113957345485687
test loss item: 0.34059053659439087
test loss item: 0.5480929613113403
test loss item: 0.31760090589523315
test loss item: 0.6265824437141418
test loss item: 0.27403774857521057
test loss item: 0.2855880856513977
test loss item: 0.7560979723930359
test loss item: 0.6133039593696594
test loss item: 0.2586955726146698
test loss item: 0.4102960228919983
test loss item: 0.27191323041915894
test loss item: 0.7541375756263733
test loss item: 0.3337915539741516
test loss item: 0.5460705161094666
test loss item: 0.6468589305877686
test loss item: 0.40331289172172546
test loss item: 0.1907721906900406
test loss item: 1.349961280822754
test loss item: 0.26866015791893005
test loss item: 0.8250028491020203
test loss item: 1.006622314453125
test loss item: 0.26233527064323425
test loss item: 0.1525888890028
test loss item: 0.2591479420661926
Epoch [1/50], Training Loss: 0.7693, Testing Loss: 0.4838
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/50
train loss item: 0.8530784845352173
train loss item: 0.4625650942325592
train loss item: 0.3809688687324524
train loss item: 0.5835763216018677
train loss item: 0.2991321384906769
train loss item: 0.35864973068237305
train loss item: 0.3826286196708679
train loss item: 0.5319647789001465
train loss item: 0.2997666001319885
train loss item: 0.3559068441390991
train loss item: 0.28267526626586914
train loss item: 0.8010956048965454
train loss item: 0.43608972430229187
train loss item: 0.32831594347953796
train loss item: 0.5846399664878845
train loss item: 1.4322606325149536
train loss item: 0.38311606645584106
train loss item: 1.8654735088348389
train loss item: 0.435563862323761
train loss item: 0.39391812682151794
train loss item: 0.26817646622657776
train loss item: 0.28279995918273926
train loss item: 0.436543732881546
train loss item: 0.31909412145614624
train loss item: 0.2407585233449936
train loss item: 0.649221658706665
train loss item: 0.2089318037033081
train loss item: 1.4434759616851807
train loss item: 0.3099333643913269
train loss item: 0.20974814891815186
train loss item: 1.349700927734375
train loss item: 0.32061582803726196
train loss item: 0.40310314297676086
train loss item: 0.35192814469337463
train loss item: 0.3204593062400818
train loss item: 0.2591325044631958
train loss item: 0.3048819899559021
train loss item: 0.22847671806812286
train loss item: 0.9508203268051147
train loss item: 0.27142608165740967
train loss item: 0.19510751962661743
train loss item: 0.3813060522079468
train loss item: 0.4492320716381073
train loss item: 2.600039005279541
train loss item: 0.35590770840644836
test loss item: 0.1924028843641281
test loss item: 0.38901200890541077
test loss item: 0.21826393902301788
test loss item: 0.7553784847259521
test loss item: 0.30172598361968994
test loss item: 0.5766850113868713
test loss item: 0.17969641089439392
test loss item: 0.2035469114780426
test loss item: 0.3262111246585846
test loss item: 0.41878992319107056
test loss item: 0.43651410937309265
test loss item: 0.2396809607744217
test loss item: 0.22214895486831665
test loss item: 0.26224586367607117
test loss item: 0.32335275411605835
test loss item: 0.507458508014679
test loss item: 0.45063671469688416
test loss item: 0.45962539315223694
test loss item: 0.8126094341278076
test loss item: 0.3641131520271301
test loss item: 0.2598801851272583
test loss item: 0.30639076232910156
test loss item: 0.4210054874420166
test loss item: 0.2530648410320282
test loss item: 0.45969319343566895
test loss item: 0.2280336171388626
test loss item: 0.26939958333969116
test loss item: 0.5392659306526184
test loss item: 0.517770528793335
test loss item: 0.21934156119823456
test loss item: 0.34101319313049316
test loss item: 0.21918857097625732
test loss item: 0.5810450911521912
test loss item: 0.26746615767478943
test loss item: 0.42877864837646484
test loss item: 0.4954307973384857
test loss item: 0.3076644241809845
test loss item: 0.16605477035045624
test loss item: 0.8322762846946716
test loss item: 0.21045993268489838
test loss item: 0.5955309271812439
test loss item: 0.7164821028709412
test loss item: 0.21455755829811096
test loss item: 0.1829734593629837
test loss item: 0.23580966889858246
Epoch [2/50], Training Loss: 0.5458, Testing Loss: 0.3757
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/50
train loss item: 0.6598713397979736
train loss item: 0.4232446849346161
train loss item: 0.2901347875595093
train loss item: 0.4724433422088623
train loss item: 0.2490486353635788
train loss item: 0.2853403389453888
train loss item: 0.3308391571044922
train loss item: 0.4407189190387726
train loss item: 0.23018403351306915
train loss item: 0.31086409091949463
train loss item: 0.22126378118991852
train loss item: 0.64383465051651
train loss item: 0.3296438753604889
train loss item: 0.24782025814056396
train loss item: 0.43594369292259216
train loss item: 1.1538946628570557
train loss item: 0.33476313948631287
train loss item: 1.5579376220703125
train loss item: 0.43418073654174805
train loss item: 0.37340864539146423
train loss item: 0.22276949882507324
train loss item: 0.24664263427257538
train loss item: 0.3776668310165405
train loss item: 0.27741819620132446
train loss item: 0.19357553124427795
train loss item: 0.6395742893218994
train loss item: 0.1662517786026001
train loss item: 1.2544194459915161
train loss item: 0.24450421333312988
train loss item: 0.16649506986141205
train loss item: 1.2141917943954468
train loss item: 0.2717919945716858
train loss item: 0.32139265537261963
train loss item: 0.31059080362319946
train loss item: 0.3024057447910309
train loss item: 0.23042164742946625
train loss item: 0.2689515948295593
train loss item: 0.18069873750209808
train loss item: 0.8145211935043335
train loss item: 0.24411973357200623
train loss item: 0.15811559557914734
train loss item: 0.3099927306175232
train loss item: 0.3743237257003784
train loss item: 2.2548959255218506
train loss item: 0.3455474078655243
test loss item: 0.1567484587430954
test loss item: 0.32524338364601135
test loss item: 0.18354667723178864
test loss item: 0.6443492770195007
test loss item: 0.248031884431839
test loss item: 0.48228785395622253
test loss item: 0.1571148782968521
test loss item: 0.15591980516910553
test loss item: 0.2755969166755676
test loss item: 0.36114421486854553
test loss item: 0.3683328330516815
test loss item: 0.19906823337078094
test loss item: 0.1932804435491562
test loss item: 0.21959657967090607
test loss item: 0.2695635259151459
test loss item: 0.4195825755596161
test loss item: 0.37004873156547546
test loss item: 0.3853686451911926
test loss item: 0.6814380884170532
test loss item: 0.30140599608421326
test loss item: 0.2276572585105896
test loss item: 0.24772590398788452
test loss item: 0.3485667109489441
test loss item: 0.21713702380657196
test loss item: 0.38144251704216003
test loss item: 0.19126345217227936
test loss item: 0.22153939306735992
test loss item: 0.4535500109195709
test loss item: 0.43874040246009827
test loss item: 0.18656742572784424
test loss item: 0.2786179184913635
test loss item: 0.19131726026535034
test loss item: 0.5063855051994324
test loss item: 0.22844058275222778
test loss item: 0.36884254217147827
test loss item: 0.41617342829704285
test loss item: 0.26360324025154114
test loss item: 0.1388445347547531
test loss item: 0.7032617926597595
test loss item: 0.1841839849948883
test loss item: 0.5050525069236755
test loss item: 0.6139421463012695
test loss item: 0.18758070468902588
test loss item: 0.1349361389875412
test loss item: 0.21195200085639954
Epoch [3/50], Training Loss: 0.4626, Testing Loss: 0.3166
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/50
train loss item: 0.5618870258331299
train loss item: 0.3722328245639801
train loss item: 0.2490004301071167
train loss item: 0.4106227159500122
train loss item: 0.21585331857204437
train loss item: 0.23959307372570038
train loss item: 0.3030990660190582
train loss item: 0.41610923409461975
train loss item: 0.19181565940380096
train loss item: 0.2672255039215088
train loss item: 0.19824333488941193
train loss item: 0.5656682848930359
train loss item: 0.28306129574775696
train loss item: 0.20236040651798248
train loss item: 0.38575372099876404
train loss item: 0.9758630990982056
train loss item: 0.30334147810935974
train loss item: 1.3312838077545166
train loss item: 0.4402458965778351
train loss item: 0.36445504426956177
train loss item: 0.21548692882061005
train loss item: 0.2280951291322708
train loss item: 0.3320624828338623
train loss item: 0.22963036596775055
train loss item: 0.17212408781051636
train loss item: 0.5709607601165771
train loss item: 0.1486683487892151
train loss item: 1.1131006479263306
train loss item: 0.22239600121974945
train loss item: 0.1416970193386078
train loss item: 1.081766963005066
train loss item: 0.2511066794395447
train loss item: 0.2881886065006256
train loss item: 0.2728324234485626
train loss item: 0.2696932852268219
train loss item: 0.20192497968673706
train loss item: 0.23364686965942383
train loss item: 0.15686996281147003
train loss item: 0.7055091857910156
train loss item: 0.23961731791496277
train loss item: 0.1528039127588272
train loss item: 0.2644255757331848
train loss item: 0.3651811182498932
train loss item: 2.0158777236938477
train loss item: 0.3106262981891632
test loss item: 0.14340484142303467
test loss item: 0.30663344264030457
test loss item: 0.17964254319667816
test loss item: 0.5757611989974976
test loss item: 0.2274440973997116
test loss item: 0.42666706442832947
test loss item: 0.14615949988365173
test loss item: 0.13580358028411865
test loss item: 0.24561995267868042
test loss item: 0.32771116495132446
test loss item: 0.33906301856040955
test loss item: 0.18428988754749298
test loss item: 0.17388392984867096
test loss item: 0.20481479167938232
test loss item: 0.24307343363761902
test loss item: 0.3703857958316803
test loss item: 0.3368488848209381
test loss item: 0.33273741602897644
test loss item: 0.6039667129516602
test loss item: 0.27708303928375244
test loss item: 0.20756562054157257
test loss item: 0.22960279881954193
test loss item: 0.30724990367889404
test loss item: 0.20498403906822205
test loss item: 0.35021117329597473
test loss item: 0.17306102812290192
test loss item: 0.21332448720932007
test loss item: 0.4067201018333435
test loss item: 0.3879269063472748
test loss item: 0.16979791224002838
test loss item: 0.25095072388648987
test loss item: 0.17552438378334045
test loss item: 0.4471025764942169
test loss item: 0.20794320106506348
test loss item: 0.33272111415863037
test loss item: 0.3695046007633209
test loss item: 0.2523035705089569
test loss item: 0.13593003153800964
test loss item: 0.5824683904647827
test loss item: 0.18316017091274261
test loss item: 0.4357914924621582
test loss item: 0.5340243577957153
test loss item: 0.17386946082115173
test loss item: 0.11617188155651093
test loss item: 0.1767515391111374
Epoch [4/50], Training Loss: 0.4103, Testing Loss: 0.2846
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/50
train loss item: 0.5013740062713623
train loss item: 0.31032848358154297
train loss item: 0.22424444556236267
train loss item: 0.3636402487754822
train loss item: 0.20785178244113922
train loss item: 0.21106576919555664
train loss item: 0.2755098342895508
train loss item: 0.41011419892311096
train loss item: 0.1712239533662796
train loss item: 0.2496809959411621
train loss item: 0.1869724541902542
train loss item: 0.5059334635734558
train loss item: 0.2949138283729553
train loss item: 0.17667461931705475
train loss item: 0.34406930208206177
train loss item: 0.8494293093681335
train loss item: 0.2649646997451782
train loss item: 1.1987065076828003
train loss item: 0.431135356426239
train loss item: 0.3233742415904999
train loss item: 0.21564146876335144
train loss item: 0.21672971546649933
train loss item: 0.30766192078590393
train loss item: 0.19931910932064056
train loss item: 0.1563977152109146
train loss item: 0.5174603462219238
train loss item: 0.1394663006067276
train loss item: 0.9935267567634583
train loss item: 0.20669110119342804
train loss item: 0.12679420411586761
train loss item: 0.9841118454933167
train loss item: 0.22322897613048553
train loss item: 0.25033268332481384
train loss item: 0.2367764115333557
train loss item: 0.23951266705989838
train loss item: 0.18053515255451202
train loss item: 0.2114439308643341
train loss item: 0.1395351141691208
train loss item: 0.6312664151191711
train loss item: 0.22452309727668762
train loss item: 0.1439131647348404
train loss item: 0.23302431404590607
train loss item: 0.37349188327789307
train loss item: 1.8478450775146484
train loss item: 0.2762938439846039
test loss item: 0.13432292640209198
test loss item: 0.2698875963687897
test loss item: 0.16619634628295898
test loss item: 0.5098472833633423
test loss item: 0.21033135056495667
test loss item: 0.3878975212574005
test loss item: 0.14286909997463226
test loss item: 0.11820726096630096
test loss item: 0.21723394095897675
test loss item: 0.29824623465538025
test loss item: 0.283408522605896
test loss item: 0.1756659895181656
test loss item: 0.15902754664421082
test loss item: 0.18850457668304443
test loss item: 0.22202034294605255
test loss item: 0.3362136483192444
test loss item: 0.2843731939792633
test loss item: 0.2979661822319031
test loss item: 0.5561423301696777
test loss item: 0.23569442331790924
test loss item: 0.18900063633918762
test loss item: 0.17881880700588226
test loss item: 0.2702197730541229
test loss item: 0.19903084635734558
test loss item: 0.3218778371810913
test loss item: 0.16384385526180267
test loss item: 0.16468198597431183
test loss item: 0.3754085600376129
test loss item: 0.3472352623939514
test loss item: 0.15991036593914032
test loss item: 0.22524623572826385
test loss item: 0.16352002322673798
test loss item: 0.38411054015159607
test loss item: 0.18911604583263397
test loss item: 0.3091127574443817
test loss item: 0.32292452454566956
test loss item: 0.24100777506828308
test loss item: 0.13480062782764435
test loss item: 0.5450472235679626
test loss item: 0.17032469809055328
test loss item: 0.38677623867988586
test loss item: 0.4849449396133423
test loss item: 0.16099335253238678
test loss item: 0.09332399815320969
test loss item: 0.16240699589252472
Epoch [5/50], Training Loss: 0.3728, Testing Loss: 0.2564
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/50
train loss item: 0.44988641142845154
train loss item: 0.27093246579170227
train loss item: 0.2079661637544632
train loss item: 0.30964550375938416
train loss item: 0.18559907376766205
train loss item: 0.1912204921245575
train loss item: 0.2342289537191391
train loss item: 0.3920990228652954
train loss item: 0.16300596296787262
train loss item: 0.23888932168483734
train loss item: 0.19406132400035858
train loss item: 0.47086137533187866
train loss item: 0.2553054094314575
train loss item: 0.15356262028217316
train loss item: 0.32063063979148865
train loss item: 0.7193990349769592
train loss item: 0.24301914870738983
train loss item: 1.0767515897750854
train loss item: 0.40787607431411743
train loss item: 0.2844446301460266
train loss item: 0.20614826679229736
train loss item: 0.1920308768749237
train loss item: 0.2868853211402893
train loss item: 0.17821799218654633
train loss item: 0.1461944580078125
train loss item: 0.4629668891429901
train loss item: 0.122275210916996
train loss item: 0.8946674466133118
train loss item: 0.19240275025367737
train loss item: 0.11612949520349503
train loss item: 0.8758742213249207
train loss item: 0.21149420738220215
train loss item: 0.23510947823524475
train loss item: 0.23900988698005676
train loss item: 0.22558818757534027
train loss item: 0.17874161899089813
train loss item: 0.19237491488456726
train loss item: 0.12507560849189758
train loss item: 0.582118034362793
train loss item: 0.2024574726819992
train loss item: 0.13249118626117706
train loss item: 0.22354823350906372
train loss item: 0.3388078808784485
train loss item: 1.7159408330917358
train loss item: 0.24550417065620422
test loss item: 0.1340607851743698
test loss item: 0.24220483005046844
test loss item: 0.15514422953128815
test loss item: 0.46529293060302734
test loss item: 0.19514508545398712
test loss item: 0.37693244218826294
test loss item: 0.13948598504066467
test loss item: 0.11864413321018219
test loss item: 0.18864358961582184
test loss item: 0.28757810592651367
test loss item: 0.2520495355129242
test loss item: 0.18057270348072052
test loss item: 0.14638762176036835
test loss item: 0.17855148017406464
test loss item: 0.20451349020004272
test loss item: 0.322742223739624
test loss item: 0.24768340587615967
test loss item: 0.2818211317062378
test loss item: 0.519569993019104
test loss item: 0.2082609087228775
test loss item: 0.1820547878742218
test loss item: 0.15688611567020416
test loss item: 0.24433763325214386
test loss item: 0.20277173817157745
test loss item: 0.3024589419364929
test loss item: 0.1549171656370163
test loss item: 0.14670492708683014
test loss item: 0.348246306180954
test loss item: 0.3248414099216461
test loss item: 0.1501992791891098
test loss item: 0.202958345413208
test loss item: 0.15449988842010498
test loss item: 0.3527458906173706
test loss item: 0.176020085811615
test loss item: 0.30298298597335815
test loss item: 0.2940640449523926
test loss item: 0.23462460935115814
test loss item: 0.13591225445270538
test loss item: 0.5034810900688171
test loss item: 0.16166161000728607
test loss item: 0.371254026889801
test loss item: 0.4629242718219757
test loss item: 0.15182191133499146
test loss item: 0.08983635157346725
test loss item: 0.14914385974407196
Epoch [6/50], Training Loss: 0.3398, Testing Loss: 0.2401
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/50
train loss item: 0.41454997658729553
train loss item: 0.26804354786872864
train loss item: 0.1916729360818863
train loss item: 0.27374932169914246
train loss item: 0.17591224610805511
train loss item: 0.1756320297718048
train loss item: 0.2303774505853653
train loss item: 0.36749327182769775
train loss item: 0.1398715227842331
train loss item: 0.22419755160808563
train loss item: 0.18504679203033447
train loss item: 0.45341071486473083
train loss item: 0.2481386363506317
train loss item: 0.14237727224826813
train loss item: 0.30714333057403564
train loss item: 0.6249163150787354
train loss item: 0.19745318591594696
train loss item: 0.9597494602203369
train loss item: 0.3917326033115387
train loss item: 0.2718021273612976
train loss item: 0.20099900662899017
train loss item: 0.17240512371063232
train loss item: 0.2829882502555847
train loss item: 0.1633988469839096
train loss item: 0.14148171246051788
train loss item: 0.4645848572254181
train loss item: 0.11329657584428787
train loss item: 0.8131594061851501
train loss item: 0.18404170870780945
train loss item: 0.10973693430423737
train loss item: 0.8055751323699951
train loss item: 0.19485902786254883
train loss item: 0.20967580378055573
train loss item: 0.21634873747825623
train loss item: 0.21603897213935852
train loss item: 0.169912651181221
train loss item: 0.18605192005634308
train loss item: 0.12169608473777771
train loss item: 0.5088026523590088
train loss item: 0.18436655402183533
train loss item: 0.11889767646789551
train loss item: 0.2062525749206543
train loss item: 0.34538379311561584
train loss item: 1.6342169046401978
train loss item: 0.21319052577018738
test loss item: 0.13626126945018768
test loss item: 0.22541064023971558
test loss item: 0.15676189959049225
test loss item: 0.43823498487472534
test loss item: 0.18042749166488647
test loss item: 0.338851660490036
test loss item: 0.1396511197090149
test loss item: 0.12104396522045135
test loss item: 0.17659509181976318
test loss item: 0.27170777320861816
test loss item: 0.24022959172725677
test loss item: 0.18207883834838867
test loss item: 0.13782164454460144
test loss item: 0.17194350063800812
test loss item: 0.19489185512065887
test loss item: 0.29474011063575745
test loss item: 0.22981835901737213
test loss item: 0.2642546594142914
test loss item: 0.47157400846481323
test loss item: 0.19928225874900818
test loss item: 0.18244311213493347
test loss item: 0.15014441311359406
test loss item: 0.2294088751077652
test loss item: 0.20566432178020477
test loss item: 0.2749324142932892
test loss item: 0.150980144739151
test loss item: 0.14523237943649292
test loss item: 0.3148833215236664
test loss item: 0.30023783445358276
test loss item: 0.14690694212913513
test loss item: 0.18690435588359833
test loss item: 0.15010209381580353
test loss item: 0.3357245624065399
test loss item: 0.1681685745716095
test loss item: 0.2854636013507843
test loss item: 0.2780090570449829
test loss item: 0.22907018661499023
test loss item: 0.14284847676753998
test loss item: 0.4634464383125305
test loss item: 0.1644568145275116
test loss item: 0.33590593934059143
test loss item: 0.4184356927871704
test loss item: 0.14570340514183044
test loss item: 0.08862804621458054
test loss item: 0.15084011852741241
Epoch [7/50], Training Loss: 0.3160, Testing Loss: 0.2270
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/50
train loss item: 0.36784061789512634
train loss item: 0.24950067698955536
train loss item: 0.18349333107471466
train loss item: 0.2408403605222702
train loss item: 0.1685318499803543
train loss item: 0.16613341867923737
train loss item: 0.21648409962654114
train loss item: 0.337696373462677
train loss item: 0.1253076046705246
train loss item: 0.20154008269309998
train loss item: 0.16166839003562927
train loss item: 0.4234488904476166
train loss item: 0.22996783256530762
train loss item: 0.13502463698387146
train loss item: 0.29763707518577576
train loss item: 0.5143784284591675
train loss item: 0.1808212250471115
train loss item: 0.8667436838150024
train loss item: 0.38528600335121155
train loss item: 0.24839942157268524
train loss item: 0.19692890346050262
train loss item: 0.16079145669937134
train loss item: 0.25983643531799316
train loss item: 0.15004892647266388
train loss item: 0.1256919950246811
train loss item: 0.4373195767402649
train loss item: 0.1183590218424797
train loss item: 0.7142419219017029
train loss item: 0.16697648167610168
train loss item: 0.10748367011547089
train loss item: 0.7046895027160645
train loss item: 0.17807410657405853
train loss item: 0.18322856724262238
train loss item: 0.20024827122688293
train loss item: 0.19781407713890076
train loss item: 0.1543402522802353
train loss item: 0.17256595194339752
train loss item: 0.10739023983478546
train loss item: 0.4688865542411804
train loss item: 0.16113485395908356
train loss item: 0.11181340366601944
train loss item: 0.19108273088932037
train loss item: 0.3211846351623535
train loss item: 1.501360297203064
train loss item: 0.2077721506357193
test loss item: 0.1177375316619873
test loss item: 0.21245895326137543
test loss item: 0.13517913222312927
test loss item: 0.3906194865703583
test loss item: 0.16884319484233856
test loss item: 0.3053142726421356
test loss item: 0.13909098505973816
test loss item: 0.10500095784664154
test loss item: 0.16523024439811707
test loss item: 0.24618013203144073
test loss item: 0.2233904004096985
test loss item: 0.17857451736927032
test loss item: 0.13167832791805267
test loss item: 0.15475240349769592
test loss item: 0.1777571588754654
test loss item: 0.2635396718978882
test loss item: 0.21417200565338135
test loss item: 0.23878416419029236
test loss item: 0.42573976516723633
test loss item: 0.18484432995319366
test loss item: 0.17094393074512482
test loss item: 0.1413283497095108
test loss item: 0.2129966765642166
test loss item: 0.19221976399421692
test loss item: 0.2563619613647461
test loss item: 0.14486943185329437
test loss item: 0.1353897601366043
test loss item: 0.27811160683631897
test loss item: 0.2652778923511505
test loss item: 0.1432388871908188
test loss item: 0.17704151570796967
test loss item: 0.14219816029071808
test loss item: 0.3038955330848694
test loss item: 0.15733391046524048
test loss item: 0.25734812021255493
test loss item: 0.24675698578357697
test loss item: 0.22132423520088196
test loss item: 0.13157080113887787
test loss item: 0.44050583243370056
test loss item: 0.1442861407995224
test loss item: 0.29807960987091064
test loss item: 0.3811245560646057
test loss item: 0.1400591880083084
test loss item: 0.07555555552244186
test loss item: 0.166922926902771
Epoch [8/50], Training Loss: 0.2889, Testing Loss: 0.2090
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/50
train loss item: 0.3302418291568756
train loss item: 0.22403936088085175
train loss item: 0.17211875319480896
train loss item: 0.21256420016288757
train loss item: 0.14980654418468475
train loss item: 0.15224815905094147
train loss item: 0.2266535460948944
train loss item: 0.3215705454349518
train loss item: 0.11121034622192383
train loss item: 0.18310467898845673
train loss item: 0.14648160338401794
train loss item: 0.40348565578460693
train loss item: 0.20336025953292847
train loss item: 0.12599597871303558
train loss item: 0.2718138098716736
train loss item: 0.4219495356082916
train loss item: 0.1730349063873291
train loss item: 0.7368584275245667
train loss item: 0.3975406587123871
train loss item: 0.23392324149608612
train loss item: 0.1839410662651062
train loss item: 0.15467926859855652
train loss item: 0.24628481268882751
train loss item: 0.14221394062042236
train loss item: 0.12027032673358917
train loss item: 0.40926358103752136
train loss item: 0.11785285919904709
train loss item: 0.5831753015518188
train loss item: 0.15283595025539398
train loss item: 0.09802483767271042
train loss item: 0.5840398669242859
train loss item: 0.1682746559381485
train loss item: 0.1680750846862793
train loss item: 0.20082467794418335
train loss item: 0.1791709065437317
train loss item: 0.14952269196510315
train loss item: 0.16032204031944275
train loss item: 0.09691616147756577
train loss item: 0.42502012848854065
train loss item: 0.14469069242477417
train loss item: 0.12223520874977112
train loss item: 0.1792389154434204
train loss item: 0.2772405743598938
train loss item: 1.3736014366149902
train loss item: 0.2033366858959198
test loss item: 0.11311081051826477
test loss item: 0.18484236299991608
test loss item: 0.12169858068227768
test loss item: 0.3644486665725708
test loss item: 0.14850309491157532
test loss item: 0.264989972114563
test loss item: 0.12849077582359314
test loss item: 0.09587249904870987
test loss item: 0.14719507098197937
test loss item: 0.22648239135742188
test loss item: 0.201063871383667
test loss item: 0.18377240002155304
test loss item: 0.11817418038845062
test loss item: 0.1362069696187973
test loss item: 0.15790009498596191
test loss item: 0.22952765226364136
test loss item: 0.1827385127544403
test loss item: 0.21693433821201324
test loss item: 0.37003934383392334
test loss item: 0.16175462305545807
test loss item: 0.17315290868282318
test loss item: 0.12692485749721527
test loss item: 0.1909516453742981
test loss item: 0.2015809416770935
test loss item: 0.22216390073299408
test loss item: 0.12948067486286163
test loss item: 0.12217728793621063
test loss item: 0.22750894725322723
test loss item: 0.2427314966917038
test loss item: 0.13007718324661255
test loss item: 0.15684086084365845
test loss item: 0.13163825869560242
test loss item: 0.2710028886795044
test loss item: 0.14216072857379913
test loss item: 0.2362583875656128
test loss item: 0.22690033912658691
test loss item: 0.20303773880004883
test loss item: 0.13828402757644653
test loss item: 0.3551681935787201
test loss item: 0.1375318467617035
test loss item: 0.27216798067092896
test loss item: 0.3282991051673889
test loss item: 0.13064239919185638
test loss item: 0.0715370699763298
test loss item: 0.14215025305747986
Epoch [9/50], Training Loss: 0.2631, Testing Loss: 0.1881
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/50
train loss item: 0.29187530279159546
train loss item: 0.2128784954547882
train loss item: 0.16123956441879272
train loss item: 0.19921891391277313
train loss item: 0.1401684433221817
train loss item: 0.14485691487789154
train loss item: 0.22190387547016144
train loss item: 0.29056307673454285
train loss item: 0.10331331938505173
train loss item: 0.1700706034898758
train loss item: 0.13084116578102112
train loss item: 0.3605635166168213
train loss item: 0.1915607452392578
train loss item: 0.1213129460811615
train loss item: 0.2429976910352707
train loss item: 0.3962511718273163
train loss item: 0.16313625872135162
train loss item: 0.6621583700180054
train loss item: 0.3682883679866791
train loss item: 0.20311768352985382
train loss item: 0.16183900833129883
train loss item: 0.16023753583431244
train loss item: 0.22252614796161652
train loss item: 0.13650193810462952
train loss item: 0.11743287742137909
train loss item: 0.36222130060195923
train loss item: 0.10197269916534424
train loss item: 0.5320253372192383
train loss item: 0.15651357173919678
train loss item: 0.09390117973089218
train loss item: 0.509249210357666
train loss item: 0.16178938746452332
train loss item: 0.15966235101222992
train loss item: 0.20981435477733612
train loss item: 0.17002639174461365
train loss item: 0.13701122999191284
train loss item: 0.14898106455802917
train loss item: 0.09256220608949661
train loss item: 0.41766098141670227
train loss item: 0.13805781304836273
train loss item: 0.11330712586641312
train loss item: 0.18175268173217773
train loss item: 0.22302955389022827
train loss item: 1.3010591268539429
train loss item: 0.21258075535297394
test loss item: 0.1093963086605072
test loss item: 0.17352086305618286
test loss item: 0.12075795233249664
test loss item: 0.3295615613460541
test loss item: 0.13816601037979126
test loss item: 0.24634750187397003
test loss item: 0.12015548348426819
test loss item: 0.10266722738742828
test loss item: 0.1322946399450302
test loss item: 0.19731055200099945
test loss item: 0.18664567172527313
test loss item: 0.15989863872528076
test loss item: 0.11059729754924774
test loss item: 0.1278533935546875
test loss item: 0.14528538286685944
test loss item: 0.20872630178928375
test loss item: 0.1673319786787033
test loss item: 0.20088325440883636
test loss item: 0.33287179470062256
test loss item: 0.14958986639976501
test loss item: 0.15235669910907745
test loss item: 0.11917900294065475
test loss item: 0.17352333664894104
test loss item: 0.16684050858020782
test loss item: 0.20281395316123962
test loss item: 0.12076814472675323
test loss item: 0.11703765392303467
test loss item: 0.20908759534358978
test loss item: 0.2333499789237976
test loss item: 0.1230529248714447
test loss item: 0.1407739818096161
test loss item: 0.12020409107208252
test loss item: 0.26270776987075806
test loss item: 0.13510505855083466
test loss item: 0.2119898647069931
test loss item: 0.20782150328159332
test loss item: 0.17220282554626465
test loss item: 0.11520545929670334
test loss item: 0.3323996961116791
test loss item: 0.12296420335769653
test loss item: 0.2553800344467163
test loss item: 0.3013341426849365
test loss item: 0.12131894379854202
test loss item: 0.08406568318605423
test loss item: 0.13791051506996155
Epoch [10/50], Training Loss: 0.2444, Testing Loss: 0.1733
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 11/50
train loss item: 0.34769773483276367
train loss item: 0.20171275734901428
train loss item: 0.1564682424068451
train loss item: 0.19840805232524872
train loss item: 0.1273791342973709
train loss item: 0.13708417117595673
train loss item: 0.21807728707790375
train loss item: 0.2900969088077545
train loss item: 0.09475115686655045
train loss item: 0.16952109336853027
train loss item: 0.11234766244888306
train loss item: 0.3464181423187256
train loss item: 0.1817818284034729
train loss item: 0.11960454285144806
train loss item: 0.2550179660320282
train loss item: 0.37402868270874023
train loss item: 0.15187543630599976
train loss item: 0.6274034976959229
train loss item: 0.2956579327583313
train loss item: 0.16168208420276642
train loss item: 0.13296447694301605
train loss item: 0.13964882493019104
train loss item: 0.2613951861858368
train loss item: 0.13610269129276276
train loss item: 0.13236218690872192
train loss item: 0.42029762268066406
train loss item: 0.10259725898504257
train loss item: 0.7007268071174622
train loss item: 0.1589992344379425
train loss item: 0.09366732835769653
train loss item: 0.48237335681915283
train loss item: 0.17213983833789825
train loss item: 0.16566234827041626
train loss item: 0.1739329993724823
train loss item: 0.22052253782749176
train loss item: 0.16613219678401947
train loss item: 0.1278107613325119
train loss item: 0.09001350402832031
train loss item: 0.4006875455379486
train loss item: 0.13072910904884338
train loss item: 0.11306418478488922
train loss item: 0.22763773798942566
train loss item: 0.23585082590579987
train loss item: 1.2788242101669312
train loss item: 0.17599846422672272
test loss item: 0.10521688312292099
test loss item: 0.185108944773674
test loss item: 0.12129636853933334
test loss item: 0.3506161868572235
test loss item: 0.15608912706375122
test loss item: 0.27378547191619873
test loss item: 0.12559038400650024
test loss item: 0.09766145050525665
test loss item: 0.1410522311925888
test loss item: 0.20951081812381744
test loss item: 0.18966472148895264
test loss item: 0.12382061034440994
test loss item: 0.11573658138513565
test loss item: 0.13817505538463593
test loss item: 0.15884438157081604
test loss item: 0.24553509056568146
test loss item: 0.18188677728176117
test loss item: 0.2278747856616974
test loss item: 0.36794108152389526
test loss item: 0.15795087814331055
test loss item: 0.13901735842227936
test loss item: 0.12472759932279587
test loss item: 0.17489910125732422
test loss item: 0.14287425577640533
test loss item: 0.23774109780788422
test loss item: 0.13535746932029724
test loss item: 0.12488117069005966
test loss item: 0.2668992578983307
test loss item: 0.23373477160930634
test loss item: 0.13315698504447937
test loss item: 0.15601523220539093
test loss item: 0.1274394392967224
test loss item: 0.27036377787590027
test loss item: 0.13389356434345245
test loss item: 0.2206151932477951
test loss item: 0.21516574919223785
test loss item: 0.15478338301181793
test loss item: 0.09789932519197464
test loss item: 0.34916990995407104
test loss item: 0.12373565882444382
test loss item: 0.2649439573287964
test loss item: 0.3389194905757904
test loss item: 0.11911504715681076
test loss item: 0.06824343651533127
test loss item: 0.15095524489879608
Epoch [11/50], Training Loss: 0.2446, Testing Loss: 0.1817
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 12/50
train loss item: 0.3332742154598236
train loss item: 0.24334947764873505
train loss item: 0.16457530856132507
train loss item: 0.25891146063804626
train loss item: 0.12135058641433716
train loss item: 0.13682743906974792
train loss item: 0.2114284187555313
train loss item: 0.25048938393592834
train loss item: 0.10459020733833313
train loss item: 0.1633760929107666
train loss item: 0.12144509702920914
train loss item: 0.46107935905456543
train loss item: 0.1915043592453003
train loss item: 0.1410498172044754
train loss item: 0.23830711841583252
train loss item: 0.626175045967102
train loss item: 0.1518000215291977
train loss item: 0.7906274199485779
train loss item: 0.5453334450721741
train loss item: 0.43716418743133545
train loss item: 0.3064177334308624
train loss item: 0.2606755793094635
train loss item: 0.3526947796344757
train loss item: 0.25995996594429016
train loss item: 0.13182790577411652
train loss item: 0.336385577917099
train loss item: 0.08853573352098465
train loss item: 0.6757394671440125
train loss item: 0.15719474852085114
train loss item: 0.10120724886655807
train loss item: 0.5871472358703613
train loss item: 0.18985623121261597
train loss item: 0.18398398160934448
train loss item: 0.19028879702091217
train loss item: 0.19711847603321075
train loss item: 0.1535181999206543
train loss item: 0.135325089097023
train loss item: 0.09683378785848618
train loss item: 0.38496726751327515
train loss item: 0.14007793366909027
train loss item: 0.10591001063585281
train loss item: 0.1822628676891327
train loss item: 0.2985135614871979
train loss item: 1.2272545099258423
train loss item: 0.20560504496097565
test loss item: 0.1086798906326294
test loss item: 0.22480562329292297
test loss item: 0.13455802202224731
test loss item: 0.3863317370414734
test loss item: 0.16983895003795624
test loss item: 0.32338303327560425
test loss item: 0.1266985535621643
test loss item: 0.10178497433662415
test loss item: 0.1634293496608734
test loss item: 0.20997068285942078
test loss item: 0.21669788658618927
test loss item: 0.13839557766914368
test loss item: 0.11750885844230652
test loss item: 0.1415783017873764
test loss item: 0.17281053960323334
test loss item: 0.27480071783065796
test loss item: 0.22162063419818878
test loss item: 0.2501993179321289
test loss item: 0.43695345520973206
test loss item: 0.17905429005622864
test loss item: 0.14243373274803162
test loss item: 0.14021968841552734
test loss item: 0.19539742171764374
test loss item: 0.140072301030159
test loss item: 0.25750523805618286
test loss item: 0.14758174121379852
test loss item: 0.13185147941112518
test loss item: 0.30532941222190857
test loss item: 0.25255918502807617
test loss item: 0.13616029918193817
test loss item: 0.17444247007369995
test loss item: 0.12390162795782089
test loss item: 0.30127254128456116
test loss item: 0.1395576298236847
test loss item: 0.23626741766929626
test loss item: 0.23166027665138245
test loss item: 0.1678166538476944
test loss item: 0.09767366200685501
test loss item: 0.4793970584869385
test loss item: 0.12389121204614639
test loss item: 0.3115977942943573
test loss item: 0.40678322315216064
test loss item: 0.1234147846698761
test loss item: 0.0638963058590889
test loss item: 0.13413462042808533
Epoch [12/50], Training Loss: 0.2809, Testing Loss: 0.2014
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 13/50
train loss item: 0.26499253511428833
train loss item: 0.20863762497901917
train loss item: 0.15868768095970154
train loss item: 0.19611142575740814
train loss item: 0.14536508917808533
train loss item: 0.1348436176776886
train loss item: 0.20306864380836487
train loss item: 0.24555659294128418
train loss item: 0.10076364129781723
train loss item: 0.16846030950546265
train loss item: 0.1264249086380005
train loss item: 0.39794713258743286
train loss item: 0.16402332484722137
train loss item: 0.13150086998939514
train loss item: 0.24600788950920105
train loss item: 0.35558417439460754
train loss item: 0.1711929589509964
train loss item: 0.5734730958938599
train loss item: 0.25230666995048523
train loss item: 0.15493059158325195
train loss item: 0.13718350231647491
train loss item: 0.18320171535015106
train loss item: 0.21732038259506226
train loss item: 0.13506945967674255
train loss item: 0.10531764477491379
train loss item: 0.3236692547798157
train loss item: 0.08049490302801132
train loss item: 0.4553273618221283
train loss item: 0.13270367681980133
train loss item: 0.08755192905664444
train loss item: 0.47668036818504333
train loss item: 0.16892382502555847
train loss item: 0.14500410854816437
train loss item: 0.15445642173290253
train loss item: 0.16114279627799988
train loss item: 0.13064877688884735
train loss item: 0.11943468451499939
train loss item: 0.09012256562709808
train loss item: 0.36054089665412903
train loss item: 0.12241599708795547
train loss item: 0.09432975947856903
train loss item: 0.17350155115127563
train loss item: 0.22890856862068176
train loss item: 1.146410584449768
train loss item: 0.18378198146820068
test loss item: 0.10039083659648895
test loss item: 0.184522345662117
test loss item: 0.11916891485452652
test loss item: 0.3240754008293152
test loss item: 0.15807035565376282
test loss item: 0.25349345803260803
test loss item: 0.13366341590881348
test loss item: 0.09175091236829758
test loss item: 0.1384328007698059
test loss item: 0.19971288740634918
test loss item: 0.18469421565532684
test loss item: 0.11411916464567184
test loss item: 0.10929567366838455
test loss item: 0.13185633718967438
test loss item: 0.15446940064430237
test loss item: 0.22228750586509705
test loss item: 0.17851446568965912
test loss item: 0.2296726107597351
test loss item: 0.34356021881103516
test loss item: 0.15364237129688263
test loss item: 0.13692732155323029
test loss item: 0.1264960616827011
test loss item: 0.16492363810539246
test loss item: 0.13417525589466095
test loss item: 0.22156035900115967
test loss item: 0.14154544472694397
test loss item: 0.12677349150180817
test loss item: 0.24393579363822937
test loss item: 0.22157856822013855
test loss item: 0.1351521909236908
test loss item: 0.154946967959404
test loss item: 0.12319448590278625
test loss item: 0.26230284571647644
test loss item: 0.12683112919330597
test loss item: 0.21396617591381073
test loss item: 0.20193585753440857
test loss item: 0.14292897284030914
test loss item: 0.09215987473726273
test loss item: 0.33057644963264465
test loss item: 0.11920211464166641
test loss item: 0.25064802169799805
test loss item: 0.31907376646995544
test loss item: 0.11821632087230682
test loss item: 0.06152801215648651
test loss item: 0.16791225969791412
Epoch [13/50], Training Loss: 0.2225, Testing Loss: 0.1748
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 14/50
train loss item: 0.28487154841423035
train loss item: 0.25127461552619934
train loss item: 0.170387402176857
train loss item: 0.18405179679393768
train loss item: 0.1437181979417801
train loss item: 0.14385324716567993
train loss item: 0.22963713109493256
train loss item: 0.2233196496963501
train loss item: 0.09837047010660172
train loss item: 0.15628105401992798
train loss item: 0.1265106350183487
train loss item: 0.42934978008270264
train loss item: 0.22764350473880768
train loss item: 0.12502440810203552
train loss item: 0.23839567601680756
train loss item: 0.2932150959968567
train loss item: 0.12149582803249359
train loss item: 0.5299999713897705
train loss item: 0.33285248279571533
train loss item: 0.1708124727010727
train loss item: 0.18715104460716248
train loss item: 0.13877110183238983
train loss item: 0.24232643842697144
train loss item: 0.13282345235347748
train loss item: 0.11212765425443649
train loss item: 0.27495574951171875
train loss item: 0.08907103538513184
train loss item: 0.39468222856521606
train loss item: 0.14035546779632568
train loss item: 0.08844342827796936
train loss item: 0.38698452711105347
train loss item: 0.14649590849876404
train loss item: 0.16279245913028717
train loss item: 0.15672659873962402
train loss item: 0.15673699975013733
train loss item: 0.12401065230369568
train loss item: 0.1241181418299675
train loss item: 0.0837625041604042
train loss item: 0.3039458394050598
train loss item: 0.13580681383609772
train loss item: 0.09703473001718521
train loss item: 0.17428316175937653
train loss item: 0.1987435668706894
train loss item: 1.086207628250122
train loss item: 0.1865399032831192
test loss item: 0.09888739138841629
test loss item: 0.1586453914642334
test loss item: 0.10897069424390793
test loss item: 0.3175095319747925
test loss item: 0.12625737488269806
test loss item: 0.21331734955310822
test loss item: 0.11716631054878235
test loss item: 0.08226065337657928
test loss item: 0.1277536153793335
test loss item: 0.17689479887485504
test loss item: 0.17037397623062134
test loss item: 0.130719855427742
test loss item: 0.10901941359043121
test loss item: 0.11445822566747665
test loss item: 0.13311684131622314
test loss item: 0.189091295003891
test loss item: 0.14661292731761932
test loss item: 0.16933134198188782
test loss item: 0.29244932532310486
test loss item: 0.1380755454301834
test loss item: 0.14129388332366943
test loss item: 0.11051248013973236
test loss item: 0.1572355180978775
test loss item: 0.14079806208610535
test loss item: 0.18181529641151428
test loss item: 0.11056975275278091
test loss item: 0.11283807456493378
test loss item: 0.18627244234085083
test loss item: 0.19287355244159698
test loss item: 0.12006669491529465
test loss item: 0.12731683254241943
test loss item: 0.12361092120409012
test loss item: 0.22468920052051544
test loss item: 0.12647834420204163
test loss item: 0.1797979474067688
test loss item: 0.20015451312065125
test loss item: 0.1737043857574463
test loss item: 0.09815992414951324
test loss item: 0.29059961438179016
test loss item: 0.11832495778799057
test loss item: 0.22696326673030853
test loss item: 0.2633252441883087
test loss item: 0.11431024223566055
test loss item: 0.054100316017866135
test loss item: 0.15235130488872528
Epoch [14/50], Training Loss: 0.2179, Testing Loss: 0.1566
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 15/50
train loss item: 0.2697738707065582
train loss item: 0.3398718237876892
train loss item: 0.14116239547729492
train loss item: 0.2147514671087265
train loss item: 0.15270933508872986
train loss item: 0.16241219639778137
train loss item: 0.2631114721298218
train loss item: 0.26311758160591125
train loss item: 0.09711399674415588
train loss item: 0.14634765684604645
train loss item: 0.0972418561577797
train loss item: 0.4613339900970459
train loss item: 0.17427915334701538
train loss item: 0.11666421592235565
train loss item: 0.23835110664367676
train loss item: 0.46034958958625793
train loss item: 0.16536444425582886
train loss item: 0.6886532306671143
train loss item: 0.3690815567970276
train loss item: 0.2526901364326477
train loss item: 0.21800853312015533
train loss item: 0.21066665649414062
train loss item: 0.2811274826526642
train loss item: 0.16991659998893738
train loss item: 0.11342322826385498
train loss item: 0.27753040194511414
train loss item: 0.09737018495798111
train loss item: 0.5697122812271118
train loss item: 0.14713600277900696
train loss item: 0.09650927037000656
train loss item: 0.584470272064209
train loss item: 0.1670522391796112
train loss item: 0.17116403579711914
train loss item: 0.1714138388633728
train loss item: 0.16913343966007233
train loss item: 0.13480521738529205
train loss item: 0.12362292408943176
train loss item: 0.08146250993013382
train loss item: 0.34678205847740173
train loss item: 0.13319829106330872
train loss item: 0.0929294005036354
train loss item: 0.181867316365242
train loss item: 0.22803863883018494
train loss item: 1.128334403038025
train loss item: 0.2006843239068985
test loss item: 0.10122977942228317
test loss item: 0.19623970985412598
test loss item: 0.12324711680412292
test loss item: 0.4583570063114166
test loss item: 0.1439688801765442
test loss item: 0.2990528345108032
test loss item: 0.11741563677787781
test loss item: 0.08996453881263733
test loss item: 0.1514711081981659
test loss item: 0.20193490386009216
test loss item: 0.20118296146392822
test loss item: 0.11559724807739258
test loss item: 0.11392378062009811
test loss item: 0.12839801609516144
test loss item: 0.1488887518644333
test loss item: 0.28471457958221436
test loss item: 0.1827985793352127
test loss item: 0.19966059923171997
test loss item: 0.41236820816993713
test loss item: 0.16254687309265137
test loss item: 0.15010526776313782
test loss item: 0.13726401329040527
test loss item: 0.16926230490207672
test loss item: 0.12650279700756073
test loss item: 0.22367163002490997
test loss item: 0.12342306971549988
test loss item: 0.13788336515426636
test loss item: 0.2552436590194702
test loss item: 0.23877203464508057
test loss item: 0.12801875174045563
test loss item: 0.1476232409477234
test loss item: 0.12278493493795395
test loss item: 0.2980060279369354
test loss item: 0.13285808265209198
test loss item: 0.21023152768611908
test loss item: 0.278943806886673
test loss item: 0.16421014070510864
test loss item: 0.10155853629112244
test loss item: 0.47776272892951965
test loss item: 0.12694339454174042
test loss item: 0.31350812315940857
test loss item: 0.39317774772644043
test loss item: 0.12706327438354492
test loss item: 0.059034693986177444
test loss item: 0.1573101133108139
Epoch [15/50], Training Loss: 0.2482, Testing Loss: 0.1919
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 16/50
train loss item: 0.2731782793998718
train loss item: 0.20292611420154572
train loss item: 0.14658625423908234
train loss item: 0.26799914240837097
train loss item: 0.1222694143652916
train loss item: 0.13493572175502777
train loss item: 0.20369650423526764
train loss item: 0.25086453557014465
train loss item: 0.0827488899230957
train loss item: 0.14588508009910583
train loss item: 0.09708511084318161
train loss item: 0.4641195237636566
train loss item: 0.16053998470306396
train loss item: 0.12926769256591797
train loss item: 0.19813068211078644
train loss item: 0.35967323184013367
train loss item: 0.11994921416044235
train loss item: 0.5132817625999451
train loss item: 0.3744561970233917
train loss item: 0.2550738751888275
train loss item: 0.15503354370594025
train loss item: 0.1606856733560562
train loss item: 0.23993515968322754
train loss item: 0.12319745868444443
train loss item: 0.09995678812265396
train loss item: 0.27808472514152527
train loss item: 0.07896610349416733
train loss item: 0.39210188388824463
train loss item: 0.12568628787994385
train loss item: 0.08084794878959656
train loss item: 0.38929834961891174
train loss item: 0.14493919909000397
train loss item: 0.13539671897888184
train loss item: 0.15781128406524658
train loss item: 0.16927102208137512
train loss item: 0.13522480428218842
train loss item: 0.11370169371366501
train loss item: 0.07825552672147751
train loss item: 0.3218105435371399
train loss item: 0.11434408277273178
train loss item: 0.08973988890647888
train loss item: 0.16564178466796875
train loss item: 0.208051860332489
train loss item: 1.0349425077438354
train loss item: 0.18327632546424866
test loss item: 0.09924588352441788
test loss item: 0.18479005992412567
test loss item: 0.1062895655632019
test loss item: 0.3470754623413086
test loss item: 0.13901112973690033
test loss item: 0.25125616788864136
test loss item: 0.11837856471538544
test loss item: 0.08205531537532806
test loss item: 0.14198696613311768
test loss item: 0.17950110137462616
test loss item: 0.179574117064476
test loss item: 0.12382594496011734
test loss item: 0.1132097989320755
test loss item: 0.11489872634410858
test loss item: 0.13639695942401886
test loss item: 0.22179998457431793
test loss item: 0.16722194850444794
test loss item: 0.180143803358078
test loss item: 0.33584821224212646
test loss item: 0.14687788486480713
test loss item: 0.15160967409610748
test loss item: 0.1278829127550125
test loss item: 0.15623727440834045
test loss item: 0.13982535898685455
test loss item: 0.20045605301856995
test loss item: 0.11905430257320404
test loss item: 0.12679533660411835
test loss item: 0.2223232090473175
test loss item: 0.20360414683818817
test loss item: 0.12406466901302338
test loss item: 0.13480272889137268
test loss item: 0.12309180945158005
test loss item: 0.24696913361549377
test loss item: 0.12292841821908951
test loss item: 0.19239473342895508
test loss item: 0.21503698825836182
test loss item: 0.15379513800144196
test loss item: 0.10692767798900604
test loss item: 0.36438819766044617
test loss item: 0.11784891039133072
test loss item: 0.25497105717658997
test loss item: 0.3100329637527466
test loss item: 0.12416919320821762
test loss item: 0.0594199076294899
test loss item: 0.18012358248233795
Epoch [16/50], Training Loss: 0.2151, Testing Loss: 0.1700
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 17/50
train loss item: 0.26907092332839966
train loss item: 0.20000019669532776
train loss item: 0.1351778209209442
train loss item: 0.1833457052707672
train loss item: 0.13041570782661438
train loss item: 0.1401609182357788
train loss item: 0.23291373252868652
train loss item: 0.24996274709701538
train loss item: 0.08412501960992813
train loss item: 0.15598268806934357
train loss item: 0.1037529781460762
train loss item: 0.4367082715034485
train loss item: 0.18270529806613922
train loss item: 0.13078755140304565
train loss item: 0.205978661775589
train loss item: 0.30492347478866577
train loss item: 0.11542711406946182
train loss item: 0.4479755163192749
train loss item: 0.29098841547966003
train loss item: 0.18300475180149078
train loss item: 0.14378131926059723
train loss item: 0.15464435517787933
train loss item: 0.22439426183700562
train loss item: 0.12693904340267181
train loss item: 0.102988600730896
train loss item: 0.2524929642677307
train loss item: 0.07728447765111923
train loss item: 0.32090678811073303
train loss item: 0.1222073882818222
train loss item: 0.07871880382299423
train loss item: 0.3414289355278015
train loss item: 0.14344705641269684
train loss item: 0.1322719305753708
train loss item: 0.15769444406032562
train loss item: 0.15551282465457916
train loss item: 0.11936262249946594
train loss item: 0.10898710787296295
train loss item: 0.07576538622379303
train loss item: 0.30527639389038086
train loss item: 0.11675291508436203
train loss item: 0.08336640149354935
train loss item: 0.15138402581214905
train loss item: 0.1710255742073059
train loss item: 0.9745721817016602
train loss item: 0.18362487852573395
test loss item: 0.09718059748411179
test loss item: 0.1646428257226944
test loss item: 0.10378462821245193
test loss item: 0.3001568615436554
test loss item: 0.1233750730752945
test loss item: 0.2263060212135315
test loss item: 0.10518841445446014
test loss item: 0.07920722663402557
test loss item: 0.12784862518310547
test loss item: 0.15639910101890564
test loss item: 0.16385765373706818
test loss item: 0.116303950548172
test loss item: 0.10903488099575043
test loss item: 0.10784786194562912
test loss item: 0.12497810274362564
test loss item: 0.19771161675453186
test loss item: 0.15304727852344513
test loss item: 0.16225537657737732
test loss item: 0.3030632734298706
test loss item: 0.1354757845401764
test loss item: 0.13806937634944916
test loss item: 0.11420614272356033
test loss item: 0.14130491018295288
test loss item: 0.12810379266738892
test loss item: 0.18026559054851532
test loss item: 0.10623745620250702
test loss item: 0.11599043756723404
test loss item: 0.19748590886592865
test loss item: 0.1856258064508438
test loss item: 0.11508884280920029
test loss item: 0.12385718524456024
test loss item: 0.11477722227573395
test loss item: 0.21864718198776245
test loss item: 0.11449183523654938
test loss item: 0.17243538796901703
test loss item: 0.18243232369422913
test loss item: 0.14375756680965424
test loss item: 0.09493305534124374
test loss item: 0.34643349051475525
test loss item: 0.10961680114269257
test loss item: 0.22795531153678894
test loss item: 0.2777901291847229
test loss item: 0.11350660026073456
test loss item: 0.059102244675159454
test loss item: 0.15377214550971985
Epoch [17/50], Training Loss: 0.2002, Testing Loss: 0.1541
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 18/50
train loss item: 0.24691012501716614
train loss item: 0.21433664858341217
train loss item: 0.15126647055149078
train loss item: 0.16250991821289062
train loss item: 0.11768773943185806
train loss item: 0.13333362340927124
train loss item: 0.2126692533493042
train loss item: 0.20404382050037384
train loss item: 0.07892615348100662
train loss item: 0.1365014612674713
train loss item: 0.10181239247322083
train loss item: 0.2869105637073517
train loss item: 0.15294845402240753
train loss item: 0.12908142805099487
train loss item: 0.19248339533805847
train loss item: 0.3440585732460022
train loss item: 0.12451827526092529
train loss item: 0.37083718180656433
train loss item: 0.2555425465106964
train loss item: 0.14615195989608765
train loss item: 0.10578825324773788
train loss item: 0.1366652548313141
train loss item: 0.18966630101203918
train loss item: 0.11052272468805313
train loss item: 0.09822707623243332
train loss item: 0.24638211727142334
train loss item: 0.08345644921064377
train loss item: 0.3645167648792267
train loss item: 0.1197177916765213
train loss item: 0.07870810478925705
train loss item: 0.33080488443374634
train loss item: 0.1708303987979889
train loss item: 0.13881640136241913
train loss item: 0.13935348391532898
train loss item: 0.16077356040477753
train loss item: 0.11424939334392548
train loss item: 0.10940027236938477
train loss item: 0.0715406984090805
train loss item: 0.33834072947502136
train loss item: 0.11190211027860641
train loss item: 0.0846504420042038
train loss item: 0.15985749661922455
train loss item: 0.1968575417995453
train loss item: 0.9374801516532898
train loss item: 0.19409435987472534
test loss item: 0.0983046442270279
test loss item: 0.16984814405441284
test loss item: 0.10399430990219116
test loss item: 0.2778889834880829
test loss item: 0.1198369488120079
test loss item: 0.2515384256839752
test loss item: 0.10469667613506317
test loss item: 0.07785308361053467
test loss item: 0.13256534934043884
test loss item: 0.15988416969776154
test loss item: 0.1616138368844986
test loss item: 0.13701754808425903
test loss item: 0.11077018827199936
test loss item: 0.10978356003761292
test loss item: 0.12532489001750946
test loss item: 0.2147480696439743
test loss item: 0.15485882759094238
test loss item: 0.16488923132419586
test loss item: 0.32911819219589233
test loss item: 0.13029932975769043
test loss item: 0.1449715942144394
test loss item: 0.11984913796186447
test loss item: 0.1476726084947586
test loss item: 0.15203148126602173
test loss item: 0.18934054672718048
test loss item: 0.10371127724647522
test loss item: 0.12000811845064163
test loss item: 0.214092418551445
test loss item: 0.1885138303041458
test loss item: 0.11255133897066116
test loss item: 0.12360185384750366
test loss item: 0.11800412088632584
test loss item: 0.2293540984392166
test loss item: 0.11459723114967346
test loss item: 0.171552836894989
test loss item: 0.16546228528022766
test loss item: 0.16255465149879456
test loss item: 0.11440953612327576
test loss item: 0.3985273838043213
test loss item: 0.1224822998046875
test loss item: 0.2407664805650711
test loss item: 0.30651044845581055
test loss item: 0.1226542741060257
test loss item: 0.05471508949995041
test loss item: 0.14403608441352844
Epoch [18/50], Training Loss: 0.1901, Testing Loss: 0.1604
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 19/50
train loss item: 0.2504764497280121
train loss item: 0.2275203913450241
train loss item: 0.16612285375595093
train loss item: 0.25135961174964905
train loss item: 0.11783735454082489
train loss item: 0.1312618851661682
train loss item: 0.24459609389305115
train loss item: 0.19231897592544556
train loss item: 0.07918725907802582
train loss item: 0.15374794602394104
train loss item: 0.0936635211110115
train loss item: 0.4912932217121124
train loss item: 0.17794179916381836
train loss item: 0.16223198175430298
train loss item: 0.2553372383117676
train loss item: 0.46198323369026184
train loss item: 0.15497449040412903
train loss item: 0.43477165699005127
train loss item: 0.40120553970336914
train loss item: 0.251583993434906
train loss item: 0.2264673113822937
train loss item: 0.2355828732252121
train loss item: 0.3515346050262451
train loss item: 0.27374863624572754
train loss item: 0.12013357132673264
train loss item: 0.34604278206825256
train loss item: 0.07770496606826782
train loss item: 0.2958581745624542
train loss item: 0.13256677985191345
train loss item: 0.08414667844772339
train loss item: 0.41254308819770813
train loss item: 0.17081527411937714
train loss item: 0.17363391816616058
train loss item: 0.207070991396904
train loss item: 0.15663518011569977
train loss item: 0.12917232513427734
train loss item: 0.11376456171274185
train loss item: 0.07719982415437698
train loss item: 0.36562108993530273
train loss item: 0.12532258033752441
train loss item: 0.08289439231157303
train loss item: 0.15840017795562744
train loss item: 0.1996869593858719
train loss item: 0.8952816128730774
train loss item: 0.23258553445339203
test loss item: 0.10623671859502792
test loss item: 0.18541721999645233
test loss item: 0.10908940434455872
test loss item: 0.25501754879951477
test loss item: 0.11977408081293106
test loss item: 0.2422720044851303
test loss item: 0.11715475469827652
test loss item: 0.07647926360368729
test loss item: 0.15135528147220612
test loss item: 0.16563208401203156
test loss item: 0.168345108628273
test loss item: 0.1461070030927658
test loss item: 0.11890589445829391
test loss item: 0.1158505454659462
test loss item: 0.12661461532115936
test loss item: 0.20038774609565735
test loss item: 0.161894753575325
test loss item: 0.16345927119255066
test loss item: 0.32135894894599915
test loss item: 0.13472600281238556
test loss item: 0.16327571868896484
test loss item: 0.13923785090446472
test loss item: 0.15511265397071838
test loss item: 0.17757554352283478
test loss item: 0.17803898453712463
test loss item: 0.11304804682731628
test loss item: 0.13655251264572144
test loss item: 0.20635394752025604
test loss item: 0.1855136603116989
test loss item: 0.11787160485982895
test loss item: 0.12004729360342026
test loss item: 0.12532542645931244
test loss item: 0.22838212549686432
test loss item: 0.12350831180810928
test loss item: 0.1753009557723999
test loss item: 0.15455329418182373
test loss item: 0.1666526347398758
test loss item: 0.1409415602684021
test loss item: 0.40322113037109375
test loss item: 0.1337192952632904
test loss item: 0.23560132086277008
test loss item: 0.30004918575286865
test loss item: 0.14051301777362823
test loss item: 0.05281960591673851
test loss item: 0.1446608453989029
Epoch [19/50], Training Loss: 0.2299, Testing Loss: 0.1645
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 20/50
train loss item: 0.21889598667621613
train loss item: 0.17926602065563202
train loss item: 0.14891284704208374
train loss item: 0.14986951649188995
train loss item: 0.10754608362913132
train loss item: 0.1191602274775505
train loss item: 0.1735827773809433
train loss item: 0.19713722169399261
train loss item: 0.07480666041374207
train loss item: 0.12594754993915558
train loss item: 0.09129863232374191
train loss item: 0.25732189416885376
train loss item: 0.14381738007068634
train loss item: 0.12793225049972534
train loss item: 0.26099562644958496
train loss item: 0.28261104226112366
train loss item: 0.15697844326496124
train loss item: 0.37362006306648254
train loss item: 0.18517686426639557
train loss item: 0.15253128111362457
train loss item: 0.10898460447788239
train loss item: 0.1642119586467743
train loss item: 0.18666301667690277
train loss item: 0.13291603326797485
train loss item: 0.1140417829155922
train loss item: 0.2758147716522217
train loss item: 0.0964059978723526
train loss item: 0.3347527086734772
train loss item: 0.12414424866437912
train loss item: 0.08667069673538208
train loss item: 0.3260626792907715
train loss item: 0.22226636111736298
train loss item: 0.15421660244464874
train loss item: 0.14117994904518127
train loss item: 0.15221664309501648
train loss item: 0.11376874148845673
train loss item: 0.12443841248750687
train loss item: 0.07240749895572662
train loss item: 0.45005354285240173
train loss item: 0.14238421618938446
train loss item: 0.10602325201034546
train loss item: 0.2340765744447708
train loss item: 0.23669496178627014
train loss item: 0.8640600442886353
train loss item: 0.1563502550125122
test loss item: 0.0924675241112709
test loss item: 0.18678808212280273
test loss item: 0.10814981162548065
test loss item: 0.2768065333366394
test loss item: 0.1263844072818756
test loss item: 0.30441412329673767
test loss item: 0.10119763761758804
test loss item: 0.08055879920721054
test loss item: 0.13384924829006195
test loss item: 0.1665218472480774
test loss item: 0.16373157501220703
test loss item: 0.11490782350301743
test loss item: 0.10621045529842377
test loss item: 0.11162620782852173
test loss item: 0.1288178712129593
test loss item: 0.25299182534217834
test loss item: 0.161525696516037
test loss item: 0.17655695974826813
test loss item: 0.39287468791007996
test loss item: 0.1329815536737442
test loss item: 0.13211415708065033
test loss item: 0.12206139415502548
test loss item: 0.14358098804950714
test loss item: 0.12798532843589783
test loss item: 0.20342031121253967
test loss item: 0.10162394493818283
test loss item: 0.121208555996418
test loss item: 0.2566053569316864
test loss item: 0.2006833851337433
test loss item: 0.11121682077646255
test loss item: 0.12559334933757782
test loss item: 0.11162291467189789
test loss item: 0.28278571367263794
test loss item: 0.11460787057876587
test loss item: 0.19021648168563843
test loss item: 0.16334006190299988
test loss item: 0.14717425405979156
test loss item: 0.09841377288103104
test loss item: 0.5217377543449402
test loss item: 0.11348753422498703
test loss item: 0.28824716806411743
test loss item: 0.38161787390708923
test loss item: 0.1208215206861496
test loss item: 0.04986372962594032
test loss item: 0.15483969449996948
Epoch [20/50], Training Loss: 0.1922, Testing Loss: 0.1712
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 21/50
train loss item: 0.212754487991333
train loss item: 0.24642090499401093
train loss item: 0.1603606641292572
train loss item: 0.28166669607162476
train loss item: 0.12861189246177673
train loss item: 0.1447068750858307
train loss item: 0.20538018643856049
train loss item: 0.21606822311878204
train loss item: 0.07766866683959961
train loss item: 0.14190229773521423
train loss item: 0.09829883277416229
train loss item: 0.38689690828323364
train loss item: 0.19695807993412018
train loss item: 0.16480188071727753
train loss item: 0.30312007665634155
train loss item: 0.3547267019748688
train loss item: 0.1779419183731079
train loss item: 0.38564953207969666
train loss item: 0.26272052526474
train loss item: 0.15883034467697144
train loss item: 0.12539726495742798
train loss item: 0.14073814451694489
train loss item: 0.21283911168575287
train loss item: 0.15750890970230103
train loss item: 0.09718181937932968
train loss item: 0.3903813660144806
train loss item: 0.07690610736608505
train loss item: 0.22889737784862518
train loss item: 0.1235993504524231
train loss item: 0.07367370277643204
train loss item: 0.2812426686286926
train loss item: 0.14081956446170807
train loss item: 0.1332404464483261
train loss item: 0.15080626308918
train loss item: 0.15012210607528687
train loss item: 0.10817116498947144
train loss item: 0.10563217103481293
train loss item: 0.06935140490531921
train loss item: 0.30977320671081543
train loss item: 0.11298341304063797
train loss item: 0.08772692829370499
train loss item: 0.17449577152729034
train loss item: 0.19181205332279205
train loss item: 0.865289568901062
train loss item: 0.18623220920562744
test loss item: 0.09480814635753632
test loss item: 0.20355968177318573
test loss item: 0.10621288418769836
test loss item: 0.2813132703304291
test loss item: 0.11936261504888535
test loss item: 0.32006925344467163
test loss item: 0.10349316895008087
test loss item: 0.07649736106395721
test loss item: 0.13551494479179382
test loss item: 0.15707437694072723
test loss item: 0.16204383969306946
test loss item: 0.1254100352525711
test loss item: 0.11458927392959595
test loss item: 0.10497505962848663
test loss item: 0.12069818377494812
test loss item: 0.26550301909446716
test loss item: 0.16643261909484863
test loss item: 0.16284476220607758
test loss item: 0.4226647615432739
test loss item: 0.1357552856206894
test loss item: 0.14073503017425537
test loss item: 0.12495932728052139
test loss item: 0.14237965643405914
test loss item: 0.14149190485477448
test loss item: 0.2046392858028412
test loss item: 0.10178608447313309
test loss item: 0.12378774583339691
test loss item: 0.2683045566082001
test loss item: 0.20733915269374847
test loss item: 0.11022820323705673
test loss item: 0.1142927035689354
test loss item: 0.11472918838262558
test loss item: 0.3144013583660126
test loss item: 0.11519619822502136
test loss item: 0.192239448428154
test loss item: 0.16268382966518402
test loss item: 0.15053026378154755
test loss item: 0.11251802742481232
test loss item: 0.6087825894355774
test loss item: 0.11859481781721115
test loss item: 0.3143083155155182
test loss item: 0.4145659804344177
test loss item: 0.12545034289360046
test loss item: 0.05201449990272522
test loss item: 0.15687759220600128
Epoch [21/50], Training Loss: 0.2000, Testing Loss: 0.1780
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 22/50
train loss item: 0.19091662764549255
train loss item: 0.19766777753829956
train loss item: 0.14822231233119965
train loss item: 0.15255160629749298
train loss item: 0.10979600995779037
train loss item: 0.13183152675628662
train loss item: 0.16347166895866394
train loss item: 0.14310495555400848
train loss item: 0.07167823612689972
train loss item: 0.12735067307949066
train loss item: 0.08847935497760773
train loss item: 0.47559717297554016
train loss item: 0.1376599818468094
train loss item: 0.1613895744085312
train loss item: 0.3228116035461426
train loss item: 0.2817881405353546
train loss item: 0.24023474752902985
train loss item: 0.49889901280403137
train loss item: 0.18764087557792664
train loss item: 0.20751726627349854
train loss item: 0.15201126039028168
train loss item: 0.12931254506111145
train loss item: 0.2062380611896515
train loss item: 0.11489593982696533
train loss item: 0.09626846760511398
train loss item: 0.2988746762275696
train loss item: 0.09624660015106201
train loss item: 0.29426494240760803
train loss item: 0.1470254361629486
train loss item: 0.09632501006126404
train loss item: 0.30009064078330994
train loss item: 0.20244859158992767
train loss item: 0.16461153328418732
train loss item: 0.17891831696033478
train loss item: 0.1740007996559143
train loss item: 0.10762125998735428
train loss item: 0.11072371155023575
train loss item: 0.0729568675160408
train loss item: 0.44268280267715454
train loss item: 0.13816127181053162
train loss item: 0.10739626735448837
train loss item: 0.26552337408065796
train loss item: 0.2607146203517914
train loss item: 0.8734986782073975
train loss item: 0.1504589468240738
test loss item: 0.09847737103700638
test loss item: 0.23796404898166656
test loss item: 0.11383321136236191
test loss item: 0.4120514392852783
test loss item: 0.1566106230020523
test loss item: 0.4227573573589325
test loss item: 0.10423503816127777
test loss item: 0.07981808483600616
test loss item: 0.16189414262771606
test loss item: 0.21007013320922852
test loss item: 0.20122915506362915
test loss item: 0.12048818171024323
test loss item: 0.12088882923126221
test loss item: 0.12561866641044617
test loss item: 0.14251311123371124
test loss item: 0.3618718981742859
test loss item: 0.20134593546390533
test loss item: 0.21444518864154816
test loss item: 0.5412164330482483
test loss item: 0.1624390333890915
test loss item: 0.1460341215133667
test loss item: 0.1498134583234787
test loss item: 0.17479927837848663
test loss item: 0.12792380154132843
test loss item: 0.2799364924430847
test loss item: 0.11354224383831024
test loss item: 0.13774633407592773
test loss item: 0.3512808084487915
test loss item: 0.26115819811820984
test loss item: 0.11500323563814163
test loss item: 0.15545690059661865
test loss item: 0.1208348199725151
test loss item: 0.3797176480293274
test loss item: 0.13340087234973907
test loss item: 0.23357431590557098
test loss item: 0.24932390451431274
test loss item: 0.1701284795999527
test loss item: 0.10778679698705673
test loss item: 0.705737829208374
test loss item: 0.12325042486190796
test loss item: 0.41716766357421875
test loss item: 0.5351740717887878
test loss item: 0.13359078764915466
test loss item: 0.05965156480669975
test loss item: 0.17603331804275513
Epoch [22/50], Training Loss: 0.2049, Testing Loss: 0.2166
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 23/50
train loss item: 0.2197376787662506
train loss item: 0.17884235084056854
train loss item: 0.13277669250965118
train loss item: 0.19885309040546417
train loss item: 0.1022365614771843
train loss item: 0.14452631771564484
train loss item: 0.16397981345653534
train loss item: 0.27701425552368164
train loss item: 0.07775558531284332
train loss item: 0.1459140032529831
train loss item: 0.09737521409988403
train loss item: 0.4399387836456299
train loss item: 0.13767674565315247
train loss item: 0.1634557992219925
train loss item: 0.2729649841785431
train loss item: 0.2962760925292969
train loss item: 0.23697537183761597
train loss item: 0.3679834306240082
train loss item: 0.17459559440612793
train loss item: 0.21280719339847565
train loss item: 0.18395861983299255
train loss item: 0.1325160712003708
train loss item: 0.2925977408885956
train loss item: 0.12458927929401398
train loss item: 0.10122980177402496
train loss item: 0.2476237416267395
train loss item: 0.07912161946296692
train loss item: 0.3396128714084625
train loss item: 0.1373862624168396
train loss item: 0.08853000402450562
train loss item: 0.3270110487937927
train loss item: 0.19654878973960876
train loss item: 0.1912958025932312
train loss item: 0.2860443592071533
train loss item: 0.21960769593715668
train loss item: 0.1550350934267044
train loss item: 0.12102632969617844
train loss item: 0.07755097001791
train loss item: 0.3173859119415283
train loss item: 0.11048715561628342
train loss item: 0.10064348578453064
train loss item: 0.18646812438964844
train loss item: 0.20225723087787628
train loss item: 0.8253968358039856
train loss item: 0.14332792162895203
test loss item: 0.09271803498268127
test loss item: 0.21925140917301178
test loss item: 0.11763453483581543
test loss item: 0.3959766626358032
test loss item: 0.16857066750526428
test loss item: 0.3702802360057831
test loss item: 0.11443964391946793
test loss item: 0.08431325852870941
test loss item: 0.14934566617012024
test loss item: 0.2054683119058609
test loss item: 0.19679395854473114
test loss item: 0.11497895419597626
test loss item: 0.11233408004045486
test loss item: 0.1311877816915512
test loss item: 0.15532636642456055
test loss item: 0.32695701718330383
test loss item: 0.19393952190876007
test loss item: 0.21632497012615204
test loss item: 0.47619232535362244
test loss item: 0.16304205358028412
test loss item: 0.13582351803779602
test loss item: 0.13434860110282898
test loss item: 0.18167032301425934
test loss item: 0.12200550734996796
test loss item: 0.2726649343967438
test loss item: 0.13448907434940338
test loss item: 0.12485998868942261
test loss item: 0.3288569450378418
test loss item: 0.24007120728492737
test loss item: 0.12353279441595078
test loss item: 0.16864705085754395
test loss item: 0.11812902987003326
test loss item: 0.3348398208618164
test loss item: 0.13300326466560364
test loss item: 0.22292254865169525
test loss item: 0.24662770330905914
test loss item: 0.1626943200826645
test loss item: 0.08772067725658417
test loss item: 0.5745207667350769
test loss item: 0.11509449779987335
test loss item: 0.360385000705719
test loss item: 0.46485665440559387
test loss item: 0.12165823578834534
test loss item: 0.05261144042015076
test loss item: 0.17956028878688812
Epoch [23/50], Training Loss: 0.2051, Testing Loss: 0.2033
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 24/50
train loss item: 0.20076268911361694
train loss item: 0.18954506516456604
train loss item: 0.12408680468797684
train loss item: 0.14659489691257477
train loss item: 0.10208690166473389
train loss item: 0.13209225237369537
train loss item: 0.1409347951412201
train loss item: 0.2873777449131012
train loss item: 0.07194061577320099
train loss item: 0.17284360527992249
train loss item: 0.09339248389005661
train loss item: 0.4868180751800537
train loss item: 0.1540176123380661
train loss item: 0.15035466849803925
train loss item: 0.2502188980579376
train loss item: 0.42420512437820435
train loss item: 0.2028479278087616
train loss item: 0.2877451181411743
train loss item: 0.17435726523399353
train loss item: 0.22805747389793396
train loss item: 0.17461413145065308
train loss item: 0.1469831019639969
train loss item: 0.3084060847759247
train loss item: 0.1413707286119461
train loss item: 0.11471042037010193
train loss item: 0.28401613235473633
train loss item: 0.08483223617076874
train loss item: 0.36882850527763367
train loss item: 0.11264495551586151
train loss item: 0.07600734382867813
train loss item: 0.3464418351650238
train loss item: 0.17835912108421326
train loss item: 0.18181069195270538
train loss item: 0.3113771378993988
train loss item: 0.22614005208015442
train loss item: 0.15955014526844025
train loss item: 0.14173424243927002
train loss item: 0.09260321408510208
train loss item: 0.35546383261680603
train loss item: 0.11885193735361099
train loss item: 0.09514525532722473
train loss item: 0.16112248599529266
train loss item: 0.1917751580476761
train loss item: 0.7949573397636414
train loss item: 0.15227048099040985
test loss item: 0.09185495227575302
test loss item: 0.16040940582752228
test loss item: 0.11360224336385727
test loss item: 0.2903766930103302
test loss item: 0.14211128652095795
test loss item: 0.2178514152765274
test loss item: 0.10875529795885086
test loss item: 0.08735731989145279
test loss item: 0.13369236886501312
test loss item: 0.17752423882484436
test loss item: 0.17778678238391876
test loss item: 0.12040738016366959
test loss item: 0.10030689090490341
test loss item: 0.12392804771661758
test loss item: 0.14625363051891327
test loss item: 0.2006201148033142
test loss item: 0.15631026029586792
test loss item: 0.18502746522426605
test loss item: 0.2843426764011383
test loss item: 0.14263060688972473
test loss item: 0.12648259103298187
test loss item: 0.12082787603139877
test loss item: 0.17205636203289032
test loss item: 0.12814421951770782
test loss item: 0.19749225676059723
test loss item: 0.13079994916915894
test loss item: 0.11501059681177139
test loss item: 0.2149847447872162
test loss item: 0.18282775580883026
test loss item: 0.11609150469303131
test loss item: 0.14615990221500397
test loss item: 0.10599400103092194
test loss item: 0.21784013509750366
test loss item: 0.12128384411334991
test loss item: 0.18160122632980347
test loss item: 0.19003576040267944
test loss item: 0.1497637927532196
test loss item: 0.08928067237138748
test loss item: 0.25443392992019653
test loss item: 0.10604340583086014
test loss item: 0.2287682145833969
test loss item: 0.2776612639427185
test loss item: 0.10998356342315674
test loss item: 0.051758281886577606
test loss item: 0.1512831747531891
Epoch [24/50], Training Loss: 0.2076, Testing Loss: 0.1566
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 25/50
train loss item: 0.21996429562568665
train loss item: 0.18688809871673584
train loss item: 0.13245588541030884
train loss item: 0.18357113003730774
train loss item: 0.11352931708097458
train loss item: 0.11265119165182114
train loss item: 0.14240805804729462
train loss item: 0.19186502695083618
train loss item: 0.07668426632881165
train loss item: 0.14690864086151123
train loss item: 0.0931052565574646
train loss item: 0.2728588879108429
train loss item: 0.12598563730716705
train loss item: 0.11532806605100632
train loss item: 0.17300082743167877
train loss item: 0.3982008397579193
train loss item: 0.1031649261713028
train loss item: 0.24599485099315643
train loss item: 0.1376124918460846
train loss item: 0.1650337129831314
train loss item: 0.12784075736999512
train loss item: 0.11798759549856186
train loss item: 0.18144653737545013
train loss item: 0.13319918513298035
train loss item: 0.08411797881126404
train loss item: 0.24888023734092712
train loss item: 0.06559410691261292
train loss item: 0.24219505488872528
train loss item: 0.10085684061050415
train loss item: 0.07916392385959625
train loss item: 0.2537517249584198
train loss item: 0.14416088163852692
train loss item: 0.1334264725446701
train loss item: 0.20943647623062134
train loss item: 0.16117027401924133
train loss item: 0.11637603491544724
train loss item: 0.10611065477132797
train loss item: 0.06985428929328918
train loss item: 0.2766343951225281
train loss item: 0.10098040848970413
train loss item: 0.0839942991733551
train loss item: 0.1670137643814087
train loss item: 0.16320784389972687
train loss item: 0.763848066329956
train loss item: 0.13768652081489563
test loss item: 0.08879346400499344
test loss item: 0.15680596232414246
test loss item: 0.1013256311416626
test loss item: 0.29265305399894714
test loss item: 0.13296422362327576
test loss item: 0.1993311047554016
test loss item: 0.10122319310903549
test loss item: 0.07583677023649216
test loss item: 0.1306696981191635
test loss item: 0.16604697704315186
test loss item: 0.17677125334739685
test loss item: 0.11316868662834167
test loss item: 0.09874602407217026
test loss item: 0.10891873389482498
test loss item: 0.13150258362293243
test loss item: 0.1839035302400589
test loss item: 0.15743684768676758
test loss item: 0.16591954231262207
test loss item: 0.2703973054885864
test loss item: 0.1359783411026001
test loss item: 0.12022346258163452
test loss item: 0.11998441070318222
test loss item: 0.1630811244249344
test loss item: 0.11912012100219727
test loss item: 0.18336966633796692
test loss item: 0.12009990960359573
test loss item: 0.11013879626989365
test loss item: 0.18913358449935913
test loss item: 0.17134764790534973
test loss item: 0.1119735985994339
test loss item: 0.14189325273036957
test loss item: 0.10355594754219055
test loss item: 0.20334522426128387
test loss item: 0.11068733036518097
test loss item: 0.17078040540218353
test loss item: 0.18466360867023468
test loss item: 0.1436215490102768
test loss item: 0.08135997503995895
test loss item: 0.24968017637729645
test loss item: 0.10218154639005661
test loss item: 0.2114870697259903
test loss item: 0.2560122609138489
test loss item: 0.10667866468429565
test loss item: 0.05517464503645897
test loss item: 0.16143225133419037
Epoch [25/50], Training Loss: 0.1690, Testing Loss: 0.1484
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 26/50
train loss item: 0.20227430760860443
train loss item: 0.18080708384513855
train loss item: 0.1286899298429489
train loss item: 0.18705134093761444
train loss item: 0.10134553909301758
train loss item: 0.11508915573358536
train loss item: 0.17517796158790588
train loss item: 0.16963692009449005
train loss item: 0.06899005174636841
train loss item: 0.13491463661193848
train loss item: 0.08328379690647125
train loss item: 0.3213307559490204
train loss item: 0.14652296900749207
train loss item: 0.13896772265434265
train loss item: 0.22175873816013336
train loss item: 0.2758316099643707
train loss item: 0.11318875849246979
train loss item: 0.23903648555278778
train loss item: 0.16414760053157806
train loss item: 0.13473284244537354
train loss item: 0.09393110126256943
train loss item: 0.1233188584446907
train loss item: 0.17779409885406494
train loss item: 0.10009101033210754
train loss item: 0.08406160026788712
train loss item: 0.21892641484737396
train loss item: 0.06766761094331741
train loss item: 0.19857320189476013
train loss item: 0.10905517637729645
train loss item: 0.0737028643488884
train loss item: 0.2585623860359192
train loss item: 0.14356201887130737
train loss item: 0.11326483637094498
train loss item: 0.13445304334163666
train loss item: 0.1457897573709488
train loss item: 0.10279963165521622
train loss item: 0.09935910254716873
train loss item: 0.0710797980427742
train loss item: 0.26026904582977295
train loss item: 0.10456056892871857
train loss item: 0.07356718927621841
train loss item: 0.13669154047966003
train loss item: 0.14053992927074432
train loss item: 0.7443402409553528
train loss item: 0.14362750947475433
test loss item: 0.10379898548126221
test loss item: 0.1744205206632614
test loss item: 0.10396377742290497
test loss item: 0.3592628538608551
test loss item: 0.1268477886915207
test loss item: 0.23270878195762634
test loss item: 0.10143212974071503
test loss item: 0.07854875922203064
test loss item: 0.1369135081768036
test loss item: 0.1739560067653656
test loss item: 0.1745000034570694
test loss item: 0.13240081071853638
test loss item: 0.10901512205600739
test loss item: 0.10876233130693436
test loss item: 0.12644344568252563
test loss item: 0.22500303387641907
test loss item: 0.16185522079467773
test loss item: 0.15784309804439545
test loss item: 0.32212236523628235
test loss item: 0.1382899135351181
test loss item: 0.14194545149803162
test loss item: 0.12311211228370667
test loss item: 0.15636008977890015
test loss item: 0.14142806828022003
test loss item: 0.19193947315216064
test loss item: 0.10552200675010681
test loss item: 0.11831942945718765
test loss item: 0.2016734629869461
test loss item: 0.1914752572774887
test loss item: 0.10801618546247482
test loss item: 0.1343734711408615
test loss item: 0.11650129407644272
test loss item: 0.22781246900558472
test loss item: 0.11378112435340881
test loss item: 0.17249588668346405
test loss item: 0.22081537544727325
test loss item: 0.16793185472488403
test loss item: 0.11025949567556381
test loss item: 0.3571195602416992
test loss item: 0.1227644756436348
test loss item: 0.25252407789230347
test loss item: 0.2955082356929779
test loss item: 0.12076321989297867
test loss item: 0.06477180123329163
test loss item: 0.17456400394439697
Epoch [26/50], Training Loss: 0.1605, Testing Loss: 0.1640
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 27/50
train loss item: 0.20199109613895416
train loss item: 0.15443074703216553
train loss item: 0.13926920294761658
train loss item: 0.13422678411006927
train loss item: 0.113031767308712
train loss item: 0.12330743670463562
train loss item: 0.14502555131912231
train loss item: 0.17264926433563232
train loss item: 0.06429682672023773
train loss item: 0.12449487298727036
train loss item: 0.0845092311501503
train loss item: 0.2849210798740387
train loss item: 0.12148197740316391
train loss item: 0.1333261877298355
train loss item: 0.215953066945076
train loss item: 0.27968284487724304
train loss item: 0.15460024774074554
train loss item: 0.22171805799007416
train loss item: 0.14533261954784393
train loss item: 0.18101619184017181
train loss item: 0.1313350796699524
train loss item: 0.14035558700561523
train loss item: 0.1844785064458847
train loss item: 0.10472165793180466
train loss item: 0.08288972079753876
train loss item: 0.21985271573066711
train loss item: 0.06725313514471054
train loss item: 0.22891481220722198
train loss item: 0.10906559973955154
train loss item: 0.07554853707551956
train loss item: 0.25625717639923096
train loss item: 0.13733769953250885
train loss item: 0.1271844059228897
train loss item: 0.19172587990760803
train loss item: 0.1588631570339203
train loss item: 0.11580977588891983
train loss item: 0.10206244140863419
train loss item: 0.07050936669111252
train loss item: 0.28131571412086487
train loss item: 0.10535818338394165
train loss item: 0.07873928546905518
train loss item: 0.1513456106185913
train loss item: 0.14433526992797852
train loss item: 0.7249644994735718
train loss item: 0.1354997307062149
test loss item: 0.09127271175384521
test loss item: 0.16546961665153503
test loss item: 0.09671299159526825
test loss item: 0.29469332098960876
test loss item: 0.12231962382793427
test loss item: 0.23883797228336334
test loss item: 0.0954902172088623
test loss item: 0.07242075353860855
test loss item: 0.13161928951740265
test loss item: 0.16471274197101593
test loss item: 0.16859012842178345
test loss item: 0.11376062035560608
test loss item: 0.10224587470293045
test loss item: 0.10590291023254395
test loss item: 0.12227579951286316
test loss item: 0.20941932499408722
test loss item: 0.15545158088207245
test loss item: 0.15646113455295563
test loss item: 0.3067467212677002
test loss item: 0.1301906853914261
test loss item: 0.12630416452884674
test loss item: 0.12021206319332123
test loss item: 0.15501409769058228
test loss item: 0.1220422014594078
test loss item: 0.19049085676670074
test loss item: 0.10266637802124023
test loss item: 0.11251205205917358
test loss item: 0.20606324076652527
test loss item: 0.17645840346813202
test loss item: 0.10154447704553604
test loss item: 0.12962213158607483
test loss item: 0.10505474358797073
test loss item: 0.22159190475940704
test loss item: 0.11127346754074097
test loss item: 0.16643370687961578
test loss item: 0.18634898960590363
test loss item: 0.15290792286396027
test loss item: 0.09458446502685547
test loss item: 0.3422302305698395
test loss item: 0.10864122956991196
test loss item: 0.23744510114192963
test loss item: 0.2899346351623535
test loss item: 0.11304464191198349
test loss item: 0.058186765760183334
test loss item: 0.1673675775527954
Epoch [27/50], Training Loss: 0.1627, Testing Loss: 0.1543
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 28/50
train loss item: 0.17433077096939087
train loss item: 0.1443684995174408
train loss item: 0.1217505931854248
train loss item: 0.12255574017763138
train loss item: 0.08810367435216904
train loss item: 0.10283622145652771
train loss item: 0.12336920946836472
train loss item: 0.1992824524641037
train loss item: 0.06255902349948883
train loss item: 0.12599113583564758
train loss item: 0.07891199737787247
train loss item: 0.2092839777469635
train loss item: 0.11472681909799576
train loss item: 0.12196057289838791
train loss item: 0.17389020323753357
train loss item: 0.270805299282074
train loss item: 0.11046553403139114
train loss item: 0.20240379869937897
train loss item: 0.13044753670692444
train loss item: 0.16978414356708527
train loss item: 0.12194163352251053
train loss item: 0.13414786756038666
train loss item: 0.13174887001514435
train loss item: 0.11845017224550247
train loss item: 0.08095823973417282
train loss item: 0.2206113636493683
train loss item: 0.06484484672546387
train loss item: 0.1878153383731842
train loss item: 0.09728468209505081
train loss item: 0.07289566844701767
train loss item: 0.2509477138519287
train loss item: 0.1377342939376831
train loss item: 0.12065068632364273
train loss item: 0.17974433302879333
train loss item: 0.14248913526535034
train loss item: 0.10168931633234024
train loss item: 0.10001488775014877
train loss item: 0.07106141746044159
train loss item: 0.24580755829811096
train loss item: 0.100509412586689
train loss item: 0.07999332249164581
train loss item: 0.15025204420089722
train loss item: 0.13887012004852295
train loss item: 0.7004213929176331
train loss item: 0.1253039687871933
test loss item: 0.08716689050197601
test loss item: 0.1613122671842575
test loss item: 0.09900673478841782
test loss item: 0.33902302384376526
test loss item: 0.12575724720954895
test loss item: 0.2284071445465088
test loss item: 0.09285905212163925
test loss item: 0.071359783411026
test loss item: 0.1332245171070099
test loss item: 0.16902022063732147
test loss item: 0.1803085207939148
test loss item: 0.1143355667591095
test loss item: 0.09716089814901352
test loss item: 0.1065315529704094
test loss item: 0.1277768760919571
test loss item: 0.21862651407718658
test loss item: 0.1609100103378296
test loss item: 0.16203491389751434
test loss item: 0.3092978000640869
test loss item: 0.13551408052444458
test loss item: 0.12243034690618515
test loss item: 0.1195407584309578
test loss item: 0.1646798998117447
test loss item: 0.12051519006490707
test loss item: 0.19333620369434357
test loss item: 0.10537952929735184
test loss item: 0.11023271828889847
test loss item: 0.20493976771831512
test loss item: 0.18245890736579895
test loss item: 0.10178550332784653
test loss item: 0.13669517636299133
test loss item: 0.10184726864099503
test loss item: 0.21625365316867828
test loss item: 0.11295226216316223
test loss item: 0.17045047879219055
test loss item: 0.2127818614244461
test loss item: 0.14817874133586884
test loss item: 0.08528081327676773
test loss item: 0.3196106553077698
test loss item: 0.10350532829761505
test loss item: 0.2382461577653885
test loss item: 0.2883129119873047
test loss item: 0.1054922416806221
test loss item: 0.05282914638519287
test loss item: 0.14471352100372314
Epoch [28/50], Training Loss: 0.1494, Testing Loss: 0.1552
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 29/50
train loss item: 0.19115355610847473
train loss item: 0.14606918394565582
train loss item: 0.12405499070882797
train loss item: 0.14060454070568085
train loss item: 0.08575009554624557
train loss item: 0.09800518304109573
train loss item: 0.12095851451158524
train loss item: 0.17244836688041687
train loss item: 0.06344833970069885
train loss item: 0.12204820662736893
train loss item: 0.07839124649763107
train loss item: 0.20652653276920319
train loss item: 0.11119820177555084
train loss item: 0.12246986478567123
train loss item: 0.18503770232200623
train loss item: 0.24886521697044373
train loss item: 0.08717405796051025
train loss item: 0.204196035861969
train loss item: 0.12582120299339294
train loss item: 0.13918627798557281
train loss item: 0.10189370065927505
train loss item: 0.12058572471141815
train loss item: 0.14530810713768005
train loss item: 0.10641833394765854
train loss item: 0.07942234724760056
train loss item: 0.2223552167415619
train loss item: 0.0667586475610733
train loss item: 0.2053506076335907
train loss item: 0.09321460872888565
train loss item: 0.07044348120689392
train loss item: 0.2356167584657669
train loss item: 0.11893472075462341
train loss item: 0.10838894546031952
train loss item: 0.15571251511573792
train loss item: 0.1252349615097046
train loss item: 0.09547968208789825
train loss item: 0.0937250629067421
train loss item: 0.06941037625074387
train loss item: 0.23796312510967255
train loss item: 0.0997096598148346
train loss item: 0.07582747936248779
train loss item: 0.1337701976299286
train loss item: 0.13437530398368835
train loss item: 0.6953557133674622
train loss item: 0.12141947448253632
test loss item: 0.09399904310703278
test loss item: 0.1830105185508728
test loss item: 0.10060390084981918
test loss item: 0.3944908082485199
test loss item: 0.13083869218826294
test loss item: 0.27708280086517334
test loss item: 0.09670992940664291
test loss item: 0.07448278367519379
test loss item: 0.13464027643203735
test loss item: 0.1828404814004898
test loss item: 0.18681398034095764
test loss item: 0.1236640140414238
test loss item: 0.09966768324375153
test loss item: 0.10870262235403061
test loss item: 0.13083870708942413
test loss item: 0.2652297914028168
test loss item: 0.17122918367385864
test loss item: 0.16855917870998383
test loss item: 0.3826160430908203
test loss item: 0.14505994319915771
test loss item: 0.12919242680072784
test loss item: 0.11491960287094116
test loss item: 0.17332524061203003
test loss item: 0.13047103583812714
test loss item: 0.21738377213478088
test loss item: 0.10473553836345673
test loss item: 0.10726520419120789
test loss item: 0.24311970174312592
test loss item: 0.2087455838918686
test loss item: 0.10304170101881027
test loss item: 0.14067897200584412
test loss item: 0.10734352469444275
test loss item: 0.2645913362503052
test loss item: 0.11655576527118683
test loss item: 0.18879106640815735
test loss item: 0.24320659041404724
test loss item: 0.16042198240756989
test loss item: 0.09028229117393494
test loss item: 0.4458196461200714
test loss item: 0.11123257130384445
test loss item: 0.2861050069332123
test loss item: 0.3566657304763794
test loss item: 0.10555542260408401
test loss item: 0.058961525559425354
test loss item: 0.14480692148208618
Epoch [29/50], Training Loss: 0.1441, Testing Loss: 0.1734
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 30/50
train loss item: 0.16731882095336914
train loss item: 0.15945903956890106
train loss item: 0.11996674537658691
train loss item: 0.18774421513080597
train loss item: 0.0843299999833107
train loss item: 0.11217585951089859
train loss item: 0.12392625957727432
train loss item: 0.13224457204341888
train loss item: 0.0673513114452362
train loss item: 0.13698987662792206
train loss item: 0.0842323750257492
train loss item: 0.28542858362197876
train loss item: 0.13754288852214813
train loss item: 0.10556201636791229
train loss item: 0.15138152241706848
train loss item: 0.25778084993362427
train loss item: 0.10230278968811035
train loss item: 0.20433452725410461
train loss item: 0.12969669699668884
train loss item: 0.18306097388267517
train loss item: 0.12998531758785248
train loss item: 0.15498162806034088
train loss item: 0.1625126153230667
train loss item: 0.14749039709568024
train loss item: 0.08648531138896942
train loss item: 0.23589777946472168
train loss item: 0.06198403611779213
train loss item: 0.25360938906669617
train loss item: 0.09746618568897247
train loss item: 0.07640455663204193
train loss item: 0.2569820284843445
train loss item: 0.14536988735198975
train loss item: 0.13812024891376495
train loss item: 0.21637088060379028
train loss item: 0.1511659026145935
train loss item: 0.12132958322763443
train loss item: 0.10371531546115875
train loss item: 0.07372802495956421
train loss item: 0.1997336596250534
train loss item: 0.10014491528272629
train loss item: 0.08326917141675949
train loss item: 0.17020556330680847
train loss item: 0.14541707932949066
train loss item: 0.6723605990409851
train loss item: 0.12824632227420807
test loss item: 0.08423760533332825
test loss item: 0.15447558462619781
test loss item: 0.09433043003082275
test loss item: 0.390158474445343
test loss item: 0.12643258273601532
test loss item: 0.22073152661323547
test loss item: 0.09754007309675217
test loss item: 0.07052555680274963
test loss item: 0.1313878446817398
test loss item: 0.1842486560344696
test loss item: 0.19124823808670044
test loss item: 0.1147972047328949
test loss item: 0.09517063945531845
test loss item: 0.11049573123455048
test loss item: 0.13062675297260284
test loss item: 0.22928206622600555
test loss item: 0.15478762984275818
test loss item: 0.16762419044971466
test loss item: 0.30877822637557983
test loss item: 0.13981647789478302
test loss item: 0.12184225022792816
test loss item: 0.11494732648134232
test loss item: 0.17757776379585266
test loss item: 0.11850450932979584
test loss item: 0.20338894426822662
test loss item: 0.11221379786729813
test loss item: 0.10760319977998734
test loss item: 0.2043491154909134
test loss item: 0.1923191398382187
test loss item: 0.10322761535644531
test loss item: 0.13975004851818085
test loss item: 0.1055416539311409
test loss item: 0.22635427117347717
test loss item: 0.12078835815191269
test loss item: 0.17415161430835724
test loss item: 0.25208112597465515
test loss item: 0.1610400378704071
test loss item: 0.0781145691871643
test loss item: 0.27925512194633484
test loss item: 0.09994537383317947
test loss item: 0.2547810971736908
test loss item: 0.29658496379852295
test loss item: 0.10421500355005264
test loss item: 0.05307396501302719
test loss item: 0.14313848316669464
Epoch [30/50], Training Loss: 0.1566, Testing Loss: 0.1587
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 31/50
train loss item: 0.19122351706027985
train loss item: 0.13979583978652954
train loss item: 0.1122843399643898
train loss item: 0.14761580526828766
train loss item: 0.09991082549095154
train loss item: 0.10215360671281815
train loss item: 0.12248550355434418
train loss item: 0.1295834630727768
train loss item: 0.06216913461685181
train loss item: 0.12886811792850494
train loss item: 0.08873020112514496
train loss item: 0.20056897401809692
train loss item: 0.11697491258382797
train loss item: 0.10089201480150223
train loss item: 0.18433877825737
train loss item: 0.29075032472610474
train loss item: 0.09993524849414825
train loss item: 0.1958027184009552
train loss item: 0.1479189246892929
train loss item: 0.1934560239315033
train loss item: 0.13453057408332825
train loss item: 0.13955992460250854
train loss item: 0.1936567723751068
train loss item: 0.18782398104667664
train loss item: 0.09462831914424896
train loss item: 0.3553486168384552
train loss item: 0.06867524981498718
train loss item: 0.3682631850242615
train loss item: 0.09222778677940369
train loss item: 0.06820293515920639
train loss item: 0.23242297768592834
train loss item: 0.12657393515110016
train loss item: 0.12554557621479034
train loss item: 0.2495163232088089
train loss item: 0.1815786212682724
train loss item: 0.12851135432720184
train loss item: 0.11671403795480728
train loss item: 0.07259553670883179
train loss item: 0.19020769000053406
train loss item: 0.10568538308143616
train loss item: 0.07140062749385834
train loss item: 0.12776346504688263
train loss item: 0.14100317656993866
train loss item: 0.6612077951431274
train loss item: 0.1287078857421875
test loss item: 0.0892539694905281
test loss item: 0.15466660261154175
test loss item: 0.09806354343891144
test loss item: 0.45279258489608765
test loss item: 0.12618790566921234
test loss item: 0.1970304250717163
test loss item: 0.1035555973649025
test loss item: 0.07231564819812775
test loss item: 0.13905060291290283
test loss item: 0.20808753371238708
test loss item: 0.19840320944786072
test loss item: 0.12021303921937943
test loss item: 0.10421375185251236
test loss item: 0.11659815907478333
test loss item: 0.13540354371070862
test loss item: 0.23971527814865112
test loss item: 0.15095466375350952
test loss item: 0.1637764424085617
test loss item: 0.30633744597435
test loss item: 0.1458137482404709
test loss item: 0.1352740377187729
test loss item: 0.1164110004901886
test loss item: 0.19459863007068634
test loss item: 0.1269092559814453
test loss item: 0.20710988342761993
test loss item: 0.10838259011507034
test loss item: 0.10838940739631653
test loss item: 0.17521250247955322
test loss item: 0.2074967622756958
test loss item: 0.10657801479101181
test loss item: 0.15042705833911896
test loss item: 0.11757908761501312
test loss item: 0.2360079139471054
test loss item: 0.137908473610878
test loss item: 0.17679603397846222
test loss item: 0.2955215871334076
test loss item: 0.18935126066207886
test loss item: 0.08911733329296112
test loss item: 0.24716661870479584
test loss item: 0.11212864518165588
test loss item: 0.2654397487640381
test loss item: 0.2880654036998749
test loss item: 0.11627882719039917
test loss item: 0.055030953139066696
test loss item: 0.1681840866804123
Epoch [31/50], Training Loss: 0.1604, Testing Loss: 0.1656
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 32/50
train loss item: 0.18546445667743683
train loss item: 0.13992741703987122
train loss item: 0.1120680421590805
train loss item: 0.17581290006637573
train loss item: 0.11470977216959
train loss item: 0.10350488871335983
train loss item: 0.21348707377910614
train loss item: 0.155402272939682
train loss item: 0.06430770456790924
train loss item: 0.13904979825019836
train loss item: 0.0852891057729721
train loss item: 0.41829243302345276
train loss item: 0.1498115360736847
train loss item: 0.1045897901058197
train loss item: 0.172407329082489
train loss item: 0.2920566499233246
train loss item: 0.08221297711133957
train loss item: 0.23795580863952637
train loss item: 0.19671280682086945
train loss item: 0.17346356809139252
train loss item: 0.10928390920162201
train loss item: 0.1763187050819397
train loss item: 0.17625953257083893
train loss item: 0.23120859265327454
train loss item: 0.08899949491024017
train loss item: 0.3705887496471405
train loss item: 0.07025392353534698
train loss item: 0.22739602625370026
train loss item: 0.11909444630146027
train loss item: 0.0760258212685585
train loss item: 0.307659387588501
train loss item: 0.14930060505867004
train loss item: 0.13150382041931152
train loss item: 0.1394181102514267
train loss item: 0.1285080462694168
train loss item: 0.11351559311151505
train loss item: 0.10141318291425705
train loss item: 0.07778249680995941
train loss item: 0.24447397887706757
train loss item: 0.14397495985031128
train loss item: 0.08271446824073792
train loss item: 0.15020231902599335
train loss item: 0.14966809749603271
train loss item: 0.6440907716751099
train loss item: 0.12714079022407532
test loss item: 0.11686717718839645
test loss item: 0.17600995302200317
test loss item: 0.105954609811306
test loss item: 0.48947271704673767
test loss item: 0.12519480288028717
test loss item: 0.24105697870254517
test loss item: 0.10680897533893585
test loss item: 0.09228084981441498
test loss item: 0.14069713652133942
test loss item: 0.21516753733158112
test loss item: 0.19351325929164886
test loss item: 0.14235107600688934
test loss item: 0.10357776284217834
test loss item: 0.12340239435434341
test loss item: 0.13629333674907684
test loss item: 0.2686782777309418
test loss item: 0.16462825238704681
test loss item: 0.1657932698726654
test loss item: 0.3625342845916748
test loss item: 0.15201303362846375
test loss item: 0.1480821818113327
test loss item: 0.11280207335948944
test loss item: 0.1898135095834732
test loss item: 0.15542162954807281
test loss item: 0.21062378585338593
test loss item: 0.10676082968711853
test loss item: 0.1076902523636818
test loss item: 0.20174629986286163
test loss item: 0.23551638424396515
test loss item: 0.10998644679784775
test loss item: 0.14480222761631012
test loss item: 0.12272864580154419
test loss item: 0.2618618607521057
test loss item: 0.1291191428899765
test loss item: 0.19263048470020294
test loss item: 0.31011322140693665
test loss item: 0.19101372361183167
test loss item: 0.11680480092763901
test loss item: 0.37005481123924255
test loss item: 0.1261490285396576
test loss item: 0.29321473836898804
test loss item: 0.3320254981517792
test loss item: 0.11603277921676636
test loss item: 0.08358929306268692
test loss item: 0.1468733549118042
Epoch [32/50], Training Loss: 0.1701, Testing Loss: 0.1808
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 33/50
train loss item: 0.1835910677909851
train loss item: 0.12758338451385498
train loss item: 0.11738757789134979
train loss item: 0.14329765737056732
train loss item: 0.10742641240358353
train loss item: 0.12017174065113068
train loss item: 0.1591811627149582
train loss item: 0.19205714762210846
train loss item: 0.06326241791248322
train loss item: 0.1248096227645874
train loss item: 0.07355883717536926
train loss item: 0.18271465599536896
train loss item: 0.10959194600582123
train loss item: 0.08604391664266586
train loss item: 0.13962793350219727
train loss item: 0.39187467098236084
train loss item: 0.08721936494112015
train loss item: 0.19576872885227203
train loss item: 0.15277069807052612
train loss item: 0.1406748741865158
train loss item: 0.09583017230033875
train loss item: 0.1506294310092926
train loss item: 0.12594468891620636
train loss item: 0.14435116946697235
train loss item: 0.07971178740262985
train loss item: 0.2795218527317047
train loss item: 0.06430642306804657
train loss item: 0.31878119707107544
train loss item: 0.09716488420963287
train loss item: 0.06639157980680466
train loss item: 0.3190069794654846
train loss item: 0.11797924339771271
train loss item: 0.11301817744970322
train loss item: 0.14711274206638336
train loss item: 0.13941390812397003
train loss item: 0.10779659450054169
train loss item: 0.10142336785793304
train loss item: 0.07005611807107925
train loss item: 0.30742064118385315
train loss item: 0.1006820797920227
train loss item: 0.06643205136060715
train loss item: 0.12381632626056671
train loss item: 0.1428263932466507
train loss item: 0.6228346824645996
train loss item: 0.1467684507369995
test loss item: 0.08495543897151947
test loss item: 0.13279148936271667
test loss item: 0.08901801705360413
test loss item: 0.37408262491226196
test loss item: 0.10495717823505402
test loss item: 0.16895842552185059
test loss item: 0.09497535228729248
test loss item: 0.06874816864728928
test loss item: 0.1227964386343956
test loss item: 0.17831453680992126
test loss item: 0.1675601750612259
test loss item: 0.11058904975652695
test loss item: 0.09125559777021408
test loss item: 0.1038253977894783
test loss item: 0.1189519613981247
test loss item: 0.18204499781131744
test loss item: 0.12380199134349823
test loss item: 0.13676851987838745
test loss item: 0.2530885338783264
test loss item: 0.12089153379201889
test loss item: 0.12420079857110977
test loss item: 0.10228146612644196
test loss item: 0.16956472396850586
test loss item: 0.12035182118415833
test loss item: 0.162971630692482
test loss item: 0.09587796777486801
test loss item: 0.09923166036605835
test loss item: 0.14128440618515015
test loss item: 0.17190079391002655
test loss item: 0.09537458419799805
test loss item: 0.11930027604103088
test loss item: 0.10563123971223831
test loss item: 0.20807163417339325
test loss item: 0.12037693709135056
test loss item: 0.1444360762834549
test loss item: 0.2483021318912506
test loss item: 0.16303476691246033
test loss item: 0.08547951281070709
test loss item: 0.19818459451198578
test loss item: 0.10237108170986176
test loss item: 0.22428582608699799
test loss item: 0.2351205050945282
test loss item: 0.10346323251724243
test loss item: 0.04826539754867554
test loss item: 0.14301429688930511
Epoch [33/50], Training Loss: 0.1544, Testing Loss: 0.1414
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 34/50
train loss item: 0.18692119419574738
train loss item: 0.1824561357498169
train loss item: 0.1078905388712883
train loss item: 0.128424733877182
train loss item: 0.11252765357494354
train loss item: 0.1176682561635971
train loss item: 0.19617033004760742
train loss item: 0.12794992327690125
train loss item: 0.06524340063333511
train loss item: 0.12846872210502625
train loss item: 0.06902904063463211
train loss item: 0.4129624664783478
train loss item: 0.1258372813463211
train loss item: 0.09828603267669678
train loss item: 0.20194301009178162
train loss item: 0.33547890186309814
train loss item: 0.09132663160562515
train loss item: 0.24834463000297546
train loss item: 0.2072291374206543
train loss item: 0.1797732412815094
train loss item: 0.10768511146306992
train loss item: 0.16831262409687042
train loss item: 0.30475378036499023
train loss item: 0.1827935427427292
train loss item: 0.07895227521657944
train loss item: 0.26902318000793457
train loss item: 0.07531747221946716
train loss item: 0.20802728831768036
train loss item: 0.12430334836244583
train loss item: 0.08425860852003098
train loss item: 0.2894730567932129
train loss item: 0.11998695135116577
train loss item: 0.12941771745681763
train loss item: 0.1468755006790161
train loss item: 0.12226282060146332
train loss item: 0.08928590267896652
train loss item: 0.09057188034057617
train loss item: 0.06936057657003403
train loss item: 0.2363867461681366
train loss item: 0.11759360879659653
train loss item: 0.07490016520023346
train loss item: 0.12750297784805298
train loss item: 0.14342956244945526
train loss item: 0.6243656277656555
train loss item: 0.1519566774368286
test loss item: 0.09751764684915543
test loss item: 0.1476752758026123
test loss item: 0.09378109872341156
test loss item: 0.36826997995376587
test loss item: 0.10883286595344543
test loss item: 0.20659703016281128
test loss item: 0.08927301317453384
test loss item: 0.0794186219573021
test loss item: 0.12334146350622177
test loss item: 0.16828350722789764
test loss item: 0.16706396639347076
test loss item: 0.11484517902135849
test loss item: 0.0952259972691536
test loss item: 0.10423054546117783
test loss item: 0.11848681420087814
test loss item: 0.20769977569580078
test loss item: 0.14609825611114502
test loss item: 0.14201362431049347
test loss item: 0.293572336435318
test loss item: 0.13275067508220673
test loss item: 0.12604737281799316
test loss item: 0.10485944896936417
test loss item: 0.15506993234157562
test loss item: 0.1190461665391922
test loss item: 0.17175577580928802
test loss item: 0.09220881760120392
test loss item: 0.1029563695192337
test loss item: 0.16956248879432678
test loss item: 0.18485556542873383
test loss item: 0.09639855474233627
test loss item: 0.1240992471575737
test loss item: 0.10183106362819672
test loss item: 0.20981770753860474
test loss item: 0.10799763351678848
test loss item: 0.16335426270961761
test loss item: 0.2320852279663086
test loss item: 0.147494375705719
test loss item: 0.08837553858757019
test loss item: 0.3017154633998871
test loss item: 0.1045270785689354
test loss item: 0.22970463335514069
test loss item: 0.26112931966781616
test loss item: 0.09965430200099945
test loss item: 0.07381247729063034
test loss item: 0.13752137124538422
Epoch [34/50], Training Loss: 0.1658, Testing Loss: 0.1491
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 35/50
train loss item: 0.1836639642715454
train loss item: 0.13308857381343842
train loss item: 0.11308938264846802
train loss item: 0.13266247510910034
train loss item: 0.07961396872997284
train loss item: 0.1018822118639946
train loss item: 0.16254079341888428
train loss item: 0.15006688237190247
train loss item: 0.06126675382256508
train loss item: 0.11149884760379791
train loss item: 0.07325968891382217
train loss item: 0.2798231244087219
train loss item: 0.10790353268384933
train loss item: 0.08741455525159836
train loss item: 0.13688808679580688
train loss item: 0.4639807939529419
train loss item: 0.09753543883562088
train loss item: 0.20788681507110596
train loss item: 0.18888629972934723
train loss item: 0.11187070608139038
train loss item: 0.07998214662075043
train loss item: 0.13396622240543365
train loss item: 0.1413787454366684
train loss item: 0.13525108993053436
train loss item: 0.08042509853839874
train loss item: 0.20326954126358032
train loss item: 0.06488971412181854
train loss item: 0.18463149666786194
train loss item: 0.09367723017930984
train loss item: 0.06249115988612175
train loss item: 0.24168626964092255
train loss item: 0.11009619385004044
train loss item: 0.09981069713830948
train loss item: 0.12203363329172134
train loss item: 0.11501140147447586
train loss item: 0.0823405459523201
train loss item: 0.08529011160135269
train loss item: 0.0647236630320549
train loss item: 0.21768787503242493
train loss item: 0.09683534502983093
train loss item: 0.06133263558149338
train loss item: 0.11849533766508102
train loss item: 0.12039869278669357
train loss item: 0.6219063401222229
train loss item: 0.13573254644870758
test loss item: 0.0841599553823471
test loss item: 0.1299968659877777
test loss item: 0.08654484152793884
test loss item: 0.39504140615463257
test loss item: 0.09730264544487
test loss item: 0.17959947884082794
test loss item: 0.08998073637485504
test loss item: 0.06682873517274857
test loss item: 0.1128772720694542
test loss item: 0.17484284937381744
test loss item: 0.1551109105348587
test loss item: 0.10990415513515472
test loss item: 0.0924067497253418
test loss item: 0.096476711332798
test loss item: 0.11231984198093414
test loss item: 0.19482919573783875
test loss item: 0.12073701620101929
test loss item: 0.13116712868213654
test loss item: 0.2696051299571991
test loss item: 0.1192011833190918
test loss item: 0.12310289591550827
test loss item: 0.09448640048503876
test loss item: 0.1514519453048706
test loss item: 0.116585873067379
test loss item: 0.15878164768218994
test loss item: 0.08444754779338837
test loss item: 0.09333767741918564
test loss item: 0.1407509744167328
test loss item: 0.17709635198116302
test loss item: 0.0892883837223053
test loss item: 0.10974352061748505
test loss item: 0.10337456315755844
test loss item: 0.20652420818805695
test loss item: 0.11334167420864105
test loss item: 0.14856940507888794
test loss item: 0.253279447555542
test loss item: 0.15425193309783936
test loss item: 0.08297078311443329
test loss item: 0.24418091773986816
test loss item: 0.09976885467767715
test loss item: 0.2324703186750412
test loss item: 0.24219852685928345
test loss item: 0.09946000576019287
test loss item: 0.04995901510119438
test loss item: 0.1392076015472412
Epoch [35/50], Training Loss: 0.1435, Testing Loss: 0.1406
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 36/50
train loss item: 0.15366318821907043
train loss item: 0.12578611075878143
train loss item: 0.11846720427274704
train loss item: 0.15793579816818237
train loss item: 0.07422570884227753
train loss item: 0.09906262904405594
train loss item: 0.18336497247219086
train loss item: 0.1250353455543518
train loss item: 0.05965487286448479
train loss item: 0.10083767026662827
train loss item: 0.06793654710054398
train loss item: 0.2685282826423645
train loss item: 0.11630858480930328
train loss item: 0.11455903202295303
train loss item: 0.1675707995891571
train loss item: 0.19915202260017395
train loss item: 0.11789403110742569
train loss item: 0.1789109706878662
train loss item: 0.210560142993927
train loss item: 0.10999929159879684
train loss item: 0.08300599455833435
train loss item: 0.1341816782951355
train loss item: 0.14644069969654083
train loss item: 0.10828777402639389
train loss item: 0.07389988005161285
train loss item: 0.22866706550121307
train loss item: 0.060229238122701645
train loss item: 0.14819972217082977
train loss item: 0.09229235351085663
train loss item: 0.0619635172188282
train loss item: 0.22989940643310547
train loss item: 0.12256500124931335
train loss item: 0.13227473199367523
train loss item: 0.13646425306797028
train loss item: 0.1103716790676117
train loss item: 0.08148407936096191
train loss item: 0.08515334129333496
train loss item: 0.06219836324453354
train loss item: 0.19486068189144135
train loss item: 0.10670829564332962
train loss item: 0.06063063070178032
train loss item: 0.11733608692884445
train loss item: 0.1268121600151062
train loss item: 0.5979250073432922
train loss item: 0.13790984451770782
test loss item: 0.08917130529880524
test loss item: 0.14370916783809662
test loss item: 0.09049810469150543
test loss item: 0.43978601694107056
test loss item: 0.10167621076107025
test loss item: 0.20897692441940308
test loss item: 0.09783425182104111
test loss item: 0.06846827268600464
test loss item: 0.12502910196781158
test loss item: 0.19422420859336853
test loss item: 0.16568946838378906
test loss item: 0.11497488617897034
test loss item: 0.10152292996644974
test loss item: 0.10212858766317368
test loss item: 0.11809488385915756
test loss item: 0.22498387098312378
test loss item: 0.13312408328056335
test loss item: 0.1412763148546219
test loss item: 0.3137306272983551
test loss item: 0.12603741884231567
test loss item: 0.13322213292121887
test loss item: 0.10851609706878662
test loss item: 0.15924391150474548
test loss item: 0.1317143440246582
test loss item: 0.17515867948532104
test loss item: 0.09189000725746155
test loss item: 0.10443657636642456
test loss item: 0.15835796296596527
test loss item: 0.2018653154373169
test loss item: 0.09444035589694977
test loss item: 0.11590906232595444
test loss item: 0.11063248664140701
test loss item: 0.22695259749889374
test loss item: 0.11992485076189041
test loss item: 0.1639525294303894
test loss item: 0.27742084860801697
test loss item: 0.1630690097808838
test loss item: 0.09744302928447723
test loss item: 0.314184308052063
test loss item: 0.10809040814638138
test loss item: 0.26812756061553955
test loss item: 0.28591617941856384
test loss item: 0.11095298081636429
test loss item: 0.053685951977968216
test loss item: 0.1461501121520996
Epoch [36/50], Training Loss: 0.1375, Testing Loss: 0.1560
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 37/50
train loss item: 0.1623993217945099
train loss item: 0.11014527827501297
train loss item: 0.11258881539106369
train loss item: 0.11382927000522614
train loss item: 0.08204936236143112
train loss item: 0.1103571429848671
train loss item: 0.13379022479057312
train loss item: 0.11151242256164551
train loss item: 0.0642852783203125
train loss item: 0.10210806131362915
train loss item: 0.06505979597568512
train loss item: 0.22404801845550537
train loss item: 0.09800446778535843
train loss item: 0.1198229044675827
train loss item: 0.19941480457782745
train loss item: 0.21247686445713043
train loss item: 0.14965181052684784
train loss item: 0.19407516717910767
train loss item: 0.13741138577461243
train loss item: 0.1254246085882187
train loss item: 0.09941866993904114
train loss item: 0.1416299194097519
train loss item: 0.12328360974788666
train loss item: 0.09930068254470825
train loss item: 0.07706253230571747
train loss item: 0.21091178059577942
train loss item: 0.05588136240839958
train loss item: 0.18385660648345947
train loss item: 0.08825504034757614
train loss item: 0.061780449002981186
train loss item: 0.20331043004989624
train loss item: 0.09868813306093216
train loss item: 0.10390743613243103
train loss item: 0.12359712272882462
train loss item: 0.09924478828907013
train loss item: 0.0774092823266983
train loss item: 0.08291304111480713
train loss item: 0.0613488107919693
train loss item: 0.29880136251449585
train loss item: 0.09074166417121887
train loss item: 0.06241590157151222
train loss item: 0.11212250590324402
train loss item: 0.12084894627332687
train loss item: 0.6169294714927673
train loss item: 0.140107199549675
test loss item: 0.09071198850870132
test loss item: 0.15236622095108032
test loss item: 0.08994986861944199
test loss item: 0.34309229254722595
test loss item: 0.10184349119663239
test loss item: 0.24147352576255798
test loss item: 0.092440165579319
test loss item: 0.07126977294683456
test loss item: 0.11671469360589981
test loss item: 0.15927723050117493
test loss item: 0.15310978889465332
test loss item: 0.11791026592254639
test loss item: 0.09640037268400192
test loss item: 0.09915013611316681
test loss item: 0.11102908849716187
test loss item: 0.22126485407352448
test loss item: 0.13791729509830475
test loss item: 0.1353723108768463
test loss item: 0.3235216736793518
test loss item: 0.12438885122537613
test loss item: 0.1274651139974594
test loss item: 0.10440292954444885
test loss item: 0.14557558298110962
test loss item: 0.12613752484321594
test loss item: 0.1709447205066681
test loss item: 0.08799654245376587
test loss item: 0.1001410111784935
test loss item: 0.18385863304138184
test loss item: 0.1821960210800171
test loss item: 0.09013689309358597
test loss item: 0.10728918761014938
test loss item: 0.1032048836350441
test loss item: 0.23163342475891113
test loss item: 0.10830358415842056
test loss item: 0.15693455934524536
test loss item: 0.21621370315551758
test loss item: 0.14730170369148254
test loss item: 0.09271152317523956
test loss item: 0.41642436385154724
test loss item: 0.10605324804782867
test loss item: 0.26426878571510315
test loss item: 0.3121931254863739
test loss item: 0.10191313922405243
test loss item: 0.062225092202425
test loss item: 0.13739457726478577
Epoch [37/50], Training Loss: 0.1347, Testing Loss: 0.1525
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 38/50
train loss item: 0.14861071109771729
train loss item: 0.11887761205434799
train loss item: 0.10619135200977325
train loss item: 0.10951073467731476
train loss item: 0.07277946174144745
train loss item: 0.09721547365188599
train loss item: 0.12895500659942627
train loss item: 0.11163070797920227
train loss item: 0.0604720413684845
train loss item: 0.10371039062738419
train loss item: 0.06797448545694351
train loss item: 0.17572374641895294
train loss item: 0.11413624882698059
train loss item: 0.09220409393310547
train loss item: 0.1651451587677002
train loss item: 0.20264668762683868
train loss item: 0.11401934921741486
train loss item: 0.1866714358329773
train loss item: 0.1143592894077301
train loss item: 0.1502930074930191
train loss item: 0.10936487466096878
train loss item: 0.13969528675079346
train loss item: 0.15107186138629913
train loss item: 0.12666486203670502
train loss item: 0.08004327118396759
train loss item: 0.2177557796239853
train loss item: 0.06436921656131744
train loss item: 0.18986830115318298
train loss item: 0.10080340504646301
train loss item: 0.07659617811441422
train loss item: 0.2040967494249344
train loss item: 0.1420341432094574
train loss item: 0.10663870722055435
train loss item: 0.13379435241222382
train loss item: 0.11105040460824966
train loss item: 0.08344727754592896
train loss item: 0.08417348563671112
train loss item: 0.06332157552242279
train loss item: 0.274903804063797
train loss item: 0.08933296799659729
train loss item: 0.07389524579048157
train loss item: 0.16359800100326538
train loss item: 0.14101091027259827
train loss item: 0.5965385437011719
train loss item: 0.12618613243103027
test loss item: 0.07818444818258286
test loss item: 0.14841505885124207
test loss item: 0.09131503105163574
test loss item: 0.28170689940452576
test loss item: 0.10583344101905823
test loss item: 0.2271421104669571
test loss item: 0.08627999573945999
test loss item: 0.06637167185544968
test loss item: 0.11673113703727722
test loss item: 0.14590071141719818
test loss item: 0.15120579302310944
test loss item: 0.09957966953516006
test loss item: 0.09242748469114304
test loss item: 0.09513864666223526
test loss item: 0.11067267507314682
test loss item: 0.19667163491249084
test loss item: 0.14105232059955597
test loss item: 0.13663633167743683
test loss item: 0.29675769805908203
test loss item: 0.12026481330394745
test loss item: 0.11311951279640198
test loss item: 0.10388956218957901
test loss item: 0.14166812598705292
test loss item: 0.09963954985141754
test loss item: 0.17168787121772766
test loss item: 0.0850113034248352
test loss item: 0.09777124971151352
test loss item: 0.18602435290813446
test loss item: 0.16608604788780212
test loss item: 0.0885973647236824
test loss item: 0.11256907880306244
test loss item: 0.09776803851127625
test loss item: 0.2132597267627716
test loss item: 0.10794171690940857
test loss item: 0.151156947016716
test loss item: 0.1813090443611145
test loss item: 0.12676803767681122
test loss item: 0.07231134176254272
test loss item: 0.366910845041275
test loss item: 0.09346437454223633
test loss item: 0.23232616484165192
test loss item: 0.27916210889816284
test loss item: 0.09641613811254501
test loss item: 0.0497913584113121
test loss item: 0.1413857340812683
Epoch [38/50], Training Loss: 0.1354, Testing Loss: 0.1414
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 39/50
train loss item: 0.15004698932170868
train loss item: 0.16437916457653046
train loss item: 0.11059002578258514
train loss item: 0.13923032581806183
train loss item: 0.07928240299224854
train loss item: 0.09545505046844482
train loss item: 0.1505769044160843
train loss item: 0.1143483892083168
train loss item: 0.057618219405412674
train loss item: 0.0957157239317894
train loss item: 0.06585904210805893
train loss item: 0.2234262377023697
train loss item: 0.09997344017028809
train loss item: 0.11145529896020889
train loss item: 0.13187509775161743
train loss item: 0.20413149893283844
train loss item: 0.08159694820642471
train loss item: 0.1782919317483902
train loss item: 0.19738896191120148
train loss item: 0.135941281914711
train loss item: 0.08142376691102982
train loss item: 0.14002475142478943
train loss item: 0.1397460699081421
train loss item: 0.0996960923075676
train loss item: 0.07282407581806183
train loss item: 0.20476283133029938
train loss item: 0.05616004392504692
train loss item: 0.1570056825876236
train loss item: 0.08418616652488708
train loss item: 0.06169300898909569
train loss item: 0.19397762417793274
train loss item: 0.11056558787822723
train loss item: 0.1091800406575203
train loss item: 0.11224190890789032
train loss item: 0.11707549542188644
train loss item: 0.08251205831766129
train loss item: 0.07755256444215775
train loss item: 0.0612955167889595
train loss item: 0.22148099541664124
train loss item: 0.09088234603404999
train loss item: 0.06246314197778702
train loss item: 0.13358649611473083
train loss item: 0.12649892270565033
train loss item: 0.5960915684700012
train loss item: 0.11248953640460968
test loss item: 0.0853067934513092
test loss item: 0.17662128806114197
test loss item: 0.09420090913772583
test loss item: 0.40905967354774475
test loss item: 0.1151358038187027
test loss item: 0.2820027470588684
test loss item: 0.08444234728813171
test loss item: 0.06841093301773071
test loss item: 0.1262383759021759
test loss item: 0.17064723372459412
test loss item: 0.17011182010173798
test loss item: 0.1061875969171524
test loss item: 0.09318489581346512
test loss item: 0.09923181682825089
test loss item: 0.11848530918359756
test loss item: 0.2675324082374573
test loss item: 0.16298802196979523
test loss item: 0.1518818438053131
test loss item: 0.3853415250778198
test loss item: 0.13906903564929962
test loss item: 0.1250668317079544
test loss item: 0.10904344171285629
test loss item: 0.15613238513469696
test loss item: 0.11402302235364914
test loss item: 0.20291867852210999
test loss item: 0.08867080509662628
test loss item: 0.10282228142023087
test loss item: 0.2357960045337677
test loss item: 0.201010063290596
test loss item: 0.09093452244997025
test loss item: 0.1203569695353508
test loss item: 0.09960762411355972
test loss item: 0.2697296440601349
test loss item: 0.10884885489940643
test loss item: 0.17539748549461365
test loss item: 0.25019288063049316
test loss item: 0.14390158653259277
test loss item: 0.08378321677446365
test loss item: 0.47680971026420593
test loss item: 0.10378401726484299
test loss item: 0.29858240485191345
test loss item: 0.3638339042663574
test loss item: 0.10030315071344376
test loss item: 0.05464877188205719
test loss item: 0.15829026699066162
Epoch [39/50], Training Loss: 0.1309, Testing Loss: 0.1676
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 40/50
train loss item: 0.17744484543800354
train loss item: 0.12646950781345367
train loss item: 0.10699567198753357
train loss item: 0.12151428312063217
train loss item: 0.08617877215147018
train loss item: 0.11577237397432327
train loss item: 0.13420423865318298
train loss item: 0.1095636785030365
train loss item: 0.06584301590919495
train loss item: 0.10945752263069153
train loss item: 0.06659083813428879
train loss item: 0.22874535620212555
train loss item: 0.09854130446910858
train loss item: 0.11469940096139908
train loss item: 0.219332754611969
train loss item: 0.3102824091911316
train loss item: 0.1519385576248169
train loss item: 0.18869738280773163
train loss item: 0.15518060326576233
train loss item: 0.17592282593250275
train loss item: 0.12550094723701477
train loss item: 0.13801886141300201
train loss item: 0.17136725783348083
train loss item: 0.09893176704645157
train loss item: 0.0783298909664154
train loss item: 0.2069472223520279
train loss item: 0.05639481917023659
train loss item: 0.2170267105102539
train loss item: 0.09778381884098053
train loss item: 0.06787444651126862
train loss item: 0.2704596221446991
train loss item: 0.13585864007472992
train loss item: 0.11910443007946014
train loss item: 0.19854146242141724
train loss item: 0.1389639675617218
train loss item: 0.09457211196422577
train loss item: 0.08942927420139313
train loss item: 0.06229998543858528
train loss item: 0.24012506008148193
train loss item: 0.0911029800772667
train loss item: 0.07659544050693512
train loss item: 0.12691481411457062
train loss item: 0.13746407628059387
train loss item: 0.5482261776924133
train loss item: 0.12436291575431824
test loss item: 0.07838307321071625
test loss item: 0.16167184710502625
test loss item: 0.09181688725948334
test loss item: 0.36120229959487915
test loss item: 0.11856915056705475
test loss item: 0.25015756487846375
test loss item: 0.08654162287712097
test loss item: 0.06525411456823349
test loss item: 0.12732882797718048
test loss item: 0.1783524751663208
test loss item: 0.17418110370635986
test loss item: 0.11232908070087433
test loss item: 0.09171057492494583
test loss item: 0.1047467589378357
test loss item: 0.12122791260480881
test loss item: 0.22978109121322632
test loss item: 0.1559077501296997
test loss item: 0.157995343208313
test loss item: 0.33485275506973267
test loss item: 0.1316462755203247
test loss item: 0.1162315234541893
test loss item: 0.10921642929315567
test loss item: 0.17065085470676422
test loss item: 0.11244234442710876
test loss item: 0.20057132840156555
test loss item: 0.09448922425508499
test loss item: 0.09922285377979279
test loss item: 0.21371573209762573
test loss item: 0.19109532237052917
test loss item: 0.09185745567083359
test loss item: 0.13191711902618408
test loss item: 0.1005302220582962
test loss item: 0.24494363367557526
test loss item: 0.11717468500137329
test loss item: 0.17143605649471283
test loss item: 0.23696449398994446
test loss item: 0.15430153906345367
test loss item: 0.07616592943668365
test loss item: 0.3724243938922882
test loss item: 0.09737801551818848
test loss item: 0.27114537358283997
test loss item: 0.32002055644989014
test loss item: 0.10078824311494827
test loss item: 0.04849325120449066
test loss item: 0.14006885886192322
Epoch [40/50], Training Loss: 0.1461, Testing Loss: 0.1582
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 41/50
train loss item: 0.15996363759040833
train loss item: 0.13220317661762238
train loss item: 0.10034231096506119
train loss item: 0.17588742077350616
train loss item: 0.0779634490609169
train loss item: 0.08573884516954422
train loss item: 0.11340529471635818
train loss item: 0.1295224130153656
train loss item: 0.06245768815279007
train loss item: 0.12539203464984894
train loss item: 0.0773221105337143
train loss item: 0.19851821660995483
train loss item: 0.12121625244617462
train loss item: 0.08629932999610901
train loss item: 0.13154299557209015
train loss item: 0.21185827255249023
train loss item: 0.07952083647251129
train loss item: 0.16963344812393188
train loss item: 0.12880834937095642
train loss item: 0.1401015967130661
train loss item: 0.11946360766887665
train loss item: 0.13095419108867645
train loss item: 0.13444823026657104
train loss item: 0.12034958600997925
train loss item: 0.0789487212896347
train loss item: 0.24706846475601196
train loss item: 0.055987708270549774
train loss item: 0.25276824831962585
train loss item: 0.08164554834365845
train loss item: 0.06567256152629852
train loss item: 0.2018175572156906
train loss item: 0.12606178224086761
train loss item: 0.11779307574033737
train loss item: 0.19089528918266296
train loss item: 0.13159888982772827
train loss item: 0.10671161860227585
train loss item: 0.09462962299585342
train loss item: 0.06643415987491608
train loss item: 0.18441076576709747
train loss item: 0.0933154970407486
train loss item: 0.0704742893576622
train loss item: 0.11595963686704636
train loss item: 0.12884379923343658
train loss item: 0.5342813730239868
train loss item: 0.11307281255722046
test loss item: 0.080231212079525
test loss item: 0.13874799013137817
test loss item: 0.09473341703414917
test loss item: 0.4004529118537903
test loss item: 0.11075863242149353
test loss item: 0.1859789937734604
test loss item: 0.08758490532636642
test loss item: 0.06970886141061783
test loss item: 0.12907858192920685
test loss item: 0.17892567813396454
test loss item: 0.17717885971069336
test loss item: 0.10209518671035767
test loss item: 0.092256560921669
test loss item: 0.10588138550519943
test loss item: 0.12353470176458359
test loss item: 0.2072807401418686
test loss item: 0.13904322683811188
test loss item: 0.1448458582162857
test loss item: 0.2750263512134552
test loss item: 0.12960925698280334
test loss item: 0.11811914294958115
test loss item: 0.11175128817558289
test loss item: 0.16908381879329681
test loss item: 0.10559746623039246
test loss item: 0.1767411082983017
test loss item: 0.09493396431207657
test loss item: 0.10454694926738739
test loss item: 0.16270148754119873
test loss item: 0.17940236628055573
test loss item: 0.09318374842405319
test loss item: 0.1279546469449997
test loss item: 0.10109654814004898
test loss item: 0.21120575070381165
test loss item: 0.12133517116308212
test loss item: 0.15483127534389496
test loss item: 0.26396653056144714
test loss item: 0.1531420648097992
test loss item: 0.07703503221273422
test loss item: 0.2299736589193344
test loss item: 0.09560666978359222
test loss item: 0.24039454758167267
test loss item: 0.2576468288898468
test loss item: 0.10128055512905121
test loss item: 0.045884206891059875
test loss item: 0.12786991894245148
Epoch [41/50], Training Loss: 0.1349, Testing Loss: 0.1466
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 42/50
train loss item: 0.14243999123573303
train loss item: 0.12794804573059082
train loss item: 0.10224912315607071
train loss item: 0.11873456090688705
train loss item: 0.08859730511903763
train loss item: 0.10311078280210495
train loss item: 0.15940436720848083
train loss item: 0.14586776494979858
train loss item: 0.056895848363637924
train loss item: 0.11575520038604736
train loss item: 0.0655144602060318
train loss item: 0.2953225076198578
train loss item: 0.10261737555265427
train loss item: 0.09509217739105225
train loss item: 0.15565796196460724
train loss item: 0.21145053207874298
train loss item: 0.08399123698472977
train loss item: 0.2270091325044632
train loss item: 0.15590959787368774
train loss item: 0.11945370584726334
train loss item: 0.08503148704767227
train loss item: 0.11093372106552124
train loss item: 0.1599453091621399
train loss item: 0.09559568017721176
train loss item: 0.07137883454561234
train loss item: 0.1967613250017166
train loss item: 0.057054273784160614
train loss item: 0.16971248388290405
train loss item: 0.09169463068246841
train loss item: 0.06701511889696121
train loss item: 0.20142219960689545
train loss item: 0.12338922917842865
train loss item: 0.11976997554302216
train loss item: 0.11072713881731033
train loss item: 0.10988041013479233
train loss item: 0.08006851375102997
train loss item: 0.07785454392433167
train loss item: 0.06510310620069504
train loss item: 0.2082422971725464
train loss item: 0.09918057173490524
train loss item: 0.06510376185178757
train loss item: 0.1014050841331482
train loss item: 0.11221175640821457
train loss item: 0.5503576993942261
train loss item: 0.11294817924499512
test loss item: 0.09462863951921463
test loss item: 0.15900053083896637
test loss item: 0.09503447264432907
test loss item: 0.4654732644557953
test loss item: 0.11169174313545227
test loss item: 0.22611019015312195
test loss item: 0.08587802946567535
test loss item: 0.07326431572437286
test loss item: 0.13228389620780945
test loss item: 0.19003525376319885
test loss item: 0.1836882084608078
test loss item: 0.1197005957365036
test loss item: 0.09852258116006851
test loss item: 0.10416623204946518
test loss item: 0.12154178321361542
test loss item: 0.25200027227401733
test loss item: 0.15720199048519135
test loss item: 0.14723485708236694
test loss item: 0.3382575213909149
test loss item: 0.14181415736675262
test loss item: 0.13257916271686554
test loss item: 0.11488741636276245
test loss item: 0.16667550802230835
test loss item: 0.12412944436073303
test loss item: 0.18976648151874542
test loss item: 0.09195318818092346
test loss item: 0.10798734426498413
test loss item: 0.18800367414951324
test loss item: 0.2055659294128418
test loss item: 0.09376335889101028
test loss item: 0.12848424911499023
test loss item: 0.10675907880067825
test loss item: 0.23920294642448425
test loss item: 0.11442437767982483
test loss item: 0.17243444919586182
test loss item: 0.28941890597343445
test loss item: 0.16370368003845215
test loss item: 0.09370025992393494
test loss item: 0.34618833661079407
test loss item: 0.11029788851737976
test loss item: 0.27908775210380554
test loss item: 0.310097873210907
test loss item: 0.10751530528068542
test loss item: 0.06845136731863022
test loss item: 0.15480343997478485
Epoch [42/50], Training Loss: 0.1315, Testing Loss: 0.1644
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 43/50
train loss item: 0.16540569067001343
train loss item: 0.11673695594072342
train loss item: 0.1014523133635521
train loss item: 0.11344369500875473
train loss item: 0.07108545303344727
train loss item: 0.09218595921993256
train loss item: 0.10204115509986877
train loss item: 0.11966142058372498
train loss item: 0.06248227879405022
train loss item: 0.10889311879873276
train loss item: 0.08215563744306564
train loss item: 0.1525161862373352
train loss item: 0.11501938104629517
train loss item: 0.08120457828044891
train loss item: 0.19848084449768066
train loss item: 0.3658398389816284
train loss item: 0.08327466249465942
train loss item: 0.2025042474269867
train loss item: 0.12486296147108078
train loss item: 0.1741952747106552
train loss item: 0.11023158580064774
train loss item: 0.1493450105190277
train loss item: 0.13881884515285492
train loss item: 0.18860313296318054
train loss item: 0.0793621838092804
train loss item: 0.35226038098335266
train loss item: 0.05434759333729744
train loss item: 0.19821247458457947
train loss item: 0.08802997320890427
train loss item: 0.0638146921992302
train loss item: 0.21677491068840027
train loss item: 0.09918332099914551
train loss item: 0.10329341143369675
train loss item: 0.14185833930969238
train loss item: 0.12100851535797119
train loss item: 0.10580688714981079
train loss item: 0.09640977531671524
train loss item: 0.061799097806215286
train loss item: 0.26003938913345337
train loss item: 0.10344286262989044
train loss item: 0.06108654662966728
train loss item: 0.11201189458370209
train loss item: 0.13608120381832123
train loss item: 0.543986439704895
train loss item: 0.1221931204199791
test loss item: 0.08653701841831207
test loss item: 0.1318858563899994
test loss item: 0.08586998283863068
test loss item: 0.3976803123950958
test loss item: 0.0997760146856308
test loss item: 0.171644389629364
test loss item: 0.09711422771215439
test loss item: 0.06747648119926453
test loss item: 0.12317094206809998
test loss item: 0.18995076417922974
test loss item: 0.16576580703258514
test loss item: 0.1268107295036316
test loss item: 0.09865030646324158
test loss item: 0.11095243692398071
test loss item: 0.11783735454082489
test loss item: 0.1955222487449646
test loss item: 0.12502571940422058
test loss item: 0.13137897849082947
test loss item: 0.25863057374954224
test loss item: 0.12677790224552155
test loss item: 0.1277918517589569
test loss item: 0.10018334537744522
test loss item: 0.18026059865951538
test loss item: 0.12913137674331665
test loss item: 0.17246074974536896
test loss item: 0.086696095764637
test loss item: 0.09405689686536789
test loss item: 0.1326129138469696
test loss item: 0.1814454197883606
test loss item: 0.0918709859251976
test loss item: 0.12221596390008926
test loss item: 0.11367762088775635
test loss item: 0.21924637258052826
test loss item: 0.13314469158649445
test loss item: 0.14683835208415985
test loss item: 0.26711300015449524
test loss item: 0.18521803617477417
test loss item: 0.08768738806247711
test loss item: 0.2188308835029602
test loss item: 0.10457325726747513
test loss item: 0.23534823954105377
test loss item: 0.23788650333881378
test loss item: 0.11119364947080612
test loss item: 0.05921659618616104
test loss item: 0.14767572283744812
Epoch [43/50], Training Loss: 0.1409, Testing Loss: 0.1466
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 44/50
train loss item: 0.15460751950740814
train loss item: 0.1444259136915207
train loss item: 0.11357873678207397
train loss item: 0.10860374569892883
train loss item: 0.10928450524806976
train loss item: 0.09738785028457642
train loss item: 0.1570987105369568
train loss item: 0.15686064958572388
train loss item: 0.05725030228495598
train loss item: 0.09595989435911179
train loss item: 0.06827987730503082
train loss item: 0.25736328959465027
train loss item: 0.10095079988241196
train loss item: 0.07500363141298294
train loss item: 0.13762019574642181
train loss item: 0.19498950242996216
train loss item: 0.09702529013156891
train loss item: 0.21295888721942902
train loss item: 0.12490317225456238
train loss item: 0.1344514936208725
train loss item: 0.07678196579217911
train loss item: 0.14770983159542084
train loss item: 0.12166877835988998
train loss item: 0.17418913543224335
train loss item: 0.0757036805152893
train loss item: 0.2633216679096222
train loss item: 0.06922130286693573
train loss item: 0.168082132935524
train loss item: 0.09520192444324493
train loss item: 0.065644271671772
train loss item: 0.18113607168197632
train loss item: 0.0996464192867279
train loss item: 0.10489965230226517
train loss item: 0.10386747866868973
train loss item: 0.10162480175495148
train loss item: 0.08008360862731934
train loss item: 0.08187060058116913
train loss item: 0.05957398936152458
train loss item: 0.20012421905994415
train loss item: 0.09949461370706558
train loss item: 0.06049177050590515
train loss item: 0.10634434223175049
train loss item: 0.10840924829244614
train loss item: 0.553615152835846
train loss item: 0.10278120636940002
test loss item: 0.10038886219263077
test loss item: 0.1538916826248169
test loss item: 0.0963411033153534
test loss item: 0.4555128216743469
test loss item: 0.1092563271522522
test loss item: 0.22507096827030182
test loss item: 0.08375860005617142
test loss item: 0.08239738643169403
test loss item: 0.12601113319396973
test loss item: 0.18161240220069885
test loss item: 0.17451204359531403
test loss item: 0.11800938099622726
test loss item: 0.09506553411483765
test loss item: 0.10804092139005661
test loss item: 0.12138614058494568
test loss item: 0.24775224924087524
test loss item: 0.15300484001636505
test loss item: 0.14330516755580902
test loss item: 0.33319443464279175
test loss item: 0.14242339134216309
test loss item: 0.12916135787963867
test loss item: 0.10533219575881958
test loss item: 0.1636277735233307
test loss item: 0.11733575910329819
test loss item: 0.18471994996070862
test loss item: 0.090288445353508
test loss item: 0.0999516174197197
test loss item: 0.18188489973545074
test loss item: 0.20187319815158844
test loss item: 0.09351601451635361
test loss item: 0.12687647342681885
test loss item: 0.10496329516172409
test loss item: 0.23780378699302673
test loss item: 0.114114910364151
test loss item: 0.1693728268146515
test loss item: 0.2860918641090393
test loss item: 0.15764877200126648
test loss item: 0.08788911998271942
test loss item: 0.3602517545223236
test loss item: 0.10556517541408539
test loss item: 0.2740654945373535
test loss item: 0.30428367853164673
test loss item: 0.09814216196537018
test loss item: 0.0781547799706459
test loss item: 0.13898847997188568
Epoch [44/50], Training Loss: 0.1311, Testing Loss: 0.1614
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 45/50
train loss item: 0.19443394243717194
train loss item: 0.11369702219963074
train loss item: 0.1034841239452362
train loss item: 0.14548511803150177
train loss item: 0.07326068729162216
train loss item: 0.10383325070142746
train loss item: 0.11665228009223938
train loss item: 0.12618519365787506
train loss item: 0.05731732398271561
train loss item: 0.09672865271568298
train loss item: 0.06596864759922028
train loss item: 0.16407325863838196
train loss item: 0.09479665756225586
train loss item: 0.08053409308195114
train loss item: 0.12313736230134964
train loss item: 0.23536400496959686
train loss item: 0.0873824879527092
train loss item: 0.1905207335948944
train loss item: 0.14214211702346802
train loss item: 0.10818763822317123
train loss item: 0.07393356412649155
train loss item: 0.13911142945289612
train loss item: 0.12122820317745209
train loss item: 0.15377435088157654
train loss item: 0.07440951466560364
train loss item: 0.20970559120178223
train loss item: 0.05866682529449463
train loss item: 0.1712290197610855
train loss item: 0.08372944593429565
train loss item: 0.05917957052588463
train loss item: 0.1898116171360016
train loss item: 0.09322531521320343
train loss item: 0.09309467673301697
train loss item: 0.114415742456913
train loss item: 0.10526037216186523
train loss item: 0.08472200483083725
train loss item: 0.08126743882894516
train loss item: 0.05891566723585129
train loss item: 0.1796261966228485
train loss item: 0.09212163835763931
train loss item: 0.055648673325777054
train loss item: 0.1209898367524147
train loss item: 0.11277856677770615
train loss item: 0.5429126620292664
train loss item: 0.10738200694322586
test loss item: 0.08622687309980392
test loss item: 0.14284631609916687
test loss item: 0.0877043604850769
test loss item: 0.46876290440559387
test loss item: 0.10002146661281586
test loss item: 0.2091110795736313
test loss item: 0.08931642770767212
test loss item: 0.06619986146688461
test loss item: 0.12123899906873703
test loss item: 0.1964767575263977
test loss item: 0.1671953797340393
test loss item: 0.11716873198747635
test loss item: 0.0955905169248581
test loss item: 0.10348005592823029
test loss item: 0.11568276584148407
test loss item: 0.23840934038162231
test loss item: 0.1339750736951828
test loss item: 0.13653749227523804
test loss item: 0.3192838430404663
test loss item: 0.1304188370704651
test loss item: 0.13018865883350372
test loss item: 0.10062301158905029
test loss item: 0.16838154196739197
test loss item: 0.1244092583656311
test loss item: 0.17938385903835297
test loss item: 0.08185530453920364
test loss item: 0.0954788327217102
test loss item: 0.15928220748901367
test loss item: 0.202728271484375
test loss item: 0.0881342813372612
test loss item: 0.11778800189495087
test loss item: 0.10967448353767395
test loss item: 0.241394504904747
test loss item: 0.12296188622713089
test loss item: 0.16107197105884552
test loss item: 0.297893226146698
test loss item: 0.17270591855049133
test loss item: 0.08807462453842163
test loss item: 0.32656288146972656
test loss item: 0.105202317237854
test loss item: 0.27665263414382935
test loss item: 0.29376477003097534
test loss item: 0.10456861555576324
test loss item: 0.055887170135974884
test loss item: 0.15103620290756226
Epoch [45/50], Training Loss: 0.1245, Testing Loss: 0.1574
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.11444098502397537
loss item: 0.324204683303833
loss item: 0.206955224275589
loss item: 0.24338850378990173
loss item: 0.09915100783109665
loss item: 0.36539703607559204
loss item: 0.2312232255935669
loss item: 0.09969890117645264
loss item: 0.1522914171218872
loss item: 0.2555631101131439
loss item: 0.12328220158815384
loss item: 0.13216622173786163
loss item: 0.21735641360282898
loss item: 0.1985444873571396
loss item: 0.1438561975955963
loss item: 0.4224192202091217
loss item: 0.17103324830532074
loss item: 0.09449902176856995
loss item: 0.11311066895723343
loss item: 0.23098237812519073
loss item: 0.26149263978004456
loss item: 0.08557901531457901
Val Loss: 0.1948
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.0001 4 360 done at Tue Nov 12 10:41:39 CET 2024
UNet2 with 1 50 0.0005 4 360 start at Tue Nov 12 10:41:39 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.6336421966552734
train loss item: 0.9993661046028137
train loss item: 0.595187783241272
train loss item: 0.9349422454833984
train loss item: 0.420171320438385
train loss item: 0.43110084533691406
train loss item: 0.4865673780441284
train loss item: 0.7318769693374634
train loss item: 0.33974796533584595
train loss item: 0.3741704523563385
train loss item: 0.3689255118370056
train loss item: 1.1589950323104858
train loss item: 0.5373875498771667
train loss item: 0.34425392746925354
train loss item: 0.6828771233558655
train loss item: 1.6828837394714355
train loss item: 0.49172812700271606
train loss item: 1.9094692468643188
train loss item: 0.6189807057380676
train loss item: 0.6172576546669006
train loss item: 0.5751233696937561
train loss item: 0.3494304418563843
train loss item: 0.46517854928970337
train loss item: 0.2958175539970398
train loss item: 0.24401570856571198
train loss item: 0.8013125061988831
train loss item: 0.2470400482416153
train loss item: 1.7671763896942139
train loss item: 0.2696566581726074
train loss item: 0.2147693783044815
train loss item: 1.5447440147399902
train loss item: 0.39145776629447937
train loss item: 0.42256706953048706
train loss item: 0.47760188579559326
train loss item: 0.3703896701335907
train loss item: 0.31359994411468506
train loss item: 0.32691898941993713
train loss item: 0.15602192282676697
train loss item: 1.1286150217056274
train loss item: 0.3056598901748657
train loss item: 0.26400911808013916
train loss item: 0.47334399819374084
train loss item: 0.44159236550331116
train loss item: 2.875567674636841
train loss item: 0.44896361231803894
test loss item: 0.18260884284973145
test loss item: 0.37658047676086426
test loss item: 0.21447274088859558
test loss item: 0.8869276642799377
test loss item: 0.2703791856765747
test loss item: 0.5653818249702454
test loss item: 0.17298828065395355
test loss item: 0.16976198554039001
test loss item: 0.3151813745498657
test loss item: 0.4063761830329895
test loss item: 0.4782122075557709
test loss item: 0.24083423614501953
test loss item: 0.21599040925502777
test loss item: 0.2523772418498993
test loss item: 0.30982324481010437
test loss item: 0.5589002966880798
test loss item: 0.45664331316947937
test loss item: 0.3833664059638977
test loss item: 0.8046218156814575
test loss item: 0.36945685744285583
test loss item: 0.26711544394493103
test loss item: 0.32015877962112427
test loss item: 0.41130152344703674
test loss item: 0.25871169567108154
test loss item: 0.4566580057144165
test loss item: 0.21447890996932983
test loss item: 0.29934096336364746
test loss item: 0.5387488603591919
test loss item: 0.46469613909721375
test loss item: 0.21642421185970306
test loss item: 0.31394293904304504
test loss item: 0.22205500304698944
test loss item: 0.5734866261482239
test loss item: 0.26601606607437134
test loss item: 0.4046967923641205
test loss item: 0.5527810454368591
test loss item: 0.30840063095092773
test loss item: 0.1677815020084381
test loss item: 0.8059555888175964
test loss item: 0.21964682638645172
test loss item: 0.5953294634819031
test loss item: 0.7180091738700867
test loss item: 0.21305808424949646
test loss item: 0.151900514960289
test loss item: 0.20145545899868011
Epoch [1/50], Training Loss: 0.6784, Testing Loss: 0.3732
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/50
train loss item: 0.6763551831245422
train loss item: 0.5072659254074097
train loss item: 0.31016770005226135
train loss item: 0.4932032525539398
train loss item: 0.28396549820899963
train loss item: 0.31024402379989624
train loss item: 0.3571765422821045
train loss item: 0.5308289527893066
train loss item: 0.23511645197868347
train loss item: 0.3242553174495697
train loss item: 0.1966618150472641
train loss item: 0.7715167999267578
train loss item: 0.34185728430747986
train loss item: 0.2585991621017456
train loss item: 0.48500949144363403
train loss item: 1.257409930229187
train loss item: 0.4677455425262451
train loss item: 1.4938323497772217
train loss item: 0.6211795806884766
train loss item: 0.697333037853241
train loss item: 0.39729008078575134
train loss item: 0.388002872467041
train loss item: 0.36994507908821106
train loss item: 0.3004932999610901
train loss item: 0.22935816645622253
train loss item: 0.7564562559127808
train loss item: 0.20619870722293854
train loss item: 1.5096603631973267
train loss item: 0.2950872778892517
train loss item: 0.16978172957897186
train loss item: 1.348725438117981
train loss item: 0.2653981149196625
train loss item: 0.36940357089042664
train loss item: 0.3703857362270355
train loss item: 0.3254009783267975
train loss item: 0.2764299511909485
train loss item: 0.2899024486541748
train loss item: 0.1495000720024109
train loss item: 0.9525243639945984
train loss item: 0.20779015123844147
train loss item: 0.16544437408447266
train loss item: 0.3925164043903351
train loss item: 0.3590438663959503
train loss item: 2.3288955688476562
train loss item: 0.3717213273048401
test loss item: 0.18622981011867523
test loss item: 0.3428483307361603
test loss item: 0.2298201024532318
test loss item: 0.6105896830558777
test loss item: 0.2833128273487091
test loss item: 0.4750601649284363
test loss item: 0.22305072844028473
test loss item: 0.17117653787136078
test loss item: 0.2590787410736084
test loss item: 0.3393717110157013
test loss item: 0.35265687108039856
test loss item: 0.206001877784729
test loss item: 0.20493285357952118
test loss item: 0.26435914635658264
test loss item: 0.3022944927215576
test loss item: 0.42907315492630005
test loss item: 0.38119131326675415
test loss item: 0.36955583095550537
test loss item: 0.6738674640655518
test loss item: 0.3190270960330963
test loss item: 0.19770286977291107
test loss item: 0.23967595398426056
test loss item: 0.3485738933086395
test loss item: 0.22463522851467133
test loss item: 0.41886553168296814
test loss item: 0.25472524762153625
test loss item: 0.22606755793094635
test loss item: 0.5007068514823914
test loss item: 0.3823719322681427
test loss item: 0.24185961484909058
test loss item: 0.2930935025215149
test loss item: 0.2187051773071289
test loss item: 0.5284643173217773
test loss item: 0.23644667863845825
test loss item: 0.36500951647758484
test loss item: 0.38949742913246155
test loss item: 0.2604151964187622
test loss item: 0.1401842087507248
test loss item: 0.7367886304855347
test loss item: 0.21407701075077057
test loss item: 0.48207220435142517
test loss item: 0.6250508427619934
test loss item: 0.19647076725959778
test loss item: 0.12782102823257446
test loss item: 0.18004202842712402
Epoch [2/50], Training Loss: 0.5203, Testing Loss: 0.3256
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/50
train loss item: 0.5393073558807373
train loss item: 0.37026771903038025
train loss item: 0.24788515269756317
train loss item: 0.41281819343566895
train loss item: 0.2681031823158264
train loss item: 0.24137426912784576
train loss item: 0.3125859797000885
train loss item: 0.387481153011322
train loss item: 0.19752901792526245
train loss item: 0.323188841342926
train loss item: 0.22378413379192352
train loss item: 0.570470929145813
train loss item: 0.3141983151435852
train loss item: 0.20689930021762848
train loss item: 0.40412047505378723
train loss item: 0.9049418568611145
train loss item: 0.27877381443977356
train loss item: 1.2179837226867676
train loss item: 0.6031314134597778
train loss item: 0.4819824993610382
train loss item: 0.23484845459461212
train loss item: 0.2489413470029831
train loss item: 0.3137591481208801
train loss item: 0.22292646765708923
train loss item: 0.16673439741134644
train loss item: 0.5971180200576782
train loss item: 0.1543111354112625
train loss item: 1.2026201486587524
train loss item: 0.2473420649766922
train loss item: 0.1368510127067566
train loss item: 1.0238720178604126
train loss item: 0.2703191041946411
train loss item: 0.31447339057922363
train loss item: 0.40621447563171387
train loss item: 0.2848120331764221
train loss item: 0.2473238706588745
train loss item: 0.22256380319595337
train loss item: 0.11141793429851532
train loss item: 0.8421390056610107
train loss item: 0.17228589951992035
train loss item: 0.13960134983062744
train loss item: 0.3064326047897339
train loss item: 0.3814127445220947
train loss item: 2.0761661529541016
train loss item: 0.29822099208831787
test loss item: 0.146224707365036
test loss item: 0.3002369999885559
test loss item: 0.22586296498775482
test loss item: 0.5330710411071777
test loss item: 0.26874497532844543
test loss item: 0.38916587829589844
test loss item: 0.18889181315898895
test loss item: 0.14602574706077576
test loss item: 0.23958048224449158
test loss item: 0.31441178917884827
test loss item: 0.3237226903438568
test loss item: 0.20532336831092834
test loss item: 0.17143487930297852
test loss item: 0.2344226837158203
test loss item: 0.2810314893722534
test loss item: 0.35330167412757874
test loss item: 0.33411887288093567
test loss item: 0.3375808298587799
test loss item: 0.5875075459480286
test loss item: 0.2796597182750702
test loss item: 0.16130013763904572
test loss item: 0.20683622360229492
test loss item: 0.325713187456131
test loss item: 0.2040078490972519
test loss item: 0.39006444811820984
test loss item: 0.2501714825630188
test loss item: 0.17708425223827362
test loss item: 0.42995700240135193
test loss item: 0.3500179052352905
test loss item: 0.2126748412847519
test loss item: 0.2761983275413513
test loss item: 0.17448557913303375
test loss item: 0.41602736711502075
test loss item: 0.20407144725322723
test loss item: 0.3154667317867279
test loss item: 0.33925923705101013
test loss item: 0.2375837117433548
test loss item: 0.1135871484875679
test loss item: 0.5986781120300293
test loss item: 0.19461461901664734
test loss item: 0.4081859886646271
test loss item: 0.5371807217597961
test loss item: 0.18453830480575562
test loss item: 0.08251414448022842
test loss item: 0.14483410120010376
Epoch [3/50], Training Loss: 0.4251, Testing Loss: 0.2843
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/50
train loss item: 0.4897162914276123
train loss item: 0.31413033604621887
train loss item: 0.20648349821567535
train loss item: 0.3144131302833557
train loss item: 0.1956438422203064
train loss item: 0.19273518025875092
train loss item: 0.2651529014110565
train loss item: 0.3908151388168335
train loss item: 0.14927053451538086
train loss item: 0.2569388151168823
train loss item: 0.16874898970127106
train loss item: 0.47656917572021484
train loss item: 0.24369961023330688
train loss item: 0.17415961623191833
train loss item: 0.31812718510627747
train loss item: 0.7173968553543091
train loss item: 0.25664207339286804
train loss item: 1.0270237922668457
train loss item: 0.6272668838500977
train loss item: 0.450464129447937
train loss item: 0.19669915735721588
train loss item: 0.18399785459041595
train loss item: 0.27988311648368835
train loss item: 0.18423420190811157
train loss item: 0.15186072885990143
train loss item: 0.5366824865341187
train loss item: 0.13888053596019745
train loss item: 1.0072901248931885
train loss item: 0.21672020852565765
train loss item: 0.1150289848446846
train loss item: 0.8523637056350708
train loss item: 0.26492443680763245
train loss item: 0.2583729326725006
train loss item: 0.27793997526168823
train loss item: 0.278328537940979
train loss item: 0.1758606880903244
train loss item: 0.17133638262748718
train loss item: 0.10860730707645416
train loss item: 0.7406320571899414
train loss item: 0.13871027529239655
train loss item: 0.11138875037431717
train loss item: 0.21881966292858124
train loss item: 0.41013458371162415
train loss item: 1.7850593328475952
train loss item: 0.3595987856388092
test loss item: 0.17625464498996735
test loss item: 0.2644307613372803
test loss item: 0.287316232919693
test loss item: 0.43765518069267273
test loss item: 0.23692159354686737
test loss item: 0.35572633147239685
test loss item: 0.16550743579864502
test loss item: 0.17594894766807556
test loss item: 0.2056770771741867
test loss item: 0.26752668619155884
test loss item: 0.2609396278858185
test loss item: 0.20183952152729034
test loss item: 0.15445998311042786
test loss item: 0.25819599628448486
test loss item: 0.26541656255722046
test loss item: 0.30201852321624756
test loss item: 0.2786847651004791
test loss item: 0.30218836665153503
test loss item: 0.488050252199173
test loss item: 0.2763323485851288
test loss item: 0.1487741768360138
test loss item: 0.1687401980161667
test loss item: 0.24797189235687256
test loss item: 0.16547518968582153
test loss item: 0.32480767369270325
test loss item: 0.2160690724849701
test loss item: 0.17131231725215912
test loss item: 0.3734331429004669
test loss item: 0.3096332550048828
test loss item: 0.19569915533065796
test loss item: 0.2329225093126297
test loss item: 0.15789364278316498
test loss item: 0.36115169525146484
test loss item: 0.18553893268108368
test loss item: 0.2545834481716156
test loss item: 0.26789912581443787
test loss item: 0.20070189237594604
test loss item: 0.11962175369262695
test loss item: 0.4453712999820709
test loss item: 0.2536574900150299
test loss item: 0.34859004616737366
test loss item: 0.4426787495613098
test loss item: 0.1755906045436859
test loss item: 0.09417106211185455
test loss item: 0.173434317111969
Epoch [4/50], Training Loss: 0.3644, Testing Loss: 0.2533
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/50
train loss item: 0.37009596824645996
train loss item: 0.2531362473964691
train loss item: 0.1522209197282791
train loss item: 0.2980888783931732
train loss item: 0.19421829283237457
train loss item: 0.19021964073181152
train loss item: 0.20453685522079468
train loss item: 0.43769630789756775
train loss item: 0.14116603136062622
train loss item: 0.2747739851474762
train loss item: 0.1614067554473877
train loss item: 0.4163457751274109
train loss item: 0.18245656788349152
train loss item: 0.17019231617450714
train loss item: 0.30869799852371216
train loss item: 0.5902789235115051
train loss item: 0.22806796431541443
train loss item: 0.8547470569610596
train loss item: 0.4695347845554352
train loss item: 0.27664703130722046
train loss item: 0.1420029252767563
train loss item: 0.2111431062221527
train loss item: 0.22597302496433258
train loss item: 0.19986818730831146
train loss item: 0.1279294490814209
train loss item: 0.5150712728500366
train loss item: 0.11983919143676758
train loss item: 0.7616610527038574
train loss item: 0.16498444974422455
train loss item: 0.09749317914247513
train loss item: 0.6706580519676208
train loss item: 0.2301790714263916
train loss item: 0.2482648491859436
train loss item: 0.3263269066810608
train loss item: 0.2514510452747345
train loss item: 0.14863720536231995
train loss item: 0.15236027538776398
train loss item: 0.09234657883644104
train loss item: 0.8302199244499207
train loss item: 0.1565205454826355
train loss item: 0.10602571070194244
train loss item: 0.2870694398880005
train loss item: 0.33907565474510193
train loss item: 1.642812728881836
train loss item: 0.32124772667884827
test loss item: 0.14779426157474518
test loss item: 0.22123053669929504
test loss item: 0.2003275752067566
test loss item: 0.4665570855140686
test loss item: 0.190566286444664
test loss item: 0.3184684216976166
test loss item: 0.12331170588731766
test loss item: 0.13545353710651398
test loss item: 0.16447392106056213
test loss item: 0.24017180502414703
test loss item: 0.2010878622531891
test loss item: 0.15544576942920685
test loss item: 0.13019196689128876
test loss item: 0.19522252678871155
test loss item: 0.19547909498214722
test loss item: 0.2928146719932556
test loss item: 0.20355944335460663
test loss item: 0.24650365114212036
test loss item: 0.4299388825893402
test loss item: 0.20777378976345062
test loss item: 0.1553778499364853
test loss item: 0.14263759553432465
test loss item: 0.17981594800949097
test loss item: 0.1380906105041504
test loss item: 0.2680199444293976
test loss item: 0.1568726748228073
test loss item: 0.14690271019935608
test loss item: 0.2941405177116394
test loss item: 0.2599181830883026
test loss item: 0.14649231731891632
test loss item: 0.18106940388679504
test loss item: 0.13466012477874756
test loss item: 0.3194475769996643
test loss item: 0.15155170857906342
test loss item: 0.21468546986579895
test loss item: 0.2817840874195099
test loss item: 0.1729176789522171
test loss item: 0.11792728304862976
test loss item: 0.37450480461120605
test loss item: 0.18684622645378113
test loss item: 0.3380759060382843
test loss item: 0.39764976501464844
test loss item: 0.14572279155254364
test loss item: 0.10850152373313904
test loss item: 0.18361926078796387
Epoch [5/50], Training Loss: 0.3232, Testing Loss: 0.2147
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/50
train loss item: 0.3704867362976074
train loss item: 0.28612861037254333
train loss item: 0.18314382433891296
train loss item: 0.2349981963634491
train loss item: 0.19215382635593414
train loss item: 0.16335855424404144
train loss item: 0.2739008069038391
train loss item: 0.5320641398429871
train loss item: 0.16620898246765137
train loss item: 0.21116818487644196
train loss item: 0.15984420478343964
train loss item: 0.6287740468978882
train loss item: 0.17890961468219757
train loss item: 0.14989367127418518
train loss item: 0.2616206109523773
train loss item: 0.43685394525527954
train loss item: 0.33246326446533203
train loss item: 0.6694057583808899
train loss item: 0.6557824611663818
train loss item: 0.41367748379707336
train loss item: 0.3033978044986725
train loss item: 0.26000887155532837
train loss item: 0.22557979822158813
train loss item: 0.18964402377605438
train loss item: 0.1539917290210724
train loss item: 0.563402533531189
train loss item: 0.1766425222158432
train loss item: 0.8635500073432922
train loss item: 0.2371762990951538
train loss item: 0.14641742408275604
train loss item: 0.807615339756012
train loss item: 0.2647928297519684
train loss item: 0.3737647533416748
train loss item: 0.27593234181404114
train loss item: 0.23315444588661194
train loss item: 0.16843488812446594
train loss item: 0.20727890729904175
train loss item: 0.09448844939470291
train loss item: 0.5830731987953186
train loss item: 0.20598545670509338
train loss item: 0.11026939749717712
train loss item: 0.22345198690891266
train loss item: 0.2790948450565338
train loss item: 1.4111433029174805
train loss item: 0.2504265308380127
test loss item: 0.14158995449543
test loss item: 0.24673286080360413
test loss item: 0.18141010403633118
test loss item: 0.5417452454566956
test loss item: 0.2125459760427475
test loss item: 0.36206915974617004
test loss item: 0.15803442895412445
test loss item: 0.14793188869953156
test loss item: 0.18241530656814575
test loss item: 0.28453540802001953
test loss item: 0.2322719544172287
test loss item: 0.15479758381843567
test loss item: 0.13954728841781616
test loss item: 0.18997319042682648
test loss item: 0.2184808999300003
test loss item: 0.31171488761901855
test loss item: 0.2107406109571457
test loss item: 0.2505902051925659
test loss item: 0.4913616478443146
test loss item: 0.20709750056266785
test loss item: 0.14556875824928284
test loss item: 0.14553408324718475
test loss item: 0.24313688278198242
test loss item: 0.1449020951986313
test loss item: 0.30432918667793274
test loss item: 0.16619333624839783
test loss item: 0.1546631157398224
test loss item: 0.32621628046035767
test loss item: 0.2883223593235016
test loss item: 0.17558147013187408
test loss item: 0.2044137567281723
test loss item: 0.1619306057691574
test loss item: 0.3802317976951599
test loss item: 0.1983601301908493
test loss item: 0.22601144015789032
test loss item: 0.3693528473377228
test loss item: 0.24109488725662231
test loss item: 0.11179845780134201
test loss item: 0.4230360686779022
test loss item: 0.15579074621200562
test loss item: 0.3773745000362396
test loss item: 0.4341104030609131
test loss item: 0.15852157771587372
test loss item: 0.0983748733997345
test loss item: 0.11923921853303909
Epoch [6/50], Training Loss: 0.3358, Testing Loss: 0.2360
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/50
train loss item: 0.2629103660583496
train loss item: 0.19943471252918243
train loss item: 0.14744463562965393
train loss item: 0.19292187690734863
train loss item: 0.16797985136508942
train loss item: 0.16578581929206848
train loss item: 0.27998772263526917
train loss item: 0.27342721819877625
train loss item: 0.11192652583122253
train loss item: 0.16936306655406952
train loss item: 0.1379067301750183
train loss item: 0.33625441789627075
train loss item: 0.17126595973968506
train loss item: 0.12481985986232758
train loss item: 0.24340549111366272
train loss item: 0.40787988901138306
train loss item: 0.22290873527526855
train loss item: 0.5980804562568665
train loss item: 0.49156203866004944
train loss item: 0.19003070890903473
train loss item: 0.13895244896411896
train loss item: 0.1516721546649933
train loss item: 0.2506973445415497
train loss item: 0.16957662999629974
train loss item: 0.09974518418312073
train loss item: 0.351901650428772
train loss item: 0.10629034787416458
train loss item: 0.5380032658576965
train loss item: 0.14812630414962769
train loss item: 0.08572030067443848
train loss item: 0.4765778183937073
train loss item: 0.22669461369514465
train loss item: 0.15618982911109924
train loss item: 0.195711150765419
train loss item: 0.17145413160324097
train loss item: 0.11921054124832153
train loss item: 0.1359882354736328
train loss item: 0.07826507091522217
train loss item: 0.6462913751602173
train loss item: 0.1130099818110466
train loss item: 0.09457623213529587
train loss item: 0.18846562504768372
train loss item: 0.31950974464416504
train loss item: 1.1430742740631104
train loss item: 0.2951463758945465
test loss item: 0.13386604189872742
test loss item: 0.25746360421180725
test loss item: 0.19813765585422516
test loss item: 0.33553290367126465
test loss item: 0.1862456500530243
test loss item: 0.3608108460903168
test loss item: 0.1282568722963333
test loss item: 0.13319776952266693
test loss item: 0.16646666824817657
test loss item: 0.20235849916934967
test loss item: 0.20200257003307343
test loss item: 0.17641529440879822
test loss item: 0.11876370012760162
test loss item: 0.18151158094406128
test loss item: 0.19618384540081024
test loss item: 0.2955976128578186
test loss item: 0.2265481799840927
test loss item: 0.23804786801338196
test loss item: 0.47061917185783386
test loss item: 0.20147112011909485
test loss item: 0.13817958533763885
test loss item: 0.12833282351493835
test loss item: 0.1984097957611084
test loss item: 0.1683875024318695
test loss item: 0.2719263732433319
test loss item: 0.15478570759296417
test loss item: 0.13764020800590515
test loss item: 0.35045844316482544
test loss item: 0.2449112832546234
test loss item: 0.14869581162929535
test loss item: 0.17273464798927307
test loss item: 0.12807150185108185
test loss item: 0.3687584400177002
test loss item: 0.15199874341487885
test loss item: 0.21165800094604492
test loss item: 0.20402313768863678
test loss item: 0.18909026682376862
test loss item: 0.12388072162866592
test loss item: 0.5676348805427551
test loss item: 0.17909620702266693
test loss item: 0.33363914489746094
test loss item: 0.44237571954727173
test loss item: 0.14734408259391785
test loss item: 0.07340683043003082
test loss item: 0.13038522005081177
Epoch [7/50], Training Loss: 0.2510, Testing Loss: 0.2172
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/50
train loss item: 0.261271208524704
train loss item: 0.19946733117103577
train loss item: 0.13846908509731293
train loss item: 0.23080991208553314
train loss item: 0.14915619790554047
train loss item: 0.1354983001947403
train loss item: 0.17040547728538513
train loss item: 0.41830599308013916
train loss item: 0.11529459059238434
train loss item: 0.22823210060596466
train loss item: 0.1444873809814453
train loss item: 0.4246535003185272
train loss item: 0.17093877494335175
train loss item: 0.11525049805641174
train loss item: 0.21981707215309143
train loss item: 0.37918001413345337
train loss item: 0.1784096658229828
train loss item: 0.46972939372062683
train loss item: 0.48255565762519836
train loss item: 0.30452319979667664
train loss item: 0.17718620598316193
train loss item: 0.22294877469539642
train loss item: 0.2254335582256317
train loss item: 0.18030160665512085
train loss item: 0.11810288578271866
train loss item: 0.46292972564697266
train loss item: 0.12823040783405304
train loss item: 0.6725529432296753
train loss item: 0.19556865096092224
train loss item: 0.09984441846609116
train loss item: 0.5914117693901062
train loss item: 0.17095665633678436
train loss item: 0.19879624247550964
train loss item: 0.24814732372760773
train loss item: 0.20532777905464172
train loss item: 0.17032459378242493
train loss item: 0.15104998648166656
train loss item: 0.0796000212430954
train loss item: 0.5874409079551697
train loss item: 0.13659706711769104
train loss item: 0.12615148723125458
train loss item: 0.2257031351327896
train loss item: 0.31328535079956055
train loss item: 1.0885984897613525
train loss item: 0.21511626243591309
test loss item: 0.099223293364048
test loss item: 0.19534100592136383
test loss item: 0.11527284234762192
test loss item: 0.3693181872367859
test loss item: 0.17608459293842316
test loss item: 0.2841672897338867
test loss item: 0.1574288159608841
test loss item: 0.0913684219121933
test loss item: 0.13171130418777466
test loss item: 0.2121117115020752
test loss item: 0.16687197983264923
test loss item: 0.12103884667158127
test loss item: 0.10755971819162369
test loss item: 0.13216347992420197
test loss item: 0.15815754234790802
test loss item: 0.2404954433441162
test loss item: 0.16534125804901123
test loss item: 0.2105712592601776
test loss item: 0.3670577108860016
test loss item: 0.148954838514328
test loss item: 0.13027502596378326
test loss item: 0.12000345438718796
test loss item: 0.1709456443786621
test loss item: 0.13999730348587036
test loss item: 0.24044042825698853
test loss item: 0.1517016887664795
test loss item: 0.10972090810537338
test loss item: 0.2573085427284241
test loss item: 0.20665784180164337
test loss item: 0.14804939925670624
test loss item: 0.15782050788402557
test loss item: 0.13269680738449097
test loss item: 0.26501983404159546
test loss item: 0.13778454065322876
test loss item: 0.19326500594615936
test loss item: 0.22619971632957458
test loss item: 0.16177313029766083
test loss item: 0.09897489100694656
test loss item: 0.30543944239616394
test loss item: 0.10999572277069092
test loss item: 0.27164092659950256
test loss item: 0.3355948328971863
test loss item: 0.12139030545949936
test loss item: 0.0515238419175148
test loss item: 0.14429138600826263
Epoch [8/50], Training Loss: 0.2651, Testing Loss: 0.1786
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/50
train loss item: 0.31130707263946533
train loss item: 0.19139131903648376
train loss item: 0.1378507763147354
train loss item: 0.16726019978523254
train loss item: 0.1710727959871292
train loss item: 0.14385272562503815
train loss item: 0.2261064350605011
train loss item: 0.3310890197753906
train loss item: 0.1353982537984848
train loss item: 0.16871792078018188
train loss item: 0.1534840166568756
train loss item: 0.4770488142967224
train loss item: 0.1700722873210907
train loss item: 0.12079021334648132
train loss item: 0.19702786207199097
train loss item: 0.38499152660369873
train loss item: 0.28098732233047485
train loss item: 0.41071441769599915
train loss item: 0.5539953708648682
train loss item: 0.2916272282600403
train loss item: 0.2139626443386078
train loss item: 0.11973587423563004
train loss item: 0.2160974144935608
train loss item: 0.14040014147758484
train loss item: 0.10926470905542374
train loss item: 0.3920300304889679
train loss item: 0.12671782076358795
train loss item: 0.6348101496696472
train loss item: 0.1870463639497757
train loss item: 0.09222724288702011
train loss item: 0.503287672996521
train loss item: 0.18054485321044922
train loss item: 0.14654888212680817
train loss item: 0.17320828139781952
train loss item: 0.1877397745847702
train loss item: 0.11144924908876419
train loss item: 0.1660364717245102
train loss item: 0.08838730305433273
train loss item: 0.5646113157272339
train loss item: 0.12188975512981415
train loss item: 0.09115153551101685
train loss item: 0.1946977823972702
train loss item: 0.3388516306877136
train loss item: 0.9566274881362915
train loss item: 0.24464763700962067
test loss item: 0.13326241075992584
test loss item: 0.31829920411109924
test loss item: 0.19143584370613098
test loss item: 0.37147244811058044
test loss item: 0.23801560699939728
test loss item: 0.46999096870422363
test loss item: 0.1352572739124298
test loss item: 0.13993728160858154
test loss item: 0.19075030088424683
test loss item: 0.2018410861492157
test loss item: 0.23167838156223297
test loss item: 0.16494831442832947
test loss item: 0.12706877291202545
test loss item: 0.18761396408081055
test loss item: 0.21666759252548218
test loss item: 0.3945191204547882
test loss item: 0.27623701095581055
test loss item: 0.3067295551300049
test loss item: 0.6068421006202698
test loss item: 0.2256857454776764
test loss item: 0.12315766513347626
test loss item: 0.15525434911251068
test loss item: 0.2234184592962265
test loss item: 0.15347017347812653
test loss item: 0.34987592697143555
test loss item: 0.18062762916088104
test loss item: 0.14522291719913483
test loss item: 0.46203944087028503
test loss item: 0.2829326093196869
test loss item: 0.15702447295188904
test loss item: 0.2253122627735138
test loss item: 0.12112388014793396
test loss item: 0.4420587122440338
test loss item: 0.1560841202735901
test loss item: 0.2548307180404663
test loss item: 0.21000824868679047
test loss item: 0.17675213515758514
test loss item: 0.11647606641054153
test loss item: 0.7637439966201782
test loss item: 0.16115356981754303
test loss item: 0.4219945967197418
test loss item: 0.5840011835098267
test loss item: 0.1443052440881729
test loss item: 0.09107307344675064
test loss item: 0.12010380625724792
Epoch [9/50], Training Loss: 0.2517, Testing Loss: 0.2522
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/50
train loss item: 0.315762460231781
train loss item: 0.21976874768733978
train loss item: 0.13234320282936096
train loss item: 0.22612839937210083
train loss item: 0.18335960805416107
train loss item: 0.17845892906188965
train loss item: 0.30827003717422485
train loss item: 0.34008726477622986
train loss item: 0.12574402987957
train loss item: 0.19080013036727905
train loss item: 0.13382311165332794
train loss item: 0.6459591388702393
train loss item: 0.20973524451255798
train loss item: 0.16793206334114075
train loss item: 0.20440512895584106
train loss item: 0.5592594146728516
train loss item: 0.19054029881954193
train loss item: 0.3956698179244995
train loss item: 0.6296862363815308
train loss item: 0.49519601464271545
train loss item: 0.37678614258766174
train loss item: 0.23240099847316742
train loss item: 0.43937647342681885
train loss item: 0.21625465154647827
train loss item: 0.1162428930401802
train loss item: 0.3237399458885193
train loss item: 0.1317378729581833
train loss item: 0.7038212418556213
train loss item: 0.2089279443025589
train loss item: 0.12856723368167877
train loss item: 0.8555094599723816
train loss item: 0.23031416535377502
train loss item: 0.30953437089920044
train loss item: 0.19941964745521545
train loss item: 0.1902802735567093
train loss item: 0.14783398807048798
train loss item: 0.20809222757816315
train loss item: 0.1068788468837738
train loss item: 0.4610536992549896
train loss item: 0.245075061917305
train loss item: 0.13859762251377106
train loss item: 0.21106185019016266
train loss item: 0.4795286953449249
train loss item: 0.8410758972167969
train loss item: 0.19869187474250793
test loss item: 0.2174210101366043
test loss item: 0.2725529074668884
test loss item: 0.2549459934234619
test loss item: 0.6419954299926758
test loss item: 0.264100581407547
test loss item: 0.3672637343406677
test loss item: 0.19655576348304749
test loss item: 0.22868479788303375
test loss item: 0.21134327352046967
test loss item: 0.2954942286014557
test loss item: 0.26472190022468567
test loss item: 0.20256811380386353
test loss item: 0.18483352661132812
test loss item: 0.2521101236343384
test loss item: 0.27470216155052185
test loss item: 0.40336617827415466
test loss item: 0.25973621010780334
test loss item: 0.3080412447452545
test loss item: 0.4901212453842163
test loss item: 0.26929935812950134
test loss item: 0.1713801473379135
test loss item: 0.17738287150859833
test loss item: 0.26212364435195923
test loss item: 0.17499086260795593
test loss item: 0.33807533979415894
test loss item: 0.23002572357654572
test loss item: 0.1818200796842575
test loss item: 0.36567437648773193
test loss item: 0.3200864791870117
test loss item: 0.2182134985923767
test loss item: 0.25765904784202576
test loss item: 0.18829287588596344
test loss item: 0.3600148558616638
test loss item: 0.22274662554264069
test loss item: 0.2871955335140228
test loss item: 0.4353511333465576
test loss item: 0.26374658942222595
test loss item: 0.17020471394062042
test loss item: 0.4131988286972046
test loss item: 0.20628224313259125
test loss item: 0.4082085192203522
test loss item: 0.4620025157928467
test loss item: 0.1860796958208084
test loss item: 0.17612016201019287
test loss item: 0.12444421648979187
Epoch [10/50], Training Loss: 0.3012, Testing Loss: 0.2769
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 11/50
train loss item: 0.2597608268260956
train loss item: 0.25168925523757935
train loss item: 0.20514465868473053
train loss item: 0.3091837167739868
train loss item: 0.2117544710636139
train loss item: 0.15438644587993622
train loss item: 0.19882473349571228
train loss item: 0.25162339210510254
train loss item: 0.09556900709867477
train loss item: 0.19355081021785736
train loss item: 0.15822014212608337
train loss item: 0.3486797511577606
train loss item: 0.1600438952445984
train loss item: 0.13343815505504608
train loss item: 0.1832808554172516
train loss item: 0.3962872326374054
train loss item: 0.21077315509319305
train loss item: 0.36051517724990845
train loss item: 0.2621730864048004
train loss item: 0.18357624113559723
train loss item: 0.13985836505889893
train loss item: 0.15989847481250763
train loss item: 0.1678890734910965
train loss item: 0.20626093447208405
train loss item: 0.13292226195335388
train loss item: 0.40268900990486145
train loss item: 0.08947509527206421
train loss item: 0.4417487382888794
train loss item: 0.15564048290252686
train loss item: 0.08435571938753128
train loss item: 0.43847355246543884
train loss item: 0.149409681558609
train loss item: 0.1389189511537552
train loss item: 0.14334870874881744
train loss item: 0.132684126496315
train loss item: 0.09664566069841385
train loss item: 0.13381868600845337
train loss item: 0.08089128881692886
train loss item: 0.4905529022216797
train loss item: 0.10002925992012024
train loss item: 0.08163940161466599
train loss item: 0.16019849479198456
train loss item: 0.41323041915893555
train loss item: 0.7969711422920227
train loss item: 0.25238069891929626
test loss item: 0.08678183704614639
test loss item: 0.17682527005672455
test loss item: 0.11459966748952866
test loss item: 0.2853323519229889
test loss item: 0.15446558594703674
test loss item: 0.2325364500284195
test loss item: 0.10517805814743042
test loss item: 0.08097430318593979
test loss item: 0.13372904062271118
test loss item: 0.17119146883487701
test loss item: 0.16411744058132172
test loss item: 0.11822713911533356
test loss item: 0.09805746376514435
test loss item: 0.12642429769039154
test loss item: 0.14672715961933136
test loss item: 0.19939611852169037
test loss item: 0.15899302065372467
test loss item: 0.187982976436615
test loss item: 0.3007547855377197
test loss item: 0.14661580324172974
test loss item: 0.11043711006641388
test loss item: 0.11570555716753006
test loss item: 0.17219404876232147
test loss item: 0.13152265548706055
test loss item: 0.2024533897638321
test loss item: 0.13206738233566284
test loss item: 0.10954465717077255
test loss item: 0.22798573970794678
test loss item: 0.17831361293792725
test loss item: 0.11615113914012909
test loss item: 0.1537197232246399
test loss item: 0.10237877815961838
test loss item: 0.22270648181438446
test loss item: 0.1252065747976303
test loss item: 0.1575448215007782
test loss item: 0.18586108088493347
test loss item: 0.1689308136701584
test loss item: 0.08766622841358185
test loss item: 0.2854635417461395
test loss item: 0.10466980189085007
test loss item: 0.21410107612609863
test loss item: 0.27496400475502014
test loss item: 0.11565716564655304
test loss item: 0.049426622688770294
test loss item: 0.10711240768432617
Epoch [11/50], Training Loss: 0.2249, Testing Loss: 0.1565
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 12/50
train loss item: 0.3436008393764496
train loss item: 0.16941313445568085
train loss item: 0.11813924461603165
train loss item: 0.2629832625389099
train loss item: 0.18479378521442413
train loss item: 0.16727736592292786
train loss item: 0.21902959048748016
train loss item: 0.3150556981563568
train loss item: 0.09363129734992981
train loss item: 0.15639245510101318
train loss item: 0.12340131402015686
train loss item: 0.3900235593318939
train loss item: 0.15865661203861237
train loss item: 0.10670483857393265
train loss item: 0.19438861310482025
train loss item: 0.340000182390213
train loss item: 0.2122012823820114
train loss item: 0.34090885519981384
train loss item: 0.29425424337387085
train loss item: 0.1418818235397339
train loss item: 0.14984916150569916
train loss item: 0.11935196816921234
train loss item: 0.23522306978702545
train loss item: 0.14109164476394653
train loss item: 0.09077344089746475
train loss item: 0.3668143153190613
train loss item: 0.09303291887044907
train loss item: 0.5731610059738159
train loss item: 0.14026227593421936
train loss item: 0.0803268551826477
train loss item: 0.4270820915699005
train loss item: 0.17592597007751465
train loss item: 0.14720240235328674
train loss item: 0.15247583389282227
train loss item: 0.16050779819488525
train loss item: 0.10222151130437851
train loss item: 0.1474224030971527
train loss item: 0.06492916494607925
train loss item: 0.4716338813304901
train loss item: 0.11774097383022308
train loss item: 0.09526047855615616
train loss item: 0.19241400063037872
train loss item: 0.32627996802330017
train loss item: 0.7108134627342224
train loss item: 0.21364744007587433
test loss item: 0.09817904978990555
test loss item: 0.18633010983467102
test loss item: 0.13035961985588074
test loss item: 0.29875412583351135
test loss item: 0.17549970746040344
test loss item: 0.2570352256298065
test loss item: 0.12653397023677826
test loss item: 0.09435141086578369
test loss item: 0.14350482821464539
test loss item: 0.18615278601646423
test loss item: 0.17610666155815125
test loss item: 0.13182225823402405
test loss item: 0.11177951842546463
test loss item: 0.14519906044006348
test loss item: 0.1688375473022461
test loss item: 0.23216821253299713
test loss item: 0.1732536107301712
test loss item: 0.21545040607452393
test loss item: 0.32875582575798035
test loss item: 0.1620362102985382
test loss item: 0.11102358251810074
test loss item: 0.12173646688461304
test loss item: 0.18691407144069672
test loss item: 0.14277338981628418
test loss item: 0.2320476472377777
test loss item: 0.15551970899105072
test loss item: 0.1229533925652504
test loss item: 0.2649248242378235
test loss item: 0.18598388135433197
test loss item: 0.1389986276626587
test loss item: 0.16906531155109406
test loss item: 0.11678092181682587
test loss item: 0.2276400774717331
test loss item: 0.1363641768693924
test loss item: 0.17587631940841675
test loss item: 0.20213806629180908
test loss item: 0.18270061910152435
test loss item: 0.09975455701351166
test loss item: 0.30513060092926025
test loss item: 0.11725737154483795
test loss item: 0.23077258467674255
test loss item: 0.3059195876121521
test loss item: 0.13757576048374176
test loss item: 0.06048884242773056
test loss item: 0.10602082312107086
Epoch [12/50], Training Loss: 0.2184, Testing Loss: 0.1729
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 13/50
train loss item: 0.2910420596599579
train loss item: 0.15877144038677216
train loss item: 0.12234341353178024
train loss item: 0.14384208619594574
train loss item: 0.17298515141010284
train loss item: 0.16664160788059235
train loss item: 0.2155485600233078
train loss item: 0.2589423358440399
train loss item: 0.09571362286806107
train loss item: 0.17834100127220154
train loss item: 0.12315195053815842
train loss item: 0.5033544898033142
train loss item: 0.17924617230892181
train loss item: 0.14839187264442444
train loss item: 0.20117737352848053
train loss item: 0.3463890552520752
train loss item: 0.13386166095733643
train loss item: 0.29867345094680786
train loss item: 0.3592480421066284
train loss item: 0.20929022133350372
train loss item: 0.21003638207912445
train loss item: 0.13231880962848663
train loss item: 0.31963708996772766
train loss item: 0.11624737828969955
train loss item: 0.13962136209011078
train loss item: 0.3279414474964142
train loss item: 0.09806430339813232
train loss item: 0.5378357768058777
train loss item: 0.16182376444339752
train loss item: 0.09326236695051193
train loss item: 0.38528120517730713
train loss item: 0.17384853959083557
train loss item: 0.16669219732284546
train loss item: 0.15085265040397644
train loss item: 0.19467169046401978
train loss item: 0.14457009732723236
train loss item: 0.15231025218963623
train loss item: 0.07184474170207977
train loss item: 0.4099063575267792
train loss item: 0.10211821645498276
train loss item: 0.09233379364013672
train loss item: 0.14259502291679382
train loss item: 0.2787097990512848
train loss item: 0.7112868428230286
train loss item: 0.18886536359786987
test loss item: 0.10444264113903046
test loss item: 0.16583608090877533
test loss item: 0.1271396428346634
test loss item: 0.3568113446235657
test loss item: 0.14866052567958832
test loss item: 0.22120659053325653
test loss item: 0.10690858215093613
test loss item: 0.09515443444252014
test loss item: 0.13994719088077545
test loss item: 0.17915970087051392
test loss item: 0.18002831935882568
test loss item: 0.13339078426361084
test loss item: 0.1257861852645874
test loss item: 0.1347571760416031
test loss item: 0.1614949107170105
test loss item: 0.2242528647184372
test loss item: 0.15787340700626373
test loss item: 0.1941753327846527
test loss item: 0.3031875193119049
test loss item: 0.16334529221057892
test loss item: 0.1257079690694809
test loss item: 0.11227976530790329
test loss item: 0.18654851615428925
test loss item: 0.14652976393699646
test loss item: 0.21549563109874725
test loss item: 0.14172278344631195
test loss item: 0.12866921722888947
test loss item: 0.2270534634590149
test loss item: 0.18672704696655273
test loss item: 0.13330277800559998
test loss item: 0.15196029841899872
test loss item: 0.11769437789916992
test loss item: 0.21752507984638214
test loss item: 0.13465283811092377
test loss item: 0.16084997355937958
test loss item: 0.2482050210237503
test loss item: 0.19289840757846832
test loss item: 0.10753825306892395
test loss item: 0.2899901866912842
test loss item: 0.12347859144210815
test loss item: 0.23970557749271393
test loss item: 0.28004857897758484
test loss item: 0.14673036336898804
test loss item: 0.06475655734539032
test loss item: 0.1244647279381752
Epoch [13/50], Training Loss: 0.2180, Testing Loss: 0.1695
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 14/50
train loss item: 0.26711392402648926
train loss item: 0.15414607524871826
train loss item: 0.11538377404212952
train loss item: 0.15810145437717438
train loss item: 0.1671290546655655
train loss item: 0.16078229248523712
train loss item: 0.23835067451000214
train loss item: 0.2607754170894623
train loss item: 0.07688786834478378
train loss item: 0.20825248956680298
train loss item: 0.11774411052465439
train loss item: 0.5423811674118042
train loss item: 0.20138798654079437
train loss item: 0.1843707263469696
train loss item: 0.229689359664917
train loss item: 0.614041805267334
train loss item: 0.18126055598258972
train loss item: 0.3149806261062622
train loss item: 0.3761225640773773
train loss item: 0.20977549254894257
train loss item: 0.2386295646429062
train loss item: 0.127570241689682
train loss item: 0.42533522844314575
train loss item: 0.12367073446512222
train loss item: 0.14343488216400146
train loss item: 0.2870579957962036
train loss item: 0.09171659499406815
train loss item: 0.40211138129234314
train loss item: 0.1542910486459732
train loss item: 0.10215942561626434
train loss item: 0.4641861021518707
train loss item: 0.14888061583042145
train loss item: 0.1738571673631668
train loss item: 0.18702824413776398
train loss item: 0.17644865810871124
train loss item: 0.13989366590976715
train loss item: 0.1310640126466751
train loss item: 0.06726893037557602
train loss item: 0.3662954270839691
train loss item: 0.11984489113092422
train loss item: 0.0838862955570221
train loss item: 0.1531880646944046
train loss item: 0.19796980917453766
train loss item: 0.6190711259841919
train loss item: 0.18392790853977203
test loss item: 0.10704734176397324
test loss item: 0.18838155269622803
test loss item: 0.12414871901273727
test loss item: 0.6166298389434814
test loss item: 0.1620321422815323
test loss item: 0.2648890018463135
test loss item: 0.12874898314476013
test loss item: 0.10112027078866959
test loss item: 0.14927120506763458
test loss item: 0.2432476133108139
test loss item: 0.21058301627635956
test loss item: 0.12738141417503357
test loss item: 0.13004441559314728
test loss item: 0.13496354222297668
test loss item: 0.16211895644664764
test loss item: 0.343945175409317
test loss item: 0.16263267397880554
test loss item: 0.1938135176897049
test loss item: 0.407200425863266
test loss item: 0.17499862611293793
test loss item: 0.13982164859771729
test loss item: 0.12810443341732025
test loss item: 0.1916898787021637
test loss item: 0.1387144774198532
test loss item: 0.25245943665504456
test loss item: 0.1340564489364624
test loss item: 0.13700076937675476
test loss item: 0.2448364496231079
test loss item: 0.237359419465065
test loss item: 0.14364053308963776
test loss item: 0.16842974722385406
test loss item: 0.13734275102615356
test loss item: 0.286772757768631
test loss item: 0.15922819077968597
test loss item: 0.20558927953243256
test loss item: 0.40188148617744446
test loss item: 0.22176684439182281
test loss item: 0.10897651314735413
test loss item: 0.3676464557647705
test loss item: 0.12138617038726807
test loss item: 0.34948602318763733
test loss item: 0.3729490637779236
test loss item: 0.14736133813858032
test loss item: 0.07436632364988327
test loss item: 0.11952079087495804
Epoch [14/50], Training Loss: 0.2242, Testing Loss: 0.2027
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 15/50
train loss item: 0.24766868352890015
train loss item: 0.20512676239013672
train loss item: 0.1277473121881485
train loss item: 0.1755506843328476
train loss item: 0.17564581334590912
train loss item: 0.14296363294124603
train loss item: 0.22769686579704285
train loss item: 0.23421259224414825
train loss item: 0.07137665897607803
train loss item: 0.1693924367427826
train loss item: 0.11683444678783417
train loss item: 0.45268064737319946
train loss item: 0.18357591331005096
train loss item: 0.1490146815776825
train loss item: 0.25207754969596863
train loss item: 0.27668049931526184
train loss item: 0.15526296198368073
train loss item: 0.2483738213777542
train loss item: 0.21501389145851135
train loss item: 0.1570596843957901
train loss item: 0.14010757207870483
train loss item: 0.15334992110729218
train loss item: 0.274236261844635
train loss item: 0.1766485571861267
train loss item: 0.12013185769319534
train loss item: 0.2907073497772217
train loss item: 0.07114449143409729
train loss item: 0.3552267551422119
train loss item: 0.10542935132980347
train loss item: 0.07490681856870651
train loss item: 0.3248549699783325
train loss item: 0.2533189058303833
train loss item: 0.1278231292963028
train loss item: 0.13901877403259277
train loss item: 0.1681373566389084
train loss item: 0.13444045186042786
train loss item: 0.10693012923002243
train loss item: 0.060836806893348694
train loss item: 0.45587795972824097
train loss item: 0.08449497073888779
train loss item: 0.07612680643796921
train loss item: 0.1424446702003479
train loss item: 0.14641033113002777
train loss item: 0.5411350727081299
train loss item: 0.23377805948257446
test loss item: 0.08686957508325577
test loss item: 0.14987176656723022
test loss item: 0.10087008774280548
test loss item: 0.34035736322402954
test loss item: 0.10854529589414597
test loss item: 0.2120468020439148
test loss item: 0.08576381206512451
test loss item: 0.07319457828998566
test loss item: 0.11171425133943558
test loss item: 0.14761841297149658
test loss item: 0.14602845907211304
test loss item: 0.10958999395370483
test loss item: 0.08839219808578491
test loss item: 0.09906794875860214
test loss item: 0.11432536691427231
test loss item: 0.2068399041891098
test loss item: 0.13246247172355652
test loss item: 0.14443062245845795
test loss item: 0.2850041091442108
test loss item: 0.12982216477394104
test loss item: 0.11615955829620361
test loss item: 0.09688249975442886
test loss item: 0.14256475865840912
test loss item: 0.12050056457519531
test loss item: 0.16977478563785553
test loss item: 0.09553801268339157
test loss item: 0.10401377081871033
test loss item: 0.19761371612548828
test loss item: 0.15794841945171356
test loss item: 0.09733767807483673
test loss item: 0.10782526433467865
test loss item: 0.09568891674280167
test loss item: 0.21262431144714355
test loss item: 0.1083439514040947
test loss item: 0.1428358405828476
test loss item: 0.22191187739372253
test loss item: 0.15541395545005798
test loss item: 0.09212960302829742
test loss item: 0.3190300762653351
test loss item: 0.10290288925170898
test loss item: 0.2240685373544693
test loss item: 0.25824716687202454
test loss item: 0.10262437909841537
test loss item: 0.049742791801691055
test loss item: 0.0984094962477684
Epoch [15/50], Training Loss: 0.1943, Testing Loss: 0.1436
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 16/50
train loss item: 0.23825109004974365
train loss item: 0.2715851366519928
train loss item: 0.11076126247644424
train loss item: 0.1579161435365677
train loss item: 0.15887576341629028
train loss item: 0.1409408152103424
train loss item: 0.2682288587093353
train loss item: 0.33226412534713745
train loss item: 0.09227050095796585
train loss item: 0.2054215669631958
train loss item: 0.0954180657863617
train loss item: 0.6570529341697693
train loss item: 0.21614404022693634
train loss item: 0.21893157064914703
train loss item: 0.26246756315231323
train loss item: 1.0313770771026611
train loss item: 0.29769185185432434
train loss item: 0.6990759968757629
train loss item: 0.38893547654151917
train loss item: 0.19446223974227905
train loss item: 0.30661824345588684
train loss item: 0.21078459918498993
train loss item: 0.5641102194786072
train loss item: 0.24712634086608887
train loss item: 0.16417627036571503
train loss item: 0.43529215455055237
train loss item: 0.1110890805721283
train loss item: 0.40008193254470825
train loss item: 0.17618249356746674
train loss item: 0.11512171477079391
train loss item: 0.6390982866287231
train loss item: 0.20048555731773376
train loss item: 0.2745361030101776
train loss item: 0.25196096301078796
train loss item: 0.1752239465713501
train loss item: 0.13742803037166595
train loss item: 0.13953259587287903
train loss item: 0.079330213367939
train loss item: 0.4542795717716217
train loss item: 0.21053217351436615
train loss item: 0.12400553375482559
train loss item: 0.20848491787910461
train loss item: 0.19526270031929016
train loss item: 0.5501319766044617
train loss item: 0.23422661423683167
test loss item: 0.10313185304403305
test loss item: 0.18433214724063873
test loss item: 0.12109693884849548
test loss item: 0.5970198512077332
test loss item: 0.12461048364639282
test loss item: 0.25914013385772705
test loss item: 0.116367407143116
test loss item: 0.09139588475227356
test loss item: 0.14387212693691254
test loss item: 0.23844978213310242
test loss item: 0.1947222650051117
test loss item: 0.12850995361804962
test loss item: 0.1293763518333435
test loss item: 0.12890741229057312
test loss item: 0.13662943243980408
test loss item: 0.31980931758880615
test loss item: 0.15924568474292755
test loss item: 0.17819319665431976
test loss item: 0.41060420870780945
test loss item: 0.1634097844362259
test loss item: 0.14430052042007446
test loss item: 0.11984328180551529
test loss item: 0.18102040886878967
test loss item: 0.13613653182983398
test loss item: 0.23571988940238953
test loss item: 0.11497646570205688
test loss item: 0.12504486739635468
test loss item: 0.2493535280227661
test loss item: 0.2475462704896927
test loss item: 0.1271713376045227
test loss item: 0.1417238861322403
test loss item: 0.13706813752651215
test loss item: 0.3066776692867279
test loss item: 0.15741944313049316
test loss item: 0.19597524404525757
test loss item: 0.38692209124565125
test loss item: 0.202633336186409
test loss item: 0.1062253937125206
test loss item: 0.42970582842826843
test loss item: 0.12662935256958008
test loss item: 0.3568151295185089
test loss item: 0.3761148750782013
test loss item: 0.13297781348228455
test loss item: 0.06737443804740906
test loss item: 0.17518660426139832
Epoch [16/50], Training Loss: 0.2810, Testing Loss: 0.1980
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 17/50
train loss item: 0.2369764745235443
train loss item: 0.313438355922699
train loss item: 0.17352695763111115
train loss item: 0.2356322854757309
train loss item: 0.1512034386396408
train loss item: 0.14321665465831757
train loss item: 0.3165290355682373
train loss item: 0.24881432950496674
train loss item: 0.08558256179094315
train loss item: 0.17201264202594757
train loss item: 0.10169894993305206
train loss item: 0.48520252108573914
train loss item: 0.17814117670059204
train loss item: 0.19366315007209778
train loss item: 0.24166160821914673
train loss item: 0.5380905270576477
train loss item: 0.27515071630477905
train loss item: 0.36906611919403076
train loss item: 0.41388440132141113
train loss item: 0.18398621678352356
train loss item: 0.1862463802099228
train loss item: 0.1802724301815033
train loss item: 0.3532998263835907
train loss item: 0.1589207798242569
train loss item: 0.12021178007125854
train loss item: 0.45193159580230713
train loss item: 0.09351645410060883
train loss item: 0.3486708104610443
train loss item: 0.12232038378715515
train loss item: 0.08554015308618546
train loss item: 0.4334695041179657
train loss item: 0.12541866302490234
train loss item: 0.18564356863498688
train loss item: 0.23760612308979034
train loss item: 0.14701877534389496
train loss item: 0.11685962975025177
train loss item: 0.129193514585495
train loss item: 0.07454678416252136
train loss item: 0.3984174430370331
train loss item: 0.13728195428848267
train loss item: 0.0940280333161354
train loss item: 0.1848488450050354
train loss item: 0.2241101861000061
train loss item: 0.4955463707447052
train loss item: 0.2053270787000656
test loss item: 0.10603068023920059
test loss item: 0.26005178689956665
test loss item: 0.11641602218151093
test loss item: 0.6550767421722412
test loss item: 0.1472589522600174
test loss item: 0.4320695102214813
test loss item: 0.11090374737977982
test loss item: 0.08704167604446411
test loss item: 0.16258838772773743
test loss item: 0.256132572889328
test loss item: 0.22765779495239258
test loss item: 0.15004390478134155
test loss item: 0.13404303789138794
test loss item: 0.12958663702011108
test loss item: 0.15207405388355255
test loss item: 0.43620628118515015
test loss item: 0.21925164759159088
test loss item: 0.21306750178337097
test loss item: 0.62037593126297
test loss item: 0.1971084177494049
test loss item: 0.15586204826831818
test loss item: 0.13159964978694916
test loss item: 0.1990758180618286
test loss item: 0.15325146913528442
test loss item: 0.30740830302238464
test loss item: 0.11327212303876877
test loss item: 0.12681123614311218
test loss item: 0.3690952956676483
test loss item: 0.3088720440864563
test loss item: 0.11738500744104385
test loss item: 0.160319522023201
test loss item: 0.1405538022518158
test loss item: 0.45055922865867615
test loss item: 0.16590891778469086
test loss item: 0.25336968898773193
test loss item: 0.4172758162021637
test loss item: 0.23956918716430664
test loss item: 0.10659325867891312
test loss item: 0.8401430249214172
test loss item: 0.12733778357505798
test loss item: 0.5041450262069702
test loss item: 0.591410756111145
test loss item: 0.1334807574748993
test loss item: 0.07144157588481903
test loss item: 0.1561208814382553
Epoch [17/50], Training Loss: 0.2299, Testing Loss: 0.2479
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 18/50
train loss item: 0.2028810828924179
train loss item: 0.1788875311613083
train loss item: 0.13040043413639069
train loss item: 0.3179333806037903
train loss item: 0.12303038686513901
train loss item: 0.13717831671237946
train loss item: 0.25240442156791687
train loss item: 0.24779725074768066
train loss item: 0.07047214359045029
train loss item: 0.1439434140920639
train loss item: 0.0912184938788414
train loss item: 0.25609925389289856
train loss item: 0.14273323118686676
train loss item: 0.17464496195316315
train loss item: 0.19934721291065216
train loss item: 0.4081757664680481
train loss item: 0.2598218321800232
train loss item: 0.3371981978416443
train loss item: 0.26021191477775574
train loss item: 0.1550079584121704
train loss item: 0.10561240464448929
train loss item: 0.15930920839309692
train loss item: 0.19006870687007904
train loss item: 0.14357911050319672
train loss item: 0.12479230761528015
train loss item: 0.40627723932266235
train loss item: 0.0863821730017662
train loss item: 0.2300586998462677
train loss item: 0.16265398263931274
train loss item: 0.08500725030899048
train loss item: 0.36695000529289246
train loss item: 0.2260267436504364
train loss item: 0.11235583573579788
train loss item: 0.1741328239440918
train loss item: 0.1362736076116562
train loss item: 0.08723603934049606
train loss item: 0.10451936721801758
train loss item: 0.05937855318188667
train loss item: 0.4935542643070221
train loss item: 0.10461534559726715
train loss item: 0.0840689092874527
train loss item: 0.1832641065120697
train loss item: 0.15689751505851746
train loss item: 0.46897804737091064
train loss item: 0.22125115990638733
test loss item: 0.09778294712305069
test loss item: 0.15712951123714447
test loss item: 0.10711344331502914
test loss item: 0.2210811823606491
test loss item: 0.10087747126817703
test loss item: 0.24157193303108215
test loss item: 0.07873056083917618
test loss item: 0.08576902002096176
test loss item: 0.10016155242919922
test loss item: 0.11713206768035889
test loss item: 0.12455723434686661
test loss item: 0.09977230429649353
test loss item: 0.08667638152837753
test loss item: 0.10458162426948547
test loss item: 0.10667470097541809
test loss item: 0.20212814211845398
test loss item: 0.14479586482048035
test loss item: 0.139255091547966
test loss item: 0.30275511741638184
test loss item: 0.12239975482225418
test loss item: 0.09706061333417892
test loss item: 0.088116355240345
test loss item: 0.11473023146390915
test loss item: 0.0955713614821434
test loss item: 0.16318435966968536
test loss item: 0.08767925947904587
test loss item: 0.09205157309770584
test loss item: 0.20533421635627747
test loss item: 0.1639735847711563
test loss item: 0.09409870207309723
test loss item: 0.10075212270021439
test loss item: 0.08924158662557602
test loss item: 0.20749753713607788
test loss item: 0.08867425471544266
test loss item: 0.1450381577014923
test loss item: 0.1406729817390442
test loss item: 0.11506348848342896
test loss item: 0.08252549916505814
test loss item: 0.4146352708339691
test loss item: 0.10393209010362625
test loss item: 0.223518505692482
test loss item: 0.27316299080848694
test loss item: 0.08805236220359802
test loss item: 0.0811193659901619
test loss item: 0.12439720332622528
Epoch [18/50], Training Loss: 0.1947, Testing Loss: 0.1382
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 19/50
train loss item: 0.29421481490135193
train loss item: 0.22631724178791046
train loss item: 0.12807616591453552
train loss item: 0.17872504889965057
train loss item: 0.09104209393262863
train loss item: 0.10245969891548157
train loss item: 0.1656987965106964
train loss item: 0.27694717049598694
train loss item: 0.0676899179816246
train loss item: 0.1492651104927063
train loss item: 0.11721444875001907
train loss item: 0.34607648849487305
train loss item: 0.15011268854141235
train loss item: 0.15956737101078033
train loss item: 0.17554780840873718
train loss item: 0.23214052617549896
train loss item: 0.18965035676956177
train loss item: 0.2754869759082794
train loss item: 0.328632652759552
train loss item: 0.1711810678243637
train loss item: 0.15287359058856964
train loss item: 0.10320837050676346
train loss item: 0.1854885071516037
train loss item: 0.10588841140270233
train loss item: 0.095455102622509
train loss item: 0.30304092168807983
train loss item: 0.07470253109931946
train loss item: 0.3399088978767395
train loss item: 0.11124604940414429
train loss item: 0.08125358819961548
train loss item: 0.3919949233531952
train loss item: 0.177531436085701
train loss item: 0.17779140174388885
train loss item: 0.1469409167766571
train loss item: 0.12232130765914917
train loss item: 0.09054095298051834
train loss item: 0.1265702098608017
train loss item: 0.05818551406264305
train loss item: 0.2835381329059601
train loss item: 0.136203333735466
train loss item: 0.07331760227680206
train loss item: 0.160737544298172
train loss item: 0.1709779053926468
train loss item: 0.5513587594032288
train loss item: 0.15175209939479828
test loss item: 0.08155867457389832
test loss item: 0.15907393395900726
test loss item: 0.09821287542581558
test loss item: 0.5429476499557495
test loss item: 0.10599785298109055
test loss item: 0.25354471802711487
test loss item: 0.09583470225334167
test loss item: 0.06711751222610474
test loss item: 0.1338113397359848
test loss item: 0.21636061370372772
test loss item: 0.1803763210773468
test loss item: 0.11893253773450851
test loss item: 0.10230310261249542
test loss item: 0.11386954039335251
test loss item: 0.12751562893390656
test loss item: 0.29161858558654785
test loss item: 0.13770532608032227
test loss item: 0.15868574380874634
test loss item: 0.3716853857040405
test loss item: 0.15335996448993683
test loss item: 0.13177908957004547
test loss item: 0.10838879644870758
test loss item: 0.17537827789783478
test loss item: 0.12534819543361664
test loss item: 0.20932537317276
test loss item: 0.088437020778656
test loss item: 0.10852054506540298
test loss item: 0.19913360476493835
test loss item: 0.2231198251247406
test loss item: 0.10007324069738388
test loss item: 0.12430895119905472
test loss item: 0.11452101171016693
test loss item: 0.2715698778629303
test loss item: 0.1426326185464859
test loss item: 0.1803571581840515
test loss item: 0.3657798767089844
test loss item: 0.21155929565429688
test loss item: 0.08957891911268234
test loss item: 0.4053685665130615
test loss item: 0.10583169013261795
test loss item: 0.3329334855079651
test loss item: 0.3453255295753479
test loss item: 0.11587859690189362
test loss item: 0.049794990569353104
test loss item: 0.10643366724252701
Epoch [19/50], Training Loss: 0.1822, Testing Loss: 0.1765
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 20/50
train loss item: 0.19495277106761932
train loss item: 0.13637709617614746
train loss item: 0.10323309898376465
train loss item: 0.2187473475933075
train loss item: 0.08418294787406921
train loss item: 0.12351945787668228
train loss item: 0.18747751414775848
train loss item: 0.16738328337669373
train loss item: 0.09435256570577621
train loss item: 0.13990534842014313
train loss item: 0.10439185053110123
train loss item: 0.20016434788703918
train loss item: 0.13284985721111298
train loss item: 0.168186217546463
train loss item: 0.16171705722808838
train loss item: 0.5218599438667297
train loss item: 0.19566796720027924
train loss item: 0.23270100355148315
train loss item: 0.23224234580993652
train loss item: 0.18444941937923431
train loss item: 0.1316893845796585
train loss item: 0.13611067831516266
train loss item: 0.2387540340423584
train loss item: 0.10423441231250763
train loss item: 0.09419931471347809
train loss item: 0.2561018168926239
train loss item: 0.07742825895547867
train loss item: 0.3899475634098053
train loss item: 0.15523165464401245
train loss item: 0.10320013016462326
train loss item: 0.30575719475746155
train loss item: 0.23620644211769104
train loss item: 0.12383341789245605
train loss item: 0.23347216844558716
train loss item: 0.1536150425672531
train loss item: 0.09018806368112564
train loss item: 0.10647522658109665
train loss item: 0.05447469279170036
train loss item: 0.4548945128917694
train loss item: 0.09058333188295364
train loss item: 0.09397421777248383
train loss item: 0.1562076210975647
train loss item: 0.19322478771209717
train loss item: 0.5688056945800781
train loss item: 0.16410093009471893
test loss item: 0.09525585919618607
test loss item: 0.1553451120853424
test loss item: 0.10235877335071564
test loss item: 0.24972933530807495
test loss item: 0.12335315346717834
test loss item: 0.2529264986515045
test loss item: 0.0930335521697998
test loss item: 0.081942118704319
test loss item: 0.11892585456371307
test loss item: 0.15304024517536163
test loss item: 0.13053733110427856
test loss item: 0.1269242763519287
test loss item: 0.09602274745702744
test loss item: 0.11664408445358276
test loss item: 0.12242986261844635
test loss item: 0.21219803392887115
test loss item: 0.13911540806293488
test loss item: 0.15777456760406494
test loss item: 0.2973117232322693
test loss item: 0.12409570068120956
test loss item: 0.12634359300136566
test loss item: 0.10929379612207413
test loss item: 0.13420289754867554
test loss item: 0.14137184619903564
test loss item: 0.1818760186433792
test loss item: 0.10623164474964142
test loss item: 0.10788055509328842
test loss item: 0.2182610034942627
test loss item: 0.15580156445503235
test loss item: 0.0980783998966217
test loss item: 0.11789215356111526
test loss item: 0.0965006873011589
test loss item: 0.20460058748722076
test loss item: 0.11224714666604996
test loss item: 0.14657801389694214
test loss item: 0.16152502596378326
test loss item: 0.1531573086977005
test loss item: 0.11127883195877075
test loss item: 0.33659327030181885
test loss item: 0.10588190704584122
test loss item: 0.21903842687606812
test loss item: 0.2753099501132965
test loss item: 0.11122564226388931
test loss item: 0.06167995557188988
test loss item: 0.09495606273412704
Epoch [20/50], Training Loss: 0.1844, Testing Loss: 0.1475
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 21/50
train loss item: 0.2652800679206848
train loss item: 0.14985865354537964
train loss item: 0.11151501536369324
train loss item: 0.17995628714561462
train loss item: 0.09390650689601898
train loss item: 0.1022203266620636
train loss item: 0.14284105598926544
train loss item: 0.14906661212444305
train loss item: 0.06737595796585083
train loss item: 0.1109386533498764
train loss item: 0.09081259369850159
train loss item: 0.24293042719364166
train loss item: 0.10780870914459229
train loss item: 0.1493462175130844
train loss item: 0.15136264264583588
train loss item: 0.2410501092672348
train loss item: 0.13564945757389069
train loss item: 0.28597062826156616
train loss item: 0.271072119474411
train loss item: 0.12636305391788483
train loss item: 0.09559158980846405
train loss item: 0.10654694586992264
train loss item: 0.16991136968135834
train loss item: 0.09678354114294052
train loss item: 0.0782991349697113
train loss item: 0.23131845891475677
train loss item: 0.06356768310070038
train loss item: 0.23644408583641052
train loss item: 0.10478796809911728
train loss item: 0.06364516168832779
train loss item: 0.27214932441711426
train loss item: 0.13549059629440308
train loss item: 0.13650187849998474
train loss item: 0.1092352345585823
train loss item: 0.13174507021903992
train loss item: 0.08389998227357864
train loss item: 0.10360392928123474
train loss item: 0.06306526809930801
train loss item: 0.26351267099380493
train loss item: 0.09028929471969604
train loss item: 0.06608896702528
train loss item: 0.133888840675354
train loss item: 0.14156369864940643
train loss item: 0.5604045987129211
train loss item: 0.12155991047620773
test loss item: 0.08471933752298355
test loss item: 0.16661839187145233
test loss item: 0.08933917433023453
test loss item: 0.5462343692779541
test loss item: 0.10681597888469696
test loss item: 0.26900431513786316
test loss item: 0.088202565908432
test loss item: 0.06529245525598526
test loss item: 0.1332991123199463
test loss item: 0.22489449381828308
test loss item: 0.18179303407669067
test loss item: 0.12435504794120789
test loss item: 0.10124115645885468
test loss item: 0.1085154265165329
test loss item: 0.12455577403306961
test loss item: 0.29526373744010925
test loss item: 0.13233990967273712
test loss item: 0.15204256772994995
test loss item: 0.39601272344589233
test loss item: 0.14795060455799103
test loss item: 0.14193855226039886
test loss item: 0.10695872455835342
test loss item: 0.17930744588375092
test loss item: 0.1364038586616516
test loss item: 0.21339452266693115
test loss item: 0.08177930861711502
test loss item: 0.10500317066907883
test loss item: 0.20680174231529236
test loss item: 0.2310706377029419
test loss item: 0.09203311055898666
test loss item: 0.12537498772144318
test loss item: 0.11881110072135925
test loss item: 0.29625844955444336
test loss item: 0.14135952293872833
test loss item: 0.1748744696378708
test loss item: 0.36152857542037964
test loss item: 0.21270161867141724
test loss item: 0.10000947117805481
test loss item: 0.4283989667892456
test loss item: 0.10889522731304169
test loss item: 0.34353524446487427
test loss item: 0.3641539216041565
test loss item: 0.11193124949932098
test loss item: 0.0536954328417778
test loss item: 0.12112729996442795
Epoch [21/50], Training Loss: 0.1519, Testing Loss: 0.1799
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 22/50
train loss item: 0.18841663002967834
train loss item: 0.12181872129440308
train loss item: 0.10044125467538834
train loss item: 0.2012195587158203
train loss item: 0.08653847873210907
train loss item: 0.09805434942245483
train loss item: 0.16167756915092468
train loss item: 0.10831091552972794
train loss item: 0.05699653923511505
train loss item: 0.1211816594004631
train loss item: 0.08059074729681015
train loss item: 0.18435180187225342
train loss item: 0.1134098619222641
train loss item: 0.14159736037254333
train loss item: 0.13992619514465332
train loss item: 0.2879059612751007
train loss item: 0.153591126203537
train loss item: 0.20141947269439697
train loss item: 0.180457204580307
train loss item: 0.16764502227306366
train loss item: 0.10821332037448883
train loss item: 0.11904896795749664
train loss item: 0.17560219764709473
train loss item: 0.11712751537561417
train loss item: 0.09947318583726883
train loss item: 0.2493584305047989
train loss item: 0.08349974453449249
train loss item: 0.34220558404922485
train loss item: 0.11804389208555222
train loss item: 0.08040914684534073
train loss item: 0.27369317412376404
train loss item: 0.17649191617965698
train loss item: 0.09915940463542938
train loss item: 0.18372827768325806
train loss item: 0.12685899436473846
train loss item: 0.0846324935555458
train loss item: 0.09479828923940659
train loss item: 0.062293220311403275
train loss item: 0.3601577877998352
train loss item: 0.07604125887155533
train loss item: 0.06862581521272659
train loss item: 0.13466374576091766
train loss item: 0.16549353301525116
train loss item: 0.5083849430084229
train loss item: 0.1253868043422699
test loss item: 0.09354852139949799
test loss item: 0.17495384812355042
test loss item: 0.10228054225444794
test loss item: 0.3976716697216034
test loss item: 0.13678506016731262
test loss item: 0.2820911407470703
test loss item: 0.10436856001615524
test loss item: 0.07732827216386795
test loss item: 0.12703314423561096
test loss item: 0.18732507526874542
test loss item: 0.15689745545387268
test loss item: 0.12961314618587494
test loss item: 0.09507471323013306
test loss item: 0.12175052613019943
test loss item: 0.13128703832626343
test loss item: 0.2697904407978058
test loss item: 0.15262968838214874
test loss item: 0.1746680736541748
test loss item: 0.367545485496521
test loss item: 0.13628865778446198
test loss item: 0.12292889505624771
test loss item: 0.10726006329059601
test loss item: 0.1582227647304535
test loss item: 0.14889150857925415
test loss item: 0.21518361568450928
test loss item: 0.11657235026359558
test loss item: 0.09972616285085678
test loss item: 0.24845504760742188
test loss item: 0.18824100494384766
test loss item: 0.10792180150747299
test loss item: 0.13713210821151733
test loss item: 0.10619194060564041
test loss item: 0.2541494071483612
test loss item: 0.12006951868534088
test loss item: 0.17338578402996063
test loss item: 0.25423091650009155
test loss item: 0.1819322109222412
test loss item: 0.10963493585586548
test loss item: 0.41946908831596375
test loss item: 0.11122499406337738
test loss item: 0.28623706102371216
test loss item: 0.3449721038341522
test loss item: 0.11600352823734283
test loss item: 0.05575565993785858
test loss item: 0.09241645783185959
Epoch [22/50], Training Loss: 0.1540, Testing Loss: 0.1710
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 23/50
train loss item: 0.1773311048746109
train loss item: 0.1273309737443924
train loss item: 0.09596699476242065
train loss item: 0.17824450135231018
train loss item: 0.07661577314138412
train loss item: 0.09971673041582108
train loss item: 0.13334344327449799
train loss item: 0.12210351973772049
train loss item: 0.06575087457895279
train loss item: 0.11112280189990997
train loss item: 0.08534730970859528
train loss item: 0.22763623297214508
train loss item: 0.10374412685632706
train loss item: 0.14295588433742523
train loss item: 0.12959536910057068
train loss item: 0.2080218493938446
train loss item: 0.1280074417591095
train loss item: 0.2801204025745392
train loss item: 0.20559439063072205
train loss item: 0.1286046952009201
train loss item: 0.09246312081813812
train loss item: 0.11785342544317245
train loss item: 0.15797941386699677
train loss item: 0.09139863401651382
train loss item: 0.07840829342603683
train loss item: 0.22809845209121704
train loss item: 0.06402773410081863
train loss item: 0.2104061394929886
train loss item: 0.09773124009370804
train loss item: 0.06046346202492714
train loss item: 0.22896359860897064
train loss item: 0.12062402069568634
train loss item: 0.10866625607013702
train loss item: 0.11772885918617249
train loss item: 0.11950518935918808
train loss item: 0.08187340945005417
train loss item: 0.08852007985115051
train loss item: 0.05504895746707916
train loss item: 0.28255292773246765
train loss item: 0.08626615256071091
train loss item: 0.06517281383275986
train loss item: 0.12105931341648102
train loss item: 0.1289370357990265
train loss item: 0.521780788898468
train loss item: 0.10708822309970856
test loss item: 0.08598403632640839
test loss item: 0.17060387134552002
test loss item: 0.08858262747526169
test loss item: 0.46921613812446594
test loss item: 0.12129919230937958
test loss item: 0.27103620767593384
test loss item: 0.08701490610837936
test loss item: 0.07232777029275894
test loss item: 0.12760871648788452
test loss item: 0.2006511688232422
test loss item: 0.16652004420757294
test loss item: 0.11537803709506989
test loss item: 0.09442908316850662
test loss item: 0.10809063166379929
test loss item: 0.12572377920150757
test loss item: 0.2766379714012146
test loss item: 0.14760971069335938
test loss item: 0.1579531878232956
test loss item: 0.38536614179611206
test loss item: 0.14082041382789612
test loss item: 0.12437772750854492
test loss item: 0.10551360994577408
test loss item: 0.16451114416122437
test loss item: 0.12538695335388184
test loss item: 0.20718298852443695
test loss item: 0.09707367420196533
test loss item: 0.09883365035057068
test loss item: 0.22111092507839203
test loss item: 0.20381683111190796
test loss item: 0.09547673165798187
test loss item: 0.13343803584575653
test loss item: 0.10730335116386414
test loss item: 0.26741287112236023
test loss item: 0.1234404668211937
test loss item: 0.1660711020231247
test loss item: 0.3037441670894623
test loss item: 0.18197409808635712
test loss item: 0.09096187353134155
test loss item: 0.4226045608520508
test loss item: 0.09807776659727097
test loss item: 0.30847325921058655
test loss item: 0.3509429097175598
test loss item: 0.1022990345954895
test loss item: 0.05682440102100372
test loss item: 0.11766175180673599
Epoch [23/50], Training Loss: 0.1391, Testing Loss: 0.1708
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 24/50
train loss item: 0.17952676117420197
train loss item: 0.11734800785779953
train loss item: 0.09817750751972198
train loss item: 0.16340036690235138
train loss item: 0.07200019806623459
train loss item: 0.08928162604570389
train loss item: 0.1109238788485527
train loss item: 0.12555469572544098
train loss item: 0.0643077939748764
train loss item: 0.11483742296695709
train loss item: 0.07659193873405457
train loss item: 0.19233351945877075
train loss item: 0.10178732126951218
train loss item: 0.13621245324611664
train loss item: 0.14207743108272552
train loss item: 0.19362589716911316
train loss item: 0.09543316811323166
train loss item: 0.33441099524497986
train loss item: 0.23425604403018951
train loss item: 0.12112519145011902
train loss item: 0.09706714749336243
train loss item: 0.0958242118358612
train loss item: 0.14677082002162933
train loss item: 0.07848947495222092
train loss item: 0.06827741116285324
train loss item: 0.19966672360897064
train loss item: 0.06618987768888474
train loss item: 0.2091979682445526
train loss item: 0.11393888294696808
train loss item: 0.05787622183561325
train loss item: 0.21060124039649963
train loss item: 0.1033688336610794
train loss item: 0.11782548576593399
train loss item: 0.10333724319934845
train loss item: 0.11419709026813507
train loss item: 0.077433280646801
train loss item: 0.09782806783914566
train loss item: 0.06462746858596802
train loss item: 0.20784489810466766
train loss item: 0.0828862115740776
train loss item: 0.06140630692243576
train loss item: 0.11173596978187561
train loss item: 0.11133837699890137
train loss item: 0.4675334095954895
train loss item: 0.10005630552768707
test loss item: 0.08547797799110413
test loss item: 0.19327804446220398
test loss item: 0.0939454734325409
test loss item: 0.5735135674476624
test loss item: 0.12178415805101395
test loss item: 0.318157434463501
test loss item: 0.09224168211221695
test loss item: 0.06747730821371078
test loss item: 0.1434689462184906
test loss item: 0.22945746779441833
test loss item: 0.19245989620685577
test loss item: 0.12470594048500061
test loss item: 0.10355262458324432
test loss item: 0.1139204278588295
test loss item: 0.13278979063034058
test loss item: 0.33735132217407227
test loss item: 0.15502457320690155
test loss item: 0.16090108454227448
test loss item: 0.4601842164993286
test loss item: 0.159328892827034
test loss item: 0.14261797070503235
test loss item: 0.11466006189584732
test loss item: 0.18782787024974823
test loss item: 0.1367403268814087
test loss item: 0.23362654447555542
test loss item: 0.09185845404863358
test loss item: 0.10866327583789825
test loss item: 0.25389164686203003
test loss item: 0.23275989294052124
test loss item: 0.09543765336275101
test loss item: 0.13628672063350677
test loss item: 0.12175308167934418
test loss item: 0.3324505090713501
test loss item: 0.1435769647359848
test loss item: 0.18705704808235168
test loss item: 0.36642488837242126
test loss item: 0.216207817196846
test loss item: 0.10235179215669632
test loss item: 0.5419571399688721
test loss item: 0.11273904889822006
test loss item: 0.37672916054725647
test loss item: 0.4295363128185272
test loss item: 0.11263085901737213
test loss item: 0.052321579307317734
test loss item: 0.12599559128284454
Epoch [24/50], Training Loss: 0.1317, Testing Loss: 0.1959
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 25/50
train loss item: 0.16279126703739166
train loss item: 0.11354159563779831
train loss item: 0.09549940377473831
train loss item: 0.1779455542564392
train loss item: 0.07118819653987885
train loss item: 0.093912273645401
train loss item: 0.11398756504058838
train loss item: 0.1291230171918869
train loss item: 0.06743598729372025
train loss item: 0.11644383519887924
train loss item: 0.09989608824253082
train loss item: 0.20381306111812592
train loss item: 0.12719032168388367
train loss item: 0.14842279255390167
train loss item: 0.15701685845851898
train loss item: 0.2710173428058624
train loss item: 0.13962359726428986
train loss item: 0.23319531977176666
train loss item: 0.1954355239868164
train loss item: 0.16226080060005188
train loss item: 0.10428920388221741
train loss item: 0.10573949664831161
train loss item: 0.15568745136260986
train loss item: 0.09854596108198166
train loss item: 0.09949465095996857
train loss item: 0.23304425179958344
train loss item: 0.0723690465092659
train loss item: 0.3355453312397003
train loss item: 0.10782619565725327
train loss item: 0.07072953879833221
train loss item: 0.311972975730896
train loss item: 0.13356295228004456
train loss item: 0.09967681020498276
train loss item: 0.1438518464565277
train loss item: 0.1132780984044075
train loss item: 0.08030866831541061
train loss item: 0.08505422621965408
train loss item: 0.06266085058450699
train loss item: 0.2284790426492691
train loss item: 0.0785834863781929
train loss item: 0.06173008680343628
train loss item: 0.1431935727596283
train loss item: 0.14894551038742065
train loss item: 0.4929678440093994
train loss item: 0.10650298744440079
test loss item: 0.08787357807159424
test loss item: 0.17561395466327667
test loss item: 0.09111089259386063
test loss item: 0.5449596643447876
test loss item: 0.13231161236763
test loss item: 0.28757035732269287
test loss item: 0.10427913069725037
test loss item: 0.06942132115364075
test loss item: 0.1357668787240982
test loss item: 0.22311460971832275
test loss item: 0.18045158684253693
test loss item: 0.13350176811218262
test loss item: 0.09857524186372757
test loss item: 0.120029978454113
test loss item: 0.13347883522510529
test loss item: 0.31423670053482056
test loss item: 0.15205830335617065
test loss item: 0.17114228010177612
test loss item: 0.4076397716999054
test loss item: 0.15188562870025635
test loss item: 0.134983628988266
test loss item: 0.112310029566288
test loss item: 0.18078072369098663
test loss item: 0.14947326481342316
test loss item: 0.2314155399799347
test loss item: 0.11049880087375641
test loss item: 0.10231970250606537
test loss item: 0.23961158096790314
test loss item: 0.21715235710144043
test loss item: 0.10512636601924896
test loss item: 0.14717581868171692
test loss item: 0.1151321604847908
test loss item: 0.2812165915966034
test loss item: 0.1371544450521469
test loss item: 0.18642489612102509
test loss item: 0.34682372212409973
test loss item: 0.21067428588867188
test loss item: 0.10591626912355423
test loss item: 0.4221605062484741
test loss item: 0.10816450417041779
test loss item: 0.3387618362903595
test loss item: 0.3815014362335205
test loss item: 0.11472499370574951
test loss item: 0.05003116652369499
test loss item: 0.09393450617790222
Epoch [25/50], Training Loss: 0.1456, Testing Loss: 0.1853
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 26/50
train loss item: 0.16174186766147614
train loss item: 0.11983948200941086
train loss item: 0.08709031343460083
train loss item: 0.14940433204174042
train loss item: 0.06728674471378326
train loss item: 0.09622974693775177
train loss item: 0.11795873939990997
train loss item: 0.14665576815605164
train loss item: 0.05341067165136337
train loss item: 0.11632824689149857
train loss item: 0.08183083683252335
train loss item: 0.19439633190631866
train loss item: 0.09976985305547714
train loss item: 0.13626188039779663
train loss item: 0.16613173484802246
train loss item: 0.20472271740436554
train loss item: 0.10389009863138199
train loss item: 0.3017463982105255
train loss item: 0.22634752094745636
train loss item: 0.15349338948726654
train loss item: 0.09724438935518265
train loss item: 0.10595814883708954
train loss item: 0.1441069394350052
train loss item: 0.09474362432956696
train loss item: 0.08242711424827576
train loss item: 0.20821411907672882
train loss item: 0.06279786676168442
train loss item: 0.23574739694595337
train loss item: 0.10610363632440567
train loss item: 0.057810258120298386
train loss item: 0.2471177875995636
train loss item: 0.10012535750865936
train loss item: 0.10542670637369156
train loss item: 0.10941064357757568
train loss item: 0.10858135670423508
train loss item: 0.07294207066297531
train loss item: 0.0866168737411499
train loss item: 0.05997348576784134
train loss item: 0.18364855647087097
train loss item: 0.07800477743148804
train loss item: 0.06335479021072388
train loss item: 0.13755007088184357
train loss item: 0.11306513845920563
train loss item: 0.5015072822570801
train loss item: 0.09749965369701385
test loss item: 0.08755835890769958
test loss item: 0.19380506873130798
test loss item: 0.09138679504394531
test loss item: 0.6048303246498108
test loss item: 0.13228315114974976
test loss item: 0.3108483552932739
test loss item: 0.10772448033094406
test loss item: 0.06561224162578583
test loss item: 0.15047402679920197
test loss item: 0.24336841702461243
test loss item: 0.20009392499923706
test loss item: 0.13946524262428284
test loss item: 0.10509524494409561
test loss item: 0.12196100503206253
test loss item: 0.14250768721103668
test loss item: 0.3481636345386505
test loss item: 0.15627272427082062
test loss item: 0.1672607809305191
test loss item: 0.45812833309173584
test loss item: 0.16470086574554443
test loss item: 0.15365572273731232
test loss item: 0.11789394170045853
test loss item: 0.20273348689079285
test loss item: 0.1611877679824829
test loss item: 0.24235504865646362
test loss item: 0.1053844541311264
test loss item: 0.11016307026147842
test loss item: 0.2520158588886261
test loss item: 0.2393452674150467
test loss item: 0.10600464046001434
test loss item: 0.14831990003585815
test loss item: 0.13146916031837463
test loss item: 0.32611215114593506
test loss item: 0.15189887583255768
test loss item: 0.19179704785346985
test loss item: 0.38354402780532837
test loss item: 0.2354108691215515
test loss item: 0.11598742753267288
test loss item: 0.5065258145332336
test loss item: 0.12072955071926117
test loss item: 0.37726160883903503
test loss item: 0.42719727754592896
test loss item: 0.1202159896492958
test loss item: 0.04916715994477272
test loss item: 0.11989587545394897
Epoch [26/50], Training Loss: 0.1343, Testing Loss: 0.2020
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 27/50
train loss item: 0.1782546490430832
train loss item: 0.12147052586078644
train loss item: 0.09479746222496033
train loss item: 0.1149233728647232
train loss item: 0.07497677952051163
train loss item: 0.10723461955785751
train loss item: 0.11392433941364288
train loss item: 0.14375776052474976
train loss item: 0.06277628988027573
train loss item: 0.1079014465212822
train loss item: 0.09134981036186218
train loss item: 0.19375546276569366
train loss item: 0.10768670588731766
train loss item: 0.1502016931772232
train loss item: 0.2196473777294159
train loss item: 0.2266281396150589
train loss item: 0.1433674395084381
train loss item: 0.24856433272361755
train loss item: 0.2096581906080246
train loss item: 0.14251038432121277
train loss item: 0.10249561816453934
train loss item: 0.09935904294252396
train loss item: 0.1528213769197464
train loss item: 0.09356456249952316
train loss item: 0.08524926751852036
train loss item: 0.2188873440027237
train loss item: 0.06672032922506332
train loss item: 0.29192590713500977
train loss item: 0.10033626109361649
train loss item: 0.06065020710229874
train loss item: 0.289734810590744
train loss item: 0.10427875071763992
train loss item: 0.10199380666017532
train loss item: 0.1028405949473381
train loss item: 0.10227712988853455
train loss item: 0.07939061522483826
train loss item: 0.08483970165252686
train loss item: 0.06519022583961487
train loss item: 0.18976667523384094
train loss item: 0.08824432641267776
train loss item: 0.06815645843744278
train loss item: 0.14148175716400146
train loss item: 0.11397518217563629
train loss item: 0.4859800636768341
train loss item: 0.0986323282122612
test loss item: 0.09729987382888794
test loss item: 0.18056976795196533
test loss item: 0.08837737143039703
test loss item: 0.6869661211967468
test loss item: 0.13267306983470917
test loss item: 0.2804797887802124
test loss item: 0.1152665764093399
test loss item: 0.07040304690599442
test loss item: 0.14824219048023224
test loss item: 0.2612212598323822
test loss item: 0.20677033066749573
test loss item: 0.1461447775363922
test loss item: 0.1033160537481308
test loss item: 0.12428432703018188
test loss item: 0.1429409682750702
test loss item: 0.3587857484817505
test loss item: 0.14702659845352173
test loss item: 0.16364355385303497
test loss item: 0.4433872103691101
test loss item: 0.16948378086090088
test loss item: 0.15714962780475616
test loss item: 0.1210068091750145
test loss item: 0.20246851444244385
test loss item: 0.16415031254291534
test loss item: 0.23509913682937622
test loss item: 0.11259447038173676
test loss item: 0.10937301069498062
test loss item: 0.21659255027770996
test loss item: 0.24786308407783508
test loss item: 0.11007411032915115
test loss item: 0.15698222815990448
test loss item: 0.1345561146736145
test loss item: 0.31590813398361206
test loss item: 0.15419991314411163
test loss item: 0.1918976604938507
test loss item: 0.43477165699005127
test loss item: 0.24800170958042145
test loss item: 0.11833822727203369
test loss item: 0.4292536675930023
test loss item: 0.12181978672742844
test loss item: 0.3880595266819
test loss item: 0.4120113253593445
test loss item: 0.11960048228502274
test loss item: 0.06059175357222557
test loss item: 0.0990452840924263
Epoch [27/50], Training Loss: 0.1387, Testing Loss: 0.2029
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 28/50
train loss item: 0.18747951090335846
train loss item: 0.13978491723537445
train loss item: 0.09686063230037689
train loss item: 0.13012059032917023
train loss item: 0.09492285549640656
train loss item: 0.0980389416217804
train loss item: 0.13999497890472412
train loss item: 0.11160197108983994
train loss item: 0.05353931710124016
train loss item: 0.12011826038360596
train loss item: 0.09608370065689087
train loss item: 0.19488020241260529
train loss item: 0.10931085050106049
train loss item: 0.14094585180282593
train loss item: 0.26151561737060547
train loss item: 0.3547268807888031
train loss item: 0.10626262426376343
train loss item: 0.2576977014541626
train loss item: 0.1137295737862587
train loss item: 0.10769467055797577
train loss item: 0.09854397922754288
train loss item: 0.07443443685770035
train loss item: 0.1945933699607849
train loss item: 0.10532429069280624
train loss item: 0.06848248839378357
train loss item: 0.20496617257595062
train loss item: 0.057492416352033615
train loss item: 0.20965389907360077
train loss item: 0.10717839747667313
train loss item: 0.0618797242641449
train loss item: 0.2721101641654968
train loss item: 0.14704133570194244
train loss item: 0.12821771204471588
train loss item: 0.13302606344223022
train loss item: 0.10729950666427612
train loss item: 0.07975603640079498
train loss item: 0.11092016100883484
train loss item: 0.07908859103918076
train loss item: 0.19078215956687927
train loss item: 0.1193220317363739
train loss item: 0.07409218698740005
train loss item: 0.14034150540828705
train loss item: 0.12193078547716141
train loss item: 0.36177459359169006
train loss item: 0.12153006345033646
test loss item: 0.09330607950687408
test loss item: 0.2064865678548813
test loss item: 0.10269499570131302
test loss item: 0.6515035033226013
test loss item: 0.14610330760478973
test loss item: 0.32006022334098816
test loss item: 0.12010388821363449
test loss item: 0.0742994025349617
test loss item: 0.15598353743553162
test loss item: 0.2690606415271759
test loss item: 0.21233375370502472
test loss item: 0.15475420653820038
test loss item: 0.10583401471376419
test loss item: 0.1332869976758957
test loss item: 0.15314750373363495
test loss item: 0.36170828342437744
test loss item: 0.16304782032966614
test loss item: 0.17906726896762848
test loss item: 0.48201784491539
test loss item: 0.17064395546913147
test loss item: 0.15861037373542786
test loss item: 0.12037981301546097
test loss item: 0.2180423140525818
test loss item: 0.17562107741832733
test loss item: 0.25970080494880676
test loss item: 0.11328314989805222
test loss item: 0.10969045758247375
test loss item: 0.2631036043167114
test loss item: 0.2607553005218506
test loss item: 0.11006267368793488
test loss item: 0.16232965886592865
test loss item: 0.13651733100414276
test loss item: 0.35301700234413147
test loss item: 0.16511501371860504
test loss item: 0.20761097967624664
test loss item: 0.41858047246932983
test loss item: 0.2518341839313507
test loss item: 0.12381072342395782
test loss item: 0.5137512683868408
test loss item: 0.13078127801418304
test loss item: 0.40337106585502625
test loss item: 0.4486818313598633
test loss item: 0.1275079846382141
test loss item: 0.04717116802930832
test loss item: 0.10777399688959122
Epoch [28/50], Training Loss: 0.1397, Testing Loss: 0.2143
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.14393049478530884
loss item: 0.5191104412078857
loss item: 0.289497047662735
loss item: 0.332757830619812
loss item: 0.13996507227420807
loss item: 0.5248458981513977
loss item: 0.32896554470062256
loss item: 0.13213637471199036
loss item: 0.22128643095493317
loss item: 0.3714844882488251
loss item: 0.16029128432273865
loss item: 0.18519045412540436
loss item: 0.30187809467315674
loss item: 0.2886209487915039
loss item: 0.20777656137943268
loss item: 0.620072066783905
loss item: 0.22958041727542877
loss item: 0.13103383779525757
loss item: 0.15893378853797913
loss item: 0.3172398507595062
loss item: 0.3844749927520752
loss item: 0.10547462850809097
Val Loss: 0.2770
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.0005 4 360 done at Tue Nov 12 10:48:40 CET 2024
UNet2 with 1 50 0.001 4 360 start at Tue Nov 12 10:48:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 50, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.6336421966552734
train loss item: 1.0241367816925049
train loss item: 0.6707100868225098
train loss item: 1.052453875541687
train loss item: 0.4325838088989258
train loss item: 0.45004919171333313
train loss item: 0.48263299465179443
train loss item: 0.7821451425552368
train loss item: 0.29314959049224854
train loss item: 0.4130592346191406
train loss item: 0.32709062099456787
train loss item: 1.3081952333450317
train loss item: 0.5725193619728088
train loss item: 0.3602299988269806
train loss item: 0.812736451625824
train loss item: 1.7246522903442383
train loss item: 0.5814995169639587
train loss item: 1.933405876159668
train loss item: 0.5622901916503906
train loss item: 0.5134773850440979
train loss item: 0.3968896269798279
train loss item: 0.3826901912689209
train loss item: 0.572571337223053
train loss item: 0.48281049728393555
train loss item: 0.28770947456359863
train loss item: 0.9830145835876465
train loss item: 0.17388230562210083
train loss item: 1.8055871725082397
train loss item: 0.27561211585998535
train loss item: 0.2561942934989929
train loss item: 1.6007624864578247
train loss item: 0.3905438482761383
train loss item: 0.5161809325218201
train loss item: 0.5474753975868225
train loss item: 0.36473026871681213
train loss item: 0.3366314768791199
train loss item: 0.3277329206466675
train loss item: 0.1944217085838318
train loss item: 1.2737903594970703
train loss item: 0.39583051204681396
train loss item: 0.27123531699180603
train loss item: 0.6088969707489014
train loss item: 0.5795220732688904
train loss item: 3.0486552715301514
train loss item: 0.3784008324146271
test loss item: 0.1844942420721054
test loss item: 0.4128219783306122
test loss item: 0.24026422202587128
test loss item: 1.1967934370040894
test loss item: 0.3261007070541382
test loss item: 0.6026497483253479
test loss item: 0.2619163990020752
test loss item: 0.1796243041753769
test loss item: 0.35363373160362244
test loss item: 0.4982045292854309
test loss item: 0.5070556402206421
test loss item: 0.3189913034439087
test loss item: 0.24735687673091888
test loss item: 0.3047749102115631
test loss item: 0.3753136992454529
test loss item: 0.7178504467010498
test loss item: 0.4652574062347412
test loss item: 0.45430421829223633
test loss item: 0.9248380064964294
test loss item: 0.4073701798915863
test loss item: 0.3169515132904053
test loss item: 0.2971665561199188
test loss item: 0.4936496913433075
test loss item: 0.37831950187683105
test loss item: 0.5440714955329895
test loss item: 0.3012947738170624
test loss item: 0.27315953373908997
test loss item: 0.6145839095115662
test loss item: 0.5141955614089966
test loss item: 0.24796162545681
test loss item: 0.3549409806728363
test loss item: 0.2525677978992462
test loss item: 0.6577371954917908
test loss item: 0.3196444511413574
test loss item: 0.4574073553085327
test loss item: 0.7410372495651245
test loss item: 0.39276254177093506
test loss item: 0.2423807680606842
test loss item: 0.9230947494506836
test loss item: 0.24159370362758636
test loss item: 0.6859398484230042
test loss item: 0.8447154760360718
test loss item: 0.26676276326179504
test loss item: 0.13432051241397858
test loss item: 0.2641008198261261
Epoch [1/50], Training Loss: 0.7196, Testing Loss: 0.4387
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/50
train loss item: 0.7582639455795288
train loss item: 0.5910776257514954
train loss item: 0.4969259798526764
train loss item: 0.5332295894622803
train loss item: 0.36325517296791077
train loss item: 0.3494485914707184
train loss item: 0.39720264077186584
train loss item: 0.5960111021995544
train loss item: 0.2659851610660553
train loss item: 0.3563295900821686
train loss item: 0.2327636033296585
train loss item: 0.9502861499786377
train loss item: 0.43850061297416687
train loss item: 0.32240673899650574
train loss item: 0.5752795338630676
train loss item: 1.332024335861206
train loss item: 0.43880146741867065
train loss item: 1.5925759077072144
train loss item: 0.7923399806022644
train loss item: 0.8012042045593262
train loss item: 0.5420367121696472
train loss item: 0.4565233588218689
train loss item: 0.4026448428630829
train loss item: 0.3233100175857544
train loss item: 0.2211102694272995
train loss item: 0.8527234792709351
train loss item: 0.20186269283294678
train loss item: 1.5608386993408203
train loss item: 0.3502146303653717
train loss item: 0.18707996606826782
train loss item: 1.5060603618621826
train loss item: 0.3520696759223938
train loss item: 0.4665796756744385
train loss item: 0.4176289737224579
train loss item: 0.4178161919116974
train loss item: 0.326056569814682
train loss item: 0.3468465507030487
train loss item: 0.10509197413921356
train loss item: 1.0316097736358643
train loss item: 0.23766133189201355
train loss item: 0.17554643750190735
train loss item: 0.4467804431915283
train loss item: 0.4113500714302063
train loss item: 2.473480701446533
train loss item: 0.40614479780197144
test loss item: 0.16071002185344696
test loss item: 0.39313262701034546
test loss item: 0.23595385253429413
test loss item: 0.7451122403144836
test loss item: 0.3502325117588043
test loss item: 0.525374710559845
test loss item: 0.260591059923172
test loss item: 0.15700353682041168
test loss item: 0.3289121985435486
test loss item: 0.40450260043144226
test loss item: 0.4155293107032776
test loss item: 0.2364223301410675
test loss item: 0.22345107793807983
test loss item: 0.2731945216655731
test loss item: 0.35201528668403625
test loss item: 0.489972859621048
test loss item: 0.46126291155815125
test loss item: 0.4114452302455902
test loss item: 0.7907271385192871
test loss item: 0.3574060797691345
test loss item: 0.21143122017383575
test loss item: 0.29464203119277954
test loss item: 0.4250290095806122
test loss item: 0.2713918387889862
test loss item: 0.4899404048919678
test loss item: 0.30553799867630005
test loss item: 0.22880898416042328
test loss item: 0.5591841340065002
test loss item: 0.4274536669254303
test loss item: 0.27993232011795044
test loss item: 0.3678373098373413
test loss item: 0.2401629537343979
test loss item: 0.5270328521728516
test loss item: 0.26906782388687134
test loss item: 0.4335390627384186
test loss item: 0.4729878604412079
test loss item: 0.30102577805519104
test loss item: 0.14824528992176056
test loss item: 0.8045731782913208
test loss item: 0.21533069014549255
test loss item: 0.5074570178985596
test loss item: 0.690883457660675
test loss item: 0.22556616365909576
test loss item: 0.06974131613969803
test loss item: 0.13377968966960907
Epoch [2/50], Training Loss: 0.5867, Testing Loss: 0.3661
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/50
train loss item: 0.6569054126739502
train loss item: 0.45908448100090027
train loss item: 0.30858343839645386
train loss item: 0.503585696220398
train loss item: 0.20400957763195038
train loss item: 0.3009120225906372
train loss item: 0.32600677013397217
train loss item: 0.4639342725276947
train loss item: 0.1995484083890915
train loss item: 0.324881911277771
train loss item: 0.21174149215221405
train loss item: 0.7569984793663025
train loss item: 0.3522612750530243
train loss item: 0.21977509558200836
train loss item: 0.4903251528739929
train loss item: 1.1341159343719482
train loss item: 0.30607089400291443
train loss item: 1.383758783340454
train loss item: 0.6250470280647278
train loss item: 0.49409615993499756
train loss item: 0.31296053528785706
train loss item: 0.3010641932487488
train loss item: 0.34526315331459045
train loss item: 0.29056188464164734
train loss item: 0.2011161893606186
train loss item: 0.7640334963798523
train loss item: 0.15611793100833893
train loss item: 1.2474092245101929
train loss item: 0.2351001501083374
train loss item: 0.1384143978357315
train loss item: 1.162762999534607
train loss item: 0.3086768686771393
train loss item: 0.39650899171829224
train loss item: 0.484634131193161
train loss item: 0.38629549741744995
train loss item: 0.2709228992462158
train loss item: 0.2698284685611725
train loss item: 0.10340185463428497
train loss item: 1.039395809173584
train loss item: 0.20091594755649567
train loss item: 0.15157297253608704
train loss item: 0.3982321321964264
train loss item: 0.440316766500473
train loss item: 2.230140447616577
train loss item: 0.3458942472934723
test loss item: 0.14856019616127014
test loss item: 0.33808428049087524
test loss item: 0.19586585462093353
test loss item: 0.7325286865234375
test loss item: 0.28273871541023254
test loss item: 0.4754360318183899
test loss item: 0.20606659352779388
test loss item: 0.14296184480190277
test loss item: 0.2876807153224945
test loss item: 0.37385696172714233
test loss item: 0.38901475071907043
test loss item: 0.23583008348941803
test loss item: 0.18410858511924744
test loss item: 0.23453758656978607
test loss item: 0.30328238010406494
test loss item: 0.44746652245521545
test loss item: 0.39157232642173767
test loss item: 0.3656146824359894
test loss item: 0.7203139066696167
test loss item: 0.30995309352874756
test loss item: 0.20970779657363892
test loss item: 0.23775742948055267
test loss item: 0.39871272444725037
test loss item: 0.2737673223018646
test loss item: 0.4194757342338562
test loss item: 0.2655319273471832
test loss item: 0.1883847862482071
test loss item: 0.5032730102539062
test loss item: 0.4010279178619385
test loss item: 0.21972212195396423
test loss item: 0.29511523246765137
test loss item: 0.19503556191921234
test loss item: 0.4985000491142273
test loss item: 0.2284877449274063
test loss item: 0.363256573677063
test loss item: 0.4474424123764038
test loss item: 0.2693040668964386
test loss item: 0.16023977100849152
test loss item: 0.6786589026451111
test loss item: 0.18742311000823975
test loss item: 0.4664582312107086
test loss item: 0.6287912130355835
test loss item: 0.1968974620103836
test loss item: 0.07915804535150528
test loss item: 0.09978855401277542
Epoch [3/50], Training Loss: 0.4867, Testing Loss: 0.3262
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/50
train loss item: 0.5846463441848755
train loss item: 0.46709364652633667
train loss item: 0.28866732120513916
train loss item: 0.38409408926963806
train loss item: 0.2060285359621048
train loss item: 0.22247622907161713
train loss item: 0.2832382023334503
train loss item: 0.4702717065811157
train loss item: 0.18137365579605103
train loss item: 0.28913965821266174
train loss item: 0.2043216973543167
train loss item: 0.6464518308639526
train loss item: 0.2878282070159912
train loss item: 0.24124747514724731
train loss item: 0.36096057295799255
train loss item: 0.8703286051750183
train loss item: 0.2203783541917801
train loss item: 1.1851563453674316
train loss item: 0.5838367938995361
train loss item: 0.44526389241218567
train loss item: 0.25277382135391235
train loss item: 0.24237991869449615
train loss item: 0.3101827800273895
train loss item: 0.2497691512107849
train loss item: 0.17877978086471558
train loss item: 0.6733039021492004
train loss item: 0.1273578703403473
train loss item: 1.049696445465088
train loss item: 0.23817545175552368
train loss item: 0.1300685703754425
train loss item: 0.9740211367607117
train loss item: 0.31113722920417786
train loss item: 0.3159659206867218
train loss item: 0.46787795424461365
train loss item: 0.2775630056858063
train loss item: 0.19834938645362854
train loss item: 0.21410180628299713
train loss item: 0.10573571175336838
train loss item: 1.0175604820251465
train loss item: 0.2257736474275589
train loss item: 0.17291687428951263
train loss item: 0.3634456694126129
train loss item: 0.441344290971756
train loss item: 2.121882438659668
train loss item: 0.32812121510505676
test loss item: 0.12478938698768616
test loss item: 0.3011118471622467
test loss item: 0.14192920923233032
test loss item: 0.630023717880249
test loss item: 0.23513418436050415
test loss item: 0.4910232722759247
test loss item: 0.15377771854400635
test loss item: 0.10398860275745392
test loss item: 0.22903139889240265
test loss item: 0.3499266505241394
test loss item: 0.3094177842140198
test loss item: 0.16115058958530426
test loss item: 0.15386931598186493
test loss item: 0.18828681111335754
test loss item: 0.23641295731067657
test loss item: 0.41571044921875
test loss item: 0.309392511844635
test loss item: 0.3198678493499756
test loss item: 0.7020140290260315
test loss item: 0.24777376651763916
test loss item: 0.16521765291690826
test loss item: 0.1826513558626175
test loss item: 0.30408164858818054
test loss item: 0.18195202946662903
test loss item: 0.3825698494911194
test loss item: 0.17259466648101807
test loss item: 0.15670301020145416
test loss item: 0.4717332422733307
test loss item: 0.40463998913764954
test loss item: 0.1730196177959442
test loss item: 0.23353876173496246
test loss item: 0.16331298649311066
test loss item: 0.4717002809047699
test loss item: 0.1917625218629837
test loss item: 0.33267685770988464
test loss item: 0.38712865114212036
test loss item: 0.23611922562122345
test loss item: 0.11025822907686234
test loss item: 0.6963543891906738
test loss item: 0.14861270785331726
test loss item: 0.47640663385391235
test loss item: 0.6013250946998596
test loss item: 0.16767430305480957
test loss item: 0.06437309086322784
test loss item: 0.10673460364341736
Epoch [4/50], Training Loss: 0.4314, Testing Loss: 0.2842
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/50
train loss item: 0.5118881464004517
train loss item: 0.3984571397304535
train loss item: 0.25530698895454407
train loss item: 0.33681821823120117
train loss item: 0.22769978642463684
train loss item: 0.22091111540794373
train loss item: 0.2868576645851135
train loss item: 0.46445000171661377
train loss item: 0.1531766951084137
train loss item: 0.2311016321182251
train loss item: 0.18453653156757355
train loss item: 0.5342930555343628
train loss item: 0.24380940198898315
train loss item: 0.1606401652097702
train loss item: 0.365777850151062
train loss item: 0.6723116040229797
train loss item: 0.19890637695789337
train loss item: 0.9866223931312561
train loss item: 0.5037716627120972
train loss item: 0.2820667028427124
train loss item: 0.16388794779777527
train loss item: 0.1771187037229538
train loss item: 0.26311975717544556
train loss item: 0.20108281075954437
train loss item: 0.15467777848243713
train loss item: 0.6240071654319763
train loss item: 0.11860055476427078
train loss item: 0.8337778449058533
train loss item: 0.19584006071090698
train loss item: 0.15960951149463654
train loss item: 0.9115292429924011
train loss item: 0.24686142802238464
train loss item: 0.24098895490169525
train loss item: 0.4093363881111145
train loss item: 0.26009929180145264
train loss item: 0.20790132880210876
train loss item: 0.18673284351825714
train loss item: 0.09641703963279724
train loss item: 0.9139260649681091
train loss item: 0.1645147055387497
train loss item: 0.13643929362297058
train loss item: 0.31835994124412537
train loss item: 0.3392528295516968
train loss item: 1.6414583921432495
train loss item: 0.2887672483921051
test loss item: 0.19550161063671112
test loss item: 0.2994236946105957
test loss item: 0.22994257509708405
test loss item: 0.48043790459632874
test loss item: 0.24603867530822754
test loss item: 0.4786829948425293
test loss item: 0.14122365415096283
test loss item: 0.20259366929531097
test loss item: 0.21829749643802643
test loss item: 0.2829376757144928
test loss item: 0.27735963463783264
test loss item: 0.20171071588993073
test loss item: 0.17650413513183594
test loss item: 0.24259249866008759
test loss item: 0.26757004857063293
test loss item: 0.40002796053886414
test loss item: 0.29948973655700684
test loss item: 0.30129939317703247
test loss item: 0.621826171875
test loss item: 0.2662537097930908
test loss item: 0.16527876257896423
test loss item: 0.1690477579832077
test loss item: 0.2929086685180664
test loss item: 0.18293209373950958
test loss item: 0.3507876992225647
test loss item: 0.2001214176416397
test loss item: 0.18503925204277039
test loss item: 0.45668745040893555
test loss item: 0.3384855389595032
test loss item: 0.20276853442192078
test loss item: 0.23671270906925201
test loss item: 0.1778458207845688
test loss item: 0.4239494502544403
test loss item: 0.2108328491449356
test loss item: 0.28574711084365845
test loss item: 0.30879294872283936
test loss item: 0.23775243759155273
test loss item: 0.14558373391628265
test loss item: 0.6663407683372498
test loss item: 0.19756272435188293
test loss item: 0.4354705214500427
test loss item: 0.5613390803337097
test loss item: 0.19301073253154755
test loss item: 0.14697960019111633
test loss item: 0.14542344212532043
Epoch [5/50], Training Loss: 0.3661, Testing Loss: 0.2833
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/50
train loss item: 0.46084246039390564
train loss item: 0.29124993085861206
train loss item: 0.17856591939926147
train loss item: 0.3340012729167938
train loss item: 0.22900518774986267
train loss item: 0.19307877123355865
train loss item: 0.24505753815174103
train loss item: 0.42446383833885193
train loss item: 0.1825067698955536
train loss item: 0.2907450199127197
train loss item: 0.1385476440191269
train loss item: 0.45174428820610046
train loss item: 0.2000202089548111
train loss item: 0.15788567066192627
train loss item: 0.3391754627227783
train loss item: 0.6018105149269104
train loss item: 0.18050283193588257
train loss item: 0.7680143117904663
train loss item: 0.3596782982349396
train loss item: 0.229379802942276
train loss item: 0.1296491175889969
train loss item: 0.2428605854511261
train loss item: 0.3597387969493866
train loss item: 0.23036834597587585
train loss item: 0.1584877073764801
train loss item: 0.5805739164352417
train loss item: 0.13082480430603027
train loss item: 0.7857862114906311
train loss item: 0.20420008897781372
train loss item: 0.13103193044662476
train loss item: 0.7884742021560669
train loss item: 0.2919475734233856
train loss item: 0.22753193974494934
train loss item: 0.30056917667388916
train loss item: 0.2467338889837265
train loss item: 0.16434571146965027
train loss item: 0.17150531709194183
train loss item: 0.11826249212026596
train loss item: 0.8173943161964417
train loss item: 0.12529797852039337
train loss item: 0.10768253356218338
train loss item: 0.24191530048847198
train loss item: 0.3802388310432434
train loss item: 1.415191650390625
train loss item: 0.32344722747802734
test loss item: 0.12564949691295624
test loss item: 0.33286014199256897
test loss item: 0.1822153627872467
test loss item: 0.46736693382263184
test loss item: 0.25457534193992615
test loss item: 0.5187902450561523
test loss item: 0.11510709673166275
test loss item: 0.11669038981199265
test loss item: 0.2097650170326233
test loss item: 0.2631450295448303
test loss item: 0.2606631815433502
test loss item: 0.1569305807352066
test loss item: 0.13217826187610626
test loss item: 0.1985919326543808
test loss item: 0.22844645380973816
test loss item: 0.43893304467201233
test loss item: 0.29101502895355225
test loss item: 0.3037087917327881
test loss item: 0.68746417760849
test loss item: 0.24219143390655518
test loss item: 0.14910094439983368
test loss item: 0.17314724624156952
test loss item: 0.24455060064792633
test loss item: 0.15600252151489258
test loss item: 0.38665303587913513
test loss item: 0.16750457882881165
test loss item: 0.15908794105052948
test loss item: 0.5058937072753906
test loss item: 0.33754149079322815
test loss item: 0.15233653783798218
test loss item: 0.23772276937961578
test loss item: 0.13408736884593964
test loss item: 0.4802306592464447
test loss item: 0.17284780740737915
test loss item: 0.2769239544868469
test loss item: 0.2602335214614868
test loss item: 0.19464950263500214
test loss item: 0.10740289092063904
test loss item: 0.79021155834198
test loss item: 0.17324848473072052
test loss item: 0.46452808380126953
test loss item: 0.6338961720466614
test loss item: 0.1439511477947235
test loss item: 0.0722859650850296
test loss item: 0.11821331083774567
Epoch [6/50], Training Loss: 0.3318, Testing Loss: 0.2715
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/50
train loss item: 0.376660019159317
train loss item: 0.24376419186592102
train loss item: 0.13689376413822174
train loss item: 0.20972086489200592
train loss item: 0.17026224732398987
train loss item: 0.18103577196598053
train loss item: 0.2528071701526642
train loss item: 0.5167192220687866
train loss item: 0.1290530413389206
train loss item: 0.1838465929031372
train loss item: 0.14821279048919678
train loss item: 0.45167532563209534
train loss item: 0.18343250453472137
train loss item: 0.20404094457626343
train loss item: 0.24509121477603912
train loss item: 0.39217740297317505
train loss item: 0.2073289304971695
train loss item: 0.6280363202095032
train loss item: 0.3093501627445221
train loss item: 0.23424379527568817
train loss item: 0.15071195363998413
train loss item: 0.17596974968910217
train loss item: 0.22452561557292938
train loss item: 0.18186475336551666
train loss item: 0.12111040204763412
train loss item: 0.5241692662239075
train loss item: 0.08185189217329025
train loss item: 0.5103247761726379
train loss item: 0.1247827336192131
train loss item: 0.09612944722175598
train loss item: 0.4892878830432892
train loss item: 0.2991751432418823
train loss item: 0.17058515548706055
train loss item: 0.2798886001110077
train loss item: 0.2042241096496582
train loss item: 0.11829137057065964
train loss item: 0.12844321131706238
train loss item: 0.07338695973157883
train loss item: 0.8722028732299805
train loss item: 0.1286972314119339
train loss item: 0.09892301261425018
train loss item: 0.26654741168022156
train loss item: 0.2561940550804138
train loss item: 1.0929689407348633
train loss item: 0.2655448019504547
test loss item: 0.10664857923984528
test loss item: 0.21219684183597565
test loss item: 0.12509772181510925
test loss item: 0.40784454345703125
test loss item: 0.14164793491363525
test loss item: 0.3534127175807953
test loss item: 0.09452932327985764
test loss item: 0.10085093230009079
test loss item: 0.1323399543762207
test loss item: 0.20507846772670746
test loss item: 0.183808833360672
test loss item: 0.1027052029967308
test loss item: 0.09573038667440414
test loss item: 0.12664085626602173
test loss item: 0.1471935212612152
test loss item: 0.30260518193244934
test loss item: 0.17380067706108093
test loss item: 0.18729478120803833
test loss item: 0.4774356782436371
test loss item: 0.1500357985496521
test loss item: 0.11258912086486816
test loss item: 0.10533970594406128
test loss item: 0.17010442912578583
test loss item: 0.10794766992330551
test loss item: 0.22841128706932068
test loss item: 0.09933117032051086
test loss item: 0.10489995777606964
test loss item: 0.30186277627944946
test loss item: 0.2494138479232788
test loss item: 0.10640663653612137
test loss item: 0.12618505954742432
test loss item: 0.105065256357193
test loss item: 0.3580602705478668
test loss item: 0.12384460866451263
test loss item: 0.1998225301504135
test loss item: 0.22850409150123596
test loss item: 0.13898079097270966
test loss item: 0.08182110637426376
test loss item: 0.5862157940864563
test loss item: 0.11730889230966568
test loss item: 0.331183522939682
test loss item: 0.4312663674354553
test loss item: 0.10398340225219727
test loss item: 0.06809762865304947
test loss item: 0.08894895762205124
Epoch [7/50], Training Loss: 0.2742, Testing Loss: 0.1889
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/50
train loss item: 0.47564172744750977
train loss item: 0.3108649253845215
train loss item: 0.15812623500823975
train loss item: 0.49305179715156555
train loss item: 0.22650647163391113
train loss item: 0.26103413105010986
train loss item: 0.33352386951446533
train loss item: 0.5514872670173645
train loss item: 0.14265896379947662
train loss item: 0.22635720670223236
train loss item: 0.1573348343372345
train loss item: 0.6616557240486145
train loss item: 0.25196799635887146
train loss item: 0.23330503702163696
train loss item: 0.2504222095012665
train loss item: 0.4495373070240021
train loss item: 0.24330569803714752
train loss item: 0.44384336471557617
train loss item: 0.36229053139686584
train loss item: 0.25172895193099976
train loss item: 0.2108772248029709
train loss item: 0.26541027426719666
train loss item: 0.19484172761440277
train loss item: 0.23356854915618896
train loss item: 0.15433581173419952
train loss item: 0.5755647420883179
train loss item: 0.10028862953186035
train loss item: 0.5470557808876038
train loss item: 0.15949547290802002
train loss item: 0.1263604760169983
train loss item: 0.5686193704605103
train loss item: 0.22944849729537964
train loss item: 0.15575672686100006
train loss item: 0.26284706592559814
train loss item: 0.1974862515926361
train loss item: 0.14595502614974976
train loss item: 0.15681175887584686
train loss item: 0.10057811439037323
train loss item: 0.7494060397148132
train loss item: 0.13394752144813538
train loss item: 0.10798189043998718
train loss item: 0.3014478087425232
train loss item: 0.2115813046693802
train loss item: 0.9815070033073425
train loss item: 0.28765273094177246
test loss item: 0.12319251894950867
test loss item: 0.2054954171180725
test loss item: 0.1338830292224884
test loss item: 0.4217035472393036
test loss item: 0.15540358424186707
test loss item: 0.3416826128959656
test loss item: 0.12794877588748932
test loss item: 0.1065998449921608
test loss item: 0.15956725180149078
test loss item: 0.23369377851486206
test loss item: 0.2132510095834732
test loss item: 0.1726071983575821
test loss item: 0.13850463926792145
test loss item: 0.15051297843456268
test loss item: 0.1636924296617508
test loss item: 0.29668885469436646
test loss item: 0.1870776265859604
test loss item: 0.20285998284816742
test loss item: 0.4579201340675354
test loss item: 0.16932110488414764
test loss item: 0.15794633328914642
test loss item: 0.13530731201171875
test loss item: 0.21804949641227722
test loss item: 0.19199229776859283
test loss item: 0.2405354380607605
test loss item: 0.1355658620595932
test loss item: 0.13040190935134888
test loss item: 0.28449246287345886
test loss item: 0.25010085105895996
test loss item: 0.1327090859413147
test loss item: 0.1429571956396103
test loss item: 0.14515537023544312
test loss item: 0.3163157105445862
test loss item: 0.15747064352035522
test loss item: 0.20128174126148224
test loss item: 0.24429981410503387
test loss item: 0.20202577114105225
test loss item: 0.12836556136608124
test loss item: 0.5160160660743713
test loss item: 0.14934924244880676
test loss item: 0.3076390027999878
test loss item: 0.3983064889907837
test loss item: 0.13633328676223755
test loss item: 0.0751756802201271
test loss item: 0.12885721027851105
Epoch [8/50], Training Loss: 0.3032, Testing Loss: 0.2064
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/50
train loss item: 0.46993744373321533
train loss item: 0.34759071469306946
train loss item: 0.1880125254392624
train loss item: 0.2218480408191681
train loss item: 0.17517074942588806
train loss item: 0.1848209798336029
train loss item: 0.2653789818286896
train loss item: 0.4205528497695923
train loss item: 0.10969223082065582
train loss item: 0.19098621606826782
train loss item: 0.1755891740322113
train loss item: 0.599787175655365
train loss item: 0.19126486778259277
train loss item: 0.12355265021324158
train loss item: 0.2056228369474411
train loss item: 0.463957816362381
train loss item: 0.2596435844898224
train loss item: 0.4401898682117462
train loss item: 0.47354793548583984
train loss item: 0.31300485134124756
train loss item: 0.21919400990009308
train loss item: 0.14787206053733826
train loss item: 0.2116064876317978
train loss item: 0.17094433307647705
train loss item: 0.13635827600955963
train loss item: 0.6081914305686951
train loss item: 0.11429645866155624
train loss item: 0.722362756729126
train loss item: 0.17983026802539825
train loss item: 0.11891281604766846
train loss item: 0.637667715549469
train loss item: 0.1952071189880371
train loss item: 0.21268296241760254
train loss item: 0.33164355158805847
train loss item: 0.19408273696899414
train loss item: 0.17708390951156616
train loss item: 0.24461431801319122
train loss item: 0.09954483807086945
train loss item: 0.5654346346855164
train loss item: 0.16124317049980164
train loss item: 0.11305233091115952
train loss item: 0.297902375459671
train loss item: 0.23655971884727478
train loss item: 0.863521158695221
train loss item: 0.2339879870414734
test loss item: 0.1076713353395462
test loss item: 0.2058778703212738
test loss item: 0.14750944077968597
test loss item: 0.4583144783973694
test loss item: 0.1727057695388794
test loss item: 0.34688451886177063
test loss item: 0.14901164174079895
test loss item: 0.0935012698173523
test loss item: 0.15795588493347168
test loss item: 0.26541420817375183
test loss item: 0.18743383884429932
test loss item: 0.13666610419750214
test loss item: 0.11802523583173752
test loss item: 0.16714759171009064
test loss item: 0.1778729110956192
test loss item: 0.3028632402420044
test loss item: 0.18828357756137848
test loss item: 0.20542630553245544
test loss item: 0.46201232075691223
test loss item: 0.16893543303012848
test loss item: 0.12987928092479706
test loss item: 0.1328919380903244
test loss item: 0.21145497262477875
test loss item: 0.14892934262752533
test loss item: 0.2626493275165558
test loss item: 0.1354244202375412
test loss item: 0.11998416483402252
test loss item: 0.3011123538017273
test loss item: 0.2451857030391693
test loss item: 0.14186401665210724
test loss item: 0.16784261167049408
test loss item: 0.1329984813928604
test loss item: 0.3328916132450104
test loss item: 0.17122752964496613
test loss item: 0.2264377474784851
test loss item: 0.29886162281036377
test loss item: 0.20291775465011597
test loss item: 0.11088887602090836
test loss item: 0.4576551914215088
test loss item: 0.14581988751888275
test loss item: 0.3400142788887024
test loss item: 0.41176795959472656
test loss item: 0.13997285068035126
test loss item: 0.059987735003232956
test loss item: 0.12953203916549683
Epoch [9/50], Training Loss: 0.2892, Testing Loss: 0.2084
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/50
train loss item: 0.3850264847278595
train loss item: 0.199227973818779
train loss item: 0.1443118155002594
train loss item: 0.18646594882011414
train loss item: 0.18763965368270874
train loss item: 0.20796555280685425
train loss item: 0.3070656359195709
train loss item: 0.26665884256362915
train loss item: 0.08799506723880768
train loss item: 0.17614473402500153
train loss item: 0.09917756170034409
train loss item: 0.5777916312217712
train loss item: 0.1801963597536087
train loss item: 0.15518011152744293
train loss item: 0.208848237991333
train loss item: 0.39145633578300476
train loss item: 0.2122974842786789
train loss item: 0.3576621115207672
train loss item: 0.5816726684570312
train loss item: 0.2663452923297882
train loss item: 0.17600277066230774
train loss item: 0.18779335916042328
train loss item: 0.2593153417110443
train loss item: 0.164068341255188
train loss item: 0.12364210933446884
train loss item: 0.4199938178062439
train loss item: 0.09292686730623245
train loss item: 0.4777231216430664
train loss item: 0.13718217611312866
train loss item: 0.09670646488666534
train loss item: 0.4257116913795471
train loss item: 0.2437710464000702
train loss item: 0.1690315157175064
train loss item: 0.22117428481578827
train loss item: 0.19159837067127228
train loss item: 0.14777591824531555
train loss item: 0.14770475029945374
train loss item: 0.09477974474430084
train loss item: 0.6215625405311584
train loss item: 0.11394143849611282
train loss item: 0.08499576151371002
train loss item: 0.2474530041217804
train loss item: 0.30662864446640015
train loss item: 0.7631977796554565
train loss item: 0.20806412398815155
test loss item: 0.11708606034517288
test loss item: 0.20358900725841522
test loss item: 0.12651784718036652
test loss item: 0.46778860688209534
test loss item: 0.1557428538799286
test loss item: 0.338223934173584
test loss item: 0.11767251789569855
test loss item: 0.09538006782531738
test loss item: 0.16636522114276886
test loss item: 0.2599972188472748
test loss item: 0.20828668773174286
test loss item: 0.16071942448616028
test loss item: 0.11259719729423523
test loss item: 0.15256398916244507
test loss item: 0.16976581513881683
test loss item: 0.2763344943523407
test loss item: 0.1669529378414154
test loss item: 0.21661362051963806
test loss item: 0.4452143907546997
test loss item: 0.1675305813550949
test loss item: 0.15962748229503632
test loss item: 0.12482929229736328
test loss item: 0.22735907137393951
test loss item: 0.17029966413974762
test loss item: 0.2536432445049286
test loss item: 0.12221615761518478
test loss item: 0.12535659968852997
test loss item: 0.27721935510635376
test loss item: 0.2874854505062103
test loss item: 0.11662551760673523
test loss item: 0.16043849289417267
test loss item: 0.13525624573230743
test loss item: 0.3483205735683441
test loss item: 0.16813763976097107
test loss item: 0.20879904925823212
test loss item: 0.31848591566085815
test loss item: 0.2301386296749115
test loss item: 0.1297474503517151
test loss item: 0.4714335501194
test loss item: 0.15074913203716278
test loss item: 0.3424518406391144
test loss item: 0.40516069531440735
test loss item: 0.13574092090129852
test loss item: 0.06283742189407349
test loss item: 0.10882475972175598
Epoch [10/50], Training Loss: 0.2512, Testing Loss: 0.2081
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 11/50
train loss item: 0.3187674283981323
train loss item: 0.24789753556251526
train loss item: 0.11799618601799011
train loss item: 0.16260473430156708
train loss item: 0.18000419437885284
train loss item: 0.19243364036083221
train loss item: 0.27350249886512756
train loss item: 0.360370934009552
train loss item: 0.08167068660259247
train loss item: 0.16906042397022247
train loss item: 0.10821914672851562
train loss item: 0.5430183410644531
train loss item: 0.161813884973526
train loss item: 0.14912286400794983
train loss item: 0.2111516147851944
train loss item: 0.36463263630867004
train loss item: 0.22351938486099243
train loss item: 0.3458004891872406
train loss item: 0.296021968126297
train loss item: 0.1704384833574295
train loss item: 0.15744565427303314
train loss item: 0.1700863242149353
train loss item: 0.26476895809173584
train loss item: 0.1523606777191162
train loss item: 0.1045478880405426
train loss item: 0.4261555075645447
train loss item: 0.09963638335466385
train loss item: 0.6344622373580933
train loss item: 0.14861100912094116
train loss item: 0.09551558643579483
train loss item: 0.37230736017227173
train loss item: 0.2578829526901245
train loss item: 0.13586553931236267
train loss item: 0.2034045159816742
train loss item: 0.161470428109169
train loss item: 0.11030667275190353
train loss item: 0.12717071175575256
train loss item: 0.0693264976143837
train loss item: 0.5925683975219727
train loss item: 0.09969516098499298
train loss item: 0.09893128275871277
train loss item: 0.23015819489955902
train loss item: 0.2707865834236145
train loss item: 0.734314501285553
train loss item: 0.1897318959236145
test loss item: 0.11510531604290009
test loss item: 0.23293931782245636
test loss item: 0.15743406116962433
test loss item: 0.3416038155555725
test loss item: 0.19268275797367096
test loss item: 0.3518213629722595
test loss item: 0.125545933842659
test loss item: 0.10928641259670258
test loss item: 0.16751529276371002
test loss item: 0.1993951052427292
test loss item: 0.1988527923822403
test loss item: 0.1536240577697754
test loss item: 0.11315001547336578
test loss item: 0.17155912518501282
test loss item: 0.19069324433803558
test loss item: 0.31150782108306885
test loss item: 0.21276645362377167
test loss item: 0.23703913390636444
test loss item: 0.44780901074409485
test loss item: 0.1915646195411682
test loss item: 0.13208319246768951
test loss item: 0.14059269428253174
test loss item: 0.2173137217760086
test loss item: 0.1615837961435318
test loss item: 0.2760388255119324
test loss item: 0.15286479890346527
test loss item: 0.12781310081481934
test loss item: 0.3493131697177887
test loss item: 0.23535266518592834
test loss item: 0.13923858106136322
test loss item: 0.18339142203330994
test loss item: 0.12341389060020447
test loss item: 0.31059083342552185
test loss item: 0.14865362644195557
test loss item: 0.21150638163089752
test loss item: 0.22224090993404388
test loss item: 0.20362217724323273
test loss item: 0.11539523303508759
test loss item: 0.4973025321960449
test loss item: 0.15587414801120758
test loss item: 0.3103637993335724
test loss item: 0.4171012043952942
test loss item: 0.13542862236499786
test loss item: 0.06429854780435562
test loss item: 0.11864570528268814
Epoch [11/50], Training Loss: 0.2352, Testing Loss: 0.2083
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 12/50
train loss item: 0.3408130705356598
train loss item: 0.19054609537124634
train loss item: 0.15801383554935455
train loss item: 0.19336465001106262
train loss item: 0.17987653613090515
train loss item: 0.23873597383499146
train loss item: 0.3612203001976013
train loss item: 0.4346420168876648
train loss item: 0.12617327272891998
train loss item: 0.2570798099040985
train loss item: 0.12575070559978485
train loss item: 0.8218103647232056
train loss item: 0.24676015973091125
train loss item: 0.23279023170471191
train loss item: 0.26456308364868164
train loss item: 1.0264700651168823
train loss item: 0.28290703892707825
train loss item: 0.46400848031044006
train loss item: 0.5242371559143066
train loss item: 0.4026128053665161
train loss item: 0.4445011019706726
train loss item: 0.3259534239768982
train loss item: 0.6855682730674744
train loss item: 0.2046712338924408
train loss item: 0.14351361989974976
train loss item: 0.4880509376525879
train loss item: 0.11305618286132812
train loss item: 0.4955371618270874
train loss item: 0.2768207788467407
train loss item: 0.17209869623184204
train loss item: 0.8043680787086487
train loss item: 0.3084886074066162
train loss item: 0.4026137590408325
train loss item: 0.256740003824234
train loss item: 0.21484901010990143
train loss item: 0.1811109185218811
train loss item: 0.17091646790504456
train loss item: 0.10670565068721771
train loss item: 0.42322811484336853
train loss item: 0.27863773703575134
train loss item: 0.15234698355197906
train loss item: 0.24213947355747223
train loss item: 0.29245513677597046
train loss item: 0.6947261095046997
train loss item: 0.22211456298828125
test loss item: 0.1362658441066742
test loss item: 0.2265436202287674
test loss item: 0.17224232852458954
test loss item: 0.6642335057258606
test loss item: 0.2107325941324234
test loss item: 0.3088584542274475
test loss item: 0.2067728042602539
test loss item: 0.12988542020320892
test loss item: 0.17658178508281708
test loss item: 0.27475929260253906
test loss item: 0.23715943098068237
test loss item: 0.1605396568775177
test loss item: 0.14698977768421173
test loss item: 0.1678016036748886
test loss item: 0.1946249157190323
test loss item: 0.3535423278808594
test loss item: 0.2195609211921692
test loss item: 0.21318091452121735
test loss item: 0.46955934166908264
test loss item: 0.20895831286907196
test loss item: 0.15736785531044006
test loss item: 0.1740187108516693
test loss item: 0.20240773260593414
test loss item: 0.15552033483982086
test loss item: 0.27019429206848145
test loss item: 0.18616963922977448
test loss item: 0.1532709151506424
test loss item: 0.27798765897750854
test loss item: 0.28260883688926697
test loss item: 0.19281314313411713
test loss item: 0.19959987699985504
test loss item: 0.17591066658496857
test loss item: 0.33421942591667175
test loss item: 0.18665091693401337
test loss item: 0.2545296549797058
test loss item: 0.4234966039657593
test loss item: 0.2289845496416092
test loss item: 0.14118576049804688
test loss item: 0.4295254945755005
test loss item: 0.1603914201259613
test loss item: 0.3812398910522461
test loss item: 0.4172748923301697
test loss item: 0.1427888721227646
test loss item: 0.11037755757570267
test loss item: 0.11735653132200241
Epoch [12/50], Training Loss: 0.3327, Testing Loss: 0.2363
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 13/50
train loss item: 0.30391067266464233
train loss item: 0.20259149372577667
train loss item: 0.18175528943538666
train loss item: 0.1806827187538147
train loss item: 0.17368453741073608
train loss item: 0.1449490785598755
train loss item: 0.1739722341299057
train loss item: 0.23466011881828308
train loss item: 0.14657588303089142
train loss item: 0.18554848432540894
train loss item: 0.17593137919902802
train loss item: 0.2979802191257477
train loss item: 0.15831278264522552
train loss item: 0.1431134045124054
train loss item: 0.19930298626422882
train loss item: 0.5865839123725891
train loss item: 0.14012469351291656
train loss item: 0.31785812973976135
train loss item: 0.18584944307804108
train loss item: 0.2038852423429489
train loss item: 0.14552684128284454
train loss item: 0.17794957756996155
train loss item: 0.19885870814323425
train loss item: 0.20054970681667328
train loss item: 0.13704133033752441
train loss item: 0.4356629550457001
train loss item: 0.10654641687870026
train loss item: 0.5117703676223755
train loss item: 0.13464242219924927
train loss item: 0.10471139848232269
train loss item: 0.34429121017456055
train loss item: 0.22299207746982574
train loss item: 0.14014297723770142
train loss item: 0.195675790309906
train loss item: 0.14228281378746033
train loss item: 0.09507281333208084
train loss item: 0.11017058789730072
train loss item: 0.07747602462768555
train loss item: 0.5696062445640564
train loss item: 0.10642102360725403
train loss item: 0.07978405058383942
train loss item: 0.19050952792167664
train loss item: 0.1977199912071228
train loss item: 0.633901059627533
train loss item: 0.19742034375667572
test loss item: 0.08543705195188522
test loss item: 0.14179939031600952
test loss item: 0.09064678847789764
test loss item: 0.32733914256095886
test loss item: 0.10954916477203369
test loss item: 0.21047966182231903
test loss item: 0.09198015183210373
test loss item: 0.06518144905567169
test loss item: 0.12030515819787979
test loss item: 0.17142842710018158
test loss item: 0.15039218962192535
test loss item: 0.11462108790874481
test loss item: 0.08782589435577393
test loss item: 0.11066702753305435
test loss item: 0.12474103271961212
test loss item: 0.17789927124977112
test loss item: 0.1302643120288849
test loss item: 0.1393498182296753
test loss item: 0.28001946210861206
test loss item: 0.12756019830703735
test loss item: 0.12237738817930222
test loss item: 0.09648671001195908
test loss item: 0.16865547001361847
test loss item: 0.14079855382442474
test loss item: 0.1601087599992752
test loss item: 0.1003330871462822
test loss item: 0.0962337777018547
test loss item: 0.17464061081409454
test loss item: 0.17116087675094604
test loss item: 0.09246401488780975
test loss item: 0.10837387293577194
test loss item: 0.09900785237550735
test loss item: 0.21696476638317108
test loss item: 0.11793367564678192
test loss item: 0.14160650968551636
test loss item: 0.21776804327964783
test loss item: 0.16752713918685913
test loss item: 0.09786662459373474
test loss item: 0.2841164171695709
test loss item: 0.1045575737953186
test loss item: 0.21196185052394867
test loss item: 0.2388412058353424
test loss item: 0.09615184366703033
test loss item: 0.0472048856317997
test loss item: 0.10218305885791779
Epoch [13/50], Training Loss: 0.2176, Testing Loss: 0.1430
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 14/50
train loss item: 0.440755695104599
train loss item: 0.37863054871559143
train loss item: 0.1363581269979477
train loss item: 0.15427307784557343
train loss item: 0.16499020159244537
train loss item: 0.17830534279346466
train loss item: 0.25969743728637695
train loss item: 0.34196195006370544
train loss item: 0.09377188235521317
train loss item: 0.1914684921503067
train loss item: 0.13095125555992126
train loss item: 0.5985245108604431
train loss item: 0.17966803908348083
train loss item: 0.16937324404716492
train loss item: 0.22137676179409027
train loss item: 0.39542582631111145
train loss item: 0.13462980091571808
train loss item: 0.30684295296669006
train loss item: 0.3960285484790802
train loss item: 0.3077033758163452
train loss item: 0.27671578526496887
train loss item: 0.1894606500864029
train loss item: 0.3521561920642853
train loss item: 0.10983474552631378
train loss item: 0.10546073317527771
train loss item: 0.38969558477401733
train loss item: 0.0866403803229332
train loss item: 0.5477548241615295
train loss item: 0.1748214215040207
train loss item: 0.10699868947267532
train loss item: 0.49319392442703247
train loss item: 0.16959148645401
train loss item: 0.21693743765354156
train loss item: 0.1468089073896408
train loss item: 0.19154095649719238
train loss item: 0.12351492047309875
train loss item: 0.15716183185577393
train loss item: 0.07064444571733475
train loss item: 0.3569848835468292
train loss item: 0.1412225365638733
train loss item: 0.07541055232286453
train loss item: 0.18642692267894745
train loss item: 0.1754651665687561
train loss item: 0.5725833177566528
train loss item: 0.15144996345043182
test loss item: 0.08867855370044708
test loss item: 0.1816161721944809
test loss item: 0.12308226525783539
test loss item: 0.34547853469848633
test loss item: 0.1575123816728592
test loss item: 0.28633585572242737
test loss item: 0.14097605645656586
test loss item: 0.08817089349031448
test loss item: 0.12643255293369293
test loss item: 0.18077756464481354
test loss item: 0.1714221090078354
test loss item: 0.11090803891420364
test loss item: 0.10393889993429184
test loss item: 0.1290760487318039
test loss item: 0.15767550468444824
test loss item: 0.2522192895412445
test loss item: 0.16619199514389038
test loss item: 0.1765580177307129
test loss item: 0.3729671239852905
test loss item: 0.1625305563211441
test loss item: 0.10135065019130707
test loss item: 0.10791703313589096
test loss item: 0.181330144405365
test loss item: 0.11696227639913559
test loss item: 0.22243943810462952
test loss item: 0.14346320927143097
test loss item: 0.10752087831497192
test loss item: 0.26316142082214355
test loss item: 0.19546549022197723
test loss item: 0.13908246159553528
test loss item: 0.14429962635040283
test loss item: 0.1242295354604721
test loss item: 0.26803165674209595
test loss item: 0.1337338089942932
test loss item: 0.1714395433664322
test loss item: 0.2353602945804596
test loss item: 0.17402033507823944
test loss item: 0.08411458134651184
test loss item: 0.41429170966148376
test loss item: 0.1168084591627121
test loss item: 0.25226375460624695
test loss item: 0.3309829533100128
test loss item: 0.10217805951833725
test loss item: 0.044727545231580734
test loss item: 0.09144090861082077
Epoch [14/50], Training Loss: 0.2389, Testing Loss: 0.1731
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 15/50
train loss item: 0.27528268098831177
train loss item: 0.14747756719589233
train loss item: 0.12658125162124634
train loss item: 0.23919044435024261
train loss item: 0.1417110115289688
train loss item: 0.14866243302822113
train loss item: 0.2337014526128769
train loss item: 0.22113698720932007
train loss item: 0.07769689708948135
train loss item: 0.18464791774749756
train loss item: 0.10275937616825104
train loss item: 0.5422465801239014
train loss item: 0.19324983656406403
train loss item: 0.18445539474487305
train loss item: 0.22201451659202576
train loss item: 0.5050479769706726
train loss item: 0.16846229135990143
train loss item: 0.3662184178829193
train loss item: 0.2756603956222534
train loss item: 0.1726040244102478
train loss item: 0.13142752647399902
train loss item: 0.15947936475276947
train loss item: 0.26608753204345703
train loss item: 0.14449584484100342
train loss item: 0.11248117685317993
train loss item: 0.32376641035079956
train loss item: 0.06456711143255234
train loss item: 0.3595747649669647
train loss item: 0.11636903882026672
train loss item: 0.06527525931596756
train loss item: 0.37865808606147766
train loss item: 0.19230252504348755
train loss item: 0.14100861549377441
train loss item: 0.1408614069223404
train loss item: 0.14863723516464233
train loss item: 0.10671048611402512
train loss item: 0.10144739598035812
train loss item: 0.06355228275060654
train loss item: 0.41848963499069214
train loss item: 0.0862383171916008
train loss item: 0.08536988496780396
train loss item: 0.1682438999414444
train loss item: 0.20399340987205505
train loss item: 0.5287050604820251
train loss item: 0.16163605451583862
test loss item: 0.08547355234622955
test loss item: 0.14863905310630798
test loss item: 0.08345550298690796
test loss item: 0.3222731053829193
test loss item: 0.10504020750522614
test loss item: 0.23390157520771027
test loss item: 0.09838249534368515
test loss item: 0.06513217091560364
test loss item: 0.12129361927509308
test loss item: 0.19715125858783722
test loss item: 0.14820905029773712
test loss item: 0.12633289396762848
test loss item: 0.09305968135595322
test loss item: 0.11441613733768463
test loss item: 0.119203582406044
test loss item: 0.19060172140598297
test loss item: 0.12091309577226639
test loss item: 0.16652439534664154
test loss item: 0.29584693908691406
test loss item: 0.1208004578948021
test loss item: 0.12015727907419205
test loss item: 0.0964215025305748
test loss item: 0.1677490621805191
test loss item: 0.13684208691120148
test loss item: 0.17760686576366425
test loss item: 0.09135905653238297
test loss item: 0.08915328979492188
test loss item: 0.17895187437534332
test loss item: 0.2049689143896103
test loss item: 0.09012849628925323
test loss item: 0.11352866142988205
test loss item: 0.10718902945518494
test loss item: 0.23589207231998444
test loss item: 0.1264602392911911
test loss item: 0.1660853773355484
test loss item: 0.2240203469991684
test loss item: 0.19084696471691132
test loss item: 0.09969841688871384
test loss item: 0.32838064432144165
test loss item: 0.10410723835229874
test loss item: 0.2402595728635788
test loss item: 0.26910173892974854
test loss item: 0.1082354411482811
test loss item: 0.05541985481977463
test loss item: 0.11405705660581589
Epoch [15/50], Training Loss: 0.2044, Testing Loss: 0.1510
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 16/50
train loss item: 0.31024953722953796
train loss item: 0.22222711145877838
train loss item: 0.10300267487764359
train loss item: 0.13692790269851685
train loss item: 0.12487365305423737
train loss item: 0.1272100955247879
train loss item: 0.2242477685213089
train loss item: 0.26455867290496826
train loss item: 0.0724160224199295
train loss item: 0.15241728723049164
train loss item: 0.10377388447523117
train loss item: 0.44585859775543213
train loss item: 0.1496644914150238
train loss item: 0.14128825068473816
train loss item: 0.21260780096054077
train loss item: 0.3021482229232788
train loss item: 0.17142385244369507
train loss item: 0.26390892267227173
train loss item: 0.17029264569282532
train loss item: 0.15638700127601624
train loss item: 0.1374528408050537
train loss item: 0.13292351365089417
train loss item: 0.22973813116550446
train loss item: 0.13857980072498322
train loss item: 0.09965037554502487
train loss item: 0.32049664855003357
train loss item: 0.06298083811998367
train loss item: 0.3397537171840668
train loss item: 0.09561189264059067
train loss item: 0.06406759470701218
train loss item: 0.29427865147590637
train loss item: 0.17060533165931702
train loss item: 0.13139329850673676
train loss item: 0.1108323410153389
train loss item: 0.11999287456274033
train loss item: 0.08109959214925766
train loss item: 0.08776404708623886
train loss item: 0.06488479673862457
train loss item: 0.3494475185871124
train loss item: 0.0836106389760971
train loss item: 0.07331126928329468
train loss item: 0.14331799745559692
train loss item: 0.15856564044952393
train loss item: 0.4236750900745392
train loss item: 0.13682720065116882
test loss item: 0.08461051434278488
test loss item: 0.13715609908103943
test loss item: 0.09211185574531555
test loss item: 0.3532012104988098
test loss item: 0.09578832238912582
test loss item: 0.21119213104248047
test loss item: 0.08819269388914108
test loss item: 0.061174873262643814
test loss item: 0.11186573654413223
test loss item: 0.1639883667230606
test loss item: 0.14523851871490479
test loss item: 0.1300525814294815
test loss item: 0.08880947530269623
test loss item: 0.10938406735658646
test loss item: 0.11588679254055023
test loss item: 0.2073814421892166
test loss item: 0.11654369533061981
test loss item: 0.12248200178146362
test loss item: 0.2772948443889618
test loss item: 0.12867522239685059
test loss item: 0.1190064325928688
test loss item: 0.08784416317939758
test loss item: 0.16469714045524597
test loss item: 0.1345362812280655
test loss item: 0.16404299437999725
test loss item: 0.0826994925737381
test loss item: 0.08857029676437378
test loss item: 0.17112571001052856
test loss item: 0.15818387269973755
test loss item: 0.0879976749420166
test loss item: 0.09886384010314941
test loss item: 0.10712038725614548
test loss item: 0.22006678581237793
test loss item: 0.12030628323554993
test loss item: 0.13512246310710907
test loss item: 0.2436678260564804
test loss item: 0.2008606642484665
test loss item: 0.09640959650278091
test loss item: 0.32871583104133606
test loss item: 0.11553356796503067
test loss item: 0.2252621054649353
test loss item: 0.24922357499599457
test loss item: 0.10189783573150635
test loss item: 0.04202219471335411
test loss item: 0.09942960739135742
Epoch [16/50], Training Loss: 0.1757, Testing Loss: 0.1441
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 17/50
train loss item: 0.2627917230129242
train loss item: 0.1811557412147522
train loss item: 0.1122988611459732
train loss item: 0.1802631914615631
train loss item: 0.12333745509386063
train loss item: 0.12975582480430603
train loss item: 0.23605775833129883
train loss item: 0.22495844960212708
train loss item: 0.08324582874774933
train loss item: 0.15921612083911896
train loss item: 0.09636057168245316
train loss item: 0.4361291825771332
train loss item: 0.15827961266040802
train loss item: 0.17685003578662872
train loss item: 0.21522878110408783
train loss item: 0.4461497664451599
train loss item: 0.19399411976337433
train loss item: 0.3398277759552002
train loss item: 0.300406813621521
train loss item: 0.20607808232307434
train loss item: 0.1474202424287796
train loss item: 0.12575045228004456
train loss item: 0.24354618787765503
train loss item: 0.12220687419176102
train loss item: 0.0940464437007904
train loss item: 0.26921790838241577
train loss item: 0.061957281082868576
train loss item: 0.30647554993629456
train loss item: 0.10210877656936646
train loss item: 0.0605478510260582
train loss item: 0.31871533393859863
train loss item: 0.17881815135478973
train loss item: 0.10740598291158676
train loss item: 0.11892881244421005
train loss item: 0.12599779665470123
train loss item: 0.08808556199073792
train loss item: 0.10727176070213318
train loss item: 0.0568433552980423
train loss item: 0.30192187428474426
train loss item: 0.07714086771011353
train loss item: 0.07020304352045059
train loss item: 0.15295596420764923
train loss item: 0.1827182024717331
train loss item: 0.4829477071762085
train loss item: 0.14947427809238434
test loss item: 0.0747246965765953
test loss item: 0.1402464061975479
test loss item: 0.08077999204397202
test loss item: 0.2398507446050644
test loss item: 0.09214857965707779
test loss item: 0.23544608056545258
test loss item: 0.07746659964323044
test loss item: 0.05987710505723953
test loss item: 0.103468157351017
test loss item: 0.14548376202583313
test loss item: 0.12973086535930634
test loss item: 0.10596615076065063
test loss item: 0.07884073257446289
test loss item: 0.09697101265192032
test loss item: 0.10252952575683594
test loss item: 0.19383609294891357
test loss item: 0.11549719423055649
test loss item: 0.1297665387392044
test loss item: 0.28992000222206116
test loss item: 0.1071021556854248
test loss item: 0.10014843940734863
test loss item: 0.07932454347610474
test loss item: 0.14580024778842926
test loss item: 0.11776717007160187
test loss item: 0.16325679421424866
test loss item: 0.07996946573257446
test loss item: 0.081243135035038
test loss item: 0.1815401166677475
test loss item: 0.16495323181152344
test loss item: 0.07827205955982208
test loss item: 0.10062067955732346
test loss item: 0.08839544653892517
test loss item: 0.20160990953445435
test loss item: 0.10214570164680481
test loss item: 0.14215077459812164
test loss item: 0.16263267397880554
test loss item: 0.15674681961536407
test loss item: 0.0888572558760643
test loss item: 0.38610032200813293
test loss item: 0.0960584506392479
test loss item: 0.20824114978313446
test loss item: 0.26162785291671753
test loss item: 0.08917481452226639
test loss item: 0.06219086796045303
test loss item: 0.08600012958049774
Epoch [17/50], Training Loss: 0.1848, Testing Loss: 0.1339
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 18/50
train loss item: 0.2722802460193634
train loss item: 0.1593465358018875
train loss item: 0.1102006658911705
train loss item: 0.18101535737514496
train loss item: 0.0987786054611206
train loss item: 0.10704664140939713
train loss item: 0.22940367460250854
train loss item: 0.242402583360672
train loss item: 0.07824769616127014
train loss item: 0.14265789091587067
train loss item: 0.09493424743413925
train loss item: 0.4132747948169708
train loss item: 0.1524653434753418
train loss item: 0.1572028398513794
train loss item: 0.2125777006149292
train loss item: 0.2826245427131653
train loss item: 0.17941701412200928
train loss item: 0.2628408372402191
train loss item: 0.21266674995422363
train loss item: 0.15051120519638062
train loss item: 0.1256767213344574
train loss item: 0.12721312046051025
train loss item: 0.21998722851276398
train loss item: 0.11972955614328384
train loss item: 0.09108229726552963
train loss item: 0.2569681704044342
train loss item: 0.06256815046072006
train loss item: 0.360370010137558
train loss item: 0.09761321544647217
train loss item: 0.06139347329735756
train loss item: 0.30698564648628235
train loss item: 0.1518349051475525
train loss item: 0.12232092022895813
train loss item: 0.10537903010845184
train loss item: 0.11124102026224136
train loss item: 0.0834098756313324
train loss item: 0.09870248287916183
train loss item: 0.05683692544698715
train loss item: 0.2763512134552002
train loss item: 0.09031036496162415
train loss item: 0.06579190492630005
train loss item: 0.12879805266857147
train loss item: 0.1701095551252365
train loss item: 0.47954273223876953
train loss item: 0.12405523657798767
test loss item: 0.08302409201860428
test loss item: 0.14589227735996246
test loss item: 0.08657106757164001
test loss item: 0.42909014225006104
test loss item: 0.09644372016191483
test loss item: 0.24113522469997406
test loss item: 0.08852502703666687
test loss item: 0.056990306824445724
test loss item: 0.12330412864685059
test loss item: 0.2031518667936325
test loss item: 0.15950769186019897
test loss item: 0.13804270327091217
test loss item: 0.09335708618164062
test loss item: 0.11514105647802353
test loss item: 0.11836288124322891
test loss item: 0.25045546889305115
test loss item: 0.12191420793533325
test loss item: 0.14825712144374847
test loss item: 0.3297172486782074
test loss item: 0.130337193608284
test loss item: 0.13167831301689148
test loss item: 0.09627675265073776
test loss item: 0.18066109716892242
test loss item: 0.15081891417503357
test loss item: 0.1928590089082718
test loss item: 0.08047106862068176
test loss item: 0.08940800279378891
test loss item: 0.1888923943042755
test loss item: 0.2024354189634323
test loss item: 0.08346856385469437
test loss item: 0.11201287060976028
test loss item: 0.11284706741571426
test loss item: 0.24602600932121277
test loss item: 0.13133157789707184
test loss item: 0.17068266868591309
test loss item: 0.2874881327152252
test loss item: 0.2163124978542328
test loss item: 0.10947994142770767
test loss item: 0.38506338000297546
test loss item: 0.11916719377040863
test loss item: 0.2814975082874298
test loss item: 0.30907943844795227
test loss item: 0.10906168073415756
test loss item: 0.04728659987449646
test loss item: 0.11330927908420563
Epoch [18/50], Training Loss: 0.1696, Testing Loss: 0.1624
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 19/50
train loss item: 0.2290310561656952
train loss item: 0.16602420806884766
train loss item: 0.10748042911291122
train loss item: 0.1660241335630417
train loss item: 0.08404257893562317
train loss item: 0.10166607052087784
train loss item: 0.1984388381242752
train loss item: 0.1305427998304367
train loss item: 0.06762783974409103
train loss item: 0.13578270375728607
train loss item: 0.09194045513868332
train loss item: 0.29580846428871155
train loss item: 0.127921000123024
train loss item: 0.15250112116336823
train loss item: 0.1847091019153595
train loss item: 0.3182467520236969
train loss item: 0.20493021607398987
train loss item: 0.2424199879169464
train loss item: 0.24922041594982147
train loss item: 0.16304054856300354
train loss item: 0.12295061349868774
train loss item: 0.10307368636131287
train loss item: 0.1901036947965622
train loss item: 0.11765162646770477
train loss item: 0.09242638945579529
train loss item: 0.28768059611320496
train loss item: 0.06978367269039154
train loss item: 0.38167673349380493
train loss item: 0.11251037567853928
train loss item: 0.07734757661819458
train loss item: 0.37723031640052795
train loss item: 0.1282167285680771
train loss item: 0.13255469501018524
train loss item: 0.13199277222156525
train loss item: 0.10994860529899597
train loss item: 0.0935213565826416
train loss item: 0.10988188534975052
train loss item: 0.06699799001216888
train loss item: 0.2582569718360901
train loss item: 0.09810858219861984
train loss item: 0.08131849765777588
train loss item: 0.16228444874286652
train loss item: 0.18629102408885956
train loss item: 0.46266722679138184
train loss item: 0.1074286550283432
test loss item: 0.09553900361061096
test loss item: 0.1539972573518753
test loss item: 0.08223016560077667
test loss item: 0.31984031200408936
test loss item: 0.10425267368555069
test loss item: 0.24744383990764618
test loss item: 0.08559475839138031
test loss item: 0.07386758923530579
test loss item: 0.10697709023952484
test loss item: 0.13940806686878204
test loss item: 0.13833238184452057
test loss item: 0.11562570184469223
test loss item: 0.08920548111200333
test loss item: 0.09843853861093521
test loss item: 0.11217167973518372
test loss item: 0.23397015035152435
test loss item: 0.1316804736852646
test loss item: 0.1411321610212326
test loss item: 0.32281091809272766
test loss item: 0.12598474323749542
test loss item: 0.14128334820270538
test loss item: 0.09916810691356659
test loss item: 0.1435222178697586
test loss item: 0.1433504819869995
test loss item: 0.16389784216880798
test loss item: 0.09694210439920425
test loss item: 0.1040160059928894
test loss item: 0.19942694902420044
test loss item: 0.1689291149377823
test loss item: 0.08846566081047058
test loss item: 0.10083737969398499
test loss item: 0.10099686682224274
test loss item: 0.23472557961940765
test loss item: 0.09969352930784225
test loss item: 0.1425568014383316
test loss item: 0.19622477889060974
test loss item: 0.15753646194934845
test loss item: 0.10715252161026001
test loss item: 0.43514513969421387
test loss item: 0.11413074284791946
test loss item: 0.24384735524654388
test loss item: 0.29704877734184265
test loss item: 0.09674438089132309
test loss item: 0.09188096970319748
test loss item: 0.13690701127052307
Epoch [19/50], Training Loss: 0.1662, Testing Loss: 0.1516
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 20/50
train loss item: 0.2526750862598419
train loss item: 0.19858233630657196
train loss item: 0.1373118907213211
train loss item: 0.300648957490921
train loss item: 0.07188840955495834
train loss item: 0.1014106348156929
train loss item: 0.14981454610824585
train loss item: 0.22474710643291473
train loss item: 0.0823543518781662
train loss item: 0.15993565320968628
train loss item: 0.12909848988056183
train loss item: 0.39289426803588867
train loss item: 0.15737217664718628
train loss item: 0.17438071966171265
train loss item: 0.3018505573272705
train loss item: 0.4872300624847412
train loss item: 0.23492981493473053
train loss item: 0.3030490279197693
train loss item: 0.25430721044540405
train loss item: 0.16330327093601227
train loss item: 0.12658070027828217
train loss item: 0.09477324038743973
train loss item: 0.20435158908367157
train loss item: 0.12308934330940247
train loss item: 0.07552589476108551
train loss item: 0.31864839792251587
train loss item: 0.05437614023685455
train loss item: 0.28178495168685913
train loss item: 0.10114375501871109
train loss item: 0.06460383534431458
train loss item: 0.32900670170783997
train loss item: 0.1562798172235489
train loss item: 0.11628042906522751
train loss item: 0.1461784690618515
train loss item: 0.13514359295368195
train loss item: 0.10207492858171463
train loss item: 0.10961166024208069
train loss item: 0.06092538684606552
train loss item: 0.24539496004581451
train loss item: 0.09979970008134842
train loss item: 0.08005894720554352
train loss item: 0.139817014336586
train loss item: 0.17622840404510498
train loss item: 0.6179536581039429
train loss item: 0.12486434727907181
test loss item: 0.08643395453691483
test loss item: 0.16890999674797058
test loss item: 0.08596640825271606
test loss item: 0.45890170335769653
test loss item: 0.10843800753355026
test loss item: 0.30564960837364197
test loss item: 0.08609607070684433
test loss item: 0.07982105761766434
test loss item: 0.11951792985200882
test loss item: 0.18281105160713196
test loss item: 0.17359769344329834
test loss item: 0.11108442395925522
test loss item: 0.09149207174777985
test loss item: 0.10478829592466354
test loss item: 0.12378744781017303
test loss item: 0.3115030527114868
test loss item: 0.1510707288980484
test loss item: 0.14419609308242798
test loss item: 0.4114038348197937
test loss item: 0.1501316875219345
test loss item: 0.12804169952869415
test loss item: 0.09639201313257217
test loss item: 0.17473956942558289
test loss item: 0.12139248847961426
test loss item: 0.20861461758613586
test loss item: 0.09689896553754807
test loss item: 0.09536566585302353
test loss item: 0.23914827406406403
test loss item: 0.2063232809305191
test loss item: 0.09252551943063736
test loss item: 0.12438558787107468
test loss item: 0.10749167203903198
test loss item: 0.2767888009548187
test loss item: 0.12028477340936661
test loss item: 0.17489369213581085
test loss item: 0.2929346561431885
test loss item: 0.19882066547870636
test loss item: 0.08993059396743774
test loss item: 0.5486626625061035
test loss item: 0.10380295664072037
test loss item: 0.3221970796585083
test loss item: 0.38687780499458313
test loss item: 0.09002740681171417
test loss item: 0.08656425774097443
test loss item: 0.13803374767303467
Epoch [20/50], Training Loss: 0.1858, Testing Loss: 0.1773
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 21/50
train loss item: 0.20068621635437012
train loss item: 0.13693267107009888
train loss item: 0.11959534138441086
train loss item: 0.26321253180503845
train loss item: 0.08840028196573257
train loss item: 0.10373860597610474
train loss item: 0.1468815952539444
train loss item: 0.1339419037103653
train loss item: 0.05851280316710472
train loss item: 0.16198983788490295
train loss item: 0.1080760732293129
train loss item: 0.2074126899242401
train loss item: 0.13975143432617188
train loss item: 0.14574389159679413
train loss item: 0.22987723350524902
train loss item: 0.45196640491485596
train loss item: 0.19741690158843994
train loss item: 0.24818207323551178
train loss item: 0.23934853076934814
train loss item: 0.20646516978740692
train loss item: 0.132177472114563
train loss item: 0.1038251668214798
train loss item: 0.19934804737567902
train loss item: 0.13639120757579803
train loss item: 0.10370998084545135
train loss item: 0.3047199845314026
train loss item: 0.08846420794725418
train loss item: 0.2983144223690033
train loss item: 0.10565982758998871
train loss item: 0.07600631564855576
train loss item: 0.3173220753669739
train loss item: 0.12455135583877563
train loss item: 0.1410841941833496
train loss item: 0.16215111315250397
train loss item: 0.10316266119480133
train loss item: 0.09670430421829224
train loss item: 0.10140588134527206
train loss item: 0.07335291802883148
train loss item: 0.3728565275669098
train loss item: 0.09717115759849548
train loss item: 0.07414791733026505
train loss item: 0.19764523208141327
train loss item: 0.14613233506679535
train loss item: 0.34872397780418396
train loss item: 0.1310441642999649
test loss item: 0.09431276470422745
test loss item: 0.14780910313129425
test loss item: 0.09343148022890091
test loss item: 0.34508928656578064
test loss item: 0.10545911639928818
test loss item: 0.2257857620716095
test loss item: 0.09868256002664566
test loss item: 0.084977887570858
test loss item: 0.1143130362033844
test loss item: 0.15517914295196533
test loss item: 0.13872985541820526
test loss item: 0.11078289896249771
test loss item: 0.08543671667575836
test loss item: 0.10468176752328873
test loss item: 0.1212584525346756
test loss item: 0.21814492344856262
test loss item: 0.1159607544541359
test loss item: 0.11360839009284973
test loss item: 0.2988370954990387
test loss item: 0.12034410983324051
test loss item: 0.13008810579776764
test loss item: 0.09361528605222702
test loss item: 0.15374130010604858
test loss item: 0.13228106498718262
test loss item: 0.16255952417850494
test loss item: 0.0879894495010376
test loss item: 0.09379845857620239
test loss item: 0.17785325646400452
test loss item: 0.15995359420776367
test loss item: 0.0950377881526947
test loss item: 0.1040463000535965
test loss item: 0.10794197767972946
test loss item: 0.22825978696346283
test loss item: 0.11935048550367355
test loss item: 0.13864557445049286
test loss item: 0.22781461477279663
test loss item: 0.17224188148975372
test loss item: 0.10685443878173828
test loss item: 0.3958909213542938
test loss item: 0.11093466728925705
test loss item: 0.23785582184791565
test loss item: 0.27675288915634155
test loss item: 0.09765724837779999
test loss item: 0.05527656525373459
test loss item: 0.0991695299744606
Epoch [21/50], Training Loss: 0.1694, Testing Loss: 0.1480
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 22/50
train loss item: 0.20075194537639618
train loss item: 0.18863995373249054
train loss item: 0.13541129231452942
train loss item: 0.16044647991657257
train loss item: 0.08865936845541
train loss item: 0.08490515500307083
train loss item: 0.12154097110033035
train loss item: 0.13995026051998138
train loss item: 0.09904368966817856
train loss item: 0.15048328042030334
train loss item: 0.15561801195144653
train loss item: 0.2605946958065033
train loss item: 0.13768893480300903
train loss item: 0.13902440667152405
train loss item: 0.2582760453224182
train loss item: 0.224336177110672
train loss item: 0.20020893216133118
train loss item: 0.2355048507452011
train loss item: 0.14259469509124756
train loss item: 0.19972693920135498
train loss item: 0.12680400907993317
train loss item: 0.09757509082555771
train loss item: 0.28090694546699524
train loss item: 0.13854172825813293
train loss item: 0.09889295697212219
train loss item: 0.29571405053138733
train loss item: 0.07002223283052444
train loss item: 0.4048272967338562
train loss item: 0.1482291966676712
train loss item: 0.09675218909978867
train loss item: 0.3042755424976349
train loss item: 0.17217254638671875
train loss item: 0.11890095472335815
train loss item: 0.150381937623024
train loss item: 0.14579549431800842
train loss item: 0.10236631333827972
train loss item: 0.11456809937953949
train loss item: 0.08100736886262894
train loss item: 0.3076694905757904
train loss item: 0.09041953831911087
train loss item: 0.08826424926519394
train loss item: 0.14260081946849823
train loss item: 0.1737792193889618
train loss item: 0.4472180902957916
train loss item: 0.12964536249637604
test loss item: 0.09857357293367386
test loss item: 0.14375612139701843
test loss item: 0.09235469996929169
test loss item: 0.3760087490081787
test loss item: 0.10538696497678757
test loss item: 0.20579449832439423
test loss item: 0.11156649887561798
test loss item: 0.07594615966081619
test loss item: 0.1286030113697052
test loss item: 0.1817125380039215
test loss item: 0.15354813635349274
test loss item: 0.1496558040380478
test loss item: 0.09219224750995636
test loss item: 0.1192474439740181
test loss item: 0.1274384707212448
test loss item: 0.22402435541152954
test loss item: 0.11567471921443939
test loss item: 0.12072402238845825
test loss item: 0.267433762550354
test loss item: 0.1272570639848709
test loss item: 0.14979183673858643
test loss item: 0.09756117314100266
test loss item: 0.1873832792043686
test loss item: 0.17667819559574127
test loss item: 0.16856378316879272
test loss item: 0.0960494801402092
test loss item: 0.09512906521558762
test loss item: 0.15667560696601868
test loss item: 0.15595433115959167
test loss item: 0.09898407012224197
test loss item: 0.11108963191509247
test loss item: 0.12395519018173218
test loss item: 0.19518300890922546
test loss item: 0.13534235954284668
test loss item: 0.13578343391418457
test loss item: 0.2519787847995758
test loss item: 0.22889529168605804
test loss item: 0.13261529803276062
test loss item: 0.31408417224884033
test loss item: 0.1311797946691513
test loss item: 0.22909550368785858
test loss item: 0.2469010353088379
test loss item: 0.11636017262935638
test loss item: 0.04963117465376854
test loss item: 0.12224438041448593
Epoch [22/50], Training Loss: 0.1700, Testing Loss: 0.1539
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 23/50
train loss item: 0.2606080174446106
train loss item: 0.1639871448278427
train loss item: 0.12423691153526306
train loss item: 0.2026311159133911
train loss item: 0.08723589777946472
train loss item: 0.08556333929300308
train loss item: 0.15987184643745422
train loss item: 0.12727326154708862
train loss item: 0.06086338311433792
train loss item: 0.13172321021556854
train loss item: 0.10076892375946045
train loss item: 0.31006699800491333
train loss item: 0.13120990991592407
train loss item: 0.13986894488334656
train loss item: 0.1685825139284134
train loss item: 0.21612562239170074
train loss item: 0.13214944303035736
train loss item: 0.38841620087623596
train loss item: 0.2662237286567688
train loss item: 0.15130771696567535
train loss item: 0.10463870316743851
train loss item: 0.0914560928940773
train loss item: 0.17229697108268738
train loss item: 0.09695213288068771
train loss item: 0.0691518634557724
train loss item: 0.2377837598323822
train loss item: 0.05555160716176033
train loss item: 0.25943848490715027
train loss item: 0.08805535733699799
train loss item: 0.053456861525774
train loss item: 0.2777962386608124
train loss item: 0.1295911967754364
train loss item: 0.10551725327968597
train loss item: 0.1352890431880951
train loss item: 0.10662466287612915
train loss item: 0.07323743402957916
train loss item: 0.08185876905918121
train loss item: 0.050952114164829254
train loss item: 0.2551475167274475
train loss item: 0.09174487739801407
train loss item: 0.07637354731559753
train loss item: 0.11697018891572952
train loss item: 0.1681791990995407
train loss item: 0.37770962715148926
train loss item: 0.09983447194099426
test loss item: 0.08050201833248138
test loss item: 0.13804370164871216
test loss item: 0.0853940099477768
test loss item: 0.26430830359458923
test loss item: 0.08799005299806595
test loss item: 0.22256216406822205
test loss item: 0.08234567940235138
test loss item: 0.06976375728845596
test loss item: 0.1141168624162674
test loss item: 0.14008741080760956
test loss item: 0.1328166127204895
test loss item: 0.11124885827302933
test loss item: 0.08667922765016556
test loss item: 0.0973002091050148
test loss item: 0.11023726314306259
test loss item: 0.2013387382030487
test loss item: 0.11909586936235428
test loss item: 0.11024294793605804
test loss item: 0.27982914447784424
test loss item: 0.11367536336183548
test loss item: 0.12236548215150833
test loss item: 0.09465046226978302
test loss item: 0.14911818504333496
test loss item: 0.13487349450588226
test loss item: 0.14948609471321106
test loss item: 0.07702982425689697
test loss item: 0.08967778831720352
test loss item: 0.16704043745994568
test loss item: 0.1477474421262741
test loss item: 0.08201002329587936
test loss item: 0.09594149142503738
test loss item: 0.09888744354248047
test loss item: 0.20416797697544098
test loss item: 0.10806724429130554
test loss item: 0.12765517830848694
test loss item: 0.17726051807403564
test loss item: 0.1675444096326828
test loss item: 0.10432948917150497
test loss item: 0.4068487584590912
test loss item: 0.10539846122264862
test loss item: 0.21817456185817719
test loss item: 0.26415354013442993
test loss item: 0.09622005373239517
test loss item: 0.03949109464883804
test loss item: 0.12734203040599823
Epoch [23/50], Training Loss: 0.1508, Testing Loss: 0.1378
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 24/50
train loss item: 0.20534759759902954
train loss item: 0.16574010252952576
train loss item: 0.1171957328915596
train loss item: 0.20919381082057953
train loss item: 0.07472455501556396
train loss item: 0.08834820240736008
train loss item: 0.15831977128982544
train loss item: 0.13824985921382904
train loss item: 0.08837893605232239
train loss item: 0.11172345280647278
train loss item: 0.10001784563064575
train loss item: 0.29890692234039307
train loss item: 0.11469554156064987
train loss item: 0.15092384815216064
train loss item: 0.19625204801559448
train loss item: 0.24498505890369415
train loss item: 0.16224481165409088
train loss item: 0.37069401144981384
train loss item: 0.2722454369068146
train loss item: 0.16147950291633606
train loss item: 0.10986708849668503
train loss item: 0.08780701458454132
train loss item: 0.1742369532585144
train loss item: 0.1069440096616745
train loss item: 0.07438404113054276
train loss item: 0.20101556181907654
train loss item: 0.05637773498892784
train loss item: 0.19094030559062958
train loss item: 0.08625748008489609
train loss item: 0.059785276651382446
train loss item: 0.2487642765045166
train loss item: 0.13154268264770508
train loss item: 0.11148857325315475
train loss item: 0.11413302272558212
train loss item: 0.1111413985490799
train loss item: 0.08845280110836029
train loss item: 0.09174081683158875
train loss item: 0.061991624534130096
train loss item: 0.23404276371002197
train loss item: 0.08362845331430435
train loss item: 0.0739886537194252
train loss item: 0.17791327834129333
train loss item: 0.21599745750427246
train loss item: 0.5241515636444092
train loss item: 0.09271802753210068
test loss item: 0.08483254909515381
test loss item: 0.1770416498184204
test loss item: 0.09201249480247498
test loss item: 0.47910213470458984
test loss item: 0.11779972910881042
test loss item: 0.3205326199531555
test loss item: 0.11779452115297318
test loss item: 0.06973566114902496
test loss item: 0.12480693310499191
test loss item: 0.20620152354240417
test loss item: 0.17564567923545837
test loss item: 0.11825387179851532
test loss item: 0.09553135931491852
test loss item: 0.10931993275880814
test loss item: 0.13266490399837494
test loss item: 0.3283238708972931
test loss item: 0.15319663286209106
test loss item: 0.15735048055648804
test loss item: 0.4345235824584961
test loss item: 0.14840532839298248
test loss item: 0.13898205757141113
test loss item: 0.09763942658901215
test loss item: 0.18782855570316315
test loss item: 0.14466062188148499
test loss item: 0.22189262509346008
test loss item: 0.10643412917852402
test loss item: 0.09188618510961533
test loss item: 0.2529493272304535
test loss item: 0.21683943271636963
test loss item: 0.1108422577381134
test loss item: 0.1226971447467804
test loss item: 0.13276366889476776
test loss item: 0.2947601079940796
test loss item: 0.12747368216514587
test loss item: 0.1853908747434616
test loss item: 0.30413728952407837
test loss item: 0.20806258916854858
test loss item: 0.10732053965330124
test loss item: 0.5760712027549744
test loss item: 0.12185165286064148
test loss item: 0.33622512221336365
test loss item: 0.4114838242530823
test loss item: 0.10390935838222504
test loss item: 0.046637531369924545
test loss item: 0.16610147058963776
Epoch [24/50], Training Loss: 0.1542, Testing Loss: 0.1880
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 25/50
train loss item: 0.18888145685195923
train loss item: 0.13918617367744446
train loss item: 0.09959986805915833
train loss item: 0.30485209822654724
train loss item: 0.10795409977436066
train loss item: 0.11790626496076584
train loss item: 0.1447700560092926
train loss item: 0.14502213895320892
train loss item: 0.05430423095822334
train loss item: 0.16678756475448608
train loss item: 0.11341038346290588
train loss item: 0.3403383791446686
train loss item: 0.17211569845676422
train loss item: 0.16408059000968933
train loss item: 0.2633745074272156
train loss item: 0.29198044538497925
train loss item: 0.19238761067390442
train loss item: 0.2667900025844574
train loss item: 0.32751402258872986
train loss item: 0.22741563618183136
train loss item: 0.15232960879802704
train loss item: 0.12362967431545258
train loss item: 0.17828235030174255
train loss item: 0.11378499120473862
train loss item: 0.08849039673805237
train loss item: 0.2990567982196808
train loss item: 0.08048873394727707
train loss item: 0.3072604835033417
train loss item: 0.1334104686975479
train loss item: 0.08444467186927795
train loss item: 0.39083850383758545
train loss item: 0.15526913106441498
train loss item: 0.13414135575294495
train loss item: 0.14227135479450226
train loss item: 0.1466871201992035
train loss item: 0.1594579964876175
train loss item: 0.14009760320186615
train loss item: 0.07154412567615509
train loss item: 0.1963243931531906
train loss item: 0.10145855695009232
train loss item: 0.06810639053583145
train loss item: 0.14710158109664917
train loss item: 0.16445958614349365
train loss item: 0.38206544518470764
train loss item: 0.12922197580337524
test loss item: 0.08218017965555191
test loss item: 0.15455973148345947
test loss item: 0.08459258824586868
test loss item: 0.3869815170764923
test loss item: 0.1068086251616478
test loss item: 0.26281410455703735
test loss item: 0.1113852709531784
test loss item: 0.07586748898029327
test loss item: 0.11286972463130951
test loss item: 0.16289550065994263
test loss item: 0.13875506818294525
test loss item: 0.10672660171985626
test loss item: 0.08587391674518585
test loss item: 0.10145208984613419
test loss item: 0.11929486691951752
test loss item: 0.25743207335472107
test loss item: 0.12264251708984375
test loss item: 0.10940156131982803
test loss item: 0.34016141295433044
test loss item: 0.1282571256160736
test loss item: 0.12223070114850998
test loss item: 0.09364070743322372
test loss item: 0.1600266546010971
test loss item: 0.12909777462482452
test loss item: 0.17417190968990326
test loss item: 0.09135253727436066
test loss item: 0.08848421275615692
test loss item: 0.1974060833454132
test loss item: 0.15411053597927094
test loss item: 0.1031428873538971
test loss item: 0.10247917473316193
test loss item: 0.11439304798841476
test loss item: 0.2460108995437622
test loss item: 0.12484759092330933
test loss item: 0.14313699305057526
test loss item: 0.2485039234161377
test loss item: 0.18843545019626617
test loss item: 0.09755843877792358
test loss item: 0.46676400303840637
test loss item: 0.10234416276216507
test loss item: 0.2725115418434143
test loss item: 0.3239154815673828
test loss item: 0.09144243597984314
test loss item: 0.043656591325998306
test loss item: 0.09770634025335312
Epoch [25/50], Training Loss: 0.1760, Testing Loss: 0.1562
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 26/50
train loss item: 0.1729346513748169
train loss item: 0.1288577914237976
train loss item: 0.09729240089654922
train loss item: 0.18854476511478424
train loss item: 0.12856325507164001
train loss item: 0.1401681900024414
train loss item: 0.11348601430654526
train loss item: 0.16971474885940552
train loss item: 0.054086972028017044
train loss item: 0.15527097880840302
train loss item: 0.12376520037651062
train loss item: 0.348489373922348
train loss item: 0.1957259178161621
train loss item: 0.188432976603508
train loss item: 0.32901498675346375
train loss item: 0.2714511454105377
train loss item: 0.1919945925474167
train loss item: 0.41905784606933594
train loss item: 0.34332823753356934
train loss item: 0.2414843738079071
train loss item: 0.14391231536865234
train loss item: 0.12699416279792786
train loss item: 0.15814487636089325
train loss item: 0.13323909044265747
train loss item: 0.08249550312757492
train loss item: 0.23739872872829437
train loss item: 0.06907331198453903
train loss item: 0.22727227210998535
train loss item: 0.15702036023139954
train loss item: 0.09637551009654999
train loss item: 0.4080905020236969
train loss item: 0.2415475994348526
train loss item: 0.1836850792169571
train loss item: 0.15136471390724182
train loss item: 0.1181255578994751
train loss item: 0.08016768097877502
train loss item: 0.1224798858165741
train loss item: 0.0630752369761467
train loss item: 0.20598198473453522
train loss item: 0.10389585047960281
train loss item: 0.08798486739397049
train loss item: 0.13666915893554688
train loss item: 0.1228058934211731
train loss item: 0.28706979751586914
train loss item: 0.10991984605789185
test loss item: 0.08450420945882797
test loss item: 0.2235732078552246
test loss item: 0.10212083905935287
test loss item: 0.6672216057777405
test loss item: 0.15420664846897125
test loss item: 0.3675481081008911
test loss item: 0.1461474895477295
test loss item: 0.07954349368810654
test loss item: 0.1504993736743927
test loss item: 0.24911725521087646
test loss item: 0.22663693130016327
test loss item: 0.13034096360206604
test loss item: 0.10278868675231934
test loss item: 0.12178289890289307
test loss item: 0.15288545191287994
test loss item: 0.40516364574432373
test loss item: 0.19817319512367249
test loss item: 0.1829574555158615
test loss item: 0.5318166613578796
test loss item: 0.18412767350673676
test loss item: 0.14227890968322754
test loss item: 0.12638261914253235
test loss item: 0.22198952734470367
test loss item: 0.14985574781894684
test loss item: 0.2833184003829956
test loss item: 0.1417676955461502
test loss item: 0.10601834207773209
test loss item: 0.3190588653087616
test loss item: 0.2646305561065674
test loss item: 0.13524511456489563
test loss item: 0.15548929572105408
test loss item: 0.13796080648899078
test loss item: 0.37742534279823303
test loss item: 0.15244625508785248
test loss item: 0.22301462292671204
test loss item: 0.41678690910339355
test loss item: 0.22925500571727753
test loss item: 0.10615751147270203
test loss item: 0.6595122218132019
test loss item: 0.11084829270839691
test loss item: 0.425701767206192
test loss item: 0.5049891471862793
test loss item: 0.11064808070659637
test loss item: 0.04615459218621254
test loss item: 0.10069914907217026
Epoch [26/50], Training Loss: 0.1746, Testing Loss: 0.2246
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 27/50
train loss item: 0.24213875830173492
train loss item: 0.2067309021949768
train loss item: 0.09871998429298401
train loss item: 0.1239093691110611
train loss item: 0.10815416276454926
train loss item: 0.13983845710754395
train loss item: 0.19229531288146973
train loss item: 0.12190417945384979
train loss item: 0.1379919797182083
train loss item: 0.12147091329097748
train loss item: 0.10252489894628525
train loss item: 0.3447256088256836
train loss item: 0.18755944073200226
train loss item: 0.13091936707496643
train loss item: 0.35787490010261536
train loss item: 0.34725096821784973
train loss item: 0.2446775883436203
train loss item: 0.32723236083984375
train loss item: 0.27690938115119934
train loss item: 0.29682737588882446
train loss item: 0.19567491114139557
train loss item: 0.15152108669281006
train loss item: 0.34597790241241455
train loss item: 0.1356564313173294
train loss item: 0.1094876229763031
train loss item: 0.35078054666519165
train loss item: 0.09471540153026581
train loss item: 0.31193941831588745
train loss item: 0.1166834905743599
train loss item: 0.11166869848966599
train loss item: 0.4653325080871582
train loss item: 0.10425063222646713
train loss item: 0.1401868611574173
train loss item: 0.16039395332336426
train loss item: 0.1319168359041214
train loss item: 0.11549083888530731
train loss item: 0.12167809903621674
train loss item: 0.09983539581298828
train loss item: 0.5581921935081482
train loss item: 0.09601566940546036
train loss item: 0.08975175023078918
train loss item: 0.2136543095111847
train loss item: 0.21290642023086548
train loss item: 0.3194153904914856
train loss item: 0.12457720190286636
test loss item: 0.1037391796708107
test loss item: 0.15555423498153687
test loss item: 0.1052665039896965
test loss item: 0.3527257740497589
test loss item: 0.10353890806436539
test loss item: 0.24814119935035706
test loss item: 0.10395295917987823
test loss item: 0.09681736677885056
test loss item: 0.12787798047065735
test loss item: 0.20418919622898102
test loss item: 0.1592804342508316
test loss item: 0.13789480924606323
test loss item: 0.09190543740987778
test loss item: 0.12384933233261108
test loss item: 0.1312784105539322
test loss item: 0.2167905867099762
test loss item: 0.13208694756031036
test loss item: 0.14304183423519135
test loss item: 0.31887343525886536
test loss item: 0.12503793835639954
test loss item: 0.1369040459394455
test loss item: 0.09312038123607635
test loss item: 0.19368138909339905
test loss item: 0.163585364818573
test loss item: 0.1801830232143402
test loss item: 0.0996931865811348
test loss item: 0.09139865636825562
test loss item: 0.19349446892738342
test loss item: 0.19223754107952118
test loss item: 0.09603744745254517
test loss item: 0.11075389385223389
test loss item: 0.12056741863489151
test loss item: 0.26859351992607117
test loss item: 0.13315248489379883
test loss item: 0.15352290868759155
test loss item: 0.24631959199905396
test loss item: 0.21005378663539886
test loss item: 0.12308020144701004
test loss item: 0.3919858932495117
test loss item: 0.1257578581571579
test loss item: 0.2466905564069748
test loss item: 0.2908453345298767
test loss item: 0.11760947108268738
test loss item: 0.06944312155246735
test loss item: 0.14658649265766144
Epoch [27/50], Training Loss: 0.1997, Testing Loss: 0.1639
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.11219392716884613
loss item: 0.3830980956554413
loss item: 0.20304979383945465
loss item: 0.19093409180641174
loss item: 0.11844141036272049
loss item: 0.3101077973842621
loss item: 0.20528478920459747
loss item: 0.12521488964557648
loss item: 0.16350582242012024
loss item: 0.27419546246528625
loss item: 0.14954587817192078
loss item: 0.16813905537128448
loss item: 0.20451347529888153
loss item: 0.2226845622062683
loss item: 0.19515562057495117
loss item: 0.379072368144989
loss item: 0.15465833246707916
loss item: 0.12476256489753723
loss item: 0.1339183747768402
loss item: 0.18434016406536102
loss item: 0.26672399044036865
loss item: 0.10347039252519608
Val Loss: 0.1988
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 50, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.001 4 360 done at Tue Nov 12 10:55:25 CET 2024
UNet2 with 1 50 0.005 4 360 start at Tue Nov 12 10:55:25 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 50, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.6336421966552734
train loss item: 1.347577691078186
train loss item: 1.2426575422286987
train loss item: 1.403577446937561
train loss item: 0.49251851439476013
train loss item: 0.45189368724823
train loss item: 0.523338794708252
train loss item: 0.8533712029457092
train loss item: 0.4423550069332123
train loss item: 0.49863359332084656
train loss item: 0.28157615661621094
train loss item: 1.4692952632904053
train loss item: 0.6577840447425842
train loss item: 0.43952804803848267
train loss item: 1.1109474897384644
train loss item: 2.2161989212036133
train loss item: 0.6377905011177063
train loss item: 2.557669162750244
train loss item: 0.5520955920219421
train loss item: 0.5395609736442566
train loss item: 0.3840208053588867
train loss item: 0.47386613488197327
train loss item: 0.5512625575065613
train loss item: 0.5325104594230652
train loss item: 0.3741435110569
train loss item: 1.080769658088684
train loss item: 0.32202449440956116
train loss item: 1.9903427362442017
train loss item: 0.39721742272377014
train loss item: 0.18291355669498444
train loss item: 1.9903628826141357
train loss item: 0.585350751876831
train loss item: 0.6599414944648743
train loss item: 0.43473342061042786
train loss item: 0.5474609732627869
train loss item: 0.346159964799881
train loss item: 0.35071614384651184
train loss item: 0.28084033727645874
train loss item: 1.416642427444458
train loss item: 0.27042609453201294
train loss item: 0.35390377044677734
train loss item: 0.630920946598053
train loss item: 0.6428886651992798
train loss item: 3.4514591693878174
train loss item: 0.4955306947231293
test loss item: 0.18652459979057312
test loss item: 0.5123259425163269
test loss item: 0.23698683083057404
test loss item: 1.199652075767517
test loss item: 0.37343162298202515
test loss item: 0.839149534702301
test loss item: 0.20760200917720795
test loss item: 0.15818800032138824
test loss item: 0.4415561258792877
test loss item: 0.5559232234954834
test loss item: 0.5511224865913391
test loss item: 0.28916239738464355
test loss item: 0.28136152029037476
test loss item: 0.31867167353630066
test loss item: 0.4116658568382263
test loss item: 0.7880279421806335
test loss item: 0.5528665781021118
test loss item: 0.5054436326026917
test loss item: 1.2191683053970337
test loss item: 0.482201486825943
test loss item: 0.33643874526023865
test loss item: 0.3294539451599121
test loss item: 0.5891830921173096
test loss item: 0.3420000672340393
test loss item: 0.6437329649925232
test loss item: 0.27744820713996887
test loss item: 0.27574583888053894
test loss item: 0.8090168833732605
test loss item: 0.6069300174713135
test loss item: 0.26123201847076416
test loss item: 0.40436360239982605
test loss item: 0.2860547602176666
test loss item: 0.8523262739181519
test loss item: 0.34835126996040344
test loss item: 0.5599121451377869
test loss item: 0.7706369757652283
test loss item: 0.4201832413673401
test loss item: 0.2194983810186386
test loss item: 1.3796803951263428
test loss item: 0.2588309645652771
test loss item: 0.8224002718925476
test loss item: 1.0600274801254272
test loss item: 0.25890272855758667
test loss item: 0.1164037212729454
test loss item: 0.19492024183273315
Epoch [1/50], Training Loss: 0.8466, Testing Loss: 0.5008
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/50
train loss item: 0.945400595664978
train loss item: 0.5656852722167969
train loss item: 0.4969066083431244
train loss item: 0.7138389945030212
train loss item: 0.41676419973373413
train loss item: 0.4335280954837799
train loss item: 0.4800505042076111
train loss item: 0.6254915595054626
train loss item: 0.27953222393989563
train loss item: 0.4126567244529724
train loss item: 0.21374163031578064
train loss item: 1.1867620944976807
train loss item: 0.5342413187026978
train loss item: 0.4554866850376129
train loss item: 0.8397504687309265
train loss item: 1.7313896417617798
train loss item: 0.4293855130672455
train loss item: 2.138850688934326
train loss item: 0.5286787748336792
train loss item: 0.5112156271934509
train loss item: 0.3450028598308563
train loss item: 0.3460937440395355
train loss item: 0.4993901550769806
train loss item: 0.32863542437553406
train loss item: 0.24903453886508942
train loss item: 0.8569633960723877
train loss item: 0.1590740978717804
train loss item: 1.8313250541687012
train loss item: 0.31091275811195374
train loss item: 0.16525501012802124
train loss item: 1.720314383506775
train loss item: 0.42017778754234314
train loss item: 0.5331020951271057
train loss item: 0.42986661195755005
train loss item: 0.41625896096229553
train loss item: 0.2995673418045044
train loss item: 0.3341169059276581
train loss item: 0.11984185129404068
train loss item: 1.2438786029815674
train loss item: 0.2610898017883301
train loss item: 0.22758682072162628
train loss item: 0.5644232034683228
train loss item: 0.5763090252876282
train loss item: 2.96242356300354
train loss item: 0.4432523250579834
test loss item: 0.16126231849193573
test loss item: 0.49072882533073425
test loss item: 0.2205481082201004
test loss item: 1.1506656408309937
test loss item: 0.3921148180961609
test loss item: 0.8079535365104675
test loss item: 0.23131026327610016
test loss item: 0.13870981335639954
test loss item: 0.43551120162010193
test loss item: 0.5888134241104126
test loss item: 0.544439971446991
test loss item: 0.2559468448162079
test loss item: 0.2746877670288086
test loss item: 0.32591214776039124
test loss item: 0.4170214831829071
test loss item: 0.7459545135498047
test loss item: 0.5304632186889648
test loss item: 0.5088574290275574
test loss item: 1.2048120498657227
test loss item: 0.4579828679561615
test loss item: 0.2913540303707123
test loss item: 0.3125852048397064
test loss item: 0.6091951727867126
test loss item: 0.31842416524887085
test loss item: 0.664040207862854
test loss item: 0.28352099657058716
test loss item: 0.2550370395183563
test loss item: 0.7749406695365906
test loss item: 0.6107324957847595
test loss item: 0.25903379917144775
test loss item: 0.4217155873775482
test loss item: 0.2799800932407379
test loss item: 0.7853072881698608
test loss item: 0.3575451076030731
test loss item: 0.5457370281219482
test loss item: 0.7555294632911682
test loss item: 0.420271098613739
test loss item: 0.1938873529434204
test loss item: 1.2912393808364868
test loss item: 0.23956875503063202
test loss item: 0.81330406665802
test loss item: 1.0305527448654175
test loss item: 0.26021909713745117
test loss item: 0.08182741701602936
test loss item: 0.12967297434806824
Epoch [2/50], Training Loss: 0.6574, Testing Loss: 0.4860
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/50
train loss item: 0.8472827076911926
train loss item: 0.6106647849082947
train loss item: 0.44940295815467834
train loss item: 0.644042432308197
train loss item: 0.31033170223236084
train loss item: 0.38958609104156494
train loss item: 0.41482388973236084
train loss item: 0.46685659885406494
train loss item: 0.25299182534217834
train loss item: 0.35189634561538696
train loss item: 0.2326698899269104
train loss item: 1.0513217449188232
train loss item: 0.45542073249816895
train loss item: 0.2806621193885803
train loss item: 0.654719352722168
train loss item: 1.4262546300888062
train loss item: 0.3385307192802429
train loss item: 1.780143141746521
train loss item: 0.7078552842140198
train loss item: 0.6721284985542297
train loss item: 0.31872767210006714
train loss item: 0.33787035942077637
train loss item: 0.43650752305984497
train loss item: 0.3212485611438751
train loss item: 0.23101668059825897
train loss item: 0.7423748970031738
train loss item: 0.15144890546798706
train loss item: 1.5260906219482422
train loss item: 0.32508742809295654
train loss item: 0.18050996959209442
train loss item: 1.4484329223632812
train loss item: 0.46051931381225586
train loss item: 0.522236168384552
train loss item: 0.4930451512336731
train loss item: 0.4201532006263733
train loss item: 0.2729872167110443
train loss item: 0.33013755083084106
train loss item: 0.11035403609275818
train loss item: 1.1148489713668823
train loss item: 0.2707400918006897
train loss item: 0.22322282195091248
train loss item: 0.5041843056678772
train loss item: 0.5557368397712708
train loss item: 2.7770726680755615
train loss item: 0.41871771216392517
test loss item: 0.1802605390548706
test loss item: 0.504517674446106
test loss item: 0.2730792164802551
test loss item: 1.075114369392395
test loss item: 0.4271893799304962
test loss item: 0.7942330837249756
test loss item: 0.2535458505153656
test loss item: 0.17768509685993195
test loss item: 0.4210967421531677
test loss item: 0.5447808504104614
test loss item: 0.5118012428283691
test loss item: 0.27079010009765625
test loss item: 0.27578604221343994
test loss item: 0.3414904475212097
test loss item: 0.43427151441574097
test loss item: 0.7314468622207642
test loss item: 0.5431112051010132
test loss item: 0.5198567509651184
test loss item: 1.17726731300354
test loss item: 0.46724966168403625
test loss item: 0.2785700559616089
test loss item: 0.3122018277645111
test loss item: 0.5717281699180603
test loss item: 0.311200350522995
test loss item: 0.6698199510574341
test loss item: 0.31621822714805603
test loss item: 0.26298436522483826
test loss item: 0.7895907163619995
test loss item: 0.575943112373352
test loss item: 0.2909041941165924
test loss item: 0.4256826937198639
test loss item: 0.27490904927253723
test loss item: 0.7381288409233093
test loss item: 0.34564247727394104
test loss item: 0.5422050356864929
test loss item: 0.7022069692611694
test loss item: 0.3799048066139221
test loss item: 0.19399434328079224
test loss item: 1.2392605543136597
test loss item: 0.26511427760124207
test loss item: 0.7768603563308716
test loss item: 1.0065412521362305
test loss item: 0.26264670491218567
test loss item: 0.09411763399839401
test loss item: 0.1608969122171402
Epoch [3/50], Training Loss: 0.5962, Testing Loss: 0.4825
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/50
train loss item: 0.8090807199478149
train loss item: 0.5690974593162537
train loss item: 0.40838858485221863
train loss item: 0.6001176238059998
train loss item: 0.28542542457580566
train loss item: 0.36870741844177246
train loss item: 0.40422549843788147
train loss item: 0.4469160735607147
train loss item: 0.24582251906394958
train loss item: 0.34188446402549744
train loss item: 0.21352605521678925
train loss item: 0.9234427809715271
train loss item: 0.42073431611061096
train loss item: 0.2652519643306732
train loss item: 0.6126670241355896
train loss item: 1.3028028011322021
train loss item: 0.32369956374168396
train loss item: 1.5854545831680298
train loss item: 0.8190464973449707
train loss item: 0.7207515835762024
train loss item: 0.34192925691604614
train loss item: 0.3292854428291321
train loss item: 0.40694233775138855
train loss item: 0.31155484914779663
train loss item: 0.23373834788799286
train loss item: 0.6925632357597351
train loss item: 0.1406780481338501
train loss item: 1.406319499015808
train loss item: 0.32040905952453613
train loss item: 0.19390727579593658
train loss item: 1.3186147212982178
train loss item: 0.42854219675064087
train loss item: 0.4895843267440796
train loss item: 0.4435997009277344
train loss item: 0.3945150375366211
train loss item: 0.24754463136196136
train loss item: 0.3291766047477722
train loss item: 0.13003401458263397
train loss item: 1.0130952596664429
train loss item: 0.2768600881099701
train loss item: 0.19242867827415466
train loss item: 0.47701987624168396
train loss item: 0.5291575789451599
train loss item: 2.5110244750976562
train loss item: 0.383695513010025
test loss item: 0.1619199812412262
test loss item: 0.44015011191368103
test loss item: 0.2177913635969162
test loss item: 1.2038090229034424
test loss item: 0.3648519814014435
test loss item: 0.7160108685493469
test loss item: 0.2592621445655823
test loss item: 0.15363512933254242
test loss item: 0.4027279019355774
test loss item: 0.5901955962181091
test loss item: 0.5210987329483032
test loss item: 0.24701179563999176
test loss item: 0.2573278546333313
test loss item: 0.3091728091239929
test loss item: 0.39390063285827637
test loss item: 0.7035701870918274
test loss item: 0.49562230706214905
test loss item: 0.47318899631500244
test loss item: 1.1034667491912842
test loss item: 0.41788968443870544
test loss item: 0.27474531531333923
test loss item: 0.2902994155883789
test loss item: 0.5850714445114136
test loss item: 0.2975107431411743
test loss item: 0.6150050163269043
test loss item: 0.2682058811187744
test loss item: 0.22692205011844635
test loss item: 0.6817983984947205
test loss item: 0.5976828932762146
test loss item: 0.26410427689552307
test loss item: 0.38909992575645447
test loss item: 0.2774963676929474
test loss item: 0.7313579320907593
test loss item: 0.34846413135528564
test loss item: 0.5332461595535278
test loss item: 0.8059496283531189
test loss item: 0.40858110785484314
test loss item: 0.18411460518836975
test loss item: 1.100257158279419
test loss item: 0.22328689694404602
test loss item: 0.7847654819488525
test loss item: 0.9487593173980713
test loss item: 0.241329163312912
test loss item: 0.08484473079442978
test loss item: 0.13726384937763214
Epoch [4/50], Training Loss: 0.5602, Testing Loss: 0.4607
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/50
train loss item: 0.7939813733100891
train loss item: 0.5870384573936462
train loss item: 0.40169617533683777
train loss item: 0.5484129786491394
train loss item: 0.2943485677242279
train loss item: 0.3320987820625305
train loss item: 0.3582610785961151
train loss item: 0.4270992875099182
train loss item: 0.23144365847110748
train loss item: 0.3207961618900299
train loss item: 0.17521385848522186
train loss item: 0.8768212795257568
train loss item: 0.39664143323898315
train loss item: 0.22368909418582916
train loss item: 0.5020948052406311
train loss item: 1.1488237380981445
train loss item: 0.342511922121048
train loss item: 1.4312740564346313
train loss item: 0.7971140146255493
train loss item: 0.6120758652687073
train loss item: 0.2298477292060852
train loss item: 0.27724507451057434
train loss item: 0.4276661276817322
train loss item: 0.3090161085128784
train loss item: 0.198374405503273
train loss item: 0.6910200119018555
train loss item: 0.1618068367242813
train loss item: 1.207358717918396
train loss item: 0.27897390723228455
train loss item: 0.17236106097698212
train loss item: 1.1014404296875
train loss item: 0.433631032705307
train loss item: 0.4285750985145569
train loss item: 0.5375449061393738
train loss item: 0.35157454013824463
train loss item: 0.2356889545917511
train loss item: 0.3230947256088257
train loss item: 0.11718650907278061
train loss item: 1.1036293506622314
train loss item: 0.22381098568439484
train loss item: 0.19120992720127106
train loss item: 0.46107274293899536
train loss item: 0.6597883105278015
train loss item: 2.5488739013671875
train loss item: 0.4447628855705261
test loss item: 0.21019500494003296
test loss item: 0.45396074652671814
test loss item: 0.2469397634267807
test loss item: 0.8688377737998962
test loss item: 0.35180479288101196
test loss item: 0.7061207890510559
test loss item: 0.21992692351341248
test loss item: 0.19687776267528534
test loss item: 0.37795397639274597
test loss item: 0.47033554315567017
test loss item: 0.4607613682746887
test loss item: 0.27084165811538696
test loss item: 0.24185776710510254
test loss item: 0.3152433931827545
test loss item: 0.37390726804733276
test loss item: 0.6184032559394836
test loss item: 0.4741443693637848
test loss item: 0.4307726323604584
test loss item: 1.0020742416381836
test loss item: 0.3992624580860138
test loss item: 0.27911651134490967
test loss item: 0.2733513414859772
test loss item: 0.514079749584198
test loss item: 0.31297504901885986
test loss item: 0.5580347180366516
test loss item: 0.25938618183135986
test loss item: 0.22726120054721832
test loss item: 0.6655758619308472
test loss item: 0.5165843963623047
test loss item: 0.2306268811225891
test loss item: 0.36289873719215393
test loss item: 0.25129541754722595
test loss item: 0.6405119895935059
test loss item: 0.3162073791027069
test loss item: 0.44570866227149963
test loss item: 0.5699805617332458
test loss item: 0.368742972612381
test loss item: 0.21327565610408783
test loss item: 1.0572994947433472
test loss item: 0.2619453966617584
test loss item: 0.6680194139480591
test loss item: 0.8670331239700317
test loss item: 0.23616822063922882
test loss item: 0.15715660154819489
test loss item: 0.1409444808959961
Epoch [5/50], Training Loss: 0.5315, Testing Loss: 0.4241
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/50
train loss item: 0.6722326874732971
train loss item: 0.6472647190093994
train loss item: 0.3674473464488983
train loss item: 0.5457723140716553
train loss item: 0.3013373911380768
train loss item: 0.3446873724460602
train loss item: 0.40469682216644287
train loss item: 0.48261162638664246
train loss item: 0.21648581326007843
train loss item: 0.3097626268863678
train loss item: 0.1766408234834671
train loss item: 0.7924415469169617
train loss item: 0.3743273615837097
train loss item: 0.24916814267635345
train loss item: 0.536395251750946
train loss item: 1.0040340423583984
train loss item: 0.27670302987098694
train loss item: 1.2049758434295654
train loss item: 0.8741863369941711
train loss item: 0.60051429271698
train loss item: 0.2985740303993225
train loss item: 0.27831676602363586
train loss item: 0.3834359347820282
train loss item: 0.2688014507293701
train loss item: 0.21656470000743866
train loss item: 0.6637131571769714
train loss item: 0.13752591609954834
train loss item: 1.215593695640564
train loss item: 0.24030710756778717
train loss item: 0.15147344768047333
train loss item: 1.0973873138427734
train loss item: 0.3600108027458191
train loss item: 0.4203082025051117
train loss item: 0.5157877206802368
train loss item: 0.37288257479667664
train loss item: 0.2113913595676422
train loss item: 0.29018718004226685
train loss item: 0.10508165508508682
train loss item: 0.953016996383667
train loss item: 0.19498303532600403
train loss item: 0.15724119544029236
train loss item: 0.3779267370700836
train loss item: 0.45830103754997253
train loss item: 1.9161124229431152
train loss item: 0.47565776109695435
test loss item: 0.17044244706630707
test loss item: 0.39845678210258484
test loss item: 0.19931359589099884
test loss item: 0.799482524394989
test loss item: 0.28499147295951843
test loss item: 0.5951049327850342
test loss item: 0.18521039187908173
test loss item: 0.1326655000448227
test loss item: 0.3584539592266083
test loss item: 0.4295026361942291
test loss item: 0.4583287835121155
test loss item: 0.25140830874443054
test loss item: 0.22953855991363525
test loss item: 0.26608267426490784
test loss item: 0.32275328040122986
test loss item: 0.5512738823890686
test loss item: 0.4549865126609802
test loss item: 0.38628271222114563
test loss item: 0.8753800392150879
test loss item: 0.360739529132843
test loss item: 0.27483218908309937
test loss item: 0.2631319463253021
test loss item: 0.4798237979412079
test loss item: 0.29522237181663513
test loss item: 0.47779014706611633
test loss item: 0.21502654254436493
test loss item: 0.21805916726589203
test loss item: 0.6000245809555054
test loss item: 0.465888112783432
test loss item: 0.20673370361328125
test loss item: 0.3215444087982178
test loss item: 0.23377498984336853
test loss item: 0.6345674991607666
test loss item: 0.2851347327232361
test loss item: 0.4409381151199341
test loss item: 0.5179892182350159
test loss item: 0.3486470580101013
test loss item: 0.20293709635734558
test loss item: 1.0244683027267456
test loss item: 0.23432783782482147
test loss item: 0.596384584903717
test loss item: 0.778014600276947
test loss item: 0.22138498723506927
test loss item: 0.12569454312324524
test loss item: 0.27469542622566223
Epoch [6/50], Training Loss: 0.4921, Testing Loss: 0.3877
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/50
train loss item: 0.6834952235221863
train loss item: 0.5108019709587097
train loss item: 0.29087987542152405
train loss item: 0.4806845188140869
train loss item: 0.304002970457077
train loss item: 0.3033292591571808
train loss item: 0.31130433082580566
train loss item: 0.4769441485404968
train loss item: 0.20422956347465515
train loss item: 0.28319859504699707
train loss item: 0.19576238095760345
train loss item: 0.681144118309021
train loss item: 0.3279729187488556
train loss item: 0.21476371586322784
train loss item: 0.46284958720207214
train loss item: 0.9002544283866882
train loss item: 0.2511739134788513
train loss item: 0.9676511883735657
train loss item: 0.6782336235046387
train loss item: 0.39863476157188416
train loss item: 0.23711882531642914
train loss item: 0.28847143054008484
train loss item: 0.33246126770973206
train loss item: 0.28792375326156616
train loss item: 0.18497583270072937
train loss item: 0.572139322757721
train loss item: 0.12339083105325699
train loss item: 0.8942172527313232
train loss item: 0.23832207918167114
train loss item: 0.18110999464988708
train loss item: 0.8381558656692505
train loss item: 0.34240245819091797
train loss item: 0.36235150694847107
train loss item: 0.4912140965461731
train loss item: 0.3161610960960388
train loss item: 0.2086329460144043
train loss item: 0.25971633195877075
train loss item: 0.12963244318962097
train loss item: 0.9323926568031311
train loss item: 0.2117735892534256
train loss item: 0.19237594306468964
train loss item: 0.3639521300792694
train loss item: 0.4831444323062897
train loss item: 1.653002142906189
train loss item: 0.412399023771286
test loss item: 0.16370932757854462
test loss item: 0.356836199760437
test loss item: 0.2377030849456787
test loss item: 0.8060991764068604
test loss item: 0.2861695885658264
test loss item: 0.5518744587898254
test loss item: 0.18577973544597626
test loss item: 0.145443856716156
test loss item: 0.3114122748374939
test loss item: 0.4363095164299011
test loss item: 0.39468586444854736
test loss item: 0.25270381569862366
test loss item: 0.21111337840557098
test loss item: 0.2711045444011688
test loss item: 0.3129524886608124
test loss item: 0.49469226598739624
test loss item: 0.3996514081954956
test loss item: 0.38837239146232605
test loss item: 0.8176052570343018
test loss item: 0.33260378241539
test loss item: 0.23500877618789673
test loss item: 0.22460907697677612
test loss item: 0.4297024607658386
test loss item: 0.2771562933921814
test loss item: 0.4704809784889221
test loss item: 0.21560658514499664
test loss item: 0.18135115504264832
test loss item: 0.5265294313430786
test loss item: 0.47292980551719666
test loss item: 0.20578834414482117
test loss item: 0.3074435591697693
test loss item: 0.20501190423965454
test loss item: 0.54923415184021
test loss item: 0.26409631967544556
test loss item: 0.4148637354373932
test loss item: 0.5244768261909485
test loss item: 0.30222079157829285
test loss item: 0.19094829261302948
test loss item: 0.8015830516815186
test loss item: 0.23871107399463654
test loss item: 0.5544226169586182
test loss item: 0.7028189897537231
test loss item: 0.20554739236831665
test loss item: 0.09685264527797699
test loss item: 0.21613264083862305
Epoch [7/50], Training Loss: 0.4325, Testing Loss: 0.3593
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/50
train loss item: 0.6159584522247314
train loss item: 0.3726058006286621
train loss item: 0.29230403900146484
train loss item: 0.4982207417488098
train loss item: 0.2291695475578308
train loss item: 0.26635345816612244
train loss item: 0.3388930559158325
train loss item: 0.45322468876838684
train loss item: 0.17693468928337097
train loss item: 0.2666698694229126
train loss item: 0.16499948501586914
train loss item: 0.7147325277328491
train loss item: 0.3136114478111267
train loss item: 0.2128148376941681
train loss item: 0.39765995740890503
train loss item: 0.7444828152656555
train loss item: 0.28488707542419434
train loss item: 0.7810381650924683
train loss item: 0.7685247659683228
train loss item: 0.3851138949394226
train loss item: 0.219159796833992
train loss item: 0.31499266624450684
train loss item: 0.330311119556427
train loss item: 0.2897900342941284
train loss item: 0.18503890931606293
train loss item: 0.5276561975479126
train loss item: 0.12511757016181946
train loss item: 0.6662341952323914
train loss item: 0.222976416349411
train loss item: 0.1700279414653778
train loss item: 0.7432228922843933
train loss item: 0.32953017950057983
train loss item: 0.292040079832077
train loss item: 0.42485490441322327
train loss item: 0.2984802722930908
train loss item: 0.1798573136329651
train loss item: 0.23677001893520355
train loss item: 0.09849874675273895
train loss item: 0.857044517993927
train loss item: 0.19253231585025787
train loss item: 0.15604683756828308
train loss item: 0.31781643629074097
train loss item: 0.46174755692481995
train loss item: 1.1914072036743164
train loss item: 0.3786194920539856
test loss item: 0.15831129252910614
test loss item: 0.3774109184741974
test loss item: 0.2193676382303238
test loss item: 0.6748121380805969
test loss item: 0.2741066813468933
test loss item: 0.5670682787895203
test loss item: 0.1665019690990448
test loss item: 0.14350613951683044
test loss item: 0.2988987863063812
test loss item: 0.3639279901981354
test loss item: 0.3631017506122589
test loss item: 0.2366778552532196
test loss item: 0.1938260793685913
test loss item: 0.25208768248558044
test loss item: 0.2930682301521301
test loss item: 0.4837612509727478
test loss item: 0.3903307020664215
test loss item: 0.34869852662086487
test loss item: 0.8113980293273926
test loss item: 0.3098466694355011
test loss item: 0.22486045956611633
test loss item: 0.21598409116268158
test loss item: 0.376176118850708
test loss item: 0.25621020793914795
test loss item: 0.4567394256591797
test loss item: 0.18878866732120514
test loss item: 0.18272823095321655
test loss item: 0.5550397038459778
test loss item: 0.419770747423172
test loss item: 0.18496114015579224
test loss item: 0.2867168188095093
test loss item: 0.19031065702438354
test loss item: 0.5554680824279785
test loss item: 0.24998778104782104
test loss item: 0.3666864037513733
test loss item: 0.42145437002182007
test loss item: 0.27817466855049133
test loss item: 0.18267394602298737
test loss item: 0.8872026801109314
test loss item: 0.22020380198955536
test loss item: 0.5397693514823914
test loss item: 0.7100871801376343
test loss item: 0.18756283819675446
test loss item: 0.08638442307710648
test loss item: 0.1778154969215393
Epoch [8/50], Training Loss: 0.3886, Testing Loss: 0.3406
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/50
train loss item: 0.5726674795150757
train loss item: 0.3511415421962738
train loss item: 0.26425859332084656
train loss item: 0.3773975372314453
train loss item: 0.2558417320251465
train loss item: 0.2604404091835022
train loss item: 0.28481072187423706
train loss item: 0.571817934513092
train loss item: 0.19668880105018616
train loss item: 0.2797573208808899
train loss item: 0.12524208426475525
train loss item: 0.6214509010314941
train loss item: 0.2812715768814087
train loss item: 0.2491178959608078
train loss item: 0.3601458966732025
train loss item: 0.7780765295028687
train loss item: 0.34482312202453613
train loss item: 0.6546589136123657
train loss item: 0.3933270573616028
train loss item: 0.2662087678909302
train loss item: 0.18778644502162933
train loss item: 0.2706407606601715
train loss item: 0.2762241065502167
train loss item: 0.26728716492652893
train loss item: 0.155086487531662
train loss item: 0.6334497332572937
train loss item: 0.10690432041883469
train loss item: 0.7557992339134216
train loss item: 0.2062920778989792
train loss item: 0.14183087646961212
train loss item: 0.7444945573806763
train loss item: 0.24572184681892395
train loss item: 0.3002210259437561
train loss item: 0.40610745549201965
train loss item: 0.28048020601272583
train loss item: 0.1841522604227066
train loss item: 0.21003012359142303
train loss item: 0.08807791024446487
train loss item: 0.8122351169586182
train loss item: 0.18065157532691956
train loss item: 0.12171285599470139
train loss item: 0.3911166489124298
train loss item: 0.41494596004486084
train loss item: 0.9855477809906006
train loss item: 0.3442762494087219
test loss item: 0.1526055783033371
test loss item: 0.3603709936141968
test loss item: 0.2319965660572052
test loss item: 0.6919817328453064
test loss item: 0.27569544315338135
test loss item: 0.5399787425994873
test loss item: 0.15210582315921783
test loss item: 0.14879944920539856
test loss item: 0.2775164842605591
test loss item: 0.325853168964386
test loss item: 0.3588808476924896
test loss item: 0.20250678062438965
test loss item: 0.17610694468021393
test loss item: 0.24663114547729492
test loss item: 0.2914465069770813
test loss item: 0.48760175704956055
test loss item: 0.38641905784606934
test loss item: 0.34905102849006653
test loss item: 0.7776722311973572
test loss item: 0.31279808282852173
test loss item: 0.17525386810302734
test loss item: 0.2075054943561554
test loss item: 0.35771968960762024
test loss item: 0.20555701851844788
test loss item: 0.4404856562614441
test loss item: 0.20427300035953522
test loss item: 0.17318086326122284
test loss item: 0.5410112738609314
test loss item: 0.3895481824874878
test loss item: 0.18665865063667297
test loss item: 0.28055915236473083
test loss item: 0.17060621082782745
test loss item: 0.5157884359359741
test loss item: 0.21346744894981384
test loss item: 0.3483826518058777
test loss item: 0.4029048979282379
test loss item: 0.24745364487171173
test loss item: 0.12093694508075714
test loss item: 0.818690836429596
test loss item: 0.21500037610530853
test loss item: 0.5141912698745728
test loss item: 0.6884729266166687
test loss item: 0.16786672174930573
test loss item: 0.07280046492815018
test loss item: 0.11660254746675491
Epoch [9/50], Training Loss: 0.3600, Testing Loss: 0.3227
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/50
train loss item: 0.6020269393920898
train loss item: 0.39847317337989807
train loss item: 0.24624276161193848
train loss item: 0.3701951801776886
train loss item: 0.23843127489089966
train loss item: 0.2669205665588379
train loss item: 0.35048267245292664
train loss item: 0.5872641205787659
train loss item: 0.22119779884815216
train loss item: 0.325479656457901
train loss item: 0.1657361090183258
train loss item: 0.7607239484786987
train loss item: 0.28758808970451355
train loss item: 0.22616659104824066
train loss item: 0.4163755774497986
train loss item: 0.679554283618927
train loss item: 0.31096145510673523
train loss item: 0.6030941605567932
train loss item: 0.6540489792823792
train loss item: 0.35537421703338623
train loss item: 0.24654889106750488
train loss item: 0.22990305721759796
train loss item: 0.2814757823944092
train loss item: 0.25349095463752747
train loss item: 0.17466750741004944
train loss item: 0.6605897545814514
train loss item: 0.11553570628166199
train loss item: 0.7396854162216187
train loss item: 0.2285119742155075
train loss item: 0.15545375645160675
train loss item: 0.8671631217002869
train loss item: 0.2861252427101135
train loss item: 0.3788702189922333
train loss item: 0.3102132976055145
train loss item: 0.2742173671722412
train loss item: 0.2545589506626129
train loss item: 0.27447256445884705
train loss item: 0.12026022374629974
train loss item: 0.6659929156303406
train loss item: 0.1677320897579193
train loss item: 0.10894176363945007
train loss item: 0.4394310414791107
train loss item: 0.3823707699775696
train loss item: 0.8869583010673523
train loss item: 0.2836077809333801
test loss item: 0.1746119111776352
test loss item: 0.2904742360115051
test loss item: 0.27779680490493774
test loss item: 0.6217815279960632
test loss item: 0.21827837824821472
test loss item: 0.4182421863079071
test loss item: 0.15391410887241364
test loss item: 0.16428209841251373
test loss item: 0.25035661458969116
test loss item: 0.3168385922908783
test loss item: 0.32131320238113403
test loss item: 0.22838300466537476
test loss item: 0.18252380192279816
test loss item: 0.2624492645263672
test loss item: 0.2782309651374817
test loss item: 0.37127071619033813
test loss item: 0.32707923650741577
test loss item: 0.266091912984848
test loss item: 0.6065648198127747
test loss item: 0.3074501156806946
test loss item: 0.20776589214801788
test loss item: 0.18681807816028595
test loss item: 0.3325122892856598
test loss item: 0.22529590129852295
test loss item: 0.3359275162220001
test loss item: 0.17777742445468903
test loss item: 0.17283155024051666
test loss item: 0.40435221791267395
test loss item: 0.3282018303871155
test loss item: 0.18606719374656677
test loss item: 0.23077870905399323
test loss item: 0.1905394345521927
test loss item: 0.4621371924877167
test loss item: 0.22808708250522614
test loss item: 0.29805752635002136
test loss item: 0.41056519746780396
test loss item: 0.2756608724594116
test loss item: 0.16249322891235352
test loss item: 0.60407555103302
test loss item: 0.2646363079547882
test loss item: 0.42142489552497864
test loss item: 0.5253686308860779
test loss item: 0.17305231094360352
test loss item: 0.09823846071958542
test loss item: 0.1757839471101761
Epoch [10/50], Training Loss: 0.3745, Testing Loss: 0.2915
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 11/50
train loss item: 0.5090538263320923
train loss item: 0.35104063153266907
train loss item: 0.24812141060829163
train loss item: 0.2993793785572052
train loss item: 0.19638973474502563
train loss item: 0.23400002717971802
train loss item: 0.2966030240058899
train loss item: 0.35924094915390015
train loss item: 0.19811460375785828
train loss item: 0.24437835812568665
train loss item: 0.15830042958259583
train loss item: 0.4937646687030792
train loss item: 0.30417194962501526
train loss item: 0.15492942929267883
train loss item: 0.36012277007102966
train loss item: 0.8039988875389099
train loss item: 0.23905296623706818
train loss item: 0.5204182267189026
train loss item: 0.42611807584762573
train loss item: 0.3111506998538971
train loss item: 0.19234700500965118
train loss item: 0.2130441665649414
train loss item: 0.31809231638908386
train loss item: 0.270246684551239
train loss item: 0.1871163547039032
train loss item: 0.5888240933418274
train loss item: 0.13005606830120087
train loss item: 0.7731960415840149
train loss item: 0.18197236955165863
train loss item: 0.14865514636039734
train loss item: 0.7095639705657959
train loss item: 0.21381230652332306
train loss item: 0.2545054256916046
train loss item: 0.38835409283638
train loss item: 0.265991747379303
train loss item: 0.20231354236602783
train loss item: 0.21065843105316162
train loss item: 0.11060399562120438
train loss item: 0.6846239566802979
train loss item: 0.173256978392601
train loss item: 0.14015933871269226
train loss item: 0.349168598651886
train loss item: 0.32556670904159546
train loss item: 0.8882597088813782
train loss item: 0.27088218927383423
test loss item: 0.14921289682388306
test loss item: 0.2566078305244446
test loss item: 0.20347318053245544
test loss item: 0.49769407510757446
test loss item: 0.2248602956533432
test loss item: 0.3865453600883484
test loss item: 0.1671435683965683
test loss item: 0.1431688517332077
test loss item: 0.21862158179283142
test loss item: 0.27723032236099243
test loss item: 0.2853095531463623
test loss item: 0.1768113076686859
test loss item: 0.1611824929714203
test loss item: 0.2205784171819687
test loss item: 0.24435651302337646
test loss item: 0.34684696793556213
test loss item: 0.2906401455402374
test loss item: 0.2642839252948761
test loss item: 0.5392557978630066
test loss item: 0.25268110632896423
test loss item: 0.1648569107055664
test loss item: 0.172511026263237
test loss item: 0.2958371937274933
test loss item: 0.19021029770374298
test loss item: 0.33121001720428467
test loss item: 0.186856210231781
test loss item: 0.15709610283374786
test loss item: 0.3916498124599457
test loss item: 0.2832378149032593
test loss item: 0.1847943663597107
test loss item: 0.22749239206314087
test loss item: 0.1675032526254654
test loss item: 0.3741583228111267
test loss item: 0.2046373039484024
test loss item: 0.29381534457206726
test loss item: 0.3098662495613098
test loss item: 0.23787027597427368
test loss item: 0.1279405653476715
test loss item: 0.5216341018676758
test loss item: 0.1908154934644699
test loss item: 0.35995984077453613
test loss item: 0.47044533491134644
test loss item: 0.15669238567352295
test loss item: 0.08128450065851212
test loss item: 0.13526226580142975
Epoch [11/50], Training Loss: 0.3311, Testing Loss: 0.2561
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 12/50
train loss item: 0.5612934827804565
train loss item: 0.33331355452537537
train loss item: 0.23747316002845764
train loss item: 0.26403993368148804
train loss item: 0.19279825687408447
train loss item: 0.19548141956329346
train loss item: 0.2648826837539673
train loss item: 0.41137629747390747
train loss item: 0.17594176530838013
train loss item: 0.22727030515670776
train loss item: 0.1742788553237915
train loss item: 0.5038493871688843
train loss item: 0.2568811774253845
train loss item: 0.16646277904510498
train loss item: 0.3754558265209198
train loss item: 0.7553635239601135
train loss item: 0.28134021162986755
train loss item: 0.47366297245025635
train loss item: 0.4023948907852173
train loss item: 0.28965267539024353
train loss item: 0.1660323143005371
train loss item: 0.17356061935424805
train loss item: 0.27867212891578674
train loss item: 0.263728529214859
train loss item: 0.1696683019399643
train loss item: 0.5868104696273804
train loss item: 0.1596727818250656
train loss item: 0.627324640750885
train loss item: 0.17367057502269745
train loss item: 0.10390978306531906
train loss item: 0.7012280225753784
train loss item: 0.23368185758590698
train loss item: 0.23445722460746765
train loss item: 0.337884783744812
train loss item: 0.21387305855751038
train loss item: 0.17726841568946838
train loss item: 0.20956437289714813
train loss item: 0.07685552537441254
train loss item: 0.6760791540145874
train loss item: 0.1476159691810608
train loss item: 0.11522164195775986
train loss item: 0.3460381031036377
train loss item: 0.3378640413284302
train loss item: 0.8028486967086792
train loss item: 0.2391355037689209
test loss item: 0.13867177069187164
test loss item: 0.2523037791252136
test loss item: 0.19065351784229279
test loss item: 0.47639861702919006
test loss item: 0.2215953916311264
test loss item: 0.38773471117019653
test loss item: 0.13868942856788635
test loss item: 0.12314759939908981
test loss item: 0.22251355648040771
test loss item: 0.2651161551475525
test loss item: 0.2891664206981659
test loss item: 0.19188176095485687
test loss item: 0.15051504969596863
test loss item: 0.2141224890947342
test loss item: 0.2333277314901352
test loss item: 0.3376722037792206
test loss item: 0.28232118487358093
test loss item: 0.27767810225486755
test loss item: 0.5268176198005676
test loss item: 0.2428707331418991
test loss item: 0.1595124751329422
test loss item: 0.17897072434425354
test loss item: 0.29028552770614624
test loss item: 0.19991904497146606
test loss item: 0.33383190631866455
test loss item: 0.19306711852550507
test loss item: 0.15255580842494965
test loss item: 0.38133445382118225
test loss item: 0.2766694128513336
test loss item: 0.1670910269021988
test loss item: 0.2373051792383194
test loss item: 0.1445629745721817
test loss item: 0.35760003328323364
test loss item: 0.18706320226192474
test loss item: 0.26572945713996887
test loss item: 0.28511834144592285
test loss item: 0.24475695192813873
test loss item: 0.12776514887809753
test loss item: 0.48025447130203247
test loss item: 0.181905597448349
test loss item: 0.36306384205818176
test loss item: 0.47371554374694824
test loss item: 0.1637711524963379
test loss item: 0.07956971228122711
test loss item: 0.11988421529531479
Epoch [12/50], Training Loss: 0.3132, Testing Loss: 0.2491
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 13/50
train loss item: 0.43973031640052795
train loss item: 0.3008052408695221
train loss item: 0.23339571058750153
train loss item: 0.2543567717075348
train loss item: 0.1528652459383011
train loss item: 0.17548662424087524
train loss item: 0.24108180403709412
train loss item: 0.37779325246810913
train loss item: 0.15257249772548676
train loss item: 0.22368395328521729
train loss item: 0.16671006381511688
train loss item: 0.43999969959259033
train loss item: 0.22288337349891663
train loss item: 0.15149790048599243
train loss item: 0.29285821318626404
train loss item: 0.595860481262207
train loss item: 0.2170378565788269
train loss item: 0.45724010467529297
train loss item: 0.37502142786979675
train loss item: 0.19839473068714142
train loss item: 0.1334700882434845
train loss item: 0.1633448749780655
train loss item: 0.21175098419189453
train loss item: 0.2465486079454422
train loss item: 0.12564806640148163
train loss item: 0.5016105771064758
train loss item: 0.10035431385040283
train loss item: 0.5228247046470642
train loss item: 0.14378103613853455
train loss item: 0.10374908149242401
train loss item: 0.5779477953910828
train loss item: 0.18888473510742188
train loss item: 0.19590406119823456
train loss item: 0.27369141578674316
train loss item: 0.19807444512844086
train loss item: 0.13505053520202637
train loss item: 0.16551776230335236
train loss item: 0.07434417307376862
train loss item: 0.6217631101608276
train loss item: 0.136310875415802
train loss item: 0.1123112142086029
train loss item: 0.2681306004524231
train loss item: 0.3280218541622162
train loss item: 0.6450841426849365
train loss item: 0.23373769223690033
test loss item: 0.1385384500026703
test loss item: 0.2693776488304138
test loss item: 0.21107040345668793
test loss item: 0.47812619805336
test loss item: 0.2188384085893631
test loss item: 0.4102323353290558
test loss item: 0.12977467477321625
test loss item: 0.13215886056423187
test loss item: 0.21713568270206451
test loss item: 0.25352948904037476
test loss item: 0.26465553045272827
test loss item: 0.1752772182226181
test loss item: 0.15731720626354218
test loss item: 0.21866361796855927
test loss item: 0.24072633683681488
test loss item: 0.350315123796463
test loss item: 0.2798604667186737
test loss item: 0.26163360476493835
test loss item: 0.5659623742103577
test loss item: 0.2538549602031708
test loss item: 0.15999901294708252
test loss item: 0.16778020560741425
test loss item: 0.2721065878868103
test loss item: 0.1746741533279419
test loss item: 0.33785760402679443
test loss item: 0.17283301055431366
test loss item: 0.1627250611782074
test loss item: 0.39595967531204224
test loss item: 0.29038795828819275
test loss item: 0.1654100865125656
test loss item: 0.22809159755706787
test loss item: 0.15311776101589203
test loss item: 0.38009050488471985
test loss item: 0.1935688555240631
test loss item: 0.25443288683891296
test loss item: 0.2839519679546356
test loss item: 0.2229585498571396
test loss item: 0.12393723428249359
test loss item: 0.5715180039405823
test loss item: 0.19904571771621704
test loss item: 0.38792818784713745
test loss item: 0.5063430070877075
test loss item: 0.16411598026752472
test loss item: 0.07893825322389603
test loss item: 0.11871406435966492
Epoch [13/50], Training Loss: 0.2684, Testing Loss: 0.2532
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 14/50
train loss item: 0.4395250976085663
train loss item: 0.23313680291175842
train loss item: 0.1616157442331314
train loss item: 0.2071162611246109
train loss item: 0.1460505723953247
train loss item: 0.14612239599227905
train loss item: 0.18602165579795837
train loss item: 0.38452965021133423
train loss item: 0.13434407114982605
train loss item: 0.17575041949748993
train loss item: 0.11008619517087936
train loss item: 0.47734177112579346
train loss item: 0.201620951294899
train loss item: 0.12830594182014465
train loss item: 0.21110735833644867
train loss item: 0.6072250008583069
train loss item: 0.18342576920986176
train loss item: 0.40235912799835205
train loss item: 0.34635129570961
train loss item: 0.27454644441604614
train loss item: 0.17092882096767426
train loss item: 0.15994004905223846
train loss item: 0.22787103056907654
train loss item: 0.21787379682064056
train loss item: 0.14362090826034546
train loss item: 0.4968594014644623
train loss item: 0.14161017537117004
train loss item: 0.641291618347168
train loss item: 0.14512524008750916
train loss item: 0.11039630323648453
train loss item: 0.5454732179641724
train loss item: 0.17611607909202576
train loss item: 0.17661556601524353
train loss item: 0.2659645676612854
train loss item: 0.185890331864357
train loss item: 0.1315545290708542
train loss item: 0.16197596490383148
train loss item: 0.0763363167643547
train loss item: 0.5630121231079102
train loss item: 0.13451237976551056
train loss item: 0.10225073993206024
train loss item: 0.27083253860473633
train loss item: 0.2839112877845764
train loss item: 0.62379390001297
train loss item: 0.2303696572780609
test loss item: 0.12051181495189667
test loss item: 0.20249012112617493
test loss item: 0.15380749106407166
test loss item: 0.4225139319896698
test loss item: 0.18523730337619781
test loss item: 0.34084683656692505
test loss item: 0.11577524244785309
test loss item: 0.10226932913064957
test loss item: 0.17899447679519653
test loss item: 0.23346376419067383
test loss item: 0.21815088391304016
test loss item: 0.1418180912733078
test loss item: 0.12465643137693405
test loss item: 0.18303155899047852
test loss item: 0.19221439957618713
test loss item: 0.290037602186203
test loss item: 0.21259310841560364
test loss item: 0.22160159051418304
test loss item: 0.45308589935302734
test loss item: 0.1920965164899826
test loss item: 0.14939191937446594
test loss item: 0.14845089614391327
test loss item: 0.2243066132068634
test loss item: 0.1526058316230774
test loss item: 0.27749019861221313
test loss item: 0.144769549369812
test loss item: 0.13639791309833527
test loss item: 0.3129698634147644
test loss item: 0.22749248147010803
test loss item: 0.1377672702074051
test loss item: 0.18974687159061432
test loss item: 0.13662277162075043
test loss item: 0.30613943934440613
test loss item: 0.16444838047027588
test loss item: 0.20747368037700653
test loss item: 0.245261088013649
test loss item: 0.20182177424430847
test loss item: 0.10756296664476395
test loss item: 0.40217798948287964
test loss item: 0.15868200361728668
test loss item: 0.3327059745788574
test loss item: 0.4109557271003723
test loss item: 0.135737344622612
test loss item: 0.0703846737742424
test loss item: 0.13194602727890015
Epoch [14/50], Training Loss: 0.2565, Testing Loss: 0.2089
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 15/50
train loss item: 0.4473496973514557
train loss item: 0.2849873900413513
train loss item: 0.17205139994621277
train loss item: 0.1960453987121582
train loss item: 0.15445123612880707
train loss item: 0.12798786163330078
train loss item: 0.17840494215488434
train loss item: 0.3998340666294098
train loss item: 0.1250905990600586
train loss item: 0.22325655817985535
train loss item: 0.13783934712409973
train loss item: 0.4214281737804413
train loss item: 0.17396840453147888
train loss item: 0.15135514736175537
train loss item: 0.24482949078083038
train loss item: 0.5057079792022705
train loss item: 0.19120196998119354
train loss item: 0.35703223943710327
train loss item: 0.3176197409629822
train loss item: 0.22521841526031494
train loss item: 0.13039453327655792
train loss item: 0.18385227024555206
train loss item: 0.20121707022190094
train loss item: 0.223125159740448
train loss item: 0.13228055834770203
train loss item: 0.43792134523391724
train loss item: 0.09565510600805283
train loss item: 0.502269983291626
train loss item: 0.1194746270775795
train loss item: 0.08766429126262665
train loss item: 0.4406205117702484
train loss item: 0.1818591207265854
train loss item: 0.16643449664115906
train loss item: 0.25477033853530884
train loss item: 0.17933513224124908
train loss item: 0.15055598318576813
train loss item: 0.16775302588939667
train loss item: 0.06909896433353424
train loss item: 0.5318313241004944
train loss item: 0.10889363288879395
train loss item: 0.09635598212480545
train loss item: 0.2978500723838806
train loss item: 0.24714268743991852
train loss item: 0.5443159341812134
train loss item: 0.1999155730009079
test loss item: 0.11576223373413086
test loss item: 0.188496932387352
test loss item: 0.15116018056869507
test loss item: 0.4175903797149658
test loss item: 0.15300649404525757
test loss item: 0.2986255884170532
test loss item: 0.12212733179330826
test loss item: 0.09943341463804245
test loss item: 0.17122521996498108
test loss item: 0.23348475992679596
test loss item: 0.20722292363643646
test loss item: 0.14143408834934235
test loss item: 0.12130417674779892
test loss item: 0.16996701061725616
test loss item: 0.17886888980865479
test loss item: 0.25022897124290466
test loss item: 0.18668977916240692
test loss item: 0.1842668652534485
test loss item: 0.4090258777141571
test loss item: 0.18184839189052582
test loss item: 0.1502634435892105
test loss item: 0.130366250872612
test loss item: 0.2210206538438797
test loss item: 0.14915090799331665
test loss item: 0.24203522503376007
test loss item: 0.12979556620121002
test loss item: 0.12563274800777435
test loss item: 0.25573045015335083
test loss item: 0.23611117899417877
test loss item: 0.12670014798641205
test loss item: 0.17006315290927887
test loss item: 0.13324986398220062
test loss item: 0.2990144193172455
test loss item: 0.1718193143606186
test loss item: 0.1974257081747055
test loss item: 0.24891775846481323
test loss item: 0.2066410332918167
test loss item: 0.11200064420700073
test loss item: 0.3709549009799957
test loss item: 0.15402856469154358
test loss item: 0.2962190508842468
test loss item: 0.3643333911895752
test loss item: 0.13177458941936493
test loss item: 0.07435999810695648
test loss item: 0.11689499765634537
Epoch [15/50], Training Loss: 0.2397, Testing Loss: 0.1955
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 16/50
train loss item: 0.4862005412578583
train loss item: 0.24519160389900208
train loss item: 0.14294469356536865
train loss item: 0.16449013352394104
train loss item: 0.1693757027387619
train loss item: 0.15890030562877655
train loss item: 0.27299052476882935
train loss item: 0.350879967212677
train loss item: 0.09914366900920868
train loss item: 0.16231204569339752
train loss item: 0.11211328208446503
train loss item: 0.4888538420200348
train loss item: 0.20301106572151184
train loss item: 0.13793271780014038
train loss item: 0.21114450693130493
train loss item: 0.43621933460235596
train loss item: 0.18632325530052185
train loss item: 0.49608221650123596
train loss item: 0.3399370610713959
train loss item: 0.192945197224617
train loss item: 0.128157377243042
train loss item: 0.14680393040180206
train loss item: 0.21083688735961914
train loss item: 0.19594377279281616
train loss item: 0.08417064696550369
train loss item: 0.3518126606941223
train loss item: 0.09372419863939285
train loss item: 0.4874747693538666
train loss item: 0.159720316529274
train loss item: 0.07618997246026993
train loss item: 0.4084770083427429
train loss item: 0.2236996442079544
train loss item: 0.13657689094543457
train loss item: 0.20602940022945404
train loss item: 0.14922504127025604
train loss item: 0.11083853244781494
train loss item: 0.14633046090602875
train loss item: 0.07284213602542877
train loss item: 0.4413962662220001
train loss item: 0.12098291516304016
train loss item: 0.0898497924208641
train loss item: 0.24467703700065613
train loss item: 0.2206546813249588
train loss item: 0.5253838896751404
train loss item: 0.19355477392673492
test loss item: 0.0984320119023323
test loss item: 0.15959623456001282
test loss item: 0.0956725925207138
test loss item: 0.3662530183792114
test loss item: 0.12848123908042908
test loss item: 0.2546510100364685
test loss item: 0.10694728046655655
test loss item: 0.0778820589184761
test loss item: 0.15001080930233002
test loss item: 0.19367288053035736
test loss item: 0.20194828510284424
test loss item: 0.15102942287921906
test loss item: 0.10664978623390198
test loss item: 0.1348736435174942
test loss item: 0.14337153732776642
test loss item: 0.21785080432891846
test loss item: 0.16591057181358337
test loss item: 0.15638376772403717
test loss item: 0.32926496863365173
test loss item: 0.1560184806585312
test loss item: 0.15079817175865173
test loss item: 0.1249857172369957
test loss item: 0.20627261698246002
test loss item: 0.15687544643878937
test loss item: 0.21197055280208588
test loss item: 0.1036459356546402
test loss item: 0.11579649150371552
test loss item: 0.21073515713214874
test loss item: 0.20204883813858032
test loss item: 0.10795290023088455
test loss item: 0.14819355309009552
test loss item: 0.12165489047765732
test loss item: 0.24969616532325745
test loss item: 0.14976854622364044
test loss item: 0.18684886395931244
test loss item: 0.23295263946056366
test loss item: 0.20095299184322357
test loss item: 0.10799697786569595
test loss item: 0.31262731552124023
test loss item: 0.1199151873588562
test loss item: 0.2540546953678131
test loss item: 0.3036324679851532
test loss item: 0.12066303938627243
test loss item: 0.07098778337240219
test loss item: 0.11653827130794525
Epoch [16/50], Training Loss: 0.2285, Testing Loss: 0.1707
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 17/50
train loss item: 0.37034496665000916
train loss item: 0.21707920730113983
train loss item: 0.15602447092533112
train loss item: 0.15922783315181732
train loss item: 0.13295958936214447
train loss item: 0.15086781978607178
train loss item: 0.24839814007282257
train loss item: 0.28418856859207153
train loss item: 0.07565686106681824
train loss item: 0.15827009081840515
train loss item: 0.0902046412229538
train loss item: 0.4277222156524658
train loss item: 0.20213641226291656
train loss item: 0.1593836396932602
train loss item: 0.2475106120109558
train loss item: 0.37843188643455505
train loss item: 0.17730164527893066
train loss item: 0.3405708968639374
train loss item: 0.2462621033191681
train loss item: 0.21787749230861664
train loss item: 0.12809281051158905
train loss item: 0.13614942133426666
train loss item: 0.2306441068649292
train loss item: 0.19491884112358093
train loss item: 0.08515796810388565
train loss item: 0.33200860023498535
train loss item: 0.0742477998137474
train loss item: 0.5466064810752869
train loss item: 0.12226937711238861
train loss item: 0.08948814123868942
train loss item: 0.3554047644138336
train loss item: 0.2195892333984375
train loss item: 0.14490635693073273
train loss item: 0.21740324795246124
train loss item: 0.14713571965694427
train loss item: 0.09923546016216278
train loss item: 0.1250677853822708
train loss item: 0.05866190418601036
train loss item: 0.4353015720844269
train loss item: 0.10259362310171127
train loss item: 0.08894208073616028
train loss item: 0.2662218511104584
train loss item: 0.24217146635055542
train loss item: 0.5111739635467529
train loss item: 0.16180351376533508
test loss item: 0.08402159810066223
test loss item: 0.14319759607315063
test loss item: 0.08650665730237961
test loss item: 0.34466052055358887
test loss item: 0.11156921833753586
test loss item: 0.22767508029937744
test loss item: 0.09850004315376282
test loss item: 0.06323715299367905
test loss item: 0.1352178454399109
test loss item: 0.18586473166942596
test loss item: 0.16787388920783997
test loss item: 0.11692260950803757
test loss item: 0.10034467279911041
test loss item: 0.11946168541908264
test loss item: 0.13090549409389496
test loss item: 0.20488063991069794
test loss item: 0.1330849677324295
test loss item: 0.15365423262119293
test loss item: 0.2970166802406311
test loss item: 0.1364913284778595
test loss item: 0.12778526544570923
test loss item: 0.1113291010260582
test loss item: 0.1791844666004181
test loss item: 0.12912043929100037
test loss item: 0.19344601035118103
test loss item: 0.09129736572504044
test loss item: 0.10927915573120117
test loss item: 0.17515020072460175
test loss item: 0.18508605659008026
test loss item: 0.10002000629901886
test loss item: 0.13513176143169403
test loss item: 0.10679318755865097
test loss item: 0.22404594719409943
test loss item: 0.13937167823314667
test loss item: 0.16593901813030243
test loss item: 0.21988588571548462
test loss item: 0.19503794610500336
test loss item: 0.09565264731645584
test loss item: 0.27127018570899963
test loss item: 0.10563775151968002
test loss item: 0.22609153389930725
test loss item: 0.27027854323387146
test loss item: 0.11853816360235214
test loss item: 0.046133894473314285
test loss item: 0.09667657315731049
Epoch [17/50], Training Loss: 0.2123, Testing Loss: 0.1524
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 18/50
train loss item: 0.4131876230239868
train loss item: 0.19649681448936462
train loss item: 0.11617258191108704
train loss item: 0.14811448752880096
train loss item: 0.12575221061706543
train loss item: 0.11697851866483688
train loss item: 0.2627967894077301
train loss item: 0.26208940148353577
train loss item: 0.06741451472043991
train loss item: 0.15476001799106598
train loss item: 0.07256029546260834
train loss item: 0.5077457427978516
train loss item: 0.1895025223493576
train loss item: 0.1540641039609909
train loss item: 0.18360991775989532
train loss item: 0.4597327709197998
train loss item: 0.15289908647537231
train loss item: 0.5216173529624939
train loss item: 0.3763705790042877
train loss item: 0.21358783543109894
train loss item: 0.13569606840610504
train loss item: 0.14131039381027222
train loss item: 0.20698536932468414
train loss item: 0.1675325185060501
train loss item: 0.11259616911411285
train loss item: 0.2960399389266968
train loss item: 0.07507602870464325
train loss item: 0.5186803936958313
train loss item: 0.10846962034702301
train loss item: 0.06349291652441025
train loss item: 0.3910074234008789
train loss item: 0.1965496689081192
train loss item: 0.13651959598064423
train loss item: 0.24679456651210785
train loss item: 0.1976916491985321
train loss item: 0.12222856283187866
train loss item: 0.13621872663497925
train loss item: 0.06005537137389183
train loss item: 0.4710967242717743
train loss item: 0.11213409900665283
train loss item: 0.10596960037946701
train loss item: 0.25742682814598083
train loss item: 0.2541140615940094
train loss item: 0.6000689268112183
train loss item: 0.1687314808368683
test loss item: 0.10745367407798767
test loss item: 0.17101073265075684
test loss item: 0.16276170313358307
test loss item: 0.4623268246650696
test loss item: 0.15302205085754395
test loss item: 0.2909126877784729
test loss item: 0.11128631234169006
test loss item: 0.10789712518453598
test loss item: 0.14541085064411163
test loss item: 0.22556161880493164
test loss item: 0.1659516543149948
test loss item: 0.12638409435749054
test loss item: 0.11589346826076508
test loss item: 0.16854071617126465
test loss item: 0.17827534675598145
test loss item: 0.2853192687034607
test loss item: 0.1625080704689026
test loss item: 0.2124689370393753
test loss item: 0.41210153698921204
test loss item: 0.17688032984733582
test loss item: 0.11998230218887329
test loss item: 0.11612600088119507
test loss item: 0.1787835955619812
test loss item: 0.1245754137635231
test loss item: 0.24347145855426788
test loss item: 0.14414982497692108
test loss item: 0.1296101212501526
test loss item: 0.26724907755851746
test loss item: 0.2489382028579712
test loss item: 0.1323968470096588
test loss item: 0.15739138424396515
test loss item: 0.11191822588443756
test loss item: 0.25898829102516174
test loss item: 0.1332104206085205
test loss item: 0.2049836814403534
test loss item: 0.27864569425582886
test loss item: 0.13854022324085236
test loss item: 0.09764589369297028
test loss item: 0.34220224618911743
test loss item: 0.15130040049552917
test loss item: 0.3053869605064392
test loss item: 0.37768521904945374
test loss item: 0.12904532253742218
test loss item: 0.06906667351722717
test loss item: 0.10136716067790985
Epoch [18/50], Training Loss: 0.2217, Testing Loss: 0.1890
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 19/50
train loss item: 0.5268347859382629
train loss item: 0.23046715557575226
train loss item: 0.13067997992038727
train loss item: 0.35319390892982483
train loss item: 0.07416249066591263
train loss item: 0.09894059598445892
train loss item: 0.20944276452064514
train loss item: 0.3235633075237274
train loss item: 0.07355586439371109
train loss item: 0.16955971717834473
train loss item: 0.0721701830625534
train loss item: 0.5626177787780762
train loss item: 0.18859979510307312
train loss item: 0.19860947132110596
train loss item: 0.2198614478111267
train loss item: 0.42292502522468567
train loss item: 0.18317250907421112
train loss item: 0.4048028886318207
train loss item: 0.3182463049888611
train loss item: 0.193141907453537
train loss item: 0.14948409795761108
train loss item: 0.10123103111982346
train loss item: 0.19654710590839386
train loss item: 0.18129003047943115
train loss item: 0.10530328005552292
train loss item: 0.37005168199539185
train loss item: 0.07519851624965668
train loss item: 0.5883358120918274
train loss item: 0.12524515390396118
train loss item: 0.06564273685216904
train loss item: 0.42073291540145874
train loss item: 0.15574146807193756
train loss item: 0.11407806724309921
train loss item: 0.18278372287750244
train loss item: 0.17939478158950806
train loss item: 0.1462712436914444
train loss item: 0.20260199904441833
train loss item: 0.07240071892738342
train loss item: 0.38078343868255615
train loss item: 0.09747727960348129
train loss item: 0.0798153355717659
train loss item: 0.2782551348209381
train loss item: 0.22780825197696686
train loss item: 0.5470765233039856
train loss item: 0.13762925565242767
test loss item: 0.14625513553619385
test loss item: 0.2162541002035141
test loss item: 0.1554836928844452
test loss item: 0.40378260612487793
test loss item: 0.17886841297149658
test loss item: 0.3291785717010498
test loss item: 0.11881344765424728
test loss item: 0.14289934933185577
test loss item: 0.15782301127910614
test loss item: 0.19198159873485565
test loss item: 0.18899662792682648
test loss item: 0.13279370963573456
test loss item: 0.11673618108034134
test loss item: 0.18283754587173462
test loss item: 0.1837678849697113
test loss item: 0.30215343832969666
test loss item: 0.1944923847913742
test loss item: 0.19931216537952423
test loss item: 0.4161383807659149
test loss item: 0.2047179788351059
test loss item: 0.14137616753578186
test loss item: 0.13573938608169556
test loss item: 0.21103593707084656
test loss item: 0.11622187495231628
test loss item: 0.2629091143608093
test loss item: 0.15381018817424774
test loss item: 0.1318439394235611
test loss item: 0.29021328687667847
test loss item: 0.21715272963047028
test loss item: 0.13437767326831818
test loss item: 0.1798890233039856
test loss item: 0.11927901953458786
test loss item: 0.30158287286758423
test loss item: 0.14850926399230957
test loss item: 0.1983896791934967
test loss item: 0.2719476819038391
test loss item: 0.1954273134469986
test loss item: 0.09853465110063553
test loss item: 0.4563370645046234
test loss item: 0.14891038835048676
test loss item: 0.30865952372550964
test loss item: 0.390845388174057
test loss item: 0.12050633877515793
test loss item: 0.13825197517871857
test loss item: 0.11271167546510696
Epoch [19/50], Training Loss: 0.2252, Testing Loss: 0.2033
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 20/50
train loss item: 0.33580920100212097
train loss item: 0.16271992027759552
train loss item: 0.11969691514968872
train loss item: 0.2250501662492752
train loss item: 0.08876406401395798
train loss item: 0.1074550598859787
train loss item: 0.2060711681842804
train loss item: 0.20607900619506836
train loss item: 0.07378502935171127
train loss item: 0.16273893415927887
train loss item: 0.09213521331548691
train loss item: 0.38333022594451904
train loss item: 0.15703697502613068
train loss item: 0.1495945155620575
train loss item: 0.22477193176746368
train loss item: 0.44110167026519775
train loss item: 0.17960906028747559
train loss item: 0.32102203369140625
train loss item: 0.1939685195684433
train loss item: 0.17672280967235565
train loss item: 0.11903221905231476
train loss item: 0.10939960181713104
train loss item: 0.1587107926607132
train loss item: 0.18440808355808258
train loss item: 0.1194743737578392
train loss item: 0.37470096349716187
train loss item: 0.06938096135854721
train loss item: 0.4247996509075165
train loss item: 0.10628112405538559
train loss item: 0.07874079793691635
train loss item: 0.39609554409980774
train loss item: 0.11310917884111404
train loss item: 0.10281815379858017
train loss item: 0.19976474344730377
train loss item: 0.12983372807502747
train loss item: 0.0907285138964653
train loss item: 0.11811263114213943
train loss item: 0.064681775867939
train loss item: 0.3941880166530609
train loss item: 0.11385231465101242
train loss item: 0.09539308398962021
train loss item: 0.243781179189682
train loss item: 0.20232412219047546
train loss item: 0.5237135291099548
train loss item: 0.12594647705554962
test loss item: 0.07747901231050491
test loss item: 0.15592901408672333
test loss item: 0.10536070168018341
test loss item: 0.3895344138145447
test loss item: 0.12964163720607758
test loss item: 0.2416478991508484
test loss item: 0.10443267971277237
test loss item: 0.07159756869077682
test loss item: 0.1370934396982193
test loss item: 0.18352234363555908
test loss item: 0.17378680408000946
test loss item: 0.11338072270154953
test loss item: 0.09932984411716461
test loss item: 0.12547287344932556
test loss item: 0.1431981474161148
test loss item: 0.25099897384643555
test loss item: 0.14940111339092255
test loss item: 0.16483736038208008
test loss item: 0.3395976126194
test loss item: 0.15645374357700348
test loss item: 0.11547891795635223
test loss item: 0.11202666163444519
test loss item: 0.18215130269527435
test loss item: 0.11543021351099014
test loss item: 0.21474245190620422
test loss item: 0.11746352165937424
test loss item: 0.10852202028036118
test loss item: 0.21724985539913177
test loss item: 0.1848115175962448
test loss item: 0.11144538223743439
test loss item: 0.14072459936141968
test loss item: 0.10397054255008698
test loss item: 0.22831951081752777
test loss item: 0.1320079267024994
test loss item: 0.16138194501399994
test loss item: 0.2456810027360916
test loss item: 0.1941802054643631
test loss item: 0.08070971816778183
test loss item: 0.341762900352478
test loss item: 0.10945650190114975
test loss item: 0.24322886765003204
test loss item: 0.3007289171218872
test loss item: 0.11575400084257126
test loss item: 0.04715472087264061
test loss item: 0.09815551340579987
Epoch [20/50], Training Loss: 0.1926, Testing Loss: 0.1630
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 21/50
train loss item: 0.2847133278846741
train loss item: 0.14228132367134094
train loss item: 0.09927806258201599
train loss item: 0.11400195956230164
train loss item: 0.0698474571108818
train loss item: 0.12406028807163239
train loss item: 0.14776566624641418
train loss item: 0.1982918530702591
train loss item: 0.06786338239908218
train loss item: 0.12311048060655594
train loss item: 0.082247294485569
train loss item: 0.33388444781303406
train loss item: 0.14152351021766663
train loss item: 0.1435633897781372
train loss item: 0.1786048859357834
train loss item: 0.4315113425254822
train loss item: 0.17032639682292938
train loss item: 0.3187561631202698
train loss item: 0.34601572155952454
train loss item: 0.2148754745721817
train loss item: 0.12343543022871017
train loss item: 0.11257035285234451
train loss item: 0.19064688682556152
train loss item: 0.18035675585269928
train loss item: 0.11356097459793091
train loss item: 0.36972278356552124
train loss item: 0.09580026566982269
train loss item: 0.47540777921676636
train loss item: 0.1014593169093132
train loss item: 0.0803542286157608
train loss item: 0.40138232707977295
train loss item: 0.13271464407444
train loss item: 0.10003189742565155
train loss item: 0.22929397225379944
train loss item: 0.15789750218391418
train loss item: 0.13898591697216034
train loss item: 0.14142437279224396
train loss item: 0.056908681988716125
train loss item: 0.33203160762786865
train loss item: 0.1282607913017273
train loss item: 0.08942756801843643
train loss item: 0.24515898525714874
train loss item: 0.2171052098274231
train loss item: 0.4842361509799957
train loss item: 0.15191996097564697
test loss item: 0.09378966689109802
test loss item: 0.18432340025901794
test loss item: 0.1450103372335434
test loss item: 0.3017141819000244
test loss item: 0.17785637080669403
test loss item: 0.2898845076560974
test loss item: 0.12363667786121368
test loss item: 0.09552999585866928
test loss item: 0.16485315561294556
test loss item: 0.17776885628700256
test loss item: 0.1912623941898346
test loss item: 0.12624748051166534
test loss item: 0.11535382270812988
test loss item: 0.1632809191942215
test loss item: 0.18179062008857727
test loss item: 0.27128997445106506
test loss item: 0.191314697265625
test loss item: 0.21986812353134155
test loss item: 0.36151981353759766
test loss item: 0.18186740577220917
test loss item: 0.11414657533168793
test loss item: 0.14466539025306702
test loss item: 0.2047228068113327
test loss item: 0.14600254595279694
test loss item: 0.2572680413722992
test loss item: 0.17727500200271606
test loss item: 0.1340387761592865
test loss item: 0.29450228810310364
test loss item: 0.17546190321445465
test loss item: 0.14960795640945435
test loss item: 0.19198216497898102
test loss item: 0.1102517619729042
test loss item: 0.22853560745716095
test loss item: 0.1420297473669052
test loss item: 0.18330174684524536
test loss item: 0.17456549406051636
test loss item: 0.177039235830307
test loss item: 0.09614209830760956
test loss item: 0.3522588014602661
test loss item: 0.13487225770950317
test loss item: 0.2546488344669342
test loss item: 0.34938791394233704
test loss item: 0.13363581895828247
test loss item: 0.05783875286579132
test loss item: 0.10004711151123047
Epoch [21/50], Training Loss: 0.1907, Testing Loss: 0.1832
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 22/50
train loss item: 0.2957388460636139
train loss item: 0.17613224685192108
train loss item: 0.1221921294927597
train loss item: 0.13510629534721375
train loss item: 0.073428213596344
train loss item: 0.1449042558670044
train loss item: 0.11692921817302704
train loss item: 0.1798023134469986
train loss item: 0.07437983900308609
train loss item: 0.12571997940540314
train loss item: 0.10584469884634018
train loss item: 0.28827598690986633
train loss item: 0.14283224940299988
train loss item: 0.14457175135612488
train loss item: 0.16956673562526703
train loss item: 0.3501628637313843
train loss item: 0.17317143082618713
train loss item: 0.4056136906147003
train loss item: 0.30880677700042725
train loss item: 0.17237508296966553
train loss item: 0.09889671951532364
train loss item: 0.10293573886156082
train loss item: 0.15879161655902863
train loss item: 0.16416038572788239
train loss item: 0.08043985813856125
train loss item: 0.3168157935142517
train loss item: 0.05796445161104202
train loss item: 0.4369381368160248
train loss item: 0.08630603551864624
train loss item: 0.06253732740879059
train loss item: 0.32342520356178284
train loss item: 0.10909318923950195
train loss item: 0.09591563791036606
train loss item: 0.18199290335178375
train loss item: 0.1282104253768921
train loss item: 0.09948283433914185
train loss item: 0.12193476408720016
train loss item: 0.05068908631801605
train loss item: 0.3060027062892914
train loss item: 0.1240634098649025
train loss item: 0.06919953227043152
train loss item: 0.20263560116291046
train loss item: 0.18317469954490662
train loss item: 0.47303763031959534
train loss item: 0.14151456952095032
test loss item: 0.10417298227548599
test loss item: 0.14878953993320465
test loss item: 0.10750523954629898
test loss item: 0.3433934152126312
test loss item: 0.13479551672935486
test loss item: 0.25197818875312805
test loss item: 0.0965920239686966
test loss item: 0.09454146027565002
test loss item: 0.14641137421131134
test loss item: 0.1733483076095581
test loss item: 0.17077577114105225
test loss item: 0.12192003428936005
test loss item: 0.10525701195001602
test loss item: 0.14147867262363434
test loss item: 0.1436389535665512
test loss item: 0.24915170669555664
test loss item: 0.1514706164598465
test loss item: 0.16121268272399902
test loss item: 0.3120366632938385
test loss item: 0.15818558633327484
test loss item: 0.1294625848531723
test loss item: 0.12924343347549438
test loss item: 0.1867874264717102
test loss item: 0.1253882497549057
test loss item: 0.20719076693058014
test loss item: 0.12224166095256805
test loss item: 0.12186181545257568
test loss item: 0.2227904200553894
test loss item: 0.17302751541137695
test loss item: 0.11201221495866776
test loss item: 0.1546175628900528
test loss item: 0.10389408469200134
test loss item: 0.21662577986717224
test loss item: 0.13605444133281708
test loss item: 0.16302432119846344
test loss item: 0.22030119597911835
test loss item: 0.19303961098194122
test loss item: 0.09775569289922714
test loss item: 0.3138308823108673
test loss item: 0.1162278950214386
test loss item: 0.24637936055660248
test loss item: 0.2993190586566925
test loss item: 0.12023838609457016
test loss item: 0.10260450094938278
test loss item: 0.1022413820028305
Epoch [22/50], Training Loss: 0.1751, Testing Loss: 0.1652
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 23/50
train loss item: 0.23198626935482025
train loss item: 0.15430298447608948
train loss item: 0.1380092203617096
train loss item: 0.12443653494119644
train loss item: 0.0915137305855751
train loss item: 0.11094751209020615
train loss item: 0.12739379703998566
train loss item: 0.14458750188350677
train loss item: 0.07138656079769135
train loss item: 0.16248154640197754
train loss item: 0.1143098771572113
train loss item: 0.25942179560661316
train loss item: 0.15837453305721283
train loss item: 0.10851319879293442
train loss item: 0.15967907011508942
train loss item: 0.2915806174278259
train loss item: 0.163530170917511
train loss item: 0.28071048855781555
train loss item: 0.22989881038665771
train loss item: 0.24236170947551727
train loss item: 0.14498385787010193
train loss item: 0.11936818063259125
train loss item: 0.24825556576251984
train loss item: 0.14407433569431305
train loss item: 0.10403356701135635
train loss item: 0.35095229744911194
train loss item: 0.10246411710977554
train loss item: 0.5253363847732544
train loss item: 0.11811936646699905
train loss item: 0.1165269985795021
train loss item: 0.35911038517951965
train loss item: 0.12122988700866699
train loss item: 0.11513695865869522
train loss item: 0.19892117381095886
train loss item: 0.1269310861825943
train loss item: 0.12729278206825256
train loss item: 0.14757925271987915
train loss item: 0.06189142167568207
train loss item: 0.347577303647995
train loss item: 0.14597856998443604
train loss item: 0.0756203904747963
train loss item: 0.1773308515548706
train loss item: 0.21634431183338165
train loss item: 0.4765525460243225
train loss item: 0.13954344391822815
test loss item: 0.08046477288007736
test loss item: 0.14383473992347717
test loss item: 0.09315120428800583
test loss item: 0.3252885043621063
test loss item: 0.13703574240207672
test loss item: 0.2571128010749817
test loss item: 0.11015878617763519
test loss item: 0.07287298142910004
test loss item: 0.13776883482933044
test loss item: 0.18329231441020966
test loss item: 0.15876607596874237
test loss item: 0.10343533754348755
test loss item: 0.09563763439655304
test loss item: 0.13442616164684296
test loss item: 0.14165347814559937
test loss item: 0.2470041811466217
test loss item: 0.13545726239681244
test loss item: 0.1795823723077774
test loss item: 0.3051334321498871
test loss item: 0.1396382749080658
test loss item: 0.12331953644752502
test loss item: 0.12335747480392456
test loss item: 0.17835043370723724
test loss item: 0.1264466792345047
test loss item: 0.21741797029972076
test loss item: 0.1299874633550644
test loss item: 0.1116613894701004
test loss item: 0.23962613940238953
test loss item: 0.1646125316619873
test loss item: 0.11832503974437714
test loss item: 0.15524528920650482
test loss item: 0.10665684193372726
test loss item: 0.21351999044418335
test loss item: 0.1347106397151947
test loss item: 0.16070741415023804
test loss item: 0.207781583070755
test loss item: 0.18849068880081177
test loss item: 0.09060157090425491
test loss item: 0.2917085886001587
test loss item: 0.10189926624298096
test loss item: 0.255786657333374
test loss item: 0.30759599804878235
test loss item: 0.1158207580447197
test loss item: 0.054561395198106766
test loss item: 0.135880246758461
Epoch [23/50], Training Loss: 0.1817, Testing Loss: 0.1608
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 24/50
train loss item: 0.312404602766037
train loss item: 0.17357699573040009
train loss item: 0.13178236782550812
train loss item: 0.1323474645614624
train loss item: 0.08995227515697479
train loss item: 0.1264980286359787
train loss item: 0.1411179155111313
train loss item: 0.15305069088935852
train loss item: 0.06604734808206558
train loss item: 0.14111600816249847
train loss item: 0.10238121449947357
train loss item: 0.2374737709760666
train loss item: 0.14423450827598572
train loss item: 0.10369008034467697
train loss item: 0.1430073082447052
train loss item: 0.32108035683631897
train loss item: 0.1493026465177536
train loss item: 0.3343174159526825
train loss item: 0.2763000726699829
train loss item: 0.211666539311409
train loss item: 0.1288614571094513
train loss item: 0.11136353015899658
train loss item: 0.18753859400749207
train loss item: 0.14704740047454834
train loss item: 0.09527196735143661
train loss item: 0.28465786576271057
train loss item: 0.09906919300556183
train loss item: 0.37230613827705383
train loss item: 0.09014587104320526
train loss item: 0.08560448884963989
train loss item: 0.28756070137023926
train loss item: 0.12109394371509552
train loss item: 0.10365737229585648
train loss item: 0.16192428767681122
train loss item: 0.10869400948286057
train loss item: 0.09219972789287567
train loss item: 0.10824710875749588
train loss item: 0.05042055621743202
train loss item: 0.2656930088996887
train loss item: 0.1291906088590622
train loss item: 0.07402081042528152
train loss item: 0.18158385157585144
train loss item: 0.1966620832681656
train loss item: 0.35772979259490967
train loss item: 0.14277313649654388
test loss item: 0.08260063827037811
test loss item: 0.12308110296726227
test loss item: 0.07303083688020706
test loss item: 0.3156610131263733
test loss item: 0.09499509632587433
test loss item: 0.18661130964756012
test loss item: 0.0908583402633667
test loss item: 0.064661905169487
test loss item: 0.1268533617258072
test loss item: 0.18266014754772186
test loss item: 0.14301900565624237
test loss item: 0.11373745650053024
test loss item: 0.09147358685731888
test loss item: 0.11644011735916138
test loss item: 0.12050427496433258
test loss item: 0.1670701652765274
test loss item: 0.10996728390455246
test loss item: 0.11428187787532806
test loss item: 0.24607396125793457
test loss item: 0.12759079039096832
test loss item: 0.13021154701709747
test loss item: 0.10292787104845047
test loss item: 0.1724153459072113
test loss item: 0.12633773684501648
test loss item: 0.15093646943569183
test loss item: 0.08448506146669388
test loss item: 0.09682375192642212
test loss item: 0.13456293940544128
test loss item: 0.163759246468544
test loss item: 0.08982238173484802
test loss item: 0.11738521605730057
test loss item: 0.1101396232843399
test loss item: 0.2143079787492752
test loss item: 0.13635312020778656
test loss item: 0.13078780472278595
test loss item: 0.21482141315937042
test loss item: 0.19632865488529205
test loss item: 0.09039109945297241
test loss item: 0.21582944691181183
test loss item: 0.10246367007493973
test loss item: 0.20078295469284058
test loss item: 0.2155531942844391
test loss item: 0.1069493442773819
test loss item: 0.06024976819753647
test loss item: 0.12286105006933212
Epoch [24/50], Training Loss: 0.1661, Testing Loss: 0.1373
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 25/50
train loss item: 0.3262295722961426
train loss item: 0.21741409599781036
train loss item: 0.15714678168296814
train loss item: 0.14919884502887726
train loss item: 0.08095654845237732
train loss item: 0.11209423094987869
train loss item: 0.13612930476665497
train loss item: 0.14103524386882782
train loss item: 0.05733901262283325
train loss item: 0.15453143417835236
train loss item: 0.09004541486501694
train loss item: 0.2329890877008438
train loss item: 0.13153506815433502
train loss item: 0.09656306356191635
train loss item: 0.13765312731266022
train loss item: 0.2372536063194275
train loss item: 0.10393036156892776
train loss item: 0.3660581409931183
train loss item: 0.2057029753923416
train loss item: 0.19294258952140808
train loss item: 0.09607943892478943
train loss item: 0.11607351154088974
train loss item: 0.14470534026622772
train loss item: 0.12110566347837448
train loss item: 0.09113448858261108
train loss item: 0.31181037425994873
train loss item: 0.05849494785070419
train loss item: 0.5467621088027954
train loss item: 0.10271608829498291
train loss item: 0.08604291081428528
train loss item: 0.3096058964729309
train loss item: 0.14668314158916473
train loss item: 0.10925763845443726
train loss item: 0.19697073101997375
train loss item: 0.12825927138328552
train loss item: 0.10647229105234146
train loss item: 0.15723057091236115
train loss item: 0.06604363769292831
train loss item: 0.2951571047306061
train loss item: 0.10854280740022659
train loss item: 0.09331368654966354
train loss item: 0.22746247053146362
train loss item: 0.21028394997119904
train loss item: 0.4240959584712982
train loss item: 0.14148631691932678
test loss item: 0.10198529809713364
test loss item: 0.13636597990989685
test loss item: 0.14228995144367218
test loss item: 0.20648644864559174
test loss item: 0.13377653062343597
test loss item: 0.20269915461540222
test loss item: 0.13376881182193756
test loss item: 0.11743395030498505
test loss item: 0.11043966561555862
test loss item: 0.1444881707429886
test loss item: 0.12750019133090973
test loss item: 0.11033184081315994
test loss item: 0.09540136903524399
test loss item: 0.1422470659017563
test loss item: 0.14969439804553986
test loss item: 0.19198542833328247
test loss item: 0.13750885426998138
test loss item: 0.14815019071102142
test loss item: 0.23966051638126373
test loss item: 0.13936088979244232
test loss item: 0.0930708795785904
test loss item: 0.10190896689891815
test loss item: 0.1493498831987381
test loss item: 0.10833623260259628
test loss item: 0.17710813879966736
test loss item: 0.13454477488994598
test loss item: 0.10217969119548798
test loss item: 0.21138472855091095
test loss item: 0.13641993701457977
test loss item: 0.1329645961523056
test loss item: 0.13049183785915375
test loss item: 0.10784147679805756
test loss item: 0.17071571946144104
test loss item: 0.12701210379600525
test loss item: 0.14967882633209229
test loss item: 0.14312775433063507
test loss item: 0.13376107811927795
test loss item: 0.08892465382814407
test loss item: 0.2410082370042801
test loss item: 0.12177658826112747
test loss item: 0.17092910408973694
test loss item: 0.22503012418746948
test loss item: 0.1046038269996643
test loss item: 0.06396700441837311
test loss item: 0.10675463825464249
Epoch [25/50], Training Loss: 0.1716, Testing Loss: 0.1410
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 26/50
train loss item: 0.3177756667137146
train loss item: 0.16971325874328613
train loss item: 0.11429527401924133
train loss item: 0.2156079113483429
train loss item: 0.1032991111278534
train loss item: 0.13401158154010773
train loss item: 0.19764217734336853
train loss item: 0.17721156775951385
train loss item: 0.05443963780999184
train loss item: 0.12430679798126221
train loss item: 0.07607073336839676
train loss item: 0.26764920353889465
train loss item: 0.16255679726600647
train loss item: 0.11250375956296921
train loss item: 0.20012825727462769
train loss item: 0.2846084237098694
train loss item: 0.14134185016155243
train loss item: 0.33376508951187134
train loss item: 0.3633701503276825
train loss item: 0.22529873251914978
train loss item: 0.1283939629793167
train loss item: 0.08891500532627106
train loss item: 0.18267475068569183
train loss item: 0.1129826083779335
train loss item: 0.09337896853685379
train loss item: 0.2723035514354706
train loss item: 0.06028621643781662
train loss item: 0.39332595467567444
train loss item: 0.09206090867519379
train loss item: 0.07657496631145477
train loss item: 0.3417630195617676
train loss item: 0.17302854359149933
train loss item: 0.12769196927547455
train loss item: 0.202053502202034
train loss item: 0.15611448884010315
train loss item: 0.12689360976219177
train loss item: 0.21902264654636383
train loss item: 0.05663427710533142
train loss item: 0.24465440213680267
train loss item: 0.11414998024702072
train loss item: 0.06765013188123703
train loss item: 0.18254046142101288
train loss item: 0.2043357640504837
train loss item: 0.4462670385837555
train loss item: 0.13356100022792816
test loss item: 0.09435134381055832
test loss item: 0.1605103611946106
test loss item: 0.10841312259435654
test loss item: 0.38865864276885986
test loss item: 0.12363693863153458
test loss item: 0.26927128434181213
test loss item: 0.10723242163658142
test loss item: 0.07769069820642471
test loss item: 0.1487237811088562
test loss item: 0.19643500447273254
test loss item: 0.17157334089279175
test loss item: 0.1258864402770996
test loss item: 0.10118085145950317
test loss item: 0.1372060328722
test loss item: 0.14842037856578827
test loss item: 0.25592243671417236
test loss item: 0.15543526411056519
test loss item: 0.15097424387931824
test loss item: 0.35054078698158264
test loss item: 0.15675115585327148
test loss item: 0.1394449770450592
test loss item: 0.11802638322114944
test loss item: 0.2025315761566162
test loss item: 0.1448500156402588
test loss item: 0.21022363007068634
test loss item: 0.1098267063498497
test loss item: 0.113383948802948
test loss item: 0.2196367084980011
test loss item: 0.18595552444458008
test loss item: 0.11154644191265106
test loss item: 0.14772814512252808
test loss item: 0.12063942849636078
test loss item: 0.25349146127700806
test loss item: 0.14528319239616394
test loss item: 0.17994743585586548
test loss item: 0.26144707202911377
test loss item: 0.199778750538826
test loss item: 0.10722047835588455
test loss item: 0.39896708726882935
test loss item: 0.13003739714622498
test loss item: 0.28174251317977905
test loss item: 0.33581724762916565
test loss item: 0.11645063757896423
test loss item: 0.06108449026942253
test loss item: 0.11709097027778625
Epoch [26/50], Training Loss: 0.1794, Testing Loss: 0.1742
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 27/50
train loss item: 0.22996868193149567
train loss item: 0.14246569573879242
train loss item: 0.17041969299316406
train loss item: 0.22915023565292358
train loss item: 0.08584538847208023
train loss item: 0.11158604919910431
train loss item: 0.2469644695520401
train loss item: 0.18424682319164276
train loss item: 0.07297114282846451
train loss item: 0.1712714582681656
train loss item: 0.10856088995933533
train loss item: 0.41071078181266785
train loss item: 0.18646612763404846
train loss item: 0.13571703433990479
train loss item: 0.17254677414894104
train loss item: 0.268621563911438
train loss item: 0.13780543208122253
train loss item: 0.311106413602829
train loss item: 0.3359977602958679
train loss item: 0.1609489917755127
train loss item: 0.13201668858528137
train loss item: 0.0898866206407547
train loss item: 0.16572941839694977
train loss item: 0.14078910648822784
train loss item: 0.07354752719402313
train loss item: 0.28679990768432617
train loss item: 0.0526641346514225
train loss item: 0.421090692281723
train loss item: 0.10720536857843399
train loss item: 0.06859400123357773
train loss item: 0.27544865012168884
train loss item: 0.13170993328094482
train loss item: 0.09636295586824417
train loss item: 0.15215840935707092
train loss item: 0.11788484454154968
train loss item: 0.072095587849617
train loss item: 0.12945163249969482
train loss item: 0.044971514493227005
train loss item: 0.2821739912033081
train loss item: 0.10804372280836105
train loss item: 0.08371271938085556
train loss item: 0.18409055471420288
train loss item: 0.20187419652938843
train loss item: 0.4318600594997406
train loss item: 0.12212114781141281
test loss item: 0.08982976526021957
test loss item: 0.14872851967811584
test loss item: 0.11340887099504471
test loss item: 0.40769827365875244
test loss item: 0.11595210433006287
test loss item: 0.2538142800331116
test loss item: 0.10049251466989517
test loss item: 0.07777614146471024
test loss item: 0.14821459352970123
test loss item: 0.21406607329845428
test loss item: 0.1711474508047104
test loss item: 0.13190209865570068
test loss item: 0.10596912354230881
test loss item: 0.13818234205245972
test loss item: 0.14657065272331238
test loss item: 0.24068783223628998
test loss item: 0.13917550444602966
test loss item: 0.14853203296661377
test loss item: 0.3495478630065918
test loss item: 0.15198618173599243
test loss item: 0.13277138769626617
test loss item: 0.10882490128278732
test loss item: 0.20629750192165375
test loss item: 0.1378941535949707
test loss item: 0.20804888010025024
test loss item: 0.10018619894981384
test loss item: 0.10734561830759048
test loss item: 0.19467011094093323
test loss item: 0.21052215993404388
test loss item: 0.10080216825008392
test loss item: 0.13874255120754242
test loss item: 0.11564410477876663
test loss item: 0.2508823275566101
test loss item: 0.15439604222774506
test loss item: 0.16336078941822052
test loss item: 0.2779289186000824
test loss item: 0.21095812320709229
test loss item: 0.10212837904691696
test loss item: 0.3652578294277191
test loss item: 0.12647637724876404
test loss item: 0.27746909856796265
test loss item: 0.3132149279117584
test loss item: 0.12449198961257935
test loss item: 0.05593390390276909
test loss item: 0.10105466097593307
Epoch [27/50], Training Loss: 0.1743, Testing Loss: 0.1706
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 28/50
train loss item: 0.2356615662574768
train loss item: 0.15033790469169617
train loss item: 0.11097118258476257
train loss item: 0.14083069562911987
train loss item: 0.0777151957154274
train loss item: 0.13369035720825195
train loss item: 0.18659918010234833
train loss item: 0.21493186056613922
train loss item: 0.05345548316836357
train loss item: 0.12187360972166061
train loss item: 0.0816820040345192
train loss item: 0.31859922409057617
train loss item: 0.17242835462093353
train loss item: 0.12170788645744324
train loss item: 0.16351735591888428
train loss item: 0.23605135083198547
train loss item: 0.10007555037736893
train loss item: 0.31541261076927185
train loss item: 0.35797375440597534
train loss item: 0.19685052335262299
train loss item: 0.11873038858175278
train loss item: 0.08744705468416214
train loss item: 0.15004533529281616
train loss item: 0.11372774094343185
train loss item: 0.0720677599310875
train loss item: 0.22401344776153564
train loss item: 0.05495910719037056
train loss item: 0.34120187163352966
train loss item: 0.09215725213289261
train loss item: 0.08253193646669388
train loss item: 0.2808625102043152
train loss item: 0.17682388424873352
train loss item: 0.11450047791004181
train loss item: 0.205849751830101
train loss item: 0.13050024211406708
train loss item: 0.12468752264976501
train loss item: 0.17493389546871185
train loss item: 0.055295757949352264
train loss item: 0.19170290231704712
train loss item: 0.11835489422082901
train loss item: 0.06970098614692688
train loss item: 0.16889633238315582
train loss item: 0.2027028650045395
train loss item: 0.3888414800167084
train loss item: 0.136038139462471
test loss item: 0.0984787791967392
test loss item: 0.18807855248451233
test loss item: 0.13111647963523865
test loss item: 0.4493948519229889
test loss item: 0.15401870012283325
test loss item: 0.2939112186431885
test loss item: 0.13706469535827637
test loss item: 0.08963432908058167
test loss item: 0.17100922763347626
test loss item: 0.23821412026882172
test loss item: 0.20093193650245667
test loss item: 0.14993445575237274
test loss item: 0.11615418642759323
test loss item: 0.16132088005542755
test loss item: 0.17552483081817627
test loss item: 0.2828366458415985
test loss item: 0.17762835323810577
test loss item: 0.18255272507667542
test loss item: 0.39921605587005615
test loss item: 0.1810111105442047
test loss item: 0.14400716125965118
test loss item: 0.13335315883159637
test loss item: 0.24326252937316895
test loss item: 0.16773411631584167
test loss item: 0.25711244344711304
test loss item: 0.1453828662633896
test loss item: 0.12078385055065155
test loss item: 0.2587452232837677
test loss item: 0.22309783101081848
test loss item: 0.13594940304756165
test loss item: 0.1777190864086151
test loss item: 0.13488620519638062
test loss item: 0.3050411343574524
test loss item: 0.1759585440158844
test loss item: 0.19433355331420898
test loss item: 0.3141118884086609
test loss item: 0.23758992552757263
test loss item: 0.1191864088177681
test loss item: 0.4292473793029785
test loss item: 0.14176157116889954
test loss item: 0.31778356432914734
test loss item: 0.3761735260486603
test loss item: 0.13744044303894043
test loss item: 0.05914589390158653
test loss item: 0.12148361653089523
Epoch [28/50], Training Loss: 0.1637, Testing Loss: 0.2011
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 29/50
train loss item: 0.20679372549057007
train loss item: 0.1377524733543396
train loss item: 0.09932052344083786
train loss item: 0.19773492217063904
train loss item: 0.08240894973278046
train loss item: 0.1020653024315834
train loss item: 0.16083259880542755
train loss item: 0.28379562497138977
train loss item: 0.06530150026082993
train loss item: 0.1321215182542801
train loss item: 0.09072652459144592
train loss item: 0.3002505898475647
train loss item: 0.151192307472229
train loss item: 0.1526334583759308
train loss item: 0.20162881910800934
train loss item: 0.25570419430732727
train loss item: 0.12293357402086258
train loss item: 0.4569849967956543
train loss item: 0.33232542872428894
train loss item: 0.19949936866760254
train loss item: 0.13249683380126953
train loss item: 0.09672363102436066
train loss item: 0.14441055059432983
train loss item: 0.08621258288621902
train loss item: 0.08163650333881378
train loss item: 0.261528879404068
train loss item: 0.08035741001367569
train loss item: 0.508065938949585
train loss item: 0.12331007421016693
train loss item: 0.06692627817392349
train loss item: 0.3186214864253998
train loss item: 0.2300644963979721
train loss item: 0.15832138061523438
train loss item: 0.2019193172454834
train loss item: 0.12800265848636627
train loss item: 0.11154401302337646
train loss item: 0.2125585973262787
train loss item: 0.07394573092460632
train loss item: 0.30172643065452576
train loss item: 0.18310664594173431
train loss item: 0.10913418233394623
train loss item: 0.12793457508087158
train loss item: 0.19594407081604004
train loss item: 0.33716994524002075
train loss item: 0.14249016344547272
test loss item: 0.12477302551269531
test loss item: 0.2762341797351837
test loss item: 0.1883765012025833
test loss item: 0.7263456583023071
test loss item: 0.23341813683509827
test loss item: 0.4178655445575714
test loss item: 0.18677563965320587
test loss item: 0.1408647745847702
test loss item: 0.21312710642814636
test loss item: 0.29843151569366455
test loss item: 0.29507866501808167
test loss item: 0.1790166199207306
test loss item: 0.1572587639093399
test loss item: 0.199752077460289
test loss item: 0.2361953854560852
test loss item: 0.45568278431892395
test loss item: 0.27242815494537354
test loss item: 0.2867524027824402
test loss item: 0.6023426651954651
test loss item: 0.25735291838645935
test loss item: 0.14533255994319916
test loss item: 0.1835058182477951
test loss item: 0.3004525601863861
test loss item: 0.18159781396389008
test loss item: 0.37841641902923584
test loss item: 0.22050750255584717
test loss item: 0.15991564095020294
test loss item: 0.41614454984664917
test loss item: 0.3202584981918335
test loss item: 0.1986042857170105
test loss item: 0.24017347395420074
test loss item: 0.16051438450813293
test loss item: 0.43933987617492676
test loss item: 0.20068906247615814
test loss item: 0.28752994537353516
test loss item: 0.4742412865161896
test loss item: 0.24418023228645325
test loss item: 0.12060092389583588
test loss item: 0.6625887751579285
test loss item: 0.1627129167318344
test loss item: 0.47485801577568054
test loss item: 0.5864821076393127
test loss item: 0.17476056516170502
test loss item: 0.06957338005304337
test loss item: 0.12304630130529404
Epoch [29/50], Training Loss: 0.1810, Testing Loss: 0.2816
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 30/50
train loss item: 0.3447228670120239
train loss item: 0.2633168399333954
train loss item: 0.13236388564109802
train loss item: 0.16905885934829712
train loss item: 0.13489317893981934
train loss item: 0.186105877161026
train loss item: 0.24597041308879852
train loss item: 0.1543608009815216
train loss item: 0.14203029870986938
train loss item: 0.10730639100074768
train loss item: 0.1163984164595604
train loss item: 0.2915085256099701
train loss item: 0.14117784798145294
train loss item: 0.16038063168525696
train loss item: 0.42502561211586
train loss item: 0.3888967037200928
train loss item: 0.2272963523864746
train loss item: 0.26588907837867737
train loss item: 0.2166866809129715
train loss item: 0.2254565954208374
train loss item: 0.11837495863437653
train loss item: 0.14017342031002045
train loss item: 0.1353408247232437
train loss item: 0.11898144334554672
train loss item: 0.10017366707324982
train loss item: 0.22404496371746063
train loss item: 0.09612172096967697
train loss item: 0.3606974184513092
train loss item: 0.11764969676733017
train loss item: 0.12495000660419464
train loss item: 0.5879282355308533
train loss item: 0.1160288080573082
train loss item: 0.1205412745475769
train loss item: 0.1558227390050888
train loss item: 0.16804519295692444
train loss item: 0.10356593132019043
train loss item: 0.0838172510266304
train loss item: 0.056967880576848984
train loss item: 0.5239670872688293
train loss item: 0.1522088199853897
train loss item: 0.13836893439292908
train loss item: 0.14191745221614838
train loss item: 0.2820664346218109
train loss item: 0.4440498948097229
train loss item: 0.18132245540618896
test loss item: 0.0977441668510437
test loss item: 0.14292383193969727
test loss item: 0.09596364200115204
test loss item: 0.4763511121273041
test loss item: 0.10592099279165268
test loss item: 0.24673902988433838
test loss item: 0.0947723537683487
test loss item: 0.08056410402059555
test loss item: 0.13615062832832336
test loss item: 0.19942615926265717
test loss item: 0.17820987105369568
test loss item: 0.12841783463954926
test loss item: 0.10264661908149719
test loss item: 0.12072669714689255
test loss item: 0.12807030975818634
test loss item: 0.2546808123588562
test loss item: 0.1482829600572586
test loss item: 0.12978816032409668
test loss item: 0.34717708826065063
test loss item: 0.15444308519363403
test loss item: 0.13242444396018982
test loss item: 0.10873212665319443
test loss item: 0.18892426788806915
test loss item: 0.1297263354063034
test loss item: 0.18936878442764282
test loss item: 0.09247007220983505
test loss item: 0.103960320353508
test loss item: 0.17992337048053741
test loss item: 0.19824811816215515
test loss item: 0.10018941760063171
test loss item: 0.12744386494159698
test loss item: 0.11225031316280365
test loss item: 0.2718394696712494
test loss item: 0.1382034718990326
test loss item: 0.16371017694473267
test loss item: 0.3152770698070526
test loss item: 0.20174992084503174
test loss item: 0.09778842329978943
test loss item: 0.40300536155700684
test loss item: 0.1126556247472763
test loss item: 0.29645347595214844
test loss item: 0.3218819797039032
test loss item: 0.11687761545181274
test loss item: 0.07111703604459763
test loss item: 0.1324150264263153
Epoch [30/50], Training Loss: 0.2029, Testing Loss: 0.1706
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 31/50
train loss item: 0.25098347663879395
train loss item: 0.13422422111034393
train loss item: 0.09946375340223312
train loss item: 0.26655638217926025
train loss item: 0.11204807460308075
train loss item: 0.113199882209301
train loss item: 0.1367117315530777
train loss item: 0.2001473307609558
train loss item: 0.08058812469244003
train loss item: 0.15997526049613953
train loss item: 0.090206578373909
train loss item: 0.26768580079078674
train loss item: 0.18697519600391388
train loss item: 0.08759982138872147
train loss item: 0.15278996527194977
train loss item: 0.23231159150600433
train loss item: 0.11366462707519531
train loss item: 0.31661203503608704
train loss item: 0.20606574416160583
train loss item: 0.23660747706890106
train loss item: 0.13307160139083862
train loss item: 0.10071849077939987
train loss item: 0.2068895399570465
train loss item: 0.10745544731616974
train loss item: 0.10698572546243668
train loss item: 0.3042480945587158
train loss item: 0.0780152976512909
train loss item: 0.41863226890563965
train loss item: 0.13724958896636963
train loss item: 0.14120106399059296
train loss item: 0.31422099471092224
train loss item: 0.13196690380573273
train loss item: 0.1263248324394226
train loss item: 0.27924153208732605
train loss item: 0.1927022784948349
train loss item: 0.1388079822063446
train loss item: 0.1283363401889801
train loss item: 0.05431795120239258
train loss item: 0.4574377238750458
train loss item: 0.10628318786621094
train loss item: 0.08499493449926376
train loss item: 0.17512181401252747
train loss item: 0.22557301819324493
train loss item: 0.3856368362903595
train loss item: 0.1397325098514557
test loss item: 0.08158386498689651
test loss item: 0.17836201190948486
test loss item: 0.12933607399463654
test loss item: 0.32684311270713806
test loss item: 0.17053548991680145
test loss item: 0.29276829957962036
test loss item: 0.1231590062379837
test loss item: 0.08900276571512222
test loss item: 0.15361160039901733
test loss item: 0.18765665590763092
test loss item: 0.19407519698143005
test loss item: 0.13418738543987274
test loss item: 0.10571154206991196
test loss item: 0.1472465842962265
test loss item: 0.17079034447669983
test loss item: 0.2675282061100006
test loss item: 0.18269982933998108
test loss item: 0.21477089822292328
test loss item: 0.38094863295555115
test loss item: 0.17014920711517334
test loss item: 0.09349216520786285
test loss item: 0.1281406581401825
test loss item: 0.21077395975589752
test loss item: 0.14943350851535797
test loss item: 0.25230762362480164
test loss item: 0.1701599806547165
test loss item: 0.12008262425661087
test loss item: 0.2930363416671753
test loss item: 0.20868231356143951
test loss item: 0.14058807492256165
test loss item: 0.17948004603385925
test loss item: 0.09421809017658234
test loss item: 0.2538037598133087
test loss item: 0.12764206528663635
test loss item: 0.18740148842334747
test loss item: 0.2063933163881302
test loss item: 0.14997591078281403
test loss item: 0.09209258109331131
test loss item: 0.4202059507369995
test loss item: 0.11391602456569672
test loss item: 0.26067915558815
test loss item: 0.371023952960968
test loss item: 0.12738078832626343
test loss item: 0.043069157749414444
test loss item: 0.0741649642586708
Epoch [31/50], Training Loss: 0.1804, Testing Loss: 0.1815
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 32/50
train loss item: 0.2679988443851471
train loss item: 0.1595950573682785
train loss item: 0.1293352097272873
train loss item: 0.13122405111789703
train loss item: 0.08868638426065445
train loss item: 0.13321374356746674
train loss item: 0.11368903517723083
train loss item: 0.23179841041564941
train loss item: 0.07321905344724655
train loss item: 0.12569990754127502
train loss item: 0.08501086384057999
train loss item: 0.26075834035873413
train loss item: 0.13081160187721252
train loss item: 0.10103698074817657
train loss item: 0.204450786113739
train loss item: 0.33307504653930664
train loss item: 0.15361352264881134
train loss item: 0.32001879811286926
train loss item: 0.2731449604034424
train loss item: 0.2189534604549408
train loss item: 0.12168404459953308
train loss item: 0.07991660386323929
train loss item: 0.22830669581890106
train loss item: 0.11344907432794571
train loss item: 0.11888816952705383
train loss item: 0.2523268461227417
train loss item: 0.05624058470129967
train loss item: 0.24636158347129822
train loss item: 0.10893343389034271
train loss item: 0.08598192036151886
train loss item: 0.2997879981994629
train loss item: 0.14888693392276764
train loss item: 0.12955866754055023
train loss item: 0.13392570614814758
train loss item: 0.14052356779575348
train loss item: 0.10639307647943497
train loss item: 0.15678469836711884
train loss item: 0.062111832201480865
train loss item: 0.2992042005062103
train loss item: 0.12345211952924728
train loss item: 0.08046038448810577
train loss item: 0.1277400106191635
train loss item: 0.1753654181957245
train loss item: 0.3098553419113159
train loss item: 0.10447113960981369
test loss item: 0.16663941740989685
test loss item: 0.2763720452785492
test loss item: 0.25185418128967285
test loss item: 0.41354572772979736
test loss item: 0.21756112575531006
test loss item: 0.3936535120010376
test loss item: 0.15013957023620605
test loss item: 0.17686298489570618
test loss item: 0.19743113219738007
test loss item: 0.2086818367242813
test loss item: 0.2345866709947586
test loss item: 0.20442675054073334
test loss item: 0.14698506891727448
test loss item: 0.22854188084602356
test loss item: 0.2456548660993576
test loss item: 0.3640645742416382
test loss item: 0.270507276058197
test loss item: 0.2556655704975128
test loss item: 0.5271791219711304
test loss item: 0.25993451476097107
test loss item: 0.13877169787883759
test loss item: 0.1526452898979187
test loss item: 0.24038319289684296
test loss item: 0.18118426203727722
test loss item: 0.3181561827659607
test loss item: 0.20195141434669495
test loss item: 0.15413793921470642
test loss item: 0.3959779441356659
test loss item: 0.252108633518219
test loss item: 0.18239322304725647
test loss item: 0.21704219281673431
test loss item: 0.14369331300258636
test loss item: 0.39363548159599304
test loss item: 0.17324692010879517
test loss item: 0.24225075542926788
test loss item: 0.26278597116470337
test loss item: 0.20385819673538208
test loss item: 0.13591718673706055
test loss item: 0.6635590195655823
test loss item: 0.21754316985607147
test loss item: 0.37573274970054626
test loss item: 0.5029976963996887
test loss item: 0.1646004319190979
test loss item: 0.09486621618270874
test loss item: 0.16442576050758362
Epoch [32/50], Training Loss: 0.1632, Testing Loss: 0.2525
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 33/50
train loss item: 0.28012320399284363
train loss item: 0.16550874710083008
train loss item: 0.1186697781085968
train loss item: 0.12528616189956665
train loss item: 0.07280294597148895
train loss item: 0.1433464139699936
train loss item: 0.1935676485300064
train loss item: 0.2587142288684845
train loss item: 0.09116438776254654
train loss item: 0.10658147931098938
train loss item: 0.08459780365228653
train loss item: 0.18122372031211853
train loss item: 0.1204226166009903
train loss item: 0.1545114368200302
train loss item: 0.16562040150165558
train loss item: 0.25131163001060486
train loss item: 0.22379982471466064
train loss item: 0.19945074617862701
train loss item: 0.23945869505405426
train loss item: 0.2264450341463089
train loss item: 0.1553315669298172
train loss item: 0.09870865195989609
train loss item: 0.18985672295093536
train loss item: 0.09895625710487366
train loss item: 0.10797396302223206
train loss item: 0.2484491765499115
train loss item: 0.08605432510375977
train loss item: 0.32724568247795105
train loss item: 0.10635419189929962
train loss item: 0.1000448614358902
train loss item: 0.31638476252555847
train loss item: 0.16665683686733246
train loss item: 0.10187393426895142
train loss item: 0.13080766797065735
train loss item: 0.150430828332901
train loss item: 0.09994877129793167
train loss item: 0.13620446622371674
train loss item: 0.05760379880666733
train loss item: 0.3527180254459381
train loss item: 0.10975245386362076
train loss item: 0.06453578174114227
train loss item: 0.11517658829689026
train loss item: 0.17039303481578827
train loss item: 0.3786250650882721
train loss item: 0.11708222329616547
test loss item: 0.10767938196659088
test loss item: 0.16433385014533997
test loss item: 0.1473550945520401
test loss item: 0.5271114110946655
test loss item: 0.13729707896709442
test loss item: 0.29756009578704834
test loss item: 0.11547637730836868
test loss item: 0.11086931079626083
test loss item: 0.1494324505329132
test loss item: 0.23978456854820251
test loss item: 0.1932077258825302
test loss item: 0.14102602005004883
test loss item: 0.10515208542346954
test loss item: 0.1538916677236557
test loss item: 0.17321783304214478
test loss item: 0.3076428472995758
test loss item: 0.17102892696857452
test loss item: 0.1751585304737091
test loss item: 0.41835102438926697
test loss item: 0.17210470139980316
test loss item: 0.12278272211551666
test loss item: 0.11936095356941223
test loss item: 0.2057955116033554
test loss item: 0.1400403380393982
test loss item: 0.2406230866909027
test loss item: 0.12932024896144867
test loss item: 0.11182516068220139
test loss item: 0.24511896073818207
test loss item: 0.23627901077270508
test loss item: 0.1253296434879303
test loss item: 0.1646994650363922
test loss item: 0.1180528774857521
test loss item: 0.28605905175209045
test loss item: 0.1567249894142151
test loss item: 0.19662335515022278
test loss item: 0.3438858985900879
test loss item: 0.20683063566684723
test loss item: 0.1034805104136467
test loss item: 0.41600361466407776
test loss item: 0.13644704222679138
test loss item: 0.3371921181678772
test loss item: 0.3847677707672119
test loss item: 0.1262659728527069
test loss item: 0.059323299676179886
test loss item: 0.10419021546840668
Epoch [33/50], Training Loss: 0.1642, Testing Loss: 0.1961
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 34/50
train loss item: 0.22989067435264587
train loss item: 0.13132357597351074
train loss item: 0.08678081631660461
train loss item: 0.1270948052406311
train loss item: 0.0787648931145668
train loss item: 0.10853004455566406
train loss item: 0.13923640549182892
train loss item: 0.15401703119277954
train loss item: 0.06745941191911697
train loss item: 0.10140007734298706
train loss item: 0.07169651985168457
train loss item: 0.188942551612854
train loss item: 0.1275561898946762
train loss item: 0.14025267958641052
train loss item: 0.2584439814090729
train loss item: 0.21377599239349365
train loss item: 0.1378197818994522
train loss item: 0.2842560112476349
train loss item: 0.2455541491508484
train loss item: 0.21665683388710022
train loss item: 0.13581383228302002
train loss item: 0.08757498115301132
train loss item: 0.16701436042785645
train loss item: 0.1050710529088974
train loss item: 0.1364770084619522
train loss item: 0.2628616690635681
train loss item: 0.08857769519090652
train loss item: 0.3032492697238922
train loss item: 0.11424817144870758
train loss item: 0.06684134155511856
train loss item: 0.3181232213973999
train loss item: 0.17671550810337067
train loss item: 0.16774629056453705
train loss item: 0.15483710169792175
train loss item: 0.13595718145370483
train loss item: 0.07992597669363022
train loss item: 0.11800234019756317
train loss item: 0.05085175856947899
train loss item: 0.3431932032108307
train loss item: 0.1306205689907074
train loss item: 0.08832601457834244
train loss item: 0.14312925934791565
train loss item: 0.1676742136478424
train loss item: 0.3419371545314789
train loss item: 0.1183948665857315
test loss item: 0.11509792506694794
test loss item: 0.17856556177139282
test loss item: 0.17863662540912628
test loss item: 0.39807403087615967
test loss item: 0.1471114158630371
test loss item: 0.2916267514228821
test loss item: 0.13107499480247498
test loss item: 0.12040586769580841
test loss item: 0.1481841504573822
test loss item: 0.20525501668453217
test loss item: 0.18393541872501373
test loss item: 0.1661519706249237
test loss item: 0.11266245692968369
test loss item: 0.16886599361896515
test loss item: 0.18157146871089935
test loss item: 0.2666153311729431
test loss item: 0.1809234768152237
test loss item: 0.18436826765537262
test loss item: 0.38982975482940674
test loss item: 0.1833047717809677
test loss item: 0.12972941994667053
test loss item: 0.11556855589151382
test loss item: 0.20610909163951874
test loss item: 0.17057394981384277
test loss item: 0.23868735134601593
test loss item: 0.14926546812057495
test loss item: 0.1128978431224823
test loss item: 0.2674647569656372
test loss item: 0.2192205935716629
test loss item: 0.13763993978500366
test loss item: 0.16150400042533875
test loss item: 0.11914938688278198
test loss item: 0.2872771620750427
test loss item: 0.14889979362487793
test loss item: 0.18819722533226013
test loss item: 0.26821354031562805
test loss item: 0.17685645818710327
test loss item: 0.13062524795532227
test loss item: 0.4425415098667145
test loss item: 0.1645226925611496
test loss item: 0.29706189036369324
test loss item: 0.3714037537574768
test loss item: 0.13327987492084503
test loss item: 0.05965321511030197
test loss item: 0.1270914226770401
Epoch [34/50], Training Loss: 0.1581, Testing Loss: 0.1946
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.15236234664916992
loss item: 0.48296818137168884
loss item: 0.22919179499149323
loss item: 0.23418007791042328
loss item: 0.13278430700302124
loss item: 0.32709839940071106
loss item: 0.23045314848423004
loss item: 0.22091297805309296
loss item: 0.2351822704076767
loss item: 0.3059622347354889
loss item: 0.15605658292770386
loss item: 0.1435350477695465
loss item: 0.23650915920734406
loss item: 0.2706030011177063
loss item: 0.18545901775360107
loss item: 0.4461347758769989
loss item: 0.18768823146820068
loss item: 0.1376291960477829
loss item: 0.15646277368068695
loss item: 0.22472381591796875
loss item: 0.30971184372901917
loss item: 0.1485242396593094
Val Loss: 0.2343
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 50, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.005 4 360 done at Tue Nov 12 11:03:54 CET 2024
UNet2 with 1 50 0.0001 8 360 start at Tue Nov 12 11:03:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.4765785932540894
train loss item: 1.083484411239624
train loss item: 0.5838243365287781
train loss item: 0.812828540802002
train loss item: 0.5618910789489746
train loss item: 1.078084111213684
train loss item: 0.5615077018737793
train loss item: 1.6320184469223022
train loss item: 1.8999967575073242
train loss item: 0.5566858649253845
train loss item: 0.39754918217658997
train loss item: 0.5428510904312134
train loss item: 0.641681432723999
train loss item: 1.4390499591827393
train loss item: 0.44381245970726013
train loss item: 1.109988808631897
train loss item: 0.5536924004554749
train loss item: 0.5271103978157043
train loss item: 0.5418879389762878
train loss item: 0.7999544143676758
train loss item: 0.41836076974868774
train loss item: 1.768530249595642
train loss item: 0.45973601937294006
test loss item: 0.6564205288887024
test loss item: 1.1753612756729126
test loss item: 0.9327887892723083
test loss item: 0.23601214587688446
test loss item: 0.6325896978378296
test loss item: 0.6444830894470215
test loss item: 0.36974871158599854
test loss item: 0.9694143533706665
test loss item: 0.7612301707267761
test loss item: 1.3546137809753418
test loss item: 0.406040221452713
test loss item: 0.6077709197998047
test loss item: 0.7900437116622925
test loss item: 0.9120163321495056
test loss item: 0.5920053124427795
test loss item: 0.4564494788646698
test loss item: 0.9680256247520447
test loss item: 0.9331833124160767
test loss item: 0.4089297652244568
test loss item: 2.0261149406433105
test loss item: 1.6520882844924927
test loss item: 0.2741067111492157
test loss item: 0.1968715488910675
Epoch [1/50], Training Loss: 0.8648, Testing Loss: 0.7807
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/50
train loss item: 0.7417500615119934
train loss item: 0.5656790137290955
train loss item: 0.365988552570343
train loss item: 0.44126635789871216
train loss item: 0.3789122998714447
train loss item: 0.618120551109314
train loss item: 0.3926723301410675
train loss item: 1.0211806297302246
train loss item: 1.2836291790008545
train loss item: 0.4075939655303955
train loss item: 0.29767176508903503
train loss item: 0.37050122022628784
train loss item: 0.4769611656665802
train loss item: 1.0178533792495728
train loss item: 0.3016112744808197
train loss item: 0.8293887972831726
train loss item: 0.4290391504764557
train loss item: 0.3414711356163025
train loss item: 0.33933156728744507
train loss item: 0.6073342561721802
train loss item: 0.329913467168808
train loss item: 1.4259922504425049
train loss item: 0.4048585593700409
test loss item: 0.3749174177646637
test loss item: 0.5841132402420044
test loss item: 0.5142123103141785
test loss item: 0.21610724925994873
test loss item: 0.4151616096496582
test loss item: 0.428355872631073
test loss item: 0.2773471176624298
test loss item: 0.4989481270313263
test loss item: 0.5812373161315918
test loss item: 0.7112188339233398
test loss item: 0.32378068566322327
test loss item: 0.416506290435791
test loss item: 0.4621787965297699
test loss item: 0.5079854130744934
test loss item: 0.42758679389953613
test loss item: 0.32240381836891174
test loss item: 0.4743603765964508
test loss item: 0.5154066681861877
test loss item: 0.27740713953971863
test loss item: 0.8332746028900146
test loss item: 0.8047391176223755
test loss item: 0.22709102928638458
test loss item: 0.23143629729747772
Epoch [2/50], Training Loss: 0.5821, Testing Loss: 0.4533
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/50
train loss item: 0.5836189985275269
train loss item: 0.460042804479599
train loss item: 0.322931706905365
train loss item: 0.3822566568851471
train loss item: 0.3139364719390869
train loss item: 0.5080469846725464
train loss item: 0.33512434363365173
train loss item: 0.8311465382575989
train loss item: 1.0217022895812988
train loss item: 0.35656672716140747
train loss item: 0.26793476939201355
train loss item: 0.32368218898773193
train loss item: 0.440357506275177
train loss item: 0.7826980352401733
train loss item: 0.2696899175643921
train loss item: 0.6817733645439148
train loss item: 0.3956076502799988
train loss item: 0.30178457498550415
train loss item: 0.2923298180103302
train loss item: 0.5213814973831177
train loss item: 0.29002702236175537
train loss item: 1.2048746347427368
train loss item: 0.36062705516815186
test loss item: 0.3052310347557068
test loss item: 0.5369422435760498
test loss item: 0.42228224873542786
test loss item: 0.20859259366989136
test loss item: 0.3693908751010895
test loss item: 0.3489859402179718
test loss item: 0.2530066967010498
test loss item: 0.43169352412223816
test loss item: 0.4590947926044464
test loss item: 0.572840690612793
test loss item: 0.27380311489105225
test loss item: 0.3643897771835327
test loss item: 0.3962213695049286
test loss item: 0.41734927892684937
test loss item: 0.36088645458221436
test loss item: 0.28456392884254456
test loss item: 0.40941131114959717
test loss item: 0.4483882188796997
test loss item: 0.26715075969696045
test loss item: 0.6281399726867676
test loss item: 0.670803427696228
test loss item: 0.21077226102352142
test loss item: 0.2520347833633423
Epoch [3/50], Training Loss: 0.4890, Testing Loss: 0.3866
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/50
train loss item: 0.5281833410263062
train loss item: 0.4317452907562256
train loss item: 0.29037660360336304
train loss item: 0.3437061905860901
train loss item: 0.27024078369140625
train loss item: 0.46432939171791077
train loss item: 0.2984854578971863
train loss item: 0.7213901281356812
train loss item: 0.8398179411888123
train loss item: 0.32816269993782043
train loss item: 0.24559886753559113
train loss item: 0.3110804557800293
train loss item: 0.4126107394695282
train loss item: 0.6318047642707825
train loss item: 0.2331475168466568
train loss item: 0.5893158316612244
train loss item: 0.3473173975944519
train loss item: 0.2793399691581726
train loss item: 0.24662169814109802
train loss item: 0.47092384099960327
train loss item: 0.25547516345977783
train loss item: 1.0721052885055542
train loss item: 0.31800419092178345
test loss item: 0.28926870226860046
test loss item: 0.5087223649024963
test loss item: 0.37412479519844055
test loss item: 0.2075520157814026
test loss item: 0.3454647958278656
test loss item: 0.3141767382621765
test loss item: 0.24933460354804993
test loss item: 0.39173218607902527
test loss item: 0.40807682275772095
test loss item: 0.5108515024185181
test loss item: 0.2517012357711792
test loss item: 0.3276495635509491
test loss item: 0.3641481399536133
test loss item: 0.3769974112510681
test loss item: 0.32736289501190186
test loss item: 0.2654727101325989
test loss item: 0.3831939995288849
test loss item: 0.41253769397735596
test loss item: 0.25438034534454346
test loss item: 0.5344184637069702
test loss item: 0.5921187400817871
test loss item: 0.211030051112175
test loss item: 0.3621618449687958
Epoch [4/50], Training Loss: 0.4317, Testing Loss: 0.3592
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/50
train loss item: 0.47892698645591736
train loss item: 0.39972272515296936
train loss item: 0.2865172326564789
train loss item: 0.3277915418148041
train loss item: 0.24260197579860687
train loss item: 0.42092201113700867
train loss item: 0.27311697602272034
train loss item: 0.6216449737548828
train loss item: 0.6964719295501709
train loss item: 0.30150866508483887
train loss item: 0.22281934320926666
train loss item: 0.2823345363140106
train loss item: 0.38671550154685974
train loss item: 0.5315948128700256
train loss item: 0.22176602482795715
train loss item: 0.5175883769989014
train loss item: 0.3155915141105652
train loss item: 0.2645622193813324
train loss item: 0.2243748903274536
train loss item: 0.4247480034828186
train loss item: 0.24222224950790405
train loss item: 0.9605743288993835
train loss item: 0.2864496111869812
test loss item: 0.2681131362915039
test loss item: 0.451811820268631
test loss item: 0.33482876420021057
test loss item: 0.19554294645786285
test loss item: 0.30788442492485046
test loss item: 0.2816539704799652
test loss item: 0.22538264095783234
test loss item: 0.3471445143222809
test loss item: 0.3609934449195862
test loss item: 0.45546281337738037
test loss item: 0.22189854085445404
test loss item: 0.2940639853477478
test loss item: 0.3267595171928406
test loss item: 0.33665940165519714
test loss item: 0.2960127294063568
test loss item: 0.23934830725193024
test loss item: 0.347905695438385
test loss item: 0.3671259582042694
test loss item: 0.2324514538049698
test loss item: 0.4746415913105011
test loss item: 0.5223944783210754
test loss item: 0.191764235496521
test loss item: 0.286038875579834
Epoch [5/50], Training Loss: 0.3883, Testing Loss: 0.3203
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/50
train loss item: 0.435422420501709
train loss item: 0.36739614605903625
train loss item: 0.2692262828350067
train loss item: 0.31787559390068054
train loss item: 0.22158408164978027
train loss item: 0.39404919743537903
train loss item: 0.24779339134693146
train loss item: 0.5712112188339233
train loss item: 0.6255072951316833
train loss item: 0.28577330708503723
train loss item: 0.22145067155361176
train loss item: 0.2787756025791168
train loss item: 0.3726474642753601
train loss item: 0.44578418135643005
train loss item: 0.2032674103975296
train loss item: 0.45304372906684875
train loss item: 0.30671411752700806
train loss item: 0.26673218607902527
train loss item: 0.21435992419719696
train loss item: 0.4000987708568573
train loss item: 0.24644064903259277
train loss item: 0.888120174407959
train loss item: 0.27682244777679443
test loss item: 0.2834940552711487
test loss item: 0.4554317891597748
test loss item: 0.36500316858291626
test loss item: 0.18664152920246124
test loss item: 0.293560653924942
test loss item: 0.26825252175331116
test loss item: 0.22290758788585663
test loss item: 0.3665391504764557
test loss item: 0.3571268916130066
test loss item: 0.4943573474884033
test loss item: 0.21391956508159637
test loss item: 0.2641841769218445
test loss item: 0.3290248215198517
test loss item: 0.3599393665790558
test loss item: 0.2939949035644531
test loss item: 0.23176777362823486
test loss item: 0.3627004325389862
test loss item: 0.3647245168685913
test loss item: 0.22026026248931885
test loss item: 0.6238955855369568
test loss item: 0.5884270668029785
test loss item: 0.18897327780723572
test loss item: 0.29573673009872437
Epoch [6/50], Training Loss: 0.3613, Testing Loss: 0.3318
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/50
train loss item: 0.3825624883174896
train loss item: 0.3148273527622223
train loss item: 0.2603245675563812
train loss item: 0.30860137939453125
train loss item: 0.20929054915905
train loss item: 0.3598375916481018
train loss item: 0.23363979160785675
train loss item: 0.4887494444847107
train loss item: 0.5538703799247742
train loss item: 0.26717397570610046
train loss item: 0.18641993403434753
train loss item: 0.2340330332517624
train loss item: 0.32728111743927
train loss item: 0.39788299798965454
train loss item: 0.1802392601966858
train loss item: 0.40818336606025696
train loss item: 0.27619147300720215
train loss item: 0.2598611116409302
train loss item: 0.20155298709869385
train loss item: 0.3630409240722656
train loss item: 0.24135839939117432
train loss item: 0.8075783252716064
train loss item: 0.27323487401008606
test loss item: 0.26877105236053467
test loss item: 0.44425004720687866
test loss item: 0.35942625999450684
test loss item: 0.16721484065055847
test loss item: 0.2811721861362457
test loss item: 0.26967039704322815
test loss item: 0.19808104634284973
test loss item: 0.3552539348602295
test loss item: 0.3388080596923828
test loss item: 0.49028724431991577
test loss item: 0.2230607122182846
test loss item: 0.2547677457332611
test loss item: 0.30006441473960876
test loss item: 0.348059743642807
test loss item: 0.27975305914878845
test loss item: 0.21007217466831207
test loss item: 0.37165385484695435
test loss item: 0.36671143770217896
test loss item: 0.22466892004013062
test loss item: 0.6670399308204651
test loss item: 0.5989232063293457
test loss item: 0.1703696846961975
test loss item: 0.2291974127292633
Epoch [7/50], Training Loss: 0.3276, Testing Loss: 0.3225
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/50
train loss item: 0.35498693585395813
train loss item: 0.27661773562431335
train loss item: 0.2507956624031067
train loss item: 0.2905431389808655
train loss item: 0.19189584255218506
train loss item: 0.3691663146018982
train loss item: 0.263126015663147
train loss item: 0.4863158166408539
train loss item: 0.526951253414154
train loss item: 0.277037650346756
train loss item: 0.18981313705444336
train loss item: 0.26853320002555847
train loss item: 0.34457796812057495
train loss item: 0.35030633211135864
train loss item: 0.16632866859436035
train loss item: 0.3841131031513214
train loss item: 0.25254303216934204
train loss item: 0.24747836589813232
train loss item: 0.1979285180568695
train loss item: 0.37553420662879944
train loss item: 0.2490677535533905
train loss item: 0.7715502977371216
train loss item: 0.2680889964103699
test loss item: 0.2663212716579437
test loss item: 0.42561075091362
test loss item: 0.37544798851013184
test loss item: 0.13880577683448792
test loss item: 0.25617116689682007
test loss item: 0.2324955016374588
test loss item: 0.16949903964996338
test loss item: 0.36494341492652893
test loss item: 0.31659290194511414
test loss item: 0.5230133533477783
test loss item: 0.18099114298820496
test loss item: 0.2141830325126648
test loss item: 0.2983261048793793
test loss item: 0.35991957783699036
test loss item: 0.2703776955604553
test loss item: 0.18631304800510406
test loss item: 0.38154688477516174
test loss item: 0.36037954688072205
test loss item: 0.1726294308900833
test loss item: 0.798258364200592
test loss item: 0.6579353213310242
test loss item: 0.1453174352645874
test loss item: 0.15778020024299622
Epoch [8/50], Training Loss: 0.3197, Testing Loss: 0.3153
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/50
train loss item: 0.32561632990837097
train loss item: 0.2447439730167389
train loss item: 0.24230165779590607
train loss item: 0.2652389407157898
train loss item: 0.19050459563732147
train loss item: 0.31225723028182983
train loss item: 0.2519325911998749
train loss item: 0.4136081337928772
train loss item: 0.44616204500198364
train loss item: 0.22507734596729279
train loss item: 0.16776694357395172
train loss item: 0.220158189535141
train loss item: 0.2912244498729706
train loss item: 0.3106955587863922
train loss item: 0.1553719937801361
train loss item: 0.3373541831970215
train loss item: 0.24508671462535858
train loss item: 0.2344696968793869
train loss item: 0.18031184375286102
train loss item: 0.3375830352306366
train loss item: 0.2286861091852188
train loss item: 0.7292516827583313
train loss item: 0.2499716877937317
test loss item: 0.22020649909973145
test loss item: 0.4375167489051819
test loss item: 0.358296275138855
test loss item: 0.12402510643005371
test loss item: 0.24307824671268463
test loss item: 0.20646925270557404
test loss item: 0.1556151807308197
test loss item: 0.3582001328468323
test loss item: 0.26221930980682373
test loss item: 0.49292004108428955
test loss item: 0.16699953377246857
test loss item: 0.20187635719776154
test loss item: 0.27578145265579224
test loss item: 0.3084455728530884
test loss item: 0.25128501653671265
test loss item: 0.1677224487066269
test loss item: 0.3451710641384125
test loss item: 0.3445272445678711
test loss item: 0.16494855284690857
test loss item: 0.7660565376281738
test loss item: 0.6412145495414734
test loss item: 0.13417299091815948
test loss item: 0.16471776366233826
Epoch [9/50], Training Loss: 0.2872, Testing Loss: 0.2953
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/50
train loss item: 0.28392836451530457
train loss item: 0.209515780210495
train loss item: 0.19540072977542877
train loss item: 0.23469007015228271
train loss item: 0.16688749194145203
train loss item: 0.2732012867927551
train loss item: 0.2021365612745285
train loss item: 0.35319235920906067
train loss item: 0.3911067247390747
train loss item: 0.21470654010772705
train loss item: 0.15046168863773346
train loss item: 0.2067679464817047
train loss item: 0.2693334221839905
train loss item: 0.2631031274795532
train loss item: 0.14134299755096436
train loss item: 0.2913076877593994
train loss item: 0.2116931825876236
train loss item: 0.20072545111179352
train loss item: 0.16184565424919128
train loss item: 0.3039773106575012
train loss item: 0.20623347163200378
train loss item: 0.6457330584526062
train loss item: 0.23005300760269165
test loss item: 0.16960111260414124
test loss item: 0.38934972882270813
test loss item: 0.24446910619735718
test loss item: 0.12984755635261536
test loss item: 0.23816046118736267
test loss item: 0.2001281976699829
test loss item: 0.14955294132232666
test loss item: 0.2680019736289978
test loss item: 0.2271704375743866
test loss item: 0.3401469886302948
test loss item: 0.16321809589862823
test loss item: 0.20453977584838867
test loss item: 0.22165893018245697
test loss item: 0.20569393038749695
test loss item: 0.2201698273420334
test loss item: 0.16511590778827667
test loss item: 0.2610361576080322
test loss item: 0.316177099943161
test loss item: 0.17664416134357452
test loss item: 0.3924379050731659
test loss item: 0.42043545842170715
test loss item: 0.1349729597568512
test loss item: 0.13761888444423676
Epoch [10/50], Training Loss: 0.2525, Testing Loss: 0.2337
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 11/50
train loss item: 0.2794940769672394
train loss item: 0.20490358769893646
train loss item: 0.18073347210884094
train loss item: 0.23252950608730316
train loss item: 0.16048641502857208
train loss item: 0.30959585309028625
train loss item: 0.1964738965034485
train loss item: 0.43584364652633667
train loss item: 0.3709879517555237
train loss item: 0.25698190927505493
train loss item: 0.1927582174539566
train loss item: 0.2646137475967407
train loss item: 0.34336963295936584
train loss item: 0.26842188835144043
train loss item: 0.13633090257644653
train loss item: 0.28319212794303894
train loss item: 0.2064317762851715
train loss item: 0.1857105791568756
train loss item: 0.15783129632472992
train loss item: 0.3167109489440918
train loss item: 0.19554030895233154
train loss item: 0.6760261058807373
train loss item: 0.22162482142448425
test loss item: 0.21667590737342834
test loss item: 0.3951656222343445
test loss item: 0.3193220794200897
test loss item: 0.12084192782640457
test loss item: 0.22079524397850037
test loss item: 0.1949419379234314
test loss item: 0.14024412631988525
test loss item: 0.3266511857509613
test loss item: 0.24794209003448486
test loss item: 0.460054874420166
test loss item: 0.15475499629974365
test loss item: 0.17783740162849426
test loss item: 0.24703949689865112
test loss item: 0.2895169258117676
test loss item: 0.23843005299568176
test loss item: 0.15742237865924835
test loss item: 0.33453667163848877
test loss item: 0.3239232003688812
test loss item: 0.15083347260951996
test loss item: 0.7560244798660278
test loss item: 0.5947263240814209
test loss item: 0.1269899159669876
test loss item: 0.13662080466747284
Epoch [11/50], Training Loss: 0.2642, Testing Loss: 0.2753
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 12/50
train loss item: 0.2918879985809326
train loss item: 0.20314598083496094
train loss item: 0.18138986825942993
train loss item: 0.2131638079881668
train loss item: 0.155845507979393
train loss item: 0.23546777665615082
train loss item: 0.19875559210777283
train loss item: 0.34830671548843384
train loss item: 0.3297506272792816
train loss item: 0.1988348364830017
train loss item: 0.13483168184757233
train loss item: 0.19188983738422394
train loss item: 0.23356452584266663
train loss item: 0.23553355038166046
train loss item: 0.13450343906879425
train loss item: 0.2741210162639618
train loss item: 0.22610069811344147
train loss item: 0.19535845518112183
train loss item: 0.14468182623386383
train loss item: 0.2943119406700134
train loss item: 0.20946386456489563
train loss item: 0.6401925086975098
train loss item: 0.1988634467124939
test loss item: 0.2101443111896515
test loss item: 0.32210591435432434
test loss item: 0.3705613315105438
test loss item: 0.11603040248155594
test loss item: 0.2276584953069687
test loss item: 0.17670942842960358
test loss item: 0.14300307631492615
test loss item: 0.34486129879951477
test loss item: 0.2677936553955078
test loss item: 0.48428526520729065
test loss item: 0.14664994180202484
test loss item: 0.18121762573719025
test loss item: 0.2776404917240143
test loss item: 0.3224368393421173
test loss item: 0.24284249544143677
test loss item: 0.14987151324748993
test loss item: 0.3267964720726013
test loss item: 0.3015449345111847
test loss item: 0.13809144496917725
test loss item: 0.7658228874206543
test loss item: 0.6264911890029907
test loss item: 0.12205298990011215
test loss item: 0.14166942238807678
Epoch [12/50], Training Loss: 0.2378, Testing Loss: 0.2785
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 13/50
train loss item: 0.2424364686012268
train loss item: 0.17966532707214355
train loss item: 0.16811636090278625
train loss item: 0.20307224988937378
train loss item: 0.1462049037218094
train loss item: 0.3301621973514557
train loss item: 0.1785586029291153
train loss item: 0.30855077505111694
train loss item: 0.3061741590499878
train loss item: 0.22351349890232086
train loss item: 0.14464008808135986
train loss item: 0.2525513768196106
train loss item: 0.21931993961334229
train loss item: 0.3099389970302582
train loss item: 0.1262792944908142
train loss item: 0.2721835672855377
train loss item: 0.2351921796798706
train loss item: 0.23688586056232452
train loss item: 0.17282603681087494
train loss item: 0.319706529378891
train loss item: 0.21317479014396667
train loss item: 0.5189911127090454
train loss item: 0.21421681344509125
test loss item: 0.1601315140724182
test loss item: 0.28342223167419434
test loss item: 0.2383066713809967
test loss item: 0.11281216889619827
test loss item: 0.2247876226902008
test loss item: 0.16915223002433777
test loss item: 0.13699881732463837
test loss item: 0.23032481968402863
test loss item: 0.24120265245437622
test loss item: 0.3042825758457184
test loss item: 0.14495429396629333
test loss item: 0.17866484820842743
test loss item: 0.22069256007671356
test loss item: 0.22009170055389404
test loss item: 0.21563969552516937
test loss item: 0.13694792985916138
test loss item: 0.2366376370191574
test loss item: 0.276886522769928
test loss item: 0.13242939114570618
test loss item: 0.2955596148967743
test loss item: 0.3735399544239044
test loss item: 0.11471997946500778
test loss item: 0.13629578053951263
Epoch [13/50], Training Loss: 0.2401, Testing Loss: 0.2080
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 14/50
train loss item: 0.26680800318717957
train loss item: 0.20008118450641632
train loss item: 0.17676971852779388
train loss item: 0.22536203265190125
train loss item: 0.1596231758594513
train loss item: 0.40789416432380676
train loss item: 0.19853253662586212
train loss item: 0.5949454307556152
train loss item: 0.4015979468822479
train loss item: 0.191998690366745
train loss item: 0.16166791319847107
train loss item: 0.209014892578125
train loss item: 0.32549425959587097
train loss item: 0.33222678303718567
train loss item: 0.14557477831840515
train loss item: 0.2881243824958801
train loss item: 0.19955666363239288
train loss item: 0.16673146188259125
train loss item: 0.1351034939289093
train loss item: 0.26463583111763
train loss item: 0.1899857521057129
train loss item: 0.6176031827926636
train loss item: 0.19916678965091705
test loss item: 0.1796843260526657
test loss item: 0.30139821767807007
test loss item: 0.28476062417030334
test loss item: 0.10655046254396439
test loss item: 0.21571114659309387
test loss item: 0.18129470944404602
test loss item: 0.13907988369464874
test loss item: 0.25807610154151917
test loss item: 0.24951747059822083
test loss item: 0.35717764496803284
test loss item: 0.1562759131193161
test loss item: 0.1796618103981018
test loss item: 0.23809675872325897
test loss item: 0.25124847888946533
test loss item: 0.21973517537117004
test loss item: 0.14346225559711456
test loss item: 0.2452402412891388
test loss item: 0.27293989062309265
test loss item: 0.14870381355285645
test loss item: 0.4265054762363434
test loss item: 0.4491974711418152
test loss item: 0.12200651317834854
test loss item: 0.12206996232271194
Epoch [14/50], Training Loss: 0.2634, Testing Loss: 0.2282
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 15/50
train loss item: 0.228946715593338
train loss item: 0.1675272434949875
train loss item: 0.1498720645904541
train loss item: 0.17613311111927032
train loss item: 0.13397552073001862
train loss item: 0.21856537461280823
train loss item: 0.13957946002483368
train loss item: 0.33557847142219543
train loss item: 0.2637956440448761
train loss item: 0.19079814851284027
train loss item: 0.12978248298168182
train loss item: 0.20682895183563232
train loss item: 0.22771188616752625
train loss item: 0.21472673118114471
train loss item: 0.12125647813081741
train loss item: 0.25562208890914917
train loss item: 0.1670817881822586
train loss item: 0.16048449277877808
train loss item: 0.13241486251354218
train loss item: 0.23405969142913818
train loss item: 0.14425140619277954
train loss item: 0.4909502863883972
train loss item: 0.18450158834457397
test loss item: 0.16124969720840454
test loss item: 0.2994196116924286
test loss item: 0.22193001210689545
test loss item: 0.11109351366758347
test loss item: 0.21225932240486145
test loss item: 0.164017453789711
test loss item: 0.12859538197517395
test loss item: 0.22357052564620972
test loss item: 0.21217475831508636
test loss item: 0.3001304566860199
test loss item: 0.13457873463630676
test loss item: 0.1727321296930313
test loss item: 0.2037145346403122
test loss item: 0.210099458694458
test loss item: 0.20159423351287842
test loss item: 0.13607807457447052
test loss item: 0.24035987257957458
test loss item: 0.27408090233802795
test loss item: 0.1293306201696396
test loss item: 0.335923433303833
test loss item: 0.36559703946113586
test loss item: 0.11686617136001587
test loss item: 0.12316663563251495
Epoch [15/50], Training Loss: 0.2032, Testing Loss: 0.2034
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 16/50
train loss item: 0.3294840455055237
train loss item: 0.211842879652977
train loss item: 0.155979186296463
train loss item: 0.198166161775589
train loss item: 0.14407074451446533
train loss item: 0.35713547468185425
train loss item: 0.196752667427063
train loss item: 0.5281106233596802
train loss item: 0.42944610118865967
train loss item: 0.1845114529132843
train loss item: 0.137818843126297
train loss item: 0.1790495067834854
train loss item: 0.2660939693450928
train loss item: 0.22506950795650482
train loss item: 0.14980274438858032
train loss item: 0.25183576345443726
train loss item: 0.213689923286438
train loss item: 0.18492983281612396
train loss item: 0.1339482069015503
train loss item: 0.25151726603507996
train loss item: 0.13956229388713837
train loss item: 0.5547567009925842
train loss item: 0.19193507730960846
test loss item: 0.19331687688827515
test loss item: 0.42068493366241455
test loss item: 0.32673466205596924
test loss item: 0.11936081200838089
test loss item: 0.2717597484588623
test loss item: 0.18471305072307587
test loss item: 0.14357441663742065
test loss item: 0.32588014006614685
test loss item: 0.2751631438732147
test loss item: 0.44881439208984375
test loss item: 0.1466091424226761
test loss item: 0.19931411743164062
test loss item: 0.2766345739364624
test loss item: 0.2859109044075012
test loss item: 0.26642146706581116
test loss item: 0.15261481702327728
test loss item: 0.3222789466381073
test loss item: 0.3719116151332855
test loss item: 0.1453997641801834
test loss item: 0.6204159259796143
test loss item: 0.5715383887290955
test loss item: 0.12373613566160202
test loss item: 0.1384059488773346
Epoch [16/50], Training Loss: 0.2442, Testing Loss: 0.2753
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 17/50
train loss item: 0.27539995312690735
train loss item: 0.18077456951141357
train loss item: 0.18190507590770721
train loss item: 0.17053668200969696
train loss item: 0.12692496180534363
train loss item: 0.22567088901996613
train loss item: 0.17255879938602448
train loss item: 0.37066149711608887
train loss item: 0.24345017969608307
train loss item: 0.16179810464382172
train loss item: 0.1267302930355072
train loss item: 0.19900421798229218
train loss item: 0.2250491976737976
train loss item: 0.20043319463729858
train loss item: 0.11900115013122559
train loss item: 0.24356688559055328
train loss item: 0.15602724254131317
train loss item: 0.16292399168014526
train loss item: 0.1247214525938034
train loss item: 0.272529661655426
train loss item: 0.18384087085723877
train loss item: 0.46130335330963135
train loss item: 0.18393369019031525
test loss item: 0.16081087291240692
test loss item: 0.31900957226753235
test loss item: 0.21046869456768036
test loss item: 0.11580783128738403
test loss item: 0.23014183342456818
test loss item: 0.16679568588733673
test loss item: 0.12656879425048828
test loss item: 0.2197098731994629
test loss item: 0.2127983719110489
test loss item: 0.2987281084060669
test loss item: 0.13221056759357452
test loss item: 0.1855752319097519
test loss item: 0.20967762172222137
test loss item: 0.19426329433918
test loss item: 0.21439382433891296
test loss item: 0.14525870978832245
test loss item: 0.24387580156326294
test loss item: 0.29156768321990967
test loss item: 0.13542963564395905
test loss item: 0.29060932993888855
test loss item: 0.35016751289367676
test loss item: 0.11437075585126877
test loss item: 0.14595510065555573
Epoch [17/50], Training Loss: 0.2073, Testing Loss: 0.2050
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 18/50
train loss item: 0.29626163840293884
train loss item: 0.22338180243968964
train loss item: 0.20735269784927368
train loss item: 0.25005561113357544
train loss item: 0.15922711789608002
train loss item: 0.3071649670600891
train loss item: 0.18213628232479095
train loss item: 0.5125168561935425
train loss item: 0.3134649097919464
train loss item: 0.1735188066959381
train loss item: 0.1253887116909027
train loss item: 0.16596175730228424
train loss item: 0.24805885553359985
train loss item: 0.2162068486213684
train loss item: 0.12015294283628464
train loss item: 0.24113337695598602
train loss item: 0.19948618113994598
train loss item: 0.18785406649112701
train loss item: 0.1287885159254074
train loss item: 0.23924410343170166
train loss item: 0.15299351513385773
train loss item: 0.5375816822052002
train loss item: 0.16012544929981232
test loss item: 0.1628638654947281
test loss item: 0.23263581097126007
test loss item: 0.25347089767456055
test loss item: 0.10029809176921844
test loss item: 0.17313732206821442
test loss item: 0.14999300241470337
test loss item: 0.12205490469932556
test loss item: 0.237369105219841
test loss item: 0.20064838230609894
test loss item: 0.31710749864578247
test loss item: 0.13091380894184113
test loss item: 0.15330538153648376
test loss item: 0.20507968962192535
test loss item: 0.22692139446735382
test loss item: 0.17767518758773804
test loss item: 0.12729519605636597
test loss item: 0.22852103412151337
test loss item: 0.21955224871635437
test loss item: 0.119967982172966
test loss item: 0.46206915378570557
test loss item: 0.4031878113746643
test loss item: 0.10366378724575043
test loss item: 0.13658976554870605
Epoch [18/50], Training Loss: 0.2325, Testing Loss: 0.2019
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 19/50
train loss item: 0.21972796320915222
train loss item: 0.16957305371761322
train loss item: 0.14151456952095032
train loss item: 0.17423762381076813
train loss item: 0.13289126753807068
train loss item: 0.21843111515045166
train loss item: 0.13579939305782318
train loss item: 0.3474935293197632
train loss item: 0.23699678480625153
train loss item: 0.15113380551338196
train loss item: 0.11902102082967758
train loss item: 0.20779629051685333
train loss item: 0.26744601130485535
train loss item: 0.226492777466774
train loss item: 0.12643872201442719
train loss item: 0.28856196999549866
train loss item: 0.1721901148557663
train loss item: 0.16642650961875916
train loss item: 0.13053841888904572
train loss item: 0.22157888114452362
train loss item: 0.1657019555568695
train loss item: 0.4273030161857605
train loss item: 0.20265942811965942
test loss item: 0.17762506008148193
test loss item: 0.2440488040447235
test loss item: 0.22039107978343964
test loss item: 0.11623474955558777
test loss item: 0.17953601479530334
test loss item: 0.15724314749240875
test loss item: 0.12369533628225327
test loss item: 0.21079221367835999
test loss item: 0.19390423595905304
test loss item: 0.29341304302215576
test loss item: 0.13225041329860687
test loss item: 0.16237659752368927
test loss item: 0.19492167234420776
test loss item: 0.2072065770626068
test loss item: 0.17959614098072052
test loss item: 0.1368192881345749
test loss item: 0.2419702708721161
test loss item: 0.22931832075119019
test loss item: 0.12124716490507126
test loss item: 0.3929871618747711
test loss item: 0.3600448668003082
test loss item: 0.11227938532829285
test loss item: 0.14409080147743225
Epoch [19/50], Training Loss: 0.2022, Testing Loss: 0.1970
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 20/50
train loss item: 0.3295484483242035
train loss item: 0.2694641053676605
train loss item: 0.14446505904197693
train loss item: 0.20536331832408905
train loss item: 0.1368778795003891
train loss item: 0.3625454902648926
train loss item: 0.17700538039207458
train loss item: 0.4999319314956665
train loss item: 0.3274655342102051
train loss item: 0.18332551419734955
train loss item: 0.11752448230981827
train loss item: 0.1534779965877533
train loss item: 0.19486628472805023
train loss item: 0.1957320123910904
train loss item: 0.11709509044885635
train loss item: 0.23310010135173798
train loss item: 0.19370603561401367
train loss item: 0.18546414375305176
train loss item: 0.13286824524402618
train loss item: 0.22768720984458923
train loss item: 0.1573605239391327
train loss item: 0.4661594331264496
train loss item: 0.1738075613975525
test loss item: 0.13783618807792664
test loss item: 0.2978697419166565
test loss item: 0.19433185458183289
test loss item: 0.09578177332878113
test loss item: 0.1780974119901657
test loss item: 0.14693129062652588
test loss item: 0.11245591193437576
test loss item: 0.2038741558790207
test loss item: 0.1763007491827011
test loss item: 0.2594720125198364
test loss item: 0.12763139605522156
test loss item: 0.14637437462806702
test loss item: 0.17592525482177734
test loss item: 0.16946786642074585
test loss item: 0.1665460765361786
test loss item: 0.12100983411073685
test loss item: 0.19940724968910217
test loss item: 0.24678778648376465
test loss item: 0.11981262266635895
test loss item: 0.29765594005584717
test loss item: 0.32816657423973083
test loss item: 0.10056187957525253
test loss item: 0.14266635477542877
Epoch [20/50], Training Loss: 0.2254, Testing Loss: 0.1802
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 21/50
train loss item: 0.21192950010299683
train loss item: 0.1513659805059433
train loss item: 0.15720757842063904
train loss item: 0.17552879452705383
train loss item: 0.12109140306711197
train loss item: 0.19437909126281738
train loss item: 0.14551374316215515
train loss item: 0.2984374761581421
train loss item: 0.22903266549110413
train loss item: 0.15088631212711334
train loss item: 0.11160120368003845
train loss item: 0.1719515472650528
train loss item: 0.19196651875972748
train loss item: 0.16469374299049377
train loss item: 0.11089547723531723
train loss item: 0.22682934999465942
train loss item: 0.13952848315238953
train loss item: 0.15129080414772034
train loss item: 0.11152403056621552
train loss item: 0.22354988753795624
train loss item: 0.15596020221710205
train loss item: 0.41304588317871094
train loss item: 0.17336955666542053
test loss item: 0.14453130960464478
test loss item: 0.26629960536956787
test loss item: 0.17918217182159424
test loss item: 0.1055186465382576
test loss item: 0.169289693236351
test loss item: 0.14344587922096252
test loss item: 0.10987021774053574
test loss item: 0.18158407509326935
test loss item: 0.16385018825531006
test loss item: 0.24197493493556976
test loss item: 0.12508796155452728
test loss item: 0.14698705077171326
test loss item: 0.1685885637998581
test loss item: 0.16347292065620422
test loss item: 0.1614900529384613
test loss item: 0.13154713809490204
test loss item: 0.20582729578018188
test loss item: 0.22776363790035248
test loss item: 0.11936765164136887
test loss item: 0.25745129585266113
test loss item: 0.28787288069725037
test loss item: 0.09717462211847305
test loss item: 0.13131681084632874
Epoch [21/50], Training Loss: 0.1818, Testing Loss: 0.1708
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 22/50
train loss item: 0.2462712973356247
train loss item: 0.17773354053497314
train loss item: 0.13596728444099426
train loss item: 0.18207339942455292
train loss item: 0.12048690766096115
train loss item: 0.26018092036247253
train loss item: 0.15616431832313538
train loss item: 0.30202221870422363
train loss item: 0.22907467186450958
train loss item: 0.15547329187393188
train loss item: 0.10893195867538452
train loss item: 0.15909703075885773
train loss item: 0.19934295117855072
train loss item: 0.18744276463985443
train loss item: 0.1119542196393013
train loss item: 0.2072267085313797
train loss item: 0.15942680835723877
train loss item: 0.15146490931510925
train loss item: 0.10530838370323181
train loss item: 0.20989342033863068
train loss item: 0.1357443630695343
train loss item: 0.47588562965393066
train loss item: 0.15204840898513794
test loss item: 0.13389527797698975
test loss item: 0.26693472266197205
test loss item: 0.1862534135580063
test loss item: 0.09247994422912598
test loss item: 0.16416361927986145
test loss item: 0.14189434051513672
test loss item: 0.10690594464540482
test loss item: 0.19203388690948486
test loss item: 0.160174161195755
test loss item: 0.25104203820228577
test loss item: 0.11894483864307404
test loss item: 0.14579182863235474
test loss item: 0.16288861632347107
test loss item: 0.16107065975666046
test loss item: 0.15330401062965393
test loss item: 0.11647063493728638
test loss item: 0.20093275606632233
test loss item: 0.2280862033367157
test loss item: 0.12225428223609924
test loss item: 0.3467080593109131
test loss item: 0.3175504505634308
test loss item: 0.09391604363918304
test loss item: 0.1207805797457695
Epoch [22/50], Training Loss: 0.1882, Testing Loss: 0.1732
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 23/50
train loss item: 0.18727868795394897
train loss item: 0.14515942335128784
train loss item: 0.15408724546432495
train loss item: 0.16890351474285126
train loss item: 0.13844239711761475
train loss item: 0.2025238275527954
train loss item: 0.12646186351776123
train loss item: 0.33273008465766907
train loss item: 0.21279336512088776
train loss item: 0.15577343106269836
train loss item: 0.11598751693964005
train loss item: 0.22659385204315186
train loss item: 0.26916444301605225
train loss item: 0.26829227805137634
train loss item: 0.12845660746097565
train loss item: 0.29792389273643494
train loss item: 0.13997891545295715
train loss item: 0.14334774017333984
train loss item: 0.11367404460906982
train loss item: 0.23514911532402039
train loss item: 0.17571015655994415
train loss item: 0.39432448148727417
train loss item: 0.17773400247097015
test loss item: 0.16043075919151306
test loss item: 0.25868090987205505
test loss item: 0.20305804908275604
test loss item: 0.11035558581352234
test loss item: 0.1614675372838974
test loss item: 0.14298607409000397
test loss item: 0.11137280613183975
test loss item: 0.19215019047260284
test loss item: 0.17045855522155762
test loss item: 0.2637118101119995
test loss item: 0.12981051206588745
test loss item: 0.14180725812911987
test loss item: 0.18034911155700684
test loss item: 0.18108604848384857
test loss item: 0.16481894254684448
test loss item: 0.13548831641674042
test loss item: 0.21551308035850525
test loss item: 0.21686820685863495
test loss item: 0.11482866108417511
test loss item: 0.31927192211151123
test loss item: 0.3263518214225769
test loss item: 0.1026197150349617
test loss item: 0.13363438844680786
Epoch [23/50], Training Loss: 0.1961, Testing Loss: 0.1799
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 24/50
train loss item: 0.35224348306655884
train loss item: 0.2622198164463043
train loss item: 0.13739053905010223
train loss item: 0.1755034476518631
train loss item: 0.12023749202489853
train loss item: 0.2948262095451355
train loss item: 0.15277978777885437
train loss item: 0.41142889857292175
train loss item: 0.3448958694934845
train loss item: 0.1676167994737625
train loss item: 0.10748112201690674
train loss item: 0.15611201524734497
train loss item: 0.1909448802471161
train loss item: 0.19737403094768524
train loss item: 0.11864422261714935
train loss item: 0.2167723923921585
train loss item: 0.17842189967632294
train loss item: 0.16719357669353485
train loss item: 0.11258739978075027
train loss item: 0.20982274413108826
train loss item: 0.1488095223903656
train loss item: 0.45374685525894165
train loss item: 0.15616385638713837
test loss item: 0.1326574832201004
test loss item: 0.29585880041122437
test loss item: 0.1868574619293213
test loss item: 0.09101874381303787
test loss item: 0.16116468608379364
test loss item: 0.14138785004615784
test loss item: 0.10420972853899002
test loss item: 0.19790677726268768
test loss item: 0.1628539264202118
test loss item: 0.25862810015678406
test loss item: 0.1194063201546669
test loss item: 0.13763253390789032
test loss item: 0.15966437757015228
test loss item: 0.1601017415523529
test loss item: 0.1544390320777893
test loss item: 0.11420323699712753
test loss item: 0.20675700902938843
test loss item: 0.24030376970767975
test loss item: 0.11899895966053009
test loss item: 0.3770269751548767
test loss item: 0.3388630747795105
test loss item: 0.09429201483726501
test loss item: 0.12774255871772766
Epoch [24/50], Training Loss: 0.2101, Testing Loss: 0.1775
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 25/50
train loss item: 0.19063913822174072
train loss item: 0.14384697377681732
train loss item: 0.14800021052360535
train loss item: 0.15716025233268738
train loss item: 0.12387420982122421
train loss item: 0.16202756762504578
train loss item: 0.12265879660844803
train loss item: 0.30364716053009033
train loss item: 0.21827886998653412
train loss item: 0.145822674036026
train loss item: 0.10381804406642914
train loss item: 0.1751747876405716
train loss item: 0.22944797575473785
train loss item: 0.16986499726772308
train loss item: 0.1214500293135643
train loss item: 0.24146583676338196
train loss item: 0.1446681022644043
train loss item: 0.1365506947040558
train loss item: 0.10129716247320175
train loss item: 0.20694807171821594
train loss item: 0.14663732051849365
train loss item: 0.3845704197883606
train loss item: 0.18313871324062347
test loss item: 0.14729353785514832
test loss item: 0.35016530752182007
test loss item: 0.19317099452018738
test loss item: 0.10314518958330154
test loss item: 0.18006758391857147
test loss item: 0.14783096313476562
test loss item: 0.10801151394844055
test loss item: 0.21600349247455597
test loss item: 0.1624174863100052
test loss item: 0.2721686363220215
test loss item: 0.12610511481761932
test loss item: 0.15221138298511505
test loss item: 0.18178722262382507
test loss item: 0.1742190271615982
test loss item: 0.16985850036144257
test loss item: 0.13537396490573883
test loss item: 0.2221045196056366
test loss item: 0.26616862416267395
test loss item: 0.12974491715431213
test loss item: 0.29605093598365784
test loss item: 0.34517231583595276
test loss item: 0.09560190141201019
test loss item: 0.1262759119272232
Epoch [25/50], Training Loss: 0.1766, Testing Loss: 0.1870
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 26/50
train loss item: 0.3210497498512268
train loss item: 0.22890761494636536
train loss item: 0.14133521914482117
train loss item: 0.1639239639043808
train loss item: 0.1109471470117569
train loss item: 0.23931726813316345
train loss item: 0.13972455263137817
train loss item: 0.29048654437065125
train loss item: 0.19851459562778473
train loss item: 0.14661569893360138
train loss item: 0.10520016402006149
train loss item: 0.14729398488998413
train loss item: 0.1871853768825531
train loss item: 0.16252799332141876
train loss item: 0.10645906627178192
train loss item: 0.19712276756763458
train loss item: 0.15490393340587616
train loss item: 0.13941043615341187
train loss item: 0.0996871069073677
train loss item: 0.20237860083580017
train loss item: 0.1297122836112976
train loss item: 0.4359680414199829
train loss item: 0.1419679969549179
test loss item: 0.12290987372398376
test loss item: 0.252189040184021
test loss item: 0.15999479591846466
test loss item: 0.08763483166694641
test loss item: 0.15226519107818604
test loss item: 0.1342976689338684
test loss item: 0.09887459874153137
test loss item: 0.1669754832983017
test loss item: 0.15227362513542175
test loss item: 0.21743695437908173
test loss item: 0.11539997905492783
test loss item: 0.13278943300247192
test loss item: 0.14758916199207306
test loss item: 0.14167827367782593
test loss item: 0.14444833993911743
test loss item: 0.11053770780563354
test loss item: 0.17499364912509918
test loss item: 0.21071216464042664
test loss item: 0.1118679791688919
test loss item: 0.2658942937850952
test loss item: 0.26432809233665466
test loss item: 0.08886934071779251
test loss item: 0.11114319413900375
Epoch [26/50], Training Loss: 0.1822, Testing Loss: 0.1550
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 27/50
train loss item: 0.17717178165912628
train loss item: 0.13770513236522675
train loss item: 0.16518571972846985
train loss item: 0.18624773621559143
train loss item: 0.14934976398944855
train loss item: 0.18440678715705872
train loss item: 0.12099681049585342
train loss item: 0.3174932301044464
train loss item: 0.21132424473762512
train loss item: 0.14384518563747406
train loss item: 0.10777841508388519
train loss item: 0.2082621306180954
train loss item: 0.3151760697364807
train loss item: 0.23811431229114532
train loss item: 0.13426262140274048
train loss item: 0.2951938211917877
train loss item: 0.17311182618141174
train loss item: 0.14018985629081726
train loss item: 0.0974762812256813
train loss item: 0.25033435225486755
train loss item: 0.14860320091247559
train loss item: 0.3664822280406952
train loss item: 0.17616590857505798
test loss item: 0.13675999641418457
test loss item: 0.41106221079826355
test loss item: 0.18444333970546722
test loss item: 0.10039430856704712
test loss item: 0.1936027854681015
test loss item: 0.15532980859279633
test loss item: 0.10733946412801743
test loss item: 0.23187488317489624
test loss item: 0.16497360169887543
test loss item: 0.273039847612381
test loss item: 0.12808114290237427
test loss item: 0.14548663794994354
test loss item: 0.18601439893245697
test loss item: 0.15865744650363922
test loss item: 0.17682170867919922
test loss item: 0.13664862513542175
test loss item: 0.21592967212200165
test loss item: 0.3003859519958496
test loss item: 0.13384351134300232
test loss item: 0.23486296832561493
test loss item: 0.35019806027412415
test loss item: 0.09603886306285858
test loss item: 0.1687602996826172
Epoch [27/50], Training Loss: 0.1933, Testing Loss: 0.1909
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 28/50
train loss item: 0.38933104276657104
train loss item: 0.31992024183273315
train loss item: 0.22427202761173248
train loss item: 0.20650802552700043
train loss item: 0.14838242530822754
train loss item: 0.22650161385536194
train loss item: 0.1304706186056137
train loss item: 0.2582857310771942
train loss item: 0.19092778861522675
train loss item: 0.14375180006027222
train loss item: 0.10505401343107224
train loss item: 0.16164745390415192
train loss item: 0.2540617287158966
train loss item: 0.18286322057247162
train loss item: 0.119301937520504
train loss item: 0.2174416184425354
train loss item: 0.18561312556266785
train loss item: 0.1547159105539322
train loss item: 0.09856586903333664
train loss item: 0.21943534910678864
train loss item: 0.1424255669116974
train loss item: 0.4507836103439331
train loss item: 0.13428950309753418
test loss item: 0.1298304796218872
test loss item: 0.2685147225856781
test loss item: 0.17736224830150604
test loss item: 0.09042159467935562
test loss item: 0.15688550472259521
test loss item: 0.14056748151779175
test loss item: 0.10313095152378082
test loss item: 0.18530680239200592
test loss item: 0.16757123172283173
test loss item: 0.2362983524799347
test loss item: 0.12214082479476929
test loss item: 0.14129111170768738
test loss item: 0.15464329719543457
test loss item: 0.1537688970565796
test loss item: 0.14783376455307007
test loss item: 0.11175112426280975
test loss item: 0.188413605093956
test loss item: 0.21905013918876648
test loss item: 0.12017311155796051
test loss item: 0.3173576295375824
test loss item: 0.30364498496055603
test loss item: 0.09498005360364914
test loss item: 0.12249833345413208
Epoch [28/50], Training Loss: 0.2028, Testing Loss: 0.1675
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 29/50
train loss item: 0.17465823888778687
train loss item: 0.14106640219688416
train loss item: 0.16695930063724518
train loss item: 0.18772609531879425
train loss item: 0.14594897627830505
train loss item: 0.17873108386993408
train loss item: 0.1340448409318924
train loss item: 0.3159864842891693
train loss item: 0.20996956527233124
train loss item: 0.1351364403963089
train loss item: 0.09842332452535629
train loss item: 0.182668074965477
train loss item: 0.3185097277164459
train loss item: 0.2842142581939697
train loss item: 0.13032644987106323
train loss item: 0.38044238090515137
train loss item: 0.1823606938123703
train loss item: 0.1539534628391266
train loss item: 0.09825698286294937
train loss item: 0.37657687067985535
train loss item: 0.19828477501869202
train loss item: 0.3643452227115631
train loss item: 0.15358823537826538
test loss item: 0.1223040223121643
test loss item: 0.2179628610610962
test loss item: 0.16097678244113922
test loss item: 0.0940299779176712
test loss item: 0.13721449673175812
test loss item: 0.12848934531211853
test loss item: 0.09999502450227737
test loss item: 0.15847882628440857
test loss item: 0.14647246897220612
test loss item: 0.20047515630722046
test loss item: 0.11602971702814102
test loss item: 0.12393752485513687
test loss item: 0.148379847407341
test loss item: 0.14220641553401947
test loss item: 0.13650265336036682
test loss item: 0.11630523949861526
test loss item: 0.15880373120307922
test loss item: 0.1762693077325821
test loss item: 0.1058875024318695
test loss item: 0.20799605548381805
test loss item: 0.2359316498041153
test loss item: 0.0871155709028244
test loss item: 0.1173432245850563
Epoch [29/50], Training Loss: 0.2049, Testing Loss: 0.1452
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 30/50
train loss item: 0.27650967240333557
train loss item: 0.24410250782966614
train loss item: 0.20866133272647858
train loss item: 0.2127014398574829
train loss item: 0.20369724929332733
train loss item: 0.2470952570438385
train loss item: 0.17026446759700775
train loss item: 0.23733364045619965
train loss item: 0.21544747054576874
train loss item: 0.14764773845672607
train loss item: 0.10647398233413696
train loss item: 0.15070600807666779
train loss item: 0.30630338191986084
train loss item: 0.2078259140253067
train loss item: 0.1364072561264038
train loss item: 0.35936906933784485
train loss item: 0.2564890384674072
train loss item: 0.22101983428001404
train loss item: 0.13241423666477203
train loss item: 0.462569922208786
train loss item: 0.31974583864212036
train loss item: 0.47673529386520386
train loss item: 0.16394823789596558
test loss item: 0.13104566931724548
test loss item: 0.2398844212293625
test loss item: 0.17684999108314514
test loss item: 0.09328819066286087
test loss item: 0.1586875468492508
test loss item: 0.1534588783979416
test loss item: 0.1098596453666687
test loss item: 0.16631926596164703
test loss item: 0.16019479930400848
test loss item: 0.23617400228977203
test loss item: 0.12290113419294357
test loss item: 0.13936202228069305
test loss item: 0.16535145044326782
test loss item: 0.15853632986545563
test loss item: 0.1624840348958969
test loss item: 0.12447546422481537
test loss item: 0.1870727390050888
test loss item: 0.2010284662246704
test loss item: 0.11009517312049866
test loss item: 0.2953723669052124
test loss item: 0.27255433797836304
test loss item: 0.10161151736974716
test loss item: 0.11967595666646957
Epoch [30/50], Training Loss: 0.2375, Testing Loss: 0.1646
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 31/50
train loss item: 0.24370920658111572
train loss item: 0.1404763013124466
train loss item: 0.20142477750778198
train loss item: 0.18259316682815552
train loss item: 0.18442954123020172
train loss item: 0.2507009208202362
train loss item: 0.21056683361530304
train loss item: 0.37120741605758667
train loss item: 0.2520011067390442
train loss item: 0.21645787358283997
train loss item: 0.14300468564033508
train loss item: 0.18029487133026123
train loss item: 0.23892426490783691
train loss item: 0.17800301313400269
train loss item: 0.13681647181510925
train loss item: 0.3466019928455353
train loss item: 0.1936098337173462
train loss item: 0.16736705601215363
train loss item: 0.11531952768564224
train loss item: 0.49278244376182556
train loss item: 0.2977950870990753
train loss item: 0.46532124280929565
train loss item: 0.15840622782707214
test loss item: 0.13504907488822937
test loss item: 0.39869987964630127
test loss item: 0.19245240092277527
test loss item: 0.10713032633066177
test loss item: 0.2148693948984146
test loss item: 0.17721961438655853
test loss item: 0.12909328937530518
test loss item: 0.21742673218250275
test loss item: 0.17657141387462616
test loss item: 0.28354397416114807
test loss item: 0.14003866910934448
test loss item: 0.16699282824993134
test loss item: 0.19581259787082672
test loss item: 0.16259975731372833
test loss item: 0.20002925395965576
test loss item: 0.1412218064069748
test loss item: 0.24174319207668304
test loss item: 0.301765501499176
test loss item: 0.13670462369918823
test loss item: 0.2587931454181671
test loss item: 0.3525431454181671
test loss item: 0.11639726161956787
test loss item: 0.18998296558856964
Epoch [31/50], Training Loss: 0.2334, Testing Loss: 0.2016
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 32/50
train loss item: 0.25538328289985657
train loss item: 0.13793841004371643
train loss item: 0.15354211628437042
train loss item: 0.13163438439369202
train loss item: 0.15470021963119507
train loss item: 0.15472330152988434
train loss item: 0.1576431393623352
train loss item: 0.27615463733673096
train loss item: 0.23706939816474915
train loss item: 0.2475038468837738
train loss item: 0.1904383897781372
train loss item: 0.2270367443561554
train loss item: 0.18034279346466064
train loss item: 0.17133286595344543
train loss item: 0.12213712930679321
train loss item: 0.23973135650157928
train loss item: 0.13994406163692474
train loss item: 0.13438910245895386
train loss item: 0.10663668811321259
train loss item: 0.4108026325702667
train loss item: 0.24927593767642975
train loss item: 0.4565374255180359
train loss item: 0.13737937808036804
test loss item: 0.1331678330898285
test loss item: 0.3157668113708496
test loss item: 0.1960468739271164
test loss item: 0.10683279484510422
test loss item: 0.1858280450105667
test loss item: 0.16734763979911804
test loss item: 0.11944007873535156
test loss item: 0.19848237931728363
test loss item: 0.16659876704216003
test loss item: 0.25929102301597595
test loss item: 0.1379634588956833
test loss item: 0.16151267290115356
test loss item: 0.1854173243045807
test loss item: 0.16712450981140137
test loss item: 0.18629199266433716
test loss item: 0.1387404203414917
test loss item: 0.22262294590473175
test loss item: 0.24845300614833832
test loss item: 0.13248856365680695
test loss item: 0.27186906337738037
test loss item: 0.3164883852005005
test loss item: 0.11262401938438416
test loss item: 0.11811041831970215
Epoch [32/50], Training Loss: 0.2031, Testing Loss: 0.1847
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 33/50
train loss item: 0.2394869476556778
train loss item: 0.1391870677471161
train loss item: 0.13280414044857025
train loss item: 0.13765528798103333
train loss item: 0.12144387513399124
train loss item: 0.15177421271800995
train loss item: 0.13761208951473236
train loss item: 0.23690998554229736
train loss item: 0.19978280365467072
train loss item: 0.25432780385017395
train loss item: 0.15089400112628937
train loss item: 0.18910600244998932
train loss item: 0.1671217381954193
train loss item: 0.15274587273597717
train loss item: 0.11366903781890869
train loss item: 0.20200374722480774
train loss item: 0.13331542909145355
train loss item: 0.1307835578918457
train loss item: 0.09910612553358078
train loss item: 0.37847158312797546
train loss item: 0.23006364703178406
train loss item: 0.4330531358718872
train loss item: 0.1295488327741623
test loss item: 0.12055771052837372
test loss item: 0.3069410026073456
test loss item: 0.1710209995508194
test loss item: 0.09402292221784592
test loss item: 0.17202390730381012
test loss item: 0.14825980365276337
test loss item: 0.10682778060436249
test loss item: 0.18339264392852783
test loss item: 0.15610356628894806
test loss item: 0.23314258456230164
test loss item: 0.1230773851275444
test loss item: 0.13976122438907623
test loss item: 0.16666415333747864
test loss item: 0.14524021744728088
test loss item: 0.1719742715358734
test loss item: 0.12322323769330978
test loss item: 0.1947474181652069
test loss item: 0.23731529712677002
test loss item: 0.11869923770427704
test loss item: 0.2180681675672531
test loss item: 0.28167644143104553
test loss item: 0.09779740869998932
test loss item: 0.11751830577850342
Epoch [33/50], Training Loss: 0.1853, Testing Loss: 0.1664
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 34/50
train loss item: 0.20376364886760712
train loss item: 0.12532517313957214
train loss item: 0.11830712109804153
train loss item: 0.12127189338207245
train loss item: 0.11575163155794144
train loss item: 0.1441047042608261
train loss item: 0.12345671653747559
train loss item: 0.24116741120815277
train loss item: 0.1925824135541916
train loss item: 0.22946125268936157
train loss item: 0.13704071938991547
train loss item: 0.16934096813201904
train loss item: 0.16310930252075195
train loss item: 0.14487800002098083
train loss item: 0.10518139600753784
train loss item: 0.1887676864862442
train loss item: 0.12533362209796906
train loss item: 0.12945611774921417
train loss item: 0.09334671497344971
train loss item: 0.33753103017807007
train loss item: 0.20090529322624207
train loss item: 0.4173479974269867
train loss item: 0.12190799415111542
test loss item: 0.12003184854984283
test loss item: 0.28179818391799927
test loss item: 0.16487714648246765
test loss item: 0.09078771620988846
test loss item: 0.15635579824447632
test loss item: 0.13976620137691498
test loss item: 0.10319552570581436
test loss item: 0.1723804622888565
test loss item: 0.14631932973861694
test loss item: 0.22140571475028992
test loss item: 0.11756489425897598
test loss item: 0.13077059388160706
test loss item: 0.15623421967029572
test loss item: 0.14408855140209198
test loss item: 0.15896663069725037
test loss item: 0.11734294891357422
test loss item: 0.18476730585098267
test loss item: 0.21831853687763214
test loss item: 0.11255518347024918
test loss item: 0.22310347855091095
test loss item: 0.2653098404407501
test loss item: 0.09503217786550522
test loss item: 0.10587261617183685
Epoch [34/50], Training Loss: 0.1717, Testing Loss: 0.1577
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 35/50
train loss item: 0.1858985424041748
train loss item: 0.12423982471227646
train loss item: 0.11328166723251343
train loss item: 0.11910589784383774
train loss item: 0.10909666121006012
train loss item: 0.14044232666492462
train loss item: 0.1157105565071106
train loss item: 0.22005029022693634
train loss item: 0.17575672268867493
train loss item: 0.2068803608417511
train loss item: 0.11896830797195435
train loss item: 0.14599904417991638
train loss item: 0.16129018366336823
train loss item: 0.14593487977981567
train loss item: 0.10839046537876129
train loss item: 0.18596261739730835
train loss item: 0.13161471486091614
train loss item: 0.1369762420654297
train loss item: 0.09214328974485397
train loss item: 0.32025715708732605
train loss item: 0.1884596198797226
train loss item: 0.4117935299873352
train loss item: 0.11898630857467651
test loss item: 0.11714846640825272
test loss item: 0.2650096118450165
test loss item: 0.16311416029930115
test loss item: 0.08943656831979752
test loss item: 0.15078304708003998
test loss item: 0.13517224788665771
test loss item: 0.09986016154289246
test loss item: 0.1681528091430664
test loss item: 0.1465907245874405
test loss item: 0.2157050520181656
test loss item: 0.11200115084648132
test loss item: 0.12907268106937408
test loss item: 0.1537986546754837
test loss item: 0.14424936473369598
test loss item: 0.154135599732399
test loss item: 0.11367010325193405
test loss item: 0.17755013704299927
test loss item: 0.20852059125900269
test loss item: 0.10767573118209839
test loss item: 0.22246906161308289
test loss item: 0.25793346762657166
test loss item: 0.09073856472969055
test loss item: 0.1025250032544136
Epoch [35/50], Training Loss: 0.1642, Testing Loss: 0.1533
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 36/50
train loss item: 0.1768757551908493
train loss item: 0.12228000909090042
train loss item: 0.10960816591978073
train loss item: 0.11966024339199066
train loss item: 0.11115504056215286
train loss item: 0.14217102527618408
train loss item: 0.11600083112716675
train loss item: 0.21434082090854645
train loss item: 0.17099323868751526
train loss item: 0.18108750879764557
train loss item: 0.11159530282020569
train loss item: 0.13175877928733826
train loss item: 0.15619470179080963
train loss item: 0.14730584621429443
train loss item: 0.10701659321784973
train loss item: 0.1810501515865326
train loss item: 0.13010360300540924
train loss item: 0.13885876536369324
train loss item: 0.08996160328388214
train loss item: 0.2783581614494324
train loss item: 0.1731490194797516
train loss item: 0.40058067440986633
train loss item: 0.11536025255918503
test loss item: 0.11516353487968445
test loss item: 0.25326165556907654
test loss item: 0.15525498986244202
test loss item: 0.0867244079709053
test loss item: 0.14334312081336975
test loss item: 0.1319938600063324
test loss item: 0.09659253805875778
test loss item: 0.15940386056900024
test loss item: 0.1409282684326172
test loss item: 0.20559874176979065
test loss item: 0.1083439365029335
test loss item: 0.12604886293411255
test loss item: 0.14685165882110596
test loss item: 0.13806091248989105
test loss item: 0.1458147168159485
test loss item: 0.10936492681503296
test loss item: 0.16936250030994415
test loss item: 0.19928768277168274
test loss item: 0.10513313859701157
test loss item: 0.21466661989688873
test loss item: 0.24413913488388062
test loss item: 0.08754332363605499
test loss item: 0.10180532932281494
Epoch [36/50], Training Loss: 0.1576, Testing Loss: 0.1472
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 37/50
train loss item: 0.16877532005310059
train loss item: 0.1211877167224884
train loss item: 0.11076090484857559
train loss item: 0.12476480007171631
train loss item: 0.10738243907690048
train loss item: 0.13592074811458588
train loss item: 0.11818955838680267
train loss item: 0.21201327443122864
train loss item: 0.16898886859416962
train loss item: 0.16938599944114685
train loss item: 0.10736120492219925
train loss item: 0.1230270192027092
train loss item: 0.15440569818019867
train loss item: 0.14900889992713928
train loss item: 0.11191749572753906
train loss item: 0.18753935396671295
train loss item: 0.13836118578910828
train loss item: 0.14368057250976562
train loss item: 0.09071515500545502
train loss item: 0.27582964301109314
train loss item: 0.17444835603237152
train loss item: 0.39620861411094666
train loss item: 0.11333424597978592
test loss item: 0.11697108298540115
test loss item: 0.2532663345336914
test loss item: 0.1560957431793213
test loss item: 0.09018468111753464
test loss item: 0.14992381632328033
test loss item: 0.1358667016029358
test loss item: 0.09920477867126465
test loss item: 0.16229356825351715
test loss item: 0.14595653116703033
test loss item: 0.20791085064411163
test loss item: 0.11110146343708038
test loss item: 0.13486304879188538
test loss item: 0.15118612349033356
test loss item: 0.13783778250217438
test loss item: 0.14921195805072784
test loss item: 0.11365174502134323
test loss item: 0.17083463072776794
test loss item: 0.20230735838413239
test loss item: 0.11155422031879425
test loss item: 0.21338389813899994
test loss item: 0.24558426439762115
test loss item: 0.08904009312391281
test loss item: 0.10937601327896118
Epoch [37/50], Training Loss: 0.1567, Testing Loss: 0.1503
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 38/50
train loss item: 0.1633652150630951
train loss item: 0.11840679496526718
train loss item: 0.10348527133464813
train loss item: 0.12121948599815369
train loss item: 0.10428284853696823
train loss item: 0.13542746007442474
train loss item: 0.11830969154834747
train loss item: 0.22076675295829773
train loss item: 0.17040327191352844
train loss item: 0.16108010709285736
train loss item: 0.10629764944314957
train loss item: 0.11715885996818542
train loss item: 0.14536480605602264
train loss item: 0.14098724722862244
train loss item: 0.10570968687534332
train loss item: 0.18025143444538116
train loss item: 0.13029296696186066
train loss item: 0.13605964183807373
train loss item: 0.08688673377037048
train loss item: 0.2639369070529938
train loss item: 0.16633880138397217
train loss item: 0.40660470724105835
train loss item: 0.11134006083011627
test loss item: 0.11800157278776169
test loss item: 0.2574012577533722
test loss item: 0.15136566758155823
test loss item: 0.08836949616670609
test loss item: 0.14719903469085693
test loss item: 0.1365317404270172
test loss item: 0.09785318374633789
test loss item: 0.16020946204662323
test loss item: 0.14473365247249603
test loss item: 0.20498034358024597
test loss item: 0.10939992219209671
test loss item: 0.1338571459054947
test loss item: 0.148319274187088
test loss item: 0.13552948832511902
test loss item: 0.1438603401184082
test loss item: 0.11169388890266418
test loss item: 0.16744937002658844
test loss item: 0.20254182815551758
test loss item: 0.11177290230989456
test loss item: 0.21672168374061584
test loss item: 0.23946547508239746
test loss item: 0.08805369585752487
test loss item: 0.11341522634029388
Epoch [38/50], Training Loss: 0.1528, Testing Loss: 0.1491
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 39/50
train loss item: 0.17715832591056824
train loss item: 0.12162531167268753
train loss item: 0.10802573710680008
train loss item: 0.12227506935596466
train loss item: 0.11096474528312683
train loss item: 0.1502203643321991
train loss item: 0.12800432741641998
train loss item: 0.231953427195549
train loss item: 0.17092031240463257
train loss item: 0.167267307639122
train loss item: 0.11479494720697403
train loss item: 0.1255558729171753
train loss item: 0.15138868987560272
train loss item: 0.14615844190120697
train loss item: 0.10849747806787491
train loss item: 0.1789512038230896
train loss item: 0.1317748725414276
train loss item: 0.14362111687660217
train loss item: 0.08744855970144272
train loss item: 0.3094865083694458
train loss item: 0.18301613628864288
train loss item: 0.41642752289772034
train loss item: 0.11075811088085175
test loss item: 0.12470860779285431
test loss item: 0.2832712233066559
test loss item: 0.15961886942386627
test loss item: 0.09397554397583008
test loss item: 0.1627807468175888
test loss item: 0.1492571085691452
test loss item: 0.10605516284704208
test loss item: 0.1733013540506363
test loss item: 0.15183989703655243
test loss item: 0.2199982851743698
test loss item: 0.12034551799297333
test loss item: 0.15420331060886383
test loss item: 0.15879905223846436
test loss item: 0.1414991319179535
test loss item: 0.15568754076957703
test loss item: 0.12124835699796677
test loss item: 0.18240301311016083
test loss item: 0.22250628471374512
test loss item: 0.1277599185705185
test loss item: 0.2277570515871048
test loss item: 0.2598552703857422
test loss item: 0.09755939245223999
test loss item: 0.1220855861902237
Epoch [39/50], Training Loss: 0.1607, Testing Loss: 0.1616
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.20073096454143524
loss item: 0.21073661744594574
loss item: 0.19513392448425293
loss item: 0.17507204413414001
loss item: 0.2099861353635788
loss item: 0.13466887176036835
loss item: 0.20010708272457123
loss item: 0.2807435989379883
loss item: 0.1463194340467453
loss item: 0.18572157621383667
loss item: 0.2057596743106842
Val Loss: 0.1950
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.0001 8 360 done at Tue Nov 12 11:13:40 CET 2024
UNet2 with 1 50 0.0005 8 360 start at Tue Nov 12 11:13:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.4765785932540894
train loss item: 0.904321551322937
train loss item: 0.506412148475647
train loss item: 0.6584682464599609
train loss item: 0.4671843647956848
train loss item: 0.8639015555381775
train loss item: 0.43315255641937256
train loss item: 1.1930599212646484
train loss item: 1.2821385860443115
train loss item: 0.7095414996147156
train loss item: 0.9180285334587097
train loss item: 0.7061329483985901
train loss item: 0.5991091728210449
train loss item: 1.0077309608459473
train loss item: 0.429999977350235
train loss item: 0.9447888135910034
train loss item: 0.4559365510940552
train loss item: 0.4064919650554657
train loss item: 0.331018328666687
train loss item: 0.807661235332489
train loss item: 0.41120532155036926
train loss item: 1.6168450117111206
train loss item: 0.4986988306045532
test loss item: 0.5259818434715271
test loss item: 0.8812240958213806
test loss item: 0.7652322053909302
test loss item: 0.22267933189868927
test loss item: 0.5283342003822327
test loss item: 0.5128481388092041
test loss item: 0.3455928862094879
test loss item: 0.7488954067230225
test loss item: 0.6395062208175659
test loss item: 1.0549241304397583
test loss item: 0.3595289885997772
test loss item: 0.49711906909942627
test loss item: 0.6538893580436707
test loss item: 0.7323530316352844
test loss item: 0.4788155257701874
test loss item: 0.40056443214416504
test loss item: 0.7099559903144836
test loss item: 0.7090582847595215
test loss item: 0.3339361548423767
test loss item: 1.4124622344970703
test loss item: 1.240813970565796
test loss item: 0.2627544403076172
test loss item: 0.2596072852611542
Epoch [1/50], Training Loss: 0.7665, Testing Loss: 0.6207
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/50
train loss item: 0.646149218082428
train loss item: 0.43746787309646606
train loss item: 0.34368908405303955
train loss item: 0.43127045035362244
train loss item: 0.38523024320602417
train loss item: 0.5840773582458496
train loss item: 0.3757498562335968
train loss item: 0.9363458156585693
train loss item: 1.1803456544876099
train loss item: 0.4603957533836365
train loss item: 0.3437851071357727
train loss item: 0.39224717020988464
train loss item: 0.47737228870391846
train loss item: 0.7694383859634399
train loss item: 0.2511711120605469
train loss item: 0.7730098366737366
train loss item: 0.41317009925842285
train loss item: 0.31543684005737305
train loss item: 0.22735552489757538
train loss item: 0.6817494034767151
train loss item: 0.27873894572257996
train loss item: 1.3096625804901123
train loss item: 0.38925567269325256
test loss item: 0.3233293294906616
test loss item: 0.6724013686180115
test loss item: 0.4798464775085449
test loss item: 0.20409585535526276
test loss item: 0.40932393074035645
test loss item: 0.35491448640823364
test loss item: 0.26095739006996155
test loss item: 0.48254141211509705
test loss item: 0.5102272033691406
test loss item: 0.6587272882461548
test loss item: 0.2686009407043457
test loss item: 0.34191209077835083
test loss item: 0.43898606300354004
test loss item: 0.45015519857406616
test loss item: 0.41564303636550903
test loss item: 0.2971726059913635
test loss item: 0.44371727108955383
test loss item: 0.5497668385505676
test loss item: 0.2395653873682022
test loss item: 0.6804041266441345
test loss item: 0.7888192534446716
test loss item: 0.20539237558841705
test loss item: 0.2737824022769928
Epoch [2/50], Training Loss: 0.5393, Testing Loss: 0.4239
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/50
train loss item: 0.5702334046363831
train loss item: 0.47487086057662964
train loss item: 0.32472917437553406
train loss item: 0.32024380564689636
train loss item: 0.27235034108161926
train loss item: 0.4972633421421051
train loss item: 0.3153633773326874
train loss item: 0.7744437456130981
train loss item: 0.7985025644302368
train loss item: 0.34334683418273926
train loss item: 0.22557611763477325
train loss item: 0.26109716296195984
train loss item: 0.3857494592666626
train loss item: 0.6142398118972778
train loss item: 0.17273133993148804
train loss item: 0.5602481961250305
train loss item: 0.348443865776062
train loss item: 0.28703176975250244
train loss item: 0.23071928322315216
train loss item: 0.5566060543060303
train loss item: 0.24255461990833282
train loss item: 0.9719066023826599
train loss item: 0.2893982231616974
test loss item: 0.24595551192760468
test loss item: 0.4175114631652832
test loss item: 0.35275670886039734
test loss item: 0.138462096452713
test loss item: 0.29462167620658875
test loss item: 0.2717451751232147
test loss item: 0.20182305574417114
test loss item: 0.33898451924324036
test loss item: 0.3379646837711334
test loss item: 0.47094467282295227
test loss item: 0.21542342007160187
test loss item: 0.2665894031524658
test loss item: 0.3020532429218292
test loss item: 0.3278811275959015
test loss item: 0.27052125334739685
test loss item: 0.22377516329288483
test loss item: 0.3571309745311737
test loss item: 0.3484717905521393
test loss item: 0.19307176768779755
test loss item: 0.6104274988174438
test loss item: 0.5661630034446716
test loss item: 0.15907268226146698
test loss item: 0.1896510273218155
Epoch [3/50], Training Loss: 0.4277, Testing Loss: 0.3087
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/50
train loss item: 0.45562443137168884
train loss item: 0.34325286746025085
train loss item: 0.2426314800977707
train loss item: 0.30251944065093994
train loss item: 0.21644629538059235
train loss item: 0.36790886521339417
train loss item: 0.27396655082702637
train loss item: 0.46329668164253235
train loss item: 0.5496596693992615
train loss item: 0.5395334362983704
train loss item: 0.34572988748550415
train loss item: 0.31916847825050354
train loss item: 0.33370691537857056
train loss item: 0.634696364402771
train loss item: 0.21721574664115906
train loss item: 0.6400171518325806
train loss item: 0.251498281955719
train loss item: 0.24310185015201569
train loss item: 0.19374173879623413
train loss item: 0.47896608710289
train loss item: 0.2271011471748352
train loss item: 0.7794975638389587
train loss item: 0.3810238540172577
test loss item: 0.25956106185913086
test loss item: 0.4672168791294098
test loss item: 0.38382381200790405
test loss item: 0.14306063950061798
test loss item: 0.3136252760887146
test loss item: 0.26761990785598755
test loss item: 0.1824907660484314
test loss item: 0.37867939472198486
test loss item: 0.3529466986656189
test loss item: 0.5340526700019836
test loss item: 0.22433942556381226
test loss item: 0.25278693437576294
test loss item: 0.2946244180202484
test loss item: 0.35582098364830017
test loss item: 0.31025710701942444
test loss item: 0.19843709468841553
test loss item: 0.4273230731487274
test loss item: 0.4160490334033966
test loss item: 0.1942237913608551
test loss item: 0.7960453033447266
test loss item: 0.6904809474945068
test loss item: 0.16237911581993103
test loss item: 0.28418511152267456
Epoch [4/50], Training Loss: 0.3826, Testing Loss: 0.3430
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/50
train loss item: 0.4627298414707184
train loss item: 0.3363535404205322
train loss item: 0.2185729593038559
train loss item: 0.295855849981308
train loss item: 0.2240525335073471
train loss item: 0.4647134244441986
train loss item: 0.2707350552082062
train loss item: 0.5724075436592102
train loss item: 0.518492579460144
train loss item: 0.47081467509269714
train loss item: 0.3736874759197235
train loss item: 0.4487855136394501
train loss item: 0.4400726556777954
train loss item: 0.3375642001628876
train loss item: 0.17595160007476807
train loss item: 0.4535883069038391
train loss item: 0.2087043970823288
train loss item: 0.20798560976982117
train loss item: 0.15593762695789337
train loss item: 0.5299893021583557
train loss item: 0.23609915375709534
train loss item: 0.8019330501556396
train loss item: 0.2711491286754608
test loss item: 0.18252615630626678
test loss item: 0.46297597885131836
test loss item: 0.24526987969875336
test loss item: 0.1252317875623703
test loss item: 0.2680961489677429
test loss item: 0.22057005763053894
test loss item: 0.15055762231349945
test loss item: 0.28010109066963196
test loss item: 0.24049600958824158
test loss item: 0.3725349009037018
test loss item: 0.1762317419052124
test loss item: 0.20063196122646332
test loss item: 0.222720205783844
test loss item: 0.21716803312301636
test loss item: 0.24353894591331482
test loss item: 0.168294757604599
test loss item: 0.27396321296691895
test loss item: 0.3572766184806824
test loss item: 0.17331121861934662
test loss item: 0.3779497742652893
test loss item: 0.45298081636428833
test loss item: 0.13635887205600739
test loss item: 0.3105308413505554
Epoch [5/50], Training Loss: 0.3685, Testing Loss: 0.2548
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/50
train loss item: 0.3525557219982147
train loss item: 0.28993070125579834
train loss item: 0.21043084561824799
train loss item: 0.20681120455265045
train loss item: 0.15451326966285706
train loss item: 0.34986069798469543
train loss item: 0.24790212512016296
train loss item: 0.5114298462867737
train loss item: 0.3958980441093445
train loss item: 0.2890373468399048
train loss item: 0.1805766522884369
train loss item: 0.22035284340381622
train loss item: 0.2923964560031891
train loss item: 0.24060599505901337
train loss item: 0.12315607070922852
train loss item: 0.30887746810913086
train loss item: 0.2096823900938034
train loss item: 0.18589869141578674
train loss item: 0.133903369307518
train loss item: 0.4328691065311432
train loss item: 0.17694121599197388
train loss item: 0.6586924195289612
train loss item: 0.19366076588630676
test loss item: 0.15426699817180634
test loss item: 0.3476596474647522
test loss item: 0.19176852703094482
test loss item: 0.12025521695613861
test loss item: 0.1895514875650406
test loss item: 0.1676361858844757
test loss item: 0.12871108949184418
test loss item: 0.211562842130661
test loss item: 0.18419715762138367
test loss item: 0.2757470905780792
test loss item: 0.13334710896015167
test loss item: 0.1483461707830429
test loss item: 0.16972962021827698
test loss item: 0.1708116978406906
test loss item: 0.18277688324451447
test loss item: 0.1331593245267868
test loss item: 0.21081140637397766
test loss item: 0.25380590558052063
test loss item: 0.12946122884750366
test loss item: 0.27220287919044495
test loss item: 0.3130112290382385
test loss item: 0.10718534886837006
test loss item: 0.19671761989593506
Epoch [6/50], Training Loss: 0.2768, Testing Loss: 0.1910
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/50
train loss item: 0.32555872201919556
train loss item: 0.21497906744480133
train loss item: 0.14866745471954346
train loss item: 0.18701061606407166
train loss item: 0.14049728214740753
train loss item: 0.25934746861457825
train loss item: 0.19468316435813904
train loss item: 0.30709290504455566
train loss item: 0.2554112374782562
train loss item: 0.311885267496109
train loss item: 0.1575358659029007
train loss item: 0.17992499470710754
train loss item: 0.23951144516468048
train loss item: 0.20659896731376648
train loss item: 0.1405148059129715
train loss item: 0.3030441105365753
train loss item: 0.1768285632133484
train loss item: 0.1733575165271759
train loss item: 0.13984131813049316
train loss item: 0.3352847099304199
train loss item: 0.15127824246883392
train loss item: 0.5354752540588379
train loss item: 0.1760980486869812
test loss item: 0.13826042413711548
test loss item: 0.2958555519580841
test loss item: 0.18446896970272064
test loss item: 0.11005322635173798
test loss item: 0.16363711655139923
test loss item: 0.153920978307724
test loss item: 0.11578797549009323
test loss item: 0.19334232807159424
test loss item: 0.16785477101802826
test loss item: 0.24696201086044312
test loss item: 0.1185421422123909
test loss item: 0.14619840681552887
test loss item: 0.167436882853508
test loss item: 0.16374850273132324
test loss item: 0.16671258211135864
test loss item: 0.1215277761220932
test loss item: 0.2063816636800766
test loss item: 0.2263036072254181
test loss item: 0.11752420663833618
test loss item: 0.28625771403312683
test loss item: 0.30209454894065857
test loss item: 0.10535407811403275
test loss item: 0.12601099908351898
Epoch [7/50], Training Loss: 0.2287, Testing Loss: 0.1750
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/50
train loss item: 0.3012543320655823
train loss item: 0.20037749409675598
train loss item: 0.15124835073947906
train loss item: 0.19189628958702087
train loss item: 0.1498374044895172
train loss item: 0.23290376365184784
train loss item: 0.1782134622335434
train loss item: 0.2549075484275818
train loss item: 0.2470044642686844
train loss item: 0.3479762077331543
train loss item: 0.17558394372463226
train loss item: 0.1654239296913147
train loss item: 0.2178492695093155
train loss item: 0.20187196135520935
train loss item: 0.14818845689296722
train loss item: 0.37684640288352966
train loss item: 0.15558870136737823
train loss item: 0.13934096693992615
train loss item: 0.12192875891923904
train loss item: 0.33646222949028015
train loss item: 0.17282699048519135
train loss item: 0.4316958487033844
train loss item: 0.1981968730688095
test loss item: 0.1437983363866806
test loss item: 0.24322709441184998
test loss item: 0.18382255733013153
test loss item: 0.0959974005818367
test loss item: 0.16204187273979187
test loss item: 0.14360186457633972
test loss item: 0.11268126219511032
test loss item: 0.1833123415708542
test loss item: 0.1660611927509308
test loss item: 0.23899421095848083
test loss item: 0.13025082647800446
test loss item: 0.13067510724067688
test loss item: 0.1573084145784378
test loss item: 0.1725132316350937
test loss item: 0.15371856093406677
test loss item: 0.12092222273349762
test loss item: 0.2014172077178955
test loss item: 0.19604329764842987
test loss item: 0.12494060397148132
test loss item: 0.3224906921386719
test loss item: 0.30743852257728577
test loss item: 0.11089477688074112
test loss item: 0.24979451298713684
Epoch [8/50], Training Loss: 0.2216, Testing Loss: 0.1762
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/50
train loss item: 0.3338316082954407
train loss item: 0.17771737277507782
train loss item: 0.1588924676179886
train loss item: 0.22411374747753143
train loss item: 0.17408092319965363
train loss item: 0.3877794146537781
train loss item: 0.21395277976989746
train loss item: 0.4650765061378479
train loss item: 0.2452603280544281
train loss item: 0.36681416630744934
train loss item: 0.2549988329410553
train loss item: 0.31607404351234436
train loss item: 0.257192999124527
train loss item: 0.3181667923927307
train loss item: 0.13541674613952637
train loss item: 0.34534984827041626
train loss item: 0.1687154471874237
train loss item: 0.16515670716762543
train loss item: 0.11993734538555145
train loss item: 0.39822518825531006
train loss item: 0.21850204467773438
train loss item: 0.5533841252326965
train loss item: 0.23953178524971008
test loss item: 0.1624395102262497
test loss item: 0.39077064394950867
test loss item: 0.20271635055541992
test loss item: 0.11896762996912003
test loss item: 0.2104427069425583
test loss item: 0.18920981884002686
test loss item: 0.16872777044773102
test loss item: 0.2503719627857208
test loss item: 0.20184193551540375
test loss item: 0.29027339816093445
test loss item: 0.16368892788887024
test loss item: 0.16960984468460083
test loss item: 0.21503379940986633
test loss item: 0.226335346698761
test loss item: 0.201276496052742
test loss item: 0.16468001902103424
test loss item: 0.25499337911605835
test loss item: 0.29053565859794617
test loss item: 0.1668405830860138
test loss item: 0.3116277754306793
test loss item: 0.36191806197166443
test loss item: 0.16376323997974396
test loss item: 0.3213746249675751
Epoch [9/50], Training Loss: 0.2712, Testing Loss: 0.2260
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/50
train loss item: 0.338926762342453
train loss item: 0.3018026053905487
train loss item: 0.22104722261428833
train loss item: 0.19400654733181
train loss item: 0.13727746903896332
train loss item: 0.3550010621547699
train loss item: 0.25028884410858154
train loss item: 0.5497902035713196
train loss item: 0.3238041400909424
train loss item: 0.16600939631462097
train loss item: 0.11922754347324371
train loss item: 0.1483672559261322
train loss item: 0.26534372568130493
train loss item: 0.23212747275829315
train loss item: 0.15061210095882416
train loss item: 0.2416793704032898
train loss item: 0.21183577179908752
train loss item: 0.13064569234848022
train loss item: 0.10517460852861404
train loss item: 0.49265915155410767
train loss item: 0.28493258357048035
train loss item: 0.7507374882698059
train loss item: 0.19929036498069763
test loss item: 0.17714014649391174
test loss item: 0.2566101551055908
test loss item: 0.23043875396251678
test loss item: 0.12219168990850449
test loss item: 0.1868738979101181
test loss item: 0.19066382944583893
test loss item: 0.14038875699043274
test loss item: 0.20967550575733185
test loss item: 0.17486175894737244
test loss item: 0.28723111748695374
test loss item: 0.1477000117301941
test loss item: 0.19551393389701843
test loss item: 0.19757981598377228
test loss item: 0.2059766948223114
test loss item: 0.17611373960971832
test loss item: 0.13474905490875244
test loss item: 0.24453771114349365
test loss item: 0.2106400728225708
test loss item: 0.18395757675170898
test loss item: 0.4013921916484833
test loss item: 0.3440716862678528
test loss item: 0.13483305275440216
test loss item: 0.12343262135982513
Epoch [10/50], Training Loss: 0.2683, Testing Loss: 0.2033
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 11/50
train loss item: 0.20690536499023438
train loss item: 0.17773473262786865
train loss item: 0.1923607587814331
train loss item: 0.20309129357337952
train loss item: 0.14787311851978302
train loss item: 0.15779004991054535
train loss item: 0.15622800588607788
train loss item: 0.2966565787792206
train loss item: 0.2618408203125
train loss item: 0.1918792724609375
train loss item: 0.1401173621416092
train loss item: 0.20129336416721344
train loss item: 0.2839632034301758
train loss item: 0.24956780672073364
train loss item: 0.1175166517496109
train loss item: 0.21291610598564148
train loss item: 0.2162613868713379
train loss item: 0.15531080961227417
train loss item: 0.1286841183900833
train loss item: 0.36952194571495056
train loss item: 0.18281716108322144
train loss item: 0.5163421034812927
train loss item: 0.20149709284305573
test loss item: 0.1391347050666809
test loss item: 0.26956114172935486
test loss item: 0.2302107810974121
test loss item: 0.09577734768390656
test loss item: 0.1657509207725525
test loss item: 0.1373865008354187
test loss item: 0.12169954180717468
test loss item: 0.21411679685115814
test loss item: 0.17257629334926605
test loss item: 0.2641477584838867
test loss item: 0.1240074634552002
test loss item: 0.1331394612789154
test loss item: 0.19048859179019928
test loss item: 0.2030666321516037
test loss item: 0.16894173622131348
test loss item: 0.11676754057407379
test loss item: 0.18344853818416595
test loss item: 0.2088382989168167
test loss item: 0.11931981891393661
test loss item: 0.2826586663722992
test loss item: 0.33323773741722107
test loss item: 0.10643832385540009
test loss item: 0.1506543904542923
Epoch [11/50], Training Loss: 0.2160, Testing Loss: 0.1796
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 12/50
train loss item: 0.26044154167175293
train loss item: 0.18461690843105316
train loss item: 0.14241059124469757
train loss item: 0.18223746120929718
train loss item: 0.12079588323831558
train loss item: 0.1653498411178589
train loss item: 0.12642547488212585
train loss item: 0.2221578061580658
train loss item: 0.1984560787677765
train loss item: 0.23194734752178192
train loss item: 0.1201518326997757
train loss item: 0.18251249194145203
train loss item: 0.23119261860847473
train loss item: 0.21793076395988464
train loss item: 0.09908583015203476
train loss item: 0.2229086309671402
train loss item: 0.14930371940135956
train loss item: 0.1311407834291458
train loss item: 0.1729613095521927
train loss item: 0.28583434224128723
train loss item: 0.12198735773563385
train loss item: 0.4471735656261444
train loss item: 0.15882284939289093
test loss item: 0.1442594826221466
test loss item: 0.22501087188720703
test loss item: 0.1755877137184143
test loss item: 0.09632411599159241
test loss item: 0.16364739835262299
test loss item: 0.1613510549068451
test loss item: 0.11446160078048706
test loss item: 0.16061484813690186
test loss item: 0.1770622879266739
test loss item: 0.22552965581417084
test loss item: 0.12031325697898865
test loss item: 0.15918394923210144
test loss item: 0.16966930031776428
test loss item: 0.16392138600349426
test loss item: 0.1656549870967865
test loss item: 0.11775638908147812
test loss item: 0.21272887289524078
test loss item: 0.19175554811954498
test loss item: 0.12859970331192017
test loss item: 0.29974979162216187
test loss item: 0.2788420021533966
test loss item: 0.10450508445501328
test loss item: 0.12916624546051025
Epoch [12/50], Training Loss: 0.1903, Testing Loss: 0.1689
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 13/50
train loss item: 0.3089812994003296
train loss item: 0.2321368157863617
train loss item: 0.12554731965065002
train loss item: 0.20197723805904388
train loss item: 0.16188719868659973
train loss item: 0.3955458700656891
train loss item: 0.1882701963186264
train loss item: 0.6388847231864929
train loss item: 0.3023850917816162
train loss item: 0.23350955545902252
train loss item: 0.16674987971782684
train loss item: 0.28334593772888184
train loss item: 0.3545098304748535
train loss item: 0.34165582060813904
train loss item: 0.10579322278499603
train loss item: 0.21531333029270172
train loss item: 0.15895847976207733
train loss item: 0.12969866394996643
train loss item: 0.11380039900541306
train loss item: 0.3081514835357666
train loss item: 0.15353380143642426
train loss item: 0.7096001505851746
train loss item: 0.18444883823394775
test loss item: 0.21804362535476685
test loss item: 0.21590539813041687
test loss item: 0.278894305229187
test loss item: 0.09835094213485718
test loss item: 0.16160249710083008
test loss item: 0.16093386709690094
test loss item: 0.11151694506406784
test loss item: 0.23780497908592224
test loss item: 0.21929754316806793
test loss item: 0.3676528334617615
test loss item: 0.11674844473600388
test loss item: 0.13778331875801086
test loss item: 0.22672642767429352
test loss item: 0.26773539185523987
test loss item: 0.18714942038059235
test loss item: 0.12932848930358887
test loss item: 0.2773125171661377
test loss item: 0.20724810659885406
test loss item: 0.10397525131702423
test loss item: 0.6023297309875488
test loss item: 0.451305627822876
test loss item: 0.10313507914543152
test loss item: 0.17905326187610626
Epoch [13/50], Training Loss: 0.2615, Testing Loss: 0.2200
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 14/50
train loss item: 0.24561074376106262
train loss item: 0.167112797498703
train loss item: 0.15019801259040833
train loss item: 0.2141425609588623
train loss item: 0.15604491531848907
train loss item: 0.43828028440475464
train loss item: 0.1416034996509552
train loss item: 0.3311622142791748
train loss item: 0.3535134196281433
train loss item: 0.2814106047153473
train loss item: 0.18515832722187042
train loss item: 0.36276987195014954
train loss item: 0.2908656597137451
train loss item: 0.3518775403499603
train loss item: 0.1527705192565918
train loss item: 0.2848336100578308
train loss item: 0.24649815261363983
train loss item: 0.1700756698846817
train loss item: 0.09886881709098816
train loss item: 0.26476845145225525
train loss item: 0.15290416777133942
train loss item: 0.3907383978366852
train loss item: 0.20234215259552002
test loss item: 0.17124266922473907
test loss item: 0.27561965584754944
test loss item: 0.26002058386802673
test loss item: 0.1247190535068512
test loss item: 0.1817469298839569
test loss item: 0.15864822268486023
test loss item: 0.14889644086360931
test loss item: 0.26483333110809326
test loss item: 0.20992083847522736
test loss item: 0.29530319571495056
test loss item: 0.1537453532218933
test loss item: 0.16810153424739838
test loss item: 0.227358877658844
test loss item: 0.242543026804924
test loss item: 0.17498067021369934
test loss item: 0.1588122546672821
test loss item: 0.2157389223575592
test loss item: 0.23612329363822937
test loss item: 0.1535934954881668
test loss item: 0.3958793580532074
test loss item: 0.40385550260543823
test loss item: 0.13959074020385742
test loss item: 0.19251562654972076
Epoch [14/50], Training Loss: 0.2449, Testing Loss: 0.2154
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 15/50
train loss item: 0.34004759788513184
train loss item: 0.2878037691116333
train loss item: 0.18995094299316406
train loss item: 0.23256073892116547
train loss item: 0.1729443073272705
train loss item: 0.46840912103652954
train loss item: 0.19778646528720856
train loss item: 0.5854936838150024
train loss item: 0.28879302740097046
train loss item: 0.21174393594264984
train loss item: 0.1423836201429367
train loss item: 0.1998469978570938
train loss item: 0.2990504503250122
train loss item: 0.3499985337257385
train loss item: 0.10887957364320755
train loss item: 0.2497738003730774
train loss item: 0.14704671502113342
train loss item: 0.12038092315196991
train loss item: 0.13596609234809875
train loss item: 0.2970401644706726
train loss item: 0.1730838418006897
train loss item: 0.6317137479782104
train loss item: 0.1488673985004425
test loss item: 0.1834230273962021
test loss item: 0.2371128499507904
test loss item: 0.2505602240562439
test loss item: 0.09421227872371674
test loss item: 0.16297946870326996
test loss item: 0.1661035567522049
test loss item: 0.10959269851446152
test loss item: 0.21874360740184784
test loss item: 0.20217986404895782
test loss item: 0.32199886441230774
test loss item: 0.11086899787187576
test loss item: 0.1531486213207245
test loss item: 0.2086990624666214
test loss item: 0.231148362159729
test loss item: 0.1752316653728485
test loss item: 0.12458159774541855
test loss item: 0.25639188289642334
test loss item: 0.21575205028057098
test loss item: 0.10717228800058365
test loss item: 0.49972087144851685
test loss item: 0.3946649432182312
test loss item: 0.08944731205701828
test loss item: 0.1488029807806015
Epoch [15/50], Training Loss: 0.2600, Testing Loss: 0.2027
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 16/50
train loss item: 0.23562687635421753
train loss item: 0.15539158880710602
train loss item: 0.15395307540893555
train loss item: 0.20522284507751465
train loss item: 0.14044538140296936
train loss item: 0.31338727474212646
train loss item: 0.13348235189914703
train loss item: 0.27901676297187805
train loss item: 0.23675978183746338
train loss item: 0.2403193712234497
train loss item: 0.17354030907154083
train loss item: 0.3665979504585266
train loss item: 0.3236079514026642
train loss item: 0.5365365147590637
train loss item: 0.16289420425891876
train loss item: 0.4161731004714966
train loss item: 0.14566858112812042
train loss item: 0.1579277664422989
train loss item: 0.13444752991199493
train loss item: 0.2892054319381714
train loss item: 0.19161410629749298
train loss item: 0.2916661500930786
train loss item: 0.2308817356824875
test loss item: 0.20314070582389832
test loss item: 0.2919785976409912
test loss item: 0.24140329658985138
test loss item: 0.10733617097139359
test loss item: 0.17495328187942505
test loss item: 0.16886194050312042
test loss item: 0.12922273576259613
test loss item: 0.250461220741272
test loss item: 0.2147398740053177
test loss item: 0.35589805245399475
test loss item: 0.14194156229496002
test loss item: 0.15932373702526093
test loss item: 0.2132261097431183
test loss item: 0.24103106558322906
test loss item: 0.18565991520881653
test loss item: 0.1315397024154663
test loss item: 0.26703211665153503
test loss item: 0.24312517046928406
test loss item: 0.1304319053888321
test loss item: 0.5774705410003662
test loss item: 0.4556067883968353
test loss item: 0.12102843821048737
test loss item: 0.21232841908931732
Epoch [16/50], Training Loss: 0.2398, Testing Loss: 0.2269
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 17/50
train loss item: 0.47814854979515076
train loss item: 0.36797893047332764
train loss item: 0.18138056993484497
train loss item: 0.24828316271305084
train loss item: 0.17737379670143127
train loss item: 0.4896818995475769
train loss item: 0.20671296119689941
train loss item: 0.6443431973457336
train loss item: 0.47280582785606384
train loss item: 0.19407671689987183
train loss item: 0.11975447833538055
train loss item: 0.15039649605751038
train loss item: 0.23641803860664368
train loss item: 0.3059614896774292
train loss item: 0.16512468457221985
train loss item: 0.32199162244796753
train loss item: 0.2120898813009262
train loss item: 0.18252643942832947
train loss item: 0.09941751509904861
train loss item: 0.2556298077106476
train loss item: 0.1353212594985962
train loss item: 0.548790454864502
train loss item: 0.1335677206516266
test loss item: 0.17263221740722656
test loss item: 0.2309011071920395
test loss item: 0.23208998143672943
test loss item: 0.09506147354841232
test loss item: 0.15240439772605896
test loss item: 0.14928366243839264
test loss item: 0.11558619886636734
test loss item: 0.21084186434745789
test loss item: 0.18440775573253632
test loss item: 0.2739444971084595
test loss item: 0.12832902371883392
test loss item: 0.13392889499664307
test loss item: 0.18781034648418427
test loss item: 0.21091748774051666
test loss item: 0.14822377264499664
test loss item: 0.1335640847682953
test loss item: 0.2112751454114914
test loss item: 0.1920100599527359
test loss item: 0.11320342123508453
test loss item: 0.3613733649253845
test loss item: 0.3315696716308594
test loss item: 0.09765003621578217
test loss item: 0.17092390358448029
Epoch [17/50], Training Loss: 0.2751, Testing Loss: 0.1843
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 18/50
train loss item: 0.23625239729881287
train loss item: 0.1581014096736908
train loss item: 0.12902523577213287
train loss item: 0.16066139936447144
train loss item: 0.11740843951702118
train loss item: 0.20920905470848083
train loss item: 0.12097073346376419
train loss item: 0.2551857829093933
train loss item: 0.2105909138917923
train loss item: 0.21660856902599335
train loss item: 0.1382676362991333
train loss item: 0.2875397503376007
train loss item: 0.2829764187335968
train loss item: 0.41412290930747986
train loss item: 0.14595213532447815
train loss item: 0.4011786878108978
train loss item: 0.14646320044994354
train loss item: 0.1500830352306366
train loss item: 0.11758702248334885
train loss item: 0.21440449357032776
train loss item: 0.16842089593410492
train loss item: 0.2641986906528473
train loss item: 0.20544962584972382
test loss item: 0.2002243548631668
test loss item: 0.324308305978775
test loss item: 0.24084177613258362
test loss item: 0.10195581614971161
test loss item: 0.16441799700260162
test loss item: 0.1674237996339798
test loss item: 0.12276461720466614
test loss item: 0.25420039892196655
test loss item: 0.21798110008239746
test loss item: 0.35014986991882324
test loss item: 0.14343750476837158
test loss item: 0.14144925773143768
test loss item: 0.21597085893154144
test loss item: 0.2381739616394043
test loss item: 0.17974863946437836
test loss item: 0.13370488584041595
test loss item: 0.2602709233760834
test loss item: 0.25296750664711
test loss item: 0.124466672539711
test loss item: 0.5470060110092163
test loss item: 0.4440627694129944
test loss item: 0.11895348131656647
test loss item: 0.19719871878623962
Epoch [18/50], Training Loss: 0.2066, Testing Loss: 0.2236
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 19/50
train loss item: 0.43088433146476746
train loss item: 0.4144124388694763
train loss item: 0.17934559285640717
train loss item: 0.23388399183750153
train loss item: 0.15439680218696594
train loss item: 0.45874375104904175
train loss item: 0.19931818544864655
train loss item: 0.5275213718414307
train loss item: 0.3275609016418457
train loss item: 0.15372203290462494
train loss item: 0.09222211688756943
train loss item: 0.12758532166481018
train loss item: 0.2222166210412979
train loss item: 0.29268258810043335
train loss item: 0.11813364923000336
train loss item: 0.2603149712085724
train loss item: 0.17342206835746765
train loss item: 0.15622912347316742
train loss item: 0.09687619656324387
train loss item: 0.21965794265270233
train loss item: 0.15796281397342682
train loss item: 0.4705863893032074
train loss item: 0.14116637408733368
test loss item: 0.1782492697238922
test loss item: 0.2191074937582016
test loss item: 0.2703952193260193
test loss item: 0.08844462037086487
test loss item: 0.15179145336151123
test loss item: 0.14464488625526428
test loss item: 0.11694485694169998
test loss item: 0.2448653131723404
test loss item: 0.20215605199337006
test loss item: 0.31298762559890747
test loss item: 0.1243913397192955
test loss item: 0.13586559891700745
test loss item: 0.21206839382648468
test loss item: 0.24686299264431
test loss item: 0.15342842042446136
test loss item: 0.13032695651054382
test loss item: 0.20861947536468506
test loss item: 0.1967063695192337
test loss item: 0.11560764163732529
test loss item: 0.42237675189971924
test loss item: 0.38959020376205444
test loss item: 0.09687194973230362
test loss item: 0.1505330204963684
Epoch [19/50], Training Loss: 0.2439, Testing Loss: 0.1962
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 20/50
train loss item: 0.22231699526309967
train loss item: 0.15008261799812317
train loss item: 0.11845797300338745
train loss item: 0.16552677750587463
train loss item: 0.11254936456680298
train loss item: 0.21416109800338745
train loss item: 0.12524081766605377
train loss item: 0.2666766047477722
train loss item: 0.23603011667728424
train loss item: 0.21384462714195251
train loss item: 0.12899622321128845
train loss item: 0.23940913379192352
train loss item: 0.22488205134868622
train loss item: 0.25631824135780334
train loss item: 0.12280619144439697
train loss item: 0.33313700556755066
train loss item: 0.15086567401885986
train loss item: 0.1697666347026825
train loss item: 0.09984223544597626
train loss item: 0.2048252522945404
train loss item: 0.15696094930171967
train loss item: 0.3041413724422455
train loss item: 0.14723797142505646
test loss item: 0.159834086894989
test loss item: 0.2480575293302536
test loss item: 0.1857096403837204
test loss item: 0.1017708033323288
test loss item: 0.15264232456684113
test loss item: 0.15118719637393951
test loss item: 0.11665590107440948
test loss item: 0.1844547688961029
test loss item: 0.17524413764476776
test loss item: 0.2517758011817932
test loss item: 0.1410001963376999
test loss item: 0.13932016491889954
test loss item: 0.16709478199481964
test loss item: 0.1783064603805542
test loss item: 0.14947938919067383
test loss item: 0.12533420324325562
test loss item: 0.1951831579208374
test loss item: 0.20305639505386353
test loss item: 0.11980778723955154
test loss item: 0.34486404061317444
test loss item: 0.29804107546806335
test loss item: 0.11291635781526566
test loss item: 0.16377973556518555
Epoch [20/50], Training Loss: 0.1897, Testing Loss: 0.1768
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 21/50
train loss item: 0.32695016264915466
train loss item: 0.2963116466999054
train loss item: 0.1684010624885559
train loss item: 0.18792161345481873
train loss item: 0.12458599358797073
train loss item: 0.37132349610328674
train loss item: 0.17973032593727112
train loss item: 0.37950399518013
train loss item: 0.22817251086235046
train loss item: 0.14298026263713837
train loss item: 0.08767632395029068
train loss item: 0.1339367926120758
train loss item: 0.17412875592708588
train loss item: 0.2253407984972
train loss item: 0.090807244181633
train loss item: 0.22531315684318542
train loss item: 0.1359335035085678
train loss item: 0.14080001413822174
train loss item: 0.07888378202915192
train loss item: 0.22677914798259735
train loss item: 0.11896149069070816
train loss item: 0.46229326725006104
train loss item: 0.13136722147464752
test loss item: 0.1601274162530899
test loss item: 0.23180240392684937
test loss item: 0.2343612164258957
test loss item: 0.08552916347980499
test loss item: 0.15900659561157227
test loss item: 0.1355101615190506
test loss item: 0.10315990447998047
test loss item: 0.21745537221431732
test loss item: 0.1787777692079544
test loss item: 0.29530537128448486
test loss item: 0.11353567242622375
test loss item: 0.12946109473705292
test loss item: 0.17764003574848175
test loss item: 0.21075615286827087
test loss item: 0.1568676382303238
test loss item: 0.10964509099721909
test loss item: 0.2065100371837616
test loss item: 0.21072900295257568
test loss item: 0.1005246639251709
test loss item: 0.42425256967544556
test loss item: 0.35971885919570923
test loss item: 0.09398601949214935
test loss item: 0.14606721699237823
Epoch [21/50], Training Loss: 0.2017, Testing Loss: 0.1844
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 22/50
train loss item: 0.254061222076416
train loss item: 0.15034708380699158
train loss item: 0.14511480927467346
train loss item: 0.14070738852024078
train loss item: 0.10414665937423706
train loss item: 0.2500896155834198
train loss item: 0.14754796028137207
train loss item: 0.31124091148376465
train loss item: 0.1951114982366562
train loss item: 0.15367811918258667
train loss item: 0.13255777955055237
train loss item: 0.2653396427631378
train loss item: 0.2447553277015686
train loss item: 0.3122413456439972
train loss item: 0.13670487701892853
train loss item: 0.2789289653301239
train loss item: 0.11980205029249191
train loss item: 0.14386864006519318
train loss item: 0.0857851654291153
train loss item: 0.2852281630039215
train loss item: 0.14370878040790558
train loss item: 0.3019523620605469
train loss item: 0.14460289478302002
test loss item: 0.1791505217552185
test loss item: 0.2064816951751709
test loss item: 0.20495732128620148
test loss item: 0.12996621429920197
test loss item: 0.1647377759218216
test loss item: 0.15745165944099426
test loss item: 0.1279318481683731
test loss item: 0.1847177892923355
test loss item: 0.19818630814552307
test loss item: 0.26327502727508545
test loss item: 0.15975581109523773
test loss item: 0.14259223639965057
test loss item: 0.18216155469417572
test loss item: 0.1944800317287445
test loss item: 0.16518166661262512
test loss item: 0.14121226966381073
test loss item: 0.20063632726669312
test loss item: 0.20185546576976776
test loss item: 0.12419401854276657
test loss item: 0.37070196866989136
test loss item: 0.3033083975315094
test loss item: 0.12940795719623566
test loss item: 0.14075899124145508
Epoch [22/50], Training Loss: 0.1934, Testing Loss: 0.1858
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.30538034439086914
loss item: 0.17516915500164032
loss item: 0.16067878901958466
loss item: 0.16214905679225922
loss item: 0.21354395151138306
loss item: 0.14693622291088104
loss item: 0.20720720291137695
loss item: 0.29442015290260315
loss item: 0.1203702986240387
loss item: 0.1827232986688614
loss item: 0.23438352346420288
Val Loss: 0.2003
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.0005 8 360 done at Tue Nov 12 11:19:09 CET 2024
UNet2 with 1 50 0.001 8 360 start at Tue Nov 12 11:19:09 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 50, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.4765785932540894
train loss item: 0.9321662187576294
train loss item: 0.5705680251121521
train loss item: 0.7235683798789978
train loss item: 0.48982417583465576
train loss item: 0.9598066806793213
train loss item: 0.43659016489982605
train loss item: 1.2260032892227173
train loss item: 1.3787102699279785
train loss item: 0.7917293310165405
train loss item: 0.9322169423103333
train loss item: 0.6345696449279785
train loss item: 0.7560602426528931
train loss item: 1.1498932838439941
train loss item: 0.3278881013393402
train loss item: 1.077573299407959
train loss item: 0.4689684212207794
train loss item: 0.5166193246841431
train loss item: 0.35709214210510254
train loss item: 0.9266363382339478
train loss item: 0.5574327707290649
train loss item: 1.6715219020843506
train loss item: 0.486640065908432
test loss item: 0.8900920748710632
test loss item: 1.806649923324585
test loss item: 1.2828243970870972
test loss item: 0.5111333131790161
test loss item: 1.2371248006820679
test loss item: 1.0926077365875244
test loss item: 0.56679368019104
test loss item: 1.1501104831695557
test loss item: 1.7554935216903687
test loss item: 1.8484928607940674
test loss item: 0.9038143157958984
test loss item: 0.8129539489746094
test loss item: 0.9455756545066833
test loss item: 1.179633617401123
test loss item: 1.4823050498962402
test loss item: 0.475413054227829
test loss item: 1.2059890031814575
test loss item: 1.6585445404052734
test loss item: 0.64629727602005
test loss item: 1.6239275932312012
test loss item: 2.2568092346191406
test loss item: 0.4669654071331024
test loss item: 0.6569624543190002
Epoch [1/50], Training Loss: 0.8195, Testing Loss: 1.1503
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/50
train loss item: 0.7198851704597473
train loss item: 0.5766774415969849
train loss item: 0.3693244457244873
train loss item: 0.47380316257476807
train loss item: 0.37415528297424316
train loss item: 0.7435067892074585
train loss item: 0.3544085621833801
train loss item: 1.0596643686294556
train loss item: 1.232591152191162
train loss item: 0.4808028042316437
train loss item: 0.39889079332351685
train loss item: 0.43824806809425354
train loss item: 0.5386667251586914
train loss item: 0.8641173839569092
train loss item: 0.2591363787651062
train loss item: 0.8595077991485596
train loss item: 0.4677795469760895
train loss item: 0.3627093434333801
train loss item: 0.262126088142395
train loss item: 0.8070115447044373
train loss item: 0.3673115074634552
train loss item: 1.401215672492981
train loss item: 0.39585059881210327
test loss item: 0.33737945556640625
test loss item: 0.6803757548332214
test loss item: 0.5224807858467102
test loss item: 0.15958459675312042
test loss item: 0.438453733921051
test loss item: 0.39053747057914734
test loss item: 0.2568058669567108
test loss item: 0.5029212236404419
test loss item: 0.5168474316596985
test loss item: 0.7240390181541443
test loss item: 0.30944234132766724
test loss item: 0.359069287776947
test loss item: 0.4218577444553375
test loss item: 0.48717018961906433
test loss item: 0.405526340007782
test loss item: 0.29365992546081543
test loss item: 0.48906639218330383
test loss item: 0.5646036863327026
test loss item: 0.24367626011371613
test loss item: 0.8112217783927917
test loss item: 0.8648074269294739
test loss item: 0.19702045619487762
test loss item: 0.2881266176700592
Epoch [2/50], Training Loss: 0.6003, Testing Loss: 0.4463
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/50
train loss item: 0.5857239365577698
train loss item: 0.47913631796836853
train loss item: 0.34196391701698303
train loss item: 0.3625548481941223
train loss item: 0.322047621011734
train loss item: 0.5890762805938721
train loss item: 0.33007514476776123
train loss item: 0.892874002456665
train loss item: 0.9750428795814514
train loss item: 0.40374162793159485
train loss item: 0.23625467717647552
train loss item: 0.311131089925766
train loss item: 0.43381816148757935
train loss item: 0.7189918160438538
train loss item: 0.20671994984149933
train loss item: 0.7044638991355896
train loss item: 0.41628825664520264
train loss item: 0.3068786859512329
train loss item: 0.21826574206352234
train loss item: 0.6536188125610352
train loss item: 0.30149081349372864
train loss item: 1.1437581777572632
train loss item: 0.32628604769706726
test loss item: 0.3164239227771759
test loss item: 0.5652851462364197
test loss item: 0.46206268668174744
test loss item: 0.17671112716197968
test loss item: 0.3733791708946228
test loss item: 0.359761118888855
test loss item: 0.2469884306192398
test loss item: 0.4529210925102234
test loss item: 0.4714938700199127
test loss item: 0.6134920120239258
test loss item: 0.29506415128707886
test loss item: 0.3338986933231354
test loss item: 0.3973461091518402
test loss item: 0.4507129192352295
test loss item: 0.3469497561454773
test loss item: 0.29272007942199707
test loss item: 0.42597338557243347
test loss item: 0.45541080832481384
test loss item: 0.23441563546657562
test loss item: 0.7079593539237976
test loss item: 0.7161606550216675
test loss item: 0.1908903419971466
test loss item: 0.2717518210411072
Epoch [3/50], Training Loss: 0.4896, Testing Loss: 0.3982
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/50
train loss item: 0.5228458642959595
train loss item: 0.42947816848754883
train loss item: 0.2872880697250366
train loss item: 0.35001304745674133
train loss item: 0.2899131774902344
train loss item: 0.4791066348552704
train loss item: 0.2831111550331116
train loss item: 0.6694863438606262
train loss item: 0.6924212574958801
train loss item: 0.6254570484161377
train loss item: 0.3395339846611023
train loss item: 0.3599051237106323
train loss item: 0.38609570264816284
train loss item: 0.6901715993881226
train loss item: 0.2499030977487564
train loss item: 0.7642113566398621
train loss item: 0.2852863073348999
train loss item: 0.2560964524745941
train loss item: 0.2003164440393448
train loss item: 0.5541471838951111
train loss item: 0.25212961435317993
train loss item: 0.8862177729606628
train loss item: 0.37143927812576294
test loss item: 0.2705531716346741
test loss item: 0.48720142245292664
test loss item: 0.423031747341156
test loss item: 0.13735458254814148
test loss item: 0.32907983660697937
test loss item: 0.276557058095932
test loss item: 0.20864078402519226
test loss item: 0.4274965524673462
test loss item: 0.35954558849334717
test loss item: 0.6025698781013489
test loss item: 0.21676217019557953
test loss item: 0.290805846452713
test loss item: 0.32221370935440063
test loss item: 0.37713536620140076
test loss item: 0.3080090880393982
test loss item: 0.22687669098377228
test loss item: 0.4496840238571167
test loss item: 0.40885546803474426
test loss item: 0.20672093331813812
test loss item: 0.9701879620552063
test loss item: 0.7683491706848145
test loss item: 0.1755107194185257
test loss item: 0.36274436116218567
Epoch [4/50], Training Loss: 0.4445, Testing Loss: 0.3742
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/50
train loss item: 0.5384072065353394
train loss item: 0.3676510751247406
train loss item: 0.24895644187927246
train loss item: 0.327865332365036
train loss item: 0.26798781752586365
train loss item: 0.505597710609436
train loss item: 0.29630738496780396
train loss item: 0.5945239067077637
train loss item: 0.5812534093856812
train loss item: 0.6535705924034119
train loss item: 0.4561678469181061
train loss item: 0.5079673528671265
train loss item: 0.367435485124588
train loss item: 0.4734421372413635
train loss item: 0.2440497875213623
train loss item: 0.6802853345870972
train loss item: 0.30604639649391174
train loss item: 0.2915448248386383
train loss item: 0.18607120215892792
train loss item: 0.5552102327346802
train loss item: 0.1966606080532074
train loss item: 0.7755084037780762
train loss item: 0.35261452198028564
test loss item: 0.25693389773368835
test loss item: 0.6362634301185608
test loss item: 0.3662925064563751
test loss item: 0.15442082285881042
test loss item: 0.3417651653289795
test loss item: 0.28926190733909607
test loss item: 0.22710475325584412
test loss item: 0.4193858802318573
test loss item: 0.3435114622116089
test loss item: 0.5583738684654236
test loss item: 0.2087879180908203
test loss item: 0.2760846018791199
test loss item: 0.3190973997116089
test loss item: 0.33902156352996826
test loss item: 0.3174228072166443
test loss item: 0.22639739513397217
test loss item: 0.4182337522506714
test loss item: 0.4764458239078522
test loss item: 0.21202200651168823
test loss item: 0.7432581186294556
test loss item: 0.6825604438781738
test loss item: 0.18403932452201843
test loss item: 0.28034594655036926
Epoch [5/50], Training Loss: 0.4250, Testing Loss: 0.3599
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/50
train loss item: 0.5585629940032959
train loss item: 0.5344494581222534
train loss item: 0.34899744391441345
train loss item: 0.3082354962825775
train loss item: 0.22890688478946686
train loss item: 0.5598739385604858
train loss item: 0.3085964322090149
train loss item: 0.8056288361549377
train loss item: 0.5848270654678345
train loss item: 0.35226064920425415
train loss item: 0.1975589543581009
train loss item: 0.23452666401863098
train loss item: 0.32209163904190063
train loss item: 0.3375929296016693
train loss item: 0.20615604519844055
train loss item: 0.44287624955177307
train loss item: 0.2652926743030548
train loss item: 0.21315178275108337
train loss item: 0.16516441106796265
train loss item: 0.53762286901474
train loss item: 0.2580186724662781
train loss item: 0.6853154897689819
train loss item: 0.284938782453537
test loss item: 0.2315720021724701
test loss item: 0.4646412432193756
test loss item: 0.3032532334327698
test loss item: 0.13924439251422882
test loss item: 0.26666226983070374
test loss item: 0.2470569610595703
test loss item: 0.20609250664710999
test loss item: 0.3299613296985626
test loss item: 0.2876373827457428
test loss item: 0.4399486482143402
test loss item: 0.1940801590681076
test loss item: 0.2270563393831253
test loss item: 0.24952436983585358
test loss item: 0.28514406085014343
test loss item: 0.24138768017292023
test loss item: 0.19574418663978577
test loss item: 0.33208319544792175
test loss item: 0.340351939201355
test loss item: 0.18697066605091095
test loss item: 0.6058893203735352
test loss item: 0.5246335864067078
test loss item: 0.15954670310020447
test loss item: 0.15267521142959595
Epoch [6/50], Training Loss: 0.3800, Testing Loss: 0.2874
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/50
train loss item: 0.4021523594856262
train loss item: 0.3162161409854889
train loss item: 0.2723442614078522
train loss item: 0.3268522322177887
train loss item: 0.21911470592021942
train loss item: 0.41691023111343384
train loss item: 0.24997203052043915
train loss item: 0.5287351012229919
train loss item: 0.37710750102996826
train loss item: 0.47766461968421936
train loss item: 0.18727412819862366
train loss item: 0.1878996044397354
train loss item: 0.29421746730804443
train loss item: 0.3607800006866455
train loss item: 0.20136696100234985
train loss item: 0.39274635910987854
train loss item: 0.25384244322776794
train loss item: 0.20083652436733246
train loss item: 0.19266709685325623
train loss item: 0.4614376425743103
train loss item: 0.20531418919563293
train loss item: 0.5728633403778076
train loss item: 0.22268982231616974
test loss item: 0.19615289568901062
test loss item: 0.481764018535614
test loss item: 0.2989967167377472
test loss item: 0.11951272934675217
test loss item: 0.25567924976348877
test loss item: 0.20863138139247894
test loss item: 0.16439186036586761
test loss item: 0.31888848543167114
test loss item: 0.2509861886501312
test loss item: 0.430711954832077
test loss item: 0.17473486065864563
test loss item: 0.2152552306652069
test loss item: 0.24665547907352448
test loss item: 0.2540634870529175
test loss item: 0.22932513058185577
test loss item: 0.18319068849086761
test loss item: 0.3293408155441284
test loss item: 0.34540244936943054
test loss item: 0.1596243679523468
test loss item: 0.6464223861694336
test loss item: 0.5668483972549438
test loss item: 0.13962748646736145
test loss item: 0.2536185383796692
Epoch [7/50], Training Loss: 0.3183, Testing Loss: 0.2813
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/50
train loss item: 0.4189450740814209
train loss item: 0.30522671341896057
train loss item: 0.20396777987480164
train loss item: 0.2514228820800781
train loss item: 0.17994077503681183
train loss item: 0.3347015976905823
train loss item: 0.20005646347999573
train loss item: 0.3385167717933655
train loss item: 0.278639018535614
train loss item: 0.4125658869743347
train loss item: 0.17626959085464478
train loss item: 0.1907232254743576
train loss item: 0.25492557883262634
train loss item: 0.25476789474487305
train loss item: 0.13487157225608826
train loss item: 0.33062511682510376
train loss item: 0.21381478011608124
train loss item: 0.1730651557445526
train loss item: 0.17049281299114227
train loss item: 0.34431037306785583
train loss item: 0.18457676470279694
train loss item: 0.5556100010871887
train loss item: 0.22263680398464203
test loss item: 0.19097179174423218
test loss item: 0.286514014005661
test loss item: 0.2705909013748169
test loss item: 0.12387676537036896
test loss item: 0.20824222266674042
test loss item: 0.18826885521411896
test loss item: 0.14587140083312988
test loss item: 0.25525540113449097
test loss item: 0.21356524527072906
test loss item: 0.3744790852069855
test loss item: 0.13932961225509644
test loss item: 0.1927987039089203
test loss item: 0.22258500754833221
test loss item: 0.24290576577186584
test loss item: 0.205287903547287
test loss item: 0.16104045510292053
test loss item: 0.2880701422691345
test loss item: 0.23833085596561432
test loss item: 0.15873445570468903
test loss item: 0.5707091689109802
test loss item: 0.46413731575012207
test loss item: 0.12349166721105576
test loss item: 0.1659897118806839
Epoch [8/50], Training Loss: 0.2666, Testing Loss: 0.2361
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/50
train loss item: 0.3802889585494995
train loss item: 0.27206093072891235
train loss item: 0.16991247236728668
train loss item: 0.29638752341270447
train loss item: 0.23741382360458374
train loss item: 0.5567935705184937
train loss item: 0.24496160447597504
train loss item: 0.7605146765708923
train loss item: 0.38512521982192993
train loss item: 0.48402002453804016
train loss item: 0.3905779719352722
train loss item: 0.5678982734680176
train loss item: 0.4188593327999115
train loss item: 0.31763923168182373
train loss item: 0.20315849781036377
train loss item: 0.5621485710144043
train loss item: 0.25946202874183655
train loss item: 0.17660945653915405
train loss item: 0.16251502931118011
train loss item: 0.46363019943237305
train loss item: 0.20161591470241547
train loss item: 0.7525853514671326
train loss item: 0.26906776428222656
test loss item: 0.1697181761264801
test loss item: 0.3958494961261749
test loss item: 0.23475107550621033
test loss item: 0.14532159268856049
test loss item: 0.20542488992214203
test loss item: 0.1956602931022644
test loss item: 0.15181979537010193
test loss item: 0.26134949922561646
test loss item: 0.22014988958835602
test loss item: 0.31401947140693665
test loss item: 0.1515907645225525
test loss item: 0.18914474546909332
test loss item: 0.221982941031456
test loss item: 0.21134255826473236
test loss item: 0.20458614826202393
test loss item: 0.17503401637077332
test loss item: 0.2530139982700348
test loss item: 0.2789519429206848
test loss item: 0.15887142717838287
test loss item: 0.30555540323257446
test loss item: 0.3827064037322998
test loss item: 0.12580417096614838
test loss item: 0.20688292384147644
Epoch [9/50], Training Loss: 0.3710, Testing Loss: 0.2243
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/50
train loss item: 0.3346715271472931
train loss item: 0.2929723262786865
train loss item: 0.2416636347770691
train loss item: 0.19509001076221466
train loss item: 0.156550794839859
train loss item: 0.40651288628578186
train loss item: 0.20927360653877258
train loss item: 0.45220455527305603
train loss item: 0.3544653058052063
train loss item: 0.30481040477752686
train loss item: 0.1297157257795334
train loss item: 0.1752721071243286
train loss item: 0.2897919714450836
train loss item: 0.3201410472393036
train loss item: 0.12874630093574524
train loss item: 0.2718420624732971
train loss item: 0.19182844460010529
train loss item: 0.14839163422584534
train loss item: 0.1459731012582779
train loss item: 0.3529197871685028
train loss item: 0.16293473541736603
train loss item: 0.5676361918449402
train loss item: 0.21354849636554718
test loss item: 0.13014233112335205
test loss item: 0.3868257701396942
test loss item: 0.2147640436887741
test loss item: 0.08463709056377411
test loss item: 0.1947013884782791
test loss item: 0.15652233362197876
test loss item: 0.10899405926465988
test loss item: 0.2535930275917053
test loss item: 0.17891110479831696
test loss item: 0.3057962954044342
test loss item: 0.11475161463022232
test loss item: 0.1364891678094864
test loss item: 0.18655724823474884
test loss item: 0.17882861196994781
test loss item: 0.18416240811347961
test loss item: 0.12706705927848816
test loss item: 0.2034531980752945
test loss item: 0.27732229232788086
test loss item: 0.11255377531051636
test loss item: 0.33339723944664
test loss item: 0.3978010416030884
test loss item: 0.09949417412281036
test loss item: 0.11371277272701263
Epoch [10/50], Training Loss: 0.2629, Testing Loss: 0.1948
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 11/50
train loss item: 0.3275589346885681
train loss item: 0.19452795386314392
train loss item: 0.13208498060703278
train loss item: 0.18438813090324402
train loss item: 0.14985673129558563
train loss item: 0.28770214319229126
train loss item: 0.1623295545578003
train loss item: 0.22299286723136902
train loss item: 0.2554283142089844
train loss item: 0.3485743999481201
train loss item: 0.18729285895824432
train loss item: 0.19506381452083588
train loss item: 0.23676085472106934
train loss item: 0.24339838325977325
train loss item: 0.12782971560955048
train loss item: 0.3229942321777344
train loss item: 0.15201804041862488
train loss item: 0.13559433817863464
train loss item: 0.14702290296554565
train loss item: 0.27183467149734497
train loss item: 0.1798892617225647
train loss item: 0.4590368866920471
train loss item: 0.17645789682865143
test loss item: 0.1593380719423294
test loss item: 0.2827260196208954
test loss item: 0.2281753122806549
test loss item: 0.09424681961536407
test loss item: 0.1804381012916565
test loss item: 0.1634477823972702
test loss item: 0.12050433456897736
test loss item: 0.22078488767147064
test loss item: 0.1765349954366684
test loss item: 0.31232622265815735
test loss item: 0.12349709123373032
test loss item: 0.15494976937770844
test loss item: 0.18269073963165283
test loss item: 0.20542733371257782
test loss item: 0.1712530255317688
test loss item: 0.12227243930101395
test loss item: 0.26069149374961853
test loss item: 0.22368444502353668
test loss item: 0.12944422662258148
test loss item: 0.47597822546958923
test loss item: 0.40507972240448
test loss item: 0.1045326516032219
test loss item: 0.17590580880641937
Epoch [11/50], Training Loss: 0.2218, Testing Loss: 0.2032
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 12/50
train loss item: 0.3143652677536011
train loss item: 0.20028363168239594
train loss item: 0.13563068211078644
train loss item: 0.18514826893806458
train loss item: 0.15526171028614044
train loss item: 0.2906447649002075
train loss item: 0.14878562092781067
train loss item: 0.2682049572467804
train loss item: 0.23215420544147491
train loss item: 0.38534095883369446
train loss item: 0.15949712693691254
train loss item: 0.1563429981470108
train loss item: 0.23042453825473785
train loss item: 0.21663996577262878
train loss item: 0.11632635444402695
train loss item: 0.3180011212825775
train loss item: 0.13417643308639526
train loss item: 0.1395290344953537
train loss item: 0.09734342247247696
train loss item: 0.24409766495227814
train loss item: 0.13239294290542603
train loss item: 0.40229544043540955
train loss item: 0.19195130467414856
test loss item: 0.11485936492681503
test loss item: 0.19832131266593933
test loss item: 0.15148240327835083
test loss item: 0.07554682344198227
test loss item: 0.1244656965136528
test loss item: 0.11854647099971771
test loss item: 0.09223821014165878
test loss item: 0.14167235791683197
test loss item: 0.13109667599201202
test loss item: 0.2028920203447342
test loss item: 0.094832643866539
test loss item: 0.10518790036439896
test loss item: 0.12261554598808289
test loss item: 0.13282285630702972
test loss item: 0.12508821487426758
test loss item: 0.09210918098688126
test loss item: 0.17015521228313446
test loss item: 0.15514886379241943
test loss item: 0.08931480348110199
test loss item: 0.28028956055641174
test loss item: 0.24482496082782745
test loss item: 0.0862061157822609
test loss item: 0.1006075069308281
Epoch [12/50], Training Loss: 0.2111, Testing Loss: 0.1370
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 13/50
train loss item: 0.23135799169540405
train loss item: 0.16528776288032532
train loss item: 0.12143750488758087
train loss item: 0.16350427269935608
train loss item: 0.15935392677783966
train loss item: 0.23295800387859344
train loss item: 0.16998057067394257
train loss item: 0.21286888420581818
train loss item: 0.20675967633724213
train loss item: 0.30472302436828613
train loss item: 0.14189212024211884
train loss item: 0.2146693766117096
train loss item: 0.21408385038375854
train loss item: 0.2521365284919739
train loss item: 0.11018318682909012
train loss item: 0.2636013627052307
train loss item: 0.14711156487464905
train loss item: 0.13229042291641235
train loss item: 0.1183105856180191
train loss item: 0.3093740940093994
train loss item: 0.11718563735485077
train loss item: 0.47694432735443115
train loss item: 0.17038194835186005
test loss item: 0.13413144648075104
test loss item: 0.4509882628917694
test loss item: 0.18571116030216217
test loss item: 0.07985825091600418
test loss item: 0.20224495232105255
test loss item: 0.1760113537311554
test loss item: 0.10871817916631699
test loss item: 0.27147161960601807
test loss item: 0.16922642290592194
test loss item: 0.30532199144363403
test loss item: 0.12233549356460571
test loss item: 0.1517663449048996
test loss item: 0.18675188720226288
test loss item: 0.18668270111083984
test loss item: 0.17381520569324493
test loss item: 0.13083234429359436
test loss item: 0.24219545722007751
test loss item: 0.3268144428730011
test loss item: 0.13788914680480957
test loss item: 0.33441463112831116
test loss item: 0.4016178846359253
test loss item: 0.09689721465110779
test loss item: 0.1083567664027214
Epoch [13/50], Training Loss: 0.2016, Testing Loss: 0.2037
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 14/50
train loss item: 0.3090096116065979
train loss item: 0.2469841092824936
train loss item: 0.19395573437213898
train loss item: 0.1964869350194931
train loss item: 0.14529971778392792
train loss item: 0.3477925956249237
train loss item: 0.20257821679115295
train loss item: 0.3565477430820465
train loss item: 0.24251841008663177
train loss item: 0.2530171871185303
train loss item: 0.11341556161642075
train loss item: 0.14141930639743805
train loss item: 0.2099127620458603
train loss item: 0.21974357962608337
train loss item: 0.10822385549545288
train loss item: 0.25819316506385803
train loss item: 0.1514667123556137
train loss item: 0.1495872139930725
train loss item: 0.0840703472495079
train loss item: 0.26843708753585815
train loss item: 0.12789933383464813
train loss item: 0.355648934841156
train loss item: 0.2497771829366684
test loss item: 0.13851813971996307
test loss item: 0.22718766331672668
test loss item: 0.18089571595191956
test loss item: 0.08387177437543869
test loss item: 0.14410223066806793
test loss item: 0.1428638994693756
test loss item: 0.10841447860002518
test loss item: 0.18537066876888275
test loss item: 0.19264072179794312
test loss item: 0.23041599988937378
test loss item: 0.11201481521129608
test loss item: 0.13787853717803955
test loss item: 0.1806260198354721
test loss item: 0.18153761327266693
test loss item: 0.1421915888786316
test loss item: 0.13043507933616638
test loss item: 0.16959567368030548
test loss item: 0.17845144867897034
test loss item: 0.10034196823835373
test loss item: 0.2664271891117096
test loss item: 0.27065134048461914
test loss item: 0.09332980960607529
test loss item: 0.08968354016542435
Epoch [14/50], Training Loss: 0.2144, Testing Loss: 0.1603
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 15/50
train loss item: 0.31086283922195435
train loss item: 0.21598897874355316
train loss item: 0.18371044099330902
train loss item: 0.1326296627521515
train loss item: 0.13525156676769257
train loss item: 0.27427005767822266
train loss item: 0.1998910754919052
train loss item: 0.3051774203777313
train loss item: 0.2506851553916931
train loss item: 0.24354027211666107
train loss item: 0.09474808722734451
train loss item: 0.13233612477779388
train loss item: 0.20690788328647614
train loss item: 0.19617080688476562
train loss item: 0.08838056772947311
train loss item: 0.21123996376991272
train loss item: 0.1325126737356186
train loss item: 0.11187136173248291
train loss item: 0.10151863843202591
train loss item: 0.3571396470069885
train loss item: 0.13839280605316162
train loss item: 0.6354599595069885
train loss item: 0.15303990244865417
test loss item: 0.13423247635364532
test loss item: 0.2481107860803604
test loss item: 0.17687803506851196
test loss item: 0.10016598552465439
test loss item: 0.15660372376441956
test loss item: 0.14098364114761353
test loss item: 0.10575801134109497
test loss item: 0.18338672816753387
test loss item: 0.1716773360967636
test loss item: 0.23467572033405304
test loss item: 0.11246200650930405
test loss item: 0.13819630444049835
test loss item: 0.1789892017841339
test loss item: 0.17143581807613373
test loss item: 0.1445452868938446
test loss item: 0.12469404190778732
test loss item: 0.1713147610425949
test loss item: 0.197459414601326
test loss item: 0.10816273093223572
test loss item: 0.25110235810279846
test loss item: 0.2647736966609955
test loss item: 0.08750323206186295
test loss item: 0.09274200350046158
Epoch [15/50], Training Loss: 0.2092, Testing Loss: 0.1607
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 16/50
train loss item: 0.2732023596763611
train loss item: 0.21976612508296967
train loss item: 0.2472693920135498
train loss item: 0.17040911316871643
train loss item: 0.12278465926647186
train loss item: 0.2533915936946869
train loss item: 0.17811919748783112
train loss item: 0.42223942279815674
train loss item: 0.29134440422058105
train loss item: 0.1548498421907425
train loss item: 0.096696637570858
train loss item: 0.12859241664409637
train loss item: 0.2512688636779785
train loss item: 0.31914153695106506
train loss item: 0.09837689995765686
train loss item: 0.24434451758861542
train loss item: 0.13097593188285828
train loss item: 0.11738350987434387
train loss item: 0.10257906466722488
train loss item: 0.401559442281723
train loss item: 0.19254618883132935
train loss item: 0.8089110851287842
train loss item: 0.1449006050825119
test loss item: 0.20789773762226105
test loss item: 0.2023884803056717
test loss item: 0.2804575562477112
test loss item: 0.09845265001058578
test loss item: 0.13940441608428955
test loss item: 0.15196169912815094
test loss item: 0.11226875334978104
test loss item: 0.25180405378341675
test loss item: 0.20598571002483368
test loss item: 0.3744586110115051
test loss item: 0.111831896007061
test loss item: 0.13845892250537872
test loss item: 0.2112390249967575
test loss item: 0.26889511942863464
test loss item: 0.17080606520175934
test loss item: 0.12212330102920532
test loss item: 0.27257564663887024
test loss item: 0.1914140284061432
test loss item: 0.10925096273422241
test loss item: 0.6358022093772888
test loss item: 0.46224844455718994
test loss item: 0.1113082766532898
test loss item: 0.1433073729276657
Epoch [16/50], Training Loss: 0.2335, Testing Loss: 0.2163
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 17/50
train loss item: 0.3163450062274933
train loss item: 0.236819326877594
train loss item: 0.2543181777000427
train loss item: 0.3213060200214386
train loss item: 0.28071340918540955
train loss item: 0.6626084446907043
train loss item: 0.22191445529460907
train loss item: 0.4037418067455292
train loss item: 0.3255635201931
train loss item: 0.26305967569351196
train loss item: 0.2289675623178482
train loss item: 0.453366219997406
train loss item: 0.38189736008644104
train loss item: 0.7854611873626709
train loss item: 0.21083320677280426
train loss item: 0.4915808439254761
train loss item: 0.20892539620399475
train loss item: 0.23699171841144562
train loss item: 0.1398700326681137
train loss item: 0.3770301938056946
train loss item: 0.2333570420742035
train loss item: 0.28633302450180054
train loss item: 0.23007042706012726
test loss item: 0.29601460695266724
test loss item: 0.35413768887519836
test loss item: 0.3984965980052948
test loss item: 0.12113795429468155
test loss item: 0.206080824136734
test loss item: 0.19999530911445618
test loss item: 0.1482996940612793
test loss item: 0.3878489136695862
test loss item: 0.2664259970188141
test loss item: 0.5999029874801636
test loss item: 0.1741955578327179
test loss item: 0.16685284674167633
test loss item: 0.3125171959400177
test loss item: 0.36544275283813477
test loss item: 0.257753849029541
test loss item: 0.17078855633735657
test loss item: 0.3868381679058075
test loss item: 0.3136376440525055
test loss item: 0.17186586558818817
test loss item: 1.0394911766052246
test loss item: 0.7716081142425537
test loss item: 0.15044419467449188
test loss item: 0.12418074905872345
Epoch [17/50], Training Loss: 0.3283, Testing Loss: 0.3210
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 18/50
train loss item: 0.43314698338508606
train loss item: 0.24611322581768036
train loss item: 0.15674497187137604
train loss item: 0.2481537163257599
train loss item: 0.16050606966018677
train loss item: 0.4571300446987152
train loss item: 0.1599660962820053
train loss item: 0.5673392415046692
train loss item: 0.357443630695343
train loss item: 0.3240668475627899
train loss item: 0.14646269381046295
train loss item: 0.20560075342655182
train loss item: 0.26705753803253174
train loss item: 0.28928664326667786
train loss item: 0.11461357772350311
train loss item: 0.24434605240821838
train loss item: 0.16765889525413513
train loss item: 0.1283113807439804
train loss item: 0.1089370921254158
train loss item: 0.33474698662757874
train loss item: 0.1624424010515213
train loss item: 0.5972700715065002
train loss item: 0.16325144469738007
test loss item: 0.15655234456062317
test loss item: 0.1906760036945343
test loss item: 0.1890304982662201
test loss item: 0.10755553841590881
test loss item: 0.13536429405212402
test loss item: 0.14370352029800415
test loss item: 0.13009727001190186
test loss item: 0.16831795871257782
test loss item: 0.17510226368904114
test loss item: 0.23316805064678192
test loss item: 0.12090068310499191
test loss item: 0.1223803162574768
test loss item: 0.17162242531776428
test loss item: 0.17945195734500885
test loss item: 0.1484716385602951
test loss item: 0.12239018827676773
test loss item: 0.19902360439300537
test loss item: 0.157210573554039
test loss item: 0.12488572299480438
test loss item: 0.31885725259780884
test loss item: 0.2788655459880829
test loss item: 0.12077917158603668
test loss item: 0.19640061259269714
Epoch [18/50], Training Loss: 0.2626, Testing Loss: 0.1692
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 19/50
train loss item: 0.22309307754039764
train loss item: 0.13791778683662415
train loss item: 0.16474802792072296
train loss item: 0.17990432679653168
train loss item: 0.15479572117328644
train loss item: 0.31293559074401855
train loss item: 0.13955676555633545
train loss item: 0.35356298089027405
train loss item: 0.30062514543533325
train loss item: 0.26473766565322876
train loss item: 0.1732974797487259
train loss item: 0.37216606736183167
train loss item: 0.3032092750072479
train loss item: 0.5552408695220947
train loss item: 0.17525264620780945
train loss item: 0.38485896587371826
train loss item: 0.18805190920829773
train loss item: 0.1567559540271759
train loss item: 0.10553234815597534
train loss item: 0.2578390836715698
train loss item: 0.14048995077610016
train loss item: 0.23577731847763062
train loss item: 0.17120347917079926
test loss item: 0.20200566947460175
test loss item: 0.23883122205734253
test loss item: 0.25321564078330994
test loss item: 0.10192595422267914
test loss item: 0.15893837809562683
test loss item: 0.15480375289916992
test loss item: 0.1265561431646347
test loss item: 0.2353135198354721
test loss item: 0.194960355758667
test loss item: 0.3537604510784149
test loss item: 0.1407867968082428
test loss item: 0.13709507882595062
test loss item: 0.19623993337154388
test loss item: 0.2385481894016266
test loss item: 0.169870525598526
test loss item: 0.12220967561006546
test loss item: 0.25996318459510803
test loss item: 0.2168475240468979
test loss item: 0.13390521705150604
test loss item: 0.5810821652412415
test loss item: 0.4510602355003357
test loss item: 0.12802021205425262
test loss item: 0.12799009680747986
Epoch [19/50], Training Loss: 0.2370, Testing Loss: 0.2141
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 20/50
train loss item: 0.44718047976493835
train loss item: 0.3370766043663025
train loss item: 0.20078827440738678
train loss item: 0.2324378788471222
train loss item: 0.12930424511432648
train loss item: 0.3400287628173828
train loss item: 0.13721409440040588
train loss item: 0.3010435104370117
train loss item: 0.1881791651248932
train loss item: 0.2269759476184845
train loss item: 0.09687657654285431
train loss item: 0.12719102203845978
train loss item: 0.22372747957706451
train loss item: 0.2147682160139084
train loss item: 0.09291363507509232
train loss item: 0.2188066989183426
train loss item: 0.1494102030992508
train loss item: 0.11385292559862137
train loss item: 0.09862899780273438
train loss item: 0.31329843401908875
train loss item: 0.1334330141544342
train loss item: 0.5816722512245178
train loss item: 0.13856260478496552
test loss item: 0.1502525806427002
test loss item: 0.18812178075313568
test loss item: 0.2039613127708435
test loss item: 0.070759616792202
test loss item: 0.11961402744054794
test loss item: 0.12209160625934601
test loss item: 0.08839132636785507
test loss item: 0.1894732564687729
test loss item: 0.1577189415693283
test loss item: 0.2702849805355072
test loss item: 0.0864621251821518
test loss item: 0.1132497489452362
test loss item: 0.15751269459724426
test loss item: 0.1926189512014389
test loss item: 0.12666764855384827
test loss item: 0.09367746114730835
test loss item: 0.19601283967494965
test loss item: 0.16358524560928345
test loss item: 0.08524222671985626
test loss item: 0.42554154992103577
test loss item: 0.32349419593811035
test loss item: 0.08065194636583328
test loss item: 0.09111976623535156
Epoch [20/50], Training Loss: 0.2193, Testing Loss: 0.1607
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 21/50
train loss item: 0.2630383372306824
train loss item: 0.1457313597202301
train loss item: 0.20848023891448975
train loss item: 0.18606647849082947
train loss item: 0.20793190598487854
train loss item: 0.3505720794200897
train loss item: 0.24781595170497894
train loss item: 0.3406229019165039
train loss item: 0.2235713005065918
train loss item: 0.1803119033575058
train loss item: 0.16190050542354584
train loss item: 0.3623344302177429
train loss item: 0.3265939950942993
train loss item: 0.605388879776001
train loss item: 0.17902304232120514
train loss item: 0.470218688249588
train loss item: 0.19208107888698578
train loss item: 0.16488294303417206
train loss item: 0.09607816487550735
train loss item: 0.26544106006622314
train loss item: 0.17969992756843567
train loss item: 0.2678314745426178
train loss item: 0.19476290047168732
test loss item: 0.1666376143693924
test loss item: 0.2790520489215851
test loss item: 0.19606934487819672
test loss item: 0.08441674709320068
test loss item: 0.16144540905952454
test loss item: 0.16448760032653809
test loss item: 0.11925297975540161
test loss item: 0.210610494017601
test loss item: 0.1632722020149231
test loss item: 0.2888626456260681
test loss item: 0.1435634195804596
test loss item: 0.149240180850029
test loss item: 0.16777153313159943
test loss item: 0.19271016120910645
test loss item: 0.14795859158039093
test loss item: 0.12056978791952133
test loss item: 0.220407173037529
test loss item: 0.22000469267368317
test loss item: 0.15196454524993896
test loss item: 0.4090319573879242
test loss item: 0.3520749509334564
test loss item: 0.11678789556026459
test loss item: 0.17267951369285583
Epoch [21/50], Training Loss: 0.2531, Testing Loss: 0.1913
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 22/50
train loss item: 0.32673975825309753
train loss item: 0.2668607831001282
train loss item: 0.2073572427034378
train loss item: 0.2638876438140869
train loss item: 0.14045067131519318
train loss item: 0.28989773988723755
train loss item: 0.10264001041650772
train loss item: 0.25098150968551636
train loss item: 0.22506429255008698
train loss item: 0.15810738503932953
train loss item: 0.12616358697414398
train loss item: 0.1649593859910965
train loss item: 0.228972926735878
train loss item: 0.2124054878950119
train loss item: 0.11752131581306458
train loss item: 0.3186171352863312
train loss item: 0.14207375049591064
train loss item: 0.12019729614257812
train loss item: 0.07661034911870956
train loss item: 0.21631090342998505
train loss item: 0.12963928282260895
train loss item: 0.5078986883163452
train loss item: 0.12449897825717926
test loss item: 0.14305689930915833
test loss item: 0.19323450326919556
test loss item: 0.1800660789012909
test loss item: 0.07406006008386612
test loss item: 0.12588313221931458
test loss item: 0.1261114925146103
test loss item: 0.09616291522979736
test loss item: 0.16697512567043304
test loss item: 0.14413611590862274
test loss item: 0.23119954764842987
test loss item: 0.10655934363603592
test loss item: 0.11555904895067215
test loss item: 0.1398172676563263
test loss item: 0.17264682054519653
test loss item: 0.11796186864376068
test loss item: 0.0921294167637825
test loss item: 0.18292509019374847
test loss item: 0.16350747644901276
test loss item: 0.09856715798377991
test loss item: 0.34459251165390015
test loss item: 0.2796076834201813
test loss item: 0.09526678919792175
test loss item: 0.10956121981143951
Epoch [22/50], Training Loss: 0.2051, Testing Loss: 0.1522
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.2660503387451172
loss item: 0.1489536315202713
loss item: 0.12166782468557358
loss item: 0.12704512476921082
loss item: 0.1922481805086136
loss item: 0.10304348170757294
loss item: 0.18580716848373413
loss item: 0.2834436893463135
loss item: 0.10279557853937149
loss item: 0.14171329140663147
loss item: 0.21432079374790192
Val Loss: 0.1716
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 50, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.001 8 360 done at Tue Nov 12 11:24:39 CET 2024
UNet2 with 1 50 0.005 8 360 start at Tue Nov 12 11:24:39 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 50, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.4765785932540894
train loss item: 1.488364577293396
train loss item: 1.227317452430725
train loss item: 0.9579159021377563
train loss item: 0.47981324791908264
train loss item: 1.0573915243148804
train loss item: 0.5085159540176392
train loss item: 1.6343568563461304
train loss item: 1.794062614440918
train loss item: 0.5039210319519043
train loss item: 0.5952209830284119
train loss item: 0.4662436246871948
train loss item: 0.6920085549354553
train loss item: 1.3686498403549194
train loss item: 0.4267558455467224
train loss item: 1.2039326429367065
train loss item: 0.47162064909935
train loss item: 0.5360599756240845
train loss item: 0.42717626690864563
train loss item: 1.0362893342971802
train loss item: 0.5555956363677979
train loss item: 1.9805022478103638
train loss item: 0.4602459967136383
test loss item: 0.6217797994613647
test loss item: 2.0337860584259033
test loss item: 1.213813066482544
test loss item: 0.38870155811309814
test loss item: 1.382132887840271
test loss item: 0.8165193200111389
test loss item: 0.5437419414520264
test loss item: 1.2737616300582886
test loss item: 1.3834030628204346
test loss item: 1.8372173309326172
test loss item: 0.592004120349884
test loss item: 0.9243448972702026
test loss item: 1.0557352304458618
test loss item: 1.036850929260254
test loss item: 1.3563196659088135
test loss item: 0.5631416440010071
test loss item: 1.1755098104476929
test loss item: 1.8684247732162476
test loss item: 0.6068812608718872
test loss item: 1.7190667390823364
test loss item: 2.2971298694610596
test loss item: 0.43986159563064575
test loss item: 0.6305710077285767
Epoch [1/50], Training Loss: 0.9282, Testing Loss: 1.1200
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/50
train loss item: 0.8817241191864014
train loss item: 0.6220057606697083
train loss item: 0.37252718210220337
train loss item: 0.48133644461631775
train loss item: 0.4621841609477997
train loss item: 0.7980542778968811
train loss item: 0.4550514817237854
train loss item: 1.257053017616272
train loss item: 1.5772531032562256
train loss item: 0.45303359627723694
train loss item: 0.451168030500412
train loss item: 0.4531153738498688
train loss item: 0.6032328009605408
train loss item: 1.275573492050171
train loss item: 0.3529285490512848
train loss item: 1.1563992500305176
train loss item: 0.4298779368400574
train loss item: 0.4244886636734009
train loss item: 0.2824743092060089
train loss item: 1.0078117847442627
train loss item: 0.5240007042884827
train loss item: 1.708648920059204
train loss item: 0.42949140071868896
test loss item: 0.442624032497406
test loss item: 0.8245567083358765
test loss item: 0.6602063179016113
test loss item: 0.20956861972808838
test loss item: 0.5388758182525635
test loss item: 0.4418867528438568
test loss item: 0.32372337579727173
test loss item: 0.6586329936981201
test loss item: 0.5979886054992676
test loss item: 0.9395972490310669
test loss item: 0.3086383044719696
test loss item: 0.4864426851272583
test loss item: 0.577355682849884
test loss item: 0.6563327312469482
test loss item: 0.4668954908847809
test loss item: 0.3657890260219574
test loss item: 0.6423410177230835
test loss item: 0.7166123986244202
test loss item: 0.2991071045398712
test loss item: 1.170305848121643
test loss item: 1.0574113130569458
test loss item: 0.21842075884342194
test loss item: 0.3052617013454437
Epoch [2/50], Training Loss: 0.7156, Testing Loss: 0.5612
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/50
train loss item: 0.7431809902191162
train loss item: 0.6191406846046448
train loss item: 0.43029603362083435
train loss item: 0.42559051513671875
train loss item: 0.4080215394496918
train loss item: 0.7563353776931763
train loss item: 0.3635371923446655
train loss item: 1.1390384435653687
train loss item: 1.3282111883163452
train loss item: 0.44343921542167664
train loss item: 0.3567367494106293
train loss item: 0.4475926160812378
train loss item: 0.5829280018806458
train loss item: 1.0786911249160767
train loss item: 0.330636203289032
train loss item: 1.0156275033950806
train loss item: 0.42239853739738464
train loss item: 0.3858896791934967
train loss item: 0.25743162631988525
train loss item: 0.9137788414955139
train loss item: 0.42193618416786194
train loss item: 1.4729211330413818
train loss item: 0.40966910123825073
test loss item: 0.3893614411354065
test loss item: 1.0323541164398193
test loss item: 0.72443687915802
test loss item: 0.23743866384029388
test loss item: 0.7091763019561768
test loss item: 0.42930880188941956
test loss item: 0.34910112619400024
test loss item: 0.7346993088722229
test loss item: 0.7086458802223206
test loss item: 1.0439419746398926
test loss item: 0.3099004924297333
test loss item: 0.5220818519592285
test loss item: 0.648734986782074
test loss item: 0.6613513827323914
test loss item: 0.6533994674682617
test loss item: 0.378279447555542
test loss item: 0.6705164313316345
test loss item: 0.9307916164398193
test loss item: 0.30650296807289124
test loss item: 1.1147801876068115
test loss item: 1.2291043996810913
test loss item: 0.23978836834430695
test loss item: 0.4042002558708191
Epoch [3/50], Training Loss: 0.6414, Testing Loss: 0.6273
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/50
train loss item: 0.7174620628356934
train loss item: 0.626370906829834
train loss item: 0.40952324867248535
train loss item: 0.4464689791202545
train loss item: 0.3397260308265686
train loss item: 0.7972732782363892
train loss item: 0.37226226925849915
train loss item: 1.0186164379119873
train loss item: 1.087173581123352
train loss item: 0.5898532271385193
train loss item: 0.43383219838142395
train loss item: 0.518644392490387
train loss item: 0.5865426063537598
train loss item: 0.9519888162612915
train loss item: 0.26932379603385925
train loss item: 1.0012365579605103
train loss item: 0.42180994153022766
train loss item: 0.3636658489704132
train loss item: 0.24974589049816132
train loss item: 0.869410514831543
train loss item: 0.39114290475845337
train loss item: 1.308923363685608
train loss item: 0.4488106369972229
test loss item: 0.46738114953041077
test loss item: 1.05255126953125
test loss item: 0.7785388231277466
test loss item: 0.22049495577812195
test loss item: 0.761809229850769
test loss item: 0.47466912865638733
test loss item: 0.34532245993614197
test loss item: 0.7612624764442444
test loss item: 0.7938814759254456
test loss item: 1.1449915170669556
test loss item: 0.3093205988407135
test loss item: 0.5632598400115967
test loss item: 0.6869807839393616
test loss item: 0.7593849897384644
test loss item: 0.7014322280883789
test loss item: 0.3816555142402649
test loss item: 0.7469164133071899
test loss item: 0.996607780456543
test loss item: 0.2980276644229889
test loss item: 1.279030680656433
test loss item: 1.3300002813339233
test loss item: 0.23272831737995148
test loss item: 0.23110859096050262
Epoch [4/50], Training Loss: 0.6183, Testing Loss: 0.6660
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/50
train loss item: 0.7039119601249695
train loss item: 0.574923574924469
train loss item: 0.3799315392971039
train loss item: 0.47770166397094727
train loss item: 0.35004091262817383
train loss item: 0.7785196900367737
train loss item: 0.383879691362381
train loss item: 0.9350206255912781
train loss item: 0.9613019824028015
train loss item: 0.5624580383300781
train loss item: 0.33632874488830566
train loss item: 0.4587704837322235
train loss item: 0.5480469465255737
train loss item: 0.8911879062652588
train loss item: 0.2724534571170807
train loss item: 0.914302408695221
train loss item: 0.4085254371166229
train loss item: 0.3735141158103943
train loss item: 0.2646847069263458
train loss item: 0.8681567311286926
train loss item: 0.3723757565021515
train loss item: 1.1929198503494263
train loss item: 0.43668046593666077
test loss item: 0.37410157918930054
test loss item: 0.9319489002227783
test loss item: 0.6321455240249634
test loss item: 0.1855507344007492
test loss item: 0.5884519815444946
test loss item: 0.4237440228462219
test loss item: 0.3056093156337738
test loss item: 0.6545339822769165
test loss item: 0.5989649295806885
test loss item: 0.9356948733329773
test loss item: 0.27890706062316895
test loss item: 0.4743272066116333
test loss item: 0.5543439388275146
test loss item: 0.5956098437309265
test loss item: 0.531182050704956
test loss item: 0.33013099431991577
test loss item: 0.6357483267784119
test loss item: 0.7942562699317932
test loss item: 0.27731576561927795
test loss item: 1.1459107398986816
test loss item: 1.1016350984573364
test loss item: 0.20692336559295654
test loss item: 0.20810559391975403
Epoch [5/50], Training Loss: 0.5846, Testing Loss: 0.5550
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/50
train loss item: 0.7258139848709106
train loss item: 0.5964581966400146
train loss item: 0.4212470054626465
train loss item: 0.45946282148361206
train loss item: 0.33255571126937866
train loss item: 0.8159078359603882
train loss item: 0.37336626648902893
train loss item: 1.3230717182159424
train loss item: 1.182820439338684
train loss item: 0.4841574728488922
train loss item: 0.32276782393455505
train loss item: 0.4924411177635193
train loss item: 0.6536904573440552
train loss item: 0.8118979334831238
train loss item: 0.27969956398010254
train loss item: 0.8857945799827576
train loss item: 0.4237791895866394
train loss item: 0.3810163736343384
train loss item: 0.2570098042488098
train loss item: 0.8441897630691528
train loss item: 0.39039427042007446
train loss item: 1.2285592555999756
train loss item: 0.4488706588745117
test loss item: 0.39778944849967957
test loss item: 0.9530107378959656
test loss item: 0.6834079623222351
test loss item: 0.21911463141441345
test loss item: 0.6431211233139038
test loss item: 0.4831697642803192
test loss item: 0.3239939510822296
test loss item: 0.6917904615402222
test loss item: 0.6468290090560913
test loss item: 1.0052273273468018
test loss item: 0.3000010848045349
test loss item: 0.5213977098464966
test loss item: 0.578122615814209
test loss item: 0.6294636726379395
test loss item: 0.5888211131095886
test loss item: 0.3422567844390869
test loss item: 0.7158852219581604
test loss item: 0.8656120896339417
test loss item: 0.3080834448337555
test loss item: 1.3518414497375488
test loss item: 1.221479058265686
test loss item: 0.22763673961162567
test loss item: 0.3262714743614197
Epoch [6/50], Training Loss: 0.6146, Testing Loss: 0.6098
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/50
train loss item: 0.7267663478851318
train loss item: 0.5698537230491638
train loss item: 0.3592057526111603
train loss item: 0.43740877509117126
train loss item: 0.35417819023132324
train loss item: 0.7272497415542603
train loss item: 0.35835132002830505
train loss item: 0.9326810836791992
train loss item: 0.9248903393745422
train loss item: 0.6234329342842102
train loss item: 0.36931127309799194
train loss item: 0.493334025144577
train loss item: 0.5250651836395264
train loss item: 0.7816253304481506
train loss item: 0.25263822078704834
train loss item: 0.8849621415138245
train loss item: 0.42843177914619446
train loss item: 0.4001248776912689
train loss item: 0.27313631772994995
train loss item: 0.8361257910728455
train loss item: 0.3223380744457245
train loss item: 1.1158024072647095
train loss item: 0.44738849997520447
test loss item: 0.35534361004829407
test loss item: 0.8205820322036743
test loss item: 0.5750560164451599
test loss item: 0.23612353205680847
test loss item: 0.5341339707374573
test loss item: 0.4210301637649536
test loss item: 0.33473560214042664
test loss item: 0.6047075986862183
test loss item: 0.5386766195297241
test loss item: 0.8434469699859619
test loss item: 0.28982749581336975
test loss item: 0.48102158308029175
test loss item: 0.5347752571105957
test loss item: 0.5691784620285034
test loss item: 0.4893149733543396
test loss item: 0.3581183850765228
test loss item: 0.6084527373313904
test loss item: 0.6960432529449463
test loss item: 0.30789896845817566
test loss item: 1.0774197578430176
test loss item: 0.9705296754837036
test loss item: 0.25533992052078247
test loss item: 0.12977609038352966
Epoch [7/50], Training Loss: 0.5715, Testing Loss: 0.5231
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/50
train loss item: 0.7272899746894836
train loss item: 0.5872588753700256
train loss item: 0.38175132870674133
train loss item: 0.4086724817752838
train loss item: 0.3289783000946045
train loss item: 0.7345446944236755
train loss item: 0.3569645285606384
train loss item: 0.9701979160308838
train loss item: 0.8142133951187134
train loss item: 0.4673137366771698
train loss item: 0.32667258381843567
train loss item: 0.42710763216018677
train loss item: 0.5883377194404602
train loss item: 0.6467156410217285
train loss item: 0.2946280837059021
train loss item: 0.8614826798439026
train loss item: 0.4490787088871002
train loss item: 0.2939826548099518
train loss item: 0.2462325543165207
train loss item: 0.8020029664039612
train loss item: 0.3233439028263092
train loss item: 0.9952220320701599
train loss item: 0.4318726062774658
test loss item: 0.34055477380752563
test loss item: 0.8369766473770142
test loss item: 0.6396313905715942
test loss item: 0.20721422135829926
test loss item: 0.6207358241081238
test loss item: 0.385470449924469
test loss item: 0.32290613651275635
test loss item: 0.6486676335334778
test loss item: 0.6326549649238586
test loss item: 0.9069697260856628
test loss item: 0.2713780999183655
test loss item: 0.4668465554714203
test loss item: 0.5623326897621155
test loss item: 0.6086522936820984
test loss item: 0.5785622000694275
test loss item: 0.34528642892837524
test loss item: 0.6217582821846008
test loss item: 0.8041443228721619
test loss item: 0.26715347170829773
test loss item: 1.1012139320373535
test loss item: 1.1010611057281494
test loss item: 0.2463863044977188
test loss item: 0.16404548287391663
Epoch [8/50], Training Loss: 0.5419, Testing Loss: 0.5513
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/50
train loss item: 0.7703940868377686
train loss item: 0.5334939360618591
train loss item: 0.3502785861492157
train loss item: 0.37166568636894226
train loss item: 0.3334176540374756
train loss item: 0.6909460425376892
train loss item: 0.3532652258872986
train loss item: 1.1528801918029785
train loss item: 1.1219911575317383
train loss item: 0.37457677721977234
train loss item: 0.2805066406726837
train loss item: 0.40913480520248413
train loss item: 0.6329443454742432
train loss item: 0.5845546126365662
train loss item: 0.2534327805042267
train loss item: 0.7026832103729248
train loss item: 0.4263654351234436
train loss item: 0.33342379331588745
train loss item: 0.28184860944747925
train loss item: 0.7777411341667175
train loss item: 0.31234097480773926
train loss item: 1.240585446357727
train loss item: 0.35906389355659485
test loss item: 0.38935062289237976
test loss item: 0.7134092450141907
test loss item: 0.6531888842582703
test loss item: 0.23014195263385773
test loss item: 0.5027258992195129
test loss item: 0.35743141174316406
test loss item: 0.3176245391368866
test loss item: 0.6231414079666138
test loss item: 0.574480414390564
test loss item: 0.8561421632766724
test loss item: 0.2829223573207855
test loss item: 0.3987257182598114
test loss item: 0.5682259202003479
test loss item: 0.6067259311676025
test loss item: 0.4729430377483368
test loss item: 0.3445263206958771
test loss item: 0.4997222423553467
test loss item: 0.6403508186340332
test loss item: 0.255167692899704
test loss item: 0.9317166209220886
test loss item: 1.013117790222168
test loss item: 0.23527471721172333
test loss item: 0.26719924807548523
Epoch [9/50], Training Loss: 0.5499, Testing Loss: 0.5102
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/50
train loss item: 0.6217573285102844
train loss item: 0.5123216509819031
train loss item: 0.3515888750553131
train loss item: 0.4296025335788727
train loss item: 0.3172314167022705
train loss item: 0.6446788907051086
train loss item: 0.3274358808994293
train loss item: 0.7559594511985779
train loss item: 0.7494234442710876
train loss item: 0.37548062205314636
train loss item: 0.23544816672801971
train loss item: 0.34681645035743713
train loss item: 0.436846524477005
train loss item: 0.5363389849662781
train loss item: 0.21451492607593536
train loss item: 0.6683383584022522
train loss item: 0.4061759114265442
train loss item: 0.3436148166656494
train loss item: 0.2299022674560547
train loss item: 0.7213573455810547
train loss item: 0.26962706446647644
train loss item: 0.842467188835144
train loss item: 0.3741322457790375
test loss item: 0.2845813035964966
test loss item: 0.5847358703613281
test loss item: 0.4401687681674957
test loss item: 0.15670783817768097
test loss item: 0.39349016547203064
test loss item: 0.33488333225250244
test loss item: 0.23750367760658264
test loss item: 0.44855281710624695
test loss item: 0.4153664708137512
test loss item: 0.63017338514328
test loss item: 0.23151730000972748
test loss item: 0.35347431898117065
test loss item: 0.3843998312950134
test loss item: 0.42891648411750793
test loss item: 0.33463162183761597
test loss item: 0.26053428649902344
test loss item: 0.4134325385093689
test loss item: 0.5011799335479736
test loss item: 0.23628869652748108
test loss item: 0.7150332927703857
test loss item: 0.6951538324356079
test loss item: 0.16753438115119934
test loss item: 0.17316603660583496
Epoch [10/50], Training Loss: 0.4657, Testing Loss: 0.3835
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 11/50
train loss item: 0.6239217519760132
train loss item: 0.4374662935733795
train loss item: 0.31729674339294434
train loss item: 0.36691999435424805
train loss item: 0.2912686765193939
train loss item: 0.574586808681488
train loss item: 0.29416748881340027
train loss item: 0.7117205262184143
train loss item: 0.5692862868309021
train loss item: 0.4640662372112274
train loss item: 0.25078970193862915
train loss item: 0.31295180320739746
train loss item: 0.440468430519104
train loss item: 0.526085615158081
train loss item: 0.20879779756069183
train loss item: 0.706867516040802
train loss item: 0.30493980646133423
train loss item: 0.2682536244392395
train loss item: 0.21056616306304932
train loss item: 0.6218894720077515
train loss item: 0.24763919413089752
train loss item: 0.6863712668418884
train loss item: 0.3771902024745941
test loss item: 0.25996941328048706
test loss item: 0.4953483045101166
test loss item: 0.3964201509952545
test loss item: 0.14188705384731293
test loss item: 0.340616375207901
test loss item: 0.29626592993736267
test loss item: 0.2192833423614502
test loss item: 0.39411574602127075
test loss item: 0.3625562787055969
test loss item: 0.5636076331138611
test loss item: 0.21532180905342102
test loss item: 0.3164033889770508
test loss item: 0.3314795196056366
test loss item: 0.38096708059310913
test loss item: 0.29080694913864136
test loss item: 0.24693511426448822
test loss item: 0.39966827630996704
test loss item: 0.41764092445373535
test loss item: 0.206881582736969
test loss item: 0.7130351066589355
test loss item: 0.6341637969017029
test loss item: 0.15532948076725006
test loss item: 0.13827694952487946
Epoch [11/50], Training Loss: 0.4267, Testing Loss: 0.3442
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 12/50
train loss item: 0.723168671131134
train loss item: 0.41939157247543335
train loss item: 0.2668781578540802
train loss item: 0.35764363408088684
train loss item: 0.3057985007762909
train loss item: 0.6058644652366638
train loss item: 0.29556944966316223
train loss item: 1.027614951133728
train loss item: 0.9764856100082397
train loss item: 0.36523038148880005
train loss item: 0.2498297393321991
train loss item: 0.3943484127521515
train loss item: 0.6269732117652893
train loss item: 0.494305282831192
train loss item: 0.20523139834403992
train loss item: 0.6079903841018677
train loss item: 0.3065178692340851
train loss item: 0.2498192936182022
train loss item: 0.20995377004146576
train loss item: 0.5817435383796692
train loss item: 0.2601989507675171
train loss item: 1.0243887901306152
train loss item: 0.35914134979248047
test loss item: 0.3125884532928467
test loss item: 0.7003306150436401
test loss item: 0.5794586539268494
test loss item: 0.15840968489646912
test loss item: 0.5172861814498901
test loss item: 0.30346518754959106
test loss item: 0.2741757333278656
test loss item: 0.5623692274093628
test loss item: 0.5479605197906494
test loss item: 0.7796016335487366
test loss item: 0.2397298961877823
test loss item: 0.38658004999160767
test loss item: 0.5089015364646912
test loss item: 0.5387187004089355
test loss item: 0.47128286957740784
test loss item: 0.27957358956336975
test loss item: 0.47035151720046997
test loss item: 0.6603280901908875
test loss item: 0.23214305937290192
test loss item: 0.7958348393440247
test loss item: 0.9530887007713318
test loss item: 0.19346758723258972
test loss item: 0.18945039808750153
Epoch [12/50], Training Loss: 0.4745, Testing Loss: 0.4633
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 13/50
train loss item: 0.523550808429718
train loss item: 0.39514604210853577
train loss item: 0.2691616117954254
train loss item: 0.34232616424560547
train loss item: 0.3015027344226837
train loss item: 0.5460984110832214
train loss item: 0.2872086763381958
train loss item: 0.6201736927032471
train loss item: 0.551821231842041
train loss item: 0.3719647526741028
train loss item: 0.23449541628360748
train loss item: 0.3271668255329132
train loss item: 0.36025702953338623
train loss item: 0.38937851786613464
train loss item: 0.1870482712984085
train loss item: 0.5470423102378845
train loss item: 0.3868390619754791
train loss item: 0.28423619270324707
train loss item: 0.19752945005893707
train loss item: 0.6917321681976318
train loss item: 0.22880129516124725
train loss item: 0.7305253148078918
train loss item: 0.2951447069644928
test loss item: 0.28530532121658325
test loss item: 0.9110441207885742
test loss item: 0.5518559813499451
test loss item: 0.20118500292301178
test loss item: 0.617883026599884
test loss item: 0.358574777841568
test loss item: 0.2967339754104614
test loss item: 0.6111057996749878
test loss item: 0.5807419419288635
test loss item: 0.8034182190895081
test loss item: 0.24740657210350037
test loss item: 0.46380090713500977
test loss item: 0.5503285527229309
test loss item: 0.5117436051368713
test loss item: 0.5536900162696838
test loss item: 0.3247326910495758
test loss item: 0.5409203767776489
test loss item: 0.8185858726501465
test loss item: 0.28845706582069397
test loss item: 0.7088980078697205
test loss item: 0.9818060398101807
test loss item: 0.22266152501106262
test loss item: 0.1220865473151207
Epoch [13/50], Training Loss: 0.3943, Testing Loss: 0.5023
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 14/50
train loss item: 0.6107270121574402
train loss item: 0.4439106285572052
train loss item: 0.3428708612918854
train loss item: 0.3142639994621277
train loss item: 0.26171553134918213
train loss item: 0.5209960341453552
train loss item: 0.2713581621646881
train loss item: 0.587709903717041
train loss item: 0.4422902464866638
train loss item: 0.2799735367298126
train loss item: 0.1746586412191391
train loss item: 0.24263082444667816
train loss item: 0.37674951553344727
train loss item: 0.4059528112411499
train loss item: 0.18178389966487885
train loss item: 0.47954702377319336
train loss item: 0.3013119399547577
train loss item: 0.22175545990467072
train loss item: 0.17613793909549713
train loss item: 0.5938990712165833
train loss item: 0.21667549014091492
train loss item: 0.6149157881736755
train loss item: 0.2823074758052826
test loss item: 0.23701179027557373
test loss item: 0.4866437315940857
test loss item: 0.34296566247940063
test loss item: 0.13716764748096466
test loss item: 0.3202938139438629
test loss item: 0.28285250067710876
test loss item: 0.21508358418941498
test loss item: 0.3538147211074829
test loss item: 0.3405279517173767
test loss item: 0.4920012354850769
test loss item: 0.1923178881406784
test loss item: 0.2965873181819916
test loss item: 0.30829918384552
test loss item: 0.3507283329963684
test loss item: 0.2835199534893036
test loss item: 0.21495744585990906
test loss item: 0.36720144748687744
test loss item: 0.4044802784919739
test loss item: 0.20006445050239563
test loss item: 0.5573975443840027
test loss item: 0.5632557272911072
test loss item: 0.16974416375160217
test loss item: 0.17806468904018402
Epoch [14/50], Training Loss: 0.3628, Testing Loss: 0.3172
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 15/50
train loss item: 0.5697202086448669
train loss item: 0.4079497754573822
train loss item: 0.25917187333106995
train loss item: 0.3057877719402313
train loss item: 0.25150182843208313
train loss item: 0.5495480298995972
train loss item: 0.25236228108406067
train loss item: 0.9325029253959656
train loss item: 0.7433618307113647
train loss item: 0.35085636377334595
train loss item: 0.22412197291851044
train loss item: 0.3937318027019501
train loss item: 0.5322188138961792
train loss item: 0.5444733500480652
train loss item: 0.22774890065193176
train loss item: 0.6013886332511902
train loss item: 0.3103809058666229
train loss item: 0.2523801326751709
train loss item: 0.18903030455112457
train loss item: 0.5578941702842712
train loss item: 0.2109857052564621
train loss item: 0.8772233724594116
train loss item: 0.33156904578208923
test loss item: 0.320600301027298
test loss item: 0.7575326561927795
test loss item: 0.6067105531692505
test loss item: 0.17670176923274994
test loss item: 0.5794807076454163
test loss item: 0.29875683784484863
test loss item: 0.26915469765663147
test loss item: 0.581546425819397
test loss item: 0.6108172535896301
test loss item: 0.8381473422050476
test loss item: 0.2248651385307312
test loss item: 0.37664490938186646
test loss item: 0.5148101449012756
test loss item: 0.5468782186508179
test loss item: 0.5499358773231506
test loss item: 0.2729811668395996
test loss item: 0.47861045598983765
test loss item: 0.7514841556549072
test loss item: 0.24124541878700256
test loss item: 0.8469224572181702
test loss item: 1.0287834405899048
test loss item: 0.22187000513076782
test loss item: 0.13460229337215424
Epoch [15/50], Training Loss: 0.4294, Testing Loss: 0.4882
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 16/50
train loss item: 0.524272620677948
train loss item: 0.3693205714225769
train loss item: 0.27047958970069885
train loss item: 0.29190248250961304
train loss item: 0.24324068427085876
train loss item: 0.5029686093330383
train loss item: 0.25919196009635925
train loss item: 0.5948578119277954
train loss item: 0.490847110748291
train loss item: 0.3067469596862793
train loss item: 0.18983128666877747
train loss item: 0.29200279712677
train loss item: 0.30088186264038086
train loss item: 0.3405331075191498
train loss item: 0.20148999989032745
train loss item: 0.4353746175765991
train loss item: 0.336061030626297
train loss item: 0.24438156187534332
train loss item: 0.1808416098356247
train loss item: 0.6325535178184509
train loss item: 0.2557312250137329
train loss item: 0.704059362411499
train loss item: 0.26359429955482483
test loss item: 0.2393864393234253
test loss item: 0.5454072952270508
test loss item: 0.39659374952316284
test loss item: 0.13190117478370667
test loss item: 0.3611680269241333
test loss item: 0.26251158118247986
test loss item: 0.20897236466407776
test loss item: 0.41048097610473633
test loss item: 0.3848353922367096
test loss item: 0.5490026473999023
test loss item: 0.196166530251503
test loss item: 0.28902339935302734
test loss item: 0.36088210344314575
test loss item: 0.38460710644721985
test loss item: 0.3193880319595337
test loss item: 0.22625420987606049
test loss item: 0.344720721244812
test loss item: 0.4595409333705902
test loss item: 0.1854749470949173
test loss item: 0.547283411026001
test loss item: 0.6481337547302246
test loss item: 0.1592046022415161
test loss item: 0.12454281002283096
Epoch [16/50], Training Loss: 0.3579, Testing Loss: 0.3363
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 17/50
train loss item: 0.4445728361606598
train loss item: 0.3200465142726898
train loss item: 0.2573886215686798
train loss item: 0.2859423756599426
train loss item: 0.21497595310211182
train loss item: 0.3675329387187958
train loss item: 0.2213885486125946
train loss item: 0.5303993225097656
train loss item: 0.47291848063468933
train loss item: 0.21358366310596466
train loss item: 0.18173173069953918
train loss item: 0.3040318191051483
train loss item: 0.3098025619983673
train loss item: 0.45368340611457825
train loss item: 0.1438298225402832
train loss item: 0.4047917127609253
train loss item: 0.38200950622558594
train loss item: 0.254922091960907
train loss item: 0.18378984928131104
train loss item: 0.574084997177124
train loss item: 0.2681257128715515
train loss item: 0.507729172706604
train loss item: 0.22961047291755676
test loss item: 0.20597098767757416
test loss item: 0.441398561000824
test loss item: 0.2933010458946228
test loss item: 0.12887613475322723
test loss item: 0.261432409286499
test loss item: 0.2262544333934784
test loss item: 0.17119522392749786
test loss item: 0.31344303488731384
test loss item: 0.29727432131767273
test loss item: 0.42242899537086487
test loss item: 0.16181200742721558
test loss item: 0.22826538980007172
test loss item: 0.26952460408210754
test loss item: 0.2922098934650421
test loss item: 0.24000339210033417
test loss item: 0.17937730252742767
test loss item: 0.30653244256973267
test loss item: 0.3427494466304779
test loss item: 0.16043220460414886
test loss item: 0.4924543797969818
test loss item: 0.4916258156299591
test loss item: 0.13459879159927368
test loss item: 0.17363868653774261
Epoch [17/50], Training Loss: 0.3273, Testing Loss: 0.2711
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 18/50
train loss item: 0.4376944303512573
train loss item: 0.3140890300273895
train loss item: 0.2242245376110077
train loss item: 0.30477020144462585
train loss item: 0.20190532505512238
train loss item: 0.34834346175193787
train loss item: 0.19319060444831848
train loss item: 0.4914502501487732
train loss item: 0.44423434138298035
train loss item: 0.21004892885684967
train loss item: 0.17604467272758484
train loss item: 0.2958518862724304
train loss item: 0.35138005018234253
train loss item: 0.5903953909873962
train loss item: 0.1495530903339386
train loss item: 0.48639756441116333
train loss item: 0.3354856073856354
train loss item: 0.2744126617908478
train loss item: 0.20530787110328674
train loss item: 0.5493718981742859
train loss item: 0.2998276352882385
train loss item: 0.5272917151451111
train loss item: 0.25854188203811646
test loss item: 0.23686367273330688
test loss item: 0.41027507185935974
test loss item: 0.3592914938926697
test loss item: 0.153448224067688
test loss item: 0.2919129729270935
test loss item: 0.2546938955783844
test loss item: 0.19998249411582947
test loss item: 0.35750603675842285
test loss item: 0.34423062205314636
test loss item: 0.484214723110199
test loss item: 0.17630481719970703
test loss item: 0.2647855877876282
test loss item: 0.33671438694000244
test loss item: 0.36803001165390015
test loss item: 0.26893186569213867
test loss item: 0.20652680099010468
test loss item: 0.35005131363868713
test loss item: 0.3633163273334503
test loss item: 0.17085948586463928
test loss item: 0.6167884469032288
test loss item: 0.5718469619750977
test loss item: 0.15103580057621002
test loss item: 0.1818690001964569
Epoch [18/50], Training Loss: 0.3335, Testing Loss: 0.3095
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 19/50
train loss item: 0.42336222529411316
train loss item: 0.3230818510055542
train loss item: 0.24179880321025848
train loss item: 0.30925270915031433
train loss item: 0.2263765186071396
train loss item: 0.4421465992927551
train loss item: 0.20234748721122742
train loss item: 0.4767149090766907
train loss item: 0.3923914432525635
train loss item: 0.3501451313495636
train loss item: 0.17381693422794342
train loss item: 0.22252054512500763
train loss item: 0.3041543960571289
train loss item: 0.33390718698501587
train loss item: 0.16638866066932678
train loss item: 0.5163837671279907
train loss item: 0.25056150555610657
train loss item: 0.2064030021429062
train loss item: 0.1423715054988861
train loss item: 0.4303828477859497
train loss item: 0.2080608606338501
train loss item: 0.5215128064155579
train loss item: 0.2600763440132141
test loss item: 0.17413245141506195
test loss item: 0.42841818928718567
test loss item: 0.24280643463134766
test loss item: 0.1057373434305191
test loss item: 0.25292477011680603
test loss item: 0.22646783292293549
test loss item: 0.15611650049686432
test loss item: 0.2662123143672943
test loss item: 0.2390015870332718
test loss item: 0.3632090091705322
test loss item: 0.1580837070941925
test loss item: 0.21108396351337433
test loss item: 0.20829345285892487
test loss item: 0.22945816814899445
test loss item: 0.21168798208236694
test loss item: 0.16462992131710052
test loss item: 0.27973127365112305
test loss item: 0.33922818303108215
test loss item: 0.17687678337097168
test loss item: 0.3511240780353546
test loss item: 0.4088115394115448
test loss item: 0.1189117431640625
test loss item: 0.13195398449897766
Epoch [19/50], Training Loss: 0.3097, Testing Loss: 0.2367
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 20/50
train loss item: 0.5291051268577576
train loss item: 0.2647283971309662
train loss item: 0.18964628875255585
train loss item: 0.3461487889289856
train loss item: 0.25637274980545044
train loss item: 0.5511115789413452
train loss item: 0.24754935503005981
train loss item: 0.607957124710083
train loss item: 0.37709930539131165
train loss item: 0.4349079728126526
train loss item: 0.286448210477829
train loss item: 0.4271252155303955
train loss item: 0.4495856761932373
train loss item: 0.5465417504310608
train loss item: 0.15701504051685333
train loss item: 0.45702603459358215
train loss item: 0.22807854413986206
train loss item: 0.25045856833457947
train loss item: 0.1526128351688385
train loss item: 0.609423041343689
train loss item: 0.1872200220823288
train loss item: 0.9163848757743835
train loss item: 0.290439635515213
test loss item: 0.29999393224716187
test loss item: 0.750943660736084
test loss item: 0.5598466396331787
test loss item: 0.15285831689834595
test loss item: 0.5769884586334229
test loss item: 0.27972251176834106
test loss item: 0.2158380150794983
test loss item: 0.5359488725662231
test loss item: 0.5583146214485168
test loss item: 0.8148514628410339
test loss item: 0.17160846292972565
test loss item: 0.3708800971508026
test loss item: 0.495581716299057
test loss item: 0.4842667579650879
test loss item: 0.5545213222503662
test loss item: 0.2523062527179718
test loss item: 0.5187549591064453
test loss item: 0.7511069774627686
test loss item: 0.1890355795621872
test loss item: 0.9295048713684082
test loss item: 1.0072499513626099
test loss item: 0.1675247848033905
test loss item: 0.0950416699051857
Epoch [20/50], Training Loss: 0.3810, Testing Loss: 0.4666
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 21/50
train loss item: 0.4637114107608795
train loss item: 0.379251092672348
train loss item: 0.3104775547981262
train loss item: 0.25812840461730957
train loss item: 0.20703597366809845
train loss item: 0.4671940803527832
train loss item: 0.2651469111442566
train loss item: 0.5996124148368835
train loss item: 0.4288795590400696
train loss item: 0.3278915286064148
train loss item: 0.23784060776233673
train loss item: 0.4705028235912323
train loss item: 0.40376609563827515
train loss item: 0.5493590235710144
train loss item: 0.22906054556369781
train loss item: 0.5172973275184631
train loss item: 0.41398757696151733
train loss item: 0.27587324380874634
train loss item: 0.19706201553344727
train loss item: 0.5821717381477356
train loss item: 0.2940339744091034
train loss item: 0.41331812739372253
train loss item: 0.36378100514411926
test loss item: 0.26810890436172485
test loss item: 0.4938206374645233
test loss item: 0.37875595688819885
test loss item: 0.11731290817260742
test loss item: 0.29677078127861023
test loss item: 0.26468050479888916
test loss item: 0.18718405067920685
test loss item: 0.3784230947494507
test loss item: 0.29750603437423706
test loss item: 0.5434313416481018
test loss item: 0.20452357828617096
test loss item: 0.26709094643592834
test loss item: 0.31278252601623535
test loss item: 0.34798476099967957
test loss item: 0.2641691565513611
test loss item: 0.21234579384326935
test loss item: 0.4251876771450043
test loss item: 0.409099817276001
test loss item: 0.2438305914402008
test loss item: 0.7720059156417847
test loss item: 0.6775578856468201
test loss item: 0.1478927731513977
test loss item: 0.13794435560703278
Epoch [21/50], Training Loss: 0.3763, Testing Loss: 0.3325
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 22/50
train loss item: 0.7539589405059814
train loss item: 0.4466768503189087
train loss item: 0.19049011170864105
train loss item: 0.2886033356189728
train loss item: 0.23156315088272095
train loss item: 0.5604615211486816
train loss item: 0.26717615127563477
train loss item: 1.011728048324585
train loss item: 1.1142175197601318
train loss item: 0.36749595403671265
train loss item: 0.18711264431476593
train loss item: 0.33136436343193054
train loss item: 0.250784307718277
train loss item: 0.27446091175079346
train loss item: 0.17283271253108978
train loss item: 0.3528393805027008
train loss item: 0.31943583488464355
train loss item: 0.20855452120304108
train loss item: 0.128828227519989
train loss item: 0.559001624584198
train loss item: 0.2005666345357895
train loss item: 0.4655899703502655
train loss item: 0.2177848368883133
test loss item: 0.15470753610134125
test loss item: 0.3471662700176239
test loss item: 0.22286927700042725
test loss item: 0.10621875524520874
test loss item: 0.1985214203596115
test loss item: 0.17970573902130127
test loss item: 0.13325758278369904
test loss item: 0.23384232819080353
test loss item: 0.21082817018032074
test loss item: 0.3225443363189697
test loss item: 0.1332901567220688
test loss item: 0.177312433719635
test loss item: 0.19619505107402802
test loss item: 0.2103283405303955
test loss item: 0.18276965618133545
test loss item: 0.1456044465303421
test loss item: 0.24261273443698883
test loss item: 0.26152855157852173
test loss item: 0.12808960676193237
test loss item: 0.38295164704322815
test loss item: 0.37015634775161743
test loss item: 0.10626731067895889
test loss item: 0.108486108481884
Epoch [22/50], Training Loss: 0.3870, Testing Loss: 0.2068
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 23/50
train loss item: 0.38960763812065125
train loss item: 0.2653416395187378
train loss item: 0.2033117115497589
train loss item: 0.21891339123249054
train loss item: 0.15036344528198242
train loss item: 0.29451784491539
train loss item: 0.17444609105587006
train loss item: 0.38816943764686584
train loss item: 0.3262910544872284
train loss item: 0.20432773232460022
train loss item: 0.1402297168970108
train loss item: 0.22550466656684875
train loss item: 0.22519055008888245
train loss item: 0.25452715158462524
train loss item: 0.122749924659729
train loss item: 0.29073160886764526
train loss item: 0.26261579990386963
train loss item: 0.17309674620628357
train loss item: 0.11818130314350128
train loss item: 0.4269365072250366
train loss item: 0.1963532567024231
train loss item: 0.3978787958621979
train loss item: 0.21207597851753235
test loss item: 0.1493568867444992
test loss item: 0.2731728255748749
test loss item: 0.20545339584350586
test loss item: 0.09171567857265472
test loss item: 0.17707058787345886
test loss item: 0.1633007675409317
test loss item: 0.12565860152244568
test loss item: 0.20203551650047302
test loss item: 0.18951427936553955
test loss item: 0.28703802824020386
test loss item: 0.11996965110301971
test loss item: 0.1622333824634552
test loss item: 0.17766593396663666
test loss item: 0.1980307400226593
test loss item: 0.16245436668395996
test loss item: 0.12789173424243927
test loss item: 0.21795576810836792
test loss item: 0.2145298719406128
test loss item: 0.11534586548805237
test loss item: 0.34191492199897766
test loss item: 0.3209380805492401
test loss item: 0.10453745722770691
test loss item: 0.10951013118028641
Epoch [23/50], Training Loss: 0.2461, Testing Loss: 0.1842
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 24/50
train loss item: 0.3176742494106293
train loss item: 0.20150533318519592
train loss item: 0.145430788397789
train loss item: 0.2123376727104187
train loss item: 0.15522807836532593
train loss item: 0.2568950653076172
train loss item: 0.1435536891222
train loss item: 0.33829525113105774
train loss item: 0.30122849345207214
train loss item: 0.2028949111700058
train loss item: 0.14131949841976166
train loss item: 0.19610878825187683
train loss item: 0.26156580448150635
train loss item: 0.2964387536048889
train loss item: 0.1066475436091423
train loss item: 0.2741226851940155
train loss item: 0.20516054332256317
train loss item: 0.148502379655838
train loss item: 0.13753587007522583
train loss item: 0.35209745168685913
train loss item: 0.12303388863801956
train loss item: 0.43332257866859436
train loss item: 0.1984557956457138
test loss item: 0.13974998891353607
test loss item: 0.2977239191532135
test loss item: 0.1837732195854187
test loss item: 0.08787640929222107
test loss item: 0.15802526473999023
test loss item: 0.15058016777038574
test loss item: 0.12675830721855164
test loss item: 0.1917562633752823
test loss item: 0.1726035624742508
test loss item: 0.24834851920604706
test loss item: 0.11519356817007065
test loss item: 0.1473064422607422
test loss item: 0.15036702156066895
test loss item: 0.1703072190284729
test loss item: 0.1384686529636383
test loss item: 0.11762817203998566
test loss item: 0.19153866171836853
test loss item: 0.2055557370185852
test loss item: 0.11926499009132385
test loss item: 0.2591092884540558
test loss item: 0.27887678146362305
test loss item: 0.10556057095527649
test loss item: 0.09843628108501434
Epoch [24/50], Training Loss: 0.2239, Testing Loss: 0.1676
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 25/50
train loss item: 0.2922501564025879
train loss item: 0.18380875885486603
train loss item: 0.14909350872039795
train loss item: 0.1665058583021164
train loss item: 0.14362287521362305
train loss item: 0.24839575588703156
train loss item: 0.12364739179611206
train loss item: 0.3352915644645691
train loss item: 0.3488205671310425
train loss item: 0.2373366504907608
train loss item: 0.12451812624931335
train loss item: 0.16800789535045624
train loss item: 0.2619551718235016
train loss item: 0.2493855059146881
train loss item: 0.10636544227600098
train loss item: 0.29125091433525085
train loss item: 0.15394777059555054
train loss item: 0.14103960990905762
train loss item: 0.12659059464931488
train loss item: 0.303959459066391
train loss item: 0.12464101612567902
train loss item: 0.5644734501838684
train loss item: 0.1671537309885025
test loss item: 0.16306738555431366
test loss item: 0.26864299178123474
test loss item: 0.18799391388893127
test loss item: 0.10761149972677231
test loss item: 0.16203279793262482
test loss item: 0.14865657687187195
test loss item: 0.1342879682779312
test loss item: 0.19125889241695404
test loss item: 0.18404719233512878
test loss item: 0.2591805160045624
test loss item: 0.12971468269824982
test loss item: 0.1406257003545761
test loss item: 0.1496996432542801
test loss item: 0.1778922975063324
test loss item: 0.14937467873096466
test loss item: 0.11919618397951126
test loss item: 0.19839392602443695
test loss item: 0.20704962313175201
test loss item: 0.12743547558784485
test loss item: 0.33894026279449463
test loss item: 0.28924110531806946
test loss item: 0.1340319812297821
test loss item: 0.09488536417484283
Epoch [25/50], Training Loss: 0.2179, Testing Loss: 0.1767
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 26/50
train loss item: 0.289721816778183
train loss item: 0.170511394739151
train loss item: 0.18827050924301147
train loss item: 0.19727584719657898
train loss item: 0.176268070936203
train loss item: 0.24995586276054382
train loss item: 0.16491565108299255
train loss item: 0.3047962486743927
train loss item: 0.32042086124420166
train loss item: 0.25336208939552307
train loss item: 0.17564885318279266
train loss item: 0.29678279161453247
train loss item: 0.2300051897764206
train loss item: 0.2818794548511505
train loss item: 0.1158088967204094
train loss item: 0.30763110518455505
train loss item: 0.21460793912410736
train loss item: 0.1761634349822998
train loss item: 0.09212485700845718
train loss item: 0.32220131158828735
train loss item: 0.19929394125938416
train loss item: 0.2929397225379944
train loss item: 0.1443101167678833
test loss item: 0.13734287023544312
test loss item: 0.30613037943840027
test loss item: 0.19821512699127197
test loss item: 0.08756696432828903
test loss item: 0.15589210391044617
test loss item: 0.1375754475593567
test loss item: 0.10943449288606644
test loss item: 0.21091727912425995
test loss item: 0.17549513280391693
test loss item: 0.26794299483299255
test loss item: 0.10294973850250244
test loss item: 0.12986986339092255
test loss item: 0.15992267429828644
test loss item: 0.17935389280319214
test loss item: 0.14394988119602203
test loss item: 0.10618733614683151
test loss item: 0.18702790141105652
test loss item: 0.21927034854888916
test loss item: 0.09792476892471313
test loss item: 0.3102180063724518
test loss item: 0.31138256192207336
test loss item: 0.09351299703121185
test loss item: 0.10103022307157516
Epoch [26/50], Training Loss: 0.2246, Testing Loss: 0.1708
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 27/50
train loss item: 0.2743491530418396
train loss item: 0.1779080033302307
train loss item: 0.15444739162921906
train loss item: 0.2042655050754547
train loss item: 0.16157372295856476
train loss item: 0.25106990337371826
train loss item: 0.17578667402267456
train loss item: 0.3456553518772125
train loss item: 0.3027516007423401
train loss item: 0.2468952238559723
train loss item: 0.21087966859340668
train loss item: 0.39686089754104614
train loss item: 0.364775151014328
train loss item: 1.0184059143066406
train loss item: 0.17967034876346588
train loss item: 0.7678374648094177
train loss item: 0.19996437430381775
train loss item: 0.2269296795129776
train loss item: 0.13341473042964935
train loss item: 0.3191620111465454
train loss item: 0.1491563618183136
train loss item: 0.3723280131816864
train loss item: 0.2593837082386017
test loss item: 0.18898944556713104
test loss item: 0.5714703798294067
test loss item: 0.42550691962242126
test loss item: 0.14759808778762817
test loss item: 0.4688051640987396
test loss item: 0.21572524309158325
test loss item: 0.19271472096443176
test loss item: 0.42819494009017944
test loss item: 0.46863847970962524
test loss item: 0.5786827802658081
test loss item: 0.16492898762226105
test loss item: 0.29523178935050964
test loss item: 0.3676987290382385
test loss item: 0.35813307762145996
test loss item: 0.4375460147857666
test loss item: 0.17921927571296692
test loss item: 0.34803301095962524
test loss item: 0.6100450158119202
test loss item: 0.17436745762825012
test loss item: 0.5175535678863525
test loss item: 0.7272332310676575
test loss item: 0.15249229967594147
test loss item: 0.18588756024837494
Epoch [27/50], Training Loss: 0.2997, Testing Loss: 0.3567
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 28/50
train loss item: 0.4302394390106201
train loss item: 0.30966711044311523
train loss item: 0.2259691208600998
train loss item: 0.23570165038108826
train loss item: 0.17878328263759613
train loss item: 0.4091865122318268
train loss item: 0.1912701278924942
train loss item: 0.3715936839580536
train loss item: 0.31734007596969604
train loss item: 0.5243076086044312
train loss item: 0.17917872965335846
train loss item: 0.2602689564228058
train loss item: 0.22306877374649048
train loss item: 0.2461673617362976
train loss item: 0.15985475480556488
train loss item: 0.39083755016326904
train loss item: 0.22280988097190857
train loss item: 0.20192179083824158
train loss item: 0.12626981735229492
train loss item: 0.4114597737789154
train loss item: 0.13019460439682007
train loss item: 0.5846640467643738
train loss item: 0.27878525853157043
test loss item: 0.1744425892829895
test loss item: 0.3690631091594696
test loss item: 0.25754934549331665
test loss item: 0.11252691596746445
test loss item: 0.2524198889732361
test loss item: 0.18412978947162628
test loss item: 0.13955357670783997
test loss item: 0.2488941103219986
test loss item: 0.21657784283161163
test loss item: 0.3689490258693695
test loss item: 0.12436401098966599
test loss item: 0.21147719025611877
test loss item: 0.225608691573143
test loss item: 0.22654984891414642
test loss item: 0.22040197253227234
test loss item: 0.15550179779529572
test loss item: 0.2799573242664337
test loss item: 0.32270386815071106
test loss item: 0.15851803123950958
test loss item: 0.466924250125885
test loss item: 0.4329252541065216
test loss item: 0.11383713781833649
test loss item: 0.0707789808511734
Epoch [28/50], Training Loss: 0.2874, Testing Loss: 0.2319
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 29/50
train loss item: 0.353631854057312
train loss item: 0.2912340462207794
train loss item: 0.2896672189235687
train loss item: 0.2211904525756836
train loss item: 0.14353591203689575
train loss item: 0.3238942623138428
train loss item: 0.20606587827205658
train loss item: 0.47233906388282776
train loss item: 0.27970197796821594
train loss item: 0.15766572952270508
train loss item: 0.15519030392169952
train loss item: 0.2892625629901886
train loss item: 0.23362989723682404
train loss item: 0.2848597764968872
train loss item: 0.1340048611164093
train loss item: 0.27254924178123474
train loss item: 0.23057982325553894
train loss item: 0.17223675549030304
train loss item: 0.09211685508489609
train loss item: 0.38824114203453064
train loss item: 0.16047027707099915
train loss item: 0.2993004024028778
train loss item: 0.18864929676055908
test loss item: 0.13799360394477844
test loss item: 0.30866891145706177
test loss item: 0.23091787099838257
test loss item: 0.08661875128746033
test loss item: 0.22100472450256348
test loss item: 0.14395858347415924
test loss item: 0.12544164061546326
test loss item: 0.22896023094654083
test loss item: 0.2179097831249237
test loss item: 0.3092244267463684
test loss item: 0.12956063449382782
test loss item: 0.16575172543525696
test loss item: 0.19118893146514893
test loss item: 0.20625048875808716
test loss item: 0.1872664988040924
test loss item: 0.12876364588737488
test loss item: 0.21452239155769348
test loss item: 0.27609938383102417
test loss item: 0.1318894624710083
test loss item: 0.3145175278186798
test loss item: 0.37088850140571594
test loss item: 0.09633339196443558
test loss item: 0.15360422432422638
Epoch [29/50], Training Loss: 0.2452, Testing Loss: 0.1990
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 30/50
train loss item: 0.2745727002620697
train loss item: 0.1745038479566574
train loss item: 0.1553567498922348
train loss item: 0.16982696950435638
train loss item: 0.1208534687757492
train loss item: 0.22819815576076508
train loss item: 0.12211227416992188
train loss item: 0.2724815011024475
train loss item: 0.28827357292175293
train loss item: 0.20334863662719727
train loss item: 0.10210686922073364
train loss item: 0.19389621913433075
train loss item: 0.22577863931655884
train loss item: 0.1754266768693924
train loss item: 0.10249923914670944
train loss item: 0.25178322196006775
train loss item: 0.12664833664894104
train loss item: 0.1382495015859604
train loss item: 0.09417886286973953
train loss item: 0.271211177110672
train loss item: 0.10733260959386826
train loss item: 0.3017866313457489
train loss item: 0.12643514573574066
test loss item: 0.12263166904449463
test loss item: 0.2874618470668793
test loss item: 0.2231818288564682
test loss item: 0.09653764963150024
test loss item: 0.2200823575258255
test loss item: 0.12906835973262787
test loss item: 0.1193782389163971
test loss item: 0.22387658059597015
test loss item: 0.2166789323091507
test loss item: 0.2892325520515442
test loss item: 0.10840514302253723
test loss item: 0.16274629533290863
test loss item: 0.19304780662059784
test loss item: 0.19383955001831055
test loss item: 0.1938919872045517
test loss item: 0.11905530840158463
test loss item: 0.19484452903270721
test loss item: 0.2745121121406555
test loss item: 0.10863780975341797
test loss item: 0.27380576729774475
test loss item: 0.35460397601127625
test loss item: 0.09254750609397888
test loss item: 0.09954267740249634
Epoch [30/50], Training Loss: 0.1838, Testing Loss: 0.1869
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 31/50
train loss item: 0.2530575692653656
train loss item: 0.1617296189069748
train loss item: 0.14455999433994293
train loss item: 0.15595199167728424
train loss item: 0.12371831387281418
train loss item: 0.21436242759227753
train loss item: 0.11529475450515747
train loss item: 0.1962168961763382
train loss item: 0.2404738813638687
train loss item: 0.23779524862766266
train loss item: 0.10438623279333115
train loss item: 0.17078325152397156
train loss item: 0.19518855214118958
train loss item: 0.1991768777370453
train loss item: 0.10060247033834457
train loss item: 0.1958155483007431
train loss item: 0.1199653148651123
train loss item: 0.09667624533176422
train loss item: 0.08033884316682816
train loss item: 0.1923714280128479
train loss item: 0.1275733858346939
train loss item: 0.24788005650043488
train loss item: 0.14113572239875793
test loss item: 0.10844602435827255
test loss item: 0.2834703028202057
test loss item: 0.14476878941059113
test loss item: 0.07412591576576233
test loss item: 0.14297804236412048
test loss item: 0.13133594393730164
test loss item: 0.09658714383840561
test loss item: 0.17300406098365784
test loss item: 0.12459039688110352
test loss item: 0.21069318056106567
test loss item: 0.10290941596031189
test loss item: 0.11734014004468918
test loss item: 0.13438552618026733
test loss item: 0.12575028836727142
test loss item: 0.12418845295906067
test loss item: 0.09664509445428848
test loss item: 0.16978947818279266
test loss item: 0.2111213505268097
test loss item: 0.11160895973443985
test loss item: 0.22628286480903625
test loss item: 0.24657899141311646
test loss item: 0.08080607652664185
test loss item: 0.08931335806846619
Epoch [31/50], Training Loss: 0.1659, Testing Loss: 0.1446
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 32/50
train loss item: 0.18298602104187012
train loss item: 0.1417359709739685
train loss item: 0.13486619293689728
train loss item: 0.15724897384643555
train loss item: 0.118562251329422
train loss item: 0.22432462871074677
train loss item: 0.11995486170053482
train loss item: 0.23617389798164368
train loss item: 0.3023555278778076
train loss item: 0.2209644764661789
train loss item: 0.12894681096076965
train loss item: 0.13720573484897614
train loss item: 0.21394750475883484
train loss item: 0.19634471833705902
train loss item: 0.10703533887863159
train loss item: 0.2168823778629303
train loss item: 0.14232711493968964
train loss item: 0.10422655194997787
train loss item: 0.09983468055725098
train loss item: 0.21689966320991516
train loss item: 0.1318560242652893
train loss item: 0.2924882769584656
train loss item: 0.13121500611305237
test loss item: 0.13461554050445557
test loss item: 0.19297100603580475
test loss item: 0.15033076703548431
test loss item: 0.11040343344211578
test loss item: 0.1282019019126892
test loss item: 0.12097401916980743
test loss item: 0.12020052969455719
test loss item: 0.15832632780075073
test loss item: 0.13757914304733276
test loss item: 0.18352152407169342
test loss item: 0.11388158053159714
test loss item: 0.12581764161586761
test loss item: 0.13185463845729828
test loss item: 0.14586690068244934
test loss item: 0.12294194102287292
test loss item: 0.10075098276138306
test loss item: 0.14717978239059448
test loss item: 0.16066931188106537
test loss item: 0.120503731071949
test loss item: 0.22813630104064941
test loss item: 0.2086159586906433
test loss item: 0.12214265763759613
test loss item: 0.08613773435354233
Epoch [32/50], Training Loss: 0.1721, Testing Loss: 0.1414
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 33/50
train loss item: 0.21567018330097198
train loss item: 0.15633559226989746
train loss item: 0.13263481855392456
train loss item: 0.15694819390773773
train loss item: 0.10778146237134933
train loss item: 0.16389518976211548
train loss item: 0.12739424407482147
train loss item: 0.23242709040641785
train loss item: 0.21196092665195465
train loss item: 0.16223976016044617
train loss item: 0.14844274520874023
train loss item: 0.22375190258026123
train loss item: 0.2668699026107788
train loss item: 0.2722328007221222
train loss item: 0.136918842792511
train loss item: 0.2203797996044159
train loss item: 0.1297590434551239
train loss item: 0.12209835648536682
train loss item: 0.09344278275966644
train loss item: 0.21864080429077148
train loss item: 0.15822336077690125
train loss item: 0.22653456032276154
train loss item: 0.1050698310136795
test loss item: 0.11910416930913925
test loss item: 0.1814962923526764
test loss item: 0.13617724180221558
test loss item: 0.08715610951185226
test loss item: 0.12665784358978271
test loss item: 0.1059044674038887
test loss item: 0.09837834537029266
test loss item: 0.1334965080022812
test loss item: 0.12637825310230255
test loss item: 0.17061157524585724
test loss item: 0.10559055209159851
test loss item: 0.09672477096319199
test loss item: 0.11792268604040146
test loss item: 0.1271275281906128
test loss item: 0.13145315647125244
test loss item: 0.09709646552801132
test loss item: 0.13685429096221924
test loss item: 0.1646440625190735
test loss item: 0.10203192383050919
test loss item: 0.19276677072048187
test loss item: 0.18752823770046234
test loss item: 0.10481702536344528
test loss item: 0.10338578373193741
Epoch [33/50], Training Loss: 0.1735, Testing Loss: 0.1284
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 34/50
train loss item: 0.20270104706287384
train loss item: 0.14638763666152954
train loss item: 0.14191623032093048
train loss item: 0.17601174116134644
train loss item: 0.13570773601531982
train loss item: 0.19849161803722382
train loss item: 0.1034829169511795
train loss item: 0.19959336519241333
train loss item: 0.2743799090385437
train loss item: 0.2592802047729492
train loss item: 0.12602530419826508
train loss item: 0.18811126053333282
train loss item: 0.15500298142433167
train loss item: 0.17891564965248108
train loss item: 0.09939810633659363
train loss item: 0.22737061977386475
train loss item: 0.13008341193199158
train loss item: 0.15616996586322784
train loss item: 0.07190275937318802
train loss item: 0.16017359495162964
train loss item: 0.17716065049171448
train loss item: 0.31289857625961304
train loss item: 0.157020702958107
test loss item: 0.12543778121471405
test loss item: 0.25740787386894226
test loss item: 0.19562965631484985
test loss item: 0.08924324065446854
test loss item: 0.1785895675420761
test loss item: 0.12899619340896606
test loss item: 0.10394881665706635
test loss item: 0.2089126855134964
test loss item: 0.18431231379508972
test loss item: 0.2572632431983948
test loss item: 0.11250418424606323
test loss item: 0.1361682265996933
test loss item: 0.16677357256412506
test loss item: 0.1765303909778595
test loss item: 0.15954779088497162
test loss item: 0.10526953637599945
test loss item: 0.16310575604438782
test loss item: 0.24226434528827667
test loss item: 0.10741126537322998
test loss item: 0.29048117995262146
test loss item: 0.31392529606819153
test loss item: 0.09126298129558563
test loss item: 0.10632725805044174
Epoch [34/50], Training Loss: 0.1730, Testing Loss: 0.1696
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 35/50
train loss item: 0.2305622547864914
train loss item: 0.16859997808933258
train loss item: 0.1439039409160614
train loss item: 0.20628148317337036
train loss item: 0.14469020068645477
train loss item: 0.31435146927833557
train loss item: 0.14655999839305878
train loss item: 0.3060709536075592
train loss item: 0.17765110731124878
train loss item: 0.20273827016353607
train loss item: 0.157184898853302
train loss item: 0.3118407130241394
train loss item: 0.29067927598953247
train loss item: 0.45842763781547546
train loss item: 0.12686845660209656
train loss item: 0.21495352685451508
train loss item: 0.13249126076698303
train loss item: 0.188309445977211
train loss item: 0.13225318491458893
train loss item: 0.4648590683937073
train loss item: 0.22829239070415497
train loss item: 0.35161179304122925
train loss item: 0.1266661286354065
test loss item: 0.1421973556280136
test loss item: 0.2693975567817688
test loss item: 0.2067680060863495
test loss item: 0.08890452235937119
test loss item: 0.190031498670578
test loss item: 0.12275729328393936
test loss item: 0.12241164594888687
test loss item: 0.20115630328655243
test loss item: 0.19858324527740479
test loss item: 0.2819622755050659
test loss item: 0.10939888656139374
test loss item: 0.1321321427822113
test loss item: 0.17564234137535095
test loss item: 0.18960019946098328
test loss item: 0.18261227011680603
test loss item: 0.10953853279352188
test loss item: 0.20660805702209473
test loss item: 0.2533110976219177
test loss item: 0.10888468474149704
test loss item: 0.35076889395713806
test loss item: 0.35229429602622986
test loss item: 0.1008777916431427
test loss item: 0.1684848666191101
Epoch [35/50], Training Loss: 0.2272, Testing Loss: 0.1854
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 36/50
train loss item: 0.30810895562171936
train loss item: 0.204547718167305
train loss item: 0.1874794214963913
train loss item: 0.21244533360004425
train loss item: 0.12640415132045746
train loss item: 0.31257981061935425
train loss item: 0.12357424944639206
train loss item: 0.3956749737262726
train loss item: 0.2041959911584854
train loss item: 0.17101776599884033
train loss item: 0.10246839374303818
train loss item: 0.16314716637134552
train loss item: 0.19969722628593445
train loss item: 0.32718974351882935
train loss item: 0.10647423565387726
train loss item: 0.21069474518299103
train loss item: 0.15681368112564087
train loss item: 0.11880462616682053
train loss item: 0.08834739774465561
train loss item: 0.3392625153064728
train loss item: 0.12417721748352051
train loss item: 0.48097628355026245
train loss item: 0.1590365171432495
test loss item: 0.1413593739271164
test loss item: 0.18387404084205627
test loss item: 0.20662467181682587
test loss item: 0.07850461453199387
test loss item: 0.1339430809020996
test loss item: 0.10948405414819717
test loss item: 0.0825166180729866
test loss item: 0.18905948102474213
test loss item: 0.15759322047233582
test loss item: 0.2832465171813965
test loss item: 0.09734301269054413
test loss item: 0.10370088368654251
test loss item: 0.15573231875896454
test loss item: 0.1878717690706253
test loss item: 0.13840940594673157
test loss item: 0.09734224528074265
test loss item: 0.18218444287776947
test loss item: 0.17962554097175598
test loss item: 0.08225323259830475
test loss item: 0.43756812810897827
test loss item: 0.3342447876930237
test loss item: 0.07267698645591736
test loss item: 0.09905586391687393
Epoch [36/50], Training Loss: 0.2097, Testing Loss: 0.1624
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 37/50
train loss item: 0.24533730745315552
train loss item: 0.16293580830097198
train loss item: 0.120035819709301
train loss item: 0.13831263780593872
train loss item: 0.11356492340564728
train loss item: 0.1690635085105896
train loss item: 0.09228912740945816
train loss item: 0.18502230942249298
train loss item: 0.20094239711761475
train loss item: 0.14920347929000854
train loss item: 0.09940522909164429
train loss item: 0.18076157569885254
train loss item: 0.15515314042568207
train loss item: 0.18359383940696716
train loss item: 0.07671814411878586
train loss item: 0.17348551750183105
train loss item: 0.1011931523680687
train loss item: 0.11570148915052414
train loss item: 0.056713178753852844
train loss item: 0.2615840435028076
train loss item: 0.09512840211391449
train loss item: 0.4492091238498688
train loss item: 0.13256977498531342
test loss item: 0.12852415442466736
test loss item: 0.2719700038433075
test loss item: 0.2004285454750061
test loss item: 0.06969563663005829
test loss item: 0.129865825176239
test loss item: 0.1152200773358345
test loss item: 0.08456185460090637
test loss item: 0.22565580904483795
test loss item: 0.15370970964431763
test loss item: 0.2880414128303528
test loss item: 0.08930667489767075
test loss item: 0.10655500739812851
test loss item: 0.15375182032585144
test loss item: 0.17604875564575195
test loss item: 0.1398235708475113
test loss item: 0.09018023312091827
test loss item: 0.19223766028881073
test loss item: 0.2043077051639557
test loss item: 0.0877125933766365
test loss item: 0.4642798602581024
test loss item: 0.3591846525669098
test loss item: 0.07629990577697754
test loss item: 0.06528354436159134
Epoch [37/50], Training Loss: 0.1590, Testing Loss: 0.1684
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 38/50
train loss item: 0.288597047328949
train loss item: 0.15705813467502594
train loss item: 0.18143633008003235
train loss item: 0.15063707530498505
train loss item: 0.11157109588384628
train loss item: 0.21497109532356262
train loss item: 0.15483875572681427
train loss item: 0.2991805374622345
train loss item: 0.2243604212999344
train loss item: 0.15414564311504364
train loss item: 0.1328020989894867
train loss item: 0.23976202309131622
train loss item: 0.19503305852413177
train loss item: 0.16457511484622955
train loss item: 0.10916272550821304
train loss item: 0.16696996986865997
train loss item: 0.09588076919317245
train loss item: 0.13267989456653595
train loss item: 0.0650421604514122
train loss item: 0.2954961359500885
train loss item: 0.15055707097053528
train loss item: 0.2612103819847107
train loss item: 0.1258658468723297
test loss item: 0.11677941679954529
test loss item: 0.20292799174785614
test loss item: 0.17426542937755585
test loss item: 0.08367182314395905
test loss item: 0.1116548627614975
test loss item: 0.11161758750677109
test loss item: 0.08979202806949615
test loss item: 0.1644265204668045
test loss item: 0.1238328069448471
test loss item: 0.21795056760311127
test loss item: 0.09756209701299667
test loss item: 0.10446766763925552
test loss item: 0.1289605051279068
test loss item: 0.14409588277339935
test loss item: 0.11582104861736298
test loss item: 0.09447882324457169
test loss item: 0.1551969051361084
test loss item: 0.16692522168159485
test loss item: 0.08648710697889328
test loss item: 0.33159348368644714
test loss item: 0.2654075622558594
test loss item: 0.08076438307762146
test loss item: 0.09110018610954285
Epoch [38/50], Training Loss: 0.1770, Testing Loss: 0.1417
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 39/50
train loss item: 0.25922220945358276
train loss item: 0.1763497292995453
train loss item: 0.19469967484474182
train loss item: 0.1524060219526291
train loss item: 0.10096114873886108
train loss item: 0.19278500974178314
train loss item: 0.11162618547677994
train loss item: 0.24354375898838043
train loss item: 0.20158928632736206
train loss item: 0.16530273854732513
train loss item: 0.12127348780632019
train loss item: 0.2088131308555603
train loss item: 0.16215218603610992
train loss item: 0.14544570446014404
train loss item: 0.10064275562763214
train loss item: 0.21402746438980103
train loss item: 0.1128261461853981
train loss item: 0.1354668140411377
train loss item: 0.07431471347808838
train loss item: 0.2482030838727951
train loss item: 0.12804827094078064
train loss item: 0.3376196026802063
train loss item: 0.11829609423875809
test loss item: 0.12431909888982773
test loss item: 0.29920247197151184
test loss item: 0.22368690371513367
test loss item: 0.09073032438755035
test loss item: 0.21399910748004913
test loss item: 0.12096170336008072
test loss item: 0.10280223190784454
test loss item: 0.23140765726566315
test loss item: 0.20000596344470978
test loss item: 0.30607980489730835
test loss item: 0.0904826745390892
test loss item: 0.1567300409078598
test loss item: 0.19169415533542633
test loss item: 0.18782976269721985
test loss item: 0.19752901792526245
test loss item: 0.10923228412866592
test loss item: 0.21092717349529266
test loss item: 0.2784450650215149
test loss item: 0.0968758836388588
test loss item: 0.40009957551956177
test loss item: 0.3843183219432831
test loss item: 0.08429251611232758
test loss item: 0.07594610750675201
Epoch [39/50], Training Loss: 0.1698, Testing Loss: 0.1903
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 40/50
train loss item: 0.2681121528148651
train loss item: 0.2055336982011795
train loss item: 0.2571573257446289
train loss item: 0.18591350317001343
train loss item: 0.1168331578373909
train loss item: 0.201970636844635
train loss item: 0.1378607600927353
train loss item: 0.37869739532470703
train loss item: 0.23793454468250275
train loss item: 0.14802947640419006
train loss item: 0.12449536472558975
train loss item: 0.19047431647777557
train loss item: 0.15368331968784332
train loss item: 0.36077770590782166
train loss item: 0.11484453082084656
train loss item: 0.2224564552307129
train loss item: 0.11852122098207474
train loss item: 0.12736079096794128
train loss item: 0.08432599902153015
train loss item: 0.30096566677093506
train loss item: 0.15813323855400085
train loss item: 0.5031638145446777
train loss item: 0.11737280339002609
test loss item: 0.19688527286052704
test loss item: 0.25660839676856995
test loss item: 0.2991849184036255
test loss item: 0.0933024138212204
test loss item: 0.19814808666706085
test loss item: 0.15063223242759705
test loss item: 0.10924851894378662
test loss item: 0.28024059534072876
test loss item: 0.24050413072109222
test loss item: 0.4063408076763153
test loss item: 0.09446360915899277
test loss item: 0.1612469106912613
test loss item: 0.23663343489170074
test loss item: 0.2853552997112274
test loss item: 0.19927655160427094
test loss item: 0.11916951835155487
test loss item: 0.2949516177177429
test loss item: 0.26936227083206177
test loss item: 0.08786286413669586
test loss item: 0.6677659749984741
test loss item: 0.5166676640510559
test loss item: 0.08946174383163452
test loss item: 0.07199014723300934
Epoch [40/50], Training Loss: 0.2050, Testing Loss: 0.2315
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 41/50
train loss item: 0.2523033022880554
train loss item: 0.17753158509731293
train loss item: 0.2585984766483307
train loss item: 0.2607681453227997
train loss item: 0.1936195194721222
train loss item: 0.4320482909679413
train loss item: 0.2133139967918396
train loss item: 0.4086487591266632
train loss item: 0.2492840439081192
train loss item: 0.16372279822826385
train loss item: 0.19850574433803558
train loss item: 0.3795619606971741
train loss item: 0.36658191680908203
train loss item: 0.6986051201820374
train loss item: 0.2100961059331894
train loss item: 0.5569366812705994
train loss item: 0.2049218863248825
train loss item: 0.18533238768577576
train loss item: 0.11578341573476791
train loss item: 0.3018379807472229
train loss item: 0.18151269853115082
train loss item: 0.2502354681491852
train loss item: 0.2062063217163086
test loss item: 0.13348983228206635
test loss item: 0.5373364686965942
test loss item: 0.19209636747837067
test loss item: 0.07528657466173172
test loss item: 0.22124235332012177
test loss item: 0.18432557582855225
test loss item: 0.11963202059268951
test loss item: 0.2875155210494995
test loss item: 0.15593062341213226
test loss item: 0.3144981861114502
test loss item: 0.15824533998966217
test loss item: 0.17338646948337555
test loss item: 0.18011239171028137
test loss item: 0.15933798253536224
test loss item: 0.1694280356168747
test loss item: 0.13353873789310455
test loss item: 0.25594067573547363
test loss item: 0.34437134861946106
test loss item: 0.17687785625457764
test loss item: 0.2981468439102173
test loss item: 0.39999285340309143
test loss item: 0.09697563201189041
test loss item: 0.09574513137340546
Epoch [41/50], Training Loss: 0.2811, Testing Loss: 0.2115
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 42/50
train loss item: 0.3302682936191559
train loss item: 0.1510762721300125
train loss item: 0.12494217604398727
train loss item: 0.24216234683990479
train loss item: 0.12409854680299759
train loss item: 0.3492094576358795
train loss item: 0.16649720072746277
train loss item: 0.22572937607765198
train loss item: 0.24299155175685883
train loss item: 0.3672439754009247
train loss item: 0.1345389485359192
train loss item: 0.16576127707958221
train loss item: 0.1806587427854538
train loss item: 0.16196243464946747
train loss item: 0.11109332740306854
train loss item: 0.26033106446266174
train loss item: 0.11605057120323181
train loss item: 0.09528827667236328
train loss item: 0.08935216814279556
train loss item: 0.1990879774093628
train loss item: 0.1387796401977539
train loss item: 0.267408549785614
train loss item: 0.1670038253068924
test loss item: 0.09464830160140991
test loss item: 0.15372899174690247
test loss item: 0.12038353830575943
test loss item: 0.06785812228918076
test loss item: 0.09747258573770523
test loss item: 0.08930612355470657
test loss item: 0.07910062372684479
test loss item: 0.1105642095208168
test loss item: 0.10617583990097046
test loss item: 0.15043671429157257
test loss item: 0.08226551115512848
test loss item: 0.07786552608013153
test loss item: 0.09772573411464691
test loss item: 0.1060400977730751
test loss item: 0.09273900836706161
test loss item: 0.07654163986444473
test loss item: 0.12333254516124725
test loss item: 0.12648698687553406
test loss item: 0.07494791597127914
test loss item: 0.17407920956611633
test loss item: 0.17765256762504578
test loss item: 0.07199728488922119
test loss item: 0.09425751119852066
Epoch [42/50], Training Loss: 0.1918, Testing Loss: 0.1063
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 43/50
train loss item: 0.24520595371723175
train loss item: 0.11035355925559998
train loss item: 0.10451129823923111
train loss item: 0.1379089057445526
train loss item: 0.12514075636863708
train loss item: 0.17033733427524567
train loss item: 0.11461682617664337
train loss item: 0.2113202065229416
train loss item: 0.2638738751411438
train loss item: 0.22664278745651245
train loss item: 0.08290290832519531
train loss item: 0.12036868929862976
train loss item: 0.17490974068641663
train loss item: 0.1722079962491989
train loss item: 0.10022887587547302
train loss item: 0.19890785217285156
train loss item: 0.11171137541532516
train loss item: 0.09222996979951859
train loss item: 0.08758356422185898
train loss item: 0.16659794747829437
train loss item: 0.10696771740913391
train loss item: 0.3569040298461914
train loss item: 0.12916310131549835
test loss item: 0.1266489326953888
test loss item: 0.1695823073387146
test loss item: 0.154607355594635
test loss item: 0.07464029639959335
test loss item: 0.10967320203781128
test loss item: 0.10344192385673523
test loss item: 0.09520812332630157
test loss item: 0.14959660172462463
test loss item: 0.128160297870636
test loss item: 0.20755916833877563
test loss item: 0.1024717167019844
test loss item: 0.09093255549669266
test loss item: 0.11787059903144836
test loss item: 0.14460088312625885
test loss item: 0.10952796041965485
test loss item: 0.0849069356918335
test loss item: 0.1470201313495636
test loss item: 0.14843304455280304
test loss item: 0.09606130421161652
test loss item: 0.3109249174594879
test loss item: 0.24540166556835175
test loss item: 0.09400272369384766
test loss item: 0.08296534419059753
Epoch [43/50], Training Loss: 0.1570, Testing Loss: 0.1345
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 44/50
train loss item: 0.1528240144252777
train loss item: 0.09988249838352203
train loss item: 0.15427431464195251
train loss item: 0.14412803947925568
train loss item: 0.12831702828407288
train loss item: 0.17930324375629425
train loss item: 0.11764619499444962
train loss item: 0.23599958419799805
train loss item: 0.2225230634212494
train loss item: 0.20658347010612488
train loss item: 0.12351500242948532
train loss item: 0.25814491510391235
train loss item: 0.19489331543445587
train loss item: 0.2836920917034149
train loss item: 0.11910271644592285
train loss item: 0.20675089955329895
train loss item: 0.1433708816766739
train loss item: 0.1211140900850296
train loss item: 0.06575938314199448
train loss item: 0.19556571543216705
train loss item: 0.1411372572183609
train loss item: 0.20657825469970703
train loss item: 0.11060208082199097
test loss item: 0.12083704024553299
test loss item: 0.191421777009964
test loss item: 0.1672016978263855
test loss item: 0.07394220679998398
test loss item: 0.11902613192796707
test loss item: 0.11271506547927856
test loss item: 0.09059280157089233
test loss item: 0.15968626737594604
test loss item: 0.152878075838089
test loss item: 0.21616661548614502
test loss item: 0.09498956054449081
test loss item: 0.10838673263788223
test loss item: 0.1292530745267868
test loss item: 0.16010956466197968
test loss item: 0.11380567401647568
test loss item: 0.08886457979679108
test loss item: 0.15378350019454956
test loss item: 0.16746479272842407
test loss item: 0.08147880434989929
test loss item: 0.2956559956073761
test loss item: 0.2532117962837219
test loss item: 0.07737891376018524
test loss item: 0.1076195016503334
Epoch [44/50], Training Loss: 0.1657, Testing Loss: 0.1407
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 45/50
train loss item: 0.20679393410682678
train loss item: 0.13574804365634918
train loss item: 0.16191774606704712
train loss item: 0.13422410190105438
train loss item: 0.11779668182134628
train loss item: 0.21226254105567932
train loss item: 0.1217740848660469
train loss item: 0.32099267840385437
train loss item: 0.19063487648963928
train loss item: 0.17927409708499908
train loss item: 0.16155144572257996
train loss item: 0.334194540977478
train loss item: 0.29075387120246887
train loss item: 0.6132867336273193
train loss item: 0.16960567235946655
train loss item: 0.46250542998313904
train loss item: 0.15249818563461304
train loss item: 0.1592719852924347
train loss item: 0.0965765193104744
train loss item: 0.2501984238624573
train loss item: 0.15933804214000702
train loss item: 0.23003719747066498
train loss item: 0.11684907972812653
test loss item: 0.11603745818138123
test loss item: 0.3153439462184906
test loss item: 0.20947979390621185
test loss item: 0.08477257192134857
test loss item: 0.21713446080684662
test loss item: 0.13061697781085968
test loss item: 0.11068131029605865
test loss item: 0.23125000298023224
test loss item: 0.21159666776657104
test loss item: 0.2824844717979431
test loss item: 0.11350779980421066
test loss item: 0.1496497541666031
test loss item: 0.18051545321941376
test loss item: 0.17823146283626556
test loss item: 0.1908779889345169
test loss item: 0.10874176770448685
test loss item: 0.18963687121868134
test loss item: 0.29854539036750793
test loss item: 0.12664233148097992
test loss item: 0.27623632550239563
test loss item: 0.3643619418144226
test loss item: 0.09343794733285904
test loss item: 0.11537082493305206
Epoch [45/50], Training Loss: 0.2164, Testing Loss: 0.1867
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 46/50
train loss item: 0.2916785180568695
train loss item: 0.16154904663562775
train loss item: 0.18861649930477142
train loss item: 0.20746354758739471
train loss item: 0.12117138504981995
train loss item: 0.26026827096939087
train loss item: 0.10982803255319595
train loss item: 0.21333561837673187
train loss item: 0.21372444927692413
train loss item: 0.2408270388841629
train loss item: 0.11171844601631165
train loss item: 0.13356949388980865
train loss item: 0.14423494040966034
train loss item: 0.17489971220493317
train loss item: 0.10548842698335648
train loss item: 0.21826645731925964
train loss item: 0.12886543571949005
train loss item: 0.09735330194234848
train loss item: 0.08413787186145782
train loss item: 0.16416864097118378
train loss item: 0.11072088032960892
train loss item: 0.31856414675712585
train loss item: 0.13733097910881042
test loss item: 0.10518072545528412
test loss item: 0.16677993535995483
test loss item: 0.14073731005191803
test loss item: 0.08158165216445923
test loss item: 0.10147461295127869
test loss item: 0.09932304918766022
test loss item: 0.08407135307788849
test loss item: 0.13292528688907623
test loss item: 0.11980725079774857
test loss item: 0.17496801912784576
test loss item: 0.09477264434099197
test loss item: 0.08639824390411377
test loss item: 0.13766230642795563
test loss item: 0.1281600147485733
test loss item: 0.10791028290987015
test loss item: 0.09719834476709366
test loss item: 0.12436932325363159
test loss item: 0.13798053562641144
test loss item: 0.07886511832475662
test loss item: 0.23407797515392303
test loss item: 0.2017175555229187
test loss item: 0.07061201333999634
test loss item: 0.10997042059898376
Epoch [46/50], Training Loss: 0.1712, Testing Loss: 0.1225
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 47/50
train loss item: 0.16144217550754547
train loss item: 0.10985049605369568
train loss item: 0.1728450506925583
train loss item: 0.13373076915740967
train loss item: 0.1129819005727768
train loss item: 0.15469123423099518
train loss item: 0.11716325581073761
train loss item: 0.1944577842950821
train loss item: 0.18330658972263336
train loss item: 0.17163683474063873
train loss item: 0.10862326622009277
train loss item: 0.20907451212406158
train loss item: 0.17043432593345642
train loss item: 0.17859390377998352
train loss item: 0.10516025125980377
train loss item: 0.17816570401191711
train loss item: 0.10218171775341034
train loss item: 0.10411159694194794
train loss item: 0.05943562090396881
train loss item: 0.16893339157104492
train loss item: 0.0954684391617775
train loss item: 0.1776445358991623
train loss item: 0.08977404981851578
test loss item: 0.10494782775640488
test loss item: 0.1758822202682495
test loss item: 0.15710723400115967
test loss item: 0.06355209648609161
test loss item: 0.10561808943748474
test loss item: 0.09025842696428299
test loss item: 0.07408155500888824
test loss item: 0.15094296634197235
test loss item: 0.12980730831623077
test loss item: 0.2018997222185135
test loss item: 0.0784863755106926
test loss item: 0.09410373866558075
test loss item: 0.12349999696016312
test loss item: 0.14497539401054382
test loss item: 0.10201253741979599
test loss item: 0.07837346941232681
test loss item: 0.1350940316915512
test loss item: 0.14843697845935822
test loss item: 0.0644107386469841
test loss item: 0.2899937331676483
test loss item: 0.24064095318317413
test loss item: 0.05991964787244797
test loss item: 0.0605904757976532
Epoch [47/50], Training Loss: 0.1417, Testing Loss: 0.1250
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 48/50
train loss item: 0.2107146680355072
train loss item: 0.13531260192394257
train loss item: 0.17939060926437378
train loss item: 0.14437615871429443
train loss item: 0.10953548550605774
train loss item: 0.16880162060260773
train loss item: 0.1244313046336174
train loss item: 0.28412148356437683
train loss item: 0.18948952853679657
train loss item: 0.1686531901359558
train loss item: 0.14430183172225952
train loss item: 0.32111412286758423
train loss item: 0.28091496229171753
train loss item: 0.5590987205505371
train loss item: 0.1618262380361557
train loss item: 0.48211926221847534
train loss item: 0.1827714592218399
train loss item: 0.16203615069389343
train loss item: 0.0874973013997078
train loss item: 0.2192034125328064
train loss item: 0.1616068035364151
train loss item: 0.16416163742542267
train loss item: 0.14644911885261536
test loss item: 0.10873407125473022
test loss item: 0.3533202111721039
test loss item: 0.1603793203830719
test loss item: 0.07100771367549896
test loss item: 0.19085973501205444
test loss item: 0.15340395271778107
test loss item: 0.10062558203935623
test loss item: 0.21532239019870758
test loss item: 0.15630455315113068
test loss item: 0.24463681876659393
test loss item: 0.13391274213790894
test loss item: 0.14581644535064697
test loss item: 0.15099424123764038
test loss item: 0.14158552885055542
test loss item: 0.15505778789520264
test loss item: 0.11171433329582214
test loss item: 0.19195745885372162
test loss item: 0.2840634286403656
test loss item: 0.1545892059803009
test loss item: 0.19271135330200195
test loss item: 0.3157290816307068
test loss item: 0.08814366161823273
test loss item: 0.09610515832901001
Epoch [48/50], Training Loss: 0.2082, Testing Loss: 0.1703
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 49/50
train loss item: 0.1839229166507721
train loss item: 0.12262681871652603
train loss item: 0.16877757012844086
train loss item: 0.1824551522731781
train loss item: 0.09367184340953827
train loss item: 0.142573744058609
train loss item: 0.13701295852661133
train loss item: 0.2382098138332367
train loss item: 0.20055656135082245
train loss item: 0.1303275227546692
train loss item: 0.1402149647474289
train loss item: 0.2501075863838196
train loss item: 0.2841801941394806
train loss item: 0.5599333643913269
train loss item: 0.14964263141155243
train loss item: 0.5110368132591248
train loss item: 0.15348224341869354
train loss item: 0.13025599718093872
train loss item: 0.07909771800041199
train loss item: 0.1636957824230194
train loss item: 0.11602906882762909
train loss item: 0.2479131519794464
train loss item: 0.10735923796892166
test loss item: 0.12545758485794067
test loss item: 0.34704411029815674
test loss item: 0.16019296646118164
test loss item: 0.10999620705842972
test loss item: 0.1733957827091217
test loss item: 0.1589588224887848
test loss item: 0.10883373767137527
test loss item: 0.20806992053985596
test loss item: 0.1493903249502182
test loss item: 0.22876635193824768
test loss item: 0.14299501478672028
test loss item: 0.1425788253545761
test loss item: 0.16779889166355133
test loss item: 0.1412491351366043
test loss item: 0.15314576029777527
test loss item: 0.13417087495326996
test loss item: 0.19002999365329742
test loss item: 0.25482457876205444
test loss item: 0.14424489438533783
test loss item: 0.1787882000207901
test loss item: 0.2786274254322052
test loss item: 0.09237971901893616
test loss item: 0.0875159278512001
Epoch [49/50], Training Loss: 0.1954, Testing Loss: 0.1686
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 50/50
train loss item: 0.15153051912784576
train loss item: 0.13448433578014374
train loss item: 0.18896974623203278
train loss item: 0.1548377424478531
train loss item: 0.09803056716918945
train loss item: 0.16664449870586395
train loss item: 0.16508783400058746
train loss item: 0.21115443110466003
train loss item: 0.22250109910964966
train loss item: 0.18736444413661957
train loss item: 0.11733607947826385
train loss item: 0.22888235747814178
train loss item: 0.23208078742027283
train loss item: 0.35937783122062683
train loss item: 0.13502702116966248
train loss item: 0.35412514209747314
train loss item: 0.1477004587650299
train loss item: 0.1345100849866867
train loss item: 0.08443973958492279
train loss item: 0.22125564515590668
train loss item: 0.14395758509635925
train loss item: 0.17844918370246887
train loss item: 0.11061284691095352
test loss item: 0.1210346519947052
test loss item: 0.2469528317451477
test loss item: 0.15547186136245728
test loss item: 0.0871235653758049
test loss item: 0.15722592175006866
test loss item: 0.13707473874092102
test loss item: 0.10127083212137222
test loss item: 0.17352920770645142
test loss item: 0.15073919296264648
test loss item: 0.20416195690631866
test loss item: 0.12586000561714172
test loss item: 0.13089066743850708
test loss item: 0.1332065463066101
test loss item: 0.14390400052070618
test loss item: 0.13489481806755066
test loss item: 0.1035122349858284
test loss item: 0.16071730852127075
test loss item: 0.20953083038330078
test loss item: 0.13338705897331238
test loss item: 0.20312000811100006
test loss item: 0.2502795457839966
test loss item: 0.09567585587501526
test loss item: 0.07401801645755768
Epoch [50/50], Training Loss: 0.1795, Testing Loss: 0.1493
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
loss item: 0.18663069605827332
loss item: 0.19587652385234833
loss item: 0.17792688310146332
loss item: 0.15022854506969452
loss item: 0.18298889696598053
loss item: 0.1169685497879982
loss item: 0.17194391787052155
loss item: 0.25655269622802734
loss item: 0.13532981276512146
loss item: 0.16559606790542603
loss item: 0.21744784712791443
Val Loss: 0.1780
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 50, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.005 8 360 done at Tue Nov 12 11:36:57 CET 2024
UNet2 with 1 50 0.0001 16 360 start at Tue Nov 12 11:36:57 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.347920298576355
train loss item: 0.7567220330238342
train loss item: 0.9415144324302673
train loss item: 1.2658209800720215
train loss item: 1.3252041339874268
train loss item: 0.5795272588729858
train loss item: 1.2090576887130737
train loss item: 0.9306648969650269
train loss item: 0.5281984210014343
train loss item: 0.7622933983802795
train loss item: 1.252486228942871
train loss item: 0.5241486430168152
test loss item: 1.1635373830795288
test loss item: 0.8743120431900024
test loss item: 0.7483742833137512
test loss item: 0.7974737882614136
test loss item: 1.2985048294067383
test loss item: 0.570023238658905
test loss item: 0.9929193258285522
test loss item: 0.6190888285636902
test loss item: 1.1566652059555054
test loss item: 1.6485538482666016
test loss item: 1.5251150131225586
test loss item: 0.20283658802509308
Epoch [1/50], Training Loss: 0.9520, Testing Loss: 0.9665
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/50
train loss item: 0.7401988506317139
train loss item: 0.4863934814929962
train loss item: 0.599054217338562
train loss item: 0.754587709903717
train loss item: 0.8665329813957214
train loss item: 0.4313562214374542
train loss item: 0.7822306156158447
train loss item: 0.6246208548545837
train loss item: 0.5153311491012573
train loss item: 0.6471831202507019
train loss item: 0.9335834980010986
train loss item: 0.43342021107673645
test loss item: 0.880848228931427
test loss item: 0.6917149424552917
test loss item: 0.6116279363632202
test loss item: 0.6236787438392639
test loss item: 1.0314371585845947
test loss item: 0.4742750823497772
test loss item: 0.7905266880989075
test loss item: 0.5056158304214478
test loss item: 0.8801586627960205
test loss item: 1.2333225011825562
test loss item: 1.1637259721755981
test loss item: 0.24054406583309174
Epoch [2/50], Training Loss: 0.6512, Testing Loss: 0.7606
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/50
train loss item: 0.5782200694084167
train loss item: 0.4201120138168335
train loss item: 0.4758269190788269
train loss item: 0.6368111968040466
train loss item: 0.7149839401245117
train loss item: 0.3648892939090729
train loss item: 0.6342721581459045
train loss item: 0.5283299684524536
train loss item: 0.4298100471496582
train loss item: 0.5449725985527039
train loss item: 0.7565566897392273
train loss item: 0.395431786775589
test loss item: 0.5319501757621765
test loss item: 0.4183981120586395
test loss item: 0.4346845746040344
test loss item: 0.38244473934173584
test loss item: 0.6375440359115601
test loss item: 0.36071017384529114
test loss item: 0.4719291627407074
test loss item: 0.36257457733154297
test loss item: 0.5221804976463318
test loss item: 0.5786992311477661
test loss item: 0.621884822845459
test loss item: 0.25444474816322327
Epoch [3/50], Training Loss: 0.5400, Testing Loss: 0.4648
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/50
train loss item: 0.5396005511283875
train loss item: 0.41185733675956726
train loss item: 0.43653613328933716
train loss item: 0.5439848899841309
train loss item: 0.6010032892227173
train loss item: 0.3382870554924011
train loss item: 0.5531575083732605
train loss item: 0.48223984241485596
train loss item: 0.34177836775779724
train loss item: 0.4872194826602936
train loss item: 0.7226658463478088
train loss item: 0.36409419775009155
test loss item: 0.41494104266166687
test loss item: 0.33787810802459717
test loss item: 0.36477580666542053
test loss item: 0.31292518973350525
test loss item: 0.5127039551734924
test loss item: 0.30048948526382446
test loss item: 0.3697968125343323
test loss item: 0.31895679235458374
test loss item: 0.4262077510356903
test loss item: 0.48441505432128906
test loss item: 0.5073458552360535
test loss item: 0.29376649856567383
Epoch [4/50], Training Loss: 0.4852, Testing Loss: 0.3870
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/50
train loss item: 0.4667614996433258
train loss item: 0.35602954030036926
train loss item: 0.3905697464942932
train loss item: 0.4654618501663208
train loss item: 0.5137914419174194
train loss item: 0.33662980794906616
train loss item: 0.4598850905895233
train loss item: 0.4228249192237854
train loss item: 0.3118244409561157
train loss item: 0.4222519099712372
train loss item: 0.6273717284202576
train loss item: 0.3169131278991699
test loss item: 0.36404329538345337
test loss item: 0.31014958024024963
test loss item: 0.322428822517395
test loss item: 0.28472375869750977
test loss item: 0.46169647574424744
test loss item: 0.2684535086154938
test loss item: 0.3343240022659302
test loss item: 0.2909172475337982
test loss item: 0.37892231345176697
test loss item: 0.44105374813079834
test loss item: 0.45781704783439636
test loss item: 0.21189063787460327
Epoch [5/50], Training Loss: 0.4242, Testing Loss: 0.3439
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/50
train loss item: 0.42646029591560364
train loss item: 0.321542888879776
train loss item: 0.3541386127471924
train loss item: 0.4172070026397705
train loss item: 0.4470345377922058
train loss item: 0.2825626730918884
train loss item: 0.40221458673477173
train loss item: 0.37018683552742004
train loss item: 0.2941639721393585
train loss item: 0.39619678258895874
train loss item: 0.5370286107063293
train loss item: 0.2920563817024231
test loss item: 0.34206172823905945
test loss item: 0.306392103433609
test loss item: 0.28875958919525146
test loss item: 0.27712246775627136
test loss item: 0.4421752691268921
test loss item: 0.24570424854755402
test loss item: 0.31886026263237
test loss item: 0.2724485993385315
test loss item: 0.3653445243835449
test loss item: 0.4829641878604889
test loss item: 0.4696064293384552
test loss item: 0.20959006249904633
Epoch [6/50], Training Loss: 0.3784, Testing Loss: 0.3351
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/50
train loss item: 0.42065373063087463
train loss item: 0.299028605222702
train loss item: 0.3209518790245056
train loss item: 0.3806475102901459
train loss item: 0.4044487476348877
train loss item: 0.2597898244857788
train loss item: 0.35629788041114807
train loss item: 0.3363831639289856
train loss item: 0.27083784341812134
train loss item: 0.3857123851776123
train loss item: 0.46953722834587097
train loss item: 0.27001869678497314
test loss item: 0.33257701992988586
test loss item: 0.2954329252243042
test loss item: 0.27253323793411255
test loss item: 0.26488226652145386
test loss item: 0.41732773184776306
test loss item: 0.2333609163761139
test loss item: 0.30824270844459534
test loss item: 0.2565782368183136
test loss item: 0.3576570153236389
test loss item: 0.45231354236602783
test loss item: 0.449957937002182
test loss item: 0.1894015222787857
Epoch [7/50], Training Loss: 0.3479, Testing Loss: 0.3192
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/50
train loss item: 0.41220542788505554
train loss item: 0.2868652939796448
train loss item: 0.3081567883491516
train loss item: 0.34732961654663086
train loss item: 0.3768295645713806
train loss item: 0.24169519543647766
train loss item: 0.3249988853931427
train loss item: 0.31343603134155273
train loss item: 0.26336759328842163
train loss item: 0.3831824064254761
train loss item: 0.427778035402298
train loss item: 0.25177326798439026
test loss item: 0.3221997916698456
test loss item: 0.2877434492111206
test loss item: 0.2592628002166748
test loss item: 0.2517662048339844
test loss item: 0.4032743275165558
test loss item: 0.21948684751987457
test loss item: 0.30327266454696655
test loss item: 0.24405038356781006
test loss item: 0.3536774218082428
test loss item: 0.43759816884994507
test loss item: 0.4363326132297516
test loss item: 0.1839670091867447
Epoch [8/50], Training Loss: 0.3281, Testing Loss: 0.3086
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/50
train loss item: 0.3800511360168457
train loss item: 0.2699737548828125
train loss item: 0.2907028794288635
train loss item: 0.32575881481170654
train loss item: 0.35931819677352905
train loss item: 0.23939499258995056
train loss item: 0.30068299174308777
train loss item: 0.30091995000839233
train loss item: 0.2408865988254547
train loss item: 0.37569931149482727
train loss item: 0.40296605229377747
train loss item: 0.24435988068580627
test loss item: 0.2964315116405487
test loss item: 0.27875208854675293
test loss item: 0.24245423078536987
test loss item: 0.2369583249092102
test loss item: 0.378653347492218
test loss item: 0.20512571930885315
test loss item: 0.28901663422584534
test loss item: 0.2355102151632309
test loss item: 0.32526904344558716
test loss item: 0.37884244322776794
test loss item: 0.4079797863960266
test loss item: 0.18805299699306488
Epoch [9/50], Training Loss: 0.3109, Testing Loss: 0.2886
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/50
train loss item: 0.34666603803634644
train loss item: 0.24981653690338135
train loss item: 0.26727473735809326
train loss item: 0.308357834815979
train loss item: 0.35065439343452454
train loss item: 0.2388707846403122
train loss item: 0.28532567620277405
train loss item: 0.2903541028499603
train loss item: 0.21650585532188416
train loss item: 0.35096192359924316
train loss item: 0.3800894320011139
train loss item: 0.2308773249387741
test loss item: 0.3177933394908905
test loss item: 0.32816585898399353
test loss item: 0.25826120376586914
test loss item: 0.2616356909275055
test loss item: 0.4336276948451996
test loss item: 0.21133142709732056
test loss item: 0.33978986740112305
test loss item: 0.26333531737327576
test loss item: 0.36563414335250854
test loss item: 0.4255470037460327
test loss item: 0.48174020648002625
test loss item: 0.18677788972854614
Epoch [10/50], Training Loss: 0.2930, Testing Loss: 0.3228
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 11/50
train loss item: 0.347891241312027
train loss item: 0.2560316026210785
train loss item: 0.24945759773254395
train loss item: 0.2845357656478882
train loss item: 0.3305457532405853
train loss item: 0.24087552726268768
train loss item: 0.3099680244922638
train loss item: 0.3068079650402069
train loss item: 0.2156068980693817
train loss item: 0.3107607066631317
train loss item: 0.34536802768707275
train loss item: 0.217264786362648
test loss item: 0.34072765707969666
test loss item: 0.3702849745750427
test loss item: 0.2656375765800476
test loss item: 0.284180611371994
test loss item: 0.4830327033996582
test loss item: 0.21812781691551208
test loss item: 0.3822464644908905
test loss item: 0.28418242931365967
test loss item: 0.4095641076564789
test loss item: 0.5124495625495911
test loss item: 0.550409197807312
test loss item: 0.20672661066055298
Epoch [11/50], Training Loss: 0.2846, Testing Loss: 0.3590
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 12/50
train loss item: 0.36933159828186035
train loss item: 0.28285467624664307
train loss item: 0.2697446048259735
train loss item: 0.3008861839771271
train loss item: 0.2832474112510681
train loss item: 0.2179907113313675
train loss item: 0.3218272030353546
train loss item: 0.340495228767395
train loss item: 0.22335776686668396
train loss item: 0.2912554442882538
train loss item: 0.361698716878891
train loss item: 0.22472809255123138
test loss item: 0.3493470251560211
test loss item: 0.39836809039115906
test loss item: 0.26887038350105286
test loss item: 0.29991692304611206
test loss item: 0.5373103022575378
test loss item: 0.23283565044403076
test loss item: 0.429537832736969
test loss item: 0.2698112428188324
test loss item: 0.44669109582901
test loss item: 0.6838924884796143
test loss item: 0.6128897070884705
test loss item: 0.19076766073703766
Epoch [12/50], Training Loss: 0.2906, Testing Loss: 0.3934
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 13/50
train loss item: 0.310799777507782
train loss item: 0.2686956822872162
train loss item: 0.2521226704120636
train loss item: 0.3431659936904907
train loss item: 0.2809893786907196
train loss item: 0.20553483068943024
train loss item: 0.24664650857448578
train loss item: 0.3120839297771454
train loss item: 0.2217014729976654
train loss item: 0.3185695707798004
train loss item: 0.44780415296554565
train loss item: 0.21862837672233582
test loss item: 0.2638278007507324
test loss item: 0.24566766619682312
test loss item: 0.23009853065013885
test loss item: 0.2162914127111435
test loss item: 0.3768601417541504
test loss item: 0.19032904505729675
test loss item: 0.2811274230480194
test loss item: 0.21397355198860168
test loss item: 0.2992720305919647
test loss item: 0.47624704241752625
test loss item: 0.3945642113685608
test loss item: 0.1779440939426422
Epoch [13/50], Training Loss: 0.2856, Testing Loss: 0.2805
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 14/50
train loss item: 0.24441437423229218
train loss item: 0.24064691364765167
train loss item: 0.26568570733070374
train loss item: 0.3428039252758026
train loss item: 0.2758849561214447
train loss item: 0.2402867078781128
train loss item: 0.22238722443580627
train loss item: 0.2526032328605652
train loss item: 0.1925911009311676
train loss item: 0.3034432530403137
train loss item: 0.5039529800415039
train loss item: 0.1993921548128128
test loss item: 0.2672710120677948
test loss item: 0.20604538917541504
test loss item: 0.20624862611293793
test loss item: 0.19942250847816467
test loss item: 0.30694347620010376
test loss item: 0.17279210686683655
test loss item: 0.2341848909854889
test loss item: 0.19424225389957428
test loss item: 0.26042938232421875
test loss item: 0.33181771636009216
test loss item: 0.31789085268974304
test loss item: 0.16157321631908417
Epoch [14/50], Training Loss: 0.2737, Testing Loss: 0.2382
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 15/50
train loss item: 0.3015146255493164
train loss item: 0.1959829330444336
train loss item: 0.21499517560005188
train loss item: 0.2558496594429016
train loss item: 0.2373930662870407
train loss item: 0.2610434889793396
train loss item: 0.232282817363739
train loss item: 0.21869546175003052
train loss item: 0.2108130306005478
train loss item: 0.2790016829967499
train loss item: 0.4134898781776428
train loss item: 0.19360581040382385
test loss item: 0.25074532628059387
test loss item: 0.21728886663913727
test loss item: 0.207977294921875
test loss item: 0.20084546506404877
test loss item: 0.30506306886672974
test loss item: 0.17579251527786255
test loss item: 0.2384076714515686
test loss item: 0.1985301375389099
test loss item: 0.2560683488845825
test loss item: 0.29233279824256897
test loss item: 0.3083442151546478
test loss item: 0.18627220392227173
Epoch [15/50], Training Loss: 0.2512, Testing Loss: 0.2365
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 16/50
train loss item: 0.28360429406166077
train loss item: 0.20082612335681915
train loss item: 0.22855116426944733
train loss item: 0.22903010249137878
train loss item: 0.23093679547309875
train loss item: 0.20070821046829224
train loss item: 0.22551080584526062
train loss item: 0.2232566922903061
train loss item: 0.22529102861881256
train loss item: 0.27830907702445984
train loss item: 0.3307356834411621
train loss item: 0.20142415165901184
test loss item: 0.23352943360805511
test loss item: 0.18462195992469788
test loss item: 0.18930338323116302
test loss item: 0.17649351060390472
test loss item: 0.25943461060523987
test loss item: 0.15861612558364868
test loss item: 0.19880744814872742
test loss item: 0.17579510807991028
test loss item: 0.22708553075790405
test loss item: 0.2202111780643463
test loss item: 0.2646808624267578
test loss item: 0.15296266973018646
Epoch [16/50], Training Loss: 0.2382, Testing Loss: 0.2035
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 17/50
train loss item: 0.21967723965644836
train loss item: 0.18388615548610687
train loss item: 0.21093565225601196
train loss item: 0.21967753767967224
train loss item: 0.24031376838684082
train loss item: 0.17796337604522705
train loss item: 0.1950828582048416
train loss item: 0.19968996942043304
train loss item: 0.18790030479431152
train loss item: 0.2678335905075073
train loss item: 0.3164569139480591
train loss item: 0.18970836699008942
test loss item: 0.20611153542995453
test loss item: 0.1655198186635971
test loss item: 0.1708715856075287
test loss item: 0.15774916112422943
test loss item: 0.23022952675819397
test loss item: 0.14827276766300201
test loss item: 0.1773974746465683
test loss item: 0.1628728210926056
test loss item: 0.2019546777009964
test loss item: 0.20060661435127258
test loss item: 0.22909240424633026
test loss item: 0.1597609966993332
Epoch [17/50], Training Loss: 0.2174, Testing Loss: 0.1842
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 18/50
train loss item: 0.20933619141578674
train loss item: 0.16878241300582886
train loss item: 0.19020044803619385
train loss item: 0.21281512081623077
train loss item: 0.22815540432929993
train loss item: 0.1662726253271103
train loss item: 0.18689799308776855
train loss item: 0.18889757990837097
train loss item: 0.17230793833732605
train loss item: 0.24968743324279785
train loss item: 0.2776159644126892
train loss item: 0.1768438071012497
test loss item: 0.2129429280757904
test loss item: 0.1743190735578537
test loss item: 0.17055176198482513
test loss item: 0.16058777272701263
test loss item: 0.23746013641357422
test loss item: 0.1459602415561676
test loss item: 0.1858300417661667
test loss item: 0.16722652316093445
test loss item: 0.20726919174194336
test loss item: 0.20160667598247528
test loss item: 0.24079422652721405
test loss item: 0.1550452709197998
Epoch [18/50], Training Loss: 0.2023, Testing Loss: 0.1883
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 19/50
train loss item: 0.2246755212545395
train loss item: 0.16634979844093323
train loss item: 0.18459048867225647
train loss item: 0.2092866599559784
train loss item: 0.212196946144104
train loss item: 0.1576564610004425
train loss item: 0.19300785660743713
train loss item: 0.20480136573314667
train loss item: 0.16745591163635254
train loss item: 0.24888111650943756
train loss item: 0.24717870354652405
train loss item: 0.16818314790725708
test loss item: 0.20111724734306335
test loss item: 0.18738797307014465
test loss item: 0.16996049880981445
test loss item: 0.16491244733333588
test loss item: 0.25039246678352356
test loss item: 0.1473967730998993
test loss item: 0.19947685301303864
test loss item: 0.17036490142345428
test loss item: 0.2131209522485733
test loss item: 0.22659100592136383
test loss item: 0.26126453280448914
test loss item: 0.1747044175863266
Epoch [19/50], Training Loss: 0.1987, Testing Loss: 0.1972
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 20/50
train loss item: 0.22749044001102448
train loss item: 0.17218871414661407
train loss item: 0.1791677474975586
train loss item: 0.21432030200958252
train loss item: 0.21280528604984283
train loss item: 0.16117580235004425
train loss item: 0.18950825929641724
train loss item: 0.2187706083059311
train loss item: 0.16558369994163513
train loss item: 0.23763997852802277
train loss item: 0.2616533637046814
train loss item: 0.1636098176240921
test loss item: 0.2010035216808319
test loss item: 0.19348107278347015
test loss item: 0.17075099050998688
test loss item: 0.1646733582019806
test loss item: 0.2539246678352356
test loss item: 0.15203070640563965
test loss item: 0.2088516354560852
test loss item: 0.16983209550380707
test loss item: 0.21942591667175293
test loss item: 0.23598182201385498
test loss item: 0.2658907473087311
test loss item: 0.14895200729370117
Epoch [20/50], Training Loss: 0.2003, Testing Loss: 0.1987
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 21/50
train loss item: 0.20588448643684387
train loss item: 0.17470479011535645
train loss item: 0.18453045189380646
train loss item: 0.23942182958126068
train loss item: 0.22611774504184723
train loss item: 0.16807407140731812
train loss item: 0.17258767783641815
train loss item: 0.23358146846294403
train loss item: 0.1660103052854538
train loss item: 0.25451287627220154
train loss item: 0.29537445306777954
train loss item: 0.15844844281673431
test loss item: 0.19290927052497864
test loss item: 0.17207255959510803
test loss item: 0.17261305451393127
test loss item: 0.15349341928958893
test loss item: 0.22982966899871826
test loss item: 0.14721953868865967
test loss item: 0.18662630021572113
test loss item: 0.1679149866104126
test loss item: 0.20633864402770996
test loss item: 0.19687236845493317
test loss item: 0.23850436508655548
test loss item: 0.18139196932315826
Epoch [21/50], Training Loss: 0.2066, Testing Loss: 0.1871
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 22/50
train loss item: 0.18537811934947968
train loss item: 0.16944453120231628
train loss item: 0.1788487434387207
train loss item: 0.2620743215084076
train loss item: 0.24398721754550934
train loss item: 0.17278580367565155
train loss item: 0.1724184900522232
train loss item: 0.209122896194458
train loss item: 0.16612876951694489
train loss item: 0.23844210803508759
train loss item: 0.39660343527793884
train loss item: 0.15762436389923096
test loss item: 0.2233467698097229
test loss item: 0.17296187579631805
test loss item: 0.1906055510044098
test loss item: 0.15856975317001343
test loss item: 0.24600470066070557
test loss item: 0.15321668982505798
test loss item: 0.18774427473545074
test loss item: 0.17984719574451447
test loss item: 0.23233731091022491
test loss item: 0.22937794029712677
test loss item: 0.27011653780937195
test loss item: 0.14906984567642212
Epoch [22/50], Training Loss: 0.2127, Testing Loss: 0.1994
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 23/50
train loss item: 0.2297198623418808
train loss item: 0.16876600682735443
train loss item: 0.17740657925605774
train loss item: 0.22926437854766846
train loss item: 0.20485590398311615
train loss item: 0.20047664642333984
train loss item: 0.19650913774967194
train loss item: 0.2186138778924942
train loss item: 0.19271613657474518
train loss item: 0.19424661993980408
train loss item: 0.3512938320636749
train loss item: 0.15552176535129547
test loss item: 0.24018113315105438
test loss item: 0.17665624618530273
test loss item: 0.19142884016036987
test loss item: 0.16540338099002838
test loss item: 0.25313764810562134
test loss item: 0.1544247567653656
test loss item: 0.19039733707904816
test loss item: 0.17860929667949677
test loss item: 0.23620055615901947
test loss item: 0.24835205078125
test loss item: 0.2785246670246124
test loss item: 0.15920457243919373
Epoch [23/50], Training Loss: 0.2099, Testing Loss: 0.2060
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 24/50
train loss item: 0.2206430584192276
train loss item: 0.17279526591300964
train loss item: 0.19059962034225464
train loss item: 0.26703542470932007
train loss item: 0.18273669481277466
train loss item: 0.15883754193782806
train loss item: 0.19089145958423615
train loss item: 0.19392375648021698
train loss item: 0.19159606099128723
train loss item: 0.18235620856285095
train loss item: 0.30897560715675354
train loss item: 0.18495437502861023
test loss item: 0.1888107806444168
test loss item: 0.16394740343093872
test loss item: 0.1560487598180771
test loss item: 0.14666903018951416
test loss item: 0.23125584423542023
test loss item: 0.1334654539823532
test loss item: 0.17444691061973572
test loss item: 0.15184172987937927
test loss item: 0.19224625825881958
test loss item: 0.22781343758106232
test loss item: 0.24131996929645538
test loss item: 0.15410126745700836
Epoch [24/50], Training Loss: 0.2038, Testing Loss: 0.1802
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 25/50
train loss item: 0.21051429212093353
train loss item: 0.14710243046283722
train loss item: 0.15827280282974243
train loss item: 0.21940459311008453
train loss item: 0.18263113498687744
train loss item: 0.14320071041584015
train loss item: 0.208529531955719
train loss item: 0.17284610867500305
train loss item: 0.1543860286474228
train loss item: 0.19398930668830872
train loss item: 0.26832711696624756
train loss item: 0.15932753682136536
test loss item: 0.2340281903743744
test loss item: 0.17587070167064667
test loss item: 0.17374955117702484
test loss item: 0.1664980947971344
test loss item: 0.25344380736351013
test loss item: 0.13882839679718018
test loss item: 0.19219046831130981
test loss item: 0.16157306730747223
test loss item: 0.2280304878950119
test loss item: 0.22948403656482697
test loss item: 0.27383461594581604
test loss item: 0.1504390686750412
Epoch [25/50], Training Loss: 0.1849, Testing Loss: 0.1982
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 26/50
train loss item: 0.21272747218608856
train loss item: 0.16929444670677185
train loss item: 0.17620718479156494
train loss item: 0.1720498502254486
train loss item: 0.17506550252437592
train loss item: 0.1319499909877777
train loss item: 0.19337612390518188
train loss item: 0.1747479885816574
train loss item: 0.1723146140575409
train loss item: 0.24134251475334167
train loss item: 0.2535175383090973
train loss item: 0.15350459516048431
test loss item: 0.17454008758068085
test loss item: 0.15001919865608215
test loss item: 0.14329196512699127
test loss item: 0.1385580450296402
test loss item: 0.2039666771888733
test loss item: 0.125982403755188
test loss item: 0.1634349375963211
test loss item: 0.13780568540096283
test loss item: 0.17603270709514618
test loss item: 0.19624318182468414
test loss item: 0.2127838283777237
test loss item: 0.14389021694660187
Epoch [26/50], Training Loss: 0.1855, Testing Loss: 0.1639
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 27/50
train loss item: 0.17189106345176697
train loss item: 0.1506168693304062
train loss item: 0.17116837203502655
train loss item: 0.17975729703903198
train loss item: 0.19638143479824066
train loss item: 0.1416432112455368
train loss item: 0.16799339652061462
train loss item: 0.15828779339790344
train loss item: 0.15814834833145142
train loss item: 0.23555342853069305
train loss item: 0.2520465552806854
train loss item: 0.14875613152980804
test loss item: 0.1600317358970642
test loss item: 0.13720011711120605
test loss item: 0.1411951184272766
test loss item: 0.1257554441690445
test loss item: 0.1844407320022583
test loss item: 0.12385796755552292
test loss item: 0.14780165255069733
test loss item: 0.1377115100622177
test loss item: 0.16362500190734863
test loss item: 0.16416260600090027
test loss item: 0.18689179420471191
test loss item: 0.15235714614391327
Epoch [27/50], Training Loss: 0.1777, Testing Loss: 0.1521
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 28/50
train loss item: 0.1621827483177185
train loss item: 0.13195101916790009
train loss item: 0.14963354170322418
train loss item: 0.16585548222064972
train loss item: 0.18678373098373413
train loss item: 0.14856648445129395
train loss item: 0.16612185537815094
train loss item: 0.14685280621051788
train loss item: 0.13913992047309875
train loss item: 0.19432544708251953
train loss item: 0.23304405808448792
train loss item: 0.13847064971923828
test loss item: 0.168849378824234
test loss item: 0.14007097482681274
test loss item: 0.14816614985466003
test loss item: 0.12748754024505615
test loss item: 0.1881406158208847
test loss item: 0.1286148875951767
test loss item: 0.14968504011631012
test loss item: 0.14187303185462952
test loss item: 0.1753387749195099
test loss item: 0.16404737532138824
test loss item: 0.19494563341140747
test loss item: 0.14341893792152405
Epoch [28/50], Training Loss: 0.1636, Testing Loss: 0.1559
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 29/50
train loss item: 0.16344328224658966
train loss item: 0.12922245264053345
train loss item: 0.13953039050102234
train loss item: 0.16321176290512085
train loss item: 0.16179533302783966
train loss item: 0.13781318068504333
train loss item: 0.16656577587127686
train loss item: 0.15028256177902222
train loss item: 0.14061787724494934
train loss item: 0.16852031648159027
train loss item: 0.21384525299072266
train loss item: 0.13555198907852173
test loss item: 0.18386879563331604
test loss item: 0.137955904006958
test loss item: 0.15226897597312927
test loss item: 0.13312651216983795
test loss item: 0.18868331611156464
test loss item: 0.13279785215854645
test loss item: 0.1484488993883133
test loss item: 0.1422923505306244
test loss item: 0.18199090659618378
test loss item: 0.16473612189292908
test loss item: 0.19911283254623413
test loss item: 0.14554928243160248
Epoch [29/50], Training Loss: 0.1559, Testing Loss: 0.1592
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 30/50
train loss item: 0.15989352762699127
train loss item: 0.13449101150035858
train loss item: 0.14491547644138336
train loss item: 0.18355460464954376
train loss item: 0.1551208794116974
train loss item: 0.12484323978424072
train loss item: 0.16659067571163177
train loss item: 0.15407076478004456
train loss item: 0.1519116908311844
train loss item: 0.1629156470298767
train loss item: 0.20049667358398438
train loss item: 0.1379145383834839
test loss item: 0.16509030759334564
test loss item: 0.1364440768957138
test loss item: 0.14422833919525146
test loss item: 0.1268264502286911
test loss item: 0.18224036693572998
test loss item: 0.12817905843257904
test loss item: 0.1452961266040802
test loss item: 0.13553720712661743
test loss item: 0.1685492843389511
test loss item: 0.16784510016441345
test loss item: 0.1906731277704239
test loss item: 0.13543827831745148
Epoch [30/50], Training Loss: 0.1564, Testing Loss: 0.1522
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 31/50
train loss item: 0.1515176147222519
train loss item: 0.12906645238399506
train loss item: 0.14719504117965698
train loss item: 0.20060570538043976
train loss item: 0.16009704768657684
train loss item: 0.1189236044883728
train loss item: 0.16525931656360626
train loss item: 0.14643144607543945
train loss item: 0.14865700900554657
train loss item: 0.1538468450307846
train loss item: 0.19555546343326569
train loss item: 0.14004799723625183
test loss item: 0.14765103161334991
test loss item: 0.13757328689098358
test loss item: 0.13159134984016418
test loss item: 0.12442218512296677
test loss item: 0.1874406635761261
test loss item: 0.1171104833483696
test loss item: 0.14637158811092377
test loss item: 0.12823855876922607
test loss item: 0.15775711834430695
test loss item: 0.20565178990364075
test loss item: 0.2000972181558609
test loss item: 0.12667933106422424
Epoch [31/50], Training Loss: 0.1548, Testing Loss: 0.1509
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 32/50
train loss item: 0.15978118777275085
train loss item: 0.1204867884516716
train loss item: 0.13818225264549255
train loss item: 0.1956159770488739
train loss item: 0.1603231430053711
train loss item: 0.11452887207269669
train loss item: 0.16927681863307953
train loss item: 0.14029087126255035
train loss item: 0.13553865253925323
train loss item: 0.14897292852401733
train loss item: 0.17731815576553345
train loss item: 0.13510240614414215
test loss item: 0.15804611146450043
test loss item: 0.1344999372959137
test loss item: 0.12921378016471863
test loss item: 0.12471381574869156
test loss item: 0.18824593722820282
test loss item: 0.11246538162231445
test loss item: 0.1450822353363037
test loss item: 0.12504619359970093
test loss item: 0.16123352944850922
test loss item: 0.19832882285118103
test loss item: 0.1980126053094864
test loss item: 0.12963759899139404
Epoch [32/50], Training Loss: 0.1496, Testing Loss: 0.1504
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 33/50
train loss item: 0.1740308701992035
train loss item: 0.13066354393959045
train loss item: 0.13403843343257904
train loss item: 0.1610058844089508
train loss item: 0.14751160144805908
train loss item: 0.1127767413854599
train loss item: 0.16463620960712433
train loss item: 0.1431112438440323
train loss item: 0.13269388675689697
train loss item: 0.16054673492908478
train loss item: 0.15987135469913483
train loss item: 0.12969572842121124
test loss item: 0.18197984993457794
test loss item: 0.1291162669658661
test loss item: 0.13707049190998077
test loss item: 0.12946459650993347
test loss item: 0.1809537708759308
test loss item: 0.11723024398088455
test loss item: 0.1422244757413864
test loss item: 0.12596279382705688
test loss item: 0.17284376919269562
test loss item: 0.1562340259552002
test loss item: 0.18816766142845154
test loss item: 0.13691364228725433
Epoch [33/50], Training Loss: 0.1459, Testing Loss: 0.1498
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 34/50
train loss item: 0.18571101129055023
train loss item: 0.15129174292087555
train loss item: 0.15346170961856842
train loss item: 0.15117745101451874
train loss item: 0.1448897421360016
train loss item: 0.11199834197759628
train loss item: 0.16556252539157867
train loss item: 0.16901829838752747
train loss item: 0.15823569893836975
train loss item: 0.22025452554225922
train loss item: 0.1557815670967102
train loss item: 0.13172771036624908
test loss item: 0.16310922801494598
test loss item: 0.12788061797618866
test loss item: 0.1345931440591812
test loss item: 0.12276944518089294
test loss item: 0.17417021095752716
test loss item: 0.11614575237035751
test loss item: 0.14048171043395996
test loss item: 0.12366388738155365
test loss item: 0.1678619086742401
test loss item: 0.1467953324317932
test loss item: 0.17747962474822998
test loss item: 0.13749107718467712
Epoch [34/50], Training Loss: 0.1583, Testing Loss: 0.1444
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 35/50
train loss item: 0.16638712584972382
train loss item: 0.14944760501384735
train loss item: 0.1642816960811615
train loss item: 0.18137924373149872
train loss item: 0.18648380041122437
train loss item: 0.1365492343902588
train loss item: 0.141911581158638
train loss item: 0.17107552289962769
train loss item: 0.1518521010875702
train loss item: 0.23689588904380798
train loss item: 0.19138745963573456
train loss item: 0.13956178724765778
test loss item: 0.15449798107147217
test loss item: 0.14530228078365326
test loss item: 0.13084986805915833
test loss item: 0.12433739006519318
test loss item: 0.1888113021850586
test loss item: 0.11683880537748337
test loss item: 0.15646032989025116
test loss item: 0.13023681938648224
test loss item: 0.16778574883937836
test loss item: 0.19305682182312012
test loss item: 0.2005782127380371
test loss item: 0.12933506071567535
Epoch [35/50], Training Loss: 0.1681, Testing Loss: 0.1532
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 36/50
train loss item: 0.16191302239894867
train loss item: 0.12631528079509735
train loss item: 0.13488657772541046
train loss item: 0.17311815917491913
train loss item: 0.2045162469148636
train loss item: 0.16469761729240417
train loss item: 0.14431987702846527
train loss item: 0.17185240983963013
train loss item: 0.12558262050151825
train loss item: 0.18525008857250214
train loss item: 0.19462616741657257
train loss item: 0.13349100947380066
test loss item: 0.19384200870990753
test loss item: 0.18722286820411682
test loss item: 0.16234536468982697
test loss item: 0.15546950697898865
test loss item: 0.2429056614637375
test loss item: 0.13002151250839233
test loss item: 0.20165754854679108
test loss item: 0.1652512550354004
test loss item: 0.21063382923603058
test loss item: 0.22908733785152435
test loss item: 0.2662985324859619
test loss item: 0.1239880695939064
Epoch [36/50], Training Loss: 0.1600, Testing Loss: 0.1891
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 37/50
train loss item: 0.17662660777568817
train loss item: 0.15001708269119263
train loss item: 0.14675714075565338
train loss item: 0.1710670441389084
train loss item: 0.16866473853588104
train loss item: 0.14587213099002838
train loss item: 0.17427505552768707
train loss item: 0.20773814618587494
train loss item: 0.14674368500709534
train loss item: 0.16350430250167847
train loss item: 0.15394575893878937
train loss item: 0.12194754928350449
test loss item: 0.20202745497226715
test loss item: 0.18553954362869263
test loss item: 0.17033688724040985
test loss item: 0.15848703682422638
test loss item: 0.24147608876228333
test loss item: 0.13757087290287018
test loss item: 0.1984260231256485
test loss item: 0.1710469275712967
test loss item: 0.21653681993484497
test loss item: 0.21373511850833893
test loss item: 0.26786646246910095
test loss item: 0.13752923905849457
Epoch [37/50], Training Loss: 0.1606, Testing Loss: 0.1917
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 38/50
train loss item: 0.17124183475971222
train loss item: 0.15503282845020294
train loss item: 0.1546521931886673
train loss item: 0.22169005870819092
train loss item: 0.15168137848377228
train loss item: 0.11319740116596222
train loss item: 0.16813470423221588
train loss item: 0.2123788446187973
train loss item: 0.1538035273551941
train loss item: 0.1595357060432434
train loss item: 0.21635814011096954
train loss item: 0.12448577582836151
test loss item: 0.1491391956806183
test loss item: 0.13887713849544525
test loss item: 0.13037434220314026
test loss item: 0.11969053000211716
test loss item: 0.17781133949756622
test loss item: 0.11785749346017838
test loss item: 0.1502314656972885
test loss item: 0.1293967366218567
test loss item: 0.1625700742006302
test loss item: 0.1696736067533493
test loss item: 0.1822987198829651
test loss item: 0.12512455880641937
Epoch [38/50], Training Loss: 0.1668, Testing Loss: 0.1461
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 39/50
train loss item: 0.15046356618404388
train loss item: 0.15664458274841309
train loss item: 0.21620652079582214
train loss item: 0.3016335964202881
train loss item: 0.20483848452568054
train loss item: 0.1110292449593544
train loss item: 0.15305493772029877
train loss item: 0.19663462042808533
train loss item: 0.13326430320739746
train loss item: 0.1920699030160904
train loss item: 0.257679283618927
train loss item: 0.12301521748304367
test loss item: 0.14642685651779175
test loss item: 0.12204848974943161
test loss item: 0.12546893954277039
test loss item: 0.11592799425125122
test loss item: 0.1700693964958191
test loss item: 0.11536676436662674
test loss item: 0.1382046490907669
test loss item: 0.12237758189439774
test loss item: 0.14901573956012726
test loss item: 0.16634631156921387
test loss item: 0.1712460070848465
test loss item: 0.1371401697397232
Epoch [39/50], Training Loss: 0.1830, Testing Loss: 0.1400
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 40/50
train loss item: 0.16250406205654144
train loss item: 0.14099407196044922
train loss item: 0.14540162682533264
train loss item: 0.24986983835697174
train loss item: 0.18125426769256592
train loss item: 0.12707580626010895
train loss item: 0.15128016471862793
train loss item: 0.18141835927963257
train loss item: 0.13273607194423676
train loss item: 0.19338564574718475
train loss item: 0.3009318709373474
train loss item: 0.1236637532711029
test loss item: 0.18064580857753754
test loss item: 0.15055684745311737
test loss item: 0.13328471779823303
test loss item: 0.138086199760437
test loss item: 0.2145266830921173
test loss item: 0.11745543777942657
test loss item: 0.1684097796678543
test loss item: 0.12919092178344727
test loss item: 0.1840449422597885
test loss item: 0.26149773597717285
test loss item: 0.23549184203147888
test loss item: 0.11948320269584656
Epoch [40/50], Training Loss: 0.1742, Testing Loss: 0.1694
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 41/50
train loss item: 0.1650848239660263
train loss item: 0.1321522295475006
train loss item: 0.1453409045934677
train loss item: 0.2190607786178589
train loss item: 0.18540628254413605
train loss item: 0.1547708511352539
train loss item: 0.1644466668367386
train loss item: 0.13513176143169403
train loss item: 0.1308935433626175
train loss item: 0.22595776617527008
train loss item: 0.36093848943710327
train loss item: 0.11771071702241898
test loss item: 0.15431863069534302
test loss item: 0.15363675355911255
test loss item: 0.12954233586788177
test loss item: 0.13216720521450043
test loss item: 0.21034905314445496
test loss item: 0.11556939035654068
test loss item: 0.16689962148666382
test loss item: 0.12931419909000397
test loss item: 0.16832824051380157
test loss item: 0.2550313472747803
test loss item: 0.23230589926242828
test loss item: 0.13916845619678497
Epoch [41/50], Training Loss: 0.1781, Testing Loss: 0.1656
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 42/50
train loss item: 0.2280053347349167
train loss item: 0.11971142888069153
train loss item: 0.12769797444343567
train loss item: 0.1586238592863083
train loss item: 0.15331104397773743
train loss item: 0.18544749915599823
train loss item: 0.2183288335800171
train loss item: 0.21663828194141388
train loss item: 0.18181639909744263
train loss item: 0.17428265511989594
train loss item: 0.22443531453609467
train loss item: 0.13007810711860657
test loss item: 0.1770389825105667
test loss item: 0.16359259188175201
test loss item: 0.1468510627746582
test loss item: 0.14196398854255676
test loss item: 0.2139257937669754
test loss item: 0.12468268722295761
test loss item: 0.178908571600914
test loss item: 0.13810181617736816
test loss item: 0.17866700887680054
test loss item: 0.1940080225467682
test loss item: 0.23361018300056458
test loss item: 0.14211668074131012
Epoch [42/50], Training Loss: 0.1765, Testing Loss: 0.1695
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 43/50
train loss item: 0.175918847322464
train loss item: 0.1389072835445404
train loss item: 0.17876741290092468
train loss item: 0.2220936417579651
train loss item: 0.17641770839691162
train loss item: 0.11303411424160004
train loss item: 0.16621257364749908
train loss item: 0.199554443359375
train loss item: 0.17218376696109772
train loss item: 0.17002074420452118
train loss item: 0.1664467602968216
train loss item: 0.14239981770515442
test loss item: 0.14189042150974274
test loss item: 0.12540358304977417
test loss item: 0.12451022863388062
test loss item: 0.11405569314956665
test loss item: 0.1655547320842743
test loss item: 0.11168821156024933
test loss item: 0.13380180299282074
test loss item: 0.11771810054779053
test loss item: 0.15174123644828796
test loss item: 0.16756443679332733
test loss item: 0.17313602566719055
test loss item: 0.12279604375362396
Epoch [43/50], Training Loss: 0.1685, Testing Loss: 0.1375
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 44/50
train loss item: 0.162436842918396
train loss item: 0.11394305527210236
train loss item: 0.14527678489685059
train loss item: 0.20953388512134552
train loss item: 0.1867896318435669
train loss item: 0.11818905174732208
train loss item: 0.13122670352458954
train loss item: 0.13806824386119843
train loss item: 0.12499770522117615
train loss item: 0.1434304416179657
train loss item: 0.15526297688484192
train loss item: 0.129337877035141
test loss item: 0.1420106440782547
test loss item: 0.12397236377000809
test loss item: 0.11744294315576553
test loss item: 0.11267243325710297
test loss item: 0.1619522124528885
test loss item: 0.10665860027074814
test loss item: 0.13619284331798553
test loss item: 0.1164538636803627
test loss item: 0.14008304476737976
test loss item: 0.14350256323814392
test loss item: 0.163675457239151
test loss item: 0.11826711893081665
Epoch [44/50], Training Loss: 0.1465, Testing Loss: 0.1319
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 45/50
train loss item: 0.19271937012672424
train loss item: 0.11472105234861374
train loss item: 0.12111511826515198
train loss item: 0.14063668251037598
train loss item: 0.1454823762178421
train loss item: 0.10815657675266266
train loss item: 0.13123004138469696
train loss item: 0.13269779086112976
train loss item: 0.11150150746107101
train loss item: 0.15702632069587708
train loss item: 0.1480519324541092
train loss item: 0.11594492197036743
test loss item: 0.1417226642370224
test loss item: 0.12975090742111206
test loss item: 0.11596307903528214
test loss item: 0.1152832880616188
test loss item: 0.1688985973596573
test loss item: 0.10435620695352554
test loss item: 0.14229334890842438
test loss item: 0.11603187769651413
test loss item: 0.14440302550792694
test loss item: 0.16186323761940002
test loss item: 0.1751445233821869
test loss item: 0.11496255546808243
Epoch [45/50], Training Loss: 0.1349, Testing Loss: 0.1359
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 46/50
train loss item: 0.1714152693748474
train loss item: 0.12118551135063171
train loss item: 0.12805065512657166
train loss item: 0.1541656255722046
train loss item: 0.1314120888710022
train loss item: 0.10289521515369415
train loss item: 0.13615839183330536
train loss item: 0.1614544689655304
train loss item: 0.11843118071556091
train loss item: 0.1744849979877472
train loss item: 0.15520991384983063
train loss item: 0.11233007907867432
test loss item: 0.13616853952407837
test loss item: 0.12377665191888809
test loss item: 0.114425428211689
test loss item: 0.11039215326309204
test loss item: 0.16253407299518585
test loss item: 0.10373497754335403
test loss item: 0.13452397286891937
test loss item: 0.11483704298734665
test loss item: 0.14480896294116974
test loss item: 0.1643826961517334
test loss item: 0.16921231150627136
test loss item: 0.12542343139648438
Epoch [46/50], Training Loss: 0.1389, Testing Loss: 0.1337
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 47/50
train loss item: 0.13878501951694489
train loss item: 0.12108875066041946
train loss item: 0.13515637814998627
train loss item: 0.18550272285938263
train loss item: 0.15808017551898956
train loss item: 0.11155170202255249
train loss item: 0.12967488169670105
train loss item: 0.16069364547729492
train loss item: 0.1211535856127739
train loss item: 0.17601653933525085
train loss item: 0.23332783579826355
train loss item: 0.11398895829916
test loss item: 0.13745561242103577
test loss item: 0.11388450860977173
test loss item: 0.11879844218492508
test loss item: 0.10582226514816284
test loss item: 0.15203924477100372
test loss item: 0.10433418303728104
test loss item: 0.12398254871368408
test loss item: 0.11491457372903824
test loss item: 0.14064288139343262
test loss item: 0.13634301722049713
test loss item: 0.15465384721755981
test loss item: 0.11878129094839096
Epoch [47/50], Training Loss: 0.1488, Testing Loss: 0.1268
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 48/50
train loss item: 0.15368494391441345
train loss item: 0.10676328092813492
train loss item: 0.1255888193845749
train loss item: 0.15582333505153656
train loss item: 0.16760089993476868
train loss item: 0.13655881583690643
train loss item: 0.15229587256908417
train loss item: 0.13103516399860382
train loss item: 0.11346525698900223
train loss item: 0.1485416740179062
train loss item: 0.2739039659500122
train loss item: 0.11088551580905914
test loss item: 0.1964835673570633
test loss item: 0.13618682324886322
test loss item: 0.15191338956356049
test loss item: 0.1352216899394989
test loss item: 0.19183219969272614
test loss item: 0.12745176255702972
test loss item: 0.1504088193178177
test loss item: 0.13653233647346497
test loss item: 0.19128885865211487
test loss item: 0.19217118620872498
test loss item: 0.21520304679870605
test loss item: 0.11339760571718216
Epoch [48/50], Training Loss: 0.1480, Testing Loss: 0.1615
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 49/50
train loss item: 0.18918268382549286
train loss item: 0.12382039427757263
train loss item: 0.13114109635353088
train loss item: 0.18844279646873474
train loss item: 0.13156567513942719
train loss item: 0.1334744691848755
train loss item: 0.16591258347034454
train loss item: 0.17890577018260956
train loss item: 0.17784151434898376
train loss item: 0.14195233583450317
train loss item: 0.1932382881641388
train loss item: 0.13519872725009918
test loss item: 0.158513605594635
test loss item: 0.13842861354351044
test loss item: 0.13341659307479858
test loss item: 0.12652400135993958
test loss item: 0.18798290193080902
test loss item: 0.11950305104255676
test loss item: 0.1488574892282486
test loss item: 0.12630289793014526
test loss item: 0.1648113876581192
test loss item: 0.20664210617542267
test loss item: 0.2011079639196396
test loss item: 0.1107938289642334
Epoch [49/50], Training Loss: 0.1576, Testing Loss: 0.1519
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 50/50
train loss item: 0.13317978382110596
train loss item: 0.11693627387285233
train loss item: 0.14995038509368896
train loss item: 0.22532056272029877
train loss item: 0.14179302752017975
train loss item: 0.10182908922433853
train loss item: 0.15622352063655853
train loss item: 0.1461845338344574
train loss item: 0.12717010080814362
train loss item: 0.14260606467723846
train loss item: 0.15841145813465118
train loss item: 0.1337430775165558
test loss item: 0.14609496295452118
test loss item: 0.11559604108333588
test loss item: 0.11443852633237839
test loss item: 0.10771264135837555
test loss item: 0.16490131616592407
test loss item: 0.09884770959615707
test loss item: 0.1239958181977272
test loss item: 0.11026378720998764
test loss item: 0.14709503948688507
test loss item: 0.17069809138774872
test loss item: 0.17202645540237427
test loss item: 0.11282573640346527
Epoch [50/50], Training Loss: 0.1444, Testing Loss: 0.1320
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
loss item: 0.16791477799415588
loss item: 0.1268749237060547
loss item: 0.12717993557453156
loss item: 0.19269168376922607
loss item: 0.12803387641906738
loss item: 0.15599855780601501
Val Loss: 0.1498
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.0001 16 360 done at Tue Nov 12 11:48:11 CET 2024
UNet2 with 1 50 0.0005 16 360 start at Tue Nov 12 11:48:11 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.347920298576355
train loss item: 0.7266309261322021
train loss item: 0.7740239500999451
train loss item: 1.0496364831924438
train loss item: 1.0384632349014282
train loss item: 0.6429359912872314
train loss item: 0.7671623826026917
train loss item: 0.6212307810783386
train loss item: 0.664842963218689
train loss item: 0.7059001922607422
train loss item: 0.9865418672561646
train loss item: 0.5210573077201843
test loss item: 1.0750242471694946
test loss item: 0.8186753392219543
test loss item: 0.6963887810707092
test loss item: 0.7405107021331787
test loss item: 1.2123366594314575
test loss item: 0.5293529033660889
test loss item: 0.9360984563827515
test loss item: 0.5811087489128113
test loss item: 1.0645079612731934
test loss item: 1.5043264627456665
test loss item: 1.4069602489471436
test loss item: 0.1715167760848999
Epoch [1/50], Training Loss: 0.8205, Testing Loss: 0.8947
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/50
train loss item: 0.5976001024246216
train loss item: 0.404432475566864
train loss item: 0.46110159158706665
train loss item: 0.6248660087585449
train loss item: 0.6578819751739502
train loss item: 0.4129352867603302
train loss item: 0.5289116501808167
train loss item: 0.466266930103302
train loss item: 0.5522606372833252
train loss item: 0.5483872890472412
train loss item: 0.72178715467453
train loss item: 0.3981081545352936
test loss item: 0.6951031684875488
test loss item: 0.6855345964431763
test loss item: 0.5552680492401123
test loss item: 0.5515146255493164
test loss item: 0.9765982627868652
test loss item: 0.4372808635234833
test loss item: 0.7715692520141602
test loss item: 0.5051904916763306
test loss item: 0.7599215507507324
test loss item: 0.9974735379219055
test loss item: 1.0572090148925781
test loss item: 0.17621488869190216
Epoch [2/50], Training Loss: 0.5312, Testing Loss: 0.6807
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/50
train loss item: 0.5564646124839783
train loss item: 0.36679497361183167
train loss item: 0.46974292397499084
train loss item: 0.6266964077949524
train loss item: 0.6239770650863647
train loss item: 0.2967890799045563
train loss item: 0.5078396201133728
train loss item: 0.45546892285346985
train loss item: 0.4670780897140503
train loss item: 0.6057668328285217
train loss item: 0.5718547105789185
train loss item: 0.4719809889793396
test loss item: 0.601479709148407
test loss item: 0.36655980348587036
test loss item: 0.4381048381328583
test loss item: 0.3487030863761902
test loss item: 0.6187194585800171
test loss item: 0.3015715777873993
test loss item: 0.4195058047771454
test loss item: 0.394687682390213
test loss item: 0.5801385641098022
test loss item: 0.4605366289615631
test loss item: 0.6481929421424866
test loss item: 0.18259242177009583
Epoch [3/50], Training Loss: 0.5017, Testing Loss: 0.4467
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/50
train loss item: 0.5266653895378113
train loss item: 0.40741994976997375
train loss item: 0.38162708282470703
train loss item: 0.5175790786743164
train loss item: 0.6108929514884949
train loss item: 0.2500734329223633
train loss item: 0.48713406920433044
train loss item: 0.4424532949924469
train loss item: 0.3712909519672394
train loss item: 0.623035192489624
train loss item: 0.5140435695648193
train loss item: 0.3840923011302948
test loss item: 0.4136197865009308
test loss item: 0.43308714032173157
test loss item: 0.3077199161052704
test loss item: 0.3446415066719055
test loss item: 0.6317203044891357
test loss item: 0.255999892950058
test loss item: 0.43539324402809143
test loss item: 0.3177187740802765
test loss item: 0.49354106187820435
test loss item: 0.8454915285110474
test loss item: 0.7373334169387817
test loss item: 0.191436767578125
Epoch [4/50], Training Loss: 0.4597, Testing Loss: 0.4506
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/50
train loss item: 0.5377596020698547
train loss item: 0.3803800344467163
train loss item: 0.34885427355766296
train loss item: 0.427085816860199
train loss item: 0.5748775005340576
train loss item: 0.32408496737480164
train loss item: 0.5103691816329956
train loss item: 0.4194781184196472
train loss item: 0.2533554136753082
train loss item: 0.45544153451919556
train loss item: 0.5112985968589783
train loss item: 0.2702866196632385
test loss item: 0.4278124272823334
test loss item: 0.47967442870140076
test loss item: 0.31891247630119324
test loss item: 0.38489314913749695
test loss item: 0.6725550293922424
test loss item: 0.29462677240371704
test loss item: 0.46586382389068604
test loss item: 0.3320733308792114
test loss item: 0.5183951258659363
test loss item: 0.9548979997634888
test loss item: 0.8068073987960815
test loss item: 0.3174644410610199
Epoch [5/50], Training Loss: 0.4178, Testing Loss: 0.4978
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/50
train loss item: 0.5181736946105957
train loss item: 0.42800554633140564
train loss item: 0.3661326766014099
train loss item: 0.37522920966148376
train loss item: 0.44005200266838074
train loss item: 0.25558826327323914
train loss item: 0.4663074016571045
train loss item: 0.43790823221206665
train loss item: 0.2666897773742676
train loss item: 0.45322006940841675
train loss item: 0.5259264707565308
train loss item: 0.2524566352367401
test loss item: 0.35432830452919006
test loss item: 0.36713945865631104
test loss item: 0.2747046649456024
test loss item: 0.2919839322566986
test loss item: 0.508633553981781
test loss item: 0.24852685630321503
test loss item: 0.36112189292907715
test loss item: 0.26502853631973267
test loss item: 0.4139389991760254
test loss item: 0.6986818909645081
test loss item: 0.6084767580032349
test loss item: 0.17104218900203705
Epoch [6/50], Training Loss: 0.3988, Testing Loss: 0.3803
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/50
train loss item: 0.3896583318710327
train loss item: 0.3583512008190155
train loss item: 0.3266514539718628
train loss item: 0.38524550199508667
train loss item: 0.3888172209262848
train loss item: 0.26679396629333496
train loss item: 0.3344147205352783
train loss item: 0.3553667962551117
train loss item: 0.25212931632995605
train loss item: 0.4066944718360901
train loss item: 0.5139721632003784
train loss item: 0.24402335286140442
test loss item: 0.320365309715271
test loss item: 0.23007917404174805
test loss item: 0.22358520328998566
test loss item: 0.22027122974395752
test loss item: 0.333446741104126
test loss item: 0.18483924865722656
test loss item: 0.23355881869792938
test loss item: 0.20403698086738586
test loss item: 0.2984307110309601
test loss item: 0.3766147792339325
test loss item: 0.3809087574481964
test loss item: 0.16893626749515533
Epoch [7/50], Training Loss: 0.3518, Testing Loss: 0.2646
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/50
train loss item: 0.2900797724723816
train loss item: 0.2899520695209503
train loss item: 0.26401472091674805
train loss item: 0.334107905626297
train loss item: 0.3422606885433197
train loss item: 0.2412721812725067
train loss item: 0.2969804108142853
train loss item: 0.29403671622276306
train loss item: 0.1964939683675766
train loss item: 0.3482327461242676
train loss item: 0.42467162013053894
train loss item: 0.22400808334350586
test loss item: 0.3730446994304657
test loss item: 0.26055100560188293
test loss item: 0.2354128360748291
test loss item: 0.24335168302059174
test loss item: 0.4050275981426239
test loss item: 0.19336602091789246
test loss item: 0.27145475149154663
test loss item: 0.24156953394412994
test loss item: 0.3427569270133972
test loss item: 0.3999805450439453
test loss item: 0.4496302008628845
test loss item: 0.1622830629348755
Epoch [8/50], Training Loss: 0.2955, Testing Loss: 0.2982
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/50
train loss item: 0.29819455742836
train loss item: 0.26895251870155334
train loss item: 0.21893127262592316
train loss item: 0.284771203994751
train loss item: 0.294852614402771
train loss item: 0.17855922877788544
train loss item: 0.2619316577911377
train loss item: 0.24963027238845825
train loss item: 0.20194394886493683
train loss item: 0.3032286465167999
train loss item: 0.3323025703430176
train loss item: 0.1965257078409195
test loss item: 0.4559842050075531
test loss item: 0.26058152318000793
test loss item: 0.24353660643100739
test loss item: 0.27119266986846924
test loss item: 0.3834061920642853
test loss item: 0.19106425344944
test loss item: 0.2751503586769104
test loss item: 0.21089468896389008
test loss item: 0.4002637267112732
test loss item: 0.4550880193710327
test loss item: 0.4866703152656555
test loss item: 0.15700039267539978
Epoch [9/50], Training Loss: 0.2575, Testing Loss: 0.3159
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/50
train loss item: 0.3313371241092682
train loss item: 0.28802111744880676
train loss item: 0.21137720346450806
train loss item: 0.23959366977214813
train loss item: 0.2594589293003082
train loss item: 0.16060705482959747
train loss item: 0.2623469829559326
train loss item: 0.261530339717865
train loss item: 0.20206382870674133
train loss item: 0.3684733808040619
train loss item: 0.31196293234825134
train loss item: 0.18311436474323273
test loss item: 0.3636276423931122
test loss item: 0.2488427609205246
test loss item: 0.2089160978794098
test loss item: 0.23157237470149994
test loss item: 0.3532368242740631
test loss item: 0.16674131155014038
test loss item: 0.24989157915115356
test loss item: 0.19827574491500854
test loss item: 0.3395673334598541
test loss item: 0.43683499097824097
test loss item: 0.4441869854927063
test loss item: 0.14056706428527832
Epoch [10/50], Training Loss: 0.2567, Testing Loss: 0.2819
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 11/50
train loss item: 0.3172994554042816
train loss item: 0.2943981885910034
train loss item: 0.24461829662322998
train loss item: 0.239157572388649
train loss item: 0.3122917413711548
train loss item: 0.1966087371110916
train loss item: 0.24039490520954132
train loss item: 0.23958726227283478
train loss item: 0.2207837700843811
train loss item: 0.43334269523620605
train loss item: 0.343569278717041
train loss item: 0.20435424149036407
test loss item: 0.23126520216464996
test loss item: 0.2552446126937866
test loss item: 0.18730291724205017
test loss item: 0.20037029683589935
test loss item: 0.33272603154182434
test loss item: 0.14321403205394745
test loss item: 0.25820010900497437
test loss item: 0.18960560858249664
test loss item: 0.25864651799201965
test loss item: 0.3840022385120392
test loss item: 0.3963817358016968
test loss item: 0.13998447358608246
Epoch [11/50], Training Loss: 0.2739, Testing Loss: 0.2481
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 12/50
train loss item: 0.2267128825187683
train loss item: 0.1885334849357605
train loss item: 0.2006455659866333
train loss item: 0.21038185060024261
train loss item: 0.29058578610420227
train loss item: 0.2637898921966553
train loss item: 0.16738426685333252
train loss item: 0.1728293001651764
train loss item: 0.16569721698760986
train loss item: 0.3510734736919403
train loss item: 0.3778233528137207
train loss item: 0.14504744112491608
test loss item: 0.22262537479400635
test loss item: 0.22845987975597382
test loss item: 0.18320035934448242
test loss item: 0.18712612986564636
test loss item: 0.30803337693214417
test loss item: 0.14417488873004913
test loss item: 0.23869960010051727
test loss item: 0.1794324368238449
test loss item: 0.24052555859088898
test loss item: 0.3185957074165344
test loss item: 0.34794101119041443
test loss item: 0.13624520599842072
Epoch [12/50], Training Loss: 0.2300, Testing Loss: 0.2279
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 13/50
train loss item: 0.19430477917194366
train loss item: 0.20257769525051117
train loss item: 0.16778281331062317
train loss item: 0.21569930016994476
train loss item: 0.25873661041259766
train loss item: 0.2005169838666916
train loss item: 0.1941172480583191
train loss item: 0.1814965456724167
train loss item: 0.15334013104438782
train loss item: 0.28319236636161804
train loss item: 0.20741470158100128
train loss item: 0.16872893273830414
test loss item: 0.22409820556640625
test loss item: 0.24997803568840027
test loss item: 0.1611500084400177
test loss item: 0.19392690062522888
test loss item: 0.33816441893577576
test loss item: 0.13650290668010712
test loss item: 0.25905659794807434
test loss item: 0.17245642840862274
test loss item: 0.2675410211086273
test loss item: 0.46137937903404236
test loss item: 0.41881683468818665
test loss item: 0.1507956087589264
Epoch [13/50], Training Loss: 0.2023, Testing Loss: 0.2528
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 14/50
train loss item: 0.25602707266807556
train loss item: 0.15526042878627777
train loss item: 0.16293711960315704
train loss item: 0.18311382830142975
train loss item: 0.21905536949634552
train loss item: 0.1899208277463913
train loss item: 0.1683693826198578
train loss item: 0.15738649666309357
train loss item: 0.14074259996414185
train loss item: 0.2790276110172272
train loss item: 0.26980292797088623
train loss item: 0.13513047993183136
test loss item: 0.2354670763015747
test loss item: 0.2575245499610901
test loss item: 0.15838979184627533
test loss item: 0.213461235165596
test loss item: 0.33097413182258606
test loss item: 0.135234072804451
test loss item: 0.26151135563850403
test loss item: 0.18180106580257416
test loss item: 0.2636595368385315
test loss item: 0.4199168086051941
test loss item: 0.4017721712589264
test loss item: 0.196289524435997
Epoch [14/50], Training Loss: 0.1931, Testing Loss: 0.2547
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 15/50
train loss item: 0.2292671948671341
train loss item: 0.21449093520641327
train loss item: 0.20764541625976562
train loss item: 0.199575275182724
train loss item: 0.24083155393600464
train loss item: 0.19494132697582245
train loss item: 0.27762195467948914
train loss item: 0.21805809438228607
train loss item: 0.15988875925540924
train loss item: 0.28354665637016296
train loss item: 0.2564166486263275
train loss item: 0.16859067976474762
test loss item: 0.3006569743156433
test loss item: 0.3706344664096832
test loss item: 0.2029949277639389
test loss item: 0.27177006006240845
test loss item: 0.5041607618331909
test loss item: 0.18254782259464264
test loss item: 0.39179304242134094
test loss item: 0.22954751551151276
test loss item: 0.38425809144973755
test loss item: 0.7302683591842651
test loss item: 0.6334853172302246
test loss item: 0.12026305496692657
Epoch [15/50], Training Loss: 0.2209, Testing Loss: 0.3602
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 16/50
train loss item: 0.31527629494667053
train loss item: 0.18586377799510956
train loss item: 0.16870439052581787
train loss item: 0.20734794437885284
train loss item: 0.2478432059288025
train loss item: 0.1786477118730545
train loss item: 0.15856574475765228
train loss item: 0.16189569234848022
train loss item: 0.13570019602775574
train loss item: 0.24297848343849182
train loss item: 0.24012596905231476
train loss item: 0.135133296251297
test loss item: 0.28658634424209595
test loss item: 0.23321311175823212
test loss item: 0.17673687636852264
test loss item: 0.203798308968544
test loss item: 0.3382575809955597
test loss item: 0.15669415891170502
test loss item: 0.25894293189048767
test loss item: 0.18379025161266327
test loss item: 0.27749139070510864
test loss item: 0.38697054982185364
test loss item: 0.38229110836982727
test loss item: 0.12324150651693344
Epoch [16/50], Training Loss: 0.1982, Testing Loss: 0.2507
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 17/50
train loss item: 0.20575426518917084
train loss item: 0.22177399694919586
train loss item: 0.19342154264450073
train loss item: 0.2436654269695282
train loss item: 0.2076922357082367
train loss item: 0.16562870144844055
train loss item: 0.30233675241470337
train loss item: 0.3268299996852875
train loss item: 0.15787860751152039
train loss item: 0.32411226630210876
train loss item: 0.2369581162929535
train loss item: 0.16162578761577606
test loss item: 0.28081831336021423
test loss item: 0.35278987884521484
test loss item: 0.22470220923423767
test loss item: 0.27353426814079285
test loss item: 0.4605652689933777
test loss item: 0.1991993486881256
test loss item: 0.3676659166812897
test loss item: 0.24460479617118835
test loss item: 0.3347383737564087
test loss item: 0.5819656848907471
test loss item: 0.5586283802986145
test loss item: 0.154598668217659
Epoch [17/50], Training Loss: 0.2290, Testing Loss: 0.3362
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 18/50
train loss item: 0.26976916193962097
train loss item: 0.2836006283760071
train loss item: 0.2149098813533783
train loss item: 0.27852240204811096
train loss item: 0.29189565777778625
train loss item: 0.18533603847026825
train loss item: 0.2775908410549164
train loss item: 0.37145623564720154
train loss item: 0.21493636071681976
train loss item: 0.40627604722976685
train loss item: 0.3785817325115204
train loss item: 0.1866263449192047
test loss item: 0.3490235209465027
test loss item: 0.30502527952194214
test loss item: 0.28634560108184814
test loss item: 0.24670863151550293
test loss item: 0.42708727717399597
test loss item: 0.17113466560840607
test loss item: 0.3052835762500763
test loss item: 0.2745756208896637
test loss item: 0.3847156763076782
test loss item: 0.38331174850463867
test loss item: 0.5056861042976379
test loss item: 0.14688682556152344
Epoch [18/50], Training Loss: 0.2800, Testing Loss: 0.3155
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 19/50
train loss item: 0.25941649079322815
train loss item: 0.2767918109893799
train loss item: 0.2455497831106186
train loss item: 0.37559792399406433
train loss item: 0.3087151050567627
train loss item: 0.27355825901031494
train loss item: 0.287615031003952
train loss item: 0.347504585981369
train loss item: 0.2143738865852356
train loss item: 0.34375694394111633
train loss item: 0.5195976495742798
train loss item: 0.14652599394321442
test loss item: 0.27969199419021606
test loss item: 0.19079846143722534
test loss item: 0.22753377258777618
test loss item: 0.17180682718753815
test loss item: 0.2709243893623352
test loss item: 0.15861156582832336
test loss item: 0.203426331281662
test loss item: 0.21738874912261963
test loss item: 0.27701616287231445
test loss item: 0.19661493599414825
test loss item: 0.27903926372528076
test loss item: 0.25979533791542053
Epoch [19/50], Training Loss: 0.2999, Testing Loss: 0.2277
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 20/50
train loss item: 0.3207132816314697
train loss item: 0.19198599457740784
train loss item: 0.22655542194843292
train loss item: 0.3650714159011841
train loss item: 0.27836355566978455
train loss item: 0.3218759000301361
train loss item: 0.20851482450962067
train loss item: 0.18713787198066711
train loss item: 0.19846892356872559
train loss item: 0.27172574400901794
train loss item: 0.5682986378669739
train loss item: 0.1870092898607254
test loss item: 0.22471113502979279
test loss item: 0.24132755398750305
test loss item: 0.1877758502960205
test loss item: 0.18784378468990326
test loss item: 0.32272154092788696
test loss item: 0.16431014239788055
test loss item: 0.266796737909317
test loss item: 0.16498467326164246
test loss item: 0.2560300827026367
test loss item: 0.396428644657135
test loss item: 0.34960824251174927
test loss item: 0.1566811352968216
Epoch [20/50], Training Loss: 0.2771, Testing Loss: 0.2433
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 21/50
train loss item: 0.36483311653137207
train loss item: 0.13222050666809082
train loss item: 0.16247008740901947
train loss item: 0.21500131487846375
train loss item: 0.18290828168392181
train loss item: 0.28007960319519043
train loss item: 0.2098878175020218
train loss item: 0.21871380507946014
train loss item: 0.20451143383979797
train loss item: 0.16778352856636047
train loss item: 0.39069896936416626
train loss item: 0.15958207845687866
test loss item: 0.19964458048343658
test loss item: 0.19445742666721344
test loss item: 0.16115021705627441
test loss item: 0.16614830493927002
test loss item: 0.24295084178447723
test loss item: 0.13556906580924988
test loss item: 0.19725240767002106
test loss item: 0.14761687815189362
test loss item: 0.19361522793769836
test loss item: 0.22166432440280914
test loss item: 0.2702315151691437
test loss item: 0.24430489540100098
Epoch [21/50], Training Loss: 0.2241, Testing Loss: 0.1979
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 22/50
train loss item: 0.2620703876018524
train loss item: 0.14673325419425964
train loss item: 0.16115672886371613
train loss item: 0.21747533977031708
train loss item: 0.173495352268219
train loss item: 0.18291907012462616
train loss item: 0.18570812046527863
train loss item: 0.17163453996181488
train loss item: 0.18776527047157288
train loss item: 0.1893610805273056
train loss item: 0.35770556330680847
train loss item: 0.1255807727575302
test loss item: 0.2196696698665619
test loss item: 0.17166920006275177
test loss item: 0.1646527200937271
test loss item: 0.15934967994689941
test loss item: 0.2202671766281128
test loss item: 0.14697808027267456
test loss item: 0.17769712209701538
test loss item: 0.1414482146501541
test loss item: 0.20431537926197052
test loss item: 0.19467267394065857
test loss item: 0.24427710473537445
test loss item: 0.1708427369594574
Epoch [22/50], Training Loss: 0.1968, Testing Loss: 0.1847
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 23/50
train loss item: 0.217006653547287
train loss item: 0.17211146652698517
train loss item: 0.15574534237384796
train loss item: 0.18851961195468903
train loss item: 0.1821197271347046
train loss item: 0.1406295895576477
train loss item: 0.15106265246868134
train loss item: 0.13912825286388397
train loss item: 0.1484285444021225
train loss item: 0.2145688682794571
train loss item: 0.35513433814048767
train loss item: 0.13741278648376465
test loss item: 0.22905132174491882
test loss item: 0.13549308478832245
test loss item: 0.1292019635438919
test loss item: 0.1323872208595276
test loss item: 0.18657894432544708
test loss item: 0.10754908621311188
test loss item: 0.1481916755437851
test loss item: 0.11548587679862976
test loss item: 0.18713659048080444
test loss item: 0.17279615998268127
test loss item: 0.20203211903572083
test loss item: 0.11662444472312927
Epoch [23/50], Training Loss: 0.1835, Testing Loss: 0.1552
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 24/50
train loss item: 0.17618490755558014
train loss item: 0.14486998319625854
train loss item: 0.11357355862855911
train loss item: 0.16722804307937622
train loss item: 0.17792928218841553
train loss item: 0.12027346342802048
train loss item: 0.14838199317455292
train loss item: 0.13544972240924835
train loss item: 0.10870446264743805
train loss item: 0.19451527297496796
train loss item: 0.30985286831855774
train loss item: 0.13215632736682892
test loss item: 0.23366808891296387
test loss item: 0.12226169556379318
test loss item: 0.12720467150211334
test loss item: 0.13210006058216095
test loss item: 0.16932925581932068
test loss item: 0.10655218362808228
test loss item: 0.13218465447425842
test loss item: 0.11454010754823685
test loss item: 0.1845441609621048
test loss item: 0.1452489197254181
test loss item: 0.18623106181621552
test loss item: 0.11510007828474045
Epoch [24/50], Training Loss: 0.1608, Testing Loss: 0.1474
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 25/50
train loss item: 0.17160287499427795
train loss item: 0.15570300817489624
train loss item: 0.11424495279788971
train loss item: 0.1496916264295578
train loss item: 0.15704289078712463
train loss item: 0.11276107281446457
train loss item: 0.15511582791805267
train loss item: 0.16031497716903687
train loss item: 0.12099987268447876
train loss item: 0.20045211911201477
train loss item: 0.23665912449359894
train loss item: 0.1194608062505722
test loss item: 0.24887484312057495
test loss item: 0.15089969336986542
test loss item: 0.13743582367897034
test loss item: 0.1581801474094391
test loss item: 0.2076951563358307
test loss item: 0.11277837306261063
test loss item: 0.16338063776493073
test loss item: 0.1311255395412445
test loss item: 0.20242007076740265
test loss item: 0.19371984899044037
test loss item: 0.23953065276145935
test loss item: 0.10778879374265671
Epoch [25/50], Training Loss: 0.1545, Testing Loss: 0.1712
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 26/50
train loss item: 0.2029525339603424
train loss item: 0.20071347057819366
train loss item: 0.16231366991996765
train loss item: 0.1640118509531021
train loss item: 0.14527252316474915
train loss item: 0.11862727254629135
train loss item: 0.18682007491588593
train loss item: 0.20921732485294342
train loss item: 0.15679267048835754
train loss item: 0.3237321972846985
train loss item: 0.2193525731563568
train loss item: 0.1237349659204483
test loss item: 0.14916649460792542
test loss item: 0.1444281041622162
test loss item: 0.12102807313203812
test loss item: 0.1167895495891571
test loss item: 0.19978442788124084
test loss item: 0.10202264785766602
test loss item: 0.15391506254673004
test loss item: 0.1221851333975792
test loss item: 0.1544816493988037
test loss item: 0.2162126749753952
test loss item: 0.21806269884109497
test loss item: 0.08909064531326294
Epoch [26/50], Training Loss: 0.1845, Testing Loss: 0.1489
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 27/50
train loss item: 0.17954079806804657
train loss item: 0.16852307319641113
train loss item: 0.16060879826545715
train loss item: 0.19783242046833038
train loss item: 0.21716168522834778
train loss item: 0.17269662022590637
train loss item: 0.1484375149011612
train loss item: 0.19777385890483856
train loss item: 0.13872885704040527
train loss item: 0.33189141750335693
train loss item: 0.24605265259742737
train loss item: 0.11156419664621353
test loss item: 0.24034245312213898
test loss item: 0.15694956481456757
test loss item: 0.16225135326385498
test loss item: 0.15192604064941406
test loss item: 0.22331589460372925
test loss item: 0.13154840469360352
test loss item: 0.1679067760705948
test loss item: 0.1463402658700943
test loss item: 0.21940548717975616
test loss item: 0.24045081436634064
test loss item: 0.26728683710098267
test loss item: 0.12496989965438843
Epoch [27/50], Training Loss: 0.1892, Testing Loss: 0.1861
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 28/50
train loss item: 0.16541732847690582
train loss item: 0.12918928265571594
train loss item: 0.13052815198898315
train loss item: 0.22159096598625183
train loss item: 0.23699061572551727
train loss item: 0.19310984015464783
train loss item: 0.2038535177707672
train loss item: 0.23517245054244995
train loss item: 0.1498258113861084
train loss item: 0.27223846316337585
train loss item: 0.3003944456577301
train loss item: 0.1063462570309639
test loss item: 0.2964567542076111
test loss item: 0.19050200283527374
test loss item: 0.21349914371967316
test loss item: 0.1943351924419403
test loss item: 0.2598925828933716
test loss item: 0.1782897412776947
test loss item: 0.20081961154937744
test loss item: 0.20478560030460358
test loss item: 0.2858685553073883
test loss item: 0.2247215211391449
test loss item: 0.29767850041389465
test loss item: 0.24884147942066193
Epoch [28/50], Training Loss: 0.1954, Testing Loss: 0.2330
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 29/50
train loss item: 0.20009814202785492
train loss item: 0.15865547955036163
train loss item: 0.21363294124603271
train loss item: 0.3732195496559143
train loss item: 0.2912859320640564
train loss item: 0.1778484582901001
train loss item: 0.1885698139667511
train loss item: 0.1891663670539856
train loss item: 0.17185190320014954
train loss item: 0.2621529996395111
train loss item: 0.5332651734352112
train loss item: 0.16389891505241394
test loss item: 0.2340860217809677
test loss item: 0.2657734751701355
test loss item: 0.1752435564994812
test loss item: 0.2001711130142212
test loss item: 0.35650092363357544
test loss item: 0.1369500756263733
test loss item: 0.28859052062034607
test loss item: 0.17003671824932098
test loss item: 0.29698237776756287
test loss item: 0.5029795169830322
test loss item: 0.41393154859542847
test loss item: 0.12249845266342163
Epoch [29/50], Training Loss: 0.2436, Testing Loss: 0.2636
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 30/50
train loss item: 0.35966557264328003
train loss item: 0.1306314617395401
train loss item: 0.14667284488677979
train loss item: 0.19034965336322784
train loss item: 0.1653202325105667
train loss item: 0.22775350511074066
train loss item: 0.23785506188869476
train loss item: 0.2500312030315399
train loss item: 0.19640874862670898
train loss item: 0.211267352104187
train loss item: 0.2889578640460968
train loss item: 0.11924313008785248
test loss item: 0.18468117713928223
test loss item: 0.15929311513900757
test loss item: 0.13604450225830078
test loss item: 0.14560341835021973
test loss item: 0.19782759249210358
test loss item: 0.11930834501981735
test loss item: 0.17608150839805603
test loss item: 0.12449813634157181
test loss item: 0.17218393087387085
test loss item: 0.18676765263080597
test loss item: 0.2049609124660492
test loss item: 0.17899970710277557
Epoch [30/50], Training Loss: 0.2103, Testing Loss: 0.1655
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 31/50
train loss item: 0.22667616605758667
train loss item: 0.14689527451992035
train loss item: 0.1845187395811081
train loss item: 0.17201703786849976
train loss item: 0.1617608368396759
train loss item: 0.14425069093704224
train loss item: 0.19697603583335876
train loss item: 0.1717427670955658
train loss item: 0.1418168842792511
train loss item: 0.20597615838050842
train loss item: 0.28731104731559753
train loss item: 0.12274780869483948
test loss item: 0.19091209769248962
test loss item: 0.17465290427207947
test loss item: 0.1497299075126648
test loss item: 0.14683502912521362
test loss item: 0.21731555461883545
test loss item: 0.13077080249786377
test loss item: 0.17949119210243225
test loss item: 0.13165400922298431
test loss item: 0.19263553619384766
test loss item: 0.21783363819122314
test loss item: 0.24023030698299408
test loss item: 0.1818627119064331
Epoch [31/50], Training Loss: 0.1802, Testing Loss: 0.1795
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 32/50
train loss item: 0.19876882433891296
train loss item: 0.1642792522907257
train loss item: 0.1411244124174118
train loss item: 0.15431393682956696
train loss item: 0.1510152667760849
train loss item: 0.11647459864616394
train loss item: 0.15615010261535645
train loss item: 0.14037370681762695
train loss item: 0.14043596386909485
train loss item: 0.22809210419654846
train loss item: 0.2778332829475403
train loss item: 0.1313638985157013
test loss item: 0.16404347121715546
test loss item: 0.1600804179906845
test loss item: 0.13252529501914978
test loss item: 0.12596681714057922
test loss item: 0.2113916426897049
test loss item: 0.1137113943696022
test loss item: 0.16931097209453583
test loss item: 0.12290510535240173
test loss item: 0.17152181267738342
test loss item: 0.20442073047161102
test loss item: 0.22323690354824066
test loss item: 0.1191941648721695
Epoch [32/50], Training Loss: 0.1667, Testing Loss: 0.1599
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 33/50
train loss item: 0.15478050708770752
train loss item: 0.12580591440200806
train loss item: 0.1208493709564209
train loss item: 0.13703902065753937
train loss item: 0.15809854865074158
train loss item: 0.11207647621631622
train loss item: 0.14303724467754364
train loss item: 0.14050474762916565
train loss item: 0.10934610664844513
train loss item: 0.21664303541183472
train loss item: 0.2644852101802826
train loss item: 0.09828098863363266
test loss item: 0.13377349078655243
test loss item: 0.12273938953876495
test loss item: 0.10554268956184387
test loss item: 0.10077463090419769
test loss item: 0.15740056335926056
test loss item: 0.09057708084583282
test loss item: 0.12971028685569763
test loss item: 0.09478987008333206
test loss item: 0.1368514746427536
test loss item: 0.17256632447242737
test loss item: 0.1592230349779129
test loss item: 0.10273721069097519
Epoch [33/50], Training Loss: 0.1484, Testing Loss: 0.1256
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 34/50
train loss item: 0.12896427512168884
train loss item: 0.10759790241718292
train loss item: 0.1085328683257103
train loss item: 0.12970763444900513
train loss item: 0.1433587372303009
train loss item: 0.09456846117973328
train loss item: 0.12675178050994873
train loss item: 0.1211523488163948
train loss item: 0.09740926325321198
train loss item: 0.18296116590499878
train loss item: 0.2299118936061859
train loss item: 0.10482637584209442
test loss item: 0.1312922239303589
test loss item: 0.11106428503990173
test loss item: 0.10048435628414154
test loss item: 0.09862746298313141
test loss item: 0.1397337019443512
test loss item: 0.0911102220416069
test loss item: 0.11306803673505783
test loss item: 0.09794106334447861
test loss item: 0.125344380736351
test loss item: 0.14332209527492523
test loss item: 0.133637934923172
test loss item: 0.14210902154445648
Epoch [34/50], Training Loss: 0.1313, Testing Loss: 0.1190
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 35/50
train loss item: 0.13144317269325256
train loss item: 0.1216917559504509
train loss item: 0.10563895106315613
train loss item: 0.12136386334896088
train loss item: 0.1268334537744522
train loss item: 0.0969618633389473
train loss item: 0.12691356241703033
train loss item: 0.12250105291604996
train loss item: 0.11108918488025665
train loss item: 0.17169521749019623
train loss item: 0.19013038277626038
train loss item: 0.09633579850196838
test loss item: 0.13036848604679108
test loss item: 0.10149838775396347
test loss item: 0.09715361893177032
test loss item: 0.09282617270946503
test loss item: 0.12626172602176666
test loss item: 0.08758816123008728
test loss item: 0.10121641308069229
test loss item: 0.09286399930715561
test loss item: 0.11776687204837799
test loss item: 0.12211155891418457
test loss item: 0.12397637963294983
test loss item: 0.11436495929956436
Epoch [35/50], Training Loss: 0.1269, Testing Loss: 0.1090
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 36/50
train loss item: 0.1396559476852417
train loss item: 0.13946376740932465
train loss item: 0.1284625381231308
train loss item: 0.14896659553050995
train loss item: 0.1417877972126007
train loss item: 0.1173359751701355
train loss item: 0.12225750088691711
train loss item: 0.13956359028816223
train loss item: 0.11168336868286133
train loss item: 0.22024662792682648
train loss item: 0.18960897624492645
train loss item: 0.09403733164072037
test loss item: 0.11568517982959747
test loss item: 0.10392504185438156
test loss item: 0.09595438092947006
test loss item: 0.08891573548316956
test loss item: 0.13300448656082153
test loss item: 0.08503678441047668
test loss item: 0.10809376835823059
test loss item: 0.09438180923461914
test loss item: 0.11349748075008392
test loss item: 0.12930260598659515
test loss item: 0.13266322016716003
test loss item: 0.09117487072944641
Epoch [36/50], Training Loss: 0.1411, Testing Loss: 0.1076
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 37/50
train loss item: 0.12820369005203247
train loss item: 0.10130570828914642
train loss item: 0.10135501623153687
train loss item: 0.15636783838272095
train loss item: 0.1637996882200241
train loss item: 0.11258899420499802
train loss item: 0.11222293972969055
train loss item: 0.13862428069114685
train loss item: 0.11124049872159958
train loss item: 0.1992412656545639
train loss item: 0.20241877436637878
train loss item: 0.08745084702968597
test loss item: 0.13915890455245972
test loss item: 0.11292102932929993
test loss item: 0.11115425825119019
test loss item: 0.10164887458086014
test loss item: 0.1436581313610077
test loss item: 0.09158671647310257
test loss item: 0.11759833991527557
test loss item: 0.10233364999294281
test loss item: 0.13256710767745972
test loss item: 0.13355731964111328
test loss item: 0.15171322226524353
test loss item: 0.11605606973171234
Epoch [37/50], Training Loss: 0.1346, Testing Loss: 0.1212
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 38/50
train loss item: 0.11472360789775848
train loss item: 0.10322249680757523
train loss item: 0.10818144679069519
train loss item: 0.17263539135456085
train loss item: 0.19625510275363922
train loss item: 0.1184910461306572
train loss item: 0.10571300238370895
train loss item: 0.1336950659751892
train loss item: 0.10952499508857727
train loss item: 0.21084313094615936
train loss item: 0.2612185478210449
train loss item: 0.09076201170682907
test loss item: 0.2273925542831421
test loss item: 0.1644924283027649
test loss item: 0.16917100548744202
test loss item: 0.14867916703224182
test loss item: 0.22467699646949768
test loss item: 0.13105659186840057
test loss item: 0.170846626162529
test loss item: 0.16211459040641785
test loss item: 0.22525320947170258
test loss item: 0.19887255132198334
test loss item: 0.25013843178749084
test loss item: 0.15253569185733795
Epoch [38/50], Training Loss: 0.1438, Testing Loss: 0.1854
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 39/50
train loss item: 0.1607949584722519
train loss item: 0.1314951628446579
train loss item: 0.12290964275598526
train loss item: 0.14728915691375732
train loss item: 0.19835205376148224
train loss item: 0.1568068265914917
train loss item: 0.16102413833141327
train loss item: 0.19479988515377045
train loss item: 0.14439499378204346
train loss item: 0.20791088044643402
train loss item: 0.23335401713848114
train loss item: 0.10145141184329987
test loss item: 0.30404171347618103
test loss item: 0.2066052109003067
test loss item: 0.23020772635936737
test loss item: 0.19644063711166382
test loss item: 0.2779695689678192
test loss item: 0.16579602658748627
test loss item: 0.22099138796329498
test loss item: 0.2077360898256302
test loss item: 0.30104291439056396
test loss item: 0.21907301247119904
test loss item: 0.32655069231987
test loss item: 0.11242067068815231
Epoch [39/50], Training Loss: 0.1634, Testing Loss: 0.2307
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 40/50
train loss item: 0.1573908030986786
train loss item: 0.15919049084186554
train loss item: 0.16009056568145752
train loss item: 0.1869448721408844
train loss item: 0.1331542283296585
train loss item: 0.14867368340492249
train loss item: 0.14014950394630432
train loss item: 0.1884050965309143
train loss item: 0.1764656901359558
train loss item: 0.13686874508857727
train loss item: 0.22426556050777435
train loss item: 0.11190672963857651
test loss item: 0.20118893682956696
test loss item: 0.13466709852218628
test loss item: 0.15866206586360931
test loss item: 0.13102374970912933
test loss item: 0.19096772372722626
test loss item: 0.13388337194919586
test loss item: 0.15110532939434052
test loss item: 0.13894037902355194
test loss item: 0.1906917691230774
test loss item: 0.16100867092609406
test loss item: 0.1960618644952774
test loss item: 0.12599925696849823
Epoch [40/50], Training Loss: 0.1603, Testing Loss: 0.1595
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 41/50
train loss item: 0.13548949360847473
train loss item: 0.12298563122749329
train loss item: 0.17134907841682434
train loss item: 0.27990323305130005
train loss item: 0.16465677320957184
train loss item: 0.10853983461856842
train loss item: 0.1299944669008255
train loss item: 0.15878693759441376
train loss item: 0.1316942572593689
train loss item: 0.16933460533618927
train loss item: 0.3250367343425751
train loss item: 0.09298740327358246
test loss item: 0.1676567792892456
test loss item: 0.16348516941070557
test loss item: 0.12327099591493607
test loss item: 0.13327458500862122
test loss item: 0.20888827741146088
test loss item: 0.10972335934638977
test loss item: 0.1678825169801712
test loss item: 0.11397717893123627
test loss item: 0.17450201511383057
test loss item: 0.258985698223114
test loss item: 0.23490211367607117
test loss item: 0.19776245951652527
Epoch [41/50], Training Loss: 0.1659, Testing Loss: 0.1712
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 42/50
train loss item: 0.2009177953004837
train loss item: 0.11744093149900436
train loss item: 0.1270202398300171
train loss item: 0.21079345047473907
train loss item: 0.1746170073747635
train loss item: 0.1368580013513565
train loss item: 0.1339014619588852
train loss item: 0.11605127155780792
train loss item: 0.11594703793525696
train loss item: 0.1919279545545578
train loss item: 0.3731151819229126
train loss item: 0.09919024258852005
test loss item: 0.18468725681304932
test loss item: 0.20553293824195862
test loss item: 0.15304529666900635
test loss item: 0.1600513905286789
test loss item: 0.26639944314956665
test loss item: 0.13341453671455383
test loss item: 0.22128625214099884
test loss item: 0.1362035572528839
test loss item: 0.208727166056633
test loss item: 0.3333834409713745
test loss item: 0.29088476300239563
test loss item: 0.11915957182645798
Epoch [42/50], Training Loss: 0.1665, Testing Loss: 0.2011
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 43/50
train loss item: 0.23930829763412476
train loss item: 0.11259867995977402
train loss item: 0.09642112255096436
train loss item: 0.1298806369304657
train loss item: 0.14578808844089508
train loss item: 0.15781643986701965
train loss item: 0.16501961648464203
train loss item: 0.1455746293067932
train loss item: 0.10440090298652649
train loss item: 0.1428431272506714
train loss item: 0.4144996404647827
train loss item: 0.09270403534173965
test loss item: 0.22642013430595398
test loss item: 0.24853679537773132
test loss item: 0.16533784568309784
test loss item: 0.19238795340061188
test loss item: 0.3253186047077179
test loss item: 0.13730746507644653
test loss item: 0.26834383606910706
test loss item: 0.15284790098667145
test loss item: 0.2564377188682556
test loss item: 0.42497915029525757
test loss item: 0.3748615086078644
test loss item: 0.14472784101963043
Epoch [43/50], Training Loss: 0.1622, Testing Loss: 0.2431
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 44/50
train loss item: 0.2889626622200012
train loss item: 0.13805387914180756
train loss item: 0.1746683418750763
train loss item: 0.24869176745414734
train loss item: 0.19080667197704315
train loss item: 0.1312776505947113
train loss item: 0.20593605935573578
train loss item: 0.2642033100128174
train loss item: 0.27794554829597473
train loss item: 0.31771227717399597
train loss item: 0.1513063609600067
train loss item: 0.186780646443367
test loss item: 0.18485033512115479
test loss item: 0.13084061443805695
test loss item: 0.14826197922229767
test loss item: 0.13649766147136688
test loss item: 0.17146091163158417
test loss item: 0.13051781058311462
test loss item: 0.13994760811328888
test loss item: 0.1210443302989006
test loss item: 0.17521430552005768
test loss item: 0.16756851971149445
test loss item: 0.19806261360645294
test loss item: 0.20878438651561737
Epoch [44/50], Training Loss: 0.2147, Testing Loss: 0.1594
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 45/50
train loss item: 0.1477920413017273
train loss item: 0.10839498043060303
train loss item: 0.17637544870376587
train loss item: 0.27615126967430115
train loss item: 0.24509160220623016
train loss item: 0.11206376552581787
train loss item: 0.11999333649873734
train loss item: 0.14452910423278809
train loss item: 0.15503737330436707
train loss item: 0.15481802821159363
train loss item: 0.13580983877182007
train loss item: 0.12150128930807114
test loss item: 0.19970294833183289
test loss item: 0.1243426650762558
test loss item: 0.13066190481185913
test loss item: 0.12724556028842926
test loss item: 0.1817503273487091
test loss item: 0.10883580148220062
test loss item: 0.13246344029903412
test loss item: 0.11347032338380814
test loss item: 0.184164896607399
test loss item: 0.20279040932655334
test loss item: 0.2149786651134491
test loss item: 0.10824225097894669
Epoch [45/50], Training Loss: 0.1581, Testing Loss: 0.1524
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 46/50
train loss item: 0.1926269829273224
train loss item: 0.11076889932155609
train loss item: 0.12105980515480042
train loss item: 0.14387796819210052
train loss item: 0.13935218751430511
train loss item: 0.09092511981725693
train loss item: 0.12376462668180466
train loss item: 0.1272224336862564
train loss item: 0.11031939089298248
train loss item: 0.14422382414340973
train loss item: 0.17269738018512726
train loss item: 0.10529918968677521
test loss item: 0.1923479586839676
test loss item: 0.11345108598470688
test loss item: 0.13432945311069489
test loss item: 0.11660842597484589
test loss item: 0.15844804048538208
test loss item: 0.11032682657241821
test loss item: 0.11663678288459778
test loss item: 0.11073417216539383
test loss item: 0.1703176200389862
test loss item: 0.14183881878852844
test loss item: 0.18105646967887878
test loss item: 0.13268394768238068
Epoch [46/50], Training Loss: 0.1318, Testing Loss: 0.1399
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.17000789940357208
loss item: 0.1583174616098404
loss item: 0.14136309921741486
loss item: 0.21437571942806244
loss item: 0.13890773057937622
loss item: 0.1725272387266159
Val Loss: 0.1659
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.0005 16 360 done at Tue Nov 12 11:58:27 CET 2024
UNet2 with 1 50 0.001 16 360 start at Tue Nov 12 11:58:27 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 50, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.347920298576355
train loss item: 0.8370859026908875
train loss item: 0.8084253072738647
train loss item: 1.0543510913848877
train loss item: 1.0508748292922974
train loss item: 0.6788036227226257
train loss item: 0.7902345657348633
train loss item: 0.6473392248153687
train loss item: 0.6429446935653687
train loss item: 0.6882081031799316
train loss item: 1.0367460250854492
train loss item: 0.5191578269004822
test loss item: 0.9778003692626953
test loss item: 0.7433786392211914
test loss item: 0.6972929835319519
test loss item: 0.6537982225418091
test loss item: 1.131282091140747
test loss item: 0.519782304763794
test loss item: 0.8478103876113892
test loss item: 0.5860170722007751
test loss item: 0.9901925325393677
test loss item: 1.297985553741455
test loss item: 1.2556926012039185
test loss item: 0.17182914912700653
Epoch [1/50], Training Loss: 0.8418, Testing Loss: 0.8227
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/50
train loss item: 0.6870045065879822
train loss item: 0.437121719121933
train loss item: 0.5212539434432983
train loss item: 0.6843154430389404
train loss item: 0.7345481514930725
train loss item: 0.512938380241394
train loss item: 0.6113349199295044
train loss item: 0.5482794642448425
train loss item: 0.6063655614852905
train loss item: 0.7168950438499451
train loss item: 0.8421348929405212
train loss item: 0.512139081954956
test loss item: 0.8918981552124023
test loss item: 0.7481124401092529
test loss item: 0.7143771052360535
test loss item: 0.6122287511825562
test loss item: 1.1233980655670166
test loss item: 0.4065004587173462
test loss item: 0.7986811399459839
test loss item: 0.6681426167488098
test loss item: 0.9690775275230408
test loss item: 0.8580244779586792
test loss item: 1.2461336851119995
test loss item: 0.19154666364192963
Epoch [2/50], Training Loss: 0.6179, Testing Loss: 0.7690
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/50
train loss item: 0.613661527633667
train loss item: 0.3876442015171051
train loss item: 0.5079360604286194
train loss item: 0.6969730854034424
train loss item: 0.7612075805664062
train loss item: 0.34873825311660767
train loss item: 0.5601683855056763
train loss item: 0.47940751910209656
train loss item: 0.49898993968963623
train loss item: 0.7060378789901733
train loss item: 0.6820985674858093
train loss item: 0.4819062054157257
test loss item: 0.5004900097846985
test loss item: 0.41489967703819275
test loss item: 0.41026756167411804
test loss item: 0.3806145191192627
test loss item: 0.6262808442115784
test loss item: 0.31133750081062317
test loss item: 0.46288323402404785
test loss item: 0.3499935269355774
test loss item: 0.5363754630088806
test loss item: 0.6676885485649109
test loss item: 0.6843309998512268
test loss item: 0.22901223599910736
Epoch [3/50], Training Loss: 0.5604, Testing Loss: 0.4645
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/50
train loss item: 0.546330451965332
train loss item: 0.3251984119415283
train loss item: 0.41699960827827454
train loss item: 0.6140895485877991
train loss item: 0.7110395431518555
train loss item: 0.285971999168396
train loss item: 0.5470634698867798
train loss item: 0.44887563586235046
train loss item: 0.38121354579925537
train loss item: 0.616769552230835
train loss item: 0.604049563407898
train loss item: 0.38655224442481995
test loss item: 0.45867496728897095
test loss item: 0.41642317175865173
test loss item: 0.3588094115257263
test loss item: 0.3668524920940399
test loss item: 0.6289511919021606
test loss item: 0.2742162048816681
test loss item: 0.46091228723526
test loss item: 0.31385862827301025
test loss item: 0.5181570053100586
test loss item: 0.798516571521759
test loss item: 0.71230149269104
test loss item: 0.1940988451242447
Epoch [4/50], Training Loss: 0.4903, Testing Loss: 0.4585
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/50
train loss item: 0.5705771446228027
train loss item: 0.38813474774360657
train loss item: 0.40440067648887634
train loss item: 0.5409359931945801
train loss item: 0.6260098218917847
train loss item: 0.25902798771858215
train loss item: 0.5231205224990845
train loss item: 0.457897424697876
train loss item: 0.34611424803733826
train loss item: 0.6021536588668823
train loss item: 0.572413444519043
train loss item: 0.3504672348499298
test loss item: 0.43738314509391785
test loss item: 0.4616278409957886
test loss item: 0.30745837092399597
test loss item: 0.37562763690948486
test loss item: 0.6606745719909668
test loss item: 0.245477095246315
test loss item: 0.4786258041858673
test loss item: 0.3009518086910248
test loss item: 0.4934687912464142
test loss item: 0.9134602546691895
test loss item: 0.7783374190330505
test loss item: 0.1953534334897995
Epoch [5/50], Training Loss: 0.4701, Testing Loss: 0.4707
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/50
train loss item: 0.5306140780448914
train loss item: 0.404539555311203
train loss item: 0.3953021168708801
train loss item: 0.47662824392318726
train loss item: 0.5741168260574341
train loss item: 0.27004164457321167
train loss item: 0.5187265276908875
train loss item: 0.47141313552856445
train loss item: 0.2612839639186859
train loss item: 0.5263849496841431
train loss item: 0.5454187989234924
train loss item: 0.3349376916885376
test loss item: 0.5808173418045044
test loss item: 0.5291622281074524
test loss item: 0.3615439236164093
test loss item: 0.4391302168369293
test loss item: 0.7497478723526001
test loss item: 0.2648063004016876
test loss item: 0.5461210608482361
test loss item: 0.35485032200813293
test loss item: 0.5854452252388
test loss item: 0.9823623299598694
test loss item: 0.9200889468193054
test loss item: 0.18086408078670502
Epoch [6/50], Training Loss: 0.4425, Testing Loss: 0.5412
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/50
train loss item: 0.5485209226608276
train loss item: 0.42131683230400085
train loss item: 0.3515545129776001
train loss item: 0.4201355278491974
train loss item: 0.5138422846794128
train loss item: 0.2468743920326233
train loss item: 0.4660016894340515
train loss item: 0.45813512802124023
train loss item: 0.29082855582237244
train loss item: 0.569748044013977
train loss item: 0.49976375699043274
train loss item: 0.30982232093811035
test loss item: 0.44801175594329834
test loss item: 0.44548383355140686
test loss item: 0.3117457628250122
test loss item: 0.3642146587371826
test loss item: 0.6183643341064453
test loss item: 0.22815892100334167
test loss item: 0.4583989679813385
test loss item: 0.3081454038619995
test loss item: 0.47969818115234375
test loss item: 0.7825171947479248
test loss item: 0.7431410551071167
test loss item: 0.1632446050643921
Epoch [7/50], Training Loss: 0.4247, Testing Loss: 0.4459
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/50
train loss item: 0.5111298561096191
train loss item: 0.43715018033981323
train loss item: 0.3500712215900421
train loss item: 0.3360290825366974
train loss item: 0.49091699719429016
train loss item: 0.30034351348876953
train loss item: 0.45800310373306274
train loss item: 0.4246000349521637
train loss item: 0.2300773561000824
train loss item: 0.5420607924461365
train loss item: 0.43600305914878845
train loss item: 0.3060809075832367
test loss item: 0.49206408858299255
test loss item: 0.5972764492034912
test loss item: 0.3494582176208496
test loss item: 0.44817814230918884
test loss item: 0.8030426502227783
test loss item: 0.2667052447795868
test loss item: 0.6053668260574341
test loss item: 0.3881642818450928
test loss item: 0.5984923243522644
test loss item: 1.0664254426956177
test loss item: 0.9821213483810425
test loss item: 0.16873690485954285
Epoch [8/50], Training Loss: 0.4019, Testing Loss: 0.5638
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/50
train loss item: 0.4918334186077118
train loss item: 0.3641921281814575
train loss item: 0.3128960132598877
train loss item: 0.32590168714523315
train loss item: 0.4262162744998932
train loss item: 0.2840878963470459
train loss item: 0.41964489221572876
train loss item: 0.41278818249702454
train loss item: 0.21011501550674438
train loss item: 0.4610602557659149
train loss item: 0.39802923798561096
train loss item: 0.22589319944381714
test loss item: 0.4289657175540924
test loss item: 0.4702092111110687
test loss item: 0.30574843287467957
test loss item: 0.36977875232696533
test loss item: 0.6457378268241882
test loss item: 0.22876080870628357
test loss item: 0.4843390882015228
test loss item: 0.30492493510246277
test loss item: 0.498197078704834
test loss item: 0.8597763776779175
test loss item: 0.795756459236145
test loss item: 0.12968245148658752
Epoch [9/50], Training Loss: 0.3611, Testing Loss: 0.4602
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/50
train loss item: 0.4792887568473816
train loss item: 0.38106417655944824
train loss item: 0.3331315815448761
train loss item: 0.31095901131629944
train loss item: 0.35327792167663574
train loss item: 0.26468899846076965
train loss item: 0.43810415267944336
train loss item: 0.43464234471321106
train loss item: 0.1933470368385315
train loss item: 0.45436325669288635
train loss item: 0.45448604226112366
train loss item: 0.20138409733772278
test loss item: 0.378557413816452
test loss item: 0.3190152049064636
test loss item: 0.2637653350830078
test loss item: 0.2725422978401184
test loss item: 0.4659784138202667
test loss item: 0.19039663672447205
test loss item: 0.3344622850418091
test loss item: 0.2634918987751007
test loss item: 0.3954746723175049
test loss item: 0.5872600078582764
test loss item: 0.5481988191604614
test loss item: 0.18809859454631805
Epoch [10/50], Training Loss: 0.3582, Testing Loss: 0.3506
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 11/50
train loss item: 0.34091123938560486
train loss item: 0.25989004969596863
train loss item: 0.24766837060451508
train loss item: 0.32728466391563416
train loss item: 0.31135690212249756
train loss item: 0.2694796919822693
train loss item: 0.27718213200569153
train loss item: 0.32858651876449585
train loss item: 0.18336495757102966
train loss item: 0.432973712682724
train loss item: 0.4638262391090393
train loss item: 0.1856430470943451
test loss item: 0.29057466983795166
test loss item: 0.2198108285665512
test loss item: 0.2140624076128006
test loss item: 0.20049233734607697
test loss item: 0.30734801292419434
test loss item: 0.17742373049259186
test loss item: 0.21903370320796967
test loss item: 0.18922343850135803
test loss item: 0.2775275707244873
test loss item: 0.3320898115634918
test loss item: 0.3574010729789734
test loss item: 0.14916175603866577
Epoch [11/50], Training Loss: 0.3023, Testing Loss: 0.2445
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 12/50
train loss item: 0.26797300577163696
train loss item: 0.20704364776611328
train loss item: 0.2062753289937973
train loss item: 0.32076770067214966
train loss item: 0.2592514157295227
train loss item: 0.2655622065067291
train loss item: 0.23307177424430847
train loss item: 0.2548776865005493
train loss item: 0.1760919988155365
train loss item: 0.39668333530426025
train loss item: 0.41061750054359436
train loss item: 0.16584055125713348
test loss item: 0.23175077140331268
test loss item: 0.18697617948055267
test loss item: 0.21379424631595612
test loss item: 0.16172325611114502
test loss item: 0.26121389865875244
test loss item: 0.178610160946846
test loss item: 0.20607323944568634
test loss item: 0.1815870702266693
test loss item: 0.2327868491411209
test loss item: 0.2298361361026764
test loss item: 0.2680814564228058
test loss item: 0.1477915495634079
Epoch [12/50], Training Loss: 0.2637, Testing Loss: 0.2084
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 13/50
train loss item: 0.2506021559238434
train loss item: 0.20138245820999146
train loss item: 0.17670059204101562
train loss item: 0.30291682481765747
train loss item: 0.22953657805919647
train loss item: 0.17480529844760895
train loss item: 0.20245470106601715
train loss item: 0.2253994643688202
train loss item: 0.17429380118846893
train loss item: 0.34937697649002075
train loss item: 0.34352320432662964
train loss item: 0.21568575501441956
test loss item: 0.26994383335113525
test loss item: 0.19755128026008606
test loss item: 0.17844101786613464
test loss item: 0.18345646560192108
test loss item: 0.2694757282733917
test loss item: 0.1395280361175537
test loss item: 0.21449024975299835
test loss item: 0.17136594653129578
test loss item: 0.24233226478099823
test loss item: 0.2549078166484833
test loss item: 0.3039521872997284
test loss item: 0.106666699051857
Epoch [13/50], Training Loss: 0.2372, Testing Loss: 0.2110
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 14/50
train loss item: 0.2744986414909363
train loss item: 0.23497983813285828
train loss item: 0.17469662427902222
train loss item: 0.26891517639160156
train loss item: 0.20477695763111115
train loss item: 0.1567867398262024
train loss item: 0.18532881140708923
train loss item: 0.19906897842884064
train loss item: 0.15486754477024078
train loss item: 0.318975031375885
train loss item: 0.2898411750793457
train loss item: 0.14720362424850464
test loss item: 0.33124881982803345
test loss item: 0.2405378371477127
test loss item: 0.1998247355222702
test loss item: 0.2208709716796875
test loss item: 0.33316171169281006
test loss item: 0.15657706558704376
test loss item: 0.2702596187591553
test loss item: 0.18782490491867065
test loss item: 0.29606813192367554
test loss item: 0.3701034188270569
test loss item: 0.40827128291130066
test loss item: 0.2104354053735733
Epoch [14/50], Training Loss: 0.2175, Testing Loss: 0.2688
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 15/50
train loss item: 0.33817681670188904
train loss item: 0.27796289324760437
train loss item: 0.1847597062587738
train loss item: 0.23229336738586426
train loss item: 0.22824017703533173
train loss item: 0.16383010149002075
train loss item: 0.2486160546541214
train loss item: 0.23771809041500092
train loss item: 0.14491134881973267
train loss item: 0.3230583369731903
train loss item: 0.2525938153266907
train loss item: 0.17307709157466888
test loss item: 0.38393980264663696
test loss item: 0.29568910598754883
test loss item: 0.23588554561138153
test loss item: 0.25772881507873535
test loss item: 0.41834864020347595
test loss item: 0.18206462264060974
test loss item: 0.3289894461631775
test loss item: 0.23135007917881012
test loss item: 0.3718310296535492
test loss item: 0.5091582536697388
test loss item: 0.5060586929321289
test loss item: 0.19946610927581787
Epoch [15/50], Training Loss: 0.2338, Testing Loss: 0.3267
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 16/50
train loss item: 0.3811604976654053
train loss item: 0.2741315960884094
train loss item: 0.18793100118637085
train loss item: 0.25414663553237915
train loss item: 0.22447453439235687
train loss item: 0.14960308372974396
train loss item: 0.26869311928749084
train loss item: 0.33522093296051025
train loss item: 0.20773117244243622
train loss item: 0.41099804639816284
train loss item: 0.3529629111289978
train loss item: 0.15657243132591248
test loss item: 0.28861767053604126
test loss item: 0.16890092194080353
test loss item: 0.1923225224018097
test loss item: 0.1816859096288681
test loss item: 0.22485186159610748
test loss item: 0.16621123254299164
test loss item: 0.1794818490743637
test loss item: 0.16218294203281403
test loss item: 0.25499042868614197
test loss item: 0.21784254908561707
test loss item: 0.26391980051994324
test loss item: 0.09007052332162857
Epoch [16/50], Training Loss: 0.2670, Testing Loss: 0.1993
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 17/50
train loss item: 0.2253950834274292
train loss item: 0.2655256390571594
train loss item: 0.22593043744564056
train loss item: 0.2864189147949219
train loss item: 0.25861239433288574
train loss item: 0.21121099591255188
train loss item: 0.17955893278121948
train loss item: 0.26513946056365967
train loss item: 0.1637117862701416
train loss item: 0.4326312839984894
train loss item: 0.3935685157775879
train loss item: 0.1813148856163025
test loss item: 0.2106311321258545
test loss item: 0.1806282252073288
test loss item: 0.19273605942726135
test loss item: 0.15352624654769897
test loss item: 0.2387845814228058
test loss item: 0.1419937014579773
test loss item: 0.19069145619869232
test loss item: 0.1760341227054596
test loss item: 0.22091074287891388
test loss item: 0.19388321042060852
test loss item: 0.2547161281108856
test loss item: 0.1367136687040329
Epoch [17/50], Training Loss: 0.2574, Testing Loss: 0.1909
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 18/50
train loss item: 0.17997565865516663
train loss item: 0.21333718299865723
train loss item: 0.1530962437391281
train loss item: 0.22329086065292358
train loss item: 0.2715027332305908
train loss item: 0.2707867920398712
train loss item: 0.17352281510829926
train loss item: 0.18004460632801056
train loss item: 0.17284318804740906
train loss item: 0.34525513648986816
train loss item: 0.37292778491973877
train loss item: 0.14403942227363586
test loss item: 0.26924070715904236
test loss item: 0.20375321805477142
test loss item: 0.21412579715251923
test loss item: 0.18567144870758057
test loss item: 0.2796746492385864
test loss item: 0.15150608122348785
test loss item: 0.22396142780780792
test loss item: 0.1893395334482193
test loss item: 0.26925238966941833
test loss item: 0.2800956070423126
test loss item: 0.3162517547607422
test loss item: 0.11793560534715652
Epoch [18/50], Training Loss: 0.2251, Testing Loss: 0.2251
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 19/50
train loss item: 0.20409566164016724
train loss item: 0.14908777177333832
train loss item: 0.14243152737617493
train loss item: 0.1748049259185791
train loss item: 0.2191704362630844
train loss item: 0.24003487825393677
train loss item: 0.15915021300315857
train loss item: 0.16759434342384338
train loss item: 0.15592744946479797
train loss item: 0.29769811034202576
train loss item: 0.32799866795539856
train loss item: 0.1284954994916916
test loss item: 0.24754798412322998
test loss item: 0.1760140210390091
test loss item: 0.1876339465379715
test loss item: 0.15753145515918732
test loss item: 0.23897922039031982
test loss item: 0.1302335113286972
test loss item: 0.19489160180091858
test loss item: 0.17552363872528076
test loss item: 0.2491372525691986
test loss item: 0.20871590077877045
test loss item: 0.2614661157131195
test loss item: 0.11439353227615356
Epoch [19/50], Training Loss: 0.1972, Testing Loss: 0.1952
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 20/50
train loss item: 0.19377277791500092
train loss item: 0.15784186124801636
train loss item: 0.14478915929794312
train loss item: 0.16784101724624634
train loss item: 0.17609813809394836
train loss item: 0.16866856813430786
train loss item: 0.14055384695529938
train loss item: 0.1664038449525833
train loss item: 0.14882095158100128
train loss item: 0.31214243173599243
train loss item: 0.25499609112739563
train loss item: 0.1268780529499054
test loss item: 0.20558200776576996
test loss item: 0.1874481439590454
test loss item: 0.16207586228847504
test loss item: 0.15147265791893005
test loss item: 0.24078594148159027
test loss item: 0.11577073484659195
test loss item: 0.19301217794418335
test loss item: 0.15793399512767792
test loss item: 0.21627099812030792
test loss item: 0.2378593534231186
test loss item: 0.2893185019493103
test loss item: 0.13087451457977295
Epoch [20/50], Training Loss: 0.1799, Testing Loss: 0.1907
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 21/50
train loss item: 0.23627743124961853
train loss item: 0.164353147149086
train loss item: 0.13977167010307312
train loss item: 0.14910699427127838
train loss item: 0.16611945629119873
train loss item: 0.12767842411994934
train loss item: 0.12915313243865967
train loss item: 0.15361431241035461
train loss item: 0.12265125662088394
train loss item: 0.27918514609336853
train loss item: 0.2362329363822937
train loss item: 0.1126144602894783
test loss item: 0.1614297330379486
test loss item: 0.1564835160970688
test loss item: 0.12915949523448944
test loss item: 0.12856292724609375
test loss item: 0.20231196284294128
test loss item: 0.11113760620355606
test loss item: 0.17977634072303772
test loss item: 0.12212482839822769
test loss item: 0.17440581321716309
test loss item: 0.23810988664627075
test loss item: 0.2301017940044403
test loss item: 0.1249595582485199
Epoch [21/50], Training Loss: 0.1681, Testing Loss: 0.1632
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 22/50
train loss item: 0.21409107744693756
train loss item: 0.17439444363117218
train loss item: 0.15747693181037903
train loss item: 0.16264234483242035
train loss item: 0.14907142519950867
train loss item: 0.1340736597776413
train loss item: 0.17759504914283752
train loss item: 0.18569204211235046
train loss item: 0.12986735999584198
train loss item: 0.25671762228012085
train loss item: 0.1556224822998047
train loss item: 0.1214323565363884
test loss item: 0.19513992965221405
test loss item: 0.21316087245941162
test loss item: 0.14310237765312195
test loss item: 0.1616053283214569
test loss item: 0.28998643159866333
test loss item: 0.12202199548482895
test loss item: 0.23484915494918823
test loss item: 0.15054930746555328
test loss item: 0.23536960780620575
test loss item: 0.3916502296924591
test loss item: 0.35014453530311584
test loss item: 0.13110648095607758
Epoch [22/50], Training Loss: 0.1682, Testing Loss: 0.2182
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 23/50
train loss item: 0.328875869512558
train loss item: 0.21907112002372742
train loss item: 0.1383725255727768
train loss item: 0.21896079182624817
train loss item: 0.18854983150959015
train loss item: 0.10877993702888489
train loss item: 0.19852879643440247
train loss item: 0.2570568919181824
train loss item: 0.15817956626415253
train loss item: 0.3286781907081604
train loss item: 0.3120822608470917
train loss item: 0.13803225755691528
test loss item: 0.18520469963550568
test loss item: 0.16260705888271332
test loss item: 0.1371738314628601
test loss item: 0.1496633142232895
test loss item: 0.20692749321460724
test loss item: 0.1277133971452713
test loss item: 0.18225796520709991
test loss item: 0.13604480028152466
test loss item: 0.17703160643577576
test loss item: 0.20408497750759125
test loss item: 0.2180858701467514
test loss item: 0.15486527979373932
Epoch [23/50], Training Loss: 0.2163, Testing Loss: 0.1701
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 24/50
train loss item: 0.16767238080501556
train loss item: 0.21762891113758087
train loss item: 0.19963021576404572
train loss item: 0.28042730689048767
train loss item: 0.3005080223083496
train loss item: 0.254790335893631
train loss item: 0.18085652589797974
train loss item: 0.2362305074930191
train loss item: 0.1753704845905304
train loss item: 0.36332595348358154
train loss item: 0.39047157764434814
train loss item: 0.16671916842460632
test loss item: 0.30904415249824524
test loss item: 0.21858732402324677
test loss item: 0.23232834041118622
test loss item: 0.19700880348682404
test loss item: 0.3005659580230713
test loss item: 0.15817099809646606
test loss item: 0.23437073826789856
test loss item: 0.20530231297016144
test loss item: 0.3200102746486664
test loss item: 0.3166443407535553
test loss item: 0.35165661573410034
test loss item: 0.11489560455083847
Epoch [24/50], Training Loss: 0.2445, Testing Loss: 0.2465
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 25/50
train loss item: 0.24024303257465363
train loss item: 0.19017353653907776
train loss item: 0.18293803930282593
train loss item: 0.19928522408008575
train loss item: 0.19717080891132355
train loss item: 0.25391626358032227
train loss item: 0.1938941478729248
train loss item: 0.21141386032104492
train loss item: 0.21470046043395996
train loss item: 0.2643406391143799
train loss item: 0.30106714367866516
train loss item: 0.1195983812212944
test loss item: 0.3121930658817291
test loss item: 0.1772414743900299
test loss item: 0.212669238448143
test loss item: 0.17593707144260406
test loss item: 0.2634463310241699
test loss item: 0.15381431579589844
test loss item: 0.19693876802921295
test loss item: 0.19785341620445251
test loss item: 0.2776634395122528
test loss item: 0.2037520408630371
test loss item: 0.2951624393463135
test loss item: 0.15019941329956055
Epoch [25/50], Training Loss: 0.2141, Testing Loss: 0.2181
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 26/50
train loss item: 0.2409367561340332
train loss item: 0.15793457627296448
train loss item: 0.14045272767543793
train loss item: 0.16449519991874695
train loss item: 0.16046597063541412
train loss item: 0.19500160217285156
train loss item: 0.15510763227939606
train loss item: 0.17838704586029053
train loss item: 0.1693679690361023
train loss item: 0.27989551424980164
train loss item: 0.28776049613952637
train loss item: 0.11636319756507874
test loss item: 0.24786794185638428
test loss item: 0.14945830404758453
test loss item: 0.17450548708438873
test loss item: 0.14826123416423798
test loss item: 0.21202436089515686
test loss item: 0.13596026599407196
test loss item: 0.1622452586889267
test loss item: 0.1547694355249405
test loss item: 0.2301880419254303
test loss item: 0.19099636375904083
test loss item: 0.24164287745952606
test loss item: 0.13829700648784637
Epoch [26/50], Training Loss: 0.1872, Testing Loss: 0.1822
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 27/50
train loss item: 0.16444149613380432
train loss item: 0.12137268483638763
train loss item: 0.11987564712762833
train loss item: 0.22202260792255402
train loss item: 0.19223549962043762
train loss item: 0.16945801675319672
train loss item: 0.14472776651382446
train loss item: 0.18703877925872803
train loss item: 0.15852417051792145
train loss item: 0.28058838844299316
train loss item: 0.2910574674606323
train loss item: 0.10708411782979965
test loss item: 0.2996656000614166
test loss item: 0.14956314861774445
test loss item: 0.19233985245227814
test loss item: 0.1685274988412857
test loss item: 0.21766343712806702
test loss item: 0.15056221187114716
test loss item: 0.1588829755783081
test loss item: 0.1629474014043808
test loss item: 0.2597469091415405
test loss item: 0.17858116328716278
test loss item: 0.25363942980766296
test loss item: 0.1120266318321228
Epoch [27/50], Training Loss: 0.1799, Testing Loss: 0.1920
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 28/50
train loss item: 0.1336228847503662
train loss item: 0.1113918125629425
train loss item: 0.12916584312915802
train loss item: 0.2421288639307022
train loss item: 0.2064080834388733
train loss item: 0.13703051209449768
train loss item: 0.11800765991210938
train loss item: 0.18433700501918793
train loss item: 0.1536189168691635
train loss item: 0.2897200286388397
train loss item: 0.35407310724258423
train loss item: 0.09547962993383408
test loss item: 0.2947978377342224
test loss item: 0.16919942200183868
test loss item: 0.18921558558940887
test loss item: 0.1739828735589981
test loss item: 0.24550655484199524
test loss item: 0.13952787220478058
test loss item: 0.18158066272735596
test loss item: 0.1551927626132965
test loss item: 0.2663910686969757
test loss item: 0.26928818225860596
test loss item: 0.29109853506088257
test loss item: 0.1291351616382599
Epoch [28/50], Training Loss: 0.1796, Testing Loss: 0.2087
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 29/50
train loss item: 0.1778113692998886
train loss item: 0.13215023279190063
train loss item: 0.15744367241859436
train loss item: 0.2463727444410324
train loss item: 0.20441143214702606
train loss item: 0.1576526165008545
train loss item: 0.15549907088279724
train loss item: 0.19347365200519562
train loss item: 0.19962170720100403
train loss item: 0.2777585983276367
train loss item: 0.3948097229003906
train loss item: 0.10908716171979904
test loss item: 0.316965788602829
test loss item: 0.2284168004989624
test loss item: 0.2267095148563385
test loss item: 0.21011604368686676
test loss item: 0.3185534179210663
test loss item: 0.18117855489253998
test loss item: 0.2547733187675476
test loss item: 0.1964251846075058
test loss item: 0.3141787052154541
test loss item: 0.39374732971191406
test loss item: 0.37044453620910645
test loss item: 0.14500100910663605
Epoch [29/50], Training Loss: 0.2005, Testing Loss: 0.2630
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 30/50
train loss item: 0.23142842948436737
train loss item: 0.13505099713802338
train loss item: 0.15496692061424255
train loss item: 0.20851746201515198
train loss item: 0.1907699704170227
train loss item: 0.21210016310214996
train loss item: 0.16353067755699158
train loss item: 0.1815955638885498
train loss item: 0.23188260197639465
train loss item: 0.21196381747722626
train loss item: 0.4198347330093384
train loss item: 0.10158523172140121
test loss item: 0.18986761569976807
test loss item: 0.19645783305168152
test loss item: 0.15890398621559143
test loss item: 0.15984457731246948
test loss item: 0.2626645863056183
test loss item: 0.13866746425628662
test loss item: 0.21376103162765503
test loss item: 0.145263671875
test loss item: 0.20747077465057373
test loss item: 0.3207768499851227
test loss item: 0.2745562791824341
test loss item: 0.16972386837005615
Epoch [30/50], Training Loss: 0.2036, Testing Loss: 0.2032
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 31/50
train loss item: 0.2736998498439789
train loss item: 0.13768886029720306
train loss item: 0.1437382996082306
train loss item: 0.2241775244474411
train loss item: 0.1686737835407257
train loss item: 0.1997911036014557
train loss item: 0.15596742928028107
train loss item: 0.1538398712873459
train loss item: 0.20543040335178375
train loss item: 0.17258387804031372
train loss item: 0.39874541759490967
train loss item: 0.12658067047595978
test loss item: 0.19693268835544586
test loss item: 0.20329619944095612
test loss item: 0.14054733514785767
test loss item: 0.1589382290840149
test loss item: 0.2529319226741791
test loss item: 0.12646250426769257
test loss item: 0.21741095185279846
test loss item: 0.1316642314195633
test loss item: 0.20997348427772522
test loss item: 0.301488995552063
test loss item: 0.28962045907974243
test loss item: 0.23527102172374725
Epoch [31/50], Training Loss: 0.1967, Testing Loss: 0.2054
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.27611199021339417
loss item: 0.15143173933029175
loss item: 0.20859384536743164
loss item: 0.29386475682258606
loss item: 0.15016327798366547
loss item: 0.2750909626483917
Val Loss: 0.2259
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 50, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.001 16 360 done at Tue Nov 12 12:05:29 CET 2024
UNet2 with 1 50 0.005 16 360 start at Tue Nov 12 12:05:29 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 50, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
train loss item: 1.347920298576355
train loss item: 1.5687456130981445
train loss item: 1.631877064704895
train loss item: 1.4319086074829102
train loss item: 1.4138485193252563
train loss item: 0.546890914440155
train loss item: 1.3041961193084717
train loss item: 1.0380523204803467
train loss item: 0.5293318033218384
train loss item: 0.9218611121177673
train loss item: 1.3710566759109497
train loss item: 0.6858503222465515
test loss item: 3.2003939151763916
test loss item: 2.154862403869629
test loss item: 2.522993803024292
test loss item: 2.072277545928955
test loss item: 3.261380672454834
test loss item: 1.5580440759658813
test loss item: 2.3153131008148193
test loss item: 2.2654213905334473
test loss item: 3.346027135848999
test loss item: 2.5312631130218506
test loss item: 3.6369071006774902
test loss item: 0.8985705375671387
Epoch [1/50], Training Loss: 1.1493, Testing Loss: 2.4803
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/50
train loss item: 0.7554489970207214
train loss item: 0.5311941504478455
train loss item: 0.6179863810539246
train loss item: 0.8203991651535034
train loss item: 0.9779049754142761
train loss item: 0.4623931050300598
train loss item: 0.8516811728477478
train loss item: 0.6761479377746582
train loss item: 0.5962315201759338
train loss item: 0.8352209329605103
train loss item: 1.0741273164749146
train loss item: 0.5220564603805542
test loss item: 7.790459156036377
test loss item: 3.576235055923462
test loss item: 5.013566970825195
test loss item: 3.944175958633423
test loss item: 6.5662665367126465
test loss item: 2.6617796421051025
test loss item: 3.747519016265869
test loss item: 4.292668342590332
test loss item: 7.04976749420166
test loss item: 4.14107084274292
test loss item: 7.614866733551025
test loss item: 2.846034288406372
Epoch [2/50], Training Loss: 0.7267, Testing Loss: 4.9370
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/50
train loss item: 0.6863020062446594
train loss item: 0.4426109492778778
train loss item: 0.5799510478973389
train loss item: 0.7794153094291687
train loss item: 0.8928535580635071
train loss item: 0.4278809726238251
train loss item: 0.7807832360267639
train loss item: 0.6580387949943542
train loss item: 0.5662275552749634
train loss item: 0.7435731291770935
train loss item: 1.0109055042266846
train loss item: 0.5526444315910339
test loss item: 1.330809473991394
test loss item: 0.8935152292251587
test loss item: 1.0789555311203003
test loss item: 0.7761048674583435
test loss item: 1.531236171722412
test loss item: 0.6736292243003845
test loss item: 0.9920744299888611
test loss item: 0.9261553287506104
test loss item: 1.3865399360656738
test loss item: 1.3352049589157104
test loss item: 1.6601319313049316
test loss item: 0.309951514005661
Epoch [3/50], Training Loss: 0.6768, Testing Loss: 1.0745
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/50
train loss item: 0.6887794733047485
train loss item: 0.49422547221183777
train loss item: 0.5770339369773865
train loss item: 0.7572455406188965
train loss item: 0.8831947445869446
train loss item: 0.4058489203453064
train loss item: 0.7843759059906006
train loss item: 0.6657115817070007
train loss item: 0.43560850620269775
train loss item: 0.7632137537002563
train loss item: 0.9187833666801453
train loss item: 0.4459364414215088
test loss item: 0.7054656744003296
test loss item: 0.6305694580078125
test loss item: 0.48126721382141113
test loss item: 0.5342040061950684
test loss item: 0.9173663258552551
test loss item: 0.39502623677253723
test loss item: 0.699359655380249
test loss item: 0.43536514043807983
test loss item: 0.7231936454772949
test loss item: 1.195124626159668
test loss item: 1.0048640966415405
test loss item: 0.3020661771297455
Epoch [4/50], Training Loss: 0.6517, Testing Loss: 0.6687
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/50
train loss item: 0.6609570384025574
train loss item: 0.4887945055961609
train loss item: 0.5706380009651184
train loss item: 0.7161975502967834
train loss item: 0.8125241994857788
train loss item: 0.37361499667167664
train loss item: 0.7603998184204102
train loss item: 0.6537167429924011
train loss item: 0.3848836123943329
train loss item: 0.7090879082679749
train loss item: 0.8640277981758118
train loss item: 0.46717530488967896
test loss item: 0.7143515944480896
test loss item: 0.6800945401191711
test loss item: 0.5133504867553711
test loss item: 0.5548902750015259
test loss item: 0.9800561666488647
test loss item: 0.3815513253211975
test loss item: 0.7185341715812683
test loss item: 0.4738336503505707
test loss item: 0.7692980766296387
test loss item: 1.2288355827331543
test loss item: 1.107201099395752
test loss item: 0.18293917179107666
Epoch [5/50], Training Loss: 0.6218, Testing Loss: 0.6921
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/50
train loss item: 0.6935371160507202
train loss item: 0.5232334733009338
train loss item: 0.5809929370880127
train loss item: 0.6600165367126465
train loss item: 0.740502119064331
train loss item: 0.3897272050380707
train loss item: 0.7430079579353333
train loss item: 0.6598523855209351
train loss item: 0.36883315443992615
train loss item: 0.6696416139602661
train loss item: 0.8549189567565918
train loss item: 0.41099363565444946
test loss item: 0.6205070614814758
test loss item: 0.5668800473213196
test loss item: 0.4473553001880646
test loss item: 0.4805130660533905
test loss item: 0.8150489926338196
test loss item: 0.3519774079322815
test loss item: 0.5836055278778076
test loss item: 0.39054054021835327
test loss item: 0.642426073551178
test loss item: 1.0142884254455566
test loss item: 0.9220860004425049
test loss item: 0.14466796815395355
Epoch [6/50], Training Loss: 0.6079, Testing Loss: 0.5817
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/50
train loss item: 0.6616132855415344
train loss item: 0.448541522026062
train loss item: 0.5705880522727966
train loss item: 0.6463158130645752
train loss item: 0.6811172962188721
train loss item: 0.37774163484573364
train loss item: 0.6869930624961853
train loss item: 0.622336745262146
train loss item: 0.3628271520137787
train loss item: 0.6563182473182678
train loss item: 0.8082332015037537
train loss item: 0.4208752512931824
test loss item: 0.5947079062461853
test loss item: 0.4916192889213562
test loss item: 0.4303413927555084
test loss item: 0.43888986110687256
test loss item: 0.727758526802063
test loss item: 0.34286263585090637
test loss item: 0.5219079256057739
test loss item: 0.36402422189712524
test loss item: 0.606358528137207
test loss item: 0.8999432921409607
test loss item: 0.7942491769790649
test loss item: 0.14240488409996033
Epoch [7/50], Training Loss: 0.5786, Testing Loss: 0.5296
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/50
train loss item: 0.6446191668510437
train loss item: 0.39430809020996094
train loss item: 0.5219672322273254
train loss item: 0.6501003503799438
train loss item: 0.6541334390640259
train loss item: 0.3448999524116516
train loss item: 0.6329718232154846
train loss item: 0.5855112075805664
train loss item: 0.36855870485305786
train loss item: 0.6449117660522461
train loss item: 0.7566896677017212
train loss item: 0.4003913402557373
test loss item: 0.5671632885932922
test loss item: 0.4763503968715668
test loss item: 0.41602852940559387
test loss item: 0.4268138110637665
test loss item: 0.701973557472229
test loss item: 0.3386044204235077
test loss item: 0.505382776260376
test loss item: 0.34729254245758057
test loss item: 0.56548672914505
test loss item: 0.8388271331787109
test loss item: 0.7582160830497742
test loss item: 0.1849266141653061
Epoch [8/50], Training Loss: 0.5499, Testing Loss: 0.5106
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/50
train loss item: 0.6501380205154419
train loss item: 0.4137910008430481
train loss item: 0.5094935297966003
train loss item: 0.6232690215110779
train loss item: 0.6280271410942078
train loss item: 0.3216910660266876
train loss item: 0.6164563298225403
train loss item: 0.5669658184051514
train loss item: 0.3618095815181732
train loss item: 0.6310023069381714
train loss item: 0.7021150588989258
train loss item: 0.37488463521003723
test loss item: 0.5576760172843933
test loss item: 0.4387529492378235
test loss item: 0.42650163173675537
test loss item: 0.40698879957199097
test loss item: 0.662597119808197
test loss item: 0.3334234654903412
test loss item: 0.4835571348667145
test loss item: 0.3523702323436737
test loss item: 0.5577371716499329
test loss item: 0.7216888070106506
test loss item: 0.6958555579185486
test loss item: 0.1581973433494568
Epoch [9/50], Training Loss: 0.5333, Testing Loss: 0.4829
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/50
train loss item: 0.6146268248558044
train loss item: 0.4009389877319336
train loss item: 0.5048874616622925
train loss item: 0.6117563843727112
train loss item: 0.5628377199172974
train loss item: 0.2973169982433319
train loss item: 0.5528077483177185
train loss item: 0.5378864407539368
train loss item: 0.3709028363227844
train loss item: 0.6384808421134949
train loss item: 0.6483501195907593
train loss item: 0.3773448169231415
test loss item: 0.49395743012428284
test loss item: 0.4037442207336426
test loss item: 0.39273738861083984
test loss item: 0.3740706741809845
test loss item: 0.5978658199310303
test loss item: 0.3202199935913086
test loss item: 0.44236990809440613
test loss item: 0.3208899199962616
test loss item: 0.4954734146595001
test loss item: 0.6402389407157898
test loss item: 0.6175023317337036
test loss item: 0.144777312874794
Epoch [10/50], Training Loss: 0.5098, Testing Loss: 0.4370
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 11/50
train loss item: 0.6289239525794983
train loss item: 0.37437668442726135
train loss item: 0.5057884454727173
train loss item: 0.6251233816146851
train loss item: 0.5547199249267578
train loss item: 0.33188432455062866
train loss item: 0.4913480877876282
train loss item: 0.47655558586120605
train loss item: 0.3450043201446533
train loss item: 0.6163378953933716
train loss item: 0.677433431148529
train loss item: 0.38690754771232605
test loss item: 0.5338671207427979
test loss item: 0.3724013864994049
test loss item: 0.42661580443382263
test loss item: 0.3544767498970032
test loss item: 0.5823766589164734
test loss item: 0.33272427320480347
test loss item: 0.4177809953689575
test loss item: 0.3382733464241028
test loss item: 0.5254193544387817
test loss item: 0.5302020311355591
test loss item: 0.585725724697113
test loss item: 0.1488630324602127
Epoch [11/50], Training Loss: 0.5012, Testing Loss: 0.4291
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 12/50
train loss item: 0.5806013941764832
train loss item: 0.3405724763870239
train loss item: 0.45533233880996704
train loss item: 0.5675888657569885
train loss item: 0.5097271203994751
train loss item: 0.31024792790412903
train loss item: 0.465900719165802
train loss item: 0.4432883560657501
train loss item: 0.3461630046367645
train loss item: 0.5293601155281067
train loss item: 0.5824204087257385
train loss item: 0.3386906087398529
test loss item: 0.4459516704082489
test loss item: 0.33856165409088135
test loss item: 0.3620835244655609
test loss item: 0.3198351562023163
test loss item: 0.5127379894256592
test loss item: 0.2960177958011627
test loss item: 0.37365642189979553
test loss item: 0.29258567094802856
test loss item: 0.44139236211776733
test loss item: 0.482864111661911
test loss item: 0.5144944190979004
test loss item: 0.2449716180562973
Epoch [12/50], Training Loss: 0.4558, Testing Loss: 0.3854
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 13/50
train loss item: 0.520420253276825
train loss item: 0.30761516094207764
train loss item: 0.4485664665699005
train loss item: 0.5118765830993652
train loss item: 0.42490774393081665
train loss item: 0.2719230353832245
train loss item: 0.4371100068092346
train loss item: 0.4013802409172058
train loss item: 0.326933890581131
train loss item: 0.48980551958084106
train loss item: 0.4925173223018646
train loss item: 0.32413432002067566
test loss item: 0.42101916670799255
test loss item: 0.31053417921066284
test loss item: 0.33756837248802185
test loss item: 0.296093612909317
test loss item: 0.4642174243927002
test loss item: 0.27586260437965393
test loss item: 0.33578625321388245
test loss item: 0.2701031267642975
test loss item: 0.4157157838344574
test loss item: 0.43252962827682495
test loss item: 0.4726213812828064
test loss item: 0.24976153671741486
Epoch [13/50], Training Loss: 0.4131, Testing Loss: 0.3568
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 14/50
train loss item: 0.5091874599456787
train loss item: 0.32602620124816895
train loss item: 0.412640243768692
train loss item: 0.5036062598228455
train loss item: 0.39116159081459045
train loss item: 0.24692150950431824
train loss item: 0.40281015634536743
train loss item: 0.36892837285995483
train loss item: 0.31477415561676025
train loss item: 0.4653816521167755
train loss item: 0.44721922278404236
train loss item: 0.3196924030780792
test loss item: 0.43136927485466003
test loss item: 0.29624098539352417
test loss item: 0.3286585807800293
test loss item: 0.28985318541526794
test loss item: 0.45022010803222656
test loss item: 0.2586131989955902
test loss item: 0.314943790435791
test loss item: 0.26120245456695557
test loss item: 0.4227326512336731
test loss item: 0.4270481765270233
test loss item: 0.47369980812072754
test loss item: 0.171733096241951
Epoch [14/50], Training Loss: 0.3924, Testing Loss: 0.3439
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 15/50
train loss item: 0.5003812909126282
train loss item: 0.3504531681537628
train loss item: 0.38688358664512634
train loss item: 0.4702037572860718
train loss item: 0.38375821709632874
train loss item: 0.22461049258708954
train loss item: 0.3603673279285431
train loss item: 0.36085084080696106
train loss item: 0.2753708064556122
train loss item: 0.44880014657974243
train loss item: 0.44809553027153015
train loss item: 0.3440135717391968
test loss item: 0.4636959135532379
test loss item: 0.3377384543418884
test loss item: 0.3316872715950012
test loss item: 0.3230426013469696
test loss item: 0.49886879324913025
test loss item: 0.2682856321334839
test loss item: 0.3797067403793335
test loss item: 0.282124787569046
test loss item: 0.44777700304985046
test loss item: 0.5159438252449036
test loss item: 0.5397335290908813
test loss item: 0.18765145540237427
Epoch [15/50], Training Loss: 0.3795, Testing Loss: 0.3814
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 16/50
train loss item: 0.6111835837364197
train loss item: 0.3878691792488098
train loss item: 0.3509238064289093
train loss item: 0.5361490249633789
train loss item: 0.5198410749435425
train loss item: 0.26711925864219666
train loss item: 0.43294841051101685
train loss item: 0.46570253372192383
train loss item: 0.32933762669563293
train loss item: 0.459236204624176
train loss item: 0.5903841853141785
train loss item: 0.309079647064209
test loss item: 1.0043561458587646
test loss item: 0.48941507935523987
test loss item: 0.6402885317802429
test loss item: 0.5018664002418518
test loss item: 0.8508216142654419
test loss item: 0.3634539842605591
test loss item: 0.5450375080108643
test loss item: 0.5633541345596313
test loss item: 0.9317217469215393
test loss item: 0.5353462100028992
test loss item: 0.9865794777870178
test loss item: 0.22636447846889496
Epoch [16/50], Training Loss: 0.4383, Testing Loss: 0.6366
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 17/50
train loss item: 0.470034122467041
train loss item: 0.3166773319244385
train loss item: 0.3651401698589325
train loss item: 0.460296630859375
train loss item: 0.36114269495010376
train loss item: 0.2391548454761505
train loss item: 0.37239840626716614
train loss item: 0.36510589718818665
train loss item: 0.2977665960788727
train loss item: 0.49570202827453613
train loss item: 0.434739351272583
train loss item: 0.32396671175956726
test loss item: 0.4298253357410431
test loss item: 0.39532995223999023
test loss item: 0.29720616340637207
test loss item: 0.3290300667285919
test loss item: 0.5531685948371887
test loss item: 0.2338263839483261
test loss item: 0.4268883466720581
test loss item: 0.27972477674484253
test loss item: 0.4419659972190857
test loss item: 0.661687970161438
test loss item: 0.6299274563789368
test loss item: 0.20846587419509888
Epoch [17/50], Training Loss: 0.3752, Testing Loss: 0.4073
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 18/50
train loss item: 0.5071486234664917
train loss item: 0.2929667830467224
train loss item: 0.35252508521080017
train loss item: 0.4866395890712738
train loss item: 0.40368735790252686
train loss item: 0.22520706057548523
train loss item: 0.3183978497982025
train loss item: 0.3274487853050232
train loss item: 0.27575919032096863
train loss item: 0.44900330901145935
train loss item: 0.43764445185661316
train loss item: 0.27542197704315186
test loss item: 0.4262324869632721
test loss item: 0.26338884234428406
test loss item: 0.286483496427536
test loss item: 0.26985061168670654
test loss item: 0.4048454761505127
test loss item: 0.21859590709209442
test loss item: 0.2905547022819519
test loss item: 0.23423027992248535
test loss item: 0.3941953778266907
test loss item: 0.40491586923599243
test loss item: 0.4489627182483673
test loss item: 0.10775388777256012
Epoch [18/50], Training Loss: 0.3627, Testing Loss: 0.3125
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 19/50
train loss item: 0.4374346137046814
train loss item: 0.31858766078948975
train loss item: 0.30378299951553345
train loss item: 0.3978126645088196
train loss item: 0.35318341851234436
train loss item: 0.19838130474090576
train loss item: 0.3404039144515991
train loss item: 0.3002532720565796
train loss item: 0.212625190615654
train loss item: 0.38450899720191956
train loss item: 0.3730122148990631
train loss item: 0.2918415665626526
test loss item: 0.42923498153686523
test loss item: 0.229812353849411
test loss item: 0.29652413725852966
test loss item: 0.2586100995540619
test loss item: 0.37120214104652405
test loss item: 0.22434498369693756
test loss item: 0.2604590058326721
test loss item: 0.2339605689048767
test loss item: 0.38778868317604065
test loss item: 0.3077769875526428
test loss item: 0.40272223949432373
test loss item: 0.1618819385766983
Epoch [19/50], Training Loss: 0.3260, Testing Loss: 0.2970
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 20/50
train loss item: 0.43268537521362305
train loss item: 0.3011864721775055
train loss item: 0.27570077776908875
train loss item: 0.3608737587928772
train loss item: 0.3035011291503906
train loss item: 0.1718485951423645
train loss item: 0.31044983863830566
train loss item: 0.2927132248878479
train loss item: 0.19822676479816437
train loss item: 0.3598613142967224
train loss item: 0.32215943932533264
train loss item: 0.23068903386592865
test loss item: 0.43050235509872437
test loss item: 0.29802069067955017
test loss item: 0.28889888525009155
test loss item: 0.27834033966064453
test loss item: 0.430124968290329
test loss item: 0.23161761462688446
test loss item: 0.33109304308891296
test loss item: 0.23153111338615417
test loss item: 0.39667192101478577
test loss item: 0.42378154397010803
test loss item: 0.48370644450187683
test loss item: 0.14966414868831635
Epoch [20/50], Training Loss: 0.2967, Testing Loss: 0.3312
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 21/50
train loss item: 0.5064462423324585
train loss item: 0.34727954864501953
train loss item: 0.28297868371009827
train loss item: 0.34704405069351196
train loss item: 0.30351439118385315
train loss item: 0.1510775089263916
train loss item: 0.347267746925354
train loss item: 0.32267507910728455
train loss item: 0.25387898087501526
train loss item: 0.47666046023368835
train loss item: 0.45918765664100647
train loss item: 0.23799599707126617
test loss item: 0.3888927400112152
test loss item: 0.219604954123497
test loss item: 0.2638972997665405
test loss item: 0.24526233971118927
test loss item: 0.34279632568359375
test loss item: 0.20376896858215332
test loss item: 0.24944323301315308
test loss item: 0.20490902662277222
test loss item: 0.3651173710823059
test loss item: 0.3361007571220398
test loss item: 0.387498140335083
test loss item: 0.19138836860656738
Epoch [21/50], Training Loss: 0.3363, Testing Loss: 0.2832
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 22/50
train loss item: 0.38065505027770996
train loss item: 0.3269011378288269
train loss item: 0.3037428855895996
train loss item: 0.3497259318828583
train loss item: 0.4085630476474762
train loss item: 0.3584836721420288
train loss item: 0.32462432980537415
train loss item: 0.30334943532943726
train loss item: 0.2172427922487259
train loss item: 0.4496070146560669
train loss item: 0.35103681683540344
train loss item: 0.25592178106307983
test loss item: 0.3078155517578125
test loss item: 0.24878902733325958
test loss item: 0.24536098539829254
test loss item: 0.22132208943367004
test loss item: 0.36635348200798035
test loss item: 0.1845751702785492
test loss item: 0.25772470235824585
test loss item: 0.2014124095439911
test loss item: 0.3385626971721649
test loss item: 0.4136098027229309
test loss item: 0.4196092486381531
test loss item: 0.1480627804994583
Epoch [22/50], Training Loss: 0.3358, Testing Loss: 0.2794
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 23/50
train loss item: 0.3502386510372162
train loss item: 0.22638410329818726
train loss item: 0.3465942442417145
train loss item: 0.4372691214084625
train loss item: 0.3144305944442749
train loss item: 0.26757776737213135
train loss item: 0.29047611355781555
train loss item: 0.2921435534954071
train loss item: 0.18445590138435364
train loss item: 0.4252239167690277
train loss item: 0.4890291690826416
train loss item: 0.23988930881023407
test loss item: 0.3770539462566376
test loss item: 0.22105790674686432
test loss item: 0.26078590750694275
test loss item: 0.21642732620239258
test loss item: 0.35178515315055847
test loss item: 0.18313762545585632
test loss item: 0.23336786031723022
test loss item: 0.20746469497680664
test loss item: 0.3478552997112274
test loss item: 0.2726277709007263
test loss item: 0.3966882824897766
test loss item: 0.1659424751996994
Epoch [23/50], Training Loss: 0.3220, Testing Loss: 0.2695
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 24/50
train loss item: 0.31694939732551575
train loss item: 0.25785648822784424
train loss item: 0.28397801518440247
train loss item: 0.3551291525363922
train loss item: 0.27991819381713867
train loss item: 0.1962129920721054
train loss item: 0.3397688567638397
train loss item: 0.30987998843193054
train loss item: 0.18227621912956238
train loss item: 0.41971564292907715
train loss item: 0.3301328718662262
train loss item: 0.22737061977386475
test loss item: 0.36987537145614624
test loss item: 0.2978235185146332
test loss item: 0.254452645778656
test loss item: 0.2554149627685547
test loss item: 0.4403928816318512
test loss item: 0.19286693632602692
test loss item: 0.33138760924339294
test loss item: 0.2278893142938614
test loss item: 0.38061070442199707
test loss item: 0.549630880355835
test loss item: 0.51621013879776
test loss item: 0.08369574695825577
Epoch [24/50], Training Loss: 0.2916, Testing Loss: 0.3250
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 25/50
train loss item: 0.42211592197418213
train loss item: 0.2602822184562683
train loss item: 0.25971049070358276
train loss item: 0.3319653272628784
train loss item: 0.30362847447395325
train loss item: 0.20847643911838531
train loss item: 0.2519252300262451
train loss item: 0.28290021419525146
train loss item: 0.21312594413757324
train loss item: 0.44756588339805603
train loss item: 0.37941744923591614
train loss item: 0.24927176535129547
test loss item: 0.265783429145813
test loss item: 0.2547629177570343
test loss item: 0.21620918810367584
test loss item: 0.21003256738185883
test loss item: 0.3431696891784668
test loss item: 0.1610449254512787
test loss item: 0.27504265308380127
test loss item: 0.1885082870721817
test loss item: 0.27769455313682556
test loss item: 0.3453279733657837
test loss item: 0.38411346077919006
test loss item: 0.104944609105587
Epoch [25/50], Training Loss: 0.3009, Testing Loss: 0.2522
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 26/50
train loss item: 0.28276193141937256
train loss item: 0.23974910378456116
train loss item: 0.21513232588768005
train loss item: 0.2855601906776428
train loss item: 0.3013112246990204
train loss item: 0.24446772038936615
train loss item: 0.25389793515205383
train loss item: 0.23374667763710022
train loss item: 0.1608382612466812
train loss item: 0.38790470361709595
train loss item: 0.295017808675766
train loss item: 0.2061651200056076
test loss item: 0.22660945355892181
test loss item: 0.19456997513771057
test loss item: 0.17226088047027588
test loss item: 0.16008904576301575
test loss item: 0.2732102572917938
test loss item: 0.13621029257774353
test loss item: 0.19850674271583557
test loss item: 0.14927488565444946
test loss item: 0.25354570150375366
test loss item: 0.33619561791419983
test loss item: 0.3218804597854614
test loss item: 0.09199349582195282
Epoch [26/50], Training Loss: 0.2589, Testing Loss: 0.2095
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 27/50
train loss item: 0.3455365300178528
train loss item: 0.2107541710138321
train loss item: 0.24769623577594757
train loss item: 0.28807303309440613
train loss item: 0.25340941548347473
train loss item: 0.2026391476392746
train loss item: 0.23428522050380707
train loss item: 0.21413911879062653
train loss item: 0.1556614488363266
train loss item: 0.3413398265838623
train loss item: 0.3229292631149292
train loss item: 0.17610862851142883
test loss item: 0.3214741051197052
test loss item: 0.2567477822303772
test loss item: 0.2002989798784256
test loss item: 0.22390976548194885
test loss item: 0.3402515947818756
test loss item: 0.1494535654783249
test loss item: 0.27880173921585083
test loss item: 0.17837071418762207
test loss item: 0.2931801378726959
test loss item: 0.3513545095920563
test loss item: 0.4106166362762451
test loss item: 0.1115318313241005
Epoch [27/50], Training Loss: 0.2494, Testing Loss: 0.2597
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 28/50
train loss item: 0.3564758896827698
train loss item: 0.3124811351299286
train loss item: 0.27297016978263855
train loss item: 0.2476806491613388
train loss item: 0.30302897095680237
train loss item: 0.21389032900333405
train loss item: 0.34981757402420044
train loss item: 0.30856749415397644
train loss item: 0.18271122872829437
train loss item: 0.41659557819366455
train loss item: 0.3208109438419342
train loss item: 0.2413598597049713
test loss item: 0.39607593417167664
test loss item: 0.47154700756073
test loss item: 0.2957201898097992
test loss item: 0.36691799759864807
test loss item: 0.6304954886436462
test loss item: 0.20791001617908478
test loss item: 0.5053976774215698
test loss item: 0.3100220561027527
test loss item: 0.4764600992202759
test loss item: 0.7879961729049683
test loss item: 0.7544137835502625
test loss item: 0.0861426442861557
Epoch [28/50], Training Loss: 0.2939, Testing Loss: 0.4408
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 29/50
train loss item: 0.48387473821640015
train loss item: 0.30262550711631775
train loss item: 0.23033811151981354
train loss item: 0.2138236165046692
train loss item: 0.280710905790329
train loss item: 0.2127676159143448
train loss item: 0.22172267735004425
train loss item: 0.24336522817611694
train loss item: 0.17840658128261566
train loss item: 0.4042409062385559
train loss item: 0.24030670523643494
train loss item: 0.1904047131538391
test loss item: 0.2760082185268402
test loss item: 0.3342939019203186
test loss item: 0.20191922783851624
test loss item: 0.2576887905597687
test loss item: 0.4261709153652191
test loss item: 0.1643657684326172
test loss item: 0.36230725049972534
test loss item: 0.21436457335948944
test loss item: 0.3475923538208008
test loss item: 0.5421594977378845
test loss item: 0.5241801738739014
test loss item: 0.09732283651828766
Epoch [29/50], Training Loss: 0.2669, Testing Loss: 0.3124
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 30/50
train loss item: 0.3778907358646393
train loss item: 0.27065208554267883
train loss item: 0.21355727314949036
train loss item: 0.21527232229709625
train loss item: 0.2986697256565094
train loss item: 0.26728132367134094
train loss item: 0.33282163739204407
train loss item: 0.2941533327102661
train loss item: 0.133158341050148
train loss item: 0.38611850142478943
train loss item: 0.273817777633667
train loss item: 0.15508607029914856
test loss item: 0.3833642899990082
test loss item: 0.42341020703315735
test loss item: 0.2651136517524719
test loss item: 0.33538511395454407
test loss item: 0.5680955648422241
test loss item: 0.2081185281276703
test loss item: 0.4668419659137726
test loss item: 0.2704296410083771
test loss item: 0.45389121770858765
test loss item: 0.7592114806175232
test loss item: 0.7013741135597229
test loss item: 0.13174781203269958
Epoch [30/50], Training Loss: 0.2682, Testing Loss: 0.4139
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 31/50
train loss item: 0.43112653493881226
train loss item: 0.2976279556751251
train loss item: 0.1768706738948822
train loss item: 0.23157690465450287
train loss item: 0.29852575063705444
train loss item: 0.2522670030593872
train loss item: 0.4127916693687439
train loss item: 0.4647415578365326
train loss item: 0.19503328204154968
train loss item: 0.42108041048049927
train loss item: 0.32252833247184753
train loss item: 0.17191791534423828
test loss item: 0.2988933026790619
test loss item: 0.24276410043239594
test loss item: 0.18093423545360565
test loss item: 0.20631393790245056
test loss item: 0.3266177177429199
test loss item: 0.143393412232399
test loss item: 0.24384041130542755
test loss item: 0.16351383924484253
test loss item: 0.32220226526260376
test loss item: 0.46257102489471436
test loss item: 0.4396730959415436
test loss item: 0.08907824754714966
Epoch [31/50], Training Loss: 0.3063, Testing Loss: 0.2600
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 32/50
train loss item: 0.2788454294204712
train loss item: 0.26806512475013733
train loss item: 0.28663161396980286
train loss item: 0.4170719385147095
train loss item: 0.29155370593070984
train loss item: 0.19078804552555084
train loss item: 0.34641215205192566
train loss item: 0.48718538880348206
train loss item: 0.18989963829517365
train loss item: 0.4707845151424408
train loss item: 0.5874319076538086
train loss item: 0.17885997891426086
test loss item: 0.3138543367385864
test loss item: 0.23589392006397247
test loss item: 0.2538122832775116
test loss item: 0.20634013414382935
test loss item: 0.3427949547767639
test loss item: 0.17114312946796417
test loss item: 0.2401975840330124
test loss item: 0.2146383672952652
test loss item: 0.32322078943252563
test loss item: 0.2745714783668518
test loss item: 0.3828916847705841
test loss item: 0.14480061829090118
Epoch [32/50], Training Loss: 0.3328, Testing Loss: 0.2587
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 33/50
train loss item: 0.28071433305740356
train loss item: 0.19346898794174194
train loss item: 0.2204681932926178
train loss item: 0.44058239459991455
train loss item: 0.36132481694221497
train loss item: 0.33480626344680786
train loss item: 0.24484609067440033
train loss item: 0.28973060846328735
train loss item: 0.1783083975315094
train loss item: 0.39354050159454346
train loss item: 0.5390594005584717
train loss item: 0.16736768186092377
test loss item: 0.24751602113246918
test loss item: 0.1874541938304901
test loss item: 0.20803892612457275
test loss item: 0.1599338799715042
test loss item: 0.2664538323879242
test loss item: 0.14755617082118988
test loss item: 0.21136410534381866
test loss item: 0.18012844026088715
test loss item: 0.2649105489253998
test loss item: 0.26092106103897095
test loss item: 0.2766168713569641
test loss item: 0.08290231227874756
Epoch [33/50], Training Loss: 0.3037, Testing Loss: 0.2078
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 34/50
train loss item: 0.26682648062705994
train loss item: 0.19196437299251556
train loss item: 0.20049813389778137
train loss item: 0.29235100746154785
train loss item: 0.18521597981452942
train loss item: 0.3138144612312317
train loss item: 0.14348889887332916
train loss item: 0.17078347504138947
train loss item: 0.16748355329036713
train loss item: 0.28158095479011536
train loss item: 0.4384198784828186
train loss item: 0.14808957278728485
test loss item: 0.17455564439296722
test loss item: 0.13286033272743225
test loss item: 0.13633207976818085
test loss item: 0.12775549292564392
test loss item: 0.1834893822669983
test loss item: 0.11511214077472687
test loss item: 0.1461762636899948
test loss item: 0.1221468597650528
test loss item: 0.17057448625564575
test loss item: 0.16818934679031372
test loss item: 0.18497858941555023
test loss item: 0.1400989592075348
Epoch [34/50], Training Loss: 0.2334, Testing Loss: 0.1502
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 35/50
train loss item: 0.16245783865451813
train loss item: 0.14116016030311584
train loss item: 0.17099156975746155
train loss item: 0.25352734327316284
train loss item: 0.13605846464633942
train loss item: 0.16095784306526184
train loss item: 0.15216098725795746
train loss item: 0.17125582695007324
train loss item: 0.13718420267105103
train loss item: 0.2595909535884857
train loss item: 0.3359132707118988
train loss item: 0.10856656730175018
test loss item: 0.16799794137477875
test loss item: 0.14291730523109436
test loss item: 0.12897852063179016
test loss item: 0.12308582663536072
test loss item: 0.18821854889392853
test loss item: 0.10200235992670059
test loss item: 0.14106494188308716
test loss item: 0.11228068917989731
test loss item: 0.1652507334947586
test loss item: 0.19394424557685852
test loss item: 0.2238304615020752
test loss item: 0.10623746365308762
Epoch [35/50], Training Loss: 0.1825, Testing Loss: 0.1497
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 36/50
train loss item: 0.21247795224189758
train loss item: 0.16002267599105835
train loss item: 0.1208716332912445
train loss item: 0.2174467146396637
train loss item: 0.14470231533050537
train loss item: 0.10500656813383102
train loss item: 0.1609877198934555
train loss item: 0.16907832026481628
train loss item: 0.1309305876493454
train loss item: 0.20278604328632355
train loss item: 0.21145103871822357
train loss item: 0.10002905875444412
test loss item: 0.20598123967647552
test loss item: 0.22936567664146423
test loss item: 0.12013370543718338
test loss item: 0.17525090277194977
test loss item: 0.3019527196884155
test loss item: 0.09231386333703995
test loss item: 0.2406649887561798
test loss item: 0.13243277370929718
test loss item: 0.2387930303812027
test loss item: 0.41636893153190613
test loss item: 0.38197073340415955
test loss item: 0.08271358162164688
Epoch [36/50], Training Loss: 0.1613, Testing Loss: 0.2182
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 37/50
train loss item: 0.33597254753112793
train loss item: 0.19722743332386017
train loss item: 0.14365029335021973
train loss item: 0.243754580616951
train loss item: 0.17224198579788208
train loss item: 0.16425076127052307
train loss item: 0.2679620385169983
train loss item: 0.30389899015426636
train loss item: 0.150191530585289
train loss item: 0.24834689497947693
train loss item: 0.2180371880531311
train loss item: 0.11343599110841751
test loss item: 0.23631702363491058
test loss item: 0.19571976363658905
test loss item: 0.1461382806301117
test loss item: 0.18044869601726532
test loss item: 0.26023197174072266
test loss item: 0.12188779562711716
test loss item: 0.21714316308498383
test loss item: 0.14526619017124176
test loss item: 0.2270602434873581
test loss item: 0.3027171194553375
test loss item: 0.31880897283554077
test loss item: 0.11348284035921097
Epoch [37/50], Training Loss: 0.2132, Testing Loss: 0.2054
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 38/50
train loss item: 0.3118976056575775
train loss item: 0.2999361455440521
train loss item: 0.28270378708839417
train loss item: 0.3618626892566681
train loss item: 0.27157020568847656
train loss item: 0.12376871705055237
train loss item: 0.2934865951538086
train loss item: 0.4358803927898407
train loss item: 0.20924951136112213
train loss item: 0.4408988058567047
train loss item: 0.5781092047691345
train loss item: 0.20739541947841644
test loss item: 0.27457186579704285
test loss item: 0.26559457182884216
test loss item: 0.24383336305618286
test loss item: 0.2435489296913147
test loss item: 0.3821086585521698
test loss item: 0.21804048120975494
test loss item: 0.3228829801082611
test loss item: 0.20204558968544006
test loss item: 0.2743351459503174
test loss item: 0.407728910446167
test loss item: 0.3669965863227844
test loss item: 0.12608255445957184
Epoch [38/50], Training Loss: 0.3181, Testing Loss: 0.2773
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 39/50
train loss item: 0.42136716842651367
train loss item: 0.2519909143447876
train loss item: 0.19100844860076904
train loss item: 0.2750077247619629
train loss item: 0.2941317558288574
train loss item: 0.3974290192127228
train loss item: 0.2738322615623474
train loss item: 0.2100270837545395
train loss item: 0.2002066671848297
train loss item: 0.27314698696136475
train loss item: 0.5270349979400635
train loss item: 0.12525522708892822
test loss item: 0.33932656049728394
test loss item: 0.30425339937210083
test loss item: 0.23794181644916534
test loss item: 0.24835766851902008
test loss item: 0.4157567322254181
test loss item: 0.1701907515525818
test loss item: 0.3225407600402832
test loss item: 0.2234346717596054
test loss item: 0.3573019206523895
test loss item: 0.4934895634651184
test loss item: 0.48374372720718384
test loss item: 0.12302349507808685
Epoch [39/50], Training Loss: 0.2867, Testing Loss: 0.3099
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 40/50
train loss item: 0.40076589584350586
train loss item: 0.22574378550052643
train loss item: 0.2100732922554016
train loss item: 0.23671554028987885
train loss item: 0.21049359440803528
train loss item: 0.26057952642440796
train loss item: 0.21609172224998474
train loss item: 0.23711450397968292
train loss item: 0.28424784541130066
train loss item: 0.33430764079093933
train loss item: 0.2879171669483185
train loss item: 0.19966106116771698
test loss item: 0.4171256422996521
test loss item: 0.1716279238462448
test loss item: 0.24712908267974854
test loss item: 0.20369009673595428
test loss item: 0.3175704777240753
test loss item: 0.14840130507946014
test loss item: 0.1941194385290146
test loss item: 0.21093475818634033
test loss item: 0.361569344997406
test loss item: 0.20113499462604523
test loss item: 0.36797472834587097
test loss item: 0.12438448518514633
Epoch [40/50], Training Loss: 0.2586, Testing Loss: 0.2471
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 41/50
train loss item: 0.23246203362941742
train loss item: 0.16871851682662964
train loss item: 0.15442660450935364
train loss item: 0.190139502286911
train loss item: 0.20077769458293915
train loss item: 0.11313116550445557
train loss item: 0.15362733602523804
train loss item: 0.17846116423606873
train loss item: 0.13446922600269318
train loss item: 0.2498854696750641
train loss item: 0.2623390853404999
train loss item: 0.10961470007896423
test loss item: 0.31541913747787476
test loss item: 0.12954868376255035
test loss item: 0.16500599682331085
test loss item: 0.17561033368110657
test loss item: 0.21370190382003784
test loss item: 0.1319781243801117
test loss item: 0.1408492624759674
test loss item: 0.13582679629325867
test loss item: 0.24843601882457733
test loss item: 0.20515526831150055
test loss item: 0.2645814120769501
test loss item: 0.15135006606578827
Epoch [41/50], Training Loss: 0.1790, Testing Loss: 0.1898
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 42/50
train loss item: 0.2502591609954834
train loss item: 0.18164078891277313
train loss item: 0.12561990320682526
train loss item: 0.18190599977970123
train loss item: 0.13835491240024567
train loss item: 0.09184744954109192
train loss item: 0.18763896822929382
train loss item: 0.23087607324123383
train loss item: 0.15592797100543976
train loss item: 0.3225227892398834
train loss item: 0.27418363094329834
train loss item: 0.13158516585826874
test loss item: 0.25524166226387024
test loss item: 0.09980656951665878
test loss item: 0.1112285628914833
test loss item: 0.13293248414993286
test loss item: 0.1543141007423401
test loss item: 0.10029188543558121
test loss item: 0.11402683705091476
test loss item: 0.09641802310943604
test loss item: 0.19025421142578125
test loss item: 0.14905980229377747
test loss item: 0.18766027688980103
test loss item: 0.08991503715515137
Epoch [42/50], Training Loss: 0.1894, Testing Loss: 0.1401
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 43/50
train loss item: 0.21491001546382904
train loss item: 0.2312358170747757
train loss item: 0.19917072355747223
train loss item: 0.3012402355670929
train loss item: 0.29729148745536804
train loss item: 0.18654726445674896
train loss item: 0.17563125491142273
train loss item: 0.23335647583007812
train loss item: 0.1573581099510193
train loss item: 0.3944404125213623
train loss item: 0.4733639359474182
train loss item: 0.17883548140525818
test loss item: 0.20699526369571686
test loss item: 0.200969859957695
test loss item: 0.171412393450737
test loss item: 0.1759432554244995
test loss item: 0.2699485719203949
test loss item: 0.1285237818956375
test loss item: 0.21724489331245422
test loss item: 0.15349367260932922
test loss item: 0.2308391034603119
test loss item: 0.3187812268733978
test loss item: 0.2899828553199768
test loss item: 0.07373977452516556
Epoch [43/50], Training Loss: 0.2536, Testing Loss: 0.2032
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 44/50
train loss item: 0.24591749906539917
train loss item: 0.1554775983095169
train loss item: 0.16196216642856598
train loss item: 0.20250964164733887
train loss item: 0.22682856023311615
train loss item: 0.23919163644313812
train loss item: 0.16692237555980682
train loss item: 0.16595785319805145
train loss item: 0.1466732770204544
train loss item: 0.2911995053291321
train loss item: 0.38592368364334106
train loss item: 0.11900020390748978
test loss item: 0.2354348748922348
test loss item: 0.1543302685022354
test loss item: 0.16789035499095917
test loss item: 0.14031440019607544
test loss item: 0.23147734999656677
test loss item: 0.1129305511713028
test loss item: 0.16908077895641327
test loss item: 0.1523832231760025
test loss item: 0.22299623489379883
test loss item: 0.21821004152297974
test loss item: 0.2507471740245819
test loss item: 0.09513609111309052
Epoch [44/50], Training Loss: 0.2090, Testing Loss: 0.1792
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 45/50
train loss item: 0.17560139298439026
train loss item: 0.12639200687408447
train loss item: 0.13933512568473816
train loss item: 0.19285348057746887
train loss item: 0.16569358110427856
train loss item: 0.21336258947849274
train loss item: 0.1236235722899437
train loss item: 0.1335480660200119
train loss item: 0.13345812261104584
train loss item: 0.2396271824836731
train loss item: 0.36444294452667236
train loss item: 0.11228708177804947
test loss item: 0.24700282514095306
test loss item: 0.11624554544687271
test loss item: 0.15452304482460022
test loss item: 0.14267049729824066
test loss item: 0.18055666983127594
test loss item: 0.11923902481794357
test loss item: 0.1323612779378891
test loss item: 0.12259657680988312
test loss item: 0.21039436757564545
test loss item: 0.17039570212364197
test loss item: 0.2170359492301941
test loss item: 0.1136862114071846
Epoch [45/50], Training Loss: 0.1767, Testing Loss: 0.1606
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 46/50
train loss item: 0.1239171177148819
train loss item: 0.10143399238586426
train loss item: 0.10130991041660309
train loss item: 0.14531084895133972
train loss item: 0.12978914380073547
train loss item: 0.16666197776794434
train loss item: 0.11245325207710266
train loss item: 0.13077740371227264
train loss item: 0.11381276696920395
train loss item: 0.21720296144485474
train loss item: 0.3146321475505829
train loss item: 0.08932135999202728
test loss item: 0.22751106321811676
test loss item: 0.10261077433824539
test loss item: 0.14041244983673096
test loss item: 0.12697485089302063
test loss item: 0.1591232866048813
test loss item: 0.10630111396312714
test loss item: 0.11332987993955612
test loss item: 0.11197918653488159
test loss item: 0.1954231858253479
test loss item: 0.13522987067699432
test loss item: 0.1941264420747757
test loss item: 0.10124950855970383
Epoch [46/50], Training Loss: 0.1456, Testing Loss: 0.1429
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 47/50
train loss item: 0.12159576267004013
train loss item: 0.0935211181640625
train loss item: 0.07825635373592377
train loss item: 0.12737300992012024
train loss item: 0.12329668551683426
train loss item: 0.10941649973392487
train loss item: 0.11152689158916473
train loss item: 0.13675831258296967
train loss item: 0.10189997404813766
train loss item: 0.1983153522014618
train loss item: 0.2339385449886322
train loss item: 0.07796630263328552
test loss item: 0.15946424007415771
test loss item: 0.09308113157749176
test loss item: 0.09755950421094894
test loss item: 0.09431957453489304
test loss item: 0.12818516790866852
test loss item: 0.08311540633440018
test loss item: 0.09295618534088135
test loss item: 0.08636604249477386
test loss item: 0.14589045941829681
test loss item: 0.1335410326719284
test loss item: 0.1546088457107544
test loss item: 0.1088583841919899
Epoch [47/50], Training Loss: 0.1262, Testing Loss: 0.1148
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 48/50
train loss item: 0.16977764666080475
train loss item: 0.13987921178340912
train loss item: 0.12528350949287415
train loss item: 0.1900581419467926
train loss item: 0.13027919828891754
train loss item: 0.08750669658184052
train loss item: 0.16963842511177063
train loss item: 0.2167855203151703
train loss item: 0.12866875529289246
train loss item: 0.2212003618478775
train loss item: 0.26919105648994446
train loss item: 0.09816580265760422
test loss item: 0.12167991697788239
test loss item: 0.09138460457324982
test loss item: 0.09337937831878662
test loss item: 0.08998104929924011
test loss item: 0.12556259334087372
test loss item: 0.08791108429431915
test loss item: 0.09771982580423355
test loss item: 0.08032098412513733
test loss item: 0.10788479447364807
test loss item: 0.12322279065847397
test loss item: 0.12340335547924042
test loss item: 0.13028430938720703
Epoch [48/50], Training Loss: 0.1622, Testing Loss: 0.1061
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 49/50
train loss item: 0.16365528106689453
train loss item: 0.16030609607696533
train loss item: 0.169470876455307
train loss item: 0.2930401861667633
train loss item: 0.2508467137813568
train loss item: 0.11906575411558151
train loss item: 0.15905894339084625
train loss item: 0.23134185373783112
train loss item: 0.14452479779720306
train loss item: 0.2825433015823364
train loss item: 0.4274810254573822
train loss item: 0.15396586060523987
test loss item: 0.28854596614837646
test loss item: 0.21860051155090332
test loss item: 0.21570004522800446
test loss item: 0.21034853160381317
test loss item: 0.330207884311676
test loss item: 0.1880994737148285
test loss item: 0.26370587944984436
test loss item: 0.1661253720521927
test loss item: 0.27544403076171875
test loss item: 0.38394492864608765
test loss item: 0.3374709486961365
test loss item: 0.09166418015956879
Epoch [49/50], Training Loss: 0.2129, Testing Loss: 0.2475
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 50/50
train loss item: 0.319670706987381
train loss item: 0.20678496360778809
train loss item: 0.1670871078968048
train loss item: 0.1988767683506012
train loss item: 0.20309202373027802
train loss item: 0.2115241438150406
train loss item: 0.22230824828147888
train loss item: 0.18980449438095093
train loss item: 0.18700557947158813
train loss item: 0.2996695041656494
train loss item: 0.4554557502269745
train loss item: 0.11729127168655396
test loss item: 0.274837851524353
test loss item: 0.24561230838298798
test loss item: 0.19202710688114166
test loss item: 0.2102569341659546
test loss item: 0.32983505725860596
test loss item: 0.15237067639827728
test loss item: 0.26446446776390076
test loss item: 0.16795948147773743
test loss item: 0.2822708487510681
test loss item: 0.4208580553531647
test loss item: 0.38358819484710693
test loss item: 0.09521222114562988
Epoch [50/50], Training Loss: 0.2315, Testing Loss: 0.2516
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
loss item: 0.3743736445903778
loss item: 0.21697819232940674
loss item: 0.2641730010509491
loss item: 0.42734187841415405
loss item: 0.2076963633298874
loss item: 0.3656686544418335
Val Loss: 0.3094
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 50, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 50 0.005 16 360 done at Tue Nov 12 12:16:37 CET 2024
UNet2 with 1 50 0.0001 32 360 start at Tue Nov 12 12:16:37 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.0001 32 360 done at Tue Nov 12 12:16:46 CET 2024
UNet2 with 1 50 0.0005 32 360 start at Tue Nov 12 12:16:46 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.0005 32 360 done at Tue Nov 12 12:16:55 CET 2024
UNet2 with 1 50 0.001 32 360 start at Tue Nov 12 12:16:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 50, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.001 32 360 done at Tue Nov 12 12:17:03 CET 2024
UNet2 with 1 50 0.005 32 360 start at Tue Nov 12 12:17:03 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 50, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.005 32 360 done at Tue Nov 12 12:17:11 CET 2024
UNet2 with 1 50 0.0001 64 360 start at Tue Nov 12 12:17:11 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.0001 64 360 done at Tue Nov 12 12:17:21 CET 2024
UNet2 with 1 50 0.0005 64 360 start at Tue Nov 12 12:17:21 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.0005 64 360 done at Tue Nov 12 12:18:57 CET 2024
UNet2 with 1 50 0.001 64 360 start at Tue Nov 12 12:18:57 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 50, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.001 64 360 done at Tue Nov 12 12:19:47 CET 2024
UNet2 with 1 50 0.005 64 360 start at Tue Nov 12 12:19:47 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 50, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.005 64 360 done at Tue Nov 12 12:20:08 CET 2024
UNet2 with 1 50 0.0001 128 360 start at Tue Nov 12 12:20:08 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 50, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.0001 128 360 done at Tue Nov 12 12:20:23 CET 2024
UNet2 with 1 50 0.0005 128 360 start at Tue Nov 12 12:20:23 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 50, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.0005 128 360 done at Tue Nov 12 12:20:30 CET 2024
UNet2 with 1 50 0.001 128 360 start at Tue Nov 12 12:20:30 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 50, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.001 128 360 done at Tue Nov 12 12:20:39 CET 2024
UNet2 with 1 50 0.005 128 360 start at Tue Nov 12 12:20:39 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 50, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/50
UNet2 with 1 50 0.005 128 360 done at Tue Nov 12 12:20:47 CET 2024
UNet2 with 1 100 0.0001 2 360 start at Tue Nov 12 12:20:47 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 0.9121710062026978
train loss item: 2.361032485961914
train loss item: 0.5908730030059814
train loss item: 1.2434922456741333
train loss item: 0.8365021347999573
train loss item: 0.5948132276535034
train loss item: 0.5484413504600525
train loss item: 1.2568069696426392
train loss item: 0.4701719582080841
train loss item: 0.49126583337783813
train loss item: 0.5907455086708069
train loss item: 0.4010674059391022
train loss item: 0.3736041486263275
train loss item: 0.7809377312660217
train loss item: 0.509601891040802
train loss item: 1.0467482805252075
train loss item: 0.38424307107925415
train loss item: 0.5152631402015686
train loss item: 0.5292810797691345
train loss item: 0.407499760389328
train loss item: 0.3384734094142914
train loss item: 0.33425581455230713
train loss item: 1.4463419914245605
train loss item: 1.2463154792785645
train loss item: 0.7553142309188843
train loss item: 0.43640974164009094
train loss item: 0.37979209423065186
train loss item: 0.43813005089759827
train loss item: 0.28189951181411743
train loss item: 1.0697678327560425
train loss item: 2.858053207397461
train loss item: 0.7476573586463928
train loss item: 0.26521676778793335
train loss item: 0.5216339826583862
train loss item: 0.5793464183807373
train loss item: 2.6721296310424805
train loss item: 0.6262391209602356
train loss item: 0.4187734127044678
train loss item: 0.5651669502258301
train loss item: 0.44667813181877136
train loss item: 0.28570106625556946
train loss item: 0.3944515585899353
train loss item: 0.3284895420074463
train loss item: 0.337677538394928
train loss item: 0.7978792190551758
train loss item: 0.3569549322128296
train loss item: 0.2912555932998657
train loss item: 0.454662024974823
train loss item: 0.3029745817184448
train loss item: 0.25580763816833496
train loss item: 0.3692210614681244
train loss item: 1.0773347616195679
train loss item: 0.26498883962631226
train loss item: 0.25303590297698975
train loss item: 2.452367067337036
train loss item: 0.2578674852848053
train loss item: 0.3483966290950775
train loss item: 0.3164193332195282
train loss item: 0.2925061285495758
train loss item: 0.2450268268585205
train loss item: 1.0275503396987915
train loss item: 2.277750015258789
train loss item: 0.26835423707962036
train loss item: 0.3801731467247009
train loss item: 0.23931489884853363
train loss item: 0.7239580750465393
train loss item: 0.445193350315094
train loss item: 0.303986132144928
train loss item: 0.324326753616333
train loss item: 0.3634343445301056
train loss item: 0.28776270151138306
train loss item: 0.27615952491760254
train loss item: 0.2999342083930969
train loss item: 0.3200346827507019
train loss item: 0.22308796644210815
train loss item: 0.18532486259937286
train loss item: 0.9706341028213501
train loss item: 1.4912152290344238
train loss item: 0.19212085008621216
train loss item: 0.2843157649040222
train loss item: 0.2530641257762909
train loss item: 0.2367672324180603
train loss item: 0.2718278169631958
train loss item: 0.6453335285186768
train loss item: 0.3626972436904907
train loss item: 0.680824339389801
train loss item: 4.3681488037109375
train loss item: 0.2382141500711441
train loss item: 0.3801846206188202
test loss item: 0.21100924909114838
test loss item: 0.1905904859304428
test loss item: 0.493234783411026
test loss item: 0.2629840075969696
test loss item: 0.30734843015670776
test loss item: 0.23107047379016876
test loss item: 1.272710919380188
test loss item: 0.3848780691623688
test loss item: 0.22346585988998413
test loss item: 0.381833016872406
test loss item: 0.8189902305603027
test loss item: 0.2084769308567047
test loss item: 0.21908438205718994
test loss item: 0.33655762672424316
test loss item: 0.23035652935504913
test loss item: 0.1612349897623062
test loss item: 0.26569706201553345
test loss item: 0.4498690366744995
test loss item: 0.5908847451210022
test loss item: 0.26883623003959656
test loss item: 0.7079334855079651
test loss item: 0.34440669417381287
test loss item: 0.30552637577056885
test loss item: 0.2102038860321045
test loss item: 0.23730531334877014
test loss item: 0.2640498876571655
test loss item: 0.3360220491886139
test loss item: 0.2627532482147217
test loss item: 0.3543626070022583
test loss item: 0.36366814374923706
test loss item: 0.6721838712692261
test loss item: 0.1511075347661972
test loss item: 0.20101863145828247
test loss item: 0.5464137196540833
test loss item: 0.4172126054763794
test loss item: 0.5716060996055603
test loss item: 0.70134437084198
test loss item: 1.356266975402832
test loss item: 0.47007670998573303
test loss item: 0.29342812299728394
test loss item: 0.2850244343280792
test loss item: 0.24279940128326416
test loss item: 0.3389380872249603
test loss item: 0.21887172758579254
test loss item: 0.5867714881896973
test loss item: 0.37481752038002014
test loss item: 0.3145896792411804
test loss item: 0.29516535997390747
test loss item: 0.4280039966106415
test loss item: 0.6496374011039734
test loss item: 0.31711316108703613
test loss item: 0.20819510519504547
test loss item: 0.23961491882801056
test loss item: 0.23810023069381714
test loss item: 0.3062787652015686
test loss item: 0.754949152469635
test loss item: 0.5467913150787354
test loss item: 0.27358928322792053
test loss item: 0.2504788339138031
test loss item: 0.23311938345432281
test loss item: 0.45070433616638184
test loss item: 0.2125469595193863
test loss item: 0.2315702736377716
test loss item: 0.2604731023311615
test loss item: 0.696123480796814
test loss item: 0.3371492326259613
test loss item: 0.3023376166820526
test loss item: 0.2690799832344055
test loss item: 0.5280156135559082
test loss item: 0.428323894739151
test loss item: 0.16557703912258148
test loss item: 0.7224841713905334
test loss item: 0.28124964237213135
test loss item: 0.3354153633117676
test loss item: 0.1801617592573166
test loss item: 0.22270898520946503
test loss item: 0.21052978932857513
test loss item: 1.345981240272522
test loss item: 0.4439548850059509
test loss item: 0.261204332113266
test loss item: 0.15042409300804138
test loss item: 0.8808879852294922
test loss item: 0.7729071974754333
test loss item: 0.9290870428085327
test loss item: 0.25774550437927246
test loss item: 0.24865679442882538
test loss item: 0.1663329303264618
test loss item: 0.16702459752559662
test loss item: 0.20241861045360565
Epoch [1/100], Training Loss: 0.6660, Testing Loss: 0.3937
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/100
train loss item: 0.48500680923461914
train loss item: 1.1864590644836426
train loss item: 0.3508640229701996
train loss item: 0.5151530504226685
train loss item: 1.8454673290252686
train loss item: 0.37411361932754517
train loss item: 0.26874735951423645
train loss item: 0.7689760327339172
train loss item: 0.21163707971572876
train loss item: 0.3168288469314575
train loss item: 0.3959479033946991
train loss item: 0.27108681201934814
train loss item: 0.1811189204454422
train loss item: 0.5443882346153259
train loss item: 0.3077506124973297
train loss item: 0.787498414516449
train loss item: 0.14723119139671326
train loss item: 0.2873050570487976
train loss item: 0.33562010526657104
train loss item: 0.3018501400947571
train loss item: 0.2441416084766388
train loss item: 0.1842338591814041
train loss item: 0.9704393744468689
train loss item: 1.043884515762329
train loss item: 0.5557245016098022
train loss item: 0.3019523024559021
train loss item: 0.28606241941452026
train loss item: 0.3080558180809021
train loss item: 0.19289523363113403
train loss item: 0.6662306189537048
train loss item: 2.1989352703094482
train loss item: 0.600832998752594
train loss item: 0.20529243350028992
train loss item: 0.4043195843696594
train loss item: 0.26840314269065857
train loss item: 2.191783905029297
train loss item: 0.5457374453544617
train loss item: 0.48889845609664917
train loss item: 0.5570715069770813
train loss item: 0.36063817143440247
train loss item: 0.32198330760002136
train loss item: 0.3245721459388733
train loss item: 0.3126809895038605
train loss item: 0.2532402575016022
train loss item: 0.6258190274238586
train loss item: 0.21640613675117493
train loss item: 0.14717531204223633
train loss item: 0.37694770097732544
train loss item: 0.21109218895435333
train loss item: 0.18790778517723083
train loss item: 0.27791184186935425
train loss item: 0.9104347229003906
train loss item: 0.1188352033495903
train loss item: 0.20859506726264954
train loss item: 2.113276243209839
train loss item: 0.19718770682811737
train loss item: 0.3474990129470825
train loss item: 0.2297925502061844
train loss item: 0.19623008370399475
train loss item: 0.16100898385047913
train loss item: 0.755406379699707
train loss item: 1.9041850566864014
train loss item: 0.23504287004470825
train loss item: 0.34660056233406067
train loss item: 0.17821645736694336
train loss item: 0.5193289518356323
train loss item: 0.4283766448497772
train loss item: 0.24446611106395721
train loss item: 0.30278101563453674
train loss item: 0.3167077898979187
train loss item: 0.2663639187812805
train loss item: 0.19255146384239197
train loss item: 0.20296163856983185
train loss item: 0.27306029200553894
train loss item: 0.16356468200683594
train loss item: 0.13581477105617523
train loss item: 0.7882338762283325
train loss item: 1.2669059038162231
train loss item: 0.10500571876764297
train loss item: 0.23480942845344543
train loss item: 0.15628831088542938
train loss item: 0.19977013766765594
train loss item: 0.23715628683567047
train loss item: 0.49897128343582153
train loss item: 0.3223642110824585
train loss item: 0.5064004063606262
train loss item: 3.836564779281616
train loss item: 0.1922953575849533
train loss item: 0.3331531584262848
test loss item: 0.16456946730613708
test loss item: 0.11038728058338165
test loss item: 0.41948583722114563
test loss item: 0.20428384840488434
test loss item: 0.21386538445949554
test loss item: 0.12129561603069305
test loss item: 1.1379759311676025
test loss item: 0.42230767011642456
test loss item: 0.17199808359146118
test loss item: 0.31706321239471436
test loss item: 0.6662368178367615
test loss item: 0.1533002108335495
test loss item: 0.16496215760707855
test loss item: 0.2558002173900604
test loss item: 0.15268272161483765
test loss item: 0.11311981081962585
test loss item: 0.23457683622837067
test loss item: 0.37272506952285767
test loss item: 0.5599627494812012
test loss item: 0.2108278125524521
test loss item: 0.6021773219108582
test loss item: 0.30609267950057983
test loss item: 0.22708241641521454
test loss item: 0.1507413536310196
test loss item: 0.19595392048358917
test loss item: 0.20579475164413452
test loss item: 0.2658422589302063
test loss item: 0.17071907222270966
test loss item: 0.27401527762413025
test loss item: 0.29511889815330505
test loss item: 0.5428682565689087
test loss item: 0.10044039040803909
test loss item: 0.13385009765625
test loss item: 0.4724656045436859
test loss item: 0.33872246742248535
test loss item: 0.3904491066932678
test loss item: 0.6551851034164429
test loss item: 1.0588656663894653
test loss item: 0.3864870071411133
test loss item: 0.22728078067302704
test loss item: 0.25358232855796814
test loss item: 0.1645478755235672
test loss item: 0.29995766282081604
test loss item: 0.17277176678180695
test loss item: 0.4874116778373718
test loss item: 0.32642003893852234
test loss item: 0.23674285411834717
test loss item: 0.2063627988100052
test loss item: 0.36967185139656067
test loss item: 0.5366275906562805
test loss item: 0.2455424666404724
test loss item: 0.14099395275115967
test loss item: 0.19800561666488647
test loss item: 0.1570899337530136
test loss item: 0.24934060871601105
test loss item: 0.6377779245376587
test loss item: 0.4665624499320984
test loss item: 0.2056286484003067
test loss item: 0.20034603774547577
test loss item: 0.1855689436197281
test loss item: 0.38074633479118347
test loss item: 0.1928337663412094
test loss item: 0.17647764086723328
test loss item: 0.22014030814170837
test loss item: 0.5952824354171753
test loss item: 0.2790825068950653
test loss item: 0.2577891945838928
test loss item: 0.22083067893981934
test loss item: 0.45469313859939575
test loss item: 0.372977614402771
test loss item: 0.09554248303174973
test loss item: 0.6771318912506104
test loss item: 0.23136042058467865
test loss item: 0.2950713336467743
test loss item: 0.12782225012779236
test loss item: 0.1396246701478958
test loss item: 0.15078453719615936
test loss item: 1.0145968198776245
test loss item: 0.3603816330432892
test loss item: 0.16605304181575775
test loss item: 0.08830113708972931
test loss item: 0.7166067361831665
test loss item: 0.6842418313026428
test loss item: 0.703576385974884
test loss item: 0.19565007090568542
test loss item: 0.1880267858505249
test loss item: 0.10575206577777863
test loss item: 0.12133488804101944
test loss item: 0.16646070778369904
Epoch [2/100], Training Loss: 0.5094, Testing Loss: 0.3178
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/100
train loss item: 0.41057389974594116
train loss item: 0.9392258524894714
train loss item: 0.22056832909584045
train loss item: 0.43680208921432495
train loss item: 0.6556686758995056
train loss item: 0.30349549651145935
train loss item: 0.2789488136768341
train loss item: 0.5759757161140442
train loss item: 0.21900008618831635
train loss item: 0.2762719392776489
train loss item: 0.3241414725780487
train loss item: 0.25244632363319397
train loss item: 0.14802424609661102
train loss item: 0.4438804090023041
train loss item: 0.22367443144321442
train loss item: 0.6498077511787415
train loss item: 0.10418679565191269
train loss item: 0.24753674864768982
train loss item: 0.271727979183197
train loss item: 0.2491001933813095
train loss item: 0.2201738804578781
train loss item: 0.16697193682193756
train loss item: 0.8138332962989807
train loss item: 0.832940936088562
train loss item: 0.5344581007957458
train loss item: 0.2553643584251404
train loss item: 0.23663429915905
train loss item: 0.24703827500343323
train loss item: 0.106563501060009
train loss item: 0.5640798807144165
train loss item: 1.7679976224899292
train loss item: 0.5301427245140076
train loss item: 0.1523536741733551
train loss item: 0.3506092429161072
train loss item: 0.2269054800271988
train loss item: 1.9261847734451294
train loss item: 0.5025743842124939
train loss item: 0.4173262119293213
train loss item: 0.612385094165802
train loss item: 0.27643051743507385
train loss item: 0.2588752210140228
train loss item: 0.2402261644601822
train loss item: 0.3003993630409241
train loss item: 0.20986206829547882
train loss item: 0.5492078065872192
train loss item: 0.16295021772384644
train loss item: 0.11572805792093277
train loss item: 0.3610960841178894
train loss item: 0.18830306828022003
train loss item: 0.15522484481334686
train loss item: 0.25792670249938965
train loss item: 0.8181875348091125
train loss item: 0.09539136290550232
train loss item: 0.17696301639080048
train loss item: 1.9070606231689453
train loss item: 0.170675590634346
train loss item: 0.28691366314888
train loss item: 0.20082181692123413
train loss item: 0.1609772890806198
train loss item: 0.1317761093378067
train loss item: 0.6230367422103882
train loss item: 1.7065331935882568
train loss item: 0.20592091977596283
train loss item: 0.33050400018692017
train loss item: 0.15625238418579102
train loss item: 0.5017097592353821
train loss item: 0.43653878569602966
train loss item: 0.22097647190093994
train loss item: 0.2648906111717224
train loss item: 0.29357579350471497
train loss item: 0.24327246844768524
train loss item: 0.15217532217502594
train loss item: 0.1687525063753128
train loss item: 0.2407342791557312
train loss item: 0.1157328262925148
train loss item: 0.11458990722894669
train loss item: 0.6786723136901855
train loss item: 1.1846877336502075
train loss item: 0.09225727617740631
train loss item: 0.20939737558364868
train loss item: 0.13876096904277802
train loss item: 0.1612091213464737
train loss item: 0.22264538705348969
train loss item: 0.42996418476104736
train loss item: 0.3240766227245331
train loss item: 0.4125942885875702
train loss item: 3.5785934925079346
train loss item: 0.14885194599628448
train loss item: 0.3150218427181244
test loss item: 0.16498811542987823
test loss item: 0.11600631475448608
test loss item: 0.3680499494075775
test loss item: 0.19585846364498138
test loss item: 0.20214354991912842
test loss item: 0.12462395429611206
test loss item: 1.0673556327819824
test loss item: 0.4267731308937073
test loss item: 0.16261166334152222
test loss item: 0.27788877487182617
test loss item: 0.5889781713485718
test loss item: 0.14192666113376617
test loss item: 0.1640489101409912
test loss item: 0.23899605870246887
test loss item: 0.15037652850151062
test loss item: 0.10529238730669022
test loss item: 0.21675445139408112
test loss item: 0.31497448682785034
test loss item: 0.536879301071167
test loss item: 0.20804831385612488
test loss item: 0.5074040293693542
test loss item: 0.29394447803497314
test loss item: 0.21730881929397583
test loss item: 0.1496402621269226
test loss item: 0.16933496296405792
test loss item: 0.2033127099275589
test loss item: 0.24408596754074097
test loss item: 0.1658170521259308
test loss item: 0.2517901659011841
test loss item: 0.26298534870147705
test loss item: 0.48619210720062256
test loss item: 0.09431294351816177
test loss item: 0.13469067215919495
test loss item: 0.4063783884048462
test loss item: 0.2847801744937897
test loss item: 0.3589833378791809
test loss item: 0.6201183199882507
test loss item: 0.9135726094245911
test loss item: 0.3269723355770111
test loss item: 0.2146047055721283
test loss item: 0.23267878592014313
test loss item: 0.19084778428077698
test loss item: 0.2560923099517822
test loss item: 0.15717189013957977
test loss item: 0.40955156087875366
test loss item: 0.30948200821876526
test loss item: 0.2351771593093872
test loss item: 0.21544206142425537
test loss item: 0.33024609088897705
test loss item: 0.47751888632774353
test loss item: 0.21951842308044434
test loss item: 0.1381026953458786
test loss item: 0.1801338940858841
test loss item: 0.1368313431739807
test loss item: 0.2214929312467575
test loss item: 0.5475833415985107
test loss item: 0.4356391131877899
test loss item: 0.20974023640155792
test loss item: 0.1905653327703476
test loss item: 0.17301692068576813
test loss item: 0.32186779379844666
test loss item: 0.19388088583946228
test loss item: 0.1754915565252304
test loss item: 0.20177891850471497
test loss item: 0.5454671382904053
test loss item: 0.26212915778160095
test loss item: 0.24920544028282166
test loss item: 0.20816993713378906
test loss item: 0.40145620703697205
test loss item: 0.36376145482063293
test loss item: 0.10478593409061432
test loss item: 0.647621214389801
test loss item: 0.2223510891199112
test loss item: 0.27984219789505005
test loss item: 0.13160434365272522
test loss item: 0.15958917140960693
test loss item: 0.15141436457633972
test loss item: 0.8801490664482117
test loss item: 0.31721606850624084
test loss item: 0.16654878854751587
test loss item: 0.09368784725666046
test loss item: 0.6575867533683777
test loss item: 0.634811282157898
test loss item: 0.6204633116722107
test loss item: 0.1728341430425644
test loss item: 0.1753714382648468
test loss item: 0.09615317732095718
test loss item: 0.09753245860338211
test loss item: 0.1807059645652771
Epoch [3/100], Training Loss: 0.4314, Testing Loss: 0.2928
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/100
train loss item: 0.35598820447921753
train loss item: 0.8042619824409485
train loss item: 0.20258288085460663
train loss item: 0.3679743707180023
train loss item: 0.3493640124797821
train loss item: 0.2614400386810303
train loss item: 0.2123015820980072
train loss item: 0.49573248624801636
train loss item: 0.12789037823677063
train loss item: 0.22288234531879425
train loss item: 0.2549700140953064
train loss item: 0.2291392683982849
train loss item: 0.1250050812959671
train loss item: 0.38927099108695984
train loss item: 0.1970185786485672
train loss item: 0.5646058320999146
train loss item: 0.08877763152122498
train loss item: 0.20903925597667694
train loss item: 0.22932535409927368
train loss item: 0.23731489479541779
train loss item: 0.1798063963651657
train loss item: 0.15170565247535706
train loss item: 0.6788648366928101
train loss item: 0.7174670100212097
train loss item: 0.40623781085014343
train loss item: 0.21019499003887177
train loss item: 0.18434979021549225
train loss item: 0.20658157765865326
train loss item: 0.0767621323466301
train loss item: 0.484586626291275
train loss item: 1.5610963106155396
train loss item: 0.4576701819896698
train loss item: 0.11579523980617523
train loss item: 0.32334160804748535
train loss item: 0.1675577461719513
train loss item: 1.7904075384140015
train loss item: 0.4623925983905792
train loss item: 0.3854462206363678
train loss item: 0.519524097442627
train loss item: 0.22983407974243164
train loss item: 0.25588035583496094
train loss item: 0.20621319115161896
train loss item: 0.28468814492225647
train loss item: 0.18225841224193573
train loss item: 0.5219123959541321
train loss item: 0.1323309987783432
train loss item: 0.10669330507516861
train loss item: 0.34430891275405884
train loss item: 0.18780651688575745
train loss item: 0.1343318372964859
train loss item: 0.2666662931442261
train loss item: 0.7907475233078003
train loss item: 0.0894383043050766
train loss item: 0.16132991015911102
train loss item: 1.8235493898391724
train loss item: 0.15067575871944427
train loss item: 0.24774223566055298
train loss item: 0.18197417259216309
train loss item: 0.1380002647638321
train loss item: 0.13140511512756348
train loss item: 0.5338607430458069
train loss item: 1.5581157207489014
train loss item: 0.19453473389148712
train loss item: 0.3236832320690155
train loss item: 0.15777035057544708
train loss item: 0.4651155173778534
train loss item: 0.41722169518470764
train loss item: 0.2116740345954895
train loss item: 0.23992526531219482
train loss item: 0.26229363679885864
train loss item: 0.2425377070903778
train loss item: 0.13498054444789886
train loss item: 0.15224233269691467
train loss item: 0.22560636699199677
train loss item: 0.09823179244995117
train loss item: 0.10817596316337585
train loss item: 0.5941234827041626
train loss item: 1.1474241018295288
train loss item: 0.07439909130334854
train loss item: 0.18922768533229828
train loss item: 0.13035689294338226
train loss item: 0.15190459787845612
train loss item: 0.2061934918165207
train loss item: 0.3775103986263275
train loss item: 0.3153328597545624
train loss item: 0.35125240683555603
train loss item: 3.4140055179595947
train loss item: 0.12561409175395966
train loss item: 0.2921113967895508
test loss item: 0.14565269649028778
test loss item: 0.09972818195819855
test loss item: 0.31904807686805725
test loss item: 0.17741473019123077
test loss item: 0.17818129062652588
test loss item: 0.1090296283364296
test loss item: 0.9717305302619934
test loss item: 0.3816626965999603
test loss item: 0.1452505886554718
test loss item: 0.2422090768814087
test loss item: 0.5103796124458313
test loss item: 0.12755726277828217
test loss item: 0.14440789818763733
test loss item: 0.2017776519060135
test loss item: 0.1303005814552307
test loss item: 0.08662473410367966
test loss item: 0.18547125160694122
test loss item: 0.2678360939025879
test loss item: 0.48603954911231995
test loss item: 0.17721052467823029
test loss item: 0.42158231139183044
test loss item: 0.26450249552726746
test loss item: 0.18629325926303864
test loss item: 0.13067232072353363
test loss item: 0.1426168531179428
test loss item: 0.19152763485908508
test loss item: 0.20925676822662354
test loss item: 0.14573708176612854
test loss item: 0.21618017554283142
test loss item: 0.22732073068618774
test loss item: 0.41734644770622253
test loss item: 0.07876484841108322
test loss item: 0.11808403581380844
test loss item: 0.3473883271217346
test loss item: 0.23896190524101257
test loss item: 0.33106085658073425
test loss item: 0.5586614608764648
test loss item: 0.7654697895050049
test loss item: 0.27772554755210876
test loss item: 0.19078901410102844
test loss item: 0.2128448337316513
test loss item: 0.15439927577972412
test loss item: 0.22256439924240112
test loss item: 0.1414870321750641
test loss item: 0.33886849880218506
test loss item: 0.2580082416534424
test loss item: 0.19026507437229156
test loss item: 0.18398751318454742
test loss item: 0.2912936806678772
test loss item: 0.4199453592300415
test loss item: 0.19200272858142853
test loss item: 0.12052552402019501
test loss item: 0.1610703319311142
test loss item: 0.12301196902990341
test loss item: 0.19241128861904144
test loss item: 0.4637324810028076
test loss item: 0.39481818675994873
test loss item: 0.16888964176177979
test loss item: 0.16964846849441528
test loss item: 0.1543264091014862
test loss item: 0.2779274880886078
test loss item: 0.16815245151519775
test loss item: 0.15325114130973816
test loss item: 0.1821765899658203
test loss item: 0.4927235543727875
test loss item: 0.24160215258598328
test loss item: 0.222931370139122
test loss item: 0.18811367452144623
test loss item: 0.34758302569389343
test loss item: 0.32354772090911865
test loss item: 0.08773090690374374
test loss item: 0.5885575413703918
test loss item: 0.1844480335712433
test loss item: 0.24837709963321686
test loss item: 0.11248736828565598
test loss item: 0.12719129025936127
test loss item: 0.13286513090133667
test loss item: 0.7408822774887085
test loss item: 0.26143887639045715
test loss item: 0.14205902814865112
test loss item: 0.08329802006483078
test loss item: 0.5837969779968262
test loss item: 0.5615742802619934
test loss item: 0.5285375714302063
test loss item: 0.1554044932126999
test loss item: 0.1572323888540268
test loss item: 0.08322959393262863
test loss item: 0.07697780430316925
test loss item: 0.17034783959388733
Epoch [4/100], Training Loss: 0.3850, Testing Loss: 0.2553
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/100
train loss item: 0.32581350207328796
train loss item: 0.68785560131073
train loss item: 0.1689162701368332
train loss item: 0.30728569626808167
train loss item: 0.3112659454345703
train loss item: 0.23388192057609558
train loss item: 0.197120800614357
train loss item: 0.4242609739303589
train loss item: 0.1765977442264557
train loss item: 0.22172120213508606
train loss item: 0.23896799981594086
train loss item: 0.21106785535812378
train loss item: 0.12419063597917557
train loss item: 0.35141801834106445
train loss item: 0.1784149706363678
train loss item: 0.4844543933868408
train loss item: 0.07442507147789001
train loss item: 0.20637254416942596
train loss item: 0.22465862333774567
train loss item: 0.2201792299747467
train loss item: 0.15568211674690247
train loss item: 0.14188474416732788
train loss item: 0.6201402544975281
train loss item: 0.6293896436691284
train loss item: 0.35873788595199585
train loss item: 0.19969846308231354
train loss item: 0.15493755042552948
train loss item: 0.20293501019477844
train loss item: 0.07407943159341812
train loss item: 0.4112387001514435
train loss item: 1.4342401027679443
train loss item: 0.3921287953853607
train loss item: 0.10434434562921524
train loss item: 0.2508352994918823
train loss item: 0.16025130450725555
train loss item: 1.702993392944336
train loss item: 0.448997437953949
train loss item: 0.34260207414627075
train loss item: 0.49870890378952026
train loss item: 0.2139338254928589
train loss item: 0.19328752160072327
train loss item: 0.177623450756073
train loss item: 0.2676558792591095
train loss item: 0.17365793883800507
train loss item: 0.4857686161994934
train loss item: 0.12671495974063873
train loss item: 0.09315690398216248
train loss item: 0.32812294363975525
train loss item: 0.17049795389175415
train loss item: 0.12038741260766983
train loss item: 0.255161851644516
train loss item: 0.7218571901321411
train loss item: 0.07501495629549026
train loss item: 0.13650180399417877
train loss item: 1.7010846138000488
train loss item: 0.13872185349464417
train loss item: 0.21724967658519745
train loss item: 0.16614073514938354
train loss item: 0.11914478242397308
train loss item: 0.12481243908405304
train loss item: 0.4534313678741455
train loss item: 1.4495065212249756
train loss item: 0.16432514786720276
train loss item: 0.3039627969264984
train loss item: 0.13752558827400208
train loss item: 0.45714709162712097
train loss item: 0.37004485726356506
train loss item: 0.19577527046203613
train loss item: 0.2399950921535492
train loss item: 0.2392459511756897
train loss item: 0.22770865261554718
train loss item: 0.13366557657718658
train loss item: 0.13317476212978363
train loss item: 0.2134573608636856
train loss item: 0.09006661176681519
train loss item: 0.10644204914569855
train loss item: 0.5051339864730835
train loss item: 1.0949790477752686
train loss item: 0.07362128049135208
train loss item: 0.18072354793548584
train loss item: 0.11900542676448822
train loss item: 0.13871333003044128
train loss item: 0.18242621421813965
train loss item: 0.34184423089027405
train loss item: 0.31136271357536316
train loss item: 0.2932506203651428
train loss item: 3.2745420932769775
train loss item: 0.11492627114057541
train loss item: 0.2705959975719452
test loss item: 0.13768187165260315
test loss item: 0.1059664711356163
test loss item: 0.31977277994155884
test loss item: 0.1687592715024948
test loss item: 0.1725543588399887
test loss item: 0.10796795785427094
test loss item: 0.9562724828720093
test loss item: 0.3778120279312134
test loss item: 0.14335952699184418
test loss item: 0.2224271446466446
test loss item: 0.5199857354164124
test loss item: 0.12026584893465042
test loss item: 0.13627663254737854
test loss item: 0.18220320343971252
test loss item: 0.13214784860610962
test loss item: 0.08959469944238663
test loss item: 0.17356204986572266
test loss item: 0.23714660108089447
test loss item: 0.46339094638824463
test loss item: 0.16378749907016754
test loss item: 0.36057114601135254
test loss item: 0.25362586975097656
test loss item: 0.17910833656787872
test loss item: 0.12696781754493713
test loss item: 0.12797391414642334
test loss item: 0.17536401748657227
test loss item: 0.19205935299396515
test loss item: 0.1396714299917221
test loss item: 0.2049058973789215
test loss item: 0.20779721438884735
test loss item: 0.4235039949417114
test loss item: 0.07797933369874954
test loss item: 0.11733958125114441
test loss item: 0.3171128034591675
test loss item: 0.22205139696598053
test loss item: 0.30162060260772705
test loss item: 0.5310007929801941
test loss item: 0.8034690022468567
test loss item: 0.24970003962516785
test loss item: 0.17983902990818024
test loss item: 0.20100010931491852
test loss item: 0.151836559176445
test loss item: 0.1871679127216339
test loss item: 0.1350000500679016
test loss item: 0.2863185703754425
test loss item: 0.2409902960062027
test loss item: 0.18057507276535034
test loss item: 0.1689620167016983
test loss item: 0.27554890513420105
test loss item: 0.4104178845882416
test loss item: 0.17607620358467102
test loss item: 0.11413232982158661
test loss item: 0.14997464418411255
test loss item: 0.1134142130613327
test loss item: 0.1721152514219284
test loss item: 0.46589237451553345
test loss item: 0.37748727202415466
test loss item: 0.15686176717281342
test loss item: 0.16111646592617035
test loss item: 0.14196616411209106
test loss item: 0.24335387349128723
test loss item: 0.1659802943468094
test loss item: 0.14308996498584747
test loss item: 0.16723257303237915
test loss item: 0.5097565054893494
test loss item: 0.22614407539367676
test loss item: 0.205703005194664
test loss item: 0.17838770151138306
test loss item: 0.3284565508365631
test loss item: 0.3089136779308319
test loss item: 0.09263037145137787
test loss item: 0.5735708475112915
test loss item: 0.16399429738521576
test loss item: 0.23387542366981506
test loss item: 0.11196247488260269
test loss item: 0.13189364969730377
test loss item: 0.1301286220550537
test loss item: 0.8231484293937683
test loss item: 0.24050746858119965
test loss item: 0.13361811637878418
test loss item: 0.08650367707014084
test loss item: 0.585909903049469
test loss item: 0.5388631224632263
test loss item: 0.569173276424408
test loss item: 0.14117766916751862
test loss item: 0.14822301268577576
test loss item: 0.08463791012763977
test loss item: 0.07698342204093933
test loss item: 0.1599806547164917
Epoch [5/100], Training Loss: 0.3537, Testing Loss: 0.2460
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/100
train loss item: 0.29320305585861206
train loss item: 0.5805436968803406
train loss item: 0.14905251562595367
train loss item: 0.2696644961833954
train loss item: 0.3526644706726074
train loss item: 0.20412614941596985
train loss item: 0.17097285389900208
train loss item: 0.3893434703350067
train loss item: 0.11060600727796555
train loss item: 0.183033749461174
train loss item: 0.19801367819309235
train loss item: 0.1877201348543167
train loss item: 0.11137298494577408
train loss item: 0.3192380368709564
train loss item: 0.1562434881925583
train loss item: 0.4516353905200958
train loss item: 0.07345494627952576
train loss item: 0.1695288121700287
train loss item: 0.21061256527900696
train loss item: 0.20932209491729736
train loss item: 0.17414578795433044
train loss item: 0.11421645432710648
train loss item: 0.5337414741516113
train loss item: 0.5032087564468384
train loss item: 0.31887197494506836
train loss item: 0.2126837521791458
train loss item: 0.1517699807882309
train loss item: 0.17568644881248474
train loss item: 0.062321364879608154
train loss item: 0.3854527175426483
train loss item: 1.3103365898132324
train loss item: 0.36351656913757324
train loss item: 0.0981878712773323
train loss item: 0.2768467664718628
train loss item: 0.13831759989261627
train loss item: 1.6364707946777344
train loss item: 0.40737658739089966
train loss item: 0.33419039845466614
train loss item: 0.3907160460948944
train loss item: 0.18263813853263855
train loss item: 0.1967734843492508
train loss item: 0.17326509952545166
train loss item: 0.2670568525791168
train loss item: 0.1632065623998642
train loss item: 0.46508556604385376
train loss item: 0.11305629462003708
train loss item: 0.08695494383573532
train loss item: 0.31322571635246277
train loss item: 0.15751515328884125
train loss item: 0.1157083809375763
train loss item: 0.2415366768836975
train loss item: 0.6862843632698059
train loss item: 0.0901777520775795
train loss item: 0.12894639372825623
train loss item: 1.6379867792129517
train loss item: 0.1284150779247284
train loss item: 0.2076406031847
train loss item: 0.16328901052474976
train loss item: 0.1148693636059761
train loss item: 0.11874019354581833
train loss item: 0.41115501523017883
train loss item: 1.3698383569717407
train loss item: 0.17907081544399261
train loss item: 0.2948562204837799
train loss item: 0.1353941559791565
train loss item: 0.3976072669029236
train loss item: 0.33196479082107544
train loss item: 0.1802922636270523
train loss item: 0.22621162235736847
train loss item: 0.2157512605190277
train loss item: 0.18949832022190094
train loss item: 0.12313772737979889
train loss item: 0.11549437046051025
train loss item: 0.19016426801681519
train loss item: 0.08416938781738281
train loss item: 0.09861043840646744
train loss item: 0.432945191860199
train loss item: 1.058131217956543
train loss item: 0.07063532620668411
train loss item: 0.1679442822933197
train loss item: 0.10572709143161774
train loss item: 0.13583625853061676
train loss item: 0.1750384271144867
train loss item: 0.32985660433769226
train loss item: 0.30972784757614136
train loss item: 0.24969516694545746
train loss item: 3.162214517593384
train loss item: 0.11106190085411072
train loss item: 0.2436966598033905
test loss item: 0.13393378257751465
test loss item: 0.10357894748449326
test loss item: 0.2958117127418518
test loss item: 0.16854976117610931
test loss item: 0.1688220053911209
test loss item: 0.1133871003985405
test loss item: 0.9990813136100769
test loss item: 0.39635494351387024
test loss item: 0.13704971969127655
test loss item: 0.20606768131256104
test loss item: 0.47104525566101074
test loss item: 0.1191643476486206
test loss item: 0.13038741052150726
test loss item: 0.17485173046588898
test loss item: 0.12715749442577362
test loss item: 0.0812983587384224
test loss item: 0.17023028433322906
test loss item: 0.21570591628551483
test loss item: 0.4580610990524292
test loss item: 0.15953487157821655
test loss item: 0.32708415389060974
test loss item: 0.25699982047080994
test loss item: 0.17102180421352386
test loss item: 0.12885412573814392
test loss item: 0.11782849580049515
test loss item: 0.16604000329971313
test loss item: 0.18112468719482422
test loss item: 0.1402529925107956
test loss item: 0.1970791220664978
test loss item: 0.19204473495483398
test loss item: 0.4119473397731781
test loss item: 0.07461952418088913
test loss item: 0.11945777386426926
test loss item: 0.28864821791648865
test loss item: 0.2030782401561737
test loss item: 0.28864234685897827
test loss item: 0.5294782519340515
test loss item: 0.7002312541007996
test loss item: 0.2344382256269455
test loss item: 0.18493503332138062
test loss item: 0.2028270661830902
test loss item: 0.14217793941497803
test loss item: 0.16722866892814636
test loss item: 0.13906803727149963
test loss item: 0.2565750181674957
test loss item: 0.23521862924098969
test loss item: 0.16720357537269592
test loss item: 0.15829229354858398
test loss item: 0.2653719186782837
test loss item: 0.37332406640052795
test loss item: 0.16804450750350952
test loss item: 0.10924287140369415
test loss item: 0.14410527050495148
test loss item: 0.11569545418024063
test loss item: 0.15690861642360687
test loss item: 0.4290822744369507
test loss item: 0.3617810606956482
test loss item: 0.1514548510313034
test loss item: 0.15716642141342163
test loss item: 0.13262292742729187
test loss item: 0.21600255370140076
test loss item: 0.1671982705593109
test loss item: 0.13945800065994263
test loss item: 0.15862970054149628
test loss item: 0.502632200717926
test loss item: 0.22253470122814178
test loss item: 0.1988542228937149
test loss item: 0.17304226756095886
test loss item: 0.29881998896598816
test loss item: 0.3042055070400238
test loss item: 0.08175045251846313
test loss item: 0.5960285663604736
test loss item: 0.15617534518241882
test loss item: 0.23675446212291718
test loss item: 0.10468503832817078
test loss item: 0.12289951741695404
test loss item: 0.13091862201690674
test loss item: 0.7389742732048035
test loss item: 0.22676850855350494
test loss item: 0.13411317765712738
test loss item: 0.07874544709920883
test loss item: 0.5552128553390503
test loss item: 0.5290501713752747
test loss item: 0.5114342570304871
test loss item: 0.13149520754814148
test loss item: 0.13825589418411255
test loss item: 0.07461167871952057
test loss item: 0.07025996595621109
test loss item: 0.1460951566696167
Epoch [6/100], Training Loss: 0.3284, Testing Loss: 0.2351
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/100
train loss item: 0.2690553069114685
train loss item: 0.49744337797164917
train loss item: 0.13738177716732025
train loss item: 0.2517392039299011
train loss item: 0.4249652922153473
train loss item: 0.18617942929267883
train loss item: 0.16257934272289276
train loss item: 0.3538842797279358
train loss item: 0.14375701546669006
train loss item: 0.17670544981956482
train loss item: 0.19733184576034546
train loss item: 0.17067871987819672
train loss item: 0.11193565279245377
train loss item: 0.320523738861084
train loss item: 0.15368053317070007
train loss item: 0.41376933455467224
train loss item: 0.06317641586065292
train loss item: 0.1736326664686203
train loss item: 0.21353700757026672
train loss item: 0.1905270367860794
train loss item: 0.13855664432048798
train loss item: 0.1220477893948555
train loss item: 0.4792018234729767
train loss item: 0.49927785992622375
train loss item: 0.29672831296920776
train loss item: 0.18822531402111053
train loss item: 0.12336472421884537
train loss item: 0.1793680191040039
train loss item: 0.08580301702022552
train loss item: 0.3248717486858368
train loss item: 1.2291922569274902
train loss item: 0.33194682002067566
train loss item: 0.097310870885849
train loss item: 0.19097164273262024
train loss item: 0.13795098662376404
train loss item: 1.5682363510131836
train loss item: 0.40128469467163086
train loss item: 0.2984718978404999
train loss item: 0.3751593232154846
train loss item: 0.1798751801252365
train loss item: 0.14379937946796417
train loss item: 0.15079541504383087
train loss item: 0.25121989846229553
train loss item: 0.1555170863866806
train loss item: 0.4381895065307617
train loss item: 0.10837026685476303
train loss item: 0.08130300045013428
train loss item: 0.3129991590976715
train loss item: 0.15698666870594025
train loss item: 0.10446800291538239
train loss item: 0.23250925540924072
train loss item: 0.6412122249603271
train loss item: 0.07863409072160721
train loss item: 0.11463811993598938
train loss item: 1.5247571468353271
train loss item: 0.12457915395498276
train loss item: 0.18448799848556519
train loss item: 0.14954979717731476
train loss item: 0.10339120030403137
train loss item: 0.11032659560441971
train loss item: 0.3600628077983856
train loss item: 1.2641246318817139
train loss item: 0.15158332884311676
train loss item: 0.2950957715511322
train loss item: 0.12259450554847717
train loss item: 0.37809208035469055
train loss item: 0.33744993805885315
train loss item: 0.1742953062057495
train loss item: 0.22065968811511993
train loss item: 0.2067362368106842
train loss item: 0.18696272373199463
train loss item: 0.1116843894124031
train loss item: 0.11276288330554962
train loss item: 0.18292659521102905
train loss item: 0.07894188165664673
train loss item: 0.0948614776134491
train loss item: 0.3748113214969635
train loss item: 1.0598634481430054
train loss item: 0.06856154650449753
train loss item: 0.1671118289232254
train loss item: 0.10189405083656311
train loss item: 0.12024785578250885
train loss item: 0.15847009420394897
train loss item: 0.3238813579082489
train loss item: 0.28711453080177307
train loss item: 0.23167690634727478
train loss item: 3.051436185836792
train loss item: 0.10099801421165466
train loss item: 0.2268325835466385
test loss item: 0.1240791380405426
test loss item: 0.09598342329263687
test loss item: 0.3296798765659332
test loss item: 0.15440692007541656
test loss item: 0.15695174038410187
test loss item: 0.0931185707449913
test loss item: 0.9716061353683472
test loss item: 0.37875816226005554
test loss item: 0.1354641169309616
test loss item: 0.20517221093177795
test loss item: 0.5277541279792786
test loss item: 0.10979904979467392
test loss item: 0.1292227804660797
test loss item: 0.15989349782466888
test loss item: 0.12087912857532501
test loss item: 0.07911522686481476
test loss item: 0.1619492918252945
test loss item: 0.21053652465343475
test loss item: 0.4381956458091736
test loss item: 0.1525784581899643
test loss item: 0.3099415600299835
test loss item: 0.24550046026706696
test loss item: 0.15422160923480988
test loss item: 0.11701967567205429
test loss item: 0.11377236992120743
test loss item: 0.15866532921791077
test loss item: 0.1708991527557373
test loss item: 0.12285982817411423
test loss item: 0.18496085703372955
test loss item: 0.18587857484817505
test loss item: 0.45008084177970886
test loss item: 0.06995292007923126
test loss item: 0.10863617807626724
test loss item: 0.29045212268829346
test loss item: 0.20906654000282288
test loss item: 0.27688485383987427
test loss item: 0.5065251588821411
test loss item: 0.8468614816665649
test loss item: 0.22955481708049774
test loss item: 0.16804856061935425
test loss item: 0.19102701544761658
test loss item: 0.1340673416852951
test loss item: 0.15875059366226196
test loss item: 0.13062721490859985
test loss item: 0.23830854892730713
test loss item: 0.228145033121109
test loss item: 0.15104658901691437
test loss item: 0.1508326381444931
test loss item: 0.2701716423034668
test loss item: 0.39219194650650024
test loss item: 0.15956753492355347
test loss item: 0.10371711105108261
test loss item: 0.13894405961036682
test loss item: 0.10433509945869446
test loss item: 0.152035653591156
test loss item: 0.48530706763267517
test loss item: 0.3605579733848572
test loss item: 0.1352187693119049
test loss item: 0.14961308240890503
test loss item: 0.1307988315820694
test loss item: 0.20720332860946655
test loss item: 0.16371262073516846
test loss item: 0.1335718035697937
test loss item: 0.15119688212871552
test loss item: 0.5494830012321472
test loss item: 0.20674240589141846
test loss item: 0.18994416296482086
test loss item: 0.16364529728889465
test loss item: 0.3120814263820648
test loss item: 0.2889366149902344
test loss item: 0.08081785589456558
test loss item: 0.5699342489242554
test loss item: 0.14091269671916962
test loss item: 0.22418774664402008
test loss item: 0.10134685784578323
test loss item: 0.10969043523073196
test loss item: 0.11909951269626617
test loss item: 0.9325453639030457
test loss item: 0.22462445497512817
test loss item: 0.11650845408439636
test loss item: 0.07579264044761658
test loss item: 0.589994490146637
test loss item: 0.5174623727798462
test loss item: 0.624301016330719
test loss item: 0.12471108138561249
test loss item: 0.13341917097568512
test loss item: 0.07084465026855469
test loss item: 0.06542738527059555
test loss item: 0.1530046910047531
Epoch [7/100], Training Loss: 0.3099, Testing Loss: 0.2355
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/100
train loss item: 0.2528838515281677
train loss item: 0.427629292011261
train loss item: 0.12645593285560608
train loss item: 0.2237349897623062
train loss item: 0.20248228311538696
train loss item: 0.1702497899532318
train loss item: 0.15236905217170715
train loss item: 0.323435515165329
train loss item: 0.08630666136741638
train loss item: 0.13210713863372803
train loss item: 0.15939323604106903
train loss item: 0.15978282690048218
train loss item: 0.10087749361991882
train loss item: 0.28691884875297546
train loss item: 0.1444740742444992
train loss item: 0.3982611298561096
train loss item: 0.05664179101586342
train loss item: 0.14752742648124695
train loss item: 0.17748518288135529
train loss item: 0.17338378727436066
train loss item: 0.13567906618118286
train loss item: 0.10308843851089478
train loss item: 0.43387317657470703
train loss item: 0.40207719802856445
train loss item: 0.2729128301143646
train loss item: 0.1728721261024475
train loss item: 0.11465610563755035
train loss item: 0.15900446474552155
train loss item: 0.06491198390722275
train loss item: 0.30267369747161865
train loss item: 1.0976018905639648
train loss item: 0.3256727457046509
train loss item: 0.08617018908262253
train loss item: 0.17329692840576172
train loss item: 0.11731186509132385
train loss item: 1.5082688331604004
train loss item: 0.34731221199035645
train loss item: 0.28172770142555237
train loss item: 0.2630724310874939
train loss item: 0.16403090953826904
train loss item: 0.14118212461471558
train loss item: 0.14349167048931122
train loss item: 0.23966936767101288
train loss item: 0.14428740739822388
train loss item: 0.4161389172077179
train loss item: 0.09893588721752167
train loss item: 0.07732409983873367
train loss item: 0.27518850564956665
train loss item: 0.1405133455991745
train loss item: 0.09741561114788055
train loss item: 0.196659117937088
train loss item: 0.5679452419281006
train loss item: 0.07137337327003479
train loss item: 0.10261611640453339
train loss item: 1.4224164485931396
train loss item: 0.11362934112548828
train loss item: 0.16704009473323822
train loss item: 0.14542832970619202
train loss item: 0.0990021675825119
train loss item: 0.10960327833890915
train loss item: 0.30949684977531433
train loss item: 1.1684331893920898
train loss item: 0.14756785333156586
train loss item: 0.2709764838218689
train loss item: 0.10073646903038025
train loss item: 0.3099285066127777
train loss item: 0.28105005621910095
train loss item: 0.15291036665439606
train loss item: 0.23596982657909393
train loss item: 0.1867050975561142
train loss item: 0.15436257421970367
train loss item: 0.10321608930826187
train loss item: 0.10721120238304138
train loss item: 0.1671491116285324
train loss item: 0.07340051233768463
train loss item: 0.08864691108465195
train loss item: 0.3378825783729553
train loss item: 1.0037657022476196
train loss item: 0.06352069228887558
train loss item: 0.15329252183437347
train loss item: 0.09475479274988174
train loss item: 0.11597327888011932
train loss item: 0.14219924807548523
train loss item: 0.32690712809562683
train loss item: 0.3063502013683319
train loss item: 0.21125416457653046
train loss item: 2.968294382095337
train loss item: 0.09563782811164856
train loss item: 0.21589359641075134
test loss item: 0.12377011030912399
test loss item: 0.09392551332712173
test loss item: 0.3073958158493042
test loss item: 0.15461768209934235
test loss item: 0.15371038019657135
test loss item: 0.09528287500143051
test loss item: 1.122927188873291
test loss item: 0.45025989413261414
test loss item: 0.1317608803510666
test loss item: 0.20129232108592987
test loss item: 0.5079737901687622
test loss item: 0.10797584801912308
test loss item: 0.13423164188861847
test loss item: 0.17538900673389435
test loss item: 0.11646212637424469
test loss item: 0.081511490046978
test loss item: 0.18026195466518402
test loss item: 0.20049840211868286
test loss item: 0.47689536213874817
test loss item: 0.17939233779907227
test loss item: 0.2899298071861267
test loss item: 0.26904165744781494
test loss item: 0.16154201328754425
test loss item: 0.12209343910217285
test loss item: 0.112668976187706
test loss item: 0.15499094128608704
test loss item: 0.18019868433475494
test loss item: 0.12267591804265976
test loss item: 0.1854882538318634
test loss item: 0.18535886704921722
test loss item: 0.4805345833301544
test loss item: 0.07008466869592667
test loss item: 0.1108919084072113
test loss item: 0.2729020416736603
test loss item: 0.19522209465503693
test loss item: 0.2839915454387665
test loss item: 0.5511936545372009
test loss item: 0.7989203929901123
test loss item: 0.22439782321453094
test loss item: 0.17739441990852356
test loss item: 0.20299023389816284
test loss item: 0.1449023336172104
test loss item: 0.15464884042739868
test loss item: 0.14160771667957306
test loss item: 0.22527235746383667
test loss item: 0.2625231146812439
test loss item: 0.16464851796627045
test loss item: 0.1791514903306961
test loss item: 0.27174463868141174
test loss item: 0.395827054977417
test loss item: 0.151327446103096
test loss item: 0.11023924499750137
test loss item: 0.14175568521022797
test loss item: 0.10700935870409012
test loss item: 0.14263315498828888
test loss item: 0.448329359292984
test loss item: 0.3782813251018524
test loss item: 0.1491878181695938
test loss item: 0.15602174401283264
test loss item: 0.1258062720298767
test loss item: 0.19416671991348267
test loss item: 0.1889554262161255
test loss item: 0.1425967961549759
test loss item: 0.14826279878616333
test loss item: 0.548929750919342
test loss item: 0.20515012741088867
test loss item: 0.20123693346977234
test loss item: 0.16850784420967102
test loss item: 0.2965027391910553
test loss item: 0.3226521909236908
test loss item: 0.08138863742351532
test loss item: 0.6634848117828369
test loss item: 0.1616768091917038
test loss item: 0.24932676553726196
test loss item: 0.11300212144851685
test loss item: 0.12182901799678802
test loss item: 0.123351089656353
test loss item: 0.9022581577301025
test loss item: 0.2335069626569748
test loss item: 0.12146558612585068
test loss item: 0.07504896819591522
test loss item: 0.6226820945739746
test loss item: 0.5609545111656189
test loss item: 0.6104802489280701
test loss item: 0.12414433807134628
test loss item: 0.1436799317598343
test loss item: 0.0712922215461731
test loss item: 0.06640568375587463
test loss item: 0.14032141864299774
Epoch [8/100], Training Loss: 0.2819, Testing Loss: 0.2427
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/100
train loss item: 0.2374982386827469
train loss item: 0.40055015683174133
train loss item: 0.1167987808585167
train loss item: 0.20894436538219452
train loss item: 0.20831595361232758
train loss item: 0.15450617671012878
train loss item: 0.13914388418197632
train loss item: 0.29502251744270325
train loss item: 0.07055243104696274
train loss item: 0.1269502192735672
train loss item: 0.1549794226884842
train loss item: 0.1482437402009964
train loss item: 0.09766502678394318
train loss item: 0.28848928213119507
train loss item: 0.13821254670619965
train loss item: 0.33291715383529663
train loss item: 0.05164565145969391
train loss item: 0.14712253212928772
train loss item: 0.16956134140491486
train loss item: 0.15950541198253632
train loss item: 0.13811035454273224
train loss item: 0.10271681100130081
train loss item: 0.3731910288333893
train loss item: 0.33081719279289246
train loss item: 0.2717144191265106
train loss item: 0.16518329083919525
train loss item: 0.10985120385885239
train loss item: 0.15054567158222198
train loss item: 0.05647026374936104
train loss item: 0.278583824634552
train loss item: 0.9928182363510132
train loss item: 0.3021385967731476
train loss item: 0.08487557619810104
train loss item: 0.18241804838180542
train loss item: 0.10720616579055786
train loss item: 1.4582912921905518
train loss item: 0.3089795410633087
train loss item: 0.25437527894973755
train loss item: 0.23665231466293335
train loss item: 0.1484738439321518
train loss item: 0.1301424652338028
train loss item: 0.13487185537815094
train loss item: 0.23341356217861176
train loss item: 0.12759675085544586
train loss item: 0.4039498269557953
train loss item: 0.09271305054426193
train loss item: 0.07573790103197098
train loss item: 0.24997766315937042
train loss item: 0.1282196342945099
train loss item: 0.09311742335557938
train loss item: 0.1627413034439087
train loss item: 0.49946674704551697
train loss item: 0.07010894268751144
train loss item: 0.09899761527776718
train loss item: 1.3499504327774048
train loss item: 0.10299330204725266
train loss item: 0.16261199116706848
train loss item: 0.14151550829410553
train loss item: 0.10643008351325989
train loss item: 0.10094919800758362
train loss item: 0.27501288056373596
train loss item: 1.0887137651443481
train loss item: 0.133083313703537
train loss item: 0.24906140565872192
train loss item: 0.09427778422832489
train loss item: 0.27248242497444153
train loss item: 0.2652284801006317
train loss item: 0.1499801129102707
train loss item: 0.24217376112937927
train loss item: 0.17603272199630737
train loss item: 0.14766594767570496
train loss item: 0.09693893045186996
train loss item: 0.10185074061155319
train loss item: 0.17322713136672974
train loss item: 0.06485071033239365
train loss item: 0.085330069065094
train loss item: 0.3007562756538391
train loss item: 0.9958276748657227
train loss item: 0.05872207507491112
train loss item: 0.14242765307426453
train loss item: 0.09104056656360626
train loss item: 0.10478385537862778
train loss item: 0.14052598178386688
train loss item: 0.33270928263664246
train loss item: 0.31591475009918213
train loss item: 0.2072223722934723
train loss item: 2.8470962047576904
train loss item: 0.09075410664081573
train loss item: 0.20944857597351074
test loss item: 0.11752871423959732
test loss item: 0.09182057529687881
test loss item: 0.29529035091400146
test loss item: 0.14318953454494476
test loss item: 0.15031376481056213
test loss item: 0.09799589961767197
test loss item: 1.0472569465637207
test loss item: 0.3987392783164978
test loss item: 0.12727373838424683
test loss item: 0.1934366524219513
test loss item: 0.5006910562515259
test loss item: 0.1041373685002327
test loss item: 0.13850176334381104
test loss item: 0.16605418920516968
test loss item: 0.11387866735458374
test loss item: 0.07570847868919373
test loss item: 0.1663714498281479
test loss item: 0.18857838213443756
test loss item: 0.43425002694129944
test loss item: 0.174860879778862
test loss item: 0.2728215456008911
test loss item: 0.24111559987068176
test loss item: 0.15811090171337128
test loss item: 0.11536365747451782
test loss item: 0.10739501565694809
test loss item: 0.14489220082759857
test loss item: 0.17107750475406647
test loss item: 0.12392605096101761
test loss item: 0.1785450577735901
test loss item: 0.17465659976005554
test loss item: 0.45631077885627747
test loss item: 0.06582332402467728
test loss item: 0.10643463581800461
test loss item: 0.2519518733024597
test loss item: 0.18493729829788208
test loss item: 0.26571354269981384
test loss item: 0.5050450563430786
test loss item: 0.7821879982948303
test loss item: 0.21318525075912476
test loss item: 0.16431808471679688
test loss item: 0.18485672771930695
test loss item: 0.14410348236560822
test loss item: 0.14815595746040344
test loss item: 0.12964467704296112
test loss item: 0.21620550751686096
test loss item: 0.24399058520793915
test loss item: 0.16311639547348022
test loss item: 0.17248189449310303
test loss item: 0.2586667537689209
test loss item: 0.3766801357269287
test loss item: 0.15007002651691437
test loss item: 0.10966090112924576
test loss item: 0.13336706161499023
test loss item: 0.09943293780088425
test loss item: 0.13590018451213837
test loss item: 0.4349435865879059
test loss item: 0.350372314453125
test loss item: 0.1545528769493103
test loss item: 0.1473197042942047
test loss item: 0.13028179109096527
test loss item: 0.17932754755020142
test loss item: 0.17200344800949097
test loss item: 0.13518501818180084
test loss item: 0.1476583480834961
test loss item: 0.5236534476280212
test loss item: 0.18911051750183105
test loss item: 0.18631568551063538
test loss item: 0.1575469821691513
test loss item: 0.27883872389793396
test loss item: 0.2929254472255707
test loss item: 0.07636252790689468
test loss item: 0.6049450039863586
test loss item: 0.16479258239269257
test loss item: 0.22637203335762024
test loss item: 0.11133286356925964
test loss item: 0.12095407396554947
test loss item: 0.11609098315238953
test loss item: 0.8848876953125
test loss item: 0.22911210358142853
test loss item: 0.12256568670272827
test loss item: 0.06844776123762131
test loss item: 0.5914137959480286
test loss item: 0.5214745402336121
test loss item: 0.605495810508728
test loss item: 0.12331819534301758
test loss item: 0.14070098102092743
test loss item: 0.06434572488069534
test loss item: 0.06002252921462059
test loss item: 0.13141047954559326
Epoch [9/100], Training Loss: 0.2654, Testing Loss: 0.2306
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/100
train loss item: 0.2224770486354828
train loss item: 0.33948302268981934
train loss item: 0.11266041547060013
train loss item: 0.20600837469100952
train loss item: 0.24760283529758453
train loss item: 0.148628830909729
train loss item: 0.13050943613052368
train loss item: 0.2748238444328308
train loss item: 0.08970768004655838
train loss item: 0.14229294657707214
train loss item: 0.16967962682247162
train loss item: 0.1406877040863037
train loss item: 0.09367577731609344
train loss item: 0.26688891649246216
train loss item: 0.14788508415222168
train loss item: 0.3633423149585724
train loss item: 0.054096173495054245
train loss item: 0.15215586125850677
train loss item: 0.18558858335018158
train loss item: 0.14733709394931793
train loss item: 0.12050636112689972
train loss item: 0.10671630501747131
train loss item: 0.4023003876209259
train loss item: 0.32062825560569763
train loss item: 0.2547696828842163
train loss item: 0.13957040011882782
train loss item: 0.10235916078090668
train loss item: 0.13882741332054138
train loss item: 0.05283390358090401
train loss item: 0.2613881230354309
train loss item: 0.8940519094467163
train loss item: 0.33742108941078186
train loss item: 0.07859686017036438
train loss item: 0.15325893461704254
train loss item: 0.10878139734268188
train loss item: 1.4156290292739868
train loss item: 0.27310019731521606
train loss item: 0.22267073392868042
train loss item: 0.19430802762508392
train loss item: 0.13923613727092743
train loss item: 0.11413094401359558
train loss item: 0.13665072619915009
train loss item: 0.22726953029632568
train loss item: 0.13315676152706146
train loss item: 0.3761923313140869
train loss item: 0.09159670770168304
train loss item: 0.07237442582845688
train loss item: 0.2465955764055252
train loss item: 0.12601684033870697
train loss item: 0.09542570263147354
train loss item: 0.16662156581878662
train loss item: 0.4658965468406677
train loss item: 0.06943871825933456
train loss item: 0.1085200384259224
train loss item: 1.2868480682373047
train loss item: 0.11286081373691559
train loss item: 0.14979678392410278
train loss item: 0.13292023539543152
train loss item: 0.08918994665145874
train loss item: 0.10227891802787781
train loss item: 0.24986106157302856
train loss item: 1.0204546451568604
train loss item: 0.11855567991733551
train loss item: 0.24014396965503693
train loss item: 0.09053007513284683
train loss item: 0.2444775402545929
train loss item: 0.23655569553375244
train loss item: 0.147705078125
train loss item: 0.22596906125545502
train loss item: 0.1679989993572235
train loss item: 0.14017267525196075
train loss item: 0.10119324177503586
train loss item: 0.09853264689445496
train loss item: 0.15963682532310486
train loss item: 0.0639081820845604
train loss item: 0.07993842661380768
train loss item: 0.26140156388282776
train loss item: 0.9708443880081177
train loss item: 0.059662509709596634
train loss item: 0.13848324120044708
train loss item: 0.0855073407292366
train loss item: 0.10294497013092041
train loss item: 0.13824476301670074
train loss item: 0.2877553105354309
train loss item: 0.2565600872039795
train loss item: 0.18964047729969025
train loss item: 2.7744739055633545
train loss item: 0.08931254595518112
train loss item: 0.18855759501457214
test loss item: 0.11829967796802521
test loss item: 0.08338980376720428
test loss item: 0.29378288984298706
test loss item: 0.14336305856704712
test loss item: 0.14508706331253052
test loss item: 0.0945182517170906
test loss item: 1.158809781074524
test loss item: 0.4142834544181824
test loss item: 0.12232186645269394
test loss item: 0.18815013766288757
test loss item: 0.4790390133857727
test loss item: 0.10422325879335403
test loss item: 0.1319609135389328
test loss item: 0.21331489086151123
test loss item: 0.10766774415969849
test loss item: 0.06507077068090439
test loss item: 0.1745334416627884
test loss item: 0.18229785561561584
test loss item: 0.44365108013153076
test loss item: 0.18600229918956757
test loss item: 0.2550666928291321
test loss item: 0.2547212541103363
test loss item: 0.1745637059211731
test loss item: 0.11900981515645981
test loss item: 0.10457000881433487
test loss item: 0.1502959430217743
test loss item: 0.1752479374408722
test loss item: 0.11905123293399811
test loss item: 0.17733284831047058
test loss item: 0.17403775453567505
test loss item: 0.47759926319122314
test loss item: 0.0581916980445385
test loss item: 0.10588912665843964
test loss item: 0.24195174872875214
test loss item: 0.17933224141597748
test loss item: 0.26883208751678467
test loss item: 0.5255251526832581
test loss item: 0.7685022950172424
test loss item: 0.2127605825662613
test loss item: 0.17337951064109802
test loss item: 0.19568705558776855
test loss item: 0.16011551022529602
test loss item: 0.1398768573999405
test loss item: 0.13690005242824554
test loss item: 0.21500509977340698
test loss item: 0.25618603825569153
test loss item: 0.17292505502700806
test loss item: 0.192815899848938
test loss item: 0.25271451473236084
test loss item: 0.3749125301837921
test loss item: 0.14378392696380615
test loss item: 0.10721465945243835
test loss item: 0.1358165591955185
test loss item: 0.10015669465065002
test loss item: 0.13273173570632935
test loss item: 0.4172884225845337
test loss item: 0.34987694025039673
test loss item: 0.16792477667331696
test loss item: 0.14878971874713898
test loss item: 0.12010055780410767
test loss item: 0.17388758063316345
test loss item: 0.17819362878799438
test loss item: 0.14374589920043945
test loss item: 0.14304018020629883
test loss item: 0.5193951725959778
test loss item: 0.18952620029449463
test loss item: 0.1962553858757019
test loss item: 0.15952980518341064
test loss item: 0.2703341543674469
test loss item: 0.29049742221832275
test loss item: 0.06770110875368118
test loss item: 0.6508193016052246
test loss item: 0.18757691979408264
test loss item: 0.24750028550624847
test loss item: 0.1099463477730751
test loss item: 0.13150368630886078
test loss item: 0.11963138729333878
test loss item: 0.869256317615509
test loss item: 0.2560209631919861
test loss item: 0.12410102039575577
test loss item: 0.062423430383205414
test loss item: 0.6114076375961304
test loss item: 0.5431535243988037
test loss item: 0.5935313701629639
test loss item: 0.1280086487531662
test loss item: 0.14130890369415283
test loss item: 0.0553220696747303
test loss item: 0.05115294083952904
test loss item: 0.14682699739933014
Epoch [10/100], Training Loss: 0.2538, Testing Loss: 0.2342
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 11/100
train loss item: 0.21223869919776917
train loss item: 0.3244521915912628
train loss item: 0.11482927203178406
train loss item: 0.17946307361125946
train loss item: 0.2527591586112976
train loss item: 0.14693492650985718
train loss item: 0.1267046183347702
train loss item: 0.27284348011016846
train loss item: 0.07475080341100693
train loss item: 0.14769141376018524
train loss item: 0.16473159193992615
train loss item: 0.13688373565673828
train loss item: 0.09205754101276398
train loss item: 0.26811137795448303
train loss item: 0.10702762752771378
train loss item: 0.28783008456230164
train loss item: 0.05958198755979538
train loss item: 0.12757155299186707
train loss item: 0.23502524197101593
train loss item: 0.14687560498714447
train loss item: 0.14425607025623322
train loss item: 0.0825117975473404
train loss item: 0.37044721841812134
train loss item: 0.29537153244018555
train loss item: 0.24645866453647614
train loss item: 0.13128989934921265
train loss item: 0.11279089003801346
train loss item: 0.14879584312438965
train loss item: 0.05228910595178604
train loss item: 0.3083121180534363
train loss item: 1.0306668281555176
train loss item: 0.27633073925971985
train loss item: 0.08160711824893951
train loss item: 0.1698530912399292
train loss item: 0.10492950677871704
train loss item: 1.3693110942840576
train loss item: 0.3349650502204895
train loss item: 0.28044864535331726
train loss item: 0.37729328870773315
train loss item: 0.15986427664756775
train loss item: 0.15762513875961304
train loss item: 0.14589598774909973
train loss item: 0.24656575918197632
train loss item: 0.15027397871017456
train loss item: 0.41482827067375183
train loss item: 0.09040084481239319
train loss item: 0.07982239872217178
train loss item: 0.2839852273464203
train loss item: 0.1442011147737503
train loss item: 0.09822510182857513
train loss item: 0.2028578668832779
train loss item: 0.6575304865837097
train loss item: 0.07636724412441254
train loss item: 0.0874837189912796
train loss item: 1.341731309890747
train loss item: 0.09924513101577759
train loss item: 0.15341925621032715
train loss item: 0.14538033306598663
train loss item: 0.09853915870189667
train loss item: 0.09506746381521225
train loss item: 0.3051479756832123
train loss item: 0.9843966960906982
train loss item: 0.143375426530838
train loss item: 0.24843080341815948
train loss item: 0.10069958120584488
train loss item: 0.3287099599838257
train loss item: 0.23643577098846436
train loss item: 0.12624184787273407
train loss item: 0.20303355157375336
train loss item: 0.15616631507873535
train loss item: 0.13151592016220093
train loss item: 0.08965231478214264
train loss item: 0.10011640936136246
train loss item: 0.16307874023914337
train loss item: 0.06568154692649841
train loss item: 0.08310294896364212
train loss item: 0.2711026072502136
train loss item: 0.9979864954948425
train loss item: 0.057013291865587234
train loss item: 0.1425853818655014
train loss item: 0.08841359615325928
train loss item: 0.10227120667695999
train loss item: 0.13613493740558624
train loss item: 0.30599576234817505
train loss item: 0.25457850098609924
train loss item: 0.1788700371980667
train loss item: 2.745734691619873
train loss item: 0.08500977605581284
train loss item: 0.17123118042945862
test loss item: 0.10855044424533844
test loss item: 0.0760752484202385
test loss item: 0.3076637089252472
test loss item: 0.13912299275398254
test loss item: 0.14452068507671356
test loss item: 0.08786674588918686
test loss item: 1.0761258602142334
test loss item: 0.34842154383659363
test loss item: 0.1281607747077942
test loss item: 0.19679193198680878
test loss item: 0.4915064871311188
test loss item: 0.09938139468431473
test loss item: 0.11971504986286163
test loss item: 0.14829418063163757
test loss item: 0.10333328694105148
test loss item: 0.05659165233373642
test loss item: 0.15375018119812012
test loss item: 0.19584748148918152
test loss item: 0.405619740486145
test loss item: 0.1380193829536438
test loss item: 0.29414841532707214
test loss item: 0.23365721106529236
test loss item: 0.1427411437034607
test loss item: 0.10734778642654419
test loss item: 0.09969690442085266
test loss item: 0.14215628802776337
test loss item: 0.15206563472747803
test loss item: 0.11594691127538681
test loss item: 0.16910988092422485
test loss item: 0.1691478043794632
test loss item: 0.4589157998561859
test loss item: 0.054491836577653885
test loss item: 0.09526047855615616
test loss item: 0.261737585067749
test loss item: 0.19203710556030273
test loss item: 0.24992701411247253
test loss item: 0.4914349317550659
test loss item: 0.7763419151306152
test loss item: 0.22298578917980194
test loss item: 0.1631840169429779
test loss item: 0.18935200572013855
test loss item: 0.11513759940862656
test loss item: 0.1619023233652115
test loss item: 0.1298253983259201
test loss item: 0.23033425211906433
test loss item: 0.2092607617378235
test loss item: 0.13522665202617645
test loss item: 0.12233942002058029
test loss item: 0.25540226697921753
test loss item: 0.3597210645675659
test loss item: 0.15658138692378998
test loss item: 0.08628059923648834
test loss item: 0.13581986725330353
test loss item: 0.09492498636245728
test loss item: 0.14287808537483215
test loss item: 0.4394254982471466
test loss item: 0.3244549334049225
test loss item: 0.12108355760574341
test loss item: 0.13503426313400269
test loss item: 0.12526606023311615
test loss item: 0.20019148290157318
test loss item: 0.14539475739002228
test loss item: 0.12117817997932434
test loss item: 0.13832658529281616
test loss item: 0.5058000683784485
test loss item: 0.1898854523897171
test loss item: 0.16801142692565918
test loss item: 0.15242615342140198
test loss item: 0.2718750536441803
test loss item: 0.25936609506607056
test loss item: 0.05868144705891609
test loss item: 0.5832683444023132
test loss item: 0.14001818001270294
test loss item: 0.2144431322813034
test loss item: 0.08648860454559326
test loss item: 0.08727673441171646
test loss item: 0.10804476588964462
test loss item: 0.8451748490333557
test loss item: 0.20773477852344513
test loss item: 0.1100638210773468
test loss item: 0.056521911174058914
test loss item: 0.5789527893066406
test loss item: 0.5180620551109314
test loss item: 0.5862385630607605
test loss item: 0.11100219190120697
test loss item: 0.11995712667703629
test loss item: 0.051307033747434616
test loss item: 0.050161994993686676
test loss item: 0.13783876597881317
Epoch [11/100], Training Loss: 0.2621, Testing Loss: 0.2201
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 12/100
train loss item: 0.22468329966068268
train loss item: 0.29172050952911377
train loss item: 0.109076127409935
train loss item: 0.1830865740776062
train loss item: 0.2579250633716583
train loss item: 0.150493785738945
train loss item: 0.13335570693016052
train loss item: 0.27096953988075256
train loss item: 0.1107698604464531
train loss item: 0.16772158443927765
train loss item: 0.16643904149532318
train loss item: 0.13377979397773743
train loss item: 0.09533828496932983
train loss item: 0.2541322708129883
train loss item: 0.12642523646354675
train loss item: 0.35706403851509094
train loss item: 0.048044875264167786
train loss item: 0.12656477093696594
train loss item: 0.16597288846969604
train loss item: 0.13151666522026062
train loss item: 0.11891823261976242
train loss item: 0.1013093814253807
train loss item: 0.3481013774871826
train loss item: 0.33873897790908813
train loss item: 0.2372656613588333
train loss item: 0.15288768708705902
train loss item: 0.10854941606521606
train loss item: 0.1369587928056717
train loss item: 0.06475364416837692
train loss item: 0.2683142125606537
train loss item: 0.7940463423728943
train loss item: 0.2479202151298523
train loss item: 0.07653217762708664
train loss item: 0.13065120577812195
train loss item: 0.09752275049686432
train loss item: 1.3259578943252563
train loss item: 0.2322586327791214
train loss item: 0.20911146700382233
train loss item: 0.1959962099790573
train loss item: 0.1305008977651596
train loss item: 0.10201618075370789
train loss item: 0.12888872623443604
train loss item: 0.20548033714294434
train loss item: 0.11784987896680832
train loss item: 0.35489940643310547
train loss item: 0.08422846347093582
train loss item: 0.07047102600336075
train loss item: 0.20489689707756042
train loss item: 0.11906884610652924
train loss item: 0.08523698151111603
train loss item: 0.1216849535703659
train loss item: 0.38455015420913696
train loss item: 0.06534310430288315
train loss item: 0.08871705830097198
train loss item: 1.1696377992630005
train loss item: 0.10284338146448135
train loss item: 0.13455216586589813
train loss item: 0.12416356056928635
train loss item: 0.0826694667339325
train loss item: 0.09327507764101028
train loss item: 0.26697587966918945
train loss item: 0.8933480978012085
train loss item: 0.10679660737514496
train loss item: 0.18742501735687256
train loss item: 0.08277464658021927
train loss item: 0.20160357654094696
train loss item: 0.2028944492340088
train loss item: 0.12305229157209396
train loss item: 0.20959295332431793
train loss item: 0.14659501612186432
train loss item: 0.12037345767021179
train loss item: 0.08881060034036636
train loss item: 0.08786062896251678
train loss item: 0.14387093484401703
train loss item: 0.059201665222644806
train loss item: 0.07371257990598679
train loss item: 0.24306657910346985
train loss item: 0.938014030456543
train loss item: 0.060621220618486404
train loss item: 0.11990903317928314
train loss item: 0.08107765018939972
train loss item: 0.10645408183336258
train loss item: 0.11889956146478653
train loss item: 0.2844012975692749
train loss item: 0.2567436099052429
train loss item: 0.16375575959682465
train loss item: 2.6493940353393555
train loss item: 0.08508091419935226
train loss item: 0.1617281287908554
test loss item: 0.09849172830581665
test loss item: 0.07250455021858215
test loss item: 0.35252615809440613
test loss item: 0.12906351685523987
test loss item: 0.14852778613567352
test loss item: 0.07995779067277908
test loss item: 1.0960747003555298
test loss item: 0.36675989627838135
test loss item: 0.13136157393455505
test loss item: 0.20515388250350952
test loss item: 0.547374427318573
test loss item: 0.09291038662195206
test loss item: 0.11507517844438553
test loss item: 0.13429148495197296
test loss item: 0.10521075874567032
test loss item: 0.054708294570446014
test loss item: 0.15735654532909393
test loss item: 0.21619147062301636
test loss item: 0.3978227376937866
test loss item: 0.14284296333789825
test loss item: 0.3253588378429413
test loss item: 0.23942746222019196
test loss item: 0.1398354172706604
test loss item: 0.10562163591384888
test loss item: 0.10570911318063736
test loss item: 0.13373036682605743
test loss item: 0.15522705018520355
test loss item: 0.11123964935541153
test loss item: 0.17341312766075134
test loss item: 0.16907833516597748
test loss item: 0.5161167979240417
test loss item: 0.05218450352549553
test loss item: 0.09230794757604599
test loss item: 0.28086555004119873
test loss item: 0.21763597428798676
test loss item: 0.24290119111537933
test loss item: 0.4807488024234772
test loss item: 0.9229027628898621
test loss item: 0.23811586201190948
test loss item: 0.16250239312648773
test loss item: 0.1846160888671875
test loss item: 0.10365794599056244
test loss item: 0.1652747541666031
test loss item: 0.1298544555902481
test loss item: 0.24834081530570984
test loss item: 0.22170966863632202
test loss item: 0.1302991807460785
test loss item: 0.11953523755073547
test loss item: 0.2776755094528198
test loss item: 0.3987005949020386
test loss item: 0.1542389988899231
test loss item: 0.08144448697566986
test loss item: 0.13871140778064728
test loss item: 0.09276604652404785
test loss item: 0.15158911049365997
test loss item: 0.5048313140869141
test loss item: 0.33679360151290894
test loss item: 0.12189251184463501
test loss item: 0.13615141808986664
test loss item: 0.12155364453792572
test loss item: 0.2039969116449356
test loss item: 0.16433005034923553
test loss item: 0.12317544221878052
test loss item: 0.13103584945201874
test loss item: 0.5723392367362976
test loss item: 0.17453184723854065
test loss item: 0.1764359474182129
test loss item: 0.1467808037996292
test loss item: 0.29990553855895996
test loss item: 0.2677747309207916
test loss item: 0.051784854382276535
test loss item: 0.6024872064590454
test loss item: 0.1353614628314972
test loss item: 0.2285713404417038
test loss item: 0.08514030277729034
test loss item: 0.07674847543239594
test loss item: 0.10581637173891068
test loss item: 1.0384039878845215
test loss item: 0.22016678750514984
test loss item: 0.10636214166879654
test loss item: 0.05313000828027725
test loss item: 0.6435731649398804
test loss item: 0.5237695574760437
test loss item: 0.7046911120414734
test loss item: 0.11343711614608765
test loss item: 0.1227969080209732
test loss item: 0.05125783383846283
test loss item: 0.04963332787156105
test loss item: 0.13233307003974915
Epoch [12/100], Training Loss: 0.2351, Testing Loss: 0.2318
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 13/100
train loss item: 0.2126547396183014
train loss item: 0.296790212392807
train loss item: 0.09692897647619247
train loss item: 0.17008854448795319
train loss item: 0.20293083786964417
train loss item: 0.1373317688703537
train loss item: 0.09610360860824585
train loss item: 0.20656068623065948
train loss item: 0.06425091624259949
train loss item: 0.1170898899435997
train loss item: 0.12934714555740356
train loss item: 0.12622173130512238
train loss item: 0.08436930179595947
train loss item: 0.2335635870695114
train loss item: 0.10037755966186523
train loss item: 0.2598382830619812
train loss item: 0.049846623092889786
train loss item: 0.10880313813686371
train loss item: 0.14678460359573364
train loss item: 0.12017418444156647
train loss item: 0.1355786919593811
train loss item: 0.07663208991289139
train loss item: 0.29040926694869995
train loss item: 0.23851265013217926
train loss item: 0.21639224886894226
train loss item: 0.12747734785079956
train loss item: 0.10577964782714844
train loss item: 0.1326858252286911
train loss item: 0.041899994015693665
train loss item: 0.28502002358436584
train loss item: 0.7352991700172424
train loss item: 0.22399328649044037
train loss item: 0.07233221083879471
train loss item: 0.13455957174301147
train loss item: 0.08990475535392761
train loss item: 1.2757781744003296
train loss item: 0.29194095730781555
train loss item: 0.24966534972190857
train loss item: 0.2642163634300232
train loss item: 0.13342280685901642
train loss item: 0.1400618851184845
train loss item: 0.12726426124572754
train loss item: 0.22047671675682068
train loss item: 0.12855041027069092
train loss item: 0.37427467107772827
train loss item: 0.08074799180030823
train loss item: 0.07173469662666321
train loss item: 0.27045655250549316
train loss item: 0.1251111626625061
train loss item: 0.09044300764799118
train loss item: 0.17951899766921997
train loss item: 0.5965969562530518
train loss item: 0.07151838392019272
train loss item: 0.08060596138238907
train loss item: 1.253484845161438
train loss item: 0.09146534651517868
train loss item: 0.1379511058330536
train loss item: 0.12364228814840317
train loss item: 0.09602560847997665
train loss item: 0.08987844735383987
train loss item: 0.30691683292388916
train loss item: 0.8860422968864441
train loss item: 0.12250900268554688
train loss item: 0.24067172408103943
train loss item: 0.0967230498790741
train loss item: 0.3210037052631378
train loss item: 0.2571762204170227
train loss item: 0.12605680525302887
train loss item: 0.17764510214328766
train loss item: 0.14477969706058502
train loss item: 0.12187501043081284
train loss item: 0.0866430401802063
train loss item: 0.10544084012508392
train loss item: 0.1728353202342987
train loss item: 0.05728136748075485
train loss item: 0.08031482994556427
train loss item: 0.23855555057525635
train loss item: 1.0140351057052612
train loss item: 0.04852762073278427
train loss item: 0.1653859168291092
train loss item: 0.07979445904493332
train loss item: 0.1095958948135376
train loss item: 0.11833590269088745
train loss item: 0.26497000455856323
train loss item: 0.2107275277376175
train loss item: 0.22008515894412994
train loss item: 2.587785482406616
train loss item: 0.08386074006557465
train loss item: 0.17281880974769592
test loss item: 0.1027061715722084
test loss item: 0.07496171444654465
test loss item: 0.2768186032772064
test loss item: 0.12841999530792236
test loss item: 0.1339874416589737
test loss item: 0.08442186564207077
test loss item: 0.8842857480049133
test loss item: 0.292523592710495
test loss item: 0.11989615112543106
test loss item: 0.1788843721151352
test loss item: 0.4784987270832062
test loss item: 0.10252595692873001
test loss item: 0.12343770265579224
test loss item: 0.1301257461309433
test loss item: 0.10130275040864944
test loss item: 0.05627540871500969
test loss item: 0.1450510174036026
test loss item: 0.1657947152853012
test loss item: 0.35889771580696106
test loss item: 0.13923074305057526
test loss item: 0.23977433145046234
test loss item: 0.2069079428911209
test loss item: 0.11591174453496933
test loss item: 0.09803857654333115
test loss item: 0.09489849209785461
test loss item: 0.1285879760980606
test loss item: 0.1420622318983078
test loss item: 0.110913947224617
test loss item: 0.1600705236196518
test loss item: 0.15377695858478546
test loss item: 0.4160901606082916
test loss item: 0.05198730155825615
test loss item: 0.0888509601354599
test loss item: 0.22391870617866516
test loss item: 0.167329803109169
test loss item: 0.22412653267383575
test loss item: 0.42400220036506653
test loss item: 0.7605762481689453
test loss item: 0.19508096575737
test loss item: 0.1470833569765091
test loss item: 0.16620881855487823
test loss item: 0.1032353937625885
test loss item: 0.1404769867658615
test loss item: 0.1172129213809967
test loss item: 0.19394657015800476
test loss item: 0.20289172232151031
test loss item: 0.11469319462776184
test loss item: 0.11726212501525879
test loss item: 0.22828829288482666
test loss item: 0.33230772614479065
test loss item: 0.1436127871274948
test loss item: 0.08236797899007797
test loss item: 0.12276476621627808
test loss item: 0.09082283824682236
test loss item: 0.12422355264425278
test loss item: 0.40278998017311096
test loss item: 0.29690220952033997
test loss item: 0.11198782920837402
test loss item: 0.12396706640720367
test loss item: 0.12598541378974915
test loss item: 0.1675192266702652
test loss item: 0.13632267713546753
test loss item: 0.11172447353601456
test loss item: 0.14409300684928894
test loss item: 0.4655377268791199
test loss item: 0.17657504975795746
test loss item: 0.15494322776794434
test loss item: 0.14353299140930176
test loss item: 0.24898888170719147
test loss item: 0.2335725873708725
test loss item: 0.0625641718506813
test loss item: 0.4918627440929413
test loss item: 0.11600209027528763
test loss item: 0.18992066383361816
test loss item: 0.08559077233076096
test loss item: 0.07455462217330933
test loss item: 0.09902578592300415
test loss item: 0.857123076915741
test loss item: 0.18827427923679352
test loss item: 0.10524052381515503
test loss item: 0.05713256075978279
test loss item: 0.5348691344261169
test loss item: 0.4472251534461975
test loss item: 0.5823870897293091
test loss item: 0.10182955116033554
test loss item: 0.11539088934659958
test loss item: 0.04874345287680626
test loss item: 0.04669621214270592
test loss item: 0.1286083310842514
Epoch [13/100], Training Loss: 0.2365, Testing Loss: 0.2010
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 14/100
train loss item: 0.215829998254776
train loss item: 0.367873877286911
train loss item: 0.1011868268251419
train loss item: 0.21159781515598297
train loss item: 0.20171846449375153
train loss item: 0.14479026198387146
train loss item: 0.1211094781756401
train loss item: 0.2372179627418518
train loss item: 0.09297411143779755
train loss item: 0.1512659639120102
train loss item: 0.17770273983478546
train loss item: 0.13814350962638855
train loss item: 0.08618824183940887
train loss item: 0.24720588326454163
train loss item: 0.1243082657456398
train loss item: 0.3944122791290283
train loss item: 0.047563474625349045
train loss item: 0.1146184578537941
train loss item: 0.1489555537700653
train loss item: 0.1327885091304779
train loss item: 0.1156444251537323
train loss item: 0.08132752776145935
train loss item: 0.43352586030960083
train loss item: 0.3311544954776764
train loss item: 0.23455014824867249
train loss item: 0.12908004224300385
train loss item: 0.12363909929990768
train loss item: 0.11721878498792648
train loss item: 0.06187869980931282
train loss item: 0.2585524916648865
train loss item: 0.9541265964508057
train loss item: 0.2676592767238617
train loss item: 0.07763002067804337
train loss item: 0.15654973685741425
train loss item: 0.1062193512916565
train loss item: 1.2675565481185913
train loss item: 0.2411733716726303
train loss item: 0.237028568983078
train loss item: 0.17146794497966766
train loss item: 0.11740336567163467
train loss item: 0.1087573915719986
train loss item: 0.12091934680938721
train loss item: 0.19711340963840485
train loss item: 0.12464521825313568
train loss item: 0.30421996116638184
train loss item: 0.08251341432332993
train loss item: 0.06310416013002396
train loss item: 0.21681033074855804
train loss item: 0.1289728730916977
train loss item: 0.085083968937397
train loss item: 0.13733412325382233
train loss item: 0.4364702105522156
train loss item: 0.06604237109422684
train loss item: 0.09993105381727219
train loss item: 1.112534523010254
train loss item: 0.11488144844770432
train loss item: 0.13551266491413116
train loss item: 0.12289639562368393
train loss item: 0.07834010571241379
train loss item: 0.09280182421207428
train loss item: 0.21315553784370422
train loss item: 0.8001510500907898
train loss item: 0.11132930964231491
train loss item: 0.21614910662174225
train loss item: 0.08688509464263916
train loss item: 0.22876675426959991
train loss item: 0.20988576114177704
train loss item: 0.13627134263515472
train loss item: 0.20108847320079803
train loss item: 0.14298132061958313
train loss item: 0.11772985011339188
train loss item: 0.08644919097423553
train loss item: 0.09379780292510986
train loss item: 0.1588720679283142
train loss item: 0.05540262535214424
train loss item: 0.07555150240659714
train loss item: 0.26896265149116516
train loss item: 0.9654219746589661
train loss item: 0.051466647535562515
train loss item: 0.1495470255613327
train loss item: 0.07605359703302383
train loss item: 0.09803296625614166
train loss item: 0.126610666513443
train loss item: 0.2643050253391266
train loss item: 0.20209503173828125
train loss item: 0.24873004853725433
train loss item: 2.5686657428741455
train loss item: 0.08286221325397491
train loss item: 0.15191709995269775
test loss item: 0.09629218280315399
test loss item: 0.07361733913421631
test loss item: 0.30118516087532043
test loss item: 0.12263757735490799
test loss item: 0.1375991851091385
test loss item: 0.08369871228933334
test loss item: 0.8675807118415833
test loss item: 0.29420924186706543
test loss item: 0.12359602004289627
test loss item: 0.18712051212787628
test loss item: 0.49835941195487976
test loss item: 0.09321322292089462
test loss item: 0.11738184839487076
test loss item: 0.15247036516666412
test loss item: 0.10129962116479874
test loss item: 0.054284751415252686
test loss item: 0.14170221984386444
test loss item: 0.17993450164794922
test loss item: 0.3475014865398407
test loss item: 0.13823848962783813
test loss item: 0.26815810799598694
test loss item: 0.20151309669017792
test loss item: 0.13485348224639893
test loss item: 0.09881996363401413
test loss item: 0.0938248559832573
test loss item: 0.1250881403684616
test loss item: 0.14589959383010864
test loss item: 0.1125703975558281
test loss item: 0.16308070719242096
test loss item: 0.15756899118423462
test loss item: 0.4341455101966858
test loss item: 0.05034511163830757
test loss item: 0.08982619643211365
test loss item: 0.23226627707481384
test loss item: 0.18414464592933655
test loss item: 0.2174118161201477
test loss item: 0.4159373939037323
test loss item: 0.8120023012161255
test loss item: 0.20606644451618195
test loss item: 0.14231395721435547
test loss item: 0.15849409997463226
test loss item: 0.11511588841676712
test loss item: 0.13751283288002014
test loss item: 0.1115596666932106
test loss item: 0.2177562564611435
test loss item: 0.2052454799413681
test loss item: 0.12952788174152374
test loss item: 0.12301037460565567
test loss item: 0.23801466822624207
test loss item: 0.3483876585960388
test loss item: 0.145018070936203
test loss item: 0.08110015094280243
test loss item: 0.1248675063252449
test loss item: 0.0861237496137619
test loss item: 0.13352443277835846
test loss item: 0.43725961446762085
test loss item: 0.2928948998451233
test loss item: 0.1301802545785904
test loss item: 0.12489338964223862
test loss item: 0.1216759905219078
test loss item: 0.17634572088718414
test loss item: 0.13911522924900055
test loss item: 0.11200844496488571
test loss item: 0.13421086966991425
test loss item: 0.4914209246635437
test loss item: 0.16735997796058655
test loss item: 0.16041740775108337
test loss item: 0.1349347084760666
test loss item: 0.2565322816371918
test loss item: 0.23145268857479095
test loss item: 0.05918426066637039
test loss item: 0.4791739583015442
test loss item: 0.1301535964012146
test loss item: 0.18729010224342346
test loss item: 0.08479055017232895
test loss item: 0.0882081538438797
test loss item: 0.09785201400518417
test loss item: 0.9135007858276367
test loss item: 0.21002794802188873
test loss item: 0.10781167447566986
test loss item: 0.05461728200316429
test loss item: 0.5484275817871094
test loss item: 0.4482770264148712
test loss item: 0.6202942132949829
test loss item: 0.10767941176891327
test loss item: 0.1158541589975357
test loss item: 0.0511067658662796
test loss item: 0.04805825650691986
test loss item: 0.1332525610923767
Epoch [14/100], Training Loss: 0.2355, Testing Loss: 0.2062
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 15/100
train loss item: 0.1890632063150406
train loss item: 0.2394534945487976
train loss item: 0.09861279278993607
train loss item: 0.15636217594146729
train loss item: 0.23138314485549927
train loss item: 0.14608317613601685
train loss item: 0.08809265494346619
train loss item: 0.19462427496910095
train loss item: 0.06169714778661728
train loss item: 0.11153953522443771
train loss item: 0.13579636812210083
train loss item: 0.11399897187948227
train loss item: 0.08024930953979492
train loss item: 0.2277338057756424
train loss item: 0.10204840451478958
train loss item: 0.29614686965942383
train loss item: 0.04459339380264282
train loss item: 0.0976577177643776
train loss item: 0.14319263398647308
train loss item: 0.12812860310077667
train loss item: 0.1252831071615219
train loss item: 0.07137304544448853
train loss item: 0.24382877349853516
train loss item: 0.21027804911136627
train loss item: 0.18701264262199402
train loss item: 0.13289813697338104
train loss item: 0.09943293780088425
train loss item: 0.11201101541519165
train loss item: 0.04776351526379585
train loss item: 0.2579476535320282
train loss item: 0.6288654208183289
train loss item: 0.19978736340999603
train loss item: 0.06597399711608887
train loss item: 0.140274778008461
train loss item: 0.07903973758220673
train loss item: 1.2056708335876465
train loss item: 0.2685023248195648
train loss item: 0.22696460783481598
train loss item: 0.22957360744476318
train loss item: 0.13059267401695251
train loss item: 0.1083620935678482
train loss item: 0.1201312467455864
train loss item: 0.16477838158607483
train loss item: 0.11378680169582367
train loss item: 0.3206159174442291
train loss item: 0.0797075554728508
train loss item: 0.06625685840845108
train loss item: 0.17076148092746735
train loss item: 0.11542821675539017
train loss item: 0.0837586373090744
train loss item: 0.10633087903261185
train loss item: 0.4220867156982422
train loss item: 0.05763685330748558
train loss item: 0.07353968918323517
train loss item: 1.054965615272522
train loss item: 0.08460956066846848
train loss item: 0.11281464248895645
train loss item: 0.12289999425411224
train loss item: 0.08328840881586075
train loss item: 0.092157281935215
train loss item: 0.2513910233974457
train loss item: 0.7611485123634338
train loss item: 0.10792810469865799
train loss item: 0.17183853685855865
train loss item: 0.08453351259231567
train loss item: 0.19861845672130585
train loss item: 0.19080272316932678
train loss item: 0.11320316046476364
train loss item: 0.17450407147407532
train loss item: 0.1369086354970932
train loss item: 0.11380288004875183
train loss item: 0.07883460819721222
train loss item: 0.08434006571769714
train loss item: 0.14775946736335754
train loss item: 0.05986513942480087
train loss item: 0.07346917688846588
train loss item: 0.30911070108413696
train loss item: 0.9564226865768433
train loss item: 0.043965164572000504
train loss item: 0.15537051856517792
train loss item: 0.07986585795879364
train loss item: 0.09841299057006836
train loss item: 0.12028561532497406
train loss item: 0.2530345916748047
train loss item: 0.19884048402309418
train loss item: 0.23564688861370087
train loss item: 2.643127918243408
train loss item: 0.07811550050973892
train loss item: 0.1349310427904129
test loss item: 0.10711661726236343
test loss item: 0.0779111236333847
test loss item: 0.2848261892795563
test loss item: 0.13159431517124176
test loss item: 0.14577458798885345
test loss item: 0.09964946657419205
test loss item: 0.8212110996246338
test loss item: 0.27287930250167847
test loss item: 0.12366491556167603
test loss item: 0.18521536886692047
test loss item: 0.46349021792411804
test loss item: 0.08999266475439072
test loss item: 0.11371617764234543
test loss item: 0.13546983897686005
test loss item: 0.10727051645517349
test loss item: 0.051198139786720276
test loss item: 0.14427781105041504
test loss item: 0.1822221577167511
test loss item: 0.3318164646625519
test loss item: 0.13082736730575562
test loss item: 0.2774239480495453
test loss item: 0.20265774428844452
test loss item: 0.12491893023252487
test loss item: 0.10935740172863007
test loss item: 0.09397429972887039
test loss item: 0.12744836509227753
test loss item: 0.1466434895992279
test loss item: 0.12384960055351257
test loss item: 0.16797062754631042
test loss item: 0.15607444941997528
test loss item: 0.4099128842353821
test loss item: 0.04829235002398491
test loss item: 0.10030960291624069
test loss item: 0.22604162991046906
test loss item: 0.18076741695404053
test loss item: 0.21167400479316711
test loss item: 0.39914682507514954
test loss item: 0.7365186810493469
test loss item: 0.20769481360912323
test loss item: 0.15378756821155548
test loss item: 0.1637001484632492
test loss item: 0.10649154335260391
test loss item: 0.13785679638385773
test loss item: 0.11860712617635727
test loss item: 0.22503983974456787
test loss item: 0.2005273699760437
test loss item: 0.12220675498247147
test loss item: 0.11347952485084534
test loss item: 0.23433120548725128
test loss item: 0.3260098695755005
test loss item: 0.1507946401834488
test loss item: 0.07903928309679031
test loss item: 0.13026411831378937
test loss item: 0.08939694613218307
test loss item: 0.13511833548545837
test loss item: 0.4101211428642273
test loss item: 0.27944591641426086
test loss item: 0.11125083267688751
test loss item: 0.12927071750164032
test loss item: 0.12019423395395279
test loss item: 0.17428544163703918
test loss item: 0.13637392222881317
test loss item: 0.11571245640516281
test loss item: 0.12799036502838135
test loss item: 0.4601176381111145
test loss item: 0.1753125786781311
test loss item: 0.15829865634441376
test loss item: 0.13243262469768524
test loss item: 0.24369771778583527
test loss item: 0.22248435020446777
test loss item: 0.054332755506038666
test loss item: 0.4484666883945465
test loss item: 0.12458597123622894
test loss item: 0.18909765779972076
test loss item: 0.08239822834730148
test loss item: 0.07832997292280197
test loss item: 0.10480546951293945
test loss item: 0.8227677345275879
test loss item: 0.19287367165088654
test loss item: 0.12003372609615326
test loss item: 0.0571836493909359
test loss item: 0.5064350366592407
test loss item: 0.43209508061408997
test loss item: 0.5671458840370178
test loss item: 0.1083354502916336
test loss item: 0.11294692009687424
test loss item: 0.057888150215148926
test loss item: 0.05355123430490494
test loss item: 0.13301053643226624
Epoch [15/100], Training Loss: 0.2153, Testing Loss: 0.1998
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 16/100
train loss item: 0.21172870695590973
train loss item: 0.2310255765914917
train loss item: 0.10046184062957764
train loss item: 0.16126605868339539
train loss item: 0.21171382069587708
train loss item: 0.15210013091564178
train loss item: 0.1009925901889801
train loss item: 0.2137065976858139
train loss item: 0.09927255660295486
train loss item: 0.13733923435211182
train loss item: 0.12427274882793427
train loss item: 0.11668681353330612
train loss item: 0.08720147609710693
train loss item: 0.23597197234630585
train loss item: 0.10995958745479584
train loss item: 0.2675464451313019
train loss item: 0.045676715672016144
train loss item: 0.09796960651874542
train loss item: 0.1421547681093216
train loss item: 0.1118927001953125
train loss item: 0.10413718968629837
train loss item: 0.08307152986526489
train loss item: 0.23963336646556854
train loss item: 0.3202199339866638
train loss item: 0.2213791012763977
train loss item: 0.11565227061510086
train loss item: 0.0984494611620903
train loss item: 0.11916932463645935
train loss item: 0.05360681563615799
train loss item: 0.2357141524553299
train loss item: 0.5570819973945618
train loss item: 0.21329864859580994
train loss item: 0.07032111287117004
train loss item: 0.12102360278367996
train loss item: 0.08046448230743408
train loss item: 1.1551570892333984
train loss item: 0.21823175251483917
train loss item: 0.17387233674526215
train loss item: 0.18919667601585388
train loss item: 0.108880914747715
train loss item: 0.10637851059436798
train loss item: 0.11088927090167999
train loss item: 0.1669798046350479
train loss item: 0.10817886888980865
train loss item: 0.2803921699523926
train loss item: 0.0765705481171608
train loss item: 0.07850553095340729
train loss item: 0.1560387760400772
train loss item: 0.1043466106057167
train loss item: 0.08420214056968689
train loss item: 0.10577140003442764
train loss item: 0.40300649404525757
train loss item: 0.060265373438596725
train loss item: 0.0827590599656105
train loss item: 1.0144175291061401
train loss item: 0.1056288406252861
train loss item: 0.1270105391740799
train loss item: 0.12606365978717804
train loss item: 0.07118072360754013
train loss item: 0.09590461105108261
train loss item: 0.21228912472724915
train loss item: 0.7389470934867859
train loss item: 0.09299425780773163
train loss item: 0.15703941881656647
train loss item: 0.07991687953472137
train loss item: 0.22850093245506287
train loss item: 0.16792388260364532
train loss item: 0.11661752313375473
train loss item: 0.17831628024578094
train loss item: 0.14844872057437897
train loss item: 0.10485555976629257
train loss item: 0.07895171642303467
train loss item: 0.07235067337751389
train loss item: 0.14312276244163513
train loss item: 0.05002843216061592
train loss item: 0.06955784559249878
train loss item: 0.2015535682439804
train loss item: 0.9036312699317932
train loss item: 0.04563843831419945
train loss item: 0.11867062002420425
train loss item: 0.07603129744529724
train loss item: 0.08521944284439087
train loss item: 0.11463838070631027
train loss item: 0.29279762506484985
train loss item: 0.21680903434753418
train loss item: 0.15516991913318634
train loss item: 2.434069871902466
train loss item: 0.08689813315868378
train loss item: 0.1236947774887085
test loss item: 0.09493935108184814
test loss item: 0.07022562623023987
test loss item: 0.3637320399284363
test loss item: 0.12581707537174225
test loss item: 0.14445285499095917
test loss item: 0.07406634837388992
test loss item: 1.1329538822174072
test loss item: 0.3852105736732483
test loss item: 0.14019891619682312
test loss item: 0.21290379762649536
test loss item: 0.5688414573669434
test loss item: 0.0922500267624855
test loss item: 0.11904925853013992
test loss item: 0.15803636610507965
test loss item: 0.1039532721042633
test loss item: 0.053526636213064194
test loss item: 0.1620330512523651
test loss item: 0.21542680263519287
test loss item: 0.4092215597629547
test loss item: 0.1545744091272354
test loss item: 0.3350587487220764
test loss item: 0.23701180517673492
test loss item: 0.1517142355442047
test loss item: 0.10420913994312286
test loss item: 0.10454824566841125
test loss item: 0.12942299246788025
test loss item: 0.16274525225162506
test loss item: 0.10777795314788818
test loss item: 0.18107597529888153
test loss item: 0.17085015773773193
test loss item: 0.5341140627861023
test loss item: 0.04670565202832222
test loss item: 0.0899665504693985
test loss item: 0.27627137303352356
test loss item: 0.22244150936603546
test loss item: 0.24510785937309265
test loss item: 0.4963003695011139
test loss item: 0.9462641477584839
test loss item: 0.2464396357536316
test loss item: 0.1607074737548828
test loss item: 0.18205925822257996
test loss item: 0.1122233048081398
test loss item: 0.15933585166931152
test loss item: 0.12853440642356873
test loss item: 0.26095202565193176
test loss item: 0.2382340431213379
test loss item: 0.1385425180196762
test loss item: 0.12747585773468018
test loss item: 0.2859950363636017
test loss item: 0.4173485338687897
test loss item: 0.16075775027275085
test loss item: 0.07920254021883011
test loss item: 0.13928797841072083
test loss item: 0.0903661698102951
test loss item: 0.15332695841789246
test loss item: 0.5207998752593994
test loss item: 0.34537217020988464
test loss item: 0.13180232048034668
test loss item: 0.1352662742137909
test loss item: 0.12217684835195541
test loss item: 0.20188909769058228
test loss item: 0.1658376157283783
test loss item: 0.12272148579359055
test loss item: 0.139038547873497
test loss item: 0.5914942622184753
test loss item: 0.17205211520195007
test loss item: 0.18423013389110565
test loss item: 0.14832837879657745
test loss item: 0.28920963406562805
test loss item: 0.2786824405193329
test loss item: 0.05262947082519531
test loss item: 0.6317517757415771
test loss item: 0.14551864564418793
test loss item: 0.2304188311100006
test loss item: 0.08949090540409088
test loss item: 0.08696100860834122
test loss item: 0.10449864715337753
test loss item: 1.0537748336791992
test loss item: 0.23840397596359253
test loss item: 0.10483796149492264
test loss item: 0.04970584437251091
test loss item: 0.6651912331581116
test loss item: 0.5413632392883301
test loss item: 0.7240590453147888
test loss item: 0.12224134802818298
test loss item: 0.12358161807060242
test loss item: 0.04779067263007164
test loss item: 0.044977691024541855
test loss item: 0.1315491944551468
Epoch [16/100], Training Loss: 0.2067, Testing Loss: 0.2375
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 17/100
train loss item: 0.17511926591396332
train loss item: 0.3074810802936554
train loss item: 0.0902220830321312
train loss item: 0.23807168006896973
train loss item: 0.1965664178133011
train loss item: 0.12809817492961884
train loss item: 0.09686792641878128
train loss item: 0.2167985737323761
train loss item: 0.062256913632154465
train loss item: 0.10077076405286789
train loss item: 0.13684292137622833
train loss item: 0.11607541888952255
train loss item: 0.08721869438886642
train loss item: 0.20996493101119995
train loss item: 0.09994859248399734
train loss item: 0.3071237802505493
train loss item: 0.05157972872257233
train loss item: 0.10094106197357178
train loss item: 0.11211533844470978
train loss item: 0.10187263786792755
train loss item: 0.13438186049461365
train loss item: 0.07673598825931549
train loss item: 0.32430824637413025
train loss item: 0.2319413721561432
train loss item: 0.19280467927455902
train loss item: 0.12011222541332245
train loss item: 0.10188474506139755
train loss item: 0.10202689468860626
train loss item: 0.04487915337085724
train loss item: 0.23980197310447693
train loss item: 0.7342220544815063
train loss item: 0.25299394130706787
train loss item: 0.06866821646690369
train loss item: 0.12883038818836212
train loss item: 0.08879861980676651
train loss item: 1.145774245262146
train loss item: 0.21040095388889313
train loss item: 0.21242687106132507
train loss item: 0.19758254289627075
train loss item: 0.11205637454986572
train loss item: 0.10423164814710617
train loss item: 0.11860296130180359
train loss item: 0.17311781644821167
train loss item: 0.12373924255371094
train loss item: 0.27195560932159424
train loss item: 0.07890275865793228
train loss item: 0.06009460985660553
train loss item: 0.21223466098308563
train loss item: 0.12092522531747818
train loss item: 0.0852636769413948
train loss item: 0.1428641676902771
train loss item: 0.45524799823760986
train loss item: 0.05673561617732048
train loss item: 0.08331615477800369
train loss item: 0.9807355403900146
train loss item: 0.09172933548688889
train loss item: 0.1557459980249405
train loss item: 0.1105344370007515
train loss item: 0.07963404059410095
train loss item: 0.0962928757071495
train loss item: 0.2219424992799759
train loss item: 0.65591961145401
train loss item: 0.10570768266916275
train loss item: 0.21070699393749237
train loss item: 0.078380286693573
train loss item: 0.20353712141513824
train loss item: 0.17949993908405304
train loss item: 0.1237250417470932
train loss item: 0.17105494439601898
train loss item: 0.13885599374771118
train loss item: 0.10233848541975021
train loss item: 0.08321166038513184
train loss item: 0.07550137490034103
train loss item: 0.13949845731258392
train loss item: 0.050566185265779495
train loss item: 0.06951642781496048
train loss item: 0.2549494504928589
train loss item: 0.8911684155464172
train loss item: 0.04743824899196625
train loss item: 0.13946232199668884
train loss item: 0.08312863111495972
train loss item: 0.09485729038715363
train loss item: 0.1160338968038559
train loss item: 0.23368901014328003
train loss item: 0.177603080868721
train loss item: 0.2211737483739853
train loss item: 2.383310317993164
train loss item: 0.07969706505537033
train loss item: 0.13491939008235931
test loss item: 0.10202744603157043
test loss item: 0.07270120829343796
test loss item: 0.3212750554084778
test loss item: 0.12165839970111847
test loss item: 0.1341845542192459
test loss item: 0.08114075660705566
test loss item: 0.8550618290901184
test loss item: 0.2948249280452728
test loss item: 0.1280849725008011
test loss item: 0.19484077394008636
test loss item: 0.5107011198997498
test loss item: 0.08736706525087357
test loss item: 0.12240786850452423
test loss item: 0.18493159115314484
test loss item: 0.10355168581008911
test loss item: 0.05583416670560837
test loss item: 0.15098129212856293
test loss item: 0.1892755627632141
test loss item: 0.3348160684108734
test loss item: 0.15038688480854034
test loss item: 0.2888113558292389
test loss item: 0.20465216040611267
test loss item: 0.1528710126876831
test loss item: 0.10276719182729721
test loss item: 0.09780404716730118
test loss item: 0.12482292205095291
test loss item: 0.15400201082229614
test loss item: 0.10640808194875717
test loss item: 0.16866721212863922
test loss item: 0.16071370244026184
test loss item: 0.45048433542251587
test loss item: 0.054139696061611176
test loss item: 0.09367506951093674
test loss item: 0.23946167528629303
test loss item: 0.1952345073223114
test loss item: 0.2177136391401291
test loss item: 0.40762969851493835
test loss item: 0.8447896242141724
test loss item: 0.21651746332645416
test loss item: 0.1429026573896408
test loss item: 0.15970897674560547
test loss item: 0.13439106941223145
test loss item: 0.13606256246566772
test loss item: 0.11505410075187683
test loss item: 0.2374744564294815
test loss item: 0.22026659548282623
test loss item: 0.152640700340271
test loss item: 0.14176850020885468
test loss item: 0.248908132314682
test loss item: 0.35782819986343384
test loss item: 0.14801594614982605
test loss item: 0.08736739307641983
test loss item: 0.1298646479845047
test loss item: 0.085669606924057
test loss item: 0.13916780054569244
test loss item: 0.4594321548938751
test loss item: 0.29232993721961975
test loss item: 0.15534564852714539
test loss item: 0.1310456097126007
test loss item: 0.12127678096294403
test loss item: 0.1793416291475296
test loss item: 0.14748533070087433
test loss item: 0.12112148851156235
test loss item: 0.13288041949272156
test loss item: 0.4991506338119507
test loss item: 0.16208085417747498
test loss item: 0.1693965345621109
test loss item: 0.1322033405303955
test loss item: 0.2596478760242462
test loss item: 0.2253188043832779
test loss item: 0.06386217474937439
test loss item: 0.4708082973957062
test loss item: 0.1526641547679901
test loss item: 0.19575467705726624
test loss item: 0.09464982151985168
test loss item: 0.11189781129360199
test loss item: 0.09923092275857925
test loss item: 0.9385945796966553
test loss item: 0.23539584875106812
test loss item: 0.11186249554157257
test loss item: 0.05763619765639305
test loss item: 0.5511259436607361
test loss item: 0.4452483654022217
test loss item: 0.638683557510376
test loss item: 0.10985207557678223
test loss item: 0.12414348870515823
test loss item: 0.05860411748290062
test loss item: 0.053958941251039505
test loss item: 0.1268572062253952
Epoch [17/100], Training Loss: 0.2104, Testing Loss: 0.2128
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 18/100
train loss item: 0.16402862966060638
train loss item: 0.20943018794059753
train loss item: 0.09757866710424423
train loss item: 0.1479482203722
train loss item: 0.1572284996509552
train loss item: 0.13684996962547302
train loss item: 0.10049614310264587
train loss item: 0.17970940470695496
train loss item: 0.05180879682302475
train loss item: 0.0921546220779419
train loss item: 0.1154436469078064
train loss item: 0.10828914493322372
train loss item: 0.0721953809261322
train loss item: 0.21460013091564178
train loss item: 0.08962970972061157
train loss item: 0.23162463307380676
train loss item: 0.04202316701412201
train loss item: 0.08795493841171265
train loss item: 0.11796031147241592
train loss item: 0.1163855567574501
train loss item: 0.09568910300731659
train loss item: 0.06501759588718414
train loss item: 0.20738163590431213
train loss item: 0.19105075299739838
train loss item: 0.19787739217281342
train loss item: 0.0953654870390892
train loss item: 0.08106952905654907
train loss item: 0.10596006363630295
train loss item: 0.0603320337831974
train loss item: 0.2586592137813568
train loss item: 0.4875819981098175
train loss item: 0.2061130702495575
train loss item: 0.06597517430782318
train loss item: 0.1090359166264534
train loss item: 0.07904373109340668
train loss item: 1.0868839025497437
train loss item: 0.21115443110466003
train loss item: 0.18377582728862762
train loss item: 0.18831801414489746
train loss item: 0.11175099015235901
train loss item: 0.09609771519899368
train loss item: 0.10785754770040512
train loss item: 0.14469420909881592
train loss item: 0.10748802870512009
train loss item: 0.25852423906326294
train loss item: 0.07363521307706833
train loss item: 0.058989301323890686
train loss item: 0.13690274953842163
train loss item: 0.10204414278268814
train loss item: 0.07486240565776825
train loss item: 0.08899806439876556
train loss item: 0.35945892333984375
train loss item: 0.05315013974905014
train loss item: 0.06766434758901596
train loss item: 0.9328452944755554
train loss item: 0.08203740417957306
train loss item: 0.09600299596786499
train loss item: 0.09956736117601395
train loss item: 0.06875735521316528
train loss item: 0.0922146588563919
train loss item: 0.19602786004543304
train loss item: 0.6064815521240234
train loss item: 0.08823733776807785
train loss item: 0.13556641340255737
train loss item: 0.07846730202436447
train loss item: 0.17953231930732727
train loss item: 0.15565602481365204
train loss item: 0.11252635717391968
train loss item: 0.16161136329174042
train loss item: 0.11753861606121063
train loss item: 0.09133648127317429
train loss item: 0.08377842605113983
train loss item: 0.07473022490739822
train loss item: 0.13283421099185944
train loss item: 0.04851599782705307
train loss item: 0.06691916286945343
train loss item: 0.22272373735904694
train loss item: 0.8186876773834229
train loss item: 0.04396098852157593
train loss item: 0.10855019092559814
train loss item: 0.0729123204946518
train loss item: 0.08482435345649719
train loss item: 0.10392175614833832
train loss item: 0.2334601730108261
train loss item: 0.19738103449344635
train loss item: 0.16577179729938507
train loss item: 2.3178160190582275
train loss item: 0.07172628492116928
train loss item: 0.11548202484846115
test loss item: 0.09696302562952042
test loss item: 0.07692952454090118
test loss item: 0.3176649510860443
test loss item: 0.1252514123916626
test loss item: 0.14260773360729218
test loss item: 0.08607833832502365
test loss item: 1.0648150444030762
test loss item: 0.3492661416530609
test loss item: 0.1313234120607376
test loss item: 0.19704581797122955
test loss item: 0.49996569752693176
test loss item: 0.08992629498243332
test loss item: 0.1153835579752922
test loss item: 0.17393746972084045
test loss item: 0.10604684799909592
test loss item: 0.053704969584941864
test loss item: 0.15370595455169678
test loss item: 0.19600935280323029
test loss item: 0.3703484833240509
test loss item: 0.14682869613170624
test loss item: 0.31197938323020935
test loss item: 0.2212233543395996
test loss item: 0.14522938430309296
test loss item: 0.10950666666030884
test loss item: 0.09910739213228226
test loss item: 0.12749433517456055
test loss item: 0.15530261397361755
test loss item: 0.11491942405700684
test loss item: 0.17874231934547424
test loss item: 0.16063794493675232
test loss item: 0.4821024239063263
test loss item: 0.048896048218011856
test loss item: 0.09720274060964584
test loss item: 0.24357710778713226
test loss item: 0.20024551451206207
test loss item: 0.22399476170539856
test loss item: 0.457983136177063
test loss item: 0.8013566732406616
test loss item: 0.23092111945152283
test loss item: 0.1605754792690277
test loss item: 0.17325399816036224
test loss item: 0.11339239776134491
test loss item: 0.14385737478733063
test loss item: 0.12268804758787155
test loss item: 0.25299108028411865
test loss item: 0.22176769375801086
test loss item: 0.13548149168491364
test loss item: 0.12563686072826385
test loss item: 0.2537778317928314
test loss item: 0.36693641543388367
test loss item: 0.1563725620508194
test loss item: 0.07865440100431442
test loss item: 0.132537841796875
test loss item: 0.08941347151994705
test loss item: 0.14326685667037964
test loss item: 0.45387083292007446
test loss item: 0.3067772686481476
test loss item: 0.12264981865882874
test loss item: 0.1303800642490387
test loss item: 0.118670254945755
test loss item: 0.18364952504634857
test loss item: 0.15011267364025116
test loss item: 0.12201538681983948
test loss item: 0.13507892191410065
test loss item: 0.5153769254684448
test loss item: 0.16552157700061798
test loss item: 0.17183257639408112
test loss item: 0.14253570139408112
test loss item: 0.2525632679462433
test loss item: 0.2474461942911148
test loss item: 0.05784808471798897
test loss item: 0.5838156938552856
test loss item: 0.15061220526695251
test loss item: 0.2183564454317093
test loss item: 0.08929693698883057
test loss item: 0.09087596088647842
test loss item: 0.10801034420728683
test loss item: 0.8824291825294495
test loss item: 0.22505956888198853
test loss item: 0.1136813834309578
test loss item: 0.05689995735883713
test loss item: 0.5834245681762695
test loss item: 0.5009907484054565
test loss item: 0.6175106167793274
test loss item: 0.11732949316501617
test loss item: 0.1182425245642662
test loss item: 0.0596429742872715
test loss item: 0.05206354334950447
test loss item: 0.1309141218662262
Epoch [18/100], Training Loss: 0.1866, Testing Loss: 0.2197
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 19/100
train loss item: 0.15827636420726776
train loss item: 0.23390451073646545
train loss item: 0.08695173263549805
train loss item: 0.14486342668533325
train loss item: 0.16645200550556183
train loss item: 0.12891621887683868
train loss item: 0.08330088108778
train loss item: 0.18479572236537933
train loss item: 0.07287134230136871
train loss item: 0.09215573221445084
train loss item: 0.10087696462869644
train loss item: 0.10222819447517395
train loss item: 0.08088471740484238
train loss item: 0.21604396402835846
train loss item: 0.10412700474262238
train loss item: 0.20500433444976807
train loss item: 0.04502858221530914
train loss item: 0.08707790076732635
train loss item: 0.13367222249507904
train loss item: 0.09457582235336304
train loss item: 0.10039067268371582
train loss item: 0.0746847614645958
train loss item: 0.20734065771102905
train loss item: 0.24314510822296143
train loss item: 0.17844951152801514
train loss item: 0.100153848528862
train loss item: 0.10154983401298523
train loss item: 0.10280836373567581
train loss item: 0.054795682430267334
train loss item: 0.24085403978824615
train loss item: 0.3809290826320648
train loss item: 0.22655291855335236
train loss item: 0.07176414877176285
train loss item: 0.11452671140432358
train loss item: 0.08479419350624084
train loss item: 1.0327799320220947
train loss item: 0.2196691781282425
train loss item: 0.2052190899848938
train loss item: 0.20272104442119598
train loss item: 0.10742656886577606
train loss item: 0.09727174043655396
train loss item: 0.10826591402292252
train loss item: 0.162422314286232
train loss item: 0.1175675019621849
train loss item: 0.257514089345932
train loss item: 0.08789268136024475
train loss item: 0.09289289265871048
train loss item: 0.23268550634384155
train loss item: 0.10850641876459122
train loss item: 0.0925975814461708
train loss item: 0.14876800775527954
train loss item: 0.5090715289115906
train loss item: 0.05961834266781807
train loss item: 0.10560943186283112
train loss item: 0.9015029668807983
train loss item: 0.10104852169752121
train loss item: 0.20054201781749725
train loss item: 0.12278339266777039
train loss item: 0.09593726694583893
train loss item: 0.10397922247648239
train loss item: 0.2609882354736328
train loss item: 0.5879340171813965
train loss item: 0.10337689518928528
train loss item: 0.19669950008392334
train loss item: 0.07646271586418152
train loss item: 0.2238496094942093
train loss item: 0.16509880125522614
train loss item: 0.1398099660873413
train loss item: 0.14187128841876984
train loss item: 0.15048962831497192
train loss item: 0.11488135159015656
train loss item: 0.09014186263084412
train loss item: 0.07619864493608475
train loss item: 0.16052541136741638
train loss item: 0.051838796585798264
train loss item: 0.07110533863306046
train loss item: 0.1852114051580429
train loss item: 0.8636706471443176
train loss item: 0.05233801528811455
train loss item: 0.14613725244998932
train loss item: 0.07402444630861282
train loss item: 0.1110839694738388
train loss item: 0.10412733256816864
train loss item: 0.300873726606369
train loss item: 0.15953703224658966
train loss item: 0.16089072823524475
train loss item: 2.2608144283294678
train loss item: 0.0955103263258934
train loss item: 0.11340790241956711
test loss item: 0.09021559357643127
test loss item: 0.07549773901700974
test loss item: 0.3992939889431
test loss item: 0.11793721467256546
test loss item: 0.15131103992462158
test loss item: 0.07708828151226044
test loss item: 0.9935464859008789
test loss item: 0.3301663100719452
test loss item: 0.14935749769210815
test loss item: 0.22902238368988037
test loss item: 0.6056647896766663
test loss item: 0.09451042860746384
test loss item: 0.127447709441185
test loss item: 0.15074126422405243
test loss item: 0.10960185527801514
test loss item: 0.05773438885807991
test loss item: 0.1523015797138214
test loss item: 0.2376033067703247
test loss item: 0.35761457681655884
test loss item: 0.1460990160703659
test loss item: 0.3757779002189636
test loss item: 0.21411241590976715
test loss item: 0.1426939070224762
test loss item: 0.10149029642343521
test loss item: 0.10961780697107315
test loss item: 0.1264854222536087
test loss item: 0.163521409034729
test loss item: 0.11099709570407867
test loss item: 0.18347351253032684
test loss item: 0.17766083776950836
test loss item: 0.5359585285186768
test loss item: 0.04945532605051994
test loss item: 0.09160924702882767
test loss item: 0.3012130558490753
test loss item: 0.24787411093711853
test loss item: 0.23823648691177368
test loss item: 0.44468578696250916
test loss item: 1.0383490324020386
test loss item: 0.2620543837547302
test loss item: 0.152654230594635
test loss item: 0.16932572424411774
test loss item: 0.10032705962657928
test loss item: 0.17582443356513977
test loss item: 0.11863092333078384
test loss item: 0.29275381565093994
test loss item: 0.22241972386837006
test loss item: 0.13519790768623352
test loss item: 0.11455529928207397
test loss item: 0.3003736138343811
test loss item: 0.42517176270484924
test loss item: 0.17921634018421173
test loss item: 0.08055444806814194
test loss item: 0.1403549164533615
test loss item: 0.08390318602323532
test loss item: 0.1681739240884781
test loss item: 0.5687081813812256
test loss item: 0.3314017653465271
test loss item: 0.12591858208179474
test loss item: 0.1312187761068344
test loss item: 0.1344991773366928
test loss item: 0.22974245250225067
test loss item: 0.14953716099262238
test loss item: 0.11533765494823456
test loss item: 0.1491232067346573
test loss item: 0.6071947813034058
test loss item: 0.15701034665107727
test loss item: 0.17678596079349518
test loss item: 0.144084632396698
test loss item: 0.3151743412017822
test loss item: 0.25025278329849243
test loss item: 0.05828716978430748
test loss item: 0.5482344627380371
test loss item: 0.14434035122394562
test loss item: 0.2073003202676773
test loss item: 0.08784975856542587
test loss item: 0.08045163005590439
test loss item: 0.10049392282962799
test loss item: 1.1577428579330444
test loss item: 0.24617253243923187
test loss item: 0.10429512709379196
test loss item: 0.0544862262904644
test loss item: 0.6615460515022278
test loss item: 0.49997350573539734
test loss item: 0.7855074405670166
test loss item: 0.11445997655391693
test loss item: 0.12589967250823975
test loss item: 0.05695252865552902
test loss item: 0.05377373844385147
test loss item: 0.11599196493625641
Epoch [19/100], Training Loss: 0.1968, Testing Loss: 0.2384
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 20/100
train loss item: 0.1527215838432312
train loss item: 0.3200642466545105
train loss item: 0.08941063284873962
train loss item: 0.29752519726753235
train loss item: 0.1260184347629547
train loss item: 0.11904498189687729
train loss item: 0.08372533321380615
train loss item: 0.265701562166214
train loss item: 0.058965910226106644
train loss item: 0.10576572269201279
train loss item: 0.1544792801141739
train loss item: 0.12565821409225464
train loss item: 0.07431097328662872
train loss item: 0.2109784185886383
train loss item: 0.09264329075813293
train loss item: 0.39848315715789795
train loss item: 0.05023212730884552
train loss item: 0.09432181715965271
train loss item: 0.11034030467271805
train loss item: 0.1030246689915657
train loss item: 0.11804889142513275
train loss item: 0.06931863725185394
train loss item: 0.4892114996910095
train loss item: 0.24756769835948944
train loss item: 0.19166257977485657
train loss item: 0.10194072872400284
train loss item: 0.0978371724486351
train loss item: 0.10120972245931625
train loss item: 0.05248188599944115
train loss item: 0.2629182040691376
train loss item: 0.9749171733856201
train loss item: 0.24000170826911926
train loss item: 0.07605338096618652
train loss item: 0.16155754029750824
train loss item: 0.1069609746336937
train loss item: 1.1615092754364014
train loss item: 0.21459375321865082
train loss item: 0.2998104989528656
train loss item: 0.23422257602214813
train loss item: 0.12173271179199219
train loss item: 0.09511309117078781
train loss item: 0.11379442363977432
train loss item: 0.17356745898723602
train loss item: 0.11819218844175339
train loss item: 0.28112468123435974
train loss item: 0.0688168928027153
train loss item: 0.06619083881378174
train loss item: 0.21184003353118896
train loss item: 0.12450859695672989
train loss item: 0.07306608557701111
train loss item: 0.13771429657936096
train loss item: 0.4618077874183655
train loss item: 0.05818094685673714
train loss item: 0.0659351795911789
train loss item: 0.9666261076927185
train loss item: 0.0863124206662178
train loss item: 0.13336056470870972
train loss item: 0.11875197291374207
train loss item: 0.07741774618625641
train loss item: 0.08853776007890701
train loss item: 0.2083439826965332
train loss item: 0.6338465213775635
train loss item: 0.1092459112405777
train loss item: 0.22556211054325104
train loss item: 0.07356833666563034
train loss item: 0.2441626340150833
train loss item: 0.19314272701740265
train loss item: 0.10349993407726288
train loss item: 0.15003429353237152
train loss item: 0.12725427746772766
train loss item: 0.11413134634494781
train loss item: 0.08855102211236954
train loss item: 0.09946101158857346
train loss item: 0.16461734473705292
train loss item: 0.05110123008489609
train loss item: 0.0741567313671112
train loss item: 0.26054006814956665
train loss item: 0.908391535282135
train loss item: 0.042987484484910965
train loss item: 0.1766023337841034
train loss item: 0.06602972745895386
train loss item: 0.10148553550243378
train loss item: 0.09165113419294357
train loss item: 0.2464010864496231
train loss item: 0.1489943116903305
train loss item: 0.1662253588438034
train loss item: 2.2598445415496826
train loss item: 0.07225785404443741
train loss item: 0.12797953188419342
test loss item: 0.09026946127414703
test loss item: 0.06554917991161346
test loss item: 0.35318800806999207
test loss item: 0.11346326023340225
test loss item: 0.12602545320987701
test loss item: 0.06723758578300476
test loss item: 0.7730892300605774
test loss item: 0.22270993888378143
test loss item: 0.12776638567447662
test loss item: 0.19199518859386444
test loss item: 0.5476982593536377
test loss item: 0.08032868802547455
test loss item: 0.10046009719371796
test loss item: 0.11904877424240112
test loss item: 0.09565340727567673
test loss item: 0.05962706357240677
test loss item: 0.1299591362476349
test loss item: 0.19627250730991364
test loss item: 0.29958629608154297
test loss item: 0.1144222766160965
test loss item: 0.30462437868118286
test loss item: 0.17220956087112427
test loss item: 0.11283574253320694
test loss item: 0.09322435408830643
test loss item: 0.09364459663629532
test loss item: 0.11060289293527603
test loss item: 0.14382801949977875
test loss item: 0.0897555872797966
test loss item: 0.1480698585510254
test loss item: 0.1530189961194992
test loss item: 0.44652020931243896
test loss item: 0.05310552567243576
test loss item: 0.0883367657661438
test loss item: 0.258101224899292
test loss item: 0.21427220106124878
test loss item: 0.20947127044200897
test loss item: 0.3637063503265381
test loss item: 0.9265236854553223
test loss item: 0.21584445238113403
test loss item: 0.12446413189172745
test loss item: 0.1481802612543106
test loss item: 0.08888579905033112
test loss item: 0.140440434217453
test loss item: 0.10359437763690948
test loss item: 0.23178496956825256
test loss item: 0.1842031478881836
test loss item: 0.10568904131650925
test loss item: 0.11117836087942123
test loss item: 0.24396918714046478
test loss item: 0.3606891334056854
test loss item: 0.13821345567703247
test loss item: 0.07684370875358582
test loss item: 0.12342802435159683
test loss item: 0.08097536116838455
test loss item: 0.14097219705581665
test loss item: 0.5109635591506958
test loss item: 0.2815869450569153
test loss item: 0.09568893164396286
test loss item: 0.11044953763484955
test loss item: 0.1082761213183403
test loss item: 0.18795138597488403
test loss item: 0.11313720047473907
test loss item: 0.09660884737968445
test loss item: 0.12178892642259598
test loss item: 0.537911057472229
test loss item: 0.15298733115196228
test loss item: 0.1419784128665924
test loss item: 0.12086048722267151
test loss item: 0.2731645107269287
test loss item: 0.21290536224842072
test loss item: 0.05326661467552185
test loss item: 0.4075528681278229
test loss item: 0.11343187838792801
test loss item: 0.15775902569293976
test loss item: 0.07961345463991165
test loss item: 0.0762612372636795
test loss item: 0.08900127559900284
test loss item: 1.0180821418762207
test loss item: 0.21612486243247986
test loss item: 0.08874166756868362
test loss item: 0.059731949120759964
test loss item: 0.5620107650756836
test loss item: 0.42258042097091675
test loss item: 0.6905816197395325
test loss item: 0.0927654430270195
test loss item: 0.1052396148443222
test loss item: 0.07684173434972763
test loss item: 0.07516404986381531
test loss item: 0.11739572882652283
Epoch [20/100], Training Loss: 0.2158, Testing Loss: 0.2027
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 21/100
train loss item: 0.19281147420406342
train loss item: 0.24248415231704712
train loss item: 0.10624107718467712
train loss item: 0.16461800038814545
train loss item: 0.13982625305652618
train loss item: 0.12022412568330765
train loss item: 0.09147283434867859
train loss item: 0.191533625125885
train loss item: 0.05296703800559044
train loss item: 0.11374031007289886
train loss item: 0.11512380838394165
train loss item: 0.09937292337417603
train loss item: 0.08425292372703552
train loss item: 0.19989345967769623
train loss item: 0.08692970871925354
train loss item: 0.3125917911529541
train loss item: 0.048000045120716095
train loss item: 0.09262148290872574
train loss item: 0.11380257457494736
train loss item: 0.1373402625322342
train loss item: 0.09901033341884613
train loss item: 0.0668426901102066
train loss item: 0.27224844694137573
train loss item: 0.15923915803432465
train loss item: 0.16707086563110352
train loss item: 0.12071499973535538
train loss item: 0.10197889059782028
train loss item: 0.11092965304851532
train loss item: 0.05254954844713211
train loss item: 0.29792359471321106
train loss item: 0.7319762110710144
train loss item: 0.21373465657234192
train loss item: 0.06896518915891647
train loss item: 0.11331760138273239
train loss item: 0.0857379287481308
train loss item: 0.9874370098114014
train loss item: 0.21242305636405945
train loss item: 0.23357254266738892
train loss item: 0.3156895041465759
train loss item: 0.1351242959499359
train loss item: 0.09640023112297058
train loss item: 0.11190339177846909
train loss item: 0.1477859914302826
train loss item: 0.11119748651981354
train loss item: 0.2664298117160797
train loss item: 0.06698659807443619
train loss item: 0.061592455953359604
train loss item: 0.16532394289970398
train loss item: 0.1179216131567955
train loss item: 0.06923835724592209
train loss item: 0.11499981582164764
train loss item: 0.3486921489238739
train loss item: 0.054121267050504684
train loss item: 0.07023457437753677
train loss item: 0.8361313343048096
train loss item: 0.07950401306152344
train loss item: 0.12148193269968033
train loss item: 0.10126347839832306
train loss item: 0.0768512636423111
train loss item: 0.0879335030913353
train loss item: 0.19068892300128937
train loss item: 0.5305615067481995
train loss item: 0.0995618999004364
train loss item: 0.1544608324766159
train loss item: 0.07097163051366806
train loss item: 0.15789616107940674
train loss item: 0.14488300681114197
train loss item: 0.10016746073961258
train loss item: 0.12407545745372772
train loss item: 0.12406478822231293
train loss item: 0.10687130689620972
train loss item: 0.07566343992948532
train loss item: 0.0736672654747963
train loss item: 0.1364007443189621
train loss item: 0.04987090453505516
train loss item: 0.0674499049782753
train loss item: 0.3039526343345642
train loss item: 0.8037228584289551
train loss item: 0.04430167376995087
train loss item: 0.1475583165884018
train loss item: 0.07101757824420929
train loss item: 0.09614669531583786
train loss item: 0.09819070249795914
train loss item: 0.2258555144071579
train loss item: 0.1477442979812622
train loss item: 0.18938632309436798
train loss item: 2.1906275749206543
train loss item: 0.07082386314868927
train loss item: 0.10632891952991486
test loss item: 0.09411919862031937
test loss item: 0.06556056439876556
test loss item: 0.32320666313171387
test loss item: 0.12009823322296143
test loss item: 0.12762463092803955
test loss item: 0.0738954246044159
test loss item: 0.9007960557937622
test loss item: 0.2911161482334137
test loss item: 0.1268773078918457
test loss item: 0.1935545653104782
test loss item: 0.5053649544715881
test loss item: 0.0810418650507927
test loss item: 0.1042853370308876
test loss item: 0.14598925411701202
test loss item: 0.09556055814027786
test loss item: 0.052837684750556946
test loss item: 0.1441667377948761
test loss item: 0.19143083691596985
test loss item: 0.3270130455493927
test loss item: 0.1252342015504837
test loss item: 0.3044230341911316
test loss item: 0.20220570266246796
test loss item: 0.12417856603860855
test loss item: 0.10133815556764603
test loss item: 0.09624740481376648
test loss item: 0.11645298451185226
test loss item: 0.14696182310581207
test loss item: 0.09688316285610199
test loss item: 0.15808072686195374
test loss item: 0.15476925671100616
test loss item: 0.4561508595943451
test loss item: 0.04749252647161484
test loss item: 0.09195523709058762
test loss item: 0.2443680763244629
test loss item: 0.19903242588043213
test loss item: 0.21357664465904236
test loss item: 0.40449258685112
test loss item: 0.8327623009681702
test loss item: 0.22092434763908386
test loss item: 0.14259636402130127
test loss item: 0.1614355444908142
test loss item: 0.09789998829364777
test loss item: 0.14242008328437805
test loss item: 0.11795151233673096
test loss item: 0.24343429505825043
test loss item: 0.2016889899969101
test loss item: 0.12183568626642227
test loss item: 0.11104701459407806
test loss item: 0.24524357914924622
test loss item: 0.35215649008750916
test loss item: 0.15120714902877808
test loss item: 0.07325395196676254
test loss item: 0.13099835813045502
test loss item: 0.08677815645933151
test loss item: 0.1408609300851822
test loss item: 0.46470317244529724
test loss item: 0.2835422158241272
test loss item: 0.10700027644634247
test loss item: 0.12381497025489807
test loss item: 0.1127525046467781
test loss item: 0.1842801570892334
test loss item: 0.13622042536735535
test loss item: 0.11105889827013016
test loss item: 0.12307090312242508
test loss item: 0.5094338059425354
test loss item: 0.16042384505271912
test loss item: 0.15266384184360504
test loss item: 0.12768544256687164
test loss item: 0.25533434748649597
test loss item: 0.22651895880699158
test loss item: 0.049393802881240845
test loss item: 0.48920947313308716
test loss item: 0.12763240933418274
test loss item: 0.18752498924732208
test loss item: 0.08195798844099045
test loss item: 0.08145157247781754
test loss item: 0.09647808223962784
test loss item: 0.9185895919799805
test loss item: 0.20565928518772125
test loss item: 0.09985433518886566
test loss item: 0.05809378996491432
test loss item: 0.5524559020996094
test loss item: 0.45255061984062195
test loss item: 0.6334043741226196
test loss item: 0.10138460993766785
test loss item: 0.10951843857765198
test loss item: 0.06644600629806519
test loss item: 0.06308668106794357
test loss item: 0.118233323097229
Epoch [21/100], Training Loss: 0.1917, Testing Loss: 0.2067
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 22/100
train loss item: 0.14890582859516144
train loss item: 0.19979031383991241
train loss item: 0.08192097395658493
train loss item: 0.1527116745710373
train loss item: 0.14797814190387726
train loss item: 0.135580375790596
train loss item: 0.08016309887170792
train loss item: 0.24711813032627106
train loss item: 0.06811525672674179
train loss item: 0.10381712019443512
train loss item: 0.09834492951631546
train loss item: 0.0950620099902153
train loss item: 0.07739761471748352
train loss item: 0.2174617201089859
train loss item: 0.10831392556428909
train loss item: 0.214199960231781
train loss item: 0.046967942267656326
train loss item: 0.12222672253847122
train loss item: 0.13102398812770844
train loss item: 0.08898033946752548
train loss item: 0.12373831123113632
train loss item: 0.057915057986974716
train loss item: 0.22332659363746643
train loss item: 0.24819715321063995
train loss item: 0.200128436088562
train loss item: 0.09544608741998672
train loss item: 0.07856176048517227
train loss item: 0.10713132470846176
train loss item: 0.05628504231572151
train loss item: 0.2305794507265091
train loss item: 0.3751309812068939
train loss item: 0.21766704320907593
train loss item: 0.07865100353956223
train loss item: 0.1285650134086609
train loss item: 0.08515049517154694
train loss item: 0.9386415481567383
train loss item: 0.23511184751987457
train loss item: 0.21522001922130585
train loss item: 0.1562938392162323
train loss item: 0.10040852427482605
train loss item: 0.08913658559322357
train loss item: 0.09490229189395905
train loss item: 0.13388875126838684
train loss item: 0.09562502801418304
train loss item: 0.22259867191314697
train loss item: 0.06993260979652405
train loss item: 0.0689227283000946
train loss item: 0.1380372941493988
train loss item: 0.10049675405025482
train loss item: 0.07050846517086029
train loss item: 0.1049865186214447
train loss item: 0.33396726846694946
train loss item: 0.05489085987210274
train loss item: 0.0690569058060646
train loss item: 0.8000507950782776
train loss item: 0.10383781045675278
train loss item: 0.11780330538749695
train loss item: 0.10331344604492188
train loss item: 0.06534377485513687
train loss item: 0.09012465178966522
train loss item: 0.16964581608772278
train loss item: 0.4735524654388428
train loss item: 0.08613743633031845
train loss item: 0.1387217491865158
train loss item: 0.07456868141889572
train loss item: 0.1822081357240677
train loss item: 0.13648389279842377
train loss item: 0.11056884378194809
train loss item: 0.12760715186595917
train loss item: 0.12296741455793381
train loss item: 0.09481561183929443
train loss item: 0.08807685971260071
train loss item: 0.06672346591949463
train loss item: 0.12440889328718185
train loss item: 0.04591817408800125
train loss item: 0.06439235806465149
train loss item: 0.1747753769159317
train loss item: 0.7760055661201477
train loss item: 0.04151163995265961
train loss item: 0.11017883569002151
train loss item: 0.06366907805204391
train loss item: 0.0867842584848404
train loss item: 0.0874348133802414
train loss item: 0.21805298328399658
train loss item: 0.14146459102630615
train loss item: 0.14505691826343536
train loss item: 2.1055829524993896
train loss item: 0.07881630212068558
train loss item: 0.10432320833206177
test loss item: 0.09176786988973618
test loss item: 0.07907422631978989
test loss item: 0.3965409994125366
test loss item: 0.11748477071523666
test loss item: 0.15864922106266022
test loss item: 0.08786353468894958
test loss item: 1.0070909261703491
test loss item: 0.3242752254009247
test loss item: 0.14855006337165833
test loss item: 0.2281511127948761
test loss item: 0.5863711833953857
test loss item: 0.08499044924974442
test loss item: 0.11348558962345123
test loss item: 0.1630782037973404
test loss item: 0.11106762290000916
test loss item: 0.06073547527194023
test loss item: 0.14627407491207123
test loss item: 0.24786891043186188
test loss item: 0.3493945002555847
test loss item: 0.13600414991378784
test loss item: 0.4072399139404297
test loss item: 0.20802155137062073
test loss item: 0.15707404911518097
test loss item: 0.10250139981508255
test loss item: 0.10919123142957687
test loss item: 0.11894121766090393
test loss item: 0.16150543093681335
test loss item: 0.11813491582870483
test loss item: 0.1850748360157013
test loss item: 0.17410622537136078
test loss item: 0.528076171875
test loss item: 0.05117194727063179
test loss item: 0.09214282035827637
test loss item: 0.3059292435646057
test loss item: 0.2544437646865845
test loss item: 0.23636290431022644
test loss item: 0.4427729547023773
test loss item: 0.9975634813308716
test loss item: 0.26665008068084717
test loss item: 0.1531136929988861
test loss item: 0.16328564286231995
test loss item: 0.09651373326778412
test loss item: 0.18393872678279877
test loss item: 0.11506769061088562
test loss item: 0.3186096251010895
test loss item: 0.2118527740240097
test loss item: 0.14309236407279968
test loss item: 0.11268569529056549
test loss item: 0.29704612493515015
test loss item: 0.4116440713405609
test loss item: 0.18644505739212036
test loss item: 0.07432358711957932
test loss item: 0.13926303386688232
test loss item: 0.08483421057462692
test loss item: 0.17488586902618408
test loss item: 0.5639650821685791
test loss item: 0.3200269341468811
test loss item: 0.13686072826385498
test loss item: 0.13220416009426117
test loss item: 0.125906839966774
test loss item: 0.23240254819393158
test loss item: 0.14095263183116913
test loss item: 0.11106818914413452
test loss item: 0.1345556229352951
test loss item: 0.6036826372146606
test loss item: 0.15526430308818817
test loss item: 0.16945137083530426
test loss item: 0.13796845078468323
test loss item: 0.30809715390205383
test loss item: 0.24510714411735535
test loss item: 0.06296510994434357
test loss item: 0.5455877780914307
test loss item: 0.16131822764873505
test loss item: 0.2014799863100052
test loss item: 0.09098132699728012
test loss item: 0.08732252568006516
test loss item: 0.10107102990150452
test loss item: 1.1045708656311035
test loss item: 0.245956689119339
test loss item: 0.11255544424057007
test loss item: 0.06638874858617783
test loss item: 0.6410332322120667
test loss item: 0.5057010650634766
test loss item: 0.7558287978172302
test loss item: 0.11835617572069168
test loss item: 0.11692115664482117
test loss item: 0.07398315519094467
test loss item: 0.06338014453649521
test loss item: 0.11125127971172333
Epoch [22/100], Training Loss: 0.1762, Testing Loss: 0.2372
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 23/100
train loss item: 0.14319415390491486
train loss item: 0.19260720908641815
train loss item: 0.0807110145688057
train loss item: 0.18117649853229523
train loss item: 0.14926202595233917
train loss item: 0.11611593514680862
train loss item: 0.09842626005411148
train loss item: 0.22747308015823364
train loss item: 0.0629965141415596
train loss item: 0.1104515790939331
train loss item: 0.12136571109294891
train loss item: 0.09687932580709457
train loss item: 0.06977084279060364
train loss item: 0.17637798190116882
train loss item: 0.09358823299407959
train loss item: 0.3001490831375122
train loss item: 0.04732193797826767
train loss item: 0.09010288864374161
train loss item: 0.12731367349624634
train loss item: 0.08449462056159973
train loss item: 0.11403568089008331
train loss item: 0.06455639749765396
train loss item: 0.22754909098148346
train loss item: 0.2000322937965393
train loss item: 0.1637369841337204
train loss item: 0.08728449791669846
train loss item: 0.07870852947235107
train loss item: 0.09525356441736221
train loss item: 0.04559539631009102
train loss item: 0.24876587092876434
train loss item: 0.3950861692428589
train loss item: 0.20490692555904388
train loss item: 0.06602094322443008
train loss item: 0.1259695589542389
train loss item: 0.07339488714933395
train loss item: 0.9180137515068054
train loss item: 0.16344712674617767
train loss item: 0.16466350853443146
train loss item: 0.15637251734733582
train loss item: 0.09992432594299316
train loss item: 0.07716027647256851
train loss item: 0.09882722049951553
train loss item: 0.1226179227232933
train loss item: 0.08769088238477707
train loss item: 0.21256349980831146
train loss item: 0.06724955886602402
train loss item: 0.05416419357061386
train loss item: 0.11245273053646088
train loss item: 0.089556485414505
train loss item: 0.07357151061296463
train loss item: 0.09372550249099731
train loss item: 0.3333500623703003
train loss item: 0.05128925293684006
train loss item: 0.06216990947723389
train loss item: 0.7611236572265625
train loss item: 0.09289994835853577
train loss item: 0.10528232902288437
train loss item: 0.10041353851556778
train loss item: 0.07454473525285721
train loss item: 0.09340980648994446
train loss item: 0.18688881397247314
train loss item: 0.4450734853744507
train loss item: 0.08330558240413666
train loss item: 0.1214013546705246
train loss item: 0.06877153366804123
train loss item: 0.15487077832221985
train loss item: 0.15129566192626953
train loss item: 0.09951885789632797
train loss item: 0.11787080019712448
train loss item: 0.13563621044158936
train loss item: 0.09738568961620331
train loss item: 0.06914966553449631
train loss item: 0.06789351999759674
train loss item: 0.11992016434669495
train loss item: 0.04756375029683113
train loss item: 0.06322970986366272
train loss item: 0.21210850775241852
train loss item: 0.7591753005981445
train loss item: 0.05175303295254707
train loss item: 0.12093869596719742
train loss item: 0.0610027052462101
train loss item: 0.09706909954547882
train loss item: 0.07604657113552094
train loss item: 0.23075196146965027
train loss item: 0.13907408714294434
train loss item: 0.12934976816177368
train loss item: 2.0482239723205566
train loss item: 0.07223653793334961
train loss item: 0.10754828155040741
test loss item: 0.09362801164388657
test loss item: 0.06327463686466217
test loss item: 0.3683127760887146
test loss item: 0.11827598512172699
test loss item: 0.14121170341968536
test loss item: 0.07629646360874176
test loss item: 1.0364705324172974
test loss item: 0.3512451946735382
test loss item: 0.13535362482070923
test loss item: 0.21023236215114594
test loss item: 0.5392427444458008
test loss item: 0.08118179440498352
test loss item: 0.10635137557983398
test loss item: 0.15793056786060333
test loss item: 0.10137435048818588
test loss item: 0.049519818276166916
test loss item: 0.15794111788272858
test loss item: 0.22914135456085205
test loss item: 0.3649093210697174
test loss item: 0.14464908838272095
test loss item: 0.3654778301715851
test loss item: 0.22504675388336182
test loss item: 0.14412710070610046
test loss item: 0.10455404222011566
test loss item: 0.10525164753198624
test loss item: 0.12464883923530579
test loss item: 0.1604352444410324
test loss item: 0.10245287418365479
test loss item: 0.17554576694965363
test loss item: 0.166422501206398
test loss item: 0.5081188678741455
test loss item: 0.04407869651913643
test loss item: 0.09176571667194366
test loss item: 0.2872382402420044
test loss item: 0.23309694230556488
test loss item: 0.22946713864803314
test loss item: 0.4519232511520386
test loss item: 0.9089640378952026
test loss item: 0.24901296198368073
test loss item: 0.15974535048007965
test loss item: 0.16982188820838928
test loss item: 0.10195960849523544
test loss item: 0.16479265689849854
test loss item: 0.12287305295467377
test loss item: 0.2828370928764343
test loss item: 0.23077653348445892
test loss item: 0.13681010901927948
test loss item: 0.12060262262821198
test loss item: 0.2810707688331604
test loss item: 0.39261364936828613
test loss item: 0.15794162452220917
test loss item: 0.07320919632911682
test loss item: 0.1379811018705368
test loss item: 0.08593831211328506
test loss item: 0.15839314460754395
test loss item: 0.5148986577987671
test loss item: 0.31725630164146423
test loss item: 0.1202336773276329
test loss item: 0.13365502655506134
test loss item: 0.11376795172691345
test loss item: 0.2114540934562683
test loss item: 0.15476642549037933
test loss item: 0.12145436555147171
test loss item: 0.12878192961215973
test loss item: 0.5649636387825012
test loss item: 0.15804335474967957
test loss item: 0.17711997032165527
test loss item: 0.13738872110843658
test loss item: 0.2888014614582062
test loss item: 0.2560621500015259
test loss item: 0.04873163625597954
test loss item: 0.5774869918823242
test loss item: 0.14715899527072906
test loss item: 0.2212376743555069
test loss item: 0.08434297889471054
test loss item: 0.0823482945561409
test loss item: 0.1017695814371109
test loss item: 1.0017895698547363
test loss item: 0.2322467416524887
test loss item: 0.10428841412067413
test loss item: 0.05468130111694336
test loss item: 0.6173256635665894
test loss item: 0.5007847547531128
test loss item: 0.6876994371414185
test loss item: 0.11140982806682587
test loss item: 0.12011753767728806
test loss item: 0.05676545202732086
test loss item: 0.052659958600997925
test loss item: 0.11833131313323975
Epoch [23/100], Training Loss: 0.1704, Testing Loss: 0.2281
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 24/100
train loss item: 0.12640179693698883
train loss item: 0.2087373286485672
train loss item: 0.07438095659017563
train loss item: 0.19225212931632996
train loss item: 0.12593066692352295
train loss item: 0.10953840613365173
train loss item: 0.074263796210289
train loss item: 0.1683800369501114
train loss item: 0.046047717332839966
train loss item: 0.09363365918397903
train loss item: 0.11395661532878876
train loss item: 0.10135866701602936
train loss item: 0.06600926071405411
train loss item: 0.15524224936962128
train loss item: 0.07910973578691483
train loss item: 0.21623705327510834
train loss item: 0.04552784562110901
train loss item: 0.09543430060148239
train loss item: 0.11104576289653778
train loss item: 0.09273654222488403
train loss item: 0.11337023973464966
train loss item: 0.05628761649131775
train loss item: 0.193311408162117
train loss item: 0.1500566154718399
train loss item: 0.14503568410873413
train loss item: 0.08877845853567123
train loss item: 0.07452421635389328
train loss item: 0.11042238771915436
train loss item: 0.04207519441843033
train loss item: 0.2464127540588379
train loss item: 0.544380247592926
train loss item: 0.17355093359947205
train loss item: 0.0650784820318222
train loss item: 0.11574406921863556
train loss item: 0.07400315999984741
train loss item: 0.8635215759277344
train loss item: 0.20760555565357208
train loss item: 0.1836131364107132
train loss item: 0.1974605917930603
train loss item: 0.12427306920289993
train loss item: 0.09138956665992737
train loss item: 0.11380346864461899
train loss item: 0.14378146827220917
train loss item: 0.101064033806324
train loss item: 0.2684113383293152
train loss item: 0.06994832307100296
train loss item: 0.07051323354244232
train loss item: 0.14988134801387787
train loss item: 0.1123797595500946
train loss item: 0.07109372317790985
train loss item: 0.09407944977283478
train loss item: 0.34938880801200867
train loss item: 0.05630740150809288
train loss item: 0.07349485158920288
train loss item: 0.6982879042625427
train loss item: 0.07810521125793457
train loss item: 0.10794668644666672
train loss item: 0.09877961128950119
train loss item: 0.06952420622110367
train loss item: 0.08795103430747986
train loss item: 0.21972981095314026
train loss item: 0.4021749198436737
train loss item: 0.09876633435487747
train loss item: 0.15488986670970917
train loss item: 0.06849558651447296
train loss item: 0.15404927730560303
train loss item: 0.17115740478038788
train loss item: 0.09500377625226974
train loss item: 0.14196152985095978
train loss item: 0.10295511782169342
train loss item: 0.11386123299598694
train loss item: 0.08315002918243408
train loss item: 0.06743375211954117
train loss item: 0.1080310195684433
train loss item: 0.05058891326189041
train loss item: 0.0660831555724144
train loss item: 0.19813446700572968
train loss item: 0.7264655828475952
train loss item: 0.04004129767417908
train loss item: 0.11420049518346786
train loss item: 0.07116582244634628
train loss item: 0.0851704552769661
train loss item: 0.0771804228425026
train loss item: 0.2099476456642151
train loss item: 0.14618009328842163
train loss item: 0.20436254143714905
train loss item: 2.001056671142578
train loss item: 0.07202596217393875
train loss item: 0.12265851348638535
test loss item: 0.08677498996257782
test loss item: 0.06912492960691452
test loss item: 0.4218963086605072
test loss item: 0.11301400512456894
test loss item: 0.1608816236257553
test loss item: 0.07149245589971542
test loss item: 1.1585527658462524
test loss item: 0.3730762004852295
test loss item: 0.16248080134391785
test loss item: 0.25339940190315247
test loss item: 0.6291850209236145
test loss item: 0.07921066880226135
test loss item: 0.11545559018850327
test loss item: 0.17117196321487427
test loss item: 0.11782639473676682
test loss item: 0.04727546125650406
test loss item: 0.1458299160003662
test loss item: 0.28010815382003784
test loss item: 0.3823509216308594
test loss item: 0.13518844544887543
test loss item: 0.460959255695343
test loss item: 0.2262686938047409
test loss item: 0.16759517788887024
test loss item: 0.09442189335823059
test loss item: 0.11408089846372604
test loss item: 0.12253027409315109
test loss item: 0.17043109238147736
test loss item: 0.11302109062671661
test loss item: 0.1925455927848816
test loss item: 0.1954832673072815
test loss item: 0.5958478450775146
test loss item: 0.0427393801510334
test loss item: 0.08070001006126404
test loss item: 0.3329484164714813
test loss item: 0.2777784466743469
test loss item: 0.274095743894577
test loss item: 0.49184247851371765
test loss item: 1.0781131982803345
test loss item: 0.29589927196502686
test loss item: 0.15463224053382874
test loss item: 0.1708701103925705
test loss item: 0.09016507118940353
test loss item: 0.22172480821609497
test loss item: 0.12341444194316864
test loss item: 0.3689977824687958
test loss item: 0.20484982430934906
test loss item: 0.16206997632980347
test loss item: 0.12137421220541
test loss item: 0.3168964684009552
test loss item: 0.4588637351989746
test loss item: 0.22432991862297058
test loss item: 0.07842867821455002
test loss item: 0.1563090831041336
test loss item: 0.08702881634235382
test loss item: 0.20378515124320984
test loss item: 0.6080583930015564
test loss item: 0.3494749069213867
test loss item: 0.19419097900390625
test loss item: 0.14085881412029266
test loss item: 0.14049503207206726
test loss item: 0.26963144540786743
test loss item: 0.1423015296459198
test loss item: 0.10811755806207657
test loss item: 0.13041327893733978
test loss item: 0.6366650462150574
test loss item: 0.15560874342918396
test loss item: 0.16868256032466888
test loss item: 0.1377941220998764
test loss item: 0.32169845700263977
test loss item: 0.2815452814102173
test loss item: 0.04337726905941963
test loss item: 0.6211268901824951
test loss item: 0.1836702674627304
test loss item: 0.2089075744152069
test loss item: 0.08105332404375076
test loss item: 0.073115773499012
test loss item: 0.09530579298734665
test loss item: 1.1783521175384521
test loss item: 0.25451919436454773
test loss item: 0.09863246232271194
test loss item: 0.04286617785692215
test loss item: 0.7066425681114197
test loss item: 0.5747305154800415
test loss item: 0.8145034909248352
test loss item: 0.12070772796869278
test loss item: 0.11939100176095963
test loss item: 0.045863863080739975
test loss item: 0.044445574283599854
test loss item: 0.10567831248044968
Epoch [24/100], Training Loss: 0.1701, Testing Loss: 0.2544
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 25/100
train loss item: 0.18456509709358215
train loss item: 0.5058474540710449
train loss item: 0.08792674541473389
train loss item: 0.1681753545999527
train loss item: 0.11880222707986832
train loss item: 0.10816740989685059
train loss item: 0.07361849397420883
train loss item: 0.352373868227005
train loss item: 0.0646866112947464
train loss item: 0.12260184437036514
train loss item: 0.1539887636899948
train loss item: 0.09886974841356277
train loss item: 0.07219687104225159
train loss item: 0.16709496080875397
train loss item: 0.10069537162780762
train loss item: 0.1829042285680771
train loss item: 0.039576008915901184
train loss item: 0.07761250436306
train loss item: 0.12772369384765625
train loss item: 0.0831783339381218
train loss item: 0.08223289251327515
train loss item: 0.05543588846921921
train loss item: 0.1988777369260788
train loss item: 0.19479253888130188
train loss item: 0.15369102358818054
train loss item: 0.0761834979057312
train loss item: 0.08250127732753754
train loss item: 0.09235882014036179
train loss item: 0.04738583788275719
train loss item: 0.23850978910923004
train loss item: 0.28422313928604126
train loss item: 0.21848635375499725
train loss item: 0.07037859410047531
train loss item: 0.11709257960319519
train loss item: 0.07692539691925049
train loss item: 0.8950580954551697
train loss item: 0.17802931368350983
train loss item: 0.15852494537830353
train loss item: 0.15991371870040894
train loss item: 0.10539181530475616
train loss item: 0.07412552088499069
train loss item: 0.08323090523481369
train loss item: 0.11322607845067978
train loss item: 0.09609900414943695
train loss item: 0.2196916788816452
train loss item: 0.07200770080089569
train loss item: 0.08274903893470764
train loss item: 0.10786332935094833
train loss item: 0.08357709646224976
train loss item: 0.07403065264225006
train loss item: 0.09656453132629395
train loss item: 0.2852330803871155
train loss item: 0.05644204095005989
train loss item: 0.06273243576288223
train loss item: 0.7325578331947327
train loss item: 0.07806694507598877
train loss item: 0.08852501213550568
train loss item: 0.09593997150659561
train loss item: 0.06250906735658646
train loss item: 0.0796598419547081
train loss item: 0.17599855363368988
train loss item: 0.3605818748474121
train loss item: 0.08650317788124084
train loss item: 0.12432650476694107
train loss item: 0.07149795442819595
train loss item: 0.24524377286434174
train loss item: 0.1579209864139557
train loss item: 0.09212233126163483
train loss item: 0.11320673674345016
train loss item: 0.10513316839933395
train loss item: 0.0916263684630394
train loss item: 0.07539153844118118
train loss item: 0.07480045408010483
train loss item: 0.14181916415691376
train loss item: 0.044309165328741074
train loss item: 0.0639597475528717
train loss item: 0.20945623517036438
train loss item: 0.7416404485702515
train loss item: 0.04192415252327919
train loss item: 0.1340421885251999
train loss item: 0.05918734893202782
train loss item: 0.08386021107435226
train loss item: 0.07543635368347168
train loss item: 0.21177957952022552
train loss item: 0.14366598427295685
train loss item: 0.2369878739118576
train loss item: 1.9637683629989624
train loss item: 0.06178582087159157
train loss item: 0.11097245663404465
test loss item: 0.08770354092121124
test loss item: 0.05673906207084656
test loss item: 0.33417630195617676
test loss item: 0.11035500466823578
test loss item: 0.12726937234401703
test loss item: 0.061810579150915146
test loss item: 0.9497482776641846
test loss item: 0.2787630558013916
test loss item: 0.1222415566444397
test loss item: 0.18700505793094635
test loss item: 0.5267153382301331
test loss item: 0.0746617391705513
test loss item: 0.09236004948616028
test loss item: 0.13752929866313934
test loss item: 0.09145088493824005
test loss item: 0.04674850404262543
test loss item: 0.1400274634361267
test loss item: 0.19900164008140564
test loss item: 0.3234134614467621
test loss item: 0.12271855771541595
test loss item: 0.3209298849105835
test loss item: 0.19141274690628052
test loss item: 0.12384437769651413
test loss item: 0.08978942036628723
test loss item: 0.09512399137020111
test loss item: 0.11493046581745148
test loss item: 0.14758194983005524
test loss item: 0.08873506635427475
test loss item: 0.158710315823555
test loss item: 0.15504184365272522
test loss item: 0.46757757663726807
test loss item: 0.041705504059791565
test loss item: 0.07996297627687454
test loss item: 0.2598513662815094
test loss item: 0.20804791152477264
test loss item: 0.20513524115085602
test loss item: 0.40442460775375366
test loss item: 0.8871987462043762
test loss item: 0.2251385748386383
test loss item: 0.14015495777130127
test loss item: 0.15926234424114227
test loss item: 0.08679166436195374
test loss item: 0.14646954834461212
test loss item: 0.11056225746870041
test loss item: 0.25291872024536133
test loss item: 0.19918836653232574
test loss item: 0.1157444417476654
test loss item: 0.10481086373329163
test loss item: 0.24378150701522827
test loss item: 0.367124080657959
test loss item: 0.1401771456003189
test loss item: 0.06736762821674347
test loss item: 0.12370990961790085
test loss item: 0.07948331534862518
test loss item: 0.14165614545345306
test loss item: 0.48721060156822205
test loss item: 0.2879621088504791
test loss item: 0.10636088997125626
test loss item: 0.11736931651830673
test loss item: 0.09794344007968903
test loss item: 0.18679143488407135
test loss item: 0.12548664212226868
test loss item: 0.10333487391471863
test loss item: 0.12158115953207016
test loss item: 0.5251365900039673
test loss item: 0.15469521284103394
test loss item: 0.15705803036689758
test loss item: 0.1297764778137207
test loss item: 0.265796035528183
test loss item: 0.21602877974510193
test loss item: 0.03957870975136757
test loss item: 0.5155026912689209
test loss item: 0.12436328083276749
test loss item: 0.19031639397144318
test loss item: 0.07195527106523514
test loss item: 0.06765273958444595
test loss item: 0.08972320705652237
test loss item: 0.9750146865844727
test loss item: 0.2182772159576416
test loss item: 0.08820756524801254
test loss item: 0.04876067861914635
test loss item: 0.5821065306663513
test loss item: 0.4571473300457001
test loss item: 0.6643699407577515
test loss item: 0.10499333590269089
test loss item: 0.105842724442482
test loss item: 0.04837445914745331
test loss item: 0.04516054317355156
test loss item: 0.10975417494773865
Epoch [25/100], Training Loss: 0.1699, Testing Loss: 0.2072
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.1736449897289276
loss item: 0.10621494799852371
loss item: 1.0051759481430054
loss item: 0.4776678681373596
loss item: 0.2866295576095581
loss item: 0.18531279265880585
loss item: 0.10572293400764465
loss item: 0.4227024018764496
loss item: 0.10118666291236877
loss item: 0.09879206866025925
loss item: 0.4956504702568054
loss item: 0.03454211726784706
loss item: 0.43597814440727234
loss item: 0.11068452149629593
loss item: 0.15428778529167175
loss item: 0.1195409893989563
loss item: 0.16372300684452057
loss item: 0.33181872963905334
loss item: 0.5203383564949036
loss item: 0.2128572314977646
loss item: 0.16695475578308105
loss item: 0.09962993860244751
loss item: 0.12537486851215363
loss item: 0.11705609411001205
loss item: 0.14171606302261353
loss item: 0.36031532287597656
loss item: 0.6423415541648865
loss item: 0.08407345414161682
loss item: 0.06921972334384918
loss item: 0.16805310547351837
loss item: 0.5475948452949524
loss item: 0.9400992393493652
loss item: 0.0871560126543045
loss item: 0.27195313572883606
loss item: 0.08864274621009827
loss item: 0.07078208029270172
loss item: 0.18516647815704346
loss item: 0.1134558767080307
loss item: 0.21536487340927124
loss item: 0.35527631640434265
loss item: 0.5793418884277344
loss item: 0.10451672971248627
loss item: 0.09457170218229294
loss item: 0.033540647476911545
Val Loss: 0.2547
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.0001 2 360 done at Tue Nov 12 12:26:55 CET 2024
UNet2 with 1 100 0.0005 2 360 start at Tue Nov 12 12:26:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 0.9121710062026978
train loss item: 2.170234203338623
train loss item: 0.5969551205635071
train loss item: 1.0422260761260986
train loss item: 1.5058915615081787
train loss item: 0.5180912613868713
train loss item: 0.49037230014801025
train loss item: 1.20503830909729
train loss item: 0.3879775404930115
train loss item: 0.5143818259239197
train loss item: 0.5442823171615601
train loss item: 0.36353808641433716
train loss item: 0.29374197125434875
train loss item: 0.721674382686615
train loss item: 0.36487895250320435
train loss item: 1.0422148704528809
train loss item: 0.3247540593147278
train loss item: 0.384751558303833
train loss item: 0.43143996596336365
train loss item: 0.3903164863586426
train loss item: 0.29459139704704285
train loss item: 0.29048487544059753
train loss item: 1.4911901950836182
train loss item: 1.181415319442749
train loss item: 0.7108883857727051
train loss item: 0.34139105677604675
train loss item: 0.26552310585975647
train loss item: 0.2971615195274353
train loss item: 0.22646090388298035
train loss item: 0.9468911290168762
train loss item: 2.5608320236206055
train loss item: 0.6372052431106567
train loss item: 0.31347858905792236
train loss item: 0.43792685866355896
train loss item: 0.38778653740882874
train loss item: 2.403876781463623
train loss item: 0.5180559158325195
train loss item: 0.454937607049942
train loss item: 0.48163050413131714
train loss item: 0.3169960379600525
train loss item: 0.2842999994754791
train loss item: 0.3337368071079254
train loss item: 0.34325841069221497
train loss item: 0.279103547334671
train loss item: 0.7303104996681213
train loss item: 0.1806126981973648
train loss item: 0.15928435325622559
train loss item: 0.5602288246154785
train loss item: 0.2483481913805008
train loss item: 0.18493935465812683
train loss item: 0.46334409713745117
train loss item: 1.1570740938186646
train loss item: 0.17289067804813385
train loss item: 0.21393296122550964
train loss item: 2.263690710067749
train loss item: 0.20760658383369446
train loss item: 0.3315351903438568
train loss item: 0.26603835821151733
train loss item: 0.22858698666095734
train loss item: 0.19368278980255127
train loss item: 0.973995566368103
train loss item: 2.126312017440796
train loss item: 0.24449199438095093
train loss item: 0.3856185972690582
train loss item: 0.19268381595611572
train loss item: 0.6291232705116272
train loss item: 0.40863367915153503
train loss item: 0.21679054200649261
train loss item: 0.2938111126422882
train loss item: 0.30855199694633484
train loss item: 0.27151304483413696
train loss item: 0.13652412593364716
train loss item: 0.38320818543434143
train loss item: 0.30155375599861145
train loss item: 0.10533125698566437
train loss item: 0.13810761272907257
train loss item: 0.8903178572654724
train loss item: 1.3625606298446655
train loss item: 0.09041062742471695
train loss item: 0.23317070305347443
train loss item: 0.1384125053882599
train loss item: 0.19903598725795746
train loss item: 0.20897766947746277
train loss item: 0.5486323237419128
train loss item: 0.3172820210456848
train loss item: 0.5693963766098022
train loss item: 4.145247459411621
train loss item: 0.18814411759376526
train loss item: 0.5067338347434998
test loss item: 0.18382667005062103
test loss item: 0.1365739405155182
test loss item: 0.41083237528800964
test loss item: 0.20865187048912048
test loss item: 0.23717115819454193
test loss item: 0.14262163639068604
test loss item: 1.1516164541244507
test loss item: 0.35866788029670715
test loss item: 0.17445608973503113
test loss item: 0.3129975199699402
test loss item: 0.6522586345672607
test loss item: 0.14945241808891296
test loss item: 0.171150341629982
test loss item: 0.34414222836494446
test loss item: 0.1705307960510254
test loss item: 0.10266879945993423
test loss item: 0.23076732456684113
test loss item: 0.3608337640762329
test loss item: 0.544313371181488
test loss item: 0.25117790699005127
test loss item: 0.5959290862083435
test loss item: 0.2902483344078064
test loss item: 0.24555017054080963
test loss item: 0.1689915955066681
test loss item: 0.18852053582668304
test loss item: 0.21177612245082855
test loss item: 0.2947025001049042
test loss item: 0.1973285973072052
test loss item: 0.2959226965904236
test loss item: 0.29615315794944763
test loss item: 0.536732017993927
test loss item: 0.08419773727655411
test loss item: 0.15306773781776428
test loss item: 0.46644914150238037
test loss item: 0.32823216915130615
test loss item: 0.41984784603118896
test loss item: 0.6306807398796082
test loss item: 1.0158989429473877
test loss item: 0.3773774802684784
test loss item: 0.23498357832431793
test loss item: 0.25026214122772217
test loss item: 0.19293440878391266
test loss item: 0.2925140857696533
test loss item: 0.158233180642128
test loss item: 0.5004450082778931
test loss item: 0.33732032775878906
test loss item: 0.26091742515563965
test loss item: 0.263500452041626
test loss item: 0.34794875979423523
test loss item: 0.5313205122947693
test loss item: 0.2480410784482956
test loss item: 0.13761262595653534
test loss item: 0.18840177357196808
test loss item: 0.14149489998817444
test loss item: 0.2472057044506073
test loss item: 0.6557876467704773
test loss item: 0.4453950822353363
test loss item: 0.24746428430080414
test loss item: 0.19734199345111847
test loss item: 0.1877332180738449
test loss item: 0.37474972009658813
test loss item: 0.1691061109304428
test loss item: 0.19565612077713013
test loss item: 0.22545501589775085
test loss item: 0.6118927597999573
test loss item: 0.2756834328174591
test loss item: 0.2549784481525421
test loss item: 0.2315780222415924
test loss item: 0.4494320750236511
test loss item: 0.3653990924358368
test loss item: 0.11065135896205902
test loss item: 0.6585938930511475
test loss item: 0.3180546462535858
test loss item: 0.30787891149520874
test loss item: 0.13355079293251038
test loss item: 0.1778392493724823
test loss item: 0.17012012004852295
test loss item: 0.9754599928855896
test loss item: 0.44219520688056946
test loss item: 0.19612756371498108
test loss item: 0.10388363897800446
test loss item: 0.666232705116272
test loss item: 0.6712315082550049
test loss item: 0.6759641170501709
test loss item: 0.19929556548595428
test loss item: 0.18416278064250946
test loss item: 0.09515104442834854
test loss item: 0.07982451468706131
test loss item: 0.18442845344543457
Epoch [1/100], Training Loss: 0.6076, Testing Loss: 0.3221
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/100
train loss item: 0.4450467824935913
train loss item: 0.9824851155281067
train loss item: 0.21558232605457306
train loss item: 0.42215126752853394
train loss item: 0.6178328394889832
train loss item: 0.28241294622421265
train loss item: 0.30494824051856995
train loss item: 0.6950170993804932
train loss item: 0.1655249297618866
train loss item: 0.33107244968414307
train loss item: 0.28655171394348145
train loss item: 0.26815223693847656
train loss item: 0.13096314668655396
train loss item: 0.4538443088531494
train loss item: 0.27114224433898926
train loss item: 0.9579570889472961
train loss item: 0.09154451638460159
train loss item: 0.2752035856246948
train loss item: 0.30435267090797424
train loss item: 0.32244816422462463
train loss item: 0.2022254765033722
train loss item: 0.26377323269844055
train loss item: 1.119254469871521
train loss item: 0.8012851476669312
train loss item: 0.6551558375358582
train loss item: 0.23846478760242462
train loss item: 0.19877980649471283
train loss item: 0.2451377660036087
train loss item: 0.1369827836751938
train loss item: 0.572328507900238
train loss item: 1.978947639465332
train loss item: 0.565528154373169
train loss item: 0.1641027182340622
train loss item: 0.34206950664520264
train loss item: 0.1470012068748474
train loss item: 2.097047805786133
train loss item: 0.6329845786094666
train loss item: 0.4981410503387451
train loss item: 0.6575279831886292
train loss item: 0.24326637387275696
train loss item: 0.24258162081241608
train loss item: 0.3306500017642975
train loss item: 0.3179427981376648
train loss item: 0.25048205256462097
train loss item: 0.7904554009437561
train loss item: 0.16197244822978973
train loss item: 0.14376601576805115
train loss item: 0.3770570158958435
train loss item: 0.24924957752227783
train loss item: 0.19223685562610626
train loss item: 0.28537946939468384
train loss item: 1.1084059476852417
train loss item: 0.10132535547018051
train loss item: 0.1369573473930359
train loss item: 2.324069023132324
train loss item: 0.20837727189064026
train loss item: 0.3174915313720703
train loss item: 0.28133657574653625
train loss item: 0.19239932298660278
train loss item: 0.1410199999809265
train loss item: 0.681387186050415
train loss item: 1.9687566757202148
train loss item: 0.2386859804391861
train loss item: 0.3375028371810913
train loss item: 0.16946417093276978
train loss item: 0.5486193299293518
train loss item: 0.35398101806640625
train loss item: 0.20696553587913513
train loss item: 0.430447518825531
train loss item: 0.30450165271759033
train loss item: 0.1973540484905243
train loss item: 0.12412653863430023
train loss item: 0.264680951833725
train loss item: 0.24869383871555328
train loss item: 0.07241223007440567
train loss item: 0.10423339903354645
train loss item: 0.6838665008544922
train loss item: 1.1029239892959595
train loss item: 0.11991212517023087
train loss item: 0.34055137634277344
train loss item: 0.2376936376094818
train loss item: 0.22207514941692352
train loss item: 0.19671185314655304
train loss item: 0.43061715364456177
train loss item: 0.3548765480518341
train loss item: 0.4760364294052124
train loss item: 3.758190393447876
train loss item: 0.20226047933101654
train loss item: 0.3746556341648102
test loss item: 0.19860294461250305
test loss item: 0.16763918101787567
test loss item: 0.3776116669178009
test loss item: 0.2312430739402771
test loss item: 0.23198853433132172
test loss item: 0.16190336644649506
test loss item: 1.7505863904953003
test loss item: 0.8248295187950134
test loss item: 0.20095330476760864
test loss item: 0.3044755160808563
test loss item: 0.5963309407234192
test loss item: 0.1799955666065216
test loss item: 0.22195079922676086
test loss item: 0.2653982937335968
test loss item: 0.19353701174259186
test loss item: 0.13066476583480835
test loss item: 0.2951430082321167
test loss item: 0.2901497483253479
test loss item: 0.8098485469818115
test loss item: 0.3268722593784332
test loss item: 0.45391082763671875
test loss item: 0.40904268622398376
test loss item: 0.25762489438056946
test loss item: 0.21307724714279175
test loss item: 0.17604738473892212
test loss item: 0.23431158065795898
test loss item: 0.31705668568611145
test loss item: 0.20268899202346802
test loss item: 0.30793607234954834
test loss item: 0.28738275170326233
test loss item: 0.6604254245758057
test loss item: 0.11647699773311615
test loss item: 0.1937674731016159
test loss item: 0.38305869698524475
test loss item: 0.26640674471855164
test loss item: 0.48732510209083557
test loss item: 0.9094134569168091
test loss item: 0.8626341223716736
test loss item: 0.3273560404777527
test loss item: 0.2847084105014801
test loss item: 0.278881311416626
test loss item: 0.2099149525165558
test loss item: 0.2599063217639923
test loss item: 0.19041453301906586
test loss item: 0.3781915009021759
test loss item: 0.47249093651771545
test loss item: 0.2731265127658844
test loss item: 0.2991393208503723
test loss item: 0.3833793103694916
test loss item: 0.6031829714775085
test loss item: 0.2429240345954895
test loss item: 0.1715661585330963
test loss item: 0.1906546801328659
test loss item: 0.14224794507026672
test loss item: 0.21324504911899567
test loss item: 0.5300920605659485
test loss item: 0.6109102964401245
test loss item: 0.23838183283805847
test loss item: 0.237455815076828
test loss item: 0.20286518335342407
test loss item: 0.30572667717933655
test loss item: 0.3051105737686157
test loss item: 0.23982074856758118
test loss item: 0.24700404703617096
test loss item: 0.7333677411079407
test loss item: 0.281881719827652
test loss item: 0.323552668094635
test loss item: 0.2532437741756439
test loss item: 0.38946694135665894
test loss item: 0.5930938124656677
test loss item: 0.12627960741519928
test loss item: 1.1162447929382324
test loss item: 0.2930023670196533
test loss item: 0.41839808225631714
test loss item: 0.1805458664894104
test loss item: 0.1960008293390274
test loss item: 0.21575488150119781
test loss item: 0.8007816076278687
test loss item: 0.34831586480140686
test loss item: 0.20295676589012146
test loss item: 0.12327347695827484
test loss item: 0.8743233680725098
test loss item: 0.8888064026832581
test loss item: 0.6278346180915833
test loss item: 0.22114606201648712
test loss item: 0.2312389463186264
test loss item: 0.11335611343383789
test loss item: 0.11128176003694534
test loss item: 0.1671617478132248
Epoch [2/100], Training Loss: 0.4774, Testing Loss: 0.3614
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/100
train loss item: 0.38973310589790344
train loss item: 0.962831974029541
train loss item: 0.2257280945777893
train loss item: 0.39786016941070557
train loss item: 0.3033396303653717
train loss item: 0.22412295639514923
train loss item: 0.1730143129825592
train loss item: 0.5492135882377625
train loss item: 0.16046284139156342
train loss item: 0.24987687170505524
train loss item: 0.2951280474662781
train loss item: 0.2154567539691925
train loss item: 0.11340955644845963
train loss item: 0.38544753193855286
train loss item: 0.2479952871799469
train loss item: 0.5814380645751953
train loss item: 0.06240956112742424
train loss item: 0.2345605343580246
train loss item: 0.24789609014987946
train loss item: 0.284737229347229
train loss item: 0.20858030021190643
train loss item: 0.1913047581911087
train loss item: 0.5606221556663513
train loss item: 0.6167322993278503
train loss item: 0.4534231722354889
train loss item: 0.22152921557426453
train loss item: 0.1968296319246292
train loss item: 0.23196372389793396
train loss item: 0.08845347911119461
train loss item: 0.533560574054718
train loss item: 1.6304466724395752
train loss item: 0.445546418428421
train loss item: 0.1249990239739418
train loss item: 0.28321075439453125
train loss item: 0.10605650395154953
train loss item: 1.905516505241394
train loss item: 0.48714926838874817
train loss item: 0.3565372824668884
train loss item: 0.5079442262649536
train loss item: 0.1747109591960907
train loss item: 0.19162829220294952
train loss item: 0.28207963705062866
train loss item: 0.33359429240226746
train loss item: 0.21607887744903564
train loss item: 0.7087498903274536
train loss item: 0.15903741121292114
train loss item: 0.1305241882801056
train loss item: 0.5008075833320618
train loss item: 0.2014252245426178
train loss item: 0.12284860014915466
train loss item: 0.32262328267097473
train loss item: 1.0107548236846924
train loss item: 0.06589873135089874
train loss item: 0.18449075520038605
train loss item: 1.892109990119934
train loss item: 0.16044487059116364
train loss item: 0.22927556931972504
train loss item: 0.18706855177879333
train loss item: 0.17526745796203613
train loss item: 0.09595169872045517
train loss item: 0.6438320875167847
train loss item: 1.7525357007980347
train loss item: 0.16533923149108887
train loss item: 0.326094388961792
train loss item: 0.12513422966003418
train loss item: 0.37169259786605835
train loss item: 0.3780488073825836
train loss item: 0.14991970360279083
train loss item: 0.34156277775764465
train loss item: 0.25614476203918457
train loss item: 0.22481834888458252
train loss item: 0.106841541826725
train loss item: 0.146328404545784
train loss item: 0.2284623384475708
train loss item: 0.08163304626941681
train loss item: 0.09982149302959442
train loss item: 0.4963840842247009
train loss item: 1.0956441164016724
train loss item: 0.11939243227243423
train loss item: 0.20589585602283478
train loss item: 0.18293018639087677
train loss item: 0.19615966081619263
train loss item: 0.21735478937625885
train loss item: 0.3943558931350708
train loss item: 0.3952179253101349
train loss item: 0.3338661789894104
train loss item: 3.356621503829956
train loss item: 0.13862977921962738
train loss item: 0.3322161138057709
test loss item: 0.2357233315706253
test loss item: 0.12224382162094116
test loss item: 0.3366797864437103
test loss item: 0.2022504359483719
test loss item: 0.1962735652923584
test loss item: 0.1540890485048294
test loss item: 1.5304021835327148
test loss item: 0.5346867442131042
test loss item: 0.16943030059337616
test loss item: 0.24887891113758087
test loss item: 0.5265551209449768
test loss item: 0.15484286844730377
test loss item: 0.19578316807746887
test loss item: 0.5511397123336792
test loss item: 0.14466997981071472
test loss item: 0.08225420117378235
test loss item: 0.2665351927280426
test loss item: 0.24092034995555878
test loss item: 0.5896663665771484
test loss item: 0.3382899761199951
test loss item: 0.3562913239002228
test loss item: 0.34012410044670105
test loss item: 0.39423689246177673
test loss item: 0.18663717806339264
test loss item: 0.1339767575263977
test loss item: 0.22958111763000488
test loss item: 0.30059272050857544
test loss item: 0.17733702063560486
test loss item: 0.2783944010734558
test loss item: 0.2602711617946625
test loss item: 0.5581129789352417
test loss item: 0.0803426057100296
test loss item: 0.16662649810314178
test loss item: 0.2917434871196747
test loss item: 0.2219845950603485
test loss item: 0.37289994955062866
test loss item: 0.6973702907562256
test loss item: 0.7881031036376953
test loss item: 0.2719917893409729
test loss item: 0.2544759511947632
test loss item: 0.2548745274543762
test loss item: 0.3624008595943451
test loss item: 0.2002364546060562
test loss item: 0.1782834529876709
test loss item: 0.3861173987388611
test loss item: 0.4087575078010559
test loss item: 0.384825199842453
test loss item: 0.3668269217014313
test loss item: 0.292622447013855
test loss item: 0.4744592308998108
test loss item: 0.21224838495254517
test loss item: 0.18967925012111664
test loss item: 0.17851608991622925
test loss item: 0.1377674788236618
test loss item: 0.19652384519577026
test loss item: 0.4296087324619293
test loss item: 0.4515147805213928
test loss item: 0.37149935960769653
test loss item: 0.23075100779533386
test loss item: 0.16033795475959778
test loss item: 0.23390592634677887
test loss item: 0.23445174098014832
test loss item: 0.27567893266677856
test loss item: 0.20886369049549103
test loss item: 0.5995132923126221
test loss item: 0.24867822229862213
test loss item: 0.30342820286750793
test loss item: 0.2174699902534485
test loss item: 0.28447839617729187
test loss item: 0.3809455633163452
test loss item: 0.08075584471225739
test loss item: 0.8982266783714294
test loss item: 0.45710811018943787
test loss item: 0.42396801710128784
test loss item: 0.18412521481513977
test loss item: 0.3200153708457947
test loss item: 0.18819200992584229
test loss item: 0.7700259685516357
test loss item: 0.5689490437507629
test loss item: 0.24971751868724823
test loss item: 0.0896703228354454
test loss item: 0.7487494349479675
test loss item: 0.6999984383583069
test loss item: 0.5846561193466187
test loss item: 0.26152050495147705
test loss item: 0.22341984510421753
test loss item: 0.07608854025602341
test loss item: 0.06809332221746445
test loss item: 0.22198233008384705
Epoch [3/100], Training Loss: 0.4007, Testing Loss: 0.3276
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/100
train loss item: 0.30188924074172974
train loss item: 0.7359023094177246
train loss item: 0.22139397263526917
train loss item: 0.2632397711277008
train loss item: 0.30720850825309753
train loss item: 0.20169687271118164
train loss item: 0.19678451120853424
train loss item: 0.4718441367149353
train loss item: 0.11791804432868958
train loss item: 0.18766212463378906
train loss item: 0.1974048912525177
train loss item: 0.1702798753976822
train loss item: 0.10563228279352188
train loss item: 0.3803000748157501
train loss item: 0.19350972771644592
train loss item: 0.512162983417511
train loss item: 0.07337002456188202
train loss item: 0.16044948995113373
train loss item: 0.22858047485351562
train loss item: 0.198069229722023
train loss item: 0.14832089841365814
train loss item: 0.11870917677879333
train loss item: 0.6211161017417908
train loss item: 0.5854637026786804
train loss item: 0.43456506729125977
train loss item: 0.18959490954875946
train loss item: 0.1214519739151001
train loss item: 0.1789051592350006
train loss item: 0.08676064759492874
train loss item: 0.3124096989631653
train loss item: 1.2388684749603271
train loss item: 0.6585726141929626
train loss item: 0.10945712774991989
train loss item: 0.19693715870380402
train loss item: 0.11325451731681824
train loss item: 1.7327842712402344
train loss item: 0.35835495591163635
train loss item: 0.26887279748916626
train loss item: 0.2869821786880493
train loss item: 0.20208460092544556
train loss item: 0.17955832183361053
train loss item: 0.21974436938762665
train loss item: 0.26068782806396484
train loss item: 0.15225322544574738
train loss item: 0.45804017782211304
train loss item: 0.09115089476108551
train loss item: 0.07979317009449005
train loss item: 0.30913814902305603
train loss item: 0.14546902477741241
train loss item: 0.16005277633666992
train loss item: 0.18137779831886292
train loss item: 0.5510744452476501
train loss item: 0.07234867662191391
train loss item: 0.13205961883068085
train loss item: 1.536494493484497
train loss item: 0.12552987039089203
train loss item: 0.1811203509569168
train loss item: 0.12800326943397522
train loss item: 0.12297999858856201
train loss item: 0.1280650794506073
train loss item: 0.32614782452583313
train loss item: 1.366019606590271
train loss item: 0.11132433265447617
train loss item: 0.28222042322158813
train loss item: 0.10837530344724655
train loss item: 0.3541455566883087
train loss item: 0.29666197299957275
train loss item: 0.13588641583919525
train loss item: 0.32518574595451355
train loss item: 0.20332001149654388
train loss item: 0.1714216023683548
train loss item: 0.11118603497743607
train loss item: 0.19826658070087433
train loss item: 0.1931086927652359
train loss item: 0.06407307088375092
train loss item: 0.11572521179914474
train loss item: 0.4524994492530823
train loss item: 1.0491267442703247
train loss item: 0.07417601346969604
train loss item: 0.2122175395488739
train loss item: 0.11623495817184448
train loss item: 0.19236987829208374
train loss item: 0.1460619419813156
train loss item: 0.44869324564933777
train loss item: 0.2683336138725281
train loss item: 0.21894073486328125
train loss item: 3.13515305519104
train loss item: 0.14630362391471863
train loss item: 0.22743500769138336
test loss item: 0.15796661376953125
test loss item: 0.10089419782161713
test loss item: 0.47785428166389465
test loss item: 0.18094928562641144
test loss item: 0.1842438131570816
test loss item: 0.09784842282533646
test loss item: 1.8177101612091064
test loss item: 0.7232916355133057
test loss item: 0.19340316951274872
test loss item: 0.2866206467151642
test loss item: 0.7911630868911743
test loss item: 0.12759758532047272
test loss item: 0.17946889996528625
test loss item: 0.2689952552318573
test loss item: 0.13238732516765594
test loss item: 0.09001730382442474
test loss item: 0.26892679929733276
test loss item: 0.2744421362876892
test loss item: 0.7028907537460327
test loss item: 0.28726258873939514
test loss item: 0.3994845151901245
test loss item: 0.38342878222465515
test loss item: 0.2501713037490845
test loss item: 0.1592433601617813
test loss item: 0.13999980688095093
test loss item: 0.19122138619422913
test loss item: 0.25996696949005127
test loss item: 0.13844554126262665
test loss item: 0.2523357570171356
test loss item: 0.2498805820941925
test loss item: 0.7851254940032959
test loss item: 0.07226786762475967
test loss item: 0.1312382072210312
test loss item: 0.3548513352870941
test loss item: 0.2806259095668793
test loss item: 0.3913733661174774
test loss item: 0.8282175660133362
test loss item: 1.3055803775787354
test loss item: 0.31071245670318604
test loss item: 0.24234020709991455
test loss item: 0.2712748944759369
test loss item: 0.191110298037529
test loss item: 0.22453589737415314
test loss item: 0.18877704441547394
test loss item: 0.31872156262397766
test loss item: 0.4089086353778839
test loss item: 0.23962631821632385
test loss item: 0.26535147428512573
test loss item: 0.38357260823249817
test loss item: 0.646457850933075
test loss item: 0.19099612534046173
test loss item: 0.13748601078987122
test loss item: 0.18724919855594635
test loss item: 0.12100420147180557
test loss item: 0.188573956489563
test loss item: 0.6925323009490967
test loss item: 0.5670812726020813
test loss item: 0.19244951009750366
test loss item: 0.2036101073026657
test loss item: 0.15440115332603455
test loss item: 0.2575732469558716
test loss item: 0.2717863619327545
test loss item: 0.2079562395811081
test loss item: 0.20432358980178833
test loss item: 0.8179131746292114
test loss item: 0.2387838512659073
test loss item: 0.294543594121933
test loss item: 0.22394590079784393
test loss item: 0.3617265522480011
test loss item: 0.4911554753780365
test loss item: 0.08195216208696365
test loss item: 1.078870415687561
test loss item: 0.28423675894737244
test loss item: 0.3899293839931488
test loss item: 0.15475842356681824
test loss item: 0.1698804646730423
test loss item: 0.16256949305534363
test loss item: 1.3574399948120117
test loss item: 0.3633885085582733
test loss item: 0.1577959656715393
test loss item: 0.06614798307418823
test loss item: 1.021561861038208
test loss item: 0.8716553449630737
test loss item: 0.977820634841919
test loss item: 0.19915449619293213
test loss item: 0.19512847065925598
test loss item: 0.060291629284620285
test loss item: 0.06537129729986191
test loss item: 0.13091856241226196
Epoch [4/100], Training Loss: 0.3309, Testing Loss: 0.3528
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/100
train loss item: 0.30876392126083374
train loss item: 0.798743486404419
train loss item: 0.1466309279203415
train loss item: 0.26477497816085815
train loss item: 0.2775145173072815
train loss item: 0.16874192655086517
train loss item: 0.10298900306224823
train loss item: 0.3225151598453522
train loss item: 0.09951147437095642
train loss item: 0.21607831120491028
train loss item: 0.22030004858970642
train loss item: 0.19161024689674377
train loss item: 0.09188918024301529
train loss item: 0.2958415746688843
train loss item: 0.15136849880218506
train loss item: 0.5231916308403015
train loss item: 0.0785447508096695
train loss item: 0.20142802596092224
train loss item: 0.22451381385326385
train loss item: 0.2336554080247879
train loss item: 0.16799846291542053
train loss item: 0.15681277215480804
train loss item: 0.5091790556907654
train loss item: 0.39574143290519714
train loss item: 0.3284384608268738
train loss item: 0.15654955804347992
train loss item: 0.1276269257068634
train loss item: 0.18329556286334991
train loss item: 0.062443289905786514
train loss item: 0.39322683215141296
train loss item: 1.0935899019241333
train loss item: 0.5144051313400269
train loss item: 0.11490015685558319
train loss item: 0.2486310601234436
train loss item: 0.09568172693252563
train loss item: 1.5532777309417725
train loss item: 0.47664207220077515
train loss item: 0.3295429050922394
train loss item: 0.38812682032585144
train loss item: 0.17344458401203156
train loss item: 0.1632068008184433
train loss item: 0.27988651394844055
train loss item: 0.314984530210495
train loss item: 0.19462262094020844
train loss item: 0.6323772072792053
train loss item: 0.11303577572107315
train loss item: 0.082303486764431
train loss item: 0.5407932996749878
train loss item: 0.19223493337631226
train loss item: 0.1117454469203949
train loss item: 0.41157856583595276
train loss item: 1.2437630891799927
train loss item: 0.08182712644338608
train loss item: 0.24041825532913208
train loss item: 1.5919889211654663
train loss item: 0.14515456557273865
train loss item: 0.2113550305366516
train loss item: 0.1703301966190338
train loss item: 0.15415500104427338
train loss item: 0.08222673088312149
train loss item: 0.7614142298698425
train loss item: 1.3164666891098022
train loss item: 0.13320091366767883
train loss item: 0.22600385546684265
train loss item: 0.11719205975532532
train loss item: 0.3320624530315399
train loss item: 0.2856105864048004
train loss item: 0.20074397325515747
train loss item: 0.17533966898918152
train loss item: 0.20678302645683289
train loss item: 0.1738305538892746
train loss item: 0.10046520829200745
train loss item: 0.14805422723293304
train loss item: 0.21190793812274933
train loss item: 0.07256069779396057
train loss item: 0.08601905405521393
train loss item: 0.3641852140426636
train loss item: 1.1792025566101074
train loss item: 0.11194700747728348
train loss item: 0.16881226003170013
train loss item: 0.16833685338497162
train loss item: 0.15865465998649597
train loss item: 0.2197062224149704
train loss item: 0.3866024911403656
train loss item: 0.3743588924407959
train loss item: 0.22932472825050354
train loss item: 3.02262282371521
train loss item: 0.1425369679927826
train loss item: 0.2276652753353119
test loss item: 0.15937328338623047
test loss item: 0.0998629480600357
test loss item: 0.3559282720088959
test loss item: 0.17844152450561523
test loss item: 0.17283205687999725
test loss item: 0.11006734520196915
test loss item: 1.4120233058929443
test loss item: 0.49045366048812866
test loss item: 0.16333389282226562
test loss item: 0.22650296986103058
test loss item: 0.6162997484207153
test loss item: 0.13809296488761902
test loss item: 0.15214915573596954
test loss item: 0.27502262592315674
test loss item: 0.12907588481903076
test loss item: 0.06877302378416061
test loss item: 0.2135535478591919
test loss item: 0.22157827019691467
test loss item: 0.5499988198280334
test loss item: 0.23034662008285522
test loss item: 0.28923970460891724
test loss item: 0.2975213825702667
test loss item: 0.23077905178070068
test loss item: 0.14712922275066376
test loss item: 0.11927217245101929
test loss item: 0.1891576051712036
test loss item: 0.21197251975536346
test loss item: 0.1369839906692505
test loss item: 0.2209225445985794
test loss item: 0.2076273113489151
test loss item: 0.5951418280601501
test loss item: 0.06271064281463623
test loss item: 0.13158607482910156
test loss item: 0.28677842020988464
test loss item: 0.21693436801433563
test loss item: 0.320677250623703
test loss item: 0.6509897708892822
test loss item: 0.9661182761192322
test loss item: 0.24845516681671143
test loss item: 0.20785649120807648
test loss item: 0.21866652369499207
test loss item: 0.2260182946920395
test loss item: 0.1971810907125473
test loss item: 0.16176478564739227
test loss item: 0.2534262239933014
test loss item: 0.30705830454826355
test loss item: 0.23702673614025116
test loss item: 0.21773198246955872
test loss item: 0.2789459824562073
test loss item: 0.4888911247253418
test loss item: 0.16090774536132812
test loss item: 0.12704350054264069
test loss item: 0.1597982943058014
test loss item: 0.1390191614627838
test loss item: 0.1687808483839035
test loss item: 0.5242500305175781
test loss item: 0.43118563294410706
test loss item: 0.17374102771282196
test loss item: 0.17599348723888397
test loss item: 0.1476341187953949
test loss item: 0.21779023110866547
test loss item: 0.18291792273521423
test loss item: 0.20166848599910736
test loss item: 0.1720677614212036
test loss item: 0.5892134308815002
test loss item: 0.23195570707321167
test loss item: 0.2268012911081314
test loss item: 0.19175517559051514
test loss item: 0.2847616672515869
test loss item: 0.36454102396965027
test loss item: 0.07991635799407959
test loss item: 0.7971625328063965
test loss item: 0.2709095776081085
test loss item: 0.3204149901866913
test loss item: 0.13741111755371094
test loss item: 0.19239959120750427
test loss item: 0.14652103185653687
test loss item: 0.9715666770935059
test loss item: 0.31322917342185974
test loss item: 0.16768330335617065
test loss item: 0.0706145167350769
test loss item: 0.7706530094146729
test loss item: 0.6792054772377014
test loss item: 0.7011962532997131
test loss item: 0.16419580578804016
test loss item: 0.17890922725200653
test loss item: 0.05811399221420288
test loss item: 0.048298098146915436
test loss item: 0.18673491477966309
Epoch [5/100], Training Loss: 0.3444, Testing Loss: 0.2856
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/100
train loss item: 0.2917080819606781
train loss item: 0.7164972424507141
train loss item: 0.13147953152656555
train loss item: 0.27987632155418396
train loss item: 0.2843770384788513
train loss item: 0.16761453449726105
train loss item: 0.18670527637004852
train loss item: 0.30425891280174255
train loss item: 0.07394283264875412
train loss item: 0.1759185492992401
train loss item: 0.13590191304683685
train loss item: 0.14009998738765717
train loss item: 0.10980413854122162
train loss item: 0.2860727310180664
train loss item: 0.1465505063533783
train loss item: 0.4652364253997803
train loss item: 0.07492024451494217
train loss item: 0.13807737827301025
train loss item: 0.18985773622989655
train loss item: 0.16900129616260529
train loss item: 0.13784809410572052
train loss item: 0.0889962762594223
train loss item: 0.5139876008033752
train loss item: 0.3397894501686096
train loss item: 0.33003753423690796
train loss item: 0.13210749626159668
train loss item: 0.12008575350046158
train loss item: 0.1398990899324417
train loss item: 0.06145325303077698
train loss item: 0.3475208878517151
train loss item: 0.9327907562255859
train loss item: 0.6409381628036499
train loss item: 0.09340706467628479
train loss item: 0.1679791361093521
train loss item: 0.09055642038583755
train loss item: 1.4838801622390747
train loss item: 0.32300716638565063
train loss item: 0.2521241009235382
train loss item: 0.2714345157146454
train loss item: 0.18323397636413574
train loss item: 0.166553795337677
train loss item: 0.1785275787115097
train loss item: 0.24153459072113037
train loss item: 0.1433839052915573
train loss item: 0.35480931401252747
train loss item: 0.08396313339471817
train loss item: 0.06536415964365005
train loss item: 0.2773841619491577
train loss item: 0.1251276731491089
train loss item: 0.1365462988615036
train loss item: 0.14717444777488708
train loss item: 0.624744713306427
train loss item: 0.09118638932704926
train loss item: 0.12883266806602478
train loss item: 1.2921864986419678
train loss item: 0.09209629893302917
train loss item: 0.1720963418483734
train loss item: 0.12160768359899521
train loss item: 0.08742205053567886
train loss item: 0.09876390546560287
train loss item: 0.2677594721317291
train loss item: 1.1173241138458252
train loss item: 0.1364602893590927
train loss item: 0.3317979872226715
train loss item: 0.08516701310873032
train loss item: 0.32608267664909363
train loss item: 0.36743441224098206
train loss item: 0.12936784327030182
train loss item: 0.3030230700969696
train loss item: 0.19296792149543762
train loss item: 0.14675557613372803
train loss item: 0.08043692260980606
train loss item: 0.1650424599647522
train loss item: 0.18903164565563202
train loss item: 0.06022094562649727
train loss item: 0.10737326741218567
train loss item: 0.40374940633773804
train loss item: 0.9546975493431091
train loss item: 0.061884235590696335
train loss item: 0.21071948111057281
train loss item: 0.10144209861755371
train loss item: 0.1573868989944458
train loss item: 0.15529625117778778
train loss item: 0.38876670598983765
train loss item: 0.2260516732931137
train loss item: 0.2730070650577545
train loss item: 2.808455228805542
train loss item: 0.12663443386554718
train loss item: 0.30171656608581543
test loss item: 0.16291023790836334
test loss item: 0.1316870152950287
test loss item: 0.3362586796283722
test loss item: 0.16390013694763184
test loss item: 0.17450806498527527
test loss item: 0.11724290996789932
test loss item: 1.4796808958053589
test loss item: 0.5737841725349426
test loss item: 0.17808249592781067
test loss item: 0.2403831034898758
test loss item: 0.547875165939331
test loss item: 0.13837219774723053
test loss item: 0.21409356594085693
test loss item: 0.24027550220489502
test loss item: 0.1435481458902359
test loss item: 0.11822059005498886
test loss item: 0.24261727929115295
test loss item: 0.19831304252147675
test loss item: 0.5944935083389282
test loss item: 0.31974151730537415
test loss item: 0.28238704800605774
test loss item: 0.30169665813446045
test loss item: 0.2560037076473236
test loss item: 0.16345110535621643
test loss item: 0.1258791983127594
test loss item: 0.2054007351398468
test loss item: 0.27207669615745544
test loss item: 0.14851060509681702
test loss item: 0.23286229372024536
test loss item: 0.23042412102222443
test loss item: 0.5712546110153198
test loss item: 0.09682918339967728
test loss item: 0.14571547508239746
test loss item: 0.25883856415748596
test loss item: 0.19890688359737396
test loss item: 0.39480358362197876
test loss item: 0.6646092534065247
test loss item: 0.8090161681175232
test loss item: 0.23292215168476105
test loss item: 0.22034317255020142
test loss item: 0.22941870987415314
test loss item: 0.24336983263492584
test loss item: 0.20039378106594086
test loss item: 0.1642916202545166
test loss item: 0.23945172131061554
test loss item: 0.37840455770492554
test loss item: 0.2680114805698395
test loss item: 0.36549627780914307
test loss item: 0.2880374491214752
test loss item: 0.46363934874534607
test loss item: 0.1835060566663742
test loss item: 0.19311228394508362
test loss item: 0.17013147473335266
test loss item: 0.11956838518381119
test loss item: 0.17896594107151031
test loss item: 0.44195756316185
test loss item: 0.46528106927871704
test loss item: 0.18840336799621582
test loss item: 0.1985771507024765
test loss item: 0.1844901293516159
test loss item: 0.19149208068847656
test loss item: 0.21866105496883392
test loss item: 0.22055545449256897
test loss item: 0.20588934421539307
test loss item: 0.6184965968132019
test loss item: 0.19368413090705872
test loss item: 0.2691214382648468
test loss item: 0.21284855902194977
test loss item: 0.27421262860298157
test loss item: 0.4281408190727234
test loss item: 0.11771370470523834
test loss item: 0.8910461068153381
test loss item: 0.2904866635799408
test loss item: 0.3527377247810364
test loss item: 0.18256451189517975
test loss item: 0.22044122219085693
test loss item: 0.16440220177173615
test loss item: 0.8562572002410889
test loss item: 0.3048493564128876
test loss item: 0.17089883983135223
test loss item: 0.08924304693937302
test loss item: 0.742188572883606
test loss item: 0.6790769100189209
test loss item: 0.6293515563011169
test loss item: 0.1977211982011795
test loss item: 0.21315394341945648
test loss item: 0.08538328856229782
test loss item: 0.0882125124335289
test loss item: 0.11919327825307846
Epoch [6/100], Training Loss: 0.2913, Testing Loss: 0.2980
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/100
train loss item: 0.23642845451831818
train loss item: 0.6114261746406555
train loss item: 0.11677771061658859
train loss item: 0.30851274728775024
train loss item: 0.2074654996395111
train loss item: 0.15800844132900238
train loss item: 0.13778066635131836
train loss item: 0.2566604018211365
train loss item: 0.07851286977529526
train loss item: 0.1385602504014969
train loss item: 0.18616917729377747
train loss item: 0.14761871099472046
train loss item: 0.12545357644557953
train loss item: 0.3064710795879364
train loss item: 0.10190275311470032
train loss item: 0.3700750768184662
train loss item: 0.07921835035085678
train loss item: 0.1408969759941101
train loss item: 0.1782124638557434
train loss item: 0.18238042294979095
train loss item: 0.15545529127120972
train loss item: 0.10131403803825378
train loss item: 0.34511399269104004
train loss item: 0.33312222361564636
train loss item: 0.2412489801645279
train loss item: 0.1431073695421219
train loss item: 0.07144945859909058
train loss item: 0.2087114155292511
train loss item: 0.0827544778585434
train loss item: 0.3110613226890564
train loss item: 0.992316722869873
train loss item: 0.26410606503486633
train loss item: 0.08212482184171677
train loss item: 0.1356925219297409
train loss item: 0.10399218648672104
train loss item: 1.314005970954895
train loss item: 0.48527073860168457
train loss item: 0.3418334424495697
train loss item: 0.44083473086357117
train loss item: 0.13098931312561035
train loss item: 0.14885874092578888
train loss item: 0.24474021792411804
train loss item: 0.2567680776119232
train loss item: 0.18650200963020325
train loss item: 0.6664311289787292
train loss item: 0.11030696332454681
train loss item: 0.08061691373586655
train loss item: 0.3693235218524933
train loss item: 0.20380334556102753
train loss item: 0.11517776548862457
train loss item: 0.2107396125793457
train loss item: 0.8914800882339478
train loss item: 0.07098550349473953
train loss item: 0.10645077377557755
train loss item: 1.6246569156646729
train loss item: 0.1819508820772171
train loss item: 0.22665850818157196
train loss item: 0.18103565275669098
train loss item: 0.1662583202123642
train loss item: 0.13912077248096466
train loss item: 0.3666037619113922
train loss item: 1.0293904542922974
train loss item: 0.17090129852294922
train loss item: 0.2652342915534973
train loss item: 0.09085126221179962
train loss item: 0.28558576107025146
train loss item: 0.18048377335071564
train loss item: 0.12966099381446838
train loss item: 0.3150474429130554
train loss item: 0.18686586618423462
train loss item: 0.15360203385353088
train loss item: 0.09262467175722122
train loss item: 0.16439072787761688
train loss item: 0.14909562468528748
train loss item: 0.06858280301094055
train loss item: 0.08041397482156754
train loss item: 0.2994934916496277
train loss item: 0.8260104060173035
train loss item: 0.07220504432916641
train loss item: 0.18387876451015472
train loss item: 0.10946645587682724
train loss item: 0.16744039952754974
train loss item: 0.1588444858789444
train loss item: 0.4008985459804535
train loss item: 0.30262821912765503
train loss item: 0.2772354185581207
train loss item: 2.6872615814208984
train loss item: 0.09592457115650177
train loss item: 0.24442119896411896
test loss item: 0.19728083908557892
test loss item: 0.08782434463500977
test loss item: 0.2865208387374878
test loss item: 0.18069463968276978
test loss item: 0.15201792120933533
test loss item: 0.11487402021884918
test loss item: 1.9393181800842285
test loss item: 0.633217453956604
test loss item: 0.13507890701293945
test loss item: 0.20377226173877716
test loss item: 0.46524474024772644
test loss item: 0.13970428705215454
test loss item: 0.15076982975006104
test loss item: 0.43086421489715576
test loss item: 0.11186408251523972
test loss item: 0.057719647884368896
test loss item: 0.2589209973812103
test loss item: 0.19761241972446442
test loss item: 0.6222745776176453
test loss item: 0.2935413420200348
test loss item: 0.2904277741909027
test loss item: 0.3634813129901886
test loss item: 0.3222728371620178
test loss item: 0.17449651658535004
test loss item: 0.12335861474275589
test loss item: 0.22707946598529816
test loss item: 0.252035528421402
test loss item: 0.13504719734191895
test loss item: 0.2588658630847931
test loss item: 0.2132701426744461
test loss item: 0.6695393323898315
test loss item: 0.055996134877204895
test loss item: 0.14027190208435059
test loss item: 0.236637681722641
test loss item: 0.18302561342716217
test loss item: 0.4131903648376465
test loss item: 0.7532121539115906
test loss item: 0.608383297920227
test loss item: 0.26336559653282166
test loss item: 0.2737135887145996
test loss item: 0.28324124217033386
test loss item: 0.3028049170970917
test loss item: 0.14034363627433777
test loss item: 0.20313236117362976
test loss item: 0.30835166573524475
test loss item: 0.3806639015674591
test loss item: 0.32128822803497314
test loss item: 0.29561352729797363
test loss item: 0.2665465772151947
test loss item: 0.46266064047813416
test loss item: 0.16761162877082825
test loss item: 0.1418953537940979
test loss item: 0.18194836378097534
test loss item: 0.13025358319282532
test loss item: 0.16455575823783875
test loss item: 0.3493400812149048
test loss item: 0.48989230394363403
test loss item: 0.3108590245246887
test loss item: 0.19962872564792633
test loss item: 0.12639375030994415
test loss item: 0.166263148188591
test loss item: 0.2318428009748459
test loss item: 0.25177255272865295
test loss item: 0.1970125436782837
test loss item: 0.6107296347618103
test loss item: 0.2315664291381836
test loss item: 0.2766656279563904
test loss item: 0.22740262746810913
test loss item: 0.22180667519569397
test loss item: 0.40796101093292236
test loss item: 0.05932817608118057
test loss item: 1.1007517576217651
test loss item: 0.3719383478164673
test loss item: 0.4449438750743866
test loss item: 0.14768455922603607
test loss item: 0.2649192810058594
test loss item: 0.1787884682416916
test loss item: 0.6276689767837524
test loss item: 0.4563030004501343
test loss item: 0.20541158318519592
test loss item: 0.06781718134880066
test loss item: 0.8353351950645447
test loss item: 0.78038090467453
test loss item: 0.5194879174232483
test loss item: 0.21696949005126953
test loss item: 0.19533129036426544
test loss item: 0.055366117507219315
test loss item: 0.046035587787628174
test loss item: 0.19582557678222656
Epoch [7/100], Training Loss: 0.2931, Testing Loss: 0.3083
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/100
train loss item: 0.22049765288829803
train loss item: 0.5859778523445129
train loss item: 0.16289068758487701
train loss item: 0.28753578662872314
train loss item: 0.2663949429988861
train loss item: 0.1471584588289261
train loss item: 0.10576729476451874
train loss item: 0.5483301281929016
train loss item: 0.10709960758686066
train loss item: 0.21180902421474457
train loss item: 0.28622570633888245
train loss item: 0.1461382955312729
train loss item: 0.08172829449176788
train loss item: 0.31885984539985657
train loss item: 0.13059677183628082
train loss item: 0.32261931896209717
train loss item: 0.06185338273644447
train loss item: 0.12313506752252579
train loss item: 0.30748677253723145
train loss item: 0.19046518206596375
train loss item: 0.1508050262928009
train loss item: 0.06630118191242218
train loss item: 0.4601221978664398
train loss item: 0.39790472388267517
train loss item: 0.21642182767391205
train loss item: 0.21676155924797058
train loss item: 0.0832328051328659
train loss item: 0.15331366658210754
train loss item: 0.046637196093797684
train loss item: 0.3811744749546051
train loss item: 1.3000259399414062
train loss item: 0.32662075757980347
train loss item: 0.08836961537599564
train loss item: 0.2459234893321991
train loss item: 0.08655335754156113
train loss item: 1.2566885948181152
train loss item: 0.49425458908081055
train loss item: 0.3562023937702179
train loss item: 0.5695052742958069
train loss item: 0.25854307413101196
train loss item: 0.19059772789478302
train loss item: 0.18427731096744537
train loss item: 0.2573634386062622
train loss item: 0.16950106620788574
train loss item: 0.5306909680366516
train loss item: 0.0861043855547905
train loss item: 0.06407719105482101
train loss item: 0.32005739212036133
train loss item: 0.17531944811344147
train loss item: 0.12523186206817627
train loss item: 0.15436244010925293
train loss item: 0.6811726689338684
train loss item: 0.07526696473360062
train loss item: 0.16409023106098175
train loss item: 1.3971736431121826
train loss item: 0.11955282092094421
train loss item: 0.22035211324691772
train loss item: 0.12851466238498688
train loss item: 0.12186507135629654
train loss item: 0.11547775566577911
train loss item: 0.28252390027046204
train loss item: 0.9774957299232483
train loss item: 0.16108104586601257
train loss item: 0.25798583030700684
train loss item: 0.1410081833600998
train loss item: 0.2626829743385315
train loss item: 0.1784377247095108
train loss item: 0.14775416254997253
train loss item: 0.32357245683670044
train loss item: 0.18242265284061432
train loss item: 0.15950678288936615
train loss item: 0.10883340984582901
train loss item: 0.14049790799617767
train loss item: 0.16159076988697052
train loss item: 0.059981390833854675
train loss item: 0.07945573329925537
train loss item: 0.2882903814315796
train loss item: 0.8447588682174683
train loss item: 0.06608883291482925
train loss item: 0.16093508899211884
train loss item: 0.07790642231702805
train loss item: 0.12051970511674881
train loss item: 0.17716693878173828
train loss item: 0.4557928144931793
train loss item: 0.3844212293624878
train loss item: 0.23792032897472382
train loss item: 2.5815610885620117
train loss item: 0.11406875401735306
train loss item: 0.19860254228115082
test loss item: 0.1529030203819275
test loss item: 0.09998752921819687
test loss item: 0.3464123010635376
test loss item: 0.17188185453414917
test loss item: 0.16672013700008392
test loss item: 0.11919562518596649
test loss item: 1.8083631992340088
test loss item: 0.6050646305084229
test loss item: 0.1478196680545807
test loss item: 0.2202664613723755
test loss item: 0.5395500063896179
test loss item: 0.1294899880886078
test loss item: 0.14855866134166718
test loss item: 0.27637141942977905
test loss item: 0.12128302454948425
test loss item: 0.06471636891365051
test loss item: 0.26104915142059326
test loss item: 0.2179134637117386
test loss item: 0.5916587710380554
test loss item: 0.2735198438167572
test loss item: 0.30764642357826233
test loss item: 0.36145979166030884
test loss item: 0.2519563138484955
test loss item: 0.1746942102909088
test loss item: 0.1284617930650711
test loss item: 0.22489561140537262
test loss item: 0.23965178430080414
test loss item: 0.1460568904876709
test loss item: 0.2519727647304535
test loss item: 0.21493113040924072
test loss item: 0.6745867133140564
test loss item: 0.05489293858408928
test loss item: 0.1436416208744049
test loss item: 0.25849294662475586
test loss item: 0.21590399742126465
test loss item: 0.3265584707260132
test loss item: 0.7209525108337402
test loss item: 0.8123244047164917
test loss item: 0.27471107244491577
test loss item: 0.26671749353408813
test loss item: 0.2766426205635071
test loss item: 0.215915709733963
test loss item: 0.148620143532753
test loss item: 0.20078600943088531
test loss item: 0.2628563642501831
test loss item: 0.37335315346717834
test loss item: 0.23775418102741241
test loss item: 0.25688233971595764
test loss item: 0.29321810603141785
test loss item: 0.48121342062950134
test loss item: 0.16955424845218658
test loss item: 0.14130724966526031
test loss item: 0.19413435459136963
test loss item: 0.12250674515962601
test loss item: 0.18483878672122955
test loss item: 0.45819324254989624
test loss item: 0.45825761556625366
test loss item: 0.1785736382007599
test loss item: 0.20099863409996033
test loss item: 0.1344885677099228
test loss item: 0.1794498860836029
test loss item: 0.24312566220760345
test loss item: 0.23261189460754395
test loss item: 0.19195780158042908
test loss item: 0.6664904952049255
test loss item: 0.21223555505275726
test loss item: 0.28488656878471375
test loss item: 0.22523963451385498
test loss item: 0.24930483102798462
test loss item: 0.3845141530036926
test loss item: 0.06485873460769653
test loss item: 1.0456485748291016
test loss item: 0.29792875051498413
test loss item: 0.42311912775039673
test loss item: 0.14412380754947662
test loss item: 0.19107362627983093
test loss item: 0.177922785282135
test loss item: 0.8716745972633362
test loss item: 0.3459792137145996
test loss item: 0.1741134524345398
test loss item: 0.06528681516647339
test loss item: 0.8357605934143066
test loss item: 0.7468024492263794
test loss item: 0.6508201360702515
test loss item: 0.21833279728889465
test loss item: 0.18090470135211945
test loss item: 0.052669458091259
test loss item: 0.04380989819765091
test loss item: 0.1576373279094696
Epoch [8/100], Training Loss: 0.2964, Testing Loss: 0.3041
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/100
train loss item: 0.2419966757297516
train loss item: 0.5365004539489746
train loss item: 0.11577986925840378
train loss item: 0.22616221010684967
train loss item: 0.1262909173965454
train loss item: 0.13671191036701202
train loss item: 0.0924627035856247
train loss item: 0.2431391477584839
train loss item: 0.07346247881650925
train loss item: 0.1228218600153923
train loss item: 0.1616969108581543
train loss item: 0.12617318332195282
train loss item: 0.07462260872125626
train loss item: 0.2690737247467041
train loss item: 0.10194303095340729
train loss item: 0.2740916311740875
train loss item: 0.06181475147604942
train loss item: 0.10286026448011398
train loss item: 0.17018456757068634
train loss item: 0.14918629825115204
train loss item: 0.1365470141172409
train loss item: 0.06488648056983948
train loss item: 0.4123314321041107
train loss item: 0.3102053105831146
train loss item: 0.2100813388824463
train loss item: 0.12446913123130798
train loss item: 0.07638414949178696
train loss item: 0.15282613039016724
train loss item: 0.04843476414680481
train loss item: 0.37728190422058105
train loss item: 0.9780248403549194
train loss item: 0.2992061972618103
train loss item: 0.0819917544722557
train loss item: 0.1635037660598755
train loss item: 0.09805136173963547
train loss item: 1.1838546991348267
train loss item: 0.2528859078884125
train loss item: 0.3033710718154907
train loss item: 0.34106916189193726
train loss item: 0.2065534144639969
train loss item: 0.1671988070011139
train loss item: 0.16682417690753937
train loss item: 0.23498152196407318
train loss item: 0.1546565741300583
train loss item: 0.4361913800239563
train loss item: 0.0820150077342987
train loss item: 0.05822638422250748
train loss item: 0.2520652115345001
train loss item: 0.15215513110160828
train loss item: 0.10550374537706375
train loss item: 0.13489730656147003
train loss item: 0.5191693305969238
train loss item: 0.08769318461418152
train loss item: 0.13132143020629883
train loss item: 1.0467091798782349
train loss item: 0.08898348361253738
train loss item: 0.1837337613105774
train loss item: 0.11605241894721985
train loss item: 0.10152699053287506
train loss item: 0.10121393203735352
train loss item: 0.2818751633167267
train loss item: 0.7694605588912964
train loss item: 0.10490056127309799
train loss item: 0.18371796607971191
train loss item: 0.07745184004306793
train loss item: 0.2329491674900055
train loss item: 0.192063570022583
train loss item: 0.11005941778421402
train loss item: 0.2846924960613251
train loss item: 0.13408932089805603
train loss item: 0.09559139609336853
train loss item: 0.09608405828475952
train loss item: 0.10870886594057083
train loss item: 0.12569266557693481
train loss item: 0.06682699918746948
train loss item: 0.0876355990767479
train loss item: 0.2808050215244293
train loss item: 0.7616645693778992
train loss item: 0.05041808634996414
train loss item: 0.15996120870113373
train loss item: 0.0960361510515213
train loss item: 0.09999557584524155
train loss item: 0.1317289173603058
train loss item: 0.41948845982551575
train loss item: 0.3284982442855835
train loss item: 0.22730782628059387
train loss item: 2.449130058288574
train loss item: 0.0803440734744072
train loss item: 0.17254860699176788
test loss item: 0.1281537562608719
test loss item: 0.07008583098649979
test loss item: 0.3504422605037689
test loss item: 0.15222913026809692
test loss item: 0.14800098538398743
test loss item: 0.08326750248670578
test loss item: 1.7728780508041382
test loss item: 0.6419951319694519
test loss item: 0.14041152596473694
test loss item: 0.21616187691688538
test loss item: 0.5378171801567078
test loss item: 0.1139649897813797
test loss item: 0.14937078952789307
test loss item: 0.2274664342403412
test loss item: 0.10440336167812347
test loss item: 0.05461540445685387
test loss item: 0.2461981326341629
test loss item: 0.20580041408538818
test loss item: 0.6109062433242798
test loss item: 0.2630102038383484
test loss item: 0.3521655797958374
test loss item: 0.35522887110710144
test loss item: 0.22532570362091064
test loss item: 0.15292170643806458
test loss item: 0.11887702345848083
test loss item: 0.17476460337638855
test loss item: 0.2218804657459259
test loss item: 0.11596132069826126
test loss item: 0.22602948546409607
test loss item: 0.19083958864212036
test loss item: 0.6807311773300171
test loss item: 0.052562370896339417
test loss item: 0.12099797278642654
test loss item: 0.2611100673675537
test loss item: 0.20763103663921356
test loss item: 0.3508034944534302
test loss item: 0.7244864702224731
test loss item: 0.8263524174690247
test loss item: 0.2647746801376343
test loss item: 0.24184109270572662
test loss item: 0.2555787265300751
test loss item: 0.17541426420211792
test loss item: 0.15052133798599243
test loss item: 0.18450438976287842
test loss item: 0.28200000524520874
test loss item: 0.3693874776363373
test loss item: 0.21239116787910461
test loss item: 0.24282370507717133
test loss item: 0.3060855269432068
test loss item: 0.481405109167099
test loss item: 0.1587420403957367
test loss item: 0.11907210946083069
test loss item: 0.165733203291893
test loss item: 0.10704873502254486
test loss item: 0.15151095390319824
test loss item: 0.46849989891052246
test loss item: 0.48042598366737366
test loss item: 0.1798318475484848
test loss item: 0.182612806558609
test loss item: 0.11743686348199844
test loss item: 0.15856939554214478
test loss item: 0.2485342174768448
test loss item: 0.19908221065998077
test loss item: 0.17596082389354706
test loss item: 0.6853188872337341
test loss item: 0.19337968528270721
test loss item: 0.2638535797595978
test loss item: 0.2050429880619049
test loss item: 0.2693631052970886
test loss item: 0.42760229110717773
test loss item: 0.050103042274713516
test loss item: 1.0392444133758545
test loss item: 0.2692849040031433
test loss item: 0.3972293436527252
test loss item: 0.13345177471637726
test loss item: 0.15504895150661469
test loss item: 0.15600621700286865
test loss item: 0.9218890070915222
test loss item: 0.3024044632911682
test loss item: 0.14134760200977325
test loss item: 0.049744825810194016
test loss item: 0.8350850939750671
test loss item: 0.7472962737083435
test loss item: 0.6688566207885742
test loss item: 0.17933374643325806
test loss item: 0.1641400307416916
test loss item: 0.045671164989471436
test loss item: 0.0444897897541523
test loss item: 0.1218777522444725
Epoch [9/100], Training Loss: 0.2445, Testing Loss: 0.2935
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/100
train loss item: 0.206228569149971
train loss item: 0.49478110671043396
train loss item: 0.09272352606058121
train loss item: 0.22243531048297882
train loss item: 0.19625169038772583
train loss item: 0.1521158665418625
train loss item: 0.08723419159650803
train loss item: 0.22830389440059662
train loss item: 0.07036270946264267
train loss item: 0.15169212222099304
train loss item: 0.20166665315628052
train loss item: 0.11882169544696808
train loss item: 0.0752955824136734
train loss item: 0.2862299680709839
train loss item: 0.11533485352993011
train loss item: 0.23958274722099304
train loss item: 0.052134595811367035
train loss item: 0.10304943472146988
train loss item: 0.20852430164813995
train loss item: 0.16666476428508759
train loss item: 0.13567472994327545
train loss item: 0.07476091384887695
train loss item: 0.3251969516277313
train loss item: 0.35185080766677856
train loss item: 0.19292578101158142
train loss item: 0.11453232169151306
train loss item: 0.0697084590792656
train loss item: 0.12065647542476654
train loss item: 0.05295652523636818
train loss item: 0.3482625186443329
train loss item: 0.8224490880966187
train loss item: 0.2647131383419037
train loss item: 0.06957712024450302
train loss item: 0.17017364501953125
train loss item: 0.09610757976770401
train loss item: 1.071749210357666
train loss item: 0.21929921209812164
train loss item: 0.2941388487815857
train loss item: 0.3364157974720001
train loss item: 0.20316913723945618
train loss item: 0.17039059102535248
train loss item: 0.16272228956222534
train loss item: 0.2473621964454651
train loss item: 0.14734205603599548
train loss item: 0.41640228033065796
train loss item: 0.07140637934207916
train loss item: 0.06473581492900848
train loss item: 0.3393242657184601
train loss item: 0.15014755725860596
train loss item: 0.08986348658800125
train loss item: 0.16996513307094574
train loss item: 0.5761714577674866
train loss item: 0.0812893956899643
train loss item: 0.11372409015893936
train loss item: 0.9481659531593323
train loss item: 0.11357077956199646
train loss item: 0.18908020853996277
train loss item: 0.11592675745487213
train loss item: 0.12216278165578842
train loss item: 0.10178498923778534
train loss item: 0.27420639991760254
train loss item: 0.6744824647903442
train loss item: 0.09494097530841827
train loss item: 0.19157040119171143
train loss item: 0.07117465883493423
train loss item: 0.1899111568927765
train loss item: 0.1869058459997177
train loss item: 0.1297197788953781
train loss item: 0.2826390266418457
train loss item: 0.12904393672943115
train loss item: 0.09578840434551239
train loss item: 0.09955790638923645
train loss item: 0.09066516906023026
train loss item: 0.12273485958576202
train loss item: 0.054058682173490524
train loss item: 0.07948827743530273
train loss item: 0.26590538024902344
train loss item: 0.7040834426879883
train loss item: 0.04554302617907524
train loss item: 0.14806164801120758
train loss item: 0.08231613039970398
train loss item: 0.08518297970294952
train loss item: 0.11977273225784302
train loss item: 0.3733292818069458
train loss item: 0.29767459630966187
train loss item: 0.2957868278026581
train loss item: 2.383212089538574
train loss item: 0.08736629039049149
train loss item: 0.13981851935386658
test loss item: 0.13108763098716736
test loss item: 0.06826060265302658
test loss item: 0.3537612557411194
test loss item: 0.15740330517292023
test loss item: 0.14192791283130646
test loss item: 0.08342359215021133
test loss item: 1.8209093809127808
test loss item: 0.6312081813812256
test loss item: 0.14016346633434296
test loss item: 0.2143571525812149
test loss item: 0.5488119125366211
test loss item: 0.11733125895261765
test loss item: 0.1368931382894516
test loss item: 0.2623635232448578
test loss item: 0.10233656316995621
test loss item: 0.05276860296726227
test loss item: 0.2529563307762146
test loss item: 0.19742818176746368
test loss item: 0.5958837866783142
test loss item: 0.2619989514350891
test loss item: 0.3286401927471161
test loss item: 0.36382758617401123
test loss item: 0.22763603925704956
test loss item: 0.15531089901924133
test loss item: 0.12307708710432053
test loss item: 0.18310250341892242
test loss item: 0.22539550065994263
test loss item: 0.11221995949745178
test loss item: 0.23643836379051208
test loss item: 0.192268505692482
test loss item: 0.6980499029159546
test loss item: 0.0470288023352623
test loss item: 0.11990389972925186
test loss item: 0.26162412762641907
test loss item: 0.204112708568573
test loss item: 0.33779284358024597
test loss item: 0.7231641411781311
test loss item: 0.8478413820266724
test loss item: 0.27174440026283264
test loss item: 0.253848135471344
test loss item: 0.269727885723114
test loss item: 0.17896434664726257
test loss item: 0.14249539375305176
test loss item: 0.19547642767429352
test loss item: 0.27491769194602966
test loss item: 0.372214674949646
test loss item: 0.2094932645559311
test loss item: 0.22590412199497223
test loss item: 0.3028523623943329
test loss item: 0.48482394218444824
test loss item: 0.15526306629180908
test loss item: 0.10295826196670532
test loss item: 0.1717471480369568
test loss item: 0.11384014785289764
test loss item: 0.14718890190124512
test loss item: 0.4711464047431946
test loss item: 0.4707070589065552
test loss item: 0.18038588762283325
test loss item: 0.18188582360744476
test loss item: 0.10888805985450745
test loss item: 0.16507293283939362
test loss item: 0.2471906691789627
test loss item: 0.20112986862659454
test loss item: 0.18063268065452576
test loss item: 0.6802865862846375
test loss item: 0.20306891202926636
test loss item: 0.26739612221717834
test loss item: 0.21373941004276276
test loss item: 0.26238396763801575
test loss item: 0.3937948942184448
test loss item: 0.054097019135951996
test loss item: 1.0534484386444092
test loss item: 0.2801845371723175
test loss item: 0.4163300693035126
test loss item: 0.1286054402589798
test loss item: 0.15616698563098907
test loss item: 0.16017486155033112
test loss item: 0.9332191944122314
test loss item: 0.3284926414489746
test loss item: 0.14207378029823303
test loss item: 0.05073152482509613
test loss item: 0.8453572988510132
test loss item: 0.7547177672386169
test loss item: 0.6779764294624329
test loss item: 0.18743665516376495
test loss item: 0.16887277364730835
test loss item: 0.045090507715940475
test loss item: 0.042304787784814835
test loss item: 0.14459529519081116
Epoch [10/100], Training Loss: 0.2358, Testing Loss: 0.2958
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 11/100
train loss item: 0.21263597905635834
train loss item: 0.5121203064918518
train loss item: 0.1083182692527771
train loss item: 0.20309093594551086
train loss item: 0.12274979799985886
train loss item: 0.14424565434455872
train loss item: 0.09393052011728287
train loss item: 0.20281824469566345
train loss item: 0.05341019108891487
train loss item: 0.11676721274852753
train loss item: 0.16775822639465332
train loss item: 0.11330010741949081
train loss item: 0.06661110371351242
train loss item: 0.2827741205692291
train loss item: 0.10497891157865524
train loss item: 0.26420435309410095
train loss item: 0.044715095311403275
train loss item: 0.10468612611293793
train loss item: 0.12352808564901352
train loss item: 0.14481136202812195
train loss item: 0.13694719970226288
train loss item: 0.06607052683830261
train loss item: 0.2887785732746124
train loss item: 0.2540797293186188
train loss item: 0.19809739291667938
train loss item: 0.14391963183879852
train loss item: 0.07822918891906738
train loss item: 0.09191678464412689
train loss item: 0.04118559882044792
train loss item: 0.3154025673866272
train loss item: 0.7878845930099487
train loss item: 0.2433708757162094
train loss item: 0.07240711152553558
train loss item: 0.1545579582452774
train loss item: 0.07662185281515121
train loss item: 0.9719760417938232
train loss item: 0.2305735945701599
train loss item: 0.264175146818161
train loss item: 0.3154183626174927
train loss item: 0.15996922552585602
train loss item: 0.1987714022397995
train loss item: 0.1928189992904663
train loss item: 0.293905645608902
train loss item: 0.19919320940971375
train loss item: 0.4123716354370117
train loss item: 0.07290066033601761
train loss item: 0.0910959392786026
train loss item: 0.4687874913215637
train loss item: 0.17943790555000305
train loss item: 0.10325879603624344
train loss item: 0.27923229336738586
train loss item: 0.7811842560768127
train loss item: 0.0803903341293335
train loss item: 0.14225558936595917
train loss item: 0.9346196055412292
train loss item: 0.1304534524679184
train loss item: 0.19010378420352936
train loss item: 0.1417733132839203
train loss item: 0.10440955311059952
train loss item: 0.09681246429681778
train loss item: 0.25924158096313477
train loss item: 0.5776193737983704
train loss item: 0.11964220553636551
train loss item: 0.19337281584739685
train loss item: 0.09711579978466034
train loss item: 0.4306049644947052
train loss item: 0.1843077838420868
train loss item: 0.11374912410974503
train loss item: 0.26375341415405273
train loss item: 0.1474398374557495
train loss item: 0.1353817880153656
train loss item: 0.10540414601564407
train loss item: 0.11677287518978119
train loss item: 0.16178260743618011
train loss item: 0.05227043479681015
train loss item: 0.06687988340854645
train loss item: 0.24496068060398102
train loss item: 0.8337935209274292
train loss item: 0.054546602070331573
train loss item: 0.14301304519176483
train loss item: 0.10193595290184021
train loss item: 0.15389245748519897
train loss item: 0.12318271398544312
train loss item: 0.5807610750198364
train loss item: 0.3266814351081848
train loss item: 0.39892488718032837
train loss item: 2.1515891551971436
train loss item: 0.11691462248563766
train loss item: 0.2006549835205078
test loss item: 0.1457493007183075
test loss item: 0.10759910941123962
test loss item: 0.6390538215637207
test loss item: 0.1703810691833496
test loss item: 0.2395026534795761
test loss item: 0.11400911211967468
test loss item: 2.0388972759246826
test loss item: 0.6638120412826538
test loss item: 0.23522602021694183
test loss item: 0.3596581816673279
test loss item: 0.9230725765228271
test loss item: 0.13550026714801788
test loss item: 0.1720253974199295
test loss item: 0.2603509724140167
test loss item: 0.166624054312706
test loss item: 0.07225856184959412
test loss item: 0.26371529698371887
test loss item: 0.4032561779022217
test loss item: 0.6488907933235168
test loss item: 0.2766711711883545
test loss item: 0.6647763848304749
test loss item: 0.38429147005081177
test loss item: 0.29973486065864563
test loss item: 0.17632390558719635
test loss item: 0.16948267817497253
test loss item: 0.19750964641571045
test loss item: 0.279826283454895
test loss item: 0.17690922319889069
test loss item: 0.3120010197162628
test loss item: 0.2701711058616638
test loss item: 0.9379291534423828
test loss item: 0.06633785367012024
test loss item: 0.1408442109823227
test loss item: 0.48494061827659607
test loss item: 0.41299229860305786
test loss item: 0.3850891888141632
test loss item: 0.8138962984085083
test loss item: 1.5975263118743896
test loss item: 0.4376817047595978
test loss item: 0.28161197900772095
test loss item: 0.2857089638710022
test loss item: 0.18350853025913239
test loss item: 0.29377833008766174
test loss item: 0.20319364964962006
test loss item: 0.5151960253715515
test loss item: 0.3960404098033905
test loss item: 0.2723522186279297
test loss item: 0.21420814096927643
test loss item: 0.4771449863910675
test loss item: 0.7140097618103027
test loss item: 0.28776586055755615
test loss item: 0.10184413939714432
test loss item: 0.22224107384681702
test loss item: 0.12429890781641006
test loss item: 0.2768399715423584
test loss item: 0.90592360496521
test loss item: 0.5577138662338257
test loss item: 0.23642928898334503
test loss item: 0.21238307654857635
test loss item: 0.1838378608226776
test loss item: 0.36513641476631165
test loss item: 0.2564018666744232
test loss item: 0.20852869749069214
test loss item: 0.21404238045215607
test loss item: 1.0197606086730957
test loss item: 0.21275287866592407
test loss item: 0.3068534731864929
test loss item: 0.2369641810655594
test loss item: 0.47739776968955994
test loss item: 0.44858095049858093
test loss item: 0.0737990215420723
test loss item: 1.1547765731811523
test loss item: 0.33042922616004944
test loss item: 0.44122302532196045
test loss item: 0.13493172824382782
test loss item: 0.17193196713924408
test loss item: 0.18286773562431335
test loss item: 1.7389274835586548
test loss item: 0.42731887102127075
test loss item: 0.17458336055278778
test loss item: 0.0644616037607193
test loss item: 1.1402785778045654
test loss item: 0.9163548350334167
test loss item: 1.2112048864364624
test loss item: 0.21908313035964966
test loss item: 0.18672744929790497
test loss item: 0.05799488723278046
test loss item: 0.05661090463399887
test loss item: 0.11930709332227707
Epoch [11/100], Training Loss: 0.2430, Testing Loss: 0.4016
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 12/100
train loss item: 0.3369159400463104
train loss item: 0.8973458409309387
train loss item: 0.14532291889190674
train loss item: 0.3746832609176636
train loss item: 0.1679268330335617
train loss item: 0.15389440953731537
train loss item: 0.11417913436889648
train loss item: 0.5163671374320984
train loss item: 0.14347410202026367
train loss item: 0.2709548771381378
train loss item: 0.40105828642845154
train loss item: 0.16201260685920715
train loss item: 0.07928168773651123
train loss item: 0.27845534682273865
train loss item: 0.12709230184555054
train loss item: 0.30009910464286804
train loss item: 0.06252552568912506
train loss item: 0.1258075088262558
train loss item: 0.22254841029644012
train loss item: 0.12650029361248016
train loss item: 0.11573778092861176
train loss item: 0.09656839817762375
train loss item: 0.32113710045814514
train loss item: 0.5637792944908142
train loss item: 0.23215503990650177
train loss item: 0.15586526691913605
train loss item: 0.09546525776386261
train loss item: 0.1255180984735489
train loss item: 0.0830058678984642
train loss item: 0.3610224425792694
train loss item: 0.6823268532752991
train loss item: 0.30937400460243225
train loss item: 0.07823609560728073
train loss item: 0.18129831552505493
train loss item: 0.13777819275856018
train loss item: 0.9499320387840271
train loss item: 0.23575767874717712
train loss item: 0.2362300455570221
train loss item: 0.2637382745742798
train loss item: 0.1118226870894432
train loss item: 0.0987260565161705
train loss item: 0.16879914700984955
train loss item: 0.21679846942424774
train loss item: 0.14482378959655762
train loss item: 0.366876482963562
train loss item: 0.08441051840782166
train loss item: 0.06557741016149521
train loss item: 0.2601793110370636
train loss item: 0.12072160840034485
train loss item: 0.10058260709047318
train loss item: 0.15520142018795013
train loss item: 0.6042941212654114
train loss item: 0.06897511333227158
train loss item: 0.08855026960372925
train loss item: 0.826399564743042
train loss item: 0.07869221270084381
train loss item: 0.12992875277996063
train loss item: 0.12056334316730499
train loss item: 0.08470859378576279
train loss item: 0.08822444826364517
train loss item: 0.2821686863899231
train loss item: 0.5823673605918884
train loss item: 0.10548245906829834
train loss item: 0.19907425343990326
train loss item: 0.09084581583738327
train loss item: 0.3613039255142212
train loss item: 0.18778327107429504
train loss item: 0.1537594497203827
train loss item: 0.24396221339702606
train loss item: 0.1394142359495163
train loss item: 0.10606225579977036
train loss item: 0.07448725402355194
train loss item: 0.08244312554597855
train loss item: 0.17037931084632874
train loss item: 0.059878673404455185
train loss item: 0.08187519013881683
train loss item: 0.21989980340003967
train loss item: 1.0093728303909302
train loss item: 0.0452331006526947
train loss item: 0.14428307116031647
train loss item: 0.07925768941640854
train loss item: 0.08786574751138687
train loss item: 0.11674920469522476
train loss item: 0.5052424073219299
train loss item: 0.27298516035079956
train loss item: 0.20645642280578613
train loss item: 2.0211002826690674
train loss item: 0.06953809410333633
train loss item: 0.16073447465896606
test loss item: 0.1299131065607071
test loss item: 0.07732722908258438
test loss item: 0.45633959770202637
test loss item: 0.15329299867153168
test loss item: 0.16756142675876617
test loss item: 0.09435337036848068
test loss item: 1.627776026725769
test loss item: 0.48978519439697266
test loss item: 0.1630641371011734
test loss item: 0.24454568326473236
test loss item: 0.6801672577857971
test loss item: 0.11459793150424957
test loss item: 0.14343155920505524
test loss item: 0.22579994797706604
test loss item: 0.1195954754948616
test loss item: 0.0539344847202301
test loss item: 0.22553513944149017
test loss item: 0.26013028621673584
test loss item: 0.5099751353263855
test loss item: 0.23697121441364288
test loss item: 0.4168517291545868
test loss item: 0.31029418110847473
test loss item: 0.23300586640834808
test loss item: 0.14941199123859406
test loss item: 0.1265784502029419
test loss item: 0.18282029032707214
test loss item: 0.2191699892282486
test loss item: 0.12321919947862625
test loss item: 0.22847728431224823
test loss item: 0.20277705788612366
test loss item: 0.7106884717941284
test loss item: 0.04528915509581566
test loss item: 0.12275848537683487
test loss item: 0.3347338140010834
test loss item: 0.2776491641998291
test loss item: 0.27426639199256897
test loss item: 0.6342920064926147
test loss item: 1.1415517330169678
test loss item: 0.308248370885849
test loss item: 0.2306385636329651
test loss item: 0.2429814487695694
test loss item: 0.1900930255651474
test loss item: 0.1856892704963684
test loss item: 0.17489346861839294
test loss item: 0.32346391677856445
test loss item: 0.3237870931625366
test loss item: 0.2180178463459015
test loss item: 0.21575792133808136
test loss item: 0.33478057384490967
test loss item: 0.5146995186805725
test loss item: 0.17469654977321625
test loss item: 0.1191781535744667
test loss item: 0.17038413882255554
test loss item: 0.1098870038986206
test loss item: 0.18474578857421875
test loss item: 0.6340591311454773
test loss item: 0.4183190166950226
test loss item: 0.16777640581130981
test loss item: 0.17770697176456451
test loss item: 0.12429369986057281
test loss item: 0.2262038141489029
test loss item: 0.20259404182434082
test loss item: 0.19312924146652222
test loss item: 0.16912434995174408
test loss item: 0.7533867359161377
test loss item: 0.19387726485729218
test loss item: 0.2536012828350067
test loss item: 0.19641193747520447
test loss item: 0.3404681086540222
test loss item: 0.32676810026168823
test loss item: 0.05756640061736107
test loss item: 0.9054065942764282
test loss item: 0.26167115569114685
test loss item: 0.3660774827003479
test loss item: 0.1284051388502121
test loss item: 0.1625063121318817
test loss item: 0.15182606875896454
test loss item: 1.2603884935379028
test loss item: 0.34783095121383667
test loss item: 0.14649778604507446
test loss item: 0.062067724764347076
test loss item: 0.8551487922668457
test loss item: 0.692622721195221
test loss item: 0.8712504506111145
test loss item: 0.18147927522659302
test loss item: 0.1629476547241211
test loss item: 0.04951920360326767
test loss item: 0.03939785435795784
test loss item: 0.15804843604564667
Epoch [12/100], Training Loss: 0.2480, Testing Loss: 0.3053
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 13/100
train loss item: 0.18581971526145935
train loss item: 0.32269421219825745
train loss item: 0.09889144450426102
train loss item: 0.20571814477443695
train loss item: 0.15680259466171265
train loss item: 0.11995875090360641
train loss item: 0.06879294663667679
train loss item: 0.18695057928562164
train loss item: 0.06258952617645264
train loss item: 0.10682964324951172
train loss item: 0.1145019680261612
train loss item: 0.1096557080745697
train loss item: 0.08873774111270905
train loss item: 0.2583290636539459
train loss item: 0.10256818681955338
train loss item: 0.3159264326095581
train loss item: 0.04664619639515877
train loss item: 0.08531004190444946
train loss item: 0.13120368123054504
train loss item: 0.15801389515399933
train loss item: 0.07211940735578537
train loss item: 0.059631798416376114
train loss item: 0.37057164311408997
train loss item: 0.4672548174858093
train loss item: 0.21528960764408112
train loss item: 0.13287796080112457
train loss item: 0.0767800584435463
train loss item: 0.09801900386810303
train loss item: 0.04180300235748291
train loss item: 0.31703245639801025
train loss item: 0.7013304829597473
train loss item: 0.24123390018939972
train loss item: 0.07040467858314514
train loss item: 0.1394529938697815
train loss item: 0.09578806161880493
train loss item: 0.8510229587554932
train loss item: 0.2577570676803589
train loss item: 0.2495458871126175
train loss item: 0.43825241923332214
train loss item: 0.20330490171909332
train loss item: 0.11294660717248917
train loss item: 0.13362695276737213
train loss item: 0.2045673131942749
train loss item: 0.13589395582675934
train loss item: 0.389672189950943
train loss item: 0.07867415994405746
train loss item: 0.063569076359272
train loss item: 0.2779868543148041
train loss item: 0.12988057732582092
train loss item: 0.08067053556442261
train loss item: 0.15391921997070312
train loss item: 0.4653211832046509
train loss item: 0.06752881407737732
train loss item: 0.11646902561187744
train loss item: 0.7918145656585693
train loss item: 0.07678475230932236
train loss item: 0.1413162350654602
train loss item: 0.10843607038259506
train loss item: 0.08626099675893784
train loss item: 0.08909531682729721
train loss item: 0.24999761581420898
train loss item: 0.505868136882782
train loss item: 0.11806695908308029
train loss item: 0.18083544075489044
train loss item: 0.07949894666671753
train loss item: 0.19213350117206573
train loss item: 0.14267778396606445
train loss item: 0.11723233759403229
train loss item: 0.2357175499200821
train loss item: 0.11534593999385834
train loss item: 0.09033478051424026
train loss item: 0.09116782248020172
train loss item: 0.0965796411037445
train loss item: 0.12244849652051926
train loss item: 0.0592980794608593
train loss item: 0.0641174390912056
train loss item: 0.22606408596038818
train loss item: 0.8029623031616211
train loss item: 0.04949941858649254
train loss item: 0.10947045683860779
train loss item: 0.06140121445059776
train loss item: 0.09947189688682556
train loss item: 0.13952748477458954
train loss item: 0.4225080609321594
train loss item: 0.3044416606426239
train loss item: 0.27781984210014343
train loss item: 1.9796521663665771
train loss item: 0.09472798556089401
train loss item: 0.13267339766025543
test loss item: 0.15677978098392487
test loss item: 0.06960944831371307
test loss item: 0.4180431067943573
test loss item: 0.16623911261558533
test loss item: 0.1557881385087967
test loss item: 0.10005689412355423
test loss item: 1.6091655492782593
test loss item: 0.5360268354415894
test loss item: 0.1536010503768921
test loss item: 0.23727211356163025
test loss item: 0.605448842048645
test loss item: 0.12064462900161743
test loss item: 0.16264639794826508
test loss item: 0.31056827306747437
test loss item: 0.11102723330259323
test loss item: 0.05026300996541977
test loss item: 0.2601909935474396
test loss item: 0.24082109332084656
test loss item: 0.5294787287712097
test loss item: 0.28694745898246765
test loss item: 0.3856079578399658
test loss item: 0.33616623282432556
test loss item: 0.2647886574268341
test loss item: 0.16432088613510132
test loss item: 0.13785803318023682
test loss item: 0.19384479522705078
test loss item: 0.24638329446315765
test loss item: 0.12446676194667816
test loss item: 0.23757478594779968
test loss item: 0.22133129835128784
test loss item: 0.6660335659980774
test loss item: 0.05019904673099518
test loss item: 0.1368875950574875
test loss item: 0.30153435468673706
test loss item: 0.25058987736701965
test loss item: 0.3072667717933655
test loss item: 0.6543126106262207
test loss item: 1.0000905990600586
test loss item: 0.29281219840049744
test loss item: 0.24164432287216187
test loss item: 0.26078200340270996
test loss item: 0.23554305732250214
test loss item: 0.16264967620372772
test loss item: 0.1944500058889389
test loss item: 0.32374945282936096
test loss item: 0.37772634625434875
test loss item: 0.2618291974067688
test loss item: 0.2851003110408783
test loss item: 0.3255879878997803
test loss item: 0.47512006759643555
test loss item: 0.16592897474765778
test loss item: 0.157791867852211
test loss item: 0.18044020235538483
test loss item: 0.12659375369548798
test loss item: 0.17263509333133698
test loss item: 0.5525190234184265
test loss item: 0.43319714069366455
test loss item: 0.2058248519897461
test loss item: 0.20095252990722656
test loss item: 0.11365282535552979
test loss item: 0.1953948736190796
test loss item: 0.23684698343276978
test loss item: 0.22583812475204468
test loss item: 0.1759578436613083
test loss item: 0.7139058709144592
test loss item: 0.207880437374115
test loss item: 0.2799359858036041
test loss item: 0.20488408207893372
test loss item: 0.309048593044281
test loss item: 0.33737078309059143
test loss item: 0.04775382950901985
test loss item: 0.92629075050354
test loss item: 0.3235366642475128
test loss item: 0.40090855956077576
test loss item: 0.15961210429668427
test loss item: 0.2081684023141861
test loss item: 0.16240626573562622
test loss item: 1.1264221668243408
test loss item: 0.3963126242160797
test loss item: 0.1699056774377823
test loss item: 0.05933724716305733
test loss item: 0.8219209909439087
test loss item: 0.6878991723060608
test loss item: 0.7885838747024536
test loss item: 0.1968638151884079
test loss item: 0.19709788262844086
test loss item: 0.05941806733608246
test loss item: 0.055264391005039215
test loss item: 0.15233993530273438
Epoch [13/100], Training Loss: 0.2123, Testing Loss: 0.3094
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 14/100
train loss item: 0.17540530860424042
train loss item: 0.5622621774673462
train loss item: 0.09796924889087677
train loss item: 0.23161934316158295
train loss item: 0.10624895244836807
train loss item: 0.13810265064239502
train loss item: 0.0755564272403717
train loss item: 0.22297008335590363
train loss item: 0.05453519895672798
train loss item: 0.1020900085568428
train loss item: 0.13419994711875916
train loss item: 0.11697882413864136
train loss item: 0.061697058379650116
train loss item: 0.23747920989990234
train loss item: 0.08397655934095383
train loss item: 0.3415820598602295
train loss item: 0.04528744891285896
train loss item: 0.11157649010419846
train loss item: 0.14815768599510193
train loss item: 0.16574901342391968
train loss item: 0.11608828604221344
train loss item: 0.07002557069063187
train loss item: 0.4560035765171051
train loss item: 0.22844822704792023
train loss item: 0.20201656222343445
train loss item: 0.11633643507957458
train loss item: 0.06700644642114639
train loss item: 0.07496707886457443
train loss item: 0.03707646578550339
train loss item: 0.28784820437431335
train loss item: 0.6788228750228882
train loss item: 0.24608033895492554
train loss item: 0.05685477703809738
train loss item: 0.15013273060321808
train loss item: 0.08522766083478928
train loss item: 0.7631323933601379
train loss item: 0.20031516253948212
train loss item: 0.28014901280403137
train loss item: 0.28032445907592773
train loss item: 0.17417192459106445
train loss item: 0.16252101957798004
train loss item: 0.17166125774383545
train loss item: 0.2391941249370575
train loss item: 0.1730841100215912
train loss item: 0.2843415141105652
train loss item: 0.06943291425704956
train loss item: 0.06022780388593674
train loss item: 0.34018734097480774
train loss item: 0.15601029992103577
train loss item: 0.0994257852435112
train loss item: 0.18856625258922577
train loss item: 0.42991533875465393
train loss item: 0.07635471969842911
train loss item: 0.1550244837999344
train loss item: 0.6594140529632568
train loss item: 0.10568294674158096
train loss item: 0.1470322608947754
train loss item: 0.10145425796508789
train loss item: 0.09993980824947357
train loss item: 0.08437245339155197
train loss item: 0.3495241105556488
train loss item: 0.4717610478401184
train loss item: 0.08172499388456345
train loss item: 0.17524848878383636
train loss item: 0.07830671221017838
train loss item: 0.26224619150161743
train loss item: 0.17643731832504272
train loss item: 0.1516214907169342
train loss item: 0.2400367558002472
train loss item: 0.13257348537445068
train loss item: 0.11096557229757309
train loss item: 0.07637607306241989
train loss item: 0.09821466356515884
train loss item: 0.13106723129749298
train loss item: 0.05591060221195221
train loss item: 0.07228397578001022
train loss item: 0.22720733284950256
train loss item: 0.7566789984703064
train loss item: 0.04896397888660431
train loss item: 0.137783020734787
train loss item: 0.08863963931798935
train loss item: 0.10511662065982819
train loss item: 0.11771475523710251
train loss item: 0.36392274498939514
train loss item: 0.2185547947883606
train loss item: 0.36193838715553284
train loss item: 1.8498138189315796
train loss item: 0.08705256134271622
train loss item: 0.12018638104200363
test loss item: 0.11746461689472198
test loss item: 0.08636346459388733
test loss item: 0.5794714093208313
test loss item: 0.14445005357265472
test loss item: 0.21344155073165894
test loss item: 0.09271546453237534
test loss item: 1.7253538370132446
test loss item: 0.5678208470344543
test loss item: 0.20242621004581451
test loss item: 0.312836229801178
test loss item: 0.8297480940818787
test loss item: 0.12031185626983643
test loss item: 0.157122403383255
test loss item: 0.21217559278011322
test loss item: 0.14748845994472504
test loss item: 0.05977283790707588
test loss item: 0.23023751378059387
test loss item: 0.36068105697631836
test loss item: 0.5538947582244873
test loss item: 0.24028830230236053
test loss item: 0.603883683681488
test loss item: 0.3281324803829193
test loss item: 0.2602267861366272
test loss item: 0.15092188119888306
test loss item: 0.15131965279579163
test loss item: 0.1734263002872467
test loss item: 0.2342565804719925
test loss item: 0.15096478164196014
test loss item: 0.2668987810611725
test loss item: 0.23386457562446594
test loss item: 0.8230060338973999
test loss item: 0.05588322505354881
test loss item: 0.12048517167568207
test loss item: 0.4408573806285858
test loss item: 0.3702126145362854
test loss item: 0.328309029340744
test loss item: 0.6992154717445374
test loss item: 1.4486221075057983
test loss item: 0.38633304834365845
test loss item: 0.23697318136692047
test loss item: 0.24491514265537262
test loss item: 0.15347827970981598
test loss item: 0.2662445902824402
test loss item: 0.17485813796520233
test loss item: 0.4608733057975769
test loss item: 0.3374772071838379
test loss item: 0.23117589950561523
test loss item: 0.18924912810325623
test loss item: 0.4263530969619751
test loss item: 0.611354649066925
test loss item: 0.25014162063598633
test loss item: 0.09578821063041687
test loss item: 0.1922367960214615
test loss item: 0.10672285407781601
test loss item: 0.245163694024086
test loss item: 0.8124287724494934
test loss item: 0.4926261007785797
test loss item: 0.1952344924211502
test loss item: 0.18985818326473236
test loss item: 0.16117572784423828
test loss item: 0.3201977014541626
test loss item: 0.21948249638080597
test loss item: 0.18348188698291779
test loss item: 0.18112556636333466
test loss item: 0.9112957715988159
test loss item: 0.18231599032878876
test loss item: 0.26676371693611145
test loss item: 0.20412901043891907
test loss item: 0.43929430842399597
test loss item: 0.3814271092414856
test loss item: 0.07272832840681076
test loss item: 0.9657779335975647
test loss item: 0.2881140410900116
test loss item: 0.3754717707633972
test loss item: 0.12350244075059891
test loss item: 0.13911934196949005
test loss item: 0.15515410900115967
test loss item: 1.6075843572616577
test loss item: 0.37754014134407043
test loss item: 0.14470821619033813
test loss item: 0.06235029175877571
test loss item: 1.0018726587295532
test loss item: 0.7830324172973633
test loss item: 1.1020811796188354
test loss item: 0.18846125900745392
test loss item: 0.16563014686107635
test loss item: 0.047313109040260315
test loss item: 0.045260246843099594
test loss item: 0.11154487729072571
Epoch [14/100], Training Loss: 0.2105, Testing Loss: 0.3517
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 15/100
train loss item: 0.19193392992019653
train loss item: 0.5216715335845947
train loss item: 0.11166802048683167
train loss item: 0.2071392834186554
train loss item: 0.15884622931480408
train loss item: 0.1351694017648697
train loss item: 0.09137404710054398
train loss item: 0.5881514549255371
train loss item: 0.08639159798622131
train loss item: 0.15673404932022095
train loss item: 0.2135341614484787
train loss item: 0.1060415729880333
train loss item: 0.09921980649232864
train loss item: 0.283218115568161
train loss item: 0.1341715008020401
train loss item: 0.25924739241600037
train loss item: 0.04939786344766617
train loss item: 0.0888596624135971
train loss item: 0.22976897656917572
train loss item: 0.11971818655729294
train loss item: 0.10750740021467209
train loss item: 0.10611727088689804
train loss item: 0.2323426604270935
train loss item: 0.49643030762672424
train loss item: 0.20912228524684906
train loss item: 0.15336287021636963
train loss item: 0.08502378314733505
train loss item: 0.11386077105998993
train loss item: 0.07268127799034119
train loss item: 0.21422240138053894
train loss item: 0.29662254452705383
train loss item: 0.3231997489929199
train loss item: 0.07489785552024841
train loss item: 0.1618475764989853
train loss item: 0.14453493058681488
train loss item: 0.7583467960357666
train loss item: 0.2999447286128998
train loss item: 0.26818832755088806
train loss item: 0.24971891939640045
train loss item: 0.10583176463842392
train loss item: 0.08863194286823273
train loss item: 0.14472417533397675
train loss item: 0.21682554483413696
train loss item: 0.1398964822292328
train loss item: 0.2979702949523926
train loss item: 0.07452433556318283
train loss item: 0.08419676125049591
train loss item: 0.3610650897026062
train loss item: 0.12897667288780212
train loss item: 0.07904747128486633
train loss item: 0.2344786822795868
train loss item: 0.6128124594688416
train loss item: 0.08019988983869553
train loss item: 0.10686077922582626
train loss item: 0.6153455972671509
train loss item: 0.09588324278593063
train loss item: 0.1532706469297409
train loss item: 0.11505896598100662
train loss item: 0.09258662909269333
train loss item: 0.08095231652259827
train loss item: 0.19616052508354187
train loss item: 0.39800840616226196
train loss item: 0.08288996666669846
train loss item: 0.18025949597358704
train loss item: 0.08489544689655304
train loss item: 0.2701391875743866
train loss item: 0.13118374347686768
train loss item: 0.1111956536769867
train loss item: 0.15115584433078766
train loss item: 0.1165817528963089
train loss item: 0.11128006875514984
train loss item: 0.06969726085662842
train loss item: 0.10285484045743942
train loss item: 0.14330419898033142
train loss item: 0.04688118025660515
train loss item: 0.06564690172672272
train loss item: 0.2585957646369934
train loss item: 0.9009904265403748
train loss item: 0.04105572775006294
train loss item: 0.12481535226106644
train loss item: 0.06571365147829056
train loss item: 0.0800449401140213
train loss item: 0.10750224441289902
train loss item: 0.46809908747673035
train loss item: 0.24005314707756042
train loss item: 0.3040081560611725
train loss item: 1.7363221645355225
train loss item: 0.06437903642654419
train loss item: 0.15206725895404816
test loss item: 0.10241414606571198
test loss item: 0.07358820736408234
test loss item: 0.5639832615852356
test loss item: 0.13631229102611542
test loss item: 0.20205770432949066
test loss item: 0.0837562084197998
test loss item: 1.4839824438095093
test loss item: 0.5824692249298096
test loss item: 0.19027234613895416
test loss item: 0.2963264584541321
test loss item: 0.8388510942459106
test loss item: 0.10604945570230484
test loss item: 0.13418157398700714
test loss item: 0.16399794816970825
test loss item: 0.1380937546491623
test loss item: 0.04924445599317551
test loss item: 0.20815825462341309
test loss item: 0.3504924476146698
test loss item: 0.5615507960319519
test loss item: 0.20377923548221588
test loss item: 0.5770186185836792
test loss item: 0.2912476062774658
test loss item: 0.22321771085262299
test loss item: 0.13014213740825653
test loss item: 0.14116159081459045
test loss item: 0.1622767299413681
test loss item: 0.21894364058971405
test loss item: 0.1330539584159851
test loss item: 0.2418445646762848
test loss item: 0.22457203269004822
test loss item: 0.7672476172447205
test loss item: 0.04747634753584862
test loss item: 0.10862801223993301
test loss item: 0.43234190344810486
test loss item: 0.36036282777786255
test loss item: 0.3446562588214874
test loss item: 0.6747632622718811
test loss item: 1.460300326347351
test loss item: 0.3625645935535431
test loss item: 0.21047574281692505
test loss item: 0.22405600547790527
test loss item: 0.11286433786153793
test loss item: 0.26049110293388367
test loss item: 0.15441042184829712
test loss item: 0.43561622500419617
test loss item: 0.30244511365890503
test loss item: 0.19739414751529694
test loss item: 0.15419018268585205
test loss item: 0.4043601453304291
test loss item: 0.6051411628723145
test loss item: 0.22564370930194855
test loss item: 0.08569980412721634
test loss item: 0.17811799049377441
test loss item: 0.09099249541759491
test loss item: 0.2339307814836502
test loss item: 0.8183290362358093
test loss item: 0.5091531276702881
test loss item: 0.17517933249473572
test loss item: 0.17383131384849548
test loss item: 0.14352987706661224
test loss item: 0.31309470534324646
test loss item: 0.19801923632621765
test loss item: 0.15439584851264954
test loss item: 0.1670900583267212
test loss item: 0.8798739910125732
test loss item: 0.1787911206483841
test loss item: 0.23824217915534973
test loss item: 0.18611282110214233
test loss item: 0.4296364486217499
test loss item: 0.4101649522781372
test loss item: 0.05583139881491661
test loss item: 0.8571043014526367
test loss item: 0.22726213932037354
test loss item: 0.3104473352432251
test loss item: 0.10724136233329773
test loss item: 0.10191362351179123
test loss item: 0.13388541340827942
test loss item: 1.5987268686294556
test loss item: 0.344326376914978
test loss item: 0.11957590281963348
test loss item: 0.056528300046920776
test loss item: 0.9585010409355164
test loss item: 0.7230724692344666
test loss item: 1.0917614698410034
test loss item: 0.1584455370903015
test loss item: 0.14679130911827087
test loss item: 0.049586355686187744
test loss item: 0.04286041110754013
test loss item: 0.10655845701694489
Epoch [15/100], Training Loss: 0.2125, Testing Loss: 0.3305
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.2719478905200958
loss item: 0.13573123514652252
loss item: 1.6610571146011353
loss item: 0.7738875150680542
loss item: 0.514004111289978
loss item: 0.30038926005363464
loss item: 0.14207600057125092
loss item: 0.6708181500434875
loss item: 0.16263531148433685
loss item: 0.14223256707191467
loss item: 0.8152409195899963
loss item: 0.045735083520412445
loss item: 0.8184831738471985
loss item: 0.16629190742969513
loss item: 0.2773703634738922
loss item: 0.217802956700325
loss item: 0.2680933177471161
loss item: 0.5485212206840515
loss item: 0.8415499925613403
loss item: 0.3161366581916809
loss item: 0.30577218532562256
loss item: 0.1504906862974167
loss item: 0.20535527169704437
loss item: 0.19191710650920868
loss item: 0.19572113454341888
loss item: 0.641125500202179
loss item: 1.1092805862426758
loss item: 0.10982585698366165
loss item: 0.10653451085090637
loss item: 0.2863885164260864
loss item: 0.842646062374115
loss item: 1.4976710081100464
loss item: 0.1328638643026352
loss item: 0.4798799455165863
loss item: 0.1244383156299591
loss item: 0.10739867389202118
loss item: 0.30979353189468384
loss item: 0.17560921609401703
loss item: 0.3750399053096771
loss item: 0.6234184503555298
loss item: 0.9587020874023438
loss item: 0.17324580252170563
loss item: 0.1425834596157074
loss item: 0.0403955839574337
Val Loss: 0.4176
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.0005 2 360 done at Tue Nov 12 12:31:24 CET 2024
UNet2 with 1 100 0.001 2 360 start at Tue Nov 12 12:31:24 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 100, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 0.9121710062026978
train loss item: 2.1258654594421387
train loss item: 0.7656190395355225
train loss item: 1.100437045097351
train loss item: 2.1631789207458496
train loss item: 0.6007260680198669
train loss item: 0.6121547222137451
train loss item: 1.1712100505828857
train loss item: 0.3923240602016449
train loss item: 0.585159182548523
train loss item: 0.5905365347862244
train loss item: 0.3662756681442261
train loss item: 0.2392287701368332
train loss item: 0.7452740669250488
train loss item: 0.3706638514995575
train loss item: 1.076843023300171
train loss item: 0.3176692724227905
train loss item: 0.3876906931400299
train loss item: 0.4380272924900055
train loss item: 0.3998122811317444
train loss item: 0.28461408615112305
train loss item: 0.28989002108573914
train loss item: 1.4297986030578613
train loss item: 1.2458375692367554
train loss item: 0.7810567021369934
train loss item: 0.3620368540287018
train loss item: 0.3075741231441498
train loss item: 0.2973628044128418
train loss item: 0.20465140044689178
train loss item: 1.1250691413879395
train loss item: 2.6976158618927
train loss item: 0.6823355555534363
train loss item: 0.32735753059387207
train loss item: 0.5191559791564941
train loss item: 0.39297470450401306
train loss item: 2.5494320392608643
train loss item: 0.5253247618675232
train loss item: 0.3948175609111786
train loss item: 0.5120791792869568
train loss item: 0.3301679491996765
train loss item: 0.2458365261554718
train loss item: 0.3248426914215088
train loss item: 0.3641613721847534
train loss item: 0.2319786548614502
train loss item: 0.6995223760604858
train loss item: 0.2514076232910156
train loss item: 0.21891114115715027
train loss item: 0.49499350786209106
train loss item: 0.3015252351760864
train loss item: 0.21804651618003845
train loss item: 0.4015234112739563
train loss item: 1.126977562904358
train loss item: 0.16852876543998718
train loss item: 0.20971401035785675
train loss item: 2.4145195484161377
train loss item: 0.23036234080791473
train loss item: 0.3066193461418152
train loss item: 0.2792584002017975
train loss item: 0.2303459197282791
train loss item: 0.15960665047168732
train loss item: 1.0253320932388306
train loss item: 2.2420740127563477
train loss item: 0.28447070717811584
train loss item: 0.4374005198478699
train loss item: 0.20419026911258698
train loss item: 0.7708473801612854
train loss item: 0.47442442178726196
train loss item: 0.23222716152668
train loss item: 0.35465168952941895
train loss item: 0.35609129071235657
train loss item: 0.26264721155166626
train loss item: 0.17640453577041626
train loss item: 0.4031560719013214
train loss item: 0.32627877593040466
train loss item: 0.15429958701133728
train loss item: 0.1423220932483673
train loss item: 0.9998055696487427
train loss item: 1.4292393922805786
train loss item: 0.1378229409456253
train loss item: 0.34643471240997314
train loss item: 0.15509024262428284
train loss item: 0.17755380272865295
train loss item: 0.24281640350818634
train loss item: 0.5816525816917419
train loss item: 0.39295297861099243
train loss item: 0.64891117811203
train loss item: 4.20023250579834
train loss item: 0.21325857937335968
train loss item: 0.6316530108451843
test loss item: 0.18573616445064545
test loss item: 0.11039507389068604
test loss item: 0.47446414828300476
test loss item: 0.21506178379058838
test loss item: 0.2324116975069046
test loss item: 0.12542012333869934
test loss item: 1.373991847038269
test loss item: 0.4523073732852936
test loss item: 0.19234715402126312
test loss item: 0.36099186539649963
test loss item: 0.709503173828125
test loss item: 0.1455998718738556
test loss item: 0.1777210384607315
test loss item: 0.36248624324798584
test loss item: 0.16839507222175598
test loss item: 0.07317930459976196
test loss item: 0.27593159675598145
test loss item: 0.42546015977859497
test loss item: 0.6373082399368286
test loss item: 0.28225329518318176
test loss item: 0.7065306305885315
test loss item: 0.3206615149974823
test loss item: 0.3108065128326416
test loss item: 0.17070086300373077
test loss item: 0.20971150696277618
test loss item: 0.27909114956855774
test loss item: 0.3343096673488617
test loss item: 0.1875535398721695
test loss item: 0.3149206340312958
test loss item: 0.3434613347053528
test loss item: 0.624456524848938
test loss item: 0.06111176684498787
test loss item: 0.15173649787902832
test loss item: 0.5297618508338928
test loss item: 0.38473543524742126
test loss item: 0.46958616375923157
test loss item: 0.7320057153701782
test loss item: 1.112637996673584
test loss item: 0.433261513710022
test loss item: 0.2553984522819519
test loss item: 0.27558115124702454
test loss item: 0.1847885400056839
test loss item: 0.3568969666957855
test loss item: 0.1688612401485443
test loss item: 0.5815560221672058
test loss item: 0.40351372957229614
test loss item: 0.30278921127319336
test loss item: 0.2927902936935425
test loss item: 0.38657346367836
test loss item: 0.622253954410553
test loss item: 0.2801019847393036
test loss item: 0.1462196260690689
test loss item: 0.23224709928035736
test loss item: 0.12738361954689026
test loss item: 0.3159025013446808
test loss item: 0.746019184589386
test loss item: 0.5049576163291931
test loss item: 0.29097527265548706
test loss item: 0.22575561702251434
test loss item: 0.2249361127614975
test loss item: 0.4290810823440552
test loss item: 0.1866779923439026
test loss item: 0.25087499618530273
test loss item: 0.25192567706108093
test loss item: 0.7237311005592346
test loss item: 0.2963245213031769
test loss item: 0.3128970265388489
test loss item: 0.2469007670879364
test loss item: 0.4840162694454193
test loss item: 0.41413629055023193
test loss item: 0.0728050023317337
test loss item: 0.840832531452179
test loss item: 0.3359127342700958
test loss item: 0.3533949553966522
test loss item: 0.15103302896022797
test loss item: 0.17004652321338654
test loss item: 0.16946670413017273
test loss item: 1.0761560201644897
test loss item: 0.4618690609931946
test loss item: 0.19068297743797302
test loss item: 0.08925171941518784
test loss item: 0.7471039891242981
test loss item: 0.7751322388648987
test loss item: 0.7345174551010132
test loss item: 0.28912729024887085
test loss item: 0.22510449588298798
test loss item: 0.07566671818494797
test loss item: 0.059314023703336716
test loss item: 0.16778980195522308
Epoch [1/100], Training Loss: 0.6461, Testing Loss: 0.3614
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/100
train loss item: 0.48665037751197815
train loss item: 1.1615359783172607
train loss item: 0.27293288707733154
train loss item: 0.5829629302024841
train loss item: 0.49121662974357605
train loss item: 0.30032771825790405
train loss item: 0.49080514907836914
train loss item: 0.697040855884552
train loss item: 0.24364978075027466
train loss item: 0.36693501472473145
train loss item: 0.32848209142684937
train loss item: 0.28080955147743225
train loss item: 0.1381971687078476
train loss item: 0.4501991868019104
train loss item: 0.27488595247268677
train loss item: 0.7843855023384094
train loss item: 0.09665995836257935
train loss item: 0.2814568877220154
train loss item: 0.3409649431705475
train loss item: 0.3013257384300232
train loss item: 0.2096235156059265
train loss item: 0.13291700184345245
train loss item: 1.0211668014526367
train loss item: 0.8384483456611633
train loss item: 0.6219689846038818
train loss item: 0.2613876163959503
train loss item: 0.18609194457530975
train loss item: 0.26740261912345886
train loss item: 0.15649399161338806
train loss item: 0.6646139025688171
train loss item: 2.1474833488464355
train loss item: 0.62767094373703
train loss item: 0.15585872530937195
train loss item: 0.37342655658721924
train loss item: 0.1427515149116516
train loss item: 2.0818710327148438
train loss item: 0.6713902950286865
train loss item: 0.5651168823242188
train loss item: 0.728975236415863
train loss item: 0.2976408004760742
train loss item: 0.23928357660770416
train loss item: 0.33928191661834717
train loss item: 0.3826754689216614
train loss item: 0.26387959718704224
train loss item: 0.8121520280838013
train loss item: 0.13374173641204834
train loss item: 0.17160259187221527
train loss item: 0.5792803168296814
train loss item: 0.2960369288921356
train loss item: 0.18335272371768951
train loss item: 0.4162694811820984
train loss item: 1.2744544744491577
train loss item: 0.07771602272987366
train loss item: 0.13509595394134521
train loss item: 2.4734129905700684
train loss item: 0.20549899339675903
train loss item: 0.28258854150772095
train loss item: 0.2546379268169403
train loss item: 0.22661451995372772
train loss item: 0.1906350553035736
train loss item: 0.8574021458625793
train loss item: 2.1517767906188965
train loss item: 0.2441401183605194
train loss item: 0.3639388084411621
train loss item: 0.17409786581993103
train loss item: 0.5436062216758728
train loss item: 0.3908716142177582
train loss item: 0.19505375623703003
train loss item: 0.3971502482891083
train loss item: 0.3207044303417206
train loss item: 0.2358579784631729
train loss item: 0.12035752832889557
train loss item: 0.19457724690437317
train loss item: 0.25068381428718567
train loss item: 0.07541542500257492
train loss item: 0.10324722528457642
train loss item: 0.7521311640739441
train loss item: 1.2019109725952148
train loss item: 0.13115519285202026
train loss item: 0.33383774757385254
train loss item: 0.1980239599943161
train loss item: 0.19759082794189453
train loss item: 0.20953501760959625
train loss item: 0.5021787285804749
train loss item: 0.31964850425720215
train loss item: 0.527762770652771
train loss item: 3.9315314292907715
train loss item: 0.17098289728164673
train loss item: 0.4442448019981384
test loss item: 0.21006281673908234
test loss item: 0.1423376351594925
test loss item: 0.43189454078674316
test loss item: 0.22836622595787048
test loss item: 0.24500957131385803
test loss item: 0.1480274498462677
test loss item: 1.5753326416015625
test loss item: 0.6171939969062805
test loss item: 0.19679374992847443
test loss item: 0.3430742025375366
test loss item: 0.5991901755332947
test loss item: 0.1830114722251892
test loss item: 0.22857216000556946
test loss item: 0.39370158314704895
test loss item: 0.17477838695049286
test loss item: 0.11177512258291245
test loss item: 0.3173048794269562
test loss item: 0.3803214430809021
test loss item: 0.681397557258606
test loss item: 0.35152676701545715
test loss item: 0.6338116526603699
test loss item: 0.38562995195388794
test loss item: 0.3705214560031891
test loss item: 0.19429898262023926
test loss item: 0.200543612241745
test loss item: 0.23529987037181854
test loss item: 0.3429310917854309
test loss item: 0.20665951073169708
test loss item: 0.3480721116065979
test loss item: 0.3213827311992645
test loss item: 0.6112701892852783
test loss item: 0.09204819053411484
test loss item: 0.1658197045326233
test loss item: 0.48093992471694946
test loss item: 0.3291372060775757
test loss item: 0.4394116997718811
test loss item: 0.8037817478179932
test loss item: 0.9103074669837952
test loss item: 0.39086413383483887
test loss item: 0.28869134187698364
test loss item: 0.2925489842891693
test loss item: 0.2698843479156494
test loss item: 0.342507541179657
test loss item: 0.20273543894290924
test loss item: 0.5248063802719116
test loss item: 0.47074079513549805
test loss item: 0.3648636043071747
test loss item: 0.3097497224807739
test loss item: 0.39487820863723755
test loss item: 0.5497589111328125
test loss item: 0.28673073649406433
test loss item: 0.15686699748039246
test loss item: 0.22900094091892242
test loss item: 0.15457342565059662
test loss item: 0.2775312662124634
test loss item: 0.5800526142120361
test loss item: 0.5446460843086243
test loss item: 0.2876228392124176
test loss item: 0.24055223166942596
test loss item: 0.23177987337112427
test loss item: 0.38563603162765503
test loss item: 0.2658858299255371
test loss item: 0.2523871660232544
test loss item: 0.27479374408721924
test loss item: 0.6772077083587646
test loss item: 0.3026731312274933
test loss item: 0.34983155131340027
test loss item: 0.26626333594322205
test loss item: 0.4295552372932434
test loss item: 0.43224048614501953
test loss item: 0.11084449291229248
test loss item: 0.9608939290046692
test loss item: 0.4131729006767273
test loss item: 0.4579004943370819
test loss item: 0.18160149455070496
test loss item: 0.2601177990436554
test loss item: 0.1957016885280609
test loss item: 0.8623129725456238
test loss item: 0.4785661995410919
test loss item: 0.22922058403491974
test loss item: 0.0930333361029625
test loss item: 0.7702300548553467
test loss item: 0.8023293614387512
test loss item: 0.6212027072906494
test loss item: 0.25932395458221436
test loss item: 0.23144811391830444
test loss item: 0.08218587189912796
test loss item: 0.0803365558385849
test loss item: 0.16108648478984833
Epoch [2/100], Training Loss: 0.5056, Testing Loss: 0.3698
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/100
train loss item: 0.40431681275367737
train loss item: 0.9510575532913208
train loss item: 0.27253180742263794
train loss item: 0.4078327715396881
train loss item: 0.33667638897895813
train loss item: 0.26616939902305603
train loss item: 0.34476032853126526
train loss item: 0.6230496168136597
train loss item: 0.15810996294021606
train loss item: 0.2924773395061493
train loss item: 0.3582819700241089
train loss item: 0.23785194754600525
train loss item: 0.10616779327392578
train loss item: 0.4532085955142975
train loss item: 0.23287665843963623
train loss item: 0.634672224521637
train loss item: 0.06615922600030899
train loss item: 0.2761218547821045
train loss item: 0.2787648141384125
train loss item: 0.2777956426143646
train loss item: 0.19797994196414948
train loss item: 0.18029166758060455
train loss item: 0.7308247685432434
train loss item: 0.8075000047683716
train loss item: 0.4558870494365692
train loss item: 0.3066309094429016
train loss item: 0.20444701611995697
train loss item: 0.24018095433712006
train loss item: 0.06978444755077362
train loss item: 0.5963158011436462
train loss item: 1.797213077545166
train loss item: 0.4466153383255005
train loss item: 0.11431712657213211
train loss item: 0.30259013175964355
train loss item: 0.10058853775262833
train loss item: 1.8615950345993042
train loss item: 0.5981590747833252
train loss item: 0.5257294774055481
train loss item: 0.6821022033691406
train loss item: 0.22152315080165863
train loss item: 0.20006245374679565
train loss item: 0.34193870425224304
train loss item: 0.3807806968688965
train loss item: 0.28866374492645264
train loss item: 0.7851067185401917
train loss item: 0.160965234041214
train loss item: 0.12154196202754974
train loss item: 0.5586856603622437
train loss item: 0.29676195979118347
train loss item: 0.18665017187595367
train loss item: 0.39012184739112854
train loss item: 1.2390329837799072
train loss item: 0.10969952493906021
train loss item: 0.17861421406269073
train loss item: 2.199936628341675
train loss item: 0.1546437293291092
train loss item: 0.22260597348213196
train loss item: 0.2400335818529129
train loss item: 0.17156507074832916
train loss item: 0.15966323018074036
train loss item: 0.7490745782852173
train loss item: 1.6288939714431763
train loss item: 0.22739648818969727
train loss item: 0.36549654603004456
train loss item: 0.18399208784103394
train loss item: 0.5185285806655884
train loss item: 0.3856385350227356
train loss item: 0.16695541143417358
train loss item: 0.3736265003681183
train loss item: 0.28584668040275574
train loss item: 0.24164298176765442
train loss item: 0.11541582643985748
train loss item: 0.28054529428482056
train loss item: 0.2937539219856262
train loss item: 0.0734165608882904
train loss item: 0.10841704905033112
train loss item: 0.860194742679596
train loss item: 1.291494607925415
train loss item: 0.07048190385103226
train loss item: 0.23353353142738342
train loss item: 0.1588250696659088
train loss item: 0.13658559322357178
train loss item: 0.21414276957511902
train loss item: 0.41752204298973083
train loss item: 0.37362056970596313
train loss item: 0.45214200019836426
train loss item: 3.5229780673980713
train loss item: 0.15353475511074066
train loss item: 0.5436218976974487
test loss item: 0.16337335109710693
test loss item: 0.12232816964387894
test loss item: 0.38695472478866577
test loss item: 0.18987947702407837
test loss item: 0.20392148196697235
test loss item: 0.11583805829286575
test loss item: 1.6741338968276978
test loss item: 0.6663385033607483
test loss item: 0.1986963152885437
test loss item: 0.3375275433063507
test loss item: 0.6163406372070312
test loss item: 0.13147974014282227
test loss item: 0.22459344565868378
test loss item: 0.31330740451812744
test loss item: 0.15271888673305511
test loss item: 0.09522467106580734
test loss item: 0.27250170707702637
test loss item: 0.32020172476768494
test loss item: 0.7188824415206909
test loss item: 0.33266109228134155
test loss item: 0.4841320812702179
test loss item: 0.3726230561733246
test loss item: 0.2549353241920471
test loss item: 0.15972846746444702
test loss item: 0.17803677916526794
test loss item: 0.214985191822052
test loss item: 0.32379254698753357
test loss item: 0.17033933103084564
test loss item: 0.2730075418949127
test loss item: 0.35309073328971863
test loss item: 0.6473550200462341
test loss item: 0.07711856812238693
test loss item: 0.13628531992435455
test loss item: 0.39945676922798157
test loss item: 0.29354918003082275
test loss item: 0.486021488904953
test loss item: 0.8210583925247192
test loss item: 0.9351065754890442
test loss item: 0.3425940275192261
test loss item: 0.2434391975402832
test loss item: 0.2722919285297394
test loss item: 0.18158051371574402
test loss item: 0.27514708042144775
test loss item: 0.17082488536834717
test loss item: 0.4058611989021301
test loss item: 0.44085365533828735
test loss item: 0.24374061822891235
test loss item: 0.39666643738746643
test loss item: 0.36835816502571106
test loss item: 0.588074266910553
test loss item: 0.22897085547447205
test loss item: 0.2426464706659317
test loss item: 0.19743968546390533
test loss item: 0.1122957319021225
test loss item: 0.22329628467559814
test loss item: 0.5876825451850891
test loss item: 0.5704299211502075
test loss item: 0.1928173303604126
test loss item: 0.2190772294998169
test loss item: 0.1775171011686325
test loss item: 0.34909874200820923
test loss item: 0.2696938216686249
test loss item: 0.20131930708885193
test loss item: 0.23531906306743622
test loss item: 0.7090719938278198
test loss item: 0.2535879611968994
test loss item: 0.32185328006744385
test loss item: 0.24589137732982635
test loss item: 0.370713472366333
test loss item: 0.5115177631378174
test loss item: 0.09999260306358337
test loss item: 1.0374881029129028
test loss item: 0.28287434577941895
test loss item: 0.37179750204086304
test loss item: 0.16662126779556274
test loss item: 0.1729808896780014
test loss item: 0.16829556226730347
test loss item: 0.9036120176315308
test loss item: 0.38485896587371826
test loss item: 0.16632553935050964
test loss item: 0.07877703011035919
test loss item: 0.8477071523666382
test loss item: 0.8401127457618713
test loss item: 0.6795732975006104
test loss item: 0.22487564384937286
test loss item: 0.20171505212783813
test loss item: 0.06708744168281555
test loss item: 0.06505702435970306
test loss item: 0.13323993980884552
Epoch [3/100], Training Loss: 0.4521, Testing Loss: 0.3467
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/100
train loss item: 0.4026936888694763
train loss item: 0.932007908821106
train loss item: 0.2073158323764801
train loss item: 0.3953281044960022
train loss item: 0.2808475196361542
train loss item: 0.22582007944583893
train loss item: 0.25516796112060547
train loss item: 0.48603031039237976
train loss item: 0.1248018890619278
train loss item: 0.22975730895996094
train loss item: 0.29003313183784485
train loss item: 0.23676207661628723
train loss item: 0.11435948312282562
train loss item: 0.3737010061740875
train loss item: 0.23646928369998932
train loss item: 0.6303900480270386
train loss item: 0.06410516053438187
train loss item: 0.21501168608665466
train loss item: 0.28950047492980957
train loss item: 0.25381699204444885
train loss item: 0.1686660498380661
train loss item: 0.11912376433610916
train loss item: 0.7424846887588501
train loss item: 0.6060930490493774
train loss item: 0.4128679633140564
train loss item: 0.22368480265140533
train loss item: 0.160282164812088
train loss item: 0.2082388997077942
train loss item: 0.08773377537727356
train loss item: 0.4481845498085022
train loss item: 1.590124249458313
train loss item: 0.5201963782310486
train loss item: 0.12274891883134842
train loss item: 0.2773289084434509
train loss item: 0.11800087988376617
train loss item: 1.679360270500183
train loss item: 0.48908519744873047
train loss item: 0.3746160566806793
train loss item: 0.3098801374435425
train loss item: 0.17172583937644958
train loss item: 0.1604207158088684
train loss item: 0.26338866353034973
train loss item: 0.3128451406955719
train loss item: 0.22770264744758606
train loss item: 0.6357381939888
train loss item: 0.10528311133384705
train loss item: 0.10703711211681366
train loss item: 0.3746113181114197
train loss item: 0.18241074681282043
train loss item: 0.2035401612520218
train loss item: 0.25165680050849915
train loss item: 0.8216364979743958
train loss item: 0.07912547141313553
train loss item: 0.1272871345281601
train loss item: 1.6295762062072754
train loss item: 0.1739395409822464
train loss item: 0.254442036151886
train loss item: 0.22294391691684723
train loss item: 0.11960458010435104
train loss item: 0.1284250020980835
train loss item: 0.529671847820282
train loss item: 1.513680338859558
train loss item: 0.17424920201301575
train loss item: 0.3672032952308655
train loss item: 0.13865409791469574
train loss item: 0.44052785634994507
train loss item: 0.4400733709335327
train loss item: 0.16348092257976532
train loss item: 0.43731847405433655
train loss item: 0.30160701274871826
train loss item: 0.24192851781845093
train loss item: 0.10278540104627609
train loss item: 0.19409982860088348
train loss item: 0.25174474716186523
train loss item: 0.06204777956008911
train loss item: 0.09537258744239807
train loss item: 0.5493372678756714
train loss item: 1.197182536125183
train loss item: 0.08754781633615494
train loss item: 0.2386907935142517
train loss item: 0.10810710489749908
train loss item: 0.18347086012363434
train loss item: 0.2087378054857254
train loss item: 0.35202494263648987
train loss item: 0.38611534237861633
train loss item: 0.3632870614528656
train loss item: 3.196484327316284
train loss item: 0.13359983265399933
train loss item: 0.3829326927661896
test loss item: 0.1643076390028
test loss item: 0.11959642916917801
test loss item: 0.35509464144706726
test loss item: 0.18919609487056732
test loss item: 0.18284744024276733
test loss item: 0.1100734993815422
test loss item: 1.9001684188842773
test loss item: 0.7392232418060303
test loss item: 0.19258010387420654
test loss item: 0.29522207379341125
test loss item: 0.5660588145256042
test loss item: 0.14380528032779694
test loss item: 0.21101760864257812
test loss item: 0.282146692276001
test loss item: 0.13525789976119995
test loss item: 0.10148810595273972
test loss item: 0.2891584038734436
test loss item: 0.2541123330593109
test loss item: 0.7366359829902649
test loss item: 0.34246352314949036
test loss item: 0.3714790344238281
test loss item: 0.40260234475135803
test loss item: 0.2328355312347412
test loss item: 0.1726139634847641
test loss item: 0.15802110731601715
test loss item: 0.2046997845172882
test loss item: 0.3172381818294525
test loss item: 0.15334555506706238
test loss item: 0.2620719373226166
test loss item: 0.2943442463874817
test loss item: 0.6989959478378296
test loss item: 0.08035016804933548
test loss item: 0.14283610880374908
test loss item: 0.3405335247516632
test loss item: 0.23293302953243256
test loss item: 0.4284932315349579
test loss item: 0.8549873232841492
test loss item: 0.8174155354499817
test loss item: 0.296234130859375
test loss item: 0.26029524207115173
test loss item: 0.28312501311302185
test loss item: 0.16441872715950012
test loss item: 0.24966101348400116
test loss item: 0.19154919683933258
test loss item: 0.31551024317741394
test loss item: 0.45528924465179443
test loss item: 0.22361956536769867
test loss item: 0.3686404526233673
test loss item: 0.3492124080657959
test loss item: 0.5626037120819092
test loss item: 0.19631676375865936
test loss item: 0.1952626258134842
test loss item: 0.18562370538711548
test loss item: 0.12496219575405121
test loss item: 0.18684767186641693
test loss item: 0.4905315637588501
test loss item: 0.5535308122634888
test loss item: 0.21055608987808228
test loss item: 0.21603330969810486
test loss item: 0.16372129321098328
test loss item: 0.2824082672595978
test loss item: 0.28990745544433594
test loss item: 0.20661994814872742
test loss item: 0.22992196679115295
test loss item: 0.7026017308235168
test loss item: 0.24473972618579865
test loss item: 0.32555317878723145
test loss item: 0.24870677292346954
test loss item: 0.3156742453575134
test loss item: 0.51814866065979
test loss item: 0.1002998948097229
test loss item: 1.160264015197754
test loss item: 0.2799358069896698
test loss item: 0.4140484929084778
test loss item: 0.17925241589546204
test loss item: 0.15918783843517303
test loss item: 0.17987167835235596
test loss item: 0.8123794794082642
test loss item: 0.3551606237888336
test loss item: 0.1602254956960678
test loss item: 0.08341857045888901
test loss item: 0.8874430060386658
test loss item: 0.8717962503433228
test loss item: 0.626115083694458
test loss item: 0.21296875178813934
test loss item: 0.2113729566335678
test loss item: 0.08066504448652267
test loss item: 0.07658101618289948
test loss item: 0.11342373490333557
Epoch [4/100], Training Loss: 0.3854, Testing Loss: 0.3376
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/100
train loss item: 0.38815298676490784
train loss item: 0.8437963128089905
train loss item: 0.18484166264533997
train loss item: 0.3176180422306061
train loss item: 0.3029039204120636
train loss item: 0.20797066390514374
train loss item: 0.2339087277650833
train loss item: 0.45675164461135864
train loss item: 0.13850827515125275
train loss item: 0.2450139820575714
train loss item: 0.32176733016967773
train loss item: 0.21275149285793304
train loss item: 0.1052074134349823
train loss item: 0.4343673288822174
train loss item: 0.20955900847911835
train loss item: 0.43117132782936096
train loss item: 0.0741044208407402
train loss item: 0.163816899061203
train loss item: 0.2816649377346039
train loss item: 0.2437783181667328
train loss item: 0.16622503101825714
train loss item: 0.11751003563404083
train loss item: 0.5580093264579773
train loss item: 0.5152767896652222
train loss item: 0.3675912022590637
train loss item: 0.19425800442695618
train loss item: 0.13175827264785767
train loss item: 0.20380856096744537
train loss item: 0.06573139131069183
train loss item: 0.35562148690223694
train loss item: 1.273242712020874
train loss item: 0.5719687342643738
train loss item: 0.12985944747924805
train loss item: 0.2580487132072449
train loss item: 0.1340484768152237
train loss item: 1.5583516359329224
train loss item: 0.37193456292152405
train loss item: 0.38543063402175903
train loss item: 0.291443407535553
train loss item: 0.16730453073978424
train loss item: 0.15997062623500824
train loss item: 0.23682883381843567
train loss item: 0.28255587816238403
train loss item: 0.16661465167999268
train loss item: 0.461301326751709
train loss item: 0.09136656671762466
train loss item: 0.11434662342071533
train loss item: 0.2479904145002365
train loss item: 0.14807942509651184
train loss item: 0.1698984056711197
train loss item: 0.24104097485542297
train loss item: 0.5828565955162048
train loss item: 0.0623154453933239
train loss item: 0.1049003154039383
train loss item: 1.3892947435379028
train loss item: 0.14323844015598297
train loss item: 0.2145889848470688
train loss item: 0.18537156283855438
train loss item: 0.11722509562969208
train loss item: 0.14316676557064056
train loss item: 0.4656302034854889
train loss item: 1.1813143491744995
train loss item: 0.13542316854000092
train loss item: 0.26234978437423706
train loss item: 0.10408952832221985
train loss item: 0.49433469772338867
train loss item: 0.344838410615921
train loss item: 0.13239046931266785
train loss item: 0.3812115490436554
train loss item: 0.2662462592124939
train loss item: 0.2704869508743286
train loss item: 0.0895189568400383
train loss item: 0.21283331513404846
train loss item: 0.2569955587387085
train loss item: 0.08398512005805969
train loss item: 0.09035051614046097
train loss item: 0.519722044467926
train loss item: 1.3740484714508057
train loss item: 0.0639837458729744
train loss item: 0.17852318286895752
train loss item: 0.11642272025346756
train loss item: 0.19639770686626434
train loss item: 0.18684305250644684
train loss item: 0.3782520294189453
train loss item: 0.3172415792942047
train loss item: 0.2971554100513458
train loss item: 2.8296117782592773
train loss item: 0.15670345723628998
train loss item: 0.24792318046092987
test loss item: 0.15296126902103424
test loss item: 0.133498877286911
test loss item: 0.5416911244392395
test loss item: 0.17583446204662323
test loss item: 0.24417896568775177
test loss item: 0.1356334388256073
test loss item: 1.6203373670578003
test loss item: 0.6536034345626831
test loss item: 0.2148706465959549
test loss item: 0.3315224051475525
test loss item: 0.7940971255302429
test loss item: 0.11568624526262283
test loss item: 0.1703909933567047
test loss item: 0.283413827419281
test loss item: 0.17327620089054108
test loss item: 0.09742289036512375
test loss item: 0.24205976724624634
test loss item: 0.3748929500579834
test loss item: 0.6532902717590332
test loss item: 0.23739616572856903
test loss item: 0.5894289612770081
test loss item: 0.3522759974002838
test loss item: 0.2821444869041443
test loss item: 0.16816142201423645
test loss item: 0.1634429693222046
test loss item: 0.18791314959526062
test loss item: 0.2603372037410736
test loss item: 0.19019441306591034
test loss item: 0.27667662501335144
test loss item: 0.2905448079109192
test loss item: 0.7623375058174133
test loss item: 0.08625738322734833
test loss item: 0.14936690032482147
test loss item: 0.4502280354499817
test loss item: 0.3648596704006195
test loss item: 0.3934861421585083
test loss item: 0.7697432041168213
test loss item: 1.3764163255691528
test loss item: 0.37091127038002014
test loss item: 0.23443453013896942
test loss item: 0.2534203827381134
test loss item: 0.16776782274246216
test loss item: 0.29350313544273376
test loss item: 0.1678258329629898
test loss item: 0.46769821643829346
test loss item: 0.36048319935798645
test loss item: 0.24840250611305237
test loss item: 0.22709369659423828
test loss item: 0.42671817541122437
test loss item: 0.6347745060920715
test loss item: 0.2529308795928955
test loss item: 0.1432102471590042
test loss item: 0.20327366888523102
test loss item: 0.10147520154714584
test loss item: 0.2603684067726135
test loss item: 0.7536219954490662
test loss item: 0.5653480887413025
test loss item: 0.22747743129730225
test loss item: 0.2093188315629959
test loss item: 0.16334861516952515
test loss item: 0.36046841740608215
test loss item: 0.25572800636291504
test loss item: 0.18247990310192108
test loss item: 0.19053910672664642
test loss item: 0.8394208550453186
test loss item: 0.21365472674369812
test loss item: 0.291299968957901
test loss item: 0.21796050667762756
test loss item: 0.4261665940284729
test loss item: 0.45089131593704224
test loss item: 0.10117828100919724
test loss item: 0.9675623178482056
test loss item: 0.2954248785972595
test loss item: 0.33475542068481445
test loss item: 0.14859122037887573
test loss item: 0.16152185201644897
test loss item: 0.17340564727783203
test loss item: 1.4589473009109497
test loss item: 0.3804328143596649
test loss item: 0.1726102977991104
test loss item: 0.09172948449850082
test loss item: 0.9717326760292053
test loss item: 0.8093504309654236
test loss item: 1.005246639251709
test loss item: 0.20225432515144348
test loss item: 0.1860290765762329
test loss item: 0.0845339447259903
test loss item: 0.07696401327848434
test loss item: 0.12775856256484985
Epoch [5/100], Training Loss: 0.3428, Testing Loss: 0.3637
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/100
train loss item: 0.2966400980949402
train loss item: 0.7064111232757568
train loss item: 0.17244380712509155
train loss item: 0.22092680633068085
train loss item: 0.26735296845436096
train loss item: 0.20832860469818115
train loss item: 0.19632261991500854
train loss item: 0.41463419795036316
train loss item: 0.08258358389139175
train loss item: 0.18865859508514404
train loss item: 0.1947103887796402
train loss item: 0.16171953082084656
train loss item: 0.10916435718536377
train loss item: 0.38482865691185
train loss item: 0.20788024365901947
train loss item: 0.4171532094478607
train loss item: 0.07160428911447525
train loss item: 0.13298927247524261
train loss item: 0.22969624400138855
train loss item: 0.19324223697185516
train loss item: 0.1370564103126526
train loss item: 0.12295227497816086
train loss item: 0.4115223288536072
train loss item: 0.44671711325645447
train loss item: 0.3645278215408325
train loss item: 0.1977793425321579
train loss item: 0.12074501812458038
train loss item: 0.18587146699428558
train loss item: 0.08143913000822067
train loss item: 0.3468596041202545
train loss item: 1.05681574344635
train loss item: 0.5029738545417786
train loss item: 0.10994357615709305
train loss item: 0.2022722065448761
train loss item: 0.10949057340621948
train loss item: 1.3182978630065918
train loss item: 0.46265605092048645
train loss item: 0.426204651594162
train loss item: 0.25317108631134033
train loss item: 0.16699466109275818
train loss item: 0.1925140768289566
train loss item: 0.2607722282409668
train loss item: 0.3693748414516449
train loss item: 0.2142953723669052
train loss item: 0.47418078780174255
train loss item: 0.10861608386039734
train loss item: 0.09215383231639862
train loss item: 0.5615369081497192
train loss item: 0.18792594969272614
train loss item: 0.13373219966888428
train loss item: 0.3465467393398285
train loss item: 0.9312170743942261
train loss item: 0.10152140259742737
train loss item: 0.1659417748451233
train loss item: 1.2698392868041992
train loss item: 0.13139460980892181
train loss item: 0.19345058500766754
train loss item: 0.174875408411026
train loss item: 0.11806090921163559
train loss item: 0.12149514257907867
train loss item: 0.45965078473091125
train loss item: 1.0966691970825195
train loss item: 0.10502481460571289
train loss item: 0.2423139065504074
train loss item: 0.09054524451494217
train loss item: 0.4516296684741974
train loss item: 0.2999398112297058
train loss item: 0.13568346202373505
train loss item: 0.2527514696121216
train loss item: 0.17794908583164215
train loss item: 0.17705468833446503
train loss item: 0.08958589285612106
train loss item: 0.18631494045257568
train loss item: 0.19684471189975739
train loss item: 0.08837073296308517
train loss item: 0.10396703332662582
train loss item: 0.3369823694229126
train loss item: 0.9925078749656677
train loss item: 0.08941922336816788
train loss item: 0.18899859488010406
train loss item: 0.11899619549512863
train loss item: 0.13424941897392273
train loss item: 0.15335029363632202
train loss item: 0.356353223323822
train loss item: 0.35139477252960205
train loss item: 0.28941962122917175
train loss item: 2.5638787746429443
train loss item: 0.1067916750907898
train loss item: 0.3483065962791443
test loss item: 0.17343640327453613
test loss item: 0.12675398588180542
test loss item: 0.3089121878147125
test loss item: 0.18620844185352325
test loss item: 0.17388062179088593
test loss item: 0.12049859762191772
test loss item: 1.8897866010665894
test loss item: 0.6998200416564941
test loss item: 0.16522185504436493
test loss item: 0.22745496034622192
test loss item: 0.49880826473236084
test loss item: 0.13479354977607727
test loss item: 0.17148184776306152
test loss item: 0.3276500105857849
test loss item: 0.14264565706253052
test loss item: 0.12216123193502426
test loss item: 0.27646616101264954
test loss item: 0.18621045351028442
test loss item: 0.6756297945976257
test loss item: 0.2862773835659027
test loss item: 0.28828340768814087
test loss item: 0.3936742842197418
test loss item: 0.2604156732559204
test loss item: 0.17184969782829285
test loss item: 0.14294713735580444
test loss item: 0.19398978352546692
test loss item: 0.25740060210227966
test loss item: 0.14781159162521362
test loss item: 0.24506627023220062
test loss item: 0.2323032021522522
test loss item: 0.6875342726707458
test loss item: 0.10216844081878662
test loss item: 0.14368796348571777
test loss item: 0.25951072573661804
test loss item: 0.18635571002960205
test loss item: 0.3708893358707428
test loss item: 0.7915622591972351
test loss item: 0.7009811401367188
test loss item: 0.2576678693294525
test loss item: 0.2570381462574005
test loss item: 0.2883356809616089
test loss item: 0.21200643479824066
test loss item: 0.1624681055545807
test loss item: 0.20841099321842194
test loss item: 0.2657875716686249
test loss item: 0.395454466342926
test loss item: 0.23885320127010345
test loss item: 0.3042204678058624
test loss item: 0.3117564022541046
test loss item: 0.4960673451423645
test loss item: 0.155413419008255
test loss item: 0.1637117862701416
test loss item: 0.18012161552906036
test loss item: 0.1350460946559906
test loss item: 0.13842490315437317
test loss item: 0.40645071864128113
test loss item: 0.4898627698421478
test loss item: 0.19697482883930206
test loss item: 0.20224402844905853
test loss item: 0.11943034827709198
test loss item: 0.18085291981697083
test loss item: 0.28379395604133606
test loss item: 0.21275106072425842
test loss item: 0.19711926579475403
test loss item: 0.6475985646247864
test loss item: 0.23453229665756226
test loss item: 0.28077223896980286
test loss item: 0.24205367267131805
test loss item: 0.26058825850486755
test loss item: 0.4560842216014862
test loss item: 0.12534219026565552
test loss item: 1.1192772388458252
test loss item: 0.3009231984615326
test loss item: 0.4043594300746918
test loss item: 0.1782899647951126
test loss item: 0.19953130185604095
test loss item: 0.1812257468700409
test loss item: 0.7605152130126953
test loss item: 0.3561897575855255
test loss item: 0.16937647759914398
test loss item: 0.10452942550182343
test loss item: 0.83476322889328
test loss item: 0.800007164478302
test loss item: 0.575590193271637
test loss item: 0.2033567577600479
test loss item: 0.21216891705989838
test loss item: 0.10144896060228348
test loss item: 0.10175994038581848
test loss item: 0.1104954406619072
Epoch [6/100], Training Loss: 0.3170, Testing Loss: 0.3134
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/100
train loss item: 0.29462775588035583
train loss item: 0.6790745854377747
train loss item: 0.16626638174057007
train loss item: 0.3189024329185486
train loss item: 0.16653040051460266
train loss item: 0.16099488735198975
train loss item: 0.1660338193178177
train loss item: 0.4153306484222412
train loss item: 0.16996081173419952
train loss item: 0.2018970102071762
train loss item: 0.22501499950885773
train loss item: 0.1571733057498932
train loss item: 0.09697192907333374
train loss item: 0.34369564056396484
train loss item: 0.1697763353586197
train loss item: 0.4066774547100067
train loss item: 0.05788402631878853
train loss item: 0.12781855463981628
train loss item: 0.2377227246761322
train loss item: 0.15513812005519867
train loss item: 0.13318905234336853
train loss item: 0.10050293058156967
train loss item: 0.43736010789871216
train loss item: 0.3840285539627075
train loss item: 0.30919960141181946
train loss item: 0.15081098675727844
train loss item: 0.10159330070018768
train loss item: 0.1971329152584076
train loss item: 0.08115514367818832
train loss item: 0.32921868562698364
train loss item: 1.0890275239944458
train loss item: 0.3467690348625183
train loss item: 0.13572515547275543
train loss item: 0.18733586370944977
train loss item: 0.1148998960852623
train loss item: 1.1531163454055786
train loss item: 0.43655359745025635
train loss item: 0.3566433787345886
train loss item: 0.28132155537605286
train loss item: 0.14848263561725616
train loss item: 0.16165435314178467
train loss item: 0.18671093881130219
train loss item: 0.2817522883415222
train loss item: 0.16286690533161163
train loss item: 0.38074690103530884
train loss item: 0.08309394121170044
train loss item: 0.08952390402555466
train loss item: 0.24935606122016907
train loss item: 0.11975234746932983
train loss item: 0.12155871838331223
train loss item: 0.1968076080083847
train loss item: 0.4274197816848755
train loss item: 0.052215248346328735
train loss item: 0.10862865298986435
train loss item: 1.014438509941101
train loss item: 0.11378800123929977
train loss item: 0.14909280836582184
train loss item: 0.1287958025932312
train loss item: 0.09014911949634552
train loss item: 0.13793815672397614
train loss item: 0.3561669588088989
train loss item: 0.8323434591293335
train loss item: 0.11281774938106537
train loss item: 0.19333116710186005
train loss item: 0.08043437451124191
train loss item: 0.38584521412849426
train loss item: 0.21088629961013794
train loss item: 0.11294996738433838
train loss item: 0.3566722869873047
train loss item: 0.24891112744808197
train loss item: 0.2052064687013626
train loss item: 0.08390989899635315
train loss item: 0.1482195407152176
train loss item: 0.21374602615833282
train loss item: 0.06553962081670761
train loss item: 0.08378811925649643
train loss item: 0.25369495153427124
train loss item: 1.1347510814666748
train loss item: 0.0718509629368782
train loss item: 0.1631438136100769
train loss item: 0.08375727385282516
train loss item: 0.20321820676326752
train loss item: 0.17922091484069824
train loss item: 0.35987669229507446
train loss item: 0.3653695285320282
train loss item: 0.3142188489437103
train loss item: 2.3146281242370605
train loss item: 0.12207164615392685
train loss item: 0.2760896384716034
test loss item: 0.1453768014907837
test loss item: 0.09231063723564148
test loss item: 0.2479974925518036
test loss item: 0.17501002550125122
test loss item: 0.14231760799884796
test loss item: 0.10727867484092712
test loss item: 1.7594728469848633
test loss item: 0.636850893497467
test loss item: 0.1425212323665619
test loss item: 0.19684886932373047
test loss item: 0.401621550321579
test loss item: 0.1261463612318039
test loss item: 0.1466275006532669
test loss item: 0.2707878649234772
test loss item: 0.11553776264190674
test loss item: 0.06909937411546707
test loss item: 0.24745482206344604
test loss item: 0.1632659137248993
test loss item: 0.600810706615448
test loss item: 0.23184359073638916
test loss item: 0.21618527173995972
test loss item: 0.3621177673339844
test loss item: 0.21191704273223877
test loss item: 0.15941636264324188
test loss item: 0.1380138099193573
test loss item: 0.19860637187957764
test loss item: 0.20749124884605408
test loss item: 0.12355104833841324
test loss item: 0.21478216350078583
test loss item: 0.20920966565608978
test loss item: 0.6192141175270081
test loss item: 0.0683601126074791
test loss item: 0.13470180332660675
test loss item: 0.21108806133270264
test loss item: 0.15212500095367432
test loss item: 0.3159962296485901
test loss item: 0.7149578332901001
test loss item: 0.5046953558921814
test loss item: 0.2383423000574112
test loss item: 0.24974820017814636
test loss item: 0.2753691077232361
test loss item: 0.1702248752117157
test loss item: 0.12692011892795563
test loss item: 0.20442891120910645
test loss item: 0.21050004661083221
test loss item: 0.3256027400493622
test loss item: 0.18596258759498596
test loss item: 0.2172820121049881
test loss item: 0.25931039452552795
test loss item: 0.4275354743003845
test loss item: 0.1393415778875351
test loss item: 0.14696656167507172
test loss item: 0.18113590776920319
test loss item: 0.13142815232276917
test loss item: 0.1455615609884262
test loss item: 0.2934522330760956
test loss item: 0.4367029070854187
test loss item: 0.15511085093021393
test loss item: 0.1865266114473343
test loss item: 0.1170395091176033
test loss item: 0.15467889606952667
test loss item: 0.24754489958286285
test loss item: 0.20686954259872437
test loss item: 0.1936112642288208
test loss item: 0.543822169303894
test loss item: 0.22166594862937927
test loss item: 0.2596612870693207
test loss item: 0.22163324058055878
test loss item: 0.18989352881908417
test loss item: 0.4074214696884155
test loss item: 0.06871207058429718
test loss item: 1.030224084854126
test loss item: 0.2425115555524826
test loss item: 0.37941235303878784
test loss item: 0.14527130126953125
test loss item: 0.1535644233226776
test loss item: 0.1642804592847824
test loss item: 0.5087347030639648
test loss item: 0.27847328782081604
test loss item: 0.14712338149547577
test loss item: 0.07406401634216309
test loss item: 0.7482435703277588
test loss item: 0.7308602333068848
test loss item: 0.43534547090530396
test loss item: 0.2069229930639267
test loss item: 0.17001676559448242
test loss item: 0.06339754909276962
test loss item: 0.052917737513780594
test loss item: 0.1383247822523117
Epoch [7/100], Training Loss: 0.2807, Testing Loss: 0.2696
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/100
train loss item: 0.31069251894950867
train loss item: 0.7722635865211487
train loss item: 0.12710480391979218
train loss item: 0.21756930649280548
train loss item: 0.13696850836277008
train loss item: 0.15410040318965912
train loss item: 0.11986466497182846
train loss item: 0.42325055599212646
train loss item: 0.136404350399971
train loss item: 0.20203295350074768
train loss item: 0.2060369849205017
train loss item: 0.15326526761054993
train loss item: 0.08329859375953674
train loss item: 0.29131123423576355
train loss item: 0.13991299271583557
train loss item: 0.35766202211380005
train loss item: 0.07341598719358444
train loss item: 0.12611234188079834
train loss item: 0.23659773170948029
train loss item: 0.15525762736797333
train loss item: 0.14444571733474731
train loss item: 0.07275515049695969
train loss item: 0.5744139552116394
train loss item: 0.3829052746295929
train loss item: 0.2984805107116699
train loss item: 0.13340073823928833
train loss item: 0.09067174792289734
train loss item: 0.16617614030838013
train loss item: 0.08425361663103104
train loss item: 0.4149567782878876
train loss item: 1.3582420349121094
train loss item: 0.41123294830322266
train loss item: 0.07685495913028717
train loss item: 0.1942749172449112
train loss item: 0.11782577633857727
train loss item: 0.9866397976875305
train loss item: 0.4881340563297272
train loss item: 0.42846691608428955
train loss item: 0.35904619097709656
train loss item: 0.29717159271240234
train loss item: 0.16936206817626953
train loss item: 0.18755482137203217
train loss item: 0.30044811964035034
train loss item: 0.19395844638347626
train loss item: 0.5037084817886353
train loss item: 0.08421222120523453
train loss item: 0.08010432869195938
train loss item: 0.3591594994068146
train loss item: 0.19450396299362183
train loss item: 0.1333082765340805
train loss item: 0.21064655482769012
train loss item: 0.6656306385993958
train loss item: 0.06939983367919922
train loss item: 0.10687088966369629
train loss item: 1.0439733266830444
train loss item: 0.12037786096334457
train loss item: 0.2039838433265686
train loss item: 0.15937480330467224
train loss item: 0.10497070103883743
train loss item: 0.13532589375972748
train loss item: 0.3480584919452667
train loss item: 0.7972911596298218
train loss item: 0.12441647052764893
train loss item: 0.24232923984527588
train loss item: 0.10003252327442169
train loss item: 0.35832569003105164
train loss item: 0.1980256587266922
train loss item: 0.11341467499732971
train loss item: 0.34525641798973083
train loss item: 0.20631934702396393
train loss item: 0.17724008858203888
train loss item: 0.09701143205165863
train loss item: 0.15594878792762756
train loss item: 0.18328556418418884
train loss item: 0.07500807195901871
train loss item: 0.08691959828138351
train loss item: 0.25821229815483093
train loss item: 0.9037817716598511
train loss item: 0.06551700085401535
train loss item: 0.1847357302904129
train loss item: 0.08870939910411835
train loss item: 0.17041881382465363
train loss item: 0.14617988467216492
train loss item: 0.42374616861343384
train loss item: 0.43878209590911865
train loss item: 0.23396258056163788
train loss item: 2.175541877746582
train loss item: 0.08576354384422302
train loss item: 0.2222008854150772
test loss item: 0.16456356644630432
test loss item: 0.09363246709108353
test loss item: 0.3359835743904114
test loss item: 0.19370782375335693
test loss item: 0.15255238115787506
test loss item: 0.11404088884592056
test loss item: 2.032405138015747
test loss item: 0.7554088234901428
test loss item: 0.16638325154781342
test loss item: 0.23082104325294495
test loss item: 0.5472571849822998
test loss item: 0.15199719369411469
test loss item: 0.17085032165050507
test loss item: 0.31615132093429565
test loss item: 0.11943305283784866
test loss item: 0.07181056588888168
test loss item: 0.29062214493751526
test loss item: 0.1896476149559021
test loss item: 0.7040677666664124
test loss item: 0.29567787051200867
test loss item: 0.23765283823013306
test loss item: 0.41858649253845215
test loss item: 0.2496233880519867
test loss item: 0.18094515800476074
test loss item: 0.15973713994026184
test loss item: 0.21969881653785706
test loss item: 0.2581101953983307
test loss item: 0.13383795320987701
test loss item: 0.24227271974086761
test loss item: 0.23878684639930725
test loss item: 0.7632843852043152
test loss item: 0.06320954859256744
test loss item: 0.14528341591358185
test loss item: 0.2540087103843689
test loss item: 0.18953274190425873
test loss item: 0.3949945271015167
test loss item: 0.8256194591522217
test loss item: 0.8103769421577454
test loss item: 0.2864249050617218
test loss item: 0.2850705087184906
test loss item: 0.31597235798835754
test loss item: 0.2107844203710556
test loss item: 0.1440175473690033
test loss item: 0.24111458659172058
test loss item: 0.22885611653327942
test loss item: 0.40132033824920654
test loss item: 0.22345933318138123
test loss item: 0.2954838275909424
test loss item: 0.31987571716308594
test loss item: 0.5424673557281494
test loss item: 0.15629304945468903
test loss item: 0.16457845270633698
test loss item: 0.20400099456310272
test loss item: 0.16054949164390564
test loss item: 0.15024833381175995
test loss item: 0.4411274790763855
test loss item: 0.532743513584137
test loss item: 0.1832277476787567
test loss item: 0.2105928510427475
test loss item: 0.12125303596258163
test loss item: 0.18265943229198456
test loss item: 0.29190975427627563
test loss item: 0.23593051731586456
test loss item: 0.21721360087394714
test loss item: 0.6987817287445068
test loss item: 0.24500900506973267
test loss item: 0.3093580901622772
test loss item: 0.2514782249927521
test loss item: 0.24168971180915833
test loss item: 0.5117028951644897
test loss item: 0.07434140890836716
test loss item: 1.197977900505066
test loss item: 0.29569897055625916
test loss item: 0.453182578086853
test loss item: 0.1659366339445114
test loss item: 0.18599693477153778
test loss item: 0.18638697266578674
test loss item: 0.8567608594894409
test loss item: 0.359792560338974
test loss item: 0.16972686350345612
test loss item: 0.07635605335235596
test loss item: 0.9207428097724915
test loss item: 0.8503413200378418
test loss item: 0.6621202230453491
test loss item: 0.22165146470069885
test loss item: 0.19662491977214813
test loss item: 0.06393681466579437
test loss item: 0.058254893869161606
test loss item: 0.1548684686422348
Epoch [8/100], Training Loss: 0.2869, Testing Loss: 0.3263
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/100
train loss item: 0.24746443331241608
train loss item: 0.6722326278686523
train loss item: 0.13063696026802063
train loss item: 0.2518001198768616
train loss item: 0.13588643074035645
train loss item: 0.14563049376010895
train loss item: 0.12381193786859512
train loss item: 0.22769200801849365
train loss item: 0.1043793335556984
train loss item: 0.20028166472911835
train loss item: 0.2702518701553345
train loss item: 0.1661255657672882
train loss item: 0.10503794252872467
train loss item: 0.37849944829940796
train loss item: 0.16011367738246918
train loss item: 0.31739407777786255
train loss item: 0.05545293167233467
train loss item: 0.1694737821817398
train loss item: 0.1530696600675583
train loss item: 0.17461375892162323
train loss item: 0.13227997720241547
train loss item: 0.07521091401576996
train loss item: 0.45326635241508484
train loss item: 0.4576914310455322
train loss item: 0.2461480349302292
train loss item: 0.18453557789325714
train loss item: 0.08785209059715271
train loss item: 0.12407597154378891
train loss item: 0.0562705397605896
train loss item: 0.33268675208091736
train loss item: 1.1739189624786377
train loss item: 0.32223445177078247
train loss item: 0.08905168622732162
train loss item: 0.21286369860172272
train loss item: 0.07282494753599167
train loss item: 0.9111947417259216
train loss item: 0.37557223439216614
train loss item: 0.38519302010536194
train loss item: 0.2753826975822449
train loss item: 0.2792118489742279
train loss item: 0.16586264967918396
train loss item: 0.22735098004341125
train loss item: 0.3236597776412964
train loss item: 0.201341912150383
train loss item: 0.37737831473350525
train loss item: 0.08840272575616837
train loss item: 0.07185392081737518
train loss item: 0.4562358856201172
train loss item: 0.21034257113933563
train loss item: 0.12223532795906067
train loss item: 0.2807832956314087
train loss item: 0.7161772847175598
train loss item: 0.0746019184589386
train loss item: 0.1190595030784607
train loss item: 0.8727970123291016
train loss item: 0.08895771205425262
train loss item: 0.15009669959545135
train loss item: 0.1364525556564331
train loss item: 0.10762695223093033
train loss item: 0.12519770860671997
train loss item: 0.3014889657497406
train loss item: 0.6740025877952576
train loss item: 0.13016323745250702
train loss item: 0.22770023345947266
train loss item: 0.10484259575605392
train loss item: 0.30574700236320496
train loss item: 0.16447488963603973
train loss item: 0.12154155969619751
train loss item: 0.2763780951499939
train loss item: 0.15878920257091522
train loss item: 0.13352768123149872
train loss item: 0.07129999995231628
train loss item: 0.14932700991630554
train loss item: 0.16822578012943268
train loss item: 0.06660662591457367
train loss item: 0.09052344411611557
train loss item: 0.24872329831123352
train loss item: 0.9201434254646301
train loss item: 0.07342415302991867
train loss item: 0.15574979782104492
train loss item: 0.09181369096040726
train loss item: 0.13834935426712036
train loss item: 0.16081777215003967
train loss item: 0.3546416163444519
train loss item: 0.3899003863334656
train loss item: 0.28962451219558716
train loss item: 2.0611276626586914
train loss item: 0.10272564738988876
train loss item: 0.1888909935951233
test loss item: 0.18310385942459106
test loss item: 0.11812178045511246
test loss item: 0.3707675039768219
test loss item: 0.19772842526435852
test loss item: 0.1774994283914566
test loss item: 0.1326485276222229
test loss item: 1.9071484804153442
test loss item: 0.672950029373169
test loss item: 0.17514410614967346
test loss item: 0.2395128756761551
test loss item: 0.5833399891853333
test loss item: 0.1598035842180252
test loss item: 0.18104270100593567
test loss item: 0.38654088973999023
test loss item: 0.1444021463394165
test loss item: 0.08891566842794418
test loss item: 0.28571781516075134
test loss item: 0.2088095247745514
test loss item: 0.6389663219451904
test loss item: 0.2952723205089569
test loss item: 0.2853880822658539
test loss item: 0.39412665367126465
test loss item: 0.2932760417461395
test loss item: 0.18706518411636353
test loss item: 0.16403236985206604
test loss item: 0.21611826121807098
test loss item: 0.2635415494441986
test loss item: 0.15387429296970367
test loss item: 0.25795692205429077
test loss item: 0.24970678985118866
test loss item: 0.7364728450775146
test loss item: 0.08620108664035797
test loss item: 0.15695783495903015
test loss item: 0.2775980532169342
test loss item: 0.21883194148540497
test loss item: 0.34511637687683105
test loss item: 0.7773826718330383
test loss item: 0.9106215834617615
test loss item: 0.29505813121795654
test loss item: 0.2780449092388153
test loss item: 0.3100707530975342
test loss item: 0.23698818683624268
test loss item: 0.15804919600486755
test loss item: 0.23559176921844482
test loss item: 0.2814303934574127
test loss item: 0.3765534460544586
test loss item: 0.2539342939853668
test loss item: 0.31246060132980347
test loss item: 0.3190489709377289
test loss item: 0.5120628476142883
test loss item: 0.18527890741825104
test loss item: 0.1803133338689804
test loss item: 0.20403125882148743
test loss item: 0.1586523950099945
test loss item: 0.16392208635807037
test loss item: 0.4980792999267578
test loss item: 0.48623955249786377
test loss item: 0.2273540049791336
test loss item: 0.21665246784687042
test loss item: 0.13074450194835663
test loss item: 0.19643534719944
test loss item: 0.2738639712333679
test loss item: 0.24025322496891022
test loss item: 0.22615604102611542
test loss item: 0.7137235403060913
test loss item: 0.24486781656742096
test loss item: 0.3000200092792511
test loss item: 0.25065112113952637
test loss item: 0.2766183316707611
test loss item: 0.419027715921402
test loss item: 0.08881818503141403
test loss item: 1.105368733406067
test loss item: 0.3477405309677124
test loss item: 0.4389042258262634
test loss item: 0.17312802374362946
test loss item: 0.217777281999588
test loss item: 0.19354024529457092
test loss item: 1.00545334815979
test loss item: 0.4291948676109314
test loss item: 0.18672232329845428
test loss item: 0.08874081820249557
test loss item: 0.889136552810669
test loss item: 0.7980656623840332
test loss item: 0.7358264327049255
test loss item: 0.2387523204088211
test loss item: 0.19565264880657196
test loss item: 0.07430136948823929
test loss item: 0.07115153223276138
test loss item: 0.13664306700229645
Epoch [9/100], Training Loss: 0.2660, Testing Loss: 0.3337
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/100
train loss item: 0.23389679193496704
train loss item: 0.6644536852836609
train loss item: 0.14344598352909088
train loss item: 0.26150837540626526
train loss item: 0.13333503901958466
train loss item: 0.14298130571842194
train loss item: 0.1004064530134201
train loss item: 0.23125210404396057
train loss item: 0.07828350365161896
train loss item: 0.18499711155891418
train loss item: 0.23493602871894836
train loss item: 0.1472126692533493
train loss item: 0.0894208550453186
train loss item: 0.3828592598438263
train loss item: 0.15785324573516846
train loss item: 0.4308154881000519
train loss item: 0.056338656693696976
train loss item: 0.1378604918718338
train loss item: 0.18864133954048157
train loss item: 0.18779157102108002
train loss item: 0.10403038561344147
train loss item: 0.09664016216993332
train loss item: 0.570580005645752
train loss item: 0.2868679165840149
train loss item: 0.2766973078250885
train loss item: 0.1759471893310547
train loss item: 0.08628754317760468
train loss item: 0.12410856783390045
train loss item: 0.06654073297977448
train loss item: 0.2727832496166229
train loss item: 0.8483908772468567
train loss item: 0.34925100207328796
train loss item: 0.08664136379957199
train loss item: 0.1669187843799591
train loss item: 0.08352695405483246
train loss item: 0.7441481947898865
train loss item: 0.34178653359413147
train loss item: 0.3387190103530884
train loss item: 0.21667803823947906
train loss item: 0.17401428520679474
train loss item: 0.16644054651260376
train loss item: 0.2217690646648407
train loss item: 0.30561867356300354
train loss item: 0.18763190507888794
train loss item: 0.3189585506916046
train loss item: 0.08398352563381195
train loss item: 0.07233481109142303
train loss item: 0.419024795293808
train loss item: 0.1901855766773224
train loss item: 0.11255252361297607
train loss item: 0.2297987937927246
train loss item: 0.6116355657577515
train loss item: 0.09713465720415115
train loss item: 0.12781138718128204
train loss item: 0.6475275158882141
train loss item: 0.08994562178850174
train loss item: 0.16527922451496124
train loss item: 0.1548183560371399
train loss item: 0.1160004660487175
train loss item: 0.11458853632211685
train loss item: 0.3179948627948761
train loss item: 0.6022362112998962
train loss item: 0.10885939002037048
train loss item: 0.2532917261123657
train loss item: 0.09486362338066101
train loss item: 0.26217204332351685
train loss item: 0.2057313472032547
train loss item: 0.10986006259918213
train loss item: 0.2481609582901001
train loss item: 0.14608103036880493
train loss item: 0.11365832388401031
train loss item: 0.08163218200206757
train loss item: 0.12390048056840897
train loss item: 0.10597337037324905
train loss item: 0.09421712905168533
train loss item: 0.10684844106435776
train loss item: 0.21396474540233612
train loss item: 1.0922901630401611
train loss item: 0.07798589020967484
train loss item: 0.18177878856658936
train loss item: 0.12744839489459991
train loss item: 0.14963464438915253
train loss item: 0.13397075235843658
train loss item: 0.3206985592842102
train loss item: 0.3014315962791443
train loss item: 0.2518998980522156
train loss item: 1.7920620441436768
train loss item: 0.10046350955963135
train loss item: 0.18386104702949524
test loss item: 0.18525339663028717
test loss item: 0.07713756710290909
test loss item: 0.5153390765190125
test loss item: 0.19838963449001312
test loss item: 0.18733248114585876
test loss item: 0.12042161077260971
test loss item: 1.5632095336914062
test loss item: 0.5512701869010925
test loss item: 0.19895130395889282
test loss item: 0.29340097308158875
test loss item: 0.7488066554069519
test loss item: 0.14538036286830902
test loss item: 0.16487228870391846
test loss item: 0.34885266423225403
test loss item: 0.13461366295814514
test loss item: 0.06715453416109085
test loss item: 0.2930694818496704
test loss item: 0.3135601282119751
test loss item: 0.5509366989135742
test loss item: 0.27949458360671997
test loss item: 0.46699970960617065
test loss item: 0.35845670104026794
test loss item: 0.3045025169849396
test loss item: 0.16416729986667633
test loss item: 0.18710318207740784
test loss item: 0.18135491013526917
test loss item: 0.26634299755096436
test loss item: 0.1357552707195282
test loss item: 0.25596392154693604
test loss item: 0.251010537147522
test loss item: 0.737194299697876
test loss item: 0.07871777564287186
test loss item: 0.1435997635126114
test loss item: 0.3969615697860718
test loss item: 0.31264516711235046
test loss item: 0.3420734405517578
test loss item: 0.6621840000152588
test loss item: 1.2803469896316528
test loss item: 0.34962186217308044
test loss item: 0.24801474809646606
test loss item: 0.2823614478111267
test loss item: 0.24670293927192688
test loss item: 0.2528615891933441
test loss item: 0.23998600244522095
test loss item: 0.38459116220474243
test loss item: 0.3656097948551178
test loss item: 0.2821677029132843
test loss item: 0.26323747634887695
test loss item: 0.39280062913894653
test loss item: 0.5819666385650635
test loss item: 0.21840354800224304
test loss item: 0.14288246631622314
test loss item: 0.21999043226242065
test loss item: 0.18888172507286072
test loss item: 0.21366959810256958
test loss item: 0.6995115280151367
test loss item: 0.4672476351261139
test loss item: 0.22274714708328247
test loss item: 0.21980364620685577
test loss item: 0.130956768989563
test loss item: 0.2961083948612213
test loss item: 0.26977071166038513
test loss item: 0.2267715334892273
test loss item: 0.1911608874797821
test loss item: 0.7982361912727356
test loss item: 0.254095196723938
test loss item: 0.29530051350593567
test loss item: 0.2182626575231552
test loss item: 0.36804473400115967
test loss item: 0.3849552571773529
test loss item: 0.059983864426612854
test loss item: 0.9148067831993103
test loss item: 0.36032986640930176
test loss item: 0.4109553098678589
test loss item: 0.18778659403324127
test loss item: 0.22327016294002533
test loss item: 0.16307438910007477
test loss item: 1.3840655088424683
test loss item: 0.42236360907554626
test loss item: 0.18999184668064117
test loss item: 0.07343307137489319
test loss item: 0.90543133020401
test loss item: 0.7283285856246948
test loss item: 0.9597517848014832
test loss item: 0.20944461226463318
test loss item: 0.22988641262054443
test loss item: 0.07279027998447418
test loss item: 0.06948041170835495
test loss item: 0.12506453692913055
Epoch [10/100], Training Loss: 0.2465, Testing Loss: 0.3491
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 11/100
train loss item: 0.24692943692207336
train loss item: 0.4923757016658783
train loss item: 0.12047514319419861
train loss item: 0.25849562883377075
train loss item: 0.1341867744922638
train loss item: 0.15141402184963226
train loss item: 0.16545577347278595
train loss item: 0.4398009777069092
train loss item: 0.08053632825613022
train loss item: 0.15259931981563568
train loss item: 0.19952154159545898
train loss item: 0.14127561450004578
train loss item: 0.10301612317562103
train loss item: 0.3856988251209259
train loss item: 0.15846101939678192
train loss item: 0.25709083676338196
train loss item: 0.046808067709207535
train loss item: 0.08946908265352249
train loss item: 0.19387036561965942
train loss item: 0.13754916191101074
train loss item: 0.09972137957811356
train loss item: 0.0928572416305542
train loss item: 0.3168012797832489
train loss item: 0.3084787428379059
train loss item: 0.2185843586921692
train loss item: 0.1483522653579712
train loss item: 0.0682535171508789
train loss item: 0.11662130802869797
train loss item: 0.06481263041496277
train loss item: 0.22596754133701324
train loss item: 0.470603883266449
train loss item: 0.43517258763313293
train loss item: 0.07569665461778641
train loss item: 0.20184704661369324
train loss item: 0.08244837075471878
train loss item: 0.6804948449134827
train loss item: 0.3461282551288605
train loss item: 0.33864134550094604
train loss item: 0.22372817993164062
train loss item: 0.1430119425058365
train loss item: 0.17234234511852264
train loss item: 0.19954751431941986
train loss item: 0.3113647401332855
train loss item: 0.1794363558292389
train loss item: 0.30246296525001526
train loss item: 0.08009515702724457
train loss item: 0.07807645201683044
train loss item: 0.38038527965545654
train loss item: 0.1568242609500885
train loss item: 0.09445995092391968
train loss item: 0.19839422404766083
train loss item: 0.40478968620300293
train loss item: 0.06293138861656189
train loss item: 0.11273130774497986
train loss item: 0.5831560492515564
train loss item: 0.08808407932519913
train loss item: 0.15965448319911957
train loss item: 0.11408717185258865
train loss item: 0.12082824110984802
train loss item: 0.138172447681427
train loss item: 0.296372652053833
train loss item: 0.5277395844459534
train loss item: 0.08974532783031464
train loss item: 0.18543455004692078
train loss item: 0.06217925623059273
train loss item: 0.26630541682243347
train loss item: 0.13598616421222687
train loss item: 0.10796664655208588
train loss item: 0.28481024503707886
train loss item: 0.1811244785785675
train loss item: 0.11589144170284271
train loss item: 0.08287850767374039
train loss item: 0.09758760780096054
train loss item: 0.16697034239768982
train loss item: 0.07166005671024323
train loss item: 0.08704912662506104
train loss item: 0.2087489664554596
train loss item: 0.8262407183647156
train loss item: 0.06563889235258102
train loss item: 0.14375892281532288
train loss item: 0.06587498635053635
train loss item: 0.12310941517353058
train loss item: 0.15808868408203125
train loss item: 0.434347927570343
train loss item: 0.45442938804626465
train loss item: 0.3287867307662964
train loss item: 1.6234337091445923
train loss item: 0.07720128446817398
train loss item: 0.160840705037117
test loss item: 0.15963232517242432
test loss item: 0.08425410091876984
test loss item: 0.36364591121673584
test loss item: 0.1916750818490982
test loss item: 0.15070118010044098
test loss item: 0.12071714550256729
test loss item: 1.7540943622589111
test loss item: 0.6268022656440735
test loss item: 0.16209881007671356
test loss item: 0.22762589156627655
test loss item: 0.5611861348152161
test loss item: 0.16071531176567078
test loss item: 0.18705835938453674
test loss item: 0.30651530623435974
test loss item: 0.11902941018342972
test loss item: 0.058627765625715256
test loss item: 0.2883020043373108
test loss item: 0.2006353735923767
test loss item: 0.5848140120506287
test loss item: 0.2885509431362152
test loss item: 0.2831462621688843
test loss item: 0.37404704093933105
test loss item: 0.25157544016838074
test loss item: 0.1690463274717331
test loss item: 0.17572535574436188
test loss item: 0.222237229347229
test loss item: 0.24900098145008087
test loss item: 0.12645985186100006
test loss item: 0.22978948056697845
test loss item: 0.24191798269748688
test loss item: 0.6882944703102112
test loss item: 0.06069258227944374
test loss item: 0.14231961965560913
test loss item: 0.2631068825721741
test loss item: 0.2043582648038864
test loss item: 0.32895001769065857
test loss item: 0.6994800567626953
test loss item: 0.8885957598686218
test loss item: 0.2789517939090729
test loss item: 0.2604033648967743
test loss item: 0.2954980432987213
test loss item: 0.2184649407863617
test loss item: 0.15097510814666748
test loss item: 0.24326688051223755
test loss item: 0.26202961802482605
test loss item: 0.3725023865699768
test loss item: 0.22753794491291046
test loss item: 0.2852920591831207
test loss item: 0.3123219311237335
test loss item: 0.4842938482761383
test loss item: 0.16223081946372986
test loss item: 0.1917300969362259
test loss item: 0.20917218923568726
test loss item: 0.17929808795452118
test loss item: 0.16811993718147278
test loss item: 0.4738435447216034
test loss item: 0.461637943983078
test loss item: 0.193158358335495
test loss item: 0.21643054485321045
test loss item: 0.12907283008098602
test loss item: 0.16435061395168304
test loss item: 0.2743893265724182
test loss item: 0.23519127070903778
test loss item: 0.21475911140441895
test loss item: 0.7028520703315735
test loss item: 0.24245186150074005
test loss item: 0.30693018436431885
test loss item: 0.23796524107456207
test loss item: 0.26221904158592224
test loss item: 0.4080236256122589
test loss item: 0.06307747215032578
test loss item: 1.030863642692566
test loss item: 0.29600200057029724
test loss item: 0.418874591588974
test loss item: 0.17908625304698944
test loss item: 0.18669834733009338
test loss item: 0.17153064906597137
test loss item: 1.03052818775177
test loss item: 0.3658478260040283
test loss item: 0.16693200170993805
test loss item: 0.06892195343971252
test loss item: 0.8485868573188782
test loss item: 0.7250383496284485
test loss item: 0.7438780665397644
test loss item: 0.2320478856563568
test loss item: 0.2127697467803955
test loss item: 0.056941259652376175
test loss item: 0.05143307149410248
test loss item: 0.16314272582530975
Epoch [11/100], Training Loss: 0.2245, Testing Loss: 0.3150
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 12/100
train loss item: 0.23176446557044983
train loss item: 0.6954120397567749
train loss item: 0.1051778718829155
train loss item: 0.17027242481708527
train loss item: 0.10521789640188217
train loss item: 0.131994366645813
train loss item: 0.09783081710338593
train loss item: 0.199549600481987
train loss item: 0.08406926691532135
train loss item: 0.1403457671403885
train loss item: 0.15431879460811615
train loss item: 0.13663721084594727
train loss item: 0.08562958240509033
train loss item: 0.29084861278533936
train loss item: 0.13461002707481384
train loss item: 0.3565678596496582
train loss item: 0.046511828899383545
train loss item: 0.12904435396194458
train loss item: 0.12907952070236206
train loss item: 0.16813924908638
train loss item: 0.09212593734264374
train loss item: 0.09431895613670349
train loss item: 0.5798218846321106
train loss item: 0.3473588228225708
train loss item: 0.227395161986351
train loss item: 0.1644456386566162
train loss item: 0.07918020337820053
train loss item: 0.10837187618017197
train loss item: 0.05611337348818779
train loss item: 0.30686822533607483
train loss item: 1.2110722064971924
train loss item: 0.3193047046661377
train loss item: 0.09918000549077988
train loss item: 0.1732243299484253
train loss item: 0.11592230200767517
train loss item: 0.5627307295799255
train loss item: 0.3911363184452057
train loss item: 0.365578293800354
train loss item: 0.31549838185310364
train loss item: 0.2494126558303833
train loss item: 0.1691395789384842
train loss item: 0.2322482019662857
train loss item: 0.31812208890914917
train loss item: 0.2128089964389801
train loss item: 0.366759717464447
train loss item: 0.0873691514134407
train loss item: 0.08745168149471283
train loss item: 0.49946480989456177
train loss item: 0.2100602090358734
train loss item: 0.11480561643838882
train loss item: 0.3714398145675659
train loss item: 0.9677728414535522
train loss item: 0.09532059729099274
train loss item: 0.13763202726840973
train loss item: 0.738945484161377
train loss item: 0.12671418488025665
train loss item: 0.13870035111904144
train loss item: 0.15037955343723297
train loss item: 0.13147605955600739
train loss item: 0.12152788788080215
train loss item: 0.3891908824443817
train loss item: 0.5815969109535217
train loss item: 0.1502525806427002
train loss item: 0.21044552326202393
train loss item: 0.1449669450521469
train loss item: 0.4411897659301758
train loss item: 0.1786240190267563
train loss item: 0.13554999232292175
train loss item: 0.23453259468078613
train loss item: 0.13277305662631989
train loss item: 0.10586796700954437
train loss item: 0.06728805601596832
train loss item: 0.14223532378673553
train loss item: 0.20016224682331085
train loss item: 0.0742967277765274
train loss item: 0.08898496627807617
train loss item: 0.3150179088115692
train loss item: 1.0095123052597046
train loss item: 0.06331290304660797
train loss item: 0.14944997429847717
train loss item: 0.07829412817955017
train loss item: 0.10760483145713806
train loss item: 0.12223100662231445
train loss item: 0.3789306581020355
train loss item: 0.30854037404060364
train loss item: 0.24739506840705872
train loss item: 1.4755958318710327
train loss item: 0.11979437619447708
train loss item: 0.21295496821403503
test loss item: 0.1360386610031128
test loss item: 0.10236606746912003
test loss item: 0.4935370683670044
test loss item: 0.17449267208576202
test loss item: 0.19361364841461182
test loss item: 0.11716407537460327
test loss item: 1.7274413108825684
test loss item: 0.5966460108757019
test loss item: 0.17849047482013702
test loss item: 0.27582645416259766
test loss item: 0.7324752807617188
test loss item: 0.11619627475738525
test loss item: 0.13981270790100098
test loss item: 0.18935588002204895
test loss item: 0.15327274799346924
test loss item: 0.062282949686050415
test loss item: 0.23926185071468353
test loss item: 0.31521302461624146
test loss item: 0.5885077714920044
test loss item: 0.22342000901699066
test loss item: 0.5112713575363159
test loss item: 0.3480880856513977
test loss item: 0.23271650075912476
test loss item: 0.17373238503932953
test loss item: 0.14667533338069916
test loss item: 0.23364605009555817
test loss item: 0.22203189134597778
test loss item: 0.14208222925662994
test loss item: 0.2393772453069687
test loss item: 0.2290012240409851
test loss item: 0.7651889324188232
test loss item: 0.06269178539514542
test loss item: 0.1553933471441269
test loss item: 0.3838439881801605
test loss item: 0.32065045833587646
test loss item: 0.31679877638816833
test loss item: 0.710730791091919
test loss item: 1.2521449327468872
test loss item: 0.34440985321998596
test loss item: 0.25381237268447876
test loss item: 0.25648602843284607
test loss item: 0.15436774492263794
test loss item: 0.22433267533779144
test loss item: 0.1897253692150116
test loss item: 0.39399978518486023
test loss item: 0.34087496995925903
test loss item: 0.20171184837818146
test loss item: 0.17886187136173248
test loss item: 0.380891352891922
test loss item: 0.5675431489944458
test loss item: 0.22228696942329407
test loss item: 0.11468107253313065
test loss item: 0.20719251036643982
test loss item: 0.12182775139808655
test loss item: 0.2519178092479706
test loss item: 0.6879953742027283
test loss item: 0.48045629262924194
test loss item: 0.18471871316432953
test loss item: 0.21569131314754486
test loss item: 0.15930259227752686
test loss item: 0.27495628595352173
test loss item: 0.2466518133878708
test loss item: 0.23539495468139648
test loss item: 0.17293982207775116
test loss item: 0.8327963948249817
test loss item: 0.20748694241046906
test loss item: 0.28903284668922424
test loss item: 0.20226745307445526
test loss item: 0.38022342324256897
test loss item: 0.3976250886917114
test loss item: 0.055218424648046494
test loss item: 1.0022649765014648
test loss item: 0.25042709708213806
test loss item: 0.3817117512226105
test loss item: 0.12348761409521103
test loss item: 0.1266127973794937
test loss item: 0.16898536682128906
test loss item: 1.3879235982894897
test loss item: 0.32630833983421326
test loss item: 0.14844253659248352
test loss item: 0.07705257087945938
test loss item: 0.9426482915878296
test loss item: 0.7634084224700928
test loss item: 0.956031322479248
test loss item: 0.23353911936283112
test loss item: 0.15906843543052673
test loss item: 0.07522308826446533
test loss item: 0.05940818786621094
test loss item: 0.19316111505031586
Epoch [12/100], Training Loss: 0.2539, Testing Loss: 0.3371
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 13/100
train loss item: 0.21771058440208435
train loss item: 0.43539637327194214
train loss item: 0.11492655426263809
train loss item: 0.16325508058071136
train loss item: 0.11612852662801743
train loss item: 0.15541338920593262
train loss item: 0.1262352019548416
train loss item: 0.39171016216278076
train loss item: 0.07072782516479492
train loss item: 0.1510666310787201
train loss item: 0.149689719080925
train loss item: 0.13477672636508942
train loss item: 0.09876309335231781
train loss item: 0.3168158531188965
train loss item: 0.14018163084983826
train loss item: 0.25114330649375916
train loss item: 0.05859201028943062
train loss item: 0.10006225854158401
train loss item: 0.21887090802192688
train loss item: 0.13724768161773682
train loss item: 0.09244368970394135
train loss item: 0.09860293567180634
train loss item: 0.23336532711982727
train loss item: 0.30506569147109985
train loss item: 0.25658637285232544
train loss item: 0.14970742166042328
train loss item: 0.06547129899263382
train loss item: 0.13854224979877472
train loss item: 0.0543159618973732
train loss item: 0.3014557361602783
train loss item: 0.3881876766681671
train loss item: 0.3297916352748871
train loss item: 0.05923115089535713
train loss item: 0.1366703361272812
train loss item: 0.11984729021787643
train loss item: 0.5238679647445679
train loss item: 0.4428534209728241
train loss item: 0.4151557981967926
train loss item: 0.24441100656986237
train loss item: 0.14083677530288696
train loss item: 0.16839003562927246
train loss item: 0.17275774478912354
train loss item: 0.29021427035331726
train loss item: 0.200368732213974
train loss item: 0.2952028512954712
train loss item: 0.08763039857149124
train loss item: 0.08461236208677292
train loss item: 0.47570136189460754
train loss item: 0.17740969359874725
train loss item: 0.11146688461303711
train loss item: 0.32229122519493103
train loss item: 0.7616666555404663
train loss item: 0.06899667531251907
train loss item: 0.11465087532997131
train loss item: 0.6102120280265808
train loss item: 0.11427821964025497
train loss item: 0.14609040319919586
train loss item: 0.12576532363891602
train loss item: 0.11829321831464767
train loss item: 0.12743735313415527
train loss item: 0.43363094329833984
train loss item: 0.5494062900543213
train loss item: 0.1095196083188057
train loss item: 0.1699594408273697
train loss item: 0.13134649395942688
train loss item: 0.3390687108039856
train loss item: 0.18697525560855865
train loss item: 0.16118934750556946
train loss item: 0.15953896939754486
train loss item: 0.12454628944396973
train loss item: 0.09016264230012894
train loss item: 0.06508441269397736
train loss item: 0.11784226447343826
train loss item: 0.2133072465658188
train loss item: 0.09221870452165604
train loss item: 0.10464926064014435
train loss item: 0.3522138297557831
train loss item: 1.0607366561889648
train loss item: 0.0553295873105526
train loss item: 0.19328951835632324
train loss item: 0.055688027292490005
train loss item: 0.0884908065199852
train loss item: 0.09878119826316833
train loss item: 0.34998559951782227
train loss item: 0.3163440227508545
train loss item: 0.24817737936973572
train loss item: 1.3317431211471558
train loss item: 0.06494046747684479
train loss item: 0.185164213180542
test loss item: 0.12528985738754272
test loss item: 0.07786860316991806
test loss item: 0.4661005437374115
test loss item: 0.15236714482307434
test loss item: 0.1673877239227295
test loss item: 0.0902276262640953
test loss item: 1.4480907917022705
test loss item: 0.46097058057785034
test loss item: 0.16140994429588318
test loss item: 0.24318328499794006
test loss item: 0.7001270651817322
test loss item: 0.10088426619768143
test loss item: 0.12122299522161484
test loss item: 0.1768382042646408
test loss item: 0.124311663210392
test loss item: 0.06340856850147247
test loss item: 0.22898000478744507
test loss item: 0.2737937271595001
test loss item: 0.4953633248806
test loss item: 0.20588523149490356
test loss item: 0.44145217537879944
test loss item: 0.3037492334842682
test loss item: 0.1946256160736084
test loss item: 0.14771676063537598
test loss item: 0.13384458422660828
test loss item: 0.16474328935146332
test loss item: 0.2126467227935791
test loss item: 0.11398304253816605
test loss item: 0.22079384326934814
test loss item: 0.20571032166481018
test loss item: 0.6681832075119019
test loss item: 0.06615600734949112
test loss item: 0.1281159520149231
test loss item: 0.3498665690422058
test loss item: 0.28480175137519836
test loss item: 0.26065772771835327
test loss item: 0.6027362942695618
test loss item: 1.2107871770858765
test loss item: 0.29856204986572266
test loss item: 0.22364681959152222
test loss item: 0.24229738116264343
test loss item: 0.1162278950214386
test loss item: 0.20200888812541962
test loss item: 0.17511004209518433
test loss item: 0.3409038484096527
test loss item: 0.31810978055000305
test loss item: 0.17539572715759277
test loss item: 0.16168443858623505
test loss item: 0.34216588735580444
test loss item: 0.5056378245353699
test loss item: 0.17956840991973877
test loss item: 0.09672373533248901
test loss item: 0.17269311845302582
test loss item: 0.10073859989643097
test loss item: 0.18720974028110504
test loss item: 0.6492849588394165
test loss item: 0.4108675718307495
test loss item: 0.16356851160526276
test loss item: 0.17858906090259552
test loss item: 0.10832864046096802
test loss item: 0.24827724695205688
test loss item: 0.2151564210653305
test loss item: 0.16079698503017426
test loss item: 0.1690002977848053
test loss item: 0.7722184658050537
test loss item: 0.19397862255573273
test loss item: 0.24470731616020203
test loss item: 0.192879781126976
test loss item: 0.35408586263656616
test loss item: 0.32243382930755615
test loss item: 0.05255028232932091
test loss item: 0.8353014588356018
test loss item: 0.20577427744865417
test loss item: 0.3285713195800781
test loss item: 0.11447534710168839
test loss item: 0.10906518995761871
test loss item: 0.14766322076320648
test loss item: 1.3583273887634277
test loss item: 0.30559951066970825
test loss item: 0.11688492447137833
test loss item: 0.0686262771487236
test loss item: 0.8571158051490784
test loss item: 0.6507377028465271
test loss item: 0.9254705309867859
test loss item: 0.1565963476896286
test loss item: 0.15170235931873322
test loss item: 0.07120748609304428
test loss item: 0.06708226352930069
test loss item: 0.10748298466205597
Epoch [13/100], Training Loss: 0.2255, Testing Loss: 0.2972
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 14/100
train loss item: 0.22879812121391296
train loss item: 0.28945422172546387
train loss item: 0.08119107037782669
train loss item: 0.1748272180557251
train loss item: 0.133629709482193
train loss item: 0.13637831807136536
train loss item: 0.08279833942651749
train loss item: 0.4362037479877472
train loss item: 0.06082773953676224
train loss item: 0.12982745468616486
train loss item: 0.13587455451488495
train loss item: 0.12797094881534576
train loss item: 0.08356161415576935
train loss item: 0.3053017556667328
train loss item: 0.1407175213098526
train loss item: 0.3586984872817993
train loss item: 0.05080442130565643
train loss item: 0.08856088668107986
train loss item: 0.18033543229103088
train loss item: 0.17485712468624115
train loss item: 0.08408791571855545
train loss item: 0.11688409745693207
train loss item: 0.22816824913024902
train loss item: 0.37104105949401855
train loss item: 0.22210045158863068
train loss item: 0.1449749767780304
train loss item: 0.10590548813343048
train loss item: 0.12647265195846558
train loss item: 0.0597744956612587
train loss item: 0.2566951811313629
train loss item: 0.546040415763855
train loss item: 0.1999342441558838
train loss item: 0.08000301569700241
train loss item: 0.17551198601722717
train loss item: 0.0796084925532341
train loss item: 0.4867728650569916
train loss item: 0.36364179849624634
train loss item: 0.33092784881591797
train loss item: 0.3577861487865448
train loss item: 0.13979946076869965
train loss item: 0.13780266046524048
train loss item: 0.12969331443309784
train loss item: 0.2306957244873047
train loss item: 0.1735578030347824
train loss item: 0.3775078356266022
train loss item: 0.0733359232544899
train loss item: 0.05107566714286804
train loss item: 0.2921631336212158
train loss item: 0.13932107388973236
train loss item: 0.07289185374975204
train loss item: 0.1473466157913208
train loss item: 0.4347417652606964
train loss item: 0.04752852022647858
train loss item: 0.08627757430076599
train loss item: 0.47227731347084045
train loss item: 0.08283409476280212
train loss item: 0.13548186421394348
train loss item: 0.125528946518898
train loss item: 0.07919502258300781
train loss item: 0.10568689554929733
train loss item: 0.2672470808029175
train loss item: 0.5391870141029358
train loss item: 0.09376993030309677
train loss item: 0.16577468812465668
train loss item: 0.07932665199041367
train loss item: 0.19900000095367432
train loss item: 0.1401287466287613
train loss item: 0.09093033522367477
train loss item: 0.21620021760463715
train loss item: 0.1098528578877449
train loss item: 0.09462641179561615
train loss item: 0.05409843474626541
train loss item: 0.0688445195555687
train loss item: 0.11330104619264603
train loss item: 0.05579535290598869
train loss item: 0.07429704815149307
train loss item: 0.1918061226606369
train loss item: 0.8659849166870117
train loss item: 0.042791418731212616
train loss item: 0.1321452558040619
train loss item: 0.07041346281766891
train loss item: 0.08424749970436096
train loss item: 0.10022414475679398
train loss item: 0.31905126571655273
train loss item: 0.2752280831336975
train loss item: 0.18334178626537323
train loss item: 1.2298328876495361
train loss item: 0.05414307489991188
train loss item: 0.16578415036201477
test loss item: 0.14469526708126068
test loss item: 0.06982094049453735
test loss item: 0.38013598322868347
test loss item: 0.16806723177433014
test loss item: 0.14253069460391998
test loss item: 0.09585759788751602
test loss item: 1.6494773626327515
test loss item: 0.5770508646965027
test loss item: 0.15106390416622162
test loss item: 0.22318428754806519
test loss item: 0.5433123707771301
test loss item: 0.12352965772151947
test loss item: 0.13912463188171387
test loss item: 0.2599703371524811
test loss item: 0.11068271845579147
test loss item: 0.06490682810544968
test loss item: 0.26464372873306274
test loss item: 0.22632896900177002
test loss item: 0.5417923331260681
test loss item: 0.25136351585388184
test loss item: 0.364712655544281
test loss item: 0.35435086488723755
test loss item: 0.21663294732570648
test loss item: 0.1674596071243286
test loss item: 0.14464052021503448
test loss item: 0.1904117465019226
test loss item: 0.23097698390483856
test loss item: 0.11368316411972046
test loss item: 0.22466762363910675
test loss item: 0.20523813366889954
test loss item: 0.6572105288505554
test loss item: 0.07149510085582733
test loss item: 0.13802731037139893
test loss item: 0.28753530979156494
test loss item: 0.22865258157253265
test loss item: 0.27444231510162354
test loss item: 0.6608221530914307
test loss item: 0.8843079209327698
test loss item: 0.2808067500591278
test loss item: 0.2525315582752228
test loss item: 0.27195942401885986
test loss item: 0.15838158130645752
test loss item: 0.15870806574821472
test loss item: 0.20964963734149933
test loss item: 0.30456632375717163
test loss item: 0.3669816851615906
test loss item: 0.19883985817432404
test loss item: 0.21692444384098053
test loss item: 0.31995710730552673
test loss item: 0.46399345993995667
test loss item: 0.17056649923324585
test loss item: 0.1175498440861702
test loss item: 0.18767504394054413
test loss item: 0.1336476057767868
test loss item: 0.1665256917476654
test loss item: 0.49082502722740173
test loss item: 0.41949039697647095
test loss item: 0.17533570528030396
test loss item: 0.19969791173934937
test loss item: 0.10871350020170212
test loss item: 0.19359177350997925
test loss item: 0.2612570524215698
test loss item: 0.20765458047389984
test loss item: 0.17815729975700378
test loss item: 0.6765593886375427
test loss item: 0.21062031388282776
test loss item: 0.2814938724040985
test loss item: 0.20883485674858093
test loss item: 0.28032663464546204
test loss item: 0.36428308486938477
test loss item: 0.05838021636009216
test loss item: 0.9724555611610413
test loss item: 0.2610195577144623
test loss item: 0.3956594169139862
test loss item: 0.1418217569589615
test loss item: 0.14730800688266754
test loss item: 0.1663622260093689
test loss item: 0.9983164668083191
test loss item: 0.3230994939804077
test loss item: 0.1406686007976532
test loss item: 0.08088099956512451
test loss item: 0.8002238869667053
test loss item: 0.6961257457733154
test loss item: 0.7066823840141296
test loss item: 0.19031353294849396
test loss item: 0.17256321012973785
test loss item: 0.07496318966150284
test loss item: 0.07386181503534317
test loss item: 0.11590823531150818
Epoch [14/100], Training Loss: 0.1949, Testing Loss: 0.2955
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 15/100
train loss item: 0.1872558742761612
train loss item: 0.5628393292427063
train loss item: 0.10940367728471756
train loss item: 0.17034591734409332
train loss item: 0.14835615456104279
train loss item: 0.13607557117938995
train loss item: 0.08175952732563019
train loss item: 0.18240053951740265
train loss item: 0.07703321427106857
train loss item: 0.12740731239318848
train loss item: 0.12345851212739944
train loss item: 0.13402846455574036
train loss item: 0.07808335870504379
train loss item: 0.3031596839427948
train loss item: 0.12634553015232086
train loss item: 0.2892032563686371
train loss item: 0.040134675800800323
train loss item: 0.09061085432767868
train loss item: 0.2052665501832962
train loss item: 0.1240113154053688
train loss item: 0.07302819192409515
train loss item: 0.126677006483078
train loss item: 0.3670872151851654
train loss item: 0.24978241324424744
train loss item: 0.2248891144990921
train loss item: 0.12749908864498138
train loss item: 0.06831296533346176
train loss item: 0.092568039894104
train loss item: 0.05040441453456879
train loss item: 0.24781113862991333
train loss item: 0.3992539942264557
train loss item: 0.22650061547756195
train loss item: 0.07699742168188095
train loss item: 0.15720029175281525
train loss item: 0.07773035019636154
train loss item: 0.4400211572647095
train loss item: 0.16289669275283813
train loss item: 0.26435840129852295
train loss item: 0.17251066863536835
train loss item: 0.1125364825129509
train loss item: 0.15348762273788452
train loss item: 0.1423032283782959
train loss item: 0.22689062356948853
train loss item: 0.134139284491539
train loss item: 0.2845548093318939
train loss item: 0.07116568088531494
train loss item: 0.05322924256324768
train loss item: 0.20580726861953735
train loss item: 0.11156119406223297
train loss item: 0.07165137678384781
train loss item: 0.11978355050086975
train loss item: 0.3753785789012909
train loss item: 0.04817787930369377
train loss item: 0.09856744855642319
train loss item: 0.3426455855369568
train loss item: 0.0968327447772026
train loss item: 0.1406569480895996
train loss item: 0.11464565247297287
train loss item: 0.07205168902873993
train loss item: 0.0990978330373764
train loss item: 0.26238372921943665
train loss item: 0.3774847090244293
train loss item: 0.0832851380109787
train loss item: 0.15723204612731934
train loss item: 0.09246662259101868
train loss item: 0.2979279160499573
train loss item: 0.16116555035114288
train loss item: 0.13051848113536835
train loss item: 0.19934126734733582
train loss item: 0.12045005708932877
train loss item: 0.10035338997840881
train loss item: 0.06009545549750328
train loss item: 0.08243297040462494
train loss item: 0.15028677880764008
train loss item: 0.05336588993668556
train loss item: 0.06797569245100021
train loss item: 0.20024913549423218
train loss item: 0.8735904097557068
train loss item: 0.051740579307079315
train loss item: 0.1270514875650406
train loss item: 0.06887353956699371
train loss item: 0.11450013518333435
train loss item: 0.10860452800989151
train loss item: 0.3274519443511963
train loss item: 0.3264579176902771
train loss item: 0.1879800707101822
train loss item: 1.04713773727417
train loss item: 0.059314195066690445
train loss item: 0.15320944786071777
test loss item: 0.17579518258571625
test loss item: 0.13597364723682404
test loss item: 0.447582483291626
test loss item: 0.20030727982521057
test loss item: 0.19412411749362946
test loss item: 0.15560629963874817
test loss item: 1.6697322130203247
test loss item: 0.585983395576477
test loss item: 0.17964158952236176
test loss item: 0.24917097389698029
test loss item: 0.6561000943183899
test loss item: 0.13688230514526367
test loss item: 0.1512060910463333
test loss item: 0.23415493965148926
test loss item: 0.17404121160507202
test loss item: 0.09961975365877151
test loss item: 0.2689240872859955
test loss item: 0.2699939012527466
test loss item: 0.5564002990722656
test loss item: 0.2599831223487854
test loss item: 0.4208436608314514
test loss item: 0.3545278310775757
test loss item: 0.23498034477233887
test loss item: 0.20898960530757904
test loss item: 0.16245056688785553
test loss item: 0.19967833161354065
test loss item: 0.2599014341831207
test loss item: 0.15782645344734192
test loss item: 0.2552470564842224
test loss item: 0.22839047014713287
test loss item: 0.7084547281265259
test loss item: 0.09677809476852417
test loss item: 0.19387145340442657
test loss item: 0.33688658475875854
test loss item: 0.2773226499557495
test loss item: 0.2922898232936859
test loss item: 0.6741085648536682
test loss item: 1.106997013092041
test loss item: 0.3115253150463104
test loss item: 0.2787680923938751
test loss item: 0.27311742305755615
test loss item: 0.17171062529087067
test loss item: 0.19161005318164825
test loss item: 0.21288497745990753
test loss item: 0.3357484042644501
test loss item: 0.3737269341945648
test loss item: 0.2120605856180191
test loss item: 0.22279171645641327
test loss item: 0.3526124358177185
test loss item: 0.5186507105827332
test loss item: 0.18503788113594055
test loss item: 0.14411786198616028
test loss item: 0.1953863650560379
test loss item: 0.14534682035446167
test loss item: 0.1933605670928955
test loss item: 0.5973883867263794
test loss item: 0.4584371745586395
test loss item: 0.1731480360031128
test loss item: 0.223002627491951
test loss item: 0.11533617973327637
test loss item: 0.2390507459640503
test loss item: 0.2700779139995575
test loss item: 0.21481971442699432
test loss item: 0.18002845346927643
test loss item: 0.7709319591522217
test loss item: 0.2181163728237152
test loss item: 0.296244353055954
test loss item: 0.2116936594247818
test loss item: 0.32779577374458313
test loss item: 0.37772616744041443
test loss item: 0.08870405703783035
test loss item: 0.9771232008934021
test loss item: 0.26609987020492554
test loss item: 0.4027053415775299
test loss item: 0.15877652168273926
test loss item: 0.16395558416843414
test loss item: 0.20288747549057007
test loss item: 1.2469414472579956
test loss item: 0.3372592329978943
test loss item: 0.17070409655570984
test loss item: 0.12003102153539658
test loss item: 0.8816145658493042
test loss item: 0.7191604375839233
test loss item: 0.8631319999694824
test loss item: 0.2073940485715866
test loss item: 0.19066302478313446
test loss item: 0.11914043873548508
test loss item: 0.11097951233386993
test loss item: 0.1516726016998291
Epoch [15/100], Training Loss: 0.1800, Testing Loss: 0.3297
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 16/100
train loss item: 0.19280515611171722
train loss item: 0.38552170991897583
train loss item: 0.08935292065143585
train loss item: 0.14607271552085876
train loss item: 0.09226153045892715
train loss item: 0.11498887836933136
train loss item: 0.0841159075498581
train loss item: 0.16784347593784332
train loss item: 0.06457589566707611
train loss item: 0.10788829624652863
train loss item: 0.11617820709943771
train loss item: 0.11659625172615051
train loss item: 0.07531096786260605
train loss item: 0.26270273327827454
train loss item: 0.11617416888475418
train loss item: 0.21014784276485443
train loss item: 0.039363179355859756
train loss item: 0.08177506178617477
train loss item: 0.15083704888820648
train loss item: 0.12300799041986465
train loss item: 0.07944516092538834
train loss item: 0.10012339800596237
train loss item: 0.2000391036272049
train loss item: 0.3601855933666229
train loss item: 0.1877739429473877
train loss item: 0.11678671836853027
train loss item: 0.06439884752035141
train loss item: 0.11973842978477478
train loss item: 0.041176971048116684
train loss item: 0.24014852941036224
train loss item: 0.5522999167442322
train loss item: 0.20123670995235443
train loss item: 0.06865991652011871
train loss item: 0.13415957987308502
train loss item: 0.09098482131958008
train loss item: 0.4076278805732727
train loss item: 0.3285706639289856
train loss item: 0.31641897559165955
train loss item: 0.35052940249443054
train loss item: 0.19466164708137512
train loss item: 0.1546216607093811
train loss item: 0.16449542343616486
train loss item: 0.2515221834182739
train loss item: 0.18088841438293457
train loss item: 0.3342660069465637
train loss item: 0.07977975159883499
train loss item: 0.04923221468925476
train loss item: 0.3614136576652527
train loss item: 0.17587421834468842
train loss item: 0.09884560853242874
train loss item: 0.23735156655311584
train loss item: 0.5261152982711792
train loss item: 0.06109509989619255
train loss item: 0.10956878215074539
train loss item: 0.40645626187324524
train loss item: 0.08048495650291443
train loss item: 0.15435537695884705
train loss item: 0.10556968301534653
train loss item: 0.07374395430088043
train loss item: 0.1078430563211441
train loss item: 0.2476850152015686
train loss item: 0.5597000122070312
train loss item: 0.09315028041601181
train loss item: 0.16725702583789825
train loss item: 0.08163528144359589
train loss item: 0.21172887086868286
train loss item: 0.13897088170051575
train loss item: 0.10216466337442398
train loss item: 0.21129903197288513
train loss item: 0.10234946757555008
train loss item: 0.09739665687084198
train loss item: 0.06544660776853561
train loss item: 0.06997387856245041
train loss item: 0.1336987167596817
train loss item: 0.06294289976358414
train loss item: 0.07461799681186676
train loss item: 0.24162425100803375
train loss item: 0.861598789691925
train loss item: 0.03911803290247917
train loss item: 0.1002512201666832
train loss item: 0.06527011096477509
train loss item: 0.09402694553136826
train loss item: 0.10519416630268097
train loss item: 0.3461727797985077
train loss item: 0.26062390208244324
train loss item: 0.1724972426891327
train loss item: 1.1045173406600952
train loss item: 0.0609392486512661
train loss item: 0.1524270921945572
test loss item: 0.14151589572429657
test loss item: 0.08686712384223938
test loss item: 0.42063775658607483
test loss item: 0.1687876582145691
test loss item: 0.158615380525589
test loss item: 0.1114475354552269
test loss item: 1.622194766998291
test loss item: 0.567914605140686
test loss item: 0.16127055883407593
test loss item: 0.24112679064273834
test loss item: 0.6313102841377258
test loss item: 0.11785615235567093
test loss item: 0.1412852704524994
test loss item: 0.2260676771402359
test loss item: 0.1273188441991806
test loss item: 0.06865131855010986
test loss item: 0.25695034861564636
test loss item: 0.24886450171470642
test loss item: 0.5422293543815613
test loss item: 0.2424812912940979
test loss item: 0.3858117461204529
test loss item: 0.3432169258594513
test loss item: 0.22624367475509644
test loss item: 0.16940341889858246
test loss item: 0.14690947532653809
test loss item: 0.19480857253074646
test loss item: 0.22855140268802643
test loss item: 0.1228526160120964
test loss item: 0.22214971482753754
test loss item: 0.2148241549730301
test loss item: 0.6885913014411926
test loss item: 0.06701206415891647
test loss item: 0.14620018005371094
test loss item: 0.32152387499809265
test loss item: 0.25353366136550903
test loss item: 0.2848935127258301
test loss item: 0.6573166251182556
test loss item: 1.056634783744812
test loss item: 0.29174625873565674
test loss item: 0.24381151795387268
test loss item: 0.2594679594039917
test loss item: 0.16433672606945038
test loss item: 0.19070960581302643
test loss item: 0.2029111087322235
test loss item: 0.3083634078502655
test loss item: 0.3514479696750641
test loss item: 0.20204845070838928
test loss item: 0.20277145504951477
test loss item: 0.3377191722393036
test loss item: 0.5026373267173767
test loss item: 0.18248817324638367
test loss item: 0.12091655284166336
test loss item: 0.1912260204553604
test loss item: 0.132064551115036
test loss item: 0.1903129369020462
test loss item: 0.5683922171592712
test loss item: 0.4347774088382721
test loss item: 0.17551541328430176
test loss item: 0.20290425419807434
test loss item: 0.1196831539273262
test loss item: 0.2385374903678894
test loss item: 0.2562638819217682
test loss item: 0.20748592913150787
test loss item: 0.16411751508712769
test loss item: 0.7157629132270813
test loss item: 0.20454244315624237
test loss item: 0.2831862270832062
test loss item: 0.1979437917470932
test loss item: 0.30799323320388794
test loss item: 0.38250869512557983
test loss item: 0.06532522290945053
test loss item: 0.9464700818061829
test loss item: 0.25555184483528137
test loss item: 0.3808729648590088
test loss item: 0.14415684342384338
test loss item: 0.15251009166240692
test loss item: 0.1669650822877884
test loss item: 1.1686733961105347
test loss item: 0.31415075063705444
test loss item: 0.1441906988620758
test loss item: 0.09174223244190216
test loss item: 0.8481190800666809
test loss item: 0.7081415057182312
test loss item: 0.8158591389656067
test loss item: 0.20260800421237946
test loss item: 0.1740265190601349
test loss item: 0.08540958166122437
test loss item: 0.07425901293754578
test loss item: 0.14024288952350616
Epoch [16/100], Training Loss: 0.1869, Testing Loss: 0.3082
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 17/100
train loss item: 0.17914627492427826
train loss item: 0.42025840282440186
train loss item: 0.09859857708215714
train loss item: 0.17777323722839355
train loss item: 0.09240857511758804
train loss item: 0.13101866841316223
train loss item: 0.07073551416397095
train loss item: 0.3132063150405884
train loss item: 0.08463778346776962
train loss item: 0.10527125746011734
train loss item: 0.1194673627614975
train loss item: 0.11839081346988678
train loss item: 0.08001377433538437
train loss item: 0.3108116388320923
train loss item: 0.1234082505106926
train loss item: 0.28708094358444214
train loss item: 0.03972700983285904
train loss item: 0.07093863189220428
train loss item: 0.23951397836208344
train loss item: 0.10714052617549896
train loss item: 0.0711335837841034
train loss item: 0.10759245604276657
train loss item: 0.2724388837814331
train loss item: 0.30036842823028564
train loss item: 0.21096791326999664
train loss item: 0.14811725914478302
train loss item: 0.06713297218084335
train loss item: 0.10844463109970093
train loss item: 0.049594197422266006
train loss item: 0.2214198261499405
train loss item: 0.3154359757900238
train loss item: 0.22607415914535522
train loss item: 0.07028058916330338
train loss item: 0.12380637973546982
train loss item: 0.06178418919444084
train loss item: 0.38843539357185364
train loss item: 0.19602975249290466
train loss item: 0.24655044078826904
train loss item: 0.18434806168079376
train loss item: 0.14834074676036835
train loss item: 0.15353070199489594
train loss item: 0.18015293776988983
train loss item: 0.2224758416414261
train loss item: 0.13750720024108887
train loss item: 0.29258811473846436
train loss item: 0.09433892369270325
train loss item: 0.053185731172561646
train loss item: 0.19527097046375275
train loss item: 0.11393529176712036
train loss item: 0.07285985350608826
train loss item: 0.11108636856079102
train loss item: 0.3207958936691284
train loss item: 0.053682707250118256
train loss item: 0.098020538687706
train loss item: 0.359958678483963
train loss item: 0.11304797977209091
train loss item: 0.13896872103214264
train loss item: 0.10310912132263184
train loss item: 0.06539302319288254
train loss item: 0.0866013765335083
train loss item: 0.2659611701965332
train loss item: 0.34998446702957153
train loss item: 0.08316586166620255
train loss item: 0.15614406764507294
train loss item: 0.10207389295101166
train loss item: 0.30958250164985657
train loss item: 0.18686969578266144
train loss item: 0.13906913995742798
train loss item: 0.15940488874912262
train loss item: 0.10474904626607895
train loss item: 0.0882035493850708
train loss item: 0.05885683372616768
train loss item: 0.08239255845546722
train loss item: 0.1646765023469925
train loss item: 0.06089917570352554
train loss item: 0.06989892572164536
train loss item: 0.22549955546855927
train loss item: 0.8490105271339417
train loss item: 0.037867628037929535
train loss item: 0.12186969071626663
train loss item: 0.05645420402288437
train loss item: 0.08930954337120056
train loss item: 0.10798168182373047
train loss item: 0.3845902383327484
train loss item: 0.37987080216407776
train loss item: 0.1927134245634079
train loss item: 0.9139693975448608
train loss item: 0.056529466062784195
train loss item: 0.14894644916057587
test loss item: 0.1650734841823578
test loss item: 0.1132141575217247
test loss item: 0.4481979012489319
test loss item: 0.18894219398498535
test loss item: 0.18316298723220825
test loss item: 0.13818620145320892
test loss item: 1.5936332941055298
test loss item: 0.5583417415618896
test loss item: 0.17179931700229645
test loss item: 0.24980752170085907
test loss item: 0.6483649015426636
test loss item: 0.13168026506900787
test loss item: 0.15533114969730377
test loss item: 0.26724696159362793
test loss item: 0.15287421643733978
test loss item: 0.0718202069401741
test loss item: 0.27495190501213074
test loss item: 0.2689310908317566
test loss item: 0.5324448943138123
test loss item: 0.2726992666721344
test loss item: 0.4070756435394287
test loss item: 0.35133928060531616
test loss item: 0.25174880027770996
test loss item: 0.1924632340669632
test loss item: 0.15882983803749084
test loss item: 0.20100754499435425
test loss item: 0.2567216455936432
test loss item: 0.14417393505573273
test loss item: 0.24961957335472107
test loss item: 0.23206041753292084
test loss item: 0.6917446255683899
test loss item: 0.067453533411026
test loss item: 0.173970565199852
test loss item: 0.3424072563648224
test loss item: 0.26926788687705994
test loss item: 0.2847915589809418
test loss item: 0.6446840763092041
test loss item: 1.104648232460022
test loss item: 0.3079705536365509
test loss item: 0.26801663637161255
test loss item: 0.27118831872940063
test loss item: 0.194939523935318
test loss item: 0.195784792304039
test loss item: 0.21529719233512878
test loss item: 0.32551103830337524
test loss item: 0.37935537099838257
test loss item: 0.2285914570093155
test loss item: 0.23361867666244507
test loss item: 0.35748451948165894
test loss item: 0.5191375613212585
test loss item: 0.17549027502536774
test loss item: 0.13899041712284088
test loss item: 0.1970866322517395
test loss item: 0.14656013250350952
test loss item: 0.1885770857334137
test loss item: 0.5968165993690491
test loss item: 0.4402461647987366
test loss item: 0.16630049049854279
test loss item: 0.2184542715549469
test loss item: 0.11681023985147476
test loss item: 0.24672815203666687
test loss item: 0.27019232511520386
test loss item: 0.22233104705810547
test loss item: 0.18110033869743347
test loss item: 0.7437442541122437
test loss item: 0.21524710953235626
test loss item: 0.3054564893245697
test loss item: 0.21068844199180603
test loss item: 0.3279708921909332
test loss item: 0.37424972653388977
test loss item: 0.06819026917219162
test loss item: 0.9394587278366089
test loss item: 0.28612539172172546
test loss item: 0.4129341244697571
test loss item: 0.16146442294120789
test loss item: 0.17561817169189453
test loss item: 0.18590614199638367
test loss item: 1.2369797229766846
test loss item: 0.35713645815849304
test loss item: 0.17138245701789856
test loss item: 0.09229213744401932
test loss item: 0.8647435307502747
test loss item: 0.6926484704017639
test loss item: 0.8562744855880737
test loss item: 0.2157578319311142
test loss item: 0.19971215724945068
test loss item: 0.08897782862186432
test loss item: 0.07543394714593887
test loss item: 0.15511606633663177
Epoch [17/100], Training Loss: 0.1753, Testing Loss: 0.3239
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.2752629220485687
loss item: 0.1911391168832779
loss item: 1.2763817310333252
loss item: 0.5657000541687012
loss item: 0.4915601909160614
loss item: 0.39522841572761536
loss item: 0.12880918383598328
loss item: 0.7001072764396667
loss item: 0.2182370126247406
loss item: 0.1496203988790512
loss item: 0.9035441279411316
loss item: 0.07489189505577087
loss item: 0.7798736691474915
loss item: 0.18412040174007416
loss item: 0.20488493144512177
loss item: 0.18636463582515717
loss item: 0.3303954303264618
loss item: 0.404796302318573
loss item: 0.747265100479126
loss item: 0.40698525309562683
loss item: 0.25075986981391907
loss item: 0.2401188313961029
loss item: 0.300721138715744
loss item: 0.2626732885837555
loss item: 0.21335667371749878
loss item: 0.5849506258964539
loss item: 0.8783235549926758
loss item: 0.12755218148231506
loss item: 0.12308068573474884
loss item: 0.4085859954357147
loss item: 0.9008670449256897
loss item: 1.2574583292007446
loss item: 0.13206824660301208
loss item: 0.4792412519454956
loss item: 0.15498948097229004
loss item: 0.19901567697525024
loss item: 0.24684542417526245
loss item: 0.23901700973510742
loss item: 0.38250643014907837
loss item: 0.5913411378860474
loss item: 0.7910870313644409
loss item: 0.31175997853279114
loss item: 0.20504426956176758
loss item: 0.0706518366932869
Val Loss: 0.4083
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 100, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.001 2 360 done at Tue Nov 12 12:35:40 CET 2024
UNet2 with 1 100 0.005 2 360 start at Tue Nov 12 12:35:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 100, batch size: 2
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 0.9121710062026978
train loss item: 2.3596537113189697
train loss item: 0.6951392889022827
train loss item: 1.2938249111175537
train loss item: 1.4231724739074707
train loss item: 0.5039922595024109
train loss item: 0.43074434995651245
train loss item: 1.4261348247528076
train loss item: 0.28414613008499146
train loss item: 0.5675510168075562
train loss item: 0.6910601854324341
train loss item: 0.42026352882385254
train loss item: 0.1324857473373413
train loss item: 0.8068372011184692
train loss item: 0.3840419054031372
train loss item: 1.257371425628662
train loss item: 0.08779767155647278
train loss item: 0.49915456771850586
train loss item: 0.6628166437149048
train loss item: 0.5061546564102173
train loss item: 0.40896642208099365
train loss item: 0.18529468774795532
train loss item: 1.878562569618225
train loss item: 1.4219703674316406
train loss item: 0.9907299280166626
train loss item: 0.4101291298866272
train loss item: 0.286479115486145
train loss item: 0.47881534695625305
train loss item: 0.19234693050384521
train loss item: 1.4333579540252686
train loss item: 3.288198947906494
train loss item: 0.9111039042472839
train loss item: 0.137279212474823
train loss item: 0.7027220129966736
train loss item: 0.20527304708957672
train loss item: 2.921581983566284
train loss item: 0.7213185429573059
train loss item: 0.5303860306739807
train loss item: 0.7365942597389221
train loss item: 0.36719605326652527
train loss item: 0.31795549392700195
train loss item: 0.3771492540836334
train loss item: 0.4621357321739197
train loss item: 0.2473013550043106
train loss item: 0.7756121754646301
train loss item: 0.32356515526771545
train loss item: 0.17513719201087952
train loss item: 0.6990630626678467
train loss item: 0.31837934255599976
train loss item: 0.16912858188152313
train loss item: 0.5299562811851501
train loss item: 1.499110460281372
train loss item: 0.0681602880358696
train loss item: 0.2920112609863281
train loss item: 2.7292673587799072
train loss item: 0.29725366830825806
train loss item: 0.3225564956665039
train loss item: 0.3299453556537628
train loss item: 0.24271030724048615
train loss item: 0.17768913507461548
train loss item: 1.4162005186080933
train loss item: 2.4564168453216553
train loss item: 0.3873443305492401
train loss item: 0.625148594379425
train loss item: 0.23776280879974365
train loss item: 0.930720865726471
train loss item: 0.43830034136772156
train loss item: 0.2984105348587036
train loss item: 0.4311758875846863
train loss item: 0.45804911851882935
train loss item: 0.3682411313056946
train loss item: 0.5147370100021362
train loss item: 0.3530140519142151
train loss item: 0.41604140400886536
train loss item: 0.1211424469947815
train loss item: 0.13685491681098938
train loss item: 1.329099178314209
train loss item: 1.9581820964813232
train loss item: 0.1391196846961975
train loss item: 0.5035191774368286
train loss item: 0.2037416398525238
train loss item: 0.3330010771751404
train loss item: 0.2958652079105377
train loss item: 1.196373462677002
train loss item: 0.6154637932777405
train loss item: 1.0099682807922363
train loss item: 4.918233394622803
train loss item: 0.20143809914588928
train loss item: 0.4690376818180084
test loss item: 0.2219582051038742
test loss item: 0.18020641803741455
test loss item: 0.8305428624153137
test loss item: 0.29015976190567017
test loss item: 0.44809016585350037
test loss item: 0.3841785490512848
test loss item: 2.8382318019866943
test loss item: 0.9022160172462463
test loss item: 0.3301982283592224
test loss item: 0.5667122006416321
test loss item: 1.2469464540481567
test loss item: 0.22060108184814453
test loss item: 0.26215502619743347
test loss item: 0.4469398558139801
test loss item: 0.2549419701099396
test loss item: 0.10355199128389359
test loss item: 0.4048226773738861
test loss item: 0.6440994143486023
test loss item: 0.9782863855361938
test loss item: 0.41897228360176086
test loss item: 0.9918761253356934
test loss item: 0.5558953285217285
test loss item: 0.39206233620643616
test loss item: 0.2843523323535919
test loss item: 0.29935961961746216
test loss item: 0.3395402729511261
test loss item: 0.46730926632881165
test loss item: 0.4087378680706024
test loss item: 0.5005202293395996
test loss item: 0.4869081377983093
test loss item: 1.272813320159912
test loss item: 0.0923331081867218
test loss item: 0.2386859506368637
test loss item: 0.7520583271980286
test loss item: 0.6116223335266113
test loss item: 0.6288796067237854
test loss item: 1.2259260416030884
test loss item: 2.087797164916992
test loss item: 0.7095513343811035
test loss item: 0.5002447366714478
test loss item: 0.43840017914772034
test loss item: 0.232686847448349
test loss item: 0.4752911329269409
test loss item: 0.2972860634326935
test loss item: 0.8312079310417175
test loss item: 0.6241165399551392
test loss item: 0.37898731231689453
test loss item: 0.3276004195213318
test loss item: 0.6847848892211914
test loss item: 1.0320032835006714
test loss item: 0.46428340673446655
test loss item: 0.1756659746170044
test loss item: 0.36126548051834106
test loss item: 0.17397168278694153
test loss item: 0.4399870038032532
test loss item: 1.2349635362625122
test loss item: 0.8089830279350281
test loss item: 0.34216636419296265
test loss item: 0.33153754472732544
test loss item: 0.3150654733181
test loss item: 0.6090577244758606
test loss item: 0.3494621813297272
test loss item: 0.30517345666885376
test loss item: 0.3546837270259857
test loss item: 1.2856695652008057
test loss item: 0.36005106568336487
test loss item: 0.46664392948150635
test loss item: 0.37960925698280334
test loss item: 0.7078253626823425
test loss item: 0.6229697465896606
test loss item: 0.13950969278812408
test loss item: 1.6218185424804688
test loss item: 0.40837159752845764
test loss item: 0.6003850102424622
test loss item: 0.21454794704914093
test loss item: 0.23020243644714355
test loss item: 0.28600776195526123
test loss item: 2.1255815029144287
test loss item: 0.634545087814331
test loss item: 0.40892294049263
test loss item: 0.14562171697616577
test loss item: 1.483009696006775
test loss item: 1.3324593305587769
test loss item: 1.4933563470840454
test loss item: 0.3548557460308075
test loss item: 0.295806884765625
test loss item: 0.13297221064567566
test loss item: 0.0987270325422287
test loss item: 0.21032162010669708
Epoch [1/100], Training Loss: 0.7491, Testing Loss: 0.5893
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 2/100
train loss item: 0.5202454328536987
train loss item: 1.5883634090423584
train loss item: 0.497993528842926
train loss item: 0.6793892979621887
train loss item: 0.8560302257537842
train loss item: 0.43026456236839294
train loss item: 0.4020290672779083
train loss item: 0.9720221757888794
train loss item: 0.19187189638614655
train loss item: 0.4412691593170166
train loss item: 0.4472671151161194
train loss item: 0.40259650349617004
train loss item: 0.12438526749610901
train loss item: 0.6006274819374084
train loss item: 0.35987281799316406
train loss item: 1.1746416091918945
train loss item: 0.09646846354007721
train loss item: 0.454369455575943
train loss item: 0.5142753720283508
train loss item: 0.42070335149765015
train loss item: 0.35345950722694397
train loss item: 0.19133871793746948
train loss item: 1.6305735111236572
train loss item: 1.1478272676467896
train loss item: 0.8611868619918823
train loss item: 0.32433584332466125
train loss item: 0.274985134601593
train loss item: 0.3265416622161865
train loss item: 0.09623387455940247
train loss item: 1.0850087404251099
train loss item: 2.6649010181427
train loss item: 0.6644923090934753
train loss item: 0.17125748097896576
train loss item: 0.4613787531852722
train loss item: 0.23047718405723572
train loss item: 2.4294028282165527
train loss item: 0.618015706539154
train loss item: 0.5975621342658997
train loss item: 0.6129162907600403
train loss item: 0.2766493558883667
train loss item: 0.19486738741397858
train loss item: 0.42431560158729553
train loss item: 0.36129313707351685
train loss item: 0.326534628868103
train loss item: 0.9694086909294128
train loss item: 0.19816818833351135
train loss item: 0.1670057624578476
train loss item: 0.535385012626648
train loss item: 0.345824658870697
train loss item: 0.2181480973958969
train loss item: 0.3927725553512573
train loss item: 1.3726980686187744
train loss item: 0.10167425870895386
train loss item: 0.24732093513011932
train loss item: 2.681530237197876
train loss item: 0.251911997795105
train loss item: 0.4266429543495178
train loss item: 0.30946847796440125
train loss item: 0.20116759836673737
train loss item: 0.14426513016223907
train loss item: 1.1352858543395996
train loss item: 2.296191692352295
train loss item: 0.4044857621192932
train loss item: 0.5181435942649841
train loss item: 0.2885459363460541
train loss item: 0.814670741558075
train loss item: 0.45427295565605164
train loss item: 0.24297881126403809
train loss item: 0.405108779668808
train loss item: 0.4397752583026886
train loss item: 0.3088932931423187
train loss item: 0.13236850500106812
train loss item: 0.3402555286884308
train loss item: 0.3749471604824066
train loss item: 0.11623818427324295
train loss item: 0.15245972573757172
train loss item: 1.1686662435531616
train loss item: 1.4485774040222168
train loss item: 0.12536732852458954
train loss item: 0.389710396528244
train loss item: 0.1605888307094574
train loss item: 0.22646893560886383
train loss item: 0.28121575713157654
train loss item: 0.704188346862793
train loss item: 0.4369463324546814
train loss item: 0.841219961643219
train loss item: 4.46937370300293
train loss item: 0.17095257341861725
train loss item: 0.5888984799385071
test loss item: 0.19769255816936493
test loss item: 0.0942649096250534
test loss item: 0.6723519563674927
test loss item: 0.22790086269378662
test loss item: 0.277523398399353
test loss item: 0.12169263511896133
test loss item: 2.117636203765869
test loss item: 0.6954542398452759
test loss item: 0.26292651891708374
test loss item: 0.47967493534088135
test loss item: 1.081426978111267
test loss item: 0.1724182516336441
test loss item: 0.22273018956184387
test loss item: 0.4699592590332031
test loss item: 0.18151436746120453
test loss item: 0.07213879376649857
test loss item: 0.3515373766422272
test loss item: 0.5452346801757812
test loss item: 0.8478008508682251
test loss item: 0.38725021481513977
test loss item: 0.8558072447776794
test loss item: 0.4213946759700775
test loss item: 0.36695459485054016
test loss item: 0.19527073204517365
test loss item: 0.2558869421482086
test loss item: 0.27263879776000977
test loss item: 0.43619051575660706
test loss item: 0.2155897170305252
test loss item: 0.40131741762161255
test loss item: 0.4422595798969269
test loss item: 0.9593598246574402
test loss item: 0.05677281692624092
test loss item: 0.16253340244293213
test loss item: 0.6515146493911743
test loss item: 0.5107977986335754
test loss item: 0.5289648175239563
test loss item: 1.0168377161026
test loss item: 1.7878464460372925
test loss item: 0.5852097868919373
test loss item: 0.31551387906074524
test loss item: 0.3545512557029724
test loss item: 0.21288084983825684
test loss item: 0.41116949915885925
test loss item: 0.21858486533164978
test loss item: 0.7293254733085632
test loss item: 0.568227231502533
test loss item: 0.3336043059825897
test loss item: 0.3612881302833557
test loss item: 0.5520521998405457
test loss item: 0.8769135475158691
test loss item: 0.36052098870277405
test loss item: 0.163754403591156
test loss item: 0.2718210518360138
test loss item: 0.12377573549747467
test loss item: 0.34418946504592896
test loss item: 1.0379128456115723
test loss item: 0.6825181245803833
test loss item: 0.28922039270401
test loss item: 0.27751609683036804
test loss item: 0.23164941370487213
test loss item: 0.530247151851654
test loss item: 0.2786214053630829
test loss item: 0.25093621015548706
test loss item: 0.3104541599750519
test loss item: 1.017695426940918
test loss item: 0.31171780824661255
test loss item: 0.3992001414299011
test loss item: 0.31043270230293274
test loss item: 0.6117001175880432
test loss item: 0.54750657081604
test loss item: 0.07124567031860352
test loss item: 1.2598762512207031
test loss item: 0.40247833728790283
test loss item: 0.46082761883735657
test loss item: 0.18239380419254303
test loss item: 0.20163115859031677
test loss item: 0.19967348873615265
test loss item: 1.7460614442825317
test loss item: 0.622539222240448
test loss item: 0.21185313165187836
test loss item: 0.07482673972845078
test loss item: 1.1851370334625244
test loss item: 1.0874840021133423
test loss item: 1.2100516557693481
test loss item: 0.3177059292793274
test loss item: 0.25603145360946655
test loss item: 0.053947992622852325
test loss item: 0.046831440180540085
test loss item: 0.15674622356891632
Epoch [2/100], Training Loss: 0.6236, Testing Loss: 0.4790
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 3/100
train loss item: 0.49028417468070984
train loss item: 1.3115317821502686
train loss item: 0.39279410243034363
train loss item: 0.6456537842750549
train loss item: 0.465495765209198
train loss item: 0.3933671712875366
train loss item: 0.32648375630378723
train loss item: 0.7854472994804382
train loss item: 0.21777796745300293
train loss item: 0.33937060832977295
train loss item: 0.4432004392147064
train loss item: 0.4394850730895996
train loss item: 0.11775092035531998
train loss item: 0.539486289024353
train loss item: 0.3084419071674347
train loss item: 0.7759978771209717
train loss item: 0.10391057282686234
train loss item: 0.370320588350296
train loss item: 0.4265836775302887
train loss item: 0.3654240667819977
train loss item: 0.26950278878211975
train loss item: 0.18585674464702606
train loss item: 1.081381916999817
train loss item: 1.061638593673706
train loss item: 0.6936229467391968
train loss item: 0.34483766555786133
train loss item: 0.2925300598144531
train loss item: 0.3445080816745758
train loss item: 0.12254957109689713
train loss item: 0.7838624119758606
train loss item: 2.363412380218506
train loss item: 0.7274218797683716
train loss item: 0.12609991431236267
train loss item: 0.4490307867527008
train loss item: 0.13747958838939667
train loss item: 2.209709644317627
train loss item: 0.6788873672485352
train loss item: 0.5553525686264038
train loss item: 0.791489839553833
train loss item: 0.3154582679271698
train loss item: 0.23276060819625854
train loss item: 0.3659941554069519
train loss item: 0.3914089798927307
train loss item: 0.2991100549697876
train loss item: 0.8604167699813843
train loss item: 0.14656716585159302
train loss item: 0.14077314734458923
train loss item: 0.5139577388763428
train loss item: 0.35866042971611023
train loss item: 0.1874372661113739
train loss item: 0.4193404018878937
train loss item: 1.281272292137146
train loss item: 0.07926522940397263
train loss item: 0.24637846648693085
train loss item: 2.4829025268554688
train loss item: 0.25373953580856323
train loss item: 0.40718111395835876
train loss item: 0.2751636505126953
train loss item: 0.18783019483089447
train loss item: 0.1169891506433487
train loss item: 0.9700027108192444
train loss item: 2.0544557571411133
train loss item: 0.3362148702144623
train loss item: 0.5342836380004883
train loss item: 0.3059868812561035
train loss item: 0.773044764995575
train loss item: 0.5659810304641724
train loss item: 0.23036304116249084
train loss item: 0.40304967761039734
train loss item: 0.4529935419559479
train loss item: 0.313376784324646
train loss item: 0.14639060199260712
train loss item: 0.339115172624588
train loss item: 0.39757630228996277
train loss item: 0.0981898233294487
train loss item: 0.14713843166828156
train loss item: 1.2282283306121826
train loss item: 1.325297474861145
train loss item: 0.08313537389039993
train loss item: 0.39787110686302185
train loss item: 0.1820702701807022
train loss item: 0.23459705710411072
train loss item: 0.32694414258003235
train loss item: 0.6765772104263306
train loss item: 0.5157465934753418
train loss item: 0.99424147605896
train loss item: 4.605356693267822
train loss item: 0.287929892539978
train loss item: 0.43526536226272583
test loss item: 0.23402291536331177
test loss item: 0.09711204469203949
test loss item: 1.0367672443389893
test loss item: 0.2616322636604309
test loss item: 0.3511967957019806
test loss item: 0.17220932245254517
test loss item: 2.125265121459961
test loss item: 0.76502525806427
test loss item: 0.4095436930656433
test loss item: 0.6428482532501221
test loss item: 1.5001180171966553
test loss item: 0.18883852660655975
test loss item: 0.24032075703144073
test loss item: 0.49721840023994446
test loss item: 0.23130810260772705
test loss item: 0.06418707966804504
test loss item: 0.4085688292980194
test loss item: 0.720257580280304
test loss item: 0.897205114364624
test loss item: 0.42820456624031067
test loss item: 1.0863351821899414
test loss item: 0.47444427013397217
test loss item: 0.4241888225078583
test loss item: 0.22415444254875183
test loss item: 0.31206241250038147
test loss item: 0.2946537137031555
test loss item: 0.5082997679710388
test loss item: 0.2617953419685364
test loss item: 0.47532522678375244
test loss item: 0.5327207446098328
test loss item: 1.254262089729309
test loss item: 0.06734172254800797
test loss item: 0.19337117671966553
test loss item: 0.8416019678115845
test loss item: 0.7052162885665894
test loss item: 0.6594303846359253
test loss item: 1.097493290901184
test loss item: 2.627600908279419
test loss item: 0.7366380095481873
test loss item: 0.33963823318481445
test loss item: 0.36891990900039673
test loss item: 0.2895925045013428
test loss item: 0.543578028678894
test loss item: 0.26385411620140076
test loss item: 0.8945998549461365
test loss item: 0.6361622214317322
test loss item: 0.4230213463306427
test loss item: 0.3634369969367981
test loss item: 0.7734684348106384
test loss item: 1.1762841939926147
test loss item: 0.4732299745082855
test loss item: 0.16771475970745087
test loss item: 0.3451259732246399
test loss item: 0.1899220049381256
test loss item: 0.4573378562927246
test loss item: 1.5093867778778076
test loss item: 0.8202298879623413
test loss item: 0.3621230721473694
test loss item: 0.3376314043998718
test loss item: 0.26512008905410767
test loss item: 0.7129887938499451
test loss item: 0.35359689593315125
test loss item: 0.30325305461883545
test loss item: 0.3115994930267334
test loss item: 1.401402235031128
test loss item: 0.3442620038986206
test loss item: 0.48202624917030334
test loss item: 0.31288373470306396
test loss item: 0.7647578120231628
test loss item: 0.6287472248077393
test loss item: 0.06255970150232315
test loss item: 1.2563743591308594
test loss item: 0.482867568731308
test loss item: 0.5167818665504456
test loss item: 0.22670501470565796
test loss item: 0.2645435333251953
test loss item: 0.216311976313591
test loss item: 2.6130781173706055
test loss item: 0.7325003743171692
test loss item: 0.27393028140068054
test loss item: 0.09091046452522278
test loss item: 1.5705578327178955
test loss item: 1.2662791013717651
test loss item: 1.8538211584091187
test loss item: 0.3213949203491211
test loss item: 0.31530776619911194
test loss item: 0.08047979325056076
test loss item: 0.0684698149561882
test loss item: 0.22111044824123383
Epoch [3/100], Training Loss: 0.5776, Testing Loss: 0.5966
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 4/100
train loss item: 0.5021392107009888
train loss item: 1.4020358324050903
train loss item: 0.2827751338481903
train loss item: 0.7027196884155273
train loss item: 0.9253207445144653
train loss item: 0.41154807806015015
train loss item: 0.40359655022621155
train loss item: 0.8218976855278015
train loss item: 0.18198658525943756
train loss item: 0.46982574462890625
train loss item: 0.5131447315216064
train loss item: 0.4556555151939392
train loss item: 0.1281735748052597
train loss item: 0.5544214844703674
train loss item: 0.38070741295814514
train loss item: 1.0628888607025146
train loss item: 0.06040704622864723
train loss item: 0.42288821935653687
train loss item: 0.48815733194351196
train loss item: 0.39996299147605896
train loss item: 0.2998802065849304
train loss item: 0.23294617235660553
train loss item: 1.2832715511322021
train loss item: 1.136642575263977
train loss item: 0.7670120000839233
train loss item: 0.3832380771636963
train loss item: 0.4265728294849396
train loss item: 0.4032289683818817
train loss item: 0.09519117325544357
train loss item: 0.779981255531311
train loss item: 2.2796053886413574
train loss item: 0.6658167839050293
train loss item: 0.14021223783493042
train loss item: 0.45156142115592957
train loss item: 0.18829071521759033
train loss item: 2.0786449909210205
train loss item: 0.8042514324188232
train loss item: 0.682248592376709
train loss item: 0.840590238571167
train loss item: 0.3404703736305237
train loss item: 0.21892841160297394
train loss item: 0.4109167456626892
train loss item: 0.44205620884895325
train loss item: 0.28155583143234253
train loss item: 0.9193791151046753
train loss item: 0.16633743047714233
train loss item: 0.15630805492401123
train loss item: 0.5433482527732849
train loss item: 0.35004597902297974
train loss item: 0.19135256111621857
train loss item: 0.4216080904006958
train loss item: 0.9644942879676819
train loss item: 0.0944901555776596
train loss item: 0.2031380534172058
train loss item: 2.087280750274658
train loss item: 0.24727149307727814
train loss item: 0.3913778066635132
train loss item: 0.2610117495059967
train loss item: 0.21332596242427826
train loss item: 0.12194395065307617
train loss item: 0.9223904013633728
train loss item: 1.9245713949203491
train loss item: 0.2970227003097534
train loss item: 0.5195898413658142
train loss item: 0.20456328988075256
train loss item: 0.7501165270805359
train loss item: 0.5125088095664978
train loss item: 0.24515289068222046
train loss item: 0.476132333278656
train loss item: 0.46479934453964233
train loss item: 0.3591982424259186
train loss item: 0.13813771307468414
train loss item: 0.3039652705192566
train loss item: 0.3725322484970093
train loss item: 0.0954902321100235
train loss item: 0.1471400260925293
train loss item: 1.0198431015014648
train loss item: 1.3626396656036377
train loss item: 0.09680171310901642
train loss item: 0.29796886444091797
train loss item: 0.16755181550979614
train loss item: 0.20642131567001343
train loss item: 0.2909388542175293
train loss item: 0.547890305519104
train loss item: 0.547717809677124
train loss item: 0.6686052083969116
train loss item: 3.799309730529785
train loss item: 0.17852364480495453
train loss item: 0.5676175951957703
test loss item: 0.22876130044460297
test loss item: 0.1925920844078064
test loss item: 0.6096324920654297
test loss item: 0.2843373119831085
test loss item: 0.4044888913631439
test loss item: 0.353555828332901
test loss item: 2.0460212230682373
test loss item: 0.831891655921936
test loss item: 0.25466403365135193
test loss item: 0.47491419315338135
test loss item: 0.9572746157646179
test loss item: 0.17033234238624573
test loss item: 0.2690514326095581
test loss item: 0.39276883006095886
test loss item: 0.25733068585395813
test loss item: 0.08704730123281479
test loss item: 0.39657631516456604
test loss item: 0.5401631593704224
test loss item: 0.9256654381752014
test loss item: 0.4304342269897461
test loss item: 0.8297269344329834
test loss item: 0.47496065497398376
test loss item: 0.4684136211872101
test loss item: 0.31661078333854675
test loss item: 0.26519492268562317
test loss item: 0.35327717661857605
test loss item: 0.4436260759830475
test loss item: 0.38905444741249084
test loss item: 0.44000133872032166
test loss item: 0.4675567150115967
test loss item: 0.8935151100158691
test loss item: 0.10401853173971176
test loss item: 0.28489717841148376
test loss item: 0.628192663192749
test loss item: 0.4906228482723236
test loss item: 0.5699187517166138
test loss item: 1.056497573852539
test loss item: 1.5257805585861206
test loss item: 0.5554651021957397
test loss item: 0.4400100111961365
test loss item: 0.36560243368148804
test loss item: 0.39962461590766907
test loss item: 0.4003780782222748
test loss item: 0.24112391471862793
test loss item: 0.6942936778068542
test loss item: 0.6473431587219238
test loss item: 0.501295268535614
test loss item: 0.4208645820617676
test loss item: 0.544355571269989
test loss item: 0.8297122120857239
test loss item: 0.35588154196739197
test loss item: 0.2584889829158783
test loss item: 0.2910763621330261
test loss item: 0.15435147285461426
test loss item: 0.3592945635318756
test loss item: 0.9324249625205994
test loss item: 0.7086411714553833
test loss item: 0.3055453598499298
test loss item: 0.33318519592285156
test loss item: 0.24370405077934265
test loss item: 0.5090181827545166
test loss item: 0.3669542670249939
test loss item: 0.32692089676856995
test loss item: 0.3012235462665558
test loss item: 0.9966466426849365
test loss item: 0.31743958592414856
test loss item: 0.4512905776500702
test loss item: 0.3324224352836609
test loss item: 0.5683555603027344
test loss item: 0.6347696781158447
test loss item: 0.17376384139060974
test loss item: 1.2921924591064453
test loss item: 0.377658486366272
test loss item: 0.48855453729629517
test loss item: 0.25200581550598145
test loss item: 0.4136265814304352
test loss item: 0.29729965329170227
test loss item: 1.4890213012695312
test loss item: 0.5281075239181519
test loss item: 0.3861309885978699
test loss item: 0.17762959003448486
test loss item: 1.1090573072433472
test loss item: 1.1014866828918457
test loss item: 1.027674674987793
test loss item: 0.2951967716217041
test loss item: 0.32918107509613037
test loss item: 0.13681660592556
test loss item: 0.07730206102132797
test loss item: 0.2770659923553467
Epoch [4/100], Training Loss: 0.5733, Testing Loss: 0.5070
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 5/100
train loss item: 0.48602986335754395
train loss item: 1.333953857421875
train loss item: 0.28156399726867676
train loss item: 0.6068131923675537
train loss item: 0.44320768117904663
train loss item: 0.3614659011363983
train loss item: 0.31360429525375366
train loss item: 0.7171801924705505
train loss item: 0.15187199413776398
train loss item: 0.30019310116767883
train loss item: 0.40707433223724365
train loss item: 0.29506146907806396
train loss item: 0.10837208479642868
train loss item: 0.5220437049865723
train loss item: 0.26147541403770447
train loss item: 0.6877620220184326
train loss item: 0.07297038286924362
train loss item: 0.3638119399547577
train loss item: 0.38641026616096497
train loss item: 0.33382782340049744
train loss item: 0.23918208479881287
train loss item: 0.1752690076828003
train loss item: 0.973395824432373
train loss item: 0.9286071062088013
train loss item: 0.638412356376648
train loss item: 0.24044714868068695
train loss item: 0.2529298961162567
train loss item: 0.29502803087234497
train loss item: 0.10129999369382858
train loss item: 0.6776465773582458
train loss item: 1.7907018661499023
train loss item: 0.7767718434333801
train loss item: 0.2212078720331192
train loss item: 0.41091376543045044
train loss item: 0.133914977312088
train loss item: 1.7703841924667358
train loss item: 0.8056597709655762
train loss item: 0.5334590077400208
train loss item: 0.6710484027862549
train loss item: 0.28273409605026245
train loss item: 0.2101016640663147
train loss item: 0.3625372052192688
train loss item: 0.39074641466140747
train loss item: 0.2726905643939972
train loss item: 0.841188907623291
train loss item: 0.13405807316303253
train loss item: 0.131875678896904
train loss item: 0.6133467555046082
train loss item: 0.35045212507247925
train loss item: 0.1714107245206833
train loss item: 0.4941314458847046
train loss item: 1.2023556232452393
train loss item: 0.07101334631443024
train loss item: 0.18202953040599823
train loss item: 1.9251779317855835
train loss item: 0.2390000969171524
train loss item: 0.333469420671463
train loss item: 0.2956734895706177
train loss item: 0.21844951808452606
train loss item: 0.15239162743091583
train loss item: 1.0345207452774048
train loss item: 1.6909229755401611
train loss item: 0.27491334080696106
train loss item: 0.4340212345123291
train loss item: 0.2247297167778015
train loss item: 0.7020635604858398
train loss item: 0.6914637684822083
train loss item: 0.2610158920288086
train loss item: 0.3718174397945404
train loss item: 0.4037328362464905
train loss item: 0.292216420173645
train loss item: 0.12692590057849884
train loss item: 0.28203192353248596
train loss item: 0.3673930764198303
train loss item: 0.07950851321220398
train loss item: 0.1273401379585266
train loss item: 1.0057584047317505
train loss item: 1.2828257083892822
train loss item: 0.07772001624107361
train loss item: 0.2843998968601227
train loss item: 0.11754105985164642
train loss item: 0.21676601469516754
train loss item: 0.2720753848552704
train loss item: 0.513117253780365
train loss item: 0.5915540456771851
train loss item: 0.624801516532898
train loss item: 3.3155555725097656
train loss item: 0.1508142352104187
train loss item: 0.506514847278595
test loss item: 0.22383758425712585
test loss item: 0.10122334212064743
test loss item: 0.5543126463890076
test loss item: 0.2636622488498688
test loss item: 0.2594273090362549
test loss item: 0.1805235892534256
test loss item: 1.9042832851409912
test loss item: 0.6523539423942566
test loss item: 0.2200760543346405
test loss item: 0.41441550850868225
test loss item: 0.8232730031013489
test loss item: 0.19732944667339325
test loss item: 0.23155143857002258
test loss item: 0.4242210388183594
test loss item: 0.17109039425849915
test loss item: 0.0637625977396965
test loss item: 0.384880930185318
test loss item: 0.47447338700294495
test loss item: 0.7842504978179932
test loss item: 0.37362971901893616
test loss item: 0.7478837370872498
test loss item: 0.44880032539367676
test loss item: 0.3389993906021118
test loss item: 0.22332286834716797
test loss item: 0.26773592829704285
test loss item: 0.2921796441078186
test loss item: 0.3963527977466583
test loss item: 0.22616900503635406
test loss item: 0.36650583148002625
test loss item: 0.4099002480506897
test loss item: 0.7908022999763489
test loss item: 0.07494983822107315
test loss item: 0.19521236419677734
test loss item: 0.5779657363891602
test loss item: 0.4314515292644501
test loss item: 0.46482810378074646
test loss item: 0.9279231429100037
test loss item: 1.3153088092803955
test loss item: 0.5005946159362793
test loss item: 0.3286193311214447
test loss item: 0.37252652645111084
test loss item: 0.27336812019348145
test loss item: 0.3538101613521576
test loss item: 0.26992666721343994
test loss item: 0.6267985105514526
test loss item: 0.5462682843208313
test loss item: 0.3583196699619293
test loss item: 0.3437707722187042
test loss item: 0.4673413336277008
test loss item: 0.6894915699958801
test loss item: 0.2991043031215668
test loss item: 0.21351222693920135
test loss item: 0.2779155671596527
test loss item: 0.20154377818107605
test loss item: 0.31217095255851746
test loss item: 0.8149411082267761
test loss item: 0.6035475134849548
test loss item: 0.28396978974342346
test loss item: 0.29878008365631104
test loss item: 0.21433952450752258
test loss item: 0.44585365056991577
test loss item: 0.31126850843429565
test loss item: 0.29898205399513245
test loss item: 0.3111124336719513
test loss item: 0.8801639676094055
test loss item: 0.3454177975654602
test loss item: 0.40018680691719055
test loss item: 0.31567564606666565
test loss item: 0.5159564018249512
test loss item: 0.4837987422943115
test loss item: 0.07037461549043655
test loss item: 1.1461952924728394
test loss item: 0.3952668309211731
test loss item: 0.48352277278900146
test loss item: 0.21889840066432953
test loss item: 0.2503947913646698
test loss item: 0.2153567522764206
test loss item: 1.3052102327346802
test loss item: 0.5531340837478638
test loss item: 0.25842010974884033
test loss item: 0.09510491788387299
test loss item: 0.9688894152641296
test loss item: 0.973979651927948
test loss item: 0.8782515525817871
test loss item: 0.2793658971786499
test loss item: 0.27570533752441406
test loss item: 0.0821133479475975
test loss item: 0.06928380578756332
test loss item: 0.19190242886543274
Epoch [5/100], Training Loss: 0.5087, Testing Loss: 0.4367
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 6/100
train loss item: 0.4300716519355774
train loss item: 1.2640435695648193
train loss item: 0.2533445358276367
train loss item: 0.6705136299133301
train loss item: 0.4189329445362091
train loss item: 0.3508652150630951
train loss item: 0.30102652311325073
train loss item: 0.8390786051750183
train loss item: 0.18592223525047302
train loss item: 0.39629629254341125
train loss item: 0.5570724606513977
train loss item: 0.27649205923080444
train loss item: 0.11372947692871094
train loss item: 0.6625910997390747
train loss item: 0.295180082321167
train loss item: 0.7447018623352051
train loss item: 0.06017201021313667
train loss item: 0.3249080181121826
train loss item: 0.3784900903701782
train loss item: 0.32053685188293457
train loss item: 0.2502790093421936
train loss item: 0.17495915293693542
train loss item: 0.8950791358947754
train loss item: 0.969197690486908
train loss item: 0.621118426322937
train loss item: 0.24585124850273132
train loss item: 0.22325463593006134
train loss item: 0.2526489496231079
train loss item: 0.06206170469522476
train loss item: 0.6424688696861267
train loss item: 1.6440699100494385
train loss item: 0.7524213790893555
train loss item: 0.13799795508384705
train loss item: 0.369232177734375
train loss item: 0.15302559733390808
train loss item: 1.5837188959121704
train loss item: 0.8019135594367981
train loss item: 0.483897864818573
train loss item: 0.4982016086578369
train loss item: 0.2561938166618347
train loss item: 0.19363677501678467
train loss item: 0.3690783679485321
train loss item: 0.335333913564682
train loss item: 0.2811272144317627
train loss item: 0.8118041157722473
train loss item: 0.1377112865447998
train loss item: 0.1463586837053299
train loss item: 0.4039442539215088
train loss item: 0.3253737688064575
train loss item: 0.20114873349666595
train loss item: 0.3585105240345001
train loss item: 1.0002375841140747
train loss item: 0.06338192522525787
train loss item: 0.19984225928783417
train loss item: 1.8003393411636353
train loss item: 0.1998046487569809
train loss item: 0.3629535138607025
train loss item: 0.26198893785476685
train loss item: 0.18824347853660583
train loss item: 0.14850829541683197
train loss item: 0.7465896010398865
train loss item: 1.3984392881393433
train loss item: 0.28325268626213074
train loss item: 0.5545751452445984
train loss item: 0.1884678453207016
train loss item: 0.6292052268981934
train loss item: 0.6255313158035278
train loss item: 0.2105501890182495
train loss item: 0.3999882936477661
train loss item: 0.38424935936927795
train loss item: 0.266610324382782
train loss item: 0.12451397627592087
train loss item: 0.3084001839160919
train loss item: 0.36424511671066284
train loss item: 0.10845480859279633
train loss item: 0.1705329418182373
train loss item: 0.987506091594696
train loss item: 1.1628057956695557
train loss item: 0.08550529181957245
train loss item: 0.2909635901451111
train loss item: 0.15275128185749054
train loss item: 0.18898840248584747
train loss item: 0.27425795793533325
train loss item: 0.47881975769996643
train loss item: 0.6513606905937195
train loss item: 0.6915993690490723
train loss item: 3.051983118057251
train loss item: 0.16804514825344086
train loss item: 0.5024146437644958
test loss item: 0.29181331396102905
test loss item: 0.14615629613399506
test loss item: 0.5625156164169312
test loss item: 0.3152744472026825
test loss item: 0.28028374910354614
test loss item: 0.23158183693885803
test loss item: 2.0832340717315674
test loss item: 0.8051947355270386
test loss item: 0.27629995346069336
test loss item: 0.4678952693939209
test loss item: 0.8109197616577148
test loss item: 0.24338024854660034
test loss item: 0.33133548498153687
test loss item: 0.513717532157898
test loss item: 0.19876155257225037
test loss item: 0.08499906212091446
test loss item: 0.4768035113811493
test loss item: 0.5003407001495361
test loss item: 0.8733910918235779
test loss item: 0.49279090762138367
test loss item: 0.732357382774353
test loss item: 0.5419308543205261
test loss item: 0.4643322825431824
test loss item: 0.27357909083366394
test loss item: 0.31829777359962463
test loss item: 0.36902281641960144
test loss item: 0.45698392391204834
test loss item: 0.2568146288394928
test loss item: 0.3836074769496918
test loss item: 0.4884847104549408
test loss item: 0.8359982967376709
test loss item: 0.09410465508699417
test loss item: 0.24845725297927856
test loss item: 0.5729253888130188
test loss item: 0.43551886081695557
test loss item: 0.5370563864707947
test loss item: 1.0058826208114624
test loss item: 1.2405544519424438
test loss item: 0.5038764476776123
test loss item: 0.3647698760032654
test loss item: 0.41638320684432983
test loss item: 0.42712870240211487
test loss item: 0.39812397956848145
test loss item: 0.34363067150115967
test loss item: 0.6279906034469604
test loss item: 0.6526355147361755
test loss item: 0.4834761917591095
test loss item: 0.4928068220615387
test loss item: 0.5191934108734131
test loss item: 0.7598298192024231
test loss item: 0.33730217814445496
test loss item: 0.34348028898239136
test loss item: 0.34383946657180786
test loss item: 0.28023239970207214
test loss item: 0.35867905616760254
test loss item: 0.7476557493209839
test loss item: 0.6716766357421875
test loss item: 0.3769041895866394
test loss item: 0.3904019594192505
test loss item: 0.26543572545051575
test loss item: 0.47699683904647827
test loss item: 0.4276728332042694
test loss item: 0.4139665961265564
test loss item: 0.34563350677490234
test loss item: 0.8785943388938904
test loss item: 0.392165869474411
test loss item: 0.5134329199790955
test loss item: 0.35011720657348633
test loss item: 0.4839220643043518
test loss item: 0.5952311754226685
test loss item: 0.08797676861286163
test loss item: 1.29764723777771
test loss item: 0.5149677991867065
test loss item: 0.6037817597389221
test loss item: 0.31520628929138184
test loss item: 0.37994301319122314
test loss item: 0.2584935426712036
test loss item: 1.1725274324417114
test loss item: 0.6203373074531555
test loss item: 0.3341832160949707
test loss item: 0.11438693851232529
test loss item: 1.0580649375915527
test loss item: 1.0551127195358276
test loss item: 0.8773736953735352
test loss item: 0.37359485030174255
test loss item: 0.3822794258594513
test loss item: 0.10529989749193192
test loss item: 0.09191145747900009
test loss item: 0.28030627965927124
Epoch [6/100], Training Loss: 0.4843, Testing Loss: 0.4961
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 7/100
train loss item: 0.44445550441741943
train loss item: 1.196074366569519
train loss item: 0.30134186148643494
train loss item: 0.6610447764396667
train loss item: 0.38494575023651123
train loss item: 0.32845404744148254
train loss item: 0.2896731197834015
train loss item: 0.584921658039093
train loss item: 0.15775281190872192
train loss item: 0.28238359093666077
train loss item: 0.3986347019672394
train loss item: 0.26916834712028503
train loss item: 0.11387396603822708
train loss item: 0.5474922060966492
train loss item: 0.2727534770965576
train loss item: 0.6056960821151733
train loss item: 0.06403099000453949
train loss item: 0.3320988714694977
train loss item: 0.35081517696380615
train loss item: 0.32113951444625854
train loss item: 0.23093314468860626
train loss item: 0.11412037909030914
train loss item: 0.8642737865447998
train loss item: 0.7655686736106873
train loss item: 0.5431575179100037
train loss item: 0.306413859128952
train loss item: 0.19230729341506958
train loss item: 0.23323602974414825
train loss item: 0.07991701364517212
train loss item: 0.5786377787590027
train loss item: 1.6732547283172607
train loss item: 0.6923893690109253
train loss item: 0.12480732798576355
train loss item: 0.33961915969848633
train loss item: 0.11168789118528366
train loss item: 1.4027258157730103
train loss item: 0.6257273554801941
train loss item: 0.46021604537963867
train loss item: 0.4841446578502655
train loss item: 0.31407150626182556
train loss item: 0.20463566482067108
train loss item: 0.3522668182849884
train loss item: 0.37489017844200134
train loss item: 0.25784197449684143
train loss item: 0.71037757396698
train loss item: 0.11012575030326843
train loss item: 0.12177683413028717
train loss item: 0.4670328199863434
train loss item: 0.3217305541038513
train loss item: 0.17216263711452484
train loss item: 0.39080214500427246
train loss item: 0.9401257038116455
train loss item: 0.07197105884552002
train loss item: 0.19589146971702576
train loss item: 1.4776074886322021
train loss item: 0.19057287275791168
train loss item: 0.3963850438594818
train loss item: 0.2379113882780075
train loss item: 0.17826944589614868
train loss item: 0.14396661520004272
train loss item: 0.7210185527801514
train loss item: 1.1686186790466309
train loss item: 0.2603455185890198
train loss item: 0.5337030291557312
train loss item: 0.20192059874534607
train loss item: 0.5993326306343079
train loss item: 0.5374658703804016
train loss item: 0.20077279210090637
train loss item: 0.40343615412712097
train loss item: 0.3575380742549896
train loss item: 0.24846871197223663
train loss item: 0.11114462465047836
train loss item: 0.25054460763931274
train loss item: 0.32031625509262085
train loss item: 0.09629762917757034
train loss item: 0.15393273532390594
train loss item: 0.8551462292671204
train loss item: 1.024643063545227
train loss item: 0.08428531885147095
train loss item: 0.3813588619232178
train loss item: 0.13117773830890656
train loss item: 0.2320852428674698
train loss item: 0.244232177734375
train loss item: 0.39694905281066895
train loss item: 0.547921895980835
train loss item: 0.5507187247276306
train loss item: 2.544010877609253
train loss item: 0.13975313305854797
train loss item: 0.4954184293746948
test loss item: 0.2962472140789032
test loss item: 0.18500465154647827
test loss item: 0.5940998196601868
test loss item: 0.3225993812084198
test loss item: 0.3082989752292633
test loss item: 0.2549231946468353
test loss item: 2.2884795665740967
test loss item: 0.9002432823181152
test loss item: 0.3216497302055359
test loss item: 0.5439707636833191
test loss item: 0.7541329860687256
test loss item: 0.2688247859477997
test loss item: 0.4029238820075989
test loss item: 0.6178768277168274
test loss item: 0.23473943769931793
test loss item: 0.08563386648893356
test loss item: 0.49148786067962646
test loss item: 0.5494091510772705
test loss item: 0.9265947937965393
test loss item: 0.5860951542854309
test loss item: 0.7589212656021118
test loss item: 0.5673730969429016
test loss item: 0.5019135475158691
test loss item: 0.29474979639053345
test loss item: 0.319225013256073
test loss item: 0.44688916206359863
test loss item: 0.5288384556770325
test loss item: 0.28684693574905396
test loss item: 0.4187181890010834
test loss item: 0.5746849775314331
test loss item: 0.8961597681045532
test loss item: 0.0890699103474617
test loss item: 0.26492658257484436
test loss item: 0.5848624110221863
test loss item: 0.47865796089172363
test loss item: 0.6502783298492432
test loss item: 1.0848026275634766
test loss item: 1.1215890645980835
test loss item: 0.5491598844528198
test loss item: 0.3945144712924957
test loss item: 0.4295493960380554
test loss item: 0.4435052275657654
test loss item: 0.4648485481739044
test loss item: 0.34785550832748413
test loss item: 0.6799997091293335
test loss item: 0.7105928659439087
test loss item: 0.5130943059921265
test loss item: 0.6575382947921753
test loss item: 0.5574197769165039
test loss item: 0.783821702003479
test loss item: 0.46677637100219727
test loss item: 0.43060562014579773
test loss item: 0.40395426750183105
test loss item: 0.28118354082107544
test loss item: 0.46702152490615845
test loss item: 0.741968035697937
test loss item: 0.7028012275695801
test loss item: 0.4921262264251709
test loss item: 0.43896016478538513
test loss item: 0.36293578147888184
test loss item: 0.5695857405662537
test loss item: 0.44798776507377625
test loss item: 0.4652719497680664
test loss item: 0.38893765211105347
test loss item: 0.9332055449485779
test loss item: 0.38961169123649597
test loss item: 0.5794054269790649
test loss item: 0.3723520040512085
test loss item: 0.47064173221588135
test loss item: 0.659311830997467
test loss item: 0.09551449865102768
test loss item: 1.426967740058899
test loss item: 0.5790250301361084
test loss item: 0.6513593792915344
test loss item: 0.34560778737068176
test loss item: 0.39561519026756287
test loss item: 0.2833142876625061
test loss item: 1.0839093923568726
test loss item: 0.7047312259674072
test loss item: 0.3489598333835602
test loss item: 0.10795216262340546
test loss item: 1.099047303199768
test loss item: 1.1458063125610352
test loss item: 0.8673787713050842
test loss item: 0.4735127091407776
test loss item: 0.4119732081890106
test loss item: 0.09640944004058838
test loss item: 0.08415107429027557
test loss item: 0.27505162358283997
Epoch [7/100], Training Loss: 0.4399, Testing Loss: 0.5379
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 8/100
train loss item: 0.4690641760826111
train loss item: 1.370843768119812
train loss item: 0.33906254172325134
train loss item: 0.6310698390007019
train loss item: 0.37503278255462646
train loss item: 0.37732088565826416
train loss item: 0.2934585213661194
train loss item: 0.7067073583602905
train loss item: 0.1925668716430664
train loss item: 0.37078243494033813
train loss item: 0.509731650352478
train loss item: 0.2693367600440979
train loss item: 0.13452497124671936
train loss item: 0.6687837243080139
train loss item: 0.32628270983695984
train loss item: 0.5695708394050598
train loss item: 0.06259627640247345
train loss item: 0.37037205696105957
train loss item: 0.35759562253952026
train loss item: 0.2613115906715393
train loss item: 0.23524600267410278
train loss item: 0.12728853523731232
train loss item: 0.8458204865455627
train loss item: 0.8515357375144958
train loss item: 0.5354660749435425
train loss item: 0.1858229786157608
train loss item: 0.2000306099653244
train loss item: 0.2145002782344818
train loss item: 0.04925678297877312
train loss item: 0.5224248766899109
train loss item: 1.3690091371536255
train loss item: 0.7756256461143494
train loss item: 0.17583271861076355
train loss item: 0.33368217945098877
train loss item: 0.11360208690166473
train loss item: 1.2340900897979736
train loss item: 0.659313976764679
train loss item: 0.4805321991443634
train loss item: 0.4125087559223175
train loss item: 0.26992470026016235
train loss item: 0.1815582662820816
train loss item: 0.311013787984848
train loss item: 0.33454301953315735
train loss item: 0.2472938746213913
train loss item: 0.6052659153938293
train loss item: 0.12290994822978973
train loss item: 0.11766999214887619
train loss item: 0.39428767561912537
train loss item: 0.2791212797164917
train loss item: 0.16540628671646118
train loss item: 0.34267452359199524
train loss item: 0.8927373886108398
train loss item: 0.08900678902864456
train loss item: 0.17248576879501343
train loss item: 1.1685435771942139
train loss item: 0.20822730660438538
train loss item: 0.4424988925457001
train loss item: 0.2119615525007248
train loss item: 0.14401598274707794
train loss item: 0.10733173042535782
train loss item: 0.662929892539978
train loss item: 1.1072558164596558
train loss item: 0.22056375443935394
train loss item: 0.4845208525657654
train loss item: 0.16145993769168854
train loss item: 0.5377627611160278
train loss item: 0.500778079032898
train loss item: 0.1910535842180252
train loss item: 0.35832345485687256
train loss item: 0.3153858780860901
train loss item: 0.23926378786563873
train loss item: 0.11486254632472992
train loss item: 0.2071431279182434
train loss item: 0.2925991117954254
train loss item: 0.11343211680650711
train loss item: 0.13531138002872467
train loss item: 0.6896268129348755
train loss item: 1.0016021728515625
train loss item: 0.08443136513233185
train loss item: 0.28996893763542175
train loss item: 0.13920217752456665
train loss item: 0.18742170929908752
train loss item: 0.2237304151058197
train loss item: 0.40799689292907715
train loss item: 0.516615092754364
train loss item: 0.5236713290214539
train loss item: 2.152217388153076
train loss item: 0.1237364262342453
train loss item: 0.4269510805606842
test loss item: 0.2567932605743408
test loss item: 0.15761049091815948
test loss item: 0.5037261247634888
test loss item: 0.28755679726600647
test loss item: 0.2799733281135559
test loss item: 0.2226824313402176
test loss item: 2.1670100688934326
test loss item: 0.7983096241950989
test loss item: 0.25100791454315186
test loss item: 0.4357367157936096
test loss item: 0.6541020274162292
test loss item: 0.23016734421253204
test loss item: 0.30277976393699646
test loss item: 0.4904247224330902
test loss item: 0.20367814600467682
test loss item: 0.09016114473342896
test loss item: 0.42522889375686646
test loss item: 0.47748976945877075
test loss item: 0.8310874700546265
test loss item: 0.4600565731525421
test loss item: 0.6939845681190491
test loss item: 0.5127993822097778
test loss item: 0.4229692220687866
test loss item: 0.25995388627052307
test loss item: 0.27470603585243225
test loss item: 0.3801916539669037
test loss item: 0.43125125765800476
test loss item: 0.25557640194892883
test loss item: 0.38432759046554565
test loss item: 0.45384252071380615
test loss item: 0.8206896185874939
test loss item: 0.08280728757381439
test loss item: 0.22916240990161896
test loss item: 0.5244811773300171
test loss item: 0.41453447937965393
test loss item: 0.5124036073684692
test loss item: 0.9803028702735901
test loss item: 0.9642666578292847
test loss item: 0.4859732985496521
test loss item: 0.3627009391784668
test loss item: 0.3904828429222107
test loss item: 0.37790361046791077
test loss item: 0.3817921280860901
test loss item: 0.30606842041015625
test loss item: 0.5996156334877014
test loss item: 0.6003375053405762
test loss item: 0.4361158311367035
test loss item: 0.4732668399810791
test loss item: 0.4692555367946625
test loss item: 0.6891291737556458
test loss item: 0.37084266543388367
test loss item: 0.3076935410499573
test loss item: 0.3376193940639496
test loss item: 0.24078120291233063
test loss item: 0.38281193375587463
test loss item: 0.6496930122375488
test loss item: 0.6182107329368591
test loss item: 0.3799244463443756
test loss item: 0.36443161964416504
test loss item: 0.28534725308418274
test loss item: 0.4684639573097229
test loss item: 0.3784245550632477
test loss item: 0.38511332869529724
test loss item: 0.327300488948822
test loss item: 0.8369375467300415
test loss item: 0.3546932339668274
test loss item: 0.4802832007408142
test loss item: 0.3356372117996216
test loss item: 0.42487016320228577
test loss item: 0.555466890335083
test loss item: 0.10445588082075119
test loss item: 1.3153855800628662
test loss item: 0.4786612093448639
test loss item: 0.5853992700576782
test loss item: 0.2791902422904968
test loss item: 0.33464714884757996
test loss item: 0.25238972902297974
test loss item: 0.9297845959663391
test loss item: 0.573838472366333
test loss item: 0.30514857172966003
test loss item: 0.11132800579071045
test loss item: 0.9930948615074158
test loss item: 1.0298348665237427
test loss item: 0.7273204326629639
test loss item: 0.37451088428497314
test loss item: 0.3491256833076477
test loss item: 0.10328185558319092
test loss item: 0.08650226145982742
test loss item: 0.28411224484443665
Epoch [8/100], Training Loss: 0.4179, Testing Loss: 0.4652
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 9/100
train loss item: 0.3943084180355072
train loss item: 1.2518301010131836
train loss item: 0.2417733371257782
train loss item: 0.5033578276634216
train loss item: 0.31762465834617615
train loss item: 0.30651310086250305
train loss item: 0.2719748020172119
train loss item: 0.49678751826286316
train loss item: 0.14055512845516205
train loss item: 0.2502962648868561
train loss item: 0.3384595215320587
train loss item: 0.21768838167190552
train loss item: 0.10802147537469864
train loss item: 0.5206465125083923
train loss item: 0.22832664847373962
train loss item: 0.5531049370765686
train loss item: 0.07221700251102448
train loss item: 0.33692964911460876
train loss item: 0.32066312432289124
train loss item: 0.29065757989883423
train loss item: 0.20987290143966675
train loss item: 0.10496153682470322
train loss item: 0.8737314939498901
train loss item: 0.6202548742294312
train loss item: 0.5031731724739075
train loss item: 0.1902940422296524
train loss item: 0.1990508884191513
train loss item: 0.18747586011886597
train loss item: 0.08616480231285095
train loss item: 0.4545786380767822
train loss item: 1.3357439041137695
train loss item: 0.6800063252449036
train loss item: 0.14511138200759888
train loss item: 0.29686275124549866
train loss item: 0.13443797826766968
train loss item: 1.1794207096099854
train loss item: 0.49578624963760376
train loss item: 0.44220465421676636
train loss item: 0.3789566159248352
train loss item: 0.3019673824310303
train loss item: 0.22432221472263336
train loss item: 0.319710373878479
train loss item: 0.37649762630462646
train loss item: 0.24996329843997955
train loss item: 0.5574735999107361
train loss item: 0.13155370950698853
train loss item: 0.12359916418790817
train loss item: 0.41753652691841125
train loss item: 0.24487647414207458
train loss item: 0.16097494959831238
train loss item: 0.34911730885505676
train loss item: 0.7844935059547424
train loss item: 0.07732833921909332
train loss item: 0.17402642965316772
train loss item: 0.8306376338005066
train loss item: 0.2039181888103485
train loss item: 0.48135289549827576
train loss item: 0.19480495154857635
train loss item: 0.14029325544834137
train loss item: 0.09558185189962387
train loss item: 0.6558430194854736
train loss item: 0.9901688694953918
train loss item: 0.178696408867836
train loss item: 0.4276404082775116
train loss item: 0.15233182907104492
train loss item: 0.5161534547805786
train loss item: 0.42756152153015137
train loss item: 0.1913672834634781
train loss item: 0.3697536587715149
train loss item: 0.3045537769794464
train loss item: 0.23685811460018158
train loss item: 0.13889606297016144
train loss item: 0.17531685531139374
train loss item: 0.2842349112033844
train loss item: 0.10026045143604279
train loss item: 0.13180258870124817
train loss item: 0.5807970762252808
train loss item: 1.1195266246795654
train loss item: 0.07228309661149979
train loss item: 0.24628476798534393
train loss item: 0.13208618760108948
train loss item: 0.17380771040916443
train loss item: 0.19949181377887726
train loss item: 0.40946468710899353
train loss item: 0.3933228552341461
train loss item: 0.4673115611076355
train loss item: 1.9249519109725952
train loss item: 0.10517001897096634
train loss item: 0.4247356951236725
test loss item: 0.2204207479953766
test loss item: 0.12424349784851074
test loss item: 0.4377097189426422
test loss item: 0.2515019476413727
test loss item: 0.22747795283794403
test loss item: 0.1653396487236023
test loss item: 1.9440281391143799
test loss item: 0.7012624740600586
test loss item: 0.21113066375255585
test loss item: 0.3685648441314697
test loss item: 0.5838293433189392
test loss item: 0.19564618170261383
test loss item: 0.2406734675168991
test loss item: 0.4197448492050171
test loss item: 0.16835032403469086
test loss item: 0.08144384622573853
test loss item: 0.35634589195251465
test loss item: 0.406818151473999
test loss item: 0.7374441623687744
test loss item: 0.38563090562820435
test loss item: 0.6313338875770569
test loss item: 0.44727596640586853
test loss item: 0.358994722366333
test loss item: 0.22699229419231415
test loss item: 0.22718161344528198
test loss item: 0.32386988401412964
test loss item: 0.3754996657371521
test loss item: 0.20187275111675262
test loss item: 0.336020827293396
test loss item: 0.37438440322875977
test loss item: 0.7395486831665039
test loss item: 0.0772009864449501
test loss item: 0.19681890308856964
test loss item: 0.46572744846343994
test loss item: 0.356590211391449
test loss item: 0.4568166136741638
test loss item: 0.8710479140281677
test loss item: 0.8426154851913452
test loss item: 0.42564958333969116
test loss item: 0.3154803216457367
test loss item: 0.34118926525115967
test loss item: 0.3044590950012207
test loss item: 0.3218909204006195
test loss item: 0.2561221420764923
test loss item: 0.5347146987915039
test loss item: 0.5165683031082153
test loss item: 0.3623445928096771
test loss item: 0.38730573654174805
test loss item: 0.40712982416152954
test loss item: 0.6189296841621399
test loss item: 0.3098899722099304
test loss item: 0.23484206199645996
test loss item: 0.27424341440200806
test loss item: 0.19664782285690308
test loss item: 0.3191346228122711
test loss item: 0.5909035801887512
test loss item: 0.5499278903007507
test loss item: 0.31522467732429504
test loss item: 0.30291709303855896
test loss item: 0.22689715027809143
test loss item: 0.40138375759124756
test loss item: 0.31830039620399475
test loss item: 0.3241020739078522
test loss item: 0.2808609902858734
test loss item: 0.7436649799346924
test loss item: 0.31405654549598694
test loss item: 0.4037174880504608
test loss item: 0.290264368057251
test loss item: 0.37645331025123596
test loss item: 0.4984920024871826
test loss item: 0.08656774461269379
test loss item: 1.1674731969833374
test loss item: 0.419001042842865
test loss item: 0.5134468078613281
test loss item: 0.22083322703838348
test loss item: 0.2707971930503845
test loss item: 0.22019171714782715
test loss item: 0.8035420775413513
test loss item: 0.507011890411377
test loss item: 0.24383126199245453
test loss item: 0.09940210729837418
test loss item: 0.8895789980888367
test loss item: 0.9265362620353699
test loss item: 0.6298977136611938
test loss item: 0.3124161958694458
test loss item: 0.28668269515037537
test loss item: 0.09571012854576111
test loss item: 0.08296304941177368
test loss item: 0.23552587628364563
Epoch [9/100], Training Loss: 0.3781, Testing Loss: 0.4024
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 10/100
train loss item: 0.36878710985183716
train loss item: 1.1763375997543335
train loss item: 0.21575602889060974
train loss item: 0.4448288381099701
train loss item: 0.3368370831012726
train loss item: 0.2958010733127594
train loss item: 0.24419847130775452
train loss item: 0.551024317741394
train loss item: 0.154616117477417
train loss item: 0.29211241006851196
train loss item: 0.4009685218334198
train loss item: 0.20642174780368805
train loss item: 0.10886412113904953
train loss item: 0.5505256056785583
train loss item: 0.25262555480003357
train loss item: 0.5175904631614685
train loss item: 0.05777578055858612
train loss item: 0.3303355276584625
train loss item: 0.30565008521080017
train loss item: 0.2700704336166382
train loss item: 0.23120786249637604
train loss item: 0.10362990200519562
train loss item: 0.8113481998443604
train loss item: 0.5591221451759338
train loss item: 0.4598255455493927
train loss item: 0.19131170213222504
train loss item: 0.16942310333251953
train loss item: 0.1938268542289734
train loss item: 0.06184440106153488
train loss item: 0.45426642894744873
train loss item: 1.2089669704437256
train loss item: 0.6438276767730713
train loss item: 0.08453910052776337
train loss item: 0.2876169979572296
train loss item: 0.11484619230031967
train loss item: 1.1217713356018066
train loss item: 0.5655614137649536
train loss item: 0.47476041316986084
train loss item: 0.33075210452079773
train loss item: 0.28030452132225037
train loss item: 0.20698845386505127
train loss item: 0.3047412037849426
train loss item: 0.34826725721359253
train loss item: 0.25430336594581604
train loss item: 0.6151103973388672
train loss item: 0.12027926743030548
train loss item: 0.12578274309635162
train loss item: 0.37028443813323975
train loss item: 0.26226845383644104
train loss item: 0.17602413892745972
train loss item: 0.27000075578689575
train loss item: 0.8621054291725159
train loss item: 0.0642240047454834
train loss item: 0.1927359253168106
train loss item: 1.0703378915786743
train loss item: 0.171883225440979
train loss item: 0.42034947872161865
train loss item: 0.2148023098707199
train loss item: 0.16113224625587463
train loss item: 0.11904363334178925
train loss item: 0.5377424955368042
train loss item: 1.0143924951553345
train loss item: 0.19995950162410736
train loss item: 0.3869819641113281
train loss item: 0.13324472308158875
train loss item: 0.48113787174224854
train loss item: 0.3302311599254608
train loss item: 0.16948848962783813
train loss item: 0.3092219829559326
train loss item: 0.2528246343135834
train loss item: 0.20946331322193146
train loss item: 0.10001591593027115
train loss item: 0.17831844091415405
train loss item: 0.24189244210720062
train loss item: 0.07724722474813461
train loss item: 0.11520673334598541
train loss item: 0.5836808681488037
train loss item: 0.8585512638092041
train loss item: 0.07447987794876099
train loss item: 0.3069455325603485
train loss item: 0.11994390189647675
train loss item: 0.1438131481409073
train loss item: 0.18901099264621735
train loss item: 0.3486930727958679
train loss item: 0.4438842535018921
train loss item: 0.4163747727870941
train loss item: 1.8966126441955566
train loss item: 0.1123899295926094
train loss item: 0.4075483977794647
test loss item: 0.21484242379665375
test loss item: 0.12628278136253357
test loss item: 0.47858038544654846
test loss item: 0.24873511493206024
test loss item: 0.21585822105407715
test loss item: 0.15981148183345795
test loss item: 2.091974973678589
test loss item: 0.8710073828697205
test loss item: 0.26112282276153564
test loss item: 0.42725706100463867
test loss item: 0.6413074731826782
test loss item: 0.1753314733505249
test loss item: 0.2865150272846222
test loss item: 0.4109778106212616
test loss item: 0.16679063439369202
test loss item: 0.07774188369512558
test loss item: 0.38298314809799194
test loss item: 0.4081336259841919
test loss item: 0.8623019456863403
test loss item: 0.423302561044693
test loss item: 0.5651770234107971
test loss item: 0.49523627758026123
test loss item: 0.3205699026584625
test loss item: 0.22970856726169586
test loss item: 0.22877700626850128
test loss item: 0.32366329431533813
test loss item: 0.4091174006462097
test loss item: 0.1992020457983017
test loss item: 0.32715409994125366
test loss item: 0.4480556547641754
test loss item: 0.8053573966026306
test loss item: 0.0771641656756401
test loss item: 0.20011018216609955
test loss item: 0.4603038728237152
test loss item: 0.3625778555870056
test loss item: 0.5532498359680176
test loss item: 0.9983686804771423
test loss item: 0.9241281747817993
test loss item: 0.42515021562576294
test loss item: 0.31712543964385986
test loss item: 0.3505900204181671
test loss item: 0.28294309973716736
test loss item: 0.34527072310447693
test loss item: 0.26400408148765564
test loss item: 0.48273369669914246
test loss item: 0.5673304200172424
test loss item: 0.33956262469291687
test loss item: 0.4624353051185608
test loss item: 0.46624618768692017
test loss item: 0.6990091800689697
test loss item: 0.3322218060493469
test loss item: 0.3107130825519562
test loss item: 0.294273316860199
test loss item: 0.1858646720647812
test loss item: 0.32647863030433655
test loss item: 0.6384111046791077
test loss item: 0.6361135244369507
test loss item: 0.3011924624443054
test loss item: 0.3273474872112274
test loss item: 0.2347787320613861
test loss item: 0.4569457173347473
test loss item: 0.38290584087371826
test loss item: 0.3255096971988678
test loss item: 0.26828521490097046
test loss item: 0.8207732439041138
test loss item: 0.3084791898727417
test loss item: 0.4488021731376648
test loss item: 0.2870396673679352
test loss item: 0.35647422075271606
test loss item: 0.6207966208457947
test loss item: 0.07183729857206345
test loss item: 1.3017041683197021
test loss item: 0.39851537346839905
test loss item: 0.5202128887176514
test loss item: 0.24250733852386475
test loss item: 0.2557038366794586
test loss item: 0.22344070672988892
test loss item: 0.8488708734512329
test loss item: 0.47000956535339355
test loss item: 0.22942163050174713
test loss item: 0.09332186728715897
test loss item: 0.9849663972854614
test loss item: 1.0423580408096313
test loss item: 0.7146645188331604
test loss item: 0.3125433623790741
test loss item: 0.29582542181015015
test loss item: 0.09069182723760605
test loss item: 0.08584767580032349
test loss item: 0.18225927650928497
Epoch [10/100], Training Loss: 0.3640, Testing Loss: 0.4280
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 11/100
train loss item: 0.3516409993171692
train loss item: 1.201147437095642
train loss item: 0.23994331061840057
train loss item: 0.5591029524803162
train loss item: 0.3794388175010681
train loss item: 0.29282987117767334
train loss item: 0.23817101120948792
train loss item: 0.5576915740966797
train loss item: 0.16893020272254944
train loss item: 0.3322283625602722
train loss item: 0.4590919315814972
train loss item: 0.21242864429950714
train loss item: 0.12817014753818512
train loss item: 0.6465445160865784
train loss item: 0.3061198890209198
train loss item: 0.5243459343910217
train loss item: 0.054712485522031784
train loss item: 0.2549760937690735
train loss item: 0.30863717198371887
train loss item: 0.19922983646392822
train loss item: 0.19130975008010864
train loss item: 0.10671661794185638
train loss item: 0.6655517220497131
train loss item: 0.7042142152786255
train loss item: 0.44304925203323364
train loss item: 0.13085633516311646
train loss item: 0.175633504986763
train loss item: 0.17624531686306
train loss item: 0.07130968570709229
train loss item: 0.40509000420570374
train loss item: 0.921065092086792
train loss item: 0.578025758266449
train loss item: 0.1708349585533142
train loss item: 0.3160601854324341
train loss item: 0.07947178184986115
train loss item: 0.9091742634773254
train loss item: 0.4133121371269226
train loss item: 0.4598950743675232
train loss item: 0.34545108675956726
train loss item: 0.2828223407268524
train loss item: 0.14905411005020142
train loss item: 0.21740491688251495
train loss item: 0.27699628472328186
train loss item: 0.17909517884254456
train loss item: 0.47550565004348755
train loss item: 0.08089124411344528
train loss item: 0.11064223200082779
train loss item: 0.25688743591308594
train loss item: 0.20177561044692993
train loss item: 0.13420560956001282
train loss item: 0.21870703995227814
train loss item: 0.5677627921104431
train loss item: 0.06442371010780334
train loss item: 0.14693422615528107
train loss item: 0.7360521554946899
train loss item: 0.13771553337574005
train loss item: 0.3373256325721741
train loss item: 0.20731544494628906
train loss item: 0.12942995131015778
train loss item: 0.10982415825128555
train loss item: 0.4982871413230896
train loss item: 0.8386845588684082
train loss item: 0.16438832879066467
train loss item: 0.37143492698669434
train loss item: 0.11477769911289215
train loss item: 0.39779096841812134
train loss item: 0.6552861332893372
train loss item: 0.1361151486635208
train loss item: 0.3262101113796234
train loss item: 0.27677059173583984
train loss item: 0.21917171776294708
train loss item: 0.08271881192922592
train loss item: 0.1982654631137848
train loss item: 0.25965800881385803
train loss item: 0.09097577631473541
train loss item: 0.12616805732250214
train loss item: 0.5393236875534058
train loss item: 0.9164692163467407
train loss item: 0.08801324665546417
train loss item: 0.2518012821674347
train loss item: 0.12071328610181808
train loss item: 0.17008225619792938
train loss item: 0.17531894147396088
train loss item: 0.4390203356742859
train loss item: 0.4528355598449707
train loss item: 0.42771753668785095
train loss item: 1.430991768836975
train loss item: 0.11251663416624069
train loss item: 0.3676459789276123
test loss item: 0.2733357548713684
test loss item: 0.15208448469638824
test loss item: 0.42200490832328796
test loss item: 0.28144019842147827
test loss item: 0.26927244663238525
test loss item: 0.2424914687871933
test loss item: 2.0768954753875732
test loss item: 0.795715868473053
test loss item: 0.2300272136926651
test loss item: 0.3807864487171173
test loss item: 0.5343923568725586
test loss item: 0.22723378241062164
test loss item: 0.2884429395198822
test loss item: 0.5109472870826721
test loss item: 0.1909208446741104
test loss item: 0.06529062986373901
test loss item: 0.3996813893318176
test loss item: 0.4001736640930176
test loss item: 0.7935696244239807
test loss item: 0.4438507556915283
test loss item: 0.539728045463562
test loss item: 0.4966568946838379
test loss item: 0.4782503545284271
test loss item: 0.259046733379364
test loss item: 0.23673811554908752
test loss item: 0.3682284951210022
test loss item: 0.39221838116645813
test loss item: 0.2577313482761383
test loss item: 0.3518717288970947
test loss item: 0.4112435281276703
test loss item: 0.7470362782478333
test loss item: 0.06025756895542145
test loss item: 0.23060840368270874
test loss item: 0.41930538415908813
test loss item: 0.3359430730342865
test loss item: 0.4596863389015198
test loss item: 0.9314870834350586
test loss item: 0.7035000324249268
test loss item: 0.40896356105804443
test loss item: 0.35917314887046814
test loss item: 0.3614037036895752
test loss item: 0.44090020656585693
test loss item: 0.32526907324790955
test loss item: 0.2949352264404297
test loss item: 0.48846274614334106
test loss item: 0.5605757832527161
test loss item: 0.4811924695968628
test loss item: 0.4545227289199829
test loss item: 0.41561439633369446
test loss item: 0.6076411604881287
test loss item: 0.31660592555999756
test loss item: 0.3044164478778839
test loss item: 0.3174501061439514
test loss item: 0.2340197116136551
test loss item: 0.3459879159927368
test loss item: 0.4733836054801941
test loss item: 0.5686827898025513
test loss item: 0.37904781103134155
test loss item: 0.35233116149902344
test loss item: 0.2610552906990051
test loss item: 0.3881884515285492
test loss item: 0.37522971630096436
test loss item: 0.3937428295612335
test loss item: 0.28696587681770325
test loss item: 0.7534306049346924
test loss item: 0.33989816904067993
test loss item: 0.4542030990123749
test loss item: 0.30633872747421265
test loss item: 0.3230188488960266
test loss item: 0.531600296497345
test loss item: 0.10149317979812622
test loss item: 1.2562055587768555
test loss item: 0.49826180934906006
test loss item: 0.5784661769866943
test loss item: 0.2808033227920532
test loss item: 0.3988070487976074
test loss item: 0.24780753254890442
test loss item: 0.6768083572387695
test loss item: 0.5641013383865356
test loss item: 0.32720494270324707
test loss item: 0.11465073376893997
test loss item: 0.9293727874755859
test loss item: 0.9536556005477905
test loss item: 0.5937883853912354
test loss item: 0.3741113841533661
test loss item: 0.35229167342185974
test loss item: 0.09643923491239548
test loss item: 0.06111721694469452
test loss item: 0.30220261216163635
Epoch [11/100], Training Loss: 0.3365, Testing Loss: 0.4300
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 12/100
train loss item: 0.318637877702713
train loss item: 1.1446057558059692
train loss item: 0.24441656470298767
train loss item: 0.43739497661590576
train loss item: 0.28658393025398254
train loss item: 0.24937263131141663
train loss item: 0.2252013236284256
train loss item: 0.41495928168296814
train loss item: 0.10861784964799881
train loss item: 0.22003062069416046
train loss item: 0.28034526109695435
train loss item: 0.17518939077854156
train loss item: 0.08583085238933563
train loss item: 0.48764750361442566
train loss item: 0.22358311712741852
train loss item: 0.5058114528656006
train loss item: 0.07784561812877655
train loss item: 0.38028228282928467
train loss item: 0.2858195900917053
train loss item: 0.2014017254114151
train loss item: 0.20406530797481537
train loss item: 0.12491460144519806
train loss item: 0.8435080647468567
train loss item: 0.5856256484985352
train loss item: 0.4806426167488098
train loss item: 0.13591182231903076
train loss item: 0.14522697031497955
train loss item: 0.16856014728546143
train loss item: 0.05926134064793587
train loss item: 0.39923959970474243
train loss item: 1.2476084232330322
train loss item: 0.6598173975944519
train loss item: 0.11028368026018143
train loss item: 0.42748281359672546
train loss item: 0.11150426417589188
train loss item: 0.8034762144088745
train loss item: 0.4103754162788391
train loss item: 0.4066591262817383
train loss item: 0.342950701713562
train loss item: 0.2908951938152313
train loss item: 0.24863070249557495
train loss item: 0.2858581244945526
train loss item: 0.4185601472854614
train loss item: 0.2813757658004761
train loss item: 0.47809430956840515
train loss item: 0.13935348391532898
train loss item: 0.1318097710609436
train loss item: 0.5793885588645935
train loss item: 0.27474620938301086
train loss item: 0.14173904061317444
train loss item: 0.4409271776676178
train loss item: 1.0888311862945557
train loss item: 0.06874044239521027
train loss item: 0.19118686020374298
train loss item: 0.6813395619392395
train loss item: 0.22477830946445465
train loss item: 0.3538033962249756
train loss item: 0.2141517996788025
train loss item: 0.1646910011768341
train loss item: 0.10130057483911514
train loss item: 0.8427532315254211
train loss item: 0.7913386225700378
train loss item: 0.2046675831079483
train loss item: 0.2820344865322113
train loss item: 0.15011394023895264
train loss item: 0.4297925531864166
train loss item: 0.3176676332950592
train loss item: 0.16713592410087585
train loss item: 0.25844287872314453
train loss item: 0.20665553212165833
train loss item: 0.17373235523700714
train loss item: 0.08717573434114456
train loss item: 0.16682197153568268
train loss item: 0.21926580369472504
train loss item: 0.07842610031366348
train loss item: 0.109316386282444
train loss item: 0.6065323948860168
train loss item: 0.8510445952415466
train loss item: 0.06471731513738632
train loss item: 0.2590792775154114
train loss item: 0.07278728485107422
train loss item: 0.12045217305421829
train loss item: 0.14970695972442627
train loss item: 0.36046114563941956
train loss item: 0.3079228699207306
train loss item: 0.3731951415538788
train loss item: 1.5809905529022217
train loss item: 0.10661996155977249
train loss item: 0.40498974919319153
test loss item: 0.19222895801067352
test loss item: 0.14337073266506195
test loss item: 0.38957467675209045
test loss item: 0.21392633020877838
test loss item: 0.2347114384174347
test loss item: 0.17028112709522247
test loss item: 1.5736446380615234
test loss item: 0.5895957350730896
test loss item: 0.215876966714859
test loss item: 0.37257522344589233
test loss item: 0.5028024911880493
test loss item: 0.1667214184999466
test loss item: 0.2358415424823761
test loss item: 0.3559458255767822
test loss item: 0.1790776550769806
test loss item: 0.09903771430253983
test loss item: 0.2802101969718933
test loss item: 0.416454017162323
test loss item: 0.6339200735092163
test loss item: 0.3202405869960785
test loss item: 0.5899062156677246
test loss item: 0.353939950466156
test loss item: 0.3380764126777649
test loss item: 0.20046837627887726
test loss item: 0.19344483315944672
test loss item: 0.30865493416786194
test loss item: 0.33334463834762573
test loss item: 0.21317608654499054
test loss item: 0.30932366847991943
test loss item: 0.3689471483230591
test loss item: 0.6103731393814087
test loss item: 0.09721767157316208
test loss item: 0.18509763479232788
test loss item: 0.42158839106559753
test loss item: 0.352631539106369
test loss item: 0.4442368149757385
test loss item: 0.7593390941619873
test loss item: 0.7005831599235535
test loss item: 0.3919951319694519
test loss item: 0.2522567808628082
test loss item: 0.2618401050567627
test loss item: 0.2872113883495331
test loss item: 0.3510647416114807
test loss item: 0.1938813179731369
test loss item: 0.5098052024841309
test loss item: 0.4029577672481537
test loss item: 0.34509968757629395
test loss item: 0.36309704184532166
test loss item: 0.36787697672843933
test loss item: 0.5543680191040039
test loss item: 0.345573753118515
test loss item: 0.2497391402721405
test loss item: 0.27710938453674316
test loss item: 0.1556738317012787
test loss item: 0.3540950119495392
test loss item: 0.5308516621589661
test loss item: 0.46551182866096497
test loss item: 0.2976935803890228
test loss item: 0.28041043877601624
test loss item: 0.25718337297439575
test loss item: 0.43464595079421997
test loss item: 0.2617886960506439
test loss item: 0.27012428641319275
test loss item: 0.22851461172103882
test loss item: 0.6104266047477722
test loss item: 0.2555275559425354
test loss item: 0.3543696701526642
test loss item: 0.2265658974647522
test loss item: 0.30031442642211914
test loss item: 0.4377051889896393
test loss item: 0.09426981210708618
test loss item: 0.940663754940033
test loss item: 0.3588665723800659
test loss item: 0.3710077404975891
test loss item: 0.20345690846443176
test loss item: 0.2698589861392975
test loss item: 0.19517342746257782
test loss item: 0.6530492901802063
test loss item: 0.35961413383483887
test loss item: 0.21754209697246552
test loss item: 0.10604681074619293
test loss item: 0.736163318157196
test loss item: 0.8190256953239441
test loss item: 0.5414702296257019
test loss item: 0.2860914170742035
test loss item: 0.27189379930496216
test loss item: 0.1039949432015419
test loss item: 0.10450989007949829
test loss item: 0.1938287913799286
Epoch [12/100], Training Loss: 0.3434, Testing Loss: 0.3569
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 13/100
train loss item: 0.33129727840423584
train loss item: 0.9997149109840393
train loss item: 0.21371065080165863
train loss item: 0.3767351806163788
train loss item: 0.25306814908981323
train loss item: 0.22630108892917633
train loss item: 0.23450639843940735
train loss item: 0.4015365242958069
train loss item: 0.13999943435192108
train loss item: 0.27346479892730713
train loss item: 0.3580811619758606
train loss item: 0.1971462219953537
train loss item: 0.09402801096439362
train loss item: 0.5317664742469788
train loss item: 0.2703207731246948
train loss item: 0.4701194763183594
train loss item: 0.04668707028031349
train loss item: 0.20773273706436157
train loss item: 0.27877214550971985
train loss item: 0.20459096133708954
train loss item: 0.14312341809272766
train loss item: 0.10213758796453476
train loss item: 0.5534709692001343
train loss item: 0.43283915519714355
train loss item: 0.38100752234458923
train loss item: 0.15521275997161865
train loss item: 0.13771915435791016
train loss item: 0.14530853927135468
train loss item: 0.05245557054877281
train loss item: 0.3519633710384369
train loss item: 0.7048084139823914
train loss item: 0.4351513981819153
train loss item: 0.1390647441148758
train loss item: 0.2052299529314041
train loss item: 0.07566659152507782
train loss item: 0.7835164666175842
train loss item: 0.3105607032775879
train loss item: 0.39337489008903503
train loss item: 0.26320788264274597
train loss item: 0.19296905398368835
train loss item: 0.1653692126274109
train loss item: 0.1877816766500473
train loss item: 0.29439452290534973
train loss item: 0.1744249016046524
train loss item: 0.39429038763046265
train loss item: 0.0691315084695816
train loss item: 0.07783379405736923
train loss item: 0.3002392053604126
train loss item: 0.14925532042980194
train loss item: 0.10666514188051224
train loss item: 0.20137491822242737
train loss item: 0.5146510601043701
train loss item: 0.044546689838171005
train loss item: 0.1570366621017456
train loss item: 0.5121350288391113
train loss item: 0.18984416127204895
train loss item: 0.38213643431663513
train loss item: 0.16193260252475739
train loss item: 0.1096283569931984
train loss item: 0.10584934800863266
train loss item: 0.4363635778427124
train loss item: 0.6641638278961182
train loss item: 0.13822738826274872
train loss item: 0.28772401809692383
train loss item: 0.11517298221588135
train loss item: 0.3399234116077423
train loss item: 0.2815433442592621
train loss item: 0.1686324179172516
train loss item: 0.3118778467178345
train loss item: 0.21918989717960358
train loss item: 0.1777353435754776
train loss item: 0.0999298095703125
train loss item: 0.12240813672542572
train loss item: 0.17501141130924225
train loss item: 0.0900561660528183
train loss item: 0.11938337236642838
train loss item: 0.3852049708366394
train loss item: 0.6177728772163391
train loss item: 0.07459402084350586
train loss item: 0.3411518633365631
train loss item: 0.11362604796886444
train loss item: 0.15428988635540009
train loss item: 0.1666763722896576
train loss item: 0.35002401471138
train loss item: 0.3767087161540985
train loss item: 0.37642550468444824
train loss item: 1.3713458776474
train loss item: 0.10918675363063812
train loss item: 0.312358021736145
test loss item: 0.2422332614660263
test loss item: 0.14215312898159027
test loss item: 0.4014225900173187
test loss item: 0.2725621163845062
test loss item: 0.216861292719841
test loss item: 0.1861467957496643
test loss item: 1.9822262525558472
test loss item: 0.7868183255195618
test loss item: 0.24746696650981903
test loss item: 0.381171315908432
test loss item: 0.5422638058662415
test loss item: 0.22570623457431793
test loss item: 0.2868424952030182
test loss item: 0.45588043332099915
test loss item: 0.18015648424625397
test loss item: 0.09087184816598892
test loss item: 0.37079522013664246
test loss item: 0.37325963377952576
test loss item: 0.7880491614341736
test loss item: 0.4192088842391968
test loss item: 0.4961617588996887
test loss item: 0.46805956959724426
test loss item: 0.37052249908447266
test loss item: 0.24273909628391266
test loss item: 0.22998274862766266
test loss item: 0.329215943813324
test loss item: 0.3848085403442383
test loss item: 0.20814020931720734
test loss item: 0.31651830673217773
test loss item: 0.3965017795562744
test loss item: 0.7326781153678894
test loss item: 0.10028354823589325
test loss item: 0.21951249241828918
test loss item: 0.38977763056755066
test loss item: 0.3164695203304291
test loss item: 0.5196441411972046
test loss item: 0.9086683392524719
test loss item: 0.6942379474639893
test loss item: 0.3908590078353882
test loss item: 0.32055285573005676
test loss item: 0.3455088138580322
test loss item: 0.3370985686779022
test loss item: 0.32027000188827515
test loss item: 0.28523215651512146
test loss item: 0.4521616995334625
test loss item: 0.5164726972579956
test loss item: 0.3730386197566986
test loss item: 0.44958004355430603
test loss item: 0.40472742915153503
test loss item: 0.6226271390914917
test loss item: 0.32104167342185974
test loss item: 0.2935582399368286
test loss item: 0.2952655851840973
test loss item: 0.23781836032867432
test loss item: 0.3163268268108368
test loss item: 0.5016356110572815
test loss item: 0.5726982355117798
test loss item: 0.34210750460624695
test loss item: 0.3259667754173279
test loss item: 0.24973715841770172
test loss item: 0.38719913363456726
test loss item: 0.357831209897995
test loss item: 0.3372289836406708
test loss item: 0.2904375493526459
test loss item: 0.7196665406227112
test loss item: 0.33467960357666016
test loss item: 0.42808160185813904
test loss item: 0.287231981754303
test loss item: 0.2766640782356262
test loss item: 0.600835382938385
test loss item: 0.09001987427473068
test loss item: 1.2101370096206665
test loss item: 0.42818230390548706
test loss item: 0.5132758021354675
test loss item: 0.25646716356277466
test loss item: 0.2992647886276245
test loss item: 0.23471003770828247
test loss item: 0.6036587953567505
test loss item: 0.4745427966117859
test loss item: 0.2566227912902832
test loss item: 0.1195027232170105
test loss item: 0.9104523658752441
test loss item: 0.9472076296806335
test loss item: 0.593033492565155
test loss item: 0.326215922832489
test loss item: 0.31728672981262207
test loss item: 0.11136329174041748
test loss item: 0.10426148772239685
test loss item: 0.2422892451286316
Epoch [13/100], Training Loss: 0.2794, Testing Loss: 0.4073
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 14/100
train loss item: 0.29536378383636475
train loss item: 1.0266008377075195
train loss item: 0.2416808307170868
train loss item: 0.4712778329849243
train loss item: 0.2816067636013031
train loss item: 0.22256717085838318
train loss item: 0.2105690836906433
train loss item: 0.3358517587184906
train loss item: 0.13705092668533325
train loss item: 0.2854313552379608
train loss item: 0.3938833475112915
train loss item: 0.19127589464187622
train loss item: 0.09862038493156433
train loss item: 0.5857881903648376
train loss item: 0.2721717953681946
train loss item: 0.5544509291648865
train loss item: 0.0435786247253418
train loss item: 0.1997734159231186
train loss item: 0.28754451870918274
train loss item: 0.1631728857755661
train loss item: 0.15244540572166443
train loss item: 0.12327562272548676
train loss item: 0.5864306092262268
train loss item: 0.7030378580093384
train loss item: 0.36912548542022705
train loss item: 0.15896287560462952
train loss item: 0.16390447318553925
train loss item: 0.1950402408838272
train loss item: 0.07802194356918335
train loss item: 0.3479628562927246
train loss item: 1.0240167379379272
train loss item: 0.4276982545852661
train loss item: 0.1596965789794922
train loss item: 0.20694613456726074
train loss item: 0.09666904807090759
train loss item: 0.9603357315063477
train loss item: 0.4408138394355774
train loss item: 0.43013039231300354
train loss item: 0.3055254817008972
train loss item: 0.2271418273448944
train loss item: 0.1419747918844223
train loss item: 0.20518575608730316
train loss item: 0.28364723920822144
train loss item: 0.21260780096054077
train loss item: 0.46071505546569824
train loss item: 0.09546293318271637
train loss item: 0.09521100670099258
train loss item: 0.33282914757728577
train loss item: 0.19846585392951965
train loss item: 0.1359979212284088
train loss item: 0.2350052446126938
train loss item: 0.7723526954650879
train loss item: 0.07479821145534515
train loss item: 0.12368158251047134
train loss item: 0.7759438753128052
train loss item: 0.12827356159687042
train loss item: 0.3175370991230011
train loss item: 0.17535126209259033
train loss item: 0.12226687371730804
train loss item: 0.10426902770996094
train loss item: 0.4140704870223999
train loss item: 1.0556013584136963
train loss item: 0.18282225728034973
train loss item: 0.3072420060634613
train loss item: 0.10996603965759277
train loss item: 0.3114738166332245
train loss item: 0.21489524841308594
train loss item: 0.1499783992767334
train loss item: 0.34737053513526917
train loss item: 0.24365638196468353
train loss item: 0.18152661621570587
train loss item: 0.07670807838439941
train loss item: 0.12549355626106262
train loss item: 0.19504958391189575
train loss item: 0.08154816180467606
train loss item: 0.09918345510959625
train loss item: 0.4166429042816162
train loss item: 0.8322312235832214
train loss item: 0.06479673832654953
train loss item: 0.246726393699646
train loss item: 0.14438731968402863
train loss item: 0.1794065535068512
train loss item: 0.18121978640556335
train loss item: 0.26890936493873596
train loss item: 0.4086291491985321
train loss item: 0.25086596608161926
train loss item: 1.413312315940857
train loss item: 0.10846136510372162
train loss item: 0.28361642360687256
test loss item: 0.18608126044273376
test loss item: 0.1126682236790657
test loss item: 0.2996617257595062
test loss item: 0.21027661859989166
test loss item: 0.16469474136829376
test loss item: 0.1370953619480133
test loss item: 1.3456614017486572
test loss item: 0.5307509899139404
test loss item: 0.1742895096540451
test loss item: 0.2790956497192383
test loss item: 0.4074774384498596
test loss item: 0.17212805151939392
test loss item: 0.22500422596931458
test loss item: 0.3011307120323181
test loss item: 0.13827994465827942
test loss item: 0.08431638777256012
test loss item: 0.2763593792915344
test loss item: 0.27114781737327576
test loss item: 0.5560455918312073
test loss item: 0.2950194180011749
test loss item: 0.3369966149330139
test loss item: 0.33608612418174744
test loss item: 0.25073477625846863
test loss item: 0.18463411927223206
test loss item: 0.18311773240566254
test loss item: 0.2912135124206543
test loss item: 0.283197283744812
test loss item: 0.15710151195526123
test loss item: 0.22784408926963806
test loss item: 0.3059382438659668
test loss item: 0.4921945631504059
test loss item: 0.09518337994813919
test loss item: 0.17267344892024994
test loss item: 0.2931827902793884
test loss item: 0.22926920652389526
test loss item: 0.4090108275413513
test loss item: 0.6364297270774841
test loss item: 0.5366259217262268
test loss item: 0.2809559404850006
test loss item: 0.23262685537338257
test loss item: 0.26374486088752747
test loss item: 0.27577441930770874
test loss item: 0.2381889373064041
test loss item: 0.21147441864013672
test loss item: 0.29854366183280945
test loss item: 0.3708484172821045
test loss item: 0.26284903287887573
test loss item: 0.3205834627151489
test loss item: 0.291806161403656
test loss item: 0.46935537457466125
test loss item: 0.22174474596977234
test loss item: 0.23302826285362244
test loss item: 0.22265011072158813
test loss item: 0.172349214553833
test loss item: 0.2333243042230606
test loss item: 0.3674697279930115
test loss item: 0.4333743453025818
test loss item: 0.21352644264698029
test loss item: 0.23953217267990112
test loss item: 0.1911741942167282
test loss item: 0.29965195059776306
test loss item: 0.2581864893436432
test loss item: 0.24577230215072632
test loss item: 0.22736646234989166
test loss item: 0.5118943452835083
test loss item: 0.2585594356060028
test loss item: 0.3193657696247101
test loss item: 0.22103117406368256
test loss item: 0.2350127249956131
test loss item: 0.38356924057006836
test loss item: 0.07855504751205444
test loss item: 0.8221140503883362
test loss item: 0.2928920090198517
test loss item: 0.3578743040561676
test loss item: 0.19320784509181976
test loss item: 0.2175140380859375
test loss item: 0.17843632400035858
test loss item: 0.5049043297767639
test loss item: 0.30178382992744446
test loss item: 0.18660986423492432
test loss item: 0.10393760353326797
test loss item: 0.6505456566810608
test loss item: 0.6507561206817627
test loss item: 0.4463253617286682
test loss item: 0.22950412333011627
test loss item: 0.2936309278011322
test loss item: 0.09798891842365265
test loss item: 0.09426061064004898
test loss item: 0.2819440960884094
Epoch [14/100], Training Loss: 0.3072, Testing Loss: 0.2986
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 15/100
train loss item: 0.28157997131347656
train loss item: 0.614370584487915
train loss item: 0.19323688745498657
train loss item: 0.32163283228874207
train loss item: 0.22640106081962585
train loss item: 0.22774077951908112
train loss item: 0.22244217991828918
train loss item: 0.5046005249023438
train loss item: 0.11248230189085007
train loss item: 0.2252214103937149
train loss item: 0.256856232881546
train loss item: 0.16103875637054443
train loss item: 0.08507596701383591
train loss item: 0.48567503690719604
train loss item: 0.24567720293998718
train loss item: 0.4722442328929901
train loss item: 0.05499917268753052
train loss item: 0.1716080904006958
train loss item: 0.2694978415966034
train loss item: 0.1493184119462967
train loss item: 0.14689795672893524
train loss item: 0.12322339415550232
train loss item: 0.48665517568588257
train loss item: 0.5148816704750061
train loss item: 0.3446958363056183
train loss item: 0.18043804168701172
train loss item: 0.12596885859966278
train loss item: 0.16325008869171143
train loss item: 0.048742372542619705
train loss item: 0.3134616017341614
train loss item: 0.964735746383667
train loss item: 0.4094257056713104
train loss item: 0.11318252980709076
train loss item: 0.17872929573059082
train loss item: 0.09898339956998825
train loss item: 0.6528072953224182
train loss item: 0.3693495988845825
train loss item: 0.40857475996017456
train loss item: 0.2487892359495163
train loss item: 0.19947664439678192
train loss item: 0.18250834941864014
train loss item: 0.2104180008172989
train loss item: 0.33016154170036316
train loss item: 0.21418775618076324
train loss item: 0.39209824800491333
train loss item: 0.08253051340579987
train loss item: 0.08163260668516159
train loss item: 0.3737960755825043
train loss item: 0.18897227942943573
train loss item: 0.10337524861097336
train loss item: 0.2626296877861023
train loss item: 0.6102070808410645
train loss item: 0.055917225778102875
train loss item: 0.1497916579246521
train loss item: 0.4633446931838989
train loss item: 0.14872920513153076
train loss item: 0.33841484785079956
train loss item: 0.1387798935174942
train loss item: 0.11066649109125137
train loss item: 0.09340839087963104
train loss item: 0.4072830379009247
train loss item: 0.8021167516708374
train loss item: 0.15852712094783783
train loss item: 0.2836247384548187
train loss item: 0.09645512700080872
train loss item: 0.28455376625061035
train loss item: 0.1993224024772644
train loss item: 0.16307011246681213
train loss item: 0.3202333450317383
train loss item: 0.21445299685001373
train loss item: 0.16376318037509918
train loss item: 0.08817725628614426
train loss item: 0.1211373582482338
train loss item: 0.1614314615726471
train loss item: 0.07449759542942047
train loss item: 0.10522924363613129
train loss item: 0.37264278531074524
train loss item: 0.6700818538665771
train loss item: 0.06570130586624146
train loss item: 0.3166355490684509
train loss item: 0.11208757758140564
train loss item: 0.15959009528160095
train loss item: 0.1644025295972824
train loss item: 0.28499889373779297
train loss item: 0.40543901920318604
train loss item: 0.2677260637283325
train loss item: 1.37565016746521
train loss item: 0.09292874485254288
train loss item: 0.2516884207725525
test loss item: 0.2021852284669876
test loss item: 0.1240730732679367
test loss item: 0.3291606307029724
test loss item: 0.2363474816083908
test loss item: 0.1843348741531372
test loss item: 0.16100859642028809
test loss item: 1.68124520778656
test loss item: 0.6901073455810547
test loss item: 0.20518092811107635
test loss item: 0.30652916431427
test loss item: 0.44759753346443176
test loss item: 0.2023928463459015
test loss item: 0.23530375957489014
test loss item: 0.332461953163147
test loss item: 0.15546853840351105
test loss item: 0.08797654509544373
test loss item: 0.317321240901947
test loss item: 0.29971078038215637
test loss item: 0.6642113924026489
test loss item: 0.3344034254550934
test loss item: 0.3685306906700134
test loss item: 0.4098605513572693
test loss item: 0.2924712300300598
test loss item: 0.2126038819551468
test loss item: 0.20354901254177094
test loss item: 0.2846205234527588
test loss item: 0.31185290217399597
test loss item: 0.17934328317642212
test loss item: 0.266507625579834
test loss item: 0.3142855167388916
test loss item: 0.6205723285675049
test loss item: 0.09852592647075653
test loss item: 0.19304873049259186
test loss item: 0.31611886620521545
test loss item: 0.253266304731369
test loss item: 0.4111863672733307
test loss item: 0.7697519659996033
test loss item: 0.5468342900276184
test loss item: 0.3242066502571106
test loss item: 0.2841288447380066
test loss item: 0.30500662326812744
test loss item: 0.26099222898483276
test loss item: 0.25959786772727966
test loss item: 0.25211167335510254
test loss item: 0.33183732628822327
test loss item: 0.42081692814826965
test loss item: 0.28760290145874023
test loss item: 0.3264176845550537
test loss item: 0.3511732816696167
test loss item: 0.5350735187530518
test loss item: 0.26030296087265015
test loss item: 0.21905837953090668
test loss item: 0.26101306080818176
test loss item: 0.20138892531394958
test loss item: 0.2651142477989197
test loss item: 0.42745184898376465
test loss item: 0.4894134998321533
test loss item: 0.22743183374404907
test loss item: 0.2756374478340149
test loss item: 0.22272059321403503
test loss item: 0.3057996332645416
test loss item: 0.3182883858680725
test loss item: 0.28279703855514526
test loss item: 0.2601887285709381
test loss item: 0.6106211543083191
test loss item: 0.290437251329422
test loss item: 0.36601847410202026
test loss item: 0.25264307856559753
test loss item: 0.2360139936208725
test loss item: 0.4918749928474426
test loss item: 0.08811480551958084
test loss item: 1.0355015993118286
test loss item: 0.32566991448402405
test loss item: 0.44176769256591797
test loss item: 0.2149195522069931
test loss item: 0.23703452944755554
test loss item: 0.20738071203231812
test loss item: 0.5067458152770996
test loss item: 0.3419218063354492
test loss item: 0.2083796113729477
test loss item: 0.11858568340539932
test loss item: 0.7720366716384888
test loss item: 0.7894129753112793
test loss item: 0.4811401665210724
test loss item: 0.27848005294799805
test loss item: 0.2609419524669647
test loss item: 0.10945252329111099
test loss item: 0.09969551116228104
test loss item: 0.19022968411445618
Epoch [15/100], Training Loss: 0.2707, Testing Loss: 0.3389
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 16/100
train loss item: 0.28206706047058105
train loss item: 0.7164016366004944
train loss item: 0.16717223823070526
train loss item: 0.3535502851009369
train loss item: 0.19204077124595642
train loss item: 0.2007530778646469
train loss item: 0.18582771718502045
train loss item: 0.330049604177475
train loss item: 0.11353000998497009
train loss item: 0.18451112508773804
train loss item: 0.26127490401268005
train loss item: 0.14673109352588654
train loss item: 0.07295162975788116
train loss item: 0.4579986333847046
train loss item: 0.23541422188282013
train loss item: 0.3315236270427704
train loss item: 0.049495209008455276
train loss item: 0.2051338255405426
train loss item: 0.24136894941329956
train loss item: 0.1553475260734558
train loss item: 0.14175006747245789
train loss item: 0.09322606027126312
train loss item: 0.420878142118454
train loss item: 0.42562928795814514
train loss item: 0.3035496771335602
train loss item: 0.12435479462146759
train loss item: 0.1254986673593521
train loss item: 0.162246435880661
train loss item: 0.05090617015957832
train loss item: 0.3082575500011444
train loss item: 0.6974407434463501
train loss item: 0.3704908490180969
train loss item: 0.10743345320224762
train loss item: 0.16990208625793457
train loss item: 0.0644209012389183
train loss item: 0.7547347545623779
train loss item: 0.32226285338401794
train loss item: 0.3690475821495056
train loss item: 0.23795579373836517
train loss item: 0.179817333817482
train loss item: 0.15758037567138672
train loss item: 0.19203738868236542
train loss item: 0.2808782160282135
train loss item: 0.18320970237255096
train loss item: 0.387305349111557
train loss item: 0.09424052387475967
train loss item: 0.07804389297962189
train loss item: 0.21140415966510773
train loss item: 0.14053380489349365
train loss item: 0.11859752982854843
train loss item: 0.16668222844600677
train loss item: 0.535613477230072
train loss item: 0.05994803458452225
train loss item: 0.1275293529033661
train loss item: 0.4701504409313202
train loss item: 0.13193130493164062
train loss item: 0.2632907032966614
train loss item: 0.12542396783828735
train loss item: 0.078042171895504
train loss item: 0.08412493020296097
train loss item: 0.4007568359375
train loss item: 0.5190532803535461
train loss item: 0.1542411595582962
train loss item: 0.30124473571777344
train loss item: 0.10241521149873734
train loss item: 0.2879505455493927
train loss item: 0.19662564992904663
train loss item: 0.1459038257598877
train loss item: 0.32724064588546753
train loss item: 0.23272854089736938
train loss item: 0.17609499394893646
train loss item: 0.07990258932113647
train loss item: 0.0945497378706932
train loss item: 0.18606135249137878
train loss item: 0.06293761730194092
train loss item: 0.08412231504917145
train loss item: 0.3166799545288086
train loss item: 0.7933341860771179
train loss item: 0.05368904024362564
train loss item: 0.21700696647167206
train loss item: 0.11293603479862213
train loss item: 0.11082957684993744
train loss item: 0.16655515134334564
train loss item: 0.28583940863609314
train loss item: 0.38372430205345154
train loss item: 0.21795019507408142
train loss item: 0.9770107865333557
train loss item: 0.07550337165594101
train loss item: 0.24066679179668427
test loss item: 0.17618925869464874
test loss item: 0.10630370676517487
test loss item: 0.27692103385925293
test loss item: 0.2044932246208191
test loss item: 0.15678724646568298
test loss item: 0.13940073549747467
test loss item: 1.4862792491912842
test loss item: 0.6030991077423096
test loss item: 0.16350701451301575
test loss item: 0.2524121105670929
test loss item: 0.3910384178161621
test loss item: 0.16074073314666748
test loss item: 0.20636582374572754
test loss item: 0.28716516494750977
test loss item: 0.13139036297798157
test loss item: 0.06921689957380295
test loss item: 0.281629353761673
test loss item: 0.24342666566371918
test loss item: 0.578521728515625
test loss item: 0.29341286420822144
test loss item: 0.25700047612190247
test loss item: 0.35921379923820496
test loss item: 0.2710017263889313
test loss item: 0.1836032122373581
test loss item: 0.167626291513443
test loss item: 0.25593599677085876
test loss item: 0.26390159130096436
test loss item: 0.15196862816810608
test loss item: 0.22206337749958038
test loss item: 0.27168017625808716
test loss item: 0.5345225930213928
test loss item: 0.07275637239217758
test loss item: 0.1687682867050171
test loss item: 0.24954868853092194
test loss item: 0.20186099410057068
test loss item: 0.3329774737358093
test loss item: 0.6712881922721863
test loss item: 0.4845421314239502
test loss item: 0.26186561584472656
test loss item: 0.24543355405330658
test loss item: 0.264483779668808
test loss item: 0.26625001430511475
test loss item: 0.20515333116054535
test loss item: 0.21871113777160645
test loss item: 0.24237433075904846
test loss item: 0.3736971914768219
test loss item: 0.27811992168426514
test loss item: 0.2965143322944641
test loss item: 0.2954099178314209
test loss item: 0.44593656063079834
test loss item: 0.20778824388980865
test loss item: 0.20528778433799744
test loss item: 0.2262248396873474
test loss item: 0.17185448110103607
test loss item: 0.22068506479263306
test loss item: 0.31532421708106995
test loss item: 0.4223614037036896
test loss item: 0.19750677049160004
test loss item: 0.24444212019443512
test loss item: 0.1824345588684082
test loss item: 0.24113662540912628
test loss item: 0.28041183948516846
test loss item: 0.25525885820388794
test loss item: 0.2097342163324356
test loss item: 0.5341310501098633
test loss item: 0.2496909648180008
test loss item: 0.3252612054347992
test loss item: 0.2148980349302292
test loss item: 0.19984170794487
test loss item: 0.40652334690093994
test loss item: 0.06625878810882568
test loss item: 0.9128981232643127
test loss item: 0.28778064250946045
test loss item: 0.3893905282020569
test loss item: 0.19380128383636475
test loss item: 0.2411591112613678
test loss item: 0.1778949350118637
test loss item: 0.4960194528102875
test loss item: 0.2861383855342865
test loss item: 0.18670882284641266
test loss item: 0.0930844098329544
test loss item: 0.6795920133590698
test loss item: 0.6775140166282654
test loss item: 0.42962080240249634
test loss item: 0.23753613233566284
test loss item: 0.24052222073078156
test loss item: 0.08636786788702011
test loss item: 0.07597390562295914
test loss item: 0.19423598051071167
Epoch [16/100], Training Loss: 0.2416, Testing Loss: 0.2920
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 17/100
train loss item: 0.24595345556735992
train loss item: 0.587264358997345
train loss item: 0.14314718544483185
train loss item: 0.24590304493904114
train loss item: 0.18664570152759552
train loss item: 0.17642225325107574
train loss item: 0.17903658747673035
train loss item: 0.3632439076900482
train loss item: 0.09460283815860748
train loss item: 0.17275086045265198
train loss item: 0.2092898041009903
train loss item: 0.12866705656051636
train loss item: 0.06548581272363663
train loss item: 0.4354759752750397
train loss item: 0.2151232659816742
train loss item: 0.4055232107639313
train loss item: 0.06207789108157158
train loss item: 0.19198238849639893
train loss item: 0.23277276754379272
train loss item: 0.13220950961112976
train loss item: 0.11798477917909622
train loss item: 0.1038656234741211
train loss item: 0.47328880429267883
train loss item: 0.38400810956954956
train loss item: 0.3420170545578003
train loss item: 0.12901976704597473
train loss item: 0.13097885251045227
train loss item: 0.1281188279390335
train loss item: 0.05368328467011452
train loss item: 0.34520530700683594
train loss item: 0.77229243516922
train loss item: 0.43687522411346436
train loss item: 0.08713509887456894
train loss item: 0.16802339255809784
train loss item: 0.07883148640394211
train loss item: 0.5474579930305481
train loss item: 0.27545225620269775
train loss item: 0.3406592011451721
train loss item: 0.24994955956935883
train loss item: 0.20118644833564758
train loss item: 0.172715425491333
train loss item: 0.19845934212207794
train loss item: 0.3081894516944885
train loss item: 0.17324402928352356
train loss item: 0.37011629343032837
train loss item: 0.07482363283634186
train loss item: 0.06962072849273682
train loss item: 0.26906949281692505
train loss item: 0.1488388627767563
train loss item: 0.07540171593427658
train loss item: 0.17030300199985504
train loss item: 0.3721020519733429
train loss item: 0.05474551022052765
train loss item: 0.1498209685087204
train loss item: 0.4341371953487396
train loss item: 0.19694583117961884
train loss item: 0.3577963411808014
train loss item: 0.1387547105550766
train loss item: 0.11074566096067429
train loss item: 0.08701229095458984
train loss item: 0.33336442708969116
train loss item: 0.5071816444396973
train loss item: 0.15955428779125214
train loss item: 0.26006948947906494
train loss item: 0.0834803581237793
train loss item: 0.2661775052547455
train loss item: 0.2151232659816742
train loss item: 0.17056363821029663
train loss item: 0.3400475084781647
train loss item: 0.25466907024383545
train loss item: 0.19999690353870392
train loss item: 0.1289781928062439
train loss item: 0.11611063778400421
train loss item: 0.21628788113594055
train loss item: 0.058273956179618835
train loss item: 0.07605351507663727
train loss item: 0.2696651518344879
train loss item: 0.8383260369300842
train loss item: 0.052430152893066406
train loss item: 0.22117933630943298
train loss item: 0.08656827360391617
train loss item: 0.09219338744878769
train loss item: 0.14867252111434937
train loss item: 0.28928032517433167
train loss item: 0.4418174624443054
train loss item: 0.24371784925460815
train loss item: 0.7166187763214111
train loss item: 0.07408425956964493
train loss item: 0.3041769564151764
test loss item: 0.15868443250656128
test loss item: 0.13878309726715088
test loss item: 0.2667474150657654
test loss item: 0.190524622797966
test loss item: 0.18541714549064636
test loss item: 0.17535300552845
test loss item: 1.2897518873214722
test loss item: 0.5435221195220947
test loss item: 0.17553626000881195
test loss item: 0.2639276385307312
test loss item: 0.40216970443725586
test loss item: 0.13036972284317017
test loss item: 0.19795431196689606
test loss item: 0.21136842668056488
test loss item: 0.1654869019985199
test loss item: 0.10550552606582642
test loss item: 0.23377373814582825
test loss item: 0.2570611238479614
test loss item: 0.5340431928634644
test loss item: 0.2706867456436157
test loss item: 0.2487642616033554
test loss item: 0.3058631122112274
test loss item: 0.3090234398841858
test loss item: 0.19513076543807983
test loss item: 0.14944422245025635
test loss item: 0.2588578164577484
test loss item: 0.266156405210495
test loss item: 0.1774301528930664
test loss item: 0.21816493570804596
test loss item: 0.27617278695106506
test loss item: 0.5090100765228271
test loss item: 0.1139313280582428
test loss item: 0.18644195795059204
test loss item: 0.23938767611980438
test loss item: 0.2162439376115799
test loss item: 0.3680970072746277
test loss item: 0.6055574417114258
test loss item: 0.5220557451248169
test loss item: 0.2511496841907501
test loss item: 0.2463383823633194
test loss item: 0.2274267077445984
test loss item: 0.2812972962856293
test loss item: 0.21853910386562347
test loss item: 0.17424584925174713
test loss item: 0.22591407597064972
test loss item: 0.33730819821357727
test loss item: 0.31311625242233276
test loss item: 0.30563613772392273
test loss item: 0.2851225435733795
test loss item: 0.44927915930747986
test loss item: 0.226158007979393
test loss item: 0.21374814212322235
test loss item: 0.2284158170223236
test loss item: 0.12868642807006836
test loss item: 0.2539636492729187
test loss item: 0.3704017996788025
test loss item: 0.40357035398483276
test loss item: 0.15544933080673218
test loss item: 0.23598478734493256
test loss item: 0.2012784779071808
test loss item: 0.27755531668663025
test loss item: 0.25466957688331604
test loss item: 0.23180148005485535
test loss item: 0.18082433938980103
test loss item: 0.49943679571151733
test loss item: 0.21137654781341553
test loss item: 0.31340861320495605
test loss item: 0.18409854173660278
test loss item: 0.1898944228887558
test loss item: 0.42677393555641174
test loss item: 0.09906933456659317
test loss item: 0.8057054281234741
test loss item: 0.21739114820957184
test loss item: 0.3206138610839844
test loss item: 0.17607299983501434
test loss item: 0.2896590530872345
test loss item: 0.1894271969795227
test loss item: 0.5111510157585144
test loss item: 0.20503607392311096
test loss item: 0.1748952567577362
test loss item: 0.12474262714385986
test loss item: 0.6151308417320251
test loss item: 0.6276789307594299
test loss item: 0.4367186427116394
test loss item: 0.2477293163537979
test loss item: 0.21054910123348236
test loss item: 0.1193954348564148
test loss item: 0.1161632239818573
test loss item: 0.160695880651474
Epoch [17/100], Training Loss: 0.2352, Testing Loss: 0.2833
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 18/100
train loss item: 0.2563544809818268
train loss item: 0.6102410554885864
train loss item: 0.13997846841812134
train loss item: 0.27318498492240906
train loss item: 0.14492712914943695
train loss item: 0.17774520814418793
train loss item: 0.18111348152160645
train loss item: 0.27117279171943665
train loss item: 0.11766164004802704
train loss item: 0.19528912007808685
train loss item: 0.2559701204299927
train loss item: 0.14584125578403473
train loss item: 0.07286904752254486
train loss item: 0.4240075647830963
train loss item: 0.1921335905790329
train loss item: 0.44260677695274353
train loss item: 0.04872597008943558
train loss item: 0.14412711560726166
train loss item: 0.17441798746585846
train loss item: 0.13538584113121033
train loss item: 0.09820404648780823
train loss item: 0.10440867394208908
train loss item: 0.5281165242195129
train loss item: 0.22832517325878143
train loss item: 0.277924507856369
train loss item: 0.18613716959953308
train loss item: 0.09514756500720978
train loss item: 0.12119349837303162
train loss item: 0.0573711171746254
train loss item: 0.4077591300010681
train loss item: 0.724250078201294
train loss item: 0.28236424922943115
train loss item: 0.07244518399238586
train loss item: 0.23997123539447784
train loss item: 0.043641965836286545
train loss item: 0.7349328398704529
train loss item: 0.3891735374927521
train loss item: 0.4790348410606384
train loss item: 0.43880775570869446
train loss item: 0.3638405501842499
train loss item: 0.1865396499633789
train loss item: 0.2887691855430603
train loss item: 0.31084197759628296
train loss item: 0.19533628225326538
train loss item: 0.37186020612716675
train loss item: 0.10664955526590347
train loss item: 0.08726029098033905
train loss item: 0.3384762704372406
train loss item: 0.21344564855098724
train loss item: 0.1303280144929886
train loss item: 0.22824738919734955
train loss item: 0.5723860859870911
train loss item: 0.06970036029815674
train loss item: 0.20177626609802246
train loss item: 0.5382452607154846
train loss item: 0.18270546197891235
train loss item: 0.2523999512195587
train loss item: 0.1302744299173355
train loss item: 0.13068558275699615
train loss item: 0.09202626347541809
train loss item: 0.34849023818969727
train loss item: 0.5262206196784973
train loss item: 0.20052795112133026
train loss item: 0.3214479684829712
train loss item: 0.12100657820701599
train loss item: 0.27171266078948975
train loss item: 0.4405094087123871
train loss item: 0.16429179906845093
train loss item: 0.2900833189487457
train loss item: 0.19806057214736938
train loss item: 0.16121165454387665
train loss item: 0.09246506541967392
train loss item: 0.11724866181612015
train loss item: 0.16929705440998077
train loss item: 0.08416885882616043
train loss item: 0.10292137414216995
train loss item: 0.2827035188674927
train loss item: 0.7459436058998108
train loss item: 0.06682782620191574
train loss item: 0.23155508935451508
train loss item: 0.11400432139635086
train loss item: 0.14561401307582855
train loss item: 0.15216444432735443
train loss item: 0.41602185368537903
train loss item: 0.6023497581481934
train loss item: 0.2175217568874359
train loss item: 0.8844995498657227
train loss item: 0.09582604467868805
train loss item: 0.18521273136138916
test loss item: 0.18042637407779694
test loss item: 0.10219239443540573
test loss item: 0.2678214907646179
test loss item: 0.20966008305549622
test loss item: 0.1704324185848236
test loss item: 0.1761881709098816
test loss item: 1.7256213426589966
test loss item: 0.709500253200531
test loss item: 0.15050309896469116
test loss item: 0.22428342700004578
test loss item: 0.44516709446907043
test loss item: 0.15844161808490753
test loss item: 0.18154551088809967
test loss item: 0.2649393379688263
test loss item: 0.13058462738990784
test loss item: 0.06764490157365799
test loss item: 0.29682326316833496
test loss item: 0.2055620700120926
test loss item: 0.6572617888450623
test loss item: 0.2946476340293884
test loss item: 0.20945368707180023
test loss item: 0.3985351622104645
test loss item: 0.27632611989974976
test loss item: 0.19718429446220398
test loss item: 0.16050627827644348
test loss item: 0.24976299703121185
test loss item: 0.25665807723999023
test loss item: 0.16201409697532654
test loss item: 0.23256631195545197
test loss item: 0.24828436970710754
test loss item: 0.6149173974990845
test loss item: 0.07728094607591629
test loss item: 0.17576035857200623
test loss item: 0.23543162643909454
test loss item: 0.1709149330854416
test loss item: 0.32522568106651306
test loss item: 0.7590634226799011
test loss item: 0.5844346284866333
test loss item: 0.2519903779029846
test loss item: 0.29046574234962463
test loss item: 0.28617191314697266
test loss item: 0.26001566648483276
test loss item: 0.1609519124031067
test loss item: 0.22923001646995544
test loss item: 0.2001114785671234
test loss item: 0.4137459099292755
test loss item: 0.2706425189971924
test loss item: 0.2605612277984619
test loss item: 0.30147311091423035
test loss item: 0.47961342334747314
test loss item: 0.1604110449552536
test loss item: 0.1757071316242218
test loss item: 0.21320436894893646
test loss item: 0.16540449857711792
test loss item: 0.18279936909675598
test loss item: 0.2972370386123657
test loss item: 0.47417500615119934
test loss item: 0.18034832179546356
test loss item: 0.23987755179405212
test loss item: 0.1453835666179657
test loss item: 0.18323028087615967
test loss item: 0.3074391782283783
test loss item: 0.2591848075389862
test loss item: 0.2077852487564087
test loss item: 0.6071006059646606
test loss item: 0.2557579278945923
test loss item: 0.3315126299858093
test loss item: 0.22935529053211212
test loss item: 0.19565613567829132
test loss item: 0.46133172512054443
test loss item: 0.07600196450948715
test loss item: 1.0640560388565063
test loss item: 0.27830058336257935
test loss item: 0.4379708170890808
test loss item: 0.18442097306251526
test loss item: 0.23770904541015625
test loss item: 0.191101536154747
test loss item: 0.6032776236534119
test loss item: 0.30266842246055603
test loss item: 0.20764587819576263
test loss item: 0.10790076106786728
test loss item: 0.7868863940238953
test loss item: 0.7560699582099915
test loss item: 0.4907737076282501
test loss item: 0.2347748577594757
test loss item: 0.22508785128593445
test loss item: 0.09888536483049393
test loss item: 0.07672721147537231
test loss item: 0.20747409760951996
Epoch [18/100], Training Loss: 0.2545, Testing Loss: 0.3056
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 19/100
train loss item: 0.2561708390712738
train loss item: 0.5527520775794983
train loss item: 0.13017071783542633
train loss item: 0.25227779150009155
train loss item: 0.1687733381986618
train loss item: 0.1610960066318512
train loss item: 0.14905095100402832
train loss item: 0.5237956047058105
train loss item: 0.07113067060709
train loss item: 0.11491796374320984
train loss item: 0.1689889132976532
train loss item: 0.12404822558164597
train loss item: 0.0692804753780365
train loss item: 0.40939202904701233
train loss item: 0.23308831453323364
train loss item: 0.33987557888031006
train loss item: 0.05377363786101341
train loss item: 0.185257688164711
train loss item: 0.22181618213653564
train loss item: 0.09890013933181763
train loss item: 0.12281467765569687
train loss item: 0.09791507571935654
train loss item: 0.4090460240840912
train loss item: 0.3354650139808655
train loss item: 0.27872511744499207
train loss item: 0.12056682258844376
train loss item: 0.10542742908000946
train loss item: 0.1348690539598465
train loss item: 0.04807867854833603
train loss item: 0.21784783899784088
train loss item: 0.46066805720329285
train loss item: 0.5176537036895752
train loss item: 0.08340909332036972
train loss item: 0.15786561369895935
train loss item: 0.06245775148272514
train loss item: 0.7077229022979736
train loss item: 0.274220734834671
train loss item: 0.2798900604248047
train loss item: 0.2544454038143158
train loss item: 0.2010178416967392
train loss item: 0.16872721910476685
train loss item: 0.24806198477745056
train loss item: 0.33417731523513794
train loss item: 0.19671039283275604
train loss item: 0.43779152631759644
train loss item: 0.08217211812734604
train loss item: 0.06927721202373505
train loss item: 0.34398525953292847
train loss item: 0.17718210816383362
train loss item: 0.09079936146736145
train loss item: 0.25583603978157043
train loss item: 0.4621528685092926
train loss item: 0.06629273295402527
train loss item: 0.13529019057750702
train loss item: 0.44397062063217163
train loss item: 0.12152902781963348
train loss item: 0.31492823362350464
train loss item: 0.10869565606117249
train loss item: 0.13332460820674896
train loss item: 0.11359133571386337
train loss item: 0.2945774793624878
train loss item: 0.5554704070091248
train loss item: 0.14230303466320038
train loss item: 0.1993945986032486
train loss item: 0.07984845340251923
train loss item: 0.2508462965488434
train loss item: 0.24032306671142578
train loss item: 0.15038847923278809
train loss item: 0.36660510301589966
train loss item: 0.2609763741493225
train loss item: 0.2163572907447815
train loss item: 0.1428380310535431
train loss item: 0.14753761887550354
train loss item: 0.2588229775428772
train loss item: 0.04871370643377304
train loss item: 0.08147793263196945
train loss item: 0.3110622465610504
train loss item: 1.0463593006134033
train loss item: 0.05998416244983673
train loss item: 0.18308797478675842
train loss item: 0.07090561836957932
train loss item: 0.10231557488441467
train loss item: 0.11708317697048187
train loss item: 0.32754868268966675
train loss item: 0.4048103988170624
train loss item: 0.2197033166885376
train loss item: 0.4789099097251892
train loss item: 0.06757669895887375
train loss item: 0.3110354542732239
test loss item: 0.11522111296653748
test loss item: 0.07103869318962097
test loss item: 0.29024985432624817
test loss item: 0.1476014256477356
test loss item: 0.12757425010204315
test loss item: 0.09384746104478836
test loss item: 1.2629390954971313
test loss item: 0.4993520975112915
test loss item: 0.13213782012462616
test loss item: 0.2100461721420288
test loss item: 0.4849715828895569
test loss item: 0.10047487169504166
test loss item: 0.16359303891658783
test loss item: 0.18795540928840637
test loss item: 0.09191754460334778
test loss item: 0.051184650510549545
test loss item: 0.22132326662540436
test loss item: 0.18932302296161652
test loss item: 0.5086714029312134
test loss item: 0.23605187237262726
test loss item: 0.19721536338329315
test loss item: 0.28669339418411255
test loss item: 0.1772577315568924
test loss item: 0.1317516714334488
test loss item: 0.11184801161289215
test loss item: 0.19540704786777496
test loss item: 0.21153464913368225
test loss item: 0.11171513050794601
test loss item: 0.16935385763645172
test loss item: 0.220027357339859
test loss item: 0.4870321750640869
test loss item: 0.04601622372865677
test loss item: 0.1177331879734993
test loss item: 0.20849043130874634
test loss item: 0.17773185670375824
test loss item: 0.270635187625885
test loss item: 0.5842199325561523
test loss item: 0.751474142074585
test loss item: 0.20241840183734894
test loss item: 0.18483975529670715
test loss item: 0.2086692750453949
test loss item: 0.15624874830245972
test loss item: 0.12945839762687683
test loss item: 0.15001219511032104
test loss item: 0.16206225752830505
test loss item: 0.3304281234741211
test loss item: 0.17481042444705963
test loss item: 0.2304389774799347
test loss item: 0.26974034309387207
test loss item: 0.40391018986701965
test loss item: 0.145276740193367
test loss item: 0.1579822599887848
test loss item: 0.15958690643310547
test loss item: 0.09579920023679733
test loss item: 0.15501125156879425
test loss item: 0.3815044164657593
test loss item: 0.38618025183677673
test loss item: 0.1423027515411377
test loss item: 0.19287827610969543
test loss item: 0.12095673382282257
test loss item: 0.16960859298706055
test loss item: 0.23823551833629608
test loss item: 0.18691858649253845
test loss item: 0.16928964853286743
test loss item: 0.5422224998474121
test loss item: 0.19065815210342407
test loss item: 0.2751607596874237
test loss item: 0.17431551218032837
test loss item: 0.21907800436019897
test loss item: 0.34906962513923645
test loss item: 0.04499632492661476
test loss item: 0.7662131190299988
test loss item: 0.19853058457374573
test loss item: 0.3019721806049347
test loss item: 0.14359690248966217
test loss item: 0.139555424451828
test loss item: 0.13082446157932281
test loss item: 0.8159998655319214
test loss item: 0.23634301126003265
test loss item: 0.12809793651103973
test loss item: 0.05511694401502609
test loss item: 0.6544970273971558
test loss item: 0.5805450677871704
test loss item: 0.5729017853736877
test loss item: 0.1777910590171814
test loss item: 0.17261555790901184
test loss item: 0.05100727081298828
test loss item: 0.04361063241958618
test loss item: 0.12136506289243698
Epoch [19/100], Training Loss: 0.2314, Testing Loss: 0.2476
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 20/100
train loss item: 0.2347777932882309
train loss item: 0.42044782638549805
train loss item: 0.14777474105358124
train loss item: 0.23129874467849731
train loss item: 0.1517406404018402
train loss item: 0.14511895179748535
train loss item: 0.18661031126976013
train loss item: 0.2598097622394562
train loss item: 0.08472482860088348
train loss item: 0.1648557484149933
train loss item: 0.17372897267341614
train loss item: 0.1411508172750473
train loss item: 0.07654552161693573
train loss item: 0.34950241446495056
train loss item: 0.20621219277381897
train loss item: 0.404773473739624
train loss item: 0.033756885677576065
train loss item: 0.11590371280908585
train loss item: 0.21298013627529144
train loss item: 0.13771656155586243
train loss item: 0.09853652119636536
train loss item: 0.08228228241205215
train loss item: 0.4539388418197632
train loss item: 0.23853975534439087
train loss item: 0.2891016900539398
train loss item: 0.12886959314346313
train loss item: 0.09226202219724655
train loss item: 0.17017687857151031
train loss item: 0.05562272295355797
train loss item: 0.3114446997642517
train loss item: 0.5220332741737366
train loss item: 0.3427136540412903
train loss item: 0.0764593780040741
train loss item: 0.1866142302751541
train loss item: 0.07830885052680969
train loss item: 0.7951930165290833
train loss item: 0.33632397651672363
train loss item: 0.32257550954818726
train loss item: 0.24635642766952515
train loss item: 0.1857399344444275
train loss item: 0.16357479989528656
train loss item: 0.17208722233772278
train loss item: 0.2985570728778839
train loss item: 0.18190646171569824
train loss item: 0.4257495105266571
train loss item: 0.08522765338420868
train loss item: 0.07276198267936707
train loss item: 0.3184245228767395
train loss item: 0.14267519116401672
train loss item: 0.08230771124362946
train loss item: 0.23489168286323547
train loss item: 0.6512664556503296
train loss item: 0.06298969686031342
train loss item: 0.10297595709562302
train loss item: 0.641771674156189
train loss item: 0.11856549978256226
train loss item: 0.27315399050712585
train loss item: 0.11249472945928574
train loss item: 0.10580375045537949
train loss item: 0.11418524384498596
train loss item: 0.28772133588790894
train loss item: 0.6150215864181519
train loss item: 0.17065775394439697
train loss item: 0.23925060033798218
train loss item: 0.07978608459234238
train loss item: 0.2511436939239502
train loss item: 0.2138500213623047
train loss item: 0.10954070091247559
train loss item: 0.2734397351741791
train loss item: 0.20329028367996216
train loss item: 0.1670001894235611
train loss item: 0.10808634012937546
train loss item: 0.10971250385046005
train loss item: 0.22472313046455383
train loss item: 0.0467480793595314
train loss item: 0.06823945045471191
train loss item: 0.34715938568115234
train loss item: 0.9748224020004272
train loss item: 0.05762322619557381
train loss item: 0.1370968222618103
train loss item: 0.07328632473945618
train loss item: 0.08851109445095062
train loss item: 0.14466984570026398
train loss item: 0.2233235090970993
train loss item: 0.3662950098514557
train loss item: 0.1775393933057785
train loss item: 0.6167740821838379
train loss item: 0.07973463088274002
train loss item: 0.3098863363265991
test loss item: 0.09794791787862778
test loss item: 0.06385356932878494
test loss item: 0.1856594681739807
test loss item: 0.12697187066078186
test loss item: 0.11066967993974686
test loss item: 0.10008030384778976
test loss item: 1.1203536987304688
test loss item: 0.3605942726135254
test loss item: 0.08432643115520477
test loss item: 0.13102936744689941
test loss item: 0.3421342074871063
test loss item: 0.08160349726676941
test loss item: 0.08391954749822617
test loss item: 0.1056617796421051
test loss item: 0.08466845005750656
test loss item: 0.04963650181889534
test loss item: 0.1490563303232193
test loss item: 0.14232966303825378
test loss item: 0.39282628893852234
test loss item: 0.10754305124282837
test loss item: 0.18244607746601105
test loss item: 0.21911443769931793
test loss item: 0.17289364337921143
test loss item: 0.10655289143323898
test loss item: 0.08843527734279633
test loss item: 0.15742303431034088
test loss item: 0.11499199271202087
test loss item: 0.09941171109676361
test loss item: 0.13475576043128967
test loss item: 0.1315697878599167
test loss item: 0.3910566568374634
test loss item: 0.054158423095941544
test loss item: 0.09626680612564087
test loss item: 0.1580348163843155
test loss item: 0.12919136881828308
test loss item: 0.17949922382831573
test loss item: 0.47827330231666565
test loss item: 0.4948681592941284
test loss item: 0.1624748706817627
test loss item: 0.16633324325084686
test loss item: 0.1727914661169052
test loss item: 0.15362825989723206
test loss item: 0.09487093240022659
test loss item: 0.12497422844171524
test loss item: 0.14611667394638062
test loss item: 0.18101200461387634
test loss item: 0.16957491636276245
test loss item: 0.08470135182142258
test loss item: 0.16302482783794403
test loss item: 0.29188257455825806
test loss item: 0.11153508722782135
test loss item: 0.08557434380054474
test loss item: 0.13038058578968048
test loss item: 0.09095261245965958
test loss item: 0.13003657758235931
test loss item: 0.25348541140556335
test loss item: 0.271091103553772
test loss item: 0.1276451051235199
test loss item: 0.12681996822357178
test loss item: 0.09376131743192673
test loss item: 0.11366917937994003
test loss item: 0.1363901048898697
test loss item: 0.1281231790781021
test loss item: 0.11535286158323288
test loss item: 0.38340049982070923
test loss item: 0.1700349599123001
test loss item: 0.16408690810203552
test loss item: 0.13673712313175201
test loss item: 0.1478578746318817
test loss item: 0.2499324083328247
test loss item: 0.052016481757164
test loss item: 0.6359221339225769
test loss item: 0.12067924439907074
test loss item: 0.20872175693511963
test loss item: 0.08600049465894699
test loss item: 0.15111149847507477
test loss item: 0.10816836357116699
test loss item: 0.5021504163742065
test loss item: 0.11946331709623337
test loss item: 0.10702337324619293
test loss item: 0.0698588564991951
test loss item: 0.516084611415863
test loss item: 0.4943130612373352
test loss item: 0.36656126379966736
test loss item: 0.12044328451156616
test loss item: 0.12067140638828278
test loss item: 0.06522943079471588
test loss item: 0.054139528423547745
test loss item: 0.13538099825382233
Epoch [20/100], Training Loss: 0.2249, Testing Loss: 0.1845
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 21/100
train loss item: 0.24438337981700897
train loss item: 0.5199728012084961
train loss item: 0.08991364389657974
train loss item: 0.19303593039512634
train loss item: 0.16735874116420746
train loss item: 0.1532081812620163
train loss item: 0.175204798579216
train loss item: 0.2137664407491684
train loss item: 0.0816703587770462
train loss item: 0.12816214561462402
train loss item: 0.11951127648353577
train loss item: 0.11855792254209518
train loss item: 0.10095060616731644
train loss item: 0.28191709518432617
train loss item: 0.16208583116531372
train loss item: 0.47689127922058105
train loss item: 0.052688125520944595
train loss item: 0.10001375526189804
train loss item: 0.14636580646038055
train loss item: 0.08948981016874313
train loss item: 0.08227013051509857
train loss item: 0.09182807058095932
train loss item: 0.6065729856491089
train loss item: 0.20270761847496033
train loss item: 0.24200023710727692
train loss item: 0.18099458515644073
train loss item: 0.1222837045788765
train loss item: 0.13034002482891083
train loss item: 0.07117302715778351
train loss item: 0.28296053409576416
train loss item: 0.44938352704048157
train loss item: 0.33915671706199646
train loss item: 0.08242177963256836
train loss item: 0.19833102822303772
train loss item: 0.0892554223537445
train loss item: 0.682448148727417
train loss item: 0.19840534031391144
train loss item: 0.2754918336868286
train loss item: 0.2488192468881607
train loss item: 0.16675110161304474
train loss item: 0.1641124039888382
train loss item: 0.15884524583816528
train loss item: 0.26501888036727905
train loss item: 0.17336280643939972
train loss item: 0.30365848541259766
train loss item: 0.1013897955417633
train loss item: 0.07815732806921005
train loss item: 0.22168850898742676
train loss item: 0.13090309500694275
train loss item: 0.07606584578752518
train loss item: 0.16459272801876068
train loss item: 0.4408819377422333
train loss item: 0.056066595017910004
train loss item: 0.12070156633853912
train loss item: 0.36328285932540894
train loss item: 0.12521834671497345
train loss item: 0.32400229573249817
train loss item: 0.09759002178907394
train loss item: 0.12210292369127274
train loss item: 0.09033583849668503
train loss item: 0.2832685112953186
train loss item: 0.47904539108276367
train loss item: 0.167043536901474
train loss item: 0.2709501385688782
train loss item: 0.07894626259803772
train loss item: 0.2593339681625366
train loss item: 0.17877629399299622
train loss item: 0.13555395603179932
train loss item: 0.27710822224617004
train loss item: 0.18927352130413055
train loss item: 0.16043983399868011
train loss item: 0.10061657428741455
train loss item: 0.1145860105752945
train loss item: 0.20258021354675293
train loss item: 0.04447750747203827
train loss item: 0.06521879881620407
train loss item: 0.34421542286872864
train loss item: 0.9536685347557068
train loss item: 0.04349560663104057
train loss item: 0.13474500179290771
train loss item: 0.08904615044593811
train loss item: 0.08623479306697845
train loss item: 0.12615635991096497
train loss item: 0.260578453540802
train loss item: 0.3612058758735657
train loss item: 0.19901983439922333
train loss item: 0.635992169380188
train loss item: 0.08272390067577362
train loss item: 0.3986249268054962
test loss item: 0.08898357301950455
test loss item: 0.08891518414020538
test loss item: 0.19353821873664856
test loss item: 0.12178180366754532
test loss item: 0.13422276079654694
test loss item: 0.10766633599996567
test loss item: 1.0469685792922974
test loss item: 0.3830905854701996
test loss item: 0.10885344445705414
test loss item: 0.18441976606845856
test loss item: 0.33350932598114014
test loss item: 0.0722862184047699
test loss item: 0.13309064507484436
test loss item: 0.15029878914356232
test loss item: 0.1138870120048523
test loss item: 0.05782246217131615
test loss item: 0.14608368277549744
test loss item: 0.199327751994133
test loss item: 0.39552825689315796
test loss item: 0.16357719898223877
test loss item: 0.22554604709148407
test loss item: 0.20473067462444305
test loss item: 0.15801186859607697
test loss item: 0.12151242792606354
test loss item: 0.090163953602314
test loss item: 0.2048480361700058
test loss item: 0.16762685775756836
test loss item: 0.12210144102573395
test loss item: 0.16804443299770355
test loss item: 0.1914130002260208
test loss item: 0.3757423460483551
test loss item: 0.05954024940729141
test loss item: 0.11360659450292587
test loss item: 0.18473729491233826
test loss item: 0.1670244336128235
test loss item: 0.24831025302410126
test loss item: 0.47323840856552124
test loss item: 0.4581690728664398
test loss item: 0.19624213874340057
test loss item: 0.1669241189956665
test loss item: 0.1586800366640091
test loss item: 0.13595528900623322
test loss item: 0.16214391589164734
test loss item: 0.10641264170408249
test loss item: 0.20079252123832703
test loss item: 0.2076258361339569
test loss item: 0.15723635256290436
test loss item: 0.18331000208854675
test loss item: 0.2034832239151001
test loss item: 0.3315550982952118
test loss item: 0.19303342700004578
test loss item: 0.1380367875099182
test loss item: 0.17642709612846375
test loss item: 0.07101438194513321
test loss item: 0.20634691417217255
test loss item: 0.2802978754043579
test loss item: 0.2955411374568939
test loss item: 0.12532462179660797
test loss item: 0.1588725596666336
test loss item: 0.16045524179935455
test loss item: 0.20362244546413422
test loss item: 0.15590204298496246
test loss item: 0.147856667637825
test loss item: 0.12330924719572067
test loss item: 0.39338016510009766
test loss item: 0.14908204972743988
test loss item: 0.23073408007621765
test loss item: 0.13202396035194397
test loss item: 0.14992722868919373
test loss item: 0.2773679196834564
test loss item: 0.05964710935950279
test loss item: 0.6219220757484436
test loss item: 0.14612191915512085
test loss item: 0.20452602207660675
test loss item: 0.10407330095767975
test loss item: 0.12999361753463745
test loss item: 0.12350385636091232
test loss item: 0.47914445400238037
test loss item: 0.13077667355537415
test loss item: 0.10678984224796295
test loss item: 0.07502365857362747
test loss item: 0.4894583821296692
test loss item: 0.4875625669956207
test loss item: 0.36196669936180115
test loss item: 0.17975817620754242
test loss item: 0.14032389223575592
test loss item: 0.06907527893781662
test loss item: 0.058246344327926636
test loss item: 0.12835216522216797
Epoch [21/100], Training Loss: 0.2097, Testing Loss: 0.2026
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 22/100
train loss item: 0.24152497947216034
train loss item: 0.5612674951553345
train loss item: 0.1358329951763153
train loss item: 0.3042532205581665
train loss item: 0.17859648168087006
train loss item: 0.16609731316566467
train loss item: 0.1949157565832138
train loss item: 0.331466943025589
train loss item: 0.11883840709924698
train loss item: 0.23801961541175842
train loss item: 0.2968667447566986
train loss item: 0.1441354602575302
train loss item: 0.07838303595781326
train loss item: 0.42312338948249817
train loss item: 0.21758988499641418
train loss item: 0.4092477262020111
train loss item: 0.03233907371759415
train loss item: 0.09221433848142624
train loss item: 0.16113005578517914
train loss item: 0.11127582937479019
train loss item: 0.08786771446466446
train loss item: 0.08807696402072906
train loss item: 0.4484962522983551
train loss item: 0.23351292312145233
train loss item: 0.22082416713237762
train loss item: 0.1431022584438324
train loss item: 0.11000382155179977
train loss item: 0.10873854160308838
train loss item: 0.03635330870747566
train loss item: 0.3083557188510895
train loss item: 0.5154487490653992
train loss item: 0.26029303669929504
train loss item: 0.07015489786863327
train loss item: 0.31881120800971985
train loss item: 0.054647523909807205
train loss item: 0.9049579501152039
train loss item: 0.32859259843826294
train loss item: 0.31557783484458923
train loss item: 0.3600953221321106
train loss item: 0.18327248096466064
train loss item: 0.14574941992759705
train loss item: 0.1780179738998413
train loss item: 0.2952437102794647
train loss item: 0.17085596919059753
train loss item: 0.2844424545764923
train loss item: 0.09919258207082748
train loss item: 0.0639910101890564
train loss item: 0.2325562685728073
train loss item: 0.12307461351156235
train loss item: 0.07879197597503662
train loss item: 0.1626100242137909
train loss item: 0.35136309266090393
train loss item: 0.05581716448068619
train loss item: 0.13521218299865723
train loss item: 0.32746338844299316
train loss item: 0.10590612143278122
train loss item: 0.2279948741197586
train loss item: 0.10425252467393875
train loss item: 0.10642889142036438
train loss item: 0.09858189523220062
train loss item: 0.3693414330482483
train loss item: 0.5762741565704346
train loss item: 0.1397736370563507
train loss item: 0.34261006116867065
train loss item: 0.09087371081113815
train loss item: 0.2647181749343872
train loss item: 0.4926997125148773
train loss item: 0.21931669116020203
train loss item: 0.2571471631526947
train loss item: 0.21866485476493835
train loss item: 0.18982437252998352
train loss item: 0.1433788239955902
train loss item: 0.10795720666646957
train loss item: 0.2444712072610855
train loss item: 0.04712865501642227
train loss item: 0.08021537214517593
train loss item: 0.33135470747947693
train loss item: 0.9744576811790466
train loss item: 0.08185390383005142
train loss item: 0.180464968085289
train loss item: 0.09886831045150757
train loss item: 0.12769578397274017
train loss item: 0.15766888856887817
train loss item: 0.26204243302345276
train loss item: 0.3603009581565857
train loss item: 0.31835585832595825
train loss item: 0.4866141676902771
train loss item: 0.12829042971134186
train loss item: 0.19996459782123566
test loss item: 0.10292060673236847
test loss item: 0.07301824539899826
test loss item: 0.32926419377326965
test loss item: 0.14900754392147064
test loss item: 0.13551859557628632
test loss item: 0.09897338598966599
test loss item: 1.5159655809402466
test loss item: 0.5504326224327087
test loss item: 0.1298856884241104
test loss item: 0.20348943769931793
test loss item: 0.5701873898506165
test loss item: 0.09712789207696915
test loss item: 0.13682496547698975
test loss item: 0.17058350145816803
test loss item: 0.10346849262714386
test loss item: 0.05472135171294212
test loss item: 0.2106972634792328
test loss item: 0.19329190254211426
test loss item: 0.5438176393508911
test loss item: 0.20488251745700836
test loss item: 0.344061017036438
test loss item: 0.304758220911026
test loss item: 0.18942907452583313
test loss item: 0.1316317915916443
test loss item: 0.1061972826719284
test loss item: 0.16198809444904327
test loss item: 0.18802368640899658
test loss item: 0.10945545136928558
test loss item: 0.18874351680278778
test loss item: 0.1956716924905777
test loss item: 0.6046099066734314
test loss item: 0.04570584371685982
test loss item: 0.11304022371768951
test loss item: 0.25571125745773315
test loss item: 0.19759966433048248
test loss item: 0.2698206603527069
test loss item: 0.6477752923965454
test loss item: 0.8919418454170227
test loss item: 0.2315370738506317
test loss item: 0.20631955564022064
test loss item: 0.21926893293857574
test loss item: 0.1411174237728119
test loss item: 0.1436915099620819
test loss item: 0.15844838321208954
test loss item: 0.27010825276374817
test loss item: 0.30425018072128296
test loss item: 0.18283532559871674
test loss item: 0.1744513064622879
test loss item: 0.2750408351421356
test loss item: 0.4560587406158447
test loss item: 0.15663261711597443
test loss item: 0.11769460886716843
test loss item: 0.14483356475830078
test loss item: 0.109473317861557
test loss item: 0.15430374443531036
test loss item: 0.47233834862709045
test loss item: 0.41083329916000366
test loss item: 0.19615833461284637
test loss item: 0.16953690350055695
test loss item: 0.0970868393778801
test loss item: 0.16794972121715546
test loss item: 0.21805799007415771
test loss item: 0.1646297425031662
test loss item: 0.15800850093364716
test loss item: 0.6077945232391357
test loss item: 0.19943587481975555
test loss item: 0.2408425211906433
test loss item: 0.1795097440481186
test loss item: 0.23790988326072693
test loss item: 0.3615538775920868
test loss item: 0.05596011504530907
test loss item: 0.8857186436653137
test loss item: 0.21513819694519043
test loss item: 0.3108351230621338
test loss item: 0.12345485389232635
test loss item: 0.13075071573257446
test loss item: 0.13403752446174622
test loss item: 0.934432327747345
test loss item: 0.25244036316871643
test loss item: 0.11927157640457153
test loss item: 0.05289024859666824
test loss item: 0.7523261904716492
test loss item: 0.6743457317352295
test loss item: 0.6667462587356567
test loss item: 0.15100803971290588
test loss item: 0.14995837211608887
test loss item: 0.05070817098021507
test loss item: 0.04301156848669052
test loss item: 0.11741867661476135
Epoch [22/100], Training Loss: 0.2289, Testing Loss: 0.2659
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 23/100
train loss item: 0.2325042486190796
train loss item: 0.34497296810150146
train loss item: 0.11004489660263062
train loss item: 0.2759237587451935
train loss item: 0.16142423450946808
train loss item: 0.21462610363960266
train loss item: 0.12838925421237946
train loss item: 0.6029290556907654
train loss item: 0.06469778716564178
train loss item: 0.1082204058766365
train loss item: 0.13903012871742249
train loss item: 0.12367135286331177
train loss item: 0.07363130152225494
train loss item: 0.3626927435398102
train loss item: 0.19880901277065277
train loss item: 0.41698139905929565
train loss item: 0.03938663750886917
train loss item: 0.09769458323717117
train loss item: 0.1985049694776535
train loss item: 0.08442825824022293
train loss item: 0.0843607634305954
train loss item: 0.07043860852718353
train loss item: 0.2893068790435791
train loss item: 0.33897069096565247
train loss item: 0.24321241676807404
train loss item: 0.19667688012123108
train loss item: 0.195807084441185
train loss item: 0.1461917608976364
train loss item: 0.07332170009613037
train loss item: 0.2234308272600174
train loss item: 0.4915672540664673
train loss item: 0.4622757136821747
train loss item: 0.12049267441034317
train loss item: 0.1661979854106903
train loss item: 0.07642249017953873
train loss item: 0.7449474930763245
train loss item: 0.3280024528503418
train loss item: 0.28356611728668213
train loss item: 0.20273807644844055
train loss item: 0.16664178669452667
train loss item: 0.15568725764751434
train loss item: 0.20126228034496307
train loss item: 0.3065781593322754
train loss item: 0.19989454746246338
train loss item: 0.3949832320213318
train loss item: 0.07678211480379105
train loss item: 0.07535400986671448
train loss item: 0.35685640573501587
train loss item: 0.1730063110589981
train loss item: 0.10203220695257187
train loss item: 0.2891489267349243
train loss item: 0.5263710618019104
train loss item: 0.07496689260005951
train loss item: 0.08104437589645386
train loss item: 0.4234602153301239
train loss item: 0.09810619801282883
train loss item: 0.2680504024028778
train loss item: 0.09669734537601471
train loss item: 0.08264341950416565
train loss item: 0.09078008681535721
train loss item: 0.23544494807720184
train loss item: 0.46373242139816284
train loss item: 0.16475847363471985
train loss item: 0.2840999960899353
train loss item: 0.08998546749353409
train loss item: 0.30678486824035645
train loss item: 0.25225159525871277
train loss item: 0.09166254103183746
train loss item: 0.2157069444656372
train loss item: 0.15749303996562958
train loss item: 0.12725314497947693
train loss item: 0.08896608650684357
train loss item: 0.10396227985620499
train loss item: 0.20527908205986023
train loss item: 0.04590710997581482
train loss item: 0.07005388289690018
train loss item: 0.29052790999412537
train loss item: 0.9529971480369568
train loss item: 0.045722126960754395
train loss item: 0.13427682220935822
train loss item: 0.06007690355181694
train loss item: 0.0769229382276535
train loss item: 0.11420832574367523
train loss item: 0.23164905607700348
train loss item: 0.2838638424873352
train loss item: 0.21511000394821167
train loss item: 0.3471820056438446
train loss item: 0.0705610066652298
train loss item: 0.23024792969226837
test loss item: 0.07884026318788528
test loss item: 0.06605015695095062
test loss item: 0.29410824179649353
test loss item: 0.1142081692814827
test loss item: 0.1221473217010498
test loss item: 0.06643087416887283
test loss item: 1.208720088005066
test loss item: 0.3729057013988495
test loss item: 0.11627615243196487
test loss item: 0.1773035228252411
test loss item: 0.48543083667755127
test loss item: 0.07072500139474869
test loss item: 0.09427149593830109
test loss item: 0.13374941051006317
test loss item: 0.08844266831874847
test loss item: 0.05566063150763512
test loss item: 0.1521497219800949
test loss item: 0.185594379901886
test loss item: 0.41349196434020996
test loss item: 0.12881669402122498
test loss item: 0.25945690274238586
test loss item: 0.22254790365695953
test loss item: 0.1359318494796753
test loss item: 0.09033858776092529
test loss item: 0.0933132991194725
test loss item: 0.12414781749248505
test loss item: 0.13824045658111572
test loss item: 0.09524380415678024
test loss item: 0.15384402871131897
test loss item: 0.1536121368408203
test loss item: 0.489778995513916
test loss item: 0.04629242792725563
test loss item: 0.07444386184215546
test loss item: 0.22618481516838074
test loss item: 0.18697012960910797
test loss item: 0.2097511887550354
test loss item: 0.5081478357315063
test loss item: 0.788769543170929
test loss item: 0.20127761363983154
test loss item: 0.15404610335826874
test loss item: 0.18215827643871307
test loss item: 0.10001061111688614
test loss item: 0.13287554681301117
test loss item: 0.12092920392751694
test loss item: 0.2032317817211151
test loss item: 0.20178374648094177
test loss item: 0.12406444549560547
test loss item: 0.11122475564479828
test loss item: 0.2225484549999237
test loss item: 0.37426239252090454
test loss item: 0.12029005587100983
test loss item: 0.07918732613325119
test loss item: 0.12312281131744385
test loss item: 0.07710757106542587
test loss item: 0.1255323588848114
test loss item: 0.42651695013046265
test loss item: 0.31419602036476135
test loss item: 0.12737323343753815
test loss item: 0.1241077184677124
test loss item: 0.08541674166917801
test loss item: 0.16829611361026764
test loss item: 0.13560421764850616
test loss item: 0.10937651991844177
test loss item: 0.13194116950035095
test loss item: 0.4846954941749573
test loss item: 0.16067782044410706
test loss item: 0.1675662100315094
test loss item: 0.15153156220912933
test loss item: 0.22274231910705566
test loss item: 0.2763611972332001
test loss item: 0.052509624511003494
test loss item: 0.6831199526786804
test loss item: 0.13035136461257935
test loss item: 0.2163768708705902
test loss item: 0.08450506627559662
test loss item: 0.08429228514432907
test loss item: 0.09988630563020706
test loss item: 0.8059337735176086
test loss item: 0.18871891498565674
test loss item: 0.09183436632156372
test loss item: 0.04042184725403786
test loss item: 0.6228823065757751
test loss item: 0.5420925617218018
test loss item: 0.5675719380378723
test loss item: 0.11246290802955627
test loss item: 0.10576143860816956
test loss item: 0.03879402205348015
test loss item: 0.03841261565685272
test loss item: 0.1099247857928276
Epoch [23/100], Training Loss: 0.2125, Testing Loss: 0.2110
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 24/100
train loss item: 0.21517550945281982
train loss item: 0.2476046085357666
train loss item: 0.10078810900449753
train loss item: 0.1971379965543747
train loss item: 0.1066313236951828
train loss item: 0.1219857782125473
train loss item: 0.12457942217588425
train loss item: 0.2637861669063568
train loss item: 0.05546468123793602
train loss item: 0.09034396708011627
train loss item: 0.10927250236272812
train loss item: 0.09675730764865875
train loss item: 0.07418373227119446
train loss item: 0.3099333643913269
train loss item: 0.1694551706314087
train loss item: 0.4145424962043762
train loss item: 0.0431198887526989
train loss item: 0.08943311870098114
train loss item: 0.15168118476867676
train loss item: 0.08978047221899033
train loss item: 0.07472328841686249
train loss item: 0.07120536267757416
train loss item: 0.369149774312973
train loss item: 0.21689701080322266
train loss item: 0.19406326115131378
train loss item: 0.1785721331834793
train loss item: 0.1599748283624649
train loss item: 0.13296622037887573
train loss item: 0.0758884996175766
train loss item: 0.2638050615787506
train loss item: 0.3430410325527191
train loss item: 0.37883827090263367
train loss item: 0.08330709487199783
train loss item: 0.15102584660053253
train loss item: 0.06327763944864273
train loss item: 0.530898928642273
train loss item: 0.17709872126579285
train loss item: 0.2589089274406433
train loss item: 0.21934975683689117
train loss item: 0.14600913226604462
train loss item: 0.15225782990455627
train loss item: 0.15614423155784607
train loss item: 0.2779754102230072
train loss item: 0.16426829993724823
train loss item: 0.32153141498565674
train loss item: 0.07259154319763184
train loss item: 0.07024277746677399
train loss item: 0.24756383895874023
train loss item: 0.12280335277318954
train loss item: 0.08307787775993347
train loss item: 0.17817357182502747
train loss item: 0.36624661087989807
train loss item: 0.05487030744552612
train loss item: 0.0920645073056221
train loss item: 0.5647215247154236
train loss item: 0.09821246564388275
train loss item: 0.28205960988998413
train loss item: 0.0760943740606308
train loss item: 0.11344197392463684
train loss item: 0.10238731652498245
train loss item: 0.2629648447036743
train loss item: 0.45311135053634644
train loss item: 0.1489529013633728
train loss item: 0.2459835410118103
train loss item: 0.09183316677808762
train loss item: 0.15496587753295898
train loss item: 0.1845370978116989
train loss item: 0.11424646526575089
train loss item: 0.2247479408979416
train loss item: 0.14793744683265686
train loss item: 0.11399112641811371
train loss item: 0.060828037559986115
train loss item: 0.098382867872715
train loss item: 0.1407012790441513
train loss item: 0.04388488829135895
train loss item: 0.05864676460623741
train loss item: 0.27312400937080383
train loss item: 0.8392207622528076
train loss item: 0.046329814940690994
train loss item: 0.1464242786169052
train loss item: 0.09398157894611359
train loss item: 0.09489409625530243
train loss item: 0.1491929143667221
train loss item: 0.2180747240781784
train loss item: 0.3360542953014374
train loss item: 0.17896924912929535
train loss item: 0.3964848220348358
train loss item: 0.0558590441942215
train loss item: 0.24480585753917694
test loss item: 0.070556640625
test loss item: 0.06849212199449539
test loss item: 0.2038782238960266
test loss item: 0.10460426658391953
test loss item: 0.10150419175624847
test loss item: 0.06741204857826233
test loss item: 1.1441621780395508
test loss item: 0.37739434838294983
test loss item: 0.08073173463344574
test loss item: 0.1409132182598114
test loss item: 0.3532662093639374
test loss item: 0.060233939439058304
test loss item: 0.09174232929944992
test loss item: 0.10795702785253525
test loss item: 0.08266644179821014
test loss item: 0.05524574965238571
test loss item: 0.14693205058574677
test loss item: 0.13993299007415771
test loss item: 0.3850749135017395
test loss item: 0.11773509532213211
test loss item: 0.17952483892440796
test loss item: 0.21084272861480713
test loss item: 0.11839164793491364
test loss item: 0.09378587454557419
test loss item: 0.08578738570213318
test loss item: 0.12128745764493942
test loss item: 0.11857322603464127
test loss item: 0.0870220959186554
test loss item: 0.13002288341522217
test loss item: 0.13644462823867798
test loss item: 0.42166846990585327
test loss item: 0.04688592627644539
test loss item: 0.0818517804145813
test loss item: 0.17312109470367432
test loss item: 0.13401412963867188
test loss item: 0.1949097216129303
test loss item: 0.4706774353981018
test loss item: 0.5463768243789673
test loss item: 0.16101498901844025
test loss item: 0.14352267980575562
test loss item: 0.16472677886486053
test loss item: 0.1016644686460495
test loss item: 0.10479588061571121
test loss item: 0.11782196164131165
test loss item: 0.1438237428665161
test loss item: 0.18907013535499573
test loss item: 0.119008868932724
test loss item: 0.10893483459949493
test loss item: 0.17846503853797913
test loss item: 0.31820014119148254
test loss item: 0.10201758146286011
test loss item: 0.08244691789150238
test loss item: 0.11597039550542831
test loss item: 0.08116200566291809
test loss item: 0.1066138818860054
test loss item: 0.2875671684741974
test loss item: 0.2802625894546509
test loss item: 0.135025754570961
test loss item: 0.11802037805318832
test loss item: 0.08328302204608917
test loss item: 0.13179971277713776
test loss item: 0.13557448983192444
test loss item: 0.11044847965240479
test loss item: 0.10799731314182281
test loss item: 0.37913963198661804
test loss item: 0.14187709987163544
test loss item: 0.15467672049999237
test loss item: 0.1313953697681427
test loss item: 0.1577426642179489
test loss item: 0.2569080591201782
test loss item: 0.051064539700746536
test loss item: 0.6606372594833374
test loss item: 0.1107996329665184
test loss item: 0.20072485506534576
test loss item: 0.08696721494197845
test loss item: 0.09106335043907166
test loss item: 0.09892760217189789
test loss item: 0.543717086315155
test loss item: 0.12622876465320587
test loss item: 0.08482792228460312
test loss item: 0.043531544506549835
test loss item: 0.5251007676124573
test loss item: 0.5005066394805908
test loss item: 0.39031532406806946
test loss item: 0.09554659575223923
test loss item: 0.10648053884506226
test loss item: 0.043944261968135834
test loss item: 0.0415046401321888
test loss item: 0.10114462673664093
Epoch [24/100], Training Loss: 0.1840, Testing Loss: 0.1810
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 25/100
train loss item: 0.21916033327579498
train loss item: 0.37672558426856995
train loss item: 0.08786582946777344
train loss item: 0.20198741555213928
train loss item: 0.12505662441253662
train loss item: 0.15443462133407593
train loss item: 0.15746591985225677
train loss item: 0.20371508598327637
train loss item: 0.06870749592781067
train loss item: 0.13952404260635376
train loss item: 0.11417996883392334
train loss item: 0.13135214149951935
train loss item: 0.0669325664639473
train loss item: 0.2220495343208313
train loss item: 0.12537948787212372
train loss item: 0.3199763000011444
train loss item: 0.044787079095840454
train loss item: 0.09573160111904144
train loss item: 0.21241377294063568
train loss item: 0.10745586454868317
train loss item: 0.09297588467597961
train loss item: 0.057725939899683
train loss item: 0.3327532112598419
train loss item: 0.23173120617866516
train loss item: 0.24804769456386566
train loss item: 0.1134907454252243
train loss item: 0.07460595667362213
train loss item: 0.14673733711242676
train loss item: 0.0630902573466301
train loss item: 0.3463904857635498
train loss item: 0.706031322479248
train loss item: 0.3120073080062866
train loss item: 0.12357960641384125
train loss item: 0.14645157754421234
train loss item: 0.12820333242416382
train loss item: 1.0752995014190674
train loss item: 0.3900008797645569
train loss item: 0.3356040120124817
train loss item: 0.23364762961864471
train loss item: 0.2291766256093979
train loss item: 0.1311381757259369
train loss item: 0.16645166277885437
train loss item: 0.2560262680053711
train loss item: 0.15855653584003448
train loss item: 0.32661187648773193
train loss item: 0.06942614912986755
train loss item: 0.061784688383340836
train loss item: 0.33239254355430603
train loss item: 0.16992175579071045
train loss item: 0.08782880753278732
train loss item: 0.275234580039978
train loss item: 0.6192988753318787
train loss item: 0.06996454298496246
train loss item: 0.08606451749801636
train loss item: 0.3962506055831909
train loss item: 0.11766267567873001
train loss item: 0.2177063673734665
train loss item: 0.10683836042881012
train loss item: 0.07820165902376175
train loss item: 0.08542120456695557
train loss item: 0.2939949631690979
train loss item: 0.6126641035079956
train loss item: 0.15346543490886688
train loss item: 0.25518372654914856
train loss item: 0.08516981452703476
train loss item: 0.26394569873809814
train loss item: 0.17985548079013824
train loss item: 0.08593165129423141
train loss item: 0.18502511084079742
train loss item: 0.14536882936954498
train loss item: 0.12958332896232605
train loss item: 0.0714663565158844
train loss item: 0.09813649952411652
train loss item: 0.18331629037857056
train loss item: 0.04942996799945831
train loss item: 0.07492194324731827
train loss item: 0.4043092131614685
train loss item: 0.9333402514457703
train loss item: 0.044558197259902954
train loss item: 0.11729839444160461
train loss item: 0.07923857867717743
train loss item: 0.07831680774688721
train loss item: 0.11666463315486908
train loss item: 0.198913112282753
train loss item: 0.2634732127189636
train loss item: 0.18344374001026154
train loss item: 0.6571829915046692
train loss item: 0.06193028390407562
train loss item: 0.2590661942958832
test loss item: 0.10223917663097382
test loss item: 0.07928945869207382
test loss item: 0.18810805678367615
test loss item: 0.12927226722240448
test loss item: 0.13525663316249847
test loss item: 0.12817387282848358
test loss item: 1.0901644229888916
test loss item: 0.34334561228752136
test loss item: 0.08956560492515564
test loss item: 0.1391144096851349
test loss item: 0.33895301818847656
test loss item: 0.08703436702489853
test loss item: 0.10043422877788544
test loss item: 0.1720200777053833
test loss item: 0.1040690690279007
test loss item: 0.0540803037583828
test loss item: 0.15460535883903503
test loss item: 0.14820997416973114
test loss item: 0.37816861271858215
test loss item: 0.1301121562719345
test loss item: 0.16962286829948425
test loss item: 0.21437221765518188
test loss item: 0.22390154004096985
test loss item: 0.11758564412593842
test loss item: 0.09498131275177002
test loss item: 0.15671966969966888
test loss item: 0.12821264564990997
test loss item: 0.12002980709075928
test loss item: 0.15326155722141266
test loss item: 0.14591854810714722
test loss item: 0.3863392472267151
test loss item: 0.055692024528980255
test loss item: 0.10901793837547302
test loss item: 0.17209918797016144
test loss item: 0.13068006932735443
test loss item: 0.18492861092090607
test loss item: 0.4621913433074951
test loss item: 0.48877570033073425
test loss item: 0.17071157693862915
test loss item: 0.18082983791828156
test loss item: 0.1792610138654709
test loss item: 0.19866976141929626
test loss item: 0.10870549082756042
test loss item: 0.13276031613349915
test loss item: 0.15922269225120544
test loss item: 0.17950330674648285
test loss item: 0.20933586359024048
test loss item: 0.1185140609741211
test loss item: 0.1681666523218155
test loss item: 0.2874731421470642
test loss item: 0.11586068570613861
test loss item: 0.09717577695846558
test loss item: 0.13608168065547943
test loss item: 0.09572995454072952
test loss item: 0.12873569130897522
test loss item: 0.2536683976650238
test loss item: 0.2657831609249115
test loss item: 0.10413321852684021
test loss item: 0.13482806086540222
test loss item: 0.1015230342745781
test loss item: 0.12910331785678864
test loss item: 0.13955579698085785
test loss item: 0.13439887762069702
test loss item: 0.13031497597694397
test loss item: 0.38610830903053284
test loss item: 0.16502808034420013
test loss item: 0.17737194895744324
test loss item: 0.14674240350723267
test loss item: 0.1536833792924881
test loss item: 0.2359343022108078
test loss item: 0.0638631284236908
test loss item: 0.6211229562759399
test loss item: 0.14905616641044617
test loss item: 0.21893708407878876
test loss item: 0.09930367767810822
test loss item: 0.1957225650548935
test loss item: 0.11789542436599731
test loss item: 0.5032100677490234
test loss item: 0.16661854088306427
test loss item: 0.12999343872070312
test loss item: 0.07329941540956497
test loss item: 0.5054218769073486
test loss item: 0.4797323942184448
test loss item: 0.3680376708507538
test loss item: 0.14443624019622803
test loss item: 0.13167433440685272
test loss item: 0.06977248191833496
test loss item: 0.052479978650808334
test loss item: 0.1543620079755783
Epoch [25/100], Training Loss: 0.2094, Testing Loss: 0.1930
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 26/100
train loss item: 0.24758586287498474
train loss item: 0.492806613445282
train loss item: 0.10419214516878128
train loss item: 0.20047400891780853
train loss item: 0.1140817403793335
train loss item: 0.1329406201839447
train loss item: 0.11156824976205826
train loss item: 0.18150529265403748
train loss item: 0.054872769862413406
train loss item: 0.1025284007191658
train loss item: 0.12023422122001648
train loss item: 0.11297962069511414
train loss item: 0.050135545432567596
train loss item: 0.24597230553627014
train loss item: 0.11741526424884796
train loss item: 0.38766688108444214
train loss item: 0.035983894020318985
train loss item: 0.0941709578037262
train loss item: 0.19683603942394257
train loss item: 0.10637880116701126
train loss item: 0.09491788595914841
train loss item: 0.06174570322036743
train loss item: 0.46263980865478516
train loss item: 0.1824893057346344
train loss item: 0.23719201982021332
train loss item: 0.132632315158844
train loss item: 0.08831943571567535
train loss item: 0.1264541894197464
train loss item: 0.054083582013845444
train loss item: 0.3326343894004822
train loss item: 0.5497695207595825
train loss item: 0.3205164968967438
train loss item: 0.09254314750432968
train loss item: 0.13363303244113922
train loss item: 0.08654797822237015
train loss item: 0.8298277854919434
train loss item: 0.24833421409130096
train loss item: 0.2959176003932953
train loss item: 0.22709105908870697
train loss item: 0.166951984167099
train loss item: 0.14505267143249512
train loss item: 0.16436374187469482
train loss item: 0.2526773512363434
train loss item: 0.16080613434314728
train loss item: 0.28638383746147156
train loss item: 0.06902492046356201
train loss item: 0.08077782392501831
train loss item: 0.2361505925655365
train loss item: 0.15265175700187683
train loss item: 0.07494745403528214
train loss item: 0.2238743007183075
train loss item: 0.41555964946746826
train loss item: 0.05229810252785683
train loss item: 0.0905667245388031
train loss item: 0.254719078540802
train loss item: 0.13323071599006653
train loss item: 0.19063085317611694
train loss item: 0.11088451743125916
train loss item: 0.0772252008318901
train loss item: 0.07614913582801819
train loss item: 0.3128581643104553
train loss item: 0.3581160604953766
train loss item: 0.17346306145191193
train loss item: 0.35550326108932495
train loss item: 0.09310691803693771
train loss item: 0.3155202567577362
train loss item: 0.22360838949680328
train loss item: 0.11603443324565887
train loss item: 0.17243169248104095
train loss item: 0.15507787466049194
train loss item: 0.11894682794809341
train loss item: 0.07707478851079941
train loss item: 0.07644300162792206
train loss item: 0.20181797444820404
train loss item: 0.04974188283085823
train loss item: 0.07314972579479218
train loss item: 0.3052188456058502
train loss item: 0.9671284556388855
train loss item: 0.04449761286377907
train loss item: 0.16274353861808777
train loss item: 0.08096779137849808
train loss item: 0.11985398083925247
train loss item: 0.1143946498632431
train loss item: 0.23657898604869843
train loss item: 0.1631374955177307
train loss item: 0.20919592678546906
train loss item: 0.29176872968673706
train loss item: 0.05286020785570145
train loss item: 0.25398728251457214
test loss item: 0.07200866937637329
test loss item: 0.055741917341947556
test loss item: 0.3221522569656372
test loss item: 0.10879328846931458
test loss item: 0.11720795929431915
test loss item: 0.058264296501874924
test loss item: 1.0462130308151245
test loss item: 0.3571455776691437
test loss item: 0.11651843786239624
test loss item: 0.17676803469657898
test loss item: 0.4728507399559021
test loss item: 0.0661734864115715
test loss item: 0.09958270192146301
test loss item: 0.10914882272481918
test loss item: 0.08673858642578125
test loss item: 0.044178083539009094
test loss item: 0.1450808048248291
test loss item: 0.19011759757995605
test loss item: 0.36455219984054565
test loss item: 0.1293579339981079
test loss item: 0.31545934081077576
test loss item: 0.21774598956108093
test loss item: 0.14211004972457886
test loss item: 0.08764304965734482
test loss item: 0.09053905308246613
test loss item: 0.11616410315036774
test loss item: 0.1289445012807846
test loss item: 0.08938417583703995
test loss item: 0.14091327786445618
test loss item: 0.1471787393093109
test loss item: 0.4608716666698456
test loss item: 0.038223348557949066
test loss item: 0.07441765815019608
test loss item: 0.23408037424087524
test loss item: 0.20000135898590088
test loss item: 0.19114483892917633
test loss item: 0.4513065218925476
test loss item: 0.7984701991081238
test loss item: 0.20415371656417847
test loss item: 0.14347174763679504
test loss item: 0.16452020406723022
test loss item: 0.08252954483032227
test loss item: 0.12516173720359802
test loss item: 0.11889331042766571
test loss item: 0.23324717581272125
test loss item: 0.19354164600372314
test loss item: 0.12462113052606583
test loss item: 0.10897935926914215
test loss item: 0.24278531968593597
test loss item: 0.3581189811229706
test loss item: 0.1311473399400711
test loss item: 0.08192425221204758
test loss item: 0.12035099416971207
test loss item: 0.08243513852357864
test loss item: 0.13504210114479065
test loss item: 0.44101426005363464
test loss item: 0.30262425541877747
test loss item: 0.1540507823228836
test loss item: 0.12770789861679077
test loss item: 0.07940724492073059
test loss item: 0.1574772149324417
test loss item: 0.15248247981071472
test loss item: 0.10750538110733032
test loss item: 0.11567681282758713
test loss item: 0.5146833062171936
test loss item: 0.15349450707435608
test loss item: 0.17515000700950623
test loss item: 0.13347265124320984
test loss item: 0.23524945974349976
test loss item: 0.23448768258094788
test loss item: 0.04130546748638153
test loss item: 0.6068596243858337
test loss item: 0.14714914560317993
test loss item: 0.21171578764915466
test loss item: 0.08468930423259735
test loss item: 0.07191359251737595
test loss item: 0.0932697206735611
test loss item: 0.861537754535675
test loss item: 0.19438469409942627
test loss item: 0.08073125779628754
test loss item: 0.036971744149923325
test loss item: 0.5826690793037415
test loss item: 0.47295424342155457
test loss item: 0.5923003554344177
test loss item: 0.1077420711517334
test loss item: 0.10624538362026215
test loss item: 0.03755859285593033
test loss item: 0.03727888688445091
test loss item: 0.08685451745986938
Epoch [26/100], Training Loss: 0.1917, Testing Loss: 0.2051
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 27/100
train loss item: 0.2224777191877365
train loss item: 0.3090437054634094
train loss item: 0.14015358686447144
train loss item: 0.21022962033748627
train loss item: 0.18421578407287598
train loss item: 0.11975708603858948
train loss item: 0.12702420353889465
train loss item: 0.1523798406124115
train loss item: 0.06772097200155258
train loss item: 0.1571698635816574
train loss item: 0.15803517401218414
train loss item: 0.09331563115119934
train loss item: 0.0638662651181221
train loss item: 0.27766433358192444
train loss item: 0.13301104307174683
train loss item: 0.45960626006126404
train loss item: 0.03880865126848221
train loss item: 0.09471365064382553
train loss item: 0.17020666599273682
train loss item: 0.11105532199144363
train loss item: 0.09049755334854126
train loss item: 0.06557300686836243
train loss item: 0.4085342586040497
train loss item: 0.26706427335739136
train loss item: 0.18141505122184753
train loss item: 0.17361947894096375
train loss item: 0.15677854418754578
train loss item: 0.14797882735729218
train loss item: 0.06110122427344322
train loss item: 0.3111918270587921
train loss item: 0.4100698232650757
train loss item: 0.30511197447776794
train loss item: 0.09878043085336685
train loss item: 0.19355984032154083
train loss item: 0.08930166810750961
train loss item: 0.3711448311805725
train loss item: 0.3255545496940613
train loss item: 0.3641803562641144
train loss item: 0.22238829731941223
train loss item: 0.2136278748512268
train loss item: 0.13771922886371613
train loss item: 0.19937153160572052
train loss item: 0.27950796484947205
train loss item: 0.1817278116941452
train loss item: 0.3282095193862915
train loss item: 0.07627812772989273
train loss item: 0.07541695982217789
train loss item: 0.25332924723625183
train loss item: 0.1394895315170288
train loss item: 0.09150432050228119
train loss item: 0.23974686861038208
train loss item: 0.45146995782852173
train loss item: 0.08144168555736542
train loss item: 0.0948786661028862
train loss item: 0.2883144021034241
train loss item: 0.09322541207075119
train loss item: 0.1745663732290268
train loss item: 0.0899980366230011
train loss item: 0.08059804141521454
train loss item: 0.08555736392736435
train loss item: 0.22998280823230743
train loss item: 0.45816075801849365
train loss item: 0.15982043743133545
train loss item: 0.29455289244651794
train loss item: 0.07425419986248016
train loss item: 0.16769634187221527
train loss item: 0.18599389493465424
train loss item: 0.08214428275823593
train loss item: 0.1681337207555771
train loss item: 0.12596909701824188
train loss item: 0.1023310124874115
train loss item: 0.04700852930545807
train loss item: 0.07939505577087402
train loss item: 0.15804409980773926
train loss item: 0.04957171902060509
train loss item: 0.06120546907186508
train loss item: 0.3855818212032318
train loss item: 0.9548314809799194
train loss item: 0.04347217455506325
train loss item: 0.12051093578338623
train loss item: 0.07135485857725143
train loss item: 0.08220568299293518
train loss item: 0.12164490669965744
train loss item: 0.19347773492336273
train loss item: 0.2577226758003235
train loss item: 0.17969045042991638
train loss item: 0.7593804001808167
train loss item: 0.05870535224676132
train loss item: 0.2536834478378296
test loss item: 0.08259523659944534
test loss item: 0.06962152570486069
test loss item: 0.20782601833343506
test loss item: 0.12064007669687271
test loss item: 0.11432094126939774
test loss item: 0.10551226884126663
test loss item: 1.1354103088378906
test loss item: 0.34239527583122253
test loss item: 0.07977978140115738
test loss item: 0.12403285503387451
test loss item: 0.3817085325717926
test loss item: 0.06692936271429062
test loss item: 0.07455714792013168
test loss item: 0.08173930644989014
test loss item: 0.09291341155767441
test loss item: 0.0502508282661438
test loss item: 0.1360248178243637
test loss item: 0.120338074862957
test loss item: 0.36383056640625
test loss item: 0.09578529745340347
test loss item: 0.15249164402484894
test loss item: 0.20364691317081451
test loss item: 0.13792461156845093
test loss item: 0.10526572167873383
test loss item: 0.08205558359622955
test loss item: 0.131087988615036
test loss item: 0.10353932529687881
test loss item: 0.09783428907394409
test loss item: 0.1338789165019989
test loss item: 0.11641981452703476
test loss item: 0.42238640785217285
test loss item: 0.05299893021583557
test loss item: 0.09630704671144485
test loss item: 0.1641741544008255
test loss item: 0.12547294795513153
test loss item: 0.16062772274017334
test loss item: 0.456255167722702
test loss item: 0.5952404737472534
test loss item: 0.1591074913740158
test loss item: 0.1654880791902542
test loss item: 0.16649332642555237
test loss item: 0.12984389066696167
test loss item: 0.08334904909133911
test loss item: 0.12163484841585159
test loss item: 0.1171610951423645
test loss item: 0.15885597467422485
test loss item: 0.12975628674030304
test loss item: 0.07700783014297485
test loss item: 0.15961961448192596
test loss item: 0.2930537462234497
test loss item: 0.09318957477807999
test loss item: 0.07097940146923065
test loss item: 0.11696226894855499
test loss item: 0.09686402231454849
test loss item: 0.1123436838388443
test loss item: 0.3037796914577484
test loss item: 0.26550793647766113
test loss item: 0.10188236832618713
test loss item: 0.10692048817873001
test loss item: 0.08035630732774734
test loss item: 0.10395722091197968
test loss item: 0.11931008100509644
test loss item: 0.11406875401735306
test loss item: 0.10370081663131714
test loss item: 0.4120308458805084
test loss item: 0.16089604794979095
test loss item: 0.14584513008594513
test loss item: 0.12991759181022644
test loss item: 0.1609199345111847
test loss item: 0.22770747542381287
test loss item: 0.05616071820259094
test loss item: 0.631898045539856
test loss item: 0.10163285583257675
test loss item: 0.19787098467350006
test loss item: 0.0748177170753479
test loss item: 0.11931107938289642
test loss item: 0.10669167339801788
test loss item: 0.625768780708313
test loss item: 0.13141341507434845
test loss item: 0.10473450273275375
test loss item: 0.07004254311323166
test loss item: 0.5307969450950623
test loss item: 0.47980067133903503
test loss item: 0.4376840591430664
test loss item: 0.11464520543813705
test loss item: 0.09407204389572144
test loss item: 0.07174274325370789
test loss item: 0.05997368320822716
test loss item: 0.13905927538871765
Epoch [27/100], Training Loss: 0.1923, Testing Loss: 0.1811
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 28/100
train loss item: 0.23161840438842773
train loss item: 0.3852843940258026
train loss item: 0.08971788734197617
train loss item: 0.17783209681510925
train loss item: 0.13380134105682373
train loss item: 0.11152388155460358
train loss item: 0.1182989552617073
train loss item: 0.14251676201820374
train loss item: 0.0531572662293911
train loss item: 0.11414448171854019
train loss item: 0.10770919173955917
train loss item: 0.0931505560874939
train loss item: 0.061946798115968704
train loss item: 0.2489665150642395
train loss item: 0.12629111111164093
train loss item: 0.3930888772010803
train loss item: 0.032568156719207764
train loss item: 0.07421774417161942
train loss item: 0.12181048095226288
train loss item: 0.0836128517985344
train loss item: 0.09834953397512436
train loss item: 0.06332416832447052
train loss item: 0.3989333510398865
train loss item: 0.16562090814113617
train loss item: 0.2203814685344696
train loss item: 0.14724469184875488
train loss item: 0.10907168686389923
train loss item: 0.1197260394692421
train loss item: 0.07240023463964462
train loss item: 0.2939770817756653
train loss item: 0.31683585047721863
train loss item: 0.28112635016441345
train loss item: 0.10661424696445465
train loss item: 0.17851974070072174
train loss item: 0.08666160702705383
train loss item: 0.44914039969444275
train loss item: 0.2903209626674652
train loss item: 0.3019687235355377
train loss item: 0.2650146782398224
train loss item: 0.19208037853240967
train loss item: 0.1401727795600891
train loss item: 0.19008439779281616
train loss item: 0.27466297149658203
train loss item: 0.18787749111652374
train loss item: 0.2924968898296356
train loss item: 0.11080694198608398
train loss item: 0.07443308085203171
train loss item: 0.2264251857995987
train loss item: 0.13823285698890686
train loss item: 0.08327046781778336
train loss item: 0.21136227250099182
train loss item: 0.34643247723579407
train loss item: 0.060622379183769226
train loss item: 0.12669743597507477
train loss item: 0.3364371359348297
train loss item: 0.12413189560174942
train loss item: 0.1631990522146225
train loss item: 0.13401885330677032
train loss item: 0.09797663986682892
train loss item: 0.0831863284111023
train loss item: 0.45708924531936646
train loss item: 0.8916293978691101
train loss item: 0.15760080516338348
train loss item: 0.32533589005470276
train loss item: 0.11432304978370667
train loss item: 0.2888267934322357
train loss item: 0.2969050705432892
train loss item: 0.18165433406829834
train loss item: 0.16531403362751007
train loss item: 0.17595437169075012
train loss item: 0.18117977678775787
train loss item: 0.08064202964305878
train loss item: 0.10159847885370255
train loss item: 0.20660719275474548
train loss item: 0.05924665555357933
train loss item: 0.08264635503292084
train loss item: 0.3177128732204437
train loss item: 0.9797439575195312
train loss item: 0.061268746852874756
train loss item: 0.2054145187139511
train loss item: 0.0939248576760292
train loss item: 0.15564972162246704
train loss item: 0.14034929871559143
train loss item: 0.2474164217710495
train loss item: 0.16583074629306793
train loss item: 0.3032260537147522
train loss item: 0.39339479804039
train loss item: 0.1012006551027298
train loss item: 0.14010365307331085
test loss item: 0.0958809107542038
test loss item: 0.07582954317331314
test loss item: 0.41911080479621887
test loss item: 0.14894872903823853
test loss item: 0.16315822303295135
test loss item: 0.08477149903774261
test loss item: 1.4407501220703125
test loss item: 0.4796335697174072
test loss item: 0.16464942693710327
test loss item: 0.26011669635772705
test loss item: 0.5985059142112732
test loss item: 0.106805220246315
test loss item: 0.14797839522361755
test loss item: 0.19631004333496094
test loss item: 0.12088309228420258
test loss item: 0.05445108562707901
test loss item: 0.2066706120967865
test loss item: 0.2775014638900757
test loss item: 0.5035446882247925
test loss item: 0.1957608163356781
test loss item: 0.4824161231517792
test loss item: 0.2986811399459839
test loss item: 0.2151312232017517
test loss item: 0.1189262643456459
test loss item: 0.12175564467906952
test loss item: 0.1564931422472
test loss item: 0.19843068718910217
test loss item: 0.1251712590456009
test loss item: 0.21566349267959595
test loss item: 0.21819785237312317
test loss item: 0.607620358467102
test loss item: 0.04619283974170685
test loss item: 0.09593559801578522
test loss item: 0.3369370102882385
test loss item: 0.2766248881816864
test loss item: 0.27421820163726807
test loss item: 0.6251578330993652
test loss item: 0.9876105189323425
test loss item: 0.29647499322891235
test loss item: 0.20388151705265045
test loss item: 0.2240688055753708
test loss item: 0.1153084933757782
test loss item: 0.21760185062885284
test loss item: 0.16482454538345337
test loss item: 0.37821418046951294
test loss item: 0.29489025473594666
test loss item: 0.19698309898376465
test loss item: 0.15780483186244965
test loss item: 0.33829566836357117
test loss item: 0.4726604223251343
test loss item: 0.23823456466197968
test loss item: 0.10068891197443008
test loss item: 0.16663037240505219
test loss item: 0.11861635744571686
test loss item: 0.20393772423267365
test loss item: 0.5675232410430908
test loss item: 0.3927660584449768
test loss item: 0.25732433795928955
test loss item: 0.1772964894771576
test loss item: 0.13792820274829865
test loss item: 0.2625097930431366
test loss item: 0.20132969319820404
test loss item: 0.14276085793972015
test loss item: 0.17450182139873505
test loss item: 0.6676614284515381
test loss item: 0.20924168825149536
test loss item: 0.23663382232189178
test loss item: 0.1877015382051468
test loss item: 0.3104071021080017
test loss item: 0.3152927756309509
test loss item: 0.05673309788107872
test loss item: 0.8335888981819153
test loss item: 0.23421961069107056
test loss item: 0.3036489188671112
test loss item: 0.11166557669639587
test loss item: 0.10662616044282913
test loss item: 0.12643282115459442
test loss item: 1.0483053922653198
test loss item: 0.2758054733276367
test loss item: 0.11052609235048294
test loss item: 0.043782688677310944
test loss item: 0.7550514340400696
test loss item: 0.6540296673774719
test loss item: 0.7382120490074158
test loss item: 0.15026403963565826
test loss item: 0.14638449251651764
test loss item: 0.04116072505712509
test loss item: 0.03865118324756622
test loss item: 0.10620735585689545
Epoch [28/100], Training Loss: 0.1970, Testing Loss: 0.2826
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 29/100
train loss item: 0.2131069451570511
train loss item: 0.279079794883728
train loss item: 0.09062474220991135
train loss item: 0.19810058176517487
train loss item: 0.19286558032035828
train loss item: 0.1929914504289627
train loss item: 0.0866468995809555
train loss item: 0.3102884292602539
train loss item: 0.06773380935192108
train loss item: 0.13456743955612183
train loss item: 0.160040020942688
train loss item: 0.14352865517139435
train loss item: 0.06306013464927673
train loss item: 0.3473356068134308
train loss item: 0.1681530624628067
train loss item: 0.38462159037590027
train loss item: 0.04472345486283302
train loss item: 0.1453867107629776
train loss item: 0.150289848446846
train loss item: 0.09596811980009079
train loss item: 0.12764491140842438
train loss item: 0.06107960268855095
train loss item: 0.2039051502943039
train loss item: 0.24405834078788757
train loss item: 0.19946277141571045
train loss item: 0.15065133571624756
train loss item: 0.1554495394229889
train loss item: 0.13606476783752441
train loss item: 0.06297570466995239
train loss item: 0.26499390602111816
train loss item: 0.29576051235198975
train loss item: 0.3483208119869232
train loss item: 0.09760339558124542
train loss item: 0.17647668719291687
train loss item: 0.11548037081956863
train loss item: 0.4754873812198639
train loss item: 0.24730218946933746
train loss item: 0.24272024631500244
train loss item: 0.22131416201591492
train loss item: 0.10916738212108612
train loss item: 0.11197160929441452
train loss item: 0.13820387423038483
train loss item: 0.22282974421977997
train loss item: 0.13702982664108276
train loss item: 0.2519894242286682
train loss item: 0.059606991708278656
train loss item: 0.06005218252539635
train loss item: 0.22549742460250854
train loss item: 0.11183738708496094
train loss item: 0.06834699958562851
train loss item: 0.17249535024166107
train loss item: 0.3807922601699829
train loss item: 0.05632946267724037
train loss item: 0.08491231501102448
train loss item: 0.33723312616348267
train loss item: 0.09743931889533997
train loss item: 0.1582672894001007
train loss item: 0.10174611955881119
train loss item: 0.08252181112766266
train loss item: 0.06898349523544312
train loss item: 0.3217497766017914
train loss item: 0.39849990606307983
train loss item: 0.11835235357284546
train loss item: 0.24962782859802246
train loss item: 0.08206911385059357
train loss item: 0.17959633469581604
train loss item: 0.34946537017822266
train loss item: 0.15703195333480835
train loss item: 0.14711864292621613
train loss item: 0.12025559693574905
train loss item: 0.14455333352088928
train loss item: 0.08044486492872238
train loss item: 0.07831676304340363
train loss item: 0.16542544960975647
train loss item: 0.04736139997839928
train loss item: 0.0751245766878128
train loss item: 0.2446468323469162
train loss item: 0.8240227699279785
train loss item: 0.06252329051494598
train loss item: 0.14775779843330383
train loss item: 0.08577354997396469
train loss item: 0.09808798879384995
train loss item: 0.10503511875867844
train loss item: 0.33886462450027466
train loss item: 0.2562122046947479
train loss item: 0.25111380219459534
train loss item: 0.31241723895072937
train loss item: 0.06444160640239716
train loss item: 0.15162605047225952
test loss item: 0.09000110626220703
test loss item: 0.07527651637792587
test loss item: 0.3701171576976776
test loss item: 0.12995167076587677
test loss item: 0.1475745588541031
test loss item: 0.09693554788827896
test loss item: 1.519590973854065
test loss item: 0.5321676731109619
test loss item: 0.14385464787483215
test loss item: 0.2177785038948059
test loss item: 0.5747449398040771
test loss item: 0.08879585564136505
test loss item: 0.12531791627407074
test loss item: 0.16303974390029907
test loss item: 0.11048135161399841
test loss item: 0.057807572185993195
test loss item: 0.19635802507400513
test loss item: 0.21987499296665192
test loss item: 0.5120801329612732
test loss item: 0.1845831722021103
test loss item: 0.3349246382713318
test loss item: 0.2964024841785431
test loss item: 0.18901805579662323
test loss item: 0.11864345520734787
test loss item: 0.11517990380525589
test loss item: 0.1398162543773651
test loss item: 0.17362427711486816
test loss item: 0.11227129399776459
test loss item: 0.1930931657552719
test loss item: 0.18537330627441406
test loss item: 0.6316050291061401
test loss item: 0.04615774005651474
test loss item: 0.09512712061405182
test loss item: 0.279666006565094
test loss item: 0.2292429655790329
test loss item: 0.26350778341293335
test loss item: 0.6293965578079224
test loss item: 0.955977737903595
test loss item: 0.25723767280578613
test loss item: 0.2062135934829712
test loss item: 0.2167450487613678
test loss item: 0.13435810804367065
test loss item: 0.15497633814811707
test loss item: 0.15557272732257843
test loss item: 0.26079317927360535
test loss item: 0.27376753091812134
test loss item: 0.1682184338569641
test loss item: 0.14309895038604736
test loss item: 0.2927301526069641
test loss item: 0.47558414936065674
test loss item: 0.15701855719089508
test loss item: 0.09134255349636078
test loss item: 0.14844481647014618
test loss item: 0.09247364103794098
test loss item: 0.15000252425670624
test loss item: 0.527077853679657
test loss item: 0.40150126814842224
test loss item: 0.15385614335536957
test loss item: 0.15246540307998657
test loss item: 0.1032290980219841
test loss item: 0.1959265023469925
test loss item: 0.2000654637813568
test loss item: 0.14286328852176666
test loss item: 0.1509101241827011
test loss item: 0.6254095435142517
test loss item: 0.1736832708120346
test loss item: 0.21931926906108856
test loss item: 0.17680078744888306
test loss item: 0.2697480618953705
test loss item: 0.3376794159412384
test loss item: 0.061362359672784805
test loss item: 0.8774884939193726
test loss item: 0.18688294291496277
test loss item: 0.3057135045528412
test loss item: 0.10729449987411499
test loss item: 0.12420269101858139
test loss item: 0.12646488845348358
test loss item: 0.994072437286377
test loss item: 0.2531081438064575
test loss item: 0.11400805413722992
test loss item: 0.048794496804475784
test loss item: 0.7638463973999023
test loss item: 0.6682902574539185
test loss item: 0.7066938877105713
test loss item: 0.1459263116121292
test loss item: 0.13092230260372162
test loss item: 0.04653158783912659
test loss item: 0.03634677454829216
test loss item: 0.11225073784589767
Epoch [29/100], Training Loss: 0.1797, Testing Loss: 0.2648
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 30/100
train loss item: 0.198426753282547
train loss item: 0.3175378739833832
train loss item: 0.09093392640352249
train loss item: 0.2049599289894104
train loss item: 0.10558211803436279
train loss item: 0.17639432847499847
train loss item: 0.08294527232646942
train loss item: 0.2928007245063782
train loss item: 0.05655679479241371
train loss item: 0.08742856234312057
train loss item: 0.11334840953350067
train loss item: 0.0988936722278595
train loss item: 0.05933142453432083
train loss item: 0.3078415095806122
train loss item: 0.16176737844944
train loss item: 0.4301687180995941
train loss item: 0.045795489102602005
train loss item: 0.15224748849868774
train loss item: 0.18882125616073608
train loss item: 0.09209709614515305
train loss item: 0.1163749024271965
train loss item: 0.04959873482584953
train loss item: 0.2514377236366272
train loss item: 0.222852885723114
train loss item: 0.21357674896717072
train loss item: 0.15999996662139893
train loss item: 0.16752155125141144
train loss item: 0.1599525660276413
train loss item: 0.07803614437580109
train loss item: 0.2937702536582947
train loss item: 0.32711929082870483
train loss item: 0.38898375630378723
train loss item: 0.10042792558670044
train loss item: 0.14160986244678497
train loss item: 0.08024962991476059
train loss item: 0.3551921248435974
train loss item: 0.22368425130844116
train loss item: 0.23963503539562225
train loss item: 0.23602186143398285
train loss item: 0.11184612661600113
train loss item: 0.11835355311632156
train loss item: 0.1464734524488449
train loss item: 0.2352110892534256
train loss item: 0.13589191436767578
train loss item: 0.24962006509304047
train loss item: 0.061326511204242706
train loss item: 0.05327337607741356
train loss item: 0.24521464109420776
train loss item: 0.12036975473165512
train loss item: 0.07156393676996231
train loss item: 0.16865961253643036
train loss item: 0.3975735306739807
train loss item: 0.056420911103487015
train loss item: 0.08215927332639694
train loss item: 0.23312298953533173
train loss item: 0.07831630855798721
train loss item: 0.15345920622348785
train loss item: 0.08066585659980774
train loss item: 0.08209532499313354
train loss item: 0.06543000787496567
train loss item: 0.2917090058326721
train loss item: 0.40738582611083984
train loss item: 0.14032170176506042
train loss item: 0.27114564180374146
train loss item: 0.10976181924343109
train loss item: 0.23168525099754333
train loss item: 0.36202943325042725
train loss item: 0.14495806396007538
train loss item: 0.12844057381153107
train loss item: 0.14724895358085632
train loss item: 0.13995376229286194
train loss item: 0.08202555030584335
train loss item: 0.08352907747030258
train loss item: 0.1783456951379776
train loss item: 0.0495876707136631
train loss item: 0.08132067322731018
train loss item: 0.2626279890537262
train loss item: 0.9479894042015076
train loss item: 0.07053638994693756
train loss item: 0.17264914512634277
train loss item: 0.08604561537504196
train loss item: 0.1266418695449829
train loss item: 0.12832413613796234
train loss item: 0.22678352892398834
train loss item: 0.20676137506961823
train loss item: 0.27301132678985596
train loss item: 0.3472852408885956
train loss item: 0.08194748312234879
train loss item: 0.15145017206668854
test loss item: 0.08427855372428894
test loss item: 0.0863189771771431
test loss item: 0.4692244827747345
test loss item: 0.1254204660654068
test loss item: 0.1806294023990631
test loss item: 0.09321489930152893
test loss item: 1.349247694015503
test loss item: 0.466987669467926
test loss item: 0.1810595691204071
test loss item: 0.27452945709228516
test loss item: 0.6738887429237366
test loss item: 0.09852459281682968
test loss item: 0.14465010166168213
test loss item: 0.17315803468227386
test loss item: 0.12859037518501282
test loss item: 0.06680864840745926
test loss item: 0.1876722127199173
test loss item: 0.30402785539627075
test loss item: 0.4746414124965668
test loss item: 0.1910293698310852
test loss item: 0.4964843690395355
test loss item: 0.27369076013565063
test loss item: 0.22277258336544037
test loss item: 0.11156162619590759
test loss item: 0.12704996764659882
test loss item: 0.14350461959838867
test loss item: 0.19533732533454895
test loss item: 0.1370830535888672
test loss item: 0.21576854586601257
test loss item: 0.212791308760643
test loss item: 0.6462715268135071
test loss item: 0.05511156842112541
test loss item: 0.08989362418651581
test loss item: 0.3630349040031433
test loss item: 0.3087630867958069
test loss item: 0.28606125712394714
test loss item: 0.591003954410553
test loss item: 1.153605580329895
test loss item: 0.3129828870296478
test loss item: 0.18947415053844452
test loss item: 0.20187576115131378
test loss item: 0.1133732944726944
test loss item: 0.22589778900146484
test loss item: 0.14473316073417664
test loss item: 0.3818320631980896
test loss item: 0.2720324993133545
test loss item: 0.1920752227306366
test loss item: 0.15149815380573273
test loss item: 0.36045747995376587
test loss item: 0.5233033299446106
test loss item: 0.2294992357492447
test loss item: 0.09165508300065994
test loss item: 0.16395771503448486
test loss item: 0.08947749435901642
test loss item: 0.20939628779888153
test loss item: 0.6561110615730286
test loss item: 0.40298622846603394
test loss item: 0.2245371788740158
test loss item: 0.16603268682956696
test loss item: 0.14097167551517487
test loss item: 0.2823139727115631
test loss item: 0.19421438872814178
test loss item: 0.13159355521202087
test loss item: 0.16189564764499664
test loss item: 0.7097501158714294
test loss item: 0.16911661624908447
test loss item: 0.22861044108867645
test loss item: 0.17483335733413696
test loss item: 0.34699705243110657
test loss item: 0.32475823163986206
test loss item: 0.07282435148954391
test loss item: 0.7837940454483032
test loss item: 0.2250126451253891
test loss item: 0.28531140089035034
test loss item: 0.10815642774105072
test loss item: 0.10931726545095444
test loss item: 0.1208900585770607
test loss item: 1.2229901552200317
test loss item: 0.2955336570739746
test loss item: 0.11612135171890259
test loss item: 0.05140990763902664
test loss item: 0.7904008626937866
test loss item: 0.643398106098175
test loss item: 0.8517197370529175
test loss item: 0.1540207415819168
test loss item: 0.14061619341373444
test loss item: 0.048479098826646805
test loss item: 0.04715102165937424
test loss item: 0.10202357172966003
Epoch [30/100], Training Loss: 0.1792, Testing Loss: 0.2890
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 31/100
train loss item: 0.20466966927051544
train loss item: 0.2936355769634247
train loss item: 0.09206966310739517
train loss item: 0.1971258819103241
train loss item: 0.08836568892002106
train loss item: 0.15018725395202637
train loss item: 0.07626324892044067
train loss item: 0.22104065120220184
train loss item: 0.05291398614645004
train loss item: 0.08968574553728104
train loss item: 0.09837545454502106
train loss item: 0.0996733009815216
train loss item: 0.058751482516527176
train loss item: 0.28640714287757874
train loss item: 0.14584270119667053
train loss item: 0.4534522593021393
train loss item: 0.04142498970031738
train loss item: 0.11531208455562592
train loss item: 0.14574754238128662
train loss item: 0.09159065037965775
train loss item: 0.10040785372257233
train loss item: 0.04994834586977959
train loss item: 0.3179762661457062
train loss item: 0.18802830576896667
train loss item: 0.17914995551109314
train loss item: 0.14069926738739014
train loss item: 0.16428042948246002
train loss item: 0.15175661444664001
train loss item: 0.08115249127149582
train loss item: 0.3044716417789459
train loss item: 0.33079251646995544
train loss item: 0.35816770792007446
train loss item: 0.10311069339513779
train loss item: 0.16397878527641296
train loss item: 0.10419868677854538
train loss item: 0.35934895277023315
train loss item: 0.26971912384033203
train loss item: 0.2722606360912323
train loss item: 0.19934971630573273
train loss item: 0.1258658468723297
train loss item: 0.11785608530044556
train loss item: 0.1824967861175537
train loss item: 0.2329593449831009
train loss item: 0.15845362842082977
train loss item: 0.33983349800109863
train loss item: 0.06528837233781815
train loss item: 0.05721311643719673
train loss item: 0.22882753610610962
train loss item: 0.11330144107341766
train loss item: 0.08557925373315811
train loss item: 0.18247710168361664
train loss item: 0.4121735692024231
train loss item: 0.07233479619026184
train loss item: 0.07922651618719101
train loss item: 0.27833646535873413
train loss item: 0.07943247258663177
train loss item: 0.19905877113342285
train loss item: 0.0807085782289505
train loss item: 0.0954778715968132
train loss item: 0.08196888118982315
train loss item: 0.18198640644550323
train loss item: 0.41865232586860657
train loss item: 0.11001000553369522
train loss item: 0.21191368997097015
train loss item: 0.10983490198850632
train loss item: 0.14709463715553284
train loss item: 0.19813819229602814
train loss item: 0.10107261687517166
train loss item: 0.13441604375839233
train loss item: 0.10311061143875122
train loss item: 0.09316488355398178
train loss item: 0.051315635442733765
train loss item: 0.09456169605255127
train loss item: 0.1200808435678482
train loss item: 0.04451746493577957
train loss item: 0.06109263747930527
train loss item: 0.2886093556880951
train loss item: 0.813720703125
train loss item: 0.050963591784238815
train loss item: 0.11449182033538818
train loss item: 0.08742592483758926
train loss item: 0.10067582875490189
train loss item: 0.12116216123104095
train loss item: 0.20213519036769867
train loss item: 0.3006977438926697
train loss item: 0.21103915572166443
train loss item: 0.7755454778671265
train loss item: 0.062439773231744766
train loss item: 0.17271456122398376
test loss item: 0.09862414747476578
test loss item: 0.08131347596645355
test loss item: 0.24222391843795776
test loss item: 0.13942331075668335
test loss item: 0.1280076652765274
test loss item: 0.1209869384765625
test loss item: 1.290778398513794
test loss item: 0.43385931849479675
test loss item: 0.09814286977052689
test loss item: 0.15042202174663544
test loss item: 0.41711583733558655
test loss item: 0.08084926009178162
test loss item: 0.08251949399709702
test loss item: 0.1188974604010582
test loss item: 0.10689922422170639
test loss item: 0.048890452831983566
test loss item: 0.17008931934833527
test loss item: 0.14605726301670074
test loss item: 0.4319208860397339
test loss item: 0.13286615908145905
test loss item: 0.19545137882232666
test loss item: 0.2523384988307953
test loss item: 0.16375544667243958
test loss item: 0.12972989678382874
test loss item: 0.10284356772899628
test loss item: 0.13333392143249512
test loss item: 0.1393006294965744
test loss item: 0.11020520329475403
test loss item: 0.16112905740737915
test loss item: 0.13918951153755188
test loss item: 0.500751793384552
test loss item: 0.05345599725842476
test loss item: 0.11614019423723221
test loss item: 0.20554229617118835
test loss item: 0.14737682044506073
test loss item: 0.20625916123390198
test loss item: 0.5278703570365906
test loss item: 0.6619644165039062
test loss item: 0.19274666905403137
test loss item: 0.20162682235240936
test loss item: 0.1978643834590912
test loss item: 0.14965565502643585
test loss item: 0.10933885723352432
test loss item: 0.15032410621643066
test loss item: 0.1577005237340927
test loss item: 0.21090824902057648
test loss item: 0.1541653573513031
test loss item: 0.10116796940565109
test loss item: 0.20031984150409698
test loss item: 0.35286378860473633
test loss item: 0.10180416703224182
test loss item: 0.07524002343416214
test loss item: 0.13354545831680298
test loss item: 0.10801880806684494
test loss item: 0.1099662110209465
test loss item: 0.34448739886283875
test loss item: 0.3191124200820923
test loss item: 0.12028536945581436
test loss item: 0.12771901488304138
test loss item: 0.07755601406097412
test loss item: 0.13976219296455383
test loss item: 0.15825983881950378
test loss item: 0.12845292687416077
test loss item: 0.12370015680789948
test loss item: 0.45944374799728394
test loss item: 0.17726483941078186
test loss item: 0.1674487143754959
test loss item: 0.15308542549610138
test loss item: 0.19017904996871948
test loss item: 0.28381049633026123
test loss item: 0.05797921121120453
test loss item: 0.741743266582489
test loss item: 0.12676426768302917
test loss item: 0.2603638470172882
test loss item: 0.09317705780267715
test loss item: 0.13699549436569214
test loss item: 0.12950393557548523
test loss item: 0.6892128586769104
test loss item: 0.17601333558559418
test loss item: 0.12243565171957016
test loss item: 0.07800386101007462
test loss item: 0.6089861392974854
test loss item: 0.5522835850715637
test loss item: 0.4867404103279114
test loss item: 0.11852280050516129
test loss item: 0.11194941401481628
test loss item: 0.07640203088521957
test loss item: 0.056502800434827805
test loss item: 0.16226935386657715
Epoch [31/100], Training Loss: 0.1752, Testing Loss: 0.2127
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 32/100
train loss item: 0.21800963580608368
train loss item: 0.26281604170799255
train loss item: 0.08701062202453613
train loss item: 0.15248501300811768
train loss item: 0.14418092370033264
train loss item: 0.12092749029397964
train loss item: 0.1004260778427124
train loss item: 0.17584899067878723
train loss item: 0.05146734416484833
train loss item: 0.10058541595935822
train loss item: 0.12645553052425385
train loss item: 0.09491217136383057
train loss item: 0.0645274892449379
train loss item: 0.24216283857822418
train loss item: 0.13768167793750763
train loss item: 0.30496296286582947
train loss item: 0.041115082800388336
train loss item: 0.07912012189626694
train loss item: 0.1413252055644989
train loss item: 0.07894821465015411
train loss item: 0.10996701568365097
train loss item: 0.05862179026007652
train loss item: 0.24883173406124115
train loss item: 0.22520755231380463
train loss item: 0.21984456479549408
train loss item: 0.10190176963806152
train loss item: 0.08296418935060501
train loss item: 0.1135663315653801
train loss item: 0.05691586062312126
train loss item: 0.26111286878585815
train loss item: 0.30932480096817017
train loss item: 0.314698189496994
train loss item: 0.09274505078792572
train loss item: 0.14163361489772797
train loss item: 0.0797666683793068
train loss item: 0.3510775864124298
train loss item: 0.194871187210083
train loss item: 0.23791691660881042
train loss item: 0.2058596909046173
train loss item: 0.13315720856189728
train loss item: 0.12117012590169907
train loss item: 0.13213856518268585
train loss item: 0.2205342799425125
train loss item: 0.1310131698846817
train loss item: 0.2613547742366791
train loss item: 0.06979384273290634
train loss item: 0.054987214505672455
train loss item: 0.1842406541109085
train loss item: 0.0984383374452591
train loss item: 0.06245480105280876
train loss item: 0.1351241022348404
train loss item: 0.3055199086666107
train loss item: 0.050791703164577484
train loss item: 0.08521407842636108
train loss item: 0.3431963324546814
train loss item: 0.10028434544801712
train loss item: 0.1666216403245926
train loss item: 0.11231502145528793
train loss item: 0.09227234870195389
train loss item: 0.07707992941141129
train loss item: 0.4116472005844116
train loss item: 0.837974488735199
train loss item: 0.1379736363887787
train loss item: 0.2479410171508789
train loss item: 0.12984773516654968
train loss item: 0.21826103329658508
train loss item: 0.23621836304664612
train loss item: 0.13691140711307526
train loss item: 0.1332918256521225
train loss item: 0.1529656946659088
train loss item: 0.1307770311832428
train loss item: 0.08193348348140717
train loss item: 0.08542072772979736
train loss item: 0.16316275298595428
train loss item: 0.04666435346007347
train loss item: 0.07424736768007278
train loss item: 0.2685706317424774
train loss item: 0.9178304076194763
train loss item: 0.07983323186635971
train loss item: 0.16995097696781158
train loss item: 0.08202486485242844
train loss item: 0.12522035837173462
train loss item: 0.10934069752693176
train loss item: 0.18929824233055115
train loss item: 0.16831988096237183
train loss item: 0.24263866245746613
train loss item: 0.37824898958206177
train loss item: 0.05939483642578125
train loss item: 0.21070197224617004
test loss item: 0.08518567681312561
test loss item: 0.0854308009147644
test loss item: 0.19926606118679047
test loss item: 0.13033729791641235
test loss item: 0.12610138952732086
test loss item: 0.10855795443058014
test loss item: 1.1391571760177612
test loss item: 0.3785550892353058
test loss item: 0.08977814018726349
test loss item: 0.1444185972213745
test loss item: 0.33760663866996765
test loss item: 0.0790332704782486
test loss item: 0.10636570304632187
test loss item: 0.11976596713066101
test loss item: 0.10716072469949722
test loss item: 0.04788335785269737
test loss item: 0.16743813455104828
test loss item: 0.1324012577533722
test loss item: 0.3969470262527466
test loss item: 0.14824888110160828
test loss item: 0.1818908154964447
test loss item: 0.2324448972940445
test loss item: 0.1646323800086975
test loss item: 0.12469258904457092
test loss item: 0.08570671081542969
test loss item: 0.13675539195537567
test loss item: 0.14040511846542358
test loss item: 0.11296996474266052
test loss item: 0.16502892971038818
test loss item: 0.14569729566574097
test loss item: 0.4054758548736572
test loss item: 0.04129474610090256
test loss item: 0.11241164803504944
test loss item: 0.16750887036323547
test loss item: 0.12492692470550537
test loss item: 0.18235507607460022
test loss item: 0.47737303376197815
test loss item: 0.47610151767730713
test loss item: 0.1622086614370346
test loss item: 0.18580123782157898
test loss item: 0.18383122980594635
test loss item: 0.1466851383447647
test loss item: 0.09841378033161163
test loss item: 0.13468095660209656
test loss item: 0.14942307770252228
test loss item: 0.2253326028585434
test loss item: 0.15716804563999176
test loss item: 0.11499302834272385
test loss item: 0.18537761270999908
test loss item: 0.3014739453792572
test loss item: 0.11234527826309204
test loss item: 0.08523281663656235
test loss item: 0.12300775945186615
test loss item: 0.08998475223779678
test loss item: 0.10540741682052612
test loss item: 0.2569134831428528
test loss item: 0.28313368558883667
test loss item: 0.12293720990419388
test loss item: 0.13169294595718384
test loss item: 0.09014859795570374
test loss item: 0.12876488268375397
test loss item: 0.15650105476379395
test loss item: 0.12580811977386475
test loss item: 0.13546596467494965
test loss item: 0.40701064467430115
test loss item: 0.1641419678926468
test loss item: 0.18003499507904053
test loss item: 0.15198618173599243
test loss item: 0.15209661424160004
test loss item: 0.25264742970466614
test loss item: 0.05760485306382179
test loss item: 0.6721863746643066
test loss item: 0.13355456292629242
test loss item: 0.24633754789829254
test loss item: 0.09494830667972565
test loss item: 0.13486197590827942
test loss item: 0.12460120767354965
test loss item: 0.4895699620246887
test loss item: 0.1741943508386612
test loss item: 0.11179947853088379
test loss item: 0.06141116842627525
test loss item: 0.5182504057884216
test loss item: 0.48406824469566345
test loss item: 0.363441526889801
test loss item: 0.12599864602088928
test loss item: 0.11297639459371567
test loss item: 0.05729633942246437
test loss item: 0.036448054015636444
test loss item: 0.1371590793132782
Epoch [32/100], Training Loss: 0.1719, Testing Loss: 0.1915
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 33/100
train loss item: 0.21643546223640442
train loss item: 0.40808260440826416
train loss item: 0.08912383019924164
train loss item: 0.2512553334236145
train loss item: 0.08817402273416519
train loss item: 0.1387692242860794
train loss item: 0.08055566251277924
train loss item: 0.24818572402000427
train loss item: 0.057436227798461914
train loss item: 0.11719650030136108
train loss item: 0.12558098137378693
train loss item: 0.1062697023153305
train loss item: 0.0536879301071167
train loss item: 0.20603877305984497
train loss item: 0.1263086348772049
train loss item: 0.38079482316970825
train loss item: 0.04173562303185463
train loss item: 0.065086230635643
train loss item: 0.18646390736103058
train loss item: 0.10013678669929504
train loss item: 0.10049968212842941
train loss item: 0.04805915802717209
train loss item: 0.39518681168556213
train loss item: 0.20867633819580078
train loss item: 0.23760324716567993
train loss item: 0.10725026577711105
train loss item: 0.06368434429168701
train loss item: 0.13844092190265656
train loss item: 0.05636842921376228
train loss item: 0.33402323722839355
train loss item: 0.8926448225975037
train loss item: 0.32744666934013367
train loss item: 0.12474509328603745
train loss item: 0.16574382781982422
train loss item: 0.11548972874879837
train loss item: 0.7782346606254578
train loss item: 0.37480175495147705
train loss item: 0.34753283858299255
train loss item: 0.20762193202972412
train loss item: 0.198884516954422
train loss item: 0.11276548355817795
train loss item: 0.12476952373981476
train loss item: 0.2156219482421875
train loss item: 0.1576181948184967
train loss item: 0.319983571767807
train loss item: 0.08151306957006454
train loss item: 0.08107129484415054
train loss item: 0.2851952910423279
train loss item: 0.1550116389989853
train loss item: 0.08343004435300827
train loss item: 0.2882593870162964
train loss item: 0.651773989200592
train loss item: 0.06592258810997009
train loss item: 0.07942797243595123
train loss item: 0.40432944893836975
train loss item: 0.1257341355085373
train loss item: 0.21318471431732178
train loss item: 0.12726788222789764
train loss item: 0.0741691142320633
train loss item: 0.08974523842334747
train loss item: 0.340744286775589
train loss item: 0.631361722946167
train loss item: 0.13467799127101898
train loss item: 0.2296362668275833
train loss item: 0.10785325616598129
train loss item: 0.1743392050266266
train loss item: 0.20821766555309296
train loss item: 0.08478284627199173
train loss item: 0.11967137455940247
train loss item: 0.1018901914358139
train loss item: 0.09985356032848358
train loss item: 0.049647752195596695
train loss item: 0.09141354262828827
train loss item: 0.16481268405914307
train loss item: 0.04519833251833916
train loss item: 0.06421135365962982
train loss item: 0.3165992200374603
train loss item: 0.9073591232299805
train loss item: 0.061435237526893616
train loss item: 0.18417055904865265
train loss item: 0.09739653766155243
train loss item: 0.09611155092716217
train loss item: 0.1176275759935379
train loss item: 0.21366481482982635
train loss item: 0.22443583607673645
train loss item: 0.24147643148899078
train loss item: 0.4968206286430359
train loss item: 0.06506036221981049
train loss item: 0.19207718968391418
test loss item: 0.0979401096701622
test loss item: 0.08674472570419312
test loss item: 0.2480236291885376
test loss item: 0.1301034539937973
test loss item: 0.13964931666851044
test loss item: 0.1401793509721756
test loss item: 1.0916314125061035
test loss item: 0.3260480761528015
test loss item: 0.10895264893770218
test loss item: 0.16462890803813934
test loss item: 0.41691267490386963
test loss item: 0.07763098180294037
test loss item: 0.07958830893039703
test loss item: 0.10923796892166138
test loss item: 0.10846693068742752
test loss item: 0.0603201799094677
test loss item: 0.13821272552013397
test loss item: 0.1653873473405838
test loss item: 0.3647029995918274
test loss item: 0.1259535253047943
test loss item: 0.23240849375724792
test loss item: 0.20876255631446838
test loss item: 0.19374585151672363
test loss item: 0.12008341401815414
test loss item: 0.09471231698989868
test loss item: 0.11686063557863235
test loss item: 0.14521420001983643
test loss item: 0.12213564664125443
test loss item: 0.1477746218442917
test loss item: 0.14516544342041016
test loss item: 0.4481605589389801
test loss item: 0.06979968398809433
test loss item: 0.11282707750797272
test loss item: 0.20933806896209717
test loss item: 0.16446886956691742
test loss item: 0.20728051662445068
test loss item: 0.44298553466796875
test loss item: 0.6600082516670227
test loss item: 0.1879851520061493
test loss item: 0.1917891949415207
test loss item: 0.17114967107772827
test loss item: 0.1585683971643448
test loss item: 0.13594146072864532
test loss item: 0.1274251937866211
test loss item: 0.1795235574245453
test loss item: 0.18098753690719604
test loss item: 0.17567957937717438
test loss item: 0.12391496449708939
test loss item: 0.19218671321868896
test loss item: 0.32856088876724243
test loss item: 0.12567010521888733
test loss item: 0.08481042832136154
test loss item: 0.12295277416706085
test loss item: 0.09621042758226395
test loss item: 0.12188748270273209
test loss item: 0.36226412653923035
test loss item: 0.26788777112960815
test loss item: 0.1353922039270401
test loss item: 0.1194358617067337
test loss item: 0.08519468456506729
test loss item: 0.17465871572494507
test loss item: 0.12725912034511566
test loss item: 0.10118045657873154
test loss item: 0.11331791430711746
test loss item: 0.42585161328315735
test loss item: 0.16410481929779053
test loss item: 0.14378048479557037
test loss item: 0.1336188018321991
test loss item: 0.19211187958717346
test loss item: 0.27018070220947266
test loss item: 0.0670485720038414
test loss item: 0.6132462620735168
test loss item: 0.12133657932281494
test loss item: 0.21790039539337158
test loss item: 0.08661927282810211
test loss item: 0.1595211923122406
test loss item: 0.12103156745433807
test loss item: 0.6731928586959839
test loss item: 0.17492403090000153
test loss item: 0.13114692270755768
test loss item: 0.0941765233874321
test loss item: 0.5433024764060974
test loss item: 0.4846276342868805
test loss item: 0.47847288846969604
test loss item: 0.12538360059261322
test loss item: 0.10113254934549332
test loss item: 0.09366387873888016
test loss item: 0.07202431559562683
test loss item: 0.15152154862880707
Epoch [33/100], Training Loss: 0.2012, Testing Loss: 0.2029
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 74.00 MB
Epoch 34/100
train loss item: 0.24262307584285736
train loss item: 0.2660713493824005
train loss item: 0.09009871631860733
train loss item: 0.24337385594844818
train loss item: 0.11847513914108276
train loss item: 0.1662069708108902
train loss item: 0.08685919642448425
train loss item: 0.1353387087583542
train loss item: 0.0730503648519516
train loss item: 0.11956895142793655
train loss item: 0.12571588158607483
train loss item: 0.1549483686685562
train loss item: 0.048727549612522125
train loss item: 0.25694411993026733
train loss item: 0.12329626828432083
train loss item: 0.3254374861717224
train loss item: 0.046293944120407104
train loss item: 0.07801252603530884
train loss item: 0.188332661986351
train loss item: 0.10663875192403793
train loss item: 0.13617263734340668
train loss item: 0.06995514035224915
train loss item: 0.23435774445533752
train loss item: 0.1978423148393631
train loss item: 0.18981754779815674
train loss item: 0.10965405404567719
train loss item: 0.08378887921571732
train loss item: 0.13698157668113708
train loss item: 0.05613114684820175
train loss item: 0.27044522762298584
train loss item: 0.6043357849121094
train loss item: 0.28919491171836853
train loss item: 0.12110189348459244
train loss item: 0.16328448057174683
train loss item: 0.09307202696800232
train loss item: 0.6612449288368225
train loss item: 0.3056783378124237
train loss item: 0.27738139033317566
train loss item: 0.19660110771656036
train loss item: 0.18264880776405334
train loss item: 0.1160423532128334
train loss item: 0.11261908710002899
train loss item: 0.208200603723526
train loss item: 0.1424390822649002
train loss item: 0.3143642246723175
train loss item: 0.06920044869184494
train loss item: 0.07254789024591446
train loss item: 0.21309903264045715
train loss item: 0.14377065002918243
train loss item: 0.07648719847202301
train loss item: 0.22834813594818115
train loss item: 0.47274893522262573
train loss item: 0.05747603625059128
train loss item: 0.08174210786819458
train loss item: 0.33069878816604614
train loss item: 0.0818508043885231
train loss item: 0.17506179213523865
train loss item: 0.09383952617645264
train loss item: 0.07883520424365997
train loss item: 0.08413325995206833
train loss item: 0.2020927220582962
train loss item: 0.6900960206985474
train loss item: 0.1264180988073349
train loss item: 0.2330208420753479
train loss item: 0.0902220830321312
train loss item: 0.13808472454547882
train loss item: 0.21650686860084534
train loss item: 0.07520772516727448
train loss item: 0.11882203817367554
train loss item: 0.08412627130746841
train loss item: 0.08342786878347397
train loss item: 0.044113632291555405
train loss item: 0.06204954534769058
train loss item: 0.11748793721199036
train loss item: 0.0486191101372242
train loss item: 0.0588054396212101
train loss item: 0.2973484992980957
train loss item: 0.8687699437141418
train loss item: 0.04218043386936188
train loss item: 0.12187014520168304
train loss item: 0.07745940238237381
train loss item: 0.07146169990301132
train loss item: 0.09939414262771606
train loss item: 0.17620277404785156
train loss item: 0.2530566453933716
train loss item: 0.17100153863430023
train loss item: 0.34125009179115295
train loss item: 0.050476912409067154
train loss item: 0.19573259353637695
test loss item: 0.08873776346445084
test loss item: 0.07628822326660156
test loss item: 0.2883429229259491
test loss item: 0.12236437201499939
test loss item: 0.14258918166160583
test loss item: 0.13434915244579315
test loss item: 1.1242910623550415
test loss item: 0.34406358003616333
test loss item: 0.11902645975351334
test loss item: 0.1848074346780777
test loss item: 0.43260443210601807
test loss item: 0.06914085149765015
test loss item: 0.08732720464468002
test loss item: 0.1209247037768364
test loss item: 0.10428760945796967
test loss item: 0.05967235192656517
test loss item: 0.13376875221729279
test loss item: 0.19433186948299408
test loss item: 0.3647661805152893
test loss item: 0.11130261421203613
test loss item: 0.3009662926197052
test loss item: 0.21181398630142212
test loss item: 0.22801150381565094
test loss item: 0.10332518070936203
test loss item: 0.09852289408445358
test loss item: 0.10777835547924042
test loss item: 0.13556964695453644
test loss item: 0.11759350448846817
test loss item: 0.14542052149772644
test loss item: 0.15186917781829834
test loss item: 0.47031694650650024
test loss item: 0.06400204449892044
test loss item: 0.09385351836681366
test loss item: 0.23321405053138733
test loss item: 0.19520995020866394
test loss item: 0.2123100906610489
test loss item: 0.45941996574401855
test loss item: 0.7054433822631836
test loss item: 0.2122054398059845
test loss item: 0.18160304427146912
test loss item: 0.16742227971553802
test loss item: 0.18579845130443573
test loss item: 0.15023508667945862
test loss item: 0.1254338026046753
test loss item: 0.233912393450737
test loss item: 0.1666109561920166
test loss item: 0.21941736340522766
test loss item: 0.11510931700468063
test loss item: 0.22495976090431213
test loss item: 0.33828431367874146
test loss item: 0.15945076942443848
test loss item: 0.08014994114637375
test loss item: 0.12913328409194946
test loss item: 0.09249750524759293
test loss item: 0.1413308084011078
test loss item: 0.40593695640563965
test loss item: 0.2769046723842621
test loss item: 0.17949415743350983
test loss item: 0.12293470650911331
test loss item: 0.09660499542951584
test loss item: 0.19626101851463318
test loss item: 0.12776221334934235
test loss item: 0.09463156759738922
test loss item: 0.10871656984090805
test loss item: 0.46088555455207825
test loss item: 0.16215936839580536
test loss item: 0.13939368724822998
test loss item: 0.1292700469493866
test loss item: 0.2191818654537201
test loss item: 0.2590402364730835
test loss item: 0.060299329459667206
test loss item: 0.6171855926513672
test loss item: 0.13542857766151428
test loss item: 0.20342375338077545
test loss item: 0.08428067713975906
test loss item: 0.19521914422512054
test loss item: 0.10572334378957748
test loss item: 0.7298663258552551
test loss item: 0.17081516981124878
test loss item: 0.12491434812545776
test loss item: 0.08122333884239197
test loss item: 0.5503886938095093
test loss item: 0.49716854095458984
test loss item: 0.5138972997665405
test loss item: 0.1048077642917633
test loss item: 0.0970853790640831
test loss item: 0.08775315433740616
test loss item: 0.07373858988285065
test loss item: 0.13391365110874176
Epoch [34/100], Training Loss: 0.1762, Testing Loss: 0.2113
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.18360450863838196
loss item: 0.11378119885921478
loss item: 0.7732493877410889
loss item: 0.39385971426963806
loss item: 0.376323938369751
loss item: 0.20087546110153198
loss item: 0.09465619176626205
loss item: 0.4832707941532135
loss item: 0.09844407439231873
loss item: 0.1067473441362381
loss item: 0.5909653902053833
loss item: 0.05410582199692726
loss item: 0.5232440233230591
loss item: 0.10001982748508453
loss item: 0.2561292350292206
loss item: 0.2660951614379883
loss item: 0.18664394319057465
loss item: 0.2860138416290283
loss item: 0.4615509510040283
loss item: 0.18914709985256195
loss item: 0.1680774986743927
loss item: 0.091843381524086
loss item: 0.11929000914096832
loss item: 0.11766696721315384
loss item: 0.11177924275398254
loss item: 0.3936399817466736
loss item: 0.5398112535476685
loss item: 0.10450177639722824
loss item: 0.08564317971467972
loss item: 0.23000174760818481
loss item: 0.6532405614852905
loss item: 0.7625669836997986
loss item: 0.09457258880138397
loss item: 0.2950652837753296
loss item: 0.08937880396842957
loss item: 0.19169865548610687
loss item: 0.19091211259365082
loss item: 0.11019188910722733
loss item: 0.2502352297306061
loss item: 0.38780081272125244
loss item: 0.5414071679115295
loss item: 0.19552569091320038
loss item: 0.14639554917812347
loss item: 0.058557331562042236
Val Loss: 0.2652
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 100, batch size: 2
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.005 2 360 done at Tue Nov 12 12:44:04 CET 2024
UNet2 with 1 100 0.0001 4 360 start at Tue Nov 12 12:44:04 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.6336421966552734
train loss item: 1.1108150482177734
train loss item: 0.6386311054229736
train loss item: 1.194264531135559
train loss item: 0.5417352318763733
train loss item: 0.5596734285354614
train loss item: 0.6423448920249939
train loss item: 0.840389609336853
train loss item: 0.516490638256073
train loss item: 0.5425041317939758
train loss item: 0.38656359910964966
train loss item: 1.3202400207519531
train loss item: 0.5797537565231323
train loss item: 0.4730110168457031
train loss item: 0.8736816644668579
train loss item: 2.072476387023926
train loss item: 0.6429057121276855
train loss item: 2.485495090484619
train loss item: 0.4917813241481781
train loss item: 0.4936889708042145
train loss item: 0.4070166349411011
train loss item: 0.3808233439922333
train loss item: 0.6257745027542114
train loss item: 0.42149874567985535
train loss item: 0.3764941394329071
train loss item: 0.8154841661453247
train loss item: 0.3215309977531433
train loss item: 1.8327252864837646
train loss item: 0.4126252233982086
train loss item: 0.32324883341789246
train loss item: 1.6522047519683838
train loss item: 0.39049842953681946
train loss item: 0.5390455722808838
train loss item: 0.41372454166412354
train loss item: 0.4230559170246124
train loss item: 0.3145202100276947
train loss item: 0.3597916066646576
train loss item: 0.3155818283557892
train loss item: 1.1574903726577759
train loss item: 0.2918848991394043
train loss item: 0.2487623244524002
train loss item: 0.5042638778686523
train loss item: 0.5764230489730835
train loss item: 3.096247673034668
train loss item: 0.3796599209308624
test loss item: 0.19254712760448456
test loss item: 0.5322990417480469
test loss item: 0.27953314781188965
test loss item: 1.0018279552459717
test loss item: 0.3794468939304352
test loss item: 0.7656427025794983
test loss item: 0.21222026646137238
test loss item: 0.202741801738739
test loss item: 0.42609620094299316
test loss item: 0.4844416677951813
test loss item: 0.540101170539856
test loss item: 0.3132360577583313
test loss item: 0.2739086449146271
test loss item: 0.3122216463088989
test loss item: 0.3926287889480591
test loss item: 0.7177404165267944
test loss item: 0.5661835670471191
test loss item: 0.5591747164726257
test loss item: 1.1336504220962524
test loss item: 0.47167396545410156
test loss item: 0.3113957345485687
test loss item: 0.34059053659439087
test loss item: 0.5480929613113403
test loss item: 0.31760090589523315
test loss item: 0.6265824437141418
test loss item: 0.27403774857521057
test loss item: 0.2855880856513977
test loss item: 0.7560979723930359
test loss item: 0.6133039593696594
test loss item: 0.2586955726146698
test loss item: 0.4102960228919983
test loss item: 0.27191323041915894
test loss item: 0.7541375756263733
test loss item: 0.3337915539741516
test loss item: 0.5460705161094666
test loss item: 0.6468589305877686
test loss item: 0.40331289172172546
test loss item: 0.1907721906900406
test loss item: 1.349961280822754
test loss item: 0.26866015791893005
test loss item: 0.8250028491020203
test loss item: 1.006622314453125
test loss item: 0.26233527064323425
test loss item: 0.1525888890028
test loss item: 0.2591479420661926
Epoch [1/100], Training Loss: 0.7693, Testing Loss: 0.4838
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/100
train loss item: 0.8530784845352173
train loss item: 0.4625650942325592
train loss item: 0.3809688687324524
train loss item: 0.5835763216018677
train loss item: 0.2991321384906769
train loss item: 0.35864973068237305
train loss item: 0.3826286196708679
train loss item: 0.5319647789001465
train loss item: 0.2997666001319885
train loss item: 0.3559068441390991
train loss item: 0.28267526626586914
train loss item: 0.8010956048965454
train loss item: 0.43608972430229187
train loss item: 0.32831594347953796
train loss item: 0.5846399664878845
train loss item: 1.4322606325149536
train loss item: 0.38311606645584106
train loss item: 1.8654735088348389
train loss item: 0.435563862323761
train loss item: 0.39391812682151794
train loss item: 0.26817646622657776
train loss item: 0.28279995918273926
train loss item: 0.436543732881546
train loss item: 0.31909412145614624
train loss item: 0.2407585233449936
train loss item: 0.649221658706665
train loss item: 0.2089318037033081
train loss item: 1.4434759616851807
train loss item: 0.3099333643913269
train loss item: 0.20974814891815186
train loss item: 1.349700927734375
train loss item: 0.32061582803726196
train loss item: 0.40310314297676086
train loss item: 0.35192814469337463
train loss item: 0.3204593062400818
train loss item: 0.2591325044631958
train loss item: 0.3048819899559021
train loss item: 0.22847671806812286
train loss item: 0.9508203268051147
train loss item: 0.27142608165740967
train loss item: 0.19510751962661743
train loss item: 0.3813060522079468
train loss item: 0.4492320716381073
train loss item: 2.600039005279541
train loss item: 0.35590770840644836
test loss item: 0.1924028843641281
test loss item: 0.38901200890541077
test loss item: 0.21826393902301788
test loss item: 0.7553784847259521
test loss item: 0.30172598361968994
test loss item: 0.5766850113868713
test loss item: 0.17969641089439392
test loss item: 0.2035469114780426
test loss item: 0.3262111246585846
test loss item: 0.41878992319107056
test loss item: 0.43651410937309265
test loss item: 0.2396809607744217
test loss item: 0.22214895486831665
test loss item: 0.26224586367607117
test loss item: 0.32335275411605835
test loss item: 0.507458508014679
test loss item: 0.45063671469688416
test loss item: 0.45962539315223694
test loss item: 0.8126094341278076
test loss item: 0.3641131520271301
test loss item: 0.2598801851272583
test loss item: 0.30639076232910156
test loss item: 0.4210054874420166
test loss item: 0.2530648410320282
test loss item: 0.45969319343566895
test loss item: 0.2280336171388626
test loss item: 0.26939958333969116
test loss item: 0.5392659306526184
test loss item: 0.517770528793335
test loss item: 0.21934156119823456
test loss item: 0.34101319313049316
test loss item: 0.21918857097625732
test loss item: 0.5810450911521912
test loss item: 0.26746615767478943
test loss item: 0.42877864837646484
test loss item: 0.4954307973384857
test loss item: 0.3076644241809845
test loss item: 0.16605477035045624
test loss item: 0.8322762846946716
test loss item: 0.21045993268489838
test loss item: 0.5955309271812439
test loss item: 0.7164821028709412
test loss item: 0.21455755829811096
test loss item: 0.1829734593629837
test loss item: 0.23580966889858246
Epoch [2/100], Training Loss: 0.5458, Testing Loss: 0.3757
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/100
train loss item: 0.6598713397979736
train loss item: 0.4232446849346161
train loss item: 0.2901347875595093
train loss item: 0.4724433422088623
train loss item: 0.2490486353635788
train loss item: 0.2853403389453888
train loss item: 0.3308391571044922
train loss item: 0.4407189190387726
train loss item: 0.23018403351306915
train loss item: 0.31086409091949463
train loss item: 0.22126378118991852
train loss item: 0.64383465051651
train loss item: 0.3296438753604889
train loss item: 0.24782025814056396
train loss item: 0.43594369292259216
train loss item: 1.1538946628570557
train loss item: 0.33476313948631287
train loss item: 1.5579376220703125
train loss item: 0.43418073654174805
train loss item: 0.37340864539146423
train loss item: 0.22276949882507324
train loss item: 0.24664263427257538
train loss item: 0.3776668310165405
train loss item: 0.27741819620132446
train loss item: 0.19357553124427795
train loss item: 0.6395742893218994
train loss item: 0.1662517786026001
train loss item: 1.2544194459915161
train loss item: 0.24450421333312988
train loss item: 0.16649506986141205
train loss item: 1.2141917943954468
train loss item: 0.2717919945716858
train loss item: 0.32139265537261963
train loss item: 0.31059080362319946
train loss item: 0.3024057447910309
train loss item: 0.23042164742946625
train loss item: 0.2689515948295593
train loss item: 0.18069873750209808
train loss item: 0.8145211935043335
train loss item: 0.24411973357200623
train loss item: 0.15811559557914734
train loss item: 0.3099927306175232
train loss item: 0.3743237257003784
train loss item: 2.2548959255218506
train loss item: 0.3455474078655243
test loss item: 0.1567484587430954
test loss item: 0.32524338364601135
test loss item: 0.18354667723178864
test loss item: 0.6443492770195007
test loss item: 0.248031884431839
test loss item: 0.48228785395622253
test loss item: 0.1571148782968521
test loss item: 0.15591980516910553
test loss item: 0.2755969166755676
test loss item: 0.36114421486854553
test loss item: 0.3683328330516815
test loss item: 0.19906823337078094
test loss item: 0.1932804435491562
test loss item: 0.21959657967090607
test loss item: 0.2695635259151459
test loss item: 0.4195825755596161
test loss item: 0.37004873156547546
test loss item: 0.3853686451911926
test loss item: 0.6814380884170532
test loss item: 0.30140599608421326
test loss item: 0.2276572585105896
test loss item: 0.24772590398788452
test loss item: 0.3485667109489441
test loss item: 0.21713702380657196
test loss item: 0.38144251704216003
test loss item: 0.19126345217227936
test loss item: 0.22153939306735992
test loss item: 0.4535500109195709
test loss item: 0.43874040246009827
test loss item: 0.18656742572784424
test loss item: 0.2786179184913635
test loss item: 0.19131726026535034
test loss item: 0.5063855051994324
test loss item: 0.22844058275222778
test loss item: 0.36884254217147827
test loss item: 0.41617342829704285
test loss item: 0.26360324025154114
test loss item: 0.1388445347547531
test loss item: 0.7032617926597595
test loss item: 0.1841839849948883
test loss item: 0.5050525069236755
test loss item: 0.6139421463012695
test loss item: 0.18758070468902588
test loss item: 0.1349361389875412
test loss item: 0.21195200085639954
Epoch [3/100], Training Loss: 0.4626, Testing Loss: 0.3166
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/100
train loss item: 0.5618870258331299
train loss item: 0.3722328245639801
train loss item: 0.2490004301071167
train loss item: 0.4106227159500122
train loss item: 0.21585331857204437
train loss item: 0.23959307372570038
train loss item: 0.3030990660190582
train loss item: 0.41610923409461975
train loss item: 0.19181565940380096
train loss item: 0.2672255039215088
train loss item: 0.19824333488941193
train loss item: 0.5656682848930359
train loss item: 0.28306129574775696
train loss item: 0.20236040651798248
train loss item: 0.38575372099876404
train loss item: 0.9758630990982056
train loss item: 0.30334147810935974
train loss item: 1.3312838077545166
train loss item: 0.4402458965778351
train loss item: 0.36445504426956177
train loss item: 0.21548692882061005
train loss item: 0.2280951291322708
train loss item: 0.3320624828338623
train loss item: 0.22963036596775055
train loss item: 0.17212408781051636
train loss item: 0.5709607601165771
train loss item: 0.1486683487892151
train loss item: 1.1131006479263306
train loss item: 0.22239600121974945
train loss item: 0.1416970193386078
train loss item: 1.081766963005066
train loss item: 0.2511066794395447
train loss item: 0.2881886065006256
train loss item: 0.2728324234485626
train loss item: 0.2696932852268219
train loss item: 0.20192497968673706
train loss item: 0.23364686965942383
train loss item: 0.15686996281147003
train loss item: 0.7055091857910156
train loss item: 0.23961731791496277
train loss item: 0.1528039127588272
train loss item: 0.2644255757331848
train loss item: 0.3651811182498932
train loss item: 2.0158777236938477
train loss item: 0.3106262981891632
test loss item: 0.14340484142303467
test loss item: 0.30663344264030457
test loss item: 0.17964254319667816
test loss item: 0.5757611989974976
test loss item: 0.2274440973997116
test loss item: 0.42666706442832947
test loss item: 0.14615949988365173
test loss item: 0.13580358028411865
test loss item: 0.24561995267868042
test loss item: 0.32771116495132446
test loss item: 0.33906301856040955
test loss item: 0.18428988754749298
test loss item: 0.17388392984867096
test loss item: 0.20481479167938232
test loss item: 0.24307343363761902
test loss item: 0.3703857958316803
test loss item: 0.3368488848209381
test loss item: 0.33273741602897644
test loss item: 0.6039667129516602
test loss item: 0.27708303928375244
test loss item: 0.20756562054157257
test loss item: 0.22960279881954193
test loss item: 0.30724990367889404
test loss item: 0.20498403906822205
test loss item: 0.35021117329597473
test loss item: 0.17306102812290192
test loss item: 0.21332448720932007
test loss item: 0.4067201018333435
test loss item: 0.3879269063472748
test loss item: 0.16979791224002838
test loss item: 0.25095072388648987
test loss item: 0.17552438378334045
test loss item: 0.4471025764942169
test loss item: 0.20794320106506348
test loss item: 0.33272111415863037
test loss item: 0.3695046007633209
test loss item: 0.2523035705089569
test loss item: 0.13593003153800964
test loss item: 0.5824683904647827
test loss item: 0.18316017091274261
test loss item: 0.4357914924621582
test loss item: 0.5340243577957153
test loss item: 0.17386946082115173
test loss item: 0.11617188155651093
test loss item: 0.1767515391111374
Epoch [4/100], Training Loss: 0.4103, Testing Loss: 0.2846
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/100
train loss item: 0.5013740062713623
train loss item: 0.31032848358154297
train loss item: 0.22424444556236267
train loss item: 0.3636402487754822
train loss item: 0.20785178244113922
train loss item: 0.21106576919555664
train loss item: 0.2755098342895508
train loss item: 0.41011419892311096
train loss item: 0.1712239533662796
train loss item: 0.2496809959411621
train loss item: 0.1869724541902542
train loss item: 0.5059334635734558
train loss item: 0.2949138283729553
train loss item: 0.17667461931705475
train loss item: 0.34406930208206177
train loss item: 0.8494293093681335
train loss item: 0.2649646997451782
train loss item: 1.1987065076828003
train loss item: 0.431135356426239
train loss item: 0.3233742415904999
train loss item: 0.21564146876335144
train loss item: 0.21672971546649933
train loss item: 0.30766192078590393
train loss item: 0.19931910932064056
train loss item: 0.1563977152109146
train loss item: 0.5174603462219238
train loss item: 0.1394663006067276
train loss item: 0.9935267567634583
train loss item: 0.20669110119342804
train loss item: 0.12679420411586761
train loss item: 0.9841118454933167
train loss item: 0.22322897613048553
train loss item: 0.25033268332481384
train loss item: 0.2367764115333557
train loss item: 0.23951266705989838
train loss item: 0.18053515255451202
train loss item: 0.2114439308643341
train loss item: 0.1395351141691208
train loss item: 0.6312664151191711
train loss item: 0.22452309727668762
train loss item: 0.1439131647348404
train loss item: 0.23302431404590607
train loss item: 0.37349188327789307
train loss item: 1.8478450775146484
train loss item: 0.2762938439846039
test loss item: 0.13432292640209198
test loss item: 0.2698875963687897
test loss item: 0.16619634628295898
test loss item: 0.5098472833633423
test loss item: 0.21033135056495667
test loss item: 0.3878975212574005
test loss item: 0.14286909997463226
test loss item: 0.11820726096630096
test loss item: 0.21723394095897675
test loss item: 0.29824623465538025
test loss item: 0.283408522605896
test loss item: 0.1756659895181656
test loss item: 0.15902754664421082
test loss item: 0.18850457668304443
test loss item: 0.22202034294605255
test loss item: 0.3362136483192444
test loss item: 0.2843731939792633
test loss item: 0.2979661822319031
test loss item: 0.5561423301696777
test loss item: 0.23569442331790924
test loss item: 0.18900063633918762
test loss item: 0.17881880700588226
test loss item: 0.2702197730541229
test loss item: 0.19903084635734558
test loss item: 0.3218778371810913
test loss item: 0.16384385526180267
test loss item: 0.16468198597431183
test loss item: 0.3754085600376129
test loss item: 0.3472352623939514
test loss item: 0.15991036593914032
test loss item: 0.22524623572826385
test loss item: 0.16352002322673798
test loss item: 0.38411054015159607
test loss item: 0.18911604583263397
test loss item: 0.3091127574443817
test loss item: 0.32292452454566956
test loss item: 0.24100777506828308
test loss item: 0.13480062782764435
test loss item: 0.5450472235679626
test loss item: 0.17032469809055328
test loss item: 0.38677623867988586
test loss item: 0.4849449396133423
test loss item: 0.16099335253238678
test loss item: 0.09332399815320969
test loss item: 0.16240699589252472
Epoch [5/100], Training Loss: 0.3728, Testing Loss: 0.2564
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/100
train loss item: 0.44988641142845154
train loss item: 0.27093246579170227
train loss item: 0.2079661637544632
train loss item: 0.30964550375938416
train loss item: 0.18559907376766205
train loss item: 0.1912204921245575
train loss item: 0.2342289537191391
train loss item: 0.3920990228652954
train loss item: 0.16300596296787262
train loss item: 0.23888932168483734
train loss item: 0.19406132400035858
train loss item: 0.47086137533187866
train loss item: 0.2553054094314575
train loss item: 0.15356262028217316
train loss item: 0.32063063979148865
train loss item: 0.7193990349769592
train loss item: 0.24301914870738983
train loss item: 1.0767515897750854
train loss item: 0.40787607431411743
train loss item: 0.2844446301460266
train loss item: 0.20614826679229736
train loss item: 0.1920308768749237
train loss item: 0.2868853211402893
train loss item: 0.17821799218654633
train loss item: 0.1461944580078125
train loss item: 0.4629668891429901
train loss item: 0.122275210916996
train loss item: 0.8946674466133118
train loss item: 0.19240275025367737
train loss item: 0.11612949520349503
train loss item: 0.8758742213249207
train loss item: 0.21149420738220215
train loss item: 0.23510947823524475
train loss item: 0.23900988698005676
train loss item: 0.22558818757534027
train loss item: 0.17874161899089813
train loss item: 0.19237491488456726
train loss item: 0.12507560849189758
train loss item: 0.582118034362793
train loss item: 0.2024574726819992
train loss item: 0.13249118626117706
train loss item: 0.22354823350906372
train loss item: 0.3388078808784485
train loss item: 1.7159408330917358
train loss item: 0.24550417065620422
test loss item: 0.1340607851743698
test loss item: 0.24220483005046844
test loss item: 0.15514422953128815
test loss item: 0.46529293060302734
test loss item: 0.19514508545398712
test loss item: 0.37693244218826294
test loss item: 0.13948598504066467
test loss item: 0.11864413321018219
test loss item: 0.18864358961582184
test loss item: 0.28757810592651367
test loss item: 0.2520495355129242
test loss item: 0.18057270348072052
test loss item: 0.14638762176036835
test loss item: 0.17855148017406464
test loss item: 0.20451349020004272
test loss item: 0.322742223739624
test loss item: 0.24768340587615967
test loss item: 0.2818211317062378
test loss item: 0.519569993019104
test loss item: 0.2082609087228775
test loss item: 0.1820547878742218
test loss item: 0.15688611567020416
test loss item: 0.24433763325214386
test loss item: 0.20277173817157745
test loss item: 0.3024589419364929
test loss item: 0.1549171656370163
test loss item: 0.14670492708683014
test loss item: 0.348246306180954
test loss item: 0.3248414099216461
test loss item: 0.1501992791891098
test loss item: 0.202958345413208
test loss item: 0.15449988842010498
test loss item: 0.3527458906173706
test loss item: 0.176020085811615
test loss item: 0.30298298597335815
test loss item: 0.2940640449523926
test loss item: 0.23462460935115814
test loss item: 0.13591225445270538
test loss item: 0.5034810900688171
test loss item: 0.16166161000728607
test loss item: 0.371254026889801
test loss item: 0.4629242718219757
test loss item: 0.15182191133499146
test loss item: 0.08983635157346725
test loss item: 0.14914385974407196
Epoch [6/100], Training Loss: 0.3398, Testing Loss: 0.2401
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/100
train loss item: 0.41454997658729553
train loss item: 0.26804354786872864
train loss item: 0.1916729360818863
train loss item: 0.27374932169914246
train loss item: 0.17591224610805511
train loss item: 0.1756320297718048
train loss item: 0.2303774505853653
train loss item: 0.36749327182769775
train loss item: 0.1398715227842331
train loss item: 0.22419755160808563
train loss item: 0.18504679203033447
train loss item: 0.45341071486473083
train loss item: 0.2481386363506317
train loss item: 0.14237727224826813
train loss item: 0.30714333057403564
train loss item: 0.6249163150787354
train loss item: 0.19745318591594696
train loss item: 0.9597494602203369
train loss item: 0.3917326033115387
train loss item: 0.2718021273612976
train loss item: 0.20099900662899017
train loss item: 0.17240512371063232
train loss item: 0.2829882502555847
train loss item: 0.1633988469839096
train loss item: 0.14148171246051788
train loss item: 0.4645848572254181
train loss item: 0.11329657584428787
train loss item: 0.8131594061851501
train loss item: 0.18404170870780945
train loss item: 0.10973693430423737
train loss item: 0.8055751323699951
train loss item: 0.19485902786254883
train loss item: 0.20967580378055573
train loss item: 0.21634873747825623
train loss item: 0.21603897213935852
train loss item: 0.169912651181221
train loss item: 0.18605192005634308
train loss item: 0.12169608473777771
train loss item: 0.5088026523590088
train loss item: 0.18436655402183533
train loss item: 0.11889767646789551
train loss item: 0.2062525749206543
train loss item: 0.34538379311561584
train loss item: 1.6342169046401978
train loss item: 0.21319052577018738
test loss item: 0.13626126945018768
test loss item: 0.22541064023971558
test loss item: 0.15676189959049225
test loss item: 0.43823498487472534
test loss item: 0.18042749166488647
test loss item: 0.338851660490036
test loss item: 0.1396511197090149
test loss item: 0.12104396522045135
test loss item: 0.17659509181976318
test loss item: 0.27170777320861816
test loss item: 0.24022959172725677
test loss item: 0.18207883834838867
test loss item: 0.13782164454460144
test loss item: 0.17194350063800812
test loss item: 0.19489185512065887
test loss item: 0.29474011063575745
test loss item: 0.22981835901737213
test loss item: 0.2642546594142914
test loss item: 0.47157400846481323
test loss item: 0.19928225874900818
test loss item: 0.18244311213493347
test loss item: 0.15014441311359406
test loss item: 0.2294088751077652
test loss item: 0.20566432178020477
test loss item: 0.2749324142932892
test loss item: 0.150980144739151
test loss item: 0.14523237943649292
test loss item: 0.3148833215236664
test loss item: 0.30023783445358276
test loss item: 0.14690694212913513
test loss item: 0.18690435588359833
test loss item: 0.15010209381580353
test loss item: 0.3357245624065399
test loss item: 0.1681685745716095
test loss item: 0.2854636013507843
test loss item: 0.2780090570449829
test loss item: 0.22907018661499023
test loss item: 0.14284847676753998
test loss item: 0.4634464383125305
test loss item: 0.1644568145275116
test loss item: 0.33590593934059143
test loss item: 0.4184356927871704
test loss item: 0.14570340514183044
test loss item: 0.08862804621458054
test loss item: 0.15084011852741241
Epoch [7/100], Training Loss: 0.3160, Testing Loss: 0.2270
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/100
train loss item: 0.36784061789512634
train loss item: 0.24950067698955536
train loss item: 0.18349333107471466
train loss item: 0.2408403605222702
train loss item: 0.1685318499803543
train loss item: 0.16613341867923737
train loss item: 0.21648409962654114
train loss item: 0.337696373462677
train loss item: 0.1253076046705246
train loss item: 0.20154008269309998
train loss item: 0.16166839003562927
train loss item: 0.4234488904476166
train loss item: 0.22996783256530762
train loss item: 0.13502463698387146
train loss item: 0.29763707518577576
train loss item: 0.5143784284591675
train loss item: 0.1808212250471115
train loss item: 0.8667436838150024
train loss item: 0.38528600335121155
train loss item: 0.24839942157268524
train loss item: 0.19692890346050262
train loss item: 0.16079145669937134
train loss item: 0.25983643531799316
train loss item: 0.15004892647266388
train loss item: 0.1256919950246811
train loss item: 0.4373195767402649
train loss item: 0.1183590218424797
train loss item: 0.7142419219017029
train loss item: 0.16697648167610168
train loss item: 0.10748367011547089
train loss item: 0.7046895027160645
train loss item: 0.17807410657405853
train loss item: 0.18322856724262238
train loss item: 0.20024827122688293
train loss item: 0.19781407713890076
train loss item: 0.1543402522802353
train loss item: 0.17256595194339752
train loss item: 0.10739023983478546
train loss item: 0.4688865542411804
train loss item: 0.16113485395908356
train loss item: 0.11181340366601944
train loss item: 0.19108273088932037
train loss item: 0.3211846351623535
train loss item: 1.501360297203064
train loss item: 0.2077721506357193
test loss item: 0.1177375316619873
test loss item: 0.21245895326137543
test loss item: 0.13517913222312927
test loss item: 0.3906194865703583
test loss item: 0.16884319484233856
test loss item: 0.3053142726421356
test loss item: 0.13909098505973816
test loss item: 0.10500095784664154
test loss item: 0.16523024439811707
test loss item: 0.24618013203144073
test loss item: 0.2233904004096985
test loss item: 0.17857451736927032
test loss item: 0.13167832791805267
test loss item: 0.15475240349769592
test loss item: 0.1777571588754654
test loss item: 0.2635396718978882
test loss item: 0.21417200565338135
test loss item: 0.23878416419029236
test loss item: 0.42573976516723633
test loss item: 0.18484432995319366
test loss item: 0.17094393074512482
test loss item: 0.1413283497095108
test loss item: 0.2129966765642166
test loss item: 0.19221976399421692
test loss item: 0.2563619613647461
test loss item: 0.14486943185329437
test loss item: 0.1353897601366043
test loss item: 0.27811160683631897
test loss item: 0.2652778923511505
test loss item: 0.1432388871908188
test loss item: 0.17704151570796967
test loss item: 0.14219816029071808
test loss item: 0.3038955330848694
test loss item: 0.15733391046524048
test loss item: 0.25734812021255493
test loss item: 0.24675698578357697
test loss item: 0.22132423520088196
test loss item: 0.13157080113887787
test loss item: 0.44050583243370056
test loss item: 0.1442861407995224
test loss item: 0.29807960987091064
test loss item: 0.3811245560646057
test loss item: 0.1400591880083084
test loss item: 0.07555555552244186
test loss item: 0.166922926902771
Epoch [8/100], Training Loss: 0.2889, Testing Loss: 0.2090
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/100
train loss item: 0.3302418291568756
train loss item: 0.22403936088085175
train loss item: 0.17211875319480896
train loss item: 0.21256420016288757
train loss item: 0.14980654418468475
train loss item: 0.15224815905094147
train loss item: 0.2266535460948944
train loss item: 0.3215705454349518
train loss item: 0.11121034622192383
train loss item: 0.18310467898845673
train loss item: 0.14648160338401794
train loss item: 0.40348565578460693
train loss item: 0.20336025953292847
train loss item: 0.12599597871303558
train loss item: 0.2718138098716736
train loss item: 0.4219495356082916
train loss item: 0.1730349063873291
train loss item: 0.7368584275245667
train loss item: 0.3975406587123871
train loss item: 0.23392324149608612
train loss item: 0.1839410662651062
train loss item: 0.15467926859855652
train loss item: 0.24628481268882751
train loss item: 0.14221394062042236
train loss item: 0.12027032673358917
train loss item: 0.40926358103752136
train loss item: 0.11785285919904709
train loss item: 0.5831753015518188
train loss item: 0.15283595025539398
train loss item: 0.09802483767271042
train loss item: 0.5840398669242859
train loss item: 0.1682746559381485
train loss item: 0.1680750846862793
train loss item: 0.20082467794418335
train loss item: 0.1791709065437317
train loss item: 0.14952269196510315
train loss item: 0.16032204031944275
train loss item: 0.09691616147756577
train loss item: 0.42502012848854065
train loss item: 0.14469069242477417
train loss item: 0.12223520874977112
train loss item: 0.1792389154434204
train loss item: 0.2772405743598938
train loss item: 1.3736014366149902
train loss item: 0.2033366858959198
test loss item: 0.11311081051826477
test loss item: 0.18484236299991608
test loss item: 0.12169858068227768
test loss item: 0.3644486665725708
test loss item: 0.14850309491157532
test loss item: 0.264989972114563
test loss item: 0.12849077582359314
test loss item: 0.09587249904870987
test loss item: 0.14719507098197937
test loss item: 0.22648239135742188
test loss item: 0.201063871383667
test loss item: 0.18377240002155304
test loss item: 0.11817418038845062
test loss item: 0.1362069696187973
test loss item: 0.15790009498596191
test loss item: 0.22952765226364136
test loss item: 0.1827385127544403
test loss item: 0.21693433821201324
test loss item: 0.37003934383392334
test loss item: 0.16175462305545807
test loss item: 0.17315290868282318
test loss item: 0.12692485749721527
test loss item: 0.1909516453742981
test loss item: 0.2015809416770935
test loss item: 0.22216390073299408
test loss item: 0.12948067486286163
test loss item: 0.12217728793621063
test loss item: 0.22750894725322723
test loss item: 0.2427314966917038
test loss item: 0.13007718324661255
test loss item: 0.15684086084365845
test loss item: 0.13163825869560242
test loss item: 0.2710028886795044
test loss item: 0.14216072857379913
test loss item: 0.2362583875656128
test loss item: 0.22690033912658691
test loss item: 0.20303773880004883
test loss item: 0.13828402757644653
test loss item: 0.3551681935787201
test loss item: 0.1375318467617035
test loss item: 0.27216798067092896
test loss item: 0.3282991051673889
test loss item: 0.13064239919185638
test loss item: 0.0715370699763298
test loss item: 0.14215025305747986
Epoch [9/100], Training Loss: 0.2631, Testing Loss: 0.1881
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/100
train loss item: 0.29187530279159546
train loss item: 0.2128784954547882
train loss item: 0.16123956441879272
train loss item: 0.19921891391277313
train loss item: 0.1401684433221817
train loss item: 0.14485691487789154
train loss item: 0.22190387547016144
train loss item: 0.29056307673454285
train loss item: 0.10331331938505173
train loss item: 0.1700706034898758
train loss item: 0.13084116578102112
train loss item: 0.3605635166168213
train loss item: 0.1915607452392578
train loss item: 0.1213129460811615
train loss item: 0.2429976910352707
train loss item: 0.3962511718273163
train loss item: 0.16313625872135162
train loss item: 0.6621583700180054
train loss item: 0.3682883679866791
train loss item: 0.20311768352985382
train loss item: 0.16183900833129883
train loss item: 0.16023753583431244
train loss item: 0.22252614796161652
train loss item: 0.13650193810462952
train loss item: 0.11743287742137909
train loss item: 0.36222130060195923
train loss item: 0.10197269916534424
train loss item: 0.5320253372192383
train loss item: 0.15651357173919678
train loss item: 0.09390117973089218
train loss item: 0.509249210357666
train loss item: 0.16178938746452332
train loss item: 0.15966235101222992
train loss item: 0.20981435477733612
train loss item: 0.17002639174461365
train loss item: 0.13701122999191284
train loss item: 0.14898106455802917
train loss item: 0.09256220608949661
train loss item: 0.41766098141670227
train loss item: 0.13805781304836273
train loss item: 0.11330712586641312
train loss item: 0.18175268173217773
train loss item: 0.22302955389022827
train loss item: 1.3010591268539429
train loss item: 0.21258075535297394
test loss item: 0.1093963086605072
test loss item: 0.17352086305618286
test loss item: 0.12075795233249664
test loss item: 0.3295615613460541
test loss item: 0.13816601037979126
test loss item: 0.24634750187397003
test loss item: 0.12015548348426819
test loss item: 0.10266722738742828
test loss item: 0.1322946399450302
test loss item: 0.19731055200099945
test loss item: 0.18664567172527313
test loss item: 0.15989863872528076
test loss item: 0.11059729754924774
test loss item: 0.1278533935546875
test loss item: 0.14528538286685944
test loss item: 0.20872630178928375
test loss item: 0.1673319786787033
test loss item: 0.20088325440883636
test loss item: 0.33287179470062256
test loss item: 0.14958986639976501
test loss item: 0.15235669910907745
test loss item: 0.11917900294065475
test loss item: 0.17352333664894104
test loss item: 0.16684050858020782
test loss item: 0.20281395316123962
test loss item: 0.12076814472675323
test loss item: 0.11703765392303467
test loss item: 0.20908759534358978
test loss item: 0.2333499789237976
test loss item: 0.1230529248714447
test loss item: 0.1407739818096161
test loss item: 0.12020409107208252
test loss item: 0.26270776987075806
test loss item: 0.13510505855083466
test loss item: 0.2119898647069931
test loss item: 0.20782150328159332
test loss item: 0.17220282554626465
test loss item: 0.11520545929670334
test loss item: 0.3323996961116791
test loss item: 0.12296420335769653
test loss item: 0.2553800344467163
test loss item: 0.3013341426849365
test loss item: 0.12131894379854202
test loss item: 0.08406568318605423
test loss item: 0.13791051506996155
Epoch [10/100], Training Loss: 0.2444, Testing Loss: 0.1733
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 11/100
train loss item: 0.34769773483276367
train loss item: 0.20171275734901428
train loss item: 0.1564682424068451
train loss item: 0.19840805232524872
train loss item: 0.1273791342973709
train loss item: 0.13708417117595673
train loss item: 0.21807728707790375
train loss item: 0.2900969088077545
train loss item: 0.09475115686655045
train loss item: 0.16952109336853027
train loss item: 0.11234766244888306
train loss item: 0.3464181423187256
train loss item: 0.1817818284034729
train loss item: 0.11960454285144806
train loss item: 0.2550179660320282
train loss item: 0.37402868270874023
train loss item: 0.15187543630599976
train loss item: 0.6274034976959229
train loss item: 0.2956579327583313
train loss item: 0.16168208420276642
train loss item: 0.13296447694301605
train loss item: 0.13964882493019104
train loss item: 0.2613951861858368
train loss item: 0.13610269129276276
train loss item: 0.13236218690872192
train loss item: 0.42029762268066406
train loss item: 0.10259725898504257
train loss item: 0.7007268071174622
train loss item: 0.1589992344379425
train loss item: 0.09366732835769653
train loss item: 0.48237335681915283
train loss item: 0.17213983833789825
train loss item: 0.16566234827041626
train loss item: 0.1739329993724823
train loss item: 0.22052253782749176
train loss item: 0.16613219678401947
train loss item: 0.1278107613325119
train loss item: 0.09001350402832031
train loss item: 0.4006875455379486
train loss item: 0.13072910904884338
train loss item: 0.11306418478488922
train loss item: 0.22763773798942566
train loss item: 0.23585082590579987
train loss item: 1.2788242101669312
train loss item: 0.17599846422672272
test loss item: 0.10521688312292099
test loss item: 0.185108944773674
test loss item: 0.12129636853933334
test loss item: 0.3506161868572235
test loss item: 0.15608912706375122
test loss item: 0.27378547191619873
test loss item: 0.12559038400650024
test loss item: 0.09766145050525665
test loss item: 0.1410522311925888
test loss item: 0.20951081812381744
test loss item: 0.18966472148895264
test loss item: 0.12382061034440994
test loss item: 0.11573658138513565
test loss item: 0.13817505538463593
test loss item: 0.15884438157081604
test loss item: 0.24553509056568146
test loss item: 0.18188677728176117
test loss item: 0.2278747856616974
test loss item: 0.36794108152389526
test loss item: 0.15795087814331055
test loss item: 0.13901735842227936
test loss item: 0.12472759932279587
test loss item: 0.17489910125732422
test loss item: 0.14287425577640533
test loss item: 0.23774109780788422
test loss item: 0.13535746932029724
test loss item: 0.12488117069005966
test loss item: 0.2668992578983307
test loss item: 0.23373477160930634
test loss item: 0.13315698504447937
test loss item: 0.15601523220539093
test loss item: 0.1274394392967224
test loss item: 0.27036377787590027
test loss item: 0.13389356434345245
test loss item: 0.2206151932477951
test loss item: 0.21516574919223785
test loss item: 0.15478338301181793
test loss item: 0.09789932519197464
test loss item: 0.34916990995407104
test loss item: 0.12373565882444382
test loss item: 0.2649439573287964
test loss item: 0.3389194905757904
test loss item: 0.11911504715681076
test loss item: 0.06824343651533127
test loss item: 0.15095524489879608
Epoch [11/100], Training Loss: 0.2446, Testing Loss: 0.1817
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 12/100
train loss item: 0.3332742154598236
train loss item: 0.24334947764873505
train loss item: 0.16457530856132507
train loss item: 0.25891146063804626
train loss item: 0.12135058641433716
train loss item: 0.13682743906974792
train loss item: 0.2114284187555313
train loss item: 0.25048938393592834
train loss item: 0.10459020733833313
train loss item: 0.1633760929107666
train loss item: 0.12144509702920914
train loss item: 0.46107935905456543
train loss item: 0.1915043592453003
train loss item: 0.1410498172044754
train loss item: 0.23830711841583252
train loss item: 0.626175045967102
train loss item: 0.1518000215291977
train loss item: 0.7906274199485779
train loss item: 0.5453334450721741
train loss item: 0.43716418743133545
train loss item: 0.3064177334308624
train loss item: 0.2606755793094635
train loss item: 0.3526947796344757
train loss item: 0.25995996594429016
train loss item: 0.13182790577411652
train loss item: 0.336385577917099
train loss item: 0.08853573352098465
train loss item: 0.6757394671440125
train loss item: 0.15719474852085114
train loss item: 0.10120724886655807
train loss item: 0.5871472358703613
train loss item: 0.18985623121261597
train loss item: 0.18398398160934448
train loss item: 0.19028879702091217
train loss item: 0.19711847603321075
train loss item: 0.1535181999206543
train loss item: 0.135325089097023
train loss item: 0.09683378785848618
train loss item: 0.38496726751327515
train loss item: 0.14007793366909027
train loss item: 0.10591001063585281
train loss item: 0.1822628676891327
train loss item: 0.2985135614871979
train loss item: 1.2272545099258423
train loss item: 0.20560504496097565
test loss item: 0.1086798906326294
test loss item: 0.22480562329292297
test loss item: 0.13455802202224731
test loss item: 0.3863317370414734
test loss item: 0.16983895003795624
test loss item: 0.32338303327560425
test loss item: 0.1266985535621643
test loss item: 0.10178497433662415
test loss item: 0.1634293496608734
test loss item: 0.20997068285942078
test loss item: 0.21669788658618927
test loss item: 0.13839557766914368
test loss item: 0.11750885844230652
test loss item: 0.1415783017873764
test loss item: 0.17281053960323334
test loss item: 0.27480071783065796
test loss item: 0.22162063419818878
test loss item: 0.2501993179321289
test loss item: 0.43695345520973206
test loss item: 0.17905429005622864
test loss item: 0.14243373274803162
test loss item: 0.14021968841552734
test loss item: 0.19539742171764374
test loss item: 0.140072301030159
test loss item: 0.25750523805618286
test loss item: 0.14758174121379852
test loss item: 0.13185147941112518
test loss item: 0.30532941222190857
test loss item: 0.25255918502807617
test loss item: 0.13616029918193817
test loss item: 0.17444247007369995
test loss item: 0.12390162795782089
test loss item: 0.30127254128456116
test loss item: 0.1395576298236847
test loss item: 0.23626741766929626
test loss item: 0.23166027665138245
test loss item: 0.1678166538476944
test loss item: 0.09767366200685501
test loss item: 0.4793970584869385
test loss item: 0.12389121204614639
test loss item: 0.3115977942943573
test loss item: 0.40678322315216064
test loss item: 0.1234147846698761
test loss item: 0.0638963058590889
test loss item: 0.13413462042808533
Epoch [12/100], Training Loss: 0.2809, Testing Loss: 0.2014
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 13/100
train loss item: 0.26499253511428833
train loss item: 0.20863762497901917
train loss item: 0.15868768095970154
train loss item: 0.19611142575740814
train loss item: 0.14536508917808533
train loss item: 0.1348436176776886
train loss item: 0.20306864380836487
train loss item: 0.24555659294128418
train loss item: 0.10076364129781723
train loss item: 0.16846030950546265
train loss item: 0.1264249086380005
train loss item: 0.39794713258743286
train loss item: 0.16402332484722137
train loss item: 0.13150086998939514
train loss item: 0.24600788950920105
train loss item: 0.35558417439460754
train loss item: 0.1711929589509964
train loss item: 0.5734730958938599
train loss item: 0.25230666995048523
train loss item: 0.15493059158325195
train loss item: 0.13718350231647491
train loss item: 0.18320171535015106
train loss item: 0.21732038259506226
train loss item: 0.13506945967674255
train loss item: 0.10531764477491379
train loss item: 0.3236692547798157
train loss item: 0.08049490302801132
train loss item: 0.4553273618221283
train loss item: 0.13270367681980133
train loss item: 0.08755192905664444
train loss item: 0.47668036818504333
train loss item: 0.16892382502555847
train loss item: 0.14500410854816437
train loss item: 0.15445642173290253
train loss item: 0.16114279627799988
train loss item: 0.13064877688884735
train loss item: 0.11943468451499939
train loss item: 0.09012256562709808
train loss item: 0.36054089665412903
train loss item: 0.12241599708795547
train loss item: 0.09432975947856903
train loss item: 0.17350155115127563
train loss item: 0.22890856862068176
train loss item: 1.146410584449768
train loss item: 0.18378198146820068
test loss item: 0.10039083659648895
test loss item: 0.184522345662117
test loss item: 0.11916891485452652
test loss item: 0.3240754008293152
test loss item: 0.15807035565376282
test loss item: 0.25349345803260803
test loss item: 0.13366341590881348
test loss item: 0.09175091236829758
test loss item: 0.1384328007698059
test loss item: 0.19971288740634918
test loss item: 0.18469421565532684
test loss item: 0.11411916464567184
test loss item: 0.10929567366838455
test loss item: 0.13185633718967438
test loss item: 0.15446940064430237
test loss item: 0.22228750586509705
test loss item: 0.17851446568965912
test loss item: 0.2296726107597351
test loss item: 0.34356021881103516
test loss item: 0.15364237129688263
test loss item: 0.13692732155323029
test loss item: 0.1264960616827011
test loss item: 0.16492363810539246
test loss item: 0.13417525589466095
test loss item: 0.22156035900115967
test loss item: 0.14154544472694397
test loss item: 0.12677349150180817
test loss item: 0.24393579363822937
test loss item: 0.22157856822013855
test loss item: 0.1351521909236908
test loss item: 0.154946967959404
test loss item: 0.12319448590278625
test loss item: 0.26230284571647644
test loss item: 0.12683112919330597
test loss item: 0.21396617591381073
test loss item: 0.20193585753440857
test loss item: 0.14292897284030914
test loss item: 0.09215987473726273
test loss item: 0.33057644963264465
test loss item: 0.11920211464166641
test loss item: 0.25064802169799805
test loss item: 0.31907376646995544
test loss item: 0.11821632087230682
test loss item: 0.06152801215648651
test loss item: 0.16791225969791412
Epoch [13/100], Training Loss: 0.2225, Testing Loss: 0.1748
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 14/100
train loss item: 0.28487154841423035
train loss item: 0.25127461552619934
train loss item: 0.170387402176857
train loss item: 0.18405179679393768
train loss item: 0.1437181979417801
train loss item: 0.14385324716567993
train loss item: 0.22963713109493256
train loss item: 0.2233196496963501
train loss item: 0.09837047010660172
train loss item: 0.15628105401992798
train loss item: 0.1265106350183487
train loss item: 0.42934978008270264
train loss item: 0.22764350473880768
train loss item: 0.12502440810203552
train loss item: 0.23839567601680756
train loss item: 0.2932150959968567
train loss item: 0.12149582803249359
train loss item: 0.5299999713897705
train loss item: 0.33285248279571533
train loss item: 0.1708124727010727
train loss item: 0.18715104460716248
train loss item: 0.13877110183238983
train loss item: 0.24232643842697144
train loss item: 0.13282345235347748
train loss item: 0.11212765425443649
train loss item: 0.27495574951171875
train loss item: 0.08907103538513184
train loss item: 0.39468222856521606
train loss item: 0.14035546779632568
train loss item: 0.08844342827796936
train loss item: 0.38698452711105347
train loss item: 0.14649590849876404
train loss item: 0.16279245913028717
train loss item: 0.15672659873962402
train loss item: 0.15673699975013733
train loss item: 0.12401065230369568
train loss item: 0.1241181418299675
train loss item: 0.0837625041604042
train loss item: 0.3039458394050598
train loss item: 0.13580681383609772
train loss item: 0.09703473001718521
train loss item: 0.17428316175937653
train loss item: 0.1987435668706894
train loss item: 1.086207628250122
train loss item: 0.1865399032831192
test loss item: 0.09888739138841629
test loss item: 0.1586453914642334
test loss item: 0.10897069424390793
test loss item: 0.3175095319747925
test loss item: 0.12625737488269806
test loss item: 0.21331734955310822
test loss item: 0.11716631054878235
test loss item: 0.08226065337657928
test loss item: 0.1277536153793335
test loss item: 0.17689479887485504
test loss item: 0.17037397623062134
test loss item: 0.130719855427742
test loss item: 0.10901941359043121
test loss item: 0.11445822566747665
test loss item: 0.13311684131622314
test loss item: 0.189091295003891
test loss item: 0.14661292731761932
test loss item: 0.16933134198188782
test loss item: 0.29244932532310486
test loss item: 0.1380755454301834
test loss item: 0.14129388332366943
test loss item: 0.11051248013973236
test loss item: 0.1572355180978775
test loss item: 0.14079806208610535
test loss item: 0.18181529641151428
test loss item: 0.11056975275278091
test loss item: 0.11283807456493378
test loss item: 0.18627244234085083
test loss item: 0.19287355244159698
test loss item: 0.12006669491529465
test loss item: 0.12731683254241943
test loss item: 0.12361092120409012
test loss item: 0.22468920052051544
test loss item: 0.12647834420204163
test loss item: 0.1797979474067688
test loss item: 0.20015451312065125
test loss item: 0.1737043857574463
test loss item: 0.09815992414951324
test loss item: 0.29059961438179016
test loss item: 0.11832495778799057
test loss item: 0.22696326673030853
test loss item: 0.2633252441883087
test loss item: 0.11431024223566055
test loss item: 0.054100316017866135
test loss item: 0.15235130488872528
Epoch [14/100], Training Loss: 0.2179, Testing Loss: 0.1566
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 15/100
train loss item: 0.2697738707065582
train loss item: 0.3398718237876892
train loss item: 0.14116239547729492
train loss item: 0.2147514671087265
train loss item: 0.15270933508872986
train loss item: 0.16241219639778137
train loss item: 0.2631114721298218
train loss item: 0.26311758160591125
train loss item: 0.09711399674415588
train loss item: 0.14634765684604645
train loss item: 0.0972418561577797
train loss item: 0.4613339900970459
train loss item: 0.17427915334701538
train loss item: 0.11666421592235565
train loss item: 0.23835110664367676
train loss item: 0.46034958958625793
train loss item: 0.16536444425582886
train loss item: 0.6886532306671143
train loss item: 0.3690815567970276
train loss item: 0.2526901364326477
train loss item: 0.21800853312015533
train loss item: 0.21066665649414062
train loss item: 0.2811274826526642
train loss item: 0.16991659998893738
train loss item: 0.11342322826385498
train loss item: 0.27753040194511414
train loss item: 0.09737018495798111
train loss item: 0.5697122812271118
train loss item: 0.14713600277900696
train loss item: 0.09650927037000656
train loss item: 0.584470272064209
train loss item: 0.1670522391796112
train loss item: 0.17116403579711914
train loss item: 0.1714138388633728
train loss item: 0.16913343966007233
train loss item: 0.13480521738529205
train loss item: 0.12362292408943176
train loss item: 0.08146250993013382
train loss item: 0.34678205847740173
train loss item: 0.13319829106330872
train loss item: 0.0929294005036354
train loss item: 0.181867316365242
train loss item: 0.22803863883018494
train loss item: 1.128334403038025
train loss item: 0.2006843239068985
test loss item: 0.10122977942228317
test loss item: 0.19623970985412598
test loss item: 0.12324711680412292
test loss item: 0.4583570063114166
test loss item: 0.1439688801765442
test loss item: 0.2990528345108032
test loss item: 0.11741563677787781
test loss item: 0.08996453881263733
test loss item: 0.1514711081981659
test loss item: 0.20193490386009216
test loss item: 0.20118296146392822
test loss item: 0.11559724807739258
test loss item: 0.11392378062009811
test loss item: 0.12839801609516144
test loss item: 0.1488887518644333
test loss item: 0.28471457958221436
test loss item: 0.1827985793352127
test loss item: 0.19966059923171997
test loss item: 0.41236820816993713
test loss item: 0.16254687309265137
test loss item: 0.15010526776313782
test loss item: 0.13726401329040527
test loss item: 0.16926230490207672
test loss item: 0.12650279700756073
test loss item: 0.22367163002490997
test loss item: 0.12342306971549988
test loss item: 0.13788336515426636
test loss item: 0.2552436590194702
test loss item: 0.23877203464508057
test loss item: 0.12801875174045563
test loss item: 0.1476232409477234
test loss item: 0.12278493493795395
test loss item: 0.2980060279369354
test loss item: 0.13285808265209198
test loss item: 0.21023152768611908
test loss item: 0.278943806886673
test loss item: 0.16421014070510864
test loss item: 0.10155853629112244
test loss item: 0.47776272892951965
test loss item: 0.12694339454174042
test loss item: 0.31350812315940857
test loss item: 0.39317774772644043
test loss item: 0.12706327438354492
test loss item: 0.059034693986177444
test loss item: 0.1573101133108139
Epoch [15/100], Training Loss: 0.2482, Testing Loss: 0.1919
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 16/100
train loss item: 0.2731782793998718
train loss item: 0.20292611420154572
train loss item: 0.14658625423908234
train loss item: 0.26799914240837097
train loss item: 0.1222694143652916
train loss item: 0.13493572175502777
train loss item: 0.20369650423526764
train loss item: 0.25086453557014465
train loss item: 0.0827488899230957
train loss item: 0.14588508009910583
train loss item: 0.09708511084318161
train loss item: 0.4641195237636566
train loss item: 0.16053998470306396
train loss item: 0.12926769256591797
train loss item: 0.19813068211078644
train loss item: 0.35967323184013367
train loss item: 0.11994921416044235
train loss item: 0.5132817625999451
train loss item: 0.3744561970233917
train loss item: 0.2550738751888275
train loss item: 0.15503354370594025
train loss item: 0.1606856733560562
train loss item: 0.23993515968322754
train loss item: 0.12319745868444443
train loss item: 0.09995678812265396
train loss item: 0.27808472514152527
train loss item: 0.07896610349416733
train loss item: 0.39210188388824463
train loss item: 0.12568628787994385
train loss item: 0.08084794878959656
train loss item: 0.38929834961891174
train loss item: 0.14493919909000397
train loss item: 0.13539671897888184
train loss item: 0.15781128406524658
train loss item: 0.16927102208137512
train loss item: 0.13522480428218842
train loss item: 0.11370169371366501
train loss item: 0.07825552672147751
train loss item: 0.3218105435371399
train loss item: 0.11434408277273178
train loss item: 0.08973988890647888
train loss item: 0.16564178466796875
train loss item: 0.208051860332489
train loss item: 1.0349425077438354
train loss item: 0.18327632546424866
test loss item: 0.09924588352441788
test loss item: 0.18479005992412567
test loss item: 0.1062895655632019
test loss item: 0.3470754623413086
test loss item: 0.13901112973690033
test loss item: 0.25125616788864136
test loss item: 0.11837856471538544
test loss item: 0.08205531537532806
test loss item: 0.14198696613311768
test loss item: 0.17950110137462616
test loss item: 0.179574117064476
test loss item: 0.12382594496011734
test loss item: 0.1132097989320755
test loss item: 0.11489872634410858
test loss item: 0.13639695942401886
test loss item: 0.22179998457431793
test loss item: 0.16722194850444794
test loss item: 0.180143803358078
test loss item: 0.33584821224212646
test loss item: 0.14687788486480713
test loss item: 0.15160967409610748
test loss item: 0.1278829127550125
test loss item: 0.15623727440834045
test loss item: 0.13982535898685455
test loss item: 0.20045605301856995
test loss item: 0.11905430257320404
test loss item: 0.12679533660411835
test loss item: 0.2223232090473175
test loss item: 0.20360414683818817
test loss item: 0.12406466901302338
test loss item: 0.13480272889137268
test loss item: 0.12309180945158005
test loss item: 0.24696913361549377
test loss item: 0.12292841821908951
test loss item: 0.19239473342895508
test loss item: 0.21503698825836182
test loss item: 0.15379513800144196
test loss item: 0.10692767798900604
test loss item: 0.36438819766044617
test loss item: 0.11784891039133072
test loss item: 0.25497105717658997
test loss item: 0.3100329637527466
test loss item: 0.12416919320821762
test loss item: 0.0594199076294899
test loss item: 0.18012358248233795
Epoch [16/100], Training Loss: 0.2151, Testing Loss: 0.1700
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 17/100
train loss item: 0.26907092332839966
train loss item: 0.20000019669532776
train loss item: 0.1351778209209442
train loss item: 0.1833457052707672
train loss item: 0.13041570782661438
train loss item: 0.1401609182357788
train loss item: 0.23291373252868652
train loss item: 0.24996274709701538
train loss item: 0.08412501960992813
train loss item: 0.15598268806934357
train loss item: 0.1037529781460762
train loss item: 0.4367082715034485
train loss item: 0.18270529806613922
train loss item: 0.13078755140304565
train loss item: 0.205978661775589
train loss item: 0.30492347478866577
train loss item: 0.11542711406946182
train loss item: 0.4479755163192749
train loss item: 0.29098841547966003
train loss item: 0.18300475180149078
train loss item: 0.14378131926059723
train loss item: 0.15464435517787933
train loss item: 0.22439426183700562
train loss item: 0.12693904340267181
train loss item: 0.102988600730896
train loss item: 0.2524929642677307
train loss item: 0.07728447765111923
train loss item: 0.32090678811073303
train loss item: 0.1222073882818222
train loss item: 0.07871880382299423
train loss item: 0.3414289355278015
train loss item: 0.14344705641269684
train loss item: 0.1322719305753708
train loss item: 0.15769444406032562
train loss item: 0.15551282465457916
train loss item: 0.11936262249946594
train loss item: 0.10898710787296295
train loss item: 0.07576538622379303
train loss item: 0.30527639389038086
train loss item: 0.11675291508436203
train loss item: 0.08336640149354935
train loss item: 0.15138402581214905
train loss item: 0.1710255742073059
train loss item: 0.9745721817016602
train loss item: 0.18362487852573395
test loss item: 0.09718059748411179
test loss item: 0.1646428257226944
test loss item: 0.10378462821245193
test loss item: 0.3001568615436554
test loss item: 0.1233750730752945
test loss item: 0.2263060212135315
test loss item: 0.10518841445446014
test loss item: 0.07920722663402557
test loss item: 0.12784862518310547
test loss item: 0.15639910101890564
test loss item: 0.16385765373706818
test loss item: 0.116303950548172
test loss item: 0.10903488099575043
test loss item: 0.10784786194562912
test loss item: 0.12497810274362564
test loss item: 0.19771161675453186
test loss item: 0.15304727852344513
test loss item: 0.16225537657737732
test loss item: 0.3030632734298706
test loss item: 0.1354757845401764
test loss item: 0.13806937634944916
test loss item: 0.11420614272356033
test loss item: 0.14130491018295288
test loss item: 0.12810379266738892
test loss item: 0.18026559054851532
test loss item: 0.10623745620250702
test loss item: 0.11599043756723404
test loss item: 0.19748590886592865
test loss item: 0.1856258064508438
test loss item: 0.11508884280920029
test loss item: 0.12385718524456024
test loss item: 0.11477722227573395
test loss item: 0.21864718198776245
test loss item: 0.11449183523654938
test loss item: 0.17243538796901703
test loss item: 0.18243232369422913
test loss item: 0.14375756680965424
test loss item: 0.09493305534124374
test loss item: 0.34643349051475525
test loss item: 0.10961680114269257
test loss item: 0.22795531153678894
test loss item: 0.2777901291847229
test loss item: 0.11350660026073456
test loss item: 0.059102244675159454
test loss item: 0.15377214550971985
Epoch [17/100], Training Loss: 0.2002, Testing Loss: 0.1541
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 18/100
train loss item: 0.24691012501716614
train loss item: 0.21433664858341217
train loss item: 0.15126647055149078
train loss item: 0.16250991821289062
train loss item: 0.11768773943185806
train loss item: 0.13333362340927124
train loss item: 0.2126692533493042
train loss item: 0.20404382050037384
train loss item: 0.07892615348100662
train loss item: 0.1365014612674713
train loss item: 0.10181239247322083
train loss item: 0.2869105637073517
train loss item: 0.15294845402240753
train loss item: 0.12908142805099487
train loss item: 0.19248339533805847
train loss item: 0.3440585732460022
train loss item: 0.12451827526092529
train loss item: 0.37083718180656433
train loss item: 0.2555425465106964
train loss item: 0.14615195989608765
train loss item: 0.10578825324773788
train loss item: 0.1366652548313141
train loss item: 0.18966630101203918
train loss item: 0.11052272468805313
train loss item: 0.09822707623243332
train loss item: 0.24638211727142334
train loss item: 0.08345644921064377
train loss item: 0.3645167648792267
train loss item: 0.1197177916765213
train loss item: 0.07870810478925705
train loss item: 0.33080488443374634
train loss item: 0.1708303987979889
train loss item: 0.13881640136241913
train loss item: 0.13935348391532898
train loss item: 0.16077356040477753
train loss item: 0.11424939334392548
train loss item: 0.10940027236938477
train loss item: 0.0715406984090805
train loss item: 0.33834072947502136
train loss item: 0.11190211027860641
train loss item: 0.0846504420042038
train loss item: 0.15985749661922455
train loss item: 0.1968575417995453
train loss item: 0.9374801516532898
train loss item: 0.19409435987472534
test loss item: 0.0983046442270279
test loss item: 0.16984814405441284
test loss item: 0.10399430990219116
test loss item: 0.2778889834880829
test loss item: 0.1198369488120079
test loss item: 0.2515384256839752
test loss item: 0.10469667613506317
test loss item: 0.07785308361053467
test loss item: 0.13256534934043884
test loss item: 0.15988416969776154
test loss item: 0.1616138368844986
test loss item: 0.13701754808425903
test loss item: 0.11077018827199936
test loss item: 0.10978356003761292
test loss item: 0.12532489001750946
test loss item: 0.2147480696439743
test loss item: 0.15485882759094238
test loss item: 0.16488923132419586
test loss item: 0.32911819219589233
test loss item: 0.13029932975769043
test loss item: 0.1449715942144394
test loss item: 0.11984913796186447
test loss item: 0.1476726084947586
test loss item: 0.15203148126602173
test loss item: 0.18934054672718048
test loss item: 0.10371127724647522
test loss item: 0.12000811845064163
test loss item: 0.214092418551445
test loss item: 0.1885138303041458
test loss item: 0.11255133897066116
test loss item: 0.12360185384750366
test loss item: 0.11800412088632584
test loss item: 0.2293540984392166
test loss item: 0.11459723114967346
test loss item: 0.171552836894989
test loss item: 0.16546228528022766
test loss item: 0.16255465149879456
test loss item: 0.11440953612327576
test loss item: 0.3985273838043213
test loss item: 0.1224822998046875
test loss item: 0.2407664805650711
test loss item: 0.30651044845581055
test loss item: 0.1226542741060257
test loss item: 0.05471508949995041
test loss item: 0.14403608441352844
Epoch [18/100], Training Loss: 0.1901, Testing Loss: 0.1604
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 19/100
train loss item: 0.2504764497280121
train loss item: 0.2275203913450241
train loss item: 0.16612285375595093
train loss item: 0.25135961174964905
train loss item: 0.11783735454082489
train loss item: 0.1312618851661682
train loss item: 0.24459609389305115
train loss item: 0.19231897592544556
train loss item: 0.07918725907802582
train loss item: 0.15374794602394104
train loss item: 0.0936635211110115
train loss item: 0.4912932217121124
train loss item: 0.17794179916381836
train loss item: 0.16223198175430298
train loss item: 0.2553372383117676
train loss item: 0.46198323369026184
train loss item: 0.15497449040412903
train loss item: 0.43477165699005127
train loss item: 0.40120553970336914
train loss item: 0.251583993434906
train loss item: 0.2264673113822937
train loss item: 0.2355828732252121
train loss item: 0.3515346050262451
train loss item: 0.27374863624572754
train loss item: 0.12013357132673264
train loss item: 0.34604278206825256
train loss item: 0.07770496606826782
train loss item: 0.2958581745624542
train loss item: 0.13256677985191345
train loss item: 0.08414667844772339
train loss item: 0.41254308819770813
train loss item: 0.17081527411937714
train loss item: 0.17363391816616058
train loss item: 0.207070991396904
train loss item: 0.15663518011569977
train loss item: 0.12917232513427734
train loss item: 0.11376456171274185
train loss item: 0.07719982415437698
train loss item: 0.36562108993530273
train loss item: 0.12532258033752441
train loss item: 0.08289439231157303
train loss item: 0.15840017795562744
train loss item: 0.1996869593858719
train loss item: 0.8952816128730774
train loss item: 0.23258553445339203
test loss item: 0.10623671859502792
test loss item: 0.18541721999645233
test loss item: 0.10908940434455872
test loss item: 0.25501754879951477
test loss item: 0.11977408081293106
test loss item: 0.2422720044851303
test loss item: 0.11715475469827652
test loss item: 0.07647926360368729
test loss item: 0.15135528147220612
test loss item: 0.16563208401203156
test loss item: 0.168345108628273
test loss item: 0.1461070030927658
test loss item: 0.11890589445829391
test loss item: 0.1158505454659462
test loss item: 0.12661461532115936
test loss item: 0.20038774609565735
test loss item: 0.161894753575325
test loss item: 0.16345927119255066
test loss item: 0.32135894894599915
test loss item: 0.13472600281238556
test loss item: 0.16327571868896484
test loss item: 0.13923785090446472
test loss item: 0.15511265397071838
test loss item: 0.17757554352283478
test loss item: 0.17803898453712463
test loss item: 0.11304804682731628
test loss item: 0.13655251264572144
test loss item: 0.20635394752025604
test loss item: 0.1855136603116989
test loss item: 0.11787160485982895
test loss item: 0.12004729360342026
test loss item: 0.12532542645931244
test loss item: 0.22838212549686432
test loss item: 0.12350831180810928
test loss item: 0.1753009557723999
test loss item: 0.15455329418182373
test loss item: 0.1666526347398758
test loss item: 0.1409415602684021
test loss item: 0.40322113037109375
test loss item: 0.1337192952632904
test loss item: 0.23560132086277008
test loss item: 0.30004918575286865
test loss item: 0.14051301777362823
test loss item: 0.05281960591673851
test loss item: 0.1446608453989029
Epoch [19/100], Training Loss: 0.2299, Testing Loss: 0.1645
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 20/100
train loss item: 0.21889598667621613
train loss item: 0.17926602065563202
train loss item: 0.14891284704208374
train loss item: 0.14986951649188995
train loss item: 0.10754608362913132
train loss item: 0.1191602274775505
train loss item: 0.1735827773809433
train loss item: 0.19713722169399261
train loss item: 0.07480666041374207
train loss item: 0.12594754993915558
train loss item: 0.09129863232374191
train loss item: 0.25732189416885376
train loss item: 0.14381738007068634
train loss item: 0.12793225049972534
train loss item: 0.26099562644958496
train loss item: 0.28261104226112366
train loss item: 0.15697844326496124
train loss item: 0.37362006306648254
train loss item: 0.18517686426639557
train loss item: 0.15253128111362457
train loss item: 0.10898460447788239
train loss item: 0.1642119586467743
train loss item: 0.18666301667690277
train loss item: 0.13291603326797485
train loss item: 0.1140417829155922
train loss item: 0.2758147716522217
train loss item: 0.0964059978723526
train loss item: 0.3347527086734772
train loss item: 0.12414424866437912
train loss item: 0.08667069673538208
train loss item: 0.3260626792907715
train loss item: 0.22226636111736298
train loss item: 0.15421660244464874
train loss item: 0.14117994904518127
train loss item: 0.15221664309501648
train loss item: 0.11376874148845673
train loss item: 0.12443841248750687
train loss item: 0.07240749895572662
train loss item: 0.45005354285240173
train loss item: 0.14238421618938446
train loss item: 0.10602325201034546
train loss item: 0.2340765744447708
train loss item: 0.23669496178627014
train loss item: 0.8640600442886353
train loss item: 0.1563502550125122
test loss item: 0.0924675241112709
test loss item: 0.18678808212280273
test loss item: 0.10814981162548065
test loss item: 0.2768065333366394
test loss item: 0.1263844072818756
test loss item: 0.30441412329673767
test loss item: 0.10119763761758804
test loss item: 0.08055879920721054
test loss item: 0.13384924829006195
test loss item: 0.1665218472480774
test loss item: 0.16373157501220703
test loss item: 0.11490782350301743
test loss item: 0.10621045529842377
test loss item: 0.11162620782852173
test loss item: 0.1288178712129593
test loss item: 0.25299182534217834
test loss item: 0.161525696516037
test loss item: 0.17655695974826813
test loss item: 0.39287468791007996
test loss item: 0.1329815536737442
test loss item: 0.13211415708065033
test loss item: 0.12206139415502548
test loss item: 0.14358098804950714
test loss item: 0.12798532843589783
test loss item: 0.20342031121253967
test loss item: 0.10162394493818283
test loss item: 0.121208555996418
test loss item: 0.2566053569316864
test loss item: 0.2006833851337433
test loss item: 0.11121682077646255
test loss item: 0.12559334933757782
test loss item: 0.11162291467189789
test loss item: 0.28278571367263794
test loss item: 0.11460787057876587
test loss item: 0.19021648168563843
test loss item: 0.16334006190299988
test loss item: 0.14717425405979156
test loss item: 0.09841377288103104
test loss item: 0.5217377543449402
test loss item: 0.11348753422498703
test loss item: 0.28824716806411743
test loss item: 0.38161787390708923
test loss item: 0.1208215206861496
test loss item: 0.04986372962594032
test loss item: 0.15483969449996948
Epoch [20/100], Training Loss: 0.1922, Testing Loss: 0.1712
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 21/100
train loss item: 0.212754487991333
train loss item: 0.24642090499401093
train loss item: 0.1603606641292572
train loss item: 0.28166669607162476
train loss item: 0.12861189246177673
train loss item: 0.1447068750858307
train loss item: 0.20538018643856049
train loss item: 0.21606822311878204
train loss item: 0.07766866683959961
train loss item: 0.14190229773521423
train loss item: 0.09829883277416229
train loss item: 0.38689690828323364
train loss item: 0.19695807993412018
train loss item: 0.16480188071727753
train loss item: 0.30312007665634155
train loss item: 0.3547267019748688
train loss item: 0.1779419183731079
train loss item: 0.38564953207969666
train loss item: 0.26272052526474
train loss item: 0.15883034467697144
train loss item: 0.12539726495742798
train loss item: 0.14073814451694489
train loss item: 0.21283911168575287
train loss item: 0.15750890970230103
train loss item: 0.09718181937932968
train loss item: 0.3903813660144806
train loss item: 0.07690610736608505
train loss item: 0.22889737784862518
train loss item: 0.1235993504524231
train loss item: 0.07367370277643204
train loss item: 0.2812426686286926
train loss item: 0.14081956446170807
train loss item: 0.1332404464483261
train loss item: 0.15080626308918
train loss item: 0.15012210607528687
train loss item: 0.10817116498947144
train loss item: 0.10563217103481293
train loss item: 0.06935140490531921
train loss item: 0.30977320671081543
train loss item: 0.11298341304063797
train loss item: 0.08772692829370499
train loss item: 0.17449577152729034
train loss item: 0.19181205332279205
train loss item: 0.865289568901062
train loss item: 0.18623220920562744
test loss item: 0.09480814635753632
test loss item: 0.20355968177318573
test loss item: 0.10621288418769836
test loss item: 0.2813132703304291
test loss item: 0.11936261504888535
test loss item: 0.32006925344467163
test loss item: 0.10349316895008087
test loss item: 0.07649736106395721
test loss item: 0.13551494479179382
test loss item: 0.15707437694072723
test loss item: 0.16204383969306946
test loss item: 0.1254100352525711
test loss item: 0.11458927392959595
test loss item: 0.10497505962848663
test loss item: 0.12069818377494812
test loss item: 0.26550301909446716
test loss item: 0.16643261909484863
test loss item: 0.16284476220607758
test loss item: 0.4226647615432739
test loss item: 0.1357552856206894
test loss item: 0.14073503017425537
test loss item: 0.12495932728052139
test loss item: 0.14237965643405914
test loss item: 0.14149190485477448
test loss item: 0.2046392858028412
test loss item: 0.10178608447313309
test loss item: 0.12378774583339691
test loss item: 0.2683045566082001
test loss item: 0.20733915269374847
test loss item: 0.11022820323705673
test loss item: 0.1142927035689354
test loss item: 0.11472918838262558
test loss item: 0.3144013583660126
test loss item: 0.11519619822502136
test loss item: 0.192239448428154
test loss item: 0.16268382966518402
test loss item: 0.15053026378154755
test loss item: 0.11251802742481232
test loss item: 0.6087825894355774
test loss item: 0.11859481781721115
test loss item: 0.3143083155155182
test loss item: 0.4145659804344177
test loss item: 0.12545034289360046
test loss item: 0.05201449990272522
test loss item: 0.15687759220600128
Epoch [21/100], Training Loss: 0.2000, Testing Loss: 0.1780
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 22/100
train loss item: 0.19091662764549255
train loss item: 0.19766777753829956
train loss item: 0.14822231233119965
train loss item: 0.15255160629749298
train loss item: 0.10979600995779037
train loss item: 0.13183152675628662
train loss item: 0.16347166895866394
train loss item: 0.14310495555400848
train loss item: 0.07167823612689972
train loss item: 0.12735067307949066
train loss item: 0.08847935497760773
train loss item: 0.47559717297554016
train loss item: 0.1376599818468094
train loss item: 0.1613895744085312
train loss item: 0.3228116035461426
train loss item: 0.2817881405353546
train loss item: 0.24023474752902985
train loss item: 0.49889901280403137
train loss item: 0.18764087557792664
train loss item: 0.20751726627349854
train loss item: 0.15201126039028168
train loss item: 0.12931254506111145
train loss item: 0.2062380611896515
train loss item: 0.11489593982696533
train loss item: 0.09626846760511398
train loss item: 0.2988746762275696
train loss item: 0.09624660015106201
train loss item: 0.29426494240760803
train loss item: 0.1470254361629486
train loss item: 0.09632501006126404
train loss item: 0.30009064078330994
train loss item: 0.20244859158992767
train loss item: 0.16461153328418732
train loss item: 0.17891831696033478
train loss item: 0.1740007996559143
train loss item: 0.10762125998735428
train loss item: 0.11072371155023575
train loss item: 0.0729568675160408
train loss item: 0.44268280267715454
train loss item: 0.13816127181053162
train loss item: 0.10739626735448837
train loss item: 0.26552337408065796
train loss item: 0.2607146203517914
train loss item: 0.8734986782073975
train loss item: 0.1504589468240738
test loss item: 0.09847737103700638
test loss item: 0.23796404898166656
test loss item: 0.11383321136236191
test loss item: 0.4120514392852783
test loss item: 0.1566106230020523
test loss item: 0.4227573573589325
test loss item: 0.10423503816127777
test loss item: 0.07981808483600616
test loss item: 0.16189414262771606
test loss item: 0.21007013320922852
test loss item: 0.20122915506362915
test loss item: 0.12048818171024323
test loss item: 0.12088882923126221
test loss item: 0.12561866641044617
test loss item: 0.14251311123371124
test loss item: 0.3618718981742859
test loss item: 0.20134593546390533
test loss item: 0.21444518864154816
test loss item: 0.5412164330482483
test loss item: 0.1624390333890915
test loss item: 0.1460341215133667
test loss item: 0.1498134583234787
test loss item: 0.17479927837848663
test loss item: 0.12792380154132843
test loss item: 0.2799364924430847
test loss item: 0.11354224383831024
test loss item: 0.13774633407592773
test loss item: 0.3512808084487915
test loss item: 0.26115819811820984
test loss item: 0.11500323563814163
test loss item: 0.15545690059661865
test loss item: 0.1208348199725151
test loss item: 0.3797176480293274
test loss item: 0.13340087234973907
test loss item: 0.23357431590557098
test loss item: 0.24932390451431274
test loss item: 0.1701284795999527
test loss item: 0.10778679698705673
test loss item: 0.705737829208374
test loss item: 0.12325042486190796
test loss item: 0.41716766357421875
test loss item: 0.5351740717887878
test loss item: 0.13359078764915466
test loss item: 0.05965156480669975
test loss item: 0.17603331804275513
Epoch [22/100], Training Loss: 0.2049, Testing Loss: 0.2166
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 23/100
train loss item: 0.2197376787662506
train loss item: 0.17884235084056854
train loss item: 0.13277669250965118
train loss item: 0.19885309040546417
train loss item: 0.1022365614771843
train loss item: 0.14452631771564484
train loss item: 0.16397981345653534
train loss item: 0.27701425552368164
train loss item: 0.07775558531284332
train loss item: 0.1459140032529831
train loss item: 0.09737521409988403
train loss item: 0.4399387836456299
train loss item: 0.13767674565315247
train loss item: 0.1634557992219925
train loss item: 0.2729649841785431
train loss item: 0.2962760925292969
train loss item: 0.23697537183761597
train loss item: 0.3679834306240082
train loss item: 0.17459559440612793
train loss item: 0.21280719339847565
train loss item: 0.18395861983299255
train loss item: 0.1325160712003708
train loss item: 0.2925977408885956
train loss item: 0.12458927929401398
train loss item: 0.10122980177402496
train loss item: 0.2476237416267395
train loss item: 0.07912161946296692
train loss item: 0.3396128714084625
train loss item: 0.1373862624168396
train loss item: 0.08853000402450562
train loss item: 0.3270110487937927
train loss item: 0.19654878973960876
train loss item: 0.1912958025932312
train loss item: 0.2860443592071533
train loss item: 0.21960769593715668
train loss item: 0.1550350934267044
train loss item: 0.12102632969617844
train loss item: 0.07755097001791
train loss item: 0.3173859119415283
train loss item: 0.11048715561628342
train loss item: 0.10064348578453064
train loss item: 0.18646812438964844
train loss item: 0.20225723087787628
train loss item: 0.8253968358039856
train loss item: 0.14332792162895203
test loss item: 0.09271803498268127
test loss item: 0.21925140917301178
test loss item: 0.11763453483581543
test loss item: 0.3959766626358032
test loss item: 0.16857066750526428
test loss item: 0.3702802360057831
test loss item: 0.11443964391946793
test loss item: 0.08431325852870941
test loss item: 0.14934566617012024
test loss item: 0.2054683119058609
test loss item: 0.19679395854473114
test loss item: 0.11497895419597626
test loss item: 0.11233408004045486
test loss item: 0.1311877816915512
test loss item: 0.15532636642456055
test loss item: 0.32695701718330383
test loss item: 0.19393952190876007
test loss item: 0.21632497012615204
test loss item: 0.47619232535362244
test loss item: 0.16304205358028412
test loss item: 0.13582351803779602
test loss item: 0.13434860110282898
test loss item: 0.18167032301425934
test loss item: 0.12200550734996796
test loss item: 0.2726649343967438
test loss item: 0.13448907434940338
test loss item: 0.12485998868942261
test loss item: 0.3288569450378418
test loss item: 0.24007120728492737
test loss item: 0.12353279441595078
test loss item: 0.16864705085754395
test loss item: 0.11812902987003326
test loss item: 0.3348398208618164
test loss item: 0.13300326466560364
test loss item: 0.22292254865169525
test loss item: 0.24662770330905914
test loss item: 0.1626943200826645
test loss item: 0.08772067725658417
test loss item: 0.5745207667350769
test loss item: 0.11509449779987335
test loss item: 0.360385000705719
test loss item: 0.46485665440559387
test loss item: 0.12165823578834534
test loss item: 0.05261144042015076
test loss item: 0.17956028878688812
Epoch [23/100], Training Loss: 0.2051, Testing Loss: 0.2033
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 24/100
train loss item: 0.20076268911361694
train loss item: 0.18954506516456604
train loss item: 0.12408680468797684
train loss item: 0.14659489691257477
train loss item: 0.10208690166473389
train loss item: 0.13209225237369537
train loss item: 0.1409347951412201
train loss item: 0.2873777449131012
train loss item: 0.07194061577320099
train loss item: 0.17284360527992249
train loss item: 0.09339248389005661
train loss item: 0.4868180751800537
train loss item: 0.1540176123380661
train loss item: 0.15035466849803925
train loss item: 0.2502188980579376
train loss item: 0.42420512437820435
train loss item: 0.2028479278087616
train loss item: 0.2877451181411743
train loss item: 0.17435726523399353
train loss item: 0.22805747389793396
train loss item: 0.17461413145065308
train loss item: 0.1469831019639969
train loss item: 0.3084060847759247
train loss item: 0.1413707286119461
train loss item: 0.11471042037010193
train loss item: 0.28401613235473633
train loss item: 0.08483223617076874
train loss item: 0.36882850527763367
train loss item: 0.11264495551586151
train loss item: 0.07600734382867813
train loss item: 0.3464418351650238
train loss item: 0.17835912108421326
train loss item: 0.18181069195270538
train loss item: 0.3113771378993988
train loss item: 0.22614005208015442
train loss item: 0.15955014526844025
train loss item: 0.14173424243927002
train loss item: 0.09260321408510208
train loss item: 0.35546383261680603
train loss item: 0.11885193735361099
train loss item: 0.09514525532722473
train loss item: 0.16112248599529266
train loss item: 0.1917751580476761
train loss item: 0.7949573397636414
train loss item: 0.15227048099040985
test loss item: 0.09185495227575302
test loss item: 0.16040940582752228
test loss item: 0.11360224336385727
test loss item: 0.2903766930103302
test loss item: 0.14211128652095795
test loss item: 0.2178514152765274
test loss item: 0.10875529795885086
test loss item: 0.08735731989145279
test loss item: 0.13369236886501312
test loss item: 0.17752423882484436
test loss item: 0.17778678238391876
test loss item: 0.12040738016366959
test loss item: 0.10030689090490341
test loss item: 0.12392804771661758
test loss item: 0.14625363051891327
test loss item: 0.2006201148033142
test loss item: 0.15631026029586792
test loss item: 0.18502746522426605
test loss item: 0.2843426764011383
test loss item: 0.14263060688972473
test loss item: 0.12648259103298187
test loss item: 0.12082787603139877
test loss item: 0.17205636203289032
test loss item: 0.12814421951770782
test loss item: 0.19749225676059723
test loss item: 0.13079994916915894
test loss item: 0.11501059681177139
test loss item: 0.2149847447872162
test loss item: 0.18282775580883026
test loss item: 0.11609150469303131
test loss item: 0.14615990221500397
test loss item: 0.10599400103092194
test loss item: 0.21784013509750366
test loss item: 0.12128384411334991
test loss item: 0.18160122632980347
test loss item: 0.19003576040267944
test loss item: 0.1497637927532196
test loss item: 0.08928067237138748
test loss item: 0.25443392992019653
test loss item: 0.10604340583086014
test loss item: 0.2287682145833969
test loss item: 0.2776612639427185
test loss item: 0.10998356342315674
test loss item: 0.051758281886577606
test loss item: 0.1512831747531891
Epoch [24/100], Training Loss: 0.2076, Testing Loss: 0.1566
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 25/100
train loss item: 0.21996429562568665
train loss item: 0.18688809871673584
train loss item: 0.13245588541030884
train loss item: 0.18357113003730774
train loss item: 0.11352931708097458
train loss item: 0.11265119165182114
train loss item: 0.14240805804729462
train loss item: 0.19186502695083618
train loss item: 0.07668426632881165
train loss item: 0.14690864086151123
train loss item: 0.0931052565574646
train loss item: 0.2728588879108429
train loss item: 0.12598563730716705
train loss item: 0.11532806605100632
train loss item: 0.17300082743167877
train loss item: 0.3982008397579193
train loss item: 0.1031649261713028
train loss item: 0.24599485099315643
train loss item: 0.1376124918460846
train loss item: 0.1650337129831314
train loss item: 0.12784075736999512
train loss item: 0.11798759549856186
train loss item: 0.18144653737545013
train loss item: 0.13319918513298035
train loss item: 0.08411797881126404
train loss item: 0.24888023734092712
train loss item: 0.06559410691261292
train loss item: 0.24219505488872528
train loss item: 0.10085684061050415
train loss item: 0.07916392385959625
train loss item: 0.2537517249584198
train loss item: 0.14416088163852692
train loss item: 0.1334264725446701
train loss item: 0.20943647623062134
train loss item: 0.16117027401924133
train loss item: 0.11637603491544724
train loss item: 0.10611065477132797
train loss item: 0.06985428929328918
train loss item: 0.2766343951225281
train loss item: 0.10098040848970413
train loss item: 0.0839942991733551
train loss item: 0.1670137643814087
train loss item: 0.16320784389972687
train loss item: 0.763848066329956
train loss item: 0.13768652081489563
test loss item: 0.08879346400499344
test loss item: 0.15680596232414246
test loss item: 0.1013256311416626
test loss item: 0.29265305399894714
test loss item: 0.13296422362327576
test loss item: 0.1993311047554016
test loss item: 0.10122319310903549
test loss item: 0.07583677023649216
test loss item: 0.1306696981191635
test loss item: 0.16604697704315186
test loss item: 0.17677125334739685
test loss item: 0.11316868662834167
test loss item: 0.09874602407217026
test loss item: 0.10891873389482498
test loss item: 0.13150258362293243
test loss item: 0.1839035302400589
test loss item: 0.15743684768676758
test loss item: 0.16591954231262207
test loss item: 0.2703973054885864
test loss item: 0.1359783411026001
test loss item: 0.12022346258163452
test loss item: 0.11998441070318222
test loss item: 0.1630811244249344
test loss item: 0.11912012100219727
test loss item: 0.18336966633796692
test loss item: 0.12009990960359573
test loss item: 0.11013879626989365
test loss item: 0.18913358449935913
test loss item: 0.17134764790534973
test loss item: 0.1119735985994339
test loss item: 0.14189325273036957
test loss item: 0.10355594754219055
test loss item: 0.20334522426128387
test loss item: 0.11068733036518097
test loss item: 0.17078040540218353
test loss item: 0.18466360867023468
test loss item: 0.1436215490102768
test loss item: 0.08135997503995895
test loss item: 0.24968017637729645
test loss item: 0.10218154639005661
test loss item: 0.2114870697259903
test loss item: 0.2560122609138489
test loss item: 0.10667866468429565
test loss item: 0.05517464503645897
test loss item: 0.16143225133419037
Epoch [25/100], Training Loss: 0.1690, Testing Loss: 0.1484
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 26/100
train loss item: 0.20227430760860443
train loss item: 0.18080708384513855
train loss item: 0.1286899298429489
train loss item: 0.18705134093761444
train loss item: 0.10134553909301758
train loss item: 0.11508915573358536
train loss item: 0.17517796158790588
train loss item: 0.16963692009449005
train loss item: 0.06899005174636841
train loss item: 0.13491463661193848
train loss item: 0.08328379690647125
train loss item: 0.3213307559490204
train loss item: 0.14652296900749207
train loss item: 0.13896772265434265
train loss item: 0.22175873816013336
train loss item: 0.2758316099643707
train loss item: 0.11318875849246979
train loss item: 0.23903648555278778
train loss item: 0.16414760053157806
train loss item: 0.13473284244537354
train loss item: 0.09393110126256943
train loss item: 0.1233188584446907
train loss item: 0.17779409885406494
train loss item: 0.10009101033210754
train loss item: 0.08406160026788712
train loss item: 0.21892641484737396
train loss item: 0.06766761094331741
train loss item: 0.19857320189476013
train loss item: 0.10905517637729645
train loss item: 0.0737028643488884
train loss item: 0.2585623860359192
train loss item: 0.14356201887130737
train loss item: 0.11326483637094498
train loss item: 0.13445304334163666
train loss item: 0.1457897573709488
train loss item: 0.10279963165521622
train loss item: 0.09935910254716873
train loss item: 0.0710797980427742
train loss item: 0.26026904582977295
train loss item: 0.10456056892871857
train loss item: 0.07356718927621841
train loss item: 0.13669154047966003
train loss item: 0.14053992927074432
train loss item: 0.7443402409553528
train loss item: 0.14362750947475433
test loss item: 0.10379898548126221
test loss item: 0.1744205206632614
test loss item: 0.10396377742290497
test loss item: 0.3592628538608551
test loss item: 0.1268477886915207
test loss item: 0.23270878195762634
test loss item: 0.10143212974071503
test loss item: 0.07854875922203064
test loss item: 0.1369135081768036
test loss item: 0.1739560067653656
test loss item: 0.1745000034570694
test loss item: 0.13240081071853638
test loss item: 0.10901512205600739
test loss item: 0.10876233130693436
test loss item: 0.12644344568252563
test loss item: 0.22500303387641907
test loss item: 0.16185522079467773
test loss item: 0.15784309804439545
test loss item: 0.32212236523628235
test loss item: 0.1382899135351181
test loss item: 0.14194545149803162
test loss item: 0.12311211228370667
test loss item: 0.15636008977890015
test loss item: 0.14142806828022003
test loss item: 0.19193947315216064
test loss item: 0.10552200675010681
test loss item: 0.11831942945718765
test loss item: 0.2016734629869461
test loss item: 0.1914752572774887
test loss item: 0.10801618546247482
test loss item: 0.1343734711408615
test loss item: 0.11650129407644272
test loss item: 0.22781246900558472
test loss item: 0.11378112435340881
test loss item: 0.17249588668346405
test loss item: 0.22081537544727325
test loss item: 0.16793185472488403
test loss item: 0.11025949567556381
test loss item: 0.3571195602416992
test loss item: 0.1227644756436348
test loss item: 0.25252407789230347
test loss item: 0.2955082356929779
test loss item: 0.12076321989297867
test loss item: 0.06477180123329163
test loss item: 0.17456400394439697
Epoch [26/100], Training Loss: 0.1605, Testing Loss: 0.1640
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 27/100
train loss item: 0.20199109613895416
train loss item: 0.15443074703216553
train loss item: 0.13926920294761658
train loss item: 0.13422678411006927
train loss item: 0.113031767308712
train loss item: 0.12330743670463562
train loss item: 0.14502555131912231
train loss item: 0.17264926433563232
train loss item: 0.06429682672023773
train loss item: 0.12449487298727036
train loss item: 0.0845092311501503
train loss item: 0.2849210798740387
train loss item: 0.12148197740316391
train loss item: 0.1333261877298355
train loss item: 0.215953066945076
train loss item: 0.27968284487724304
train loss item: 0.15460024774074554
train loss item: 0.22171805799007416
train loss item: 0.14533261954784393
train loss item: 0.18101619184017181
train loss item: 0.1313350796699524
train loss item: 0.14035558700561523
train loss item: 0.1844785064458847
train loss item: 0.10472165793180466
train loss item: 0.08288972079753876
train loss item: 0.21985271573066711
train loss item: 0.06725313514471054
train loss item: 0.22891481220722198
train loss item: 0.10906559973955154
train loss item: 0.07554853707551956
train loss item: 0.25625717639923096
train loss item: 0.13733769953250885
train loss item: 0.1271844059228897
train loss item: 0.19172587990760803
train loss item: 0.1588631570339203
train loss item: 0.11580977588891983
train loss item: 0.10206244140863419
train loss item: 0.07050936669111252
train loss item: 0.28131571412086487
train loss item: 0.10535818338394165
train loss item: 0.07873928546905518
train loss item: 0.1513456106185913
train loss item: 0.14433526992797852
train loss item: 0.7249644994735718
train loss item: 0.1354997307062149
test loss item: 0.09127271175384521
test loss item: 0.16546961665153503
test loss item: 0.09671299159526825
test loss item: 0.29469332098960876
test loss item: 0.12231962382793427
test loss item: 0.23883797228336334
test loss item: 0.0954902172088623
test loss item: 0.07242075353860855
test loss item: 0.13161928951740265
test loss item: 0.16471274197101593
test loss item: 0.16859012842178345
test loss item: 0.11376062035560608
test loss item: 0.10224587470293045
test loss item: 0.10590291023254395
test loss item: 0.12227579951286316
test loss item: 0.20941932499408722
test loss item: 0.15545158088207245
test loss item: 0.15646113455295563
test loss item: 0.3067467212677002
test loss item: 0.1301906853914261
test loss item: 0.12630416452884674
test loss item: 0.12021206319332123
test loss item: 0.15501409769058228
test loss item: 0.1220422014594078
test loss item: 0.19049085676670074
test loss item: 0.10266637802124023
test loss item: 0.11251205205917358
test loss item: 0.20606324076652527
test loss item: 0.17645840346813202
test loss item: 0.10154447704553604
test loss item: 0.12962213158607483
test loss item: 0.10505474358797073
test loss item: 0.22159190475940704
test loss item: 0.11127346754074097
test loss item: 0.16643370687961578
test loss item: 0.18634898960590363
test loss item: 0.15290792286396027
test loss item: 0.09458446502685547
test loss item: 0.3422302305698395
test loss item: 0.10864122956991196
test loss item: 0.23744510114192963
test loss item: 0.2899346351623535
test loss item: 0.11304464191198349
test loss item: 0.058186765760183334
test loss item: 0.1673675775527954
Epoch [27/100], Training Loss: 0.1627, Testing Loss: 0.1543
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 28/100
train loss item: 0.17433077096939087
train loss item: 0.1443684995174408
train loss item: 0.1217505931854248
train loss item: 0.12255574017763138
train loss item: 0.08810367435216904
train loss item: 0.10283622145652771
train loss item: 0.12336920946836472
train loss item: 0.1992824524641037
train loss item: 0.06255902349948883
train loss item: 0.12599113583564758
train loss item: 0.07891199737787247
train loss item: 0.2092839777469635
train loss item: 0.11472681909799576
train loss item: 0.12196057289838791
train loss item: 0.17389020323753357
train loss item: 0.270805299282074
train loss item: 0.11046553403139114
train loss item: 0.20240379869937897
train loss item: 0.13044753670692444
train loss item: 0.16978414356708527
train loss item: 0.12194163352251053
train loss item: 0.13414786756038666
train loss item: 0.13174887001514435
train loss item: 0.11845017224550247
train loss item: 0.08095823973417282
train loss item: 0.2206113636493683
train loss item: 0.06484484672546387
train loss item: 0.1878153383731842
train loss item: 0.09728468209505081
train loss item: 0.07289566844701767
train loss item: 0.2509477138519287
train loss item: 0.1377342939376831
train loss item: 0.12065068632364273
train loss item: 0.17974433302879333
train loss item: 0.14248913526535034
train loss item: 0.10168931633234024
train loss item: 0.10001488775014877
train loss item: 0.07106141746044159
train loss item: 0.24580755829811096
train loss item: 0.100509412586689
train loss item: 0.07999332249164581
train loss item: 0.15025204420089722
train loss item: 0.13887012004852295
train loss item: 0.7004213929176331
train loss item: 0.1253039687871933
test loss item: 0.08716689050197601
test loss item: 0.1613122671842575
test loss item: 0.09900673478841782
test loss item: 0.33902302384376526
test loss item: 0.12575724720954895
test loss item: 0.2284071445465088
test loss item: 0.09285905212163925
test loss item: 0.071359783411026
test loss item: 0.1332245171070099
test loss item: 0.16902022063732147
test loss item: 0.1803085207939148
test loss item: 0.1143355667591095
test loss item: 0.09716089814901352
test loss item: 0.1065315529704094
test loss item: 0.1277768760919571
test loss item: 0.21862651407718658
test loss item: 0.1609100103378296
test loss item: 0.16203491389751434
test loss item: 0.3092978000640869
test loss item: 0.13551408052444458
test loss item: 0.12243034690618515
test loss item: 0.1195407584309578
test loss item: 0.1646798998117447
test loss item: 0.12051519006490707
test loss item: 0.19333620369434357
test loss item: 0.10537952929735184
test loss item: 0.11023271828889847
test loss item: 0.20493976771831512
test loss item: 0.18245890736579895
test loss item: 0.10178550332784653
test loss item: 0.13669517636299133
test loss item: 0.10184726864099503
test loss item: 0.21625365316867828
test loss item: 0.11295226216316223
test loss item: 0.17045047879219055
test loss item: 0.2127818614244461
test loss item: 0.14817874133586884
test loss item: 0.08528081327676773
test loss item: 0.3196106553077698
test loss item: 0.10350532829761505
test loss item: 0.2382461577653885
test loss item: 0.2883129119873047
test loss item: 0.1054922416806221
test loss item: 0.05282914638519287
test loss item: 0.14471352100372314
Epoch [28/100], Training Loss: 0.1494, Testing Loss: 0.1552
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 29/100
train loss item: 0.19115355610847473
train loss item: 0.14606918394565582
train loss item: 0.12405499070882797
train loss item: 0.14060454070568085
train loss item: 0.08575009554624557
train loss item: 0.09800518304109573
train loss item: 0.12095851451158524
train loss item: 0.17244836688041687
train loss item: 0.06344833970069885
train loss item: 0.12204820662736893
train loss item: 0.07839124649763107
train loss item: 0.20652653276920319
train loss item: 0.11119820177555084
train loss item: 0.12246986478567123
train loss item: 0.18503770232200623
train loss item: 0.24886521697044373
train loss item: 0.08717405796051025
train loss item: 0.204196035861969
train loss item: 0.12582120299339294
train loss item: 0.13918627798557281
train loss item: 0.10189370065927505
train loss item: 0.12058572471141815
train loss item: 0.14530810713768005
train loss item: 0.10641833394765854
train loss item: 0.07942234724760056
train loss item: 0.2223552167415619
train loss item: 0.0667586475610733
train loss item: 0.2053506076335907
train loss item: 0.09321460872888565
train loss item: 0.07044348120689392
train loss item: 0.2356167584657669
train loss item: 0.11893472075462341
train loss item: 0.10838894546031952
train loss item: 0.15571251511573792
train loss item: 0.1252349615097046
train loss item: 0.09547968208789825
train loss item: 0.0937250629067421
train loss item: 0.06941037625074387
train loss item: 0.23796312510967255
train loss item: 0.0997096598148346
train loss item: 0.07582747936248779
train loss item: 0.1337701976299286
train loss item: 0.13437530398368835
train loss item: 0.6953557133674622
train loss item: 0.12141947448253632
test loss item: 0.09399904310703278
test loss item: 0.1830105185508728
test loss item: 0.10060390084981918
test loss item: 0.3944908082485199
test loss item: 0.13083869218826294
test loss item: 0.27708280086517334
test loss item: 0.09670992940664291
test loss item: 0.07448278367519379
test loss item: 0.13464027643203735
test loss item: 0.1828404814004898
test loss item: 0.18681398034095764
test loss item: 0.1236640140414238
test loss item: 0.09966768324375153
test loss item: 0.10870262235403061
test loss item: 0.13083870708942413
test loss item: 0.2652297914028168
test loss item: 0.17122918367385864
test loss item: 0.16855917870998383
test loss item: 0.3826160430908203
test loss item: 0.14505994319915771
test loss item: 0.12919242680072784
test loss item: 0.11491960287094116
test loss item: 0.17332524061203003
test loss item: 0.13047103583812714
test loss item: 0.21738377213478088
test loss item: 0.10473553836345673
test loss item: 0.10726520419120789
test loss item: 0.24311970174312592
test loss item: 0.2087455838918686
test loss item: 0.10304170101881027
test loss item: 0.14067897200584412
test loss item: 0.10734352469444275
test loss item: 0.2645913362503052
test loss item: 0.11655576527118683
test loss item: 0.18879106640815735
test loss item: 0.24320659041404724
test loss item: 0.16042198240756989
test loss item: 0.09028229117393494
test loss item: 0.4458196461200714
test loss item: 0.11123257130384445
test loss item: 0.2861050069332123
test loss item: 0.3566657304763794
test loss item: 0.10555542260408401
test loss item: 0.058961525559425354
test loss item: 0.14480692148208618
Epoch [29/100], Training Loss: 0.1441, Testing Loss: 0.1734
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 30/100
train loss item: 0.16731882095336914
train loss item: 0.15945903956890106
train loss item: 0.11996674537658691
train loss item: 0.18774421513080597
train loss item: 0.0843299999833107
train loss item: 0.11217585951089859
train loss item: 0.12392625957727432
train loss item: 0.13224457204341888
train loss item: 0.0673513114452362
train loss item: 0.13698987662792206
train loss item: 0.0842323750257492
train loss item: 0.28542858362197876
train loss item: 0.13754288852214813
train loss item: 0.10556201636791229
train loss item: 0.15138152241706848
train loss item: 0.25778084993362427
train loss item: 0.10230278968811035
train loss item: 0.20433452725410461
train loss item: 0.12969669699668884
train loss item: 0.18306097388267517
train loss item: 0.12998531758785248
train loss item: 0.15498162806034088
train loss item: 0.1625126153230667
train loss item: 0.14749039709568024
train loss item: 0.08648531138896942
train loss item: 0.23589777946472168
train loss item: 0.06198403611779213
train loss item: 0.25360938906669617
train loss item: 0.09746618568897247
train loss item: 0.07640455663204193
train loss item: 0.2569820284843445
train loss item: 0.14536988735198975
train loss item: 0.13812024891376495
train loss item: 0.21637088060379028
train loss item: 0.1511659026145935
train loss item: 0.12132958322763443
train loss item: 0.10371531546115875
train loss item: 0.07372802495956421
train loss item: 0.1997336596250534
train loss item: 0.10014491528272629
train loss item: 0.08326917141675949
train loss item: 0.17020556330680847
train loss item: 0.14541707932949066
train loss item: 0.6723605990409851
train loss item: 0.12824632227420807
test loss item: 0.08423760533332825
test loss item: 0.15447558462619781
test loss item: 0.09433043003082275
test loss item: 0.390158474445343
test loss item: 0.12643258273601532
test loss item: 0.22073152661323547
test loss item: 0.09754007309675217
test loss item: 0.07052555680274963
test loss item: 0.1313878446817398
test loss item: 0.1842486560344696
test loss item: 0.19124823808670044
test loss item: 0.1147972047328949
test loss item: 0.09517063945531845
test loss item: 0.11049573123455048
test loss item: 0.13062675297260284
test loss item: 0.22928206622600555
test loss item: 0.15478762984275818
test loss item: 0.16762419044971466
test loss item: 0.30877822637557983
test loss item: 0.13981647789478302
test loss item: 0.12184225022792816
test loss item: 0.11494732648134232
test loss item: 0.17757776379585266
test loss item: 0.11850450932979584
test loss item: 0.20338894426822662
test loss item: 0.11221379786729813
test loss item: 0.10760319977998734
test loss item: 0.2043491154909134
test loss item: 0.1923191398382187
test loss item: 0.10322761535644531
test loss item: 0.13975004851818085
test loss item: 0.1055416539311409
test loss item: 0.22635427117347717
test loss item: 0.12078835815191269
test loss item: 0.17415161430835724
test loss item: 0.25208112597465515
test loss item: 0.1610400378704071
test loss item: 0.0781145691871643
test loss item: 0.27925512194633484
test loss item: 0.09994537383317947
test loss item: 0.2547810971736908
test loss item: 0.29658496379852295
test loss item: 0.10421500355005264
test loss item: 0.05307396501302719
test loss item: 0.14313848316669464
Epoch [30/100], Training Loss: 0.1566, Testing Loss: 0.1587
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 31/100
train loss item: 0.19122351706027985
train loss item: 0.13979583978652954
train loss item: 0.1122843399643898
train loss item: 0.14761580526828766
train loss item: 0.09991082549095154
train loss item: 0.10215360671281815
train loss item: 0.12248550355434418
train loss item: 0.1295834630727768
train loss item: 0.06216913461685181
train loss item: 0.12886811792850494
train loss item: 0.08873020112514496
train loss item: 0.20056897401809692
train loss item: 0.11697491258382797
train loss item: 0.10089201480150223
train loss item: 0.18433877825737
train loss item: 0.29075032472610474
train loss item: 0.09993524849414825
train loss item: 0.1958027184009552
train loss item: 0.1479189246892929
train loss item: 0.1934560239315033
train loss item: 0.13453057408332825
train loss item: 0.13955992460250854
train loss item: 0.1936567723751068
train loss item: 0.18782398104667664
train loss item: 0.09462831914424896
train loss item: 0.3553486168384552
train loss item: 0.06867524981498718
train loss item: 0.3682631850242615
train loss item: 0.09222778677940369
train loss item: 0.06820293515920639
train loss item: 0.23242297768592834
train loss item: 0.12657393515110016
train loss item: 0.12554557621479034
train loss item: 0.2495163232088089
train loss item: 0.1815786212682724
train loss item: 0.12851135432720184
train loss item: 0.11671403795480728
train loss item: 0.07259553670883179
train loss item: 0.19020769000053406
train loss item: 0.10568538308143616
train loss item: 0.07140062749385834
train loss item: 0.12776346504688263
train loss item: 0.14100317656993866
train loss item: 0.6612077951431274
train loss item: 0.1287078857421875
test loss item: 0.0892539694905281
test loss item: 0.15466660261154175
test loss item: 0.09806354343891144
test loss item: 0.45279258489608765
test loss item: 0.12618790566921234
test loss item: 0.1970304250717163
test loss item: 0.1035555973649025
test loss item: 0.07231564819812775
test loss item: 0.13905060291290283
test loss item: 0.20808753371238708
test loss item: 0.19840320944786072
test loss item: 0.12021303921937943
test loss item: 0.10421375185251236
test loss item: 0.11659815907478333
test loss item: 0.13540354371070862
test loss item: 0.23971527814865112
test loss item: 0.15095466375350952
test loss item: 0.1637764424085617
test loss item: 0.30633744597435
test loss item: 0.1458137482404709
test loss item: 0.1352740377187729
test loss item: 0.1164110004901886
test loss item: 0.19459863007068634
test loss item: 0.1269092559814453
test loss item: 0.20710988342761993
test loss item: 0.10838259011507034
test loss item: 0.10838940739631653
test loss item: 0.17521250247955322
test loss item: 0.2074967622756958
test loss item: 0.10657801479101181
test loss item: 0.15042705833911896
test loss item: 0.11757908761501312
test loss item: 0.2360079139471054
test loss item: 0.137908473610878
test loss item: 0.17679603397846222
test loss item: 0.2955215871334076
test loss item: 0.18935126066207886
test loss item: 0.08911733329296112
test loss item: 0.24716661870479584
test loss item: 0.11212864518165588
test loss item: 0.2654397487640381
test loss item: 0.2880654036998749
test loss item: 0.11627882719039917
test loss item: 0.055030953139066696
test loss item: 0.1681840866804123
Epoch [31/100], Training Loss: 0.1604, Testing Loss: 0.1656
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 32/100
train loss item: 0.18546445667743683
train loss item: 0.13992741703987122
train loss item: 0.1120680421590805
train loss item: 0.17581290006637573
train loss item: 0.11470977216959
train loss item: 0.10350488871335983
train loss item: 0.21348707377910614
train loss item: 0.155402272939682
train loss item: 0.06430770456790924
train loss item: 0.13904979825019836
train loss item: 0.0852891057729721
train loss item: 0.41829243302345276
train loss item: 0.1498115360736847
train loss item: 0.1045897901058197
train loss item: 0.172407329082489
train loss item: 0.2920566499233246
train loss item: 0.08221297711133957
train loss item: 0.23795580863952637
train loss item: 0.19671280682086945
train loss item: 0.17346356809139252
train loss item: 0.10928390920162201
train loss item: 0.1763187050819397
train loss item: 0.17625953257083893
train loss item: 0.23120859265327454
train loss item: 0.08899949491024017
train loss item: 0.3705887496471405
train loss item: 0.07025392353534698
train loss item: 0.22739602625370026
train loss item: 0.11909444630146027
train loss item: 0.0760258212685585
train loss item: 0.307659387588501
train loss item: 0.14930060505867004
train loss item: 0.13150382041931152
train loss item: 0.1394181102514267
train loss item: 0.1285080462694168
train loss item: 0.11351559311151505
train loss item: 0.10141318291425705
train loss item: 0.07778249680995941
train loss item: 0.24447397887706757
train loss item: 0.14397495985031128
train loss item: 0.08271446824073792
train loss item: 0.15020231902599335
train loss item: 0.14966809749603271
train loss item: 0.6440907716751099
train loss item: 0.12714079022407532
test loss item: 0.11686717718839645
test loss item: 0.17600995302200317
test loss item: 0.105954609811306
test loss item: 0.48947271704673767
test loss item: 0.12519480288028717
test loss item: 0.24105697870254517
test loss item: 0.10680897533893585
test loss item: 0.09228084981441498
test loss item: 0.14069713652133942
test loss item: 0.21516753733158112
test loss item: 0.19351325929164886
test loss item: 0.14235107600688934
test loss item: 0.10357776284217834
test loss item: 0.12340239435434341
test loss item: 0.13629333674907684
test loss item: 0.2686782777309418
test loss item: 0.16462825238704681
test loss item: 0.1657932698726654
test loss item: 0.3625342845916748
test loss item: 0.15201303362846375
test loss item: 0.1480821818113327
test loss item: 0.11280207335948944
test loss item: 0.1898135095834732
test loss item: 0.15542162954807281
test loss item: 0.21062378585338593
test loss item: 0.10676082968711853
test loss item: 0.1076902523636818
test loss item: 0.20174629986286163
test loss item: 0.23551638424396515
test loss item: 0.10998644679784775
test loss item: 0.14480222761631012
test loss item: 0.12272864580154419
test loss item: 0.2618618607521057
test loss item: 0.1291191428899765
test loss item: 0.19263048470020294
test loss item: 0.31011322140693665
test loss item: 0.19101372361183167
test loss item: 0.11680480092763901
test loss item: 0.37005481123924255
test loss item: 0.1261490285396576
test loss item: 0.29321473836898804
test loss item: 0.3320254981517792
test loss item: 0.11603277921676636
test loss item: 0.08358929306268692
test loss item: 0.1468733549118042
Epoch [32/100], Training Loss: 0.1701, Testing Loss: 0.1808
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 33/100
train loss item: 0.1835910677909851
train loss item: 0.12758338451385498
train loss item: 0.11738757789134979
train loss item: 0.14329765737056732
train loss item: 0.10742641240358353
train loss item: 0.12017174065113068
train loss item: 0.1591811627149582
train loss item: 0.19205714762210846
train loss item: 0.06326241791248322
train loss item: 0.1248096227645874
train loss item: 0.07355883717536926
train loss item: 0.18271465599536896
train loss item: 0.10959194600582123
train loss item: 0.08604391664266586
train loss item: 0.13962793350219727
train loss item: 0.39187467098236084
train loss item: 0.08721936494112015
train loss item: 0.19576872885227203
train loss item: 0.15277069807052612
train loss item: 0.1406748741865158
train loss item: 0.09583017230033875
train loss item: 0.1506294310092926
train loss item: 0.12594468891620636
train loss item: 0.14435116946697235
train loss item: 0.07971178740262985
train loss item: 0.2795218527317047
train loss item: 0.06430642306804657
train loss item: 0.31878119707107544
train loss item: 0.09716488420963287
train loss item: 0.06639157980680466
train loss item: 0.3190069794654846
train loss item: 0.11797924339771271
train loss item: 0.11301817744970322
train loss item: 0.14711274206638336
train loss item: 0.13941390812397003
train loss item: 0.10779659450054169
train loss item: 0.10142336785793304
train loss item: 0.07005611807107925
train loss item: 0.30742064118385315
train loss item: 0.1006820797920227
train loss item: 0.06643205136060715
train loss item: 0.12381632626056671
train loss item: 0.1428263932466507
train loss item: 0.6228346824645996
train loss item: 0.1467684507369995
test loss item: 0.08495543897151947
test loss item: 0.13279148936271667
test loss item: 0.08901801705360413
test loss item: 0.37408262491226196
test loss item: 0.10495717823505402
test loss item: 0.16895842552185059
test loss item: 0.09497535228729248
test loss item: 0.06874816864728928
test loss item: 0.1227964386343956
test loss item: 0.17831453680992126
test loss item: 0.1675601750612259
test loss item: 0.11058904975652695
test loss item: 0.09125559777021408
test loss item: 0.1038253977894783
test loss item: 0.1189519613981247
test loss item: 0.18204499781131744
test loss item: 0.12380199134349823
test loss item: 0.13676851987838745
test loss item: 0.2530885338783264
test loss item: 0.12089153379201889
test loss item: 0.12420079857110977
test loss item: 0.10228146612644196
test loss item: 0.16956472396850586
test loss item: 0.12035182118415833
test loss item: 0.162971630692482
test loss item: 0.09587796777486801
test loss item: 0.09923166036605835
test loss item: 0.14128440618515015
test loss item: 0.17190079391002655
test loss item: 0.09537458419799805
test loss item: 0.11930027604103088
test loss item: 0.10563123971223831
test loss item: 0.20807163417339325
test loss item: 0.12037693709135056
test loss item: 0.1444360762834549
test loss item: 0.2483021318912506
test loss item: 0.16303476691246033
test loss item: 0.08547951281070709
test loss item: 0.19818459451198578
test loss item: 0.10237108170986176
test loss item: 0.22428582608699799
test loss item: 0.2351205050945282
test loss item: 0.10346323251724243
test loss item: 0.04826539754867554
test loss item: 0.14301429688930511
Epoch [33/100], Training Loss: 0.1544, Testing Loss: 0.1414
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 34/100
train loss item: 0.18692119419574738
train loss item: 0.1824561357498169
train loss item: 0.1078905388712883
train loss item: 0.128424733877182
train loss item: 0.11252765357494354
train loss item: 0.1176682561635971
train loss item: 0.19617033004760742
train loss item: 0.12794992327690125
train loss item: 0.06524340063333511
train loss item: 0.12846872210502625
train loss item: 0.06902904063463211
train loss item: 0.4129624664783478
train loss item: 0.1258372813463211
train loss item: 0.09828603267669678
train loss item: 0.20194301009178162
train loss item: 0.33547890186309814
train loss item: 0.09132663160562515
train loss item: 0.24834463000297546
train loss item: 0.2072291374206543
train loss item: 0.1797732412815094
train loss item: 0.10768511146306992
train loss item: 0.16831262409687042
train loss item: 0.30475378036499023
train loss item: 0.1827935427427292
train loss item: 0.07895227521657944
train loss item: 0.26902318000793457
train loss item: 0.07531747221946716
train loss item: 0.20802728831768036
train loss item: 0.12430334836244583
train loss item: 0.08425860852003098
train loss item: 0.2894730567932129
train loss item: 0.11998695135116577
train loss item: 0.12941771745681763
train loss item: 0.1468755006790161
train loss item: 0.12226282060146332
train loss item: 0.08928590267896652
train loss item: 0.09057188034057617
train loss item: 0.06936057657003403
train loss item: 0.2363867461681366
train loss item: 0.11759360879659653
train loss item: 0.07490016520023346
train loss item: 0.12750297784805298
train loss item: 0.14342956244945526
train loss item: 0.6243656277656555
train loss item: 0.1519566774368286
test loss item: 0.09751764684915543
test loss item: 0.1476752758026123
test loss item: 0.09378109872341156
test loss item: 0.36826997995376587
test loss item: 0.10883286595344543
test loss item: 0.20659703016281128
test loss item: 0.08927301317453384
test loss item: 0.0794186219573021
test loss item: 0.12334146350622177
test loss item: 0.16828350722789764
test loss item: 0.16706396639347076
test loss item: 0.11484517902135849
test loss item: 0.0952259972691536
test loss item: 0.10423054546117783
test loss item: 0.11848681420087814
test loss item: 0.20769977569580078
test loss item: 0.14609825611114502
test loss item: 0.14201362431049347
test loss item: 0.293572336435318
test loss item: 0.13275067508220673
test loss item: 0.12604737281799316
test loss item: 0.10485944896936417
test loss item: 0.15506993234157562
test loss item: 0.1190461665391922
test loss item: 0.17175577580928802
test loss item: 0.09220881760120392
test loss item: 0.1029563695192337
test loss item: 0.16956248879432678
test loss item: 0.18485556542873383
test loss item: 0.09639855474233627
test loss item: 0.1240992471575737
test loss item: 0.10183106362819672
test loss item: 0.20981770753860474
test loss item: 0.10799763351678848
test loss item: 0.16335426270961761
test loss item: 0.2320852279663086
test loss item: 0.147494375705719
test loss item: 0.08837553858757019
test loss item: 0.3017154633998871
test loss item: 0.1045270785689354
test loss item: 0.22970463335514069
test loss item: 0.26112931966781616
test loss item: 0.09965430200099945
test loss item: 0.07381247729063034
test loss item: 0.13752137124538422
Epoch [34/100], Training Loss: 0.1658, Testing Loss: 0.1491
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 35/100
train loss item: 0.1836639642715454
train loss item: 0.13308857381343842
train loss item: 0.11308938264846802
train loss item: 0.13266247510910034
train loss item: 0.07961396872997284
train loss item: 0.1018822118639946
train loss item: 0.16254079341888428
train loss item: 0.15006688237190247
train loss item: 0.06126675382256508
train loss item: 0.11149884760379791
train loss item: 0.07325968891382217
train loss item: 0.2798231244087219
train loss item: 0.10790353268384933
train loss item: 0.08741455525159836
train loss item: 0.13688808679580688
train loss item: 0.4639807939529419
train loss item: 0.09753543883562088
train loss item: 0.20788681507110596
train loss item: 0.18888629972934723
train loss item: 0.11187070608139038
train loss item: 0.07998214662075043
train loss item: 0.13396622240543365
train loss item: 0.1413787454366684
train loss item: 0.13525108993053436
train loss item: 0.08042509853839874
train loss item: 0.20326954126358032
train loss item: 0.06488971412181854
train loss item: 0.18463149666786194
train loss item: 0.09367723017930984
train loss item: 0.06249115988612175
train loss item: 0.24168626964092255
train loss item: 0.11009619385004044
train loss item: 0.09981069713830948
train loss item: 0.12203363329172134
train loss item: 0.11501140147447586
train loss item: 0.0823405459523201
train loss item: 0.08529011160135269
train loss item: 0.0647236630320549
train loss item: 0.21768787503242493
train loss item: 0.09683534502983093
train loss item: 0.06133263558149338
train loss item: 0.11849533766508102
train loss item: 0.12039869278669357
train loss item: 0.6219063401222229
train loss item: 0.13573254644870758
test loss item: 0.0841599553823471
test loss item: 0.1299968659877777
test loss item: 0.08654484152793884
test loss item: 0.39504140615463257
test loss item: 0.09730264544487
test loss item: 0.17959947884082794
test loss item: 0.08998073637485504
test loss item: 0.06682873517274857
test loss item: 0.1128772720694542
test loss item: 0.17484284937381744
test loss item: 0.1551109105348587
test loss item: 0.10990415513515472
test loss item: 0.0924067497253418
test loss item: 0.096476711332798
test loss item: 0.11231984198093414
test loss item: 0.19482919573783875
test loss item: 0.12073701620101929
test loss item: 0.13116712868213654
test loss item: 0.2696051299571991
test loss item: 0.1192011833190918
test loss item: 0.12310289591550827
test loss item: 0.09448640048503876
test loss item: 0.1514519453048706
test loss item: 0.116585873067379
test loss item: 0.15878164768218994
test loss item: 0.08444754779338837
test loss item: 0.09333767741918564
test loss item: 0.1407509744167328
test loss item: 0.17709635198116302
test loss item: 0.0892883837223053
test loss item: 0.10974352061748505
test loss item: 0.10337456315755844
test loss item: 0.20652420818805695
test loss item: 0.11334167420864105
test loss item: 0.14856940507888794
test loss item: 0.253279447555542
test loss item: 0.15425193309783936
test loss item: 0.08297078311443329
test loss item: 0.24418091773986816
test loss item: 0.09976885467767715
test loss item: 0.2324703186750412
test loss item: 0.24219852685928345
test loss item: 0.09946000576019287
test loss item: 0.04995901510119438
test loss item: 0.1392076015472412
Epoch [35/100], Training Loss: 0.1435, Testing Loss: 0.1406
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 36/100
train loss item: 0.15366318821907043
train loss item: 0.12578611075878143
train loss item: 0.11846720427274704
train loss item: 0.15793579816818237
train loss item: 0.07422570884227753
train loss item: 0.09906262904405594
train loss item: 0.18336497247219086
train loss item: 0.1250353455543518
train loss item: 0.05965487286448479
train loss item: 0.10083767026662827
train loss item: 0.06793654710054398
train loss item: 0.2685282826423645
train loss item: 0.11630858480930328
train loss item: 0.11455903202295303
train loss item: 0.1675707995891571
train loss item: 0.19915202260017395
train loss item: 0.11789403110742569
train loss item: 0.1789109706878662
train loss item: 0.210560142993927
train loss item: 0.10999929159879684
train loss item: 0.08300599455833435
train loss item: 0.1341816782951355
train loss item: 0.14644069969654083
train loss item: 0.10828777402639389
train loss item: 0.07389988005161285
train loss item: 0.22866706550121307
train loss item: 0.060229238122701645
train loss item: 0.14819972217082977
train loss item: 0.09229235351085663
train loss item: 0.0619635172188282
train loss item: 0.22989940643310547
train loss item: 0.12256500124931335
train loss item: 0.13227473199367523
train loss item: 0.13646425306797028
train loss item: 0.1103716790676117
train loss item: 0.08148407936096191
train loss item: 0.08515334129333496
train loss item: 0.06219836324453354
train loss item: 0.19486068189144135
train loss item: 0.10670829564332962
train loss item: 0.06063063070178032
train loss item: 0.11733608692884445
train loss item: 0.1268121600151062
train loss item: 0.5979250073432922
train loss item: 0.13790984451770782
test loss item: 0.08917130529880524
test loss item: 0.14370916783809662
test loss item: 0.09049810469150543
test loss item: 0.43978601694107056
test loss item: 0.10167621076107025
test loss item: 0.20897692441940308
test loss item: 0.09783425182104111
test loss item: 0.06846827268600464
test loss item: 0.12502910196781158
test loss item: 0.19422420859336853
test loss item: 0.16568946838378906
test loss item: 0.11497488617897034
test loss item: 0.10152292996644974
test loss item: 0.10212858766317368
test loss item: 0.11809488385915756
test loss item: 0.22498387098312378
test loss item: 0.13312408328056335
test loss item: 0.1412763148546219
test loss item: 0.3137306272983551
test loss item: 0.12603741884231567
test loss item: 0.13322213292121887
test loss item: 0.10851609706878662
test loss item: 0.15924391150474548
test loss item: 0.1317143440246582
test loss item: 0.17515867948532104
test loss item: 0.09189000725746155
test loss item: 0.10443657636642456
test loss item: 0.15835796296596527
test loss item: 0.2018653154373169
test loss item: 0.09444035589694977
test loss item: 0.11590906232595444
test loss item: 0.11063248664140701
test loss item: 0.22695259749889374
test loss item: 0.11992485076189041
test loss item: 0.1639525294303894
test loss item: 0.27742084860801697
test loss item: 0.1630690097808838
test loss item: 0.09744302928447723
test loss item: 0.314184308052063
test loss item: 0.10809040814638138
test loss item: 0.26812756061553955
test loss item: 0.28591617941856384
test loss item: 0.11095298081636429
test loss item: 0.053685951977968216
test loss item: 0.1461501121520996
Epoch [36/100], Training Loss: 0.1375, Testing Loss: 0.1560
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 37/100
train loss item: 0.1623993217945099
train loss item: 0.11014527827501297
train loss item: 0.11258881539106369
train loss item: 0.11382927000522614
train loss item: 0.08204936236143112
train loss item: 0.1103571429848671
train loss item: 0.13379022479057312
train loss item: 0.11151242256164551
train loss item: 0.0642852783203125
train loss item: 0.10210806131362915
train loss item: 0.06505979597568512
train loss item: 0.22404801845550537
train loss item: 0.09800446778535843
train loss item: 0.1198229044675827
train loss item: 0.19941480457782745
train loss item: 0.21247686445713043
train loss item: 0.14965181052684784
train loss item: 0.19407516717910767
train loss item: 0.13741138577461243
train loss item: 0.1254246085882187
train loss item: 0.09941866993904114
train loss item: 0.1416299194097519
train loss item: 0.12328360974788666
train loss item: 0.09930068254470825
train loss item: 0.07706253230571747
train loss item: 0.21091178059577942
train loss item: 0.05588136240839958
train loss item: 0.18385660648345947
train loss item: 0.08825504034757614
train loss item: 0.061780449002981186
train loss item: 0.20331043004989624
train loss item: 0.09868813306093216
train loss item: 0.10390743613243103
train loss item: 0.12359712272882462
train loss item: 0.09924478828907013
train loss item: 0.0774092823266983
train loss item: 0.08291304111480713
train loss item: 0.0613488107919693
train loss item: 0.29880136251449585
train loss item: 0.09074166417121887
train loss item: 0.06241590157151222
train loss item: 0.11212250590324402
train loss item: 0.12084894627332687
train loss item: 0.6169294714927673
train loss item: 0.140107199549675
test loss item: 0.09071198850870132
test loss item: 0.15236622095108032
test loss item: 0.08994986861944199
test loss item: 0.34309229254722595
test loss item: 0.10184349119663239
test loss item: 0.24147352576255798
test loss item: 0.092440165579319
test loss item: 0.07126977294683456
test loss item: 0.11671469360589981
test loss item: 0.15927723050117493
test loss item: 0.15310978889465332
test loss item: 0.11791026592254639
test loss item: 0.09640037268400192
test loss item: 0.09915013611316681
test loss item: 0.11102908849716187
test loss item: 0.22126485407352448
test loss item: 0.13791729509830475
test loss item: 0.1353723108768463
test loss item: 0.3235216736793518
test loss item: 0.12438885122537613
test loss item: 0.1274651139974594
test loss item: 0.10440292954444885
test loss item: 0.14557558298110962
test loss item: 0.12613752484321594
test loss item: 0.1709447205066681
test loss item: 0.08799654245376587
test loss item: 0.1001410111784935
test loss item: 0.18385863304138184
test loss item: 0.1821960210800171
test loss item: 0.09013689309358597
test loss item: 0.10728918761014938
test loss item: 0.1032048836350441
test loss item: 0.23163342475891113
test loss item: 0.10830358415842056
test loss item: 0.15693455934524536
test loss item: 0.21621370315551758
test loss item: 0.14730170369148254
test loss item: 0.09271152317523956
test loss item: 0.41642436385154724
test loss item: 0.10605324804782867
test loss item: 0.26426878571510315
test loss item: 0.3121931254863739
test loss item: 0.10191313922405243
test loss item: 0.062225092202425
test loss item: 0.13739457726478577
Epoch [37/100], Training Loss: 0.1347, Testing Loss: 0.1525
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 38/100
train loss item: 0.14861071109771729
train loss item: 0.11887761205434799
train loss item: 0.10619135200977325
train loss item: 0.10951073467731476
train loss item: 0.07277946174144745
train loss item: 0.09721547365188599
train loss item: 0.12895500659942627
train loss item: 0.11163070797920227
train loss item: 0.0604720413684845
train loss item: 0.10371039062738419
train loss item: 0.06797448545694351
train loss item: 0.17572374641895294
train loss item: 0.11413624882698059
train loss item: 0.09220409393310547
train loss item: 0.1651451587677002
train loss item: 0.20264668762683868
train loss item: 0.11401934921741486
train loss item: 0.1866714358329773
train loss item: 0.1143592894077301
train loss item: 0.1502930074930191
train loss item: 0.10936487466096878
train loss item: 0.13969528675079346
train loss item: 0.15107186138629913
train loss item: 0.12666486203670502
train loss item: 0.08004327118396759
train loss item: 0.2177557796239853
train loss item: 0.06436921656131744
train loss item: 0.18986830115318298
train loss item: 0.10080340504646301
train loss item: 0.07659617811441422
train loss item: 0.2040967494249344
train loss item: 0.1420341432094574
train loss item: 0.10663870722055435
train loss item: 0.13379435241222382
train loss item: 0.11105040460824966
train loss item: 0.08344727754592896
train loss item: 0.08417348563671112
train loss item: 0.06332157552242279
train loss item: 0.274903804063797
train loss item: 0.08933296799659729
train loss item: 0.07389524579048157
train loss item: 0.16359800100326538
train loss item: 0.14101091027259827
train loss item: 0.5965385437011719
train loss item: 0.12618613243103027
test loss item: 0.07818444818258286
test loss item: 0.14841505885124207
test loss item: 0.09131503105163574
test loss item: 0.28170689940452576
test loss item: 0.10583344101905823
test loss item: 0.2271421104669571
test loss item: 0.08627999573945999
test loss item: 0.06637167185544968
test loss item: 0.11673113703727722
test loss item: 0.14590071141719818
test loss item: 0.15120579302310944
test loss item: 0.09957966953516006
test loss item: 0.09242748469114304
test loss item: 0.09513864666223526
test loss item: 0.11067267507314682
test loss item: 0.19667163491249084
test loss item: 0.14105232059955597
test loss item: 0.13663633167743683
test loss item: 0.29675769805908203
test loss item: 0.12026481330394745
test loss item: 0.11311951279640198
test loss item: 0.10388956218957901
test loss item: 0.14166812598705292
test loss item: 0.09963954985141754
test loss item: 0.17168787121772766
test loss item: 0.0850113034248352
test loss item: 0.09777124971151352
test loss item: 0.18602435290813446
test loss item: 0.16608604788780212
test loss item: 0.0885973647236824
test loss item: 0.11256907880306244
test loss item: 0.09776803851127625
test loss item: 0.2132597267627716
test loss item: 0.10794171690940857
test loss item: 0.151156947016716
test loss item: 0.1813090443611145
test loss item: 0.12676803767681122
test loss item: 0.07231134176254272
test loss item: 0.366910845041275
test loss item: 0.09346437454223633
test loss item: 0.23232616484165192
test loss item: 0.27916210889816284
test loss item: 0.09641613811254501
test loss item: 0.0497913584113121
test loss item: 0.1413857340812683
Epoch [38/100], Training Loss: 0.1354, Testing Loss: 0.1414
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 39/100
train loss item: 0.15004698932170868
train loss item: 0.16437916457653046
train loss item: 0.11059002578258514
train loss item: 0.13923032581806183
train loss item: 0.07928240299224854
train loss item: 0.09545505046844482
train loss item: 0.1505769044160843
train loss item: 0.1143483892083168
train loss item: 0.057618219405412674
train loss item: 0.0957157239317894
train loss item: 0.06585904210805893
train loss item: 0.2234262377023697
train loss item: 0.09997344017028809
train loss item: 0.11145529896020889
train loss item: 0.13187509775161743
train loss item: 0.20413149893283844
train loss item: 0.08159694820642471
train loss item: 0.1782919317483902
train loss item: 0.19738896191120148
train loss item: 0.135941281914711
train loss item: 0.08142376691102982
train loss item: 0.14002475142478943
train loss item: 0.1397460699081421
train loss item: 0.0996960923075676
train loss item: 0.07282407581806183
train loss item: 0.20476283133029938
train loss item: 0.05616004392504692
train loss item: 0.1570056825876236
train loss item: 0.08418616652488708
train loss item: 0.06169300898909569
train loss item: 0.19397762417793274
train loss item: 0.11056558787822723
train loss item: 0.1091800406575203
train loss item: 0.11224190890789032
train loss item: 0.11707549542188644
train loss item: 0.08251205831766129
train loss item: 0.07755256444215775
train loss item: 0.0612955167889595
train loss item: 0.22148099541664124
train loss item: 0.09088234603404999
train loss item: 0.06246314197778702
train loss item: 0.13358649611473083
train loss item: 0.12649892270565033
train loss item: 0.5960915684700012
train loss item: 0.11248953640460968
test loss item: 0.0853067934513092
test loss item: 0.17662128806114197
test loss item: 0.09420090913772583
test loss item: 0.40905967354774475
test loss item: 0.1151358038187027
test loss item: 0.2820027470588684
test loss item: 0.08444234728813171
test loss item: 0.06841093301773071
test loss item: 0.1262383759021759
test loss item: 0.17064723372459412
test loss item: 0.17011182010173798
test loss item: 0.1061875969171524
test loss item: 0.09318489581346512
test loss item: 0.09923181682825089
test loss item: 0.11848530918359756
test loss item: 0.2675324082374573
test loss item: 0.16298802196979523
test loss item: 0.1518818438053131
test loss item: 0.3853415250778198
test loss item: 0.13906903564929962
test loss item: 0.1250668317079544
test loss item: 0.10904344171285629
test loss item: 0.15613238513469696
test loss item: 0.11402302235364914
test loss item: 0.20291867852210999
test loss item: 0.08867080509662628
test loss item: 0.10282228142023087
test loss item: 0.2357960045337677
test loss item: 0.201010063290596
test loss item: 0.09093452244997025
test loss item: 0.1203569695353508
test loss item: 0.09960762411355972
test loss item: 0.2697296440601349
test loss item: 0.10884885489940643
test loss item: 0.17539748549461365
test loss item: 0.25019288063049316
test loss item: 0.14390158653259277
test loss item: 0.08378321677446365
test loss item: 0.47680971026420593
test loss item: 0.10378401726484299
test loss item: 0.29858240485191345
test loss item: 0.3638339042663574
test loss item: 0.10030315071344376
test loss item: 0.05464877188205719
test loss item: 0.15829026699066162
Epoch [39/100], Training Loss: 0.1309, Testing Loss: 0.1676
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 40/100
train loss item: 0.17744484543800354
train loss item: 0.12646950781345367
train loss item: 0.10699567198753357
train loss item: 0.12151428312063217
train loss item: 0.08617877215147018
train loss item: 0.11577237397432327
train loss item: 0.13420423865318298
train loss item: 0.1095636785030365
train loss item: 0.06584301590919495
train loss item: 0.10945752263069153
train loss item: 0.06659083813428879
train loss item: 0.22874535620212555
train loss item: 0.09854130446910858
train loss item: 0.11469940096139908
train loss item: 0.219332754611969
train loss item: 0.3102824091911316
train loss item: 0.1519385576248169
train loss item: 0.18869738280773163
train loss item: 0.15518060326576233
train loss item: 0.17592282593250275
train loss item: 0.12550094723701477
train loss item: 0.13801886141300201
train loss item: 0.17136725783348083
train loss item: 0.09893176704645157
train loss item: 0.0783298909664154
train loss item: 0.2069472223520279
train loss item: 0.05639481917023659
train loss item: 0.2170267105102539
train loss item: 0.09778381884098053
train loss item: 0.06787444651126862
train loss item: 0.2704596221446991
train loss item: 0.13585864007472992
train loss item: 0.11910443007946014
train loss item: 0.19854146242141724
train loss item: 0.1389639675617218
train loss item: 0.09457211196422577
train loss item: 0.08942927420139313
train loss item: 0.06229998543858528
train loss item: 0.24012506008148193
train loss item: 0.0911029800772667
train loss item: 0.07659544050693512
train loss item: 0.12691481411457062
train loss item: 0.13746407628059387
train loss item: 0.5482261776924133
train loss item: 0.12436291575431824
test loss item: 0.07838307321071625
test loss item: 0.16167184710502625
test loss item: 0.09181688725948334
test loss item: 0.36120229959487915
test loss item: 0.11856915056705475
test loss item: 0.25015756487846375
test loss item: 0.08654162287712097
test loss item: 0.06525411456823349
test loss item: 0.12732882797718048
test loss item: 0.1783524751663208
test loss item: 0.17418110370635986
test loss item: 0.11232908070087433
test loss item: 0.09171057492494583
test loss item: 0.1047467589378357
test loss item: 0.12122791260480881
test loss item: 0.22978109121322632
test loss item: 0.1559077501296997
test loss item: 0.157995343208313
test loss item: 0.33485275506973267
test loss item: 0.1316462755203247
test loss item: 0.1162315234541893
test loss item: 0.10921642929315567
test loss item: 0.17065085470676422
test loss item: 0.11244234442710876
test loss item: 0.20057132840156555
test loss item: 0.09448922425508499
test loss item: 0.09922285377979279
test loss item: 0.21371573209762573
test loss item: 0.19109532237052917
test loss item: 0.09185745567083359
test loss item: 0.13191711902618408
test loss item: 0.1005302220582962
test loss item: 0.24494363367557526
test loss item: 0.11717468500137329
test loss item: 0.17143605649471283
test loss item: 0.23696449398994446
test loss item: 0.15430153906345367
test loss item: 0.07616592943668365
test loss item: 0.3724243938922882
test loss item: 0.09737801551818848
test loss item: 0.27114537358283997
test loss item: 0.32002055644989014
test loss item: 0.10078824311494827
test loss item: 0.04849325120449066
test loss item: 0.14006885886192322
Epoch [40/100], Training Loss: 0.1461, Testing Loss: 0.1582
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 41/100
train loss item: 0.15996363759040833
train loss item: 0.13220317661762238
train loss item: 0.10034231096506119
train loss item: 0.17588742077350616
train loss item: 0.0779634490609169
train loss item: 0.08573884516954422
train loss item: 0.11340529471635818
train loss item: 0.1295224130153656
train loss item: 0.06245768815279007
train loss item: 0.12539203464984894
train loss item: 0.0773221105337143
train loss item: 0.19851821660995483
train loss item: 0.12121625244617462
train loss item: 0.08629932999610901
train loss item: 0.13154299557209015
train loss item: 0.21185827255249023
train loss item: 0.07952083647251129
train loss item: 0.16963344812393188
train loss item: 0.12880834937095642
train loss item: 0.1401015967130661
train loss item: 0.11946360766887665
train loss item: 0.13095419108867645
train loss item: 0.13444823026657104
train loss item: 0.12034958600997925
train loss item: 0.0789487212896347
train loss item: 0.24706846475601196
train loss item: 0.055987708270549774
train loss item: 0.25276824831962585
train loss item: 0.08164554834365845
train loss item: 0.06567256152629852
train loss item: 0.2018175572156906
train loss item: 0.12606178224086761
train loss item: 0.11779307574033737
train loss item: 0.19089528918266296
train loss item: 0.13159888982772827
train loss item: 0.10671161860227585
train loss item: 0.09462962299585342
train loss item: 0.06643415987491608
train loss item: 0.18441076576709747
train loss item: 0.0933154970407486
train loss item: 0.0704742893576622
train loss item: 0.11595963686704636
train loss item: 0.12884379923343658
train loss item: 0.5342813730239868
train loss item: 0.11307281255722046
test loss item: 0.080231212079525
test loss item: 0.13874799013137817
test loss item: 0.09473341703414917
test loss item: 0.4004529118537903
test loss item: 0.11075863242149353
test loss item: 0.1859789937734604
test loss item: 0.08758490532636642
test loss item: 0.06970886141061783
test loss item: 0.12907858192920685
test loss item: 0.17892567813396454
test loss item: 0.17717885971069336
test loss item: 0.10209518671035767
test loss item: 0.092256560921669
test loss item: 0.10588138550519943
test loss item: 0.12353470176458359
test loss item: 0.2072807401418686
test loss item: 0.13904322683811188
test loss item: 0.1448458582162857
test loss item: 0.2750263512134552
test loss item: 0.12960925698280334
test loss item: 0.11811914294958115
test loss item: 0.11175128817558289
test loss item: 0.16908381879329681
test loss item: 0.10559746623039246
test loss item: 0.1767411082983017
test loss item: 0.09493396431207657
test loss item: 0.10454694926738739
test loss item: 0.16270148754119873
test loss item: 0.17940236628055573
test loss item: 0.09318374842405319
test loss item: 0.1279546469449997
test loss item: 0.10109654814004898
test loss item: 0.21120575070381165
test loss item: 0.12133517116308212
test loss item: 0.15483127534389496
test loss item: 0.26396653056144714
test loss item: 0.1531420648097992
test loss item: 0.07703503221273422
test loss item: 0.2299736589193344
test loss item: 0.09560666978359222
test loss item: 0.24039454758167267
test loss item: 0.2576468288898468
test loss item: 0.10128055512905121
test loss item: 0.045884206891059875
test loss item: 0.12786991894245148
Epoch [41/100], Training Loss: 0.1349, Testing Loss: 0.1466
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 42/100
train loss item: 0.14243999123573303
train loss item: 0.12794804573059082
train loss item: 0.10224912315607071
train loss item: 0.11873456090688705
train loss item: 0.08859730511903763
train loss item: 0.10311078280210495
train loss item: 0.15940436720848083
train loss item: 0.14586776494979858
train loss item: 0.056895848363637924
train loss item: 0.11575520038604736
train loss item: 0.0655144602060318
train loss item: 0.2953225076198578
train loss item: 0.10261737555265427
train loss item: 0.09509217739105225
train loss item: 0.15565796196460724
train loss item: 0.21145053207874298
train loss item: 0.08399123698472977
train loss item: 0.2270091325044632
train loss item: 0.15590959787368774
train loss item: 0.11945370584726334
train loss item: 0.08503148704767227
train loss item: 0.11093372106552124
train loss item: 0.1599453091621399
train loss item: 0.09559568017721176
train loss item: 0.07137883454561234
train loss item: 0.1967613250017166
train loss item: 0.057054273784160614
train loss item: 0.16971248388290405
train loss item: 0.09169463068246841
train loss item: 0.06701511889696121
train loss item: 0.20142219960689545
train loss item: 0.12338922917842865
train loss item: 0.11976997554302216
train loss item: 0.11072713881731033
train loss item: 0.10988041013479233
train loss item: 0.08006851375102997
train loss item: 0.07785454392433167
train loss item: 0.06510310620069504
train loss item: 0.2082422971725464
train loss item: 0.09918057173490524
train loss item: 0.06510376185178757
train loss item: 0.1014050841331482
train loss item: 0.11221175640821457
train loss item: 0.5503576993942261
train loss item: 0.11294817924499512
test loss item: 0.09462863951921463
test loss item: 0.15900053083896637
test loss item: 0.09503447264432907
test loss item: 0.4654732644557953
test loss item: 0.11169174313545227
test loss item: 0.22611019015312195
test loss item: 0.08587802946567535
test loss item: 0.07326431572437286
test loss item: 0.13228389620780945
test loss item: 0.19003525376319885
test loss item: 0.1836882084608078
test loss item: 0.1197005957365036
test loss item: 0.09852258116006851
test loss item: 0.10416623204946518
test loss item: 0.12154178321361542
test loss item: 0.25200027227401733
test loss item: 0.15720199048519135
test loss item: 0.14723485708236694
test loss item: 0.3382575213909149
test loss item: 0.14181415736675262
test loss item: 0.13257916271686554
test loss item: 0.11488741636276245
test loss item: 0.16667550802230835
test loss item: 0.12412944436073303
test loss item: 0.18976648151874542
test loss item: 0.09195318818092346
test loss item: 0.10798734426498413
test loss item: 0.18800367414951324
test loss item: 0.2055659294128418
test loss item: 0.09376335889101028
test loss item: 0.12848424911499023
test loss item: 0.10675907880067825
test loss item: 0.23920294642448425
test loss item: 0.11442437767982483
test loss item: 0.17243444919586182
test loss item: 0.28941890597343445
test loss item: 0.16370368003845215
test loss item: 0.09370025992393494
test loss item: 0.34618833661079407
test loss item: 0.11029788851737976
test loss item: 0.27908775210380554
test loss item: 0.310097873210907
test loss item: 0.10751530528068542
test loss item: 0.06845136731863022
test loss item: 0.15480343997478485
Epoch [42/100], Training Loss: 0.1315, Testing Loss: 0.1644
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 43/100
train loss item: 0.16540569067001343
train loss item: 0.11673695594072342
train loss item: 0.1014523133635521
train loss item: 0.11344369500875473
train loss item: 0.07108545303344727
train loss item: 0.09218595921993256
train loss item: 0.10204115509986877
train loss item: 0.11966142058372498
train loss item: 0.06248227879405022
train loss item: 0.10889311879873276
train loss item: 0.08215563744306564
train loss item: 0.1525161862373352
train loss item: 0.11501938104629517
train loss item: 0.08120457828044891
train loss item: 0.19848084449768066
train loss item: 0.3658398389816284
train loss item: 0.08327466249465942
train loss item: 0.2025042474269867
train loss item: 0.12486296147108078
train loss item: 0.1741952747106552
train loss item: 0.11023158580064774
train loss item: 0.1493450105190277
train loss item: 0.13881884515285492
train loss item: 0.18860313296318054
train loss item: 0.0793621838092804
train loss item: 0.35226038098335266
train loss item: 0.05434759333729744
train loss item: 0.19821247458457947
train loss item: 0.08802997320890427
train loss item: 0.0638146921992302
train loss item: 0.21677491068840027
train loss item: 0.09918332099914551
train loss item: 0.10329341143369675
train loss item: 0.14185833930969238
train loss item: 0.12100851535797119
train loss item: 0.10580688714981079
train loss item: 0.09640977531671524
train loss item: 0.061799097806215286
train loss item: 0.26003938913345337
train loss item: 0.10344286262989044
train loss item: 0.06108654662966728
train loss item: 0.11201189458370209
train loss item: 0.13608120381832123
train loss item: 0.543986439704895
train loss item: 0.1221931204199791
test loss item: 0.08653701841831207
test loss item: 0.1318858563899994
test loss item: 0.08586998283863068
test loss item: 0.3976803123950958
test loss item: 0.0997760146856308
test loss item: 0.171644389629364
test loss item: 0.09711422771215439
test loss item: 0.06747648119926453
test loss item: 0.12317094206809998
test loss item: 0.18995076417922974
test loss item: 0.16576580703258514
test loss item: 0.1268107295036316
test loss item: 0.09865030646324158
test loss item: 0.11095243692398071
test loss item: 0.11783735454082489
test loss item: 0.1955222487449646
test loss item: 0.12502571940422058
test loss item: 0.13137897849082947
test loss item: 0.25863057374954224
test loss item: 0.12677790224552155
test loss item: 0.1277918517589569
test loss item: 0.10018334537744522
test loss item: 0.18026059865951538
test loss item: 0.12913137674331665
test loss item: 0.17246074974536896
test loss item: 0.086696095764637
test loss item: 0.09405689686536789
test loss item: 0.1326129138469696
test loss item: 0.1814454197883606
test loss item: 0.0918709859251976
test loss item: 0.12221596390008926
test loss item: 0.11367762088775635
test loss item: 0.21924637258052826
test loss item: 0.13314469158649445
test loss item: 0.14683835208415985
test loss item: 0.26711300015449524
test loss item: 0.18521803617477417
test loss item: 0.08768738806247711
test loss item: 0.2188308835029602
test loss item: 0.10457325726747513
test loss item: 0.23534823954105377
test loss item: 0.23788650333881378
test loss item: 0.11119364947080612
test loss item: 0.05921659618616104
test loss item: 0.14767572283744812
Epoch [43/100], Training Loss: 0.1409, Testing Loss: 0.1466
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 44/100
train loss item: 0.15460751950740814
train loss item: 0.1444259136915207
train loss item: 0.11357873678207397
train loss item: 0.10860374569892883
train loss item: 0.10928450524806976
train loss item: 0.09738785028457642
train loss item: 0.1570987105369568
train loss item: 0.15686064958572388
train loss item: 0.05725030228495598
train loss item: 0.09595989435911179
train loss item: 0.06827987730503082
train loss item: 0.25736328959465027
train loss item: 0.10095079988241196
train loss item: 0.07500363141298294
train loss item: 0.13762019574642181
train loss item: 0.19498950242996216
train loss item: 0.09702529013156891
train loss item: 0.21295888721942902
train loss item: 0.12490317225456238
train loss item: 0.1344514936208725
train loss item: 0.07678196579217911
train loss item: 0.14770983159542084
train loss item: 0.12166877835988998
train loss item: 0.17418913543224335
train loss item: 0.0757036805152893
train loss item: 0.2633216679096222
train loss item: 0.06922130286693573
train loss item: 0.168082132935524
train loss item: 0.09520192444324493
train loss item: 0.065644271671772
train loss item: 0.18113607168197632
train loss item: 0.0996464192867279
train loss item: 0.10489965230226517
train loss item: 0.10386747866868973
train loss item: 0.10162480175495148
train loss item: 0.08008360862731934
train loss item: 0.08187060058116913
train loss item: 0.05957398936152458
train loss item: 0.20012421905994415
train loss item: 0.09949461370706558
train loss item: 0.06049177050590515
train loss item: 0.10634434223175049
train loss item: 0.10840924829244614
train loss item: 0.553615152835846
train loss item: 0.10278120636940002
test loss item: 0.10038886219263077
test loss item: 0.1538916826248169
test loss item: 0.0963411033153534
test loss item: 0.4555128216743469
test loss item: 0.1092563271522522
test loss item: 0.22507096827030182
test loss item: 0.08375860005617142
test loss item: 0.08239738643169403
test loss item: 0.12601113319396973
test loss item: 0.18161240220069885
test loss item: 0.17451204359531403
test loss item: 0.11800938099622726
test loss item: 0.09506553411483765
test loss item: 0.10804092139005661
test loss item: 0.12138614058494568
test loss item: 0.24775224924087524
test loss item: 0.15300484001636505
test loss item: 0.14330516755580902
test loss item: 0.33319443464279175
test loss item: 0.14242339134216309
test loss item: 0.12916135787963867
test loss item: 0.10533219575881958
test loss item: 0.1636277735233307
test loss item: 0.11733575910329819
test loss item: 0.18471994996070862
test loss item: 0.090288445353508
test loss item: 0.0999516174197197
test loss item: 0.18188489973545074
test loss item: 0.20187319815158844
test loss item: 0.09351601451635361
test loss item: 0.12687647342681885
test loss item: 0.10496329516172409
test loss item: 0.23780378699302673
test loss item: 0.114114910364151
test loss item: 0.1693728268146515
test loss item: 0.2860918641090393
test loss item: 0.15764877200126648
test loss item: 0.08788911998271942
test loss item: 0.3602517545223236
test loss item: 0.10556517541408539
test loss item: 0.2740654945373535
test loss item: 0.30428367853164673
test loss item: 0.09814216196537018
test loss item: 0.0781547799706459
test loss item: 0.13898847997188568
Epoch [44/100], Training Loss: 0.1311, Testing Loss: 0.1614
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 45/100
train loss item: 0.19443394243717194
train loss item: 0.11369702219963074
train loss item: 0.1034841239452362
train loss item: 0.14548511803150177
train loss item: 0.07326068729162216
train loss item: 0.10383325070142746
train loss item: 0.11665228009223938
train loss item: 0.12618519365787506
train loss item: 0.05731732398271561
train loss item: 0.09672865271568298
train loss item: 0.06596864759922028
train loss item: 0.16407325863838196
train loss item: 0.09479665756225586
train loss item: 0.08053409308195114
train loss item: 0.12313736230134964
train loss item: 0.23536400496959686
train loss item: 0.0873824879527092
train loss item: 0.1905207335948944
train loss item: 0.14214211702346802
train loss item: 0.10818763822317123
train loss item: 0.07393356412649155
train loss item: 0.13911142945289612
train loss item: 0.12122820317745209
train loss item: 0.15377435088157654
train loss item: 0.07440951466560364
train loss item: 0.20970559120178223
train loss item: 0.05866682529449463
train loss item: 0.1712290197610855
train loss item: 0.08372944593429565
train loss item: 0.05917957052588463
train loss item: 0.1898116171360016
train loss item: 0.09322531521320343
train loss item: 0.09309467673301697
train loss item: 0.114415742456913
train loss item: 0.10526037216186523
train loss item: 0.08472200483083725
train loss item: 0.08126743882894516
train loss item: 0.05891566723585129
train loss item: 0.1796261966228485
train loss item: 0.09212163835763931
train loss item: 0.055648673325777054
train loss item: 0.1209898367524147
train loss item: 0.11277856677770615
train loss item: 0.5429126620292664
train loss item: 0.10738200694322586
test loss item: 0.08622687309980392
test loss item: 0.14284631609916687
test loss item: 0.0877043604850769
test loss item: 0.46876290440559387
test loss item: 0.10002146661281586
test loss item: 0.2091110795736313
test loss item: 0.08931642770767212
test loss item: 0.06619986146688461
test loss item: 0.12123899906873703
test loss item: 0.1964767575263977
test loss item: 0.1671953797340393
test loss item: 0.11716873198747635
test loss item: 0.0955905169248581
test loss item: 0.10348005592823029
test loss item: 0.11568276584148407
test loss item: 0.23840934038162231
test loss item: 0.1339750736951828
test loss item: 0.13653749227523804
test loss item: 0.3192838430404663
test loss item: 0.1304188370704651
test loss item: 0.13018865883350372
test loss item: 0.10062301158905029
test loss item: 0.16838154196739197
test loss item: 0.1244092583656311
test loss item: 0.17938385903835297
test loss item: 0.08185530453920364
test loss item: 0.0954788327217102
test loss item: 0.15928220748901367
test loss item: 0.202728271484375
test loss item: 0.0881342813372612
test loss item: 0.11778800189495087
test loss item: 0.10967448353767395
test loss item: 0.241394504904747
test loss item: 0.12296188622713089
test loss item: 0.16107197105884552
test loss item: 0.297893226146698
test loss item: 0.17270591855049133
test loss item: 0.08807462453842163
test loss item: 0.32656288146972656
test loss item: 0.105202317237854
test loss item: 0.27665263414382935
test loss item: 0.29376477003097534
test loss item: 0.10456861555576324
test loss item: 0.055887170135974884
test loss item: 0.15103620290756226
Epoch [45/100], Training Loss: 0.1245, Testing Loss: 0.1574
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.11444098502397537
loss item: 0.324204683303833
loss item: 0.206955224275589
loss item: 0.24338850378990173
loss item: 0.09915100783109665
loss item: 0.36539703607559204
loss item: 0.2312232255935669
loss item: 0.09969890117645264
loss item: 0.1522914171218872
loss item: 0.2555631101131439
loss item: 0.12328220158815384
loss item: 0.13216622173786163
loss item: 0.21735641360282898
loss item: 0.1985444873571396
loss item: 0.1438561975955963
loss item: 0.4224192202091217
loss item: 0.17103324830532074
loss item: 0.09449902176856995
loss item: 0.11311066895723343
loss item: 0.23098237812519073
loss item: 0.26149263978004456
loss item: 0.08557901531457901
Val Loss: 0.1948
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.0001 4 360 done at Tue Nov 12 12:56:10 CET 2024
UNet2 with 1 100 0.0005 4 360 start at Tue Nov 12 12:56:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.6336421966552734
train loss item: 0.9993661046028137
train loss item: 0.595187783241272
train loss item: 0.9349422454833984
train loss item: 0.420171320438385
train loss item: 0.43110084533691406
train loss item: 0.4865673780441284
train loss item: 0.7318769693374634
train loss item: 0.33974796533584595
train loss item: 0.3741704523563385
train loss item: 0.3689255118370056
train loss item: 1.1589950323104858
train loss item: 0.5373875498771667
train loss item: 0.34425392746925354
train loss item: 0.6828771233558655
train loss item: 1.6828837394714355
train loss item: 0.49172812700271606
train loss item: 1.9094692468643188
train loss item: 0.6189807057380676
train loss item: 0.6172576546669006
train loss item: 0.5751233696937561
train loss item: 0.3494304418563843
train loss item: 0.46517854928970337
train loss item: 0.2958175539970398
train loss item: 0.24401570856571198
train loss item: 0.8013125061988831
train loss item: 0.2470400482416153
train loss item: 1.7671763896942139
train loss item: 0.2696566581726074
train loss item: 0.2147693783044815
train loss item: 1.5447440147399902
train loss item: 0.39145776629447937
train loss item: 0.42256706953048706
train loss item: 0.47760188579559326
train loss item: 0.3703896701335907
train loss item: 0.31359994411468506
train loss item: 0.32691898941993713
train loss item: 0.15602192282676697
train loss item: 1.1286150217056274
train loss item: 0.3056598901748657
train loss item: 0.26400911808013916
train loss item: 0.47334399819374084
train loss item: 0.44159236550331116
train loss item: 2.875567674636841
train loss item: 0.44896361231803894
test loss item: 0.18260884284973145
test loss item: 0.37658047676086426
test loss item: 0.21447274088859558
test loss item: 0.8869276642799377
test loss item: 0.2703791856765747
test loss item: 0.5653818249702454
test loss item: 0.17298828065395355
test loss item: 0.16976198554039001
test loss item: 0.3151813745498657
test loss item: 0.4063761830329895
test loss item: 0.4782122075557709
test loss item: 0.24083423614501953
test loss item: 0.21599040925502777
test loss item: 0.2523772418498993
test loss item: 0.30982324481010437
test loss item: 0.5589002966880798
test loss item: 0.45664331316947937
test loss item: 0.3833664059638977
test loss item: 0.8046218156814575
test loss item: 0.36945685744285583
test loss item: 0.26711544394493103
test loss item: 0.32015877962112427
test loss item: 0.41130152344703674
test loss item: 0.25871169567108154
test loss item: 0.4566580057144165
test loss item: 0.21447890996932983
test loss item: 0.29934096336364746
test loss item: 0.5387488603591919
test loss item: 0.46469613909721375
test loss item: 0.21642421185970306
test loss item: 0.31394293904304504
test loss item: 0.22205500304698944
test loss item: 0.5734866261482239
test loss item: 0.26601606607437134
test loss item: 0.4046967923641205
test loss item: 0.5527810454368591
test loss item: 0.30840063095092773
test loss item: 0.1677815020084381
test loss item: 0.8059555888175964
test loss item: 0.21964682638645172
test loss item: 0.5953294634819031
test loss item: 0.7180091738700867
test loss item: 0.21305808424949646
test loss item: 0.151900514960289
test loss item: 0.20145545899868011
Epoch [1/100], Training Loss: 0.6784, Testing Loss: 0.3732
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/100
train loss item: 0.6763551831245422
train loss item: 0.5072659254074097
train loss item: 0.31016770005226135
train loss item: 0.4932032525539398
train loss item: 0.28396549820899963
train loss item: 0.31024402379989624
train loss item: 0.3571765422821045
train loss item: 0.5308289527893066
train loss item: 0.23511645197868347
train loss item: 0.3242553174495697
train loss item: 0.1966618150472641
train loss item: 0.7715167999267578
train loss item: 0.34185728430747986
train loss item: 0.2585991621017456
train loss item: 0.48500949144363403
train loss item: 1.257409930229187
train loss item: 0.4677455425262451
train loss item: 1.4938323497772217
train loss item: 0.6211795806884766
train loss item: 0.697333037853241
train loss item: 0.39729008078575134
train loss item: 0.388002872467041
train loss item: 0.36994507908821106
train loss item: 0.3004932999610901
train loss item: 0.22935816645622253
train loss item: 0.7564562559127808
train loss item: 0.20619870722293854
train loss item: 1.5096603631973267
train loss item: 0.2950872778892517
train loss item: 0.16978172957897186
train loss item: 1.348725438117981
train loss item: 0.2653981149196625
train loss item: 0.36940357089042664
train loss item: 0.3703857362270355
train loss item: 0.3254009783267975
train loss item: 0.2764299511909485
train loss item: 0.2899024486541748
train loss item: 0.1495000720024109
train loss item: 0.9525243639945984
train loss item: 0.20779015123844147
train loss item: 0.16544437408447266
train loss item: 0.3925164043903351
train loss item: 0.3590438663959503
train loss item: 2.3288955688476562
train loss item: 0.3717213273048401
test loss item: 0.18622981011867523
test loss item: 0.3428483307361603
test loss item: 0.2298201024532318
test loss item: 0.6105896830558777
test loss item: 0.2833128273487091
test loss item: 0.4750601649284363
test loss item: 0.22305072844028473
test loss item: 0.17117653787136078
test loss item: 0.2590787410736084
test loss item: 0.3393717110157013
test loss item: 0.35265687108039856
test loss item: 0.206001877784729
test loss item: 0.20493285357952118
test loss item: 0.26435914635658264
test loss item: 0.3022944927215576
test loss item: 0.42907315492630005
test loss item: 0.38119131326675415
test loss item: 0.36955583095550537
test loss item: 0.6738674640655518
test loss item: 0.3190270960330963
test loss item: 0.19770286977291107
test loss item: 0.23967595398426056
test loss item: 0.3485738933086395
test loss item: 0.22463522851467133
test loss item: 0.41886553168296814
test loss item: 0.25472524762153625
test loss item: 0.22606755793094635
test loss item: 0.5007068514823914
test loss item: 0.3823719322681427
test loss item: 0.24185961484909058
test loss item: 0.2930935025215149
test loss item: 0.2187051773071289
test loss item: 0.5284643173217773
test loss item: 0.23644667863845825
test loss item: 0.36500951647758484
test loss item: 0.38949742913246155
test loss item: 0.2604151964187622
test loss item: 0.1401842087507248
test loss item: 0.7367886304855347
test loss item: 0.21407701075077057
test loss item: 0.48207220435142517
test loss item: 0.6250508427619934
test loss item: 0.19647076725959778
test loss item: 0.12782102823257446
test loss item: 0.18004202842712402
Epoch [2/100], Training Loss: 0.5203, Testing Loss: 0.3256
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/100
train loss item: 0.5393073558807373
train loss item: 0.37026771903038025
train loss item: 0.24788515269756317
train loss item: 0.41281819343566895
train loss item: 0.2681031823158264
train loss item: 0.24137426912784576
train loss item: 0.3125859797000885
train loss item: 0.387481153011322
train loss item: 0.19752901792526245
train loss item: 0.323188841342926
train loss item: 0.22378413379192352
train loss item: 0.570470929145813
train loss item: 0.3141983151435852
train loss item: 0.20689930021762848
train loss item: 0.40412047505378723
train loss item: 0.9049418568611145
train loss item: 0.27877381443977356
train loss item: 1.2179837226867676
train loss item: 0.6031314134597778
train loss item: 0.4819824993610382
train loss item: 0.23484845459461212
train loss item: 0.2489413470029831
train loss item: 0.3137591481208801
train loss item: 0.22292646765708923
train loss item: 0.16673439741134644
train loss item: 0.5971180200576782
train loss item: 0.1543111354112625
train loss item: 1.2026201486587524
train loss item: 0.2473420649766922
train loss item: 0.1368510127067566
train loss item: 1.0238720178604126
train loss item: 0.2703191041946411
train loss item: 0.31447339057922363
train loss item: 0.40621447563171387
train loss item: 0.2848120331764221
train loss item: 0.2473238706588745
train loss item: 0.22256380319595337
train loss item: 0.11141793429851532
train loss item: 0.8421390056610107
train loss item: 0.17228589951992035
train loss item: 0.13960134983062744
train loss item: 0.3064326047897339
train loss item: 0.3814127445220947
train loss item: 2.0761661529541016
train loss item: 0.29822099208831787
test loss item: 0.146224707365036
test loss item: 0.3002369999885559
test loss item: 0.22586296498775482
test loss item: 0.5330710411071777
test loss item: 0.26874497532844543
test loss item: 0.38916587829589844
test loss item: 0.18889181315898895
test loss item: 0.14602574706077576
test loss item: 0.23958048224449158
test loss item: 0.31441178917884827
test loss item: 0.3237226903438568
test loss item: 0.20532336831092834
test loss item: 0.17143487930297852
test loss item: 0.2344226837158203
test loss item: 0.2810314893722534
test loss item: 0.35330167412757874
test loss item: 0.33411887288093567
test loss item: 0.3375808298587799
test loss item: 0.5875075459480286
test loss item: 0.2796597182750702
test loss item: 0.16130013763904572
test loss item: 0.20683622360229492
test loss item: 0.325713187456131
test loss item: 0.2040078490972519
test loss item: 0.39006444811820984
test loss item: 0.2501714825630188
test loss item: 0.17708425223827362
test loss item: 0.42995700240135193
test loss item: 0.3500179052352905
test loss item: 0.2126748412847519
test loss item: 0.2761983275413513
test loss item: 0.17448557913303375
test loss item: 0.41602736711502075
test loss item: 0.20407144725322723
test loss item: 0.3154667317867279
test loss item: 0.33925923705101013
test loss item: 0.2375837117433548
test loss item: 0.1135871484875679
test loss item: 0.5986781120300293
test loss item: 0.19461461901664734
test loss item: 0.4081859886646271
test loss item: 0.5371807217597961
test loss item: 0.18453830480575562
test loss item: 0.08251414448022842
test loss item: 0.14483410120010376
Epoch [3/100], Training Loss: 0.4251, Testing Loss: 0.2843
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/100
train loss item: 0.4897162914276123
train loss item: 0.31413033604621887
train loss item: 0.20648349821567535
train loss item: 0.3144131302833557
train loss item: 0.1956438422203064
train loss item: 0.19273518025875092
train loss item: 0.2651529014110565
train loss item: 0.3908151388168335
train loss item: 0.14927053451538086
train loss item: 0.2569388151168823
train loss item: 0.16874898970127106
train loss item: 0.47656917572021484
train loss item: 0.24369961023330688
train loss item: 0.17415961623191833
train loss item: 0.31812718510627747
train loss item: 0.7173968553543091
train loss item: 0.25664207339286804
train loss item: 1.0270237922668457
train loss item: 0.6272668838500977
train loss item: 0.450464129447937
train loss item: 0.19669915735721588
train loss item: 0.18399785459041595
train loss item: 0.27988311648368835
train loss item: 0.18423420190811157
train loss item: 0.15186072885990143
train loss item: 0.5366824865341187
train loss item: 0.13888053596019745
train loss item: 1.0072901248931885
train loss item: 0.21672020852565765
train loss item: 0.1150289848446846
train loss item: 0.8523637056350708
train loss item: 0.26492443680763245
train loss item: 0.2583729326725006
train loss item: 0.27793997526168823
train loss item: 0.278328537940979
train loss item: 0.1758606880903244
train loss item: 0.17133638262748718
train loss item: 0.10860730707645416
train loss item: 0.7406320571899414
train loss item: 0.13871027529239655
train loss item: 0.11138875037431717
train loss item: 0.21881966292858124
train loss item: 0.41013458371162415
train loss item: 1.7850593328475952
train loss item: 0.3595987856388092
test loss item: 0.17625464498996735
test loss item: 0.2644307613372803
test loss item: 0.287316232919693
test loss item: 0.43765518069267273
test loss item: 0.23692159354686737
test loss item: 0.35572633147239685
test loss item: 0.16550743579864502
test loss item: 0.17594894766807556
test loss item: 0.2056770771741867
test loss item: 0.26752668619155884
test loss item: 0.2609396278858185
test loss item: 0.20183952152729034
test loss item: 0.15445998311042786
test loss item: 0.25819599628448486
test loss item: 0.26541656255722046
test loss item: 0.30201852321624756
test loss item: 0.2786847651004791
test loss item: 0.30218836665153503
test loss item: 0.488050252199173
test loss item: 0.2763323485851288
test loss item: 0.1487741768360138
test loss item: 0.1687401980161667
test loss item: 0.24797189235687256
test loss item: 0.16547518968582153
test loss item: 0.32480767369270325
test loss item: 0.2160690724849701
test loss item: 0.17131231725215912
test loss item: 0.3734331429004669
test loss item: 0.3096332550048828
test loss item: 0.19569915533065796
test loss item: 0.2329225093126297
test loss item: 0.15789364278316498
test loss item: 0.36115169525146484
test loss item: 0.18553893268108368
test loss item: 0.2545834481716156
test loss item: 0.26789912581443787
test loss item: 0.20070189237594604
test loss item: 0.11962175369262695
test loss item: 0.4453712999820709
test loss item: 0.2536574900150299
test loss item: 0.34859004616737366
test loss item: 0.4426787495613098
test loss item: 0.1755906045436859
test loss item: 0.09417106211185455
test loss item: 0.173434317111969
Epoch [4/100], Training Loss: 0.3644, Testing Loss: 0.2533
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/100
train loss item: 0.37009596824645996
train loss item: 0.2531362473964691
train loss item: 0.1522209197282791
train loss item: 0.2980888783931732
train loss item: 0.19421829283237457
train loss item: 0.19021964073181152
train loss item: 0.20453685522079468
train loss item: 0.43769630789756775
train loss item: 0.14116603136062622
train loss item: 0.2747739851474762
train loss item: 0.1614067554473877
train loss item: 0.4163457751274109
train loss item: 0.18245656788349152
train loss item: 0.17019231617450714
train loss item: 0.30869799852371216
train loss item: 0.5902789235115051
train loss item: 0.22806796431541443
train loss item: 0.8547470569610596
train loss item: 0.4695347845554352
train loss item: 0.27664703130722046
train loss item: 0.1420029252767563
train loss item: 0.2111431062221527
train loss item: 0.22597302496433258
train loss item: 0.19986818730831146
train loss item: 0.1279294490814209
train loss item: 0.5150712728500366
train loss item: 0.11983919143676758
train loss item: 0.7616610527038574
train loss item: 0.16498444974422455
train loss item: 0.09749317914247513
train loss item: 0.6706580519676208
train loss item: 0.2301790714263916
train loss item: 0.2482648491859436
train loss item: 0.3263269066810608
train loss item: 0.2514510452747345
train loss item: 0.14863720536231995
train loss item: 0.15236027538776398
train loss item: 0.09234657883644104
train loss item: 0.8302199244499207
train loss item: 0.1565205454826355
train loss item: 0.10602571070194244
train loss item: 0.2870694398880005
train loss item: 0.33907565474510193
train loss item: 1.642812728881836
train loss item: 0.32124772667884827
test loss item: 0.14779426157474518
test loss item: 0.22123053669929504
test loss item: 0.2003275752067566
test loss item: 0.4665570855140686
test loss item: 0.190566286444664
test loss item: 0.3184684216976166
test loss item: 0.12331170588731766
test loss item: 0.13545353710651398
test loss item: 0.16447392106056213
test loss item: 0.24017180502414703
test loss item: 0.2010878622531891
test loss item: 0.15544576942920685
test loss item: 0.13019196689128876
test loss item: 0.19522252678871155
test loss item: 0.19547909498214722
test loss item: 0.2928146719932556
test loss item: 0.20355944335460663
test loss item: 0.24650365114212036
test loss item: 0.4299388825893402
test loss item: 0.20777378976345062
test loss item: 0.1553778499364853
test loss item: 0.14263759553432465
test loss item: 0.17981594800949097
test loss item: 0.1380906105041504
test loss item: 0.2680199444293976
test loss item: 0.1568726748228073
test loss item: 0.14690271019935608
test loss item: 0.2941405177116394
test loss item: 0.2599181830883026
test loss item: 0.14649231731891632
test loss item: 0.18106940388679504
test loss item: 0.13466012477874756
test loss item: 0.3194475769996643
test loss item: 0.15155170857906342
test loss item: 0.21468546986579895
test loss item: 0.2817840874195099
test loss item: 0.1729176789522171
test loss item: 0.11792728304862976
test loss item: 0.37450480461120605
test loss item: 0.18684622645378113
test loss item: 0.3380759060382843
test loss item: 0.39764976501464844
test loss item: 0.14572279155254364
test loss item: 0.10850152373313904
test loss item: 0.18361926078796387
Epoch [5/100], Training Loss: 0.3232, Testing Loss: 0.2147
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/100
train loss item: 0.3704867362976074
train loss item: 0.28612861037254333
train loss item: 0.18314382433891296
train loss item: 0.2349981963634491
train loss item: 0.19215382635593414
train loss item: 0.16335855424404144
train loss item: 0.2739008069038391
train loss item: 0.5320641398429871
train loss item: 0.16620898246765137
train loss item: 0.21116818487644196
train loss item: 0.15984420478343964
train loss item: 0.6287740468978882
train loss item: 0.17890961468219757
train loss item: 0.14989367127418518
train loss item: 0.2616206109523773
train loss item: 0.43685394525527954
train loss item: 0.33246326446533203
train loss item: 0.6694057583808899
train loss item: 0.6557824611663818
train loss item: 0.41367748379707336
train loss item: 0.3033978044986725
train loss item: 0.26000887155532837
train loss item: 0.22557979822158813
train loss item: 0.18964402377605438
train loss item: 0.1539917290210724
train loss item: 0.563402533531189
train loss item: 0.1766425222158432
train loss item: 0.8635500073432922
train loss item: 0.2371762990951538
train loss item: 0.14641742408275604
train loss item: 0.807615339756012
train loss item: 0.2647928297519684
train loss item: 0.3737647533416748
train loss item: 0.27593234181404114
train loss item: 0.23315444588661194
train loss item: 0.16843488812446594
train loss item: 0.20727890729904175
train loss item: 0.09448844939470291
train loss item: 0.5830731987953186
train loss item: 0.20598545670509338
train loss item: 0.11026939749717712
train loss item: 0.22345198690891266
train loss item: 0.2790948450565338
train loss item: 1.4111433029174805
train loss item: 0.2504265308380127
test loss item: 0.14158995449543
test loss item: 0.24673286080360413
test loss item: 0.18141010403633118
test loss item: 0.5417452454566956
test loss item: 0.2125459760427475
test loss item: 0.36206915974617004
test loss item: 0.15803442895412445
test loss item: 0.14793188869953156
test loss item: 0.18241530656814575
test loss item: 0.28453540802001953
test loss item: 0.2322719544172287
test loss item: 0.15479758381843567
test loss item: 0.13954728841781616
test loss item: 0.18997319042682648
test loss item: 0.2184808999300003
test loss item: 0.31171488761901855
test loss item: 0.2107406109571457
test loss item: 0.2505902051925659
test loss item: 0.4913616478443146
test loss item: 0.20709750056266785
test loss item: 0.14556875824928284
test loss item: 0.14553408324718475
test loss item: 0.24313688278198242
test loss item: 0.1449020951986313
test loss item: 0.30432918667793274
test loss item: 0.16619333624839783
test loss item: 0.1546631157398224
test loss item: 0.32621628046035767
test loss item: 0.2883223593235016
test loss item: 0.17558147013187408
test loss item: 0.2044137567281723
test loss item: 0.1619306057691574
test loss item: 0.3802317976951599
test loss item: 0.1983601301908493
test loss item: 0.22601144015789032
test loss item: 0.3693528473377228
test loss item: 0.24109488725662231
test loss item: 0.11179845780134201
test loss item: 0.4230360686779022
test loss item: 0.15579074621200562
test loss item: 0.3773745000362396
test loss item: 0.4341104030609131
test loss item: 0.15852157771587372
test loss item: 0.0983748733997345
test loss item: 0.11923921853303909
Epoch [6/100], Training Loss: 0.3358, Testing Loss: 0.2360
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/100
train loss item: 0.2629103660583496
train loss item: 0.19943471252918243
train loss item: 0.14744463562965393
train loss item: 0.19292187690734863
train loss item: 0.16797985136508942
train loss item: 0.16578581929206848
train loss item: 0.27998772263526917
train loss item: 0.27342721819877625
train loss item: 0.11192652583122253
train loss item: 0.16936306655406952
train loss item: 0.1379067301750183
train loss item: 0.33625441789627075
train loss item: 0.17126595973968506
train loss item: 0.12481985986232758
train loss item: 0.24340549111366272
train loss item: 0.40787988901138306
train loss item: 0.22290873527526855
train loss item: 0.5980804562568665
train loss item: 0.49156203866004944
train loss item: 0.19003070890903473
train loss item: 0.13895244896411896
train loss item: 0.1516721546649933
train loss item: 0.2506973445415497
train loss item: 0.16957662999629974
train loss item: 0.09974518418312073
train loss item: 0.351901650428772
train loss item: 0.10629034787416458
train loss item: 0.5380032658576965
train loss item: 0.14812630414962769
train loss item: 0.08572030067443848
train loss item: 0.4765778183937073
train loss item: 0.22669461369514465
train loss item: 0.15618982911109924
train loss item: 0.195711150765419
train loss item: 0.17145413160324097
train loss item: 0.11921054124832153
train loss item: 0.1359882354736328
train loss item: 0.07826507091522217
train loss item: 0.6462913751602173
train loss item: 0.1130099818110466
train loss item: 0.09457623213529587
train loss item: 0.18846562504768372
train loss item: 0.31950974464416504
train loss item: 1.1430742740631104
train loss item: 0.2951463758945465
test loss item: 0.13386604189872742
test loss item: 0.25746360421180725
test loss item: 0.19813765585422516
test loss item: 0.33553290367126465
test loss item: 0.1862456500530243
test loss item: 0.3608108460903168
test loss item: 0.1282568722963333
test loss item: 0.13319776952266693
test loss item: 0.16646666824817657
test loss item: 0.20235849916934967
test loss item: 0.20200257003307343
test loss item: 0.17641529440879822
test loss item: 0.11876370012760162
test loss item: 0.18151158094406128
test loss item: 0.19618384540081024
test loss item: 0.2955976128578186
test loss item: 0.2265481799840927
test loss item: 0.23804786801338196
test loss item: 0.47061917185783386
test loss item: 0.20147112011909485
test loss item: 0.13817958533763885
test loss item: 0.12833282351493835
test loss item: 0.1984097957611084
test loss item: 0.1683875024318695
test loss item: 0.2719263732433319
test loss item: 0.15478570759296417
test loss item: 0.13764020800590515
test loss item: 0.35045844316482544
test loss item: 0.2449112832546234
test loss item: 0.14869581162929535
test loss item: 0.17273464798927307
test loss item: 0.12807150185108185
test loss item: 0.3687584400177002
test loss item: 0.15199874341487885
test loss item: 0.21165800094604492
test loss item: 0.20402313768863678
test loss item: 0.18909026682376862
test loss item: 0.12388072162866592
test loss item: 0.5676348805427551
test loss item: 0.17909620702266693
test loss item: 0.33363914489746094
test loss item: 0.44237571954727173
test loss item: 0.14734408259391785
test loss item: 0.07340683043003082
test loss item: 0.13038522005081177
Epoch [7/100], Training Loss: 0.2510, Testing Loss: 0.2172
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/100
train loss item: 0.261271208524704
train loss item: 0.19946733117103577
train loss item: 0.13846908509731293
train loss item: 0.23080991208553314
train loss item: 0.14915619790554047
train loss item: 0.1354983001947403
train loss item: 0.17040547728538513
train loss item: 0.41830599308013916
train loss item: 0.11529459059238434
train loss item: 0.22823210060596466
train loss item: 0.1444873809814453
train loss item: 0.4246535003185272
train loss item: 0.17093877494335175
train loss item: 0.11525049805641174
train loss item: 0.21981707215309143
train loss item: 0.37918001413345337
train loss item: 0.1784096658229828
train loss item: 0.46972939372062683
train loss item: 0.48255565762519836
train loss item: 0.30452319979667664
train loss item: 0.17718620598316193
train loss item: 0.22294877469539642
train loss item: 0.2254335582256317
train loss item: 0.18030160665512085
train loss item: 0.11810288578271866
train loss item: 0.46292972564697266
train loss item: 0.12823040783405304
train loss item: 0.6725529432296753
train loss item: 0.19556865096092224
train loss item: 0.09984441846609116
train loss item: 0.5914117693901062
train loss item: 0.17095665633678436
train loss item: 0.19879624247550964
train loss item: 0.24814732372760773
train loss item: 0.20532777905464172
train loss item: 0.17032459378242493
train loss item: 0.15104998648166656
train loss item: 0.0796000212430954
train loss item: 0.5874409079551697
train loss item: 0.13659706711769104
train loss item: 0.12615148723125458
train loss item: 0.2257031351327896
train loss item: 0.31328535079956055
train loss item: 1.0885984897613525
train loss item: 0.21511626243591309
test loss item: 0.099223293364048
test loss item: 0.19534100592136383
test loss item: 0.11527284234762192
test loss item: 0.3693181872367859
test loss item: 0.17608459293842316
test loss item: 0.2841672897338867
test loss item: 0.1574288159608841
test loss item: 0.0913684219121933
test loss item: 0.13171130418777466
test loss item: 0.2121117115020752
test loss item: 0.16687197983264923
test loss item: 0.12103884667158127
test loss item: 0.10755971819162369
test loss item: 0.13216347992420197
test loss item: 0.15815754234790802
test loss item: 0.2404954433441162
test loss item: 0.16534125804901123
test loss item: 0.2105712592601776
test loss item: 0.3670577108860016
test loss item: 0.148954838514328
test loss item: 0.13027502596378326
test loss item: 0.12000345438718796
test loss item: 0.1709456443786621
test loss item: 0.13999730348587036
test loss item: 0.24044042825698853
test loss item: 0.1517016887664795
test loss item: 0.10972090810537338
test loss item: 0.2573085427284241
test loss item: 0.20665784180164337
test loss item: 0.14804939925670624
test loss item: 0.15782050788402557
test loss item: 0.13269680738449097
test loss item: 0.26501983404159546
test loss item: 0.13778454065322876
test loss item: 0.19326500594615936
test loss item: 0.22619971632957458
test loss item: 0.16177313029766083
test loss item: 0.09897489100694656
test loss item: 0.30543944239616394
test loss item: 0.10999572277069092
test loss item: 0.27164092659950256
test loss item: 0.3355948328971863
test loss item: 0.12139030545949936
test loss item: 0.0515238419175148
test loss item: 0.14429138600826263
Epoch [8/100], Training Loss: 0.2651, Testing Loss: 0.1786
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/100
train loss item: 0.31130707263946533
train loss item: 0.19139131903648376
train loss item: 0.1378507763147354
train loss item: 0.16726019978523254
train loss item: 0.1710727959871292
train loss item: 0.14385272562503815
train loss item: 0.2261064350605011
train loss item: 0.3310890197753906
train loss item: 0.1353982537984848
train loss item: 0.16871792078018188
train loss item: 0.1534840166568756
train loss item: 0.4770488142967224
train loss item: 0.1700722873210907
train loss item: 0.12079021334648132
train loss item: 0.19702786207199097
train loss item: 0.38499152660369873
train loss item: 0.28098732233047485
train loss item: 0.41071441769599915
train loss item: 0.5539953708648682
train loss item: 0.2916272282600403
train loss item: 0.2139626443386078
train loss item: 0.11973587423563004
train loss item: 0.2160974144935608
train loss item: 0.14040014147758484
train loss item: 0.10926470905542374
train loss item: 0.3920300304889679
train loss item: 0.12671782076358795
train loss item: 0.6348101496696472
train loss item: 0.1870463639497757
train loss item: 0.09222724288702011
train loss item: 0.503287672996521
train loss item: 0.18054485321044922
train loss item: 0.14654888212680817
train loss item: 0.17320828139781952
train loss item: 0.1877397745847702
train loss item: 0.11144924908876419
train loss item: 0.1660364717245102
train loss item: 0.08838730305433273
train loss item: 0.5646113157272339
train loss item: 0.12188975512981415
train loss item: 0.09115153551101685
train loss item: 0.1946977823972702
train loss item: 0.3388516306877136
train loss item: 0.9566274881362915
train loss item: 0.24464763700962067
test loss item: 0.13326241075992584
test loss item: 0.31829920411109924
test loss item: 0.19143584370613098
test loss item: 0.37147244811058044
test loss item: 0.23801560699939728
test loss item: 0.46999096870422363
test loss item: 0.1352572739124298
test loss item: 0.13993728160858154
test loss item: 0.19075030088424683
test loss item: 0.2018410861492157
test loss item: 0.23167838156223297
test loss item: 0.16494831442832947
test loss item: 0.12706877291202545
test loss item: 0.18761396408081055
test loss item: 0.21666759252548218
test loss item: 0.3945191204547882
test loss item: 0.27623701095581055
test loss item: 0.3067295551300049
test loss item: 0.6068421006202698
test loss item: 0.2256857454776764
test loss item: 0.12315766513347626
test loss item: 0.15525434911251068
test loss item: 0.2234184592962265
test loss item: 0.15347017347812653
test loss item: 0.34987592697143555
test loss item: 0.18062762916088104
test loss item: 0.14522291719913483
test loss item: 0.46203944087028503
test loss item: 0.2829326093196869
test loss item: 0.15702447295188904
test loss item: 0.2253122627735138
test loss item: 0.12112388014793396
test loss item: 0.4420587122440338
test loss item: 0.1560841202735901
test loss item: 0.2548307180404663
test loss item: 0.21000824868679047
test loss item: 0.17675213515758514
test loss item: 0.11647606641054153
test loss item: 0.7637439966201782
test loss item: 0.16115356981754303
test loss item: 0.4219945967197418
test loss item: 0.5840011835098267
test loss item: 0.1443052440881729
test loss item: 0.09107307344675064
test loss item: 0.12010380625724792
Epoch [9/100], Training Loss: 0.2517, Testing Loss: 0.2522
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/100
train loss item: 0.315762460231781
train loss item: 0.21976874768733978
train loss item: 0.13234320282936096
train loss item: 0.22612839937210083
train loss item: 0.18335960805416107
train loss item: 0.17845892906188965
train loss item: 0.30827003717422485
train loss item: 0.34008726477622986
train loss item: 0.12574402987957
train loss item: 0.19080013036727905
train loss item: 0.13382311165332794
train loss item: 0.6459591388702393
train loss item: 0.20973524451255798
train loss item: 0.16793206334114075
train loss item: 0.20440512895584106
train loss item: 0.5592594146728516
train loss item: 0.19054029881954193
train loss item: 0.3956698179244995
train loss item: 0.6296862363815308
train loss item: 0.49519601464271545
train loss item: 0.37678614258766174
train loss item: 0.23240099847316742
train loss item: 0.43937647342681885
train loss item: 0.21625465154647827
train loss item: 0.1162428930401802
train loss item: 0.3237399458885193
train loss item: 0.1317378729581833
train loss item: 0.7038212418556213
train loss item: 0.2089279443025589
train loss item: 0.12856723368167877
train loss item: 0.8555094599723816
train loss item: 0.23031416535377502
train loss item: 0.30953437089920044
train loss item: 0.19941964745521545
train loss item: 0.1902802735567093
train loss item: 0.14783398807048798
train loss item: 0.20809222757816315
train loss item: 0.1068788468837738
train loss item: 0.4610536992549896
train loss item: 0.245075061917305
train loss item: 0.13859762251377106
train loss item: 0.21106185019016266
train loss item: 0.4795286953449249
train loss item: 0.8410758972167969
train loss item: 0.19869187474250793
test loss item: 0.2174210101366043
test loss item: 0.2725529074668884
test loss item: 0.2549459934234619
test loss item: 0.6419954299926758
test loss item: 0.264100581407547
test loss item: 0.3672637343406677
test loss item: 0.19655576348304749
test loss item: 0.22868479788303375
test loss item: 0.21134327352046967
test loss item: 0.2954942286014557
test loss item: 0.26472190022468567
test loss item: 0.20256811380386353
test loss item: 0.18483352661132812
test loss item: 0.2521101236343384
test loss item: 0.27470216155052185
test loss item: 0.40336617827415466
test loss item: 0.25973621010780334
test loss item: 0.3080412447452545
test loss item: 0.4901212453842163
test loss item: 0.26929935812950134
test loss item: 0.1713801473379135
test loss item: 0.17738287150859833
test loss item: 0.26212364435195923
test loss item: 0.17499086260795593
test loss item: 0.33807533979415894
test loss item: 0.23002572357654572
test loss item: 0.1818200796842575
test loss item: 0.36567437648773193
test loss item: 0.3200864791870117
test loss item: 0.2182134985923767
test loss item: 0.25765904784202576
test loss item: 0.18829287588596344
test loss item: 0.3600148558616638
test loss item: 0.22274662554264069
test loss item: 0.2871955335140228
test loss item: 0.4353511333465576
test loss item: 0.26374658942222595
test loss item: 0.17020471394062042
test loss item: 0.4131988286972046
test loss item: 0.20628224313259125
test loss item: 0.4082085192203522
test loss item: 0.4620025157928467
test loss item: 0.1860796958208084
test loss item: 0.17612016201019287
test loss item: 0.12444421648979187
Epoch [10/100], Training Loss: 0.3012, Testing Loss: 0.2769
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 11/100
train loss item: 0.2597608268260956
train loss item: 0.25168925523757935
train loss item: 0.20514465868473053
train loss item: 0.3091837167739868
train loss item: 0.2117544710636139
train loss item: 0.15438644587993622
train loss item: 0.19882473349571228
train loss item: 0.25162339210510254
train loss item: 0.09556900709867477
train loss item: 0.19355081021785736
train loss item: 0.15822014212608337
train loss item: 0.3486797511577606
train loss item: 0.1600438952445984
train loss item: 0.13343815505504608
train loss item: 0.1832808554172516
train loss item: 0.3962872326374054
train loss item: 0.21077315509319305
train loss item: 0.36051517724990845
train loss item: 0.2621730864048004
train loss item: 0.18357624113559723
train loss item: 0.13985836505889893
train loss item: 0.15989847481250763
train loss item: 0.1678890734910965
train loss item: 0.20626093447208405
train loss item: 0.13292226195335388
train loss item: 0.40268900990486145
train loss item: 0.08947509527206421
train loss item: 0.4417487382888794
train loss item: 0.15564048290252686
train loss item: 0.08435571938753128
train loss item: 0.43847355246543884
train loss item: 0.149409681558609
train loss item: 0.1389189511537552
train loss item: 0.14334870874881744
train loss item: 0.132684126496315
train loss item: 0.09664566069841385
train loss item: 0.13381868600845337
train loss item: 0.08089128881692886
train loss item: 0.4905529022216797
train loss item: 0.10002925992012024
train loss item: 0.08163940161466599
train loss item: 0.16019849479198456
train loss item: 0.41323041915893555
train loss item: 0.7969711422920227
train loss item: 0.25238069891929626
test loss item: 0.08678183704614639
test loss item: 0.17682527005672455
test loss item: 0.11459966748952866
test loss item: 0.2853323519229889
test loss item: 0.15446558594703674
test loss item: 0.2325364500284195
test loss item: 0.10517805814743042
test loss item: 0.08097430318593979
test loss item: 0.13372904062271118
test loss item: 0.17119146883487701
test loss item: 0.16411744058132172
test loss item: 0.11822713911533356
test loss item: 0.09805746376514435
test loss item: 0.12642429769039154
test loss item: 0.14672715961933136
test loss item: 0.19939611852169037
test loss item: 0.15899302065372467
test loss item: 0.187982976436615
test loss item: 0.3007547855377197
test loss item: 0.14661580324172974
test loss item: 0.11043711006641388
test loss item: 0.11570555716753006
test loss item: 0.17219404876232147
test loss item: 0.13152265548706055
test loss item: 0.2024533897638321
test loss item: 0.13206738233566284
test loss item: 0.10954465717077255
test loss item: 0.22798573970794678
test loss item: 0.17831361293792725
test loss item: 0.11615113914012909
test loss item: 0.1537197232246399
test loss item: 0.10237877815961838
test loss item: 0.22270648181438446
test loss item: 0.1252065747976303
test loss item: 0.1575448215007782
test loss item: 0.18586108088493347
test loss item: 0.1689308136701584
test loss item: 0.08766622841358185
test loss item: 0.2854635417461395
test loss item: 0.10466980189085007
test loss item: 0.21410107612609863
test loss item: 0.27496400475502014
test loss item: 0.11565716564655304
test loss item: 0.049426622688770294
test loss item: 0.10711240768432617
Epoch [11/100], Training Loss: 0.2249, Testing Loss: 0.1565
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 12/100
train loss item: 0.3436008393764496
train loss item: 0.16941313445568085
train loss item: 0.11813924461603165
train loss item: 0.2629832625389099
train loss item: 0.18479378521442413
train loss item: 0.16727736592292786
train loss item: 0.21902959048748016
train loss item: 0.3150556981563568
train loss item: 0.09363129734992981
train loss item: 0.15639245510101318
train loss item: 0.12340131402015686
train loss item: 0.3900235593318939
train loss item: 0.15865661203861237
train loss item: 0.10670483857393265
train loss item: 0.19438861310482025
train loss item: 0.340000182390213
train loss item: 0.2122012823820114
train loss item: 0.34090885519981384
train loss item: 0.29425424337387085
train loss item: 0.1418818235397339
train loss item: 0.14984916150569916
train loss item: 0.11935196816921234
train loss item: 0.23522306978702545
train loss item: 0.14109164476394653
train loss item: 0.09077344089746475
train loss item: 0.3668143153190613
train loss item: 0.09303291887044907
train loss item: 0.5731610059738159
train loss item: 0.14026227593421936
train loss item: 0.0803268551826477
train loss item: 0.4270820915699005
train loss item: 0.17592597007751465
train loss item: 0.14720240235328674
train loss item: 0.15247583389282227
train loss item: 0.16050779819488525
train loss item: 0.10222151130437851
train loss item: 0.1474224030971527
train loss item: 0.06492916494607925
train loss item: 0.4716338813304901
train loss item: 0.11774097383022308
train loss item: 0.09526047855615616
train loss item: 0.19241400063037872
train loss item: 0.32627996802330017
train loss item: 0.7108134627342224
train loss item: 0.21364744007587433
test loss item: 0.09817904978990555
test loss item: 0.18633010983467102
test loss item: 0.13035961985588074
test loss item: 0.29875412583351135
test loss item: 0.17549970746040344
test loss item: 0.2570352256298065
test loss item: 0.12653397023677826
test loss item: 0.09435141086578369
test loss item: 0.14350482821464539
test loss item: 0.18615278601646423
test loss item: 0.17610666155815125
test loss item: 0.13182225823402405
test loss item: 0.11177951842546463
test loss item: 0.14519906044006348
test loss item: 0.1688375473022461
test loss item: 0.23216821253299713
test loss item: 0.1732536107301712
test loss item: 0.21545040607452393
test loss item: 0.32875582575798035
test loss item: 0.1620362102985382
test loss item: 0.11102358251810074
test loss item: 0.12173646688461304
test loss item: 0.18691407144069672
test loss item: 0.14277338981628418
test loss item: 0.2320476472377777
test loss item: 0.15551970899105072
test loss item: 0.1229533925652504
test loss item: 0.2649248242378235
test loss item: 0.18598388135433197
test loss item: 0.1389986276626587
test loss item: 0.16906531155109406
test loss item: 0.11678092181682587
test loss item: 0.2276400774717331
test loss item: 0.1363641768693924
test loss item: 0.17587631940841675
test loss item: 0.20213806629180908
test loss item: 0.18270061910152435
test loss item: 0.09975455701351166
test loss item: 0.30513060092926025
test loss item: 0.11725737154483795
test loss item: 0.23077258467674255
test loss item: 0.3059195876121521
test loss item: 0.13757576048374176
test loss item: 0.06048884242773056
test loss item: 0.10602082312107086
Epoch [12/100], Training Loss: 0.2184, Testing Loss: 0.1729
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 13/100
train loss item: 0.2910420596599579
train loss item: 0.15877144038677216
train loss item: 0.12234341353178024
train loss item: 0.14384208619594574
train loss item: 0.17298515141010284
train loss item: 0.16664160788059235
train loss item: 0.2155485600233078
train loss item: 0.2589423358440399
train loss item: 0.09571362286806107
train loss item: 0.17834100127220154
train loss item: 0.12315195053815842
train loss item: 0.5033544898033142
train loss item: 0.17924617230892181
train loss item: 0.14839187264442444
train loss item: 0.20117737352848053
train loss item: 0.3463890552520752
train loss item: 0.13386166095733643
train loss item: 0.29867345094680786
train loss item: 0.3592480421066284
train loss item: 0.20929022133350372
train loss item: 0.21003638207912445
train loss item: 0.13231880962848663
train loss item: 0.31963708996772766
train loss item: 0.11624737828969955
train loss item: 0.13962136209011078
train loss item: 0.3279414474964142
train loss item: 0.09806430339813232
train loss item: 0.5378357768058777
train loss item: 0.16182376444339752
train loss item: 0.09326236695051193
train loss item: 0.38528120517730713
train loss item: 0.17384853959083557
train loss item: 0.16669219732284546
train loss item: 0.15085265040397644
train loss item: 0.19467169046401978
train loss item: 0.14457009732723236
train loss item: 0.15231025218963623
train loss item: 0.07184474170207977
train loss item: 0.4099063575267792
train loss item: 0.10211821645498276
train loss item: 0.09233379364013672
train loss item: 0.14259502291679382
train loss item: 0.2787097990512848
train loss item: 0.7112868428230286
train loss item: 0.18886536359786987
test loss item: 0.10444264113903046
test loss item: 0.16583608090877533
test loss item: 0.1271396428346634
test loss item: 0.3568113446235657
test loss item: 0.14866052567958832
test loss item: 0.22120659053325653
test loss item: 0.10690858215093613
test loss item: 0.09515443444252014
test loss item: 0.13994719088077545
test loss item: 0.17915970087051392
test loss item: 0.18002831935882568
test loss item: 0.13339078426361084
test loss item: 0.1257861852645874
test loss item: 0.1347571760416031
test loss item: 0.1614949107170105
test loss item: 0.2242528647184372
test loss item: 0.15787340700626373
test loss item: 0.1941753327846527
test loss item: 0.3031875193119049
test loss item: 0.16334529221057892
test loss item: 0.1257079690694809
test loss item: 0.11227976530790329
test loss item: 0.18654851615428925
test loss item: 0.14652976393699646
test loss item: 0.21549563109874725
test loss item: 0.14172278344631195
test loss item: 0.12866921722888947
test loss item: 0.2270534634590149
test loss item: 0.18672704696655273
test loss item: 0.13330277800559998
test loss item: 0.15196029841899872
test loss item: 0.11769437789916992
test loss item: 0.21752507984638214
test loss item: 0.13465283811092377
test loss item: 0.16084997355937958
test loss item: 0.2482050210237503
test loss item: 0.19289840757846832
test loss item: 0.10753825306892395
test loss item: 0.2899901866912842
test loss item: 0.12347859144210815
test loss item: 0.23970557749271393
test loss item: 0.28004857897758484
test loss item: 0.14673036336898804
test loss item: 0.06475655734539032
test loss item: 0.1244647279381752
Epoch [13/100], Training Loss: 0.2180, Testing Loss: 0.1695
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 14/100
train loss item: 0.26711392402648926
train loss item: 0.15414607524871826
train loss item: 0.11538377404212952
train loss item: 0.15810145437717438
train loss item: 0.1671290546655655
train loss item: 0.16078229248523712
train loss item: 0.23835067451000214
train loss item: 0.2607754170894623
train loss item: 0.07688786834478378
train loss item: 0.20825248956680298
train loss item: 0.11774411052465439
train loss item: 0.5423811674118042
train loss item: 0.20138798654079437
train loss item: 0.1843707263469696
train loss item: 0.229689359664917
train loss item: 0.614041805267334
train loss item: 0.18126055598258972
train loss item: 0.3149806261062622
train loss item: 0.3761225640773773
train loss item: 0.20977549254894257
train loss item: 0.2386295646429062
train loss item: 0.127570241689682
train loss item: 0.42533522844314575
train loss item: 0.12367073446512222
train loss item: 0.14343488216400146
train loss item: 0.2870579957962036
train loss item: 0.09171659499406815
train loss item: 0.40211138129234314
train loss item: 0.1542910486459732
train loss item: 0.10215942561626434
train loss item: 0.4641861021518707
train loss item: 0.14888061583042145
train loss item: 0.1738571673631668
train loss item: 0.18702824413776398
train loss item: 0.17644865810871124
train loss item: 0.13989366590976715
train loss item: 0.1310640126466751
train loss item: 0.06726893037557602
train loss item: 0.3662954270839691
train loss item: 0.11984489113092422
train loss item: 0.0838862955570221
train loss item: 0.1531880646944046
train loss item: 0.19796980917453766
train loss item: 0.6190711259841919
train loss item: 0.18392790853977203
test loss item: 0.10704734176397324
test loss item: 0.18838155269622803
test loss item: 0.12414871901273727
test loss item: 0.6166298389434814
test loss item: 0.1620321422815323
test loss item: 0.2648890018463135
test loss item: 0.12874898314476013
test loss item: 0.10112027078866959
test loss item: 0.14927120506763458
test loss item: 0.2432476133108139
test loss item: 0.21058301627635956
test loss item: 0.12738141417503357
test loss item: 0.13004441559314728
test loss item: 0.13496354222297668
test loss item: 0.16211895644664764
test loss item: 0.343945175409317
test loss item: 0.16263267397880554
test loss item: 0.1938135176897049
test loss item: 0.407200425863266
test loss item: 0.17499862611293793
test loss item: 0.13982164859771729
test loss item: 0.12810443341732025
test loss item: 0.1916898787021637
test loss item: 0.1387144774198532
test loss item: 0.25245943665504456
test loss item: 0.1340564489364624
test loss item: 0.13700076937675476
test loss item: 0.2448364496231079
test loss item: 0.237359419465065
test loss item: 0.14364053308963776
test loss item: 0.16842974722385406
test loss item: 0.13734275102615356
test loss item: 0.286772757768631
test loss item: 0.15922819077968597
test loss item: 0.20558927953243256
test loss item: 0.40188148617744446
test loss item: 0.22176684439182281
test loss item: 0.10897651314735413
test loss item: 0.3676464557647705
test loss item: 0.12138617038726807
test loss item: 0.34948602318763733
test loss item: 0.3729490637779236
test loss item: 0.14736133813858032
test loss item: 0.07436632364988327
test loss item: 0.11952079087495804
Epoch [14/100], Training Loss: 0.2242, Testing Loss: 0.2027
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 15/100
train loss item: 0.24766868352890015
train loss item: 0.20512676239013672
train loss item: 0.1277473121881485
train loss item: 0.1755506843328476
train loss item: 0.17564581334590912
train loss item: 0.14296363294124603
train loss item: 0.22769686579704285
train loss item: 0.23421259224414825
train loss item: 0.07137665897607803
train loss item: 0.1693924367427826
train loss item: 0.11683444678783417
train loss item: 0.45268064737319946
train loss item: 0.18357591331005096
train loss item: 0.1490146815776825
train loss item: 0.25207754969596863
train loss item: 0.27668049931526184
train loss item: 0.15526296198368073
train loss item: 0.2483738213777542
train loss item: 0.21501389145851135
train loss item: 0.1570596843957901
train loss item: 0.14010757207870483
train loss item: 0.15334992110729218
train loss item: 0.274236261844635
train loss item: 0.1766485571861267
train loss item: 0.12013185769319534
train loss item: 0.2907073497772217
train loss item: 0.07114449143409729
train loss item: 0.3552267551422119
train loss item: 0.10542935132980347
train loss item: 0.07490681856870651
train loss item: 0.3248549699783325
train loss item: 0.2533189058303833
train loss item: 0.1278231292963028
train loss item: 0.13901877403259277
train loss item: 0.1681373566389084
train loss item: 0.13444045186042786
train loss item: 0.10693012923002243
train loss item: 0.060836806893348694
train loss item: 0.45587795972824097
train loss item: 0.08449497073888779
train loss item: 0.07612680643796921
train loss item: 0.1424446702003479
train loss item: 0.14641033113002777
train loss item: 0.5411350727081299
train loss item: 0.23377805948257446
test loss item: 0.08686957508325577
test loss item: 0.14987176656723022
test loss item: 0.10087008774280548
test loss item: 0.34035736322402954
test loss item: 0.10854529589414597
test loss item: 0.2120468020439148
test loss item: 0.08576381206512451
test loss item: 0.07319457828998566
test loss item: 0.11171425133943558
test loss item: 0.14761841297149658
test loss item: 0.14602845907211304
test loss item: 0.10958999395370483
test loss item: 0.08839219808578491
test loss item: 0.09906794875860214
test loss item: 0.11432536691427231
test loss item: 0.2068399041891098
test loss item: 0.13246247172355652
test loss item: 0.14443062245845795
test loss item: 0.2850041091442108
test loss item: 0.12982216477394104
test loss item: 0.11615955829620361
test loss item: 0.09688249975442886
test loss item: 0.14256475865840912
test loss item: 0.12050056457519531
test loss item: 0.16977478563785553
test loss item: 0.09553801268339157
test loss item: 0.10401377081871033
test loss item: 0.19761371612548828
test loss item: 0.15794841945171356
test loss item: 0.09733767807483673
test loss item: 0.10782526433467865
test loss item: 0.09568891674280167
test loss item: 0.21262431144714355
test loss item: 0.1083439514040947
test loss item: 0.1428358405828476
test loss item: 0.22191187739372253
test loss item: 0.15541395545005798
test loss item: 0.09212960302829742
test loss item: 0.3190300762653351
test loss item: 0.10290288925170898
test loss item: 0.2240685373544693
test loss item: 0.25824716687202454
test loss item: 0.10262437909841537
test loss item: 0.049742791801691055
test loss item: 0.0984094962477684
Epoch [15/100], Training Loss: 0.1943, Testing Loss: 0.1436
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 16/100
train loss item: 0.23825109004974365
train loss item: 0.2715851366519928
train loss item: 0.11076126247644424
train loss item: 0.1579161435365677
train loss item: 0.15887576341629028
train loss item: 0.1409408152103424
train loss item: 0.2682288587093353
train loss item: 0.33226412534713745
train loss item: 0.09227050095796585
train loss item: 0.2054215669631958
train loss item: 0.0954180657863617
train loss item: 0.6570529341697693
train loss item: 0.21614404022693634
train loss item: 0.21893157064914703
train loss item: 0.26246756315231323
train loss item: 1.0313770771026611
train loss item: 0.29769185185432434
train loss item: 0.6990759968757629
train loss item: 0.38893547654151917
train loss item: 0.19446223974227905
train loss item: 0.30661824345588684
train loss item: 0.21078459918498993
train loss item: 0.5641102194786072
train loss item: 0.24712634086608887
train loss item: 0.16417627036571503
train loss item: 0.43529215455055237
train loss item: 0.1110890805721283
train loss item: 0.40008193254470825
train loss item: 0.17618249356746674
train loss item: 0.11512171477079391
train loss item: 0.6390982866287231
train loss item: 0.20048555731773376
train loss item: 0.2745361030101776
train loss item: 0.25196096301078796
train loss item: 0.1752239465713501
train loss item: 0.13742803037166595
train loss item: 0.13953259587287903
train loss item: 0.079330213367939
train loss item: 0.4542795717716217
train loss item: 0.21053217351436615
train loss item: 0.12400553375482559
train loss item: 0.20848491787910461
train loss item: 0.19526270031929016
train loss item: 0.5501319766044617
train loss item: 0.23422661423683167
test loss item: 0.10313185304403305
test loss item: 0.18433214724063873
test loss item: 0.12109693884849548
test loss item: 0.5970198512077332
test loss item: 0.12461048364639282
test loss item: 0.25914013385772705
test loss item: 0.116367407143116
test loss item: 0.09139588475227356
test loss item: 0.14387212693691254
test loss item: 0.23844978213310242
test loss item: 0.1947222650051117
test loss item: 0.12850995361804962
test loss item: 0.1293763518333435
test loss item: 0.12890741229057312
test loss item: 0.13662943243980408
test loss item: 0.31980931758880615
test loss item: 0.15924568474292755
test loss item: 0.17819319665431976
test loss item: 0.41060420870780945
test loss item: 0.1634097844362259
test loss item: 0.14430052042007446
test loss item: 0.11984328180551529
test loss item: 0.18102040886878967
test loss item: 0.13613653182983398
test loss item: 0.23571988940238953
test loss item: 0.11497646570205688
test loss item: 0.12504486739635468
test loss item: 0.2493535280227661
test loss item: 0.2475462704896927
test loss item: 0.1271713376045227
test loss item: 0.1417238861322403
test loss item: 0.13706813752651215
test loss item: 0.3066776692867279
test loss item: 0.15741944313049316
test loss item: 0.19597524404525757
test loss item: 0.38692209124565125
test loss item: 0.202633336186409
test loss item: 0.1062253937125206
test loss item: 0.42970582842826843
test loss item: 0.12662935256958008
test loss item: 0.3568151295185089
test loss item: 0.3761148750782013
test loss item: 0.13297781348228455
test loss item: 0.06737443804740906
test loss item: 0.17518660426139832
Epoch [16/100], Training Loss: 0.2810, Testing Loss: 0.1980
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 17/100
train loss item: 0.2369764745235443
train loss item: 0.313438355922699
train loss item: 0.17352695763111115
train loss item: 0.2356322854757309
train loss item: 0.1512034386396408
train loss item: 0.14321665465831757
train loss item: 0.3165290355682373
train loss item: 0.24881432950496674
train loss item: 0.08558256179094315
train loss item: 0.17201264202594757
train loss item: 0.10169894993305206
train loss item: 0.48520252108573914
train loss item: 0.17814117670059204
train loss item: 0.19366315007209778
train loss item: 0.24166160821914673
train loss item: 0.5380905270576477
train loss item: 0.27515071630477905
train loss item: 0.36906611919403076
train loss item: 0.41388440132141113
train loss item: 0.18398621678352356
train loss item: 0.1862463802099228
train loss item: 0.1802724301815033
train loss item: 0.3532998263835907
train loss item: 0.1589207798242569
train loss item: 0.12021178007125854
train loss item: 0.45193159580230713
train loss item: 0.09351645410060883
train loss item: 0.3486708104610443
train loss item: 0.12232038378715515
train loss item: 0.08554015308618546
train loss item: 0.4334695041179657
train loss item: 0.12541866302490234
train loss item: 0.18564356863498688
train loss item: 0.23760612308979034
train loss item: 0.14701877534389496
train loss item: 0.11685962975025177
train loss item: 0.129193514585495
train loss item: 0.07454678416252136
train loss item: 0.3984174430370331
train loss item: 0.13728195428848267
train loss item: 0.0940280333161354
train loss item: 0.1848488450050354
train loss item: 0.2241101861000061
train loss item: 0.4955463707447052
train loss item: 0.2053270787000656
test loss item: 0.10603068023920059
test loss item: 0.26005178689956665
test loss item: 0.11641602218151093
test loss item: 0.6550767421722412
test loss item: 0.1472589522600174
test loss item: 0.4320695102214813
test loss item: 0.11090374737977982
test loss item: 0.08704167604446411
test loss item: 0.16258838772773743
test loss item: 0.256132572889328
test loss item: 0.22765779495239258
test loss item: 0.15004390478134155
test loss item: 0.13404303789138794
test loss item: 0.12958663702011108
test loss item: 0.15207405388355255
test loss item: 0.43620628118515015
test loss item: 0.21925164759159088
test loss item: 0.21306750178337097
test loss item: 0.62037593126297
test loss item: 0.1971084177494049
test loss item: 0.15586204826831818
test loss item: 0.13159964978694916
test loss item: 0.1990758180618286
test loss item: 0.15325146913528442
test loss item: 0.30740830302238464
test loss item: 0.11327212303876877
test loss item: 0.12681123614311218
test loss item: 0.3690952956676483
test loss item: 0.3088720440864563
test loss item: 0.11738500744104385
test loss item: 0.160319522023201
test loss item: 0.1405538022518158
test loss item: 0.45055922865867615
test loss item: 0.16590891778469086
test loss item: 0.25336968898773193
test loss item: 0.4172758162021637
test loss item: 0.23956918716430664
test loss item: 0.10659325867891312
test loss item: 0.8401430249214172
test loss item: 0.12733778357505798
test loss item: 0.5041450262069702
test loss item: 0.591410756111145
test loss item: 0.1334807574748993
test loss item: 0.07144157588481903
test loss item: 0.1561208814382553
Epoch [17/100], Training Loss: 0.2299, Testing Loss: 0.2479
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 18/100
train loss item: 0.2028810828924179
train loss item: 0.1788875311613083
train loss item: 0.13040043413639069
train loss item: 0.3179333806037903
train loss item: 0.12303038686513901
train loss item: 0.13717831671237946
train loss item: 0.25240442156791687
train loss item: 0.24779725074768066
train loss item: 0.07047214359045029
train loss item: 0.1439434140920639
train loss item: 0.0912184938788414
train loss item: 0.25609925389289856
train loss item: 0.14273323118686676
train loss item: 0.17464496195316315
train loss item: 0.19934721291065216
train loss item: 0.4081757664680481
train loss item: 0.2598218321800232
train loss item: 0.3371981978416443
train loss item: 0.26021191477775574
train loss item: 0.1550079584121704
train loss item: 0.10561240464448929
train loss item: 0.15930920839309692
train loss item: 0.19006870687007904
train loss item: 0.14357911050319672
train loss item: 0.12479230761528015
train loss item: 0.40627723932266235
train loss item: 0.0863821730017662
train loss item: 0.2300586998462677
train loss item: 0.16265398263931274
train loss item: 0.08500725030899048
train loss item: 0.36695000529289246
train loss item: 0.2260267436504364
train loss item: 0.11235583573579788
train loss item: 0.1741328239440918
train loss item: 0.1362736076116562
train loss item: 0.08723603934049606
train loss item: 0.10451936721801758
train loss item: 0.05937855318188667
train loss item: 0.4935542643070221
train loss item: 0.10461534559726715
train loss item: 0.0840689092874527
train loss item: 0.1832641065120697
train loss item: 0.15689751505851746
train loss item: 0.46897804737091064
train loss item: 0.22125115990638733
test loss item: 0.09778294712305069
test loss item: 0.15712951123714447
test loss item: 0.10711344331502914
test loss item: 0.2210811823606491
test loss item: 0.10087747126817703
test loss item: 0.24157193303108215
test loss item: 0.07873056083917618
test loss item: 0.08576902002096176
test loss item: 0.10016155242919922
test loss item: 0.11713206768035889
test loss item: 0.12455723434686661
test loss item: 0.09977230429649353
test loss item: 0.08667638152837753
test loss item: 0.10458162426948547
test loss item: 0.10667470097541809
test loss item: 0.20212814211845398
test loss item: 0.14479586482048035
test loss item: 0.139255091547966
test loss item: 0.30275511741638184
test loss item: 0.12239975482225418
test loss item: 0.09706061333417892
test loss item: 0.088116355240345
test loss item: 0.11473023146390915
test loss item: 0.0955713614821434
test loss item: 0.16318435966968536
test loss item: 0.08767925947904587
test loss item: 0.09205157309770584
test loss item: 0.20533421635627747
test loss item: 0.1639735847711563
test loss item: 0.09409870207309723
test loss item: 0.10075212270021439
test loss item: 0.08924158662557602
test loss item: 0.20749753713607788
test loss item: 0.08867425471544266
test loss item: 0.1450381577014923
test loss item: 0.1406729817390442
test loss item: 0.11506348848342896
test loss item: 0.08252549916505814
test loss item: 0.4146352708339691
test loss item: 0.10393209010362625
test loss item: 0.223518505692482
test loss item: 0.27316299080848694
test loss item: 0.08805236220359802
test loss item: 0.0811193659901619
test loss item: 0.12439720332622528
Epoch [18/100], Training Loss: 0.1947, Testing Loss: 0.1382
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 19/100
train loss item: 0.29421481490135193
train loss item: 0.22631724178791046
train loss item: 0.12807616591453552
train loss item: 0.17872504889965057
train loss item: 0.09104209393262863
train loss item: 0.10245969891548157
train loss item: 0.1656987965106964
train loss item: 0.27694717049598694
train loss item: 0.0676899179816246
train loss item: 0.1492651104927063
train loss item: 0.11721444875001907
train loss item: 0.34607648849487305
train loss item: 0.15011268854141235
train loss item: 0.15956737101078033
train loss item: 0.17554780840873718
train loss item: 0.23214052617549896
train loss item: 0.18965035676956177
train loss item: 0.2754869759082794
train loss item: 0.328632652759552
train loss item: 0.1711810678243637
train loss item: 0.15287359058856964
train loss item: 0.10320837050676346
train loss item: 0.1854885071516037
train loss item: 0.10588841140270233
train loss item: 0.095455102622509
train loss item: 0.30304092168807983
train loss item: 0.07470253109931946
train loss item: 0.3399088978767395
train loss item: 0.11124604940414429
train loss item: 0.08125358819961548
train loss item: 0.3919949233531952
train loss item: 0.177531436085701
train loss item: 0.17779140174388885
train loss item: 0.1469409167766571
train loss item: 0.12232130765914917
train loss item: 0.09054095298051834
train loss item: 0.1265702098608017
train loss item: 0.05818551406264305
train loss item: 0.2835381329059601
train loss item: 0.136203333735466
train loss item: 0.07331760227680206
train loss item: 0.160737544298172
train loss item: 0.1709779053926468
train loss item: 0.5513587594032288
train loss item: 0.15175209939479828
test loss item: 0.08155867457389832
test loss item: 0.15907393395900726
test loss item: 0.09821287542581558
test loss item: 0.5429476499557495
test loss item: 0.10599785298109055
test loss item: 0.25354471802711487
test loss item: 0.09583470225334167
test loss item: 0.06711751222610474
test loss item: 0.1338113397359848
test loss item: 0.21636061370372772
test loss item: 0.1803763210773468
test loss item: 0.11893253773450851
test loss item: 0.10230310261249542
test loss item: 0.11386954039335251
test loss item: 0.12751562893390656
test loss item: 0.29161858558654785
test loss item: 0.13770532608032227
test loss item: 0.15868574380874634
test loss item: 0.3716853857040405
test loss item: 0.15335996448993683
test loss item: 0.13177908957004547
test loss item: 0.10838879644870758
test loss item: 0.17537827789783478
test loss item: 0.12534819543361664
test loss item: 0.20932537317276
test loss item: 0.088437020778656
test loss item: 0.10852054506540298
test loss item: 0.19913360476493835
test loss item: 0.2231198251247406
test loss item: 0.10007324069738388
test loss item: 0.12430895119905472
test loss item: 0.11452101171016693
test loss item: 0.2715698778629303
test loss item: 0.1426326185464859
test loss item: 0.1803571581840515
test loss item: 0.3657798767089844
test loss item: 0.21155929565429688
test loss item: 0.08957891911268234
test loss item: 0.4053685665130615
test loss item: 0.10583169013261795
test loss item: 0.3329334855079651
test loss item: 0.3453255295753479
test loss item: 0.11587859690189362
test loss item: 0.049794990569353104
test loss item: 0.10643366724252701
Epoch [19/100], Training Loss: 0.1822, Testing Loss: 0.1765
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 20/100
train loss item: 0.19495277106761932
train loss item: 0.13637709617614746
train loss item: 0.10323309898376465
train loss item: 0.2187473475933075
train loss item: 0.08418294787406921
train loss item: 0.12351945787668228
train loss item: 0.18747751414775848
train loss item: 0.16738328337669373
train loss item: 0.09435256570577621
train loss item: 0.13990534842014313
train loss item: 0.10439185053110123
train loss item: 0.20016434788703918
train loss item: 0.13284985721111298
train loss item: 0.168186217546463
train loss item: 0.16171705722808838
train loss item: 0.5218599438667297
train loss item: 0.19566796720027924
train loss item: 0.23270100355148315
train loss item: 0.23224234580993652
train loss item: 0.18444941937923431
train loss item: 0.1316893845796585
train loss item: 0.13611067831516266
train loss item: 0.2387540340423584
train loss item: 0.10423441231250763
train loss item: 0.09419931471347809
train loss item: 0.2561018168926239
train loss item: 0.07742825895547867
train loss item: 0.3899475634098053
train loss item: 0.15523165464401245
train loss item: 0.10320013016462326
train loss item: 0.30575719475746155
train loss item: 0.23620644211769104
train loss item: 0.12383341789245605
train loss item: 0.23347216844558716
train loss item: 0.1536150425672531
train loss item: 0.09018806368112564
train loss item: 0.10647522658109665
train loss item: 0.05447469279170036
train loss item: 0.4548945128917694
train loss item: 0.09058333188295364
train loss item: 0.09397421777248383
train loss item: 0.1562076210975647
train loss item: 0.19322478771209717
train loss item: 0.5688056945800781
train loss item: 0.16410093009471893
test loss item: 0.09525585919618607
test loss item: 0.1553451120853424
test loss item: 0.10235877335071564
test loss item: 0.24972933530807495
test loss item: 0.12335315346717834
test loss item: 0.2529264986515045
test loss item: 0.0930335521697998
test loss item: 0.081942118704319
test loss item: 0.11892585456371307
test loss item: 0.15304024517536163
test loss item: 0.13053733110427856
test loss item: 0.1269242763519287
test loss item: 0.09602274745702744
test loss item: 0.11664408445358276
test loss item: 0.12242986261844635
test loss item: 0.21219803392887115
test loss item: 0.13911540806293488
test loss item: 0.15777456760406494
test loss item: 0.2973117232322693
test loss item: 0.12409570068120956
test loss item: 0.12634359300136566
test loss item: 0.10929379612207413
test loss item: 0.13420289754867554
test loss item: 0.14137184619903564
test loss item: 0.1818760186433792
test loss item: 0.10623164474964142
test loss item: 0.10788055509328842
test loss item: 0.2182610034942627
test loss item: 0.15580156445503235
test loss item: 0.0980783998966217
test loss item: 0.11789215356111526
test loss item: 0.0965006873011589
test loss item: 0.20460058748722076
test loss item: 0.11224714666604996
test loss item: 0.14657801389694214
test loss item: 0.16152502596378326
test loss item: 0.1531573086977005
test loss item: 0.11127883195877075
test loss item: 0.33659327030181885
test loss item: 0.10588190704584122
test loss item: 0.21903842687606812
test loss item: 0.2753099501132965
test loss item: 0.11122564226388931
test loss item: 0.06167995557188988
test loss item: 0.09495606273412704
Epoch [20/100], Training Loss: 0.1844, Testing Loss: 0.1475
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 21/100
train loss item: 0.2652800679206848
train loss item: 0.14985865354537964
train loss item: 0.11151501536369324
train loss item: 0.17995628714561462
train loss item: 0.09390650689601898
train loss item: 0.1022203266620636
train loss item: 0.14284105598926544
train loss item: 0.14906661212444305
train loss item: 0.06737595796585083
train loss item: 0.1109386533498764
train loss item: 0.09081259369850159
train loss item: 0.24293042719364166
train loss item: 0.10780870914459229
train loss item: 0.1493462175130844
train loss item: 0.15136264264583588
train loss item: 0.2410501092672348
train loss item: 0.13564945757389069
train loss item: 0.28597062826156616
train loss item: 0.271072119474411
train loss item: 0.12636305391788483
train loss item: 0.09559158980846405
train loss item: 0.10654694586992264
train loss item: 0.16991136968135834
train loss item: 0.09678354114294052
train loss item: 0.0782991349697113
train loss item: 0.23131845891475677
train loss item: 0.06356768310070038
train loss item: 0.23644408583641052
train loss item: 0.10478796809911728
train loss item: 0.06364516168832779
train loss item: 0.27214932441711426
train loss item: 0.13549059629440308
train loss item: 0.13650187849998474
train loss item: 0.1092352345585823
train loss item: 0.13174507021903992
train loss item: 0.08389998227357864
train loss item: 0.10360392928123474
train loss item: 0.06306526809930801
train loss item: 0.26351267099380493
train loss item: 0.09028929471969604
train loss item: 0.06608896702528
train loss item: 0.133888840675354
train loss item: 0.14156369864940643
train loss item: 0.5604045987129211
train loss item: 0.12155991047620773
test loss item: 0.08471933752298355
test loss item: 0.16661839187145233
test loss item: 0.08933917433023453
test loss item: 0.5462343692779541
test loss item: 0.10681597888469696
test loss item: 0.26900431513786316
test loss item: 0.088202565908432
test loss item: 0.06529245525598526
test loss item: 0.1332991123199463
test loss item: 0.22489449381828308
test loss item: 0.18179303407669067
test loss item: 0.12435504794120789
test loss item: 0.10124115645885468
test loss item: 0.1085154265165329
test loss item: 0.12455577403306961
test loss item: 0.29526373744010925
test loss item: 0.13233990967273712
test loss item: 0.15204256772994995
test loss item: 0.39601272344589233
test loss item: 0.14795060455799103
test loss item: 0.14193855226039886
test loss item: 0.10695872455835342
test loss item: 0.17930744588375092
test loss item: 0.1364038586616516
test loss item: 0.21339452266693115
test loss item: 0.08177930861711502
test loss item: 0.10500317066907883
test loss item: 0.20680174231529236
test loss item: 0.2310706377029419
test loss item: 0.09203311055898666
test loss item: 0.12537498772144318
test loss item: 0.11881110072135925
test loss item: 0.29625844955444336
test loss item: 0.14135952293872833
test loss item: 0.1748744696378708
test loss item: 0.36152857542037964
test loss item: 0.21270161867141724
test loss item: 0.10000947117805481
test loss item: 0.4283989667892456
test loss item: 0.10889522731304169
test loss item: 0.34353524446487427
test loss item: 0.3641539216041565
test loss item: 0.11193124949932098
test loss item: 0.0536954328417778
test loss item: 0.12112729996442795
Epoch [21/100], Training Loss: 0.1519, Testing Loss: 0.1799
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 22/100
train loss item: 0.18841663002967834
train loss item: 0.12181872129440308
train loss item: 0.10044125467538834
train loss item: 0.2012195587158203
train loss item: 0.08653847873210907
train loss item: 0.09805434942245483
train loss item: 0.16167756915092468
train loss item: 0.10831091552972794
train loss item: 0.05699653923511505
train loss item: 0.1211816594004631
train loss item: 0.08059074729681015
train loss item: 0.18435180187225342
train loss item: 0.1134098619222641
train loss item: 0.14159736037254333
train loss item: 0.13992619514465332
train loss item: 0.2879059612751007
train loss item: 0.153591126203537
train loss item: 0.20141947269439697
train loss item: 0.180457204580307
train loss item: 0.16764502227306366
train loss item: 0.10821332037448883
train loss item: 0.11904896795749664
train loss item: 0.17560219764709473
train loss item: 0.11712751537561417
train loss item: 0.09947318583726883
train loss item: 0.2493584305047989
train loss item: 0.08349974453449249
train loss item: 0.34220558404922485
train loss item: 0.11804389208555222
train loss item: 0.08040914684534073
train loss item: 0.27369317412376404
train loss item: 0.17649191617965698
train loss item: 0.09915940463542938
train loss item: 0.18372827768325806
train loss item: 0.12685899436473846
train loss item: 0.0846324935555458
train loss item: 0.09479828923940659
train loss item: 0.062293220311403275
train loss item: 0.3601577877998352
train loss item: 0.07604125887155533
train loss item: 0.06862581521272659
train loss item: 0.13466374576091766
train loss item: 0.16549353301525116
train loss item: 0.5083849430084229
train loss item: 0.1253868043422699
test loss item: 0.09354852139949799
test loss item: 0.17495384812355042
test loss item: 0.10228054225444794
test loss item: 0.3976716697216034
test loss item: 0.13678506016731262
test loss item: 0.2820911407470703
test loss item: 0.10436856001615524
test loss item: 0.07732827216386795
test loss item: 0.12703314423561096
test loss item: 0.18732507526874542
test loss item: 0.15689745545387268
test loss item: 0.12961314618587494
test loss item: 0.09507471323013306
test loss item: 0.12175052613019943
test loss item: 0.13128703832626343
test loss item: 0.2697904407978058
test loss item: 0.15262968838214874
test loss item: 0.1746680736541748
test loss item: 0.367545485496521
test loss item: 0.13628865778446198
test loss item: 0.12292889505624771
test loss item: 0.10726006329059601
test loss item: 0.1582227647304535
test loss item: 0.14889150857925415
test loss item: 0.21518361568450928
test loss item: 0.11657235026359558
test loss item: 0.09972616285085678
test loss item: 0.24845504760742188
test loss item: 0.18824100494384766
test loss item: 0.10792180150747299
test loss item: 0.13713210821151733
test loss item: 0.10619194060564041
test loss item: 0.2541494071483612
test loss item: 0.12006951868534088
test loss item: 0.17338578402996063
test loss item: 0.25423091650009155
test loss item: 0.1819322109222412
test loss item: 0.10963493585586548
test loss item: 0.41946908831596375
test loss item: 0.11122499406337738
test loss item: 0.28623706102371216
test loss item: 0.3449721038341522
test loss item: 0.11600352823734283
test loss item: 0.05575565993785858
test loss item: 0.09241645783185959
Epoch [22/100], Training Loss: 0.1540, Testing Loss: 0.1710
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 23/100
train loss item: 0.1773311048746109
train loss item: 0.1273309737443924
train loss item: 0.09596699476242065
train loss item: 0.17824450135231018
train loss item: 0.07661577314138412
train loss item: 0.09971673041582108
train loss item: 0.13334344327449799
train loss item: 0.12210351973772049
train loss item: 0.06575087457895279
train loss item: 0.11112280189990997
train loss item: 0.08534730970859528
train loss item: 0.22763623297214508
train loss item: 0.10374412685632706
train loss item: 0.14295588433742523
train loss item: 0.12959536910057068
train loss item: 0.2080218493938446
train loss item: 0.1280074417591095
train loss item: 0.2801204025745392
train loss item: 0.20559439063072205
train loss item: 0.1286046952009201
train loss item: 0.09246312081813812
train loss item: 0.11785342544317245
train loss item: 0.15797941386699677
train loss item: 0.09139863401651382
train loss item: 0.07840829342603683
train loss item: 0.22809845209121704
train loss item: 0.06402773410081863
train loss item: 0.2104061394929886
train loss item: 0.09773124009370804
train loss item: 0.06046346202492714
train loss item: 0.22896359860897064
train loss item: 0.12062402069568634
train loss item: 0.10866625607013702
train loss item: 0.11772885918617249
train loss item: 0.11950518935918808
train loss item: 0.08187340945005417
train loss item: 0.08852007985115051
train loss item: 0.05504895746707916
train loss item: 0.28255292773246765
train loss item: 0.08626615256071091
train loss item: 0.06517281383275986
train loss item: 0.12105931341648102
train loss item: 0.1289370357990265
train loss item: 0.521780788898468
train loss item: 0.10708822309970856
test loss item: 0.08598403632640839
test loss item: 0.17060387134552002
test loss item: 0.08858262747526169
test loss item: 0.46921613812446594
test loss item: 0.12129919230937958
test loss item: 0.27103620767593384
test loss item: 0.08701490610837936
test loss item: 0.07232777029275894
test loss item: 0.12760871648788452
test loss item: 0.2006511688232422
test loss item: 0.16652004420757294
test loss item: 0.11537803709506989
test loss item: 0.09442908316850662
test loss item: 0.10809063166379929
test loss item: 0.12572377920150757
test loss item: 0.2766379714012146
test loss item: 0.14760971069335938
test loss item: 0.1579531878232956
test loss item: 0.38536614179611206
test loss item: 0.14082041382789612
test loss item: 0.12437772750854492
test loss item: 0.10551360994577408
test loss item: 0.16451114416122437
test loss item: 0.12538695335388184
test loss item: 0.20718298852443695
test loss item: 0.09707367420196533
test loss item: 0.09883365035057068
test loss item: 0.22111092507839203
test loss item: 0.20381683111190796
test loss item: 0.09547673165798187
test loss item: 0.13343803584575653
test loss item: 0.10730335116386414
test loss item: 0.26741287112236023
test loss item: 0.1234404668211937
test loss item: 0.1660711020231247
test loss item: 0.3037441670894623
test loss item: 0.18197409808635712
test loss item: 0.09096187353134155
test loss item: 0.4226045608520508
test loss item: 0.09807776659727097
test loss item: 0.30847325921058655
test loss item: 0.3509429097175598
test loss item: 0.1022990345954895
test loss item: 0.05682440102100372
test loss item: 0.11766175180673599
Epoch [23/100], Training Loss: 0.1391, Testing Loss: 0.1708
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 24/100
train loss item: 0.17952676117420197
train loss item: 0.11734800785779953
train loss item: 0.09817750751972198
train loss item: 0.16340036690235138
train loss item: 0.07200019806623459
train loss item: 0.08928162604570389
train loss item: 0.1109238788485527
train loss item: 0.12555469572544098
train loss item: 0.0643077939748764
train loss item: 0.11483742296695709
train loss item: 0.07659193873405457
train loss item: 0.19233351945877075
train loss item: 0.10178732126951218
train loss item: 0.13621245324611664
train loss item: 0.14207743108272552
train loss item: 0.19362589716911316
train loss item: 0.09543316811323166
train loss item: 0.33441099524497986
train loss item: 0.23425604403018951
train loss item: 0.12112519145011902
train loss item: 0.09706714749336243
train loss item: 0.0958242118358612
train loss item: 0.14677082002162933
train loss item: 0.07848947495222092
train loss item: 0.06827741116285324
train loss item: 0.19966672360897064
train loss item: 0.06618987768888474
train loss item: 0.2091979682445526
train loss item: 0.11393888294696808
train loss item: 0.05787622183561325
train loss item: 0.21060124039649963
train loss item: 0.1033688336610794
train loss item: 0.11782548576593399
train loss item: 0.10333724319934845
train loss item: 0.11419709026813507
train loss item: 0.077433280646801
train loss item: 0.09782806783914566
train loss item: 0.06462746858596802
train loss item: 0.20784489810466766
train loss item: 0.0828862115740776
train loss item: 0.06140630692243576
train loss item: 0.11173596978187561
train loss item: 0.11133837699890137
train loss item: 0.4675334095954895
train loss item: 0.10005630552768707
test loss item: 0.08547797799110413
test loss item: 0.19327804446220398
test loss item: 0.0939454734325409
test loss item: 0.5735135674476624
test loss item: 0.12178415805101395
test loss item: 0.318157434463501
test loss item: 0.09224168211221695
test loss item: 0.06747730821371078
test loss item: 0.1434689462184906
test loss item: 0.22945746779441833
test loss item: 0.19245989620685577
test loss item: 0.12470594048500061
test loss item: 0.10355262458324432
test loss item: 0.1139204278588295
test loss item: 0.13278979063034058
test loss item: 0.33735132217407227
test loss item: 0.15502457320690155
test loss item: 0.16090108454227448
test loss item: 0.4601842164993286
test loss item: 0.159328892827034
test loss item: 0.14261797070503235
test loss item: 0.11466006189584732
test loss item: 0.18782787024974823
test loss item: 0.1367403268814087
test loss item: 0.23362654447555542
test loss item: 0.09185845404863358
test loss item: 0.10866327583789825
test loss item: 0.25389164686203003
test loss item: 0.23275989294052124
test loss item: 0.09543765336275101
test loss item: 0.13628672063350677
test loss item: 0.12175308167934418
test loss item: 0.3324505090713501
test loss item: 0.1435769647359848
test loss item: 0.18705704808235168
test loss item: 0.36642488837242126
test loss item: 0.216207817196846
test loss item: 0.10235179215669632
test loss item: 0.5419571399688721
test loss item: 0.11273904889822006
test loss item: 0.37672916054725647
test loss item: 0.4295363128185272
test loss item: 0.11263085901737213
test loss item: 0.052321579307317734
test loss item: 0.12599559128284454
Epoch [24/100], Training Loss: 0.1317, Testing Loss: 0.1959
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 25/100
train loss item: 0.16279126703739166
train loss item: 0.11354159563779831
train loss item: 0.09549940377473831
train loss item: 0.1779455542564392
train loss item: 0.07118819653987885
train loss item: 0.093912273645401
train loss item: 0.11398756504058838
train loss item: 0.1291230171918869
train loss item: 0.06743598729372025
train loss item: 0.11644383519887924
train loss item: 0.09989608824253082
train loss item: 0.20381306111812592
train loss item: 0.12719032168388367
train loss item: 0.14842279255390167
train loss item: 0.15701685845851898
train loss item: 0.2710173428058624
train loss item: 0.13962359726428986
train loss item: 0.23319531977176666
train loss item: 0.1954355239868164
train loss item: 0.16226080060005188
train loss item: 0.10428920388221741
train loss item: 0.10573949664831161
train loss item: 0.15568745136260986
train loss item: 0.09854596108198166
train loss item: 0.09949465095996857
train loss item: 0.23304425179958344
train loss item: 0.0723690465092659
train loss item: 0.3355453312397003
train loss item: 0.10782619565725327
train loss item: 0.07072953879833221
train loss item: 0.311972975730896
train loss item: 0.13356295228004456
train loss item: 0.09967681020498276
train loss item: 0.1438518464565277
train loss item: 0.1132780984044075
train loss item: 0.08030866831541061
train loss item: 0.08505422621965408
train loss item: 0.06266085058450699
train loss item: 0.2284790426492691
train loss item: 0.0785834863781929
train loss item: 0.06173008680343628
train loss item: 0.1431935727596283
train loss item: 0.14894551038742065
train loss item: 0.4929678440093994
train loss item: 0.10650298744440079
test loss item: 0.08787357807159424
test loss item: 0.17561395466327667
test loss item: 0.09111089259386063
test loss item: 0.5449596643447876
test loss item: 0.13231161236763
test loss item: 0.28757035732269287
test loss item: 0.10427913069725037
test loss item: 0.06942132115364075
test loss item: 0.1357668787240982
test loss item: 0.22311460971832275
test loss item: 0.18045158684253693
test loss item: 0.13350176811218262
test loss item: 0.09857524186372757
test loss item: 0.120029978454113
test loss item: 0.13347883522510529
test loss item: 0.31423670053482056
test loss item: 0.15205830335617065
test loss item: 0.17114228010177612
test loss item: 0.4076397716999054
test loss item: 0.15188562870025635
test loss item: 0.134983628988266
test loss item: 0.112310029566288
test loss item: 0.18078072369098663
test loss item: 0.14947326481342316
test loss item: 0.2314155399799347
test loss item: 0.11049880087375641
test loss item: 0.10231970250606537
test loss item: 0.23961158096790314
test loss item: 0.21715235710144043
test loss item: 0.10512636601924896
test loss item: 0.14717581868171692
test loss item: 0.1151321604847908
test loss item: 0.2812165915966034
test loss item: 0.1371544450521469
test loss item: 0.18642489612102509
test loss item: 0.34682372212409973
test loss item: 0.21067428588867188
test loss item: 0.10591626912355423
test loss item: 0.4221605062484741
test loss item: 0.10816450417041779
test loss item: 0.3387618362903595
test loss item: 0.3815014362335205
test loss item: 0.11472499370574951
test loss item: 0.05003116652369499
test loss item: 0.09393450617790222
Epoch [25/100], Training Loss: 0.1456, Testing Loss: 0.1853
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 26/100
train loss item: 0.16174186766147614
train loss item: 0.11983948200941086
train loss item: 0.08709031343460083
train loss item: 0.14940433204174042
train loss item: 0.06728674471378326
train loss item: 0.09622974693775177
train loss item: 0.11795873939990997
train loss item: 0.14665576815605164
train loss item: 0.05341067165136337
train loss item: 0.11632824689149857
train loss item: 0.08183083683252335
train loss item: 0.19439633190631866
train loss item: 0.09976985305547714
train loss item: 0.13626188039779663
train loss item: 0.16613173484802246
train loss item: 0.20472271740436554
train loss item: 0.10389009863138199
train loss item: 0.3017463982105255
train loss item: 0.22634752094745636
train loss item: 0.15349338948726654
train loss item: 0.09724438935518265
train loss item: 0.10595814883708954
train loss item: 0.1441069394350052
train loss item: 0.09474362432956696
train loss item: 0.08242711424827576
train loss item: 0.20821411907672882
train loss item: 0.06279786676168442
train loss item: 0.23574739694595337
train loss item: 0.10610363632440567
train loss item: 0.057810258120298386
train loss item: 0.2471177875995636
train loss item: 0.10012535750865936
train loss item: 0.10542670637369156
train loss item: 0.10941064357757568
train loss item: 0.10858135670423508
train loss item: 0.07294207066297531
train loss item: 0.0866168737411499
train loss item: 0.05997348576784134
train loss item: 0.18364855647087097
train loss item: 0.07800477743148804
train loss item: 0.06335479021072388
train loss item: 0.13755007088184357
train loss item: 0.11306513845920563
train loss item: 0.5015072822570801
train loss item: 0.09749965369701385
test loss item: 0.08755835890769958
test loss item: 0.19380506873130798
test loss item: 0.09138679504394531
test loss item: 0.6048303246498108
test loss item: 0.13228315114974976
test loss item: 0.3108483552932739
test loss item: 0.10772448033094406
test loss item: 0.06561224162578583
test loss item: 0.15047402679920197
test loss item: 0.24336841702461243
test loss item: 0.20009392499923706
test loss item: 0.13946524262428284
test loss item: 0.10509524494409561
test loss item: 0.12196100503206253
test loss item: 0.14250768721103668
test loss item: 0.3481636345386505
test loss item: 0.15627272427082062
test loss item: 0.1672607809305191
test loss item: 0.45812833309173584
test loss item: 0.16470086574554443
test loss item: 0.15365572273731232
test loss item: 0.11789394170045853
test loss item: 0.20273348689079285
test loss item: 0.1611877679824829
test loss item: 0.24235504865646362
test loss item: 0.1053844541311264
test loss item: 0.11016307026147842
test loss item: 0.2520158588886261
test loss item: 0.2393452674150467
test loss item: 0.10600464046001434
test loss item: 0.14831990003585815
test loss item: 0.13146916031837463
test loss item: 0.32611215114593506
test loss item: 0.15189887583255768
test loss item: 0.19179704785346985
test loss item: 0.38354402780532837
test loss item: 0.2354108691215515
test loss item: 0.11598742753267288
test loss item: 0.5065258145332336
test loss item: 0.12072955071926117
test loss item: 0.37726160883903503
test loss item: 0.42719727754592896
test loss item: 0.1202159896492958
test loss item: 0.04916715994477272
test loss item: 0.11989587545394897
Epoch [26/100], Training Loss: 0.1343, Testing Loss: 0.2020
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 27/100
train loss item: 0.1782546490430832
train loss item: 0.12147052586078644
train loss item: 0.09479746222496033
train loss item: 0.1149233728647232
train loss item: 0.07497677952051163
train loss item: 0.10723461955785751
train loss item: 0.11392433941364288
train loss item: 0.14375776052474976
train loss item: 0.06277628988027573
train loss item: 0.1079014465212822
train loss item: 0.09134981036186218
train loss item: 0.19375546276569366
train loss item: 0.10768670588731766
train loss item: 0.1502016931772232
train loss item: 0.2196473777294159
train loss item: 0.2266281396150589
train loss item: 0.1433674395084381
train loss item: 0.24856433272361755
train loss item: 0.2096581906080246
train loss item: 0.14251038432121277
train loss item: 0.10249561816453934
train loss item: 0.09935904294252396
train loss item: 0.1528213769197464
train loss item: 0.09356456249952316
train loss item: 0.08524926751852036
train loss item: 0.2188873440027237
train loss item: 0.06672032922506332
train loss item: 0.29192590713500977
train loss item: 0.10033626109361649
train loss item: 0.06065020710229874
train loss item: 0.289734810590744
train loss item: 0.10427875071763992
train loss item: 0.10199380666017532
train loss item: 0.1028405949473381
train loss item: 0.10227712988853455
train loss item: 0.07939061522483826
train loss item: 0.08483970165252686
train loss item: 0.06519022583961487
train loss item: 0.18976667523384094
train loss item: 0.08824432641267776
train loss item: 0.06815645843744278
train loss item: 0.14148175716400146
train loss item: 0.11397518217563629
train loss item: 0.4859800636768341
train loss item: 0.0986323282122612
test loss item: 0.09729987382888794
test loss item: 0.18056976795196533
test loss item: 0.08837737143039703
test loss item: 0.6869661211967468
test loss item: 0.13267306983470917
test loss item: 0.2804797887802124
test loss item: 0.1152665764093399
test loss item: 0.07040304690599442
test loss item: 0.14824219048023224
test loss item: 0.2612212598323822
test loss item: 0.20677033066749573
test loss item: 0.1461447775363922
test loss item: 0.1033160537481308
test loss item: 0.12428432703018188
test loss item: 0.1429409682750702
test loss item: 0.3587857484817505
test loss item: 0.14702659845352173
test loss item: 0.16364355385303497
test loss item: 0.4433872103691101
test loss item: 0.16948378086090088
test loss item: 0.15714962780475616
test loss item: 0.1210068091750145
test loss item: 0.20246851444244385
test loss item: 0.16415031254291534
test loss item: 0.23509913682937622
test loss item: 0.11259447038173676
test loss item: 0.10937301069498062
test loss item: 0.21659255027770996
test loss item: 0.24786308407783508
test loss item: 0.11007411032915115
test loss item: 0.15698222815990448
test loss item: 0.1345561146736145
test loss item: 0.31590813398361206
test loss item: 0.15419991314411163
test loss item: 0.1918976604938507
test loss item: 0.43477165699005127
test loss item: 0.24800170958042145
test loss item: 0.11833822727203369
test loss item: 0.4292536675930023
test loss item: 0.12181978672742844
test loss item: 0.3880595266819
test loss item: 0.4120113253593445
test loss item: 0.11960048228502274
test loss item: 0.06059175357222557
test loss item: 0.0990452840924263
Epoch [27/100], Training Loss: 0.1387, Testing Loss: 0.2029
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 28/100
train loss item: 0.18747951090335846
train loss item: 0.13978491723537445
train loss item: 0.09686063230037689
train loss item: 0.13012059032917023
train loss item: 0.09492285549640656
train loss item: 0.0980389416217804
train loss item: 0.13999497890472412
train loss item: 0.11160197108983994
train loss item: 0.05353931710124016
train loss item: 0.12011826038360596
train loss item: 0.09608370065689087
train loss item: 0.19488020241260529
train loss item: 0.10931085050106049
train loss item: 0.14094585180282593
train loss item: 0.26151561737060547
train loss item: 0.3547268807888031
train loss item: 0.10626262426376343
train loss item: 0.2576977014541626
train loss item: 0.1137295737862587
train loss item: 0.10769467055797577
train loss item: 0.09854397922754288
train loss item: 0.07443443685770035
train loss item: 0.1945933699607849
train loss item: 0.10532429069280624
train loss item: 0.06848248839378357
train loss item: 0.20496617257595062
train loss item: 0.057492416352033615
train loss item: 0.20965389907360077
train loss item: 0.10717839747667313
train loss item: 0.0618797242641449
train loss item: 0.2721101641654968
train loss item: 0.14704133570194244
train loss item: 0.12821771204471588
train loss item: 0.13302606344223022
train loss item: 0.10729950666427612
train loss item: 0.07975603640079498
train loss item: 0.11092016100883484
train loss item: 0.07908859103918076
train loss item: 0.19078215956687927
train loss item: 0.1193220317363739
train loss item: 0.07409218698740005
train loss item: 0.14034150540828705
train loss item: 0.12193078547716141
train loss item: 0.36177459359169006
train loss item: 0.12153006345033646
test loss item: 0.09330607950687408
test loss item: 0.2064865678548813
test loss item: 0.10269499570131302
test loss item: 0.6515035033226013
test loss item: 0.14610330760478973
test loss item: 0.32006022334098816
test loss item: 0.12010388821363449
test loss item: 0.0742994025349617
test loss item: 0.15598353743553162
test loss item: 0.2690606415271759
test loss item: 0.21233375370502472
test loss item: 0.15475420653820038
test loss item: 0.10583401471376419
test loss item: 0.1332869976758957
test loss item: 0.15314750373363495
test loss item: 0.36170828342437744
test loss item: 0.16304782032966614
test loss item: 0.17906726896762848
test loss item: 0.48201784491539
test loss item: 0.17064395546913147
test loss item: 0.15861037373542786
test loss item: 0.12037981301546097
test loss item: 0.2180423140525818
test loss item: 0.17562107741832733
test loss item: 0.25970080494880676
test loss item: 0.11328314989805222
test loss item: 0.10969045758247375
test loss item: 0.2631036043167114
test loss item: 0.2607553005218506
test loss item: 0.11006267368793488
test loss item: 0.16232965886592865
test loss item: 0.13651733100414276
test loss item: 0.35301700234413147
test loss item: 0.16511501371860504
test loss item: 0.20761097967624664
test loss item: 0.41858047246932983
test loss item: 0.2518341839313507
test loss item: 0.12381072342395782
test loss item: 0.5137512683868408
test loss item: 0.13078127801418304
test loss item: 0.40337106585502625
test loss item: 0.4486818313598633
test loss item: 0.1275079846382141
test loss item: 0.04717116802930832
test loss item: 0.10777399688959122
Epoch [28/100], Training Loss: 0.1397, Testing Loss: 0.2143
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.14393049478530884
loss item: 0.5191104412078857
loss item: 0.289497047662735
loss item: 0.332757830619812
loss item: 0.13996507227420807
loss item: 0.5248458981513977
loss item: 0.32896554470062256
loss item: 0.13213637471199036
loss item: 0.22128643095493317
loss item: 0.3714844882488251
loss item: 0.16029128432273865
loss item: 0.18519045412540436
loss item: 0.30187809467315674
loss item: 0.2886209487915039
loss item: 0.20777656137943268
loss item: 0.620072066783905
loss item: 0.22958041727542877
loss item: 0.13103383779525757
loss item: 0.15893378853797913
loss item: 0.3172398507595062
loss item: 0.3844749927520752
loss item: 0.10547462850809097
Val Loss: 0.2770
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.0005 4 360 done at Tue Nov 12 13:03:10 CET 2024
UNet2 with 1 100 0.001 4 360 start at Tue Nov 12 13:03:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 100, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.6336421966552734
train loss item: 1.0241367816925049
train loss item: 0.6707100868225098
train loss item: 1.052453875541687
train loss item: 0.4325838088989258
train loss item: 0.45004919171333313
train loss item: 0.48263299465179443
train loss item: 0.7821451425552368
train loss item: 0.29314959049224854
train loss item: 0.4130592346191406
train loss item: 0.32709062099456787
train loss item: 1.3081952333450317
train loss item: 0.5725193619728088
train loss item: 0.3602299988269806
train loss item: 0.812736451625824
train loss item: 1.7246522903442383
train loss item: 0.5814995169639587
train loss item: 1.933405876159668
train loss item: 0.5622901916503906
train loss item: 0.5134773850440979
train loss item: 0.3968896269798279
train loss item: 0.3826901912689209
train loss item: 0.572571337223053
train loss item: 0.48281049728393555
train loss item: 0.28770947456359863
train loss item: 0.9830145835876465
train loss item: 0.17388230562210083
train loss item: 1.8055871725082397
train loss item: 0.27561211585998535
train loss item: 0.2561942934989929
train loss item: 1.6007624864578247
train loss item: 0.3905438482761383
train loss item: 0.5161809325218201
train loss item: 0.5474753975868225
train loss item: 0.36473026871681213
train loss item: 0.3366314768791199
train loss item: 0.3277329206466675
train loss item: 0.1944217085838318
train loss item: 1.2737903594970703
train loss item: 0.39583051204681396
train loss item: 0.27123531699180603
train loss item: 0.6088969707489014
train loss item: 0.5795220732688904
train loss item: 3.0486552715301514
train loss item: 0.3784008324146271
test loss item: 0.1844942420721054
test loss item: 0.4128219783306122
test loss item: 0.24026422202587128
test loss item: 1.1967934370040894
test loss item: 0.3261007070541382
test loss item: 0.6026497483253479
test loss item: 0.2619163990020752
test loss item: 0.1796243041753769
test loss item: 0.35363373160362244
test loss item: 0.4982045292854309
test loss item: 0.5070556402206421
test loss item: 0.3189913034439087
test loss item: 0.24735687673091888
test loss item: 0.3047749102115631
test loss item: 0.3753136992454529
test loss item: 0.7178504467010498
test loss item: 0.4652574062347412
test loss item: 0.45430421829223633
test loss item: 0.9248380064964294
test loss item: 0.4073701798915863
test loss item: 0.3169515132904053
test loss item: 0.2971665561199188
test loss item: 0.4936496913433075
test loss item: 0.37831950187683105
test loss item: 0.5440714955329895
test loss item: 0.3012947738170624
test loss item: 0.27315953373908997
test loss item: 0.6145839095115662
test loss item: 0.5141955614089966
test loss item: 0.24796162545681
test loss item: 0.3549409806728363
test loss item: 0.2525677978992462
test loss item: 0.6577371954917908
test loss item: 0.3196444511413574
test loss item: 0.4574073553085327
test loss item: 0.7410372495651245
test loss item: 0.39276254177093506
test loss item: 0.2423807680606842
test loss item: 0.9230947494506836
test loss item: 0.24159370362758636
test loss item: 0.6859398484230042
test loss item: 0.8447154760360718
test loss item: 0.26676276326179504
test loss item: 0.13432051241397858
test loss item: 0.2641008198261261
Epoch [1/100], Training Loss: 0.7196, Testing Loss: 0.4387
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/100
train loss item: 0.7582639455795288
train loss item: 0.5910776257514954
train loss item: 0.4969259798526764
train loss item: 0.5332295894622803
train loss item: 0.36325517296791077
train loss item: 0.3494485914707184
train loss item: 0.39720264077186584
train loss item: 0.5960111021995544
train loss item: 0.2659851610660553
train loss item: 0.3563295900821686
train loss item: 0.2327636033296585
train loss item: 0.9502861499786377
train loss item: 0.43850061297416687
train loss item: 0.32240673899650574
train loss item: 0.5752795338630676
train loss item: 1.332024335861206
train loss item: 0.43880146741867065
train loss item: 1.5925759077072144
train loss item: 0.7923399806022644
train loss item: 0.8012042045593262
train loss item: 0.5420367121696472
train loss item: 0.4565233588218689
train loss item: 0.4026448428630829
train loss item: 0.3233100175857544
train loss item: 0.2211102694272995
train loss item: 0.8527234792709351
train loss item: 0.20186269283294678
train loss item: 1.5608386993408203
train loss item: 0.3502146303653717
train loss item: 0.18707996606826782
train loss item: 1.5060603618621826
train loss item: 0.3520696759223938
train loss item: 0.4665796756744385
train loss item: 0.4176289737224579
train loss item: 0.4178161919116974
train loss item: 0.326056569814682
train loss item: 0.3468465507030487
train loss item: 0.10509197413921356
train loss item: 1.0316097736358643
train loss item: 0.23766133189201355
train loss item: 0.17554643750190735
train loss item: 0.4467804431915283
train loss item: 0.4113500714302063
train loss item: 2.473480701446533
train loss item: 0.40614479780197144
test loss item: 0.16071002185344696
test loss item: 0.39313262701034546
test loss item: 0.23595385253429413
test loss item: 0.7451122403144836
test loss item: 0.3502325117588043
test loss item: 0.525374710559845
test loss item: 0.260591059923172
test loss item: 0.15700353682041168
test loss item: 0.3289121985435486
test loss item: 0.40450260043144226
test loss item: 0.4155293107032776
test loss item: 0.2364223301410675
test loss item: 0.22345107793807983
test loss item: 0.2731945216655731
test loss item: 0.35201528668403625
test loss item: 0.489972859621048
test loss item: 0.46126291155815125
test loss item: 0.4114452302455902
test loss item: 0.7907271385192871
test loss item: 0.3574060797691345
test loss item: 0.21143122017383575
test loss item: 0.29464203119277954
test loss item: 0.4250290095806122
test loss item: 0.2713918387889862
test loss item: 0.4899404048919678
test loss item: 0.30553799867630005
test loss item: 0.22880898416042328
test loss item: 0.5591841340065002
test loss item: 0.4274536669254303
test loss item: 0.27993232011795044
test loss item: 0.3678373098373413
test loss item: 0.2401629537343979
test loss item: 0.5270328521728516
test loss item: 0.26906782388687134
test loss item: 0.4335390627384186
test loss item: 0.4729878604412079
test loss item: 0.30102577805519104
test loss item: 0.14824528992176056
test loss item: 0.8045731782913208
test loss item: 0.21533069014549255
test loss item: 0.5074570178985596
test loss item: 0.690883457660675
test loss item: 0.22556616365909576
test loss item: 0.06974131613969803
test loss item: 0.13377968966960907
Epoch [2/100], Training Loss: 0.5867, Testing Loss: 0.3661
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/100
train loss item: 0.6569054126739502
train loss item: 0.45908448100090027
train loss item: 0.30858343839645386
train loss item: 0.503585696220398
train loss item: 0.20400957763195038
train loss item: 0.3009120225906372
train loss item: 0.32600677013397217
train loss item: 0.4639342725276947
train loss item: 0.1995484083890915
train loss item: 0.324881911277771
train loss item: 0.21174149215221405
train loss item: 0.7569984793663025
train loss item: 0.3522612750530243
train loss item: 0.21977509558200836
train loss item: 0.4903251528739929
train loss item: 1.1341159343719482
train loss item: 0.30607089400291443
train loss item: 1.383758783340454
train loss item: 0.6250470280647278
train loss item: 0.49409615993499756
train loss item: 0.31296053528785706
train loss item: 0.3010641932487488
train loss item: 0.34526315331459045
train loss item: 0.29056188464164734
train loss item: 0.2011161893606186
train loss item: 0.7640334963798523
train loss item: 0.15611793100833893
train loss item: 1.2474092245101929
train loss item: 0.2351001501083374
train loss item: 0.1384143978357315
train loss item: 1.162762999534607
train loss item: 0.3086768686771393
train loss item: 0.39650899171829224
train loss item: 0.484634131193161
train loss item: 0.38629549741744995
train loss item: 0.2709228992462158
train loss item: 0.2698284685611725
train loss item: 0.10340185463428497
train loss item: 1.039395809173584
train loss item: 0.20091594755649567
train loss item: 0.15157297253608704
train loss item: 0.3982321321964264
train loss item: 0.440316766500473
train loss item: 2.230140447616577
train loss item: 0.3458942472934723
test loss item: 0.14856019616127014
test loss item: 0.33808428049087524
test loss item: 0.19586585462093353
test loss item: 0.7325286865234375
test loss item: 0.28273871541023254
test loss item: 0.4754360318183899
test loss item: 0.20606659352779388
test loss item: 0.14296184480190277
test loss item: 0.2876807153224945
test loss item: 0.37385696172714233
test loss item: 0.38901475071907043
test loss item: 0.23583008348941803
test loss item: 0.18410858511924744
test loss item: 0.23453758656978607
test loss item: 0.30328238010406494
test loss item: 0.44746652245521545
test loss item: 0.39157232642173767
test loss item: 0.3656146824359894
test loss item: 0.7203139066696167
test loss item: 0.30995309352874756
test loss item: 0.20970779657363892
test loss item: 0.23775742948055267
test loss item: 0.39871272444725037
test loss item: 0.2737673223018646
test loss item: 0.4194757342338562
test loss item: 0.2655319273471832
test loss item: 0.1883847862482071
test loss item: 0.5032730102539062
test loss item: 0.4010279178619385
test loss item: 0.21972212195396423
test loss item: 0.29511523246765137
test loss item: 0.19503556191921234
test loss item: 0.4985000491142273
test loss item: 0.2284877449274063
test loss item: 0.363256573677063
test loss item: 0.4474424123764038
test loss item: 0.2693040668964386
test loss item: 0.16023977100849152
test loss item: 0.6786589026451111
test loss item: 0.18742311000823975
test loss item: 0.4664582312107086
test loss item: 0.6287912130355835
test loss item: 0.1968974620103836
test loss item: 0.07915804535150528
test loss item: 0.09978855401277542
Epoch [3/100], Training Loss: 0.4867, Testing Loss: 0.3262
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/100
train loss item: 0.5846463441848755
train loss item: 0.46709364652633667
train loss item: 0.28866732120513916
train loss item: 0.38409408926963806
train loss item: 0.2060285359621048
train loss item: 0.22247622907161713
train loss item: 0.2832382023334503
train loss item: 0.4702717065811157
train loss item: 0.18137365579605103
train loss item: 0.28913965821266174
train loss item: 0.2043216973543167
train loss item: 0.6464518308639526
train loss item: 0.2878282070159912
train loss item: 0.24124747514724731
train loss item: 0.36096057295799255
train loss item: 0.8703286051750183
train loss item: 0.2203783541917801
train loss item: 1.1851563453674316
train loss item: 0.5838367938995361
train loss item: 0.44526389241218567
train loss item: 0.25277382135391235
train loss item: 0.24237991869449615
train loss item: 0.3101827800273895
train loss item: 0.2497691512107849
train loss item: 0.17877978086471558
train loss item: 0.6733039021492004
train loss item: 0.1273578703403473
train loss item: 1.049696445465088
train loss item: 0.23817545175552368
train loss item: 0.1300685703754425
train loss item: 0.9740211367607117
train loss item: 0.31113722920417786
train loss item: 0.3159659206867218
train loss item: 0.46787795424461365
train loss item: 0.2775630056858063
train loss item: 0.19834938645362854
train loss item: 0.21410180628299713
train loss item: 0.10573571175336838
train loss item: 1.0175604820251465
train loss item: 0.2257736474275589
train loss item: 0.17291687428951263
train loss item: 0.3634456694126129
train loss item: 0.441344290971756
train loss item: 2.121882438659668
train loss item: 0.32812121510505676
test loss item: 0.12478938698768616
test loss item: 0.3011118471622467
test loss item: 0.14192920923233032
test loss item: 0.630023717880249
test loss item: 0.23513418436050415
test loss item: 0.4910232722759247
test loss item: 0.15377771854400635
test loss item: 0.10398860275745392
test loss item: 0.22903139889240265
test loss item: 0.3499266505241394
test loss item: 0.3094177842140198
test loss item: 0.16115058958530426
test loss item: 0.15386931598186493
test loss item: 0.18828681111335754
test loss item: 0.23641295731067657
test loss item: 0.41571044921875
test loss item: 0.309392511844635
test loss item: 0.3198678493499756
test loss item: 0.7020140290260315
test loss item: 0.24777376651763916
test loss item: 0.16521765291690826
test loss item: 0.1826513558626175
test loss item: 0.30408164858818054
test loss item: 0.18195202946662903
test loss item: 0.3825698494911194
test loss item: 0.17259466648101807
test loss item: 0.15670301020145416
test loss item: 0.4717332422733307
test loss item: 0.40463998913764954
test loss item: 0.1730196177959442
test loss item: 0.23353876173496246
test loss item: 0.16331298649311066
test loss item: 0.4717002809047699
test loss item: 0.1917625218629837
test loss item: 0.33267685770988464
test loss item: 0.38712865114212036
test loss item: 0.23611922562122345
test loss item: 0.11025822907686234
test loss item: 0.6963543891906738
test loss item: 0.14861270785331726
test loss item: 0.47640663385391235
test loss item: 0.6013250946998596
test loss item: 0.16767430305480957
test loss item: 0.06437309086322784
test loss item: 0.10673460364341736
Epoch [4/100], Training Loss: 0.4314, Testing Loss: 0.2842
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/100
train loss item: 0.5118881464004517
train loss item: 0.3984571397304535
train loss item: 0.25530698895454407
train loss item: 0.33681821823120117
train loss item: 0.22769978642463684
train loss item: 0.22091111540794373
train loss item: 0.2868576645851135
train loss item: 0.46445000171661377
train loss item: 0.1531766951084137
train loss item: 0.2311016321182251
train loss item: 0.18453653156757355
train loss item: 0.5342930555343628
train loss item: 0.24380940198898315
train loss item: 0.1606401652097702
train loss item: 0.365777850151062
train loss item: 0.6723116040229797
train loss item: 0.19890637695789337
train loss item: 0.9866223931312561
train loss item: 0.5037716627120972
train loss item: 0.2820667028427124
train loss item: 0.16388794779777527
train loss item: 0.1771187037229538
train loss item: 0.26311975717544556
train loss item: 0.20108281075954437
train loss item: 0.15467777848243713
train loss item: 0.6240071654319763
train loss item: 0.11860055476427078
train loss item: 0.8337778449058533
train loss item: 0.19584006071090698
train loss item: 0.15960951149463654
train loss item: 0.9115292429924011
train loss item: 0.24686142802238464
train loss item: 0.24098895490169525
train loss item: 0.4093363881111145
train loss item: 0.26009929180145264
train loss item: 0.20790132880210876
train loss item: 0.18673284351825714
train loss item: 0.09641703963279724
train loss item: 0.9139260649681091
train loss item: 0.1645147055387497
train loss item: 0.13643929362297058
train loss item: 0.31835994124412537
train loss item: 0.3392528295516968
train loss item: 1.6414583921432495
train loss item: 0.2887672483921051
test loss item: 0.19550161063671112
test loss item: 0.2994236946105957
test loss item: 0.22994257509708405
test loss item: 0.48043790459632874
test loss item: 0.24603867530822754
test loss item: 0.4786829948425293
test loss item: 0.14122365415096283
test loss item: 0.20259366929531097
test loss item: 0.21829749643802643
test loss item: 0.2829376757144928
test loss item: 0.27735963463783264
test loss item: 0.20171071588993073
test loss item: 0.17650413513183594
test loss item: 0.24259249866008759
test loss item: 0.26757004857063293
test loss item: 0.40002796053886414
test loss item: 0.29948973655700684
test loss item: 0.30129939317703247
test loss item: 0.621826171875
test loss item: 0.2662537097930908
test loss item: 0.16527876257896423
test loss item: 0.1690477579832077
test loss item: 0.2929086685180664
test loss item: 0.18293209373950958
test loss item: 0.3507876992225647
test loss item: 0.2001214176416397
test loss item: 0.18503925204277039
test loss item: 0.45668745040893555
test loss item: 0.3384855389595032
test loss item: 0.20276853442192078
test loss item: 0.23671270906925201
test loss item: 0.1778458207845688
test loss item: 0.4239494502544403
test loss item: 0.2108328491449356
test loss item: 0.28574711084365845
test loss item: 0.30879294872283936
test loss item: 0.23775243759155273
test loss item: 0.14558373391628265
test loss item: 0.6663407683372498
test loss item: 0.19756272435188293
test loss item: 0.4354705214500427
test loss item: 0.5613390803337097
test loss item: 0.19301073253154755
test loss item: 0.14697960019111633
test loss item: 0.14542344212532043
Epoch [5/100], Training Loss: 0.3661, Testing Loss: 0.2833
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/100
train loss item: 0.46084246039390564
train loss item: 0.29124993085861206
train loss item: 0.17856591939926147
train loss item: 0.3340012729167938
train loss item: 0.22900518774986267
train loss item: 0.19307877123355865
train loss item: 0.24505753815174103
train loss item: 0.42446383833885193
train loss item: 0.1825067698955536
train loss item: 0.2907450199127197
train loss item: 0.1385476440191269
train loss item: 0.45174428820610046
train loss item: 0.2000202089548111
train loss item: 0.15788567066192627
train loss item: 0.3391754627227783
train loss item: 0.6018105149269104
train loss item: 0.18050283193588257
train loss item: 0.7680143117904663
train loss item: 0.3596782982349396
train loss item: 0.229379802942276
train loss item: 0.1296491175889969
train loss item: 0.2428605854511261
train loss item: 0.3597387969493866
train loss item: 0.23036834597587585
train loss item: 0.1584877073764801
train loss item: 0.5805739164352417
train loss item: 0.13082480430603027
train loss item: 0.7857862114906311
train loss item: 0.20420008897781372
train loss item: 0.13103193044662476
train loss item: 0.7884742021560669
train loss item: 0.2919475734233856
train loss item: 0.22753193974494934
train loss item: 0.30056917667388916
train loss item: 0.2467338889837265
train loss item: 0.16434571146965027
train loss item: 0.17150531709194183
train loss item: 0.11826249212026596
train loss item: 0.8173943161964417
train loss item: 0.12529797852039337
train loss item: 0.10768253356218338
train loss item: 0.24191530048847198
train loss item: 0.3802388310432434
train loss item: 1.415191650390625
train loss item: 0.32344722747802734
test loss item: 0.12564949691295624
test loss item: 0.33286014199256897
test loss item: 0.1822153627872467
test loss item: 0.46736693382263184
test loss item: 0.25457534193992615
test loss item: 0.5187902450561523
test loss item: 0.11510709673166275
test loss item: 0.11669038981199265
test loss item: 0.2097650170326233
test loss item: 0.2631450295448303
test loss item: 0.2606631815433502
test loss item: 0.1569305807352066
test loss item: 0.13217826187610626
test loss item: 0.1985919326543808
test loss item: 0.22844645380973816
test loss item: 0.43893304467201233
test loss item: 0.29101502895355225
test loss item: 0.3037087917327881
test loss item: 0.68746417760849
test loss item: 0.24219143390655518
test loss item: 0.14910094439983368
test loss item: 0.17314724624156952
test loss item: 0.24455060064792633
test loss item: 0.15600252151489258
test loss item: 0.38665303587913513
test loss item: 0.16750457882881165
test loss item: 0.15908794105052948
test loss item: 0.5058937072753906
test loss item: 0.33754149079322815
test loss item: 0.15233653783798218
test loss item: 0.23772276937961578
test loss item: 0.13408736884593964
test loss item: 0.4802306592464447
test loss item: 0.17284780740737915
test loss item: 0.2769239544868469
test loss item: 0.2602335214614868
test loss item: 0.19464950263500214
test loss item: 0.10740289092063904
test loss item: 0.79021155834198
test loss item: 0.17324848473072052
test loss item: 0.46452808380126953
test loss item: 0.6338961720466614
test loss item: 0.1439511477947235
test loss item: 0.0722859650850296
test loss item: 0.11821331083774567
Epoch [6/100], Training Loss: 0.3318, Testing Loss: 0.2715
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/100
train loss item: 0.376660019159317
train loss item: 0.24376419186592102
train loss item: 0.13689376413822174
train loss item: 0.20972086489200592
train loss item: 0.17026224732398987
train loss item: 0.18103577196598053
train loss item: 0.2528071701526642
train loss item: 0.5167192220687866
train loss item: 0.1290530413389206
train loss item: 0.1838465929031372
train loss item: 0.14821279048919678
train loss item: 0.45167532563209534
train loss item: 0.18343250453472137
train loss item: 0.20404094457626343
train loss item: 0.24509121477603912
train loss item: 0.39217740297317505
train loss item: 0.2073289304971695
train loss item: 0.6280363202095032
train loss item: 0.3093501627445221
train loss item: 0.23424379527568817
train loss item: 0.15071195363998413
train loss item: 0.17596974968910217
train loss item: 0.22452561557292938
train loss item: 0.18186475336551666
train loss item: 0.12111040204763412
train loss item: 0.5241692662239075
train loss item: 0.08185189217329025
train loss item: 0.5103247761726379
train loss item: 0.1247827336192131
train loss item: 0.09612944722175598
train loss item: 0.4892878830432892
train loss item: 0.2991751432418823
train loss item: 0.17058515548706055
train loss item: 0.2798886001110077
train loss item: 0.2042241096496582
train loss item: 0.11829137057065964
train loss item: 0.12844321131706238
train loss item: 0.07338695973157883
train loss item: 0.8722028732299805
train loss item: 0.1286972314119339
train loss item: 0.09892301261425018
train loss item: 0.26654741168022156
train loss item: 0.2561940550804138
train loss item: 1.0929689407348633
train loss item: 0.2655448019504547
test loss item: 0.10664857923984528
test loss item: 0.21219684183597565
test loss item: 0.12509772181510925
test loss item: 0.40784454345703125
test loss item: 0.14164793491363525
test loss item: 0.3534127175807953
test loss item: 0.09452932327985764
test loss item: 0.10085093230009079
test loss item: 0.1323399543762207
test loss item: 0.20507846772670746
test loss item: 0.183808833360672
test loss item: 0.1027052029967308
test loss item: 0.09573038667440414
test loss item: 0.12664085626602173
test loss item: 0.1471935212612152
test loss item: 0.30260518193244934
test loss item: 0.17380067706108093
test loss item: 0.18729478120803833
test loss item: 0.4774356782436371
test loss item: 0.1500357985496521
test loss item: 0.11258912086486816
test loss item: 0.10533970594406128
test loss item: 0.17010442912578583
test loss item: 0.10794766992330551
test loss item: 0.22841128706932068
test loss item: 0.09933117032051086
test loss item: 0.10489995777606964
test loss item: 0.30186277627944946
test loss item: 0.2494138479232788
test loss item: 0.10640663653612137
test loss item: 0.12618505954742432
test loss item: 0.105065256357193
test loss item: 0.3580602705478668
test loss item: 0.12384460866451263
test loss item: 0.1998225301504135
test loss item: 0.22850409150123596
test loss item: 0.13898079097270966
test loss item: 0.08182110637426376
test loss item: 0.5862157940864563
test loss item: 0.11730889230966568
test loss item: 0.331183522939682
test loss item: 0.4312663674354553
test loss item: 0.10398340225219727
test loss item: 0.06809762865304947
test loss item: 0.08894895762205124
Epoch [7/100], Training Loss: 0.2742, Testing Loss: 0.1889
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/100
train loss item: 0.47564172744750977
train loss item: 0.3108649253845215
train loss item: 0.15812623500823975
train loss item: 0.49305179715156555
train loss item: 0.22650647163391113
train loss item: 0.26103413105010986
train loss item: 0.33352386951446533
train loss item: 0.5514872670173645
train loss item: 0.14265896379947662
train loss item: 0.22635720670223236
train loss item: 0.1573348343372345
train loss item: 0.6616557240486145
train loss item: 0.25196799635887146
train loss item: 0.23330503702163696
train loss item: 0.2504222095012665
train loss item: 0.4495373070240021
train loss item: 0.24330569803714752
train loss item: 0.44384336471557617
train loss item: 0.36229053139686584
train loss item: 0.25172895193099976
train loss item: 0.2108772248029709
train loss item: 0.26541027426719666
train loss item: 0.19484172761440277
train loss item: 0.23356854915618896
train loss item: 0.15433581173419952
train loss item: 0.5755647420883179
train loss item: 0.10028862953186035
train loss item: 0.5470557808876038
train loss item: 0.15949547290802002
train loss item: 0.1263604760169983
train loss item: 0.5686193704605103
train loss item: 0.22944849729537964
train loss item: 0.15575672686100006
train loss item: 0.26284706592559814
train loss item: 0.1974862515926361
train loss item: 0.14595502614974976
train loss item: 0.15681175887584686
train loss item: 0.10057811439037323
train loss item: 0.7494060397148132
train loss item: 0.13394752144813538
train loss item: 0.10798189043998718
train loss item: 0.3014478087425232
train loss item: 0.2115813046693802
train loss item: 0.9815070033073425
train loss item: 0.28765273094177246
test loss item: 0.12319251894950867
test loss item: 0.2054954171180725
test loss item: 0.1338830292224884
test loss item: 0.4217035472393036
test loss item: 0.15540358424186707
test loss item: 0.3416826128959656
test loss item: 0.12794877588748932
test loss item: 0.1065998449921608
test loss item: 0.15956725180149078
test loss item: 0.23369377851486206
test loss item: 0.2132510095834732
test loss item: 0.1726071983575821
test loss item: 0.13850463926792145
test loss item: 0.15051297843456268
test loss item: 0.1636924296617508
test loss item: 0.29668885469436646
test loss item: 0.1870776265859604
test loss item: 0.20285998284816742
test loss item: 0.4579201340675354
test loss item: 0.16932110488414764
test loss item: 0.15794633328914642
test loss item: 0.13530731201171875
test loss item: 0.21804949641227722
test loss item: 0.19199229776859283
test loss item: 0.2405354380607605
test loss item: 0.1355658620595932
test loss item: 0.13040190935134888
test loss item: 0.28449246287345886
test loss item: 0.25010085105895996
test loss item: 0.1327090859413147
test loss item: 0.1429571956396103
test loss item: 0.14515537023544312
test loss item: 0.3163157105445862
test loss item: 0.15747064352035522
test loss item: 0.20128174126148224
test loss item: 0.24429981410503387
test loss item: 0.20202577114105225
test loss item: 0.12836556136608124
test loss item: 0.5160160660743713
test loss item: 0.14934924244880676
test loss item: 0.3076390027999878
test loss item: 0.3983064889907837
test loss item: 0.13633328676223755
test loss item: 0.0751756802201271
test loss item: 0.12885721027851105
Epoch [8/100], Training Loss: 0.3032, Testing Loss: 0.2064
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/100
train loss item: 0.46993744373321533
train loss item: 0.34759071469306946
train loss item: 0.1880125254392624
train loss item: 0.2218480408191681
train loss item: 0.17517074942588806
train loss item: 0.1848209798336029
train loss item: 0.2653789818286896
train loss item: 0.4205528497695923
train loss item: 0.10969223082065582
train loss item: 0.19098621606826782
train loss item: 0.1755891740322113
train loss item: 0.599787175655365
train loss item: 0.19126486778259277
train loss item: 0.12355265021324158
train loss item: 0.2056228369474411
train loss item: 0.463957816362381
train loss item: 0.2596435844898224
train loss item: 0.4401898682117462
train loss item: 0.47354793548583984
train loss item: 0.31300485134124756
train loss item: 0.21919400990009308
train loss item: 0.14787206053733826
train loss item: 0.2116064876317978
train loss item: 0.17094433307647705
train loss item: 0.13635827600955963
train loss item: 0.6081914305686951
train loss item: 0.11429645866155624
train loss item: 0.722362756729126
train loss item: 0.17983026802539825
train loss item: 0.11891281604766846
train loss item: 0.637667715549469
train loss item: 0.1952071189880371
train loss item: 0.21268296241760254
train loss item: 0.33164355158805847
train loss item: 0.19408273696899414
train loss item: 0.17708390951156616
train loss item: 0.24461431801319122
train loss item: 0.09954483807086945
train loss item: 0.5654346346855164
train loss item: 0.16124317049980164
train loss item: 0.11305233091115952
train loss item: 0.297902375459671
train loss item: 0.23655971884727478
train loss item: 0.863521158695221
train loss item: 0.2339879870414734
test loss item: 0.1076713353395462
test loss item: 0.2058778703212738
test loss item: 0.14750944077968597
test loss item: 0.4583144783973694
test loss item: 0.1727057695388794
test loss item: 0.34688451886177063
test loss item: 0.14901164174079895
test loss item: 0.0935012698173523
test loss item: 0.15795588493347168
test loss item: 0.26541420817375183
test loss item: 0.18743383884429932
test loss item: 0.13666610419750214
test loss item: 0.11802523583173752
test loss item: 0.16714759171009064
test loss item: 0.1778729110956192
test loss item: 0.3028632402420044
test loss item: 0.18828357756137848
test loss item: 0.20542630553245544
test loss item: 0.46201232075691223
test loss item: 0.16893543303012848
test loss item: 0.12987928092479706
test loss item: 0.1328919380903244
test loss item: 0.21145497262477875
test loss item: 0.14892934262752533
test loss item: 0.2626493275165558
test loss item: 0.1354244202375412
test loss item: 0.11998416483402252
test loss item: 0.3011123538017273
test loss item: 0.2451857030391693
test loss item: 0.14186401665210724
test loss item: 0.16784261167049408
test loss item: 0.1329984813928604
test loss item: 0.3328916132450104
test loss item: 0.17122752964496613
test loss item: 0.2264377474784851
test loss item: 0.29886162281036377
test loss item: 0.20291775465011597
test loss item: 0.11088887602090836
test loss item: 0.4576551914215088
test loss item: 0.14581988751888275
test loss item: 0.3400142788887024
test loss item: 0.41176795959472656
test loss item: 0.13997285068035126
test loss item: 0.059987735003232956
test loss item: 0.12953203916549683
Epoch [9/100], Training Loss: 0.2892, Testing Loss: 0.2084
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/100
train loss item: 0.3850264847278595
train loss item: 0.199227973818779
train loss item: 0.1443118155002594
train loss item: 0.18646594882011414
train loss item: 0.18763965368270874
train loss item: 0.20796555280685425
train loss item: 0.3070656359195709
train loss item: 0.26665884256362915
train loss item: 0.08799506723880768
train loss item: 0.17614473402500153
train loss item: 0.09917756170034409
train loss item: 0.5777916312217712
train loss item: 0.1801963597536087
train loss item: 0.15518011152744293
train loss item: 0.208848237991333
train loss item: 0.39145633578300476
train loss item: 0.2122974842786789
train loss item: 0.3576621115207672
train loss item: 0.5816726684570312
train loss item: 0.2663452923297882
train loss item: 0.17600277066230774
train loss item: 0.18779335916042328
train loss item: 0.2593153417110443
train loss item: 0.164068341255188
train loss item: 0.12364210933446884
train loss item: 0.4199938178062439
train loss item: 0.09292686730623245
train loss item: 0.4777231216430664
train loss item: 0.13718217611312866
train loss item: 0.09670646488666534
train loss item: 0.4257116913795471
train loss item: 0.2437710464000702
train loss item: 0.1690315157175064
train loss item: 0.22117428481578827
train loss item: 0.19159837067127228
train loss item: 0.14777591824531555
train loss item: 0.14770475029945374
train loss item: 0.09477974474430084
train loss item: 0.6215625405311584
train loss item: 0.11394143849611282
train loss item: 0.08499576151371002
train loss item: 0.2474530041217804
train loss item: 0.30662864446640015
train loss item: 0.7631977796554565
train loss item: 0.20806412398815155
test loss item: 0.11708606034517288
test loss item: 0.20358900725841522
test loss item: 0.12651784718036652
test loss item: 0.46778860688209534
test loss item: 0.1557428538799286
test loss item: 0.338223934173584
test loss item: 0.11767251789569855
test loss item: 0.09538006782531738
test loss item: 0.16636522114276886
test loss item: 0.2599972188472748
test loss item: 0.20828668773174286
test loss item: 0.16071942448616028
test loss item: 0.11259719729423523
test loss item: 0.15256398916244507
test loss item: 0.16976581513881683
test loss item: 0.2763344943523407
test loss item: 0.1669529378414154
test loss item: 0.21661362051963806
test loss item: 0.4452143907546997
test loss item: 0.1675305813550949
test loss item: 0.15962748229503632
test loss item: 0.12482929229736328
test loss item: 0.22735907137393951
test loss item: 0.17029966413974762
test loss item: 0.2536432445049286
test loss item: 0.12221615761518478
test loss item: 0.12535659968852997
test loss item: 0.27721935510635376
test loss item: 0.2874854505062103
test loss item: 0.11662551760673523
test loss item: 0.16043849289417267
test loss item: 0.13525624573230743
test loss item: 0.3483205735683441
test loss item: 0.16813763976097107
test loss item: 0.20879904925823212
test loss item: 0.31848591566085815
test loss item: 0.2301386296749115
test loss item: 0.1297474503517151
test loss item: 0.4714335501194
test loss item: 0.15074913203716278
test loss item: 0.3424518406391144
test loss item: 0.40516069531440735
test loss item: 0.13574092090129852
test loss item: 0.06283742189407349
test loss item: 0.10882475972175598
Epoch [10/100], Training Loss: 0.2512, Testing Loss: 0.2081
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 11/100
train loss item: 0.3187674283981323
train loss item: 0.24789753556251526
train loss item: 0.11799618601799011
train loss item: 0.16260473430156708
train loss item: 0.18000419437885284
train loss item: 0.19243364036083221
train loss item: 0.27350249886512756
train loss item: 0.360370934009552
train loss item: 0.08167068660259247
train loss item: 0.16906042397022247
train loss item: 0.10821914672851562
train loss item: 0.5430183410644531
train loss item: 0.161813884973526
train loss item: 0.14912286400794983
train loss item: 0.2111516147851944
train loss item: 0.36463263630867004
train loss item: 0.22351938486099243
train loss item: 0.3458004891872406
train loss item: 0.296021968126297
train loss item: 0.1704384833574295
train loss item: 0.15744565427303314
train loss item: 0.1700863242149353
train loss item: 0.26476895809173584
train loss item: 0.1523606777191162
train loss item: 0.1045478880405426
train loss item: 0.4261555075645447
train loss item: 0.09963638335466385
train loss item: 0.6344622373580933
train loss item: 0.14861100912094116
train loss item: 0.09551558643579483
train loss item: 0.37230736017227173
train loss item: 0.2578829526901245
train loss item: 0.13586553931236267
train loss item: 0.2034045159816742
train loss item: 0.161470428109169
train loss item: 0.11030667275190353
train loss item: 0.12717071175575256
train loss item: 0.0693264976143837
train loss item: 0.5925683975219727
train loss item: 0.09969516098499298
train loss item: 0.09893128275871277
train loss item: 0.23015819489955902
train loss item: 0.2707865834236145
train loss item: 0.734314501285553
train loss item: 0.1897318959236145
test loss item: 0.11510531604290009
test loss item: 0.23293931782245636
test loss item: 0.15743406116962433
test loss item: 0.3416038155555725
test loss item: 0.19268275797367096
test loss item: 0.3518213629722595
test loss item: 0.125545933842659
test loss item: 0.10928641259670258
test loss item: 0.16751529276371002
test loss item: 0.1993951052427292
test loss item: 0.1988527923822403
test loss item: 0.1536240577697754
test loss item: 0.11315001547336578
test loss item: 0.17155912518501282
test loss item: 0.19069324433803558
test loss item: 0.31150782108306885
test loss item: 0.21276645362377167
test loss item: 0.23703913390636444
test loss item: 0.44780901074409485
test loss item: 0.1915646195411682
test loss item: 0.13208319246768951
test loss item: 0.14059269428253174
test loss item: 0.2173137217760086
test loss item: 0.1615837961435318
test loss item: 0.2760388255119324
test loss item: 0.15286479890346527
test loss item: 0.12781310081481934
test loss item: 0.3493131697177887
test loss item: 0.23535266518592834
test loss item: 0.13923858106136322
test loss item: 0.18339142203330994
test loss item: 0.12341389060020447
test loss item: 0.31059083342552185
test loss item: 0.14865362644195557
test loss item: 0.21150638163089752
test loss item: 0.22224090993404388
test loss item: 0.20362217724323273
test loss item: 0.11539523303508759
test loss item: 0.4973025321960449
test loss item: 0.15587414801120758
test loss item: 0.3103637993335724
test loss item: 0.4171012043952942
test loss item: 0.13542862236499786
test loss item: 0.06429854780435562
test loss item: 0.11864570528268814
Epoch [11/100], Training Loss: 0.2352, Testing Loss: 0.2083
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 12/100
train loss item: 0.3408130705356598
train loss item: 0.19054609537124634
train loss item: 0.15801383554935455
train loss item: 0.19336465001106262
train loss item: 0.17987653613090515
train loss item: 0.23873597383499146
train loss item: 0.3612203001976013
train loss item: 0.4346420168876648
train loss item: 0.12617327272891998
train loss item: 0.2570798099040985
train loss item: 0.12575070559978485
train loss item: 0.8218103647232056
train loss item: 0.24676015973091125
train loss item: 0.23279023170471191
train loss item: 0.26456308364868164
train loss item: 1.0264700651168823
train loss item: 0.28290703892707825
train loss item: 0.46400848031044006
train loss item: 0.5242371559143066
train loss item: 0.4026128053665161
train loss item: 0.4445011019706726
train loss item: 0.3259534239768982
train loss item: 0.6855682730674744
train loss item: 0.2046712338924408
train loss item: 0.14351361989974976
train loss item: 0.4880509376525879
train loss item: 0.11305618286132812
train loss item: 0.4955371618270874
train loss item: 0.2768207788467407
train loss item: 0.17209869623184204
train loss item: 0.8043680787086487
train loss item: 0.3084886074066162
train loss item: 0.4026137590408325
train loss item: 0.256740003824234
train loss item: 0.21484901010990143
train loss item: 0.1811109185218811
train loss item: 0.17091646790504456
train loss item: 0.10670565068721771
train loss item: 0.42322811484336853
train loss item: 0.27863773703575134
train loss item: 0.15234698355197906
train loss item: 0.24213947355747223
train loss item: 0.29245513677597046
train loss item: 0.6947261095046997
train loss item: 0.22211456298828125
test loss item: 0.1362658441066742
test loss item: 0.2265436202287674
test loss item: 0.17224232852458954
test loss item: 0.6642335057258606
test loss item: 0.2107325941324234
test loss item: 0.3088584542274475
test loss item: 0.2067728042602539
test loss item: 0.12988542020320892
test loss item: 0.17658178508281708
test loss item: 0.27475929260253906
test loss item: 0.23715943098068237
test loss item: 0.1605396568775177
test loss item: 0.14698977768421173
test loss item: 0.1678016036748886
test loss item: 0.1946249157190323
test loss item: 0.3535423278808594
test loss item: 0.2195609211921692
test loss item: 0.21318091452121735
test loss item: 0.46955934166908264
test loss item: 0.20895831286907196
test loss item: 0.15736785531044006
test loss item: 0.1740187108516693
test loss item: 0.20240773260593414
test loss item: 0.15552033483982086
test loss item: 0.27019429206848145
test loss item: 0.18616963922977448
test loss item: 0.1532709151506424
test loss item: 0.27798765897750854
test loss item: 0.28260883688926697
test loss item: 0.19281314313411713
test loss item: 0.19959987699985504
test loss item: 0.17591066658496857
test loss item: 0.33421942591667175
test loss item: 0.18665091693401337
test loss item: 0.2545296549797058
test loss item: 0.4234966039657593
test loss item: 0.2289845496416092
test loss item: 0.14118576049804688
test loss item: 0.4295254945755005
test loss item: 0.1603914201259613
test loss item: 0.3812398910522461
test loss item: 0.4172748923301697
test loss item: 0.1427888721227646
test loss item: 0.11037755757570267
test loss item: 0.11735653132200241
Epoch [12/100], Training Loss: 0.3327, Testing Loss: 0.2363
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 13/100
train loss item: 0.30391067266464233
train loss item: 0.20259149372577667
train loss item: 0.18175528943538666
train loss item: 0.1806827187538147
train loss item: 0.17368453741073608
train loss item: 0.1449490785598755
train loss item: 0.1739722341299057
train loss item: 0.23466011881828308
train loss item: 0.14657588303089142
train loss item: 0.18554848432540894
train loss item: 0.17593137919902802
train loss item: 0.2979802191257477
train loss item: 0.15831278264522552
train loss item: 0.1431134045124054
train loss item: 0.19930298626422882
train loss item: 0.5865839123725891
train loss item: 0.14012469351291656
train loss item: 0.31785812973976135
train loss item: 0.18584944307804108
train loss item: 0.2038852423429489
train loss item: 0.14552684128284454
train loss item: 0.17794957756996155
train loss item: 0.19885870814323425
train loss item: 0.20054970681667328
train loss item: 0.13704133033752441
train loss item: 0.4356629550457001
train loss item: 0.10654641687870026
train loss item: 0.5117703676223755
train loss item: 0.13464242219924927
train loss item: 0.10471139848232269
train loss item: 0.34429121017456055
train loss item: 0.22299207746982574
train loss item: 0.14014297723770142
train loss item: 0.195675790309906
train loss item: 0.14228281378746033
train loss item: 0.09507281333208084
train loss item: 0.11017058789730072
train loss item: 0.07747602462768555
train loss item: 0.5696062445640564
train loss item: 0.10642102360725403
train loss item: 0.07978405058383942
train loss item: 0.19050952792167664
train loss item: 0.1977199912071228
train loss item: 0.633901059627533
train loss item: 0.19742034375667572
test loss item: 0.08543705195188522
test loss item: 0.14179939031600952
test loss item: 0.09064678847789764
test loss item: 0.32733914256095886
test loss item: 0.10954916477203369
test loss item: 0.21047966182231903
test loss item: 0.09198015183210373
test loss item: 0.06518144905567169
test loss item: 0.12030515819787979
test loss item: 0.17142842710018158
test loss item: 0.15039218962192535
test loss item: 0.11462108790874481
test loss item: 0.08782589435577393
test loss item: 0.11066702753305435
test loss item: 0.12474103271961212
test loss item: 0.17789927124977112
test loss item: 0.1302643120288849
test loss item: 0.1393498182296753
test loss item: 0.28001946210861206
test loss item: 0.12756019830703735
test loss item: 0.12237738817930222
test loss item: 0.09648671001195908
test loss item: 0.16865547001361847
test loss item: 0.14079855382442474
test loss item: 0.1601087599992752
test loss item: 0.1003330871462822
test loss item: 0.0962337777018547
test loss item: 0.17464061081409454
test loss item: 0.17116087675094604
test loss item: 0.09246401488780975
test loss item: 0.10837387293577194
test loss item: 0.09900785237550735
test loss item: 0.21696476638317108
test loss item: 0.11793367564678192
test loss item: 0.14160650968551636
test loss item: 0.21776804327964783
test loss item: 0.16752713918685913
test loss item: 0.09786662459373474
test loss item: 0.2841164171695709
test loss item: 0.1045575737953186
test loss item: 0.21196185052394867
test loss item: 0.2388412058353424
test loss item: 0.09615184366703033
test loss item: 0.0472048856317997
test loss item: 0.10218305885791779
Epoch [13/100], Training Loss: 0.2176, Testing Loss: 0.1430
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 14/100
train loss item: 0.440755695104599
train loss item: 0.37863054871559143
train loss item: 0.1363581269979477
train loss item: 0.15427307784557343
train loss item: 0.16499020159244537
train loss item: 0.17830534279346466
train loss item: 0.25969743728637695
train loss item: 0.34196195006370544
train loss item: 0.09377188235521317
train loss item: 0.1914684921503067
train loss item: 0.13095125555992126
train loss item: 0.5985245108604431
train loss item: 0.17966803908348083
train loss item: 0.16937324404716492
train loss item: 0.22137676179409027
train loss item: 0.39542582631111145
train loss item: 0.13462980091571808
train loss item: 0.30684295296669006
train loss item: 0.3960285484790802
train loss item: 0.3077033758163452
train loss item: 0.27671578526496887
train loss item: 0.1894606500864029
train loss item: 0.3521561920642853
train loss item: 0.10983474552631378
train loss item: 0.10546073317527771
train loss item: 0.38969558477401733
train loss item: 0.0866403803229332
train loss item: 0.5477548241615295
train loss item: 0.1748214215040207
train loss item: 0.10699868947267532
train loss item: 0.49319392442703247
train loss item: 0.16959148645401
train loss item: 0.21693743765354156
train loss item: 0.1468089073896408
train loss item: 0.19154095649719238
train loss item: 0.12351492047309875
train loss item: 0.15716183185577393
train loss item: 0.07064444571733475
train loss item: 0.3569848835468292
train loss item: 0.1412225365638733
train loss item: 0.07541055232286453
train loss item: 0.18642692267894745
train loss item: 0.1754651665687561
train loss item: 0.5725833177566528
train loss item: 0.15144996345043182
test loss item: 0.08867855370044708
test loss item: 0.1816161721944809
test loss item: 0.12308226525783539
test loss item: 0.34547853469848633
test loss item: 0.1575123816728592
test loss item: 0.28633585572242737
test loss item: 0.14097605645656586
test loss item: 0.08817089349031448
test loss item: 0.12643255293369293
test loss item: 0.18077756464481354
test loss item: 0.1714221090078354
test loss item: 0.11090803891420364
test loss item: 0.10393889993429184
test loss item: 0.1290760487318039
test loss item: 0.15767550468444824
test loss item: 0.2522192895412445
test loss item: 0.16619199514389038
test loss item: 0.1765580177307129
test loss item: 0.3729671239852905
test loss item: 0.1625305563211441
test loss item: 0.10135065019130707
test loss item: 0.10791703313589096
test loss item: 0.181330144405365
test loss item: 0.11696227639913559
test loss item: 0.22243943810462952
test loss item: 0.14346320927143097
test loss item: 0.10752087831497192
test loss item: 0.26316142082214355
test loss item: 0.19546549022197723
test loss item: 0.13908246159553528
test loss item: 0.14429962635040283
test loss item: 0.1242295354604721
test loss item: 0.26803165674209595
test loss item: 0.1337338089942932
test loss item: 0.1714395433664322
test loss item: 0.2353602945804596
test loss item: 0.17402033507823944
test loss item: 0.08411458134651184
test loss item: 0.41429170966148376
test loss item: 0.1168084591627121
test loss item: 0.25226375460624695
test loss item: 0.3309829533100128
test loss item: 0.10217805951833725
test loss item: 0.044727545231580734
test loss item: 0.09144090861082077
Epoch [14/100], Training Loss: 0.2389, Testing Loss: 0.1731
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 15/100
train loss item: 0.27528268098831177
train loss item: 0.14747756719589233
train loss item: 0.12658125162124634
train loss item: 0.23919044435024261
train loss item: 0.1417110115289688
train loss item: 0.14866243302822113
train loss item: 0.2337014526128769
train loss item: 0.22113698720932007
train loss item: 0.07769689708948135
train loss item: 0.18464791774749756
train loss item: 0.10275937616825104
train loss item: 0.5422465801239014
train loss item: 0.19324983656406403
train loss item: 0.18445539474487305
train loss item: 0.22201451659202576
train loss item: 0.5050479769706726
train loss item: 0.16846229135990143
train loss item: 0.3662184178829193
train loss item: 0.2756603956222534
train loss item: 0.1726040244102478
train loss item: 0.13142752647399902
train loss item: 0.15947936475276947
train loss item: 0.26608753204345703
train loss item: 0.14449584484100342
train loss item: 0.11248117685317993
train loss item: 0.32376641035079956
train loss item: 0.06456711143255234
train loss item: 0.3595747649669647
train loss item: 0.11636903882026672
train loss item: 0.06527525931596756
train loss item: 0.37865808606147766
train loss item: 0.19230252504348755
train loss item: 0.14100861549377441
train loss item: 0.1408614069223404
train loss item: 0.14863723516464233
train loss item: 0.10671048611402512
train loss item: 0.10144739598035812
train loss item: 0.06355228275060654
train loss item: 0.41848963499069214
train loss item: 0.0862383171916008
train loss item: 0.08536988496780396
train loss item: 0.1682438999414444
train loss item: 0.20399340987205505
train loss item: 0.5287050604820251
train loss item: 0.16163605451583862
test loss item: 0.08547355234622955
test loss item: 0.14863905310630798
test loss item: 0.08345550298690796
test loss item: 0.3222731053829193
test loss item: 0.10504020750522614
test loss item: 0.23390157520771027
test loss item: 0.09838249534368515
test loss item: 0.06513217091560364
test loss item: 0.12129361927509308
test loss item: 0.19715125858783722
test loss item: 0.14820905029773712
test loss item: 0.12633289396762848
test loss item: 0.09305968135595322
test loss item: 0.11441613733768463
test loss item: 0.119203582406044
test loss item: 0.19060172140598297
test loss item: 0.12091309577226639
test loss item: 0.16652439534664154
test loss item: 0.29584693908691406
test loss item: 0.1208004578948021
test loss item: 0.12015727907419205
test loss item: 0.0964215025305748
test loss item: 0.1677490621805191
test loss item: 0.13684208691120148
test loss item: 0.17760686576366425
test loss item: 0.09135905653238297
test loss item: 0.08915328979492188
test loss item: 0.17895187437534332
test loss item: 0.2049689143896103
test loss item: 0.09012849628925323
test loss item: 0.11352866142988205
test loss item: 0.10718902945518494
test loss item: 0.23589207231998444
test loss item: 0.1264602392911911
test loss item: 0.1660853773355484
test loss item: 0.2240203469991684
test loss item: 0.19084696471691132
test loss item: 0.09969841688871384
test loss item: 0.32838064432144165
test loss item: 0.10410723835229874
test loss item: 0.2402595728635788
test loss item: 0.26910173892974854
test loss item: 0.1082354411482811
test loss item: 0.05541985481977463
test loss item: 0.11405705660581589
Epoch [15/100], Training Loss: 0.2044, Testing Loss: 0.1510
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 16/100
train loss item: 0.31024953722953796
train loss item: 0.22222711145877838
train loss item: 0.10300267487764359
train loss item: 0.13692790269851685
train loss item: 0.12487365305423737
train loss item: 0.1272100955247879
train loss item: 0.2242477685213089
train loss item: 0.26455867290496826
train loss item: 0.0724160224199295
train loss item: 0.15241728723049164
train loss item: 0.10377388447523117
train loss item: 0.44585859775543213
train loss item: 0.1496644914150238
train loss item: 0.14128825068473816
train loss item: 0.21260780096054077
train loss item: 0.3021482229232788
train loss item: 0.17142385244369507
train loss item: 0.26390892267227173
train loss item: 0.17029264569282532
train loss item: 0.15638700127601624
train loss item: 0.1374528408050537
train loss item: 0.13292351365089417
train loss item: 0.22973813116550446
train loss item: 0.13857980072498322
train loss item: 0.09965037554502487
train loss item: 0.32049664855003357
train loss item: 0.06298083811998367
train loss item: 0.3397537171840668
train loss item: 0.09561189264059067
train loss item: 0.06406759470701218
train loss item: 0.29427865147590637
train loss item: 0.17060533165931702
train loss item: 0.13139329850673676
train loss item: 0.1108323410153389
train loss item: 0.11999287456274033
train loss item: 0.08109959214925766
train loss item: 0.08776404708623886
train loss item: 0.06488479673862457
train loss item: 0.3494475185871124
train loss item: 0.0836106389760971
train loss item: 0.07331126928329468
train loss item: 0.14331799745559692
train loss item: 0.15856564044952393
train loss item: 0.4236750900745392
train loss item: 0.13682720065116882
test loss item: 0.08461051434278488
test loss item: 0.13715609908103943
test loss item: 0.09211185574531555
test loss item: 0.3532012104988098
test loss item: 0.09578832238912582
test loss item: 0.21119213104248047
test loss item: 0.08819269388914108
test loss item: 0.061174873262643814
test loss item: 0.11186573654413223
test loss item: 0.1639883667230606
test loss item: 0.14523851871490479
test loss item: 0.1300525814294815
test loss item: 0.08880947530269623
test loss item: 0.10938406735658646
test loss item: 0.11588679254055023
test loss item: 0.2073814421892166
test loss item: 0.11654369533061981
test loss item: 0.12248200178146362
test loss item: 0.2772948443889618
test loss item: 0.12867522239685059
test loss item: 0.1190064325928688
test loss item: 0.08784416317939758
test loss item: 0.16469714045524597
test loss item: 0.1345362812280655
test loss item: 0.16404299437999725
test loss item: 0.0826994925737381
test loss item: 0.08857029676437378
test loss item: 0.17112571001052856
test loss item: 0.15818387269973755
test loss item: 0.0879976749420166
test loss item: 0.09886384010314941
test loss item: 0.10712038725614548
test loss item: 0.22006678581237793
test loss item: 0.12030628323554993
test loss item: 0.13512246310710907
test loss item: 0.2436678260564804
test loss item: 0.2008606642484665
test loss item: 0.09640959650278091
test loss item: 0.32871583104133606
test loss item: 0.11553356796503067
test loss item: 0.2252621054649353
test loss item: 0.24922357499599457
test loss item: 0.10189783573150635
test loss item: 0.04202219471335411
test loss item: 0.09942960739135742
Epoch [16/100], Training Loss: 0.1757, Testing Loss: 0.1441
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 17/100
train loss item: 0.2627917230129242
train loss item: 0.1811557412147522
train loss item: 0.1122988611459732
train loss item: 0.1802631914615631
train loss item: 0.12333745509386063
train loss item: 0.12975582480430603
train loss item: 0.23605775833129883
train loss item: 0.22495844960212708
train loss item: 0.08324582874774933
train loss item: 0.15921612083911896
train loss item: 0.09636057168245316
train loss item: 0.4361291825771332
train loss item: 0.15827961266040802
train loss item: 0.17685003578662872
train loss item: 0.21522878110408783
train loss item: 0.4461497664451599
train loss item: 0.19399411976337433
train loss item: 0.3398277759552002
train loss item: 0.300406813621521
train loss item: 0.20607808232307434
train loss item: 0.1474202424287796
train loss item: 0.12575045228004456
train loss item: 0.24354618787765503
train loss item: 0.12220687419176102
train loss item: 0.0940464437007904
train loss item: 0.26921790838241577
train loss item: 0.061957281082868576
train loss item: 0.30647554993629456
train loss item: 0.10210877656936646
train loss item: 0.0605478510260582
train loss item: 0.31871533393859863
train loss item: 0.17881815135478973
train loss item: 0.10740598291158676
train loss item: 0.11892881244421005
train loss item: 0.12599779665470123
train loss item: 0.08808556199073792
train loss item: 0.10727176070213318
train loss item: 0.0568433552980423
train loss item: 0.30192187428474426
train loss item: 0.07714086771011353
train loss item: 0.07020304352045059
train loss item: 0.15295596420764923
train loss item: 0.1827182024717331
train loss item: 0.4829477071762085
train loss item: 0.14947427809238434
test loss item: 0.0747246965765953
test loss item: 0.1402464061975479
test loss item: 0.08077999204397202
test loss item: 0.2398507446050644
test loss item: 0.09214857965707779
test loss item: 0.23544608056545258
test loss item: 0.07746659964323044
test loss item: 0.05987710505723953
test loss item: 0.103468157351017
test loss item: 0.14548376202583313
test loss item: 0.12973086535930634
test loss item: 0.10596615076065063
test loss item: 0.07884073257446289
test loss item: 0.09697101265192032
test loss item: 0.10252952575683594
test loss item: 0.19383609294891357
test loss item: 0.11549719423055649
test loss item: 0.1297665387392044
test loss item: 0.28992000222206116
test loss item: 0.1071021556854248
test loss item: 0.10014843940734863
test loss item: 0.07932454347610474
test loss item: 0.14580024778842926
test loss item: 0.11776717007160187
test loss item: 0.16325679421424866
test loss item: 0.07996946573257446
test loss item: 0.081243135035038
test loss item: 0.1815401166677475
test loss item: 0.16495323181152344
test loss item: 0.07827205955982208
test loss item: 0.10062067955732346
test loss item: 0.08839544653892517
test loss item: 0.20160990953445435
test loss item: 0.10214570164680481
test loss item: 0.14215077459812164
test loss item: 0.16263267397880554
test loss item: 0.15674681961536407
test loss item: 0.0888572558760643
test loss item: 0.38610032200813293
test loss item: 0.0960584506392479
test loss item: 0.20824114978313446
test loss item: 0.26162785291671753
test loss item: 0.08917481452226639
test loss item: 0.06219086796045303
test loss item: 0.08600012958049774
Epoch [17/100], Training Loss: 0.1848, Testing Loss: 0.1339
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 18/100
train loss item: 0.2722802460193634
train loss item: 0.1593465358018875
train loss item: 0.1102006658911705
train loss item: 0.18101535737514496
train loss item: 0.0987786054611206
train loss item: 0.10704664140939713
train loss item: 0.22940367460250854
train loss item: 0.242402583360672
train loss item: 0.07824769616127014
train loss item: 0.14265789091587067
train loss item: 0.09493424743413925
train loss item: 0.4132747948169708
train loss item: 0.1524653434753418
train loss item: 0.1572028398513794
train loss item: 0.2125777006149292
train loss item: 0.2826245427131653
train loss item: 0.17941701412200928
train loss item: 0.2628408372402191
train loss item: 0.21266674995422363
train loss item: 0.15051120519638062
train loss item: 0.1256767213344574
train loss item: 0.12721312046051025
train loss item: 0.21998722851276398
train loss item: 0.11972955614328384
train loss item: 0.09108229726552963
train loss item: 0.2569681704044342
train loss item: 0.06256815046072006
train loss item: 0.360370010137558
train loss item: 0.09761321544647217
train loss item: 0.06139347329735756
train loss item: 0.30698564648628235
train loss item: 0.1518349051475525
train loss item: 0.12232092022895813
train loss item: 0.10537903010845184
train loss item: 0.11124102026224136
train loss item: 0.0834098756313324
train loss item: 0.09870248287916183
train loss item: 0.05683692544698715
train loss item: 0.2763512134552002
train loss item: 0.09031036496162415
train loss item: 0.06579190492630005
train loss item: 0.12879805266857147
train loss item: 0.1701095551252365
train loss item: 0.47954273223876953
train loss item: 0.12405523657798767
test loss item: 0.08302409201860428
test loss item: 0.14589227735996246
test loss item: 0.08657106757164001
test loss item: 0.42909014225006104
test loss item: 0.09644372016191483
test loss item: 0.24113522469997406
test loss item: 0.08852502703666687
test loss item: 0.056990306824445724
test loss item: 0.12330412864685059
test loss item: 0.2031518667936325
test loss item: 0.15950769186019897
test loss item: 0.13804270327091217
test loss item: 0.09335708618164062
test loss item: 0.11514105647802353
test loss item: 0.11836288124322891
test loss item: 0.25045546889305115
test loss item: 0.12191420793533325
test loss item: 0.14825712144374847
test loss item: 0.3297172486782074
test loss item: 0.130337193608284
test loss item: 0.13167831301689148
test loss item: 0.09627675265073776
test loss item: 0.18066109716892242
test loss item: 0.15081891417503357
test loss item: 0.1928590089082718
test loss item: 0.08047106862068176
test loss item: 0.08940800279378891
test loss item: 0.1888923943042755
test loss item: 0.2024354189634323
test loss item: 0.08346856385469437
test loss item: 0.11201287060976028
test loss item: 0.11284706741571426
test loss item: 0.24602600932121277
test loss item: 0.13133157789707184
test loss item: 0.17068266868591309
test loss item: 0.2874881327152252
test loss item: 0.2163124978542328
test loss item: 0.10947994142770767
test loss item: 0.38506338000297546
test loss item: 0.11916719377040863
test loss item: 0.2814975082874298
test loss item: 0.30907943844795227
test loss item: 0.10906168073415756
test loss item: 0.04728659987449646
test loss item: 0.11330927908420563
Epoch [18/100], Training Loss: 0.1696, Testing Loss: 0.1624
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 19/100
train loss item: 0.2290310561656952
train loss item: 0.16602420806884766
train loss item: 0.10748042911291122
train loss item: 0.1660241335630417
train loss item: 0.08404257893562317
train loss item: 0.10166607052087784
train loss item: 0.1984388381242752
train loss item: 0.1305427998304367
train loss item: 0.06762783974409103
train loss item: 0.13578270375728607
train loss item: 0.09194045513868332
train loss item: 0.29580846428871155
train loss item: 0.127921000123024
train loss item: 0.15250112116336823
train loss item: 0.1847091019153595
train loss item: 0.3182467520236969
train loss item: 0.20493021607398987
train loss item: 0.2424199879169464
train loss item: 0.24922041594982147
train loss item: 0.16304054856300354
train loss item: 0.12295061349868774
train loss item: 0.10307368636131287
train loss item: 0.1901036947965622
train loss item: 0.11765162646770477
train loss item: 0.09242638945579529
train loss item: 0.28768059611320496
train loss item: 0.06978367269039154
train loss item: 0.38167673349380493
train loss item: 0.11251037567853928
train loss item: 0.07734757661819458
train loss item: 0.37723031640052795
train loss item: 0.1282167285680771
train loss item: 0.13255469501018524
train loss item: 0.13199277222156525
train loss item: 0.10994860529899597
train loss item: 0.0935213565826416
train loss item: 0.10988188534975052
train loss item: 0.06699799001216888
train loss item: 0.2582569718360901
train loss item: 0.09810858219861984
train loss item: 0.08131849765777588
train loss item: 0.16228444874286652
train loss item: 0.18629102408885956
train loss item: 0.46266722679138184
train loss item: 0.1074286550283432
test loss item: 0.09553900361061096
test loss item: 0.1539972573518753
test loss item: 0.08223016560077667
test loss item: 0.31984031200408936
test loss item: 0.10425267368555069
test loss item: 0.24744383990764618
test loss item: 0.08559475839138031
test loss item: 0.07386758923530579
test loss item: 0.10697709023952484
test loss item: 0.13940806686878204
test loss item: 0.13833238184452057
test loss item: 0.11562570184469223
test loss item: 0.08920548111200333
test loss item: 0.09843853861093521
test loss item: 0.11217167973518372
test loss item: 0.23397015035152435
test loss item: 0.1316804736852646
test loss item: 0.1411321610212326
test loss item: 0.32281091809272766
test loss item: 0.12598474323749542
test loss item: 0.14128334820270538
test loss item: 0.09916810691356659
test loss item: 0.1435222178697586
test loss item: 0.1433504819869995
test loss item: 0.16389784216880798
test loss item: 0.09694210439920425
test loss item: 0.1040160059928894
test loss item: 0.19942694902420044
test loss item: 0.1689291149377823
test loss item: 0.08846566081047058
test loss item: 0.10083737969398499
test loss item: 0.10099686682224274
test loss item: 0.23472557961940765
test loss item: 0.09969352930784225
test loss item: 0.1425568014383316
test loss item: 0.19622477889060974
test loss item: 0.15753646194934845
test loss item: 0.10715252161026001
test loss item: 0.43514513969421387
test loss item: 0.11413074284791946
test loss item: 0.24384735524654388
test loss item: 0.29704877734184265
test loss item: 0.09674438089132309
test loss item: 0.09188096970319748
test loss item: 0.13690701127052307
Epoch [19/100], Training Loss: 0.1662, Testing Loss: 0.1516
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 20/100
train loss item: 0.2526750862598419
train loss item: 0.19858233630657196
train loss item: 0.1373118907213211
train loss item: 0.300648957490921
train loss item: 0.07188840955495834
train loss item: 0.1014106348156929
train loss item: 0.14981454610824585
train loss item: 0.22474710643291473
train loss item: 0.0823543518781662
train loss item: 0.15993565320968628
train loss item: 0.12909848988056183
train loss item: 0.39289426803588867
train loss item: 0.15737217664718628
train loss item: 0.17438071966171265
train loss item: 0.3018505573272705
train loss item: 0.4872300624847412
train loss item: 0.23492981493473053
train loss item: 0.3030490279197693
train loss item: 0.25430721044540405
train loss item: 0.16330327093601227
train loss item: 0.12658070027828217
train loss item: 0.09477324038743973
train loss item: 0.20435158908367157
train loss item: 0.12308934330940247
train loss item: 0.07552589476108551
train loss item: 0.31864839792251587
train loss item: 0.05437614023685455
train loss item: 0.28178495168685913
train loss item: 0.10114375501871109
train loss item: 0.06460383534431458
train loss item: 0.32900670170783997
train loss item: 0.1562798172235489
train loss item: 0.11628042906522751
train loss item: 0.1461784690618515
train loss item: 0.13514359295368195
train loss item: 0.10207492858171463
train loss item: 0.10961166024208069
train loss item: 0.06092538684606552
train loss item: 0.24539496004581451
train loss item: 0.09979970008134842
train loss item: 0.08005894720554352
train loss item: 0.139817014336586
train loss item: 0.17622840404510498
train loss item: 0.6179536581039429
train loss item: 0.12486434727907181
test loss item: 0.08643395453691483
test loss item: 0.16890999674797058
test loss item: 0.08596640825271606
test loss item: 0.45890170335769653
test loss item: 0.10843800753355026
test loss item: 0.30564960837364197
test loss item: 0.08609607070684433
test loss item: 0.07982105761766434
test loss item: 0.11951792985200882
test loss item: 0.18281105160713196
test loss item: 0.17359769344329834
test loss item: 0.11108442395925522
test loss item: 0.09149207174777985
test loss item: 0.10478829592466354
test loss item: 0.12378744781017303
test loss item: 0.3115030527114868
test loss item: 0.1510707288980484
test loss item: 0.14419609308242798
test loss item: 0.4114038348197937
test loss item: 0.1501316875219345
test loss item: 0.12804169952869415
test loss item: 0.09639201313257217
test loss item: 0.17473956942558289
test loss item: 0.12139248847961426
test loss item: 0.20861461758613586
test loss item: 0.09689896553754807
test loss item: 0.09536566585302353
test loss item: 0.23914827406406403
test loss item: 0.2063232809305191
test loss item: 0.09252551943063736
test loss item: 0.12438558787107468
test loss item: 0.10749167203903198
test loss item: 0.2767888009548187
test loss item: 0.12028477340936661
test loss item: 0.17489369213581085
test loss item: 0.2929346561431885
test loss item: 0.19882066547870636
test loss item: 0.08993059396743774
test loss item: 0.5486626625061035
test loss item: 0.10380295664072037
test loss item: 0.3221970796585083
test loss item: 0.38687780499458313
test loss item: 0.09002740681171417
test loss item: 0.08656425774097443
test loss item: 0.13803374767303467
Epoch [20/100], Training Loss: 0.1858, Testing Loss: 0.1773
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 21/100
train loss item: 0.20068621635437012
train loss item: 0.13693267107009888
train loss item: 0.11959534138441086
train loss item: 0.26321253180503845
train loss item: 0.08840028196573257
train loss item: 0.10373860597610474
train loss item: 0.1468815952539444
train loss item: 0.1339419037103653
train loss item: 0.05851280316710472
train loss item: 0.16198983788490295
train loss item: 0.1080760732293129
train loss item: 0.2074126899242401
train loss item: 0.13975143432617188
train loss item: 0.14574389159679413
train loss item: 0.22987723350524902
train loss item: 0.45196640491485596
train loss item: 0.19741690158843994
train loss item: 0.24818207323551178
train loss item: 0.23934853076934814
train loss item: 0.20646516978740692
train loss item: 0.132177472114563
train loss item: 0.1038251668214798
train loss item: 0.19934804737567902
train loss item: 0.13639120757579803
train loss item: 0.10370998084545135
train loss item: 0.3047199845314026
train loss item: 0.08846420794725418
train loss item: 0.2983144223690033
train loss item: 0.10565982758998871
train loss item: 0.07600631564855576
train loss item: 0.3173220753669739
train loss item: 0.12455135583877563
train loss item: 0.1410841941833496
train loss item: 0.16215111315250397
train loss item: 0.10316266119480133
train loss item: 0.09670430421829224
train loss item: 0.10140588134527206
train loss item: 0.07335291802883148
train loss item: 0.3728565275669098
train loss item: 0.09717115759849548
train loss item: 0.07414791733026505
train loss item: 0.19764523208141327
train loss item: 0.14613233506679535
train loss item: 0.34872397780418396
train loss item: 0.1310441642999649
test loss item: 0.09431276470422745
test loss item: 0.14780910313129425
test loss item: 0.09343148022890091
test loss item: 0.34508928656578064
test loss item: 0.10545911639928818
test loss item: 0.2257857620716095
test loss item: 0.09868256002664566
test loss item: 0.084977887570858
test loss item: 0.1143130362033844
test loss item: 0.15517914295196533
test loss item: 0.13872985541820526
test loss item: 0.11078289896249771
test loss item: 0.08543671667575836
test loss item: 0.10468176752328873
test loss item: 0.1212584525346756
test loss item: 0.21814492344856262
test loss item: 0.1159607544541359
test loss item: 0.11360839009284973
test loss item: 0.2988370954990387
test loss item: 0.12034410983324051
test loss item: 0.13008810579776764
test loss item: 0.09361528605222702
test loss item: 0.15374130010604858
test loss item: 0.13228106498718262
test loss item: 0.16255952417850494
test loss item: 0.0879894495010376
test loss item: 0.09379845857620239
test loss item: 0.17785325646400452
test loss item: 0.15995359420776367
test loss item: 0.0950377881526947
test loss item: 0.1040463000535965
test loss item: 0.10794197767972946
test loss item: 0.22825978696346283
test loss item: 0.11935048550367355
test loss item: 0.13864557445049286
test loss item: 0.22781461477279663
test loss item: 0.17224188148975372
test loss item: 0.10685443878173828
test loss item: 0.3958909213542938
test loss item: 0.11093466728925705
test loss item: 0.23785582184791565
test loss item: 0.27675288915634155
test loss item: 0.09765724837779999
test loss item: 0.05527656525373459
test loss item: 0.0991695299744606
Epoch [21/100], Training Loss: 0.1694, Testing Loss: 0.1480
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 22/100
train loss item: 0.20075194537639618
train loss item: 0.18863995373249054
train loss item: 0.13541129231452942
train loss item: 0.16044647991657257
train loss item: 0.08865936845541
train loss item: 0.08490515500307083
train loss item: 0.12154097110033035
train loss item: 0.13995026051998138
train loss item: 0.09904368966817856
train loss item: 0.15048328042030334
train loss item: 0.15561801195144653
train loss item: 0.2605946958065033
train loss item: 0.13768893480300903
train loss item: 0.13902440667152405
train loss item: 0.2582760453224182
train loss item: 0.224336177110672
train loss item: 0.20020893216133118
train loss item: 0.2355048507452011
train loss item: 0.14259469509124756
train loss item: 0.19972693920135498
train loss item: 0.12680400907993317
train loss item: 0.09757509082555771
train loss item: 0.28090694546699524
train loss item: 0.13854172825813293
train loss item: 0.09889295697212219
train loss item: 0.29571405053138733
train loss item: 0.07002223283052444
train loss item: 0.4048272967338562
train loss item: 0.1482291966676712
train loss item: 0.09675218909978867
train loss item: 0.3042755424976349
train loss item: 0.17217254638671875
train loss item: 0.11890095472335815
train loss item: 0.150381937623024
train loss item: 0.14579549431800842
train loss item: 0.10236631333827972
train loss item: 0.11456809937953949
train loss item: 0.08100736886262894
train loss item: 0.3076694905757904
train loss item: 0.09041953831911087
train loss item: 0.08826424926519394
train loss item: 0.14260081946849823
train loss item: 0.1737792193889618
train loss item: 0.4472180902957916
train loss item: 0.12964536249637604
test loss item: 0.09857357293367386
test loss item: 0.14375612139701843
test loss item: 0.09235469996929169
test loss item: 0.3760087490081787
test loss item: 0.10538696497678757
test loss item: 0.20579449832439423
test loss item: 0.11156649887561798
test loss item: 0.07594615966081619
test loss item: 0.1286030113697052
test loss item: 0.1817125380039215
test loss item: 0.15354813635349274
test loss item: 0.1496558040380478
test loss item: 0.09219224750995636
test loss item: 0.1192474439740181
test loss item: 0.1274384707212448
test loss item: 0.22402435541152954
test loss item: 0.11567471921443939
test loss item: 0.12072402238845825
test loss item: 0.267433762550354
test loss item: 0.1272570639848709
test loss item: 0.14979183673858643
test loss item: 0.09756117314100266
test loss item: 0.1873832792043686
test loss item: 0.17667819559574127
test loss item: 0.16856378316879272
test loss item: 0.0960494801402092
test loss item: 0.09512906521558762
test loss item: 0.15667560696601868
test loss item: 0.15595433115959167
test loss item: 0.09898407012224197
test loss item: 0.11108963191509247
test loss item: 0.12395519018173218
test loss item: 0.19518300890922546
test loss item: 0.13534235954284668
test loss item: 0.13578343391418457
test loss item: 0.2519787847995758
test loss item: 0.22889529168605804
test loss item: 0.13261529803276062
test loss item: 0.31408417224884033
test loss item: 0.1311797946691513
test loss item: 0.22909550368785858
test loss item: 0.2469010353088379
test loss item: 0.11636017262935638
test loss item: 0.04963117465376854
test loss item: 0.12224438041448593
Epoch [22/100], Training Loss: 0.1700, Testing Loss: 0.1539
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 23/100
train loss item: 0.2606080174446106
train loss item: 0.1639871448278427
train loss item: 0.12423691153526306
train loss item: 0.2026311159133911
train loss item: 0.08723589777946472
train loss item: 0.08556333929300308
train loss item: 0.15987184643745422
train loss item: 0.12727326154708862
train loss item: 0.06086338311433792
train loss item: 0.13172321021556854
train loss item: 0.10076892375946045
train loss item: 0.31006699800491333
train loss item: 0.13120990991592407
train loss item: 0.13986894488334656
train loss item: 0.1685825139284134
train loss item: 0.21612562239170074
train loss item: 0.13214944303035736
train loss item: 0.38841620087623596
train loss item: 0.2662237286567688
train loss item: 0.15130771696567535
train loss item: 0.10463870316743851
train loss item: 0.0914560928940773
train loss item: 0.17229697108268738
train loss item: 0.09695213288068771
train loss item: 0.0691518634557724
train loss item: 0.2377837598323822
train loss item: 0.05555160716176033
train loss item: 0.25943848490715027
train loss item: 0.08805535733699799
train loss item: 0.053456861525774
train loss item: 0.2777962386608124
train loss item: 0.1295911967754364
train loss item: 0.10551725327968597
train loss item: 0.1352890431880951
train loss item: 0.10662466287612915
train loss item: 0.07323743402957916
train loss item: 0.08185876905918121
train loss item: 0.050952114164829254
train loss item: 0.2551475167274475
train loss item: 0.09174487739801407
train loss item: 0.07637354731559753
train loss item: 0.11697018891572952
train loss item: 0.1681791990995407
train loss item: 0.37770962715148926
train loss item: 0.09983447194099426
test loss item: 0.08050201833248138
test loss item: 0.13804370164871216
test loss item: 0.0853940099477768
test loss item: 0.26430830359458923
test loss item: 0.08799005299806595
test loss item: 0.22256216406822205
test loss item: 0.08234567940235138
test loss item: 0.06976375728845596
test loss item: 0.1141168624162674
test loss item: 0.14008741080760956
test loss item: 0.1328166127204895
test loss item: 0.11124885827302933
test loss item: 0.08667922765016556
test loss item: 0.0973002091050148
test loss item: 0.11023726314306259
test loss item: 0.2013387382030487
test loss item: 0.11909586936235428
test loss item: 0.11024294793605804
test loss item: 0.27982914447784424
test loss item: 0.11367536336183548
test loss item: 0.12236548215150833
test loss item: 0.09465046226978302
test loss item: 0.14911818504333496
test loss item: 0.13487349450588226
test loss item: 0.14948609471321106
test loss item: 0.07702982425689697
test loss item: 0.08967778831720352
test loss item: 0.16704043745994568
test loss item: 0.1477474421262741
test loss item: 0.08201002329587936
test loss item: 0.09594149142503738
test loss item: 0.09888744354248047
test loss item: 0.20416797697544098
test loss item: 0.10806724429130554
test loss item: 0.12765517830848694
test loss item: 0.17726051807403564
test loss item: 0.1675444096326828
test loss item: 0.10432948917150497
test loss item: 0.4068487584590912
test loss item: 0.10539846122264862
test loss item: 0.21817456185817719
test loss item: 0.26415354013442993
test loss item: 0.09622005373239517
test loss item: 0.03949109464883804
test loss item: 0.12734203040599823
Epoch [23/100], Training Loss: 0.1508, Testing Loss: 0.1378
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 24/100
train loss item: 0.20534759759902954
train loss item: 0.16574010252952576
train loss item: 0.1171957328915596
train loss item: 0.20919381082057953
train loss item: 0.07472455501556396
train loss item: 0.08834820240736008
train loss item: 0.15831977128982544
train loss item: 0.13824985921382904
train loss item: 0.08837893605232239
train loss item: 0.11172345280647278
train loss item: 0.10001784563064575
train loss item: 0.29890692234039307
train loss item: 0.11469554156064987
train loss item: 0.15092384815216064
train loss item: 0.19625204801559448
train loss item: 0.24498505890369415
train loss item: 0.16224481165409088
train loss item: 0.37069401144981384
train loss item: 0.2722454369068146
train loss item: 0.16147950291633606
train loss item: 0.10986708849668503
train loss item: 0.08780701458454132
train loss item: 0.1742369532585144
train loss item: 0.1069440096616745
train loss item: 0.07438404113054276
train loss item: 0.20101556181907654
train loss item: 0.05637773498892784
train loss item: 0.19094030559062958
train loss item: 0.08625748008489609
train loss item: 0.059785276651382446
train loss item: 0.2487642765045166
train loss item: 0.13154268264770508
train loss item: 0.11148857325315475
train loss item: 0.11413302272558212
train loss item: 0.1111413985490799
train loss item: 0.08845280110836029
train loss item: 0.09174081683158875
train loss item: 0.061991624534130096
train loss item: 0.23404276371002197
train loss item: 0.08362845331430435
train loss item: 0.0739886537194252
train loss item: 0.17791327834129333
train loss item: 0.21599745750427246
train loss item: 0.5241515636444092
train loss item: 0.09271802753210068
test loss item: 0.08483254909515381
test loss item: 0.1770416498184204
test loss item: 0.09201249480247498
test loss item: 0.47910213470458984
test loss item: 0.11779972910881042
test loss item: 0.3205326199531555
test loss item: 0.11779452115297318
test loss item: 0.06973566114902496
test loss item: 0.12480693310499191
test loss item: 0.20620152354240417
test loss item: 0.17564567923545837
test loss item: 0.11825387179851532
test loss item: 0.09553135931491852
test loss item: 0.10931993275880814
test loss item: 0.13266490399837494
test loss item: 0.3283238708972931
test loss item: 0.15319663286209106
test loss item: 0.15735048055648804
test loss item: 0.4345235824584961
test loss item: 0.14840532839298248
test loss item: 0.13898205757141113
test loss item: 0.09763942658901215
test loss item: 0.18782855570316315
test loss item: 0.14466062188148499
test loss item: 0.22189262509346008
test loss item: 0.10643412917852402
test loss item: 0.09188618510961533
test loss item: 0.2529493272304535
test loss item: 0.21683943271636963
test loss item: 0.1108422577381134
test loss item: 0.1226971447467804
test loss item: 0.13276366889476776
test loss item: 0.2947601079940796
test loss item: 0.12747368216514587
test loss item: 0.1853908747434616
test loss item: 0.30413728952407837
test loss item: 0.20806258916854858
test loss item: 0.10732053965330124
test loss item: 0.5760712027549744
test loss item: 0.12185165286064148
test loss item: 0.33622512221336365
test loss item: 0.4114838242530823
test loss item: 0.10390935838222504
test loss item: 0.046637531369924545
test loss item: 0.16610147058963776
Epoch [24/100], Training Loss: 0.1542, Testing Loss: 0.1880
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 25/100
train loss item: 0.18888145685195923
train loss item: 0.13918617367744446
train loss item: 0.09959986805915833
train loss item: 0.30485209822654724
train loss item: 0.10795409977436066
train loss item: 0.11790626496076584
train loss item: 0.1447700560092926
train loss item: 0.14502213895320892
train loss item: 0.05430423095822334
train loss item: 0.16678756475448608
train loss item: 0.11341038346290588
train loss item: 0.3403383791446686
train loss item: 0.17211569845676422
train loss item: 0.16408059000968933
train loss item: 0.2633745074272156
train loss item: 0.29198044538497925
train loss item: 0.19238761067390442
train loss item: 0.2667900025844574
train loss item: 0.32751402258872986
train loss item: 0.22741563618183136
train loss item: 0.15232960879802704
train loss item: 0.12362967431545258
train loss item: 0.17828235030174255
train loss item: 0.11378499120473862
train loss item: 0.08849039673805237
train loss item: 0.2990567982196808
train loss item: 0.08048873394727707
train loss item: 0.3072604835033417
train loss item: 0.1334104686975479
train loss item: 0.08444467186927795
train loss item: 0.39083850383758545
train loss item: 0.15526913106441498
train loss item: 0.13414135575294495
train loss item: 0.14227135479450226
train loss item: 0.1466871201992035
train loss item: 0.1594579964876175
train loss item: 0.14009760320186615
train loss item: 0.07154412567615509
train loss item: 0.1963243931531906
train loss item: 0.10145855695009232
train loss item: 0.06810639053583145
train loss item: 0.14710158109664917
train loss item: 0.16445958614349365
train loss item: 0.38206544518470764
train loss item: 0.12922197580337524
test loss item: 0.08218017965555191
test loss item: 0.15455973148345947
test loss item: 0.08459258824586868
test loss item: 0.3869815170764923
test loss item: 0.1068086251616478
test loss item: 0.26281410455703735
test loss item: 0.1113852709531784
test loss item: 0.07586748898029327
test loss item: 0.11286972463130951
test loss item: 0.16289550065994263
test loss item: 0.13875506818294525
test loss item: 0.10672660171985626
test loss item: 0.08587391674518585
test loss item: 0.10145208984613419
test loss item: 0.11929486691951752
test loss item: 0.25743207335472107
test loss item: 0.12264251708984375
test loss item: 0.10940156131982803
test loss item: 0.34016141295433044
test loss item: 0.1282571256160736
test loss item: 0.12223070114850998
test loss item: 0.09364070743322372
test loss item: 0.1600266546010971
test loss item: 0.12909777462482452
test loss item: 0.17417190968990326
test loss item: 0.09135253727436066
test loss item: 0.08848421275615692
test loss item: 0.1974060833454132
test loss item: 0.15411053597927094
test loss item: 0.1031428873538971
test loss item: 0.10247917473316193
test loss item: 0.11439304798841476
test loss item: 0.2460108995437622
test loss item: 0.12484759092330933
test loss item: 0.14313699305057526
test loss item: 0.2485039234161377
test loss item: 0.18843545019626617
test loss item: 0.09755843877792358
test loss item: 0.46676400303840637
test loss item: 0.10234416276216507
test loss item: 0.2725115418434143
test loss item: 0.3239154815673828
test loss item: 0.09144243597984314
test loss item: 0.043656591325998306
test loss item: 0.09770634025335312
Epoch [25/100], Training Loss: 0.1760, Testing Loss: 0.1562
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 26/100
train loss item: 0.1729346513748169
train loss item: 0.1288577914237976
train loss item: 0.09729240089654922
train loss item: 0.18854476511478424
train loss item: 0.12856325507164001
train loss item: 0.1401681900024414
train loss item: 0.11348601430654526
train loss item: 0.16971474885940552
train loss item: 0.054086972028017044
train loss item: 0.15527097880840302
train loss item: 0.12376520037651062
train loss item: 0.348489373922348
train loss item: 0.1957259178161621
train loss item: 0.188432976603508
train loss item: 0.32901498675346375
train loss item: 0.2714511454105377
train loss item: 0.1919945925474167
train loss item: 0.41905784606933594
train loss item: 0.34332823753356934
train loss item: 0.2414843738079071
train loss item: 0.14391231536865234
train loss item: 0.12699416279792786
train loss item: 0.15814487636089325
train loss item: 0.13323909044265747
train loss item: 0.08249550312757492
train loss item: 0.23739872872829437
train loss item: 0.06907331198453903
train loss item: 0.22727227210998535
train loss item: 0.15702036023139954
train loss item: 0.09637551009654999
train loss item: 0.4080905020236969
train loss item: 0.2415475994348526
train loss item: 0.1836850792169571
train loss item: 0.15136471390724182
train loss item: 0.1181255578994751
train loss item: 0.08016768097877502
train loss item: 0.1224798858165741
train loss item: 0.0630752369761467
train loss item: 0.20598198473453522
train loss item: 0.10389585047960281
train loss item: 0.08798486739397049
train loss item: 0.13666915893554688
train loss item: 0.1228058934211731
train loss item: 0.28706979751586914
train loss item: 0.10991984605789185
test loss item: 0.08450420945882797
test loss item: 0.2235732078552246
test loss item: 0.10212083905935287
test loss item: 0.6672216057777405
test loss item: 0.15420664846897125
test loss item: 0.3675481081008911
test loss item: 0.1461474895477295
test loss item: 0.07954349368810654
test loss item: 0.1504993736743927
test loss item: 0.24911725521087646
test loss item: 0.22663693130016327
test loss item: 0.13034096360206604
test loss item: 0.10278868675231934
test loss item: 0.12178289890289307
test loss item: 0.15288545191287994
test loss item: 0.40516364574432373
test loss item: 0.19817319512367249
test loss item: 0.1829574555158615
test loss item: 0.5318166613578796
test loss item: 0.18412767350673676
test loss item: 0.14227890968322754
test loss item: 0.12638261914253235
test loss item: 0.22198952734470367
test loss item: 0.14985574781894684
test loss item: 0.2833184003829956
test loss item: 0.1417676955461502
test loss item: 0.10601834207773209
test loss item: 0.3190588653087616
test loss item: 0.2646305561065674
test loss item: 0.13524511456489563
test loss item: 0.15548929572105408
test loss item: 0.13796080648899078
test loss item: 0.37742534279823303
test loss item: 0.15244625508785248
test loss item: 0.22301462292671204
test loss item: 0.41678690910339355
test loss item: 0.22925500571727753
test loss item: 0.10615751147270203
test loss item: 0.6595122218132019
test loss item: 0.11084829270839691
test loss item: 0.425701767206192
test loss item: 0.5049891471862793
test loss item: 0.11064808070659637
test loss item: 0.04615459218621254
test loss item: 0.10069914907217026
Epoch [26/100], Training Loss: 0.1746, Testing Loss: 0.2246
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 27/100
train loss item: 0.24213875830173492
train loss item: 0.2067309021949768
train loss item: 0.09871998429298401
train loss item: 0.1239093691110611
train loss item: 0.10815416276454926
train loss item: 0.13983845710754395
train loss item: 0.19229531288146973
train loss item: 0.12190417945384979
train loss item: 0.1379919797182083
train loss item: 0.12147091329097748
train loss item: 0.10252489894628525
train loss item: 0.3447256088256836
train loss item: 0.18755944073200226
train loss item: 0.13091936707496643
train loss item: 0.35787490010261536
train loss item: 0.34725096821784973
train loss item: 0.2446775883436203
train loss item: 0.32723236083984375
train loss item: 0.27690938115119934
train loss item: 0.29682737588882446
train loss item: 0.19567491114139557
train loss item: 0.15152108669281006
train loss item: 0.34597790241241455
train loss item: 0.1356564313173294
train loss item: 0.1094876229763031
train loss item: 0.35078054666519165
train loss item: 0.09471540153026581
train loss item: 0.31193941831588745
train loss item: 0.1166834905743599
train loss item: 0.11166869848966599
train loss item: 0.4653325080871582
train loss item: 0.10425063222646713
train loss item: 0.1401868611574173
train loss item: 0.16039395332336426
train loss item: 0.1319168359041214
train loss item: 0.11549083888530731
train loss item: 0.12167809903621674
train loss item: 0.09983539581298828
train loss item: 0.5581921935081482
train loss item: 0.09601566940546036
train loss item: 0.08975175023078918
train loss item: 0.2136543095111847
train loss item: 0.21290642023086548
train loss item: 0.3194153904914856
train loss item: 0.12457720190286636
test loss item: 0.1037391796708107
test loss item: 0.15555423498153687
test loss item: 0.1052665039896965
test loss item: 0.3527257740497589
test loss item: 0.10353890806436539
test loss item: 0.24814119935035706
test loss item: 0.10395295917987823
test loss item: 0.09681736677885056
test loss item: 0.12787798047065735
test loss item: 0.20418919622898102
test loss item: 0.1592804342508316
test loss item: 0.13789480924606323
test loss item: 0.09190543740987778
test loss item: 0.12384933233261108
test loss item: 0.1312784105539322
test loss item: 0.2167905867099762
test loss item: 0.13208694756031036
test loss item: 0.14304183423519135
test loss item: 0.31887343525886536
test loss item: 0.12503793835639954
test loss item: 0.1369040459394455
test loss item: 0.09312038123607635
test loss item: 0.19368138909339905
test loss item: 0.163585364818573
test loss item: 0.1801830232143402
test loss item: 0.0996931865811348
test loss item: 0.09139865636825562
test loss item: 0.19349446892738342
test loss item: 0.19223754107952118
test loss item: 0.09603744745254517
test loss item: 0.11075389385223389
test loss item: 0.12056741863489151
test loss item: 0.26859351992607117
test loss item: 0.13315248489379883
test loss item: 0.15352290868759155
test loss item: 0.24631959199905396
test loss item: 0.21005378663539886
test loss item: 0.12308020144701004
test loss item: 0.3919858932495117
test loss item: 0.1257578581571579
test loss item: 0.2466905564069748
test loss item: 0.2908453345298767
test loss item: 0.11760947108268738
test loss item: 0.06944312155246735
test loss item: 0.14658649265766144
Epoch [27/100], Training Loss: 0.1997, Testing Loss: 0.1639
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.11219392716884613
loss item: 0.3830980956554413
loss item: 0.20304979383945465
loss item: 0.19093409180641174
loss item: 0.11844141036272049
loss item: 0.3101077973842621
loss item: 0.20528478920459747
loss item: 0.12521488964557648
loss item: 0.16350582242012024
loss item: 0.27419546246528625
loss item: 0.14954587817192078
loss item: 0.16813905537128448
loss item: 0.20451347529888153
loss item: 0.2226845622062683
loss item: 0.19515562057495117
loss item: 0.379072368144989
loss item: 0.15465833246707916
loss item: 0.12476256489753723
loss item: 0.1339183747768402
loss item: 0.18434016406536102
loss item: 0.26672399044036865
loss item: 0.10347039252519608
Val Loss: 0.1988
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 100, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.001 4 360 done at Tue Nov 12 13:09:57 CET 2024
UNet2 with 1 100 0.005 4 360 start at Tue Nov 12 13:09:57 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 100, batch size: 4
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.6336421966552734
train loss item: 1.347577691078186
train loss item: 1.2426575422286987
train loss item: 1.403577446937561
train loss item: 0.49251851439476013
train loss item: 0.45189368724823
train loss item: 0.523338794708252
train loss item: 0.8533712029457092
train loss item: 0.4423550069332123
train loss item: 0.49863359332084656
train loss item: 0.28157615661621094
train loss item: 1.4692952632904053
train loss item: 0.6577840447425842
train loss item: 0.43952804803848267
train loss item: 1.1109474897384644
train loss item: 2.2161989212036133
train loss item: 0.6377905011177063
train loss item: 2.557669162750244
train loss item: 0.5520955920219421
train loss item: 0.5395609736442566
train loss item: 0.3840208053588867
train loss item: 0.47386613488197327
train loss item: 0.5512625575065613
train loss item: 0.5325104594230652
train loss item: 0.3741435110569
train loss item: 1.080769658088684
train loss item: 0.32202449440956116
train loss item: 1.9903427362442017
train loss item: 0.39721742272377014
train loss item: 0.18291355669498444
train loss item: 1.9903628826141357
train loss item: 0.585350751876831
train loss item: 0.6599414944648743
train loss item: 0.43473342061042786
train loss item: 0.5474609732627869
train loss item: 0.346159964799881
train loss item: 0.35071614384651184
train loss item: 0.28084033727645874
train loss item: 1.416642427444458
train loss item: 0.27042609453201294
train loss item: 0.35390377044677734
train loss item: 0.630920946598053
train loss item: 0.6428886651992798
train loss item: 3.4514591693878174
train loss item: 0.4955306947231293
test loss item: 0.18652459979057312
test loss item: 0.5123259425163269
test loss item: 0.23698683083057404
test loss item: 1.199652075767517
test loss item: 0.37343162298202515
test loss item: 0.839149534702301
test loss item: 0.20760200917720795
test loss item: 0.15818800032138824
test loss item: 0.4415561258792877
test loss item: 0.5559232234954834
test loss item: 0.5511224865913391
test loss item: 0.28916239738464355
test loss item: 0.28136152029037476
test loss item: 0.31867167353630066
test loss item: 0.4116658568382263
test loss item: 0.7880279421806335
test loss item: 0.5528665781021118
test loss item: 0.5054436326026917
test loss item: 1.2191683053970337
test loss item: 0.482201486825943
test loss item: 0.33643874526023865
test loss item: 0.3294539451599121
test loss item: 0.5891830921173096
test loss item: 0.3420000672340393
test loss item: 0.6437329649925232
test loss item: 0.27744820713996887
test loss item: 0.27574583888053894
test loss item: 0.8090168833732605
test loss item: 0.6069300174713135
test loss item: 0.26123201847076416
test loss item: 0.40436360239982605
test loss item: 0.2860547602176666
test loss item: 0.8523262739181519
test loss item: 0.34835126996040344
test loss item: 0.5599121451377869
test loss item: 0.7706369757652283
test loss item: 0.4201832413673401
test loss item: 0.2194983810186386
test loss item: 1.3796803951263428
test loss item: 0.2588309645652771
test loss item: 0.8224002718925476
test loss item: 1.0600274801254272
test loss item: 0.25890272855758667
test loss item: 0.1164037212729454
test loss item: 0.19492024183273315
Epoch [1/100], Training Loss: 0.8466, Testing Loss: 0.5008
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/100
train loss item: 0.945400595664978
train loss item: 0.5656852722167969
train loss item: 0.4969066083431244
train loss item: 0.7138389945030212
train loss item: 0.41676419973373413
train loss item: 0.4335280954837799
train loss item: 0.4800505042076111
train loss item: 0.6254915595054626
train loss item: 0.27953222393989563
train loss item: 0.4126567244529724
train loss item: 0.21374163031578064
train loss item: 1.1867620944976807
train loss item: 0.5342413187026978
train loss item: 0.4554866850376129
train loss item: 0.8397504687309265
train loss item: 1.7313896417617798
train loss item: 0.4293855130672455
train loss item: 2.138850688934326
train loss item: 0.5286787748336792
train loss item: 0.5112156271934509
train loss item: 0.3450028598308563
train loss item: 0.3460937440395355
train loss item: 0.4993901550769806
train loss item: 0.32863542437553406
train loss item: 0.24903453886508942
train loss item: 0.8569633960723877
train loss item: 0.1590740978717804
train loss item: 1.8313250541687012
train loss item: 0.31091275811195374
train loss item: 0.16525501012802124
train loss item: 1.720314383506775
train loss item: 0.42017778754234314
train loss item: 0.5331020951271057
train loss item: 0.42986661195755005
train loss item: 0.41625896096229553
train loss item: 0.2995673418045044
train loss item: 0.3341169059276581
train loss item: 0.11984185129404068
train loss item: 1.2438786029815674
train loss item: 0.2610898017883301
train loss item: 0.22758682072162628
train loss item: 0.5644232034683228
train loss item: 0.5763090252876282
train loss item: 2.96242356300354
train loss item: 0.4432523250579834
test loss item: 0.16126231849193573
test loss item: 0.49072882533073425
test loss item: 0.2205481082201004
test loss item: 1.1506656408309937
test loss item: 0.3921148180961609
test loss item: 0.8079535365104675
test loss item: 0.23131026327610016
test loss item: 0.13870981335639954
test loss item: 0.43551120162010193
test loss item: 0.5888134241104126
test loss item: 0.544439971446991
test loss item: 0.2559468448162079
test loss item: 0.2746877670288086
test loss item: 0.32591214776039124
test loss item: 0.4170214831829071
test loss item: 0.7459545135498047
test loss item: 0.5304632186889648
test loss item: 0.5088574290275574
test loss item: 1.2048120498657227
test loss item: 0.4579828679561615
test loss item: 0.2913540303707123
test loss item: 0.3125852048397064
test loss item: 0.6091951727867126
test loss item: 0.31842416524887085
test loss item: 0.664040207862854
test loss item: 0.28352099657058716
test loss item: 0.2550370395183563
test loss item: 0.7749406695365906
test loss item: 0.6107324957847595
test loss item: 0.25903379917144775
test loss item: 0.4217155873775482
test loss item: 0.2799800932407379
test loss item: 0.7853072881698608
test loss item: 0.3575451076030731
test loss item: 0.5457370281219482
test loss item: 0.7555294632911682
test loss item: 0.420271098613739
test loss item: 0.1938873529434204
test loss item: 1.2912393808364868
test loss item: 0.23956875503063202
test loss item: 0.81330406665802
test loss item: 1.0305527448654175
test loss item: 0.26021909713745117
test loss item: 0.08182741701602936
test loss item: 0.12967297434806824
Epoch [2/100], Training Loss: 0.6574, Testing Loss: 0.4860
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 3/100
train loss item: 0.8472827076911926
train loss item: 0.6106647849082947
train loss item: 0.44940295815467834
train loss item: 0.644042432308197
train loss item: 0.31033170223236084
train loss item: 0.38958609104156494
train loss item: 0.41482388973236084
train loss item: 0.46685659885406494
train loss item: 0.25299182534217834
train loss item: 0.35189634561538696
train loss item: 0.2326698899269104
train loss item: 1.0513217449188232
train loss item: 0.45542073249816895
train loss item: 0.2806621193885803
train loss item: 0.654719352722168
train loss item: 1.4262546300888062
train loss item: 0.3385307192802429
train loss item: 1.780143141746521
train loss item: 0.7078552842140198
train loss item: 0.6721284985542297
train loss item: 0.31872767210006714
train loss item: 0.33787035942077637
train loss item: 0.43650752305984497
train loss item: 0.3212485611438751
train loss item: 0.23101668059825897
train loss item: 0.7423748970031738
train loss item: 0.15144890546798706
train loss item: 1.5260906219482422
train loss item: 0.32508742809295654
train loss item: 0.18050996959209442
train loss item: 1.4484329223632812
train loss item: 0.46051931381225586
train loss item: 0.522236168384552
train loss item: 0.4930451512336731
train loss item: 0.4201532006263733
train loss item: 0.2729872167110443
train loss item: 0.33013755083084106
train loss item: 0.11035403609275818
train loss item: 1.1148489713668823
train loss item: 0.2707400918006897
train loss item: 0.22322282195091248
train loss item: 0.5041843056678772
train loss item: 0.5557368397712708
train loss item: 2.7770726680755615
train loss item: 0.41871771216392517
test loss item: 0.1802605390548706
test loss item: 0.504517674446106
test loss item: 0.2730792164802551
test loss item: 1.075114369392395
test loss item: 0.4271893799304962
test loss item: 0.7942330837249756
test loss item: 0.2535458505153656
test loss item: 0.17768509685993195
test loss item: 0.4210967421531677
test loss item: 0.5447808504104614
test loss item: 0.5118012428283691
test loss item: 0.27079010009765625
test loss item: 0.27578604221343994
test loss item: 0.3414904475212097
test loss item: 0.43427151441574097
test loss item: 0.7314468622207642
test loss item: 0.5431112051010132
test loss item: 0.5198567509651184
test loss item: 1.17726731300354
test loss item: 0.46724966168403625
test loss item: 0.2785700559616089
test loss item: 0.3122018277645111
test loss item: 0.5717281699180603
test loss item: 0.311200350522995
test loss item: 0.6698199510574341
test loss item: 0.31621822714805603
test loss item: 0.26298436522483826
test loss item: 0.7895907163619995
test loss item: 0.575943112373352
test loss item: 0.2909041941165924
test loss item: 0.4256826937198639
test loss item: 0.27490904927253723
test loss item: 0.7381288409233093
test loss item: 0.34564247727394104
test loss item: 0.5422050356864929
test loss item: 0.7022069692611694
test loss item: 0.3799048066139221
test loss item: 0.19399434328079224
test loss item: 1.2392605543136597
test loss item: 0.26511427760124207
test loss item: 0.7768603563308716
test loss item: 1.0065412521362305
test loss item: 0.26264670491218567
test loss item: 0.09411763399839401
test loss item: 0.1608969122171402
Epoch [3/100], Training Loss: 0.5962, Testing Loss: 0.4825
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 4/100
train loss item: 0.8090807199478149
train loss item: 0.5690974593162537
train loss item: 0.40838858485221863
train loss item: 0.6001176238059998
train loss item: 0.28542542457580566
train loss item: 0.36870741844177246
train loss item: 0.40422549843788147
train loss item: 0.4469160735607147
train loss item: 0.24582251906394958
train loss item: 0.34188446402549744
train loss item: 0.21352605521678925
train loss item: 0.9234427809715271
train loss item: 0.42073431611061096
train loss item: 0.2652519643306732
train loss item: 0.6126670241355896
train loss item: 1.3028028011322021
train loss item: 0.32369956374168396
train loss item: 1.5854545831680298
train loss item: 0.8190464973449707
train loss item: 0.7207515835762024
train loss item: 0.34192925691604614
train loss item: 0.3292854428291321
train loss item: 0.40694233775138855
train loss item: 0.31155484914779663
train loss item: 0.23373834788799286
train loss item: 0.6925632357597351
train loss item: 0.1406780481338501
train loss item: 1.406319499015808
train loss item: 0.32040905952453613
train loss item: 0.19390727579593658
train loss item: 1.3186147212982178
train loss item: 0.42854219675064087
train loss item: 0.4895843267440796
train loss item: 0.4435997009277344
train loss item: 0.3945150375366211
train loss item: 0.24754463136196136
train loss item: 0.3291766047477722
train loss item: 0.13003401458263397
train loss item: 1.0130952596664429
train loss item: 0.2768600881099701
train loss item: 0.19242867827415466
train loss item: 0.47701987624168396
train loss item: 0.5291575789451599
train loss item: 2.5110244750976562
train loss item: 0.383695513010025
test loss item: 0.1619199812412262
test loss item: 0.44015011191368103
test loss item: 0.2177913635969162
test loss item: 1.2038090229034424
test loss item: 0.3648519814014435
test loss item: 0.7160108685493469
test loss item: 0.2592621445655823
test loss item: 0.15363512933254242
test loss item: 0.4027279019355774
test loss item: 0.5901955962181091
test loss item: 0.5210987329483032
test loss item: 0.24701179563999176
test loss item: 0.2573278546333313
test loss item: 0.3091728091239929
test loss item: 0.39390063285827637
test loss item: 0.7035701870918274
test loss item: 0.49562230706214905
test loss item: 0.47318899631500244
test loss item: 1.1034667491912842
test loss item: 0.41788968443870544
test loss item: 0.27474531531333923
test loss item: 0.2902994155883789
test loss item: 0.5850714445114136
test loss item: 0.2975107431411743
test loss item: 0.6150050163269043
test loss item: 0.2682058811187744
test loss item: 0.22692205011844635
test loss item: 0.6817983984947205
test loss item: 0.5976828932762146
test loss item: 0.26410427689552307
test loss item: 0.38909992575645447
test loss item: 0.2774963676929474
test loss item: 0.7313579320907593
test loss item: 0.34846413135528564
test loss item: 0.5332461595535278
test loss item: 0.8059496283531189
test loss item: 0.40858110785484314
test loss item: 0.18411460518836975
test loss item: 1.100257158279419
test loss item: 0.22328689694404602
test loss item: 0.7847654819488525
test loss item: 0.9487593173980713
test loss item: 0.241329163312912
test loss item: 0.08484473079442978
test loss item: 0.13726384937763214
Epoch [4/100], Training Loss: 0.5602, Testing Loss: 0.4607
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 5/100
train loss item: 0.7939813733100891
train loss item: 0.5870384573936462
train loss item: 0.40169617533683777
train loss item: 0.5484129786491394
train loss item: 0.2943485677242279
train loss item: 0.3320987820625305
train loss item: 0.3582610785961151
train loss item: 0.4270992875099182
train loss item: 0.23144365847110748
train loss item: 0.3207961618900299
train loss item: 0.17521385848522186
train loss item: 0.8768212795257568
train loss item: 0.39664143323898315
train loss item: 0.22368909418582916
train loss item: 0.5020948052406311
train loss item: 1.1488237380981445
train loss item: 0.342511922121048
train loss item: 1.4312740564346313
train loss item: 0.7971140146255493
train loss item: 0.6120758652687073
train loss item: 0.2298477292060852
train loss item: 0.27724507451057434
train loss item: 0.4276661276817322
train loss item: 0.3090161085128784
train loss item: 0.198374405503273
train loss item: 0.6910200119018555
train loss item: 0.1618068367242813
train loss item: 1.207358717918396
train loss item: 0.27897390723228455
train loss item: 0.17236106097698212
train loss item: 1.1014404296875
train loss item: 0.433631032705307
train loss item: 0.4285750985145569
train loss item: 0.5375449061393738
train loss item: 0.35157454013824463
train loss item: 0.2356889545917511
train loss item: 0.3230947256088257
train loss item: 0.11718650907278061
train loss item: 1.1036293506622314
train loss item: 0.22381098568439484
train loss item: 0.19120992720127106
train loss item: 0.46107274293899536
train loss item: 0.6597883105278015
train loss item: 2.5488739013671875
train loss item: 0.4447628855705261
test loss item: 0.21019500494003296
test loss item: 0.45396074652671814
test loss item: 0.2469397634267807
test loss item: 0.8688377737998962
test loss item: 0.35180479288101196
test loss item: 0.7061207890510559
test loss item: 0.21992692351341248
test loss item: 0.19687776267528534
test loss item: 0.37795397639274597
test loss item: 0.47033554315567017
test loss item: 0.4607613682746887
test loss item: 0.27084165811538696
test loss item: 0.24185776710510254
test loss item: 0.3152433931827545
test loss item: 0.37390726804733276
test loss item: 0.6184032559394836
test loss item: 0.4741443693637848
test loss item: 0.4307726323604584
test loss item: 1.0020742416381836
test loss item: 0.3992624580860138
test loss item: 0.27911651134490967
test loss item: 0.2733513414859772
test loss item: 0.514079749584198
test loss item: 0.31297504901885986
test loss item: 0.5580347180366516
test loss item: 0.25938618183135986
test loss item: 0.22726120054721832
test loss item: 0.6655758619308472
test loss item: 0.5165843963623047
test loss item: 0.2306268811225891
test loss item: 0.36289873719215393
test loss item: 0.25129541754722595
test loss item: 0.6405119895935059
test loss item: 0.3162073791027069
test loss item: 0.44570866227149963
test loss item: 0.5699805617332458
test loss item: 0.368742972612381
test loss item: 0.21327565610408783
test loss item: 1.0572994947433472
test loss item: 0.2619453966617584
test loss item: 0.6680194139480591
test loss item: 0.8670331239700317
test loss item: 0.23616822063922882
test loss item: 0.15715660154819489
test loss item: 0.1409444808959961
Epoch [5/100], Training Loss: 0.5315, Testing Loss: 0.4241
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 6/100
train loss item: 0.6722326874732971
train loss item: 0.6472647190093994
train loss item: 0.3674473464488983
train loss item: 0.5457723140716553
train loss item: 0.3013373911380768
train loss item: 0.3446873724460602
train loss item: 0.40469682216644287
train loss item: 0.48261162638664246
train loss item: 0.21648581326007843
train loss item: 0.3097626268863678
train loss item: 0.1766408234834671
train loss item: 0.7924415469169617
train loss item: 0.3743273615837097
train loss item: 0.24916814267635345
train loss item: 0.536395251750946
train loss item: 1.0040340423583984
train loss item: 0.27670302987098694
train loss item: 1.2049758434295654
train loss item: 0.8741863369941711
train loss item: 0.60051429271698
train loss item: 0.2985740303993225
train loss item: 0.27831676602363586
train loss item: 0.3834359347820282
train loss item: 0.2688014507293701
train loss item: 0.21656470000743866
train loss item: 0.6637131571769714
train loss item: 0.13752591609954834
train loss item: 1.215593695640564
train loss item: 0.24030710756778717
train loss item: 0.15147344768047333
train loss item: 1.0973873138427734
train loss item: 0.3600108027458191
train loss item: 0.4203082025051117
train loss item: 0.5157877206802368
train loss item: 0.37288257479667664
train loss item: 0.2113913595676422
train loss item: 0.29018718004226685
train loss item: 0.10508165508508682
train loss item: 0.953016996383667
train loss item: 0.19498303532600403
train loss item: 0.15724119544029236
train loss item: 0.3779267370700836
train loss item: 0.45830103754997253
train loss item: 1.9161124229431152
train loss item: 0.47565776109695435
test loss item: 0.17044244706630707
test loss item: 0.39845678210258484
test loss item: 0.19931359589099884
test loss item: 0.799482524394989
test loss item: 0.28499147295951843
test loss item: 0.5951049327850342
test loss item: 0.18521039187908173
test loss item: 0.1326655000448227
test loss item: 0.3584539592266083
test loss item: 0.4295026361942291
test loss item: 0.4583287835121155
test loss item: 0.25140830874443054
test loss item: 0.22953855991363525
test loss item: 0.26608267426490784
test loss item: 0.32275328040122986
test loss item: 0.5512738823890686
test loss item: 0.4549865126609802
test loss item: 0.38628271222114563
test loss item: 0.8753800392150879
test loss item: 0.360739529132843
test loss item: 0.27483218908309937
test loss item: 0.2631319463253021
test loss item: 0.4798237979412079
test loss item: 0.29522237181663513
test loss item: 0.47779014706611633
test loss item: 0.21502654254436493
test loss item: 0.21805916726589203
test loss item: 0.6000245809555054
test loss item: 0.465888112783432
test loss item: 0.20673370361328125
test loss item: 0.3215444087982178
test loss item: 0.23377498984336853
test loss item: 0.6345674991607666
test loss item: 0.2851347327232361
test loss item: 0.4409381151199341
test loss item: 0.5179892182350159
test loss item: 0.3486470580101013
test loss item: 0.20293709635734558
test loss item: 1.0244683027267456
test loss item: 0.23432783782482147
test loss item: 0.596384584903717
test loss item: 0.778014600276947
test loss item: 0.22138498723506927
test loss item: 0.12569454312324524
test loss item: 0.27469542622566223
Epoch [6/100], Training Loss: 0.4921, Testing Loss: 0.3877
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 7/100
train loss item: 0.6834952235221863
train loss item: 0.5108019709587097
train loss item: 0.29087987542152405
train loss item: 0.4806845188140869
train loss item: 0.304002970457077
train loss item: 0.3033292591571808
train loss item: 0.31130433082580566
train loss item: 0.4769441485404968
train loss item: 0.20422956347465515
train loss item: 0.28319859504699707
train loss item: 0.19576238095760345
train loss item: 0.681144118309021
train loss item: 0.3279729187488556
train loss item: 0.21476371586322784
train loss item: 0.46284958720207214
train loss item: 0.9002544283866882
train loss item: 0.2511739134788513
train loss item: 0.9676511883735657
train loss item: 0.6782336235046387
train loss item: 0.39863476157188416
train loss item: 0.23711882531642914
train loss item: 0.28847143054008484
train loss item: 0.33246126770973206
train loss item: 0.28792375326156616
train loss item: 0.18497583270072937
train loss item: 0.572139322757721
train loss item: 0.12339083105325699
train loss item: 0.8942172527313232
train loss item: 0.23832207918167114
train loss item: 0.18110999464988708
train loss item: 0.8381558656692505
train loss item: 0.34240245819091797
train loss item: 0.36235150694847107
train loss item: 0.4912140965461731
train loss item: 0.3161610960960388
train loss item: 0.2086329460144043
train loss item: 0.25971633195877075
train loss item: 0.12963244318962097
train loss item: 0.9323926568031311
train loss item: 0.2117735892534256
train loss item: 0.19237594306468964
train loss item: 0.3639521300792694
train loss item: 0.4831444323062897
train loss item: 1.653002142906189
train loss item: 0.412399023771286
test loss item: 0.16370932757854462
test loss item: 0.356836199760437
test loss item: 0.2377030849456787
test loss item: 0.8060991764068604
test loss item: 0.2861695885658264
test loss item: 0.5518744587898254
test loss item: 0.18577973544597626
test loss item: 0.145443856716156
test loss item: 0.3114122748374939
test loss item: 0.4363095164299011
test loss item: 0.39468586444854736
test loss item: 0.25270381569862366
test loss item: 0.21111337840557098
test loss item: 0.2711045444011688
test loss item: 0.3129524886608124
test loss item: 0.49469226598739624
test loss item: 0.3996514081954956
test loss item: 0.38837239146232605
test loss item: 0.8176052570343018
test loss item: 0.33260378241539
test loss item: 0.23500877618789673
test loss item: 0.22460907697677612
test loss item: 0.4297024607658386
test loss item: 0.2771562933921814
test loss item: 0.4704809784889221
test loss item: 0.21560658514499664
test loss item: 0.18135115504264832
test loss item: 0.5265294313430786
test loss item: 0.47292980551719666
test loss item: 0.20578834414482117
test loss item: 0.3074435591697693
test loss item: 0.20501190423965454
test loss item: 0.54923415184021
test loss item: 0.26409631967544556
test loss item: 0.4148637354373932
test loss item: 0.5244768261909485
test loss item: 0.30222079157829285
test loss item: 0.19094829261302948
test loss item: 0.8015830516815186
test loss item: 0.23871107399463654
test loss item: 0.5544226169586182
test loss item: 0.7028189897537231
test loss item: 0.20554739236831665
test loss item: 0.09685264527797699
test loss item: 0.21613264083862305
Epoch [7/100], Training Loss: 0.4325, Testing Loss: 0.3593
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 8/100
train loss item: 0.6159584522247314
train loss item: 0.3726058006286621
train loss item: 0.29230403900146484
train loss item: 0.4982207417488098
train loss item: 0.2291695475578308
train loss item: 0.26635345816612244
train loss item: 0.3388930559158325
train loss item: 0.45322468876838684
train loss item: 0.17693468928337097
train loss item: 0.2666698694229126
train loss item: 0.16499948501586914
train loss item: 0.7147325277328491
train loss item: 0.3136114478111267
train loss item: 0.2128148376941681
train loss item: 0.39765995740890503
train loss item: 0.7444828152656555
train loss item: 0.28488707542419434
train loss item: 0.7810381650924683
train loss item: 0.7685247659683228
train loss item: 0.3851138949394226
train loss item: 0.219159796833992
train loss item: 0.31499266624450684
train loss item: 0.330311119556427
train loss item: 0.2897900342941284
train loss item: 0.18503890931606293
train loss item: 0.5276561975479126
train loss item: 0.12511757016181946
train loss item: 0.6662341952323914
train loss item: 0.222976416349411
train loss item: 0.1700279414653778
train loss item: 0.7432228922843933
train loss item: 0.32953017950057983
train loss item: 0.292040079832077
train loss item: 0.42485490441322327
train loss item: 0.2984802722930908
train loss item: 0.1798573136329651
train loss item: 0.23677001893520355
train loss item: 0.09849874675273895
train loss item: 0.857044517993927
train loss item: 0.19253231585025787
train loss item: 0.15604683756828308
train loss item: 0.31781643629074097
train loss item: 0.46174755692481995
train loss item: 1.1914072036743164
train loss item: 0.3786194920539856
test loss item: 0.15831129252910614
test loss item: 0.3774109184741974
test loss item: 0.2193676382303238
test loss item: 0.6748121380805969
test loss item: 0.2741066813468933
test loss item: 0.5670682787895203
test loss item: 0.1665019690990448
test loss item: 0.14350613951683044
test loss item: 0.2988987863063812
test loss item: 0.3639279901981354
test loss item: 0.3631017506122589
test loss item: 0.2366778552532196
test loss item: 0.1938260793685913
test loss item: 0.25208768248558044
test loss item: 0.2930682301521301
test loss item: 0.4837612509727478
test loss item: 0.3903307020664215
test loss item: 0.34869852662086487
test loss item: 0.8113980293273926
test loss item: 0.3098466694355011
test loss item: 0.22486045956611633
test loss item: 0.21598409116268158
test loss item: 0.376176118850708
test loss item: 0.25621020793914795
test loss item: 0.4567394256591797
test loss item: 0.18878866732120514
test loss item: 0.18272823095321655
test loss item: 0.5550397038459778
test loss item: 0.419770747423172
test loss item: 0.18496114015579224
test loss item: 0.2867168188095093
test loss item: 0.19031065702438354
test loss item: 0.5554680824279785
test loss item: 0.24998778104782104
test loss item: 0.3666864037513733
test loss item: 0.42145437002182007
test loss item: 0.27817466855049133
test loss item: 0.18267394602298737
test loss item: 0.8872026801109314
test loss item: 0.22020380198955536
test loss item: 0.5397693514823914
test loss item: 0.7100871801376343
test loss item: 0.18756283819675446
test loss item: 0.08638442307710648
test loss item: 0.1778154969215393
Epoch [8/100], Training Loss: 0.3886, Testing Loss: 0.3406
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 9/100
train loss item: 0.5726674795150757
train loss item: 0.3511415421962738
train loss item: 0.26425859332084656
train loss item: 0.3773975372314453
train loss item: 0.2558417320251465
train loss item: 0.2604404091835022
train loss item: 0.28481072187423706
train loss item: 0.571817934513092
train loss item: 0.19668880105018616
train loss item: 0.2797573208808899
train loss item: 0.12524208426475525
train loss item: 0.6214509010314941
train loss item: 0.2812715768814087
train loss item: 0.2491178959608078
train loss item: 0.3601458966732025
train loss item: 0.7780765295028687
train loss item: 0.34482312202453613
train loss item: 0.6546589136123657
train loss item: 0.3933270573616028
train loss item: 0.2662087678909302
train loss item: 0.18778644502162933
train loss item: 0.2706407606601715
train loss item: 0.2762241065502167
train loss item: 0.26728716492652893
train loss item: 0.155086487531662
train loss item: 0.6334497332572937
train loss item: 0.10690432041883469
train loss item: 0.7557992339134216
train loss item: 0.2062920778989792
train loss item: 0.14183087646961212
train loss item: 0.7444945573806763
train loss item: 0.24572184681892395
train loss item: 0.3002210259437561
train loss item: 0.40610745549201965
train loss item: 0.28048020601272583
train loss item: 0.1841522604227066
train loss item: 0.21003012359142303
train loss item: 0.08807791024446487
train loss item: 0.8122351169586182
train loss item: 0.18065157532691956
train loss item: 0.12171285599470139
train loss item: 0.3911166489124298
train loss item: 0.41494596004486084
train loss item: 0.9855477809906006
train loss item: 0.3442762494087219
test loss item: 0.1526055783033371
test loss item: 0.3603709936141968
test loss item: 0.2319965660572052
test loss item: 0.6919817328453064
test loss item: 0.27569544315338135
test loss item: 0.5399787425994873
test loss item: 0.15210582315921783
test loss item: 0.14879944920539856
test loss item: 0.2775164842605591
test loss item: 0.325853168964386
test loss item: 0.3588808476924896
test loss item: 0.20250678062438965
test loss item: 0.17610694468021393
test loss item: 0.24663114547729492
test loss item: 0.2914465069770813
test loss item: 0.48760175704956055
test loss item: 0.38641905784606934
test loss item: 0.34905102849006653
test loss item: 0.7776722311973572
test loss item: 0.31279808282852173
test loss item: 0.17525386810302734
test loss item: 0.2075054943561554
test loss item: 0.35771968960762024
test loss item: 0.20555701851844788
test loss item: 0.4404856562614441
test loss item: 0.20427300035953522
test loss item: 0.17318086326122284
test loss item: 0.5410112738609314
test loss item: 0.3895481824874878
test loss item: 0.18665865063667297
test loss item: 0.28055915236473083
test loss item: 0.17060621082782745
test loss item: 0.5157884359359741
test loss item: 0.21346744894981384
test loss item: 0.3483826518058777
test loss item: 0.4029048979282379
test loss item: 0.24745364487171173
test loss item: 0.12093694508075714
test loss item: 0.818690836429596
test loss item: 0.21500037610530853
test loss item: 0.5141912698745728
test loss item: 0.6884729266166687
test loss item: 0.16786672174930573
test loss item: 0.07280046492815018
test loss item: 0.11660254746675491
Epoch [9/100], Training Loss: 0.3600, Testing Loss: 0.3227
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 10/100
train loss item: 0.6020269393920898
train loss item: 0.39847317337989807
train loss item: 0.24624276161193848
train loss item: 0.3701951801776886
train loss item: 0.23843127489089966
train loss item: 0.2669205665588379
train loss item: 0.35048267245292664
train loss item: 0.5872641205787659
train loss item: 0.22119779884815216
train loss item: 0.325479656457901
train loss item: 0.1657361090183258
train loss item: 0.7607239484786987
train loss item: 0.28758808970451355
train loss item: 0.22616659104824066
train loss item: 0.4163755774497986
train loss item: 0.679554283618927
train loss item: 0.31096145510673523
train loss item: 0.6030941605567932
train loss item: 0.6540489792823792
train loss item: 0.35537421703338623
train loss item: 0.24654889106750488
train loss item: 0.22990305721759796
train loss item: 0.2814757823944092
train loss item: 0.25349095463752747
train loss item: 0.17466750741004944
train loss item: 0.6605897545814514
train loss item: 0.11553570628166199
train loss item: 0.7396854162216187
train loss item: 0.2285119742155075
train loss item: 0.15545375645160675
train loss item: 0.8671631217002869
train loss item: 0.2861252427101135
train loss item: 0.3788702189922333
train loss item: 0.3102132976055145
train loss item: 0.2742173671722412
train loss item: 0.2545589506626129
train loss item: 0.27447256445884705
train loss item: 0.12026022374629974
train loss item: 0.6659929156303406
train loss item: 0.1677320897579193
train loss item: 0.10894176363945007
train loss item: 0.4394310414791107
train loss item: 0.3823707699775696
train loss item: 0.8869583010673523
train loss item: 0.2836077809333801
test loss item: 0.1746119111776352
test loss item: 0.2904742360115051
test loss item: 0.27779680490493774
test loss item: 0.6217815279960632
test loss item: 0.21827837824821472
test loss item: 0.4182421863079071
test loss item: 0.15391410887241364
test loss item: 0.16428209841251373
test loss item: 0.25035661458969116
test loss item: 0.3168385922908783
test loss item: 0.32131320238113403
test loss item: 0.22838300466537476
test loss item: 0.18252380192279816
test loss item: 0.2624492645263672
test loss item: 0.2782309651374817
test loss item: 0.37127071619033813
test loss item: 0.32707923650741577
test loss item: 0.266091912984848
test loss item: 0.6065648198127747
test loss item: 0.3074501156806946
test loss item: 0.20776589214801788
test loss item: 0.18681807816028595
test loss item: 0.3325122892856598
test loss item: 0.22529590129852295
test loss item: 0.3359275162220001
test loss item: 0.17777742445468903
test loss item: 0.17283155024051666
test loss item: 0.40435221791267395
test loss item: 0.3282018303871155
test loss item: 0.18606719374656677
test loss item: 0.23077870905399323
test loss item: 0.1905394345521927
test loss item: 0.4621371924877167
test loss item: 0.22808708250522614
test loss item: 0.29805752635002136
test loss item: 0.41056519746780396
test loss item: 0.2756608724594116
test loss item: 0.16249322891235352
test loss item: 0.60407555103302
test loss item: 0.2646363079547882
test loss item: 0.42142489552497864
test loss item: 0.5253686308860779
test loss item: 0.17305231094360352
test loss item: 0.09823846071958542
test loss item: 0.1757839471101761
Epoch [10/100], Training Loss: 0.3745, Testing Loss: 0.2915
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 11/100
train loss item: 0.5090538263320923
train loss item: 0.35104063153266907
train loss item: 0.24812141060829163
train loss item: 0.2993793785572052
train loss item: 0.19638973474502563
train loss item: 0.23400002717971802
train loss item: 0.2966030240058899
train loss item: 0.35924094915390015
train loss item: 0.19811460375785828
train loss item: 0.24437835812568665
train loss item: 0.15830042958259583
train loss item: 0.4937646687030792
train loss item: 0.30417194962501526
train loss item: 0.15492942929267883
train loss item: 0.36012277007102966
train loss item: 0.8039988875389099
train loss item: 0.23905296623706818
train loss item: 0.5204182267189026
train loss item: 0.42611807584762573
train loss item: 0.3111506998538971
train loss item: 0.19234700500965118
train loss item: 0.2130441665649414
train loss item: 0.31809231638908386
train loss item: 0.270246684551239
train loss item: 0.1871163547039032
train loss item: 0.5888240933418274
train loss item: 0.13005606830120087
train loss item: 0.7731960415840149
train loss item: 0.18197236955165863
train loss item: 0.14865514636039734
train loss item: 0.7095639705657959
train loss item: 0.21381230652332306
train loss item: 0.2545054256916046
train loss item: 0.38835409283638
train loss item: 0.265991747379303
train loss item: 0.20231354236602783
train loss item: 0.21065843105316162
train loss item: 0.11060399562120438
train loss item: 0.6846239566802979
train loss item: 0.173256978392601
train loss item: 0.14015933871269226
train loss item: 0.349168598651886
train loss item: 0.32556670904159546
train loss item: 0.8882597088813782
train loss item: 0.27088218927383423
test loss item: 0.14921289682388306
test loss item: 0.2566078305244446
test loss item: 0.20347318053245544
test loss item: 0.49769407510757446
test loss item: 0.2248602956533432
test loss item: 0.3865453600883484
test loss item: 0.1671435683965683
test loss item: 0.1431688517332077
test loss item: 0.21862158179283142
test loss item: 0.27723032236099243
test loss item: 0.2853095531463623
test loss item: 0.1768113076686859
test loss item: 0.1611824929714203
test loss item: 0.2205784171819687
test loss item: 0.24435651302337646
test loss item: 0.34684696793556213
test loss item: 0.2906401455402374
test loss item: 0.2642839252948761
test loss item: 0.5392557978630066
test loss item: 0.25268110632896423
test loss item: 0.1648569107055664
test loss item: 0.172511026263237
test loss item: 0.2958371937274933
test loss item: 0.19021029770374298
test loss item: 0.33121001720428467
test loss item: 0.186856210231781
test loss item: 0.15709610283374786
test loss item: 0.3916498124599457
test loss item: 0.2832378149032593
test loss item: 0.1847943663597107
test loss item: 0.22749239206314087
test loss item: 0.1675032526254654
test loss item: 0.3741583228111267
test loss item: 0.2046373039484024
test loss item: 0.29381534457206726
test loss item: 0.3098662495613098
test loss item: 0.23787027597427368
test loss item: 0.1279405653476715
test loss item: 0.5216341018676758
test loss item: 0.1908154934644699
test loss item: 0.35995984077453613
test loss item: 0.47044533491134644
test loss item: 0.15669238567352295
test loss item: 0.08128450065851212
test loss item: 0.13526226580142975
Epoch [11/100], Training Loss: 0.3311, Testing Loss: 0.2561
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 12/100
train loss item: 0.5612934827804565
train loss item: 0.33331355452537537
train loss item: 0.23747316002845764
train loss item: 0.26403993368148804
train loss item: 0.19279825687408447
train loss item: 0.19548141956329346
train loss item: 0.2648826837539673
train loss item: 0.41137629747390747
train loss item: 0.17594176530838013
train loss item: 0.22727030515670776
train loss item: 0.1742788553237915
train loss item: 0.5038493871688843
train loss item: 0.2568811774253845
train loss item: 0.16646277904510498
train loss item: 0.3754558265209198
train loss item: 0.7553635239601135
train loss item: 0.28134021162986755
train loss item: 0.47366297245025635
train loss item: 0.4023948907852173
train loss item: 0.28965267539024353
train loss item: 0.1660323143005371
train loss item: 0.17356061935424805
train loss item: 0.27867212891578674
train loss item: 0.263728529214859
train loss item: 0.1696683019399643
train loss item: 0.5868104696273804
train loss item: 0.1596727818250656
train loss item: 0.627324640750885
train loss item: 0.17367057502269745
train loss item: 0.10390978306531906
train loss item: 0.7012280225753784
train loss item: 0.23368185758590698
train loss item: 0.23445722460746765
train loss item: 0.337884783744812
train loss item: 0.21387305855751038
train loss item: 0.17726841568946838
train loss item: 0.20956437289714813
train loss item: 0.07685552537441254
train loss item: 0.6760791540145874
train loss item: 0.1476159691810608
train loss item: 0.11522164195775986
train loss item: 0.3460381031036377
train loss item: 0.3378640413284302
train loss item: 0.8028486967086792
train loss item: 0.2391355037689209
test loss item: 0.13867177069187164
test loss item: 0.2523037791252136
test loss item: 0.19065351784229279
test loss item: 0.47639861702919006
test loss item: 0.2215953916311264
test loss item: 0.38773471117019653
test loss item: 0.13868942856788635
test loss item: 0.12314759939908981
test loss item: 0.22251355648040771
test loss item: 0.2651161551475525
test loss item: 0.2891664206981659
test loss item: 0.19188176095485687
test loss item: 0.15051504969596863
test loss item: 0.2141224890947342
test loss item: 0.2333277314901352
test loss item: 0.3376722037792206
test loss item: 0.28232118487358093
test loss item: 0.27767810225486755
test loss item: 0.5268176198005676
test loss item: 0.2428707331418991
test loss item: 0.1595124751329422
test loss item: 0.17897072434425354
test loss item: 0.29028552770614624
test loss item: 0.19991904497146606
test loss item: 0.33383190631866455
test loss item: 0.19306711852550507
test loss item: 0.15255580842494965
test loss item: 0.38133445382118225
test loss item: 0.2766694128513336
test loss item: 0.1670910269021988
test loss item: 0.2373051792383194
test loss item: 0.1445629745721817
test loss item: 0.35760003328323364
test loss item: 0.18706320226192474
test loss item: 0.26572945713996887
test loss item: 0.28511834144592285
test loss item: 0.24475695192813873
test loss item: 0.12776514887809753
test loss item: 0.48025447130203247
test loss item: 0.181905597448349
test loss item: 0.36306384205818176
test loss item: 0.47371554374694824
test loss item: 0.1637711524963379
test loss item: 0.07956971228122711
test loss item: 0.11988421529531479
Epoch [12/100], Training Loss: 0.3132, Testing Loss: 0.2491
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 13/100
train loss item: 0.43973031640052795
train loss item: 0.3008052408695221
train loss item: 0.23339571058750153
train loss item: 0.2543567717075348
train loss item: 0.1528652459383011
train loss item: 0.17548662424087524
train loss item: 0.24108180403709412
train loss item: 0.37779325246810913
train loss item: 0.15257249772548676
train loss item: 0.22368395328521729
train loss item: 0.16671006381511688
train loss item: 0.43999969959259033
train loss item: 0.22288337349891663
train loss item: 0.15149790048599243
train loss item: 0.29285821318626404
train loss item: 0.595860481262207
train loss item: 0.2170378565788269
train loss item: 0.45724010467529297
train loss item: 0.37502142786979675
train loss item: 0.19839473068714142
train loss item: 0.1334700882434845
train loss item: 0.1633448749780655
train loss item: 0.21175098419189453
train loss item: 0.2465486079454422
train loss item: 0.12564806640148163
train loss item: 0.5016105771064758
train loss item: 0.10035431385040283
train loss item: 0.5228247046470642
train loss item: 0.14378103613853455
train loss item: 0.10374908149242401
train loss item: 0.5779477953910828
train loss item: 0.18888473510742188
train loss item: 0.19590406119823456
train loss item: 0.27369141578674316
train loss item: 0.19807444512844086
train loss item: 0.13505053520202637
train loss item: 0.16551776230335236
train loss item: 0.07434417307376862
train loss item: 0.6217631101608276
train loss item: 0.136310875415802
train loss item: 0.1123112142086029
train loss item: 0.2681306004524231
train loss item: 0.3280218541622162
train loss item: 0.6450841426849365
train loss item: 0.23373769223690033
test loss item: 0.1385384500026703
test loss item: 0.2693776488304138
test loss item: 0.21107040345668793
test loss item: 0.47812619805336
test loss item: 0.2188384085893631
test loss item: 0.4102323353290558
test loss item: 0.12977467477321625
test loss item: 0.13215886056423187
test loss item: 0.21713568270206451
test loss item: 0.25352948904037476
test loss item: 0.26465553045272827
test loss item: 0.1752772182226181
test loss item: 0.15731720626354218
test loss item: 0.21866361796855927
test loss item: 0.24072633683681488
test loss item: 0.350315123796463
test loss item: 0.2798604667186737
test loss item: 0.26163360476493835
test loss item: 0.5659623742103577
test loss item: 0.2538549602031708
test loss item: 0.15999901294708252
test loss item: 0.16778020560741425
test loss item: 0.2721065878868103
test loss item: 0.1746741533279419
test loss item: 0.33785760402679443
test loss item: 0.17283301055431366
test loss item: 0.1627250611782074
test loss item: 0.39595967531204224
test loss item: 0.29038795828819275
test loss item: 0.1654100865125656
test loss item: 0.22809159755706787
test loss item: 0.15311776101589203
test loss item: 0.38009050488471985
test loss item: 0.1935688555240631
test loss item: 0.25443288683891296
test loss item: 0.2839519679546356
test loss item: 0.2229585498571396
test loss item: 0.12393723428249359
test loss item: 0.5715180039405823
test loss item: 0.19904571771621704
test loss item: 0.38792818784713745
test loss item: 0.5063430070877075
test loss item: 0.16411598026752472
test loss item: 0.07893825322389603
test loss item: 0.11871406435966492
Epoch [13/100], Training Loss: 0.2684, Testing Loss: 0.2532
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 14/100
train loss item: 0.4395250976085663
train loss item: 0.23313680291175842
train loss item: 0.1616157442331314
train loss item: 0.2071162611246109
train loss item: 0.1460505723953247
train loss item: 0.14612239599227905
train loss item: 0.18602165579795837
train loss item: 0.38452965021133423
train loss item: 0.13434407114982605
train loss item: 0.17575041949748993
train loss item: 0.11008619517087936
train loss item: 0.47734177112579346
train loss item: 0.201620951294899
train loss item: 0.12830594182014465
train loss item: 0.21110735833644867
train loss item: 0.6072250008583069
train loss item: 0.18342576920986176
train loss item: 0.40235912799835205
train loss item: 0.34635129570961
train loss item: 0.27454644441604614
train loss item: 0.17092882096767426
train loss item: 0.15994004905223846
train loss item: 0.22787103056907654
train loss item: 0.21787379682064056
train loss item: 0.14362090826034546
train loss item: 0.4968594014644623
train loss item: 0.14161017537117004
train loss item: 0.641291618347168
train loss item: 0.14512524008750916
train loss item: 0.11039630323648453
train loss item: 0.5454732179641724
train loss item: 0.17611607909202576
train loss item: 0.17661556601524353
train loss item: 0.2659645676612854
train loss item: 0.185890331864357
train loss item: 0.1315545290708542
train loss item: 0.16197596490383148
train loss item: 0.0763363167643547
train loss item: 0.5630121231079102
train loss item: 0.13451237976551056
train loss item: 0.10225073993206024
train loss item: 0.27083253860473633
train loss item: 0.2839112877845764
train loss item: 0.62379390001297
train loss item: 0.2303696572780609
test loss item: 0.12051181495189667
test loss item: 0.20249012112617493
test loss item: 0.15380749106407166
test loss item: 0.4225139319896698
test loss item: 0.18523730337619781
test loss item: 0.34084683656692505
test loss item: 0.11577524244785309
test loss item: 0.10226932913064957
test loss item: 0.17899447679519653
test loss item: 0.23346376419067383
test loss item: 0.21815088391304016
test loss item: 0.1418180912733078
test loss item: 0.12465643137693405
test loss item: 0.18303155899047852
test loss item: 0.19221439957618713
test loss item: 0.290037602186203
test loss item: 0.21259310841560364
test loss item: 0.22160159051418304
test loss item: 0.45308589935302734
test loss item: 0.1920965164899826
test loss item: 0.14939191937446594
test loss item: 0.14845089614391327
test loss item: 0.2243066132068634
test loss item: 0.1526058316230774
test loss item: 0.27749019861221313
test loss item: 0.144769549369812
test loss item: 0.13639791309833527
test loss item: 0.3129698634147644
test loss item: 0.22749248147010803
test loss item: 0.1377672702074051
test loss item: 0.18974687159061432
test loss item: 0.13662277162075043
test loss item: 0.30613943934440613
test loss item: 0.16444838047027588
test loss item: 0.20747368037700653
test loss item: 0.245261088013649
test loss item: 0.20182177424430847
test loss item: 0.10756296664476395
test loss item: 0.40217798948287964
test loss item: 0.15868200361728668
test loss item: 0.3327059745788574
test loss item: 0.4109557271003723
test loss item: 0.135737344622612
test loss item: 0.0703846737742424
test loss item: 0.13194602727890015
Epoch [14/100], Training Loss: 0.2565, Testing Loss: 0.2089
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 15/100
train loss item: 0.4473496973514557
train loss item: 0.2849873900413513
train loss item: 0.17205139994621277
train loss item: 0.1960453987121582
train loss item: 0.15445123612880707
train loss item: 0.12798786163330078
train loss item: 0.17840494215488434
train loss item: 0.3998340666294098
train loss item: 0.1250905990600586
train loss item: 0.22325655817985535
train loss item: 0.13783934712409973
train loss item: 0.4214281737804413
train loss item: 0.17396840453147888
train loss item: 0.15135514736175537
train loss item: 0.24482949078083038
train loss item: 0.5057079792022705
train loss item: 0.19120196998119354
train loss item: 0.35703223943710327
train loss item: 0.3176197409629822
train loss item: 0.22521841526031494
train loss item: 0.13039453327655792
train loss item: 0.18385227024555206
train loss item: 0.20121707022190094
train loss item: 0.223125159740448
train loss item: 0.13228055834770203
train loss item: 0.43792134523391724
train loss item: 0.09565510600805283
train loss item: 0.502269983291626
train loss item: 0.1194746270775795
train loss item: 0.08766429126262665
train loss item: 0.4406205117702484
train loss item: 0.1818591207265854
train loss item: 0.16643449664115906
train loss item: 0.25477033853530884
train loss item: 0.17933513224124908
train loss item: 0.15055598318576813
train loss item: 0.16775302588939667
train loss item: 0.06909896433353424
train loss item: 0.5318313241004944
train loss item: 0.10889363288879395
train loss item: 0.09635598212480545
train loss item: 0.2978500723838806
train loss item: 0.24714268743991852
train loss item: 0.5443159341812134
train loss item: 0.1999155730009079
test loss item: 0.11576223373413086
test loss item: 0.188496932387352
test loss item: 0.15116018056869507
test loss item: 0.4175903797149658
test loss item: 0.15300649404525757
test loss item: 0.2986255884170532
test loss item: 0.12212733179330826
test loss item: 0.09943341463804245
test loss item: 0.17122521996498108
test loss item: 0.23348475992679596
test loss item: 0.20722292363643646
test loss item: 0.14143408834934235
test loss item: 0.12130417674779892
test loss item: 0.16996701061725616
test loss item: 0.17886888980865479
test loss item: 0.25022897124290466
test loss item: 0.18668977916240692
test loss item: 0.1842668652534485
test loss item: 0.4090258777141571
test loss item: 0.18184839189052582
test loss item: 0.1502634435892105
test loss item: 0.130366250872612
test loss item: 0.2210206538438797
test loss item: 0.14915090799331665
test loss item: 0.24203522503376007
test loss item: 0.12979556620121002
test loss item: 0.12563274800777435
test loss item: 0.25573045015335083
test loss item: 0.23611117899417877
test loss item: 0.12670014798641205
test loss item: 0.17006315290927887
test loss item: 0.13324986398220062
test loss item: 0.2990144193172455
test loss item: 0.1718193143606186
test loss item: 0.1974257081747055
test loss item: 0.24891775846481323
test loss item: 0.2066410332918167
test loss item: 0.11200064420700073
test loss item: 0.3709549009799957
test loss item: 0.15402856469154358
test loss item: 0.2962190508842468
test loss item: 0.3643333911895752
test loss item: 0.13177458941936493
test loss item: 0.07435999810695648
test loss item: 0.11689499765634537
Epoch [15/100], Training Loss: 0.2397, Testing Loss: 0.1955
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 16/100
train loss item: 0.4862005412578583
train loss item: 0.24519160389900208
train loss item: 0.14294469356536865
train loss item: 0.16449013352394104
train loss item: 0.1693757027387619
train loss item: 0.15890030562877655
train loss item: 0.27299052476882935
train loss item: 0.350879967212677
train loss item: 0.09914366900920868
train loss item: 0.16231204569339752
train loss item: 0.11211328208446503
train loss item: 0.4888538420200348
train loss item: 0.20301106572151184
train loss item: 0.13793271780014038
train loss item: 0.21114450693130493
train loss item: 0.43621933460235596
train loss item: 0.18632325530052185
train loss item: 0.49608221650123596
train loss item: 0.3399370610713959
train loss item: 0.192945197224617
train loss item: 0.128157377243042
train loss item: 0.14680393040180206
train loss item: 0.21083688735961914
train loss item: 0.19594377279281616
train loss item: 0.08417064696550369
train loss item: 0.3518126606941223
train loss item: 0.09372419863939285
train loss item: 0.4874747693538666
train loss item: 0.159720316529274
train loss item: 0.07618997246026993
train loss item: 0.4084770083427429
train loss item: 0.2236996442079544
train loss item: 0.13657689094543457
train loss item: 0.20602940022945404
train loss item: 0.14922504127025604
train loss item: 0.11083853244781494
train loss item: 0.14633046090602875
train loss item: 0.07284213602542877
train loss item: 0.4413962662220001
train loss item: 0.12098291516304016
train loss item: 0.0898497924208641
train loss item: 0.24467703700065613
train loss item: 0.2206546813249588
train loss item: 0.5253838896751404
train loss item: 0.19355477392673492
test loss item: 0.0984320119023323
test loss item: 0.15959623456001282
test loss item: 0.0956725925207138
test loss item: 0.3662530183792114
test loss item: 0.12848123908042908
test loss item: 0.2546510100364685
test loss item: 0.10694728046655655
test loss item: 0.0778820589184761
test loss item: 0.15001080930233002
test loss item: 0.19367288053035736
test loss item: 0.20194828510284424
test loss item: 0.15102942287921906
test loss item: 0.10664978623390198
test loss item: 0.1348736435174942
test loss item: 0.14337153732776642
test loss item: 0.21785080432891846
test loss item: 0.16591057181358337
test loss item: 0.15638376772403717
test loss item: 0.32926496863365173
test loss item: 0.1560184806585312
test loss item: 0.15079817175865173
test loss item: 0.1249857172369957
test loss item: 0.20627261698246002
test loss item: 0.15687544643878937
test loss item: 0.21197055280208588
test loss item: 0.1036459356546402
test loss item: 0.11579649150371552
test loss item: 0.21073515713214874
test loss item: 0.20204883813858032
test loss item: 0.10795290023088455
test loss item: 0.14819355309009552
test loss item: 0.12165489047765732
test loss item: 0.24969616532325745
test loss item: 0.14976854622364044
test loss item: 0.18684886395931244
test loss item: 0.23295263946056366
test loss item: 0.20095299184322357
test loss item: 0.10799697786569595
test loss item: 0.31262731552124023
test loss item: 0.1199151873588562
test loss item: 0.2540546953678131
test loss item: 0.3036324679851532
test loss item: 0.12066303938627243
test loss item: 0.07098778337240219
test loss item: 0.11653827130794525
Epoch [16/100], Training Loss: 0.2285, Testing Loss: 0.1707
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 17/100
train loss item: 0.37034496665000916
train loss item: 0.21707920730113983
train loss item: 0.15602447092533112
train loss item: 0.15922783315181732
train loss item: 0.13295958936214447
train loss item: 0.15086781978607178
train loss item: 0.24839814007282257
train loss item: 0.28418856859207153
train loss item: 0.07565686106681824
train loss item: 0.15827009081840515
train loss item: 0.0902046412229538
train loss item: 0.4277222156524658
train loss item: 0.20213641226291656
train loss item: 0.1593836396932602
train loss item: 0.2475106120109558
train loss item: 0.37843188643455505
train loss item: 0.17730164527893066
train loss item: 0.3405708968639374
train loss item: 0.2462621033191681
train loss item: 0.21787749230861664
train loss item: 0.12809281051158905
train loss item: 0.13614942133426666
train loss item: 0.2306441068649292
train loss item: 0.19491884112358093
train loss item: 0.08515796810388565
train loss item: 0.33200860023498535
train loss item: 0.0742477998137474
train loss item: 0.5466064810752869
train loss item: 0.12226937711238861
train loss item: 0.08948814123868942
train loss item: 0.3554047644138336
train loss item: 0.2195892333984375
train loss item: 0.14490635693073273
train loss item: 0.21740324795246124
train loss item: 0.14713571965694427
train loss item: 0.09923546016216278
train loss item: 0.1250677853822708
train loss item: 0.05866190418601036
train loss item: 0.4353015720844269
train loss item: 0.10259362310171127
train loss item: 0.08894208073616028
train loss item: 0.2662218511104584
train loss item: 0.24217146635055542
train loss item: 0.5111739635467529
train loss item: 0.16180351376533508
test loss item: 0.08402159810066223
test loss item: 0.14319759607315063
test loss item: 0.08650665730237961
test loss item: 0.34466052055358887
test loss item: 0.11156921833753586
test loss item: 0.22767508029937744
test loss item: 0.09850004315376282
test loss item: 0.06323715299367905
test loss item: 0.1352178454399109
test loss item: 0.18586473166942596
test loss item: 0.16787388920783997
test loss item: 0.11692260950803757
test loss item: 0.10034467279911041
test loss item: 0.11946168541908264
test loss item: 0.13090549409389496
test loss item: 0.20488063991069794
test loss item: 0.1330849677324295
test loss item: 0.15365423262119293
test loss item: 0.2970166802406311
test loss item: 0.1364913284778595
test loss item: 0.12778526544570923
test loss item: 0.1113291010260582
test loss item: 0.1791844666004181
test loss item: 0.12912043929100037
test loss item: 0.19344601035118103
test loss item: 0.09129736572504044
test loss item: 0.10927915573120117
test loss item: 0.17515020072460175
test loss item: 0.18508605659008026
test loss item: 0.10002000629901886
test loss item: 0.13513176143169403
test loss item: 0.10679318755865097
test loss item: 0.22404594719409943
test loss item: 0.13937167823314667
test loss item: 0.16593901813030243
test loss item: 0.21988588571548462
test loss item: 0.19503794610500336
test loss item: 0.09565264731645584
test loss item: 0.27127018570899963
test loss item: 0.10563775151968002
test loss item: 0.22609153389930725
test loss item: 0.27027854323387146
test loss item: 0.11853816360235214
test loss item: 0.046133894473314285
test loss item: 0.09667657315731049
Epoch [17/100], Training Loss: 0.2123, Testing Loss: 0.1524
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 18/100
train loss item: 0.4131876230239868
train loss item: 0.19649681448936462
train loss item: 0.11617258191108704
train loss item: 0.14811448752880096
train loss item: 0.12575221061706543
train loss item: 0.11697851866483688
train loss item: 0.2627967894077301
train loss item: 0.26208940148353577
train loss item: 0.06741451472043991
train loss item: 0.15476001799106598
train loss item: 0.07256029546260834
train loss item: 0.5077457427978516
train loss item: 0.1895025223493576
train loss item: 0.1540641039609909
train loss item: 0.18360991775989532
train loss item: 0.4597327709197998
train loss item: 0.15289908647537231
train loss item: 0.5216173529624939
train loss item: 0.3763705790042877
train loss item: 0.21358783543109894
train loss item: 0.13569606840610504
train loss item: 0.14131039381027222
train loss item: 0.20698536932468414
train loss item: 0.1675325185060501
train loss item: 0.11259616911411285
train loss item: 0.2960399389266968
train loss item: 0.07507602870464325
train loss item: 0.5186803936958313
train loss item: 0.10846962034702301
train loss item: 0.06349291652441025
train loss item: 0.3910074234008789
train loss item: 0.1965496689081192
train loss item: 0.13651959598064423
train loss item: 0.24679456651210785
train loss item: 0.1976916491985321
train loss item: 0.12222856283187866
train loss item: 0.13621872663497925
train loss item: 0.06005537137389183
train loss item: 0.4710967242717743
train loss item: 0.11213409900665283
train loss item: 0.10596960037946701
train loss item: 0.25742682814598083
train loss item: 0.2541140615940094
train loss item: 0.6000689268112183
train loss item: 0.1687314808368683
test loss item: 0.10745367407798767
test loss item: 0.17101073265075684
test loss item: 0.16276170313358307
test loss item: 0.4623268246650696
test loss item: 0.15302205085754395
test loss item: 0.2909126877784729
test loss item: 0.11128631234169006
test loss item: 0.10789712518453598
test loss item: 0.14541085064411163
test loss item: 0.22556161880493164
test loss item: 0.1659516543149948
test loss item: 0.12638409435749054
test loss item: 0.11589346826076508
test loss item: 0.16854071617126465
test loss item: 0.17827534675598145
test loss item: 0.2853192687034607
test loss item: 0.1625080704689026
test loss item: 0.2124689370393753
test loss item: 0.41210153698921204
test loss item: 0.17688032984733582
test loss item: 0.11998230218887329
test loss item: 0.11612600088119507
test loss item: 0.1787835955619812
test loss item: 0.1245754137635231
test loss item: 0.24347145855426788
test loss item: 0.14414982497692108
test loss item: 0.1296101212501526
test loss item: 0.26724907755851746
test loss item: 0.2489382028579712
test loss item: 0.1323968470096588
test loss item: 0.15739138424396515
test loss item: 0.11191822588443756
test loss item: 0.25898829102516174
test loss item: 0.1332104206085205
test loss item: 0.2049836814403534
test loss item: 0.27864569425582886
test loss item: 0.13854022324085236
test loss item: 0.09764589369297028
test loss item: 0.34220224618911743
test loss item: 0.15130040049552917
test loss item: 0.3053869605064392
test loss item: 0.37768521904945374
test loss item: 0.12904532253742218
test loss item: 0.06906667351722717
test loss item: 0.10136716067790985
Epoch [18/100], Training Loss: 0.2217, Testing Loss: 0.1890
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 19/100
train loss item: 0.5268347859382629
train loss item: 0.23046715557575226
train loss item: 0.13067997992038727
train loss item: 0.35319390892982483
train loss item: 0.07416249066591263
train loss item: 0.09894059598445892
train loss item: 0.20944276452064514
train loss item: 0.3235633075237274
train loss item: 0.07355586439371109
train loss item: 0.16955971717834473
train loss item: 0.0721701830625534
train loss item: 0.5626177787780762
train loss item: 0.18859979510307312
train loss item: 0.19860947132110596
train loss item: 0.2198614478111267
train loss item: 0.42292502522468567
train loss item: 0.18317250907421112
train loss item: 0.4048028886318207
train loss item: 0.3182463049888611
train loss item: 0.193141907453537
train loss item: 0.14948409795761108
train loss item: 0.10123103111982346
train loss item: 0.19654710590839386
train loss item: 0.18129003047943115
train loss item: 0.10530328005552292
train loss item: 0.37005168199539185
train loss item: 0.07519851624965668
train loss item: 0.5883358120918274
train loss item: 0.12524515390396118
train loss item: 0.06564273685216904
train loss item: 0.42073291540145874
train loss item: 0.15574146807193756
train loss item: 0.11407806724309921
train loss item: 0.18278372287750244
train loss item: 0.17939478158950806
train loss item: 0.1462712436914444
train loss item: 0.20260199904441833
train loss item: 0.07240071892738342
train loss item: 0.38078343868255615
train loss item: 0.09747727960348129
train loss item: 0.0798153355717659
train loss item: 0.2782551348209381
train loss item: 0.22780825197696686
train loss item: 0.5470765233039856
train loss item: 0.13762925565242767
test loss item: 0.14625513553619385
test loss item: 0.2162541002035141
test loss item: 0.1554836928844452
test loss item: 0.40378260612487793
test loss item: 0.17886841297149658
test loss item: 0.3291785717010498
test loss item: 0.11881344765424728
test loss item: 0.14289934933185577
test loss item: 0.15782301127910614
test loss item: 0.19198159873485565
test loss item: 0.18899662792682648
test loss item: 0.13279370963573456
test loss item: 0.11673618108034134
test loss item: 0.18283754587173462
test loss item: 0.1837678849697113
test loss item: 0.30215343832969666
test loss item: 0.1944923847913742
test loss item: 0.19931216537952423
test loss item: 0.4161383807659149
test loss item: 0.2047179788351059
test loss item: 0.14137616753578186
test loss item: 0.13573938608169556
test loss item: 0.21103593707084656
test loss item: 0.11622187495231628
test loss item: 0.2629091143608093
test loss item: 0.15381018817424774
test loss item: 0.1318439394235611
test loss item: 0.29021328687667847
test loss item: 0.21715272963047028
test loss item: 0.13437767326831818
test loss item: 0.1798890233039856
test loss item: 0.11927901953458786
test loss item: 0.30158287286758423
test loss item: 0.14850926399230957
test loss item: 0.1983896791934967
test loss item: 0.2719476819038391
test loss item: 0.1954273134469986
test loss item: 0.09853465110063553
test loss item: 0.4563370645046234
test loss item: 0.14891038835048676
test loss item: 0.30865952372550964
test loss item: 0.390845388174057
test loss item: 0.12050633877515793
test loss item: 0.13825197517871857
test loss item: 0.11271167546510696
Epoch [19/100], Training Loss: 0.2252, Testing Loss: 0.2033
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 20/100
train loss item: 0.33580920100212097
train loss item: 0.16271992027759552
train loss item: 0.11969691514968872
train loss item: 0.2250501662492752
train loss item: 0.08876406401395798
train loss item: 0.1074550598859787
train loss item: 0.2060711681842804
train loss item: 0.20607900619506836
train loss item: 0.07378502935171127
train loss item: 0.16273893415927887
train loss item: 0.09213521331548691
train loss item: 0.38333022594451904
train loss item: 0.15703697502613068
train loss item: 0.1495945155620575
train loss item: 0.22477193176746368
train loss item: 0.44110167026519775
train loss item: 0.17960906028747559
train loss item: 0.32102203369140625
train loss item: 0.1939685195684433
train loss item: 0.17672280967235565
train loss item: 0.11903221905231476
train loss item: 0.10939960181713104
train loss item: 0.1587107926607132
train loss item: 0.18440808355808258
train loss item: 0.1194743737578392
train loss item: 0.37470096349716187
train loss item: 0.06938096135854721
train loss item: 0.4247996509075165
train loss item: 0.10628112405538559
train loss item: 0.07874079793691635
train loss item: 0.39609554409980774
train loss item: 0.11310917884111404
train loss item: 0.10281815379858017
train loss item: 0.19976474344730377
train loss item: 0.12983372807502747
train loss item: 0.0907285138964653
train loss item: 0.11811263114213943
train loss item: 0.064681775867939
train loss item: 0.3941880166530609
train loss item: 0.11385231465101242
train loss item: 0.09539308398962021
train loss item: 0.243781179189682
train loss item: 0.20232412219047546
train loss item: 0.5237135291099548
train loss item: 0.12594647705554962
test loss item: 0.07747901231050491
test loss item: 0.15592901408672333
test loss item: 0.10536070168018341
test loss item: 0.3895344138145447
test loss item: 0.12964163720607758
test loss item: 0.2416478991508484
test loss item: 0.10443267971277237
test loss item: 0.07159756869077682
test loss item: 0.1370934396982193
test loss item: 0.18352234363555908
test loss item: 0.17378680408000946
test loss item: 0.11338072270154953
test loss item: 0.09932984411716461
test loss item: 0.12547287344932556
test loss item: 0.1431981474161148
test loss item: 0.25099897384643555
test loss item: 0.14940111339092255
test loss item: 0.16483736038208008
test loss item: 0.3395976126194
test loss item: 0.15645374357700348
test loss item: 0.11547891795635223
test loss item: 0.11202666163444519
test loss item: 0.18215130269527435
test loss item: 0.11543021351099014
test loss item: 0.21474245190620422
test loss item: 0.11746352165937424
test loss item: 0.10852202028036118
test loss item: 0.21724985539913177
test loss item: 0.1848115175962448
test loss item: 0.11144538223743439
test loss item: 0.14072459936141968
test loss item: 0.10397054255008698
test loss item: 0.22831951081752777
test loss item: 0.1320079267024994
test loss item: 0.16138194501399994
test loss item: 0.2456810027360916
test loss item: 0.1941802054643631
test loss item: 0.08070971816778183
test loss item: 0.341762900352478
test loss item: 0.10945650190114975
test loss item: 0.24322886765003204
test loss item: 0.3007289171218872
test loss item: 0.11575400084257126
test loss item: 0.04715472087264061
test loss item: 0.09815551340579987
Epoch [20/100], Training Loss: 0.1926, Testing Loss: 0.1630
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 21/100
train loss item: 0.2847133278846741
train loss item: 0.14228132367134094
train loss item: 0.09927806258201599
train loss item: 0.11400195956230164
train loss item: 0.0698474571108818
train loss item: 0.12406028807163239
train loss item: 0.14776566624641418
train loss item: 0.1982918530702591
train loss item: 0.06786338239908218
train loss item: 0.12311048060655594
train loss item: 0.082247294485569
train loss item: 0.33388444781303406
train loss item: 0.14152351021766663
train loss item: 0.1435633897781372
train loss item: 0.1786048859357834
train loss item: 0.4315113425254822
train loss item: 0.17032639682292938
train loss item: 0.3187561631202698
train loss item: 0.34601572155952454
train loss item: 0.2148754745721817
train loss item: 0.12343543022871017
train loss item: 0.11257035285234451
train loss item: 0.19064688682556152
train loss item: 0.18035675585269928
train loss item: 0.11356097459793091
train loss item: 0.36972278356552124
train loss item: 0.09580026566982269
train loss item: 0.47540777921676636
train loss item: 0.1014593169093132
train loss item: 0.0803542286157608
train loss item: 0.40138232707977295
train loss item: 0.13271464407444
train loss item: 0.10003189742565155
train loss item: 0.22929397225379944
train loss item: 0.15789750218391418
train loss item: 0.13898591697216034
train loss item: 0.14142437279224396
train loss item: 0.056908681988716125
train loss item: 0.33203160762786865
train loss item: 0.1282607913017273
train loss item: 0.08942756801843643
train loss item: 0.24515898525714874
train loss item: 0.2171052098274231
train loss item: 0.4842361509799957
train loss item: 0.15191996097564697
test loss item: 0.09378966689109802
test loss item: 0.18432340025901794
test loss item: 0.1450103372335434
test loss item: 0.3017141819000244
test loss item: 0.17785637080669403
test loss item: 0.2898845076560974
test loss item: 0.12363667786121368
test loss item: 0.09552999585866928
test loss item: 0.16485315561294556
test loss item: 0.17776885628700256
test loss item: 0.1912623941898346
test loss item: 0.12624748051166534
test loss item: 0.11535382270812988
test loss item: 0.1632809191942215
test loss item: 0.18179062008857727
test loss item: 0.27128997445106506
test loss item: 0.191314697265625
test loss item: 0.21986812353134155
test loss item: 0.36151981353759766
test loss item: 0.18186740577220917
test loss item: 0.11414657533168793
test loss item: 0.14466539025306702
test loss item: 0.2047228068113327
test loss item: 0.14600254595279694
test loss item: 0.2572680413722992
test loss item: 0.17727500200271606
test loss item: 0.1340387761592865
test loss item: 0.29450228810310364
test loss item: 0.17546190321445465
test loss item: 0.14960795640945435
test loss item: 0.19198216497898102
test loss item: 0.1102517619729042
test loss item: 0.22853560745716095
test loss item: 0.1420297473669052
test loss item: 0.18330174684524536
test loss item: 0.17456549406051636
test loss item: 0.177039235830307
test loss item: 0.09614209830760956
test loss item: 0.3522588014602661
test loss item: 0.13487225770950317
test loss item: 0.2546488344669342
test loss item: 0.34938791394233704
test loss item: 0.13363581895828247
test loss item: 0.05783875286579132
test loss item: 0.10004711151123047
Epoch [21/100], Training Loss: 0.1907, Testing Loss: 0.1832
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 22/100
train loss item: 0.2957388460636139
train loss item: 0.17613224685192108
train loss item: 0.1221921294927597
train loss item: 0.13510629534721375
train loss item: 0.073428213596344
train loss item: 0.1449042558670044
train loss item: 0.11692921817302704
train loss item: 0.1798023134469986
train loss item: 0.07437983900308609
train loss item: 0.12571997940540314
train loss item: 0.10584469884634018
train loss item: 0.28827598690986633
train loss item: 0.14283224940299988
train loss item: 0.14457175135612488
train loss item: 0.16956673562526703
train loss item: 0.3501628637313843
train loss item: 0.17317143082618713
train loss item: 0.4056136906147003
train loss item: 0.30880677700042725
train loss item: 0.17237508296966553
train loss item: 0.09889671951532364
train loss item: 0.10293573886156082
train loss item: 0.15879161655902863
train loss item: 0.16416038572788239
train loss item: 0.08043985813856125
train loss item: 0.3168157935142517
train loss item: 0.05796445161104202
train loss item: 0.4369381368160248
train loss item: 0.08630603551864624
train loss item: 0.06253732740879059
train loss item: 0.32342520356178284
train loss item: 0.10909318923950195
train loss item: 0.09591563791036606
train loss item: 0.18199290335178375
train loss item: 0.1282104253768921
train loss item: 0.09948283433914185
train loss item: 0.12193476408720016
train loss item: 0.05068908631801605
train loss item: 0.3060027062892914
train loss item: 0.1240634098649025
train loss item: 0.06919953227043152
train loss item: 0.20263560116291046
train loss item: 0.18317469954490662
train loss item: 0.47303763031959534
train loss item: 0.14151456952095032
test loss item: 0.10417298227548599
test loss item: 0.14878953993320465
test loss item: 0.10750523954629898
test loss item: 0.3433934152126312
test loss item: 0.13479551672935486
test loss item: 0.25197818875312805
test loss item: 0.0965920239686966
test loss item: 0.09454146027565002
test loss item: 0.14641137421131134
test loss item: 0.1733483076095581
test loss item: 0.17077577114105225
test loss item: 0.12192003428936005
test loss item: 0.10525701195001602
test loss item: 0.14147867262363434
test loss item: 0.1436389535665512
test loss item: 0.24915170669555664
test loss item: 0.1514706164598465
test loss item: 0.16121268272399902
test loss item: 0.3120366632938385
test loss item: 0.15818558633327484
test loss item: 0.1294625848531723
test loss item: 0.12924343347549438
test loss item: 0.1867874264717102
test loss item: 0.1253882497549057
test loss item: 0.20719076693058014
test loss item: 0.12224166095256805
test loss item: 0.12186181545257568
test loss item: 0.2227904200553894
test loss item: 0.17302751541137695
test loss item: 0.11201221495866776
test loss item: 0.1546175628900528
test loss item: 0.10389408469200134
test loss item: 0.21662577986717224
test loss item: 0.13605444133281708
test loss item: 0.16302432119846344
test loss item: 0.22030119597911835
test loss item: 0.19303961098194122
test loss item: 0.09775569289922714
test loss item: 0.3138308823108673
test loss item: 0.1162278950214386
test loss item: 0.24637936055660248
test loss item: 0.2993190586566925
test loss item: 0.12023838609457016
test loss item: 0.10260450094938278
test loss item: 0.1022413820028305
Epoch [22/100], Training Loss: 0.1751, Testing Loss: 0.1652
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 23/100
train loss item: 0.23198626935482025
train loss item: 0.15430298447608948
train loss item: 0.1380092203617096
train loss item: 0.12443653494119644
train loss item: 0.0915137305855751
train loss item: 0.11094751209020615
train loss item: 0.12739379703998566
train loss item: 0.14458750188350677
train loss item: 0.07138656079769135
train loss item: 0.16248154640197754
train loss item: 0.1143098771572113
train loss item: 0.25942179560661316
train loss item: 0.15837453305721283
train loss item: 0.10851319879293442
train loss item: 0.15967907011508942
train loss item: 0.2915806174278259
train loss item: 0.163530170917511
train loss item: 0.28071048855781555
train loss item: 0.22989881038665771
train loss item: 0.24236170947551727
train loss item: 0.14498385787010193
train loss item: 0.11936818063259125
train loss item: 0.24825556576251984
train loss item: 0.14407433569431305
train loss item: 0.10403356701135635
train loss item: 0.35095229744911194
train loss item: 0.10246411710977554
train loss item: 0.5253363847732544
train loss item: 0.11811936646699905
train loss item: 0.1165269985795021
train loss item: 0.35911038517951965
train loss item: 0.12122988700866699
train loss item: 0.11513695865869522
train loss item: 0.19892117381095886
train loss item: 0.1269310861825943
train loss item: 0.12729278206825256
train loss item: 0.14757925271987915
train loss item: 0.06189142167568207
train loss item: 0.347577303647995
train loss item: 0.14597856998443604
train loss item: 0.0756203904747963
train loss item: 0.1773308515548706
train loss item: 0.21634431183338165
train loss item: 0.4765525460243225
train loss item: 0.13954344391822815
test loss item: 0.08046477288007736
test loss item: 0.14383473992347717
test loss item: 0.09315120428800583
test loss item: 0.3252885043621063
test loss item: 0.13703574240207672
test loss item: 0.2571128010749817
test loss item: 0.11015878617763519
test loss item: 0.07287298142910004
test loss item: 0.13776883482933044
test loss item: 0.18329231441020966
test loss item: 0.15876607596874237
test loss item: 0.10343533754348755
test loss item: 0.09563763439655304
test loss item: 0.13442616164684296
test loss item: 0.14165347814559937
test loss item: 0.2470041811466217
test loss item: 0.13545726239681244
test loss item: 0.1795823723077774
test loss item: 0.3051334321498871
test loss item: 0.1396382749080658
test loss item: 0.12331953644752502
test loss item: 0.12335747480392456
test loss item: 0.17835043370723724
test loss item: 0.1264466792345047
test loss item: 0.21741797029972076
test loss item: 0.1299874633550644
test loss item: 0.1116613894701004
test loss item: 0.23962613940238953
test loss item: 0.1646125316619873
test loss item: 0.11832503974437714
test loss item: 0.15524528920650482
test loss item: 0.10665684193372726
test loss item: 0.21351999044418335
test loss item: 0.1347106397151947
test loss item: 0.16070741415023804
test loss item: 0.207781583070755
test loss item: 0.18849068880081177
test loss item: 0.09060157090425491
test loss item: 0.2917085886001587
test loss item: 0.10189926624298096
test loss item: 0.255786657333374
test loss item: 0.30759599804878235
test loss item: 0.1158207580447197
test loss item: 0.054561395198106766
test loss item: 0.135880246758461
Epoch [23/100], Training Loss: 0.1817, Testing Loss: 0.1608
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 24/100
train loss item: 0.312404602766037
train loss item: 0.17357699573040009
train loss item: 0.13178236782550812
train loss item: 0.1323474645614624
train loss item: 0.08995227515697479
train loss item: 0.1264980286359787
train loss item: 0.1411179155111313
train loss item: 0.15305069088935852
train loss item: 0.06604734808206558
train loss item: 0.14111600816249847
train loss item: 0.10238121449947357
train loss item: 0.2374737709760666
train loss item: 0.14423450827598572
train loss item: 0.10369008034467697
train loss item: 0.1430073082447052
train loss item: 0.32108035683631897
train loss item: 0.1493026465177536
train loss item: 0.3343174159526825
train loss item: 0.2763000726699829
train loss item: 0.211666539311409
train loss item: 0.1288614571094513
train loss item: 0.11136353015899658
train loss item: 0.18753859400749207
train loss item: 0.14704740047454834
train loss item: 0.09527196735143661
train loss item: 0.28465786576271057
train loss item: 0.09906919300556183
train loss item: 0.37230613827705383
train loss item: 0.09014587104320526
train loss item: 0.08560448884963989
train loss item: 0.28756070137023926
train loss item: 0.12109394371509552
train loss item: 0.10365737229585648
train loss item: 0.16192428767681122
train loss item: 0.10869400948286057
train loss item: 0.09219972789287567
train loss item: 0.10824710875749588
train loss item: 0.05042055621743202
train loss item: 0.2656930088996887
train loss item: 0.1291906088590622
train loss item: 0.07402081042528152
train loss item: 0.18158385157585144
train loss item: 0.1966620832681656
train loss item: 0.35772979259490967
train loss item: 0.14277313649654388
test loss item: 0.08260063827037811
test loss item: 0.12308110296726227
test loss item: 0.07303083688020706
test loss item: 0.3156610131263733
test loss item: 0.09499509632587433
test loss item: 0.18661130964756012
test loss item: 0.0908583402633667
test loss item: 0.064661905169487
test loss item: 0.1268533617258072
test loss item: 0.18266014754772186
test loss item: 0.14301900565624237
test loss item: 0.11373745650053024
test loss item: 0.09147358685731888
test loss item: 0.11644011735916138
test loss item: 0.12050427496433258
test loss item: 0.1670701652765274
test loss item: 0.10996728390455246
test loss item: 0.11428187787532806
test loss item: 0.24607396125793457
test loss item: 0.12759079039096832
test loss item: 0.13021154701709747
test loss item: 0.10292787104845047
test loss item: 0.1724153459072113
test loss item: 0.12633773684501648
test loss item: 0.15093646943569183
test loss item: 0.08448506146669388
test loss item: 0.09682375192642212
test loss item: 0.13456293940544128
test loss item: 0.163759246468544
test loss item: 0.08982238173484802
test loss item: 0.11738521605730057
test loss item: 0.1101396232843399
test loss item: 0.2143079787492752
test loss item: 0.13635312020778656
test loss item: 0.13078780472278595
test loss item: 0.21482141315937042
test loss item: 0.19632865488529205
test loss item: 0.09039109945297241
test loss item: 0.21582944691181183
test loss item: 0.10246367007493973
test loss item: 0.20078295469284058
test loss item: 0.2155531942844391
test loss item: 0.1069493442773819
test loss item: 0.06024976819753647
test loss item: 0.12286105006933212
Epoch [24/100], Training Loss: 0.1661, Testing Loss: 0.1373
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 25/100
train loss item: 0.3262295722961426
train loss item: 0.21741409599781036
train loss item: 0.15714678168296814
train loss item: 0.14919884502887726
train loss item: 0.08095654845237732
train loss item: 0.11209423094987869
train loss item: 0.13612930476665497
train loss item: 0.14103524386882782
train loss item: 0.05733901262283325
train loss item: 0.15453143417835236
train loss item: 0.09004541486501694
train loss item: 0.2329890877008438
train loss item: 0.13153506815433502
train loss item: 0.09656306356191635
train loss item: 0.13765312731266022
train loss item: 0.2372536063194275
train loss item: 0.10393036156892776
train loss item: 0.3660581409931183
train loss item: 0.2057029753923416
train loss item: 0.19294258952140808
train loss item: 0.09607943892478943
train loss item: 0.11607351154088974
train loss item: 0.14470534026622772
train loss item: 0.12110566347837448
train loss item: 0.09113448858261108
train loss item: 0.31181037425994873
train loss item: 0.05849494785070419
train loss item: 0.5467621088027954
train loss item: 0.10271608829498291
train loss item: 0.08604291081428528
train loss item: 0.3096058964729309
train loss item: 0.14668314158916473
train loss item: 0.10925763845443726
train loss item: 0.19697073101997375
train loss item: 0.12825927138328552
train loss item: 0.10647229105234146
train loss item: 0.15723057091236115
train loss item: 0.06604363769292831
train loss item: 0.2951571047306061
train loss item: 0.10854280740022659
train loss item: 0.09331368654966354
train loss item: 0.22746247053146362
train loss item: 0.21028394997119904
train loss item: 0.4240959584712982
train loss item: 0.14148631691932678
test loss item: 0.10198529809713364
test loss item: 0.13636597990989685
test loss item: 0.14228995144367218
test loss item: 0.20648644864559174
test loss item: 0.13377653062343597
test loss item: 0.20269915461540222
test loss item: 0.13376881182193756
test loss item: 0.11743395030498505
test loss item: 0.11043966561555862
test loss item: 0.1444881707429886
test loss item: 0.12750019133090973
test loss item: 0.11033184081315994
test loss item: 0.09540136903524399
test loss item: 0.1422470659017563
test loss item: 0.14969439804553986
test loss item: 0.19198542833328247
test loss item: 0.13750885426998138
test loss item: 0.14815019071102142
test loss item: 0.23966051638126373
test loss item: 0.13936088979244232
test loss item: 0.0930708795785904
test loss item: 0.10190896689891815
test loss item: 0.1493498831987381
test loss item: 0.10833623260259628
test loss item: 0.17710813879966736
test loss item: 0.13454477488994598
test loss item: 0.10217969119548798
test loss item: 0.21138472855091095
test loss item: 0.13641993701457977
test loss item: 0.1329645961523056
test loss item: 0.13049183785915375
test loss item: 0.10784147679805756
test loss item: 0.17071571946144104
test loss item: 0.12701210379600525
test loss item: 0.14967882633209229
test loss item: 0.14312775433063507
test loss item: 0.13376107811927795
test loss item: 0.08892465382814407
test loss item: 0.2410082370042801
test loss item: 0.12177658826112747
test loss item: 0.17092910408973694
test loss item: 0.22503012418746948
test loss item: 0.1046038269996643
test loss item: 0.06396700441837311
test loss item: 0.10675463825464249
Epoch [25/100], Training Loss: 0.1716, Testing Loss: 0.1410
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 26/100
train loss item: 0.3177756667137146
train loss item: 0.16971325874328613
train loss item: 0.11429527401924133
train loss item: 0.2156079113483429
train loss item: 0.1032991111278534
train loss item: 0.13401158154010773
train loss item: 0.19764217734336853
train loss item: 0.17721156775951385
train loss item: 0.05443963780999184
train loss item: 0.12430679798126221
train loss item: 0.07607073336839676
train loss item: 0.26764920353889465
train loss item: 0.16255679726600647
train loss item: 0.11250375956296921
train loss item: 0.20012825727462769
train loss item: 0.2846084237098694
train loss item: 0.14134185016155243
train loss item: 0.33376508951187134
train loss item: 0.3633701503276825
train loss item: 0.22529873251914978
train loss item: 0.1283939629793167
train loss item: 0.08891500532627106
train loss item: 0.18267475068569183
train loss item: 0.1129826083779335
train loss item: 0.09337896853685379
train loss item: 0.2723035514354706
train loss item: 0.06028621643781662
train loss item: 0.39332595467567444
train loss item: 0.09206090867519379
train loss item: 0.07657496631145477
train loss item: 0.3417630195617676
train loss item: 0.17302854359149933
train loss item: 0.12769196927547455
train loss item: 0.202053502202034
train loss item: 0.15611448884010315
train loss item: 0.12689360976219177
train loss item: 0.21902264654636383
train loss item: 0.05663427710533142
train loss item: 0.24465440213680267
train loss item: 0.11414998024702072
train loss item: 0.06765013188123703
train loss item: 0.18254046142101288
train loss item: 0.2043357640504837
train loss item: 0.4462670385837555
train loss item: 0.13356100022792816
test loss item: 0.09435134381055832
test loss item: 0.1605103611946106
test loss item: 0.10841312259435654
test loss item: 0.38865864276885986
test loss item: 0.12363693863153458
test loss item: 0.26927128434181213
test loss item: 0.10723242163658142
test loss item: 0.07769069820642471
test loss item: 0.1487237811088562
test loss item: 0.19643500447273254
test loss item: 0.17157334089279175
test loss item: 0.1258864402770996
test loss item: 0.10118085145950317
test loss item: 0.1372060328722
test loss item: 0.14842037856578827
test loss item: 0.25592243671417236
test loss item: 0.15543526411056519
test loss item: 0.15097424387931824
test loss item: 0.35054078698158264
test loss item: 0.15675115585327148
test loss item: 0.1394449770450592
test loss item: 0.11802638322114944
test loss item: 0.2025315761566162
test loss item: 0.1448500156402588
test loss item: 0.21022363007068634
test loss item: 0.1098267063498497
test loss item: 0.113383948802948
test loss item: 0.2196367084980011
test loss item: 0.18595552444458008
test loss item: 0.11154644191265106
test loss item: 0.14772814512252808
test loss item: 0.12063942849636078
test loss item: 0.25349146127700806
test loss item: 0.14528319239616394
test loss item: 0.17994743585586548
test loss item: 0.26144707202911377
test loss item: 0.199778750538826
test loss item: 0.10722047835588455
test loss item: 0.39896708726882935
test loss item: 0.13003739714622498
test loss item: 0.28174251317977905
test loss item: 0.33581724762916565
test loss item: 0.11645063757896423
test loss item: 0.06108449026942253
test loss item: 0.11709097027778625
Epoch [26/100], Training Loss: 0.1794, Testing Loss: 0.1742
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 27/100
train loss item: 0.22996868193149567
train loss item: 0.14246569573879242
train loss item: 0.17041969299316406
train loss item: 0.22915023565292358
train loss item: 0.08584538847208023
train loss item: 0.11158604919910431
train loss item: 0.2469644695520401
train loss item: 0.18424682319164276
train loss item: 0.07297114282846451
train loss item: 0.1712714582681656
train loss item: 0.10856088995933533
train loss item: 0.41071078181266785
train loss item: 0.18646612763404846
train loss item: 0.13571703433990479
train loss item: 0.17254677414894104
train loss item: 0.268621563911438
train loss item: 0.13780543208122253
train loss item: 0.311106413602829
train loss item: 0.3359977602958679
train loss item: 0.1609489917755127
train loss item: 0.13201668858528137
train loss item: 0.0898866206407547
train loss item: 0.16572941839694977
train loss item: 0.14078910648822784
train loss item: 0.07354752719402313
train loss item: 0.28679990768432617
train loss item: 0.0526641346514225
train loss item: 0.421090692281723
train loss item: 0.10720536857843399
train loss item: 0.06859400123357773
train loss item: 0.27544865012168884
train loss item: 0.13170993328094482
train loss item: 0.09636295586824417
train loss item: 0.15215840935707092
train loss item: 0.11788484454154968
train loss item: 0.072095587849617
train loss item: 0.12945163249969482
train loss item: 0.044971514493227005
train loss item: 0.2821739912033081
train loss item: 0.10804372280836105
train loss item: 0.08371271938085556
train loss item: 0.18409055471420288
train loss item: 0.20187419652938843
train loss item: 0.4318600594997406
train loss item: 0.12212114781141281
test loss item: 0.08982976526021957
test loss item: 0.14872851967811584
test loss item: 0.11340887099504471
test loss item: 0.40769827365875244
test loss item: 0.11595210433006287
test loss item: 0.2538142800331116
test loss item: 0.10049251466989517
test loss item: 0.07777614146471024
test loss item: 0.14821459352970123
test loss item: 0.21406607329845428
test loss item: 0.1711474508047104
test loss item: 0.13190209865570068
test loss item: 0.10596912354230881
test loss item: 0.13818234205245972
test loss item: 0.14657065272331238
test loss item: 0.24068783223628998
test loss item: 0.13917550444602966
test loss item: 0.14853203296661377
test loss item: 0.3495478630065918
test loss item: 0.15198618173599243
test loss item: 0.13277138769626617
test loss item: 0.10882490128278732
test loss item: 0.20629750192165375
test loss item: 0.1378941535949707
test loss item: 0.20804888010025024
test loss item: 0.10018619894981384
test loss item: 0.10734561830759048
test loss item: 0.19467011094093323
test loss item: 0.21052215993404388
test loss item: 0.10080216825008392
test loss item: 0.13874255120754242
test loss item: 0.11564410477876663
test loss item: 0.2508823275566101
test loss item: 0.15439604222774506
test loss item: 0.16336078941822052
test loss item: 0.2779289186000824
test loss item: 0.21095812320709229
test loss item: 0.10212837904691696
test loss item: 0.3652578294277191
test loss item: 0.12647637724876404
test loss item: 0.27746909856796265
test loss item: 0.3132149279117584
test loss item: 0.12449198961257935
test loss item: 0.05593390390276909
test loss item: 0.10105466097593307
Epoch [27/100], Training Loss: 0.1743, Testing Loss: 0.1706
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 28/100
train loss item: 0.2356615662574768
train loss item: 0.15033790469169617
train loss item: 0.11097118258476257
train loss item: 0.14083069562911987
train loss item: 0.0777151957154274
train loss item: 0.13369035720825195
train loss item: 0.18659918010234833
train loss item: 0.21493186056613922
train loss item: 0.05345548316836357
train loss item: 0.12187360972166061
train loss item: 0.0816820040345192
train loss item: 0.31859922409057617
train loss item: 0.17242835462093353
train loss item: 0.12170788645744324
train loss item: 0.16351735591888428
train loss item: 0.23605135083198547
train loss item: 0.10007555037736893
train loss item: 0.31541261076927185
train loss item: 0.35797375440597534
train loss item: 0.19685052335262299
train loss item: 0.11873038858175278
train loss item: 0.08744705468416214
train loss item: 0.15004533529281616
train loss item: 0.11372774094343185
train loss item: 0.0720677599310875
train loss item: 0.22401344776153564
train loss item: 0.05495910719037056
train loss item: 0.34120187163352966
train loss item: 0.09215725213289261
train loss item: 0.08253193646669388
train loss item: 0.2808625102043152
train loss item: 0.17682388424873352
train loss item: 0.11450047791004181
train loss item: 0.205849751830101
train loss item: 0.13050024211406708
train loss item: 0.12468752264976501
train loss item: 0.17493389546871185
train loss item: 0.055295757949352264
train loss item: 0.19170290231704712
train loss item: 0.11835489422082901
train loss item: 0.06970098614692688
train loss item: 0.16889633238315582
train loss item: 0.2027028650045395
train loss item: 0.3888414800167084
train loss item: 0.136038139462471
test loss item: 0.0984787791967392
test loss item: 0.18807855248451233
test loss item: 0.13111647963523865
test loss item: 0.4493948519229889
test loss item: 0.15401870012283325
test loss item: 0.2939112186431885
test loss item: 0.13706469535827637
test loss item: 0.08963432908058167
test loss item: 0.17100922763347626
test loss item: 0.23821412026882172
test loss item: 0.20093193650245667
test loss item: 0.14993445575237274
test loss item: 0.11615418642759323
test loss item: 0.16132088005542755
test loss item: 0.17552483081817627
test loss item: 0.2828366458415985
test loss item: 0.17762835323810577
test loss item: 0.18255272507667542
test loss item: 0.39921605587005615
test loss item: 0.1810111105442047
test loss item: 0.14400716125965118
test loss item: 0.13335315883159637
test loss item: 0.24326252937316895
test loss item: 0.16773411631584167
test loss item: 0.25711244344711304
test loss item: 0.1453828662633896
test loss item: 0.12078385055065155
test loss item: 0.2587452232837677
test loss item: 0.22309783101081848
test loss item: 0.13594940304756165
test loss item: 0.1777190864086151
test loss item: 0.13488620519638062
test loss item: 0.3050411343574524
test loss item: 0.1759585440158844
test loss item: 0.19433355331420898
test loss item: 0.3141118884086609
test loss item: 0.23758992552757263
test loss item: 0.1191864088177681
test loss item: 0.4292473793029785
test loss item: 0.14176157116889954
test loss item: 0.31778356432914734
test loss item: 0.3761735260486603
test loss item: 0.13744044303894043
test loss item: 0.05914589390158653
test loss item: 0.12148361653089523
Epoch [28/100], Training Loss: 0.1637, Testing Loss: 0.2011
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 29/100
train loss item: 0.20679372549057007
train loss item: 0.1377524733543396
train loss item: 0.09932052344083786
train loss item: 0.19773492217063904
train loss item: 0.08240894973278046
train loss item: 0.1020653024315834
train loss item: 0.16083259880542755
train loss item: 0.28379562497138977
train loss item: 0.06530150026082993
train loss item: 0.1321215182542801
train loss item: 0.09072652459144592
train loss item: 0.3002505898475647
train loss item: 0.151192307472229
train loss item: 0.1526334583759308
train loss item: 0.20162881910800934
train loss item: 0.25570419430732727
train loss item: 0.12293357402086258
train loss item: 0.4569849967956543
train loss item: 0.33232542872428894
train loss item: 0.19949936866760254
train loss item: 0.13249683380126953
train loss item: 0.09672363102436066
train loss item: 0.14441055059432983
train loss item: 0.08621258288621902
train loss item: 0.08163650333881378
train loss item: 0.261528879404068
train loss item: 0.08035741001367569
train loss item: 0.508065938949585
train loss item: 0.12331007421016693
train loss item: 0.06692627817392349
train loss item: 0.3186214864253998
train loss item: 0.2300644963979721
train loss item: 0.15832138061523438
train loss item: 0.2019193172454834
train loss item: 0.12800265848636627
train loss item: 0.11154401302337646
train loss item: 0.2125585973262787
train loss item: 0.07394573092460632
train loss item: 0.30172643065452576
train loss item: 0.18310664594173431
train loss item: 0.10913418233394623
train loss item: 0.12793457508087158
train loss item: 0.19594407081604004
train loss item: 0.33716994524002075
train loss item: 0.14249016344547272
test loss item: 0.12477302551269531
test loss item: 0.2762341797351837
test loss item: 0.1883765012025833
test loss item: 0.7263456583023071
test loss item: 0.23341813683509827
test loss item: 0.4178655445575714
test loss item: 0.18677563965320587
test loss item: 0.1408647745847702
test loss item: 0.21312710642814636
test loss item: 0.29843151569366455
test loss item: 0.29507866501808167
test loss item: 0.1790166199207306
test loss item: 0.1572587639093399
test loss item: 0.199752077460289
test loss item: 0.2361953854560852
test loss item: 0.45568278431892395
test loss item: 0.27242815494537354
test loss item: 0.2867524027824402
test loss item: 0.6023426651954651
test loss item: 0.25735291838645935
test loss item: 0.14533255994319916
test loss item: 0.1835058182477951
test loss item: 0.3004525601863861
test loss item: 0.18159781396389008
test loss item: 0.37841641902923584
test loss item: 0.22050750255584717
test loss item: 0.15991564095020294
test loss item: 0.41614454984664917
test loss item: 0.3202584981918335
test loss item: 0.1986042857170105
test loss item: 0.24017347395420074
test loss item: 0.16051438450813293
test loss item: 0.43933987617492676
test loss item: 0.20068906247615814
test loss item: 0.28752994537353516
test loss item: 0.4742412865161896
test loss item: 0.24418023228645325
test loss item: 0.12060092389583588
test loss item: 0.6625887751579285
test loss item: 0.1627129167318344
test loss item: 0.47485801577568054
test loss item: 0.5864821076393127
test loss item: 0.17476056516170502
test loss item: 0.06957338005304337
test loss item: 0.12304630130529404
Epoch [29/100], Training Loss: 0.1810, Testing Loss: 0.2816
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 30/100
train loss item: 0.3447228670120239
train loss item: 0.2633168399333954
train loss item: 0.13236388564109802
train loss item: 0.16905885934829712
train loss item: 0.13489317893981934
train loss item: 0.186105877161026
train loss item: 0.24597041308879852
train loss item: 0.1543608009815216
train loss item: 0.14203029870986938
train loss item: 0.10730639100074768
train loss item: 0.1163984164595604
train loss item: 0.2915085256099701
train loss item: 0.14117784798145294
train loss item: 0.16038063168525696
train loss item: 0.42502561211586
train loss item: 0.3888967037200928
train loss item: 0.2272963523864746
train loss item: 0.26588907837867737
train loss item: 0.2166866809129715
train loss item: 0.2254565954208374
train loss item: 0.11837495863437653
train loss item: 0.14017342031002045
train loss item: 0.1353408247232437
train loss item: 0.11898144334554672
train loss item: 0.10017366707324982
train loss item: 0.22404496371746063
train loss item: 0.09612172096967697
train loss item: 0.3606974184513092
train loss item: 0.11764969676733017
train loss item: 0.12495000660419464
train loss item: 0.5879282355308533
train loss item: 0.1160288080573082
train loss item: 0.1205412745475769
train loss item: 0.1558227390050888
train loss item: 0.16804519295692444
train loss item: 0.10356593132019043
train loss item: 0.0838172510266304
train loss item: 0.056967880576848984
train loss item: 0.5239670872688293
train loss item: 0.1522088199853897
train loss item: 0.13836893439292908
train loss item: 0.14191745221614838
train loss item: 0.2820664346218109
train loss item: 0.4440498948097229
train loss item: 0.18132245540618896
test loss item: 0.0977441668510437
test loss item: 0.14292383193969727
test loss item: 0.09596364200115204
test loss item: 0.4763511121273041
test loss item: 0.10592099279165268
test loss item: 0.24673902988433838
test loss item: 0.0947723537683487
test loss item: 0.08056410402059555
test loss item: 0.13615062832832336
test loss item: 0.19942615926265717
test loss item: 0.17820987105369568
test loss item: 0.12841783463954926
test loss item: 0.10264661908149719
test loss item: 0.12072669714689255
test loss item: 0.12807030975818634
test loss item: 0.2546808123588562
test loss item: 0.1482829600572586
test loss item: 0.12978816032409668
test loss item: 0.34717708826065063
test loss item: 0.15444308519363403
test loss item: 0.13242444396018982
test loss item: 0.10873212665319443
test loss item: 0.18892426788806915
test loss item: 0.1297263354063034
test loss item: 0.18936878442764282
test loss item: 0.09247007220983505
test loss item: 0.103960320353508
test loss item: 0.17992337048053741
test loss item: 0.19824811816215515
test loss item: 0.10018941760063171
test loss item: 0.12744386494159698
test loss item: 0.11225031316280365
test loss item: 0.2718394696712494
test loss item: 0.1382034718990326
test loss item: 0.16371017694473267
test loss item: 0.3152770698070526
test loss item: 0.20174992084503174
test loss item: 0.09778842329978943
test loss item: 0.40300536155700684
test loss item: 0.1126556247472763
test loss item: 0.29645347595214844
test loss item: 0.3218819797039032
test loss item: 0.11687761545181274
test loss item: 0.07111703604459763
test loss item: 0.1324150264263153
Epoch [30/100], Training Loss: 0.2029, Testing Loss: 0.1706
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 31/100
train loss item: 0.25098347663879395
train loss item: 0.13422422111034393
train loss item: 0.09946375340223312
train loss item: 0.26655638217926025
train loss item: 0.11204807460308075
train loss item: 0.113199882209301
train loss item: 0.1367117315530777
train loss item: 0.2001473307609558
train loss item: 0.08058812469244003
train loss item: 0.15997526049613953
train loss item: 0.090206578373909
train loss item: 0.26768580079078674
train loss item: 0.18697519600391388
train loss item: 0.08759982138872147
train loss item: 0.15278996527194977
train loss item: 0.23231159150600433
train loss item: 0.11366462707519531
train loss item: 0.31661203503608704
train loss item: 0.20606574416160583
train loss item: 0.23660747706890106
train loss item: 0.13307160139083862
train loss item: 0.10071849077939987
train loss item: 0.2068895399570465
train loss item: 0.10745544731616974
train loss item: 0.10698572546243668
train loss item: 0.3042480945587158
train loss item: 0.0780152976512909
train loss item: 0.41863226890563965
train loss item: 0.13724958896636963
train loss item: 0.14120106399059296
train loss item: 0.31422099471092224
train loss item: 0.13196690380573273
train loss item: 0.1263248324394226
train loss item: 0.27924153208732605
train loss item: 0.1927022784948349
train loss item: 0.1388079822063446
train loss item: 0.1283363401889801
train loss item: 0.05431795120239258
train loss item: 0.4574377238750458
train loss item: 0.10628318786621094
train loss item: 0.08499493449926376
train loss item: 0.17512181401252747
train loss item: 0.22557301819324493
train loss item: 0.3856368362903595
train loss item: 0.1397325098514557
test loss item: 0.08158386498689651
test loss item: 0.17836201190948486
test loss item: 0.12933607399463654
test loss item: 0.32684311270713806
test loss item: 0.17053548991680145
test loss item: 0.29276829957962036
test loss item: 0.1231590062379837
test loss item: 0.08900276571512222
test loss item: 0.15361160039901733
test loss item: 0.18765665590763092
test loss item: 0.19407519698143005
test loss item: 0.13418738543987274
test loss item: 0.10571154206991196
test loss item: 0.1472465842962265
test loss item: 0.17079034447669983
test loss item: 0.2675282061100006
test loss item: 0.18269982933998108
test loss item: 0.21477089822292328
test loss item: 0.38094863295555115
test loss item: 0.17014920711517334
test loss item: 0.09349216520786285
test loss item: 0.1281406581401825
test loss item: 0.21077395975589752
test loss item: 0.14943350851535797
test loss item: 0.25230762362480164
test loss item: 0.1701599806547165
test loss item: 0.12008262425661087
test loss item: 0.2930363416671753
test loss item: 0.20868231356143951
test loss item: 0.14058807492256165
test loss item: 0.17948004603385925
test loss item: 0.09421809017658234
test loss item: 0.2538037598133087
test loss item: 0.12764206528663635
test loss item: 0.18740148842334747
test loss item: 0.2063933163881302
test loss item: 0.14997591078281403
test loss item: 0.09209258109331131
test loss item: 0.4202059507369995
test loss item: 0.11391602456569672
test loss item: 0.26067915558815
test loss item: 0.371023952960968
test loss item: 0.12738078832626343
test loss item: 0.043069157749414444
test loss item: 0.0741649642586708
Epoch [31/100], Training Loss: 0.1804, Testing Loss: 0.1815
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 32/100
train loss item: 0.2679988443851471
train loss item: 0.1595950573682785
train loss item: 0.1293352097272873
train loss item: 0.13122405111789703
train loss item: 0.08868638426065445
train loss item: 0.13321374356746674
train loss item: 0.11368903517723083
train loss item: 0.23179841041564941
train loss item: 0.07321905344724655
train loss item: 0.12569990754127502
train loss item: 0.08501086384057999
train loss item: 0.26075834035873413
train loss item: 0.13081160187721252
train loss item: 0.10103698074817657
train loss item: 0.204450786113739
train loss item: 0.33307504653930664
train loss item: 0.15361352264881134
train loss item: 0.32001879811286926
train loss item: 0.2731449604034424
train loss item: 0.2189534604549408
train loss item: 0.12168404459953308
train loss item: 0.07991660386323929
train loss item: 0.22830669581890106
train loss item: 0.11344907432794571
train loss item: 0.11888816952705383
train loss item: 0.2523268461227417
train loss item: 0.05624058470129967
train loss item: 0.24636158347129822
train loss item: 0.10893343389034271
train loss item: 0.08598192036151886
train loss item: 0.2997879981994629
train loss item: 0.14888693392276764
train loss item: 0.12955866754055023
train loss item: 0.13392570614814758
train loss item: 0.14052356779575348
train loss item: 0.10639307647943497
train loss item: 0.15678469836711884
train loss item: 0.062111832201480865
train loss item: 0.2992042005062103
train loss item: 0.12345211952924728
train loss item: 0.08046038448810577
train loss item: 0.1277400106191635
train loss item: 0.1753654181957245
train loss item: 0.3098553419113159
train loss item: 0.10447113960981369
test loss item: 0.16663941740989685
test loss item: 0.2763720452785492
test loss item: 0.25185418128967285
test loss item: 0.41354572772979736
test loss item: 0.21756112575531006
test loss item: 0.3936535120010376
test loss item: 0.15013957023620605
test loss item: 0.17686298489570618
test loss item: 0.19743113219738007
test loss item: 0.2086818367242813
test loss item: 0.2345866709947586
test loss item: 0.20442675054073334
test loss item: 0.14698506891727448
test loss item: 0.22854188084602356
test loss item: 0.2456548660993576
test loss item: 0.3640645742416382
test loss item: 0.270507276058197
test loss item: 0.2556655704975128
test loss item: 0.5271791219711304
test loss item: 0.25993451476097107
test loss item: 0.13877169787883759
test loss item: 0.1526452898979187
test loss item: 0.24038319289684296
test loss item: 0.18118426203727722
test loss item: 0.3181561827659607
test loss item: 0.20195141434669495
test loss item: 0.15413793921470642
test loss item: 0.3959779441356659
test loss item: 0.252108633518219
test loss item: 0.18239322304725647
test loss item: 0.21704219281673431
test loss item: 0.14369331300258636
test loss item: 0.39363548159599304
test loss item: 0.17324692010879517
test loss item: 0.24225075542926788
test loss item: 0.26278597116470337
test loss item: 0.20385819673538208
test loss item: 0.13591718673706055
test loss item: 0.6635590195655823
test loss item: 0.21754316985607147
test loss item: 0.37573274970054626
test loss item: 0.5029976963996887
test loss item: 0.1646004319190979
test loss item: 0.09486621618270874
test loss item: 0.16442576050758362
Epoch [32/100], Training Loss: 0.1632, Testing Loss: 0.2525
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 33/100
train loss item: 0.28012320399284363
train loss item: 0.16550874710083008
train loss item: 0.1186697781085968
train loss item: 0.12528616189956665
train loss item: 0.07280294597148895
train loss item: 0.1433464139699936
train loss item: 0.1935676485300064
train loss item: 0.2587142288684845
train loss item: 0.09116438776254654
train loss item: 0.10658147931098938
train loss item: 0.08459780365228653
train loss item: 0.18122372031211853
train loss item: 0.1204226166009903
train loss item: 0.1545114368200302
train loss item: 0.16562040150165558
train loss item: 0.25131163001060486
train loss item: 0.22379982471466064
train loss item: 0.19945074617862701
train loss item: 0.23945869505405426
train loss item: 0.2264450341463089
train loss item: 0.1553315669298172
train loss item: 0.09870865195989609
train loss item: 0.18985672295093536
train loss item: 0.09895625710487366
train loss item: 0.10797396302223206
train loss item: 0.2484491765499115
train loss item: 0.08605432510375977
train loss item: 0.32724568247795105
train loss item: 0.10635419189929962
train loss item: 0.1000448614358902
train loss item: 0.31638476252555847
train loss item: 0.16665683686733246
train loss item: 0.10187393426895142
train loss item: 0.13080766797065735
train loss item: 0.150430828332901
train loss item: 0.09994877129793167
train loss item: 0.13620446622371674
train loss item: 0.05760379880666733
train loss item: 0.3527180254459381
train loss item: 0.10975245386362076
train loss item: 0.06453578174114227
train loss item: 0.11517658829689026
train loss item: 0.17039303481578827
train loss item: 0.3786250650882721
train loss item: 0.11708222329616547
test loss item: 0.10767938196659088
test loss item: 0.16433385014533997
test loss item: 0.1473550945520401
test loss item: 0.5271114110946655
test loss item: 0.13729707896709442
test loss item: 0.29756009578704834
test loss item: 0.11547637730836868
test loss item: 0.11086931079626083
test loss item: 0.1494324505329132
test loss item: 0.23978456854820251
test loss item: 0.1932077258825302
test loss item: 0.14102602005004883
test loss item: 0.10515208542346954
test loss item: 0.1538916677236557
test loss item: 0.17321783304214478
test loss item: 0.3076428472995758
test loss item: 0.17102892696857452
test loss item: 0.1751585304737091
test loss item: 0.41835102438926697
test loss item: 0.17210470139980316
test loss item: 0.12278272211551666
test loss item: 0.11936095356941223
test loss item: 0.2057955116033554
test loss item: 0.1400403380393982
test loss item: 0.2406230866909027
test loss item: 0.12932024896144867
test loss item: 0.11182516068220139
test loss item: 0.24511896073818207
test loss item: 0.23627901077270508
test loss item: 0.1253296434879303
test loss item: 0.1646994650363922
test loss item: 0.1180528774857521
test loss item: 0.28605905175209045
test loss item: 0.1567249894142151
test loss item: 0.19662335515022278
test loss item: 0.3438858985900879
test loss item: 0.20683063566684723
test loss item: 0.1034805104136467
test loss item: 0.41600361466407776
test loss item: 0.13644704222679138
test loss item: 0.3371921181678772
test loss item: 0.3847677707672119
test loss item: 0.1262659728527069
test loss item: 0.059323299676179886
test loss item: 0.10419021546840668
Epoch [33/100], Training Loss: 0.1642, Testing Loss: 0.1961
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 34/100
train loss item: 0.22989067435264587
train loss item: 0.13132357597351074
train loss item: 0.08678081631660461
train loss item: 0.1270948052406311
train loss item: 0.0787648931145668
train loss item: 0.10853004455566406
train loss item: 0.13923640549182892
train loss item: 0.15401703119277954
train loss item: 0.06745941191911697
train loss item: 0.10140007734298706
train loss item: 0.07169651985168457
train loss item: 0.188942551612854
train loss item: 0.1275561898946762
train loss item: 0.14025267958641052
train loss item: 0.2584439814090729
train loss item: 0.21377599239349365
train loss item: 0.1378197818994522
train loss item: 0.2842560112476349
train loss item: 0.2455541491508484
train loss item: 0.21665683388710022
train loss item: 0.13581383228302002
train loss item: 0.08757498115301132
train loss item: 0.16701436042785645
train loss item: 0.1050710529088974
train loss item: 0.1364770084619522
train loss item: 0.2628616690635681
train loss item: 0.08857769519090652
train loss item: 0.3032492697238922
train loss item: 0.11424817144870758
train loss item: 0.06684134155511856
train loss item: 0.3181232213973999
train loss item: 0.17671550810337067
train loss item: 0.16774629056453705
train loss item: 0.15483710169792175
train loss item: 0.13595718145370483
train loss item: 0.07992597669363022
train loss item: 0.11800234019756317
train loss item: 0.05085175856947899
train loss item: 0.3431932032108307
train loss item: 0.1306205689907074
train loss item: 0.08832601457834244
train loss item: 0.14312925934791565
train loss item: 0.1676742136478424
train loss item: 0.3419371545314789
train loss item: 0.1183948665857315
test loss item: 0.11509792506694794
test loss item: 0.17856556177139282
test loss item: 0.17863662540912628
test loss item: 0.39807403087615967
test loss item: 0.1471114158630371
test loss item: 0.2916267514228821
test loss item: 0.13107499480247498
test loss item: 0.12040586769580841
test loss item: 0.1481841504573822
test loss item: 0.20525501668453217
test loss item: 0.18393541872501373
test loss item: 0.1661519706249237
test loss item: 0.11266245692968369
test loss item: 0.16886599361896515
test loss item: 0.18157146871089935
test loss item: 0.2666153311729431
test loss item: 0.1809234768152237
test loss item: 0.18436826765537262
test loss item: 0.38982975482940674
test loss item: 0.1833047717809677
test loss item: 0.12972941994667053
test loss item: 0.11556855589151382
test loss item: 0.20610909163951874
test loss item: 0.17057394981384277
test loss item: 0.23868735134601593
test loss item: 0.14926546812057495
test loss item: 0.1128978431224823
test loss item: 0.2674647569656372
test loss item: 0.2192205935716629
test loss item: 0.13763993978500366
test loss item: 0.16150400042533875
test loss item: 0.11914938688278198
test loss item: 0.2872771620750427
test loss item: 0.14889979362487793
test loss item: 0.18819722533226013
test loss item: 0.26821354031562805
test loss item: 0.17685645818710327
test loss item: 0.13062524795532227
test loss item: 0.4425415098667145
test loss item: 0.1645226925611496
test loss item: 0.29706189036369324
test loss item: 0.3714037537574768
test loss item: 0.13327987492084503
test loss item: 0.05965321511030197
test loss item: 0.1270914226770401
Epoch [34/100], Training Loss: 0.1581, Testing Loss: 0.1946
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.15236234664916992
loss item: 0.48296818137168884
loss item: 0.22919179499149323
loss item: 0.23418007791042328
loss item: 0.13278430700302124
loss item: 0.32709839940071106
loss item: 0.23045314848423004
loss item: 0.22091297805309296
loss item: 0.2351822704076767
loss item: 0.3059622347354889
loss item: 0.15605658292770386
loss item: 0.1435350477695465
loss item: 0.23650915920734406
loss item: 0.2706030011177063
loss item: 0.18545901775360107
loss item: 0.4461347758769989
loss item: 0.18768823146820068
loss item: 0.1376291960477829
loss item: 0.15646277368068695
loss item: 0.22472381591796875
loss item: 0.30971184372901917
loss item: 0.1485242396593094
Val Loss: 0.2343
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 100, batch size: 4
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.005 4 360 done at Tue Nov 12 13:18:40 CET 2024
UNet2 with 1 100 0.0001 8 360 start at Tue Nov 12 13:18:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.4765785932540894
train loss item: 1.083484411239624
train loss item: 0.5838243365287781
train loss item: 0.812828540802002
train loss item: 0.5618910789489746
train loss item: 1.078084111213684
train loss item: 0.5615077018737793
train loss item: 1.6320184469223022
train loss item: 1.8999967575073242
train loss item: 0.5566858649253845
train loss item: 0.39754918217658997
train loss item: 0.5428510904312134
train loss item: 0.641681432723999
train loss item: 1.4390499591827393
train loss item: 0.44381245970726013
train loss item: 1.109988808631897
train loss item: 0.5536924004554749
train loss item: 0.5271103978157043
train loss item: 0.5418879389762878
train loss item: 0.7999544143676758
train loss item: 0.41836076974868774
train loss item: 1.768530249595642
train loss item: 0.45973601937294006
test loss item: 0.6564205288887024
test loss item: 1.1753612756729126
test loss item: 0.9327887892723083
test loss item: 0.23601214587688446
test loss item: 0.6325896978378296
test loss item: 0.6444830894470215
test loss item: 0.36974871158599854
test loss item: 0.9694143533706665
test loss item: 0.7612301707267761
test loss item: 1.3546137809753418
test loss item: 0.406040221452713
test loss item: 0.6077709197998047
test loss item: 0.7900437116622925
test loss item: 0.9120163321495056
test loss item: 0.5920053124427795
test loss item: 0.4564494788646698
test loss item: 0.9680256247520447
test loss item: 0.9331833124160767
test loss item: 0.4089297652244568
test loss item: 2.0261149406433105
test loss item: 1.6520882844924927
test loss item: 0.2741067111492157
test loss item: 0.1968715488910675
Epoch [1/100], Training Loss: 0.8648, Testing Loss: 0.7807
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/100
train loss item: 0.7417500615119934
train loss item: 0.5656790137290955
train loss item: 0.365988552570343
train loss item: 0.44126635789871216
train loss item: 0.3789122998714447
train loss item: 0.618120551109314
train loss item: 0.3926723301410675
train loss item: 1.0211806297302246
train loss item: 1.2836291790008545
train loss item: 0.4075939655303955
train loss item: 0.29767176508903503
train loss item: 0.37050122022628784
train loss item: 0.4769611656665802
train loss item: 1.0178533792495728
train loss item: 0.3016112744808197
train loss item: 0.8293887972831726
train loss item: 0.4290391504764557
train loss item: 0.3414711356163025
train loss item: 0.33933156728744507
train loss item: 0.6073342561721802
train loss item: 0.329913467168808
train loss item: 1.4259922504425049
train loss item: 0.4048585593700409
test loss item: 0.3749174177646637
test loss item: 0.5841132402420044
test loss item: 0.5142123103141785
test loss item: 0.21610724925994873
test loss item: 0.4151616096496582
test loss item: 0.428355872631073
test loss item: 0.2773471176624298
test loss item: 0.4989481270313263
test loss item: 0.5812373161315918
test loss item: 0.7112188339233398
test loss item: 0.32378068566322327
test loss item: 0.416506290435791
test loss item: 0.4621787965297699
test loss item: 0.5079854130744934
test loss item: 0.42758679389953613
test loss item: 0.32240381836891174
test loss item: 0.4743603765964508
test loss item: 0.5154066681861877
test loss item: 0.27740713953971863
test loss item: 0.8332746028900146
test loss item: 0.8047391176223755
test loss item: 0.22709102928638458
test loss item: 0.23143629729747772
Epoch [2/100], Training Loss: 0.5821, Testing Loss: 0.4533
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/100
train loss item: 0.5836189985275269
train loss item: 0.460042804479599
train loss item: 0.322931706905365
train loss item: 0.3822566568851471
train loss item: 0.3139364719390869
train loss item: 0.5080469846725464
train loss item: 0.33512434363365173
train loss item: 0.8311465382575989
train loss item: 1.0217022895812988
train loss item: 0.35656672716140747
train loss item: 0.26793476939201355
train loss item: 0.32368218898773193
train loss item: 0.440357506275177
train loss item: 0.7826980352401733
train loss item: 0.2696899175643921
train loss item: 0.6817733645439148
train loss item: 0.3956076502799988
train loss item: 0.30178457498550415
train loss item: 0.2923298180103302
train loss item: 0.5213814973831177
train loss item: 0.29002702236175537
train loss item: 1.2048746347427368
train loss item: 0.36062705516815186
test loss item: 0.3052310347557068
test loss item: 0.5369422435760498
test loss item: 0.42228224873542786
test loss item: 0.20859259366989136
test loss item: 0.3693908751010895
test loss item: 0.3489859402179718
test loss item: 0.2530066967010498
test loss item: 0.43169352412223816
test loss item: 0.4590947926044464
test loss item: 0.572840690612793
test loss item: 0.27380311489105225
test loss item: 0.3643897771835327
test loss item: 0.3962213695049286
test loss item: 0.41734927892684937
test loss item: 0.36088645458221436
test loss item: 0.28456392884254456
test loss item: 0.40941131114959717
test loss item: 0.4483882188796997
test loss item: 0.26715075969696045
test loss item: 0.6281399726867676
test loss item: 0.670803427696228
test loss item: 0.21077226102352142
test loss item: 0.2520347833633423
Epoch [3/100], Training Loss: 0.4890, Testing Loss: 0.3866
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/100
train loss item: 0.5281833410263062
train loss item: 0.4317452907562256
train loss item: 0.29037660360336304
train loss item: 0.3437061905860901
train loss item: 0.27024078369140625
train loss item: 0.46432939171791077
train loss item: 0.2984854578971863
train loss item: 0.7213901281356812
train loss item: 0.8398179411888123
train loss item: 0.32816269993782043
train loss item: 0.24559886753559113
train loss item: 0.3110804557800293
train loss item: 0.4126107394695282
train loss item: 0.6318047642707825
train loss item: 0.2331475168466568
train loss item: 0.5893158316612244
train loss item: 0.3473173975944519
train loss item: 0.2793399691581726
train loss item: 0.24662169814109802
train loss item: 0.47092384099960327
train loss item: 0.25547516345977783
train loss item: 1.0721052885055542
train loss item: 0.31800419092178345
test loss item: 0.28926870226860046
test loss item: 0.5087223649024963
test loss item: 0.37412479519844055
test loss item: 0.2075520157814026
test loss item: 0.3454647958278656
test loss item: 0.3141767382621765
test loss item: 0.24933460354804993
test loss item: 0.39173218607902527
test loss item: 0.40807682275772095
test loss item: 0.5108515024185181
test loss item: 0.2517012357711792
test loss item: 0.3276495635509491
test loss item: 0.3641481399536133
test loss item: 0.3769974112510681
test loss item: 0.32736289501190186
test loss item: 0.2654727101325989
test loss item: 0.3831939995288849
test loss item: 0.41253769397735596
test loss item: 0.25438034534454346
test loss item: 0.5344184637069702
test loss item: 0.5921187400817871
test loss item: 0.211030051112175
test loss item: 0.3621618449687958
Epoch [4/100], Training Loss: 0.4317, Testing Loss: 0.3592
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/100
train loss item: 0.47892698645591736
train loss item: 0.39972272515296936
train loss item: 0.2865172326564789
train loss item: 0.3277915418148041
train loss item: 0.24260197579860687
train loss item: 0.42092201113700867
train loss item: 0.27311697602272034
train loss item: 0.6216449737548828
train loss item: 0.6964719295501709
train loss item: 0.30150866508483887
train loss item: 0.22281934320926666
train loss item: 0.2823345363140106
train loss item: 0.38671550154685974
train loss item: 0.5315948128700256
train loss item: 0.22176602482795715
train loss item: 0.5175883769989014
train loss item: 0.3155915141105652
train loss item: 0.2645622193813324
train loss item: 0.2243748903274536
train loss item: 0.4247480034828186
train loss item: 0.24222224950790405
train loss item: 0.9605743288993835
train loss item: 0.2864496111869812
test loss item: 0.2681131362915039
test loss item: 0.451811820268631
test loss item: 0.33482876420021057
test loss item: 0.19554294645786285
test loss item: 0.30788442492485046
test loss item: 0.2816539704799652
test loss item: 0.22538264095783234
test loss item: 0.3471445143222809
test loss item: 0.3609934449195862
test loss item: 0.45546281337738037
test loss item: 0.22189854085445404
test loss item: 0.2940639853477478
test loss item: 0.3267595171928406
test loss item: 0.33665940165519714
test loss item: 0.2960127294063568
test loss item: 0.23934830725193024
test loss item: 0.347905695438385
test loss item: 0.3671259582042694
test loss item: 0.2324514538049698
test loss item: 0.4746415913105011
test loss item: 0.5223944783210754
test loss item: 0.191764235496521
test loss item: 0.286038875579834
Epoch [5/100], Training Loss: 0.3883, Testing Loss: 0.3203
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/100
train loss item: 0.435422420501709
train loss item: 0.36739614605903625
train loss item: 0.2692262828350067
train loss item: 0.31787559390068054
train loss item: 0.22158408164978027
train loss item: 0.39404919743537903
train loss item: 0.24779339134693146
train loss item: 0.5712112188339233
train loss item: 0.6255072951316833
train loss item: 0.28577330708503723
train loss item: 0.22145067155361176
train loss item: 0.2787756025791168
train loss item: 0.3726474642753601
train loss item: 0.44578418135643005
train loss item: 0.2032674103975296
train loss item: 0.45304372906684875
train loss item: 0.30671411752700806
train loss item: 0.26673218607902527
train loss item: 0.21435992419719696
train loss item: 0.4000987708568573
train loss item: 0.24644064903259277
train loss item: 0.888120174407959
train loss item: 0.27682244777679443
test loss item: 0.2834940552711487
test loss item: 0.4554317891597748
test loss item: 0.36500316858291626
test loss item: 0.18664152920246124
test loss item: 0.293560653924942
test loss item: 0.26825252175331116
test loss item: 0.22290758788585663
test loss item: 0.3665391504764557
test loss item: 0.3571268916130066
test loss item: 0.4943573474884033
test loss item: 0.21391956508159637
test loss item: 0.2641841769218445
test loss item: 0.3290248215198517
test loss item: 0.3599393665790558
test loss item: 0.2939949035644531
test loss item: 0.23176777362823486
test loss item: 0.3627004325389862
test loss item: 0.3647245168685913
test loss item: 0.22026026248931885
test loss item: 0.6238955855369568
test loss item: 0.5884270668029785
test loss item: 0.18897327780723572
test loss item: 0.29573673009872437
Epoch [6/100], Training Loss: 0.3613, Testing Loss: 0.3318
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/100
train loss item: 0.3825624883174896
train loss item: 0.3148273527622223
train loss item: 0.2603245675563812
train loss item: 0.30860137939453125
train loss item: 0.20929054915905
train loss item: 0.3598375916481018
train loss item: 0.23363979160785675
train loss item: 0.4887494444847107
train loss item: 0.5538703799247742
train loss item: 0.26717397570610046
train loss item: 0.18641993403434753
train loss item: 0.2340330332517624
train loss item: 0.32728111743927
train loss item: 0.39788299798965454
train loss item: 0.1802392601966858
train loss item: 0.40818336606025696
train loss item: 0.27619147300720215
train loss item: 0.2598611116409302
train loss item: 0.20155298709869385
train loss item: 0.3630409240722656
train loss item: 0.24135839939117432
train loss item: 0.8075783252716064
train loss item: 0.27323487401008606
test loss item: 0.26877105236053467
test loss item: 0.44425004720687866
test loss item: 0.35942625999450684
test loss item: 0.16721484065055847
test loss item: 0.2811721861362457
test loss item: 0.26967039704322815
test loss item: 0.19808104634284973
test loss item: 0.3552539348602295
test loss item: 0.3388080596923828
test loss item: 0.49028724431991577
test loss item: 0.2230607122182846
test loss item: 0.2547677457332611
test loss item: 0.30006441473960876
test loss item: 0.348059743642807
test loss item: 0.27975305914878845
test loss item: 0.21007217466831207
test loss item: 0.37165385484695435
test loss item: 0.36671143770217896
test loss item: 0.22466892004013062
test loss item: 0.6670399308204651
test loss item: 0.5989232063293457
test loss item: 0.1703696846961975
test loss item: 0.2291974127292633
Epoch [7/100], Training Loss: 0.3276, Testing Loss: 0.3225
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/100
train loss item: 0.35498693585395813
train loss item: 0.27661773562431335
train loss item: 0.2507956624031067
train loss item: 0.2905431389808655
train loss item: 0.19189584255218506
train loss item: 0.3691663146018982
train loss item: 0.263126015663147
train loss item: 0.4863158166408539
train loss item: 0.526951253414154
train loss item: 0.277037650346756
train loss item: 0.18981313705444336
train loss item: 0.26853320002555847
train loss item: 0.34457796812057495
train loss item: 0.35030633211135864
train loss item: 0.16632866859436035
train loss item: 0.3841131031513214
train loss item: 0.25254303216934204
train loss item: 0.24747836589813232
train loss item: 0.1979285180568695
train loss item: 0.37553420662879944
train loss item: 0.2490677535533905
train loss item: 0.7715502977371216
train loss item: 0.2680889964103699
test loss item: 0.2663212716579437
test loss item: 0.42561075091362
test loss item: 0.37544798851013184
test loss item: 0.13880577683448792
test loss item: 0.25617116689682007
test loss item: 0.2324955016374588
test loss item: 0.16949903964996338
test loss item: 0.36494341492652893
test loss item: 0.31659290194511414
test loss item: 0.5230133533477783
test loss item: 0.18099114298820496
test loss item: 0.2141830325126648
test loss item: 0.2983261048793793
test loss item: 0.35991957783699036
test loss item: 0.2703776955604553
test loss item: 0.18631304800510406
test loss item: 0.38154688477516174
test loss item: 0.36037954688072205
test loss item: 0.1726294308900833
test loss item: 0.798258364200592
test loss item: 0.6579353213310242
test loss item: 0.1453174352645874
test loss item: 0.15778020024299622
Epoch [8/100], Training Loss: 0.3197, Testing Loss: 0.3153
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/100
train loss item: 0.32561632990837097
train loss item: 0.2447439730167389
train loss item: 0.24230165779590607
train loss item: 0.2652389407157898
train loss item: 0.19050459563732147
train loss item: 0.31225723028182983
train loss item: 0.2519325911998749
train loss item: 0.4136081337928772
train loss item: 0.44616204500198364
train loss item: 0.22507734596729279
train loss item: 0.16776694357395172
train loss item: 0.220158189535141
train loss item: 0.2912244498729706
train loss item: 0.3106955587863922
train loss item: 0.1553719937801361
train loss item: 0.3373541831970215
train loss item: 0.24508671462535858
train loss item: 0.2344696968793869
train loss item: 0.18031184375286102
train loss item: 0.3375830352306366
train loss item: 0.2286861091852188
train loss item: 0.7292516827583313
train loss item: 0.2499716877937317
test loss item: 0.22020649909973145
test loss item: 0.4375167489051819
test loss item: 0.358296275138855
test loss item: 0.12402510643005371
test loss item: 0.24307824671268463
test loss item: 0.20646925270557404
test loss item: 0.1556151807308197
test loss item: 0.3582001328468323
test loss item: 0.26221930980682373
test loss item: 0.49292004108428955
test loss item: 0.16699953377246857
test loss item: 0.20187635719776154
test loss item: 0.27578145265579224
test loss item: 0.3084455728530884
test loss item: 0.25128501653671265
test loss item: 0.1677224487066269
test loss item: 0.3451710641384125
test loss item: 0.3445272445678711
test loss item: 0.16494855284690857
test loss item: 0.7660565376281738
test loss item: 0.6412145495414734
test loss item: 0.13417299091815948
test loss item: 0.16471776366233826
Epoch [9/100], Training Loss: 0.2872, Testing Loss: 0.2953
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/100
train loss item: 0.28392836451530457
train loss item: 0.209515780210495
train loss item: 0.19540072977542877
train loss item: 0.23469007015228271
train loss item: 0.16688749194145203
train loss item: 0.2732012867927551
train loss item: 0.2021365612745285
train loss item: 0.35319235920906067
train loss item: 0.3911067247390747
train loss item: 0.21470654010772705
train loss item: 0.15046168863773346
train loss item: 0.2067679464817047
train loss item: 0.2693334221839905
train loss item: 0.2631031274795532
train loss item: 0.14134299755096436
train loss item: 0.2913076877593994
train loss item: 0.2116931825876236
train loss item: 0.20072545111179352
train loss item: 0.16184565424919128
train loss item: 0.3039773106575012
train loss item: 0.20623347163200378
train loss item: 0.6457330584526062
train loss item: 0.23005300760269165
test loss item: 0.16960111260414124
test loss item: 0.38934972882270813
test loss item: 0.24446910619735718
test loss item: 0.12984755635261536
test loss item: 0.23816046118736267
test loss item: 0.2001281976699829
test loss item: 0.14955294132232666
test loss item: 0.2680019736289978
test loss item: 0.2271704375743866
test loss item: 0.3401469886302948
test loss item: 0.16321809589862823
test loss item: 0.20453977584838867
test loss item: 0.22165893018245697
test loss item: 0.20569393038749695
test loss item: 0.2201698273420334
test loss item: 0.16511590778827667
test loss item: 0.2610361576080322
test loss item: 0.316177099943161
test loss item: 0.17664416134357452
test loss item: 0.3924379050731659
test loss item: 0.42043545842170715
test loss item: 0.1349729597568512
test loss item: 0.13761888444423676
Epoch [10/100], Training Loss: 0.2525, Testing Loss: 0.2337
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 11/100
train loss item: 0.2794940769672394
train loss item: 0.20490358769893646
train loss item: 0.18073347210884094
train loss item: 0.23252950608730316
train loss item: 0.16048641502857208
train loss item: 0.30959585309028625
train loss item: 0.1964738965034485
train loss item: 0.43584364652633667
train loss item: 0.3709879517555237
train loss item: 0.25698190927505493
train loss item: 0.1927582174539566
train loss item: 0.2646137475967407
train loss item: 0.34336963295936584
train loss item: 0.26842188835144043
train loss item: 0.13633090257644653
train loss item: 0.28319212794303894
train loss item: 0.2064317762851715
train loss item: 0.1857105791568756
train loss item: 0.15783129632472992
train loss item: 0.3167109489440918
train loss item: 0.19554030895233154
train loss item: 0.6760261058807373
train loss item: 0.22162482142448425
test loss item: 0.21667590737342834
test loss item: 0.3951656222343445
test loss item: 0.3193220794200897
test loss item: 0.12084192782640457
test loss item: 0.22079524397850037
test loss item: 0.1949419379234314
test loss item: 0.14024412631988525
test loss item: 0.3266511857509613
test loss item: 0.24794209003448486
test loss item: 0.460054874420166
test loss item: 0.15475499629974365
test loss item: 0.17783740162849426
test loss item: 0.24703949689865112
test loss item: 0.2895169258117676
test loss item: 0.23843005299568176
test loss item: 0.15742237865924835
test loss item: 0.33453667163848877
test loss item: 0.3239232003688812
test loss item: 0.15083347260951996
test loss item: 0.7560244798660278
test loss item: 0.5947263240814209
test loss item: 0.1269899159669876
test loss item: 0.13662080466747284
Epoch [11/100], Training Loss: 0.2642, Testing Loss: 0.2753
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 12/100
train loss item: 0.2918879985809326
train loss item: 0.20314598083496094
train loss item: 0.18138986825942993
train loss item: 0.2131638079881668
train loss item: 0.155845507979393
train loss item: 0.23546777665615082
train loss item: 0.19875559210777283
train loss item: 0.34830671548843384
train loss item: 0.3297506272792816
train loss item: 0.1988348364830017
train loss item: 0.13483168184757233
train loss item: 0.19188983738422394
train loss item: 0.23356452584266663
train loss item: 0.23553355038166046
train loss item: 0.13450343906879425
train loss item: 0.2741210162639618
train loss item: 0.22610069811344147
train loss item: 0.19535845518112183
train loss item: 0.14468182623386383
train loss item: 0.2943119406700134
train loss item: 0.20946386456489563
train loss item: 0.6401925086975098
train loss item: 0.1988634467124939
test loss item: 0.2101443111896515
test loss item: 0.32210591435432434
test loss item: 0.3705613315105438
test loss item: 0.11603040248155594
test loss item: 0.2276584953069687
test loss item: 0.17670942842960358
test loss item: 0.14300307631492615
test loss item: 0.34486129879951477
test loss item: 0.2677936553955078
test loss item: 0.48428526520729065
test loss item: 0.14664994180202484
test loss item: 0.18121762573719025
test loss item: 0.2776404917240143
test loss item: 0.3224368393421173
test loss item: 0.24284249544143677
test loss item: 0.14987151324748993
test loss item: 0.3267964720726013
test loss item: 0.3015449345111847
test loss item: 0.13809144496917725
test loss item: 0.7658228874206543
test loss item: 0.6264911890029907
test loss item: 0.12205298990011215
test loss item: 0.14166942238807678
Epoch [12/100], Training Loss: 0.2378, Testing Loss: 0.2785
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 13/100
train loss item: 0.2424364686012268
train loss item: 0.17966532707214355
train loss item: 0.16811636090278625
train loss item: 0.20307224988937378
train loss item: 0.1462049037218094
train loss item: 0.3301621973514557
train loss item: 0.1785586029291153
train loss item: 0.30855077505111694
train loss item: 0.3061741590499878
train loss item: 0.22351349890232086
train loss item: 0.14464008808135986
train loss item: 0.2525513768196106
train loss item: 0.21931993961334229
train loss item: 0.3099389970302582
train loss item: 0.1262792944908142
train loss item: 0.2721835672855377
train loss item: 0.2351921796798706
train loss item: 0.23688586056232452
train loss item: 0.17282603681087494
train loss item: 0.319706529378891
train loss item: 0.21317479014396667
train loss item: 0.5189911127090454
train loss item: 0.21421681344509125
test loss item: 0.1601315140724182
test loss item: 0.28342223167419434
test loss item: 0.2383066713809967
test loss item: 0.11281216889619827
test loss item: 0.2247876226902008
test loss item: 0.16915223002433777
test loss item: 0.13699881732463837
test loss item: 0.23032481968402863
test loss item: 0.24120265245437622
test loss item: 0.3042825758457184
test loss item: 0.14495429396629333
test loss item: 0.17866484820842743
test loss item: 0.22069256007671356
test loss item: 0.22009170055389404
test loss item: 0.21563969552516937
test loss item: 0.13694792985916138
test loss item: 0.2366376370191574
test loss item: 0.276886522769928
test loss item: 0.13242939114570618
test loss item: 0.2955596148967743
test loss item: 0.3735399544239044
test loss item: 0.11471997946500778
test loss item: 0.13629578053951263
Epoch [13/100], Training Loss: 0.2401, Testing Loss: 0.2080
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 14/100
train loss item: 0.26680800318717957
train loss item: 0.20008118450641632
train loss item: 0.17676971852779388
train loss item: 0.22536203265190125
train loss item: 0.1596231758594513
train loss item: 0.40789416432380676
train loss item: 0.19853253662586212
train loss item: 0.5949454307556152
train loss item: 0.4015979468822479
train loss item: 0.191998690366745
train loss item: 0.16166791319847107
train loss item: 0.209014892578125
train loss item: 0.32549425959587097
train loss item: 0.33222678303718567
train loss item: 0.14557477831840515
train loss item: 0.2881243824958801
train loss item: 0.19955666363239288
train loss item: 0.16673146188259125
train loss item: 0.1351034939289093
train loss item: 0.26463583111763
train loss item: 0.1899857521057129
train loss item: 0.6176031827926636
train loss item: 0.19916678965091705
test loss item: 0.1796843260526657
test loss item: 0.30139821767807007
test loss item: 0.28476062417030334
test loss item: 0.10655046254396439
test loss item: 0.21571114659309387
test loss item: 0.18129470944404602
test loss item: 0.13907988369464874
test loss item: 0.25807610154151917
test loss item: 0.24951747059822083
test loss item: 0.35717764496803284
test loss item: 0.1562759131193161
test loss item: 0.1796618103981018
test loss item: 0.23809675872325897
test loss item: 0.25124847888946533
test loss item: 0.21973517537117004
test loss item: 0.14346225559711456
test loss item: 0.2452402412891388
test loss item: 0.27293989062309265
test loss item: 0.14870381355285645
test loss item: 0.4265054762363434
test loss item: 0.4491974711418152
test loss item: 0.12200651317834854
test loss item: 0.12206996232271194
Epoch [14/100], Training Loss: 0.2634, Testing Loss: 0.2282
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 15/100
train loss item: 0.228946715593338
train loss item: 0.1675272434949875
train loss item: 0.1498720645904541
train loss item: 0.17613311111927032
train loss item: 0.13397552073001862
train loss item: 0.21856537461280823
train loss item: 0.13957946002483368
train loss item: 0.33557847142219543
train loss item: 0.2637956440448761
train loss item: 0.19079814851284027
train loss item: 0.12978248298168182
train loss item: 0.20682895183563232
train loss item: 0.22771188616752625
train loss item: 0.21472673118114471
train loss item: 0.12125647813081741
train loss item: 0.25562208890914917
train loss item: 0.1670817881822586
train loss item: 0.16048449277877808
train loss item: 0.13241486251354218
train loss item: 0.23405969142913818
train loss item: 0.14425140619277954
train loss item: 0.4909502863883972
train loss item: 0.18450158834457397
test loss item: 0.16124969720840454
test loss item: 0.2994196116924286
test loss item: 0.22193001210689545
test loss item: 0.11109351366758347
test loss item: 0.21225932240486145
test loss item: 0.164017453789711
test loss item: 0.12859538197517395
test loss item: 0.22357052564620972
test loss item: 0.21217475831508636
test loss item: 0.3001304566860199
test loss item: 0.13457873463630676
test loss item: 0.1727321296930313
test loss item: 0.2037145346403122
test loss item: 0.210099458694458
test loss item: 0.20159423351287842
test loss item: 0.13607807457447052
test loss item: 0.24035987257957458
test loss item: 0.27408090233802795
test loss item: 0.1293306201696396
test loss item: 0.335923433303833
test loss item: 0.36559703946113586
test loss item: 0.11686617136001587
test loss item: 0.12316663563251495
Epoch [15/100], Training Loss: 0.2032, Testing Loss: 0.2034
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 16/100
train loss item: 0.3294840455055237
train loss item: 0.211842879652977
train loss item: 0.155979186296463
train loss item: 0.198166161775589
train loss item: 0.14407074451446533
train loss item: 0.35713547468185425
train loss item: 0.196752667427063
train loss item: 0.5281106233596802
train loss item: 0.42944610118865967
train loss item: 0.1845114529132843
train loss item: 0.137818843126297
train loss item: 0.1790495067834854
train loss item: 0.2660939693450928
train loss item: 0.22506950795650482
train loss item: 0.14980274438858032
train loss item: 0.25183576345443726
train loss item: 0.213689923286438
train loss item: 0.18492983281612396
train loss item: 0.1339482069015503
train loss item: 0.25151726603507996
train loss item: 0.13956229388713837
train loss item: 0.5547567009925842
train loss item: 0.19193507730960846
test loss item: 0.19331687688827515
test loss item: 0.42068493366241455
test loss item: 0.32673466205596924
test loss item: 0.11936081200838089
test loss item: 0.2717597484588623
test loss item: 0.18471305072307587
test loss item: 0.14357441663742065
test loss item: 0.32588014006614685
test loss item: 0.2751631438732147
test loss item: 0.44881439208984375
test loss item: 0.1466091424226761
test loss item: 0.19931411743164062
test loss item: 0.2766345739364624
test loss item: 0.2859109044075012
test loss item: 0.26642146706581116
test loss item: 0.15261481702327728
test loss item: 0.3222789466381073
test loss item: 0.3719116151332855
test loss item: 0.1453997641801834
test loss item: 0.6204159259796143
test loss item: 0.5715383887290955
test loss item: 0.12373613566160202
test loss item: 0.1384059488773346
Epoch [16/100], Training Loss: 0.2442, Testing Loss: 0.2753
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 17/100
train loss item: 0.27539995312690735
train loss item: 0.18077456951141357
train loss item: 0.18190507590770721
train loss item: 0.17053668200969696
train loss item: 0.12692496180534363
train loss item: 0.22567088901996613
train loss item: 0.17255879938602448
train loss item: 0.37066149711608887
train loss item: 0.24345017969608307
train loss item: 0.16179810464382172
train loss item: 0.1267302930355072
train loss item: 0.19900421798229218
train loss item: 0.2250491976737976
train loss item: 0.20043319463729858
train loss item: 0.11900115013122559
train loss item: 0.24356688559055328
train loss item: 0.15602724254131317
train loss item: 0.16292399168014526
train loss item: 0.1247214525938034
train loss item: 0.272529661655426
train loss item: 0.18384087085723877
train loss item: 0.46130335330963135
train loss item: 0.18393369019031525
test loss item: 0.16081087291240692
test loss item: 0.31900957226753235
test loss item: 0.21046869456768036
test loss item: 0.11580783128738403
test loss item: 0.23014183342456818
test loss item: 0.16679568588733673
test loss item: 0.12656879425048828
test loss item: 0.2197098731994629
test loss item: 0.2127983719110489
test loss item: 0.2987281084060669
test loss item: 0.13221056759357452
test loss item: 0.1855752319097519
test loss item: 0.20967762172222137
test loss item: 0.19426329433918
test loss item: 0.21439382433891296
test loss item: 0.14525870978832245
test loss item: 0.24387580156326294
test loss item: 0.29156768321990967
test loss item: 0.13542963564395905
test loss item: 0.29060932993888855
test loss item: 0.35016751289367676
test loss item: 0.11437075585126877
test loss item: 0.14595510065555573
Epoch [17/100], Training Loss: 0.2073, Testing Loss: 0.2050
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 18/100
train loss item: 0.29626163840293884
train loss item: 0.22338180243968964
train loss item: 0.20735269784927368
train loss item: 0.25005561113357544
train loss item: 0.15922711789608002
train loss item: 0.3071649670600891
train loss item: 0.18213628232479095
train loss item: 0.5125168561935425
train loss item: 0.3134649097919464
train loss item: 0.1735188066959381
train loss item: 0.1253887116909027
train loss item: 0.16596175730228424
train loss item: 0.24805885553359985
train loss item: 0.2162068486213684
train loss item: 0.12015294283628464
train loss item: 0.24113337695598602
train loss item: 0.19948618113994598
train loss item: 0.18785406649112701
train loss item: 0.1287885159254074
train loss item: 0.23924410343170166
train loss item: 0.15299351513385773
train loss item: 0.5375816822052002
train loss item: 0.16012544929981232
test loss item: 0.1628638654947281
test loss item: 0.23263581097126007
test loss item: 0.25347089767456055
test loss item: 0.10029809176921844
test loss item: 0.17313732206821442
test loss item: 0.14999300241470337
test loss item: 0.12205490469932556
test loss item: 0.237369105219841
test loss item: 0.20064838230609894
test loss item: 0.31710749864578247
test loss item: 0.13091380894184113
test loss item: 0.15330538153648376
test loss item: 0.20507968962192535
test loss item: 0.22692139446735382
test loss item: 0.17767518758773804
test loss item: 0.12729519605636597
test loss item: 0.22852103412151337
test loss item: 0.21955224871635437
test loss item: 0.119967982172966
test loss item: 0.46206915378570557
test loss item: 0.4031878113746643
test loss item: 0.10366378724575043
test loss item: 0.13658976554870605
Epoch [18/100], Training Loss: 0.2325, Testing Loss: 0.2019
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 19/100
train loss item: 0.21972796320915222
train loss item: 0.16957305371761322
train loss item: 0.14151456952095032
train loss item: 0.17423762381076813
train loss item: 0.13289126753807068
train loss item: 0.21843111515045166
train loss item: 0.13579939305782318
train loss item: 0.3474935293197632
train loss item: 0.23699678480625153
train loss item: 0.15113380551338196
train loss item: 0.11902102082967758
train loss item: 0.20779629051685333
train loss item: 0.26744601130485535
train loss item: 0.226492777466774
train loss item: 0.12643872201442719
train loss item: 0.28856196999549866
train loss item: 0.1721901148557663
train loss item: 0.16642650961875916
train loss item: 0.13053841888904572
train loss item: 0.22157888114452362
train loss item: 0.1657019555568695
train loss item: 0.4273030161857605
train loss item: 0.20265942811965942
test loss item: 0.17762506008148193
test loss item: 0.2440488040447235
test loss item: 0.22039107978343964
test loss item: 0.11623474955558777
test loss item: 0.17953601479530334
test loss item: 0.15724314749240875
test loss item: 0.12369533628225327
test loss item: 0.21079221367835999
test loss item: 0.19390423595905304
test loss item: 0.29341304302215576
test loss item: 0.13225041329860687
test loss item: 0.16237659752368927
test loss item: 0.19492167234420776
test loss item: 0.2072065770626068
test loss item: 0.17959614098072052
test loss item: 0.1368192881345749
test loss item: 0.2419702708721161
test loss item: 0.22931832075119019
test loss item: 0.12124716490507126
test loss item: 0.3929871618747711
test loss item: 0.3600448668003082
test loss item: 0.11227938532829285
test loss item: 0.14409080147743225
Epoch [19/100], Training Loss: 0.2022, Testing Loss: 0.1970
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 20/100
train loss item: 0.3295484483242035
train loss item: 0.2694641053676605
train loss item: 0.14446505904197693
train loss item: 0.20536331832408905
train loss item: 0.1368778795003891
train loss item: 0.3625454902648926
train loss item: 0.17700538039207458
train loss item: 0.4999319314956665
train loss item: 0.3274655342102051
train loss item: 0.18332551419734955
train loss item: 0.11752448230981827
train loss item: 0.1534779965877533
train loss item: 0.19486628472805023
train loss item: 0.1957320123910904
train loss item: 0.11709509044885635
train loss item: 0.23310010135173798
train loss item: 0.19370603561401367
train loss item: 0.18546414375305176
train loss item: 0.13286824524402618
train loss item: 0.22768720984458923
train loss item: 0.1573605239391327
train loss item: 0.4661594331264496
train loss item: 0.1738075613975525
test loss item: 0.13783618807792664
test loss item: 0.2978697419166565
test loss item: 0.19433185458183289
test loss item: 0.09578177332878113
test loss item: 0.1780974119901657
test loss item: 0.14693129062652588
test loss item: 0.11245591193437576
test loss item: 0.2038741558790207
test loss item: 0.1763007491827011
test loss item: 0.2594720125198364
test loss item: 0.12763139605522156
test loss item: 0.14637437462806702
test loss item: 0.17592525482177734
test loss item: 0.16946786642074585
test loss item: 0.1665460765361786
test loss item: 0.12100983411073685
test loss item: 0.19940724968910217
test loss item: 0.24678778648376465
test loss item: 0.11981262266635895
test loss item: 0.29765594005584717
test loss item: 0.32816657423973083
test loss item: 0.10056187957525253
test loss item: 0.14266635477542877
Epoch [20/100], Training Loss: 0.2254, Testing Loss: 0.1802
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 21/100
train loss item: 0.21192950010299683
train loss item: 0.1513659805059433
train loss item: 0.15720757842063904
train loss item: 0.17552879452705383
train loss item: 0.12109140306711197
train loss item: 0.19437909126281738
train loss item: 0.14551374316215515
train loss item: 0.2984374761581421
train loss item: 0.22903266549110413
train loss item: 0.15088631212711334
train loss item: 0.11160120368003845
train loss item: 0.1719515472650528
train loss item: 0.19196651875972748
train loss item: 0.16469374299049377
train loss item: 0.11089547723531723
train loss item: 0.22682934999465942
train loss item: 0.13952848315238953
train loss item: 0.15129080414772034
train loss item: 0.11152403056621552
train loss item: 0.22354988753795624
train loss item: 0.15596020221710205
train loss item: 0.41304588317871094
train loss item: 0.17336955666542053
test loss item: 0.14453130960464478
test loss item: 0.26629960536956787
test loss item: 0.17918217182159424
test loss item: 0.1055186465382576
test loss item: 0.169289693236351
test loss item: 0.14344587922096252
test loss item: 0.10987021774053574
test loss item: 0.18158407509326935
test loss item: 0.16385018825531006
test loss item: 0.24197493493556976
test loss item: 0.12508796155452728
test loss item: 0.14698705077171326
test loss item: 0.1685885637998581
test loss item: 0.16347292065620422
test loss item: 0.1614900529384613
test loss item: 0.13154713809490204
test loss item: 0.20582729578018188
test loss item: 0.22776363790035248
test loss item: 0.11936765164136887
test loss item: 0.25745129585266113
test loss item: 0.28787288069725037
test loss item: 0.09717462211847305
test loss item: 0.13131681084632874
Epoch [21/100], Training Loss: 0.1818, Testing Loss: 0.1708
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 22/100
train loss item: 0.2462712973356247
train loss item: 0.17773354053497314
train loss item: 0.13596728444099426
train loss item: 0.18207339942455292
train loss item: 0.12048690766096115
train loss item: 0.26018092036247253
train loss item: 0.15616431832313538
train loss item: 0.30202221870422363
train loss item: 0.22907467186450958
train loss item: 0.15547329187393188
train loss item: 0.10893195867538452
train loss item: 0.15909703075885773
train loss item: 0.19934295117855072
train loss item: 0.18744276463985443
train loss item: 0.1119542196393013
train loss item: 0.2072267085313797
train loss item: 0.15942680835723877
train loss item: 0.15146490931510925
train loss item: 0.10530838370323181
train loss item: 0.20989342033863068
train loss item: 0.1357443630695343
train loss item: 0.47588562965393066
train loss item: 0.15204840898513794
test loss item: 0.13389527797698975
test loss item: 0.26693472266197205
test loss item: 0.1862534135580063
test loss item: 0.09247994422912598
test loss item: 0.16416361927986145
test loss item: 0.14189434051513672
test loss item: 0.10690594464540482
test loss item: 0.19203388690948486
test loss item: 0.160174161195755
test loss item: 0.25104203820228577
test loss item: 0.11894483864307404
test loss item: 0.14579182863235474
test loss item: 0.16288861632347107
test loss item: 0.16107065975666046
test loss item: 0.15330401062965393
test loss item: 0.11647063493728638
test loss item: 0.20093275606632233
test loss item: 0.2280862033367157
test loss item: 0.12225428223609924
test loss item: 0.3467080593109131
test loss item: 0.3175504505634308
test loss item: 0.09391604363918304
test loss item: 0.1207805797457695
Epoch [22/100], Training Loss: 0.1882, Testing Loss: 0.1732
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 23/100
train loss item: 0.18727868795394897
train loss item: 0.14515942335128784
train loss item: 0.15408724546432495
train loss item: 0.16890351474285126
train loss item: 0.13844239711761475
train loss item: 0.2025238275527954
train loss item: 0.12646186351776123
train loss item: 0.33273008465766907
train loss item: 0.21279336512088776
train loss item: 0.15577343106269836
train loss item: 0.11598751693964005
train loss item: 0.22659385204315186
train loss item: 0.26916444301605225
train loss item: 0.26829227805137634
train loss item: 0.12845660746097565
train loss item: 0.29792389273643494
train loss item: 0.13997891545295715
train loss item: 0.14334774017333984
train loss item: 0.11367404460906982
train loss item: 0.23514911532402039
train loss item: 0.17571015655994415
train loss item: 0.39432448148727417
train loss item: 0.17773400247097015
test loss item: 0.16043075919151306
test loss item: 0.25868090987205505
test loss item: 0.20305804908275604
test loss item: 0.11035558581352234
test loss item: 0.1614675372838974
test loss item: 0.14298607409000397
test loss item: 0.11137280613183975
test loss item: 0.19215019047260284
test loss item: 0.17045855522155762
test loss item: 0.2637118101119995
test loss item: 0.12981051206588745
test loss item: 0.14180725812911987
test loss item: 0.18034911155700684
test loss item: 0.18108604848384857
test loss item: 0.16481894254684448
test loss item: 0.13548831641674042
test loss item: 0.21551308035850525
test loss item: 0.21686820685863495
test loss item: 0.11482866108417511
test loss item: 0.31927192211151123
test loss item: 0.3263518214225769
test loss item: 0.1026197150349617
test loss item: 0.13363438844680786
Epoch [23/100], Training Loss: 0.1961, Testing Loss: 0.1799
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 24/100
train loss item: 0.35224348306655884
train loss item: 0.2622198164463043
train loss item: 0.13739053905010223
train loss item: 0.1755034476518631
train loss item: 0.12023749202489853
train loss item: 0.2948262095451355
train loss item: 0.15277978777885437
train loss item: 0.41142889857292175
train loss item: 0.3448958694934845
train loss item: 0.1676167994737625
train loss item: 0.10748112201690674
train loss item: 0.15611201524734497
train loss item: 0.1909448802471161
train loss item: 0.19737403094768524
train loss item: 0.11864422261714935
train loss item: 0.2167723923921585
train loss item: 0.17842189967632294
train loss item: 0.16719357669353485
train loss item: 0.11258739978075027
train loss item: 0.20982274413108826
train loss item: 0.1488095223903656
train loss item: 0.45374685525894165
train loss item: 0.15616385638713837
test loss item: 0.1326574832201004
test loss item: 0.29585880041122437
test loss item: 0.1868574619293213
test loss item: 0.09101874381303787
test loss item: 0.16116468608379364
test loss item: 0.14138785004615784
test loss item: 0.10420972853899002
test loss item: 0.19790677726268768
test loss item: 0.1628539264202118
test loss item: 0.25862810015678406
test loss item: 0.1194063201546669
test loss item: 0.13763253390789032
test loss item: 0.15966437757015228
test loss item: 0.1601017415523529
test loss item: 0.1544390320777893
test loss item: 0.11420323699712753
test loss item: 0.20675700902938843
test loss item: 0.24030376970767975
test loss item: 0.11899895966053009
test loss item: 0.3770269751548767
test loss item: 0.3388630747795105
test loss item: 0.09429201483726501
test loss item: 0.12774255871772766
Epoch [24/100], Training Loss: 0.2101, Testing Loss: 0.1775
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 25/100
train loss item: 0.19063913822174072
train loss item: 0.14384697377681732
train loss item: 0.14800021052360535
train loss item: 0.15716025233268738
train loss item: 0.12387420982122421
train loss item: 0.16202756762504578
train loss item: 0.12265879660844803
train loss item: 0.30364716053009033
train loss item: 0.21827886998653412
train loss item: 0.145822674036026
train loss item: 0.10381804406642914
train loss item: 0.1751747876405716
train loss item: 0.22944797575473785
train loss item: 0.16986499726772308
train loss item: 0.1214500293135643
train loss item: 0.24146583676338196
train loss item: 0.1446681022644043
train loss item: 0.1365506947040558
train loss item: 0.10129716247320175
train loss item: 0.20694807171821594
train loss item: 0.14663732051849365
train loss item: 0.3845704197883606
train loss item: 0.18313871324062347
test loss item: 0.14729353785514832
test loss item: 0.35016530752182007
test loss item: 0.19317099452018738
test loss item: 0.10314518958330154
test loss item: 0.18006758391857147
test loss item: 0.14783096313476562
test loss item: 0.10801151394844055
test loss item: 0.21600349247455597
test loss item: 0.1624174863100052
test loss item: 0.2721686363220215
test loss item: 0.12610511481761932
test loss item: 0.15221138298511505
test loss item: 0.18178722262382507
test loss item: 0.1742190271615982
test loss item: 0.16985850036144257
test loss item: 0.13537396490573883
test loss item: 0.2221045196056366
test loss item: 0.26616862416267395
test loss item: 0.12974491715431213
test loss item: 0.29605093598365784
test loss item: 0.34517231583595276
test loss item: 0.09560190141201019
test loss item: 0.1262759119272232
Epoch [25/100], Training Loss: 0.1766, Testing Loss: 0.1870
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 26/100
train loss item: 0.3210497498512268
train loss item: 0.22890761494636536
train loss item: 0.14133521914482117
train loss item: 0.1639239639043808
train loss item: 0.1109471470117569
train loss item: 0.23931726813316345
train loss item: 0.13972455263137817
train loss item: 0.29048654437065125
train loss item: 0.19851459562778473
train loss item: 0.14661569893360138
train loss item: 0.10520016402006149
train loss item: 0.14729398488998413
train loss item: 0.1871853768825531
train loss item: 0.16252799332141876
train loss item: 0.10645906627178192
train loss item: 0.19712276756763458
train loss item: 0.15490393340587616
train loss item: 0.13941043615341187
train loss item: 0.0996871069073677
train loss item: 0.20237860083580017
train loss item: 0.1297122836112976
train loss item: 0.4359680414199829
train loss item: 0.1419679969549179
test loss item: 0.12290987372398376
test loss item: 0.252189040184021
test loss item: 0.15999479591846466
test loss item: 0.08763483166694641
test loss item: 0.15226519107818604
test loss item: 0.1342976689338684
test loss item: 0.09887459874153137
test loss item: 0.1669754832983017
test loss item: 0.15227362513542175
test loss item: 0.21743695437908173
test loss item: 0.11539997905492783
test loss item: 0.13278943300247192
test loss item: 0.14758916199207306
test loss item: 0.14167827367782593
test loss item: 0.14444833993911743
test loss item: 0.11053770780563354
test loss item: 0.17499364912509918
test loss item: 0.21071216464042664
test loss item: 0.1118679791688919
test loss item: 0.2658942937850952
test loss item: 0.26432809233665466
test loss item: 0.08886934071779251
test loss item: 0.11114319413900375
Epoch [26/100], Training Loss: 0.1822, Testing Loss: 0.1550
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 27/100
train loss item: 0.17717178165912628
train loss item: 0.13770513236522675
train loss item: 0.16518571972846985
train loss item: 0.18624773621559143
train loss item: 0.14934976398944855
train loss item: 0.18440678715705872
train loss item: 0.12099681049585342
train loss item: 0.3174932301044464
train loss item: 0.21132424473762512
train loss item: 0.14384518563747406
train loss item: 0.10777841508388519
train loss item: 0.2082621306180954
train loss item: 0.3151760697364807
train loss item: 0.23811431229114532
train loss item: 0.13426262140274048
train loss item: 0.2951938211917877
train loss item: 0.17311182618141174
train loss item: 0.14018985629081726
train loss item: 0.0974762812256813
train loss item: 0.25033435225486755
train loss item: 0.14860320091247559
train loss item: 0.3664822280406952
train loss item: 0.17616590857505798
test loss item: 0.13675999641418457
test loss item: 0.41106221079826355
test loss item: 0.18444333970546722
test loss item: 0.10039430856704712
test loss item: 0.1936027854681015
test loss item: 0.15532980859279633
test loss item: 0.10733946412801743
test loss item: 0.23187488317489624
test loss item: 0.16497360169887543
test loss item: 0.273039847612381
test loss item: 0.12808114290237427
test loss item: 0.14548663794994354
test loss item: 0.18601439893245697
test loss item: 0.15865744650363922
test loss item: 0.17682170867919922
test loss item: 0.13664862513542175
test loss item: 0.21592967212200165
test loss item: 0.3003859519958496
test loss item: 0.13384351134300232
test loss item: 0.23486296832561493
test loss item: 0.35019806027412415
test loss item: 0.09603886306285858
test loss item: 0.1687602996826172
Epoch [27/100], Training Loss: 0.1933, Testing Loss: 0.1909
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 28/100
train loss item: 0.38933104276657104
train loss item: 0.31992024183273315
train loss item: 0.22427202761173248
train loss item: 0.20650802552700043
train loss item: 0.14838242530822754
train loss item: 0.22650161385536194
train loss item: 0.1304706186056137
train loss item: 0.2582857310771942
train loss item: 0.19092778861522675
train loss item: 0.14375180006027222
train loss item: 0.10505401343107224
train loss item: 0.16164745390415192
train loss item: 0.2540617287158966
train loss item: 0.18286322057247162
train loss item: 0.119301937520504
train loss item: 0.2174416184425354
train loss item: 0.18561312556266785
train loss item: 0.1547159105539322
train loss item: 0.09856586903333664
train loss item: 0.21943534910678864
train loss item: 0.1424255669116974
train loss item: 0.4507836103439331
train loss item: 0.13428950309753418
test loss item: 0.1298304796218872
test loss item: 0.2685147225856781
test loss item: 0.17736224830150604
test loss item: 0.09042159467935562
test loss item: 0.15688550472259521
test loss item: 0.14056748151779175
test loss item: 0.10313095152378082
test loss item: 0.18530680239200592
test loss item: 0.16757123172283173
test loss item: 0.2362983524799347
test loss item: 0.12214082479476929
test loss item: 0.14129111170768738
test loss item: 0.15464329719543457
test loss item: 0.1537688970565796
test loss item: 0.14783376455307007
test loss item: 0.11175112426280975
test loss item: 0.188413605093956
test loss item: 0.21905013918876648
test loss item: 0.12017311155796051
test loss item: 0.3173576295375824
test loss item: 0.30364498496055603
test loss item: 0.09498005360364914
test loss item: 0.12249833345413208
Epoch [28/100], Training Loss: 0.2028, Testing Loss: 0.1675
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 29/100
train loss item: 0.17465823888778687
train loss item: 0.14106640219688416
train loss item: 0.16695930063724518
train loss item: 0.18772609531879425
train loss item: 0.14594897627830505
train loss item: 0.17873108386993408
train loss item: 0.1340448409318924
train loss item: 0.3159864842891693
train loss item: 0.20996956527233124
train loss item: 0.1351364403963089
train loss item: 0.09842332452535629
train loss item: 0.182668074965477
train loss item: 0.3185097277164459
train loss item: 0.2842142581939697
train loss item: 0.13032644987106323
train loss item: 0.38044238090515137
train loss item: 0.1823606938123703
train loss item: 0.1539534628391266
train loss item: 0.09825698286294937
train loss item: 0.37657687067985535
train loss item: 0.19828477501869202
train loss item: 0.3643452227115631
train loss item: 0.15358823537826538
test loss item: 0.1223040223121643
test loss item: 0.2179628610610962
test loss item: 0.16097678244113922
test loss item: 0.0940299779176712
test loss item: 0.13721449673175812
test loss item: 0.12848934531211853
test loss item: 0.09999502450227737
test loss item: 0.15847882628440857
test loss item: 0.14647246897220612
test loss item: 0.20047515630722046
test loss item: 0.11602971702814102
test loss item: 0.12393752485513687
test loss item: 0.148379847407341
test loss item: 0.14220641553401947
test loss item: 0.13650265336036682
test loss item: 0.11630523949861526
test loss item: 0.15880373120307922
test loss item: 0.1762693077325821
test loss item: 0.1058875024318695
test loss item: 0.20799605548381805
test loss item: 0.2359316498041153
test loss item: 0.0871155709028244
test loss item: 0.1173432245850563
Epoch [29/100], Training Loss: 0.2049, Testing Loss: 0.1452
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 30/100
train loss item: 0.27650967240333557
train loss item: 0.24410250782966614
train loss item: 0.20866133272647858
train loss item: 0.2127014398574829
train loss item: 0.20369724929332733
train loss item: 0.2470952570438385
train loss item: 0.17026446759700775
train loss item: 0.23733364045619965
train loss item: 0.21544747054576874
train loss item: 0.14764773845672607
train loss item: 0.10647398233413696
train loss item: 0.15070600807666779
train loss item: 0.30630338191986084
train loss item: 0.2078259140253067
train loss item: 0.1364072561264038
train loss item: 0.35936906933784485
train loss item: 0.2564890384674072
train loss item: 0.22101983428001404
train loss item: 0.13241423666477203
train loss item: 0.462569922208786
train loss item: 0.31974583864212036
train loss item: 0.47673529386520386
train loss item: 0.16394823789596558
test loss item: 0.13104566931724548
test loss item: 0.2398844212293625
test loss item: 0.17684999108314514
test loss item: 0.09328819066286087
test loss item: 0.1586875468492508
test loss item: 0.1534588783979416
test loss item: 0.1098596453666687
test loss item: 0.16631926596164703
test loss item: 0.16019479930400848
test loss item: 0.23617400228977203
test loss item: 0.12290113419294357
test loss item: 0.13936202228069305
test loss item: 0.16535145044326782
test loss item: 0.15853632986545563
test loss item: 0.1624840348958969
test loss item: 0.12447546422481537
test loss item: 0.1870727390050888
test loss item: 0.2010284662246704
test loss item: 0.11009517312049866
test loss item: 0.2953723669052124
test loss item: 0.27255433797836304
test loss item: 0.10161151736974716
test loss item: 0.11967595666646957
Epoch [30/100], Training Loss: 0.2375, Testing Loss: 0.1646
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 31/100
train loss item: 0.24370920658111572
train loss item: 0.1404763013124466
train loss item: 0.20142477750778198
train loss item: 0.18259316682815552
train loss item: 0.18442954123020172
train loss item: 0.2507009208202362
train loss item: 0.21056683361530304
train loss item: 0.37120741605758667
train loss item: 0.2520011067390442
train loss item: 0.21645787358283997
train loss item: 0.14300468564033508
train loss item: 0.18029487133026123
train loss item: 0.23892426490783691
train loss item: 0.17800301313400269
train loss item: 0.13681647181510925
train loss item: 0.3466019928455353
train loss item: 0.1936098337173462
train loss item: 0.16736705601215363
train loss item: 0.11531952768564224
train loss item: 0.49278244376182556
train loss item: 0.2977950870990753
train loss item: 0.46532124280929565
train loss item: 0.15840622782707214
test loss item: 0.13504907488822937
test loss item: 0.39869987964630127
test loss item: 0.19245240092277527
test loss item: 0.10713032633066177
test loss item: 0.2148693948984146
test loss item: 0.17721961438655853
test loss item: 0.12909328937530518
test loss item: 0.21742673218250275
test loss item: 0.17657141387462616
test loss item: 0.28354397416114807
test loss item: 0.14003866910934448
test loss item: 0.16699282824993134
test loss item: 0.19581259787082672
test loss item: 0.16259975731372833
test loss item: 0.20002925395965576
test loss item: 0.1412218064069748
test loss item: 0.24174319207668304
test loss item: 0.301765501499176
test loss item: 0.13670462369918823
test loss item: 0.2587931454181671
test loss item: 0.3525431454181671
test loss item: 0.11639726161956787
test loss item: 0.18998296558856964
Epoch [31/100], Training Loss: 0.2334, Testing Loss: 0.2016
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 32/100
train loss item: 0.25538328289985657
train loss item: 0.13793841004371643
train loss item: 0.15354211628437042
train loss item: 0.13163438439369202
train loss item: 0.15470021963119507
train loss item: 0.15472330152988434
train loss item: 0.1576431393623352
train loss item: 0.27615463733673096
train loss item: 0.23706939816474915
train loss item: 0.2475038468837738
train loss item: 0.1904383897781372
train loss item: 0.2270367443561554
train loss item: 0.18034279346466064
train loss item: 0.17133286595344543
train loss item: 0.12213712930679321
train loss item: 0.23973135650157928
train loss item: 0.13994406163692474
train loss item: 0.13438910245895386
train loss item: 0.10663668811321259
train loss item: 0.4108026325702667
train loss item: 0.24927593767642975
train loss item: 0.4565374255180359
train loss item: 0.13737937808036804
test loss item: 0.1331678330898285
test loss item: 0.3157668113708496
test loss item: 0.1960468739271164
test loss item: 0.10683279484510422
test loss item: 0.1858280450105667
test loss item: 0.16734763979911804
test loss item: 0.11944007873535156
test loss item: 0.19848237931728363
test loss item: 0.16659876704216003
test loss item: 0.25929102301597595
test loss item: 0.1379634588956833
test loss item: 0.16151267290115356
test loss item: 0.1854173243045807
test loss item: 0.16712450981140137
test loss item: 0.18629199266433716
test loss item: 0.1387404203414917
test loss item: 0.22262294590473175
test loss item: 0.24845300614833832
test loss item: 0.13248856365680695
test loss item: 0.27186906337738037
test loss item: 0.3164883852005005
test loss item: 0.11262401938438416
test loss item: 0.11811041831970215
Epoch [32/100], Training Loss: 0.2031, Testing Loss: 0.1847
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 33/100
train loss item: 0.2394869476556778
train loss item: 0.1391870677471161
train loss item: 0.13280414044857025
train loss item: 0.13765528798103333
train loss item: 0.12144387513399124
train loss item: 0.15177421271800995
train loss item: 0.13761208951473236
train loss item: 0.23690998554229736
train loss item: 0.19978280365467072
train loss item: 0.25432780385017395
train loss item: 0.15089400112628937
train loss item: 0.18910600244998932
train loss item: 0.1671217381954193
train loss item: 0.15274587273597717
train loss item: 0.11366903781890869
train loss item: 0.20200374722480774
train loss item: 0.13331542909145355
train loss item: 0.1307835578918457
train loss item: 0.09910612553358078
train loss item: 0.37847158312797546
train loss item: 0.23006364703178406
train loss item: 0.4330531358718872
train loss item: 0.1295488327741623
test loss item: 0.12055771052837372
test loss item: 0.3069410026073456
test loss item: 0.1710209995508194
test loss item: 0.09402292221784592
test loss item: 0.17202390730381012
test loss item: 0.14825980365276337
test loss item: 0.10682778060436249
test loss item: 0.18339264392852783
test loss item: 0.15610356628894806
test loss item: 0.23314258456230164
test loss item: 0.1230773851275444
test loss item: 0.13976122438907623
test loss item: 0.16666415333747864
test loss item: 0.14524021744728088
test loss item: 0.1719742715358734
test loss item: 0.12322323769330978
test loss item: 0.1947474181652069
test loss item: 0.23731529712677002
test loss item: 0.11869923770427704
test loss item: 0.2180681675672531
test loss item: 0.28167644143104553
test loss item: 0.09779740869998932
test loss item: 0.11751830577850342
Epoch [33/100], Training Loss: 0.1853, Testing Loss: 0.1664
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 34/100
train loss item: 0.20376364886760712
train loss item: 0.12532517313957214
train loss item: 0.11830712109804153
train loss item: 0.12127189338207245
train loss item: 0.11575163155794144
train loss item: 0.1441047042608261
train loss item: 0.12345671653747559
train loss item: 0.24116741120815277
train loss item: 0.1925824135541916
train loss item: 0.22946125268936157
train loss item: 0.13704071938991547
train loss item: 0.16934096813201904
train loss item: 0.16310930252075195
train loss item: 0.14487800002098083
train loss item: 0.10518139600753784
train loss item: 0.1887676864862442
train loss item: 0.12533362209796906
train loss item: 0.12945611774921417
train loss item: 0.09334671497344971
train loss item: 0.33753103017807007
train loss item: 0.20090529322624207
train loss item: 0.4173479974269867
train loss item: 0.12190799415111542
test loss item: 0.12003184854984283
test loss item: 0.28179818391799927
test loss item: 0.16487714648246765
test loss item: 0.09078771620988846
test loss item: 0.15635579824447632
test loss item: 0.13976620137691498
test loss item: 0.10319552570581436
test loss item: 0.1723804622888565
test loss item: 0.14631932973861694
test loss item: 0.22140571475028992
test loss item: 0.11756489425897598
test loss item: 0.13077059388160706
test loss item: 0.15623421967029572
test loss item: 0.14408855140209198
test loss item: 0.15896663069725037
test loss item: 0.11734294891357422
test loss item: 0.18476730585098267
test loss item: 0.21831853687763214
test loss item: 0.11255518347024918
test loss item: 0.22310347855091095
test loss item: 0.2653098404407501
test loss item: 0.09503217786550522
test loss item: 0.10587261617183685
Epoch [34/100], Training Loss: 0.1717, Testing Loss: 0.1577
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 35/100
train loss item: 0.1858985424041748
train loss item: 0.12423982471227646
train loss item: 0.11328166723251343
train loss item: 0.11910589784383774
train loss item: 0.10909666121006012
train loss item: 0.14044232666492462
train loss item: 0.1157105565071106
train loss item: 0.22005029022693634
train loss item: 0.17575672268867493
train loss item: 0.2068803608417511
train loss item: 0.11896830797195435
train loss item: 0.14599904417991638
train loss item: 0.16129018366336823
train loss item: 0.14593487977981567
train loss item: 0.10839046537876129
train loss item: 0.18596261739730835
train loss item: 0.13161471486091614
train loss item: 0.1369762420654297
train loss item: 0.09214328974485397
train loss item: 0.32025715708732605
train loss item: 0.1884596198797226
train loss item: 0.4117935299873352
train loss item: 0.11898630857467651
test loss item: 0.11714846640825272
test loss item: 0.2650096118450165
test loss item: 0.16311416029930115
test loss item: 0.08943656831979752
test loss item: 0.15078304708003998
test loss item: 0.13517224788665771
test loss item: 0.09986016154289246
test loss item: 0.1681528091430664
test loss item: 0.1465907245874405
test loss item: 0.2157050520181656
test loss item: 0.11200115084648132
test loss item: 0.12907268106937408
test loss item: 0.1537986546754837
test loss item: 0.14424936473369598
test loss item: 0.154135599732399
test loss item: 0.11367010325193405
test loss item: 0.17755013704299927
test loss item: 0.20852059125900269
test loss item: 0.10767573118209839
test loss item: 0.22246906161308289
test loss item: 0.25793346762657166
test loss item: 0.09073856472969055
test loss item: 0.1025250032544136
Epoch [35/100], Training Loss: 0.1642, Testing Loss: 0.1533
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 36/100
train loss item: 0.1768757551908493
train loss item: 0.12228000909090042
train loss item: 0.10960816591978073
train loss item: 0.11966024339199066
train loss item: 0.11115504056215286
train loss item: 0.14217102527618408
train loss item: 0.11600083112716675
train loss item: 0.21434082090854645
train loss item: 0.17099323868751526
train loss item: 0.18108750879764557
train loss item: 0.11159530282020569
train loss item: 0.13175877928733826
train loss item: 0.15619470179080963
train loss item: 0.14730584621429443
train loss item: 0.10701659321784973
train loss item: 0.1810501515865326
train loss item: 0.13010360300540924
train loss item: 0.13885876536369324
train loss item: 0.08996160328388214
train loss item: 0.2783581614494324
train loss item: 0.1731490194797516
train loss item: 0.40058067440986633
train loss item: 0.11536025255918503
test loss item: 0.11516353487968445
test loss item: 0.25326165556907654
test loss item: 0.15525498986244202
test loss item: 0.0867244079709053
test loss item: 0.14334312081336975
test loss item: 0.1319938600063324
test loss item: 0.09659253805875778
test loss item: 0.15940386056900024
test loss item: 0.1409282684326172
test loss item: 0.20559874176979065
test loss item: 0.1083439365029335
test loss item: 0.12604886293411255
test loss item: 0.14685165882110596
test loss item: 0.13806091248989105
test loss item: 0.1458147168159485
test loss item: 0.10936492681503296
test loss item: 0.16936250030994415
test loss item: 0.19928768277168274
test loss item: 0.10513313859701157
test loss item: 0.21466661989688873
test loss item: 0.24413913488388062
test loss item: 0.08754332363605499
test loss item: 0.10180532932281494
Epoch [36/100], Training Loss: 0.1576, Testing Loss: 0.1472
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 37/100
train loss item: 0.16877532005310059
train loss item: 0.1211877167224884
train loss item: 0.11076090484857559
train loss item: 0.12476480007171631
train loss item: 0.10738243907690048
train loss item: 0.13592074811458588
train loss item: 0.11818955838680267
train loss item: 0.21201327443122864
train loss item: 0.16898886859416962
train loss item: 0.16938599944114685
train loss item: 0.10736120492219925
train loss item: 0.1230270192027092
train loss item: 0.15440569818019867
train loss item: 0.14900889992713928
train loss item: 0.11191749572753906
train loss item: 0.18753935396671295
train loss item: 0.13836118578910828
train loss item: 0.14368057250976562
train loss item: 0.09071515500545502
train loss item: 0.27582964301109314
train loss item: 0.17444835603237152
train loss item: 0.39620861411094666
train loss item: 0.11333424597978592
test loss item: 0.11697108298540115
test loss item: 0.2532663345336914
test loss item: 0.1560957431793213
test loss item: 0.09018468111753464
test loss item: 0.14992381632328033
test loss item: 0.1358667016029358
test loss item: 0.09920477867126465
test loss item: 0.16229356825351715
test loss item: 0.14595653116703033
test loss item: 0.20791085064411163
test loss item: 0.11110146343708038
test loss item: 0.13486304879188538
test loss item: 0.15118612349033356
test loss item: 0.13783778250217438
test loss item: 0.14921195805072784
test loss item: 0.11365174502134323
test loss item: 0.17083463072776794
test loss item: 0.20230735838413239
test loss item: 0.11155422031879425
test loss item: 0.21338389813899994
test loss item: 0.24558426439762115
test loss item: 0.08904009312391281
test loss item: 0.10937601327896118
Epoch [37/100], Training Loss: 0.1567, Testing Loss: 0.1503
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 38/100
train loss item: 0.1633652150630951
train loss item: 0.11840679496526718
train loss item: 0.10348527133464813
train loss item: 0.12121948599815369
train loss item: 0.10428284853696823
train loss item: 0.13542746007442474
train loss item: 0.11830969154834747
train loss item: 0.22076675295829773
train loss item: 0.17040327191352844
train loss item: 0.16108010709285736
train loss item: 0.10629764944314957
train loss item: 0.11715885996818542
train loss item: 0.14536480605602264
train loss item: 0.14098724722862244
train loss item: 0.10570968687534332
train loss item: 0.18025143444538116
train loss item: 0.13029296696186066
train loss item: 0.13605964183807373
train loss item: 0.08688673377037048
train loss item: 0.2639369070529938
train loss item: 0.16633880138397217
train loss item: 0.40660470724105835
train loss item: 0.11134006083011627
test loss item: 0.11800157278776169
test loss item: 0.2574012577533722
test loss item: 0.15136566758155823
test loss item: 0.08836949616670609
test loss item: 0.14719903469085693
test loss item: 0.1365317404270172
test loss item: 0.09785318374633789
test loss item: 0.16020946204662323
test loss item: 0.14473365247249603
test loss item: 0.20498034358024597
test loss item: 0.10939992219209671
test loss item: 0.1338571459054947
test loss item: 0.148319274187088
test loss item: 0.13552948832511902
test loss item: 0.1438603401184082
test loss item: 0.11169388890266418
test loss item: 0.16744937002658844
test loss item: 0.20254182815551758
test loss item: 0.11177290230989456
test loss item: 0.21672168374061584
test loss item: 0.23946547508239746
test loss item: 0.08805369585752487
test loss item: 0.11341522634029388
Epoch [38/100], Training Loss: 0.1528, Testing Loss: 0.1491
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 39/100
train loss item: 0.17715832591056824
train loss item: 0.12162531167268753
train loss item: 0.10802573710680008
train loss item: 0.12227506935596466
train loss item: 0.11096474528312683
train loss item: 0.1502203643321991
train loss item: 0.12800432741641998
train loss item: 0.231953427195549
train loss item: 0.17092031240463257
train loss item: 0.167267307639122
train loss item: 0.11479494720697403
train loss item: 0.1255558729171753
train loss item: 0.15138868987560272
train loss item: 0.14615844190120697
train loss item: 0.10849747806787491
train loss item: 0.1789512038230896
train loss item: 0.1317748725414276
train loss item: 0.14362111687660217
train loss item: 0.08744855970144272
train loss item: 0.3094865083694458
train loss item: 0.18301613628864288
train loss item: 0.41642752289772034
train loss item: 0.11075811088085175
test loss item: 0.12470860779285431
test loss item: 0.2832712233066559
test loss item: 0.15961886942386627
test loss item: 0.09397554397583008
test loss item: 0.1627807468175888
test loss item: 0.1492571085691452
test loss item: 0.10605516284704208
test loss item: 0.1733013540506363
test loss item: 0.15183989703655243
test loss item: 0.2199982851743698
test loss item: 0.12034551799297333
test loss item: 0.15420331060886383
test loss item: 0.15879905223846436
test loss item: 0.1414991319179535
test loss item: 0.15568754076957703
test loss item: 0.12124835699796677
test loss item: 0.18240301311016083
test loss item: 0.22250628471374512
test loss item: 0.1277599185705185
test loss item: 0.2277570515871048
test loss item: 0.2598552703857422
test loss item: 0.09755939245223999
test loss item: 0.1220855861902237
Epoch [39/100], Training Loss: 0.1607, Testing Loss: 0.1616
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.20073096454143524
loss item: 0.21073661744594574
loss item: 0.19513392448425293
loss item: 0.17507204413414001
loss item: 0.2099861353635788
loss item: 0.13466887176036835
loss item: 0.20010708272457123
loss item: 0.2807435989379883
loss item: 0.1463194340467453
loss item: 0.18572157621383667
loss item: 0.2057596743106842
Val Loss: 0.1950
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.0001 8 360 done at Tue Nov 12 13:28:25 CET 2024
UNet2 with 1 100 0.0005 8 360 start at Tue Nov 12 13:28:25 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.4765785932540894
train loss item: 0.904321551322937
train loss item: 0.506412148475647
train loss item: 0.6584682464599609
train loss item: 0.4671843647956848
train loss item: 0.8639015555381775
train loss item: 0.43315255641937256
train loss item: 1.1930599212646484
train loss item: 1.2821385860443115
train loss item: 0.7095414996147156
train loss item: 0.9180285334587097
train loss item: 0.7061329483985901
train loss item: 0.5991091728210449
train loss item: 1.0077309608459473
train loss item: 0.429999977350235
train loss item: 0.9447888135910034
train loss item: 0.4559365510940552
train loss item: 0.4064919650554657
train loss item: 0.331018328666687
train loss item: 0.807661235332489
train loss item: 0.41120532155036926
train loss item: 1.6168450117111206
train loss item: 0.4986988306045532
test loss item: 0.5259818434715271
test loss item: 0.8812240958213806
test loss item: 0.7652322053909302
test loss item: 0.22267933189868927
test loss item: 0.5283342003822327
test loss item: 0.5128481388092041
test loss item: 0.3455928862094879
test loss item: 0.7488954067230225
test loss item: 0.6395062208175659
test loss item: 1.0549241304397583
test loss item: 0.3595289885997772
test loss item: 0.49711906909942627
test loss item: 0.6538893580436707
test loss item: 0.7323530316352844
test loss item: 0.4788155257701874
test loss item: 0.40056443214416504
test loss item: 0.7099559903144836
test loss item: 0.7090582847595215
test loss item: 0.3339361548423767
test loss item: 1.4124622344970703
test loss item: 1.240813970565796
test loss item: 0.2627544403076172
test loss item: 0.2596072852611542
Epoch [1/100], Training Loss: 0.7665, Testing Loss: 0.6207
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/100
train loss item: 0.646149218082428
train loss item: 0.43746787309646606
train loss item: 0.34368908405303955
train loss item: 0.43127045035362244
train loss item: 0.38523024320602417
train loss item: 0.5840773582458496
train loss item: 0.3757498562335968
train loss item: 0.9363458156585693
train loss item: 1.1803456544876099
train loss item: 0.4603957533836365
train loss item: 0.3437851071357727
train loss item: 0.39224717020988464
train loss item: 0.47737228870391846
train loss item: 0.7694383859634399
train loss item: 0.2511711120605469
train loss item: 0.7730098366737366
train loss item: 0.41317009925842285
train loss item: 0.31543684005737305
train loss item: 0.22735552489757538
train loss item: 0.6817494034767151
train loss item: 0.27873894572257996
train loss item: 1.3096625804901123
train loss item: 0.38925567269325256
test loss item: 0.3233293294906616
test loss item: 0.6724013686180115
test loss item: 0.4798464775085449
test loss item: 0.20409585535526276
test loss item: 0.40932393074035645
test loss item: 0.35491448640823364
test loss item: 0.26095739006996155
test loss item: 0.48254141211509705
test loss item: 0.5102272033691406
test loss item: 0.6587272882461548
test loss item: 0.2686009407043457
test loss item: 0.34191209077835083
test loss item: 0.43898606300354004
test loss item: 0.45015519857406616
test loss item: 0.41564303636550903
test loss item: 0.2971726059913635
test loss item: 0.44371727108955383
test loss item: 0.5497668385505676
test loss item: 0.2395653873682022
test loss item: 0.6804041266441345
test loss item: 0.7888192534446716
test loss item: 0.20539237558841705
test loss item: 0.2737824022769928
Epoch [2/100], Training Loss: 0.5393, Testing Loss: 0.4239
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/100
train loss item: 0.5702334046363831
train loss item: 0.47487086057662964
train loss item: 0.32472917437553406
train loss item: 0.32024380564689636
train loss item: 0.27235034108161926
train loss item: 0.4972633421421051
train loss item: 0.3153633773326874
train loss item: 0.7744437456130981
train loss item: 0.7985025644302368
train loss item: 0.34334683418273926
train loss item: 0.22557611763477325
train loss item: 0.26109716296195984
train loss item: 0.3857494592666626
train loss item: 0.6142398118972778
train loss item: 0.17273133993148804
train loss item: 0.5602481961250305
train loss item: 0.348443865776062
train loss item: 0.28703176975250244
train loss item: 0.23071928322315216
train loss item: 0.5566060543060303
train loss item: 0.24255461990833282
train loss item: 0.9719066023826599
train loss item: 0.2893982231616974
test loss item: 0.24595551192760468
test loss item: 0.4175114631652832
test loss item: 0.35275670886039734
test loss item: 0.138462096452713
test loss item: 0.29462167620658875
test loss item: 0.2717451751232147
test loss item: 0.20182305574417114
test loss item: 0.33898451924324036
test loss item: 0.3379646837711334
test loss item: 0.47094467282295227
test loss item: 0.21542342007160187
test loss item: 0.2665894031524658
test loss item: 0.3020532429218292
test loss item: 0.3278811275959015
test loss item: 0.27052125334739685
test loss item: 0.22377516329288483
test loss item: 0.3571309745311737
test loss item: 0.3484717905521393
test loss item: 0.19307176768779755
test loss item: 0.6104274988174438
test loss item: 0.5661630034446716
test loss item: 0.15907268226146698
test loss item: 0.1896510273218155
Epoch [3/100], Training Loss: 0.4277, Testing Loss: 0.3087
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/100
train loss item: 0.45562443137168884
train loss item: 0.34325286746025085
train loss item: 0.2426314800977707
train loss item: 0.30251944065093994
train loss item: 0.21644629538059235
train loss item: 0.36790886521339417
train loss item: 0.27396655082702637
train loss item: 0.46329668164253235
train loss item: 0.5496596693992615
train loss item: 0.5395334362983704
train loss item: 0.34572988748550415
train loss item: 0.31916847825050354
train loss item: 0.33370691537857056
train loss item: 0.634696364402771
train loss item: 0.21721574664115906
train loss item: 0.6400171518325806
train loss item: 0.251498281955719
train loss item: 0.24310185015201569
train loss item: 0.19374173879623413
train loss item: 0.47896608710289
train loss item: 0.2271011471748352
train loss item: 0.7794975638389587
train loss item: 0.3810238540172577
test loss item: 0.25956106185913086
test loss item: 0.4672168791294098
test loss item: 0.38382381200790405
test loss item: 0.14306063950061798
test loss item: 0.3136252760887146
test loss item: 0.26761990785598755
test loss item: 0.1824907660484314
test loss item: 0.37867939472198486
test loss item: 0.3529466986656189
test loss item: 0.5340526700019836
test loss item: 0.22433942556381226
test loss item: 0.25278693437576294
test loss item: 0.2946244180202484
test loss item: 0.35582098364830017
test loss item: 0.31025710701942444
test loss item: 0.19843709468841553
test loss item: 0.4273230731487274
test loss item: 0.4160490334033966
test loss item: 0.1942237913608551
test loss item: 0.7960453033447266
test loss item: 0.6904809474945068
test loss item: 0.16237911581993103
test loss item: 0.28418511152267456
Epoch [4/100], Training Loss: 0.3826, Testing Loss: 0.3430
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/100
train loss item: 0.4627298414707184
train loss item: 0.3363535404205322
train loss item: 0.2185729593038559
train loss item: 0.295855849981308
train loss item: 0.2240525335073471
train loss item: 0.4647134244441986
train loss item: 0.2707350552082062
train loss item: 0.5724075436592102
train loss item: 0.518492579460144
train loss item: 0.47081467509269714
train loss item: 0.3736874759197235
train loss item: 0.4487855136394501
train loss item: 0.4400726556777954
train loss item: 0.3375642001628876
train loss item: 0.17595160007476807
train loss item: 0.4535883069038391
train loss item: 0.2087043970823288
train loss item: 0.20798560976982117
train loss item: 0.15593762695789337
train loss item: 0.5299893021583557
train loss item: 0.23609915375709534
train loss item: 0.8019330501556396
train loss item: 0.2711491286754608
test loss item: 0.18252615630626678
test loss item: 0.46297597885131836
test loss item: 0.24526987969875336
test loss item: 0.1252317875623703
test loss item: 0.2680961489677429
test loss item: 0.22057005763053894
test loss item: 0.15055762231349945
test loss item: 0.28010109066963196
test loss item: 0.24049600958824158
test loss item: 0.3725349009037018
test loss item: 0.1762317419052124
test loss item: 0.20063196122646332
test loss item: 0.222720205783844
test loss item: 0.21716803312301636
test loss item: 0.24353894591331482
test loss item: 0.168294757604599
test loss item: 0.27396321296691895
test loss item: 0.3572766184806824
test loss item: 0.17331121861934662
test loss item: 0.3779497742652893
test loss item: 0.45298081636428833
test loss item: 0.13635887205600739
test loss item: 0.3105308413505554
Epoch [5/100], Training Loss: 0.3685, Testing Loss: 0.2548
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/100
train loss item: 0.3525557219982147
train loss item: 0.28993070125579834
train loss item: 0.21043084561824799
train loss item: 0.20681120455265045
train loss item: 0.15451326966285706
train loss item: 0.34986069798469543
train loss item: 0.24790212512016296
train loss item: 0.5114298462867737
train loss item: 0.3958980441093445
train loss item: 0.2890373468399048
train loss item: 0.1805766522884369
train loss item: 0.22035284340381622
train loss item: 0.2923964560031891
train loss item: 0.24060599505901337
train loss item: 0.12315607070922852
train loss item: 0.30887746810913086
train loss item: 0.2096823900938034
train loss item: 0.18589869141578674
train loss item: 0.133903369307518
train loss item: 0.4328691065311432
train loss item: 0.17694121599197388
train loss item: 0.6586924195289612
train loss item: 0.19366076588630676
test loss item: 0.15426699817180634
test loss item: 0.3476596474647522
test loss item: 0.19176852703094482
test loss item: 0.12025521695613861
test loss item: 0.1895514875650406
test loss item: 0.1676361858844757
test loss item: 0.12871108949184418
test loss item: 0.211562842130661
test loss item: 0.18419715762138367
test loss item: 0.2757470905780792
test loss item: 0.13334710896015167
test loss item: 0.1483461707830429
test loss item: 0.16972962021827698
test loss item: 0.1708116978406906
test loss item: 0.18277688324451447
test loss item: 0.1331593245267868
test loss item: 0.21081140637397766
test loss item: 0.25380590558052063
test loss item: 0.12946122884750366
test loss item: 0.27220287919044495
test loss item: 0.3130112290382385
test loss item: 0.10718534886837006
test loss item: 0.19671761989593506
Epoch [6/100], Training Loss: 0.2768, Testing Loss: 0.1910
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/100
train loss item: 0.32555872201919556
train loss item: 0.21497906744480133
train loss item: 0.14866745471954346
train loss item: 0.18701061606407166
train loss item: 0.14049728214740753
train loss item: 0.25934746861457825
train loss item: 0.19468316435813904
train loss item: 0.30709290504455566
train loss item: 0.2554112374782562
train loss item: 0.311885267496109
train loss item: 0.1575358659029007
train loss item: 0.17992499470710754
train loss item: 0.23951144516468048
train loss item: 0.20659896731376648
train loss item: 0.1405148059129715
train loss item: 0.3030441105365753
train loss item: 0.1768285632133484
train loss item: 0.1733575165271759
train loss item: 0.13984131813049316
train loss item: 0.3352847099304199
train loss item: 0.15127824246883392
train loss item: 0.5354752540588379
train loss item: 0.1760980486869812
test loss item: 0.13826042413711548
test loss item: 0.2958555519580841
test loss item: 0.18446896970272064
test loss item: 0.11005322635173798
test loss item: 0.16363711655139923
test loss item: 0.153920978307724
test loss item: 0.11578797549009323
test loss item: 0.19334232807159424
test loss item: 0.16785477101802826
test loss item: 0.24696201086044312
test loss item: 0.1185421422123909
test loss item: 0.14619840681552887
test loss item: 0.167436882853508
test loss item: 0.16374850273132324
test loss item: 0.16671258211135864
test loss item: 0.1215277761220932
test loss item: 0.2063816636800766
test loss item: 0.2263036072254181
test loss item: 0.11752420663833618
test loss item: 0.28625771403312683
test loss item: 0.30209454894065857
test loss item: 0.10535407811403275
test loss item: 0.12601099908351898
Epoch [7/100], Training Loss: 0.2287, Testing Loss: 0.1750
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/100
train loss item: 0.3012543320655823
train loss item: 0.20037749409675598
train loss item: 0.15124835073947906
train loss item: 0.19189628958702087
train loss item: 0.1498374044895172
train loss item: 0.23290376365184784
train loss item: 0.1782134622335434
train loss item: 0.2549075484275818
train loss item: 0.2470044642686844
train loss item: 0.3479762077331543
train loss item: 0.17558394372463226
train loss item: 0.1654239296913147
train loss item: 0.2178492695093155
train loss item: 0.20187196135520935
train loss item: 0.14818845689296722
train loss item: 0.37684640288352966
train loss item: 0.15558870136737823
train loss item: 0.13934096693992615
train loss item: 0.12192875891923904
train loss item: 0.33646222949028015
train loss item: 0.17282699048519135
train loss item: 0.4316958487033844
train loss item: 0.1981968730688095
test loss item: 0.1437983363866806
test loss item: 0.24322709441184998
test loss item: 0.18382255733013153
test loss item: 0.0959974005818367
test loss item: 0.16204187273979187
test loss item: 0.14360186457633972
test loss item: 0.11268126219511032
test loss item: 0.1833123415708542
test loss item: 0.1660611927509308
test loss item: 0.23899421095848083
test loss item: 0.13025082647800446
test loss item: 0.13067510724067688
test loss item: 0.1573084145784378
test loss item: 0.1725132316350937
test loss item: 0.15371856093406677
test loss item: 0.12092222273349762
test loss item: 0.2014172077178955
test loss item: 0.19604329764842987
test loss item: 0.12494060397148132
test loss item: 0.3224906921386719
test loss item: 0.30743852257728577
test loss item: 0.11089477688074112
test loss item: 0.24979451298713684
Epoch [8/100], Training Loss: 0.2216, Testing Loss: 0.1762
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/100
train loss item: 0.3338316082954407
train loss item: 0.17771737277507782
train loss item: 0.1588924676179886
train loss item: 0.22411374747753143
train loss item: 0.17408092319965363
train loss item: 0.3877794146537781
train loss item: 0.21395277976989746
train loss item: 0.4650765061378479
train loss item: 0.2452603280544281
train loss item: 0.36681416630744934
train loss item: 0.2549988329410553
train loss item: 0.31607404351234436
train loss item: 0.257192999124527
train loss item: 0.3181667923927307
train loss item: 0.13541674613952637
train loss item: 0.34534984827041626
train loss item: 0.1687154471874237
train loss item: 0.16515670716762543
train loss item: 0.11993734538555145
train loss item: 0.39822518825531006
train loss item: 0.21850204467773438
train loss item: 0.5533841252326965
train loss item: 0.23953178524971008
test loss item: 0.1624395102262497
test loss item: 0.39077064394950867
test loss item: 0.20271635055541992
test loss item: 0.11896762996912003
test loss item: 0.2104427069425583
test loss item: 0.18920981884002686
test loss item: 0.16872777044773102
test loss item: 0.2503719627857208
test loss item: 0.20184193551540375
test loss item: 0.29027339816093445
test loss item: 0.16368892788887024
test loss item: 0.16960984468460083
test loss item: 0.21503379940986633
test loss item: 0.226335346698761
test loss item: 0.201276496052742
test loss item: 0.16468001902103424
test loss item: 0.25499337911605835
test loss item: 0.29053565859794617
test loss item: 0.1668405830860138
test loss item: 0.3116277754306793
test loss item: 0.36191806197166443
test loss item: 0.16376323997974396
test loss item: 0.3213746249675751
Epoch [9/100], Training Loss: 0.2712, Testing Loss: 0.2260
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/100
train loss item: 0.338926762342453
train loss item: 0.3018026053905487
train loss item: 0.22104722261428833
train loss item: 0.19400654733181
train loss item: 0.13727746903896332
train loss item: 0.3550010621547699
train loss item: 0.25028884410858154
train loss item: 0.5497902035713196
train loss item: 0.3238041400909424
train loss item: 0.16600939631462097
train loss item: 0.11922754347324371
train loss item: 0.1483672559261322
train loss item: 0.26534372568130493
train loss item: 0.23212747275829315
train loss item: 0.15061210095882416
train loss item: 0.2416793704032898
train loss item: 0.21183577179908752
train loss item: 0.13064569234848022
train loss item: 0.10517460852861404
train loss item: 0.49265915155410767
train loss item: 0.28493258357048035
train loss item: 0.7507374882698059
train loss item: 0.19929036498069763
test loss item: 0.17714014649391174
test loss item: 0.2566101551055908
test loss item: 0.23043875396251678
test loss item: 0.12219168990850449
test loss item: 0.1868738979101181
test loss item: 0.19066382944583893
test loss item: 0.14038875699043274
test loss item: 0.20967550575733185
test loss item: 0.17486175894737244
test loss item: 0.28723111748695374
test loss item: 0.1477000117301941
test loss item: 0.19551393389701843
test loss item: 0.19757981598377228
test loss item: 0.2059766948223114
test loss item: 0.17611373960971832
test loss item: 0.13474905490875244
test loss item: 0.24453771114349365
test loss item: 0.2106400728225708
test loss item: 0.18395757675170898
test loss item: 0.4013921916484833
test loss item: 0.3440716862678528
test loss item: 0.13483305275440216
test loss item: 0.12343262135982513
Epoch [10/100], Training Loss: 0.2683, Testing Loss: 0.2033
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 11/100
train loss item: 0.20690536499023438
train loss item: 0.17773473262786865
train loss item: 0.1923607587814331
train loss item: 0.20309129357337952
train loss item: 0.14787311851978302
train loss item: 0.15779004991054535
train loss item: 0.15622800588607788
train loss item: 0.2966565787792206
train loss item: 0.2618408203125
train loss item: 0.1918792724609375
train loss item: 0.1401173621416092
train loss item: 0.20129336416721344
train loss item: 0.2839632034301758
train loss item: 0.24956780672073364
train loss item: 0.1175166517496109
train loss item: 0.21291610598564148
train loss item: 0.2162613868713379
train loss item: 0.15531080961227417
train loss item: 0.1286841183900833
train loss item: 0.36952194571495056
train loss item: 0.18281716108322144
train loss item: 0.5163421034812927
train loss item: 0.20149709284305573
test loss item: 0.1391347050666809
test loss item: 0.26956114172935486
test loss item: 0.2302107810974121
test loss item: 0.09577734768390656
test loss item: 0.1657509207725525
test loss item: 0.1373865008354187
test loss item: 0.12169954180717468
test loss item: 0.21411679685115814
test loss item: 0.17257629334926605
test loss item: 0.2641477584838867
test loss item: 0.1240074634552002
test loss item: 0.1331394612789154
test loss item: 0.19048859179019928
test loss item: 0.2030666321516037
test loss item: 0.16894173622131348
test loss item: 0.11676754057407379
test loss item: 0.18344853818416595
test loss item: 0.2088382989168167
test loss item: 0.11931981891393661
test loss item: 0.2826586663722992
test loss item: 0.33323773741722107
test loss item: 0.10643832385540009
test loss item: 0.1506543904542923
Epoch [11/100], Training Loss: 0.2160, Testing Loss: 0.1796
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 12/100
train loss item: 0.26044154167175293
train loss item: 0.18461690843105316
train loss item: 0.14241059124469757
train loss item: 0.18223746120929718
train loss item: 0.12079588323831558
train loss item: 0.1653498411178589
train loss item: 0.12642547488212585
train loss item: 0.2221578061580658
train loss item: 0.1984560787677765
train loss item: 0.23194734752178192
train loss item: 0.1201518326997757
train loss item: 0.18251249194145203
train loss item: 0.23119261860847473
train loss item: 0.21793076395988464
train loss item: 0.09908583015203476
train loss item: 0.2229086309671402
train loss item: 0.14930371940135956
train loss item: 0.1311407834291458
train loss item: 0.1729613095521927
train loss item: 0.28583434224128723
train loss item: 0.12198735773563385
train loss item: 0.4471735656261444
train loss item: 0.15882284939289093
test loss item: 0.1442594826221466
test loss item: 0.22501087188720703
test loss item: 0.1755877137184143
test loss item: 0.09632411599159241
test loss item: 0.16364739835262299
test loss item: 0.1613510549068451
test loss item: 0.11446160078048706
test loss item: 0.16061484813690186
test loss item: 0.1770622879266739
test loss item: 0.22552965581417084
test loss item: 0.12031325697898865
test loss item: 0.15918394923210144
test loss item: 0.16966930031776428
test loss item: 0.16392138600349426
test loss item: 0.1656549870967865
test loss item: 0.11775638908147812
test loss item: 0.21272887289524078
test loss item: 0.19175554811954498
test loss item: 0.12859970331192017
test loss item: 0.29974979162216187
test loss item: 0.2788420021533966
test loss item: 0.10450508445501328
test loss item: 0.12916624546051025
Epoch [12/100], Training Loss: 0.1903, Testing Loss: 0.1689
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 13/100
train loss item: 0.3089812994003296
train loss item: 0.2321368157863617
train loss item: 0.12554731965065002
train loss item: 0.20197723805904388
train loss item: 0.16188719868659973
train loss item: 0.3955458700656891
train loss item: 0.1882701963186264
train loss item: 0.6388847231864929
train loss item: 0.3023850917816162
train loss item: 0.23350955545902252
train loss item: 0.16674987971782684
train loss item: 0.28334593772888184
train loss item: 0.3545098304748535
train loss item: 0.34165582060813904
train loss item: 0.10579322278499603
train loss item: 0.21531333029270172
train loss item: 0.15895847976207733
train loss item: 0.12969866394996643
train loss item: 0.11380039900541306
train loss item: 0.3081514835357666
train loss item: 0.15353380143642426
train loss item: 0.7096001505851746
train loss item: 0.18444883823394775
test loss item: 0.21804362535476685
test loss item: 0.21590539813041687
test loss item: 0.278894305229187
test loss item: 0.09835094213485718
test loss item: 0.16160249710083008
test loss item: 0.16093386709690094
test loss item: 0.11151694506406784
test loss item: 0.23780497908592224
test loss item: 0.21929754316806793
test loss item: 0.3676528334617615
test loss item: 0.11674844473600388
test loss item: 0.13778331875801086
test loss item: 0.22672642767429352
test loss item: 0.26773539185523987
test loss item: 0.18714942038059235
test loss item: 0.12932848930358887
test loss item: 0.2773125171661377
test loss item: 0.20724810659885406
test loss item: 0.10397525131702423
test loss item: 0.6023297309875488
test loss item: 0.451305627822876
test loss item: 0.10313507914543152
test loss item: 0.17905326187610626
Epoch [13/100], Training Loss: 0.2615, Testing Loss: 0.2200
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 14/100
train loss item: 0.24561074376106262
train loss item: 0.167112797498703
train loss item: 0.15019801259040833
train loss item: 0.2141425609588623
train loss item: 0.15604491531848907
train loss item: 0.43828028440475464
train loss item: 0.1416034996509552
train loss item: 0.3311622142791748
train loss item: 0.3535134196281433
train loss item: 0.2814106047153473
train loss item: 0.18515832722187042
train loss item: 0.36276987195014954
train loss item: 0.2908656597137451
train loss item: 0.3518775403499603
train loss item: 0.1527705192565918
train loss item: 0.2848336100578308
train loss item: 0.24649815261363983
train loss item: 0.1700756698846817
train loss item: 0.09886881709098816
train loss item: 0.26476845145225525
train loss item: 0.15290416777133942
train loss item: 0.3907383978366852
train loss item: 0.20234215259552002
test loss item: 0.17124266922473907
test loss item: 0.27561965584754944
test loss item: 0.26002058386802673
test loss item: 0.1247190535068512
test loss item: 0.1817469298839569
test loss item: 0.15864822268486023
test loss item: 0.14889644086360931
test loss item: 0.26483333110809326
test loss item: 0.20992083847522736
test loss item: 0.29530319571495056
test loss item: 0.1537453532218933
test loss item: 0.16810153424739838
test loss item: 0.227358877658844
test loss item: 0.242543026804924
test loss item: 0.17498067021369934
test loss item: 0.1588122546672821
test loss item: 0.2157389223575592
test loss item: 0.23612329363822937
test loss item: 0.1535934954881668
test loss item: 0.3958793580532074
test loss item: 0.40385550260543823
test loss item: 0.13959074020385742
test loss item: 0.19251562654972076
Epoch [14/100], Training Loss: 0.2449, Testing Loss: 0.2154
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 15/100
train loss item: 0.34004759788513184
train loss item: 0.2878037691116333
train loss item: 0.18995094299316406
train loss item: 0.23256073892116547
train loss item: 0.1729443073272705
train loss item: 0.46840912103652954
train loss item: 0.19778646528720856
train loss item: 0.5854936838150024
train loss item: 0.28879302740097046
train loss item: 0.21174393594264984
train loss item: 0.1423836201429367
train loss item: 0.1998469978570938
train loss item: 0.2990504503250122
train loss item: 0.3499985337257385
train loss item: 0.10887957364320755
train loss item: 0.2497738003730774
train loss item: 0.14704671502113342
train loss item: 0.12038092315196991
train loss item: 0.13596609234809875
train loss item: 0.2970401644706726
train loss item: 0.1730838418006897
train loss item: 0.6317137479782104
train loss item: 0.1488673985004425
test loss item: 0.1834230273962021
test loss item: 0.2371128499507904
test loss item: 0.2505602240562439
test loss item: 0.09421227872371674
test loss item: 0.16297946870326996
test loss item: 0.1661035567522049
test loss item: 0.10959269851446152
test loss item: 0.21874360740184784
test loss item: 0.20217986404895782
test loss item: 0.32199886441230774
test loss item: 0.11086899787187576
test loss item: 0.1531486213207245
test loss item: 0.2086990624666214
test loss item: 0.231148362159729
test loss item: 0.1752316653728485
test loss item: 0.12458159774541855
test loss item: 0.25639188289642334
test loss item: 0.21575205028057098
test loss item: 0.10717228800058365
test loss item: 0.49972087144851685
test loss item: 0.3946649432182312
test loss item: 0.08944731205701828
test loss item: 0.1488029807806015
Epoch [15/100], Training Loss: 0.2600, Testing Loss: 0.2027
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 16/100
train loss item: 0.23562687635421753
train loss item: 0.15539158880710602
train loss item: 0.15395307540893555
train loss item: 0.20522284507751465
train loss item: 0.14044538140296936
train loss item: 0.31338727474212646
train loss item: 0.13348235189914703
train loss item: 0.27901676297187805
train loss item: 0.23675978183746338
train loss item: 0.2403193712234497
train loss item: 0.17354030907154083
train loss item: 0.3665979504585266
train loss item: 0.3236079514026642
train loss item: 0.5365365147590637
train loss item: 0.16289420425891876
train loss item: 0.4161731004714966
train loss item: 0.14566858112812042
train loss item: 0.1579277664422989
train loss item: 0.13444752991199493
train loss item: 0.2892054319381714
train loss item: 0.19161410629749298
train loss item: 0.2916661500930786
train loss item: 0.2308817356824875
test loss item: 0.20314070582389832
test loss item: 0.2919785976409912
test loss item: 0.24140329658985138
test loss item: 0.10733617097139359
test loss item: 0.17495328187942505
test loss item: 0.16886194050312042
test loss item: 0.12922273576259613
test loss item: 0.250461220741272
test loss item: 0.2147398740053177
test loss item: 0.35589805245399475
test loss item: 0.14194156229496002
test loss item: 0.15932373702526093
test loss item: 0.2132261097431183
test loss item: 0.24103106558322906
test loss item: 0.18565991520881653
test loss item: 0.1315397024154663
test loss item: 0.26703211665153503
test loss item: 0.24312517046928406
test loss item: 0.1304319053888321
test loss item: 0.5774705410003662
test loss item: 0.4556067883968353
test loss item: 0.12102843821048737
test loss item: 0.21232841908931732
Epoch [16/100], Training Loss: 0.2398, Testing Loss: 0.2269
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 17/100
train loss item: 0.47814854979515076
train loss item: 0.36797893047332764
train loss item: 0.18138056993484497
train loss item: 0.24828316271305084
train loss item: 0.17737379670143127
train loss item: 0.4896818995475769
train loss item: 0.20671296119689941
train loss item: 0.6443431973457336
train loss item: 0.47280582785606384
train loss item: 0.19407671689987183
train loss item: 0.11975447833538055
train loss item: 0.15039649605751038
train loss item: 0.23641803860664368
train loss item: 0.3059614896774292
train loss item: 0.16512468457221985
train loss item: 0.32199162244796753
train loss item: 0.2120898813009262
train loss item: 0.18252643942832947
train loss item: 0.09941751509904861
train loss item: 0.2556298077106476
train loss item: 0.1353212594985962
train loss item: 0.548790454864502
train loss item: 0.1335677206516266
test loss item: 0.17263221740722656
test loss item: 0.2309011071920395
test loss item: 0.23208998143672943
test loss item: 0.09506147354841232
test loss item: 0.15240439772605896
test loss item: 0.14928366243839264
test loss item: 0.11558619886636734
test loss item: 0.21084186434745789
test loss item: 0.18440775573253632
test loss item: 0.2739444971084595
test loss item: 0.12832902371883392
test loss item: 0.13392889499664307
test loss item: 0.18781034648418427
test loss item: 0.21091748774051666
test loss item: 0.14822377264499664
test loss item: 0.1335640847682953
test loss item: 0.2112751454114914
test loss item: 0.1920100599527359
test loss item: 0.11320342123508453
test loss item: 0.3613733649253845
test loss item: 0.3315696716308594
test loss item: 0.09765003621578217
test loss item: 0.17092390358448029
Epoch [17/100], Training Loss: 0.2751, Testing Loss: 0.1843
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 18/100
train loss item: 0.23625239729881287
train loss item: 0.1581014096736908
train loss item: 0.12902523577213287
train loss item: 0.16066139936447144
train loss item: 0.11740843951702118
train loss item: 0.20920905470848083
train loss item: 0.12097073346376419
train loss item: 0.2551857829093933
train loss item: 0.2105909138917923
train loss item: 0.21660856902599335
train loss item: 0.1382676362991333
train loss item: 0.2875397503376007
train loss item: 0.2829764187335968
train loss item: 0.41412290930747986
train loss item: 0.14595213532447815
train loss item: 0.4011786878108978
train loss item: 0.14646320044994354
train loss item: 0.1500830352306366
train loss item: 0.11758702248334885
train loss item: 0.21440449357032776
train loss item: 0.16842089593410492
train loss item: 0.2641986906528473
train loss item: 0.20544962584972382
test loss item: 0.2002243548631668
test loss item: 0.324308305978775
test loss item: 0.24084177613258362
test loss item: 0.10195581614971161
test loss item: 0.16441799700260162
test loss item: 0.1674237996339798
test loss item: 0.12276461720466614
test loss item: 0.25420039892196655
test loss item: 0.21798110008239746
test loss item: 0.35014986991882324
test loss item: 0.14343750476837158
test loss item: 0.14144925773143768
test loss item: 0.21597085893154144
test loss item: 0.2381739616394043
test loss item: 0.17974863946437836
test loss item: 0.13370488584041595
test loss item: 0.2602709233760834
test loss item: 0.25296750664711
test loss item: 0.124466672539711
test loss item: 0.5470060110092163
test loss item: 0.4440627694129944
test loss item: 0.11895348131656647
test loss item: 0.19719871878623962
Epoch [18/100], Training Loss: 0.2066, Testing Loss: 0.2236
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 19/100
train loss item: 0.43088433146476746
train loss item: 0.4144124388694763
train loss item: 0.17934559285640717
train loss item: 0.23388399183750153
train loss item: 0.15439680218696594
train loss item: 0.45874375104904175
train loss item: 0.19931818544864655
train loss item: 0.5275213718414307
train loss item: 0.3275609016418457
train loss item: 0.15372203290462494
train loss item: 0.09222211688756943
train loss item: 0.12758532166481018
train loss item: 0.2222166210412979
train loss item: 0.29268258810043335
train loss item: 0.11813364923000336
train loss item: 0.2603149712085724
train loss item: 0.17342206835746765
train loss item: 0.15622912347316742
train loss item: 0.09687619656324387
train loss item: 0.21965794265270233
train loss item: 0.15796281397342682
train loss item: 0.4705863893032074
train loss item: 0.14116637408733368
test loss item: 0.1782492697238922
test loss item: 0.2191074937582016
test loss item: 0.2703952193260193
test loss item: 0.08844462037086487
test loss item: 0.15179145336151123
test loss item: 0.14464488625526428
test loss item: 0.11694485694169998
test loss item: 0.2448653131723404
test loss item: 0.20215605199337006
test loss item: 0.31298762559890747
test loss item: 0.1243913397192955
test loss item: 0.13586559891700745
test loss item: 0.21206839382648468
test loss item: 0.24686299264431
test loss item: 0.15342842042446136
test loss item: 0.13032695651054382
test loss item: 0.20861947536468506
test loss item: 0.1967063695192337
test loss item: 0.11560764163732529
test loss item: 0.42237675189971924
test loss item: 0.38959020376205444
test loss item: 0.09687194973230362
test loss item: 0.1505330204963684
Epoch [19/100], Training Loss: 0.2439, Testing Loss: 0.1962
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 20/100
train loss item: 0.22231699526309967
train loss item: 0.15008261799812317
train loss item: 0.11845797300338745
train loss item: 0.16552677750587463
train loss item: 0.11254936456680298
train loss item: 0.21416109800338745
train loss item: 0.12524081766605377
train loss item: 0.2666766047477722
train loss item: 0.23603011667728424
train loss item: 0.21384462714195251
train loss item: 0.12899622321128845
train loss item: 0.23940913379192352
train loss item: 0.22488205134868622
train loss item: 0.25631824135780334
train loss item: 0.12280619144439697
train loss item: 0.33313700556755066
train loss item: 0.15086567401885986
train loss item: 0.1697666347026825
train loss item: 0.09984223544597626
train loss item: 0.2048252522945404
train loss item: 0.15696094930171967
train loss item: 0.3041413724422455
train loss item: 0.14723797142505646
test loss item: 0.159834086894989
test loss item: 0.2480575293302536
test loss item: 0.1857096403837204
test loss item: 0.1017708033323288
test loss item: 0.15264232456684113
test loss item: 0.15118719637393951
test loss item: 0.11665590107440948
test loss item: 0.1844547688961029
test loss item: 0.17524413764476776
test loss item: 0.2517758011817932
test loss item: 0.1410001963376999
test loss item: 0.13932016491889954
test loss item: 0.16709478199481964
test loss item: 0.1783064603805542
test loss item: 0.14947938919067383
test loss item: 0.12533420324325562
test loss item: 0.1951831579208374
test loss item: 0.20305639505386353
test loss item: 0.11980778723955154
test loss item: 0.34486404061317444
test loss item: 0.29804107546806335
test loss item: 0.11291635781526566
test loss item: 0.16377973556518555
Epoch [20/100], Training Loss: 0.1897, Testing Loss: 0.1768
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 21/100
train loss item: 0.32695016264915466
train loss item: 0.2963116466999054
train loss item: 0.1684010624885559
train loss item: 0.18792161345481873
train loss item: 0.12458599358797073
train loss item: 0.37132349610328674
train loss item: 0.17973032593727112
train loss item: 0.37950399518013
train loss item: 0.22817251086235046
train loss item: 0.14298026263713837
train loss item: 0.08767632395029068
train loss item: 0.1339367926120758
train loss item: 0.17412875592708588
train loss item: 0.2253407984972
train loss item: 0.090807244181633
train loss item: 0.22531315684318542
train loss item: 0.1359335035085678
train loss item: 0.14080001413822174
train loss item: 0.07888378202915192
train loss item: 0.22677914798259735
train loss item: 0.11896149069070816
train loss item: 0.46229326725006104
train loss item: 0.13136722147464752
test loss item: 0.1601274162530899
test loss item: 0.23180240392684937
test loss item: 0.2343612164258957
test loss item: 0.08552916347980499
test loss item: 0.15900659561157227
test loss item: 0.1355101615190506
test loss item: 0.10315990447998047
test loss item: 0.21745537221431732
test loss item: 0.1787777692079544
test loss item: 0.29530537128448486
test loss item: 0.11353567242622375
test loss item: 0.12946109473705292
test loss item: 0.17764003574848175
test loss item: 0.21075615286827087
test loss item: 0.1568676382303238
test loss item: 0.10964509099721909
test loss item: 0.2065100371837616
test loss item: 0.21072900295257568
test loss item: 0.1005246639251709
test loss item: 0.42425256967544556
test loss item: 0.35971885919570923
test loss item: 0.09398601949214935
test loss item: 0.14606721699237823
Epoch [21/100], Training Loss: 0.2017, Testing Loss: 0.1844
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 22/100
train loss item: 0.254061222076416
train loss item: 0.15034708380699158
train loss item: 0.14511480927467346
train loss item: 0.14070738852024078
train loss item: 0.10414665937423706
train loss item: 0.2500896155834198
train loss item: 0.14754796028137207
train loss item: 0.31124091148376465
train loss item: 0.1951114982366562
train loss item: 0.15367811918258667
train loss item: 0.13255777955055237
train loss item: 0.2653396427631378
train loss item: 0.2447553277015686
train loss item: 0.3122413456439972
train loss item: 0.13670487701892853
train loss item: 0.2789289653301239
train loss item: 0.11980205029249191
train loss item: 0.14386864006519318
train loss item: 0.0857851654291153
train loss item: 0.2852281630039215
train loss item: 0.14370878040790558
train loss item: 0.3019523620605469
train loss item: 0.14460289478302002
test loss item: 0.1791505217552185
test loss item: 0.2064816951751709
test loss item: 0.20495732128620148
test loss item: 0.12996621429920197
test loss item: 0.1647377759218216
test loss item: 0.15745165944099426
test loss item: 0.1279318481683731
test loss item: 0.1847177892923355
test loss item: 0.19818630814552307
test loss item: 0.26327502727508545
test loss item: 0.15975581109523773
test loss item: 0.14259223639965057
test loss item: 0.18216155469417572
test loss item: 0.1944800317287445
test loss item: 0.16518166661262512
test loss item: 0.14121226966381073
test loss item: 0.20063632726669312
test loss item: 0.20185546576976776
test loss item: 0.12419401854276657
test loss item: 0.37070196866989136
test loss item: 0.3033083975315094
test loss item: 0.12940795719623566
test loss item: 0.14075899124145508
Epoch [22/100], Training Loss: 0.1934, Testing Loss: 0.1858
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.30538034439086914
loss item: 0.17516915500164032
loss item: 0.16067878901958466
loss item: 0.16214905679225922
loss item: 0.21354395151138306
loss item: 0.14693622291088104
loss item: 0.20720720291137695
loss item: 0.29442015290260315
loss item: 0.1203702986240387
loss item: 0.1827232986688614
loss item: 0.23438352346420288
Val Loss: 0.2003
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.0005 8 360 done at Tue Nov 12 13:33:55 CET 2024
UNet2 with 1 100 0.001 8 360 start at Tue Nov 12 13:33:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 100, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.4765785932540894
train loss item: 0.9321662187576294
train loss item: 0.5705680251121521
train loss item: 0.7235683798789978
train loss item: 0.48982417583465576
train loss item: 0.9598066806793213
train loss item: 0.43659016489982605
train loss item: 1.2260032892227173
train loss item: 1.3787102699279785
train loss item: 0.7917293310165405
train loss item: 0.9322169423103333
train loss item: 0.6345696449279785
train loss item: 0.7560602426528931
train loss item: 1.1498932838439941
train loss item: 0.3278881013393402
train loss item: 1.077573299407959
train loss item: 0.4689684212207794
train loss item: 0.5166193246841431
train loss item: 0.35709214210510254
train loss item: 0.9266363382339478
train loss item: 0.5574327707290649
train loss item: 1.6715219020843506
train loss item: 0.486640065908432
test loss item: 0.8900920748710632
test loss item: 1.806649923324585
test loss item: 1.2828243970870972
test loss item: 0.5111333131790161
test loss item: 1.2371248006820679
test loss item: 1.0926077365875244
test loss item: 0.56679368019104
test loss item: 1.1501104831695557
test loss item: 1.7554935216903687
test loss item: 1.8484928607940674
test loss item: 0.9038143157958984
test loss item: 0.8129539489746094
test loss item: 0.9455756545066833
test loss item: 1.179633617401123
test loss item: 1.4823050498962402
test loss item: 0.475413054227829
test loss item: 1.2059890031814575
test loss item: 1.6585445404052734
test loss item: 0.64629727602005
test loss item: 1.6239275932312012
test loss item: 2.2568092346191406
test loss item: 0.4669654071331024
test loss item: 0.6569624543190002
Epoch [1/100], Training Loss: 0.8195, Testing Loss: 1.1503
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/100
train loss item: 0.7198851704597473
train loss item: 0.5766774415969849
train loss item: 0.3693244457244873
train loss item: 0.47380316257476807
train loss item: 0.37415528297424316
train loss item: 0.7435067892074585
train loss item: 0.3544085621833801
train loss item: 1.0596643686294556
train loss item: 1.232591152191162
train loss item: 0.4808028042316437
train loss item: 0.39889079332351685
train loss item: 0.43824806809425354
train loss item: 0.5386667251586914
train loss item: 0.8641173839569092
train loss item: 0.2591363787651062
train loss item: 0.8595077991485596
train loss item: 0.4677795469760895
train loss item: 0.3627093434333801
train loss item: 0.262126088142395
train loss item: 0.8070115447044373
train loss item: 0.3673115074634552
train loss item: 1.401215672492981
train loss item: 0.39585059881210327
test loss item: 0.33737945556640625
test loss item: 0.6803757548332214
test loss item: 0.5224807858467102
test loss item: 0.15958459675312042
test loss item: 0.438453733921051
test loss item: 0.39053747057914734
test loss item: 0.2568058669567108
test loss item: 0.5029212236404419
test loss item: 0.5168474316596985
test loss item: 0.7240390181541443
test loss item: 0.30944234132766724
test loss item: 0.359069287776947
test loss item: 0.4218577444553375
test loss item: 0.48717018961906433
test loss item: 0.405526340007782
test loss item: 0.29365992546081543
test loss item: 0.48906639218330383
test loss item: 0.5646036863327026
test loss item: 0.24367626011371613
test loss item: 0.8112217783927917
test loss item: 0.8648074269294739
test loss item: 0.19702045619487762
test loss item: 0.2881266176700592
Epoch [2/100], Training Loss: 0.6003, Testing Loss: 0.4463
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/100
train loss item: 0.5857239365577698
train loss item: 0.47913631796836853
train loss item: 0.34196391701698303
train loss item: 0.3625548481941223
train loss item: 0.322047621011734
train loss item: 0.5890762805938721
train loss item: 0.33007514476776123
train loss item: 0.892874002456665
train loss item: 0.9750428795814514
train loss item: 0.40374162793159485
train loss item: 0.23625467717647552
train loss item: 0.311131089925766
train loss item: 0.43381816148757935
train loss item: 0.7189918160438538
train loss item: 0.20671994984149933
train loss item: 0.7044638991355896
train loss item: 0.41628825664520264
train loss item: 0.3068786859512329
train loss item: 0.21826574206352234
train loss item: 0.6536188125610352
train loss item: 0.30149081349372864
train loss item: 1.1437581777572632
train loss item: 0.32628604769706726
test loss item: 0.3164239227771759
test loss item: 0.5652851462364197
test loss item: 0.46206268668174744
test loss item: 0.17671112716197968
test loss item: 0.3733791708946228
test loss item: 0.359761118888855
test loss item: 0.2469884306192398
test loss item: 0.4529210925102234
test loss item: 0.4714938700199127
test loss item: 0.6134920120239258
test loss item: 0.29506415128707886
test loss item: 0.3338986933231354
test loss item: 0.3973461091518402
test loss item: 0.4507129192352295
test loss item: 0.3469497561454773
test loss item: 0.29272007942199707
test loss item: 0.42597338557243347
test loss item: 0.45541080832481384
test loss item: 0.23441563546657562
test loss item: 0.7079593539237976
test loss item: 0.7161606550216675
test loss item: 0.1908903419971466
test loss item: 0.2717518210411072
Epoch [3/100], Training Loss: 0.4896, Testing Loss: 0.3982
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/100
train loss item: 0.5228458642959595
train loss item: 0.42947816848754883
train loss item: 0.2872880697250366
train loss item: 0.35001304745674133
train loss item: 0.2899131774902344
train loss item: 0.4791066348552704
train loss item: 0.2831111550331116
train loss item: 0.6694863438606262
train loss item: 0.6924212574958801
train loss item: 0.6254570484161377
train loss item: 0.3395339846611023
train loss item: 0.3599051237106323
train loss item: 0.38609570264816284
train loss item: 0.6901715993881226
train loss item: 0.2499030977487564
train loss item: 0.7642113566398621
train loss item: 0.2852863073348999
train loss item: 0.2560964524745941
train loss item: 0.2003164440393448
train loss item: 0.5541471838951111
train loss item: 0.25212961435317993
train loss item: 0.8862177729606628
train loss item: 0.37143927812576294
test loss item: 0.2705531716346741
test loss item: 0.48720142245292664
test loss item: 0.423031747341156
test loss item: 0.13735458254814148
test loss item: 0.32907983660697937
test loss item: 0.276557058095932
test loss item: 0.20864078402519226
test loss item: 0.4274965524673462
test loss item: 0.35954558849334717
test loss item: 0.6025698781013489
test loss item: 0.21676217019557953
test loss item: 0.290805846452713
test loss item: 0.32221370935440063
test loss item: 0.37713536620140076
test loss item: 0.3080090880393982
test loss item: 0.22687669098377228
test loss item: 0.4496840238571167
test loss item: 0.40885546803474426
test loss item: 0.20672093331813812
test loss item: 0.9701879620552063
test loss item: 0.7683491706848145
test loss item: 0.1755107194185257
test loss item: 0.36274436116218567
Epoch [4/100], Training Loss: 0.4445, Testing Loss: 0.3742
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/100
train loss item: 0.5384072065353394
train loss item: 0.3676510751247406
train loss item: 0.24895644187927246
train loss item: 0.327865332365036
train loss item: 0.26798781752586365
train loss item: 0.505597710609436
train loss item: 0.29630738496780396
train loss item: 0.5945239067077637
train loss item: 0.5812534093856812
train loss item: 0.6535705924034119
train loss item: 0.4561678469181061
train loss item: 0.5079673528671265
train loss item: 0.367435485124588
train loss item: 0.4734421372413635
train loss item: 0.2440497875213623
train loss item: 0.6802853345870972
train loss item: 0.30604639649391174
train loss item: 0.2915448248386383
train loss item: 0.18607120215892792
train loss item: 0.5552102327346802
train loss item: 0.1966606080532074
train loss item: 0.7755084037780762
train loss item: 0.35261452198028564
test loss item: 0.25693389773368835
test loss item: 0.6362634301185608
test loss item: 0.3662925064563751
test loss item: 0.15442082285881042
test loss item: 0.3417651653289795
test loss item: 0.28926190733909607
test loss item: 0.22710475325584412
test loss item: 0.4193858802318573
test loss item: 0.3435114622116089
test loss item: 0.5583738684654236
test loss item: 0.2087879180908203
test loss item: 0.2760846018791199
test loss item: 0.3190973997116089
test loss item: 0.33902156352996826
test loss item: 0.3174228072166443
test loss item: 0.22639739513397217
test loss item: 0.4182337522506714
test loss item: 0.4764458239078522
test loss item: 0.21202200651168823
test loss item: 0.7432581186294556
test loss item: 0.6825604438781738
test loss item: 0.18403932452201843
test loss item: 0.28034594655036926
Epoch [5/100], Training Loss: 0.4250, Testing Loss: 0.3599
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/100
train loss item: 0.5585629940032959
train loss item: 0.5344494581222534
train loss item: 0.34899744391441345
train loss item: 0.3082354962825775
train loss item: 0.22890688478946686
train loss item: 0.5598739385604858
train loss item: 0.3085964322090149
train loss item: 0.8056288361549377
train loss item: 0.5848270654678345
train loss item: 0.35226064920425415
train loss item: 0.1975589543581009
train loss item: 0.23452666401863098
train loss item: 0.32209163904190063
train loss item: 0.3375929296016693
train loss item: 0.20615604519844055
train loss item: 0.44287624955177307
train loss item: 0.2652926743030548
train loss item: 0.21315178275108337
train loss item: 0.16516441106796265
train loss item: 0.53762286901474
train loss item: 0.2580186724662781
train loss item: 0.6853154897689819
train loss item: 0.284938782453537
test loss item: 0.2315720021724701
test loss item: 0.4646412432193756
test loss item: 0.3032532334327698
test loss item: 0.13924439251422882
test loss item: 0.26666226983070374
test loss item: 0.2470569610595703
test loss item: 0.20609250664710999
test loss item: 0.3299613296985626
test loss item: 0.2876373827457428
test loss item: 0.4399486482143402
test loss item: 0.1940801590681076
test loss item: 0.2270563393831253
test loss item: 0.24952436983585358
test loss item: 0.28514406085014343
test loss item: 0.24138768017292023
test loss item: 0.19574418663978577
test loss item: 0.33208319544792175
test loss item: 0.340351939201355
test loss item: 0.18697066605091095
test loss item: 0.6058893203735352
test loss item: 0.5246335864067078
test loss item: 0.15954670310020447
test loss item: 0.15267521142959595
Epoch [6/100], Training Loss: 0.3800, Testing Loss: 0.2874
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/100
train loss item: 0.4021523594856262
train loss item: 0.3162161409854889
train loss item: 0.2723442614078522
train loss item: 0.3268522322177887
train loss item: 0.21911470592021942
train loss item: 0.41691023111343384
train loss item: 0.24997203052043915
train loss item: 0.5287351012229919
train loss item: 0.37710750102996826
train loss item: 0.47766461968421936
train loss item: 0.18727412819862366
train loss item: 0.1878996044397354
train loss item: 0.29421746730804443
train loss item: 0.3607800006866455
train loss item: 0.20136696100234985
train loss item: 0.39274635910987854
train loss item: 0.25384244322776794
train loss item: 0.20083652436733246
train loss item: 0.19266709685325623
train loss item: 0.4614376425743103
train loss item: 0.20531418919563293
train loss item: 0.5728633403778076
train loss item: 0.22268982231616974
test loss item: 0.19615289568901062
test loss item: 0.481764018535614
test loss item: 0.2989967167377472
test loss item: 0.11951272934675217
test loss item: 0.25567924976348877
test loss item: 0.20863138139247894
test loss item: 0.16439186036586761
test loss item: 0.31888848543167114
test loss item: 0.2509861886501312
test loss item: 0.430711954832077
test loss item: 0.17473486065864563
test loss item: 0.2152552306652069
test loss item: 0.24665547907352448
test loss item: 0.2540634870529175
test loss item: 0.22932513058185577
test loss item: 0.18319068849086761
test loss item: 0.3293408155441284
test loss item: 0.34540244936943054
test loss item: 0.1596243679523468
test loss item: 0.6464223861694336
test loss item: 0.5668483972549438
test loss item: 0.13962748646736145
test loss item: 0.2536185383796692
Epoch [7/100], Training Loss: 0.3183, Testing Loss: 0.2813
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/100
train loss item: 0.4189450740814209
train loss item: 0.30522671341896057
train loss item: 0.20396777987480164
train loss item: 0.2514228820800781
train loss item: 0.17994077503681183
train loss item: 0.3347015976905823
train loss item: 0.20005646347999573
train loss item: 0.3385167717933655
train loss item: 0.278639018535614
train loss item: 0.4125658869743347
train loss item: 0.17626959085464478
train loss item: 0.1907232254743576
train loss item: 0.25492557883262634
train loss item: 0.25476789474487305
train loss item: 0.13487157225608826
train loss item: 0.33062511682510376
train loss item: 0.21381478011608124
train loss item: 0.1730651557445526
train loss item: 0.17049281299114227
train loss item: 0.34431037306785583
train loss item: 0.18457676470279694
train loss item: 0.5556100010871887
train loss item: 0.22263680398464203
test loss item: 0.19097179174423218
test loss item: 0.286514014005661
test loss item: 0.2705909013748169
test loss item: 0.12387676537036896
test loss item: 0.20824222266674042
test loss item: 0.18826885521411896
test loss item: 0.14587140083312988
test loss item: 0.25525540113449097
test loss item: 0.21356524527072906
test loss item: 0.3744790852069855
test loss item: 0.13932961225509644
test loss item: 0.1927987039089203
test loss item: 0.22258500754833221
test loss item: 0.24290576577186584
test loss item: 0.205287903547287
test loss item: 0.16104045510292053
test loss item: 0.2880701422691345
test loss item: 0.23833085596561432
test loss item: 0.15873445570468903
test loss item: 0.5707091689109802
test loss item: 0.46413731575012207
test loss item: 0.12349166721105576
test loss item: 0.1659897118806839
Epoch [8/100], Training Loss: 0.2666, Testing Loss: 0.2361
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/100
train loss item: 0.3802889585494995
train loss item: 0.27206093072891235
train loss item: 0.16991247236728668
train loss item: 0.29638752341270447
train loss item: 0.23741382360458374
train loss item: 0.5567935705184937
train loss item: 0.24496160447597504
train loss item: 0.7605146765708923
train loss item: 0.38512521982192993
train loss item: 0.48402002453804016
train loss item: 0.3905779719352722
train loss item: 0.5678982734680176
train loss item: 0.4188593327999115
train loss item: 0.31763923168182373
train loss item: 0.20315849781036377
train loss item: 0.5621485710144043
train loss item: 0.25946202874183655
train loss item: 0.17660945653915405
train loss item: 0.16251502931118011
train loss item: 0.46363019943237305
train loss item: 0.20161591470241547
train loss item: 0.7525853514671326
train loss item: 0.26906776428222656
test loss item: 0.1697181761264801
test loss item: 0.3958494961261749
test loss item: 0.23475107550621033
test loss item: 0.14532159268856049
test loss item: 0.20542488992214203
test loss item: 0.1956602931022644
test loss item: 0.15181979537010193
test loss item: 0.26134949922561646
test loss item: 0.22014988958835602
test loss item: 0.31401947140693665
test loss item: 0.1515907645225525
test loss item: 0.18914474546909332
test loss item: 0.221982941031456
test loss item: 0.21134255826473236
test loss item: 0.20458614826202393
test loss item: 0.17503401637077332
test loss item: 0.2530139982700348
test loss item: 0.2789519429206848
test loss item: 0.15887142717838287
test loss item: 0.30555540323257446
test loss item: 0.3827064037322998
test loss item: 0.12580417096614838
test loss item: 0.20688292384147644
Epoch [9/100], Training Loss: 0.3710, Testing Loss: 0.2243
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/100
train loss item: 0.3346715271472931
train loss item: 0.2929723262786865
train loss item: 0.2416636347770691
train loss item: 0.19509001076221466
train loss item: 0.156550794839859
train loss item: 0.40651288628578186
train loss item: 0.20927360653877258
train loss item: 0.45220455527305603
train loss item: 0.3544653058052063
train loss item: 0.30481040477752686
train loss item: 0.1297157257795334
train loss item: 0.1752721071243286
train loss item: 0.2897919714450836
train loss item: 0.3201410472393036
train loss item: 0.12874630093574524
train loss item: 0.2718420624732971
train loss item: 0.19182844460010529
train loss item: 0.14839163422584534
train loss item: 0.1459731012582779
train loss item: 0.3529197871685028
train loss item: 0.16293473541736603
train loss item: 0.5676361918449402
train loss item: 0.21354849636554718
test loss item: 0.13014233112335205
test loss item: 0.3868257701396942
test loss item: 0.2147640436887741
test loss item: 0.08463709056377411
test loss item: 0.1947013884782791
test loss item: 0.15652233362197876
test loss item: 0.10899405926465988
test loss item: 0.2535930275917053
test loss item: 0.17891110479831696
test loss item: 0.3057962954044342
test loss item: 0.11475161463022232
test loss item: 0.1364891678094864
test loss item: 0.18655724823474884
test loss item: 0.17882861196994781
test loss item: 0.18416240811347961
test loss item: 0.12706705927848816
test loss item: 0.2034531980752945
test loss item: 0.27732229232788086
test loss item: 0.11255377531051636
test loss item: 0.33339723944664
test loss item: 0.3978010416030884
test loss item: 0.09949417412281036
test loss item: 0.11371277272701263
Epoch [10/100], Training Loss: 0.2629, Testing Loss: 0.1948
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 11/100
train loss item: 0.3275589346885681
train loss item: 0.19452795386314392
train loss item: 0.13208498060703278
train loss item: 0.18438813090324402
train loss item: 0.14985673129558563
train loss item: 0.28770214319229126
train loss item: 0.1623295545578003
train loss item: 0.22299286723136902
train loss item: 0.2554283142089844
train loss item: 0.3485743999481201
train loss item: 0.18729285895824432
train loss item: 0.19506381452083588
train loss item: 0.23676085472106934
train loss item: 0.24339838325977325
train loss item: 0.12782971560955048
train loss item: 0.3229942321777344
train loss item: 0.15201804041862488
train loss item: 0.13559433817863464
train loss item: 0.14702290296554565
train loss item: 0.27183467149734497
train loss item: 0.1798892617225647
train loss item: 0.4590368866920471
train loss item: 0.17645789682865143
test loss item: 0.1593380719423294
test loss item: 0.2827260196208954
test loss item: 0.2281753122806549
test loss item: 0.09424681961536407
test loss item: 0.1804381012916565
test loss item: 0.1634477823972702
test loss item: 0.12050433456897736
test loss item: 0.22078488767147064
test loss item: 0.1765349954366684
test loss item: 0.31232622265815735
test loss item: 0.12349709123373032
test loss item: 0.15494976937770844
test loss item: 0.18269073963165283
test loss item: 0.20542733371257782
test loss item: 0.1712530255317688
test loss item: 0.12227243930101395
test loss item: 0.26069149374961853
test loss item: 0.22368444502353668
test loss item: 0.12944422662258148
test loss item: 0.47597822546958923
test loss item: 0.40507972240448
test loss item: 0.1045326516032219
test loss item: 0.17590580880641937
Epoch [11/100], Training Loss: 0.2218, Testing Loss: 0.2032
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 12/100
train loss item: 0.3143652677536011
train loss item: 0.20028363168239594
train loss item: 0.13563068211078644
train loss item: 0.18514826893806458
train loss item: 0.15526171028614044
train loss item: 0.2906447649002075
train loss item: 0.14878562092781067
train loss item: 0.2682049572467804
train loss item: 0.23215420544147491
train loss item: 0.38534095883369446
train loss item: 0.15949712693691254
train loss item: 0.1563429981470108
train loss item: 0.23042453825473785
train loss item: 0.21663996577262878
train loss item: 0.11632635444402695
train loss item: 0.3180011212825775
train loss item: 0.13417643308639526
train loss item: 0.1395290344953537
train loss item: 0.09734342247247696
train loss item: 0.24409766495227814
train loss item: 0.13239294290542603
train loss item: 0.40229544043540955
train loss item: 0.19195130467414856
test loss item: 0.11485936492681503
test loss item: 0.19832131266593933
test loss item: 0.15148240327835083
test loss item: 0.07554682344198227
test loss item: 0.1244656965136528
test loss item: 0.11854647099971771
test loss item: 0.09223821014165878
test loss item: 0.14167235791683197
test loss item: 0.13109667599201202
test loss item: 0.2028920203447342
test loss item: 0.094832643866539
test loss item: 0.10518790036439896
test loss item: 0.12261554598808289
test loss item: 0.13282285630702972
test loss item: 0.12508821487426758
test loss item: 0.09210918098688126
test loss item: 0.17015521228313446
test loss item: 0.15514886379241943
test loss item: 0.08931480348110199
test loss item: 0.28028956055641174
test loss item: 0.24482496082782745
test loss item: 0.0862061157822609
test loss item: 0.1006075069308281
Epoch [12/100], Training Loss: 0.2111, Testing Loss: 0.1370
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 13/100
train loss item: 0.23135799169540405
train loss item: 0.16528776288032532
train loss item: 0.12143750488758087
train loss item: 0.16350427269935608
train loss item: 0.15935392677783966
train loss item: 0.23295800387859344
train loss item: 0.16998057067394257
train loss item: 0.21286888420581818
train loss item: 0.20675967633724213
train loss item: 0.30472302436828613
train loss item: 0.14189212024211884
train loss item: 0.2146693766117096
train loss item: 0.21408385038375854
train loss item: 0.2521365284919739
train loss item: 0.11018318682909012
train loss item: 0.2636013627052307
train loss item: 0.14711156487464905
train loss item: 0.13229042291641235
train loss item: 0.1183105856180191
train loss item: 0.3093740940093994
train loss item: 0.11718563735485077
train loss item: 0.47694432735443115
train loss item: 0.17038194835186005
test loss item: 0.13413144648075104
test loss item: 0.4509882628917694
test loss item: 0.18571116030216217
test loss item: 0.07985825091600418
test loss item: 0.20224495232105255
test loss item: 0.1760113537311554
test loss item: 0.10871817916631699
test loss item: 0.27147161960601807
test loss item: 0.16922642290592194
test loss item: 0.30532199144363403
test loss item: 0.12233549356460571
test loss item: 0.1517663449048996
test loss item: 0.18675188720226288
test loss item: 0.18668270111083984
test loss item: 0.17381520569324493
test loss item: 0.13083234429359436
test loss item: 0.24219545722007751
test loss item: 0.3268144428730011
test loss item: 0.13788914680480957
test loss item: 0.33441463112831116
test loss item: 0.4016178846359253
test loss item: 0.09689721465110779
test loss item: 0.1083567664027214
Epoch [13/100], Training Loss: 0.2016, Testing Loss: 0.2037
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 14/100
train loss item: 0.3090096116065979
train loss item: 0.2469841092824936
train loss item: 0.19395573437213898
train loss item: 0.1964869350194931
train loss item: 0.14529971778392792
train loss item: 0.3477925956249237
train loss item: 0.20257821679115295
train loss item: 0.3565477430820465
train loss item: 0.24251841008663177
train loss item: 0.2530171871185303
train loss item: 0.11341556161642075
train loss item: 0.14141930639743805
train loss item: 0.2099127620458603
train loss item: 0.21974357962608337
train loss item: 0.10822385549545288
train loss item: 0.25819316506385803
train loss item: 0.1514667123556137
train loss item: 0.1495872139930725
train loss item: 0.0840703472495079
train loss item: 0.26843708753585815
train loss item: 0.12789933383464813
train loss item: 0.355648934841156
train loss item: 0.2497771829366684
test loss item: 0.13851813971996307
test loss item: 0.22718766331672668
test loss item: 0.18089571595191956
test loss item: 0.08387177437543869
test loss item: 0.14410223066806793
test loss item: 0.1428638994693756
test loss item: 0.10841447860002518
test loss item: 0.18537066876888275
test loss item: 0.19264072179794312
test loss item: 0.23041599988937378
test loss item: 0.11201481521129608
test loss item: 0.13787853717803955
test loss item: 0.1806260198354721
test loss item: 0.18153761327266693
test loss item: 0.1421915888786316
test loss item: 0.13043507933616638
test loss item: 0.16959567368030548
test loss item: 0.17845144867897034
test loss item: 0.10034196823835373
test loss item: 0.2664271891117096
test loss item: 0.27065134048461914
test loss item: 0.09332980960607529
test loss item: 0.08968354016542435
Epoch [14/100], Training Loss: 0.2144, Testing Loss: 0.1603
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 15/100
train loss item: 0.31086283922195435
train loss item: 0.21598897874355316
train loss item: 0.18371044099330902
train loss item: 0.1326296627521515
train loss item: 0.13525156676769257
train loss item: 0.27427005767822266
train loss item: 0.1998910754919052
train loss item: 0.3051774203777313
train loss item: 0.2506851553916931
train loss item: 0.24354027211666107
train loss item: 0.09474808722734451
train loss item: 0.13233612477779388
train loss item: 0.20690788328647614
train loss item: 0.19617080688476562
train loss item: 0.08838056772947311
train loss item: 0.21123996376991272
train loss item: 0.1325126737356186
train loss item: 0.11187136173248291
train loss item: 0.10151863843202591
train loss item: 0.3571396470069885
train loss item: 0.13839280605316162
train loss item: 0.6354599595069885
train loss item: 0.15303990244865417
test loss item: 0.13423247635364532
test loss item: 0.2481107860803604
test loss item: 0.17687803506851196
test loss item: 0.10016598552465439
test loss item: 0.15660372376441956
test loss item: 0.14098364114761353
test loss item: 0.10575801134109497
test loss item: 0.18338672816753387
test loss item: 0.1716773360967636
test loss item: 0.23467572033405304
test loss item: 0.11246200650930405
test loss item: 0.13819630444049835
test loss item: 0.1789892017841339
test loss item: 0.17143581807613373
test loss item: 0.1445452868938446
test loss item: 0.12469404190778732
test loss item: 0.1713147610425949
test loss item: 0.197459414601326
test loss item: 0.10816273093223572
test loss item: 0.25110235810279846
test loss item: 0.2647736966609955
test loss item: 0.08750323206186295
test loss item: 0.09274200350046158
Epoch [15/100], Training Loss: 0.2092, Testing Loss: 0.1607
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 16/100
train loss item: 0.2732023596763611
train loss item: 0.21976612508296967
train loss item: 0.2472693920135498
train loss item: 0.17040911316871643
train loss item: 0.12278465926647186
train loss item: 0.2533915936946869
train loss item: 0.17811919748783112
train loss item: 0.42223942279815674
train loss item: 0.29134440422058105
train loss item: 0.1548498421907425
train loss item: 0.096696637570858
train loss item: 0.12859241664409637
train loss item: 0.2512688636779785
train loss item: 0.31914153695106506
train loss item: 0.09837689995765686
train loss item: 0.24434451758861542
train loss item: 0.13097593188285828
train loss item: 0.11738350987434387
train loss item: 0.10257906466722488
train loss item: 0.401559442281723
train loss item: 0.19254618883132935
train loss item: 0.8089110851287842
train loss item: 0.1449006050825119
test loss item: 0.20789773762226105
test loss item: 0.2023884803056717
test loss item: 0.2804575562477112
test loss item: 0.09845265001058578
test loss item: 0.13940441608428955
test loss item: 0.15196169912815094
test loss item: 0.11226875334978104
test loss item: 0.25180405378341675
test loss item: 0.20598571002483368
test loss item: 0.3744586110115051
test loss item: 0.111831896007061
test loss item: 0.13845892250537872
test loss item: 0.2112390249967575
test loss item: 0.26889511942863464
test loss item: 0.17080606520175934
test loss item: 0.12212330102920532
test loss item: 0.27257564663887024
test loss item: 0.1914140284061432
test loss item: 0.10925096273422241
test loss item: 0.6358022093772888
test loss item: 0.46224844455718994
test loss item: 0.1113082766532898
test loss item: 0.1433073729276657
Epoch [16/100], Training Loss: 0.2335, Testing Loss: 0.2163
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 17/100
train loss item: 0.3163450062274933
train loss item: 0.236819326877594
train loss item: 0.2543181777000427
train loss item: 0.3213060200214386
train loss item: 0.28071340918540955
train loss item: 0.6626084446907043
train loss item: 0.22191445529460907
train loss item: 0.4037418067455292
train loss item: 0.3255635201931
train loss item: 0.26305967569351196
train loss item: 0.2289675623178482
train loss item: 0.453366219997406
train loss item: 0.38189736008644104
train loss item: 0.7854611873626709
train loss item: 0.21083320677280426
train loss item: 0.4915808439254761
train loss item: 0.20892539620399475
train loss item: 0.23699171841144562
train loss item: 0.1398700326681137
train loss item: 0.3770301938056946
train loss item: 0.2333570420742035
train loss item: 0.28633302450180054
train loss item: 0.23007042706012726
test loss item: 0.29601460695266724
test loss item: 0.35413768887519836
test loss item: 0.3984965980052948
test loss item: 0.12113795429468155
test loss item: 0.206080824136734
test loss item: 0.19999530911445618
test loss item: 0.1482996940612793
test loss item: 0.3878489136695862
test loss item: 0.2664259970188141
test loss item: 0.5999029874801636
test loss item: 0.1741955578327179
test loss item: 0.16685284674167633
test loss item: 0.3125171959400177
test loss item: 0.36544275283813477
test loss item: 0.257753849029541
test loss item: 0.17078855633735657
test loss item: 0.3868381679058075
test loss item: 0.3136376440525055
test loss item: 0.17186586558818817
test loss item: 1.0394911766052246
test loss item: 0.7716081142425537
test loss item: 0.15044419467449188
test loss item: 0.12418074905872345
Epoch [17/100], Training Loss: 0.3283, Testing Loss: 0.3210
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 18/100
train loss item: 0.43314698338508606
train loss item: 0.24611322581768036
train loss item: 0.15674497187137604
train loss item: 0.2481537163257599
train loss item: 0.16050606966018677
train loss item: 0.4571300446987152
train loss item: 0.1599660962820053
train loss item: 0.5673392415046692
train loss item: 0.357443630695343
train loss item: 0.3240668475627899
train loss item: 0.14646269381046295
train loss item: 0.20560075342655182
train loss item: 0.26705753803253174
train loss item: 0.28928664326667786
train loss item: 0.11461357772350311
train loss item: 0.24434605240821838
train loss item: 0.16765889525413513
train loss item: 0.1283113807439804
train loss item: 0.1089370921254158
train loss item: 0.33474698662757874
train loss item: 0.1624424010515213
train loss item: 0.5972700715065002
train loss item: 0.16325144469738007
test loss item: 0.15655234456062317
test loss item: 0.1906760036945343
test loss item: 0.1890304982662201
test loss item: 0.10755553841590881
test loss item: 0.13536429405212402
test loss item: 0.14370352029800415
test loss item: 0.13009727001190186
test loss item: 0.16831795871257782
test loss item: 0.17510226368904114
test loss item: 0.23316805064678192
test loss item: 0.12090068310499191
test loss item: 0.1223803162574768
test loss item: 0.17162242531776428
test loss item: 0.17945195734500885
test loss item: 0.1484716385602951
test loss item: 0.12239018827676773
test loss item: 0.19902360439300537
test loss item: 0.157210573554039
test loss item: 0.12488572299480438
test loss item: 0.31885725259780884
test loss item: 0.2788655459880829
test loss item: 0.12077917158603668
test loss item: 0.19640061259269714
Epoch [18/100], Training Loss: 0.2626, Testing Loss: 0.1692
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 19/100
train loss item: 0.22309307754039764
train loss item: 0.13791778683662415
train loss item: 0.16474802792072296
train loss item: 0.17990432679653168
train loss item: 0.15479572117328644
train loss item: 0.31293559074401855
train loss item: 0.13955676555633545
train loss item: 0.35356298089027405
train loss item: 0.30062514543533325
train loss item: 0.26473766565322876
train loss item: 0.1732974797487259
train loss item: 0.37216606736183167
train loss item: 0.3032092750072479
train loss item: 0.5552408695220947
train loss item: 0.17525264620780945
train loss item: 0.38485896587371826
train loss item: 0.18805190920829773
train loss item: 0.1567559540271759
train loss item: 0.10553234815597534
train loss item: 0.2578390836715698
train loss item: 0.14048995077610016
train loss item: 0.23577731847763062
train loss item: 0.17120347917079926
test loss item: 0.20200566947460175
test loss item: 0.23883122205734253
test loss item: 0.25321564078330994
test loss item: 0.10192595422267914
test loss item: 0.15893837809562683
test loss item: 0.15480375289916992
test loss item: 0.1265561431646347
test loss item: 0.2353135198354721
test loss item: 0.194960355758667
test loss item: 0.3537604510784149
test loss item: 0.1407867968082428
test loss item: 0.13709507882595062
test loss item: 0.19623993337154388
test loss item: 0.2385481894016266
test loss item: 0.169870525598526
test loss item: 0.12220967561006546
test loss item: 0.25996318459510803
test loss item: 0.2168475240468979
test loss item: 0.13390521705150604
test loss item: 0.5810821652412415
test loss item: 0.4510602355003357
test loss item: 0.12802021205425262
test loss item: 0.12799009680747986
Epoch [19/100], Training Loss: 0.2370, Testing Loss: 0.2141
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 20/100
train loss item: 0.44718047976493835
train loss item: 0.3370766043663025
train loss item: 0.20078827440738678
train loss item: 0.2324378788471222
train loss item: 0.12930424511432648
train loss item: 0.3400287628173828
train loss item: 0.13721409440040588
train loss item: 0.3010435104370117
train loss item: 0.1881791651248932
train loss item: 0.2269759476184845
train loss item: 0.09687657654285431
train loss item: 0.12719102203845978
train loss item: 0.22372747957706451
train loss item: 0.2147682160139084
train loss item: 0.09291363507509232
train loss item: 0.2188066989183426
train loss item: 0.1494102030992508
train loss item: 0.11385292559862137
train loss item: 0.09862899780273438
train loss item: 0.31329843401908875
train loss item: 0.1334330141544342
train loss item: 0.5816722512245178
train loss item: 0.13856260478496552
test loss item: 0.1502525806427002
test loss item: 0.18812178075313568
test loss item: 0.2039613127708435
test loss item: 0.070759616792202
test loss item: 0.11961402744054794
test loss item: 0.12209160625934601
test loss item: 0.08839132636785507
test loss item: 0.1894732564687729
test loss item: 0.1577189415693283
test loss item: 0.2702849805355072
test loss item: 0.0864621251821518
test loss item: 0.1132497489452362
test loss item: 0.15751269459724426
test loss item: 0.1926189512014389
test loss item: 0.12666764855384827
test loss item: 0.09367746114730835
test loss item: 0.19601283967494965
test loss item: 0.16358524560928345
test loss item: 0.08524222671985626
test loss item: 0.42554154992103577
test loss item: 0.32349419593811035
test loss item: 0.08065194636583328
test loss item: 0.09111976623535156
Epoch [20/100], Training Loss: 0.2193, Testing Loss: 0.1607
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 21/100
train loss item: 0.2630383372306824
train loss item: 0.1457313597202301
train loss item: 0.20848023891448975
train loss item: 0.18606647849082947
train loss item: 0.20793190598487854
train loss item: 0.3505720794200897
train loss item: 0.24781595170497894
train loss item: 0.3406229019165039
train loss item: 0.2235713005065918
train loss item: 0.1803119033575058
train loss item: 0.16190050542354584
train loss item: 0.3623344302177429
train loss item: 0.3265939950942993
train loss item: 0.605388879776001
train loss item: 0.17902304232120514
train loss item: 0.470218688249588
train loss item: 0.19208107888698578
train loss item: 0.16488294303417206
train loss item: 0.09607816487550735
train loss item: 0.26544106006622314
train loss item: 0.17969992756843567
train loss item: 0.2678314745426178
train loss item: 0.19476290047168732
test loss item: 0.1666376143693924
test loss item: 0.2790520489215851
test loss item: 0.19606934487819672
test loss item: 0.08441674709320068
test loss item: 0.16144540905952454
test loss item: 0.16448760032653809
test loss item: 0.11925297975540161
test loss item: 0.210610494017601
test loss item: 0.1632722020149231
test loss item: 0.2888626456260681
test loss item: 0.1435634195804596
test loss item: 0.149240180850029
test loss item: 0.16777153313159943
test loss item: 0.19271016120910645
test loss item: 0.14795859158039093
test loss item: 0.12056978791952133
test loss item: 0.220407173037529
test loss item: 0.22000469267368317
test loss item: 0.15196454524993896
test loss item: 0.4090319573879242
test loss item: 0.3520749509334564
test loss item: 0.11678789556026459
test loss item: 0.17267951369285583
Epoch [21/100], Training Loss: 0.2531, Testing Loss: 0.1913
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 22/100
train loss item: 0.32673975825309753
train loss item: 0.2668607831001282
train loss item: 0.2073572427034378
train loss item: 0.2638876438140869
train loss item: 0.14045067131519318
train loss item: 0.28989773988723755
train loss item: 0.10264001041650772
train loss item: 0.25098150968551636
train loss item: 0.22506429255008698
train loss item: 0.15810738503932953
train loss item: 0.12616358697414398
train loss item: 0.1649593859910965
train loss item: 0.228972926735878
train loss item: 0.2124054878950119
train loss item: 0.11752131581306458
train loss item: 0.3186171352863312
train loss item: 0.14207375049591064
train loss item: 0.12019729614257812
train loss item: 0.07661034911870956
train loss item: 0.21631090342998505
train loss item: 0.12963928282260895
train loss item: 0.5078986883163452
train loss item: 0.12449897825717926
test loss item: 0.14305689930915833
test loss item: 0.19323450326919556
test loss item: 0.1800660789012909
test loss item: 0.07406006008386612
test loss item: 0.12588313221931458
test loss item: 0.1261114925146103
test loss item: 0.09616291522979736
test loss item: 0.16697512567043304
test loss item: 0.14413611590862274
test loss item: 0.23119954764842987
test loss item: 0.10655934363603592
test loss item: 0.11555904895067215
test loss item: 0.1398172676563263
test loss item: 0.17264682054519653
test loss item: 0.11796186864376068
test loss item: 0.0921294167637825
test loss item: 0.18292509019374847
test loss item: 0.16350747644901276
test loss item: 0.09856715798377991
test loss item: 0.34459251165390015
test loss item: 0.2796076834201813
test loss item: 0.09526678919792175
test loss item: 0.10956121981143951
Epoch [22/100], Training Loss: 0.2051, Testing Loss: 0.1522
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.2660503387451172
loss item: 0.1489536315202713
loss item: 0.12166782468557358
loss item: 0.12704512476921082
loss item: 0.1922481805086136
loss item: 0.10304348170757294
loss item: 0.18580716848373413
loss item: 0.2834436893463135
loss item: 0.10279557853937149
loss item: 0.14171329140663147
loss item: 0.21432079374790192
Val Loss: 0.1716
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 100, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.001 8 360 done at Tue Nov 12 13:40:01 CET 2024
UNet2 with 1 100 0.005 8 360 start at Tue Nov 12 13:40:01 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 100, batch size: 8
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.4765785932540894
train loss item: 1.488364577293396
train loss item: 1.227317452430725
train loss item: 0.9579159021377563
train loss item: 0.47981324791908264
train loss item: 1.0573915243148804
train loss item: 0.5085159540176392
train loss item: 1.6343568563461304
train loss item: 1.794062614440918
train loss item: 0.5039210319519043
train loss item: 0.5952209830284119
train loss item: 0.4662436246871948
train loss item: 0.6920085549354553
train loss item: 1.3686498403549194
train loss item: 0.4267558455467224
train loss item: 1.2039326429367065
train loss item: 0.47162064909935
train loss item: 0.5360599756240845
train loss item: 0.42717626690864563
train loss item: 1.0362893342971802
train loss item: 0.5555956363677979
train loss item: 1.9805022478103638
train loss item: 0.4602459967136383
test loss item: 0.6217797994613647
test loss item: 2.0337860584259033
test loss item: 1.213813066482544
test loss item: 0.38870155811309814
test loss item: 1.382132887840271
test loss item: 0.8165193200111389
test loss item: 0.5437419414520264
test loss item: 1.2737616300582886
test loss item: 1.3834030628204346
test loss item: 1.8372173309326172
test loss item: 0.592004120349884
test loss item: 0.9243448972702026
test loss item: 1.0557352304458618
test loss item: 1.036850929260254
test loss item: 1.3563196659088135
test loss item: 0.5631416440010071
test loss item: 1.1755098104476929
test loss item: 1.8684247732162476
test loss item: 0.6068812608718872
test loss item: 1.7190667390823364
test loss item: 2.2971298694610596
test loss item: 0.43986159563064575
test loss item: 0.6305710077285767
Epoch [1/100], Training Loss: 0.9282, Testing Loss: 1.1200
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 2/100
train loss item: 0.8817241191864014
train loss item: 0.6220057606697083
train loss item: 0.37252718210220337
train loss item: 0.48133644461631775
train loss item: 0.4621841609477997
train loss item: 0.7980542778968811
train loss item: 0.4550514817237854
train loss item: 1.257053017616272
train loss item: 1.5772531032562256
train loss item: 0.45303359627723694
train loss item: 0.451168030500412
train loss item: 0.4531153738498688
train loss item: 0.6032328009605408
train loss item: 1.275573492050171
train loss item: 0.3529285490512848
train loss item: 1.1563992500305176
train loss item: 0.4298779368400574
train loss item: 0.4244886636734009
train loss item: 0.2824743092060089
train loss item: 1.0078117847442627
train loss item: 0.5240007042884827
train loss item: 1.708648920059204
train loss item: 0.42949140071868896
test loss item: 0.442624032497406
test loss item: 0.8245567083358765
test loss item: 0.6602063179016113
test loss item: 0.20956861972808838
test loss item: 0.5388758182525635
test loss item: 0.4418867528438568
test loss item: 0.32372337579727173
test loss item: 0.6586329936981201
test loss item: 0.5979886054992676
test loss item: 0.9395972490310669
test loss item: 0.3086383044719696
test loss item: 0.4864426851272583
test loss item: 0.577355682849884
test loss item: 0.6563327312469482
test loss item: 0.4668954908847809
test loss item: 0.3657890260219574
test loss item: 0.6423410177230835
test loss item: 0.7166123986244202
test loss item: 0.2991071045398712
test loss item: 1.170305848121643
test loss item: 1.0574113130569458
test loss item: 0.21842075884342194
test loss item: 0.3052617013454437
Epoch [2/100], Training Loss: 0.7156, Testing Loss: 0.5612
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 3/100
train loss item: 0.7431809902191162
train loss item: 0.6191406846046448
train loss item: 0.43029603362083435
train loss item: 0.42559051513671875
train loss item: 0.4080215394496918
train loss item: 0.7563353776931763
train loss item: 0.3635371923446655
train loss item: 1.1390384435653687
train loss item: 1.3282111883163452
train loss item: 0.44343921542167664
train loss item: 0.3567367494106293
train loss item: 0.4475926160812378
train loss item: 0.5829280018806458
train loss item: 1.0786911249160767
train loss item: 0.330636203289032
train loss item: 1.0156275033950806
train loss item: 0.42239853739738464
train loss item: 0.3858896791934967
train loss item: 0.25743162631988525
train loss item: 0.9137788414955139
train loss item: 0.42193618416786194
train loss item: 1.4729211330413818
train loss item: 0.40966910123825073
test loss item: 0.3893614411354065
test loss item: 1.0323541164398193
test loss item: 0.72443687915802
test loss item: 0.23743866384029388
test loss item: 0.7091763019561768
test loss item: 0.42930880188941956
test loss item: 0.34910112619400024
test loss item: 0.7346993088722229
test loss item: 0.7086458802223206
test loss item: 1.0439419746398926
test loss item: 0.3099004924297333
test loss item: 0.5220818519592285
test loss item: 0.648734986782074
test loss item: 0.6613513827323914
test loss item: 0.6533994674682617
test loss item: 0.378279447555542
test loss item: 0.6705164313316345
test loss item: 0.9307916164398193
test loss item: 0.30650296807289124
test loss item: 1.1147801876068115
test loss item: 1.2291043996810913
test loss item: 0.23978836834430695
test loss item: 0.4042002558708191
Epoch [3/100], Training Loss: 0.6414, Testing Loss: 0.6273
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 4/100
train loss item: 0.7174620628356934
train loss item: 0.626370906829834
train loss item: 0.40952324867248535
train loss item: 0.4464689791202545
train loss item: 0.3397260308265686
train loss item: 0.7972732782363892
train loss item: 0.37226226925849915
train loss item: 1.0186164379119873
train loss item: 1.087173581123352
train loss item: 0.5898532271385193
train loss item: 0.43383219838142395
train loss item: 0.518644392490387
train loss item: 0.5865426063537598
train loss item: 0.9519888162612915
train loss item: 0.26932379603385925
train loss item: 1.0012365579605103
train loss item: 0.42180994153022766
train loss item: 0.3636658489704132
train loss item: 0.24974589049816132
train loss item: 0.869410514831543
train loss item: 0.39114290475845337
train loss item: 1.308923363685608
train loss item: 0.4488106369972229
test loss item: 0.46738114953041077
test loss item: 1.05255126953125
test loss item: 0.7785388231277466
test loss item: 0.22049495577812195
test loss item: 0.761809229850769
test loss item: 0.47466912865638733
test loss item: 0.34532245993614197
test loss item: 0.7612624764442444
test loss item: 0.7938814759254456
test loss item: 1.1449915170669556
test loss item: 0.3093205988407135
test loss item: 0.5632598400115967
test loss item: 0.6869807839393616
test loss item: 0.7593849897384644
test loss item: 0.7014322280883789
test loss item: 0.3816555142402649
test loss item: 0.7469164133071899
test loss item: 0.996607780456543
test loss item: 0.2980276644229889
test loss item: 1.279030680656433
test loss item: 1.3300002813339233
test loss item: 0.23272831737995148
test loss item: 0.23110859096050262
Epoch [4/100], Training Loss: 0.6183, Testing Loss: 0.6660
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 5/100
train loss item: 0.7039119601249695
train loss item: 0.574923574924469
train loss item: 0.3799315392971039
train loss item: 0.47770166397094727
train loss item: 0.35004091262817383
train loss item: 0.7785196900367737
train loss item: 0.383879691362381
train loss item: 0.9350206255912781
train loss item: 0.9613019824028015
train loss item: 0.5624580383300781
train loss item: 0.33632874488830566
train loss item: 0.4587704837322235
train loss item: 0.5480469465255737
train loss item: 0.8911879062652588
train loss item: 0.2724534571170807
train loss item: 0.914302408695221
train loss item: 0.4085254371166229
train loss item: 0.3735141158103943
train loss item: 0.2646847069263458
train loss item: 0.8681567311286926
train loss item: 0.3723757565021515
train loss item: 1.1929198503494263
train loss item: 0.43668046593666077
test loss item: 0.37410157918930054
test loss item: 0.9319489002227783
test loss item: 0.6321455240249634
test loss item: 0.1855507344007492
test loss item: 0.5884519815444946
test loss item: 0.4237440228462219
test loss item: 0.3056093156337738
test loss item: 0.6545339822769165
test loss item: 0.5989649295806885
test loss item: 0.9356948733329773
test loss item: 0.27890706062316895
test loss item: 0.4743272066116333
test loss item: 0.5543439388275146
test loss item: 0.5956098437309265
test loss item: 0.531182050704956
test loss item: 0.33013099431991577
test loss item: 0.6357483267784119
test loss item: 0.7942562699317932
test loss item: 0.27731576561927795
test loss item: 1.1459107398986816
test loss item: 1.1016350984573364
test loss item: 0.20692336559295654
test loss item: 0.20810559391975403
Epoch [5/100], Training Loss: 0.5846, Testing Loss: 0.5550
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 6/100
train loss item: 0.7258139848709106
train loss item: 0.5964581966400146
train loss item: 0.4212470054626465
train loss item: 0.45946282148361206
train loss item: 0.33255571126937866
train loss item: 0.8159078359603882
train loss item: 0.37336626648902893
train loss item: 1.3230717182159424
train loss item: 1.182820439338684
train loss item: 0.4841574728488922
train loss item: 0.32276782393455505
train loss item: 0.4924411177635193
train loss item: 0.6536904573440552
train loss item: 0.8118979334831238
train loss item: 0.27969956398010254
train loss item: 0.8857945799827576
train loss item: 0.4237791895866394
train loss item: 0.3810163736343384
train loss item: 0.2570098042488098
train loss item: 0.8441897630691528
train loss item: 0.39039427042007446
train loss item: 1.2285592555999756
train loss item: 0.4488706588745117
test loss item: 0.39778944849967957
test loss item: 0.9530107378959656
test loss item: 0.6834079623222351
test loss item: 0.21911463141441345
test loss item: 0.6431211233139038
test loss item: 0.4831697642803192
test loss item: 0.3239939510822296
test loss item: 0.6917904615402222
test loss item: 0.6468290090560913
test loss item: 1.0052273273468018
test loss item: 0.3000010848045349
test loss item: 0.5213977098464966
test loss item: 0.578122615814209
test loss item: 0.6294636726379395
test loss item: 0.5888211131095886
test loss item: 0.3422567844390869
test loss item: 0.7158852219581604
test loss item: 0.8656120896339417
test loss item: 0.3080834448337555
test loss item: 1.3518414497375488
test loss item: 1.221479058265686
test loss item: 0.22763673961162567
test loss item: 0.3262714743614197
Epoch [6/100], Training Loss: 0.6146, Testing Loss: 0.6098
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 7/100
train loss item: 0.7267663478851318
train loss item: 0.5698537230491638
train loss item: 0.3592057526111603
train loss item: 0.43740877509117126
train loss item: 0.35417819023132324
train loss item: 0.7272497415542603
train loss item: 0.35835132002830505
train loss item: 0.9326810836791992
train loss item: 0.9248903393745422
train loss item: 0.6234329342842102
train loss item: 0.36931127309799194
train loss item: 0.493334025144577
train loss item: 0.5250651836395264
train loss item: 0.7816253304481506
train loss item: 0.25263822078704834
train loss item: 0.8849621415138245
train loss item: 0.42843177914619446
train loss item: 0.4001248776912689
train loss item: 0.27313631772994995
train loss item: 0.8361257910728455
train loss item: 0.3223380744457245
train loss item: 1.1158024072647095
train loss item: 0.44738849997520447
test loss item: 0.35534361004829407
test loss item: 0.8205820322036743
test loss item: 0.5750560164451599
test loss item: 0.23612353205680847
test loss item: 0.5341339707374573
test loss item: 0.4210301637649536
test loss item: 0.33473560214042664
test loss item: 0.6047075986862183
test loss item: 0.5386766195297241
test loss item: 0.8434469699859619
test loss item: 0.28982749581336975
test loss item: 0.48102158308029175
test loss item: 0.5347752571105957
test loss item: 0.5691784620285034
test loss item: 0.4893149733543396
test loss item: 0.3581183850765228
test loss item: 0.6084527373313904
test loss item: 0.6960432529449463
test loss item: 0.30789896845817566
test loss item: 1.0774197578430176
test loss item: 0.9705296754837036
test loss item: 0.25533992052078247
test loss item: 0.12977609038352966
Epoch [7/100], Training Loss: 0.5715, Testing Loss: 0.5231
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 8/100
train loss item: 0.7272899746894836
train loss item: 0.5872588753700256
train loss item: 0.38175132870674133
train loss item: 0.4086724817752838
train loss item: 0.3289783000946045
train loss item: 0.7345446944236755
train loss item: 0.3569645285606384
train loss item: 0.9701979160308838
train loss item: 0.8142133951187134
train loss item: 0.4673137366771698
train loss item: 0.32667258381843567
train loss item: 0.42710763216018677
train loss item: 0.5883377194404602
train loss item: 0.6467156410217285
train loss item: 0.2946280837059021
train loss item: 0.8614826798439026
train loss item: 0.4490787088871002
train loss item: 0.2939826548099518
train loss item: 0.2462325543165207
train loss item: 0.8020029664039612
train loss item: 0.3233439028263092
train loss item: 0.9952220320701599
train loss item: 0.4318726062774658
test loss item: 0.34055477380752563
test loss item: 0.8369766473770142
test loss item: 0.6396313905715942
test loss item: 0.20721422135829926
test loss item: 0.6207358241081238
test loss item: 0.385470449924469
test loss item: 0.32290613651275635
test loss item: 0.6486676335334778
test loss item: 0.6326549649238586
test loss item: 0.9069697260856628
test loss item: 0.2713780999183655
test loss item: 0.4668465554714203
test loss item: 0.5623326897621155
test loss item: 0.6086522936820984
test loss item: 0.5785622000694275
test loss item: 0.34528642892837524
test loss item: 0.6217582821846008
test loss item: 0.8041443228721619
test loss item: 0.26715347170829773
test loss item: 1.1012139320373535
test loss item: 1.1010611057281494
test loss item: 0.2463863044977188
test loss item: 0.16404548287391663
Epoch [8/100], Training Loss: 0.5419, Testing Loss: 0.5513
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 9/100
train loss item: 0.7703940868377686
train loss item: 0.5334939360618591
train loss item: 0.3502785861492157
train loss item: 0.37166568636894226
train loss item: 0.3334176540374756
train loss item: 0.6909460425376892
train loss item: 0.3532652258872986
train loss item: 1.1528801918029785
train loss item: 1.1219911575317383
train loss item: 0.37457677721977234
train loss item: 0.2805066406726837
train loss item: 0.40913480520248413
train loss item: 0.6329443454742432
train loss item: 0.5845546126365662
train loss item: 0.2534327805042267
train loss item: 0.7026832103729248
train loss item: 0.4263654351234436
train loss item: 0.33342379331588745
train loss item: 0.28184860944747925
train loss item: 0.7777411341667175
train loss item: 0.31234097480773926
train loss item: 1.240585446357727
train loss item: 0.35906389355659485
test loss item: 0.38935062289237976
test loss item: 0.7134092450141907
test loss item: 0.6531888842582703
test loss item: 0.23014195263385773
test loss item: 0.5027258992195129
test loss item: 0.35743141174316406
test loss item: 0.3176245391368866
test loss item: 0.6231414079666138
test loss item: 0.574480414390564
test loss item: 0.8561421632766724
test loss item: 0.2829223573207855
test loss item: 0.3987257182598114
test loss item: 0.5682259202003479
test loss item: 0.6067259311676025
test loss item: 0.4729430377483368
test loss item: 0.3445263206958771
test loss item: 0.4997222423553467
test loss item: 0.6403508186340332
test loss item: 0.255167692899704
test loss item: 0.9317166209220886
test loss item: 1.013117790222168
test loss item: 0.23527471721172333
test loss item: 0.26719924807548523
Epoch [9/100], Training Loss: 0.5499, Testing Loss: 0.5102
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 10/100
train loss item: 0.6217573285102844
train loss item: 0.5123216509819031
train loss item: 0.3515888750553131
train loss item: 0.4296025335788727
train loss item: 0.3172314167022705
train loss item: 0.6446788907051086
train loss item: 0.3274358808994293
train loss item: 0.7559594511985779
train loss item: 0.7494234442710876
train loss item: 0.37548062205314636
train loss item: 0.23544816672801971
train loss item: 0.34681645035743713
train loss item: 0.436846524477005
train loss item: 0.5363389849662781
train loss item: 0.21451492607593536
train loss item: 0.6683383584022522
train loss item: 0.4061759114265442
train loss item: 0.3436148166656494
train loss item: 0.2299022674560547
train loss item: 0.7213573455810547
train loss item: 0.26962706446647644
train loss item: 0.842467188835144
train loss item: 0.3741322457790375
test loss item: 0.2845813035964966
test loss item: 0.5847358703613281
test loss item: 0.4401687681674957
test loss item: 0.15670783817768097
test loss item: 0.39349016547203064
test loss item: 0.33488333225250244
test loss item: 0.23750367760658264
test loss item: 0.44855281710624695
test loss item: 0.4153664708137512
test loss item: 0.63017338514328
test loss item: 0.23151730000972748
test loss item: 0.35347431898117065
test loss item: 0.3843998312950134
test loss item: 0.42891648411750793
test loss item: 0.33463162183761597
test loss item: 0.26053428649902344
test loss item: 0.4134325385093689
test loss item: 0.5011799335479736
test loss item: 0.23628869652748108
test loss item: 0.7150332927703857
test loss item: 0.6951538324356079
test loss item: 0.16753438115119934
test loss item: 0.17316603660583496
Epoch [10/100], Training Loss: 0.4657, Testing Loss: 0.3835
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 11/100
train loss item: 0.6239217519760132
train loss item: 0.4374662935733795
train loss item: 0.31729674339294434
train loss item: 0.36691999435424805
train loss item: 0.2912686765193939
train loss item: 0.574586808681488
train loss item: 0.29416748881340027
train loss item: 0.7117205262184143
train loss item: 0.5692862868309021
train loss item: 0.4640662372112274
train loss item: 0.25078970193862915
train loss item: 0.31295180320739746
train loss item: 0.440468430519104
train loss item: 0.526085615158081
train loss item: 0.20879779756069183
train loss item: 0.706867516040802
train loss item: 0.30493980646133423
train loss item: 0.2682536244392395
train loss item: 0.21056616306304932
train loss item: 0.6218894720077515
train loss item: 0.24763919413089752
train loss item: 0.6863712668418884
train loss item: 0.3771902024745941
test loss item: 0.25996941328048706
test loss item: 0.4953483045101166
test loss item: 0.3964201509952545
test loss item: 0.14188705384731293
test loss item: 0.340616375207901
test loss item: 0.29626592993736267
test loss item: 0.2192833423614502
test loss item: 0.39411574602127075
test loss item: 0.3625562787055969
test loss item: 0.5636076331138611
test loss item: 0.21532180905342102
test loss item: 0.3164033889770508
test loss item: 0.3314795196056366
test loss item: 0.38096708059310913
test loss item: 0.29080694913864136
test loss item: 0.24693511426448822
test loss item: 0.39966827630996704
test loss item: 0.41764092445373535
test loss item: 0.206881582736969
test loss item: 0.7130351066589355
test loss item: 0.6341637969017029
test loss item: 0.15532948076725006
test loss item: 0.13827694952487946
Epoch [11/100], Training Loss: 0.4267, Testing Loss: 0.3442
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 12/100
train loss item: 0.723168671131134
train loss item: 0.41939157247543335
train loss item: 0.2668781578540802
train loss item: 0.35764363408088684
train loss item: 0.3057985007762909
train loss item: 0.6058644652366638
train loss item: 0.29556944966316223
train loss item: 1.027614951133728
train loss item: 0.9764856100082397
train loss item: 0.36523038148880005
train loss item: 0.2498297393321991
train loss item: 0.3943484127521515
train loss item: 0.6269732117652893
train loss item: 0.494305282831192
train loss item: 0.20523139834403992
train loss item: 0.6079903841018677
train loss item: 0.3065178692340851
train loss item: 0.2498192936182022
train loss item: 0.20995377004146576
train loss item: 0.5817435383796692
train loss item: 0.2601989507675171
train loss item: 1.0243887901306152
train loss item: 0.35914134979248047
test loss item: 0.3125884532928467
test loss item: 0.7003306150436401
test loss item: 0.5794586539268494
test loss item: 0.15840968489646912
test loss item: 0.5172861814498901
test loss item: 0.30346518754959106
test loss item: 0.2741757333278656
test loss item: 0.5623692274093628
test loss item: 0.5479605197906494
test loss item: 0.7796016335487366
test loss item: 0.2397298961877823
test loss item: 0.38658004999160767
test loss item: 0.5089015364646912
test loss item: 0.5387187004089355
test loss item: 0.47128286957740784
test loss item: 0.27957358956336975
test loss item: 0.47035151720046997
test loss item: 0.6603280901908875
test loss item: 0.23214305937290192
test loss item: 0.7958348393440247
test loss item: 0.9530887007713318
test loss item: 0.19346758723258972
test loss item: 0.18945039808750153
Epoch [12/100], Training Loss: 0.4745, Testing Loss: 0.4633
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 13/100
train loss item: 0.523550808429718
train loss item: 0.39514604210853577
train loss item: 0.2691616117954254
train loss item: 0.34232616424560547
train loss item: 0.3015027344226837
train loss item: 0.5460984110832214
train loss item: 0.2872086763381958
train loss item: 0.6201736927032471
train loss item: 0.551821231842041
train loss item: 0.3719647526741028
train loss item: 0.23449541628360748
train loss item: 0.3271668255329132
train loss item: 0.36025702953338623
train loss item: 0.38937851786613464
train loss item: 0.1870482712984085
train loss item: 0.5470423102378845
train loss item: 0.3868390619754791
train loss item: 0.28423619270324707
train loss item: 0.19752945005893707
train loss item: 0.6917321681976318
train loss item: 0.22880129516124725
train loss item: 0.7305253148078918
train loss item: 0.2951447069644928
test loss item: 0.28530532121658325
test loss item: 0.9110441207885742
test loss item: 0.5518559813499451
test loss item: 0.20118500292301178
test loss item: 0.617883026599884
test loss item: 0.358574777841568
test loss item: 0.2967339754104614
test loss item: 0.6111057996749878
test loss item: 0.5807419419288635
test loss item: 0.8034182190895081
test loss item: 0.24740657210350037
test loss item: 0.46380090713500977
test loss item: 0.5503285527229309
test loss item: 0.5117436051368713
test loss item: 0.5536900162696838
test loss item: 0.3247326910495758
test loss item: 0.5409203767776489
test loss item: 0.8185858726501465
test loss item: 0.28845706582069397
test loss item: 0.7088980078697205
test loss item: 0.9818060398101807
test loss item: 0.22266152501106262
test loss item: 0.1220865473151207
Epoch [13/100], Training Loss: 0.3943, Testing Loss: 0.5023
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 14/100
train loss item: 0.6107270121574402
train loss item: 0.4439106285572052
train loss item: 0.3428708612918854
train loss item: 0.3142639994621277
train loss item: 0.26171553134918213
train loss item: 0.5209960341453552
train loss item: 0.2713581621646881
train loss item: 0.587709903717041
train loss item: 0.4422902464866638
train loss item: 0.2799735367298126
train loss item: 0.1746586412191391
train loss item: 0.24263082444667816
train loss item: 0.37674951553344727
train loss item: 0.4059528112411499
train loss item: 0.18178389966487885
train loss item: 0.47954702377319336
train loss item: 0.3013119399547577
train loss item: 0.22175545990467072
train loss item: 0.17613793909549713
train loss item: 0.5938990712165833
train loss item: 0.21667549014091492
train loss item: 0.6149157881736755
train loss item: 0.2823074758052826
test loss item: 0.23701179027557373
test loss item: 0.4866437315940857
test loss item: 0.34296566247940063
test loss item: 0.13716764748096466
test loss item: 0.3202938139438629
test loss item: 0.28285250067710876
test loss item: 0.21508358418941498
test loss item: 0.3538147211074829
test loss item: 0.3405279517173767
test loss item: 0.4920012354850769
test loss item: 0.1923178881406784
test loss item: 0.2965873181819916
test loss item: 0.30829918384552
test loss item: 0.3507283329963684
test loss item: 0.2835199534893036
test loss item: 0.21495744585990906
test loss item: 0.36720144748687744
test loss item: 0.4044802784919739
test loss item: 0.20006445050239563
test loss item: 0.5573975443840027
test loss item: 0.5632557272911072
test loss item: 0.16974416375160217
test loss item: 0.17806468904018402
Epoch [14/100], Training Loss: 0.3628, Testing Loss: 0.3172
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 15/100
train loss item: 0.5697202086448669
train loss item: 0.4079497754573822
train loss item: 0.25917187333106995
train loss item: 0.3057877719402313
train loss item: 0.25150182843208313
train loss item: 0.5495480298995972
train loss item: 0.25236228108406067
train loss item: 0.9325029253959656
train loss item: 0.7433618307113647
train loss item: 0.35085636377334595
train loss item: 0.22412197291851044
train loss item: 0.3937318027019501
train loss item: 0.5322188138961792
train loss item: 0.5444733500480652
train loss item: 0.22774890065193176
train loss item: 0.6013886332511902
train loss item: 0.3103809058666229
train loss item: 0.2523801326751709
train loss item: 0.18903030455112457
train loss item: 0.5578941702842712
train loss item: 0.2109857052564621
train loss item: 0.8772233724594116
train loss item: 0.33156904578208923
test loss item: 0.320600301027298
test loss item: 0.7575326561927795
test loss item: 0.6067105531692505
test loss item: 0.17670176923274994
test loss item: 0.5794807076454163
test loss item: 0.29875683784484863
test loss item: 0.26915469765663147
test loss item: 0.581546425819397
test loss item: 0.6108172535896301
test loss item: 0.8381473422050476
test loss item: 0.2248651385307312
test loss item: 0.37664490938186646
test loss item: 0.5148101449012756
test loss item: 0.5468782186508179
test loss item: 0.5499358773231506
test loss item: 0.2729811668395996
test loss item: 0.47861045598983765
test loss item: 0.7514841556549072
test loss item: 0.24124541878700256
test loss item: 0.8469224572181702
test loss item: 1.0287834405899048
test loss item: 0.22187000513076782
test loss item: 0.13460229337215424
Epoch [15/100], Training Loss: 0.4294, Testing Loss: 0.4882
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 16/100
train loss item: 0.524272620677948
train loss item: 0.3693205714225769
train loss item: 0.27047958970069885
train loss item: 0.29190248250961304
train loss item: 0.24324068427085876
train loss item: 0.5029686093330383
train loss item: 0.25919196009635925
train loss item: 0.5948578119277954
train loss item: 0.490847110748291
train loss item: 0.3067469596862793
train loss item: 0.18983128666877747
train loss item: 0.29200279712677
train loss item: 0.30088186264038086
train loss item: 0.3405331075191498
train loss item: 0.20148999989032745
train loss item: 0.4353746175765991
train loss item: 0.336061030626297
train loss item: 0.24438156187534332
train loss item: 0.1808416098356247
train loss item: 0.6325535178184509
train loss item: 0.2557312250137329
train loss item: 0.704059362411499
train loss item: 0.26359429955482483
test loss item: 0.2393864393234253
test loss item: 0.5454072952270508
test loss item: 0.39659374952316284
test loss item: 0.13190117478370667
test loss item: 0.3611680269241333
test loss item: 0.26251158118247986
test loss item: 0.20897236466407776
test loss item: 0.41048097610473633
test loss item: 0.3848353922367096
test loss item: 0.5490026473999023
test loss item: 0.196166530251503
test loss item: 0.28902339935302734
test loss item: 0.36088210344314575
test loss item: 0.38460710644721985
test loss item: 0.3193880319595337
test loss item: 0.22625420987606049
test loss item: 0.344720721244812
test loss item: 0.4595409333705902
test loss item: 0.1854749470949173
test loss item: 0.547283411026001
test loss item: 0.6481337547302246
test loss item: 0.1592046022415161
test loss item: 0.12454281002283096
Epoch [16/100], Training Loss: 0.3579, Testing Loss: 0.3363
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 17/100
train loss item: 0.4445728361606598
train loss item: 0.3200465142726898
train loss item: 0.2573886215686798
train loss item: 0.2859423756599426
train loss item: 0.21497595310211182
train loss item: 0.3675329387187958
train loss item: 0.2213885486125946
train loss item: 0.5303993225097656
train loss item: 0.47291848063468933
train loss item: 0.21358366310596466
train loss item: 0.18173173069953918
train loss item: 0.3040318191051483
train loss item: 0.3098025619983673
train loss item: 0.45368340611457825
train loss item: 0.1438298225402832
train loss item: 0.4047917127609253
train loss item: 0.38200950622558594
train loss item: 0.254922091960907
train loss item: 0.18378984928131104
train loss item: 0.574084997177124
train loss item: 0.2681257128715515
train loss item: 0.507729172706604
train loss item: 0.22961047291755676
test loss item: 0.20597098767757416
test loss item: 0.441398561000824
test loss item: 0.2933010458946228
test loss item: 0.12887613475322723
test loss item: 0.261432409286499
test loss item: 0.2262544333934784
test loss item: 0.17119522392749786
test loss item: 0.31344303488731384
test loss item: 0.29727432131767273
test loss item: 0.42242899537086487
test loss item: 0.16181200742721558
test loss item: 0.22826538980007172
test loss item: 0.26952460408210754
test loss item: 0.2922098934650421
test loss item: 0.24000339210033417
test loss item: 0.17937730252742767
test loss item: 0.30653244256973267
test loss item: 0.3427494466304779
test loss item: 0.16043220460414886
test loss item: 0.4924543797969818
test loss item: 0.4916258156299591
test loss item: 0.13459879159927368
test loss item: 0.17363868653774261
Epoch [17/100], Training Loss: 0.3273, Testing Loss: 0.2711
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 18/100
train loss item: 0.4376944303512573
train loss item: 0.3140890300273895
train loss item: 0.2242245376110077
train loss item: 0.30477020144462585
train loss item: 0.20190532505512238
train loss item: 0.34834346175193787
train loss item: 0.19319060444831848
train loss item: 0.4914502501487732
train loss item: 0.44423434138298035
train loss item: 0.21004892885684967
train loss item: 0.17604467272758484
train loss item: 0.2958518862724304
train loss item: 0.35138005018234253
train loss item: 0.5903953909873962
train loss item: 0.1495530903339386
train loss item: 0.48639756441116333
train loss item: 0.3354856073856354
train loss item: 0.2744126617908478
train loss item: 0.20530787110328674
train loss item: 0.5493718981742859
train loss item: 0.2998276352882385
train loss item: 0.5272917151451111
train loss item: 0.25854188203811646
test loss item: 0.23686367273330688
test loss item: 0.41027507185935974
test loss item: 0.3592914938926697
test loss item: 0.153448224067688
test loss item: 0.2919129729270935
test loss item: 0.2546938955783844
test loss item: 0.19998249411582947
test loss item: 0.35750603675842285
test loss item: 0.34423062205314636
test loss item: 0.484214723110199
test loss item: 0.17630481719970703
test loss item: 0.2647855877876282
test loss item: 0.33671438694000244
test loss item: 0.36803001165390015
test loss item: 0.26893186569213867
test loss item: 0.20652680099010468
test loss item: 0.35005131363868713
test loss item: 0.3633163273334503
test loss item: 0.17085948586463928
test loss item: 0.6167884469032288
test loss item: 0.5718469619750977
test loss item: 0.15103580057621002
test loss item: 0.1818690001964569
Epoch [18/100], Training Loss: 0.3335, Testing Loss: 0.3095
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 19/100
train loss item: 0.42336222529411316
train loss item: 0.3230818510055542
train loss item: 0.24179880321025848
train loss item: 0.30925270915031433
train loss item: 0.2263765186071396
train loss item: 0.4421465992927551
train loss item: 0.20234748721122742
train loss item: 0.4767149090766907
train loss item: 0.3923914432525635
train loss item: 0.3501451313495636
train loss item: 0.17381693422794342
train loss item: 0.22252054512500763
train loss item: 0.3041543960571289
train loss item: 0.33390718698501587
train loss item: 0.16638866066932678
train loss item: 0.5163837671279907
train loss item: 0.25056150555610657
train loss item: 0.2064030021429062
train loss item: 0.1423715054988861
train loss item: 0.4303828477859497
train loss item: 0.2080608606338501
train loss item: 0.5215128064155579
train loss item: 0.2600763440132141
test loss item: 0.17413245141506195
test loss item: 0.42841818928718567
test loss item: 0.24280643463134766
test loss item: 0.1057373434305191
test loss item: 0.25292477011680603
test loss item: 0.22646783292293549
test loss item: 0.15611650049686432
test loss item: 0.2662123143672943
test loss item: 0.2390015870332718
test loss item: 0.3632090091705322
test loss item: 0.1580837070941925
test loss item: 0.21108396351337433
test loss item: 0.20829345285892487
test loss item: 0.22945816814899445
test loss item: 0.21168798208236694
test loss item: 0.16462992131710052
test loss item: 0.27973127365112305
test loss item: 0.33922818303108215
test loss item: 0.17687678337097168
test loss item: 0.3511240780353546
test loss item: 0.4088115394115448
test loss item: 0.1189117431640625
test loss item: 0.13195398449897766
Epoch [19/100], Training Loss: 0.3097, Testing Loss: 0.2367
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 20/100
train loss item: 0.5291051268577576
train loss item: 0.2647283971309662
train loss item: 0.18964628875255585
train loss item: 0.3461487889289856
train loss item: 0.25637274980545044
train loss item: 0.5511115789413452
train loss item: 0.24754935503005981
train loss item: 0.607957124710083
train loss item: 0.37709930539131165
train loss item: 0.4349079728126526
train loss item: 0.286448210477829
train loss item: 0.4271252155303955
train loss item: 0.4495856761932373
train loss item: 0.5465417504310608
train loss item: 0.15701504051685333
train loss item: 0.45702603459358215
train loss item: 0.22807854413986206
train loss item: 0.25045856833457947
train loss item: 0.1526128351688385
train loss item: 0.609423041343689
train loss item: 0.1872200220823288
train loss item: 0.9163848757743835
train loss item: 0.290439635515213
test loss item: 0.29999393224716187
test loss item: 0.750943660736084
test loss item: 0.5598466396331787
test loss item: 0.15285831689834595
test loss item: 0.5769884586334229
test loss item: 0.27972251176834106
test loss item: 0.2158380150794983
test loss item: 0.5359488725662231
test loss item: 0.5583146214485168
test loss item: 0.8148514628410339
test loss item: 0.17160846292972565
test loss item: 0.3708800971508026
test loss item: 0.495581716299057
test loss item: 0.4842667579650879
test loss item: 0.5545213222503662
test loss item: 0.2523062527179718
test loss item: 0.5187549591064453
test loss item: 0.7511069774627686
test loss item: 0.1890355795621872
test loss item: 0.9295048713684082
test loss item: 1.0072499513626099
test loss item: 0.1675247848033905
test loss item: 0.0950416699051857
Epoch [20/100], Training Loss: 0.3810, Testing Loss: 0.4666
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 21/100
train loss item: 0.4637114107608795
train loss item: 0.379251092672348
train loss item: 0.3104775547981262
train loss item: 0.25812840461730957
train loss item: 0.20703597366809845
train loss item: 0.4671940803527832
train loss item: 0.2651469111442566
train loss item: 0.5996124148368835
train loss item: 0.4288795590400696
train loss item: 0.3278915286064148
train loss item: 0.23784060776233673
train loss item: 0.4705028235912323
train loss item: 0.40376609563827515
train loss item: 0.5493590235710144
train loss item: 0.22906054556369781
train loss item: 0.5172973275184631
train loss item: 0.41398757696151733
train loss item: 0.27587324380874634
train loss item: 0.19706201553344727
train loss item: 0.5821717381477356
train loss item: 0.2940339744091034
train loss item: 0.41331812739372253
train loss item: 0.36378100514411926
test loss item: 0.26810890436172485
test loss item: 0.4938206374645233
test loss item: 0.37875595688819885
test loss item: 0.11731290817260742
test loss item: 0.29677078127861023
test loss item: 0.26468050479888916
test loss item: 0.18718405067920685
test loss item: 0.3784230947494507
test loss item: 0.29750603437423706
test loss item: 0.5434313416481018
test loss item: 0.20452357828617096
test loss item: 0.26709094643592834
test loss item: 0.31278252601623535
test loss item: 0.34798476099967957
test loss item: 0.2641691565513611
test loss item: 0.21234579384326935
test loss item: 0.4251876771450043
test loss item: 0.409099817276001
test loss item: 0.2438305914402008
test loss item: 0.7720059156417847
test loss item: 0.6775578856468201
test loss item: 0.1478927731513977
test loss item: 0.13794435560703278
Epoch [21/100], Training Loss: 0.3763, Testing Loss: 0.3325
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 22/100
train loss item: 0.7539589405059814
train loss item: 0.4466768503189087
train loss item: 0.19049011170864105
train loss item: 0.2886033356189728
train loss item: 0.23156315088272095
train loss item: 0.5604615211486816
train loss item: 0.26717615127563477
train loss item: 1.011728048324585
train loss item: 1.1142175197601318
train loss item: 0.36749595403671265
train loss item: 0.18711264431476593
train loss item: 0.33136436343193054
train loss item: 0.250784307718277
train loss item: 0.27446091175079346
train loss item: 0.17283271253108978
train loss item: 0.3528393805027008
train loss item: 0.31943583488464355
train loss item: 0.20855452120304108
train loss item: 0.128828227519989
train loss item: 0.559001624584198
train loss item: 0.2005666345357895
train loss item: 0.4655899703502655
train loss item: 0.2177848368883133
test loss item: 0.15470753610134125
test loss item: 0.3471662700176239
test loss item: 0.22286927700042725
test loss item: 0.10621875524520874
test loss item: 0.1985214203596115
test loss item: 0.17970573902130127
test loss item: 0.13325758278369904
test loss item: 0.23384232819080353
test loss item: 0.21082817018032074
test loss item: 0.3225443363189697
test loss item: 0.1332901567220688
test loss item: 0.177312433719635
test loss item: 0.19619505107402802
test loss item: 0.2103283405303955
test loss item: 0.18276965618133545
test loss item: 0.1456044465303421
test loss item: 0.24261273443698883
test loss item: 0.26152855157852173
test loss item: 0.12808960676193237
test loss item: 0.38295164704322815
test loss item: 0.37015634775161743
test loss item: 0.10626731067895889
test loss item: 0.108486108481884
Epoch [22/100], Training Loss: 0.3870, Testing Loss: 0.2068
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 23/100
train loss item: 0.38960763812065125
train loss item: 0.2653416395187378
train loss item: 0.2033117115497589
train loss item: 0.21891339123249054
train loss item: 0.15036344528198242
train loss item: 0.29451784491539
train loss item: 0.17444609105587006
train loss item: 0.38816943764686584
train loss item: 0.3262910544872284
train loss item: 0.20432773232460022
train loss item: 0.1402297168970108
train loss item: 0.22550466656684875
train loss item: 0.22519055008888245
train loss item: 0.25452715158462524
train loss item: 0.122749924659729
train loss item: 0.29073160886764526
train loss item: 0.26261579990386963
train loss item: 0.17309674620628357
train loss item: 0.11818130314350128
train loss item: 0.4269365072250366
train loss item: 0.1963532567024231
train loss item: 0.3978787958621979
train loss item: 0.21207597851753235
test loss item: 0.1493568867444992
test loss item: 0.2731728255748749
test loss item: 0.20545339584350586
test loss item: 0.09171567857265472
test loss item: 0.17707058787345886
test loss item: 0.1633007675409317
test loss item: 0.12565860152244568
test loss item: 0.20203551650047302
test loss item: 0.18951427936553955
test loss item: 0.28703802824020386
test loss item: 0.11996965110301971
test loss item: 0.1622333824634552
test loss item: 0.17766593396663666
test loss item: 0.1980307400226593
test loss item: 0.16245436668395996
test loss item: 0.12789173424243927
test loss item: 0.21795576810836792
test loss item: 0.2145298719406128
test loss item: 0.11534586548805237
test loss item: 0.34191492199897766
test loss item: 0.3209380805492401
test loss item: 0.10453745722770691
test loss item: 0.10951013118028641
Epoch [23/100], Training Loss: 0.2461, Testing Loss: 0.1842
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 24/100
train loss item: 0.3176742494106293
train loss item: 0.20150533318519592
train loss item: 0.145430788397789
train loss item: 0.2123376727104187
train loss item: 0.15522807836532593
train loss item: 0.2568950653076172
train loss item: 0.1435536891222
train loss item: 0.33829525113105774
train loss item: 0.30122849345207214
train loss item: 0.2028949111700058
train loss item: 0.14131949841976166
train loss item: 0.19610878825187683
train loss item: 0.26156580448150635
train loss item: 0.2964387536048889
train loss item: 0.1066475436091423
train loss item: 0.2741226851940155
train loss item: 0.20516054332256317
train loss item: 0.148502379655838
train loss item: 0.13753587007522583
train loss item: 0.35209745168685913
train loss item: 0.12303388863801956
train loss item: 0.43332257866859436
train loss item: 0.1984557956457138
test loss item: 0.13974998891353607
test loss item: 0.2977239191532135
test loss item: 0.1837732195854187
test loss item: 0.08787640929222107
test loss item: 0.15802526473999023
test loss item: 0.15058016777038574
test loss item: 0.12675830721855164
test loss item: 0.1917562633752823
test loss item: 0.1726035624742508
test loss item: 0.24834851920604706
test loss item: 0.11519356817007065
test loss item: 0.1473064422607422
test loss item: 0.15036702156066895
test loss item: 0.1703072190284729
test loss item: 0.1384686529636383
test loss item: 0.11762817203998566
test loss item: 0.19153866171836853
test loss item: 0.2055557370185852
test loss item: 0.11926499009132385
test loss item: 0.2591092884540558
test loss item: 0.27887678146362305
test loss item: 0.10556057095527649
test loss item: 0.09843628108501434
Epoch [24/100], Training Loss: 0.2239, Testing Loss: 0.1676
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 25/100
train loss item: 0.2922501564025879
train loss item: 0.18380875885486603
train loss item: 0.14909350872039795
train loss item: 0.1665058583021164
train loss item: 0.14362287521362305
train loss item: 0.24839575588703156
train loss item: 0.12364739179611206
train loss item: 0.3352915644645691
train loss item: 0.3488205671310425
train loss item: 0.2373366504907608
train loss item: 0.12451812624931335
train loss item: 0.16800789535045624
train loss item: 0.2619551718235016
train loss item: 0.2493855059146881
train loss item: 0.10636544227600098
train loss item: 0.29125091433525085
train loss item: 0.15394777059555054
train loss item: 0.14103960990905762
train loss item: 0.12659059464931488
train loss item: 0.303959459066391
train loss item: 0.12464101612567902
train loss item: 0.5644734501838684
train loss item: 0.1671537309885025
test loss item: 0.16306738555431366
test loss item: 0.26864299178123474
test loss item: 0.18799391388893127
test loss item: 0.10761149972677231
test loss item: 0.16203279793262482
test loss item: 0.14865657687187195
test loss item: 0.1342879682779312
test loss item: 0.19125889241695404
test loss item: 0.18404719233512878
test loss item: 0.2591805160045624
test loss item: 0.12971468269824982
test loss item: 0.1406257003545761
test loss item: 0.1496996432542801
test loss item: 0.1778922975063324
test loss item: 0.14937467873096466
test loss item: 0.11919618397951126
test loss item: 0.19839392602443695
test loss item: 0.20704962313175201
test loss item: 0.12743547558784485
test loss item: 0.33894026279449463
test loss item: 0.28924110531806946
test loss item: 0.1340319812297821
test loss item: 0.09488536417484283
Epoch [25/100], Training Loss: 0.2179, Testing Loss: 0.1767
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 26/100
train loss item: 0.289721816778183
train loss item: 0.170511394739151
train loss item: 0.18827050924301147
train loss item: 0.19727584719657898
train loss item: 0.176268070936203
train loss item: 0.24995586276054382
train loss item: 0.16491565108299255
train loss item: 0.3047962486743927
train loss item: 0.32042086124420166
train loss item: 0.25336208939552307
train loss item: 0.17564885318279266
train loss item: 0.29678279161453247
train loss item: 0.2300051897764206
train loss item: 0.2818794548511505
train loss item: 0.1158088967204094
train loss item: 0.30763110518455505
train loss item: 0.21460793912410736
train loss item: 0.1761634349822998
train loss item: 0.09212485700845718
train loss item: 0.32220131158828735
train loss item: 0.19929394125938416
train loss item: 0.2929397225379944
train loss item: 0.1443101167678833
test loss item: 0.13734287023544312
test loss item: 0.30613037943840027
test loss item: 0.19821512699127197
test loss item: 0.08756696432828903
test loss item: 0.15589210391044617
test loss item: 0.1375754475593567
test loss item: 0.10943449288606644
test loss item: 0.21091727912425995
test loss item: 0.17549513280391693
test loss item: 0.26794299483299255
test loss item: 0.10294973850250244
test loss item: 0.12986986339092255
test loss item: 0.15992267429828644
test loss item: 0.17935389280319214
test loss item: 0.14394988119602203
test loss item: 0.10618733614683151
test loss item: 0.18702790141105652
test loss item: 0.21927034854888916
test loss item: 0.09792476892471313
test loss item: 0.3102180063724518
test loss item: 0.31138256192207336
test loss item: 0.09351299703121185
test loss item: 0.10103022307157516
Epoch [26/100], Training Loss: 0.2246, Testing Loss: 0.1708
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 27/100
train loss item: 0.2743491530418396
train loss item: 0.1779080033302307
train loss item: 0.15444739162921906
train loss item: 0.2042655050754547
train loss item: 0.16157372295856476
train loss item: 0.25106990337371826
train loss item: 0.17578667402267456
train loss item: 0.3456553518772125
train loss item: 0.3027516007423401
train loss item: 0.2468952238559723
train loss item: 0.21087966859340668
train loss item: 0.39686089754104614
train loss item: 0.364775151014328
train loss item: 1.0184059143066406
train loss item: 0.17967034876346588
train loss item: 0.7678374648094177
train loss item: 0.19996437430381775
train loss item: 0.2269296795129776
train loss item: 0.13341473042964935
train loss item: 0.3191620111465454
train loss item: 0.1491563618183136
train loss item: 0.3723280131816864
train loss item: 0.2593837082386017
test loss item: 0.18898944556713104
test loss item: 0.5714703798294067
test loss item: 0.42550691962242126
test loss item: 0.14759808778762817
test loss item: 0.4688051640987396
test loss item: 0.21572524309158325
test loss item: 0.19271472096443176
test loss item: 0.42819494009017944
test loss item: 0.46863847970962524
test loss item: 0.5786827802658081
test loss item: 0.16492898762226105
test loss item: 0.29523178935050964
test loss item: 0.3676987290382385
test loss item: 0.35813307762145996
test loss item: 0.4375460147857666
test loss item: 0.17921927571296692
test loss item: 0.34803301095962524
test loss item: 0.6100450158119202
test loss item: 0.17436745762825012
test loss item: 0.5175535678863525
test loss item: 0.7272332310676575
test loss item: 0.15249229967594147
test loss item: 0.18588756024837494
Epoch [27/100], Training Loss: 0.2997, Testing Loss: 0.3567
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 28/100
train loss item: 0.4302394390106201
train loss item: 0.30966711044311523
train loss item: 0.2259691208600998
train loss item: 0.23570165038108826
train loss item: 0.17878328263759613
train loss item: 0.4091865122318268
train loss item: 0.1912701278924942
train loss item: 0.3715936839580536
train loss item: 0.31734007596969604
train loss item: 0.5243076086044312
train loss item: 0.17917872965335846
train loss item: 0.2602689564228058
train loss item: 0.22306877374649048
train loss item: 0.2461673617362976
train loss item: 0.15985475480556488
train loss item: 0.39083755016326904
train loss item: 0.22280988097190857
train loss item: 0.20192179083824158
train loss item: 0.12626981735229492
train loss item: 0.4114597737789154
train loss item: 0.13019460439682007
train loss item: 0.5846640467643738
train loss item: 0.27878525853157043
test loss item: 0.1744425892829895
test loss item: 0.3690631091594696
test loss item: 0.25754934549331665
test loss item: 0.11252691596746445
test loss item: 0.2524198889732361
test loss item: 0.18412978947162628
test loss item: 0.13955357670783997
test loss item: 0.2488941103219986
test loss item: 0.21657784283161163
test loss item: 0.3689490258693695
test loss item: 0.12436401098966599
test loss item: 0.21147719025611877
test loss item: 0.225608691573143
test loss item: 0.22654984891414642
test loss item: 0.22040197253227234
test loss item: 0.15550179779529572
test loss item: 0.2799573242664337
test loss item: 0.32270386815071106
test loss item: 0.15851803123950958
test loss item: 0.466924250125885
test loss item: 0.4329252541065216
test loss item: 0.11383713781833649
test loss item: 0.0707789808511734
Epoch [28/100], Training Loss: 0.2874, Testing Loss: 0.2319
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 29/100
train loss item: 0.353631854057312
train loss item: 0.2912340462207794
train loss item: 0.2896672189235687
train loss item: 0.2211904525756836
train loss item: 0.14353591203689575
train loss item: 0.3238942623138428
train loss item: 0.20606587827205658
train loss item: 0.47233906388282776
train loss item: 0.27970197796821594
train loss item: 0.15766572952270508
train loss item: 0.15519030392169952
train loss item: 0.2892625629901886
train loss item: 0.23362989723682404
train loss item: 0.2848597764968872
train loss item: 0.1340048611164093
train loss item: 0.27254924178123474
train loss item: 0.23057982325553894
train loss item: 0.17223675549030304
train loss item: 0.09211685508489609
train loss item: 0.38824114203453064
train loss item: 0.16047027707099915
train loss item: 0.2993004024028778
train loss item: 0.18864929676055908
test loss item: 0.13799360394477844
test loss item: 0.30866891145706177
test loss item: 0.23091787099838257
test loss item: 0.08661875128746033
test loss item: 0.22100472450256348
test loss item: 0.14395858347415924
test loss item: 0.12544164061546326
test loss item: 0.22896023094654083
test loss item: 0.2179097831249237
test loss item: 0.3092244267463684
test loss item: 0.12956063449382782
test loss item: 0.16575172543525696
test loss item: 0.19118893146514893
test loss item: 0.20625048875808716
test loss item: 0.1872664988040924
test loss item: 0.12876364588737488
test loss item: 0.21452239155769348
test loss item: 0.27609938383102417
test loss item: 0.1318894624710083
test loss item: 0.3145175278186798
test loss item: 0.37088850140571594
test loss item: 0.09633339196443558
test loss item: 0.15360422432422638
Epoch [29/100], Training Loss: 0.2452, Testing Loss: 0.1990
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 30/100
train loss item: 0.2745727002620697
train loss item: 0.1745038479566574
train loss item: 0.1553567498922348
train loss item: 0.16982696950435638
train loss item: 0.1208534687757492
train loss item: 0.22819815576076508
train loss item: 0.12211227416992188
train loss item: 0.2724815011024475
train loss item: 0.28827357292175293
train loss item: 0.20334863662719727
train loss item: 0.10210686922073364
train loss item: 0.19389621913433075
train loss item: 0.22577863931655884
train loss item: 0.1754266768693924
train loss item: 0.10249923914670944
train loss item: 0.25178322196006775
train loss item: 0.12664833664894104
train loss item: 0.1382495015859604
train loss item: 0.09417886286973953
train loss item: 0.271211177110672
train loss item: 0.10733260959386826
train loss item: 0.3017866313457489
train loss item: 0.12643514573574066
test loss item: 0.12263166904449463
test loss item: 0.2874618470668793
test loss item: 0.2231818288564682
test loss item: 0.09653764963150024
test loss item: 0.2200823575258255
test loss item: 0.12906835973262787
test loss item: 0.1193782389163971
test loss item: 0.22387658059597015
test loss item: 0.2166789323091507
test loss item: 0.2892325520515442
test loss item: 0.10840514302253723
test loss item: 0.16274629533290863
test loss item: 0.19304780662059784
test loss item: 0.19383955001831055
test loss item: 0.1938919872045517
test loss item: 0.11905530840158463
test loss item: 0.19484452903270721
test loss item: 0.2745121121406555
test loss item: 0.10863780975341797
test loss item: 0.27380576729774475
test loss item: 0.35460397601127625
test loss item: 0.09254750609397888
test loss item: 0.09954267740249634
Epoch [30/100], Training Loss: 0.1838, Testing Loss: 0.1869
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 31/100
train loss item: 0.2530575692653656
train loss item: 0.1617296189069748
train loss item: 0.14455999433994293
train loss item: 0.15595199167728424
train loss item: 0.12371831387281418
train loss item: 0.21436242759227753
train loss item: 0.11529475450515747
train loss item: 0.1962168961763382
train loss item: 0.2404738813638687
train loss item: 0.23779524862766266
train loss item: 0.10438623279333115
train loss item: 0.17078325152397156
train loss item: 0.19518855214118958
train loss item: 0.1991768777370453
train loss item: 0.10060247033834457
train loss item: 0.1958155483007431
train loss item: 0.1199653148651123
train loss item: 0.09667624533176422
train loss item: 0.08033884316682816
train loss item: 0.1923714280128479
train loss item: 0.1275733858346939
train loss item: 0.24788005650043488
train loss item: 0.14113572239875793
test loss item: 0.10844602435827255
test loss item: 0.2834703028202057
test loss item: 0.14476878941059113
test loss item: 0.07412591576576233
test loss item: 0.14297804236412048
test loss item: 0.13133594393730164
test loss item: 0.09658714383840561
test loss item: 0.17300406098365784
test loss item: 0.12459039688110352
test loss item: 0.21069318056106567
test loss item: 0.10290941596031189
test loss item: 0.11734014004468918
test loss item: 0.13438552618026733
test loss item: 0.12575028836727142
test loss item: 0.12418845295906067
test loss item: 0.09664509445428848
test loss item: 0.16978947818279266
test loss item: 0.2111213505268097
test loss item: 0.11160895973443985
test loss item: 0.22628286480903625
test loss item: 0.24657899141311646
test loss item: 0.08080607652664185
test loss item: 0.08931335806846619
Epoch [31/100], Training Loss: 0.1659, Testing Loss: 0.1446
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 32/100
train loss item: 0.18298602104187012
train loss item: 0.1417359709739685
train loss item: 0.13486619293689728
train loss item: 0.15724897384643555
train loss item: 0.118562251329422
train loss item: 0.22432462871074677
train loss item: 0.11995486170053482
train loss item: 0.23617389798164368
train loss item: 0.3023555278778076
train loss item: 0.2209644764661789
train loss item: 0.12894681096076965
train loss item: 0.13720573484897614
train loss item: 0.21394750475883484
train loss item: 0.19634471833705902
train loss item: 0.10703533887863159
train loss item: 0.2168823778629303
train loss item: 0.14232711493968964
train loss item: 0.10422655194997787
train loss item: 0.09983468055725098
train loss item: 0.21689966320991516
train loss item: 0.1318560242652893
train loss item: 0.2924882769584656
train loss item: 0.13121500611305237
test loss item: 0.13461554050445557
test loss item: 0.19297100603580475
test loss item: 0.15033076703548431
test loss item: 0.11040343344211578
test loss item: 0.1282019019126892
test loss item: 0.12097401916980743
test loss item: 0.12020052969455719
test loss item: 0.15832632780075073
test loss item: 0.13757914304733276
test loss item: 0.18352152407169342
test loss item: 0.11388158053159714
test loss item: 0.12581764161586761
test loss item: 0.13185463845729828
test loss item: 0.14586690068244934
test loss item: 0.12294194102287292
test loss item: 0.10075098276138306
test loss item: 0.14717978239059448
test loss item: 0.16066931188106537
test loss item: 0.120503731071949
test loss item: 0.22813630104064941
test loss item: 0.2086159586906433
test loss item: 0.12214265763759613
test loss item: 0.08613773435354233
Epoch [32/100], Training Loss: 0.1721, Testing Loss: 0.1414
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 33/100
train loss item: 0.21567018330097198
train loss item: 0.15633559226989746
train loss item: 0.13263481855392456
train loss item: 0.15694819390773773
train loss item: 0.10778146237134933
train loss item: 0.16389518976211548
train loss item: 0.12739424407482147
train loss item: 0.23242709040641785
train loss item: 0.21196092665195465
train loss item: 0.16223976016044617
train loss item: 0.14844274520874023
train loss item: 0.22375190258026123
train loss item: 0.2668699026107788
train loss item: 0.2722328007221222
train loss item: 0.136918842792511
train loss item: 0.2203797996044159
train loss item: 0.1297590434551239
train loss item: 0.12209835648536682
train loss item: 0.09344278275966644
train loss item: 0.21864080429077148
train loss item: 0.15822336077690125
train loss item: 0.22653456032276154
train loss item: 0.1050698310136795
test loss item: 0.11910416930913925
test loss item: 0.1814962923526764
test loss item: 0.13617724180221558
test loss item: 0.08715610951185226
test loss item: 0.12665784358978271
test loss item: 0.1059044674038887
test loss item: 0.09837834537029266
test loss item: 0.1334965080022812
test loss item: 0.12637825310230255
test loss item: 0.17061157524585724
test loss item: 0.10559055209159851
test loss item: 0.09672477096319199
test loss item: 0.11792268604040146
test loss item: 0.1271275281906128
test loss item: 0.13145315647125244
test loss item: 0.09709646552801132
test loss item: 0.13685429096221924
test loss item: 0.1646440625190735
test loss item: 0.10203192383050919
test loss item: 0.19276677072048187
test loss item: 0.18752823770046234
test loss item: 0.10481702536344528
test loss item: 0.10338578373193741
Epoch [33/100], Training Loss: 0.1735, Testing Loss: 0.1284
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 34/100
train loss item: 0.20270104706287384
train loss item: 0.14638763666152954
train loss item: 0.14191623032093048
train loss item: 0.17601174116134644
train loss item: 0.13570773601531982
train loss item: 0.19849161803722382
train loss item: 0.1034829169511795
train loss item: 0.19959336519241333
train loss item: 0.2743799090385437
train loss item: 0.2592802047729492
train loss item: 0.12602530419826508
train loss item: 0.18811126053333282
train loss item: 0.15500298142433167
train loss item: 0.17891564965248108
train loss item: 0.09939810633659363
train loss item: 0.22737061977386475
train loss item: 0.13008341193199158
train loss item: 0.15616996586322784
train loss item: 0.07190275937318802
train loss item: 0.16017359495162964
train loss item: 0.17716065049171448
train loss item: 0.31289857625961304
train loss item: 0.157020702958107
test loss item: 0.12543778121471405
test loss item: 0.25740787386894226
test loss item: 0.19562965631484985
test loss item: 0.08924324065446854
test loss item: 0.1785895675420761
test loss item: 0.12899619340896606
test loss item: 0.10394881665706635
test loss item: 0.2089126855134964
test loss item: 0.18431231379508972
test loss item: 0.2572632431983948
test loss item: 0.11250418424606323
test loss item: 0.1361682265996933
test loss item: 0.16677357256412506
test loss item: 0.1765303909778595
test loss item: 0.15954779088497162
test loss item: 0.10526953637599945
test loss item: 0.16310575604438782
test loss item: 0.24226434528827667
test loss item: 0.10741126537322998
test loss item: 0.29048117995262146
test loss item: 0.31392529606819153
test loss item: 0.09126298129558563
test loss item: 0.10632725805044174
Epoch [34/100], Training Loss: 0.1730, Testing Loss: 0.1696
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 35/100
train loss item: 0.2305622547864914
train loss item: 0.16859997808933258
train loss item: 0.1439039409160614
train loss item: 0.20628148317337036
train loss item: 0.14469020068645477
train loss item: 0.31435146927833557
train loss item: 0.14655999839305878
train loss item: 0.3060709536075592
train loss item: 0.17765110731124878
train loss item: 0.20273827016353607
train loss item: 0.157184898853302
train loss item: 0.3118407130241394
train loss item: 0.29067927598953247
train loss item: 0.45842763781547546
train loss item: 0.12686845660209656
train loss item: 0.21495352685451508
train loss item: 0.13249126076698303
train loss item: 0.188309445977211
train loss item: 0.13225318491458893
train loss item: 0.4648590683937073
train loss item: 0.22829239070415497
train loss item: 0.35161179304122925
train loss item: 0.1266661286354065
test loss item: 0.1421973556280136
test loss item: 0.2693975567817688
test loss item: 0.2067680060863495
test loss item: 0.08890452235937119
test loss item: 0.190031498670578
test loss item: 0.12275729328393936
test loss item: 0.12241164594888687
test loss item: 0.20115630328655243
test loss item: 0.19858324527740479
test loss item: 0.2819622755050659
test loss item: 0.10939888656139374
test loss item: 0.1321321427822113
test loss item: 0.17564234137535095
test loss item: 0.18960019946098328
test loss item: 0.18261227011680603
test loss item: 0.10953853279352188
test loss item: 0.20660805702209473
test loss item: 0.2533110976219177
test loss item: 0.10888468474149704
test loss item: 0.35076889395713806
test loss item: 0.35229429602622986
test loss item: 0.1008777916431427
test loss item: 0.1684848666191101
Epoch [35/100], Training Loss: 0.2272, Testing Loss: 0.1854
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 36/100
train loss item: 0.30810895562171936
train loss item: 0.204547718167305
train loss item: 0.1874794214963913
train loss item: 0.21244533360004425
train loss item: 0.12640415132045746
train loss item: 0.31257981061935425
train loss item: 0.12357424944639206
train loss item: 0.3956749737262726
train loss item: 0.2041959911584854
train loss item: 0.17101776599884033
train loss item: 0.10246839374303818
train loss item: 0.16314716637134552
train loss item: 0.19969722628593445
train loss item: 0.32718974351882935
train loss item: 0.10647423565387726
train loss item: 0.21069474518299103
train loss item: 0.15681368112564087
train loss item: 0.11880462616682053
train loss item: 0.08834739774465561
train loss item: 0.3392625153064728
train loss item: 0.12417721748352051
train loss item: 0.48097628355026245
train loss item: 0.1590365171432495
test loss item: 0.1413593739271164
test loss item: 0.18387404084205627
test loss item: 0.20662467181682587
test loss item: 0.07850461453199387
test loss item: 0.1339430809020996
test loss item: 0.10948405414819717
test loss item: 0.0825166180729866
test loss item: 0.18905948102474213
test loss item: 0.15759322047233582
test loss item: 0.2832465171813965
test loss item: 0.09734301269054413
test loss item: 0.10370088368654251
test loss item: 0.15573231875896454
test loss item: 0.1878717690706253
test loss item: 0.13840940594673157
test loss item: 0.09734224528074265
test loss item: 0.18218444287776947
test loss item: 0.17962554097175598
test loss item: 0.08225323259830475
test loss item: 0.43756812810897827
test loss item: 0.3342447876930237
test loss item: 0.07267698645591736
test loss item: 0.09905586391687393
Epoch [36/100], Training Loss: 0.2097, Testing Loss: 0.1624
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 37/100
train loss item: 0.24533730745315552
train loss item: 0.16293580830097198
train loss item: 0.120035819709301
train loss item: 0.13831263780593872
train loss item: 0.11356492340564728
train loss item: 0.1690635085105896
train loss item: 0.09228912740945816
train loss item: 0.18502230942249298
train loss item: 0.20094239711761475
train loss item: 0.14920347929000854
train loss item: 0.09940522909164429
train loss item: 0.18076157569885254
train loss item: 0.15515314042568207
train loss item: 0.18359383940696716
train loss item: 0.07671814411878586
train loss item: 0.17348551750183105
train loss item: 0.1011931523680687
train loss item: 0.11570148915052414
train loss item: 0.056713178753852844
train loss item: 0.2615840435028076
train loss item: 0.09512840211391449
train loss item: 0.4492091238498688
train loss item: 0.13256977498531342
test loss item: 0.12852415442466736
test loss item: 0.2719700038433075
test loss item: 0.2004285454750061
test loss item: 0.06969563663005829
test loss item: 0.129865825176239
test loss item: 0.1152200773358345
test loss item: 0.08456185460090637
test loss item: 0.22565580904483795
test loss item: 0.15370970964431763
test loss item: 0.2880414128303528
test loss item: 0.08930667489767075
test loss item: 0.10655500739812851
test loss item: 0.15375182032585144
test loss item: 0.17604875564575195
test loss item: 0.1398235708475113
test loss item: 0.09018023312091827
test loss item: 0.19223766028881073
test loss item: 0.2043077051639557
test loss item: 0.0877125933766365
test loss item: 0.4642798602581024
test loss item: 0.3591846525669098
test loss item: 0.07629990577697754
test loss item: 0.06528354436159134
Epoch [37/100], Training Loss: 0.1590, Testing Loss: 0.1684
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 38/100
train loss item: 0.288597047328949
train loss item: 0.15705813467502594
train loss item: 0.18143633008003235
train loss item: 0.15063707530498505
train loss item: 0.11157109588384628
train loss item: 0.21497109532356262
train loss item: 0.15483875572681427
train loss item: 0.2991805374622345
train loss item: 0.2243604212999344
train loss item: 0.15414564311504364
train loss item: 0.1328020989894867
train loss item: 0.23976202309131622
train loss item: 0.19503305852413177
train loss item: 0.16457511484622955
train loss item: 0.10916272550821304
train loss item: 0.16696996986865997
train loss item: 0.09588076919317245
train loss item: 0.13267989456653595
train loss item: 0.0650421604514122
train loss item: 0.2954961359500885
train loss item: 0.15055707097053528
train loss item: 0.2612103819847107
train loss item: 0.1258658468723297
test loss item: 0.11677941679954529
test loss item: 0.20292799174785614
test loss item: 0.17426542937755585
test loss item: 0.08367182314395905
test loss item: 0.1116548627614975
test loss item: 0.11161758750677109
test loss item: 0.08979202806949615
test loss item: 0.1644265204668045
test loss item: 0.1238328069448471
test loss item: 0.21795056760311127
test loss item: 0.09756209701299667
test loss item: 0.10446766763925552
test loss item: 0.1289605051279068
test loss item: 0.14409588277339935
test loss item: 0.11582104861736298
test loss item: 0.09447882324457169
test loss item: 0.1551969051361084
test loss item: 0.16692522168159485
test loss item: 0.08648710697889328
test loss item: 0.33159348368644714
test loss item: 0.2654075622558594
test loss item: 0.08076438307762146
test loss item: 0.09110018610954285
Epoch [38/100], Training Loss: 0.1770, Testing Loss: 0.1417
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 39/100
train loss item: 0.25922220945358276
train loss item: 0.1763497292995453
train loss item: 0.19469967484474182
train loss item: 0.1524060219526291
train loss item: 0.10096114873886108
train loss item: 0.19278500974178314
train loss item: 0.11162618547677994
train loss item: 0.24354375898838043
train loss item: 0.20158928632736206
train loss item: 0.16530273854732513
train loss item: 0.12127348780632019
train loss item: 0.2088131308555603
train loss item: 0.16215218603610992
train loss item: 0.14544570446014404
train loss item: 0.10064275562763214
train loss item: 0.21402746438980103
train loss item: 0.1128261461853981
train loss item: 0.1354668140411377
train loss item: 0.07431471347808838
train loss item: 0.2482030838727951
train loss item: 0.12804827094078064
train loss item: 0.3376196026802063
train loss item: 0.11829609423875809
test loss item: 0.12431909888982773
test loss item: 0.29920247197151184
test loss item: 0.22368690371513367
test loss item: 0.09073032438755035
test loss item: 0.21399910748004913
test loss item: 0.12096170336008072
test loss item: 0.10280223190784454
test loss item: 0.23140765726566315
test loss item: 0.20000596344470978
test loss item: 0.30607980489730835
test loss item: 0.0904826745390892
test loss item: 0.1567300409078598
test loss item: 0.19169415533542633
test loss item: 0.18782976269721985
test loss item: 0.19752901792526245
test loss item: 0.10923228412866592
test loss item: 0.21092717349529266
test loss item: 0.2784450650215149
test loss item: 0.0968758836388588
test loss item: 0.40009957551956177
test loss item: 0.3843183219432831
test loss item: 0.08429251611232758
test loss item: 0.07594610750675201
Epoch [39/100], Training Loss: 0.1698, Testing Loss: 0.1903
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 40/100
train loss item: 0.2681121528148651
train loss item: 0.2055336982011795
train loss item: 0.2571573257446289
train loss item: 0.18591350317001343
train loss item: 0.1168331578373909
train loss item: 0.201970636844635
train loss item: 0.1378607600927353
train loss item: 0.37869739532470703
train loss item: 0.23793454468250275
train loss item: 0.14802947640419006
train loss item: 0.12449536472558975
train loss item: 0.19047431647777557
train loss item: 0.15368331968784332
train loss item: 0.36077770590782166
train loss item: 0.11484453082084656
train loss item: 0.2224564552307129
train loss item: 0.11852122098207474
train loss item: 0.12736079096794128
train loss item: 0.08432599902153015
train loss item: 0.30096566677093506
train loss item: 0.15813323855400085
train loss item: 0.5031638145446777
train loss item: 0.11737280339002609
test loss item: 0.19688527286052704
test loss item: 0.25660839676856995
test loss item: 0.2991849184036255
test loss item: 0.0933024138212204
test loss item: 0.19814808666706085
test loss item: 0.15063223242759705
test loss item: 0.10924851894378662
test loss item: 0.28024059534072876
test loss item: 0.24050413072109222
test loss item: 0.4063408076763153
test loss item: 0.09446360915899277
test loss item: 0.1612469106912613
test loss item: 0.23663343489170074
test loss item: 0.2853552997112274
test loss item: 0.19927655160427094
test loss item: 0.11916951835155487
test loss item: 0.2949516177177429
test loss item: 0.26936227083206177
test loss item: 0.08786286413669586
test loss item: 0.6677659749984741
test loss item: 0.5166676640510559
test loss item: 0.08946174383163452
test loss item: 0.07199014723300934
Epoch [40/100], Training Loss: 0.2050, Testing Loss: 0.2315
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 41/100
train loss item: 0.2523033022880554
train loss item: 0.17753158509731293
train loss item: 0.2585984766483307
train loss item: 0.2607681453227997
train loss item: 0.1936195194721222
train loss item: 0.4320482909679413
train loss item: 0.2133139967918396
train loss item: 0.4086487591266632
train loss item: 0.2492840439081192
train loss item: 0.16372279822826385
train loss item: 0.19850574433803558
train loss item: 0.3795619606971741
train loss item: 0.36658191680908203
train loss item: 0.6986051201820374
train loss item: 0.2100961059331894
train loss item: 0.5569366812705994
train loss item: 0.2049218863248825
train loss item: 0.18533238768577576
train loss item: 0.11578341573476791
train loss item: 0.3018379807472229
train loss item: 0.18151269853115082
train loss item: 0.2502354681491852
train loss item: 0.2062063217163086
test loss item: 0.13348983228206635
test loss item: 0.5373364686965942
test loss item: 0.19209636747837067
test loss item: 0.07528657466173172
test loss item: 0.22124235332012177
test loss item: 0.18432557582855225
test loss item: 0.11963202059268951
test loss item: 0.2875155210494995
test loss item: 0.15593062341213226
test loss item: 0.3144981861114502
test loss item: 0.15824533998966217
test loss item: 0.17338646948337555
test loss item: 0.18011239171028137
test loss item: 0.15933798253536224
test loss item: 0.1694280356168747
test loss item: 0.13353873789310455
test loss item: 0.25594067573547363
test loss item: 0.34437134861946106
test loss item: 0.17687785625457764
test loss item: 0.2981468439102173
test loss item: 0.39999285340309143
test loss item: 0.09697563201189041
test loss item: 0.09574513137340546
Epoch [41/100], Training Loss: 0.2811, Testing Loss: 0.2115
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 42/100
train loss item: 0.3302682936191559
train loss item: 0.1510762721300125
train loss item: 0.12494217604398727
train loss item: 0.24216234683990479
train loss item: 0.12409854680299759
train loss item: 0.3492094576358795
train loss item: 0.16649720072746277
train loss item: 0.22572937607765198
train loss item: 0.24299155175685883
train loss item: 0.3672439754009247
train loss item: 0.1345389485359192
train loss item: 0.16576127707958221
train loss item: 0.1806587427854538
train loss item: 0.16196243464946747
train loss item: 0.11109332740306854
train loss item: 0.26033106446266174
train loss item: 0.11605057120323181
train loss item: 0.09528827667236328
train loss item: 0.08935216814279556
train loss item: 0.1990879774093628
train loss item: 0.1387796401977539
train loss item: 0.267408549785614
train loss item: 0.1670038253068924
test loss item: 0.09464830160140991
test loss item: 0.15372899174690247
test loss item: 0.12038353830575943
test loss item: 0.06785812228918076
test loss item: 0.09747258573770523
test loss item: 0.08930612355470657
test loss item: 0.07910062372684479
test loss item: 0.1105642095208168
test loss item: 0.10617583990097046
test loss item: 0.15043671429157257
test loss item: 0.08226551115512848
test loss item: 0.07786552608013153
test loss item: 0.09772573411464691
test loss item: 0.1060400977730751
test loss item: 0.09273900836706161
test loss item: 0.07654163986444473
test loss item: 0.12333254516124725
test loss item: 0.12648698687553406
test loss item: 0.07494791597127914
test loss item: 0.17407920956611633
test loss item: 0.17765256762504578
test loss item: 0.07199728488922119
test loss item: 0.09425751119852066
Epoch [42/100], Training Loss: 0.1918, Testing Loss: 0.1063
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 43/100
train loss item: 0.24520595371723175
train loss item: 0.11035355925559998
train loss item: 0.10451129823923111
train loss item: 0.1379089057445526
train loss item: 0.12514075636863708
train loss item: 0.17033733427524567
train loss item: 0.11461682617664337
train loss item: 0.2113202065229416
train loss item: 0.2638738751411438
train loss item: 0.22664278745651245
train loss item: 0.08290290832519531
train loss item: 0.12036868929862976
train loss item: 0.17490974068641663
train loss item: 0.1722079962491989
train loss item: 0.10022887587547302
train loss item: 0.19890785217285156
train loss item: 0.11171137541532516
train loss item: 0.09222996979951859
train loss item: 0.08758356422185898
train loss item: 0.16659794747829437
train loss item: 0.10696771740913391
train loss item: 0.3569040298461914
train loss item: 0.12916310131549835
test loss item: 0.1266489326953888
test loss item: 0.1695823073387146
test loss item: 0.154607355594635
test loss item: 0.07464029639959335
test loss item: 0.10967320203781128
test loss item: 0.10344192385673523
test loss item: 0.09520812332630157
test loss item: 0.14959660172462463
test loss item: 0.128160297870636
test loss item: 0.20755916833877563
test loss item: 0.1024717167019844
test loss item: 0.09093255549669266
test loss item: 0.11787059903144836
test loss item: 0.14460088312625885
test loss item: 0.10952796041965485
test loss item: 0.0849069356918335
test loss item: 0.1470201313495636
test loss item: 0.14843304455280304
test loss item: 0.09606130421161652
test loss item: 0.3109249174594879
test loss item: 0.24540166556835175
test loss item: 0.09400272369384766
test loss item: 0.08296534419059753
Epoch [43/100], Training Loss: 0.1570, Testing Loss: 0.1345
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 44/100
train loss item: 0.1528240144252777
train loss item: 0.09988249838352203
train loss item: 0.15427431464195251
train loss item: 0.14412803947925568
train loss item: 0.12831702828407288
train loss item: 0.17930324375629425
train loss item: 0.11764619499444962
train loss item: 0.23599958419799805
train loss item: 0.2225230634212494
train loss item: 0.20658347010612488
train loss item: 0.12351500242948532
train loss item: 0.25814491510391235
train loss item: 0.19489331543445587
train loss item: 0.2836920917034149
train loss item: 0.11910271644592285
train loss item: 0.20675089955329895
train loss item: 0.1433708816766739
train loss item: 0.1211140900850296
train loss item: 0.06575938314199448
train loss item: 0.19556571543216705
train loss item: 0.1411372572183609
train loss item: 0.20657825469970703
train loss item: 0.11060208082199097
test loss item: 0.12083704024553299
test loss item: 0.191421777009964
test loss item: 0.1672016978263855
test loss item: 0.07394220679998398
test loss item: 0.11902613192796707
test loss item: 0.11271506547927856
test loss item: 0.09059280157089233
test loss item: 0.15968626737594604
test loss item: 0.152878075838089
test loss item: 0.21616661548614502
test loss item: 0.09498956054449081
test loss item: 0.10838673263788223
test loss item: 0.1292530745267868
test loss item: 0.16010956466197968
test loss item: 0.11380567401647568
test loss item: 0.08886457979679108
test loss item: 0.15378350019454956
test loss item: 0.16746479272842407
test loss item: 0.08147880434989929
test loss item: 0.2956559956073761
test loss item: 0.2532117962837219
test loss item: 0.07737891376018524
test loss item: 0.1076195016503334
Epoch [44/100], Training Loss: 0.1657, Testing Loss: 0.1407
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 45/100
train loss item: 0.20679393410682678
train loss item: 0.13574804365634918
train loss item: 0.16191774606704712
train loss item: 0.13422410190105438
train loss item: 0.11779668182134628
train loss item: 0.21226254105567932
train loss item: 0.1217740848660469
train loss item: 0.32099267840385437
train loss item: 0.19063487648963928
train loss item: 0.17927409708499908
train loss item: 0.16155144572257996
train loss item: 0.334194540977478
train loss item: 0.29075387120246887
train loss item: 0.6132867336273193
train loss item: 0.16960567235946655
train loss item: 0.46250542998313904
train loss item: 0.15249818563461304
train loss item: 0.1592719852924347
train loss item: 0.0965765193104744
train loss item: 0.2501984238624573
train loss item: 0.15933804214000702
train loss item: 0.23003719747066498
train loss item: 0.11684907972812653
test loss item: 0.11603745818138123
test loss item: 0.3153439462184906
test loss item: 0.20947979390621185
test loss item: 0.08477257192134857
test loss item: 0.21713446080684662
test loss item: 0.13061697781085968
test loss item: 0.11068131029605865
test loss item: 0.23125000298023224
test loss item: 0.21159666776657104
test loss item: 0.2824844717979431
test loss item: 0.11350779980421066
test loss item: 0.1496497541666031
test loss item: 0.18051545321941376
test loss item: 0.17823146283626556
test loss item: 0.1908779889345169
test loss item: 0.10874176770448685
test loss item: 0.18963687121868134
test loss item: 0.29854539036750793
test loss item: 0.12664233148097992
test loss item: 0.27623632550239563
test loss item: 0.3643619418144226
test loss item: 0.09343794733285904
test loss item: 0.11537082493305206
Epoch [45/100], Training Loss: 0.2164, Testing Loss: 0.1867
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 46/100
train loss item: 0.2916785180568695
train loss item: 0.16154904663562775
train loss item: 0.18861649930477142
train loss item: 0.20746354758739471
train loss item: 0.12117138504981995
train loss item: 0.26026827096939087
train loss item: 0.10982803255319595
train loss item: 0.21333561837673187
train loss item: 0.21372444927692413
train loss item: 0.2408270388841629
train loss item: 0.11171844601631165
train loss item: 0.13356949388980865
train loss item: 0.14423494040966034
train loss item: 0.17489971220493317
train loss item: 0.10548842698335648
train loss item: 0.21826645731925964
train loss item: 0.12886543571949005
train loss item: 0.09735330194234848
train loss item: 0.08413787186145782
train loss item: 0.16416864097118378
train loss item: 0.11072088032960892
train loss item: 0.31856414675712585
train loss item: 0.13733097910881042
test loss item: 0.10518072545528412
test loss item: 0.16677993535995483
test loss item: 0.14073731005191803
test loss item: 0.08158165216445923
test loss item: 0.10147461295127869
test loss item: 0.09932304918766022
test loss item: 0.08407135307788849
test loss item: 0.13292528688907623
test loss item: 0.11980725079774857
test loss item: 0.17496801912784576
test loss item: 0.09477264434099197
test loss item: 0.08639824390411377
test loss item: 0.13766230642795563
test loss item: 0.1281600147485733
test loss item: 0.10791028290987015
test loss item: 0.09719834476709366
test loss item: 0.12436932325363159
test loss item: 0.13798053562641144
test loss item: 0.07886511832475662
test loss item: 0.23407797515392303
test loss item: 0.2017175555229187
test loss item: 0.07061201333999634
test loss item: 0.10997042059898376
Epoch [46/100], Training Loss: 0.1712, Testing Loss: 0.1225
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 47/100
train loss item: 0.16144217550754547
train loss item: 0.10985049605369568
train loss item: 0.1728450506925583
train loss item: 0.13373076915740967
train loss item: 0.1129819005727768
train loss item: 0.15469123423099518
train loss item: 0.11716325581073761
train loss item: 0.1944577842950821
train loss item: 0.18330658972263336
train loss item: 0.17163683474063873
train loss item: 0.10862326622009277
train loss item: 0.20907451212406158
train loss item: 0.17043432593345642
train loss item: 0.17859390377998352
train loss item: 0.10516025125980377
train loss item: 0.17816570401191711
train loss item: 0.10218171775341034
train loss item: 0.10411159694194794
train loss item: 0.05943562090396881
train loss item: 0.16893339157104492
train loss item: 0.0954684391617775
train loss item: 0.1776445358991623
train loss item: 0.08977404981851578
test loss item: 0.10494782775640488
test loss item: 0.1758822202682495
test loss item: 0.15710723400115967
test loss item: 0.06355209648609161
test loss item: 0.10561808943748474
test loss item: 0.09025842696428299
test loss item: 0.07408155500888824
test loss item: 0.15094296634197235
test loss item: 0.12980730831623077
test loss item: 0.2018997222185135
test loss item: 0.0784863755106926
test loss item: 0.09410373866558075
test loss item: 0.12349999696016312
test loss item: 0.14497539401054382
test loss item: 0.10201253741979599
test loss item: 0.07837346941232681
test loss item: 0.1350940316915512
test loss item: 0.14843697845935822
test loss item: 0.0644107386469841
test loss item: 0.2899937331676483
test loss item: 0.24064095318317413
test loss item: 0.05991964787244797
test loss item: 0.0605904757976532
Epoch [47/100], Training Loss: 0.1417, Testing Loss: 0.1250
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 48/100
train loss item: 0.2107146680355072
train loss item: 0.13531260192394257
train loss item: 0.17939060926437378
train loss item: 0.14437615871429443
train loss item: 0.10953548550605774
train loss item: 0.16880162060260773
train loss item: 0.1244313046336174
train loss item: 0.28412148356437683
train loss item: 0.18948952853679657
train loss item: 0.1686531901359558
train loss item: 0.14430183172225952
train loss item: 0.32111412286758423
train loss item: 0.28091496229171753
train loss item: 0.5590987205505371
train loss item: 0.1618262380361557
train loss item: 0.48211926221847534
train loss item: 0.1827714592218399
train loss item: 0.16203615069389343
train loss item: 0.0874973013997078
train loss item: 0.2192034125328064
train loss item: 0.1616068035364151
train loss item: 0.16416163742542267
train loss item: 0.14644911885261536
test loss item: 0.10873407125473022
test loss item: 0.3533202111721039
test loss item: 0.1603793203830719
test loss item: 0.07100771367549896
test loss item: 0.19085973501205444
test loss item: 0.15340395271778107
test loss item: 0.10062558203935623
test loss item: 0.21532239019870758
test loss item: 0.15630455315113068
test loss item: 0.24463681876659393
test loss item: 0.13391274213790894
test loss item: 0.14581644535064697
test loss item: 0.15099424123764038
test loss item: 0.14158552885055542
test loss item: 0.15505778789520264
test loss item: 0.11171433329582214
test loss item: 0.19195745885372162
test loss item: 0.2840634286403656
test loss item: 0.1545892059803009
test loss item: 0.19271135330200195
test loss item: 0.3157290816307068
test loss item: 0.08814366161823273
test loss item: 0.09610515832901001
Epoch [48/100], Training Loss: 0.2082, Testing Loss: 0.1703
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 49/100
train loss item: 0.1839229166507721
train loss item: 0.12262681871652603
train loss item: 0.16877757012844086
train loss item: 0.1824551522731781
train loss item: 0.09367184340953827
train loss item: 0.142573744058609
train loss item: 0.13701295852661133
train loss item: 0.2382098138332367
train loss item: 0.20055656135082245
train loss item: 0.1303275227546692
train loss item: 0.1402149647474289
train loss item: 0.2501075863838196
train loss item: 0.2841801941394806
train loss item: 0.5599333643913269
train loss item: 0.14964263141155243
train loss item: 0.5110368132591248
train loss item: 0.15348224341869354
train loss item: 0.13025599718093872
train loss item: 0.07909771800041199
train loss item: 0.1636957824230194
train loss item: 0.11602906882762909
train loss item: 0.2479131519794464
train loss item: 0.10735923796892166
test loss item: 0.12545758485794067
test loss item: 0.34704411029815674
test loss item: 0.16019296646118164
test loss item: 0.10999620705842972
test loss item: 0.1733957827091217
test loss item: 0.1589588224887848
test loss item: 0.10883373767137527
test loss item: 0.20806992053985596
test loss item: 0.1493903249502182
test loss item: 0.22876635193824768
test loss item: 0.14299501478672028
test loss item: 0.1425788253545761
test loss item: 0.16779889166355133
test loss item: 0.1412491351366043
test loss item: 0.15314576029777527
test loss item: 0.13417087495326996
test loss item: 0.19002999365329742
test loss item: 0.25482457876205444
test loss item: 0.14424489438533783
test loss item: 0.1787882000207901
test loss item: 0.2786274254322052
test loss item: 0.09237971901893616
test loss item: 0.0875159278512001
Epoch [49/100], Training Loss: 0.1954, Testing Loss: 0.1686
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 50/100
train loss item: 0.15153051912784576
train loss item: 0.13448433578014374
train loss item: 0.18896974623203278
train loss item: 0.1548377424478531
train loss item: 0.09803056716918945
train loss item: 0.16664449870586395
train loss item: 0.16508783400058746
train loss item: 0.21115443110466003
train loss item: 0.22250109910964966
train loss item: 0.18736444413661957
train loss item: 0.11733607947826385
train loss item: 0.22888235747814178
train loss item: 0.23208078742027283
train loss item: 0.35937783122062683
train loss item: 0.13502702116966248
train loss item: 0.35412514209747314
train loss item: 0.1477004587650299
train loss item: 0.1345100849866867
train loss item: 0.08443973958492279
train loss item: 0.22125564515590668
train loss item: 0.14395758509635925
train loss item: 0.17844918370246887
train loss item: 0.11061284691095352
test loss item: 0.1210346519947052
test loss item: 0.2469528317451477
test loss item: 0.15547186136245728
test loss item: 0.0871235653758049
test loss item: 0.15722592175006866
test loss item: 0.13707473874092102
test loss item: 0.10127083212137222
test loss item: 0.17352920770645142
test loss item: 0.15073919296264648
test loss item: 0.20416195690631866
test loss item: 0.12586000561714172
test loss item: 0.13089066743850708
test loss item: 0.1332065463066101
test loss item: 0.14390400052070618
test loss item: 0.13489481806755066
test loss item: 0.1035122349858284
test loss item: 0.16071730852127075
test loss item: 0.20953083038330078
test loss item: 0.13338705897331238
test loss item: 0.20312000811100006
test loss item: 0.2502795457839966
test loss item: 0.09567585587501526
test loss item: 0.07401801645755768
Epoch [50/100], Training Loss: 0.1795, Testing Loss: 0.1493
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 152.00 MB
Epoch 51/100
train loss item: 0.14927932620048523
train loss item: 0.1125544086098671
train loss item: 0.17514874041080475
train loss item: 0.1322973668575287
train loss item: 0.10639160871505737
train loss item: 0.16571193933486938
train loss item: 0.14967240393161774
train loss item: 0.293113112449646
train loss item: 0.24659548699855804
train loss item: 0.16917060315608978
train loss item: 0.1381402611732483
train loss item: 0.29076021909713745
train loss item: 0.27895691990852356
train loss item: 0.5010709166526794
train loss item: 0.15438306331634521
train loss item: 0.536865234375
train loss item: 0.1934935301542282
train loss item: 0.1425192803144455
train loss item: 0.09536834806203842
train loss item: 0.22823166847229004
train loss item: 0.1312488317489624
train loss item: 0.264568954706192
train loss item: 0.10939724743366241
test loss item: 0.13530105352401733
test loss item: 0.27558645606040955
test loss item: 0.20287421345710754
test loss item: 0.10273989289999008
test loss item: 0.1652006208896637
test loss item: 0.15123136341571808
test loss item: 0.09841211885213852
test loss item: 0.20969893038272858
test loss item: 0.16471600532531738
test loss item: 0.27060890197753906
test loss item: 0.1272689551115036
test loss item: 0.14937974512577057
test loss item: 0.16994807124137878
test loss item: 0.17679713666439056
test loss item: 0.15933901071548462
test loss item: 0.11916912347078323
test loss item: 0.19647429883480072
test loss item: 0.22817504405975342
test loss item: 0.1386311650276184
test loss item: 0.3517281711101532
test loss item: 0.33087337017059326
test loss item: 0.08930903673171997
test loss item: 0.10979967564344406
Epoch [51/100], Training Loss: 0.2072, Testing Loss: 0.1793
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 132.00 MB
Epoch 52/100
train loss item: 0.20193015038967133
train loss item: 0.1876479536294937
train loss item: 0.20771320164203644
train loss item: 0.15529495477676392
train loss item: 0.10154742002487183
train loss item: 0.2180742770433426
train loss item: 0.16814009845256805
train loss item: 0.35906288027763367
train loss item: 0.34665095806121826
train loss item: 0.18446382880210876
train loss item: 0.11545149981975555
train loss item: 0.20631654560565948
train loss item: 0.19419465959072113
train loss item: 0.20783206820487976
train loss item: 0.14586544036865234
train loss item: 0.3024144470691681
train loss item: 0.14981284737586975
train loss item: 0.11083681881427765
train loss item: 0.07245942950248718
train loss item: 0.2016860842704773
train loss item: 0.10345873236656189
train loss item: 0.1636466085910797
train loss item: 0.09455003589391708
test loss item: 0.11865522712469101
test loss item: 0.24811168015003204
test loss item: 0.16118258237838745
test loss item: 0.064860999584198
test loss item: 0.13100668787956238
test loss item: 0.13055594265460968
test loss item: 0.08388090133666992
test loss item: 0.1783352941274643
test loss item: 0.1401062160730362
test loss item: 0.22872678935527802
test loss item: 0.10296349227428436
test loss item: 0.11745341867208481
test loss item: 0.134932741522789
test loss item: 0.15940988063812256
test loss item: 0.11947906762361526
test loss item: 0.09026362746953964
test loss item: 0.1749684065580368
test loss item: 0.1942104697227478
test loss item: 0.10625030845403671
test loss item: 0.30385589599609375
test loss item: 0.27222973108291626
test loss item: 0.07104645669460297
test loss item: 0.07443621009588242
Epoch [52/100], Training Loss: 0.1826, Testing Loss: 0.1481
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.25412723422050476
loss item: 0.17430835962295532
loss item: 0.1663035750389099
loss item: 0.14160646498203278
loss item: 0.20412546396255493
loss item: 0.09940750151872635
loss item: 0.18415142595767975
loss item: 0.28867578506469727
loss item: 0.10744045674800873
loss item: 0.14938919246196747
loss item: 0.21261948347091675
Val Loss: 0.1802
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 100, batch size: 8
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.005 8 360 done at Tue Nov 12 13:54:25 CET 2024
UNet2 with 1 100 0.0001 16 360 start at Tue Nov 12 13:54:25 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.347920298576355
train loss item: 0.7567220330238342
train loss item: 0.9415144324302673
train loss item: 1.2658209800720215
train loss item: 1.3252041339874268
train loss item: 0.5795272588729858
train loss item: 1.2090576887130737
train loss item: 0.9306648969650269
train loss item: 0.5281984210014343
train loss item: 0.7622933983802795
train loss item: 1.252486228942871
train loss item: 0.5241486430168152
test loss item: 1.1635373830795288
test loss item: 0.8743120431900024
test loss item: 0.7483742833137512
test loss item: 0.7974737882614136
test loss item: 1.2985048294067383
test loss item: 0.570023238658905
test loss item: 0.9929193258285522
test loss item: 0.6190888285636902
test loss item: 1.1566652059555054
test loss item: 1.6485538482666016
test loss item: 1.5251150131225586
test loss item: 0.20283658802509308
Epoch [1/100], Training Loss: 0.9520, Testing Loss: 0.9665
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/100
train loss item: 0.7401988506317139
train loss item: 0.4863934814929962
train loss item: 0.599054217338562
train loss item: 0.754587709903717
train loss item: 0.8665329813957214
train loss item: 0.4313562214374542
train loss item: 0.7822306156158447
train loss item: 0.6246208548545837
train loss item: 0.5153311491012573
train loss item: 0.6471831202507019
train loss item: 0.9335834980010986
train loss item: 0.43342021107673645
test loss item: 0.880848228931427
test loss item: 0.6917149424552917
test loss item: 0.6116279363632202
test loss item: 0.6236787438392639
test loss item: 1.0314371585845947
test loss item: 0.4742750823497772
test loss item: 0.7905266880989075
test loss item: 0.5056158304214478
test loss item: 0.8801586627960205
test loss item: 1.2333225011825562
test loss item: 1.1637259721755981
test loss item: 0.24054406583309174
Epoch [2/100], Training Loss: 0.6512, Testing Loss: 0.7606
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/100
train loss item: 0.5782200694084167
train loss item: 0.4201120138168335
train loss item: 0.4758269190788269
train loss item: 0.6368111968040466
train loss item: 0.7149839401245117
train loss item: 0.3648892939090729
train loss item: 0.6342721581459045
train loss item: 0.5283299684524536
train loss item: 0.4298100471496582
train loss item: 0.5449725985527039
train loss item: 0.7565566897392273
train loss item: 0.395431786775589
test loss item: 0.5319501757621765
test loss item: 0.4183981120586395
test loss item: 0.4346845746040344
test loss item: 0.38244473934173584
test loss item: 0.6375440359115601
test loss item: 0.36071017384529114
test loss item: 0.4719291627407074
test loss item: 0.36257457733154297
test loss item: 0.5221804976463318
test loss item: 0.5786992311477661
test loss item: 0.621884822845459
test loss item: 0.25444474816322327
Epoch [3/100], Training Loss: 0.5400, Testing Loss: 0.4648
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/100
train loss item: 0.5396005511283875
train loss item: 0.41185733675956726
train loss item: 0.43653613328933716
train loss item: 0.5439848899841309
train loss item: 0.6010032892227173
train loss item: 0.3382870554924011
train loss item: 0.5531575083732605
train loss item: 0.48223984241485596
train loss item: 0.34177836775779724
train loss item: 0.4872194826602936
train loss item: 0.7226658463478088
train loss item: 0.36409419775009155
test loss item: 0.41494104266166687
test loss item: 0.33787810802459717
test loss item: 0.36477580666542053
test loss item: 0.31292518973350525
test loss item: 0.5127039551734924
test loss item: 0.30048948526382446
test loss item: 0.3697968125343323
test loss item: 0.31895679235458374
test loss item: 0.4262077510356903
test loss item: 0.48441505432128906
test loss item: 0.5073458552360535
test loss item: 0.29376649856567383
Epoch [4/100], Training Loss: 0.4852, Testing Loss: 0.3870
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/100
train loss item: 0.4667614996433258
train loss item: 0.35602954030036926
train loss item: 0.3905697464942932
train loss item: 0.4654618501663208
train loss item: 0.5137914419174194
train loss item: 0.33662980794906616
train loss item: 0.4598850905895233
train loss item: 0.4228249192237854
train loss item: 0.3118244409561157
train loss item: 0.4222519099712372
train loss item: 0.6273717284202576
train loss item: 0.3169131278991699
test loss item: 0.36404329538345337
test loss item: 0.31014958024024963
test loss item: 0.322428822517395
test loss item: 0.28472375869750977
test loss item: 0.46169647574424744
test loss item: 0.2684535086154938
test loss item: 0.3343240022659302
test loss item: 0.2909172475337982
test loss item: 0.37892231345176697
test loss item: 0.44105374813079834
test loss item: 0.45781704783439636
test loss item: 0.21189063787460327
Epoch [5/100], Training Loss: 0.4242, Testing Loss: 0.3439
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/100
train loss item: 0.42646029591560364
train loss item: 0.321542888879776
train loss item: 0.3541386127471924
train loss item: 0.4172070026397705
train loss item: 0.4470345377922058
train loss item: 0.2825626730918884
train loss item: 0.40221458673477173
train loss item: 0.37018683552742004
train loss item: 0.2941639721393585
train loss item: 0.39619678258895874
train loss item: 0.5370286107063293
train loss item: 0.2920563817024231
test loss item: 0.34206172823905945
test loss item: 0.306392103433609
test loss item: 0.28875958919525146
test loss item: 0.27712246775627136
test loss item: 0.4421752691268921
test loss item: 0.24570424854755402
test loss item: 0.31886026263237
test loss item: 0.2724485993385315
test loss item: 0.3653445243835449
test loss item: 0.4829641878604889
test loss item: 0.4696064293384552
test loss item: 0.20959006249904633
Epoch [6/100], Training Loss: 0.3784, Testing Loss: 0.3351
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/100
train loss item: 0.42065373063087463
train loss item: 0.299028605222702
train loss item: 0.3209518790245056
train loss item: 0.3806475102901459
train loss item: 0.4044487476348877
train loss item: 0.2597898244857788
train loss item: 0.35629788041114807
train loss item: 0.3363831639289856
train loss item: 0.27083784341812134
train loss item: 0.3857123851776123
train loss item: 0.46953722834587097
train loss item: 0.27001869678497314
test loss item: 0.33257701992988586
test loss item: 0.2954329252243042
test loss item: 0.27253323793411255
test loss item: 0.26488226652145386
test loss item: 0.41732773184776306
test loss item: 0.2333609163761139
test loss item: 0.30824270844459534
test loss item: 0.2565782368183136
test loss item: 0.3576570153236389
test loss item: 0.45231354236602783
test loss item: 0.449957937002182
test loss item: 0.1894015222787857
Epoch [7/100], Training Loss: 0.3479, Testing Loss: 0.3192
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/100
train loss item: 0.41220542788505554
train loss item: 0.2868652939796448
train loss item: 0.3081567883491516
train loss item: 0.34732961654663086
train loss item: 0.3768295645713806
train loss item: 0.24169519543647766
train loss item: 0.3249988853931427
train loss item: 0.31343603134155273
train loss item: 0.26336759328842163
train loss item: 0.3831824064254761
train loss item: 0.427778035402298
train loss item: 0.25177326798439026
test loss item: 0.3221997916698456
test loss item: 0.2877434492111206
test loss item: 0.2592628002166748
test loss item: 0.2517662048339844
test loss item: 0.4032743275165558
test loss item: 0.21948684751987457
test loss item: 0.30327266454696655
test loss item: 0.24405038356781006
test loss item: 0.3536774218082428
test loss item: 0.43759816884994507
test loss item: 0.4363326132297516
test loss item: 0.1839670091867447
Epoch [8/100], Training Loss: 0.3281, Testing Loss: 0.3086
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/100
train loss item: 0.3800511360168457
train loss item: 0.2699737548828125
train loss item: 0.2907028794288635
train loss item: 0.32575881481170654
train loss item: 0.35931819677352905
train loss item: 0.23939499258995056
train loss item: 0.30068299174308777
train loss item: 0.30091995000839233
train loss item: 0.2408865988254547
train loss item: 0.37569931149482727
train loss item: 0.40296605229377747
train loss item: 0.24435988068580627
test loss item: 0.2964315116405487
test loss item: 0.27875208854675293
test loss item: 0.24245423078536987
test loss item: 0.2369583249092102
test loss item: 0.378653347492218
test loss item: 0.20512571930885315
test loss item: 0.28901663422584534
test loss item: 0.2355102151632309
test loss item: 0.32526904344558716
test loss item: 0.37884244322776794
test loss item: 0.4079797863960266
test loss item: 0.18805299699306488
Epoch [9/100], Training Loss: 0.3109, Testing Loss: 0.2886
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/100
train loss item: 0.34666603803634644
train loss item: 0.24981653690338135
train loss item: 0.26727473735809326
train loss item: 0.308357834815979
train loss item: 0.35065439343452454
train loss item: 0.2388707846403122
train loss item: 0.28532567620277405
train loss item: 0.2903541028499603
train loss item: 0.21650585532188416
train loss item: 0.35096192359924316
train loss item: 0.3800894320011139
train loss item: 0.2308773249387741
test loss item: 0.3177933394908905
test loss item: 0.32816585898399353
test loss item: 0.25826120376586914
test loss item: 0.2616356909275055
test loss item: 0.4336276948451996
test loss item: 0.21133142709732056
test loss item: 0.33978986740112305
test loss item: 0.26333531737327576
test loss item: 0.36563414335250854
test loss item: 0.4255470037460327
test loss item: 0.48174020648002625
test loss item: 0.18677788972854614
Epoch [10/100], Training Loss: 0.2930, Testing Loss: 0.3228
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 11/100
train loss item: 0.347891241312027
train loss item: 0.2560316026210785
train loss item: 0.24945759773254395
train loss item: 0.2845357656478882
train loss item: 0.3305457532405853
train loss item: 0.24087552726268768
train loss item: 0.3099680244922638
train loss item: 0.3068079650402069
train loss item: 0.2156068980693817
train loss item: 0.3107607066631317
train loss item: 0.34536802768707275
train loss item: 0.217264786362648
test loss item: 0.34072765707969666
test loss item: 0.3702849745750427
test loss item: 0.2656375765800476
test loss item: 0.284180611371994
test loss item: 0.4830327033996582
test loss item: 0.21812781691551208
test loss item: 0.3822464644908905
test loss item: 0.28418242931365967
test loss item: 0.4095641076564789
test loss item: 0.5124495625495911
test loss item: 0.550409197807312
test loss item: 0.20672661066055298
Epoch [11/100], Training Loss: 0.2846, Testing Loss: 0.3590
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 12/100
train loss item: 0.36933159828186035
train loss item: 0.28285467624664307
train loss item: 0.2697446048259735
train loss item: 0.3008861839771271
train loss item: 0.2832474112510681
train loss item: 0.2179907113313675
train loss item: 0.3218272030353546
train loss item: 0.340495228767395
train loss item: 0.22335776686668396
train loss item: 0.2912554442882538
train loss item: 0.361698716878891
train loss item: 0.22472809255123138
test loss item: 0.3493470251560211
test loss item: 0.39836809039115906
test loss item: 0.26887038350105286
test loss item: 0.29991692304611206
test loss item: 0.5373103022575378
test loss item: 0.23283565044403076
test loss item: 0.429537832736969
test loss item: 0.2698112428188324
test loss item: 0.44669109582901
test loss item: 0.6838924884796143
test loss item: 0.6128897070884705
test loss item: 0.19076766073703766
Epoch [12/100], Training Loss: 0.2906, Testing Loss: 0.3934
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 13/100
train loss item: 0.310799777507782
train loss item: 0.2686956822872162
train loss item: 0.2521226704120636
train loss item: 0.3431659936904907
train loss item: 0.2809893786907196
train loss item: 0.20553483068943024
train loss item: 0.24664650857448578
train loss item: 0.3120839297771454
train loss item: 0.2217014729976654
train loss item: 0.3185695707798004
train loss item: 0.44780415296554565
train loss item: 0.21862837672233582
test loss item: 0.2638278007507324
test loss item: 0.24566766619682312
test loss item: 0.23009853065013885
test loss item: 0.2162914127111435
test loss item: 0.3768601417541504
test loss item: 0.19032904505729675
test loss item: 0.2811274230480194
test loss item: 0.21397355198860168
test loss item: 0.2992720305919647
test loss item: 0.47624704241752625
test loss item: 0.3945642113685608
test loss item: 0.1779440939426422
Epoch [13/100], Training Loss: 0.2856, Testing Loss: 0.2805
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 14/100
train loss item: 0.24441437423229218
train loss item: 0.24064691364765167
train loss item: 0.26568570733070374
train loss item: 0.3428039252758026
train loss item: 0.2758849561214447
train loss item: 0.2402867078781128
train loss item: 0.22238722443580627
train loss item: 0.2526032328605652
train loss item: 0.1925911009311676
train loss item: 0.3034432530403137
train loss item: 0.5039529800415039
train loss item: 0.1993921548128128
test loss item: 0.2672710120677948
test loss item: 0.20604538917541504
test loss item: 0.20624862611293793
test loss item: 0.19942250847816467
test loss item: 0.30694347620010376
test loss item: 0.17279210686683655
test loss item: 0.2341848909854889
test loss item: 0.19424225389957428
test loss item: 0.26042938232421875
test loss item: 0.33181771636009216
test loss item: 0.31789085268974304
test loss item: 0.16157321631908417
Epoch [14/100], Training Loss: 0.2737, Testing Loss: 0.2382
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 15/100
train loss item: 0.3015146255493164
train loss item: 0.1959829330444336
train loss item: 0.21499517560005188
train loss item: 0.2558496594429016
train loss item: 0.2373930662870407
train loss item: 0.2610434889793396
train loss item: 0.232282817363739
train loss item: 0.21869546175003052
train loss item: 0.2108130306005478
train loss item: 0.2790016829967499
train loss item: 0.4134898781776428
train loss item: 0.19360581040382385
test loss item: 0.25074532628059387
test loss item: 0.21728886663913727
test loss item: 0.207977294921875
test loss item: 0.20084546506404877
test loss item: 0.30506306886672974
test loss item: 0.17579251527786255
test loss item: 0.2384076714515686
test loss item: 0.1985301375389099
test loss item: 0.2560683488845825
test loss item: 0.29233279824256897
test loss item: 0.3083442151546478
test loss item: 0.18627220392227173
Epoch [15/100], Training Loss: 0.2512, Testing Loss: 0.2365
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 16/100
train loss item: 0.28360429406166077
train loss item: 0.20082612335681915
train loss item: 0.22855116426944733
train loss item: 0.22903010249137878
train loss item: 0.23093679547309875
train loss item: 0.20070821046829224
train loss item: 0.22551080584526062
train loss item: 0.2232566922903061
train loss item: 0.22529102861881256
train loss item: 0.27830907702445984
train loss item: 0.3307356834411621
train loss item: 0.20142415165901184
test loss item: 0.23352943360805511
test loss item: 0.18462195992469788
test loss item: 0.18930338323116302
test loss item: 0.17649351060390472
test loss item: 0.25943461060523987
test loss item: 0.15861612558364868
test loss item: 0.19880744814872742
test loss item: 0.17579510807991028
test loss item: 0.22708553075790405
test loss item: 0.2202111780643463
test loss item: 0.2646808624267578
test loss item: 0.15296266973018646
Epoch [16/100], Training Loss: 0.2382, Testing Loss: 0.2035
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 17/100
train loss item: 0.21967723965644836
train loss item: 0.18388615548610687
train loss item: 0.21093565225601196
train loss item: 0.21967753767967224
train loss item: 0.24031376838684082
train loss item: 0.17796337604522705
train loss item: 0.1950828582048416
train loss item: 0.19968996942043304
train loss item: 0.18790030479431152
train loss item: 0.2678335905075073
train loss item: 0.3164569139480591
train loss item: 0.18970836699008942
test loss item: 0.20611153542995453
test loss item: 0.1655198186635971
test loss item: 0.1708715856075287
test loss item: 0.15774916112422943
test loss item: 0.23022952675819397
test loss item: 0.14827276766300201
test loss item: 0.1773974746465683
test loss item: 0.1628728210926056
test loss item: 0.2019546777009964
test loss item: 0.20060661435127258
test loss item: 0.22909240424633026
test loss item: 0.1597609966993332
Epoch [17/100], Training Loss: 0.2174, Testing Loss: 0.1842
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 18/100
train loss item: 0.20933619141578674
train loss item: 0.16878241300582886
train loss item: 0.19020044803619385
train loss item: 0.21281512081623077
train loss item: 0.22815540432929993
train loss item: 0.1662726253271103
train loss item: 0.18689799308776855
train loss item: 0.18889757990837097
train loss item: 0.17230793833732605
train loss item: 0.24968743324279785
train loss item: 0.2776159644126892
train loss item: 0.1768438071012497
test loss item: 0.2129429280757904
test loss item: 0.1743190735578537
test loss item: 0.17055176198482513
test loss item: 0.16058777272701263
test loss item: 0.23746013641357422
test loss item: 0.1459602415561676
test loss item: 0.1858300417661667
test loss item: 0.16722652316093445
test loss item: 0.20726919174194336
test loss item: 0.20160667598247528
test loss item: 0.24079422652721405
test loss item: 0.1550452709197998
Epoch [18/100], Training Loss: 0.2023, Testing Loss: 0.1883
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 19/100
train loss item: 0.2246755212545395
train loss item: 0.16634979844093323
train loss item: 0.18459048867225647
train loss item: 0.2092866599559784
train loss item: 0.212196946144104
train loss item: 0.1576564610004425
train loss item: 0.19300785660743713
train loss item: 0.20480136573314667
train loss item: 0.16745591163635254
train loss item: 0.24888111650943756
train loss item: 0.24717870354652405
train loss item: 0.16818314790725708
test loss item: 0.20111724734306335
test loss item: 0.18738797307014465
test loss item: 0.16996049880981445
test loss item: 0.16491244733333588
test loss item: 0.25039246678352356
test loss item: 0.1473967730998993
test loss item: 0.19947685301303864
test loss item: 0.17036490142345428
test loss item: 0.2131209522485733
test loss item: 0.22659100592136383
test loss item: 0.26126453280448914
test loss item: 0.1747044175863266
Epoch [19/100], Training Loss: 0.1987, Testing Loss: 0.1972
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 20/100
train loss item: 0.22749044001102448
train loss item: 0.17218871414661407
train loss item: 0.1791677474975586
train loss item: 0.21432030200958252
train loss item: 0.21280528604984283
train loss item: 0.16117580235004425
train loss item: 0.18950825929641724
train loss item: 0.2187706083059311
train loss item: 0.16558369994163513
train loss item: 0.23763997852802277
train loss item: 0.2616533637046814
train loss item: 0.1636098176240921
test loss item: 0.2010035216808319
test loss item: 0.19348107278347015
test loss item: 0.17075099050998688
test loss item: 0.1646733582019806
test loss item: 0.2539246678352356
test loss item: 0.15203070640563965
test loss item: 0.2088516354560852
test loss item: 0.16983209550380707
test loss item: 0.21942591667175293
test loss item: 0.23598182201385498
test loss item: 0.2658907473087311
test loss item: 0.14895200729370117
Epoch [20/100], Training Loss: 0.2003, Testing Loss: 0.1987
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 21/100
train loss item: 0.20588448643684387
train loss item: 0.17470479011535645
train loss item: 0.18453045189380646
train loss item: 0.23942182958126068
train loss item: 0.22611774504184723
train loss item: 0.16807407140731812
train loss item: 0.17258767783641815
train loss item: 0.23358146846294403
train loss item: 0.1660103052854538
train loss item: 0.25451287627220154
train loss item: 0.29537445306777954
train loss item: 0.15844844281673431
test loss item: 0.19290927052497864
test loss item: 0.17207255959510803
test loss item: 0.17261305451393127
test loss item: 0.15349341928958893
test loss item: 0.22982966899871826
test loss item: 0.14721953868865967
test loss item: 0.18662630021572113
test loss item: 0.1679149866104126
test loss item: 0.20633864402770996
test loss item: 0.19687236845493317
test loss item: 0.23850436508655548
test loss item: 0.18139196932315826
Epoch [21/100], Training Loss: 0.2066, Testing Loss: 0.1871
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 22/100
train loss item: 0.18537811934947968
train loss item: 0.16944453120231628
train loss item: 0.1788487434387207
train loss item: 0.2620743215084076
train loss item: 0.24398721754550934
train loss item: 0.17278580367565155
train loss item: 0.1724184900522232
train loss item: 0.209122896194458
train loss item: 0.16612876951694489
train loss item: 0.23844210803508759
train loss item: 0.39660343527793884
train loss item: 0.15762436389923096
test loss item: 0.2233467698097229
test loss item: 0.17296187579631805
test loss item: 0.1906055510044098
test loss item: 0.15856975317001343
test loss item: 0.24600470066070557
test loss item: 0.15321668982505798
test loss item: 0.18774427473545074
test loss item: 0.17984719574451447
test loss item: 0.23233731091022491
test loss item: 0.22937794029712677
test loss item: 0.27011653780937195
test loss item: 0.14906984567642212
Epoch [22/100], Training Loss: 0.2127, Testing Loss: 0.1994
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 23/100
train loss item: 0.2297198623418808
train loss item: 0.16876600682735443
train loss item: 0.17740657925605774
train loss item: 0.22926437854766846
train loss item: 0.20485590398311615
train loss item: 0.20047664642333984
train loss item: 0.19650913774967194
train loss item: 0.2186138778924942
train loss item: 0.19271613657474518
train loss item: 0.19424661993980408
train loss item: 0.3512938320636749
train loss item: 0.15552176535129547
test loss item: 0.24018113315105438
test loss item: 0.17665624618530273
test loss item: 0.19142884016036987
test loss item: 0.16540338099002838
test loss item: 0.25313764810562134
test loss item: 0.1544247567653656
test loss item: 0.19039733707904816
test loss item: 0.17860929667949677
test loss item: 0.23620055615901947
test loss item: 0.24835205078125
test loss item: 0.2785246670246124
test loss item: 0.15920457243919373
Epoch [23/100], Training Loss: 0.2099, Testing Loss: 0.2060
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 24/100
train loss item: 0.2206430584192276
train loss item: 0.17279526591300964
train loss item: 0.19059962034225464
train loss item: 0.26703542470932007
train loss item: 0.18273669481277466
train loss item: 0.15883754193782806
train loss item: 0.19089145958423615
train loss item: 0.19392375648021698
train loss item: 0.19159606099128723
train loss item: 0.18235620856285095
train loss item: 0.30897560715675354
train loss item: 0.18495437502861023
test loss item: 0.1888107806444168
test loss item: 0.16394740343093872
test loss item: 0.1560487598180771
test loss item: 0.14666903018951416
test loss item: 0.23125584423542023
test loss item: 0.1334654539823532
test loss item: 0.17444691061973572
test loss item: 0.15184172987937927
test loss item: 0.19224625825881958
test loss item: 0.22781343758106232
test loss item: 0.24131996929645538
test loss item: 0.15410126745700836
Epoch [24/100], Training Loss: 0.2038, Testing Loss: 0.1802
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 25/100
train loss item: 0.21051429212093353
train loss item: 0.14710243046283722
train loss item: 0.15827280282974243
train loss item: 0.21940459311008453
train loss item: 0.18263113498687744
train loss item: 0.14320071041584015
train loss item: 0.208529531955719
train loss item: 0.17284610867500305
train loss item: 0.1543860286474228
train loss item: 0.19398930668830872
train loss item: 0.26832711696624756
train loss item: 0.15932753682136536
test loss item: 0.2340281903743744
test loss item: 0.17587070167064667
test loss item: 0.17374955117702484
test loss item: 0.1664980947971344
test loss item: 0.25344380736351013
test loss item: 0.13882839679718018
test loss item: 0.19219046831130981
test loss item: 0.16157306730747223
test loss item: 0.2280304878950119
test loss item: 0.22948403656482697
test loss item: 0.27383461594581604
test loss item: 0.1504390686750412
Epoch [25/100], Training Loss: 0.1849, Testing Loss: 0.1982
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 26/100
train loss item: 0.21272747218608856
train loss item: 0.16929444670677185
train loss item: 0.17620718479156494
train loss item: 0.1720498502254486
train loss item: 0.17506550252437592
train loss item: 0.1319499909877777
train loss item: 0.19337612390518188
train loss item: 0.1747479885816574
train loss item: 0.1723146140575409
train loss item: 0.24134251475334167
train loss item: 0.2535175383090973
train loss item: 0.15350459516048431
test loss item: 0.17454008758068085
test loss item: 0.15001919865608215
test loss item: 0.14329196512699127
test loss item: 0.1385580450296402
test loss item: 0.2039666771888733
test loss item: 0.125982403755188
test loss item: 0.1634349375963211
test loss item: 0.13780568540096283
test loss item: 0.17603270709514618
test loss item: 0.19624318182468414
test loss item: 0.2127838283777237
test loss item: 0.14389021694660187
Epoch [26/100], Training Loss: 0.1855, Testing Loss: 0.1639
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 27/100
train loss item: 0.17189106345176697
train loss item: 0.1506168693304062
train loss item: 0.17116837203502655
train loss item: 0.17975729703903198
train loss item: 0.19638143479824066
train loss item: 0.1416432112455368
train loss item: 0.16799339652061462
train loss item: 0.15828779339790344
train loss item: 0.15814834833145142
train loss item: 0.23555342853069305
train loss item: 0.2520465552806854
train loss item: 0.14875613152980804
test loss item: 0.1600317358970642
test loss item: 0.13720011711120605
test loss item: 0.1411951184272766
test loss item: 0.1257554441690445
test loss item: 0.1844407320022583
test loss item: 0.12385796755552292
test loss item: 0.14780165255069733
test loss item: 0.1377115100622177
test loss item: 0.16362500190734863
test loss item: 0.16416260600090027
test loss item: 0.18689179420471191
test loss item: 0.15235714614391327
Epoch [27/100], Training Loss: 0.1777, Testing Loss: 0.1521
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 28/100
train loss item: 0.1621827483177185
train loss item: 0.13195101916790009
train loss item: 0.14963354170322418
train loss item: 0.16585548222064972
train loss item: 0.18678373098373413
train loss item: 0.14856648445129395
train loss item: 0.16612185537815094
train loss item: 0.14685280621051788
train loss item: 0.13913992047309875
train loss item: 0.19432544708251953
train loss item: 0.23304405808448792
train loss item: 0.13847064971923828
test loss item: 0.168849378824234
test loss item: 0.14007097482681274
test loss item: 0.14816614985466003
test loss item: 0.12748754024505615
test loss item: 0.1881406158208847
test loss item: 0.1286148875951767
test loss item: 0.14968504011631012
test loss item: 0.14187303185462952
test loss item: 0.1753387749195099
test loss item: 0.16404737532138824
test loss item: 0.19494563341140747
test loss item: 0.14341893792152405
Epoch [28/100], Training Loss: 0.1636, Testing Loss: 0.1559
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 29/100
train loss item: 0.16344328224658966
train loss item: 0.12922245264053345
train loss item: 0.13953039050102234
train loss item: 0.16321176290512085
train loss item: 0.16179533302783966
train loss item: 0.13781318068504333
train loss item: 0.16656577587127686
train loss item: 0.15028256177902222
train loss item: 0.14061787724494934
train loss item: 0.16852031648159027
train loss item: 0.21384525299072266
train loss item: 0.13555198907852173
test loss item: 0.18386879563331604
test loss item: 0.137955904006958
test loss item: 0.15226897597312927
test loss item: 0.13312651216983795
test loss item: 0.18868331611156464
test loss item: 0.13279785215854645
test loss item: 0.1484488993883133
test loss item: 0.1422923505306244
test loss item: 0.18199090659618378
test loss item: 0.16473612189292908
test loss item: 0.19911283254623413
test loss item: 0.14554928243160248
Epoch [29/100], Training Loss: 0.1559, Testing Loss: 0.1592
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 30/100
train loss item: 0.15989352762699127
train loss item: 0.13449101150035858
train loss item: 0.14491547644138336
train loss item: 0.18355460464954376
train loss item: 0.1551208794116974
train loss item: 0.12484323978424072
train loss item: 0.16659067571163177
train loss item: 0.15407076478004456
train loss item: 0.1519116908311844
train loss item: 0.1629156470298767
train loss item: 0.20049667358398438
train loss item: 0.1379145383834839
test loss item: 0.16509030759334564
test loss item: 0.1364440768957138
test loss item: 0.14422833919525146
test loss item: 0.1268264502286911
test loss item: 0.18224036693572998
test loss item: 0.12817905843257904
test loss item: 0.1452961266040802
test loss item: 0.13553720712661743
test loss item: 0.1685492843389511
test loss item: 0.16784510016441345
test loss item: 0.1906731277704239
test loss item: 0.13543827831745148
Epoch [30/100], Training Loss: 0.1564, Testing Loss: 0.1522
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 31/100
train loss item: 0.1515176147222519
train loss item: 0.12906645238399506
train loss item: 0.14719504117965698
train loss item: 0.20060570538043976
train loss item: 0.16009704768657684
train loss item: 0.1189236044883728
train loss item: 0.16525931656360626
train loss item: 0.14643144607543945
train loss item: 0.14865700900554657
train loss item: 0.1538468450307846
train loss item: 0.19555546343326569
train loss item: 0.14004799723625183
test loss item: 0.14765103161334991
test loss item: 0.13757328689098358
test loss item: 0.13159134984016418
test loss item: 0.12442218512296677
test loss item: 0.1874406635761261
test loss item: 0.1171104833483696
test loss item: 0.14637158811092377
test loss item: 0.12823855876922607
test loss item: 0.15775711834430695
test loss item: 0.20565178990364075
test loss item: 0.2000972181558609
test loss item: 0.12667933106422424
Epoch [31/100], Training Loss: 0.1548, Testing Loss: 0.1509
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 32/100
train loss item: 0.15978118777275085
train loss item: 0.1204867884516716
train loss item: 0.13818225264549255
train loss item: 0.1956159770488739
train loss item: 0.1603231430053711
train loss item: 0.11452887207269669
train loss item: 0.16927681863307953
train loss item: 0.14029087126255035
train loss item: 0.13553865253925323
train loss item: 0.14897292852401733
train loss item: 0.17731815576553345
train loss item: 0.13510240614414215
test loss item: 0.15804611146450043
test loss item: 0.1344999372959137
test loss item: 0.12921378016471863
test loss item: 0.12471381574869156
test loss item: 0.18824593722820282
test loss item: 0.11246538162231445
test loss item: 0.1450822353363037
test loss item: 0.12504619359970093
test loss item: 0.16123352944850922
test loss item: 0.19832882285118103
test loss item: 0.1980126053094864
test loss item: 0.12963759899139404
Epoch [32/100], Training Loss: 0.1496, Testing Loss: 0.1504
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 33/100
train loss item: 0.1740308701992035
train loss item: 0.13066354393959045
train loss item: 0.13403843343257904
train loss item: 0.1610058844089508
train loss item: 0.14751160144805908
train loss item: 0.1127767413854599
train loss item: 0.16463620960712433
train loss item: 0.1431112438440323
train loss item: 0.13269388675689697
train loss item: 0.16054673492908478
train loss item: 0.15987135469913483
train loss item: 0.12969572842121124
test loss item: 0.18197984993457794
test loss item: 0.1291162669658661
test loss item: 0.13707049190998077
test loss item: 0.12946459650993347
test loss item: 0.1809537708759308
test loss item: 0.11723024398088455
test loss item: 0.1422244757413864
test loss item: 0.12596279382705688
test loss item: 0.17284376919269562
test loss item: 0.1562340259552002
test loss item: 0.18816766142845154
test loss item: 0.13691364228725433
Epoch [33/100], Training Loss: 0.1459, Testing Loss: 0.1498
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 34/100
train loss item: 0.18571101129055023
train loss item: 0.15129174292087555
train loss item: 0.15346170961856842
train loss item: 0.15117745101451874
train loss item: 0.1448897421360016
train loss item: 0.11199834197759628
train loss item: 0.16556252539157867
train loss item: 0.16901829838752747
train loss item: 0.15823569893836975
train loss item: 0.22025452554225922
train loss item: 0.1557815670967102
train loss item: 0.13172771036624908
test loss item: 0.16310922801494598
test loss item: 0.12788061797618866
test loss item: 0.1345931440591812
test loss item: 0.12276944518089294
test loss item: 0.17417021095752716
test loss item: 0.11614575237035751
test loss item: 0.14048171043395996
test loss item: 0.12366388738155365
test loss item: 0.1678619086742401
test loss item: 0.1467953324317932
test loss item: 0.17747962474822998
test loss item: 0.13749107718467712
Epoch [34/100], Training Loss: 0.1583, Testing Loss: 0.1444
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 35/100
train loss item: 0.16638712584972382
train loss item: 0.14944760501384735
train loss item: 0.1642816960811615
train loss item: 0.18137924373149872
train loss item: 0.18648380041122437
train loss item: 0.1365492343902588
train loss item: 0.141911581158638
train loss item: 0.17107552289962769
train loss item: 0.1518521010875702
train loss item: 0.23689588904380798
train loss item: 0.19138745963573456
train loss item: 0.13956178724765778
test loss item: 0.15449798107147217
test loss item: 0.14530228078365326
test loss item: 0.13084986805915833
test loss item: 0.12433739006519318
test loss item: 0.1888113021850586
test loss item: 0.11683880537748337
test loss item: 0.15646032989025116
test loss item: 0.13023681938648224
test loss item: 0.16778574883937836
test loss item: 0.19305682182312012
test loss item: 0.2005782127380371
test loss item: 0.12933506071567535
Epoch [35/100], Training Loss: 0.1681, Testing Loss: 0.1532
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 36/100
train loss item: 0.16191302239894867
train loss item: 0.12631528079509735
train loss item: 0.13488657772541046
train loss item: 0.17311815917491913
train loss item: 0.2045162469148636
train loss item: 0.16469761729240417
train loss item: 0.14431987702846527
train loss item: 0.17185240983963013
train loss item: 0.12558262050151825
train loss item: 0.18525008857250214
train loss item: 0.19462616741657257
train loss item: 0.13349100947380066
test loss item: 0.19384200870990753
test loss item: 0.18722286820411682
test loss item: 0.16234536468982697
test loss item: 0.15546950697898865
test loss item: 0.2429056614637375
test loss item: 0.13002151250839233
test loss item: 0.20165754854679108
test loss item: 0.1652512550354004
test loss item: 0.21063382923603058
test loss item: 0.22908733785152435
test loss item: 0.2662985324859619
test loss item: 0.1239880695939064
Epoch [36/100], Training Loss: 0.1600, Testing Loss: 0.1891
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 37/100
train loss item: 0.17662660777568817
train loss item: 0.15001708269119263
train loss item: 0.14675714075565338
train loss item: 0.1710670441389084
train loss item: 0.16866473853588104
train loss item: 0.14587213099002838
train loss item: 0.17427505552768707
train loss item: 0.20773814618587494
train loss item: 0.14674368500709534
train loss item: 0.16350430250167847
train loss item: 0.15394575893878937
train loss item: 0.12194754928350449
test loss item: 0.20202745497226715
test loss item: 0.18553954362869263
test loss item: 0.17033688724040985
test loss item: 0.15848703682422638
test loss item: 0.24147608876228333
test loss item: 0.13757087290287018
test loss item: 0.1984260231256485
test loss item: 0.1710469275712967
test loss item: 0.21653681993484497
test loss item: 0.21373511850833893
test loss item: 0.26786646246910095
test loss item: 0.13752923905849457
Epoch [37/100], Training Loss: 0.1606, Testing Loss: 0.1917
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 38/100
train loss item: 0.17124183475971222
train loss item: 0.15503282845020294
train loss item: 0.1546521931886673
train loss item: 0.22169005870819092
train loss item: 0.15168137848377228
train loss item: 0.11319740116596222
train loss item: 0.16813470423221588
train loss item: 0.2123788446187973
train loss item: 0.1538035273551941
train loss item: 0.1595357060432434
train loss item: 0.21635814011096954
train loss item: 0.12448577582836151
test loss item: 0.1491391956806183
test loss item: 0.13887713849544525
test loss item: 0.13037434220314026
test loss item: 0.11969053000211716
test loss item: 0.17781133949756622
test loss item: 0.11785749346017838
test loss item: 0.1502314656972885
test loss item: 0.1293967366218567
test loss item: 0.1625700742006302
test loss item: 0.1696736067533493
test loss item: 0.1822987198829651
test loss item: 0.12512455880641937
Epoch [38/100], Training Loss: 0.1668, Testing Loss: 0.1461
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 39/100
train loss item: 0.15046356618404388
train loss item: 0.15664458274841309
train loss item: 0.21620652079582214
train loss item: 0.3016335964202881
train loss item: 0.20483848452568054
train loss item: 0.1110292449593544
train loss item: 0.15305493772029877
train loss item: 0.19663462042808533
train loss item: 0.13326430320739746
train loss item: 0.1920699030160904
train loss item: 0.257679283618927
train loss item: 0.12301521748304367
test loss item: 0.14642685651779175
test loss item: 0.12204848974943161
test loss item: 0.12546893954277039
test loss item: 0.11592799425125122
test loss item: 0.1700693964958191
test loss item: 0.11536676436662674
test loss item: 0.1382046490907669
test loss item: 0.12237758189439774
test loss item: 0.14901573956012726
test loss item: 0.16634631156921387
test loss item: 0.1712460070848465
test loss item: 0.1371401697397232
Epoch [39/100], Training Loss: 0.1830, Testing Loss: 0.1400
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 40/100
train loss item: 0.16250406205654144
train loss item: 0.14099407196044922
train loss item: 0.14540162682533264
train loss item: 0.24986983835697174
train loss item: 0.18125426769256592
train loss item: 0.12707580626010895
train loss item: 0.15128016471862793
train loss item: 0.18141835927963257
train loss item: 0.13273607194423676
train loss item: 0.19338564574718475
train loss item: 0.3009318709373474
train loss item: 0.1236637532711029
test loss item: 0.18064580857753754
test loss item: 0.15055684745311737
test loss item: 0.13328471779823303
test loss item: 0.138086199760437
test loss item: 0.2145266830921173
test loss item: 0.11745543777942657
test loss item: 0.1684097796678543
test loss item: 0.12919092178344727
test loss item: 0.1840449422597885
test loss item: 0.26149773597717285
test loss item: 0.23549184203147888
test loss item: 0.11948320269584656
Epoch [40/100], Training Loss: 0.1742, Testing Loss: 0.1694
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 41/100
train loss item: 0.1650848239660263
train loss item: 0.1321522295475006
train loss item: 0.1453409045934677
train loss item: 0.2190607786178589
train loss item: 0.18540628254413605
train loss item: 0.1547708511352539
train loss item: 0.1644466668367386
train loss item: 0.13513176143169403
train loss item: 0.1308935433626175
train loss item: 0.22595776617527008
train loss item: 0.36093848943710327
train loss item: 0.11771071702241898
test loss item: 0.15431863069534302
test loss item: 0.15363675355911255
test loss item: 0.12954233586788177
test loss item: 0.13216720521450043
test loss item: 0.21034905314445496
test loss item: 0.11556939035654068
test loss item: 0.16689962148666382
test loss item: 0.12931419909000397
test loss item: 0.16832824051380157
test loss item: 0.2550313472747803
test loss item: 0.23230589926242828
test loss item: 0.13916845619678497
Epoch [41/100], Training Loss: 0.1781, Testing Loss: 0.1656
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 42/100
train loss item: 0.2280053347349167
train loss item: 0.11971142888069153
train loss item: 0.12769797444343567
train loss item: 0.1586238592863083
train loss item: 0.15331104397773743
train loss item: 0.18544749915599823
train loss item: 0.2183288335800171
train loss item: 0.21663828194141388
train loss item: 0.18181639909744263
train loss item: 0.17428265511989594
train loss item: 0.22443531453609467
train loss item: 0.13007810711860657
test loss item: 0.1770389825105667
test loss item: 0.16359259188175201
test loss item: 0.1468510627746582
test loss item: 0.14196398854255676
test loss item: 0.2139257937669754
test loss item: 0.12468268722295761
test loss item: 0.178908571600914
test loss item: 0.13810181617736816
test loss item: 0.17866700887680054
test loss item: 0.1940080225467682
test loss item: 0.23361018300056458
test loss item: 0.14211668074131012
Epoch [42/100], Training Loss: 0.1765, Testing Loss: 0.1695
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 43/100
train loss item: 0.175918847322464
train loss item: 0.1389072835445404
train loss item: 0.17876741290092468
train loss item: 0.2220936417579651
train loss item: 0.17641770839691162
train loss item: 0.11303411424160004
train loss item: 0.16621257364749908
train loss item: 0.199554443359375
train loss item: 0.17218376696109772
train loss item: 0.17002074420452118
train loss item: 0.1664467602968216
train loss item: 0.14239981770515442
test loss item: 0.14189042150974274
test loss item: 0.12540358304977417
test loss item: 0.12451022863388062
test loss item: 0.11405569314956665
test loss item: 0.1655547320842743
test loss item: 0.11168821156024933
test loss item: 0.13380180299282074
test loss item: 0.11771810054779053
test loss item: 0.15174123644828796
test loss item: 0.16756443679332733
test loss item: 0.17313602566719055
test loss item: 0.12279604375362396
Epoch [43/100], Training Loss: 0.1685, Testing Loss: 0.1375
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 44/100
train loss item: 0.162436842918396
train loss item: 0.11394305527210236
train loss item: 0.14527678489685059
train loss item: 0.20953388512134552
train loss item: 0.1867896318435669
train loss item: 0.11818905174732208
train loss item: 0.13122670352458954
train loss item: 0.13806824386119843
train loss item: 0.12499770522117615
train loss item: 0.1434304416179657
train loss item: 0.15526297688484192
train loss item: 0.129337877035141
test loss item: 0.1420106440782547
test loss item: 0.12397236377000809
test loss item: 0.11744294315576553
test loss item: 0.11267243325710297
test loss item: 0.1619522124528885
test loss item: 0.10665860027074814
test loss item: 0.13619284331798553
test loss item: 0.1164538636803627
test loss item: 0.14008304476737976
test loss item: 0.14350256323814392
test loss item: 0.163675457239151
test loss item: 0.11826711893081665
Epoch [44/100], Training Loss: 0.1465, Testing Loss: 0.1319
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 45/100
train loss item: 0.19271937012672424
train loss item: 0.11472105234861374
train loss item: 0.12111511826515198
train loss item: 0.14063668251037598
train loss item: 0.1454823762178421
train loss item: 0.10815657675266266
train loss item: 0.13123004138469696
train loss item: 0.13269779086112976
train loss item: 0.11150150746107101
train loss item: 0.15702632069587708
train loss item: 0.1480519324541092
train loss item: 0.11594492197036743
test loss item: 0.1417226642370224
test loss item: 0.12975090742111206
test loss item: 0.11596307903528214
test loss item: 0.1152832880616188
test loss item: 0.1688985973596573
test loss item: 0.10435620695352554
test loss item: 0.14229334890842438
test loss item: 0.11603187769651413
test loss item: 0.14440302550792694
test loss item: 0.16186323761940002
test loss item: 0.1751445233821869
test loss item: 0.11496255546808243
Epoch [45/100], Training Loss: 0.1349, Testing Loss: 0.1359
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 46/100
train loss item: 0.1714152693748474
train loss item: 0.12118551135063171
train loss item: 0.12805065512657166
train loss item: 0.1541656255722046
train loss item: 0.1314120888710022
train loss item: 0.10289521515369415
train loss item: 0.13615839183330536
train loss item: 0.1614544689655304
train loss item: 0.11843118071556091
train loss item: 0.1744849979877472
train loss item: 0.15520991384983063
train loss item: 0.11233007907867432
test loss item: 0.13616853952407837
test loss item: 0.12377665191888809
test loss item: 0.114425428211689
test loss item: 0.11039215326309204
test loss item: 0.16253407299518585
test loss item: 0.10373497754335403
test loss item: 0.13452397286891937
test loss item: 0.11483704298734665
test loss item: 0.14480896294116974
test loss item: 0.1643826961517334
test loss item: 0.16921231150627136
test loss item: 0.12542343139648438
Epoch [46/100], Training Loss: 0.1389, Testing Loss: 0.1337
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 47/100
train loss item: 0.13878501951694489
train loss item: 0.12108875066041946
train loss item: 0.13515637814998627
train loss item: 0.18550272285938263
train loss item: 0.15808017551898956
train loss item: 0.11155170202255249
train loss item: 0.12967488169670105
train loss item: 0.16069364547729492
train loss item: 0.1211535856127739
train loss item: 0.17601653933525085
train loss item: 0.23332783579826355
train loss item: 0.11398895829916
test loss item: 0.13745561242103577
test loss item: 0.11388450860977173
test loss item: 0.11879844218492508
test loss item: 0.10582226514816284
test loss item: 0.15203924477100372
test loss item: 0.10433418303728104
test loss item: 0.12398254871368408
test loss item: 0.11491457372903824
test loss item: 0.14064288139343262
test loss item: 0.13634301722049713
test loss item: 0.15465384721755981
test loss item: 0.11878129094839096
Epoch [47/100], Training Loss: 0.1488, Testing Loss: 0.1268
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 48/100
train loss item: 0.15368494391441345
train loss item: 0.10676328092813492
train loss item: 0.1255888193845749
train loss item: 0.15582333505153656
train loss item: 0.16760089993476868
train loss item: 0.13655881583690643
train loss item: 0.15229587256908417
train loss item: 0.13103516399860382
train loss item: 0.11346525698900223
train loss item: 0.1485416740179062
train loss item: 0.2739039659500122
train loss item: 0.11088551580905914
test loss item: 0.1964835673570633
test loss item: 0.13618682324886322
test loss item: 0.15191338956356049
test loss item: 0.1352216899394989
test loss item: 0.19183219969272614
test loss item: 0.12745176255702972
test loss item: 0.1504088193178177
test loss item: 0.13653233647346497
test loss item: 0.19128885865211487
test loss item: 0.19217118620872498
test loss item: 0.21520304679870605
test loss item: 0.11339760571718216
Epoch [48/100], Training Loss: 0.1480, Testing Loss: 0.1615
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 49/100
train loss item: 0.18918268382549286
train loss item: 0.12382039427757263
train loss item: 0.13114109635353088
train loss item: 0.18844279646873474
train loss item: 0.13156567513942719
train loss item: 0.1334744691848755
train loss item: 0.16591258347034454
train loss item: 0.17890577018260956
train loss item: 0.17784151434898376
train loss item: 0.14195233583450317
train loss item: 0.1932382881641388
train loss item: 0.13519872725009918
test loss item: 0.158513605594635
test loss item: 0.13842861354351044
test loss item: 0.13341659307479858
test loss item: 0.12652400135993958
test loss item: 0.18798290193080902
test loss item: 0.11950305104255676
test loss item: 0.1488574892282486
test loss item: 0.12630289793014526
test loss item: 0.1648113876581192
test loss item: 0.20664210617542267
test loss item: 0.2011079639196396
test loss item: 0.1107938289642334
Epoch [49/100], Training Loss: 0.1576, Testing Loss: 0.1519
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 50/100
train loss item: 0.13317978382110596
train loss item: 0.11693627387285233
train loss item: 0.14995038509368896
train loss item: 0.22532056272029877
train loss item: 0.14179302752017975
train loss item: 0.10182908922433853
train loss item: 0.15622352063655853
train loss item: 0.1461845338344574
train loss item: 0.12717010080814362
train loss item: 0.14260606467723846
train loss item: 0.15841145813465118
train loss item: 0.1337430775165558
test loss item: 0.14609496295452118
test loss item: 0.11559604108333588
test loss item: 0.11443852633237839
test loss item: 0.10771264135837555
test loss item: 0.16490131616592407
test loss item: 0.09884770959615707
test loss item: 0.1239958181977272
test loss item: 0.11026378720998764
test loss item: 0.14709503948688507
test loss item: 0.17069809138774872
test loss item: 0.17202645540237427
test loss item: 0.11282573640346527
Epoch [50/100], Training Loss: 0.1444, Testing Loss: 0.1320
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 51/100
train loss item: 0.18198420107364655
train loss item: 0.1254994124174118
train loss item: 0.12289449572563171
train loss item: 0.15262220799922943
train loss item: 0.1382128745317459
train loss item: 0.09951549768447876
train loss item: 0.146144837141037
train loss item: 0.13059337437152863
train loss item: 0.11676694452762604
train loss item: 0.17129459977149963
train loss item: 0.14099499583244324
train loss item: 0.11541585624217987
test loss item: 0.14018239080905914
test loss item: 0.11391627043485641
test loss item: 0.11668213456869125
test loss item: 0.10838896036148071
test loss item: 0.15318146347999573
test loss item: 0.10216029733419418
test loss item: 0.12325222790241241
test loss item: 0.10842382907867432
test loss item: 0.14164495468139648
test loss item: 0.1302713304758072
test loss item: 0.15830104053020477
test loss item: 0.12062332779169083
Epoch [51/100], Training Loss: 0.1368, Testing Loss: 0.1264
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 52/100
train loss item: 0.14976374804973602
train loss item: 0.12208808958530426
train loss item: 0.13396866619586945
train loss item: 0.1358637809753418
train loss item: 0.1282617598772049
train loss item: 0.10150200128555298
train loss item: 0.129291832447052
train loss item: 0.13057544827461243
train loss item: 0.11660744249820709
train loss item: 0.174446240067482
train loss item: 0.14308279752731323
train loss item: 0.10802987962961197
test loss item: 0.12542010843753815
test loss item: 0.11062850058078766
test loss item: 0.11339212954044342
test loss item: 0.10303444415330887
test loss item: 0.14633050560951233
test loss item: 0.10120102763175964
test loss item: 0.12150362133979797
test loss item: 0.10516751557588577
test loss item: 0.13342450559139252
test loss item: 0.12761370837688446
test loss item: 0.14975053071975708
test loss item: 0.11534655839204788
Epoch [52/100], Training Loss: 0.1311, Testing Loss: 0.1211
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 53/100
train loss item: 0.12931375205516815
train loss item: 0.10803613066673279
train loss item: 0.11933362483978271
train loss item: 0.13406339287757874
train loss item: 0.13448871672153473
train loss item: 0.10496174544095993
train loss item: 0.1294877976179123
train loss item: 0.11818583309650421
train loss item: 0.11245757341384888
train loss item: 0.1458803117275238
train loss item: 0.1693463772535324
train loss item: 0.1092085912823677
test loss item: 0.1262461394071579
test loss item: 0.10672928392887115
test loss item: 0.10995893180370331
test loss item: 0.09977594017982483
test loss item: 0.14119738340377808
test loss item: 0.09780429303646088
test loss item: 0.11621236056089401
test loss item: 0.10442698001861572
test loss item: 0.12855441868305206
test loss item: 0.12962576746940613
test loss item: 0.14314310252666473
test loss item: 0.11538619548082352
Epoch [53/100], Training Loss: 0.1262, Testing Loss: 0.1183
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 54/100
train loss item: 0.1301480531692505
train loss item: 0.09809857606887817
train loss item: 0.11070511490106583
train loss item: 0.13103951513767242
train loss item: 0.13463188707828522
train loss item: 0.10691024363040924
train loss item: 0.14371825754642487
train loss item: 0.11459141224622726
train loss item: 0.10605667531490326
train loss item: 0.12987357378005981
train loss item: 0.16543929278850555
train loss item: 0.10411250591278076
test loss item: 0.1585119664669037
test loss item: 0.1135641559958458
test loss item: 0.12580448389053345
test loss item: 0.11115111410617828
test loss item: 0.15755707025527954
test loss item: 0.10606714338064194
test loss item: 0.1245216578245163
test loss item: 0.11729050427675247
test loss item: 0.15413716435432434
test loss item: 0.14585062861442566
test loss item: 0.16806186735630035
test loss item: 0.1145227923989296
Epoch [54/100], Training Loss: 0.1229, Testing Loss: 0.1331
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 55/100
train loss item: 0.13574503362178802
train loss item: 0.10326121747493744
train loss item: 0.10966193675994873
train loss item: 0.14503836631774902
train loss item: 0.12010064721107483
train loss item: 0.1015707477927208
train loss item: 0.14912384748458862
train loss item: 0.13799791038036346
train loss item: 0.1298777163028717
train loss item: 0.12399423867464066
train loss item: 0.14191587269306183
train loss item: 0.10807353258132935
test loss item: 0.15978080034255981
test loss item: 0.1186109259724617
test loss item: 0.1261664628982544
test loss item: 0.11628849059343338
test loss item: 0.16114696860313416
test loss item: 0.10998605936765671
test loss item: 0.12789314985275269
test loss item: 0.11605135351419449
test loss item: 0.15544670820236206
test loss item: 0.1626468449831009
test loss item: 0.17523178458213806
test loss item: 0.11139018088579178
Epoch [55/100], Training Loss: 0.1255, Testing Loss: 0.1367
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 56/100
train loss item: 0.12120425701141357
train loss item: 0.10849282145500183
train loss item: 0.1306612491607666
train loss item: 0.20340928435325623
train loss item: 0.1511455476284027
train loss item: 0.09640567004680634
train loss item: 0.1265578418970108
train loss item: 0.13363845646381378
train loss item: 0.14040756225585938
train loss item: 0.12975704669952393
train loss item: 0.1400764286518097
train loss item: 0.12566864490509033
test loss item: 0.12803207337856293
test loss item: 0.12142989039421082
test loss item: 0.1093343198299408
test loss item: 0.10733267664909363
test loss item: 0.16629020869731903
test loss item: 0.09627360850572586
test loss item: 0.12853215634822845
test loss item: 0.1056232899427414
test loss item: 0.1412263959646225
test loss item: 0.19246536493301392
test loss item: 0.1800399273633957
test loss item: 0.09952336549758911
Epoch [56/100], Training Loss: 0.1340, Testing Loss: 0.1313
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 57/100
train loss item: 0.1727433204650879
train loss item: 0.10177553445100784
train loss item: 0.12787874042987823
train loss item: 0.1960754692554474
train loss item: 0.15760134160518646
train loss item: 0.10304652899503708
train loss item: 0.14288067817687988
train loss item: 0.131332665681839
train loss item: 0.11919362097978592
train loss item: 0.1336013227701187
train loss item: 0.13501130044460297
train loss item: 0.11437626928091049
test loss item: 0.159813791513443
test loss item: 0.11650334298610687
test loss item: 0.12291568517684937
test loss item: 0.11234471201896667
test loss item: 0.16461549699306488
test loss item: 0.0994255542755127
test loss item: 0.1271904706954956
test loss item: 0.1107158362865448
test loss item: 0.15930981934070587
test loss item: 0.1358441263437271
test loss item: 0.17638006806373596
test loss item: 0.09842487424612045
Epoch [57/100], Training Loss: 0.1363, Testing Loss: 0.1320
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 58/100
train loss item: 0.20773112773895264
train loss item: 0.13603834807872772
train loss item: 0.13989880681037903
train loss item: 0.14556729793548584
train loss item: 0.13244903087615967
train loss item: 0.09757625311613083
train loss item: 0.14131183922290802
train loss item: 0.14692775905132294
train loss item: 0.128556489944458
train loss item: 0.19095981121063232
train loss item: 0.16555602848529816
train loss item: 0.11213687807321548
test loss item: 0.12494107335805893
test loss item: 0.11252819001674652
test loss item: 0.1022905632853508
test loss item: 0.10222326219081879
test loss item: 0.14609496295452118
test loss item: 0.09336940944194794
test loss item: 0.12172912061214447
test loss item: 0.10124637931585312
test loss item: 0.1305953413248062
test loss item: 0.1510162353515625
test loss item: 0.15169253945350647
test loss item: 0.1193302646279335
Epoch [58/100], Training Loss: 0.1454, Testing Loss: 0.1214
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 59/100
train loss item: 0.1564103364944458
train loss item: 0.12048318237066269
train loss item: 0.13717226684093475
train loss item: 0.15588702261447906
train loss item: 0.15816473960876465
train loss item: 0.11743731796741486
train loss item: 0.1244288980960846
train loss item: 0.13633356988430023
train loss item: 0.1167464330792427
train loss item: 0.19622895121574402
train loss item: 0.15409712493419647
train loss item: 0.11877783387899399
test loss item: 0.16311441361904144
test loss item: 0.1438751518726349
test loss item: 0.13160260021686554
test loss item: 0.12550485134124756
test loss item: 0.19199404120445251
test loss item: 0.10741043835878372
test loss item: 0.15610569715499878
test loss item: 0.13432088494300842
test loss item: 0.1716637909412384
test loss item: 0.18923597037792206
test loss item: 0.20938128232955933
test loss item: 0.12100620567798615
Epoch [59/100], Training Loss: 0.1410, Testing Loss: 0.1538
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 60/100
train loss item: 0.14688822627067566
train loss item: 0.10536790639162064
train loss item: 0.10680130124092102
train loss item: 0.1394357979297638
train loss item: 0.14701081812381744
train loss item: 0.13217604160308838
train loss item: 0.13042764365673065
train loss item: 0.14866754412651062
train loss item: 0.10903099924325943
train loss item: 0.13493426144123077
train loss item: 0.14761008322238922
train loss item: 0.10295495390892029
test loss item: 0.16959074139595032
test loss item: 0.15183287858963013
test loss item: 0.14696550369262695
test loss item: 0.13569378852844238
test loss item: 0.19372093677520752
test loss item: 0.1255050003528595
test loss item: 0.1658898890018463
test loss item: 0.14370426535606384
test loss item: 0.1808273047208786
test loss item: 0.17831435799598694
test loss item: 0.2120041847229004
test loss item: 0.10874626040458679
Epoch [60/100], Training Loss: 0.1293, Testing Loss: 0.1594
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 61/100
train loss item: 0.13981494307518005
train loss item: 0.12367669492959976
train loss item: 0.11749687790870667
train loss item: 0.1513499915599823
train loss item: 0.12783002853393555
train loss item: 0.11432736366987228
train loss item: 0.11932975053787231
train loss item: 0.1688985675573349
train loss item: 0.13520175218582153
train loss item: 0.14272306859493256
train loss item: 0.14003711938858032
train loss item: 0.1005842462182045
test loss item: 0.15389126539230347
test loss item: 0.130172997713089
test loss item: 0.13661929965019226
test loss item: 0.12389048933982849
test loss item: 0.16499634087085724
test loss item: 0.12114018946886063
test loss item: 0.1427120715379715
test loss item: 0.13016566634178162
test loss item: 0.15928225219249725
test loss item: 0.15193060040473938
test loss item: 0.17683568596839905
test loss item: 0.1126377135515213
Epoch [61/100], Training Loss: 0.1318, Testing Loss: 0.1420
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 62/100
train loss item: 0.1288592517375946
train loss item: 0.13122135400772095
train loss item: 0.14401875436306
train loss item: 0.20910988748073578
train loss item: 0.14575938880443573
train loss item: 0.09375409781932831
train loss item: 0.11133363097906113
train loss item: 0.1685427576303482
train loss item: 0.1332276314496994
train loss item: 0.1552267074584961
train loss item: 0.21107599139213562
train loss item: 0.1092667356133461
test loss item: 0.12167222052812576
test loss item: 0.11021168529987335
test loss item: 0.10544992983341217
test loss item: 0.09927348792552948
test loss item: 0.150244802236557
test loss item: 0.09425453841686249
test loss item: 0.11975333839654922
test loss item: 0.10250148922204971
test loss item: 0.12618449330329895
test loss item: 0.15850992500782013
test loss item: 0.15617406368255615
test loss item: 0.10801320523023605
Epoch [62/100], Training Loss: 0.1451, Testing Loss: 0.1210
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 63/100
train loss item: 0.1683850884437561
train loss item: 0.10424765944480896
train loss item: 0.12017402797937393
train loss item: 0.17214927077293396
train loss item: 0.13859599828720093
train loss item: 0.11703748255968094
train loss item: 0.14492952823638916
train loss item: 0.11321725696325302
train loss item: 0.11529169976711273
train loss item: 0.14856459200382233
train loss item: 0.2455880045890808
train loss item: 0.10478372871875763
test loss item: 0.13564841449260712
test loss item: 0.12825629115104675
test loss item: 0.11368132382631302
test loss item: 0.11412952095270157
test loss item: 0.16787397861480713
test loss item: 0.10133045166730881
test loss item: 0.13922041654586792
test loss item: 0.10810738801956177
test loss item: 0.14103610813617706
test loss item: 0.17693307995796204
test loss item: 0.1818254292011261
test loss item: 0.13053405284881592
Epoch [63/100], Training Loss: 0.1411, Testing Loss: 0.1365
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.172857403755188
loss item: 0.11505218595266342
loss item: 0.1305461972951889
loss item: 0.1822294443845749
loss item: 0.12270405143499374
loss item: 0.17204339802265167
Val Loss: 0.1492
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.0001 16 360 done at Tue Nov 12 14:09:03 CET 2024
UNet2 with 1 100 0.0005 16 360 start at Tue Nov 12 14:09:03 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.347920298576355
train loss item: 0.7266309261322021
train loss item: 0.7740239500999451
train loss item: 1.0496364831924438
train loss item: 1.0384632349014282
train loss item: 0.6429359912872314
train loss item: 0.7671623826026917
train loss item: 0.6212307810783386
train loss item: 0.664842963218689
train loss item: 0.7059001922607422
train loss item: 0.9865418672561646
train loss item: 0.5210573077201843
test loss item: 1.0750242471694946
test loss item: 0.8186753392219543
test loss item: 0.6963887810707092
test loss item: 0.7405107021331787
test loss item: 1.2123366594314575
test loss item: 0.5293529033660889
test loss item: 0.9360984563827515
test loss item: 0.5811087489128113
test loss item: 1.0645079612731934
test loss item: 1.5043264627456665
test loss item: 1.4069602489471436
test loss item: 0.1715167760848999
Epoch [1/100], Training Loss: 0.8205, Testing Loss: 0.8947
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/100
train loss item: 0.5976001024246216
train loss item: 0.404432475566864
train loss item: 0.46110159158706665
train loss item: 0.6248660087585449
train loss item: 0.6578819751739502
train loss item: 0.4129352867603302
train loss item: 0.5289116501808167
train loss item: 0.466266930103302
train loss item: 0.5522606372833252
train loss item: 0.5483872890472412
train loss item: 0.72178715467453
train loss item: 0.3981081545352936
test loss item: 0.6951031684875488
test loss item: 0.6855345964431763
test loss item: 0.5552680492401123
test loss item: 0.5515146255493164
test loss item: 0.9765982627868652
test loss item: 0.4372808635234833
test loss item: 0.7715692520141602
test loss item: 0.5051904916763306
test loss item: 0.7599215507507324
test loss item: 0.9974735379219055
test loss item: 1.0572090148925781
test loss item: 0.17621488869190216
Epoch [2/100], Training Loss: 0.5312, Testing Loss: 0.6807
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/100
train loss item: 0.5564646124839783
train loss item: 0.36679497361183167
train loss item: 0.46974292397499084
train loss item: 0.6266964077949524
train loss item: 0.6239770650863647
train loss item: 0.2967890799045563
train loss item: 0.5078396201133728
train loss item: 0.45546892285346985
train loss item: 0.4670780897140503
train loss item: 0.6057668328285217
train loss item: 0.5718547105789185
train loss item: 0.4719809889793396
test loss item: 0.601479709148407
test loss item: 0.36655980348587036
test loss item: 0.4381048381328583
test loss item: 0.3487030863761902
test loss item: 0.6187194585800171
test loss item: 0.3015715777873993
test loss item: 0.4195058047771454
test loss item: 0.394687682390213
test loss item: 0.5801385641098022
test loss item: 0.4605366289615631
test loss item: 0.6481929421424866
test loss item: 0.18259242177009583
Epoch [3/100], Training Loss: 0.5017, Testing Loss: 0.4467
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/100
train loss item: 0.5266653895378113
train loss item: 0.40741994976997375
train loss item: 0.38162708282470703
train loss item: 0.5175790786743164
train loss item: 0.6108929514884949
train loss item: 0.2500734329223633
train loss item: 0.48713406920433044
train loss item: 0.4424532949924469
train loss item: 0.3712909519672394
train loss item: 0.623035192489624
train loss item: 0.5140435695648193
train loss item: 0.3840923011302948
test loss item: 0.4136197865009308
test loss item: 0.43308714032173157
test loss item: 0.3077199161052704
test loss item: 0.3446415066719055
test loss item: 0.6317203044891357
test loss item: 0.255999892950058
test loss item: 0.43539324402809143
test loss item: 0.3177187740802765
test loss item: 0.49354106187820435
test loss item: 0.8454915285110474
test loss item: 0.7373334169387817
test loss item: 0.191436767578125
Epoch [4/100], Training Loss: 0.4597, Testing Loss: 0.4506
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/100
train loss item: 0.5377596020698547
train loss item: 0.3803800344467163
train loss item: 0.34885427355766296
train loss item: 0.427085816860199
train loss item: 0.5748775005340576
train loss item: 0.32408496737480164
train loss item: 0.5103691816329956
train loss item: 0.4194781184196472
train loss item: 0.2533554136753082
train loss item: 0.45544153451919556
train loss item: 0.5112985968589783
train loss item: 0.2702866196632385
test loss item: 0.4278124272823334
test loss item: 0.47967442870140076
test loss item: 0.31891247630119324
test loss item: 0.38489314913749695
test loss item: 0.6725550293922424
test loss item: 0.29462677240371704
test loss item: 0.46586382389068604
test loss item: 0.3320733308792114
test loss item: 0.5183951258659363
test loss item: 0.9548979997634888
test loss item: 0.8068073987960815
test loss item: 0.3174644410610199
Epoch [5/100], Training Loss: 0.4178, Testing Loss: 0.4978
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/100
train loss item: 0.5181736946105957
train loss item: 0.42800554633140564
train loss item: 0.3661326766014099
train loss item: 0.37522920966148376
train loss item: 0.44005200266838074
train loss item: 0.25558826327323914
train loss item: 0.4663074016571045
train loss item: 0.43790823221206665
train loss item: 0.2666897773742676
train loss item: 0.45322006940841675
train loss item: 0.5259264707565308
train loss item: 0.2524566352367401
test loss item: 0.35432830452919006
test loss item: 0.36713945865631104
test loss item: 0.2747046649456024
test loss item: 0.2919839322566986
test loss item: 0.508633553981781
test loss item: 0.24852685630321503
test loss item: 0.36112189292907715
test loss item: 0.26502853631973267
test loss item: 0.4139389991760254
test loss item: 0.6986818909645081
test loss item: 0.6084767580032349
test loss item: 0.17104218900203705
Epoch [6/100], Training Loss: 0.3988, Testing Loss: 0.3803
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/100
train loss item: 0.3896583318710327
train loss item: 0.3583512008190155
train loss item: 0.3266514539718628
train loss item: 0.38524550199508667
train loss item: 0.3888172209262848
train loss item: 0.26679396629333496
train loss item: 0.3344147205352783
train loss item: 0.3553667962551117
train loss item: 0.25212931632995605
train loss item: 0.4066944718360901
train loss item: 0.5139721632003784
train loss item: 0.24402335286140442
test loss item: 0.320365309715271
test loss item: 0.23007917404174805
test loss item: 0.22358520328998566
test loss item: 0.22027122974395752
test loss item: 0.333446741104126
test loss item: 0.18483924865722656
test loss item: 0.23355881869792938
test loss item: 0.20403698086738586
test loss item: 0.2984307110309601
test loss item: 0.3766147792339325
test loss item: 0.3809087574481964
test loss item: 0.16893626749515533
Epoch [7/100], Training Loss: 0.3518, Testing Loss: 0.2646
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/100
train loss item: 0.2900797724723816
train loss item: 0.2899520695209503
train loss item: 0.26401472091674805
train loss item: 0.334107905626297
train loss item: 0.3422606885433197
train loss item: 0.2412721812725067
train loss item: 0.2969804108142853
train loss item: 0.29403671622276306
train loss item: 0.1964939683675766
train loss item: 0.3482327461242676
train loss item: 0.42467162013053894
train loss item: 0.22400808334350586
test loss item: 0.3730446994304657
test loss item: 0.26055100560188293
test loss item: 0.2354128360748291
test loss item: 0.24335168302059174
test loss item: 0.4050275981426239
test loss item: 0.19336602091789246
test loss item: 0.27145475149154663
test loss item: 0.24156953394412994
test loss item: 0.3427569270133972
test loss item: 0.3999805450439453
test loss item: 0.4496302008628845
test loss item: 0.1622830629348755
Epoch [8/100], Training Loss: 0.2955, Testing Loss: 0.2982
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/100
train loss item: 0.29819455742836
train loss item: 0.26895251870155334
train loss item: 0.21893127262592316
train loss item: 0.284771203994751
train loss item: 0.294852614402771
train loss item: 0.17855922877788544
train loss item: 0.2619316577911377
train loss item: 0.24963027238845825
train loss item: 0.20194394886493683
train loss item: 0.3032286465167999
train loss item: 0.3323025703430176
train loss item: 0.1965257078409195
test loss item: 0.4559842050075531
test loss item: 0.26058152318000793
test loss item: 0.24353660643100739
test loss item: 0.27119266986846924
test loss item: 0.3834061920642853
test loss item: 0.19106425344944
test loss item: 0.2751503586769104
test loss item: 0.21089468896389008
test loss item: 0.4002637267112732
test loss item: 0.4550880193710327
test loss item: 0.4866703152656555
test loss item: 0.15700039267539978
Epoch [9/100], Training Loss: 0.2575, Testing Loss: 0.3159
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/100
train loss item: 0.3313371241092682
train loss item: 0.28802111744880676
train loss item: 0.21137720346450806
train loss item: 0.23959366977214813
train loss item: 0.2594589293003082
train loss item: 0.16060705482959747
train loss item: 0.2623469829559326
train loss item: 0.261530339717865
train loss item: 0.20206382870674133
train loss item: 0.3684733808040619
train loss item: 0.31196293234825134
train loss item: 0.18311436474323273
test loss item: 0.3636276423931122
test loss item: 0.2488427609205246
test loss item: 0.2089160978794098
test loss item: 0.23157237470149994
test loss item: 0.3532368242740631
test loss item: 0.16674131155014038
test loss item: 0.24989157915115356
test loss item: 0.19827574491500854
test loss item: 0.3395673334598541
test loss item: 0.43683499097824097
test loss item: 0.4441869854927063
test loss item: 0.14056706428527832
Epoch [10/100], Training Loss: 0.2567, Testing Loss: 0.2819
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 11/100
train loss item: 0.3172994554042816
train loss item: 0.2943981885910034
train loss item: 0.24461829662322998
train loss item: 0.239157572388649
train loss item: 0.3122917413711548
train loss item: 0.1966087371110916
train loss item: 0.24039490520954132
train loss item: 0.23958726227283478
train loss item: 0.2207837700843811
train loss item: 0.43334269523620605
train loss item: 0.343569278717041
train loss item: 0.20435424149036407
test loss item: 0.23126520216464996
test loss item: 0.2552446126937866
test loss item: 0.18730291724205017
test loss item: 0.20037029683589935
test loss item: 0.33272603154182434
test loss item: 0.14321403205394745
test loss item: 0.25820010900497437
test loss item: 0.18960560858249664
test loss item: 0.25864651799201965
test loss item: 0.3840022385120392
test loss item: 0.3963817358016968
test loss item: 0.13998447358608246
Epoch [11/100], Training Loss: 0.2739, Testing Loss: 0.2481
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 12/100
train loss item: 0.2267128825187683
train loss item: 0.1885334849357605
train loss item: 0.2006455659866333
train loss item: 0.21038185060024261
train loss item: 0.29058578610420227
train loss item: 0.2637898921966553
train loss item: 0.16738426685333252
train loss item: 0.1728293001651764
train loss item: 0.16569721698760986
train loss item: 0.3510734736919403
train loss item: 0.3778233528137207
train loss item: 0.14504744112491608
test loss item: 0.22262537479400635
test loss item: 0.22845987975597382
test loss item: 0.18320035934448242
test loss item: 0.18712612986564636
test loss item: 0.30803337693214417
test loss item: 0.14417488873004913
test loss item: 0.23869960010051727
test loss item: 0.1794324368238449
test loss item: 0.24052555859088898
test loss item: 0.3185957074165344
test loss item: 0.34794101119041443
test loss item: 0.13624520599842072
Epoch [12/100], Training Loss: 0.2300, Testing Loss: 0.2279
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 13/100
train loss item: 0.19430477917194366
train loss item: 0.20257769525051117
train loss item: 0.16778281331062317
train loss item: 0.21569930016994476
train loss item: 0.25873661041259766
train loss item: 0.2005169838666916
train loss item: 0.1941172480583191
train loss item: 0.1814965456724167
train loss item: 0.15334013104438782
train loss item: 0.28319236636161804
train loss item: 0.20741470158100128
train loss item: 0.16872893273830414
test loss item: 0.22409820556640625
test loss item: 0.24997803568840027
test loss item: 0.1611500084400177
test loss item: 0.19392690062522888
test loss item: 0.33816441893577576
test loss item: 0.13650290668010712
test loss item: 0.25905659794807434
test loss item: 0.17245642840862274
test loss item: 0.2675410211086273
test loss item: 0.46137937903404236
test loss item: 0.41881683468818665
test loss item: 0.1507956087589264
Epoch [13/100], Training Loss: 0.2023, Testing Loss: 0.2528
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 14/100
train loss item: 0.25602707266807556
train loss item: 0.15526042878627777
train loss item: 0.16293711960315704
train loss item: 0.18311382830142975
train loss item: 0.21905536949634552
train loss item: 0.1899208277463913
train loss item: 0.1683693826198578
train loss item: 0.15738649666309357
train loss item: 0.14074259996414185
train loss item: 0.2790276110172272
train loss item: 0.26980292797088623
train loss item: 0.13513047993183136
test loss item: 0.2354670763015747
test loss item: 0.2575245499610901
test loss item: 0.15838979184627533
test loss item: 0.213461235165596
test loss item: 0.33097413182258606
test loss item: 0.135234072804451
test loss item: 0.26151135563850403
test loss item: 0.18180106580257416
test loss item: 0.2636595368385315
test loss item: 0.4199168086051941
test loss item: 0.4017721712589264
test loss item: 0.196289524435997
Epoch [14/100], Training Loss: 0.1931, Testing Loss: 0.2547
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 15/100
train loss item: 0.2292671948671341
train loss item: 0.21449093520641327
train loss item: 0.20764541625976562
train loss item: 0.199575275182724
train loss item: 0.24083155393600464
train loss item: 0.19494132697582245
train loss item: 0.27762195467948914
train loss item: 0.21805809438228607
train loss item: 0.15988875925540924
train loss item: 0.28354665637016296
train loss item: 0.2564166486263275
train loss item: 0.16859067976474762
test loss item: 0.3006569743156433
test loss item: 0.3706344664096832
test loss item: 0.2029949277639389
test loss item: 0.27177006006240845
test loss item: 0.5041607618331909
test loss item: 0.18254782259464264
test loss item: 0.39179304242134094
test loss item: 0.22954751551151276
test loss item: 0.38425809144973755
test loss item: 0.7302683591842651
test loss item: 0.6334853172302246
test loss item: 0.12026305496692657
Epoch [15/100], Training Loss: 0.2209, Testing Loss: 0.3602
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 16/100
train loss item: 0.31527629494667053
train loss item: 0.18586377799510956
train loss item: 0.16870439052581787
train loss item: 0.20734794437885284
train loss item: 0.2478432059288025
train loss item: 0.1786477118730545
train loss item: 0.15856574475765228
train loss item: 0.16189569234848022
train loss item: 0.13570019602775574
train loss item: 0.24297848343849182
train loss item: 0.24012596905231476
train loss item: 0.135133296251297
test loss item: 0.28658634424209595
test loss item: 0.23321311175823212
test loss item: 0.17673687636852264
test loss item: 0.203798308968544
test loss item: 0.3382575809955597
test loss item: 0.15669415891170502
test loss item: 0.25894293189048767
test loss item: 0.18379025161266327
test loss item: 0.27749139070510864
test loss item: 0.38697054982185364
test loss item: 0.38229110836982727
test loss item: 0.12324150651693344
Epoch [16/100], Training Loss: 0.1982, Testing Loss: 0.2507
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 17/100
train loss item: 0.20575426518917084
train loss item: 0.22177399694919586
train loss item: 0.19342154264450073
train loss item: 0.2436654269695282
train loss item: 0.2076922357082367
train loss item: 0.16562870144844055
train loss item: 0.30233675241470337
train loss item: 0.3268299996852875
train loss item: 0.15787860751152039
train loss item: 0.32411226630210876
train loss item: 0.2369581162929535
train loss item: 0.16162578761577606
test loss item: 0.28081831336021423
test loss item: 0.35278987884521484
test loss item: 0.22470220923423767
test loss item: 0.27353426814079285
test loss item: 0.4605652689933777
test loss item: 0.1991993486881256
test loss item: 0.3676659166812897
test loss item: 0.24460479617118835
test loss item: 0.3347383737564087
test loss item: 0.5819656848907471
test loss item: 0.5586283802986145
test loss item: 0.154598668217659
Epoch [17/100], Training Loss: 0.2290, Testing Loss: 0.3362
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 18/100
train loss item: 0.26976916193962097
train loss item: 0.2836006283760071
train loss item: 0.2149098813533783
train loss item: 0.27852240204811096
train loss item: 0.29189565777778625
train loss item: 0.18533603847026825
train loss item: 0.2775908410549164
train loss item: 0.37145623564720154
train loss item: 0.21493636071681976
train loss item: 0.40627604722976685
train loss item: 0.3785817325115204
train loss item: 0.1866263449192047
test loss item: 0.3490235209465027
test loss item: 0.30502527952194214
test loss item: 0.28634560108184814
test loss item: 0.24670863151550293
test loss item: 0.42708727717399597
test loss item: 0.17113466560840607
test loss item: 0.3052835762500763
test loss item: 0.2745756208896637
test loss item: 0.3847156763076782
test loss item: 0.38331174850463867
test loss item: 0.5056861042976379
test loss item: 0.14688682556152344
Epoch [18/100], Training Loss: 0.2800, Testing Loss: 0.3155
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 19/100
train loss item: 0.25941649079322815
train loss item: 0.2767918109893799
train loss item: 0.2455497831106186
train loss item: 0.37559792399406433
train loss item: 0.3087151050567627
train loss item: 0.27355825901031494
train loss item: 0.287615031003952
train loss item: 0.347504585981369
train loss item: 0.2143738865852356
train loss item: 0.34375694394111633
train loss item: 0.5195976495742798
train loss item: 0.14652599394321442
test loss item: 0.27969199419021606
test loss item: 0.19079846143722534
test loss item: 0.22753377258777618
test loss item: 0.17180682718753815
test loss item: 0.2709243893623352
test loss item: 0.15861156582832336
test loss item: 0.203426331281662
test loss item: 0.21738874912261963
test loss item: 0.27701616287231445
test loss item: 0.19661493599414825
test loss item: 0.27903926372528076
test loss item: 0.25979533791542053
Epoch [19/100], Training Loss: 0.2999, Testing Loss: 0.2277
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 20/100
train loss item: 0.3207132816314697
train loss item: 0.19198599457740784
train loss item: 0.22655542194843292
train loss item: 0.3650714159011841
train loss item: 0.27836355566978455
train loss item: 0.3218759000301361
train loss item: 0.20851482450962067
train loss item: 0.18713787198066711
train loss item: 0.19846892356872559
train loss item: 0.27172574400901794
train loss item: 0.5682986378669739
train loss item: 0.1870092898607254
test loss item: 0.22471113502979279
test loss item: 0.24132755398750305
test loss item: 0.1877758502960205
test loss item: 0.18784378468990326
test loss item: 0.32272154092788696
test loss item: 0.16431014239788055
test loss item: 0.266796737909317
test loss item: 0.16498467326164246
test loss item: 0.2560300827026367
test loss item: 0.396428644657135
test loss item: 0.34960824251174927
test loss item: 0.1566811352968216
Epoch [20/100], Training Loss: 0.2771, Testing Loss: 0.2433
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 21/100
train loss item: 0.36483311653137207
train loss item: 0.13222050666809082
train loss item: 0.16247008740901947
train loss item: 0.21500131487846375
train loss item: 0.18290828168392181
train loss item: 0.28007960319519043
train loss item: 0.2098878175020218
train loss item: 0.21871380507946014
train loss item: 0.20451143383979797
train loss item: 0.16778352856636047
train loss item: 0.39069896936416626
train loss item: 0.15958207845687866
test loss item: 0.19964458048343658
test loss item: 0.19445742666721344
test loss item: 0.16115021705627441
test loss item: 0.16614830493927002
test loss item: 0.24295084178447723
test loss item: 0.13556906580924988
test loss item: 0.19725240767002106
test loss item: 0.14761687815189362
test loss item: 0.19361522793769836
test loss item: 0.22166432440280914
test loss item: 0.2702315151691437
test loss item: 0.24430489540100098
Epoch [21/100], Training Loss: 0.2241, Testing Loss: 0.1979
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 22/100
train loss item: 0.2620703876018524
train loss item: 0.14673325419425964
train loss item: 0.16115672886371613
train loss item: 0.21747533977031708
train loss item: 0.173495352268219
train loss item: 0.18291907012462616
train loss item: 0.18570812046527863
train loss item: 0.17163453996181488
train loss item: 0.18776527047157288
train loss item: 0.1893610805273056
train loss item: 0.35770556330680847
train loss item: 0.1255807727575302
test loss item: 0.2196696698665619
test loss item: 0.17166920006275177
test loss item: 0.1646527200937271
test loss item: 0.15934967994689941
test loss item: 0.2202671766281128
test loss item: 0.14697808027267456
test loss item: 0.17769712209701538
test loss item: 0.1414482146501541
test loss item: 0.20431537926197052
test loss item: 0.19467267394065857
test loss item: 0.24427710473537445
test loss item: 0.1708427369594574
Epoch [22/100], Training Loss: 0.1968, Testing Loss: 0.1847
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 23/100
train loss item: 0.217006653547287
train loss item: 0.17211146652698517
train loss item: 0.15574534237384796
train loss item: 0.18851961195468903
train loss item: 0.1821197271347046
train loss item: 0.1406295895576477
train loss item: 0.15106265246868134
train loss item: 0.13912825286388397
train loss item: 0.1484285444021225
train loss item: 0.2145688682794571
train loss item: 0.35513433814048767
train loss item: 0.13741278648376465
test loss item: 0.22905132174491882
test loss item: 0.13549308478832245
test loss item: 0.1292019635438919
test loss item: 0.1323872208595276
test loss item: 0.18657894432544708
test loss item: 0.10754908621311188
test loss item: 0.1481916755437851
test loss item: 0.11548587679862976
test loss item: 0.18713659048080444
test loss item: 0.17279615998268127
test loss item: 0.20203211903572083
test loss item: 0.11662444472312927
Epoch [23/100], Training Loss: 0.1835, Testing Loss: 0.1552
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 24/100
train loss item: 0.17618490755558014
train loss item: 0.14486998319625854
train loss item: 0.11357355862855911
train loss item: 0.16722804307937622
train loss item: 0.17792928218841553
train loss item: 0.12027346342802048
train loss item: 0.14838199317455292
train loss item: 0.13544972240924835
train loss item: 0.10870446264743805
train loss item: 0.19451527297496796
train loss item: 0.30985286831855774
train loss item: 0.13215632736682892
test loss item: 0.23366808891296387
test loss item: 0.12226169556379318
test loss item: 0.12720467150211334
test loss item: 0.13210006058216095
test loss item: 0.16932925581932068
test loss item: 0.10655218362808228
test loss item: 0.13218465447425842
test loss item: 0.11454010754823685
test loss item: 0.1845441609621048
test loss item: 0.1452489197254181
test loss item: 0.18623106181621552
test loss item: 0.11510007828474045
Epoch [24/100], Training Loss: 0.1608, Testing Loss: 0.1474
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 25/100
train loss item: 0.17160287499427795
train loss item: 0.15570300817489624
train loss item: 0.11424495279788971
train loss item: 0.1496916264295578
train loss item: 0.15704289078712463
train loss item: 0.11276107281446457
train loss item: 0.15511582791805267
train loss item: 0.16031497716903687
train loss item: 0.12099987268447876
train loss item: 0.20045211911201477
train loss item: 0.23665912449359894
train loss item: 0.1194608062505722
test loss item: 0.24887484312057495
test loss item: 0.15089969336986542
test loss item: 0.13743582367897034
test loss item: 0.1581801474094391
test loss item: 0.2076951563358307
test loss item: 0.11277837306261063
test loss item: 0.16338063776493073
test loss item: 0.1311255395412445
test loss item: 0.20242007076740265
test loss item: 0.19371984899044037
test loss item: 0.23953065276145935
test loss item: 0.10778879374265671
Epoch [25/100], Training Loss: 0.1545, Testing Loss: 0.1712
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 26/100
train loss item: 0.2029525339603424
train loss item: 0.20071347057819366
train loss item: 0.16231366991996765
train loss item: 0.1640118509531021
train loss item: 0.14527252316474915
train loss item: 0.11862727254629135
train loss item: 0.18682007491588593
train loss item: 0.20921732485294342
train loss item: 0.15679267048835754
train loss item: 0.3237321972846985
train loss item: 0.2193525731563568
train loss item: 0.1237349659204483
test loss item: 0.14916649460792542
test loss item: 0.1444281041622162
test loss item: 0.12102807313203812
test loss item: 0.1167895495891571
test loss item: 0.19978442788124084
test loss item: 0.10202264785766602
test loss item: 0.15391506254673004
test loss item: 0.1221851333975792
test loss item: 0.1544816493988037
test loss item: 0.2162126749753952
test loss item: 0.21806269884109497
test loss item: 0.08909064531326294
Epoch [26/100], Training Loss: 0.1845, Testing Loss: 0.1489
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 27/100
train loss item: 0.17954079806804657
train loss item: 0.16852307319641113
train loss item: 0.16060879826545715
train loss item: 0.19783242046833038
train loss item: 0.21716168522834778
train loss item: 0.17269662022590637
train loss item: 0.1484375149011612
train loss item: 0.19777385890483856
train loss item: 0.13872885704040527
train loss item: 0.33189141750335693
train loss item: 0.24605265259742737
train loss item: 0.11156419664621353
test loss item: 0.24034245312213898
test loss item: 0.15694956481456757
test loss item: 0.16225135326385498
test loss item: 0.15192604064941406
test loss item: 0.22331589460372925
test loss item: 0.13154840469360352
test loss item: 0.1679067760705948
test loss item: 0.1463402658700943
test loss item: 0.21940548717975616
test loss item: 0.24045081436634064
test loss item: 0.26728683710098267
test loss item: 0.12496989965438843
Epoch [27/100], Training Loss: 0.1892, Testing Loss: 0.1861
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 28/100
train loss item: 0.16541732847690582
train loss item: 0.12918928265571594
train loss item: 0.13052815198898315
train loss item: 0.22159096598625183
train loss item: 0.23699061572551727
train loss item: 0.19310984015464783
train loss item: 0.2038535177707672
train loss item: 0.23517245054244995
train loss item: 0.1498258113861084
train loss item: 0.27223846316337585
train loss item: 0.3003944456577301
train loss item: 0.1063462570309639
test loss item: 0.2964567542076111
test loss item: 0.19050200283527374
test loss item: 0.21349914371967316
test loss item: 0.1943351924419403
test loss item: 0.2598925828933716
test loss item: 0.1782897412776947
test loss item: 0.20081961154937744
test loss item: 0.20478560030460358
test loss item: 0.2858685553073883
test loss item: 0.2247215211391449
test loss item: 0.29767850041389465
test loss item: 0.24884147942066193
Epoch [28/100], Training Loss: 0.1954, Testing Loss: 0.2330
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 29/100
train loss item: 0.20009814202785492
train loss item: 0.15865547955036163
train loss item: 0.21363294124603271
train loss item: 0.3732195496559143
train loss item: 0.2912859320640564
train loss item: 0.1778484582901001
train loss item: 0.1885698139667511
train loss item: 0.1891663670539856
train loss item: 0.17185190320014954
train loss item: 0.2621529996395111
train loss item: 0.5332651734352112
train loss item: 0.16389891505241394
test loss item: 0.2340860217809677
test loss item: 0.2657734751701355
test loss item: 0.1752435564994812
test loss item: 0.2001711130142212
test loss item: 0.35650092363357544
test loss item: 0.1369500756263733
test loss item: 0.28859052062034607
test loss item: 0.17003671824932098
test loss item: 0.29698237776756287
test loss item: 0.5029795169830322
test loss item: 0.41393154859542847
test loss item: 0.12249845266342163
Epoch [29/100], Training Loss: 0.2436, Testing Loss: 0.2636
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 30/100
train loss item: 0.35966557264328003
train loss item: 0.1306314617395401
train loss item: 0.14667284488677979
train loss item: 0.19034965336322784
train loss item: 0.1653202325105667
train loss item: 0.22775350511074066
train loss item: 0.23785506188869476
train loss item: 0.2500312030315399
train loss item: 0.19640874862670898
train loss item: 0.211267352104187
train loss item: 0.2889578640460968
train loss item: 0.11924313008785248
test loss item: 0.18468117713928223
test loss item: 0.15929311513900757
test loss item: 0.13604450225830078
test loss item: 0.14560341835021973
test loss item: 0.19782759249210358
test loss item: 0.11930834501981735
test loss item: 0.17608150839805603
test loss item: 0.12449813634157181
test loss item: 0.17218393087387085
test loss item: 0.18676765263080597
test loss item: 0.2049609124660492
test loss item: 0.17899970710277557
Epoch [30/100], Training Loss: 0.2103, Testing Loss: 0.1655
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 31/100
train loss item: 0.22667616605758667
train loss item: 0.14689527451992035
train loss item: 0.1845187395811081
train loss item: 0.17201703786849976
train loss item: 0.1617608368396759
train loss item: 0.14425069093704224
train loss item: 0.19697603583335876
train loss item: 0.1717427670955658
train loss item: 0.1418168842792511
train loss item: 0.20597615838050842
train loss item: 0.28731104731559753
train loss item: 0.12274780869483948
test loss item: 0.19091209769248962
test loss item: 0.17465290427207947
test loss item: 0.1497299075126648
test loss item: 0.14683502912521362
test loss item: 0.21731555461883545
test loss item: 0.13077080249786377
test loss item: 0.17949119210243225
test loss item: 0.13165400922298431
test loss item: 0.19263553619384766
test loss item: 0.21783363819122314
test loss item: 0.24023030698299408
test loss item: 0.1818627119064331
Epoch [31/100], Training Loss: 0.1802, Testing Loss: 0.1795
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 32/100
train loss item: 0.19876882433891296
train loss item: 0.1642792522907257
train loss item: 0.1411244124174118
train loss item: 0.15431393682956696
train loss item: 0.1510152667760849
train loss item: 0.11647459864616394
train loss item: 0.15615010261535645
train loss item: 0.14037370681762695
train loss item: 0.14043596386909485
train loss item: 0.22809210419654846
train loss item: 0.2778332829475403
train loss item: 0.1313638985157013
test loss item: 0.16404347121715546
test loss item: 0.1600804179906845
test loss item: 0.13252529501914978
test loss item: 0.12596681714057922
test loss item: 0.2113916426897049
test loss item: 0.1137113943696022
test loss item: 0.16931097209453583
test loss item: 0.12290510535240173
test loss item: 0.17152181267738342
test loss item: 0.20442073047161102
test loss item: 0.22323690354824066
test loss item: 0.1191941648721695
Epoch [32/100], Training Loss: 0.1667, Testing Loss: 0.1599
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 33/100
train loss item: 0.15478050708770752
train loss item: 0.12580591440200806
train loss item: 0.1208493709564209
train loss item: 0.13703902065753937
train loss item: 0.15809854865074158
train loss item: 0.11207647621631622
train loss item: 0.14303724467754364
train loss item: 0.14050474762916565
train loss item: 0.10934610664844513
train loss item: 0.21664303541183472
train loss item: 0.2644852101802826
train loss item: 0.09828098863363266
test loss item: 0.13377349078655243
test loss item: 0.12273938953876495
test loss item: 0.10554268956184387
test loss item: 0.10077463090419769
test loss item: 0.15740056335926056
test loss item: 0.09057708084583282
test loss item: 0.12971028685569763
test loss item: 0.09478987008333206
test loss item: 0.1368514746427536
test loss item: 0.17256632447242737
test loss item: 0.1592230349779129
test loss item: 0.10273721069097519
Epoch [33/100], Training Loss: 0.1484, Testing Loss: 0.1256
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 34/100
train loss item: 0.12896427512168884
train loss item: 0.10759790241718292
train loss item: 0.1085328683257103
train loss item: 0.12970763444900513
train loss item: 0.1433587372303009
train loss item: 0.09456846117973328
train loss item: 0.12675178050994873
train loss item: 0.1211523488163948
train loss item: 0.09740926325321198
train loss item: 0.18296116590499878
train loss item: 0.2299118936061859
train loss item: 0.10482637584209442
test loss item: 0.1312922239303589
test loss item: 0.11106428503990173
test loss item: 0.10048435628414154
test loss item: 0.09862746298313141
test loss item: 0.1397337019443512
test loss item: 0.0911102220416069
test loss item: 0.11306803673505783
test loss item: 0.09794106334447861
test loss item: 0.125344380736351
test loss item: 0.14332209527492523
test loss item: 0.133637934923172
test loss item: 0.14210902154445648
Epoch [34/100], Training Loss: 0.1313, Testing Loss: 0.1190
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 35/100
train loss item: 0.13144317269325256
train loss item: 0.1216917559504509
train loss item: 0.10563895106315613
train loss item: 0.12136386334896088
train loss item: 0.1268334537744522
train loss item: 0.0969618633389473
train loss item: 0.12691356241703033
train loss item: 0.12250105291604996
train loss item: 0.11108918488025665
train loss item: 0.17169521749019623
train loss item: 0.19013038277626038
train loss item: 0.09633579850196838
test loss item: 0.13036848604679108
test loss item: 0.10149838775396347
test loss item: 0.09715361893177032
test loss item: 0.09282617270946503
test loss item: 0.12626172602176666
test loss item: 0.08758816123008728
test loss item: 0.10121641308069229
test loss item: 0.09286399930715561
test loss item: 0.11776687204837799
test loss item: 0.12211155891418457
test loss item: 0.12397637963294983
test loss item: 0.11436495929956436
Epoch [35/100], Training Loss: 0.1269, Testing Loss: 0.1090
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 36/100
train loss item: 0.1396559476852417
train loss item: 0.13946376740932465
train loss item: 0.1284625381231308
train loss item: 0.14896659553050995
train loss item: 0.1417877972126007
train loss item: 0.1173359751701355
train loss item: 0.12225750088691711
train loss item: 0.13956359028816223
train loss item: 0.11168336868286133
train loss item: 0.22024662792682648
train loss item: 0.18960897624492645
train loss item: 0.09403733164072037
test loss item: 0.11568517982959747
test loss item: 0.10392504185438156
test loss item: 0.09595438092947006
test loss item: 0.08891573548316956
test loss item: 0.13300448656082153
test loss item: 0.08503678441047668
test loss item: 0.10809376835823059
test loss item: 0.09438180923461914
test loss item: 0.11349748075008392
test loss item: 0.12930260598659515
test loss item: 0.13266322016716003
test loss item: 0.09117487072944641
Epoch [36/100], Training Loss: 0.1411, Testing Loss: 0.1076
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 37/100
train loss item: 0.12820369005203247
train loss item: 0.10130570828914642
train loss item: 0.10135501623153687
train loss item: 0.15636783838272095
train loss item: 0.1637996882200241
train loss item: 0.11258899420499802
train loss item: 0.11222293972969055
train loss item: 0.13862428069114685
train loss item: 0.11124049872159958
train loss item: 0.1992412656545639
train loss item: 0.20241877436637878
train loss item: 0.08745084702968597
test loss item: 0.13915890455245972
test loss item: 0.11292102932929993
test loss item: 0.11115425825119019
test loss item: 0.10164887458086014
test loss item: 0.1436581313610077
test loss item: 0.09158671647310257
test loss item: 0.11759833991527557
test loss item: 0.10233364999294281
test loss item: 0.13256710767745972
test loss item: 0.13355731964111328
test loss item: 0.15171322226524353
test loss item: 0.11605606973171234
Epoch [37/100], Training Loss: 0.1346, Testing Loss: 0.1212
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 38/100
train loss item: 0.11472360789775848
train loss item: 0.10322249680757523
train loss item: 0.10818144679069519
train loss item: 0.17263539135456085
train loss item: 0.19625510275363922
train loss item: 0.1184910461306572
train loss item: 0.10571300238370895
train loss item: 0.1336950659751892
train loss item: 0.10952499508857727
train loss item: 0.21084313094615936
train loss item: 0.2612185478210449
train loss item: 0.09076201170682907
test loss item: 0.2273925542831421
test loss item: 0.1644924283027649
test loss item: 0.16917100548744202
test loss item: 0.14867916703224182
test loss item: 0.22467699646949768
test loss item: 0.13105659186840057
test loss item: 0.170846626162529
test loss item: 0.16211459040641785
test loss item: 0.22525320947170258
test loss item: 0.19887255132198334
test loss item: 0.25013843178749084
test loss item: 0.15253569185733795
Epoch [38/100], Training Loss: 0.1438, Testing Loss: 0.1854
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 39/100
train loss item: 0.1607949584722519
train loss item: 0.1314951628446579
train loss item: 0.12290964275598526
train loss item: 0.14728915691375732
train loss item: 0.19835205376148224
train loss item: 0.1568068265914917
train loss item: 0.16102413833141327
train loss item: 0.19479988515377045
train loss item: 0.14439499378204346
train loss item: 0.20791088044643402
train loss item: 0.23335401713848114
train loss item: 0.10145141184329987
test loss item: 0.30404171347618103
test loss item: 0.2066052109003067
test loss item: 0.23020772635936737
test loss item: 0.19644063711166382
test loss item: 0.2779695689678192
test loss item: 0.16579602658748627
test loss item: 0.22099138796329498
test loss item: 0.2077360898256302
test loss item: 0.30104291439056396
test loss item: 0.21907301247119904
test loss item: 0.32655069231987
test loss item: 0.11242067068815231
Epoch [39/100], Training Loss: 0.1634, Testing Loss: 0.2307
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 40/100
train loss item: 0.1573908030986786
train loss item: 0.15919049084186554
train loss item: 0.16009056568145752
train loss item: 0.1869448721408844
train loss item: 0.1331542283296585
train loss item: 0.14867368340492249
train loss item: 0.14014950394630432
train loss item: 0.1884050965309143
train loss item: 0.1764656901359558
train loss item: 0.13686874508857727
train loss item: 0.22426556050777435
train loss item: 0.11190672963857651
test loss item: 0.20118893682956696
test loss item: 0.13466709852218628
test loss item: 0.15866206586360931
test loss item: 0.13102374970912933
test loss item: 0.19096772372722626
test loss item: 0.13388337194919586
test loss item: 0.15110532939434052
test loss item: 0.13894037902355194
test loss item: 0.1906917691230774
test loss item: 0.16100867092609406
test loss item: 0.1960618644952774
test loss item: 0.12599925696849823
Epoch [40/100], Training Loss: 0.1603, Testing Loss: 0.1595
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 41/100
train loss item: 0.13548949360847473
train loss item: 0.12298563122749329
train loss item: 0.17134907841682434
train loss item: 0.27990323305130005
train loss item: 0.16465677320957184
train loss item: 0.10853983461856842
train loss item: 0.1299944669008255
train loss item: 0.15878693759441376
train loss item: 0.1316942572593689
train loss item: 0.16933460533618927
train loss item: 0.3250367343425751
train loss item: 0.09298740327358246
test loss item: 0.1676567792892456
test loss item: 0.16348516941070557
test loss item: 0.12327099591493607
test loss item: 0.13327458500862122
test loss item: 0.20888827741146088
test loss item: 0.10972335934638977
test loss item: 0.1678825169801712
test loss item: 0.11397717893123627
test loss item: 0.17450201511383057
test loss item: 0.258985698223114
test loss item: 0.23490211367607117
test loss item: 0.19776245951652527
Epoch [41/100], Training Loss: 0.1659, Testing Loss: 0.1712
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 42/100
train loss item: 0.2009177953004837
train loss item: 0.11744093149900436
train loss item: 0.1270202398300171
train loss item: 0.21079345047473907
train loss item: 0.1746170073747635
train loss item: 0.1368580013513565
train loss item: 0.1339014619588852
train loss item: 0.11605127155780792
train loss item: 0.11594703793525696
train loss item: 0.1919279545545578
train loss item: 0.3731151819229126
train loss item: 0.09919024258852005
test loss item: 0.18468725681304932
test loss item: 0.20553293824195862
test loss item: 0.15304529666900635
test loss item: 0.1600513905286789
test loss item: 0.26639944314956665
test loss item: 0.13341453671455383
test loss item: 0.22128625214099884
test loss item: 0.1362035572528839
test loss item: 0.208727166056633
test loss item: 0.3333834409713745
test loss item: 0.29088476300239563
test loss item: 0.11915957182645798
Epoch [42/100], Training Loss: 0.1665, Testing Loss: 0.2011
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 43/100
train loss item: 0.23930829763412476
train loss item: 0.11259867995977402
train loss item: 0.09642112255096436
train loss item: 0.1298806369304657
train loss item: 0.14578808844089508
train loss item: 0.15781643986701965
train loss item: 0.16501961648464203
train loss item: 0.1455746293067932
train loss item: 0.10440090298652649
train loss item: 0.1428431272506714
train loss item: 0.4144996404647827
train loss item: 0.09270403534173965
test loss item: 0.22642013430595398
test loss item: 0.24853679537773132
test loss item: 0.16533784568309784
test loss item: 0.19238795340061188
test loss item: 0.3253186047077179
test loss item: 0.13730746507644653
test loss item: 0.26834383606910706
test loss item: 0.15284790098667145
test loss item: 0.2564377188682556
test loss item: 0.42497915029525757
test loss item: 0.3748615086078644
test loss item: 0.14472784101963043
Epoch [43/100], Training Loss: 0.1622, Testing Loss: 0.2431
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 44/100
train loss item: 0.2889626622200012
train loss item: 0.13805387914180756
train loss item: 0.1746683418750763
train loss item: 0.24869176745414734
train loss item: 0.19080667197704315
train loss item: 0.1312776505947113
train loss item: 0.20593605935573578
train loss item: 0.2642033100128174
train loss item: 0.27794554829597473
train loss item: 0.31771227717399597
train loss item: 0.1513063609600067
train loss item: 0.186780646443367
test loss item: 0.18485033512115479
test loss item: 0.13084061443805695
test loss item: 0.14826197922229767
test loss item: 0.13649766147136688
test loss item: 0.17146091163158417
test loss item: 0.13051781058311462
test loss item: 0.13994760811328888
test loss item: 0.1210443302989006
test loss item: 0.17521430552005768
test loss item: 0.16756851971149445
test loss item: 0.19806261360645294
test loss item: 0.20878438651561737
Epoch [44/100], Training Loss: 0.2147, Testing Loss: 0.1594
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 45/100
train loss item: 0.1477920413017273
train loss item: 0.10839498043060303
train loss item: 0.17637544870376587
train loss item: 0.27615126967430115
train loss item: 0.24509160220623016
train loss item: 0.11206376552581787
train loss item: 0.11999333649873734
train loss item: 0.14452910423278809
train loss item: 0.15503737330436707
train loss item: 0.15481802821159363
train loss item: 0.13580983877182007
train loss item: 0.12150128930807114
test loss item: 0.19970294833183289
test loss item: 0.1243426650762558
test loss item: 0.13066190481185913
test loss item: 0.12724556028842926
test loss item: 0.1817503273487091
test loss item: 0.10883580148220062
test loss item: 0.13246344029903412
test loss item: 0.11347032338380814
test loss item: 0.184164896607399
test loss item: 0.20279040932655334
test loss item: 0.2149786651134491
test loss item: 0.10824225097894669
Epoch [45/100], Training Loss: 0.1581, Testing Loss: 0.1524
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 46/100
train loss item: 0.1926269829273224
train loss item: 0.11076889932155609
train loss item: 0.12105980515480042
train loss item: 0.14387796819210052
train loss item: 0.13935218751430511
train loss item: 0.09092511981725693
train loss item: 0.12376462668180466
train loss item: 0.1272224336862564
train loss item: 0.11031939089298248
train loss item: 0.14422382414340973
train loss item: 0.17269738018512726
train loss item: 0.10529918968677521
test loss item: 0.1923479586839676
test loss item: 0.11345108598470688
test loss item: 0.13432945311069489
test loss item: 0.11660842597484589
test loss item: 0.15844804048538208
test loss item: 0.11032682657241821
test loss item: 0.11663678288459778
test loss item: 0.11073417216539383
test loss item: 0.1703176200389862
test loss item: 0.14183881878852844
test loss item: 0.18105646967887878
test loss item: 0.13268394768238068
Epoch [46/100], Training Loss: 0.1318, Testing Loss: 0.1399
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.17000789940357208
loss item: 0.1583174616098404
loss item: 0.14136309921741486
loss item: 0.21437571942806244
loss item: 0.13890773057937622
loss item: 0.1725272387266159
Val Loss: 0.1659
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.0005 16 360 done at Tue Nov 12 14:20:15 CET 2024
UNet2 with 1 100 0.001 16 360 start at Tue Nov 12 14:20:15 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 100, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.347920298576355
train loss item: 0.8370859026908875
train loss item: 0.8084253072738647
train loss item: 1.0543510913848877
train loss item: 1.0508748292922974
train loss item: 0.6788036227226257
train loss item: 0.7902345657348633
train loss item: 0.6473392248153687
train loss item: 0.6429446935653687
train loss item: 0.6882081031799316
train loss item: 1.0367460250854492
train loss item: 0.5191578269004822
test loss item: 0.9778003692626953
test loss item: 0.7433786392211914
test loss item: 0.6972929835319519
test loss item: 0.6537982225418091
test loss item: 1.131282091140747
test loss item: 0.519782304763794
test loss item: 0.8478103876113892
test loss item: 0.5860170722007751
test loss item: 0.9901925325393677
test loss item: 1.297985553741455
test loss item: 1.2556926012039185
test loss item: 0.17182914912700653
Epoch [1/100], Training Loss: 0.8418, Testing Loss: 0.8227
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/100
train loss item: 0.6870045065879822
train loss item: 0.437121719121933
train loss item: 0.5212539434432983
train loss item: 0.6843154430389404
train loss item: 0.7345481514930725
train loss item: 0.512938380241394
train loss item: 0.6113349199295044
train loss item: 0.5482794642448425
train loss item: 0.6063655614852905
train loss item: 0.7168950438499451
train loss item: 0.8421348929405212
train loss item: 0.512139081954956
test loss item: 0.8918981552124023
test loss item: 0.7481124401092529
test loss item: 0.7143771052360535
test loss item: 0.6122287511825562
test loss item: 1.1233980655670166
test loss item: 0.4065004587173462
test loss item: 0.7986811399459839
test loss item: 0.6681426167488098
test loss item: 0.9690775275230408
test loss item: 0.8580244779586792
test loss item: 1.2461336851119995
test loss item: 0.19154666364192963
Epoch [2/100], Training Loss: 0.6179, Testing Loss: 0.7690
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/100
train loss item: 0.613661527633667
train loss item: 0.3876442015171051
train loss item: 0.5079360604286194
train loss item: 0.6969730854034424
train loss item: 0.7612075805664062
train loss item: 0.34873825311660767
train loss item: 0.5601683855056763
train loss item: 0.47940751910209656
train loss item: 0.49898993968963623
train loss item: 0.7060378789901733
train loss item: 0.6820985674858093
train loss item: 0.4819062054157257
test loss item: 0.5004900097846985
test loss item: 0.41489967703819275
test loss item: 0.41026756167411804
test loss item: 0.3806145191192627
test loss item: 0.6262808442115784
test loss item: 0.31133750081062317
test loss item: 0.46288323402404785
test loss item: 0.3499935269355774
test loss item: 0.5363754630088806
test loss item: 0.6676885485649109
test loss item: 0.6843309998512268
test loss item: 0.22901223599910736
Epoch [3/100], Training Loss: 0.5604, Testing Loss: 0.4645
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/100
train loss item: 0.546330451965332
train loss item: 0.3251984119415283
train loss item: 0.41699960827827454
train loss item: 0.6140895485877991
train loss item: 0.7110395431518555
train loss item: 0.285971999168396
train loss item: 0.5470634698867798
train loss item: 0.44887563586235046
train loss item: 0.38121354579925537
train loss item: 0.616769552230835
train loss item: 0.604049563407898
train loss item: 0.38655224442481995
test loss item: 0.45867496728897095
test loss item: 0.41642317175865173
test loss item: 0.3588094115257263
test loss item: 0.3668524920940399
test loss item: 0.6289511919021606
test loss item: 0.2742162048816681
test loss item: 0.46091228723526
test loss item: 0.31385862827301025
test loss item: 0.5181570053100586
test loss item: 0.798516571521759
test loss item: 0.71230149269104
test loss item: 0.1940988451242447
Epoch [4/100], Training Loss: 0.4903, Testing Loss: 0.4585
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/100
train loss item: 0.5705771446228027
train loss item: 0.38813474774360657
train loss item: 0.40440067648887634
train loss item: 0.5409359931945801
train loss item: 0.6260098218917847
train loss item: 0.25902798771858215
train loss item: 0.5231205224990845
train loss item: 0.457897424697876
train loss item: 0.34611424803733826
train loss item: 0.6021536588668823
train loss item: 0.572413444519043
train loss item: 0.3504672348499298
test loss item: 0.43738314509391785
test loss item: 0.4616278409957886
test loss item: 0.30745837092399597
test loss item: 0.37562763690948486
test loss item: 0.6606745719909668
test loss item: 0.245477095246315
test loss item: 0.4786258041858673
test loss item: 0.3009518086910248
test loss item: 0.4934687912464142
test loss item: 0.9134602546691895
test loss item: 0.7783374190330505
test loss item: 0.1953534334897995
Epoch [5/100], Training Loss: 0.4701, Testing Loss: 0.4707
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/100
train loss item: 0.5306140780448914
train loss item: 0.404539555311203
train loss item: 0.3953021168708801
train loss item: 0.47662824392318726
train loss item: 0.5741168260574341
train loss item: 0.27004164457321167
train loss item: 0.5187265276908875
train loss item: 0.47141313552856445
train loss item: 0.2612839639186859
train loss item: 0.5263849496841431
train loss item: 0.5454187989234924
train loss item: 0.3349376916885376
test loss item: 0.5808173418045044
test loss item: 0.5291622281074524
test loss item: 0.3615439236164093
test loss item: 0.4391302168369293
test loss item: 0.7497478723526001
test loss item: 0.2648063004016876
test loss item: 0.5461210608482361
test loss item: 0.35485032200813293
test loss item: 0.5854452252388
test loss item: 0.9823623299598694
test loss item: 0.9200889468193054
test loss item: 0.18086408078670502
Epoch [6/100], Training Loss: 0.4425, Testing Loss: 0.5412
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/100
train loss item: 0.5485209226608276
train loss item: 0.42131683230400085
train loss item: 0.3515545129776001
train loss item: 0.4201355278491974
train loss item: 0.5138422846794128
train loss item: 0.2468743920326233
train loss item: 0.4660016894340515
train loss item: 0.45813512802124023
train loss item: 0.29082855582237244
train loss item: 0.569748044013977
train loss item: 0.49976375699043274
train loss item: 0.30982232093811035
test loss item: 0.44801175594329834
test loss item: 0.44548383355140686
test loss item: 0.3117457628250122
test loss item: 0.3642146587371826
test loss item: 0.6183643341064453
test loss item: 0.22815892100334167
test loss item: 0.4583989679813385
test loss item: 0.3081454038619995
test loss item: 0.47969818115234375
test loss item: 0.7825171947479248
test loss item: 0.7431410551071167
test loss item: 0.1632446050643921
Epoch [7/100], Training Loss: 0.4247, Testing Loss: 0.4459
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/100
train loss item: 0.5111298561096191
train loss item: 0.43715018033981323
train loss item: 0.3500712215900421
train loss item: 0.3360290825366974
train loss item: 0.49091699719429016
train loss item: 0.30034351348876953
train loss item: 0.45800310373306274
train loss item: 0.4246000349521637
train loss item: 0.2300773561000824
train loss item: 0.5420607924461365
train loss item: 0.43600305914878845
train loss item: 0.3060809075832367
test loss item: 0.49206408858299255
test loss item: 0.5972764492034912
test loss item: 0.3494582176208496
test loss item: 0.44817814230918884
test loss item: 0.8030426502227783
test loss item: 0.2667052447795868
test loss item: 0.6053668260574341
test loss item: 0.3881642818450928
test loss item: 0.5984923243522644
test loss item: 1.0664254426956177
test loss item: 0.9821213483810425
test loss item: 0.16873690485954285
Epoch [8/100], Training Loss: 0.4019, Testing Loss: 0.5638
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/100
train loss item: 0.4918334186077118
train loss item: 0.3641921281814575
train loss item: 0.3128960132598877
train loss item: 0.32590168714523315
train loss item: 0.4262162744998932
train loss item: 0.2840878963470459
train loss item: 0.41964489221572876
train loss item: 0.41278818249702454
train loss item: 0.21011501550674438
train loss item: 0.4610602557659149
train loss item: 0.39802923798561096
train loss item: 0.22589319944381714
test loss item: 0.4289657175540924
test loss item: 0.4702092111110687
test loss item: 0.30574843287467957
test loss item: 0.36977875232696533
test loss item: 0.6457378268241882
test loss item: 0.22876080870628357
test loss item: 0.4843390882015228
test loss item: 0.30492493510246277
test loss item: 0.498197078704834
test loss item: 0.8597763776779175
test loss item: 0.795756459236145
test loss item: 0.12968245148658752
Epoch [9/100], Training Loss: 0.3611, Testing Loss: 0.4602
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/100
train loss item: 0.4792887568473816
train loss item: 0.38106417655944824
train loss item: 0.3331315815448761
train loss item: 0.31095901131629944
train loss item: 0.35327792167663574
train loss item: 0.26468899846076965
train loss item: 0.43810415267944336
train loss item: 0.43464234471321106
train loss item: 0.1933470368385315
train loss item: 0.45436325669288635
train loss item: 0.45448604226112366
train loss item: 0.20138409733772278
test loss item: 0.378557413816452
test loss item: 0.3190152049064636
test loss item: 0.2637653350830078
test loss item: 0.2725422978401184
test loss item: 0.4659784138202667
test loss item: 0.19039663672447205
test loss item: 0.3344622850418091
test loss item: 0.2634918987751007
test loss item: 0.3954746723175049
test loss item: 0.5872600078582764
test loss item: 0.5481988191604614
test loss item: 0.18809859454631805
Epoch [10/100], Training Loss: 0.3582, Testing Loss: 0.3506
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 11/100
train loss item: 0.34091123938560486
train loss item: 0.25989004969596863
train loss item: 0.24766837060451508
train loss item: 0.32728466391563416
train loss item: 0.31135690212249756
train loss item: 0.2694796919822693
train loss item: 0.27718213200569153
train loss item: 0.32858651876449585
train loss item: 0.18336495757102966
train loss item: 0.432973712682724
train loss item: 0.4638262391090393
train loss item: 0.1856430470943451
test loss item: 0.29057466983795166
test loss item: 0.2198108285665512
test loss item: 0.2140624076128006
test loss item: 0.20049233734607697
test loss item: 0.30734801292419434
test loss item: 0.17742373049259186
test loss item: 0.21903370320796967
test loss item: 0.18922343850135803
test loss item: 0.2775275707244873
test loss item: 0.3320898115634918
test loss item: 0.3574010729789734
test loss item: 0.14916175603866577
Epoch [11/100], Training Loss: 0.3023, Testing Loss: 0.2445
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 12/100
train loss item: 0.26797300577163696
train loss item: 0.20704364776611328
train loss item: 0.2062753289937973
train loss item: 0.32076770067214966
train loss item: 0.2592514157295227
train loss item: 0.2655622065067291
train loss item: 0.23307177424430847
train loss item: 0.2548776865005493
train loss item: 0.1760919988155365
train loss item: 0.39668333530426025
train loss item: 0.41061750054359436
train loss item: 0.16584055125713348
test loss item: 0.23175077140331268
test loss item: 0.18697617948055267
test loss item: 0.21379424631595612
test loss item: 0.16172325611114502
test loss item: 0.26121389865875244
test loss item: 0.178610160946846
test loss item: 0.20607323944568634
test loss item: 0.1815870702266693
test loss item: 0.2327868491411209
test loss item: 0.2298361361026764
test loss item: 0.2680814564228058
test loss item: 0.1477915495634079
Epoch [12/100], Training Loss: 0.2637, Testing Loss: 0.2084
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 13/100
train loss item: 0.2506021559238434
train loss item: 0.20138245820999146
train loss item: 0.17670059204101562
train loss item: 0.30291682481765747
train loss item: 0.22953657805919647
train loss item: 0.17480529844760895
train loss item: 0.20245470106601715
train loss item: 0.2253994643688202
train loss item: 0.17429380118846893
train loss item: 0.34937697649002075
train loss item: 0.34352320432662964
train loss item: 0.21568575501441956
test loss item: 0.26994383335113525
test loss item: 0.19755128026008606
test loss item: 0.17844101786613464
test loss item: 0.18345646560192108
test loss item: 0.2694757282733917
test loss item: 0.1395280361175537
test loss item: 0.21449024975299835
test loss item: 0.17136594653129578
test loss item: 0.24233226478099823
test loss item: 0.2549078166484833
test loss item: 0.3039521872997284
test loss item: 0.106666699051857
Epoch [13/100], Training Loss: 0.2372, Testing Loss: 0.2110
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 14/100
train loss item: 0.2744986414909363
train loss item: 0.23497983813285828
train loss item: 0.17469662427902222
train loss item: 0.26891517639160156
train loss item: 0.20477695763111115
train loss item: 0.1567867398262024
train loss item: 0.18532881140708923
train loss item: 0.19906897842884064
train loss item: 0.15486754477024078
train loss item: 0.318975031375885
train loss item: 0.2898411750793457
train loss item: 0.14720362424850464
test loss item: 0.33124881982803345
test loss item: 0.2405378371477127
test loss item: 0.1998247355222702
test loss item: 0.2208709716796875
test loss item: 0.33316171169281006
test loss item: 0.15657706558704376
test loss item: 0.2702596187591553
test loss item: 0.18782490491867065
test loss item: 0.29606813192367554
test loss item: 0.3701034188270569
test loss item: 0.40827128291130066
test loss item: 0.2104354053735733
Epoch [14/100], Training Loss: 0.2175, Testing Loss: 0.2688
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 15/100
train loss item: 0.33817681670188904
train loss item: 0.27796289324760437
train loss item: 0.1847597062587738
train loss item: 0.23229336738586426
train loss item: 0.22824017703533173
train loss item: 0.16383010149002075
train loss item: 0.2486160546541214
train loss item: 0.23771809041500092
train loss item: 0.14491134881973267
train loss item: 0.3230583369731903
train loss item: 0.2525938153266907
train loss item: 0.17307709157466888
test loss item: 0.38393980264663696
test loss item: 0.29568910598754883
test loss item: 0.23588554561138153
test loss item: 0.25772881507873535
test loss item: 0.41834864020347595
test loss item: 0.18206462264060974
test loss item: 0.3289894461631775
test loss item: 0.23135007917881012
test loss item: 0.3718310296535492
test loss item: 0.5091582536697388
test loss item: 0.5060586929321289
test loss item: 0.19946610927581787
Epoch [15/100], Training Loss: 0.2338, Testing Loss: 0.3267
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 16/100
train loss item: 0.3811604976654053
train loss item: 0.2741315960884094
train loss item: 0.18793100118637085
train loss item: 0.25414663553237915
train loss item: 0.22447453439235687
train loss item: 0.14960308372974396
train loss item: 0.26869311928749084
train loss item: 0.33522093296051025
train loss item: 0.20773117244243622
train loss item: 0.41099804639816284
train loss item: 0.3529629111289978
train loss item: 0.15657243132591248
test loss item: 0.28861767053604126
test loss item: 0.16890092194080353
test loss item: 0.1923225224018097
test loss item: 0.1816859096288681
test loss item: 0.22485186159610748
test loss item: 0.16621123254299164
test loss item: 0.1794818490743637
test loss item: 0.16218294203281403
test loss item: 0.25499042868614197
test loss item: 0.21784254908561707
test loss item: 0.26391980051994324
test loss item: 0.09007052332162857
Epoch [16/100], Training Loss: 0.2670, Testing Loss: 0.1993
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 17/100
train loss item: 0.2253950834274292
train loss item: 0.2655256390571594
train loss item: 0.22593043744564056
train loss item: 0.2864189147949219
train loss item: 0.25861239433288574
train loss item: 0.21121099591255188
train loss item: 0.17955893278121948
train loss item: 0.26513946056365967
train loss item: 0.1637117862701416
train loss item: 0.4326312839984894
train loss item: 0.3935685157775879
train loss item: 0.1813148856163025
test loss item: 0.2106311321258545
test loss item: 0.1806282252073288
test loss item: 0.19273605942726135
test loss item: 0.15352624654769897
test loss item: 0.2387845814228058
test loss item: 0.1419937014579773
test loss item: 0.19069145619869232
test loss item: 0.1760341227054596
test loss item: 0.22091074287891388
test loss item: 0.19388321042060852
test loss item: 0.2547161281108856
test loss item: 0.1367136687040329
Epoch [17/100], Training Loss: 0.2574, Testing Loss: 0.1909
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 18/100
train loss item: 0.17997565865516663
train loss item: 0.21333718299865723
train loss item: 0.1530962437391281
train loss item: 0.22329086065292358
train loss item: 0.2715027332305908
train loss item: 0.2707867920398712
train loss item: 0.17352281510829926
train loss item: 0.18004460632801056
train loss item: 0.17284318804740906
train loss item: 0.34525513648986816
train loss item: 0.37292778491973877
train loss item: 0.14403942227363586
test loss item: 0.26924070715904236
test loss item: 0.20375321805477142
test loss item: 0.21412579715251923
test loss item: 0.18567144870758057
test loss item: 0.2796746492385864
test loss item: 0.15150608122348785
test loss item: 0.22396142780780792
test loss item: 0.1893395334482193
test loss item: 0.26925238966941833
test loss item: 0.2800956070423126
test loss item: 0.3162517547607422
test loss item: 0.11793560534715652
Epoch [18/100], Training Loss: 0.2251, Testing Loss: 0.2251
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 19/100
train loss item: 0.20409566164016724
train loss item: 0.14908777177333832
train loss item: 0.14243152737617493
train loss item: 0.1748049259185791
train loss item: 0.2191704362630844
train loss item: 0.24003487825393677
train loss item: 0.15915021300315857
train loss item: 0.16759434342384338
train loss item: 0.15592744946479797
train loss item: 0.29769811034202576
train loss item: 0.32799866795539856
train loss item: 0.1284954994916916
test loss item: 0.24754798412322998
test loss item: 0.1760140210390091
test loss item: 0.1876339465379715
test loss item: 0.15753145515918732
test loss item: 0.23897922039031982
test loss item: 0.1302335113286972
test loss item: 0.19489160180091858
test loss item: 0.17552363872528076
test loss item: 0.2491372525691986
test loss item: 0.20871590077877045
test loss item: 0.2614661157131195
test loss item: 0.11439353227615356
Epoch [19/100], Training Loss: 0.1972, Testing Loss: 0.1952
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 20/100
train loss item: 0.19377277791500092
train loss item: 0.15784186124801636
train loss item: 0.14478915929794312
train loss item: 0.16784101724624634
train loss item: 0.17609813809394836
train loss item: 0.16866856813430786
train loss item: 0.14055384695529938
train loss item: 0.1664038449525833
train loss item: 0.14882095158100128
train loss item: 0.31214243173599243
train loss item: 0.25499609112739563
train loss item: 0.1268780529499054
test loss item: 0.20558200776576996
test loss item: 0.1874481439590454
test loss item: 0.16207586228847504
test loss item: 0.15147265791893005
test loss item: 0.24078594148159027
test loss item: 0.11577073484659195
test loss item: 0.19301217794418335
test loss item: 0.15793399512767792
test loss item: 0.21627099812030792
test loss item: 0.2378593534231186
test loss item: 0.2893185019493103
test loss item: 0.13087451457977295
Epoch [20/100], Training Loss: 0.1799, Testing Loss: 0.1907
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 21/100
train loss item: 0.23627743124961853
train loss item: 0.164353147149086
train loss item: 0.13977167010307312
train loss item: 0.14910699427127838
train loss item: 0.16611945629119873
train loss item: 0.12767842411994934
train loss item: 0.12915313243865967
train loss item: 0.15361431241035461
train loss item: 0.12265125662088394
train loss item: 0.27918514609336853
train loss item: 0.2362329363822937
train loss item: 0.1126144602894783
test loss item: 0.1614297330379486
test loss item: 0.1564835160970688
test loss item: 0.12915949523448944
test loss item: 0.12856292724609375
test loss item: 0.20231196284294128
test loss item: 0.11113760620355606
test loss item: 0.17977634072303772
test loss item: 0.12212482839822769
test loss item: 0.17440581321716309
test loss item: 0.23810988664627075
test loss item: 0.2301017940044403
test loss item: 0.1249595582485199
Epoch [21/100], Training Loss: 0.1681, Testing Loss: 0.1632
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 22/100
train loss item: 0.21409107744693756
train loss item: 0.17439444363117218
train loss item: 0.15747693181037903
train loss item: 0.16264234483242035
train loss item: 0.14907142519950867
train loss item: 0.1340736597776413
train loss item: 0.17759504914283752
train loss item: 0.18569204211235046
train loss item: 0.12986735999584198
train loss item: 0.25671762228012085
train loss item: 0.1556224822998047
train loss item: 0.1214323565363884
test loss item: 0.19513992965221405
test loss item: 0.21316087245941162
test loss item: 0.14310237765312195
test loss item: 0.1616053283214569
test loss item: 0.28998643159866333
test loss item: 0.12202199548482895
test loss item: 0.23484915494918823
test loss item: 0.15054930746555328
test loss item: 0.23536960780620575
test loss item: 0.3916502296924591
test loss item: 0.35014453530311584
test loss item: 0.13110648095607758
Epoch [22/100], Training Loss: 0.1682, Testing Loss: 0.2182
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 23/100
train loss item: 0.328875869512558
train loss item: 0.21907112002372742
train loss item: 0.1383725255727768
train loss item: 0.21896079182624817
train loss item: 0.18854983150959015
train loss item: 0.10877993702888489
train loss item: 0.19852879643440247
train loss item: 0.2570568919181824
train loss item: 0.15817956626415253
train loss item: 0.3286781907081604
train loss item: 0.3120822608470917
train loss item: 0.13803225755691528
test loss item: 0.18520469963550568
test loss item: 0.16260705888271332
test loss item: 0.1371738314628601
test loss item: 0.1496633142232895
test loss item: 0.20692749321460724
test loss item: 0.1277133971452713
test loss item: 0.18225796520709991
test loss item: 0.13604480028152466
test loss item: 0.17703160643577576
test loss item: 0.20408497750759125
test loss item: 0.2180858701467514
test loss item: 0.15486527979373932
Epoch [23/100], Training Loss: 0.2163, Testing Loss: 0.1701
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 24/100
train loss item: 0.16767238080501556
train loss item: 0.21762891113758087
train loss item: 0.19963021576404572
train loss item: 0.28042730689048767
train loss item: 0.3005080223083496
train loss item: 0.254790335893631
train loss item: 0.18085652589797974
train loss item: 0.2362305074930191
train loss item: 0.1753704845905304
train loss item: 0.36332595348358154
train loss item: 0.39047157764434814
train loss item: 0.16671916842460632
test loss item: 0.30904415249824524
test loss item: 0.21858732402324677
test loss item: 0.23232834041118622
test loss item: 0.19700880348682404
test loss item: 0.3005659580230713
test loss item: 0.15817099809646606
test loss item: 0.23437073826789856
test loss item: 0.20530231297016144
test loss item: 0.3200102746486664
test loss item: 0.3166443407535553
test loss item: 0.35165661573410034
test loss item: 0.11489560455083847
Epoch [24/100], Training Loss: 0.2445, Testing Loss: 0.2465
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 25/100
train loss item: 0.24024303257465363
train loss item: 0.19017353653907776
train loss item: 0.18293803930282593
train loss item: 0.19928522408008575
train loss item: 0.19717080891132355
train loss item: 0.25391626358032227
train loss item: 0.1938941478729248
train loss item: 0.21141386032104492
train loss item: 0.21470046043395996
train loss item: 0.2643406391143799
train loss item: 0.30106714367866516
train loss item: 0.1195983812212944
test loss item: 0.3121930658817291
test loss item: 0.1772414743900299
test loss item: 0.212669238448143
test loss item: 0.17593707144260406
test loss item: 0.2634463310241699
test loss item: 0.15381431579589844
test loss item: 0.19693876802921295
test loss item: 0.19785341620445251
test loss item: 0.2776634395122528
test loss item: 0.2037520408630371
test loss item: 0.2951624393463135
test loss item: 0.15019941329956055
Epoch [25/100], Training Loss: 0.2141, Testing Loss: 0.2181
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 26/100
train loss item: 0.2409367561340332
train loss item: 0.15793457627296448
train loss item: 0.14045272767543793
train loss item: 0.16449519991874695
train loss item: 0.16046597063541412
train loss item: 0.19500160217285156
train loss item: 0.15510763227939606
train loss item: 0.17838704586029053
train loss item: 0.1693679690361023
train loss item: 0.27989551424980164
train loss item: 0.28776049613952637
train loss item: 0.11636319756507874
test loss item: 0.24786794185638428
test loss item: 0.14945830404758453
test loss item: 0.17450548708438873
test loss item: 0.14826123416423798
test loss item: 0.21202436089515686
test loss item: 0.13596026599407196
test loss item: 0.1622452586889267
test loss item: 0.1547694355249405
test loss item: 0.2301880419254303
test loss item: 0.19099636375904083
test loss item: 0.24164287745952606
test loss item: 0.13829700648784637
Epoch [26/100], Training Loss: 0.1872, Testing Loss: 0.1822
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 27/100
train loss item: 0.16444149613380432
train loss item: 0.12137268483638763
train loss item: 0.11987564712762833
train loss item: 0.22202260792255402
train loss item: 0.19223549962043762
train loss item: 0.16945801675319672
train loss item: 0.14472776651382446
train loss item: 0.18703877925872803
train loss item: 0.15852417051792145
train loss item: 0.28058838844299316
train loss item: 0.2910574674606323
train loss item: 0.10708411782979965
test loss item: 0.2996656000614166
test loss item: 0.14956314861774445
test loss item: 0.19233985245227814
test loss item: 0.1685274988412857
test loss item: 0.21766343712806702
test loss item: 0.15056221187114716
test loss item: 0.1588829755783081
test loss item: 0.1629474014043808
test loss item: 0.2597469091415405
test loss item: 0.17858116328716278
test loss item: 0.25363942980766296
test loss item: 0.1120266318321228
Epoch [27/100], Training Loss: 0.1799, Testing Loss: 0.1920
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 28/100
train loss item: 0.1336228847503662
train loss item: 0.1113918125629425
train loss item: 0.12916584312915802
train loss item: 0.2421288639307022
train loss item: 0.2064080834388733
train loss item: 0.13703051209449768
train loss item: 0.11800765991210938
train loss item: 0.18433700501918793
train loss item: 0.1536189168691635
train loss item: 0.2897200286388397
train loss item: 0.35407310724258423
train loss item: 0.09547962993383408
test loss item: 0.2947978377342224
test loss item: 0.16919942200183868
test loss item: 0.18921558558940887
test loss item: 0.1739828735589981
test loss item: 0.24550655484199524
test loss item: 0.13952787220478058
test loss item: 0.18158066272735596
test loss item: 0.1551927626132965
test loss item: 0.2663910686969757
test loss item: 0.26928818225860596
test loss item: 0.29109853506088257
test loss item: 0.1291351616382599
Epoch [28/100], Training Loss: 0.1796, Testing Loss: 0.2087
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 29/100
train loss item: 0.1778113692998886
train loss item: 0.13215023279190063
train loss item: 0.15744367241859436
train loss item: 0.2463727444410324
train loss item: 0.20441143214702606
train loss item: 0.1576526165008545
train loss item: 0.15549907088279724
train loss item: 0.19347365200519562
train loss item: 0.19962170720100403
train loss item: 0.2777585983276367
train loss item: 0.3948097229003906
train loss item: 0.10908716171979904
test loss item: 0.316965788602829
test loss item: 0.2284168004989624
test loss item: 0.2267095148563385
test loss item: 0.21011604368686676
test loss item: 0.3185534179210663
test loss item: 0.18117855489253998
test loss item: 0.2547733187675476
test loss item: 0.1964251846075058
test loss item: 0.3141787052154541
test loss item: 0.39374732971191406
test loss item: 0.37044453620910645
test loss item: 0.14500100910663605
Epoch [29/100], Training Loss: 0.2005, Testing Loss: 0.2630
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 30/100
train loss item: 0.23142842948436737
train loss item: 0.13505099713802338
train loss item: 0.15496692061424255
train loss item: 0.20851746201515198
train loss item: 0.1907699704170227
train loss item: 0.21210016310214996
train loss item: 0.16353067755699158
train loss item: 0.1815955638885498
train loss item: 0.23188260197639465
train loss item: 0.21196381747722626
train loss item: 0.4198347330093384
train loss item: 0.10158523172140121
test loss item: 0.18986761569976807
test loss item: 0.19645783305168152
test loss item: 0.15890398621559143
test loss item: 0.15984457731246948
test loss item: 0.2626645863056183
test loss item: 0.13866746425628662
test loss item: 0.21376103162765503
test loss item: 0.145263671875
test loss item: 0.20747077465057373
test loss item: 0.3207768499851227
test loss item: 0.2745562791824341
test loss item: 0.16972386837005615
Epoch [30/100], Training Loss: 0.2036, Testing Loss: 0.2032
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 31/100
train loss item: 0.2736998498439789
train loss item: 0.13768886029720306
train loss item: 0.1437382996082306
train loss item: 0.2241775244474411
train loss item: 0.1686737835407257
train loss item: 0.1997911036014557
train loss item: 0.15596742928028107
train loss item: 0.1538398712873459
train loss item: 0.20543040335178375
train loss item: 0.17258387804031372
train loss item: 0.39874541759490967
train loss item: 0.12658067047595978
test loss item: 0.19693268835544586
test loss item: 0.20329619944095612
test loss item: 0.14054733514785767
test loss item: 0.1589382290840149
test loss item: 0.2529319226741791
test loss item: 0.12646250426769257
test loss item: 0.21741095185279846
test loss item: 0.1316642314195633
test loss item: 0.20997348427772522
test loss item: 0.301488995552063
test loss item: 0.28962045907974243
test loss item: 0.23527102172374725
Epoch [31/100], Training Loss: 0.1967, Testing Loss: 0.2054
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.27611199021339417
loss item: 0.15143173933029175
loss item: 0.20859384536743164
loss item: 0.29386475682258606
loss item: 0.15016327798366547
loss item: 0.2750909626483917
Val Loss: 0.2259
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.001, epochs: 100, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.001 16 360 done at Tue Nov 12 14:27:38 CET 2024
UNet2 with 1 100 0.005 16 360 start at Tue Nov 12 14:27:38 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 100, batch size: 16
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
train loss item: 1.347920298576355
train loss item: 1.5687456130981445
train loss item: 1.631877064704895
train loss item: 1.4319086074829102
train loss item: 1.4138485193252563
train loss item: 0.546890914440155
train loss item: 1.3041961193084717
train loss item: 1.0380523204803467
train loss item: 0.5293318033218384
train loss item: 0.9218611121177673
train loss item: 1.3710566759109497
train loss item: 0.6858503222465515
test loss item: 3.2003939151763916
test loss item: 2.154862403869629
test loss item: 2.522993803024292
test loss item: 2.072277545928955
test loss item: 3.261380672454834
test loss item: 1.5580440759658813
test loss item: 2.3153131008148193
test loss item: 2.2654213905334473
test loss item: 3.346027135848999
test loss item: 2.5312631130218506
test loss item: 3.6369071006774902
test loss item: 0.8985705375671387
Epoch [1/100], Training Loss: 1.1493, Testing Loss: 2.4803
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 92.00 MB
Epoch 2/100
train loss item: 0.7554489970207214
train loss item: 0.5311941504478455
train loss item: 0.6179863810539246
train loss item: 0.8203991651535034
train loss item: 0.9779049754142761
train loss item: 0.4623931050300598
train loss item: 0.8516811728477478
train loss item: 0.6761479377746582
train loss item: 0.5962315201759338
train loss item: 0.8352209329605103
train loss item: 1.0741273164749146
train loss item: 0.5220564603805542
test loss item: 7.790459156036377
test loss item: 3.576235055923462
test loss item: 5.013566970825195
test loss item: 3.944175958633423
test loss item: 6.5662665367126465
test loss item: 2.6617796421051025
test loss item: 3.747519016265869
test loss item: 4.292668342590332
test loss item: 7.04976749420166
test loss item: 4.14107084274292
test loss item: 7.614866733551025
test loss item: 2.846034288406372
Epoch [2/100], Training Loss: 0.7267, Testing Loss: 4.9370
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 3/100
train loss item: 0.6863020062446594
train loss item: 0.4426109492778778
train loss item: 0.5799510478973389
train loss item: 0.7794153094291687
train loss item: 0.8928535580635071
train loss item: 0.4278809726238251
train loss item: 0.7807832360267639
train loss item: 0.6580387949943542
train loss item: 0.5662275552749634
train loss item: 0.7435731291770935
train loss item: 1.0109055042266846
train loss item: 0.5526444315910339
test loss item: 1.330809473991394
test loss item: 0.8935152292251587
test loss item: 1.0789555311203003
test loss item: 0.7761048674583435
test loss item: 1.531236171722412
test loss item: 0.6736292243003845
test loss item: 0.9920744299888611
test loss item: 0.9261553287506104
test loss item: 1.3865399360656738
test loss item: 1.3352049589157104
test loss item: 1.6601319313049316
test loss item: 0.309951514005661
Epoch [3/100], Training Loss: 0.6768, Testing Loss: 1.0745
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 4/100
train loss item: 0.6887794733047485
train loss item: 0.49422547221183777
train loss item: 0.5770339369773865
train loss item: 0.7572455406188965
train loss item: 0.8831947445869446
train loss item: 0.4058489203453064
train loss item: 0.7843759059906006
train loss item: 0.6657115817070007
train loss item: 0.43560850620269775
train loss item: 0.7632137537002563
train loss item: 0.9187833666801453
train loss item: 0.4459364414215088
test loss item: 0.7054656744003296
test loss item: 0.6305694580078125
test loss item: 0.48126721382141113
test loss item: 0.5342040061950684
test loss item: 0.9173663258552551
test loss item: 0.39502623677253723
test loss item: 0.699359655380249
test loss item: 0.43536514043807983
test loss item: 0.7231936454772949
test loss item: 1.195124626159668
test loss item: 1.0048640966415405
test loss item: 0.3020661771297455
Epoch [4/100], Training Loss: 0.6517, Testing Loss: 0.6687
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 5/100
train loss item: 0.6609570384025574
train loss item: 0.4887945055961609
train loss item: 0.5706380009651184
train loss item: 0.7161975502967834
train loss item: 0.8125241994857788
train loss item: 0.37361499667167664
train loss item: 0.7603998184204102
train loss item: 0.6537167429924011
train loss item: 0.3848836123943329
train loss item: 0.7090879082679749
train loss item: 0.8640277981758118
train loss item: 0.46717530488967896
test loss item: 0.7143515944480896
test loss item: 0.6800945401191711
test loss item: 0.5133504867553711
test loss item: 0.5548902750015259
test loss item: 0.9800561666488647
test loss item: 0.3815513253211975
test loss item: 0.7185341715812683
test loss item: 0.4738336503505707
test loss item: 0.7692980766296387
test loss item: 1.2288355827331543
test loss item: 1.107201099395752
test loss item: 0.18293917179107666
Epoch [5/100], Training Loss: 0.6218, Testing Loss: 0.6921
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 6/100
train loss item: 0.6935371160507202
train loss item: 0.5232334733009338
train loss item: 0.5809929370880127
train loss item: 0.6600165367126465
train loss item: 0.740502119064331
train loss item: 0.3897272050380707
train loss item: 0.7430079579353333
train loss item: 0.6598523855209351
train loss item: 0.36883315443992615
train loss item: 0.6696416139602661
train loss item: 0.8549189567565918
train loss item: 0.41099363565444946
test loss item: 0.6205070614814758
test loss item: 0.5668800473213196
test loss item: 0.4473553001880646
test loss item: 0.4805130660533905
test loss item: 0.8150489926338196
test loss item: 0.3519774079322815
test loss item: 0.5836055278778076
test loss item: 0.39054054021835327
test loss item: 0.642426073551178
test loss item: 1.0142884254455566
test loss item: 0.9220860004425049
test loss item: 0.14466796815395355
Epoch [6/100], Training Loss: 0.6079, Testing Loss: 0.5817
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 7/100
train loss item: 0.6616132855415344
train loss item: 0.448541522026062
train loss item: 0.5705880522727966
train loss item: 0.6463158130645752
train loss item: 0.6811172962188721
train loss item: 0.37774163484573364
train loss item: 0.6869930624961853
train loss item: 0.622336745262146
train loss item: 0.3628271520137787
train loss item: 0.6563182473182678
train loss item: 0.8082332015037537
train loss item: 0.4208752512931824
test loss item: 0.5947079062461853
test loss item: 0.4916192889213562
test loss item: 0.4303413927555084
test loss item: 0.43888986110687256
test loss item: 0.727758526802063
test loss item: 0.34286263585090637
test loss item: 0.5219079256057739
test loss item: 0.36402422189712524
test loss item: 0.606358528137207
test loss item: 0.8999432921409607
test loss item: 0.7942491769790649
test loss item: 0.14240488409996033
Epoch [7/100], Training Loss: 0.5786, Testing Loss: 0.5296
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 8/100
train loss item: 0.6446191668510437
train loss item: 0.39430809020996094
train loss item: 0.5219672322273254
train loss item: 0.6501003503799438
train loss item: 0.6541334390640259
train loss item: 0.3448999524116516
train loss item: 0.6329718232154846
train loss item: 0.5855112075805664
train loss item: 0.36855870485305786
train loss item: 0.6449117660522461
train loss item: 0.7566896677017212
train loss item: 0.4003913402557373
test loss item: 0.5671632885932922
test loss item: 0.4763503968715668
test loss item: 0.41602852940559387
test loss item: 0.4268138110637665
test loss item: 0.701973557472229
test loss item: 0.3386044204235077
test loss item: 0.505382776260376
test loss item: 0.34729254245758057
test loss item: 0.56548672914505
test loss item: 0.8388271331787109
test loss item: 0.7582160830497742
test loss item: 0.1849266141653061
Epoch [8/100], Training Loss: 0.5499, Testing Loss: 0.5106
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 9/100
train loss item: 0.6501380205154419
train loss item: 0.4137910008430481
train loss item: 0.5094935297966003
train loss item: 0.6232690215110779
train loss item: 0.6280271410942078
train loss item: 0.3216910660266876
train loss item: 0.6164563298225403
train loss item: 0.5669658184051514
train loss item: 0.3618095815181732
train loss item: 0.6310023069381714
train loss item: 0.7021150588989258
train loss item: 0.37488463521003723
test loss item: 0.5576760172843933
test loss item: 0.4387529492378235
test loss item: 0.42650163173675537
test loss item: 0.40698879957199097
test loss item: 0.662597119808197
test loss item: 0.3334234654903412
test loss item: 0.4835571348667145
test loss item: 0.3523702323436737
test loss item: 0.5577371716499329
test loss item: 0.7216888070106506
test loss item: 0.6958555579185486
test loss item: 0.1581973433494568
Epoch [9/100], Training Loss: 0.5333, Testing Loss: 0.4829
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 10/100
train loss item: 0.6146268248558044
train loss item: 0.4009389877319336
train loss item: 0.5048874616622925
train loss item: 0.6117563843727112
train loss item: 0.5628377199172974
train loss item: 0.2973169982433319
train loss item: 0.5528077483177185
train loss item: 0.5378864407539368
train loss item: 0.3709028363227844
train loss item: 0.6384808421134949
train loss item: 0.6483501195907593
train loss item: 0.3773448169231415
test loss item: 0.49395743012428284
test loss item: 0.4037442207336426
test loss item: 0.39273738861083984
test loss item: 0.3740706741809845
test loss item: 0.5978658199310303
test loss item: 0.3202199935913086
test loss item: 0.44236990809440613
test loss item: 0.3208899199962616
test loss item: 0.4954734146595001
test loss item: 0.6402389407157898
test loss item: 0.6175023317337036
test loss item: 0.144777312874794
Epoch [10/100], Training Loss: 0.5098, Testing Loss: 0.4370
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 11/100
train loss item: 0.6289239525794983
train loss item: 0.37437668442726135
train loss item: 0.5057884454727173
train loss item: 0.6251233816146851
train loss item: 0.5547199249267578
train loss item: 0.33188432455062866
train loss item: 0.4913480877876282
train loss item: 0.47655558586120605
train loss item: 0.3450043201446533
train loss item: 0.6163378953933716
train loss item: 0.677433431148529
train loss item: 0.38690754771232605
test loss item: 0.5338671207427979
test loss item: 0.3724013864994049
test loss item: 0.42661580443382263
test loss item: 0.3544767498970032
test loss item: 0.5823766589164734
test loss item: 0.33272427320480347
test loss item: 0.4177809953689575
test loss item: 0.3382733464241028
test loss item: 0.5254193544387817
test loss item: 0.5302020311355591
test loss item: 0.585725724697113
test loss item: 0.1488630324602127
Epoch [11/100], Training Loss: 0.5012, Testing Loss: 0.4291
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 12/100
train loss item: 0.5806013941764832
train loss item: 0.3405724763870239
train loss item: 0.45533233880996704
train loss item: 0.5675888657569885
train loss item: 0.5097271203994751
train loss item: 0.31024792790412903
train loss item: 0.465900719165802
train loss item: 0.4432883560657501
train loss item: 0.3461630046367645
train loss item: 0.5293601155281067
train loss item: 0.5824204087257385
train loss item: 0.3386906087398529
test loss item: 0.4459516704082489
test loss item: 0.33856165409088135
test loss item: 0.3620835244655609
test loss item: 0.3198351562023163
test loss item: 0.5127379894256592
test loss item: 0.2960177958011627
test loss item: 0.37365642189979553
test loss item: 0.29258567094802856
test loss item: 0.44139236211776733
test loss item: 0.482864111661911
test loss item: 0.5144944190979004
test loss item: 0.2449716180562973
Epoch [12/100], Training Loss: 0.4558, Testing Loss: 0.3854
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 13/100
train loss item: 0.520420253276825
train loss item: 0.30761516094207764
train loss item: 0.4485664665699005
train loss item: 0.5118765830993652
train loss item: 0.42490774393081665
train loss item: 0.2719230353832245
train loss item: 0.4371100068092346
train loss item: 0.4013802409172058
train loss item: 0.326933890581131
train loss item: 0.48980551958084106
train loss item: 0.4925173223018646
train loss item: 0.32413432002067566
test loss item: 0.42101916670799255
test loss item: 0.31053417921066284
test loss item: 0.33756837248802185
test loss item: 0.296093612909317
test loss item: 0.4642174243927002
test loss item: 0.27586260437965393
test loss item: 0.33578625321388245
test loss item: 0.2701031267642975
test loss item: 0.4157157838344574
test loss item: 0.43252962827682495
test loss item: 0.4726213812828064
test loss item: 0.24976153671741486
Epoch [13/100], Training Loss: 0.4131, Testing Loss: 0.3568
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 14/100
train loss item: 0.5091874599456787
train loss item: 0.32602620124816895
train loss item: 0.412640243768692
train loss item: 0.5036062598228455
train loss item: 0.39116159081459045
train loss item: 0.24692150950431824
train loss item: 0.40281015634536743
train loss item: 0.36892837285995483
train loss item: 0.31477415561676025
train loss item: 0.4653816521167755
train loss item: 0.44721922278404236
train loss item: 0.3196924030780792
test loss item: 0.43136927485466003
test loss item: 0.29624098539352417
test loss item: 0.3286585807800293
test loss item: 0.28985318541526794
test loss item: 0.45022010803222656
test loss item: 0.2586131989955902
test loss item: 0.314943790435791
test loss item: 0.26120245456695557
test loss item: 0.4227326512336731
test loss item: 0.4270481765270233
test loss item: 0.47369980812072754
test loss item: 0.171733096241951
Epoch [14/100], Training Loss: 0.3924, Testing Loss: 0.3439
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 15/100
train loss item: 0.5003812909126282
train loss item: 0.3504531681537628
train loss item: 0.38688358664512634
train loss item: 0.4702037572860718
train loss item: 0.38375821709632874
train loss item: 0.22461049258708954
train loss item: 0.3603673279285431
train loss item: 0.36085084080696106
train loss item: 0.2753708064556122
train loss item: 0.44880014657974243
train loss item: 0.44809553027153015
train loss item: 0.3440135717391968
test loss item: 0.4636959135532379
test loss item: 0.3377384543418884
test loss item: 0.3316872715950012
test loss item: 0.3230426013469696
test loss item: 0.49886879324913025
test loss item: 0.2682856321334839
test loss item: 0.3797067403793335
test loss item: 0.282124787569046
test loss item: 0.44777700304985046
test loss item: 0.5159438252449036
test loss item: 0.5397335290908813
test loss item: 0.18765145540237427
Epoch [15/100], Training Loss: 0.3795, Testing Loss: 0.3814
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 16/100
train loss item: 0.6111835837364197
train loss item: 0.3878691792488098
train loss item: 0.3509238064289093
train loss item: 0.5361490249633789
train loss item: 0.5198410749435425
train loss item: 0.26711925864219666
train loss item: 0.43294841051101685
train loss item: 0.46570253372192383
train loss item: 0.32933762669563293
train loss item: 0.459236204624176
train loss item: 0.5903841853141785
train loss item: 0.309079647064209
test loss item: 1.0043561458587646
test loss item: 0.48941507935523987
test loss item: 0.6402885317802429
test loss item: 0.5018664002418518
test loss item: 0.8508216142654419
test loss item: 0.3634539842605591
test loss item: 0.5450375080108643
test loss item: 0.5633541345596313
test loss item: 0.9317217469215393
test loss item: 0.5353462100028992
test loss item: 0.9865794777870178
test loss item: 0.22636447846889496
Epoch [16/100], Training Loss: 0.4383, Testing Loss: 0.6366
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 17/100
train loss item: 0.470034122467041
train loss item: 0.3166773319244385
train loss item: 0.3651401698589325
train loss item: 0.460296630859375
train loss item: 0.36114269495010376
train loss item: 0.2391548454761505
train loss item: 0.37239840626716614
train loss item: 0.36510589718818665
train loss item: 0.2977665960788727
train loss item: 0.49570202827453613
train loss item: 0.434739351272583
train loss item: 0.32396671175956726
test loss item: 0.4298253357410431
test loss item: 0.39532995223999023
test loss item: 0.29720616340637207
test loss item: 0.3290300667285919
test loss item: 0.5531685948371887
test loss item: 0.2338263839483261
test loss item: 0.4268883466720581
test loss item: 0.27972477674484253
test loss item: 0.4419659972190857
test loss item: 0.661687970161438
test loss item: 0.6299274563789368
test loss item: 0.20846587419509888
Epoch [17/100], Training Loss: 0.3752, Testing Loss: 0.4073
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 18/100
train loss item: 0.5071486234664917
train loss item: 0.2929667830467224
train loss item: 0.35252508521080017
train loss item: 0.4866395890712738
train loss item: 0.40368735790252686
train loss item: 0.22520706057548523
train loss item: 0.3183978497982025
train loss item: 0.3274487853050232
train loss item: 0.27575919032096863
train loss item: 0.44900330901145935
train loss item: 0.43764445185661316
train loss item: 0.27542197704315186
test loss item: 0.4262324869632721
test loss item: 0.26338884234428406
test loss item: 0.286483496427536
test loss item: 0.26985061168670654
test loss item: 0.4048454761505127
test loss item: 0.21859590709209442
test loss item: 0.2905547022819519
test loss item: 0.23423027992248535
test loss item: 0.3941953778266907
test loss item: 0.40491586923599243
test loss item: 0.4489627182483673
test loss item: 0.10775388777256012
Epoch [18/100], Training Loss: 0.3627, Testing Loss: 0.3125
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 19/100
train loss item: 0.4374346137046814
train loss item: 0.31858766078948975
train loss item: 0.30378299951553345
train loss item: 0.3978126645088196
train loss item: 0.35318341851234436
train loss item: 0.19838130474090576
train loss item: 0.3404039144515991
train loss item: 0.3002532720565796
train loss item: 0.212625190615654
train loss item: 0.38450899720191956
train loss item: 0.3730122148990631
train loss item: 0.2918415665626526
test loss item: 0.42923498153686523
test loss item: 0.229812353849411
test loss item: 0.29652413725852966
test loss item: 0.2586100995540619
test loss item: 0.37120214104652405
test loss item: 0.22434498369693756
test loss item: 0.2604590058326721
test loss item: 0.2339605689048767
test loss item: 0.38778868317604065
test loss item: 0.3077769875526428
test loss item: 0.40272223949432373
test loss item: 0.1618819385766983
Epoch [19/100], Training Loss: 0.3260, Testing Loss: 0.2970
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 20/100
train loss item: 0.43268537521362305
train loss item: 0.3011864721775055
train loss item: 0.27570077776908875
train loss item: 0.3608737587928772
train loss item: 0.3035011291503906
train loss item: 0.1718485951423645
train loss item: 0.31044983863830566
train loss item: 0.2927132248878479
train loss item: 0.19822676479816437
train loss item: 0.3598613142967224
train loss item: 0.32215943932533264
train loss item: 0.23068903386592865
test loss item: 0.43050235509872437
test loss item: 0.29802069067955017
test loss item: 0.28889888525009155
test loss item: 0.27834033966064453
test loss item: 0.430124968290329
test loss item: 0.23161761462688446
test loss item: 0.33109304308891296
test loss item: 0.23153111338615417
test loss item: 0.39667192101478577
test loss item: 0.42378154397010803
test loss item: 0.48370644450187683
test loss item: 0.14966414868831635
Epoch [20/100], Training Loss: 0.2967, Testing Loss: 0.3312
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 21/100
train loss item: 0.5064462423324585
train loss item: 0.34727954864501953
train loss item: 0.28297868371009827
train loss item: 0.34704405069351196
train loss item: 0.30351439118385315
train loss item: 0.1510775089263916
train loss item: 0.347267746925354
train loss item: 0.32267507910728455
train loss item: 0.25387898087501526
train loss item: 0.47666046023368835
train loss item: 0.45918765664100647
train loss item: 0.23799599707126617
test loss item: 0.3888927400112152
test loss item: 0.219604954123497
test loss item: 0.2638972997665405
test loss item: 0.24526233971118927
test loss item: 0.34279632568359375
test loss item: 0.20376896858215332
test loss item: 0.24944323301315308
test loss item: 0.20490902662277222
test loss item: 0.3651173710823059
test loss item: 0.3361007571220398
test loss item: 0.387498140335083
test loss item: 0.19138836860656738
Epoch [21/100], Training Loss: 0.3363, Testing Loss: 0.2832
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 22/100
train loss item: 0.38065505027770996
train loss item: 0.3269011378288269
train loss item: 0.3037428855895996
train loss item: 0.3497259318828583
train loss item: 0.4085630476474762
train loss item: 0.3584836721420288
train loss item: 0.32462432980537415
train loss item: 0.30334943532943726
train loss item: 0.2172427922487259
train loss item: 0.4496070146560669
train loss item: 0.35103681683540344
train loss item: 0.25592178106307983
test loss item: 0.3078155517578125
test loss item: 0.24878902733325958
test loss item: 0.24536098539829254
test loss item: 0.22132208943367004
test loss item: 0.36635348200798035
test loss item: 0.1845751702785492
test loss item: 0.25772470235824585
test loss item: 0.2014124095439911
test loss item: 0.3385626971721649
test loss item: 0.4136098027229309
test loss item: 0.4196092486381531
test loss item: 0.1480627804994583
Epoch [22/100], Training Loss: 0.3358, Testing Loss: 0.2794
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 23/100
train loss item: 0.3502386510372162
train loss item: 0.22638410329818726
train loss item: 0.3465942442417145
train loss item: 0.4372691214084625
train loss item: 0.3144305944442749
train loss item: 0.26757776737213135
train loss item: 0.29047611355781555
train loss item: 0.2921435534954071
train loss item: 0.18445590138435364
train loss item: 0.4252239167690277
train loss item: 0.4890291690826416
train loss item: 0.23988930881023407
test loss item: 0.3770539462566376
test loss item: 0.22105790674686432
test loss item: 0.26078590750694275
test loss item: 0.21642732620239258
test loss item: 0.35178515315055847
test loss item: 0.18313762545585632
test loss item: 0.23336786031723022
test loss item: 0.20746469497680664
test loss item: 0.3478552997112274
test loss item: 0.2726277709007263
test loss item: 0.3966882824897766
test loss item: 0.1659424751996994
Epoch [23/100], Training Loss: 0.3220, Testing Loss: 0.2695
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 24/100
train loss item: 0.31694939732551575
train loss item: 0.25785648822784424
train loss item: 0.28397801518440247
train loss item: 0.3551291525363922
train loss item: 0.27991819381713867
train loss item: 0.1962129920721054
train loss item: 0.3397688567638397
train loss item: 0.30987998843193054
train loss item: 0.18227621912956238
train loss item: 0.41971564292907715
train loss item: 0.3301328718662262
train loss item: 0.22737061977386475
test loss item: 0.36987537145614624
test loss item: 0.2978235185146332
test loss item: 0.254452645778656
test loss item: 0.2554149627685547
test loss item: 0.4403928816318512
test loss item: 0.19286693632602692
test loss item: 0.33138760924339294
test loss item: 0.2278893142938614
test loss item: 0.38061070442199707
test loss item: 0.549630880355835
test loss item: 0.51621013879776
test loss item: 0.08369574695825577
Epoch [24/100], Training Loss: 0.2916, Testing Loss: 0.3250
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 25/100
train loss item: 0.42211592197418213
train loss item: 0.2602822184562683
train loss item: 0.25971049070358276
train loss item: 0.3319653272628784
train loss item: 0.30362847447395325
train loss item: 0.20847643911838531
train loss item: 0.2519252300262451
train loss item: 0.28290021419525146
train loss item: 0.21312594413757324
train loss item: 0.44756588339805603
train loss item: 0.37941744923591614
train loss item: 0.24927176535129547
test loss item: 0.265783429145813
test loss item: 0.2547629177570343
test loss item: 0.21620918810367584
test loss item: 0.21003256738185883
test loss item: 0.3431696891784668
test loss item: 0.1610449254512787
test loss item: 0.27504265308380127
test loss item: 0.1885082870721817
test loss item: 0.27769455313682556
test loss item: 0.3453279733657837
test loss item: 0.38411346077919006
test loss item: 0.104944609105587
Epoch [25/100], Training Loss: 0.3009, Testing Loss: 0.2522
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 26/100
train loss item: 0.28276193141937256
train loss item: 0.23974910378456116
train loss item: 0.21513232588768005
train loss item: 0.2855601906776428
train loss item: 0.3013112246990204
train loss item: 0.24446772038936615
train loss item: 0.25389793515205383
train loss item: 0.23374667763710022
train loss item: 0.1608382612466812
train loss item: 0.38790470361709595
train loss item: 0.295017808675766
train loss item: 0.2061651200056076
test loss item: 0.22660945355892181
test loss item: 0.19456997513771057
test loss item: 0.17226088047027588
test loss item: 0.16008904576301575
test loss item: 0.2732102572917938
test loss item: 0.13621029257774353
test loss item: 0.19850674271583557
test loss item: 0.14927488565444946
test loss item: 0.25354570150375366
test loss item: 0.33619561791419983
test loss item: 0.3218804597854614
test loss item: 0.09199349582195282
Epoch [26/100], Training Loss: 0.2589, Testing Loss: 0.2095
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 27/100
train loss item: 0.3455365300178528
train loss item: 0.2107541710138321
train loss item: 0.24769623577594757
train loss item: 0.28807303309440613
train loss item: 0.25340941548347473
train loss item: 0.2026391476392746
train loss item: 0.23428522050380707
train loss item: 0.21413911879062653
train loss item: 0.1556614488363266
train loss item: 0.3413398265838623
train loss item: 0.3229292631149292
train loss item: 0.17610862851142883
test loss item: 0.3214741051197052
test loss item: 0.2567477822303772
test loss item: 0.2002989798784256
test loss item: 0.22390976548194885
test loss item: 0.3402515947818756
test loss item: 0.1494535654783249
test loss item: 0.27880173921585083
test loss item: 0.17837071418762207
test loss item: 0.2931801378726959
test loss item: 0.3513545095920563
test loss item: 0.4106166362762451
test loss item: 0.1115318313241005
Epoch [27/100], Training Loss: 0.2494, Testing Loss: 0.2597
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 28/100
train loss item: 0.3564758896827698
train loss item: 0.3124811351299286
train loss item: 0.27297016978263855
train loss item: 0.2476806491613388
train loss item: 0.30302897095680237
train loss item: 0.21389032900333405
train loss item: 0.34981757402420044
train loss item: 0.30856749415397644
train loss item: 0.18271122872829437
train loss item: 0.41659557819366455
train loss item: 0.3208109438419342
train loss item: 0.2413598597049713
test loss item: 0.39607593417167664
test loss item: 0.47154700756073
test loss item: 0.2957201898097992
test loss item: 0.36691799759864807
test loss item: 0.6304954886436462
test loss item: 0.20791001617908478
test loss item: 0.5053976774215698
test loss item: 0.3100220561027527
test loss item: 0.4764600992202759
test loss item: 0.7879961729049683
test loss item: 0.7544137835502625
test loss item: 0.0861426442861557
Epoch [28/100], Training Loss: 0.2939, Testing Loss: 0.4408
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 29/100
train loss item: 0.48387473821640015
train loss item: 0.30262550711631775
train loss item: 0.23033811151981354
train loss item: 0.2138236165046692
train loss item: 0.280710905790329
train loss item: 0.2127676159143448
train loss item: 0.22172267735004425
train loss item: 0.24336522817611694
train loss item: 0.17840658128261566
train loss item: 0.4042409062385559
train loss item: 0.24030670523643494
train loss item: 0.1904047131538391
test loss item: 0.2760082185268402
test loss item: 0.3342939019203186
test loss item: 0.20191922783851624
test loss item: 0.2576887905597687
test loss item: 0.4261709153652191
test loss item: 0.1643657684326172
test loss item: 0.36230725049972534
test loss item: 0.21436457335948944
test loss item: 0.3475923538208008
test loss item: 0.5421594977378845
test loss item: 0.5241801738739014
test loss item: 0.09732283651828766
Epoch [29/100], Training Loss: 0.2669, Testing Loss: 0.3124
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 30/100
train loss item: 0.3778907358646393
train loss item: 0.27065208554267883
train loss item: 0.21355727314949036
train loss item: 0.21527232229709625
train loss item: 0.2986697256565094
train loss item: 0.26728132367134094
train loss item: 0.33282163739204407
train loss item: 0.2941533327102661
train loss item: 0.133158341050148
train loss item: 0.38611850142478943
train loss item: 0.273817777633667
train loss item: 0.15508607029914856
test loss item: 0.3833642899990082
test loss item: 0.42341020703315735
test loss item: 0.2651136517524719
test loss item: 0.33538511395454407
test loss item: 0.5680955648422241
test loss item: 0.2081185281276703
test loss item: 0.4668419659137726
test loss item: 0.2704296410083771
test loss item: 0.45389121770858765
test loss item: 0.7592114806175232
test loss item: 0.7013741135597229
test loss item: 0.13174781203269958
Epoch [30/100], Training Loss: 0.2682, Testing Loss: 0.4139
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 31/100
train loss item: 0.43112653493881226
train loss item: 0.2976279556751251
train loss item: 0.1768706738948822
train loss item: 0.23157690465450287
train loss item: 0.29852575063705444
train loss item: 0.2522670030593872
train loss item: 0.4127916693687439
train loss item: 0.4647415578365326
train loss item: 0.19503328204154968
train loss item: 0.42108041048049927
train loss item: 0.32252833247184753
train loss item: 0.17191791534423828
test loss item: 0.2988933026790619
test loss item: 0.24276410043239594
test loss item: 0.18093423545360565
test loss item: 0.20631393790245056
test loss item: 0.3266177177429199
test loss item: 0.143393412232399
test loss item: 0.24384041130542755
test loss item: 0.16351383924484253
test loss item: 0.32220226526260376
test loss item: 0.46257102489471436
test loss item: 0.4396730959415436
test loss item: 0.08907824754714966
Epoch [31/100], Training Loss: 0.3063, Testing Loss: 0.2600
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 32/100
train loss item: 0.2788454294204712
train loss item: 0.26806512475013733
train loss item: 0.28663161396980286
train loss item: 0.4170719385147095
train loss item: 0.29155370593070984
train loss item: 0.19078804552555084
train loss item: 0.34641215205192566
train loss item: 0.48718538880348206
train loss item: 0.18989963829517365
train loss item: 0.4707845151424408
train loss item: 0.5874319076538086
train loss item: 0.17885997891426086
test loss item: 0.3138543367385864
test loss item: 0.23589392006397247
test loss item: 0.2538122832775116
test loss item: 0.20634013414382935
test loss item: 0.3427949547767639
test loss item: 0.17114312946796417
test loss item: 0.2401975840330124
test loss item: 0.2146383672952652
test loss item: 0.32322078943252563
test loss item: 0.2745714783668518
test loss item: 0.3828916847705841
test loss item: 0.14480061829090118
Epoch [32/100], Training Loss: 0.3328, Testing Loss: 0.2587
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 33/100
train loss item: 0.28071433305740356
train loss item: 0.19346898794174194
train loss item: 0.2204681932926178
train loss item: 0.44058239459991455
train loss item: 0.36132481694221497
train loss item: 0.33480626344680786
train loss item: 0.24484609067440033
train loss item: 0.28973060846328735
train loss item: 0.1783083975315094
train loss item: 0.39354050159454346
train loss item: 0.5390594005584717
train loss item: 0.16736768186092377
test loss item: 0.24751602113246918
test loss item: 0.1874541938304901
test loss item: 0.20803892612457275
test loss item: 0.1599338799715042
test loss item: 0.2664538323879242
test loss item: 0.14755617082118988
test loss item: 0.21136410534381866
test loss item: 0.18012844026088715
test loss item: 0.2649105489253998
test loss item: 0.26092106103897095
test loss item: 0.2766168713569641
test loss item: 0.08290231227874756
Epoch [33/100], Training Loss: 0.3037, Testing Loss: 0.2078
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 34/100
train loss item: 0.26682648062705994
train loss item: 0.19196437299251556
train loss item: 0.20049813389778137
train loss item: 0.29235100746154785
train loss item: 0.18521597981452942
train loss item: 0.3138144612312317
train loss item: 0.14348889887332916
train loss item: 0.17078347504138947
train loss item: 0.16748355329036713
train loss item: 0.28158095479011536
train loss item: 0.4384198784828186
train loss item: 0.14808957278728485
test loss item: 0.17455564439296722
test loss item: 0.13286033272743225
test loss item: 0.13633207976818085
test loss item: 0.12775549292564392
test loss item: 0.1834893822669983
test loss item: 0.11511214077472687
test loss item: 0.1461762636899948
test loss item: 0.1221468597650528
test loss item: 0.17057448625564575
test loss item: 0.16818934679031372
test loss item: 0.18497858941555023
test loss item: 0.1400989592075348
Epoch [34/100], Training Loss: 0.2334, Testing Loss: 0.1502
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 35/100
train loss item: 0.16245783865451813
train loss item: 0.14116016030311584
train loss item: 0.17099156975746155
train loss item: 0.25352734327316284
train loss item: 0.13605846464633942
train loss item: 0.16095784306526184
train loss item: 0.15216098725795746
train loss item: 0.17125582695007324
train loss item: 0.13718420267105103
train loss item: 0.2595909535884857
train loss item: 0.3359132707118988
train loss item: 0.10856656730175018
test loss item: 0.16799794137477875
test loss item: 0.14291730523109436
test loss item: 0.12897852063179016
test loss item: 0.12308582663536072
test loss item: 0.18821854889392853
test loss item: 0.10200235992670059
test loss item: 0.14106494188308716
test loss item: 0.11228068917989731
test loss item: 0.1652507334947586
test loss item: 0.19394424557685852
test loss item: 0.2238304615020752
test loss item: 0.10623746365308762
Epoch [35/100], Training Loss: 0.1825, Testing Loss: 0.1497
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 36/100
train loss item: 0.21247795224189758
train loss item: 0.16002267599105835
train loss item: 0.1208716332912445
train loss item: 0.2174467146396637
train loss item: 0.14470231533050537
train loss item: 0.10500656813383102
train loss item: 0.1609877198934555
train loss item: 0.16907832026481628
train loss item: 0.1309305876493454
train loss item: 0.20278604328632355
train loss item: 0.21145103871822357
train loss item: 0.10002905875444412
test loss item: 0.20598123967647552
test loss item: 0.22936567664146423
test loss item: 0.12013370543718338
test loss item: 0.17525090277194977
test loss item: 0.3019527196884155
test loss item: 0.09231386333703995
test loss item: 0.2406649887561798
test loss item: 0.13243277370929718
test loss item: 0.2387930303812027
test loss item: 0.41636893153190613
test loss item: 0.38197073340415955
test loss item: 0.08271358162164688
Epoch [36/100], Training Loss: 0.1613, Testing Loss: 0.2182
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 37/100
train loss item: 0.33597254753112793
train loss item: 0.19722743332386017
train loss item: 0.14365029335021973
train loss item: 0.243754580616951
train loss item: 0.17224198579788208
train loss item: 0.16425076127052307
train loss item: 0.2679620385169983
train loss item: 0.30389899015426636
train loss item: 0.150191530585289
train loss item: 0.24834689497947693
train loss item: 0.2180371880531311
train loss item: 0.11343599110841751
test loss item: 0.23631702363491058
test loss item: 0.19571976363658905
test loss item: 0.1461382806301117
test loss item: 0.18044869601726532
test loss item: 0.26023197174072266
test loss item: 0.12188779562711716
test loss item: 0.21714316308498383
test loss item: 0.14526619017124176
test loss item: 0.2270602434873581
test loss item: 0.3027171194553375
test loss item: 0.31880897283554077
test loss item: 0.11348284035921097
Epoch [37/100], Training Loss: 0.2132, Testing Loss: 0.2054
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 38/100
train loss item: 0.3118976056575775
train loss item: 0.2999361455440521
train loss item: 0.28270378708839417
train loss item: 0.3618626892566681
train loss item: 0.27157020568847656
train loss item: 0.12376871705055237
train loss item: 0.2934865951538086
train loss item: 0.4358803927898407
train loss item: 0.20924951136112213
train loss item: 0.4408988058567047
train loss item: 0.5781092047691345
train loss item: 0.20739541947841644
test loss item: 0.27457186579704285
test loss item: 0.26559457182884216
test loss item: 0.24383336305618286
test loss item: 0.2435489296913147
test loss item: 0.3821086585521698
test loss item: 0.21804048120975494
test loss item: 0.3228829801082611
test loss item: 0.20204558968544006
test loss item: 0.2743351459503174
test loss item: 0.407728910446167
test loss item: 0.3669965863227844
test loss item: 0.12608255445957184
Epoch [38/100], Training Loss: 0.3181, Testing Loss: 0.2773
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 39/100
train loss item: 0.42136716842651367
train loss item: 0.2519909143447876
train loss item: 0.19100844860076904
train loss item: 0.2750077247619629
train loss item: 0.2941317558288574
train loss item: 0.3974290192127228
train loss item: 0.2738322615623474
train loss item: 0.2100270837545395
train loss item: 0.2002066671848297
train loss item: 0.27314698696136475
train loss item: 0.5270349979400635
train loss item: 0.12525522708892822
test loss item: 0.33932656049728394
test loss item: 0.30425339937210083
test loss item: 0.23794181644916534
test loss item: 0.24835766851902008
test loss item: 0.4157567322254181
test loss item: 0.1701907515525818
test loss item: 0.3225407600402832
test loss item: 0.2234346717596054
test loss item: 0.3573019206523895
test loss item: 0.4934895634651184
test loss item: 0.48374372720718384
test loss item: 0.12302349507808685
Epoch [39/100], Training Loss: 0.2867, Testing Loss: 0.3099
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 40/100
train loss item: 0.40076589584350586
train loss item: 0.22574378550052643
train loss item: 0.2100732922554016
train loss item: 0.23671554028987885
train loss item: 0.21049359440803528
train loss item: 0.26057952642440796
train loss item: 0.21609172224998474
train loss item: 0.23711450397968292
train loss item: 0.28424784541130066
train loss item: 0.33430764079093933
train loss item: 0.2879171669483185
train loss item: 0.19966106116771698
test loss item: 0.4171256422996521
test loss item: 0.1716279238462448
test loss item: 0.24712908267974854
test loss item: 0.20369009673595428
test loss item: 0.3175704777240753
test loss item: 0.14840130507946014
test loss item: 0.1941194385290146
test loss item: 0.21093475818634033
test loss item: 0.361569344997406
test loss item: 0.20113499462604523
test loss item: 0.36797472834587097
test loss item: 0.12438448518514633
Epoch [40/100], Training Loss: 0.2586, Testing Loss: 0.2471
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 41/100
train loss item: 0.23246203362941742
train loss item: 0.16871851682662964
train loss item: 0.15442660450935364
train loss item: 0.190139502286911
train loss item: 0.20077769458293915
train loss item: 0.11313116550445557
train loss item: 0.15362733602523804
train loss item: 0.17846116423606873
train loss item: 0.13446922600269318
train loss item: 0.2498854696750641
train loss item: 0.2623390853404999
train loss item: 0.10961470007896423
test loss item: 0.31541913747787476
test loss item: 0.12954868376255035
test loss item: 0.16500599682331085
test loss item: 0.17561033368110657
test loss item: 0.21370190382003784
test loss item: 0.1319781243801117
test loss item: 0.1408492624759674
test loss item: 0.13582679629325867
test loss item: 0.24843601882457733
test loss item: 0.20515526831150055
test loss item: 0.2645814120769501
test loss item: 0.15135006606578827
Epoch [41/100], Training Loss: 0.1790, Testing Loss: 0.1898
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 42/100
train loss item: 0.2502591609954834
train loss item: 0.18164078891277313
train loss item: 0.12561990320682526
train loss item: 0.18190599977970123
train loss item: 0.13835491240024567
train loss item: 0.09184744954109192
train loss item: 0.18763896822929382
train loss item: 0.23087607324123383
train loss item: 0.15592797100543976
train loss item: 0.3225227892398834
train loss item: 0.27418363094329834
train loss item: 0.13158516585826874
test loss item: 0.25524166226387024
test loss item: 0.09980656951665878
test loss item: 0.1112285628914833
test loss item: 0.13293248414993286
test loss item: 0.1543141007423401
test loss item: 0.10029188543558121
test loss item: 0.11402683705091476
test loss item: 0.09641802310943604
test loss item: 0.19025421142578125
test loss item: 0.14905980229377747
test loss item: 0.18766027688980103
test loss item: 0.08991503715515137
Epoch [42/100], Training Loss: 0.1894, Testing Loss: 0.1401
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 43/100
train loss item: 0.21491001546382904
train loss item: 0.2312358170747757
train loss item: 0.19917072355747223
train loss item: 0.3012402355670929
train loss item: 0.29729148745536804
train loss item: 0.18654726445674896
train loss item: 0.17563125491142273
train loss item: 0.23335647583007812
train loss item: 0.1573581099510193
train loss item: 0.3944404125213623
train loss item: 0.4733639359474182
train loss item: 0.17883548140525818
test loss item: 0.20699526369571686
test loss item: 0.200969859957695
test loss item: 0.171412393450737
test loss item: 0.1759432554244995
test loss item: 0.2699485719203949
test loss item: 0.1285237818956375
test loss item: 0.21724489331245422
test loss item: 0.15349367260932922
test loss item: 0.2308391034603119
test loss item: 0.3187812268733978
test loss item: 0.2899828553199768
test loss item: 0.07373977452516556
Epoch [43/100], Training Loss: 0.2536, Testing Loss: 0.2032
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 44/100
train loss item: 0.24591749906539917
train loss item: 0.1554775983095169
train loss item: 0.16196216642856598
train loss item: 0.20250964164733887
train loss item: 0.22682856023311615
train loss item: 0.23919163644313812
train loss item: 0.16692237555980682
train loss item: 0.16595785319805145
train loss item: 0.1466732770204544
train loss item: 0.2911995053291321
train loss item: 0.38592368364334106
train loss item: 0.11900020390748978
test loss item: 0.2354348748922348
test loss item: 0.1543302685022354
test loss item: 0.16789035499095917
test loss item: 0.14031440019607544
test loss item: 0.23147734999656677
test loss item: 0.1129305511713028
test loss item: 0.16908077895641327
test loss item: 0.1523832231760025
test loss item: 0.22299623489379883
test loss item: 0.21821004152297974
test loss item: 0.2507471740245819
test loss item: 0.09513609111309052
Epoch [44/100], Training Loss: 0.2090, Testing Loss: 0.1792
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 45/100
train loss item: 0.17560139298439026
train loss item: 0.12639200687408447
train loss item: 0.13933512568473816
train loss item: 0.19285348057746887
train loss item: 0.16569358110427856
train loss item: 0.21336258947849274
train loss item: 0.1236235722899437
train loss item: 0.1335480660200119
train loss item: 0.13345812261104584
train loss item: 0.2396271824836731
train loss item: 0.36444294452667236
train loss item: 0.11228708177804947
test loss item: 0.24700282514095306
test loss item: 0.11624554544687271
test loss item: 0.15452304482460022
test loss item: 0.14267049729824066
test loss item: 0.18055666983127594
test loss item: 0.11923902481794357
test loss item: 0.1323612779378891
test loss item: 0.12259657680988312
test loss item: 0.21039436757564545
test loss item: 0.17039570212364197
test loss item: 0.2170359492301941
test loss item: 0.1136862114071846
Epoch [45/100], Training Loss: 0.1767, Testing Loss: 0.1606
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 46/100
train loss item: 0.1239171177148819
train loss item: 0.10143399238586426
train loss item: 0.10130991041660309
train loss item: 0.14531084895133972
train loss item: 0.12978914380073547
train loss item: 0.16666197776794434
train loss item: 0.11245325207710266
train loss item: 0.13077740371227264
train loss item: 0.11381276696920395
train loss item: 0.21720296144485474
train loss item: 0.3146321475505829
train loss item: 0.08932135999202728
test loss item: 0.22751106321811676
test loss item: 0.10261077433824539
test loss item: 0.14041244983673096
test loss item: 0.12697485089302063
test loss item: 0.1591232866048813
test loss item: 0.10630111396312714
test loss item: 0.11332987993955612
test loss item: 0.11197918653488159
test loss item: 0.1954231858253479
test loss item: 0.13522987067699432
test loss item: 0.1941264420747757
test loss item: 0.10124950855970383
Epoch [46/100], Training Loss: 0.1456, Testing Loss: 0.1429
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 47/100
train loss item: 0.12159576267004013
train loss item: 0.0935211181640625
train loss item: 0.07825635373592377
train loss item: 0.12737300992012024
train loss item: 0.12329668551683426
train loss item: 0.10941649973392487
train loss item: 0.11152689158916473
train loss item: 0.13675831258296967
train loss item: 0.10189997404813766
train loss item: 0.1983153522014618
train loss item: 0.2339385449886322
train loss item: 0.07796630263328552
test loss item: 0.15946424007415771
test loss item: 0.09308113157749176
test loss item: 0.09755950421094894
test loss item: 0.09431957453489304
test loss item: 0.12818516790866852
test loss item: 0.08311540633440018
test loss item: 0.09295618534088135
test loss item: 0.08636604249477386
test loss item: 0.14589045941829681
test loss item: 0.1335410326719284
test loss item: 0.1546088457107544
test loss item: 0.1088583841919899
Epoch [47/100], Training Loss: 0.1262, Testing Loss: 0.1148
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 48/100
train loss item: 0.16977764666080475
train loss item: 0.13987921178340912
train loss item: 0.12528350949287415
train loss item: 0.1900581419467926
train loss item: 0.13027919828891754
train loss item: 0.08750669658184052
train loss item: 0.16963842511177063
train loss item: 0.2167855203151703
train loss item: 0.12866875529289246
train loss item: 0.2212003618478775
train loss item: 0.26919105648994446
train loss item: 0.09816580265760422
test loss item: 0.12167991697788239
test loss item: 0.09138460457324982
test loss item: 0.09337937831878662
test loss item: 0.08998104929924011
test loss item: 0.12556259334087372
test loss item: 0.08791108429431915
test loss item: 0.09771982580423355
test loss item: 0.08032098412513733
test loss item: 0.10788479447364807
test loss item: 0.12322279065847397
test loss item: 0.12340335547924042
test loss item: 0.13028430938720703
Epoch [48/100], Training Loss: 0.1622, Testing Loss: 0.1061
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 49/100
train loss item: 0.16365528106689453
train loss item: 0.16030609607696533
train loss item: 0.169470876455307
train loss item: 0.2930401861667633
train loss item: 0.2508467137813568
train loss item: 0.11906575411558151
train loss item: 0.15905894339084625
train loss item: 0.23134185373783112
train loss item: 0.14452479779720306
train loss item: 0.2825433015823364
train loss item: 0.4274810254573822
train loss item: 0.15396586060523987
test loss item: 0.28854596614837646
test loss item: 0.21860051155090332
test loss item: 0.21570004522800446
test loss item: 0.21034853160381317
test loss item: 0.330207884311676
test loss item: 0.1880994737148285
test loss item: 0.26370587944984436
test loss item: 0.1661253720521927
test loss item: 0.27544403076171875
test loss item: 0.38394492864608765
test loss item: 0.3374709486961365
test loss item: 0.09166418015956879
Epoch [49/100], Training Loss: 0.2129, Testing Loss: 0.2475
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 50/100
train loss item: 0.319670706987381
train loss item: 0.20678496360778809
train loss item: 0.1670871078968048
train loss item: 0.1988767683506012
train loss item: 0.20309202373027802
train loss item: 0.2115241438150406
train loss item: 0.22230824828147888
train loss item: 0.18980449438095093
train loss item: 0.18700557947158813
train loss item: 0.2996695041656494
train loss item: 0.4554557502269745
train loss item: 0.11729127168655396
test loss item: 0.274837851524353
test loss item: 0.24561230838298798
test loss item: 0.19202710688114166
test loss item: 0.2102569341659546
test loss item: 0.32983505725860596
test loss item: 0.15237067639827728
test loss item: 0.26446446776390076
test loss item: 0.16795948147773743
test loss item: 0.2822708487510681
test loss item: 0.4208580553531647
test loss item: 0.38358819484710693
test loss item: 0.09521222114562988
Epoch [50/100], Training Loss: 0.2315, Testing Loss: 0.2516
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 51/100
train loss item: 0.3202042877674103
train loss item: 0.20844978094100952
train loss item: 0.19502660632133484
train loss item: 0.17958979308605194
train loss item: 0.17752273380756378
train loss item: 0.1967383176088333
train loss item: 0.2114623636007309
train loss item: 0.2361665964126587
train loss item: 0.20716658234596252
train loss item: 0.3346005380153656
train loss item: 0.2870095670223236
train loss item: 0.1618628054857254
test loss item: 0.215273916721344
test loss item: 0.1603952795267105
test loss item: 0.17070233821868896
test loss item: 0.14113181829452515
test loss item: 0.26777440309524536
test loss item: 0.1302090883255005
test loss item: 0.1677490770816803
test loss item: 0.18720567226409912
test loss item: 0.21914726495742798
test loss item: 0.16732406616210938
test loss item: 0.2604062259197235
test loss item: 0.13263754546642303
Epoch [51/100], Training Loss: 0.2263, Testing Loss: 0.1850
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 52/100
train loss item: 0.17191462218761444
train loss item: 0.14800742268562317
train loss item: 0.14091524481773376
train loss item: 0.13854701817035675
train loss item: 0.18721407651901245
train loss item: 0.11490976065397263
train loss item: 0.12999340891838074
train loss item: 0.17300476133823395
train loss item: 0.1417943686246872
train loss item: 0.27819544076919556
train loss item: 0.27884241938591003
train loss item: 0.09749207645654678
test loss item: 0.13300026953220367
test loss item: 0.13847167789936066
test loss item: 0.11640024185180664
test loss item: 0.11879140883684158
test loss item: 0.18025349080562592
test loss item: 0.09456885606050491
test loss item: 0.1434030532836914
test loss item: 0.10491211712360382
test loss item: 0.13927944004535675
test loss item: 0.155455082654953
test loss item: 0.19517439603805542
test loss item: 0.12752261757850647
Epoch [52/100], Training Loss: 0.1667, Testing Loss: 0.1373
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 53/100
train loss item: 0.14453893899917603
train loss item: 0.12766008079051971
train loss item: 0.11387118697166443
train loss item: 0.17112018167972565
train loss item: 0.18092070519924164
train loss item: 0.07300297915935516
train loss item: 0.12600961327552795
train loss item: 0.14869634807109833
train loss item: 0.13318561017513275
train loss item: 0.2729555070400238
train loss item: 0.30175215005874634
train loss item: 0.08893447369337082
test loss item: 0.12647907435894012
test loss item: 0.11488302797079086
test loss item: 0.09655215591192245
test loss item: 0.09543513506650925
test loss item: 0.1485416442155838
test loss item: 0.08534248173236847
test loss item: 0.11879012733697891
test loss item: 0.08894394338130951
test loss item: 0.1311941295862198
test loss item: 0.16926172375679016
test loss item: 0.15822239220142365
test loss item: 0.12988048791885376
Epoch [53/100], Training Loss: 0.1569, Testing Loss: 0.1220
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 54/100
train loss item: 0.1336202174425125
train loss item: 0.14508526027202606
train loss item: 0.1130479946732521
train loss item: 0.17276982963085175
train loss item: 0.16535547375679016
train loss item: 0.0965806096792221
train loss item: 0.12592406570911407
train loss item: 0.15010793507099152
train loss item: 0.1293427050113678
train loss item: 0.2577745020389557
train loss item: 0.2892996370792389
train loss item: 0.10725990682840347
test loss item: 0.1262526959180832
test loss item: 0.0974603146314621
test loss item: 0.09906432777643204
test loss item: 0.08393601328134537
test loss item: 0.1315084844827652
test loss item: 0.08035881072282791
test loss item: 0.10383471846580505
test loss item: 0.09058044105768204
test loss item: 0.12135852128267288
test loss item: 0.1265115737915039
test loss item: 0.13372908532619476
test loss item: 0.06788776069879532
Epoch [54/100], Training Loss: 0.1572, Testing Loss: 0.1052
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 55/100
train loss item: 0.12363818287849426
train loss item: 0.13202551007270813
train loss item: 0.12248373031616211
train loss item: 0.16564840078353882
train loss item: 0.15973436832427979
train loss item: 0.12144643068313599
train loss item: 0.12331846356391907
train loss item: 0.15716227889060974
train loss item: 0.11011587083339691
train loss item: 0.25556066632270813
train loss item: 0.29979294538497925
train loss item: 0.0805220827460289
test loss item: 0.1347884237766266
test loss item: 0.11586551368236542
test loss item: 0.10379587113857269
test loss item: 0.10024574398994446
test loss item: 0.1514817625284195
test loss item: 0.08065396547317505
test loss item: 0.11922412365674973
test loss item: 0.09635693579912186
test loss item: 0.13496583700180054
test loss item: 0.14889170229434967
test loss item: 0.15544112026691437
test loss item: 0.06418699771165848
Epoch [55/100], Training Loss: 0.1543, Testing Loss: 0.1172
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 56/100
train loss item: 0.11850111186504364
train loss item: 0.12047281861305237
train loss item: 0.13444627821445465
train loss item: 0.1990755796432495
train loss item: 0.21628634631633759
train loss item: 0.09840798377990723
train loss item: 0.12412045150995255
train loss item: 0.15745887160301208
train loss item: 0.12901487946510315
train loss item: 0.30421486496925354
train loss item: 0.35950368642807007
train loss item: 0.08885904401540756
test loss item: 0.21824724972248077
test loss item: 0.1517145335674286
test loss item: 0.15133067965507507
test loss item: 0.14020207524299622
test loss item: 0.222748264670372
test loss item: 0.10011979937553406
test loss item: 0.16680659353733063
test loss item: 0.13582798838615417
test loss item: 0.2065763622522354
test loss item: 0.2253338247537613
test loss item: 0.2519388794898987
test loss item: 0.08401859551668167
Epoch [56/100], Training Loss: 0.1709, Testing Loss: 0.1712
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 57/100
train loss item: 0.15758465230464935
train loss item: 0.1009325385093689
train loss item: 0.11784399300813675
train loss item: 0.1791624277830124
train loss item: 0.20723360776901245
train loss item: 0.14891019463539124
train loss item: 0.15028002858161926
train loss item: 0.14784356951713562
train loss item: 0.12327612936496735
train loss item: 0.2516825795173645
train loss item: 0.39144042134284973
train loss item: 0.09411740303039551
test loss item: 0.29022645950317383
test loss item: 0.15995606780052185
test loss item: 0.19033357501029968
test loss item: 0.16594962775707245
test loss item: 0.24404172599315643
test loss item: 0.12711726129055023
test loss item: 0.18017977476119995
test loss item: 0.16972161829471588
test loss item: 0.2659778296947479
test loss item: 0.24511776864528656
test loss item: 0.28992053866386414
test loss item: 0.1237548366189003
Epoch [57/100], Training Loss: 0.1725, Testing Loss: 0.2044
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 58/100
train loss item: 0.19786791503429413
train loss item: 0.12187068164348602
train loss item: 0.13613009452819824
train loss item: 0.1430879682302475
train loss item: 0.15724870562553406
train loss item: 0.19336137175559998
train loss item: 0.16439248621463776
train loss item: 0.17254500091075897
train loss item: 0.17838339507579803
train loss item: 0.1696195751428604
train loss item: 0.38260555267333984
train loss item: 0.1201372891664505
test loss item: 0.26805129647254944
test loss item: 0.14054378867149353
test loss item: 0.1556740403175354
test loss item: 0.15242236852645874
test loss item: 0.20630314946174622
test loss item: 0.11713464558124542
test loss item: 0.14725854992866516
test loss item: 0.12557172775268555
test loss item: 0.23852486908435822
test loss item: 0.23564015328884125
test loss item: 0.26437854766845703
test loss item: 0.10026858001947403
Epoch [58/100], Training Loss: 0.1781, Testing Loss: 0.1793
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 59/100
train loss item: 0.14902395009994507
train loss item: 0.09171460568904877
train loss item: 0.13978718221187592
train loss item: 0.18774688243865967
train loss item: 0.11570370942354202
train loss item: 0.14611247181892395
train loss item: 0.11780692636966705
train loss item: 0.16022592782974243
train loss item: 0.17902417480945587
train loss item: 0.1280575394630432
train loss item: 0.3267785310745239
train loss item: 0.09086714684963226
test loss item: 0.19628381729125977
test loss item: 0.16414396464824677
test loss item: 0.13199900090694427
test loss item: 0.14121514558792114
test loss item: 0.2117292881011963
test loss item: 0.10966629534959793
test loss item: 0.160727396607399
test loss item: 0.11692339926958084
test loss item: 0.18151165544986725
test loss item: 0.21806056797504425
test loss item: 0.25296372175216675
test loss item: 0.1176421195268631
Epoch [59/100], Training Loss: 0.1527, Testing Loss: 0.1669
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 60/100
train loss item: 0.12932802736759186
train loss item: 0.08384575694799423
train loss item: 0.13600078225135803
train loss item: 0.1804719716310501
train loss item: 0.11405134946107864
train loss item: 0.10393259674310684
train loss item: 0.10997305810451508
train loss item: 0.12746864557266235
train loss item: 0.14048977196216583
train loss item: 0.13963700830936432
train loss item: 0.3009214401245117
train loss item: 0.08478711545467377
test loss item: 0.15128427743911743
test loss item: 0.14765897393226624
test loss item: 0.11430023610591888
test loss item: 0.12269729375839233
test loss item: 0.19035589694976807
test loss item: 0.10068217664957047
test loss item: 0.1513640135526657
test loss item: 0.10349477827548981
test loss item: 0.1503632664680481
test loss item: 0.20381677150726318
test loss item: 0.21365568041801453
test loss item: 0.11099527031183243
Epoch [60/100], Training Loss: 0.1376, Testing Loss: 0.1467
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 61/100
train loss item: 0.1282506287097931
train loss item: 0.08733946084976196
train loss item: 0.11999648064374924
train loss item: 0.16202573478221893
train loss item: 0.13644437491893768
train loss item: 0.06847810000181198
train loss item: 0.10366711020469666
train loss item: 0.10296671837568283
train loss item: 0.10422667860984802
train loss item: 0.13575203716754913
train loss item: 0.2710018754005432
train loss item: 0.06839067488908768
test loss item: 0.14840905368328094
test loss item: 0.1253960132598877
test loss item: 0.11981058865785599
test loss item: 0.11239813268184662
test loss item: 0.17192570865154266
test loss item: 0.10685843974351883
test loss item: 0.14247338473796844
test loss item: 0.10227477550506592
test loss item: 0.14927081763744354
test loss item: 0.18464422225952148
test loss item: 0.1784338802099228
test loss item: 0.09076805412769318
Epoch [61/100], Training Loss: 0.1240, Testing Loss: 0.1361
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 62/100
train loss item: 0.13297387957572937
train loss item: 0.11212974041700363
train loss item: 0.10005129873752594
train loss item: 0.14456899464130402
train loss item: 0.12596774101257324
train loss item: 0.058628130704164505
train loss item: 0.09789546579122543
train loss item: 0.10457136482000351
train loss item: 0.09002956748008728
train loss item: 0.13208797574043274
train loss item: 0.25156369805336
train loss item: 0.07516422867774963
test loss item: 0.13768845796585083
test loss item: 0.12289173156023026
test loss item: 0.10302171111106873
test loss item: 0.10546615719795227
test loss item: 0.16410788893699646
test loss item: 0.09187821298837662
test loss item: 0.136127308011055
test loss item: 0.09493036568164825
test loss item: 0.13050498068332672
test loss item: 0.17079773545265198
test loss item: 0.1703346073627472
test loss item: 0.1010480672121048
Epoch [62/100], Training Loss: 0.1188, Testing Loss: 0.1274
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 63/100
train loss item: 0.11256642639636993
train loss item: 0.10144968330860138
train loss item: 0.0884917601943016
train loss item: 0.16128088533878326
train loss item: 0.1365380734205246
train loss item: 0.07191605865955353
train loss item: 0.08775158226490021
train loss item: 0.09492947906255722
train loss item: 0.0868052989244461
train loss item: 0.12089690566062927
train loss item: 0.2544417083263397
train loss item: 0.06861892342567444
test loss item: 0.11663112789392471
test loss item: 0.11425118893384933
test loss item: 0.09170754998922348
test loss item: 0.09330828487873077
test loss item: 0.15024951100349426
test loss item: 0.08020081371068954
test loss item: 0.12082831561565399
test loss item: 0.08376870304346085
test loss item: 0.12055893987417221
test loss item: 0.18542887270450592
test loss item: 0.15678809583187103
test loss item: 0.09850204735994339
Epoch [63/100], Training Loss: 0.1155, Testing Loss: 0.1177
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 64/100
train loss item: 0.10537398606538773
train loss item: 0.08990612626075745
train loss item: 0.09616676717996597
train loss item: 0.1565086543560028
train loss item: 0.12458266317844391
train loss item: 0.05878977105021477
train loss item: 0.09183555841445923
train loss item: 0.10478156059980392
train loss item: 0.0987163782119751
train loss item: 0.13781890273094177
train loss item: 0.2234596461057663
train loss item: 0.07678623497486115
test loss item: 0.10453551262617111
test loss item: 0.08513683825731277
test loss item: 0.07675544917583466
test loss item: 0.07546856999397278
test loss item: 0.1067952886223793
test loss item: 0.06902328133583069
test loss item: 0.08615726977586746
test loss item: 0.06612175703048706
test loss item: 0.09560324996709824
test loss item: 0.11575564742088318
test loss item: 0.11667205393314362
test loss item: 0.06930180639028549
Epoch [64/100], Training Loss: 0.1137, Testing Loss: 0.0889
Best model saved!
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 65/100
train loss item: 0.13503187894821167
train loss item: 0.12390211224555969
train loss item: 0.0860975831747055
train loss item: 0.1389060765504837
train loss item: 0.11674287170171738
train loss item: 0.06724809855222702
train loss item: 0.1064629852771759
train loss item: 0.10688598453998566
train loss item: 0.09609302878379822
train loss item: 0.10436441749334335
train loss item: 0.2195959985256195
train loss item: 0.06274423003196716
test loss item: 0.11848606169223785
test loss item: 0.09724686294794083
test loss item: 0.08759292215108871
test loss item: 0.08782484382390976
test loss item: 0.1442757099866867
test loss item: 0.07553321123123169
test loss item: 0.10604080557823181
test loss item: 0.08495038747787476
test loss item: 0.11325729638338089
test loss item: 0.15849320590496063
test loss item: 0.13842655718326569
test loss item: 0.08051721006631851
Epoch [65/100], Training Loss: 0.1137, Testing Loss: 0.1077
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 66/100
train loss item: 0.1278296560049057
train loss item: 0.13503555953502655
train loss item: 0.09701094776391983
train loss item: 0.16258147358894348
train loss item: 0.12202788144350052
train loss item: 0.07283978909254074
train loss item: 0.13060583174228668
train loss item: 0.15077751874923706
train loss item: 0.11838565021753311
train loss item: 0.1839323341846466
train loss item: 0.2112349271774292
train loss item: 0.06884657591581345
test loss item: 0.21459820866584778
test loss item: 0.10510040819644928
test loss item: 0.11613524705171585
test loss item: 0.12468144297599792
test loss item: 0.15151703357696533
test loss item: 0.09614788740873337
test loss item: 0.10941976308822632
test loss item: 0.09410908818244934
test loss item: 0.17457722127437592
test loss item: 0.14334478974342346
test loss item: 0.17408393323421478
test loss item: 0.06956803053617477
Epoch [66/100], Training Loss: 0.1318, Testing Loss: 0.1311
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 67/100
train loss item: 0.14085979759693146
train loss item: 0.16800318658351898
train loss item: 0.1663532257080078
train loss item: 0.1916627138853073
train loss item: 0.17269808053970337
train loss item: 0.06739316880702972
train loss item: 0.1473524570465088
train loss item: 0.1942695677280426
train loss item: 0.1390787661075592
train loss item: 0.27876731753349304
train loss item: 0.3213987946510315
train loss item: 0.09404641389846802
test loss item: 0.1534942388534546
test loss item: 0.15702885389328003
test loss item: 0.12091945856809616
test loss item: 0.1301943063735962
test loss item: 0.2176847606897354
test loss item: 0.10311971604824066
test loss item: 0.1711745411157608
test loss item: 0.10859716683626175
test loss item: 0.15909171104431152
test loss item: 0.2753017246723175
test loss item: 0.22964340448379517
test loss item: 0.0943058654665947
Epoch [67/100], Training Loss: 0.1735, Testing Loss: 0.1600
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 68/100
train loss item: 0.14460813999176025
train loss item: 0.12293191254138947
train loss item: 0.13564951717853546
train loss item: 0.2078913450241089
train loss item: 0.2216782122850418
train loss item: 0.13781730830669403
train loss item: 0.1211681216955185
train loss item: 0.11253038048744202
train loss item: 0.12878860533237457
train loss item: 0.28550419211387634
train loss item: 0.4532122313976288
train loss item: 0.10035459697246552
test loss item: 0.1860218644142151
test loss item: 0.20991122722625732
test loss item: 0.11810583621263504
test loss item: 0.15956538915634155
test loss item: 0.2750092148780823
test loss item: 0.09539400786161423
test loss item: 0.21279767155647278
test loss item: 0.1162509024143219
test loss item: 0.21121607720851898
test loss item: 0.3918984532356262
test loss item: 0.33457812666893005
test loss item: 0.0888901948928833
Epoch [68/100], Training Loss: 0.1810, Testing Loss: 0.2000
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 69/100
train loss item: 0.2577711343765259
train loss item: 0.10666172951459885
train loss item: 0.09195927530527115
train loss item: 0.10709964483976364
train loss item: 0.1540296971797943
train loss item: 0.26301151514053345
train loss item: 0.24333274364471436
train loss item: 0.2652578055858612
train loss item: 0.20352625846862793
train loss item: 0.15550173819065094
train loss item: 0.3452790379524231
train loss item: 0.12022189050912857
test loss item: 0.19669532775878906
test loss item: 0.2212132215499878
test loss item: 0.13696834444999695
test loss item: 0.1737724244594574
test loss item: 0.2928762435913086
test loss item: 0.11748883873224258
test loss item: 0.2383689135313034
test loss item: 0.14642708003520966
test loss item: 0.2069946974515915
test loss item: 0.338508278131485
test loss item: 0.32738757133483887
test loss item: 0.1137932613492012
Epoch [69/100], Training Loss: 0.1928, Testing Loss: 0.2092
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 70/100
train loss item: 0.23532576858997345
train loss item: 0.15337485074996948
train loss item: 0.1964815855026245
train loss item: 0.31894057989120483
train loss item: 0.19778744876384735
train loss item: 0.10074767470359802
train loss item: 0.12060626596212387
train loss item: 0.20993725955486298
train loss item: 0.21272194385528564
train loss item: 0.17646974325180054
train loss item: 0.16626884043216705
train loss item: 0.16359943151474
test loss item: 0.13890059292316437
test loss item: 0.11326701194047928
test loss item: 0.10282387584447861
test loss item: 0.10352382063865662
test loss item: 0.15120825171470642
test loss item: 0.08289185166358948
test loss item: 0.10973908752202988
test loss item: 0.08644700795412064
test loss item: 0.13539426028728485
test loss item: 0.13562653958797455
test loss item: 0.168544203042984
test loss item: 0.1371990144252777
Epoch [70/100], Training Loss: 0.1877, Testing Loss: 0.1221
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 71/100
train loss item: 0.12985940277576447
train loss item: 0.0885496735572815
train loss item: 0.1426209807395935
train loss item: 0.22584368288516998
train loss item: 0.12618222832679749
train loss item: 0.06711854785680771
train loss item: 0.11045587807893753
train loss item: 0.1461343616247177
train loss item: 0.09874055534601212
train loss item: 0.13844016194343567
train loss item: 0.17472673952579498
train loss item: 0.08458972722291946
test loss item: 0.10490962862968445
test loss item: 0.08653964847326279
test loss item: 0.08611679822206497
test loss item: 0.08318626880645752
test loss item: 0.12514226138591766
test loss item: 0.07668815553188324
test loss item: 0.08879746496677399
test loss item: 0.07962355762720108
test loss item: 0.10586993396282196
test loss item: 0.10655272752046585
test loss item: 0.12344138324260712
test loss item: 0.10830767452716827
Epoch [71/100], Training Loss: 0.1278, Testing Loss: 0.0979
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 72/100
train loss item: 0.14068864285945892
train loss item: 0.0921938344836235
train loss item: 0.08465546369552612
train loss item: 0.0992070734500885
train loss item: 0.09510865062475204
train loss item: 0.0738113597035408
train loss item: 0.09498272091150284
train loss item: 0.08990743011236191
train loss item: 0.07843206077814102
train loss item: 0.13197208940982819
train loss item: 0.20901361107826233
train loss item: 0.06560000777244568
test loss item: 0.13358455896377563
test loss item: 0.11371485888957977
test loss item: 0.10674817860126495
test loss item: 0.10760948807001114
test loss item: 0.1601669192314148
test loss item: 0.09306459128856659
test loss item: 0.13106320798397064
test loss item: 0.1014455035328865
test loss item: 0.12754729390144348
test loss item: 0.14164701104164124
test loss item: 0.15332067012786865
test loss item: 0.10873853415250778
Epoch [72/100], Training Loss: 0.1046, Testing Loss: 0.1232
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 73/100
train loss item: 0.12411575019359589
train loss item: 0.0929858386516571
train loss item: 0.08986981958150864
train loss item: 0.11962293833494186
train loss item: 0.08840671926736832
train loss item: 0.06262566149234772
train loss item: 0.10605310648679733
train loss item: 0.11232893168926239
train loss item: 0.08873772621154785
train loss item: 0.11460749059915543
train loss item: 0.17957530915737152
train loss item: 0.06260887533426285
test loss item: 0.1106676310300827
test loss item: 0.09171926230192184
test loss item: 0.08622314035892487
test loss item: 0.08654215186834335
test loss item: 0.13205689191818237
test loss item: 0.0764249861240387
test loss item: 0.10190364718437195
test loss item: 0.08315884321928024
test loss item: 0.10634556412696838
test loss item: 0.11173701286315918
test loss item: 0.12418416887521744
test loss item: 0.08595184236764908
Epoch [73/100], Training Loss: 0.1035, Testing Loss: 0.0997
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Before cleanup - Allocated memory: 40.15 MB, Reserved memory: 52.00 MB
Epoch 74/100
train loss item: 0.12182953208684921
train loss item: 0.09423324465751648
train loss item: 0.07907717674970627
train loss item: 0.1309041529893875
train loss item: 0.0977729931473732
train loss item: 0.05890130251646042
train loss item: 0.10380017012357712
train loss item: 0.12947164475917816
train loss item: 0.10559114068746567
train loss item: 0.15275894105434418
train loss item: 0.1948716938495636
train loss item: 0.06911014020442963
test loss item: 0.11701208353042603
test loss item: 0.09068664163351059
test loss item: 0.08186028152704239
test loss item: 0.08160829544067383
test loss item: 0.1267118901014328
test loss item: 0.06829322129487991
test loss item: 0.0895872637629509
test loss item: 0.0720858946442604
test loss item: 0.11345528811216354
test loss item: 0.13305485248565674
test loss item: 0.12978434562683105
test loss item: 0.07222522795200348
Epoch [74/100], Training Loss: 0.1115, Testing Loss: 0.0980
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.12907804548740387
loss item: 0.09151472896337509
loss item: 0.09793918579816818
loss item: 0.15082025527954102
loss item: 0.08553998917341232
loss item: 0.12864099442958832
Val Loss: 0.1139
done with hyperparameter tuning training
prediction model: UNet2, learning rate: 0.005, epochs: 100, batch size: 16
Hyperparameter tuning prediction finished
UNet2 with 1 100 0.005 16 360 done at Tue Nov 12 14:44:45 CET 2024
UNet2 with 1 100 0.0001 32 360 start at Tue Nov 12 14:44:45 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.0001 32 360 done at Tue Nov 12 14:44:56 CET 2024
UNet2 with 1 100 0.0005 32 360 start at Tue Nov 12 14:44:56 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.0005 32 360 done at Tue Nov 12 14:45:03 CET 2024
UNet2 with 1 100 0.001 32 360 start at Tue Nov 12 14:45:03 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 100, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.001 32 360 done at Tue Nov 12 14:45:11 CET 2024
UNet2 with 1 100 0.005 32 360 start at Tue Nov 12 14:45:11 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 100, batch size: 32
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.005 32 360 done at Tue Nov 12 14:45:17 CET 2024
UNet2 with 1 100 0.0001 64 360 start at Tue Nov 12 14:45:17 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.0001 64 360 done at Tue Nov 12 14:45:26 CET 2024
UNet2 with 1 100 0.0005 64 360 start at Tue Nov 12 14:45:26 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.0005 64 360 done at Tue Nov 12 14:45:33 CET 2024
UNet2 with 1 100 0.001 64 360 start at Tue Nov 12 14:45:33 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 100, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.001 64 360 done at Tue Nov 12 14:45:40 CET 2024
UNet2 with 1 100 0.005 64 360 start at Tue Nov 12 14:45:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 100, batch size: 64
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.005 64 360 done at Tue Nov 12 14:45:48 CET 2024
UNet2 with 1 100 0.0001 128 360 start at Tue Nov 12 14:45:48 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0001, epochs: 100, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.0001 128 360 done at Tue Nov 12 14:45:56 CET 2024
UNet2 with 1 100 0.0005 128 360 start at Tue Nov 12 14:45:56 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.0005, epochs: 100, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.0005 128 360 done at Tue Nov 12 14:46:03 CET 2024
UNet2 with 1 100 0.001 128 360 start at Tue Nov 12 14:46:03 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.001, epochs: 100, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.001 128 360 done at Tue Nov 12 14:46:10 CET 2024
UNet2 with 1 100 0.005 128 360 start at Tue Nov 12 14:46:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet2, learning rate: 0.005, epochs: 100, batch size: 128
Before cleanup - Allocated memory: 7.18 MB, Reserved memory: 24.00 MB
Epoch 1/100
UNet2 with 1 100 0.005 128 360 done at Tue Nov 12 14:46:17 CET 2024
SBATCH job finished
