SBATCH job
Started 01/11/2024 10:47:08
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
UNet6 with 0.4 0.3 50 0.0001 16 large start at Fri Nov  1 10:47:10 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder is empty
Data loading
Normalization
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 16 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.1109, Validation Loss: 0.0864
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.1021, Validation Loss: 0.0863
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0958, Validation Loss: 0.0862
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0908, Validation Loss: 0.0860
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0872, Validation Loss: 0.0858
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0842, Validation Loss: 0.0855
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0819, Validation Loss: 0.0852
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0813, Validation Loss: 0.0847
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0780, Validation Loss: 0.0839
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0774, Validation Loss: 0.0829
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0758, Validation Loss: 0.0819
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0738, Validation Loss: 0.0808
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0723, Validation Loss: 0.0789
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0704, Validation Loss: 0.0773
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0692, Validation Loss: 0.0751
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0681, Validation Loss: 0.0737
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0667, Validation Loss: 0.0716
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0652, Validation Loss: 0.0695
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0642, Validation Loss: 0.0686
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0631, Validation Loss: 0.0666
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0624, Validation Loss: 0.0662
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0611, Validation Loss: 0.0654
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0608, Validation Loss: 0.0650
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0591, Validation Loss: 0.0630
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0585, Validation Loss: 0.0645
Epoch 26/50
Epoch [26/50], Training Loss: 0.0582, Validation Loss: 0.0628
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0580, Validation Loss: 0.0633
Epoch 28/50
Epoch [28/50], Training Loss: 0.0587, Validation Loss: 0.0634
Epoch 29/50
Epoch [29/50], Training Loss: 0.0574, Validation Loss: 0.0609
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0560, Validation Loss: 0.0605
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0547, Validation Loss: 0.0605
Epoch 32/50
Epoch [32/50], Training Loss: 0.0539, Validation Loss: 0.0594
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0526, Validation Loss: 0.0588
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0518, Validation Loss: 0.0594
Epoch 35/50
Epoch [35/50], Training Loss: 0.0511, Validation Loss: 0.0586
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0512, Validation Loss: 0.0606
Epoch 37/50
Epoch [37/50], Training Loss: 0.0502, Validation Loss: 0.0579
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0503, Validation Loss: 0.0596
Epoch 39/50
Epoch [39/50], Training Loss: 0.0496, Validation Loss: 0.0575
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0501, Validation Loss: 0.0575
Epoch 41/50
Epoch [41/50], Training Loss: 0.0488, Validation Loss: 0.0569
Best model saved!
Epoch 42/50
Epoch [42/50], Training Loss: 0.0473, Validation Loss: 0.0563
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0466, Validation Loss: 0.0561
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0457, Validation Loss: 0.0561
Best model saved!
Epoch 45/50
Epoch [45/50], Training Loss: 0.0449, Validation Loss: 0.0551
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0451, Validation Loss: 0.0544
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0441, Validation Loss: 0.0544
Best model saved!
Epoch 48/50
Epoch [48/50], Training Loss: 0.0433, Validation Loss: 0.0542
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0427, Validation Loss: 0.0538
Best model saved!
Epoch 50/50
Epoch [50/50], Training Loss: 0.0420, Validation Loss: 0.0531
Best model saved!
Test Loss: 0.0369
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 16
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 16 large done at Fri Nov  1 16:30:14 CET 2024
UNet6 with 0.4 0.3 50 0.0001 32 large start at Fri Nov  1 16:30:14 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 32 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0545, Validation Loss: 0.0456
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0513, Validation Loss: 0.0455
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0495, Validation Loss: 0.0455
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0479, Validation Loss: 0.0455
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0462, Validation Loss: 0.0454
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0448, Validation Loss: 0.0454
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0435, Validation Loss: 0.0454
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0424, Validation Loss: 0.0453
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0412, Validation Loss: 0.0452
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0412, Validation Loss: 0.0451
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0399, Validation Loss: 0.0450
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0402, Validation Loss: 0.0450
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0389, Validation Loss: 0.0448
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0387, Validation Loss: 0.0447
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0380, Validation Loss: 0.0446
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0372, Validation Loss: 0.0444
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0367, Validation Loss: 0.0442
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0361, Validation Loss: 0.0439
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0356, Validation Loss: 0.0437
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0349, Validation Loss: 0.0435
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0345, Validation Loss: 0.0431
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0340, Validation Loss: 0.0427
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0335, Validation Loss: 0.0422
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0336, Validation Loss: 0.0418
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0336, Validation Loss: 0.0411
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0344, Validation Loss: 0.0408
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0332, Validation Loss: 0.0405
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0329, Validation Loss: 0.0398
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0326, Validation Loss: 0.0390
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0322, Validation Loss: 0.0385
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0321, Validation Loss: 0.0383
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0317, Validation Loss: 0.0382
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0314, Validation Loss: 0.0378
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0310, Validation Loss: 0.0372
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0308, Validation Loss: 0.0368
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0305, Validation Loss: 0.0364
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0301, Validation Loss: 0.0361
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0299, Validation Loss: 0.0356
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0296, Validation Loss: 0.0351
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0293, Validation Loss: 0.0350
Best model saved!
Epoch 41/50
Epoch [41/50], Training Loss: 0.0290, Validation Loss: 0.0348
Best model saved!
Epoch 42/50
Epoch [42/50], Training Loss: 0.0287, Validation Loss: 0.0346
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0284, Validation Loss: 0.0341
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0282, Validation Loss: 0.0342
Epoch 45/50
Epoch [45/50], Training Loss: 0.0280, Validation Loss: 0.0333
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0284, Validation Loss: 0.0330
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0278, Validation Loss: 0.0333
Epoch 48/50
Epoch [48/50], Training Loss: 0.0279, Validation Loss: 0.0321
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0274, Validation Loss: 0.0321
Epoch 50/50
Epoch [50/50], Training Loss: 0.0271, Validation Loss: 0.0316
Best model saved!
Test Loss: 0.0221
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 32
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 32 large done at Fri Nov  1 22:51:53 CET 2024
UNet6 with 0.4 0.3 50 0.0001 64 large start at Fri Nov  1 22:51:53 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 64 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0545, Validation Loss: 0.0456
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0513, Validation Loss: 0.0455
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0495, Validation Loss: 0.0455
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0479, Validation Loss: 0.0455
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0462, Validation Loss: 0.0454
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0448, Validation Loss: 0.0454
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0435, Validation Loss: 0.0454
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0424, Validation Loss: 0.0453
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0412, Validation Loss: 0.0452
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0412, Validation Loss: 0.0451
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0399, Validation Loss: 0.0450
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0402, Validation Loss: 0.0450
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0389, Validation Loss: 0.0448
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0387, Validation Loss: 0.0447
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0380, Validation Loss: 0.0446
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0372, Validation Loss: 0.0444
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0367, Validation Loss: 0.0442
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0361, Validation Loss: 0.0439
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0356, Validation Loss: 0.0437
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0349, Validation Loss: 0.0435
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0345, Validation Loss: 0.0431
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0340, Validation Loss: 0.0427
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0335, Validation Loss: 0.0422
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0336, Validation Loss: 0.0418
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0336, Validation Loss: 0.0411
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0344, Validation Loss: 0.0408
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0332, Validation Loss: 0.0405
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0329, Validation Loss: 0.0398
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0326, Validation Loss: 0.0390
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0322, Validation Loss: 0.0385
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0321, Validation Loss: 0.0383
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0317, Validation Loss: 0.0382
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0314, Validation Loss: 0.0378
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0310, Validation Loss: 0.0372
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0308, Validation Loss: 0.0368
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0305, Validation Loss: 0.0364
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0301, Validation Loss: 0.0361
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0299, Validation Loss: 0.0356
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0296, Validation Loss: 0.0351
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0293, Validation Loss: 0.0350
Best model saved!
Epoch 41/50
Epoch [41/50], Training Loss: 0.0290, Validation Loss: 0.0348
Best model saved!
Epoch 42/50
Epoch [42/50], Training Loss: 0.0287, Validation Loss: 0.0346
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0284, Validation Loss: 0.0341
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0282, Validation Loss: 0.0342
Epoch 45/50
Epoch [45/50], Training Loss: 0.0280, Validation Loss: 0.0333
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0284, Validation Loss: 0.0330
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0278, Validation Loss: 0.0333
Epoch 48/50
Epoch [48/50], Training Loss: 0.0279, Validation Loss: 0.0321
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0274, Validation Loss: 0.0321
Epoch 50/50
Epoch [50/50], Training Loss: 0.0271, Validation Loss: 0.0316
Best model saved!
Test Loss: 0.0221
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 64
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 64 large done at Sat Nov  2 05:04:52 CET 2024
UNet6 with 0.4 0.3 50 0.0001 128 large start at Sat Nov  2 05:04:52 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 128 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0545, Validation Loss: 0.0456
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0513, Validation Loss: 0.0455
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0495, Validation Loss: 0.0455
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0479, Validation Loss: 0.0455
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0462, Validation Loss: 0.0454
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0448, Validation Loss: 0.0454
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0435, Validation Loss: 0.0454
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0424, Validation Loss: 0.0453
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0412, Validation Loss: 0.0452
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0412, Validation Loss: 0.0451
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0399, Validation Loss: 0.0450
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0402, Validation Loss: 0.0450
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0389, Validation Loss: 0.0448
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0387, Validation Loss: 0.0447
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0380, Validation Loss: 0.0446
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0372, Validation Loss: 0.0444
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0367, Validation Loss: 0.0442
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0361, Validation Loss: 0.0439
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0356, Validation Loss: 0.0437
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0349, Validation Loss: 0.0435
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0345, Validation Loss: 0.0431
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0340, Validation Loss: 0.0427
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0335, Validation Loss: 0.0422
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0336, Validation Loss: 0.0418
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0336, Validation Loss: 0.0411
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0344, Validation Loss: 0.0408
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0332, Validation Loss: 0.0405
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0329, Validation Loss: 0.0398
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0326, Validation Loss: 0.0390
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0322, Validation Loss: 0.0385
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0321, Validation Loss: 0.0383
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0317, Validation Loss: 0.0382
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0314, Validation Loss: 0.0378
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0310, Validation Loss: 0.0372
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0308, Validation Loss: 0.0368
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0305, Validation Loss: 0.0364
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0301, Validation Loss: 0.0361
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0299, Validation Loss: 0.0356
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0296, Validation Loss: 0.0351
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0293, Validation Loss: 0.0350
Best model saved!
Epoch 41/50
Epoch [41/50], Training Loss: 0.0290, Validation Loss: 0.0348
Best model saved!
Epoch 42/50
Epoch [42/50], Training Loss: 0.0287, Validation Loss: 0.0346
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0284, Validation Loss: 0.0341
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0282, Validation Loss: 0.0342
Epoch 45/50
Epoch [45/50], Training Loss: 0.0280, Validation Loss: 0.0333
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0284, Validation Loss: 0.0330
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0278, Validation Loss: 0.0333
Epoch 48/50
Epoch [48/50], Training Loss: 0.0279, Validation Loss: 0.0321
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0274, Validation Loss: 0.0321
Epoch 50/50
Epoch [50/50], Training Loss: 0.0271, Validation Loss: 0.0316
Best model saved!
Test Loss: 0.0221
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 128
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 128 large done at Sat Nov  2 11:17:47 CET 2024
UNet6 with 0.4 0.3 50 0.0001 256 large start at Sat Nov  2 11:17:47 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 256 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0545, Validation Loss: 0.0456
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0513, Validation Loss: 0.0455
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0495, Validation Loss: 0.0455
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0479, Validation Loss: 0.0455
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0462, Validation Loss: 0.0454
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0448, Validation Loss: 0.0454
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0435, Validation Loss: 0.0454
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0424, Validation Loss: 0.0453
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0412, Validation Loss: 0.0452
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0412, Validation Loss: 0.0451
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0399, Validation Loss: 0.0450
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0402, Validation Loss: 0.0450
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0389, Validation Loss: 0.0448
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0387, Validation Loss: 0.0447
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0380, Validation Loss: 0.0446
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0372, Validation Loss: 0.0444
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0367, Validation Loss: 0.0442
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0361, Validation Loss: 0.0439
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0356, Validation Loss: 0.0437
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0349, Validation Loss: 0.0435
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0345, Validation Loss: 0.0431
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0340, Validation Loss: 0.0427
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0335, Validation Loss: 0.0422
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0336, Validation Loss: 0.0418
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0336, Validation Loss: 0.0411
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0344, Validation Loss: 0.0408
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0332, Validation Loss: 0.0405
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0329, Validation Loss: 0.0398
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0326, Validation Loss: 0.0390
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0322, Validation Loss: 0.0385
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0321, Validation Loss: 0.0383
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0317, Validation Loss: 0.0382
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0314, Validation Loss: 0.0378
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0310, Validation Loss: 0.0372
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0308, Validation Loss: 0.0368
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0305, Validation Loss: 0.0364
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0301, Validation Loss: 0.0361
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0299, Validation Loss: 0.0356
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0296, Validation Loss: 0.0351
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0293, Validation Loss: 0.0350
Best model saved!
Epoch 41/50
Epoch [41/50], Training Loss: 0.0290, Validation Loss: 0.0348
Best model saved!
Epoch 42/50
Epoch [42/50], Training Loss: 0.0287, Validation Loss: 0.0346
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0284, Validation Loss: 0.0341
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0282, Validation Loss: 0.0342
Epoch 45/50
Epoch [45/50], Training Loss: 0.0280, Validation Loss: 0.0333
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0284, Validation Loss: 0.0330
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0278, Validation Loss: 0.0333
Epoch 48/50
Epoch [48/50], Training Loss: 0.0279, Validation Loss: 0.0321
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0274, Validation Loss: 0.0321
Epoch 50/50
Epoch [50/50], Training Loss: 0.0271, Validation Loss: 0.0316
Best model saved!
Test Loss: 0.0221
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 256
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 256 large done at Sat Nov  2 17:31:36 CET 2024
SBATCH job finished
