SBATCH job
Started 01/11/2024 10:45:47
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
UNet6 with 0.4 0.3 50 0.0001 32 small start at Fri Nov  1 10:45:48 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 32 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0500, Validation Loss: 0.0523
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0471, Validation Loss: 0.0523
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0454, Validation Loss: 0.0522
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0440, Validation Loss: 0.0522
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0429, Validation Loss: 0.0521
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0419, Validation Loss: 0.0521
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0410, Validation Loss: 0.0520
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0399, Validation Loss: 0.0519
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0385, Validation Loss: 0.0518
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0373, Validation Loss: 0.0517
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0384, Validation Loss: 0.0516
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0358, Validation Loss: 0.0515
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0352, Validation Loss: 0.0514
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0339, Validation Loss: 0.0512
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0334, Validation Loss: 0.0511
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0325, Validation Loss: 0.0509
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0317, Validation Loss: 0.0507
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0313, Validation Loss: 0.0505
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0305, Validation Loss: 0.0502
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0300, Validation Loss: 0.0499
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0296, Validation Loss: 0.0496
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0290, Validation Loss: 0.0494
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0285, Validation Loss: 0.0489
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0279, Validation Loss: 0.0486
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0275, Validation Loss: 0.0482
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0271, Validation Loss: 0.0476
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0267, Validation Loss: 0.0473
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0264, Validation Loss: 0.0466
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0263, Validation Loss: 0.0463
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0271, Validation Loss: 0.0456
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0270, Validation Loss: 0.0450
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0257, Validation Loss: 0.0445
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0258, Validation Loss: 0.0434
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0253, Validation Loss: 0.0423
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0249, Validation Loss: 0.0419
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0249, Validation Loss: 0.0415
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0244, Validation Loss: 0.0407
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0242, Validation Loss: 0.0393
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0238, Validation Loss: 0.0384
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0236, Validation Loss: 0.0386
Epoch 41/50
Epoch [41/50], Training Loss: 0.0233, Validation Loss: 0.0387
Epoch 42/50
Epoch [42/50], Training Loss: 0.0231, Validation Loss: 0.0381
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0227, Validation Loss: 0.0371
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0225, Validation Loss: 0.0362
Best model saved!
Epoch 45/50
Epoch [45/50], Training Loss: 0.0222, Validation Loss: 0.0361
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0220, Validation Loss: 0.0355
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0220, Validation Loss: 0.0360
Epoch 48/50
Epoch [48/50], Training Loss: 0.0221, Validation Loss: 0.0348
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0223, Validation Loss: 0.0351
Epoch 50/50
Epoch [50/50], Training Loss: 0.0214, Validation Loss: 0.0346
Best model saved!
Test Loss: 0.0210
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 32
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 32 small done at Fri Nov  1 12:05:14 CET 2024
UNet6 with 0.4 0.3 50 0.0001 64 small start at Fri Nov  1 12:05:14 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 64 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0500, Validation Loss: 0.0523
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0471, Validation Loss: 0.0523
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0454, Validation Loss: 0.0522
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0440, Validation Loss: 0.0522
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0429, Validation Loss: 0.0521
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0419, Validation Loss: 0.0521
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0410, Validation Loss: 0.0520
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0399, Validation Loss: 0.0519
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0385, Validation Loss: 0.0518
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0373, Validation Loss: 0.0517
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0384, Validation Loss: 0.0516
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0358, Validation Loss: 0.0515
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0352, Validation Loss: 0.0514
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0339, Validation Loss: 0.0512
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0334, Validation Loss: 0.0511
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0325, Validation Loss: 0.0509
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0317, Validation Loss: 0.0507
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0313, Validation Loss: 0.0505
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0305, Validation Loss: 0.0502
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0300, Validation Loss: 0.0499
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0296, Validation Loss: 0.0496
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0290, Validation Loss: 0.0494
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0285, Validation Loss: 0.0489
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0279, Validation Loss: 0.0486
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0275, Validation Loss: 0.0482
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0271, Validation Loss: 0.0476
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0267, Validation Loss: 0.0473
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0264, Validation Loss: 0.0466
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0263, Validation Loss: 0.0463
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0271, Validation Loss: 0.0456
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0270, Validation Loss: 0.0450
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0257, Validation Loss: 0.0445
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0258, Validation Loss: 0.0434
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0253, Validation Loss: 0.0423
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0249, Validation Loss: 0.0419
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0249, Validation Loss: 0.0415
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0244, Validation Loss: 0.0407
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0242, Validation Loss: 0.0393
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0238, Validation Loss: 0.0384
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0236, Validation Loss: 0.0386
Epoch 41/50
Epoch [41/50], Training Loss: 0.0233, Validation Loss: 0.0387
Epoch 42/50
Epoch [42/50], Training Loss: 0.0231, Validation Loss: 0.0381
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0227, Validation Loss: 0.0371
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0225, Validation Loss: 0.0362
Best model saved!
Epoch 45/50
Epoch [45/50], Training Loss: 0.0222, Validation Loss: 0.0361
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0220, Validation Loss: 0.0355
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0220, Validation Loss: 0.0360
Epoch 48/50
Epoch [48/50], Training Loss: 0.0221, Validation Loss: 0.0348
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0223, Validation Loss: 0.0351
Epoch 50/50
Epoch [50/50], Training Loss: 0.0214, Validation Loss: 0.0346
Best model saved!
Test Loss: 0.0210
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 64
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 64 small done at Fri Nov  1 13:22:13 CET 2024
UNet6 with 0.4 0.3 50 0.0001 128 small start at Fri Nov  1 13:22:13 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 128 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0500, Validation Loss: 0.0523
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0471, Validation Loss: 0.0523
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0454, Validation Loss: 0.0522
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0440, Validation Loss: 0.0522
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0429, Validation Loss: 0.0521
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0419, Validation Loss: 0.0521
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0410, Validation Loss: 0.0520
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0399, Validation Loss: 0.0519
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0385, Validation Loss: 0.0518
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0373, Validation Loss: 0.0517
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0384, Validation Loss: 0.0516
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0358, Validation Loss: 0.0515
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0352, Validation Loss: 0.0514
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0339, Validation Loss: 0.0512
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0334, Validation Loss: 0.0511
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0325, Validation Loss: 0.0509
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0317, Validation Loss: 0.0507
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0313, Validation Loss: 0.0505
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0305, Validation Loss: 0.0502
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0300, Validation Loss: 0.0499
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0296, Validation Loss: 0.0496
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0290, Validation Loss: 0.0494
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0285, Validation Loss: 0.0489
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0279, Validation Loss: 0.0486
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0275, Validation Loss: 0.0482
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0271, Validation Loss: 0.0476
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0267, Validation Loss: 0.0473
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0264, Validation Loss: 0.0466
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0263, Validation Loss: 0.0463
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0271, Validation Loss: 0.0456
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0270, Validation Loss: 0.0450
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0257, Validation Loss: 0.0445
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0258, Validation Loss: 0.0434
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0253, Validation Loss: 0.0423
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0249, Validation Loss: 0.0419
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0249, Validation Loss: 0.0415
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0244, Validation Loss: 0.0407
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0242, Validation Loss: 0.0393
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0238, Validation Loss: 0.0384
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0236, Validation Loss: 0.0386
Epoch 41/50
Epoch [41/50], Training Loss: 0.0233, Validation Loss: 0.0387
Epoch 42/50
Epoch [42/50], Training Loss: 0.0231, Validation Loss: 0.0381
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0227, Validation Loss: 0.0371
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0225, Validation Loss: 0.0362
Best model saved!
Epoch 45/50
Epoch [45/50], Training Loss: 0.0222, Validation Loss: 0.0361
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0220, Validation Loss: 0.0355
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0220, Validation Loss: 0.0360
Epoch 48/50
Epoch [48/50], Training Loss: 0.0221, Validation Loss: 0.0348
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0223, Validation Loss: 0.0351
Epoch 50/50
Epoch [50/50], Training Loss: 0.0214, Validation Loss: 0.0346
Best model saved!
Test Loss: 0.0210
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 128
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 128 small done at Fri Nov  1 14:39:19 CET 2024
UNet6 with 0.4 0.3 50 0.0001 256 small start at Fri Nov  1 14:39:19 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 256 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0500, Validation Loss: 0.0523
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0471, Validation Loss: 0.0523
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0454, Validation Loss: 0.0522
Best model saved!
Epoch 4/50
Epoch [4/50], Training Loss: 0.0440, Validation Loss: 0.0522
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0429, Validation Loss: 0.0521
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0419, Validation Loss: 0.0521
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0410, Validation Loss: 0.0520
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0399, Validation Loss: 0.0519
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0385, Validation Loss: 0.0518
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0373, Validation Loss: 0.0517
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0384, Validation Loss: 0.0516
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0358, Validation Loss: 0.0515
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0352, Validation Loss: 0.0514
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0339, Validation Loss: 0.0512
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0334, Validation Loss: 0.0511
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0325, Validation Loss: 0.0509
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0317, Validation Loss: 0.0507
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0313, Validation Loss: 0.0505
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0305, Validation Loss: 0.0502
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0300, Validation Loss: 0.0499
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0296, Validation Loss: 0.0496
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0290, Validation Loss: 0.0494
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0285, Validation Loss: 0.0489
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0279, Validation Loss: 0.0486
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0275, Validation Loss: 0.0482
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0271, Validation Loss: 0.0476
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0267, Validation Loss: 0.0473
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0264, Validation Loss: 0.0466
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0263, Validation Loss: 0.0463
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0271, Validation Loss: 0.0456
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0270, Validation Loss: 0.0450
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0257, Validation Loss: 0.0445
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0258, Validation Loss: 0.0434
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0253, Validation Loss: 0.0423
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0249, Validation Loss: 0.0419
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0249, Validation Loss: 0.0415
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0244, Validation Loss: 0.0407
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0242, Validation Loss: 0.0393
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0238, Validation Loss: 0.0384
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0236, Validation Loss: 0.0386
Epoch 41/50
Epoch [41/50], Training Loss: 0.0233, Validation Loss: 0.0387
Epoch 42/50
Epoch [42/50], Training Loss: 0.0231, Validation Loss: 0.0381
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0227, Validation Loss: 0.0371
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0225, Validation Loss: 0.0362
Best model saved!
Epoch 45/50
Epoch [45/50], Training Loss: 0.0222, Validation Loss: 0.0361
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0220, Validation Loss: 0.0355
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0220, Validation Loss: 0.0360
Epoch 48/50
Epoch [48/50], Training Loss: 0.0221, Validation Loss: 0.0348
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0223, Validation Loss: 0.0351
Epoch 50/50
Epoch [50/50], Training Loss: 0.0214, Validation Loss: 0.0346
Best model saved!
Test Loss: 0.0210
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.0001, Batch size: 256
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.0001 256 small done at Fri Nov  1 15:56:35 CET 2024
SBATCH job finished
