SBATCH job
Started 11/11/2024 09:31:53
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
UNet6 with 1 50 0.0001 128 180 start at Mon Nov 11 09:31:55 CET 2024
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 128
Epoch 1/50
loss item: 1.314956545829773
loss item: 1.270584225654602
loss item: 1.000308871269226
loss item: 0.8740573525428772
loss item: 0.7180201411247253
loss item: 0.7930599451065063
loss item: 1.0123279094696045
loss item: 1.0499740839004517
loss item: 1.5358933210372925
loss item: 1.0992978811264038
loss item: 1.8920927047729492
loss item: 1.501132845878601
Epoch [1/50], Training Loss: 0.9952, Testing Loss: 1.3485
Best model saved!
Epoch 2/50
loss item: 0.8174898624420166
loss item: 0.8407853841781616
loss item: 0.659397542476654
loss item: 0.6148054003715515
loss item: 0.5695058703422546
loss item: 0.6089639067649841
loss item: 0.9603678584098816
loss item: 0.9906255006790161
loss item: 1.455845832824707
loss item: 1.0515450239181519
loss item: 1.7993911504745483
loss item: 1.427668571472168
Epoch [2/50], Training Loss: 0.6852, Testing Loss: 1.2809
Best model saved!
Epoch 3/50
loss item: 0.6391938328742981
loss item: 0.6839631199836731
loss item: 0.5445468425750732
loss item: 0.5269098281860352
loss item: 0.4834650158882141
loss item: 0.5180936455726624
loss item: 0.8731481432914734
loss item: 0.896729052066803
loss item: 1.3159645795822144
loss item: 0.9661827087402344
loss item: 1.6327660083770752
loss item: 1.2965726852416992
Epoch [3/50], Training Loss: 0.5660, Testing Loss: 1.1636
Best model saved!
Epoch 4/50
loss item: 0.5607158541679382
loss item: 0.6133367419242859
loss item: 0.48262345790863037
loss item: 0.46523723006248474
loss item: 0.4250103533267975
loss item: 0.47485992312431335
loss item: 0.7345860600471497
loss item: 0.7495006322860718
loss item: 1.0894299745559692
loss item: 0.8207690715789795
loss item: 1.337998867034912
loss item: 1.0734004974365234
Epoch [4/50], Training Loss: 0.5036, Testing Loss: 0.9676
Best model saved!
Epoch 5/50
loss item: 0.4968300759792328
loss item: 0.5559338331222534
loss item: 0.4318540394306183
loss item: 0.42628517746925354
loss item: 0.407129168510437
loss item: 0.42925190925598145
loss item: 0.5731611251831055
loss item: 0.5829623341560364
loss item: 0.8299558162689209
loss item: 0.6462810039520264
loss item: 1.003731369972229
loss item: 0.8156558871269226
Epoch [5/50], Training Loss: 0.4579, Testing Loss: 0.7420
Best model saved!
Epoch 6/50
loss item: 0.4582401216030121
loss item: 0.5025803446769714
loss item: 0.39606335759162903
loss item: 0.4031449556350708
loss item: 0.37517213821411133
loss item: 0.4022766351699829
loss item: 0.4594845473766327
loss item: 0.46580770611763
loss item: 0.6540349125862122
loss item: 0.523462176322937
loss item: 0.7754417061805725
loss item: 0.6426147222518921
Epoch [6/50], Training Loss: 0.4229, Testing Loss: 0.5868
Best model saved!
Epoch 7/50
loss item: 0.42897096276283264
loss item: 0.47251659631729126
loss item: 0.3699522912502289
loss item: 0.3719806969165802
loss item: 0.35490232706069946
loss item: 0.37631329894065857
loss item: 0.3738951086997986
loss item: 0.3766155540943146
loss item: 0.5156376361846924
loss item: 0.42701077461242676
loss item: 0.5785046815872192
loss item: 0.5039924383163452
Epoch [7/50], Training Loss: 0.3958, Testing Loss: 0.4626
Best model saved!
Epoch 8/50
loss item: 0.39347803592681885
loss item: 0.43900781869888306
loss item: 0.34138306975364685
loss item: 0.35099250078201294
loss item: 0.33376383781433105
loss item: 0.3499657213687897
loss item: 0.3422190248966217
loss item: 0.3439229130744934
loss item: 0.4695473909378052
loss item: 0.39127117395401
loss item: 0.5248457789421082
loss item: 0.4621865153312683
Epoch [8/50], Training Loss: 0.3681, Testing Loss: 0.4223
Best model saved!
Epoch 9/50
loss item: 0.37901073694229126
loss item: 0.41159704327583313
loss item: 0.3174844980239868
loss item: 0.3325675129890442
loss item: 0.31500765681266785
loss item: 0.3314005732536316
loss item: 0.31126219034194946
loss item: 0.3129207193851471
loss item: 0.4189760982990265
loss item: 0.3521842658519745
loss item: 0.45650410652160645
loss item: 0.4120505452156067
Epoch [9/50], Training Loss: 0.3478, Testing Loss: 0.3773
Best model saved!
Epoch 10/50
loss item: 0.34955310821533203
loss item: 0.3849033713340759
loss item: 0.29742729663848877
loss item: 0.30792781710624695
loss item: 0.29873716831207275
loss item: 0.3095741271972656
loss item: 0.2929357886314392
loss item: 0.2934044599533081
loss item: 0.3904168903827667
loss item: 0.32804837822914124
loss item: 0.42890632152557373
loss item: 0.38721874356269836
Epoch [10/50], Training Loss: 0.3247, Testing Loss: 0.3535
Best model saved!
Epoch 11/50
loss item: 0.32989028096199036
loss item: 0.3606360852718353
loss item: 0.2778743803501129
loss item: 0.29521870613098145
loss item: 0.2861981987953186
loss item: 0.29138779640197754
loss item: 0.27919894456863403
loss item: 0.28017690777778625
loss item: 0.3666410744190216
loss item: 0.3080979585647583
loss item: 0.4045148491859436
loss item: 0.36721229553222656
Epoch [11/50], Training Loss: 0.3069, Testing Loss: 0.3343
Best model saved!
Epoch 12/50
loss item: 0.3118159770965576
loss item: 0.3391401767730713
loss item: 0.26034095883369446
loss item: 0.2791765630245209
loss item: 0.26959478855133057
loss item: 0.2752097547054291
loss item: 0.2654249370098114
loss item: 0.26662424206733704
loss item: 0.34346503019332886
loss item: 0.288222074508667
loss item: 0.3765503764152527
loss item: 0.34462878108024597
Epoch [12/50], Training Loss: 0.2892, Testing Loss: 0.3142
Best model saved!
Epoch 13/50
loss item: 0.2941327691078186
loss item: 0.31849798560142517
loss item: 0.24616168439388275
loss item: 0.26635023951530457
loss item: 0.2566799521446228
loss item: 0.25964853167533875
loss item: 0.25324347615242004
loss item: 0.25456443428993225
loss item: 0.32598721981048584
loss item: 0.2730366289615631
loss item: 0.36293983459472656
loss item: 0.3284109830856323
Epoch [13/50], Training Loss: 0.2736, Testing Loss: 0.2997
Best model saved!
Epoch 14/50
loss item: 0.27941450476646423
loss item: 0.3023635447025299
loss item: 0.23341324925422668
loss item: 0.2522580027580261
loss item: 0.24308669567108154
loss item: 0.24661646783351898
loss item: 0.2359846830368042
loss item: 0.23780982196331024
loss item: 0.29883038997650146
loss item: 0.25189024209976196
loss item: 0.33349090814590454
loss item: 0.30213144421577454
Epoch [14/50], Training Loss: 0.2595, Testing Loss: 0.2767
Best model saved!
Epoch 15/50
loss item: 0.26361334323883057
loss item: 0.2853376567363739
loss item: 0.2214600294828415
loss item: 0.2398667335510254
loss item: 0.23146389424800873
loss item: 0.23549620807170868
loss item: 0.22465689480304718
loss item: 0.22707946598529816
loss item: 0.2814360558986664
loss item: 0.23719914257526398
loss item: 0.3144589960575104
loss item: 0.2844190299510956
Epoch [15/50], Training Loss: 0.2462, Testing Loss: 0.2615
Best model saved!
Epoch 16/50
loss item: 0.2503024637699127
loss item: 0.2723146677017212
loss item: 0.21093791723251343
loss item: 0.23004426062107086
loss item: 0.2220442295074463
loss item: 0.22393754124641418
loss item: 0.2147190272808075
loss item: 0.21764226257801056
loss item: 0.26565584540367126
loss item: 0.22419901192188263
loss item: 0.29184284806251526
loss item: 0.26815301179885864
Epoch [16/50], Training Loss: 0.2349, Testing Loss: 0.2470
Best model saved!
Epoch 17/50
loss item: 0.23802973330020905
loss item: 0.25877606868743896
loss item: 0.20214565098285675
loss item: 0.22184231877326965
loss item: 0.21131697297096252
loss item: 0.21466891467571259
loss item: 0.20908841490745544
loss item: 0.21238376200199127
loss item: 0.25660887360572815
loss item: 0.21587298810482025
loss item: 0.2783318758010864
loss item: 0.258955717086792
Epoch [17/50], Training Loss: 0.2245, Testing Loss: 0.2385
Best model saved!
Epoch 18/50
loss item: 0.22894713282585144
loss item: 0.24715600907802582
loss item: 0.1953994631767273
loss item: 0.21614232659339905
loss item: 0.20193463563919067
loss item: 0.20675598084926605
loss item: 0.20404039323329926
loss item: 0.20730562508106232
loss item: 0.25068435072898865
loss item: 0.2106437385082245
loss item: 0.27534404397010803
loss item: 0.2532957196235657
Epoch [18/50], Training Loss: 0.2161, Testing Loss: 0.2336
Best model saved!
Epoch 19/50
loss item: 0.21990536153316498
loss item: 0.23569075763225555
loss item: 0.1901588886976242
loss item: 0.20804159343242645
loss item: 0.19285908341407776
loss item: 0.19979777932167053
loss item: 0.19814236462116241
loss item: 0.2019602656364441
loss item: 0.24426418542861938
loss item: 0.20450879633426666
loss item: 0.2705639600753784
loss item: 0.2471403330564499
Epoch [19/50], Training Loss: 0.2077, Testing Loss: 0.2278
Best model saved!
Epoch 20/50
loss item: 0.21274009346961975
loss item: 0.22610318660736084
loss item: 0.18642044067382812
loss item: 0.20062322914600372
loss item: 0.18429669737815857
loss item: 0.19403225183486938
loss item: 0.1897711306810379
loss item: 0.19370025396347046
loss item: 0.2330678552389145
loss item: 0.19552847743034363
loss item: 0.25875580310821533
loss item: 0.23603537678718567
Epoch [20/50], Training Loss: 0.2007, Testing Loss: 0.2178
Best model saved!
Epoch 21/50
loss item: 0.20541781187057495
loss item: 0.21581487357616425
loss item: 0.18300122022628784
loss item: 0.19511179625988007
loss item: 0.17731979489326477
loss item: 0.18695376813411713
loss item: 0.18323388695716858
loss item: 0.18630634248256683
loss item: 0.22479769587516785
loss item: 0.18906202912330627
loss item: 0.25223398208618164
loss item: 0.22865030169487
Epoch [21/50], Training Loss: 0.1939, Testing Loss: 0.2107
Best model saved!
Epoch 22/50
loss item: 0.20093198120594025
loss item: 0.21170951426029205
loss item: 0.17699019610881805
loss item: 0.1865122765302658
loss item: 0.17196358740329742
loss item: 0.18096870183944702
loss item: 0.18333640694618225
loss item: 0.1868833750486374
loss item: 0.23243838548660278
loss item: 0.1925952136516571
loss item: 0.2868048846721649
loss item: 0.23796389997005463
Epoch [22/50], Training Loss: 0.1882, Testing Loss: 0.2200
no improvement in test loss for 1 epochs
Epoch 23/50
loss item: 0.19381147623062134
loss item: 0.20309659838676453
loss item: 0.1700921207666397
loss item: 0.17894889414310455
loss item: 0.1662900149822235
loss item: 0.1756121665239334
loss item: 0.17237065732479095
loss item: 0.17559805512428284
loss item: 0.20939743518829346
loss item: 0.1767115294933319
loss item: 0.22784246504306793
loss item: 0.21241459250450134
Epoch [23/50], Training Loss: 0.1813, Testing Loss: 0.1957
Best model saved!
Epoch 24/50
loss item: 0.18794524669647217
loss item: 0.2016197293996811
loss item: 0.1650777906179428
loss item: 0.17621168494224548
loss item: 0.17165309190750122
loss item: 0.17205792665481567
loss item: 0.17351995408535004
loss item: 0.17496615648269653
loss item: 0.2121928632259369
loss item: 0.17822378873825073
loss item: 0.23336927592754364
loss item: 0.21585410833358765
Epoch [24/50], Training Loss: 0.1791, Testing Loss: 0.1980
no improvement in test loss for 1 epochs
Epoch 25/50
loss item: 0.1819947361946106
loss item: 0.19690120220184326
loss item: 0.1640593558549881
loss item: 0.17052017152309418
loss item: 0.16763056814670563
loss item: 0.18055544793605804
loss item: 0.16783380508422852
loss item: 0.17203322052955627
loss item: 0.207285076379776
loss item: 0.17224079370498657
loss item: 0.2218085378408432
loss item: 0.21247150003910065
Epoch [25/50], Training Loss: 0.1769, Testing Loss: 0.1923
Best model saved!
Epoch 26/50
loss item: 0.1813390552997589
loss item: 0.18788886070251465
loss item: 0.1666330248117447
loss item: 0.18178561329841614
loss item: 0.1564084142446518
loss item: 0.17519234120845795
loss item: 0.1833968311548233
loss item: 0.18770073354244232
loss item: 0.23416836559772491
loss item: 0.18639706075191498
loss item: 0.2697369158267975
loss item: 0.24104958772659302
Epoch [26/50], Training Loss: 0.1749, Testing Loss: 0.2171
no improvement in test loss for 1 epochs
Epoch 27/50
loss item: 0.19038590788841248
loss item: 0.18123869597911835
loss item: 0.15630489587783813
loss item: 0.1738806515932083
loss item: 0.16737942397594452
loss item: 0.16623108088970184
loss item: 0.16629502177238464
loss item: 0.17058445513248444
loss item: 0.21433259546756744
loss item: 0.17151665687561035
loss item: 0.23623380064964294
loss item: 0.21625623106956482
Epoch [27/50], Training Loss: 0.1726, Testing Loss: 0.1959
no improvement in test loss for 2 epochs
Epoch 28/50
loss item: 0.1674310564994812
loss item: 0.17519596219062805
loss item: 0.18278217315673828
loss item: 0.16710855066776276
loss item: 0.15200209617614746
loss item: 0.17428117990493774
loss item: 0.18704035878181458
loss item: 0.18804754316806793
loss item: 0.24061685800552368
loss item: 0.19659189879894257
loss item: 0.29196175932884216
loss item: 0.24661721289157867
Epoch [28/50], Training Loss: 0.1698, Testing Loss: 0.2251
no improvement in test loss for 3 epochs
Epoch 29/50
loss item: 0.20008493959903717
loss item: 0.1875532865524292
loss item: 0.16192181408405304
loss item: 0.18444642424583435
loss item: 0.1643044501543045
loss item: 0.16955550014972687
loss item: 0.17258936166763306
loss item: 0.17565876245498657
loss item: 0.21984770894050598
loss item: 0.1788286417722702
loss item: 0.24904829263687134
loss item: 0.22296413779258728
Epoch [29/50], Training Loss: 0.1780, Testing Loss: 0.2032
no improvement in test loss for 4 epochs
Epoch 30/50
loss item: 0.18440279364585876
loss item: 0.17832858860492706
loss item: 0.1587371528148651
loss item: 0.1772146373987198
loss item: 0.1492040902376175
loss item: 0.16953948140144348
loss item: 0.16340111196041107
loss item: 0.1663980633020401
loss item: 0.1987830251455307
loss item: 0.16636188328266144
loss item: 0.21841469407081604
loss item: 0.20252124965190887
Epoch [30/50], Training Loss: 0.1696, Testing Loss: 0.1860
Best model saved!
Epoch 31/50
loss item: 0.17246489226818085
loss item: 0.17914605140686035
loss item: 0.1709839105606079
loss item: 0.15382899343967438
loss item: 0.14143240451812744
loss item: 0.188370943069458
loss item: 0.1601412296295166
loss item: 0.1622220277786255
loss item: 0.19533030688762665
loss item: 0.1629513055086136
loss item: 0.22015012800693512
loss item: 0.19858288764953613
Epoch [31/50], Training Loss: 0.1677, Testing Loss: 0.1832
Best model saved!
Epoch 32/50
loss item: 0.17108850181102753
loss item: 0.17075392603874207
loss item: 0.16113680601119995
loss item: 0.1662844717502594
loss item: 0.15596014261245728
loss item: 0.16660760343074799
loss item: 0.16274595260620117
loss item: 0.1678139865398407
loss item: 0.20301884412765503
loss item: 0.16298899054527283
loss item: 0.21210825443267822
loss item: 0.19863292574882507
Epoch [32/50], Training Loss: 0.1653, Testing Loss: 0.1846
no improvement in test loss for 1 epochs
Epoch 33/50
loss item: 0.16727320849895477
loss item: 0.188912495970726
loss item: 0.14413180947303772
loss item: 0.14397107064723969
loss item: 0.17708905041217804
loss item: 0.15907351672649384
loss item: 0.14355048537254333
loss item: 0.14648370444774628
loss item: 0.17249350249767303
loss item: 0.1453639268875122
loss item: 0.18741239607334137
loss item: 0.17524653673171997
Epoch [33/50], Training Loss: 0.1634, Testing Loss: 0.1618
Best model saved!
Epoch 34/50
loss item: 0.15721066296100616
loss item: 0.17146143317222595
loss item: 0.1665204018354416
loss item: 0.17512977123260498
loss item: 0.14673404395580292
loss item: 0.14582514762878418
loss item: 0.16701404750347137
loss item: 0.1686231791973114
loss item: 0.20883168280124664
loss item: 0.17021030187606812
loss item: 0.2402251660823822
loss item: 0.20978181064128876
Epoch [34/50], Training Loss: 0.1605, Testing Loss: 0.1941
no improvement in test loss for 1 epochs
Epoch 35/50
loss item: 0.17090223729610443
loss item: 0.1666622906923294
loss item: 0.13916771113872528
loss item: 0.14671246707439423
loss item: 0.13813434541225433
loss item: 0.15798409283161163
loss item: 0.13957563042640686
loss item: 0.14241552352905273
loss item: 0.17516972124576569
loss item: 0.144767165184021
loss item: 0.19616469740867615
loss item: 0.1799350380897522
Epoch [35/50], Training Loss: 0.1533, Testing Loss: 0.1630
no improvement in test loss for 2 epochs
Epoch 36/50
loss item: 0.14920201897621155
loss item: 0.15283524990081787
loss item: 0.14123541116714478
loss item: 0.14686240255832672
loss item: 0.13715742528438568
loss item: 0.1464383602142334
loss item: 0.1525883972644806
loss item: 0.1549190729856491
loss item: 0.19648490846157074
loss item: 0.15760071575641632
loss item: 0.21405553817749023
loss item: 0.19782181084156036
Epoch [36/50], Training Loss: 0.1456, Testing Loss: 0.1789
no improvement in test loss for 3 epochs
Epoch 37/50
loss item: 0.15013627707958221
loss item: 0.1513715386390686
loss item: 0.14791584014892578
loss item: 0.1351434588432312
loss item: 0.1476549655199051
loss item: 0.16503353416919708
loss item: 0.13778604567050934
loss item: 0.13837914168834686
loss item: 0.16629205644130707
loss item: 0.14226646721363068
loss item: 0.1893976926803589
loss item: 0.17091213166713715
Epoch [37/50], Training Loss: 0.1495, Testing Loss: 0.1575
Best model saved!
Epoch 38/50
loss item: 0.15485608577728271
loss item: 0.15025103092193604
loss item: 0.15305718779563904
loss item: 0.1733763962984085
loss item: 0.1427987962961197
loss item: 0.13961493968963623
loss item: 0.15216821432113647
loss item: 0.15298593044281006
loss item: 0.1869678795337677
loss item: 0.1558041125535965
loss item: 0.21500468254089355
loss item: 0.1902443915605545
Epoch [38/50], Training Loss: 0.1523, Testing Loss: 0.1755
no improvement in test loss for 1 epochs
Epoch 39/50
loss item: 0.1704123318195343
loss item: 0.17042122781276703
loss item: 0.13222265243530273
loss item: 0.1361965835094452
loss item: 0.13647997379302979
loss item: 0.14172929525375366
loss item: 0.13330312073230743
loss item: 0.13471511006355286
loss item: 0.16201360523700714
loss item: 0.1362006962299347
loss item: 0.17774997651576996
loss item: 0.1648898869752884
Epoch [39/50], Training Loss: 0.1479, Testing Loss: 0.1515
Best model saved!
Epoch 40/50
loss item: 0.14134137332439423
loss item: 0.14129577577114105
loss item: 0.1316513568162918
loss item: 0.13940513134002686
loss item: 0.12659890949726105
loss item: 0.13368336856365204
loss item: 0.13412727415561676
loss item: 0.13675910234451294
loss item: 0.16473111510276794
loss item: 0.13648712635040283
loss item: 0.1813591718673706
loss item: 0.1672932505607605
Epoch [40/50], Training Loss: 0.1357, Testing Loss: 0.1535
no improvement in test loss for 1 epochs
Epoch 41/50
loss item: 0.14363333582878113
loss item: 0.14010083675384521
loss item: 0.14009688794612885
loss item: 0.14236702024936676
loss item: 0.1293049156665802
loss item: 0.15639950335025787
loss item: 0.14526285231113434
loss item: 0.1453286111354828
loss item: 0.1827474981546402
loss item: 0.1525232195854187
loss item: 0.22027429938316345
loss item: 0.18782445788383484
Epoch [41/50], Training Loss: 0.1420, Testing Loss: 0.1723
no improvement in test loss for 2 epochs
Epoch 42/50
loss item: 0.15723374485969543
loss item: 0.15075592696666718
loss item: 0.13452871143817902
loss item: 0.14650416374206543
loss item: 0.12991052865982056
loss item: 0.13542093336582184
loss item: 0.1284889578819275
loss item: 0.12943482398986816
loss item: 0.15238241851329803
loss item: 0.1309758871793747
loss item: 0.17012938857078552
loss item: 0.15511436760425568
Epoch [42/50], Training Loss: 0.1424, Testing Loss: 0.1444
Best model saved!
Epoch 43/50
loss item: 0.14442375302314758
loss item: 0.150535449385643
loss item: 0.12638945877552032
loss item: 0.12591247260570526
loss item: 0.12340936809778214
loss item: 0.1339479386806488
loss item: 0.1304379105567932
loss item: 0.1316555142402649
loss item: 0.16271492838859558
loss item: 0.1354726403951645
loss item: 0.1786193996667862
loss item: 0.16593100130558014
Epoch [43/50], Training Loss: 0.1341, Testing Loss: 0.1508
no improvement in test loss for 1 epochs
Epoch 44/50
loss item: 0.1315901279449463
loss item: 0.1353633850812912
loss item: 0.12440813332796097
loss item: 0.12674656510353088
loss item: 0.12694695591926575
loss item: 0.1304549127817154
loss item: 0.12686237692832947
loss item: 0.1295466423034668
loss item: 0.1551586389541626
loss item: 0.1290172040462494
loss item: 0.17096512019634247
loss item: 0.15758740901947021
Epoch [44/50], Training Loss: 0.1293, Testing Loss: 0.1449
no improvement in test loss for 2 epochs
Epoch 45/50
loss item: 0.1360010802745819
loss item: 0.13302983343601227
loss item: 0.13335061073303223
loss item: 0.13713034987449646
loss item: 0.11942543834447861
loss item: 0.12997569143772125
loss item: 0.14375105500221252
loss item: 0.14644509553909302
loss item: 0.17369943857192993
loss item: 0.14190642535686493
loss item: 0.19194938242435455
loss item: 0.17448459565639496
Epoch [45/50], Training Loss: 0.1315, Testing Loss: 0.1620
no improvement in test loss for 3 epochs
Epoch 46/50
loss item: 0.1499134600162506
loss item: 0.133869007229805
loss item: 0.1252327859401703
loss item: 0.14401832222938538
loss item: 0.11702778190374374
loss item: 0.1308647096157074
loss item: 0.13600985705852509
loss item: 0.1378374844789505
loss item: 0.16321483254432678
loss item: 0.13669517636299133
loss item: 0.18254049122333527
loss item: 0.16630354523658752
Epoch [46/50], Training Loss: 0.1335, Testing Loss: 0.1538
no improvement in test loss for 4 epochs
Epoch 47/50
loss item: 0.14145128428936005
loss item: 0.13948221504688263
loss item: 0.12458052486181259
loss item: 0.1236632838845253
loss item: 0.1152193620800972
loss item: 0.13812293112277985
loss item: 0.12077970802783966
loss item: 0.12210816890001297
loss item: 0.14481239020824432
loss item: 0.1228899136185646
loss item: 0.15713931620121002
loss item: 0.14628955721855164
Epoch [47/50], Training Loss: 0.1304, Testing Loss: 0.1357
Best model saved!
Epoch 48/50
loss item: 0.12504743039608002
loss item: 0.1286744475364685
loss item: 0.12377265840768814
loss item: 0.11813165992498398
loss item: 0.11834307014942169
loss item: 0.12726274132728577
loss item: 0.1323949098587036
loss item: 0.1341685652732849
loss item: 0.15793024003505707
loss item: 0.1311434507369995
loss item: 0.16712428629398346
loss item: 0.1606270968914032
Epoch [48/50], Training Loss: 0.1235, Testing Loss: 0.1472
no improvement in test loss for 1 epochs
Epoch 49/50
loss item: 0.12562395632266998
loss item: 0.13288336992263794
loss item: 0.11764208227396011
loss item: 0.11412166804075241
loss item: 0.12627989053726196
loss item: 0.12552829086780548
loss item: 0.11874610185623169
loss item: 0.12152978777885437
loss item: 0.14353808760643005
loss item: 0.12026415765285492
loss item: 0.15646757185459137
loss item: 0.14479592442512512
Epoch [49/50], Training Loss: 0.1237, Testing Loss: 0.1342
Best model saved!
Epoch 50/50
loss item: 0.12673690915107727
loss item: 0.12859779596328735
loss item: 0.12603065371513367
loss item: 0.13895416259765625
loss item: 0.10985974967479706
loss item: 0.12054122239351273
loss item: 0.14163580536842346
loss item: 0.1433030515909195
loss item: 0.16884011030197144
loss item: 0.1380547434091568
loss item: 0.18135260045528412
loss item: 0.1698358803987503
Epoch [50/50], Training Loss: 0.1251, Testing Loss: 0.1572
no improvement in test loss for 1 epochs
loss item: 0.14870242774486542
loss item: 0.1462678164243698
loss item: 0.1173238530755043
Val Loss: 0.2749
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 128
Hyperparameter tuning prediction finished
UNet6 with 1 50 0.0001 128 180 done at Mon Nov 11 17:37:54 CET 2024
SBATCH job finished
