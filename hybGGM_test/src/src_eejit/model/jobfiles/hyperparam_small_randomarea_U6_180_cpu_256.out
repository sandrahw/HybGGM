SBATCH job
Started 11/11/2024 09:33:00
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
UNet6 with 1 50 0.0001 256 180 start at Mon Nov 11 09:33:01 CET 2024
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 256
Epoch 1/50
loss item: 1.3577042818069458
loss item: 1.052114486694336
loss item: 0.9016825556755066
loss item: 1.0450842380523682
loss item: 1.3479571342468262
loss item: 1.7732435464859009
Epoch [1/50], Training Loss: 1.1038, Testing Loss: 1.3888
Best model saved!
Epoch 2/50
loss item: 1.030579924583435
loss item: 0.7989593148231506
loss item: 0.6922342777252197
loss item: 1.0307279825210571
loss item: 1.3334324359893799
loss item: 1.7554198503494263
Epoch [2/50], Training Loss: 0.8406, Testing Loss: 1.3732
Best model saved!
Epoch 3/50
loss item: 0.8323107361793518
loss item: 0.6536296606063843
loss item: 0.5978716015815735
loss item: 1.0073248147964478
loss item: 1.306499719619751
loss item: 1.7206844091415405
Epoch [3/50], Training Loss: 0.6946, Testing Loss: 1.3448
Best model saved!
Epoch 4/50
loss item: 0.709069013595581
loss item: 0.5806013941764832
loss item: 0.5404891967773438
loss item: 0.97467041015625
loss item: 1.2667075395584106
loss item: 1.6678557395935059
Epoch [4/50], Training Loss: 0.6101, Testing Loss: 1.3031
Best model saved!
Epoch 5/50
loss item: 0.6409662961959839
loss item: 0.526256799697876
loss item: 0.4875252842903137
loss item: 0.9325168132781982
loss item: 1.2135590314865112
loss item: 1.5965293645858765
Epoch [5/50], Training Loss: 0.5516, Testing Loss: 1.2475
Best model saved!
Epoch 6/50
loss item: 0.5962826609611511
loss item: 0.4853236675262451
loss item: 0.4516189396381378
loss item: 0.876752495765686
loss item: 1.1405302286148071
loss item: 1.4943963289260864
Epoch [6/50], Training Loss: 0.5111, Testing Loss: 1.1706
Best model saved!
Epoch 7/50
loss item: 0.5565994381904602
loss item: 0.455722838640213
loss item: 0.42387598752975464
loss item: 0.805592954158783
loss item: 1.0474281311035156
loss item: 1.3640103340148926
Epoch [7/50], Training Loss: 0.4787, Testing Loss: 1.0723
Best model saved!
Epoch 8/50
loss item: 0.5244117379188538
loss item: 0.4303714334964752
loss item: 0.4043624699115753
loss item: 0.7218907475471497
loss item: 0.9369964599609375
loss item: 1.2092481851577759
Epoch [8/50], Training Loss: 0.4530, Testing Loss: 0.9560
Best model saved!
Epoch 9/50
loss item: 0.49390706419944763
loss item: 0.4089999496936798
loss item: 0.38854318857192993
loss item: 0.6397037506103516
loss item: 0.8251729607582092
loss item: 1.0530868768692017
Epoch [9/50], Training Loss: 0.4305, Testing Loss: 0.8393
Best model saved!
Epoch 10/50
loss item: 0.4682265520095825
loss item: 0.3912578523159027
loss item: 0.370794415473938
loss item: 0.5647528767585754
loss item: 0.7229986786842346
loss item: 0.9095145463943481
Epoch [10/50], Training Loss: 0.4101, Testing Loss: 0.7324
Best model saved!
Epoch 11/50
loss item: 0.448869913816452
loss item: 0.37313219904899597
loss item: 0.35430043935775757
loss item: 0.489762544631958
loss item: 0.6234304904937744
loss item: 0.7664126753807068
Epoch [11/50], Training Loss: 0.3921, Testing Loss: 0.6265
Best model saved!
Epoch 12/50
loss item: 0.4295561611652374
loss item: 0.35638856887817383
loss item: 0.3397676646709442
loss item: 0.4272981286048889
loss item: 0.542471170425415
loss item: 0.6516814827919006
Epoch [12/50], Training Loss: 0.3752, Testing Loss: 0.5405
Best model saved!
Epoch 13/50
loss item: 0.4116065800189972
loss item: 0.3397902250289917
loss item: 0.3247423470020294
loss item: 0.3845091760158539
loss item: 0.48914116621017456
loss item: 0.5800808668136597
Epoch [13/50], Training Loss: 0.3587, Testing Loss: 0.4846
Best model saved!
Epoch 14/50
loss item: 0.3953460454940796
loss item: 0.3255102038383484
loss item: 0.31104427576065063
loss item: 0.3527974486351013
loss item: 0.44786858558654785
loss item: 0.5222465395927429
Epoch [14/50], Training Loss: 0.3440, Testing Loss: 0.4410
Best model saved!
Epoch 15/50
loss item: 0.3794931173324585
loss item: 0.31023702025413513
loss item: 0.29898953437805176
loss item: 0.32719099521636963
loss item: 0.41233184933662415
loss item: 0.47259706258773804
Epoch [15/50], Training Loss: 0.3296, Testing Loss: 0.4040
Best model saved!
Epoch 16/50
loss item: 0.36283478140830994
loss item: 0.2978343963623047
loss item: 0.28701159358024597
loss item: 0.3101162910461426
loss item: 0.386066198348999
loss item: 0.4395064115524292
Epoch [16/50], Training Loss: 0.3159, Testing Loss: 0.3786
Best model saved!
Epoch 17/50
loss item: 0.34772196412086487
loss item: 0.2849903106689453
loss item: 0.2758064568042755
loss item: 0.2923465967178345
loss item: 0.36026498675346375
loss item: 0.4107447862625122
Epoch [17/50], Training Loss: 0.3028, Testing Loss: 0.3545
Best model saved!
Epoch 18/50
loss item: 0.3325907289981842
loss item: 0.27383485436439514
loss item: 0.2656311094760895
loss item: 0.2803463339805603
loss item: 0.3401666581630707
loss item: 0.386038601398468
Epoch [18/50], Training Loss: 0.2907, Testing Loss: 0.3355
Best model saved!
Epoch 19/50
loss item: 0.31945672631263733
loss item: 0.26233533024787903
loss item: 0.2549295723438263
loss item: 0.2649630606174469
loss item: 0.31981566548347473
loss item: 0.3631857633590698
Epoch [19/50], Training Loss: 0.2789, Testing Loss: 0.3160
Best model saved!
Epoch 20/50
loss item: 0.3063310980796814
loss item: 0.25198376178741455
loss item: 0.24517396092414856
loss item: 0.25749823451042175
loss item: 0.30601346492767334
loss item: 0.3480284810066223
Epoch [20/50], Training Loss: 0.2678, Testing Loss: 0.3038
Best model saved!
Epoch 21/50
loss item: 0.2950952649116516
loss item: 0.24197708070278168
loss item: 0.23578554391860962
loss item: 0.24394412338733673
loss item: 0.2873116433620453
loss item: 0.32822003960609436
Epoch [21/50], Training Loss: 0.2576, Testing Loss: 0.2865
Best model saved!
Epoch 22/50
loss item: 0.28255319595336914
loss item: 0.23301921784877777
loss item: 0.22733105719089508
loss item: 0.23501592874526978
loss item: 0.27340832352638245
loss item: 0.31197699904441833
Epoch [22/50], Training Loss: 0.2476, Testing Loss: 0.2735
Best model saved!
Epoch 23/50
loss item: 0.2716522216796875
loss item: 0.2248951643705368
loss item: 0.21907252073287964
loss item: 0.22851933538913727
loss item: 0.26245102286338806
loss item: 0.2988000810146332
Epoch [23/50], Training Loss: 0.2385, Testing Loss: 0.2633
Best model saved!
Epoch 24/50
loss item: 0.26149091124534607
loss item: 0.21706873178482056
loss item: 0.21185442805290222
loss item: 0.21853899955749512
loss item: 0.2495609074831009
loss item: 0.28418517112731934
Epoch [24/50], Training Loss: 0.2301, Testing Loss: 0.2508
Best model saved!
Epoch 25/50
loss item: 0.2511955201625824
loss item: 0.2101961225271225
loss item: 0.2051617056131363
loss item: 0.21312783658504486
loss item: 0.2419026643037796
loss item: 0.2771753966808319
Epoch [25/50], Training Loss: 0.2222, Testing Loss: 0.2441
Best model saved!
Epoch 26/50
loss item: 0.24303090572357178
loss item: 0.2037731260061264
loss item: 0.19928018748760223
loss item: 0.20911090075969696
loss item: 0.23586246371269226
loss item: 0.27017807960510254
Epoch [26/50], Training Loss: 0.2154, Testing Loss: 0.2384
Best model saved!
Epoch 27/50
loss item: 0.23481525480747223
loss item: 0.1976948082447052
loss item: 0.19325479865074158
loss item: 0.2022448033094406
loss item: 0.22769968211650848
loss item: 0.2629064619541168
Epoch [27/50], Training Loss: 0.2086, Testing Loss: 0.2310
Best model saved!
Epoch 28/50
loss item: 0.22647102177143097
loss item: 0.1927369385957718
loss item: 0.19032560288906097
loss item: 0.19777534902095795
loss item: 0.22483935952186584
loss item: 0.2554662525653839
Epoch [28/50], Training Loss: 0.2032, Testing Loss: 0.2260
Best model saved!
Epoch 29/50
loss item: 0.21827799081802368
loss item: 0.1926301270723343
loss item: 0.18439047038555145
loss item: 0.20454153418540955
loss item: 0.23866848647594452
loss item: 0.29407310485839844
Epoch [29/50], Training Loss: 0.1984, Testing Loss: 0.2458
no improvement in test loss for 1 epochs
Epoch 30/50
loss item: 0.22236615419387817
loss item: 0.1834084391593933
loss item: 0.1846666932106018
loss item: 0.18532569706439972
loss item: 0.2070320099592209
loss item: 0.24077653884887695
Epoch [30/50], Training Loss: 0.1968, Testing Loss: 0.2110
Best model saved!
Epoch 31/50
loss item: 0.20899178087711334
loss item: 0.17943105101585388
loss item: 0.17740607261657715
loss item: 0.18829986453056335
loss item: 0.21360892057418823
loss item: 0.252239853143692
Epoch [31/50], Training Loss: 0.1886, Testing Loss: 0.2180
no improvement in test loss for 1 epochs
Epoch 32/50
loss item: 0.20225383341312408
loss item: 0.1805877536535263
loss item: 0.1726304441690445
loss item: 0.18833698332309723
loss item: 0.20783744752407074
loss item: 0.2416815608739853
Epoch [32/50], Training Loss: 0.1852, Testing Loss: 0.2126
no improvement in test loss for 2 epochs
Epoch 33/50
loss item: 0.19962655007839203
loss item: 0.17353549599647522
loss item: 0.1704282909631729
loss item: 0.17481909692287445
loss item: 0.195291668176651
loss item: 0.2264218032360077
Epoch [33/50], Training Loss: 0.1812, Testing Loss: 0.1988
Best model saved!
Epoch 34/50
loss item: 0.19521814584732056
loss item: 0.18142449855804443
loss item: 0.1695960909128189
loss item: 0.18283326923847198
loss item: 0.20860536396503448
loss item: 0.25833559036254883
Epoch [34/50], Training Loss: 0.1821, Testing Loss: 0.2166
no improvement in test loss for 1 epochs
Epoch 35/50
loss item: 0.19724024832248688
loss item: 0.1680503785610199
loss item: 0.16763389110565186
loss item: 0.17925812304019928
loss item: 0.1972741037607193
loss item: 0.23000092804431915
Epoch [35/50], Training Loss: 0.1776, Testing Loss: 0.2022
no improvement in test loss for 2 epochs
Epoch 36/50
loss item: 0.18938401341438293
loss item: 0.16302844882011414
loss item: 0.16063277423381805
loss item: 0.16889339685440063
loss item: 0.18693558871746063
loss item: 0.21580767631530762
Epoch [36/50], Training Loss: 0.1710, Testing Loss: 0.1905
Best model saved!
Epoch 37/50
loss item: 0.18230783939361572
loss item: 0.1645137369632721
loss item: 0.15712152421474457
loss item: 0.1662324219942093
loss item: 0.18577541410923004
loss item: 0.22055557370185852
Epoch [37/50], Training Loss: 0.1680, Testing Loss: 0.1909
no improvement in test loss for 1 epochs
Epoch 38/50
loss item: 0.18439263105392456
loss item: 0.15577104687690735
loss item: 0.15665896236896515
loss item: 0.16331446170806885
loss item: 0.18198946118354797
loss item: 0.21187959611415863
Epoch [38/50], Training Loss: 0.1656, Testing Loss: 0.1857
Best model saved!
Epoch 39/50
loss item: 0.17277540266513824
loss item: 0.15450848639011383
loss item: 0.15202981233596802
loss item: 0.16639868915081024
loss item: 0.19525577127933502
loss item: 0.23244845867156982
Epoch [39/50], Training Loss: 0.1598, Testing Loss: 0.1980
no improvement in test loss for 1 epochs
Epoch 40/50
loss item: 0.1691029816865921
loss item: 0.15597301721572876
loss item: 0.15319694578647614
loss item: 0.15780502557754517
loss item: 0.17510081827640533
loss item: 0.20435017347335815
Epoch [40/50], Training Loss: 0.1594, Testing Loss: 0.1791
Best model saved!
Epoch 41/50
loss item: 0.16909460723400116
loss item: 0.1568506509065628
loss item: 0.14917652308940887
loss item: 0.15436847507953644
loss item: 0.17241963744163513
loss item: 0.20160111784934998
Epoch [41/50], Training Loss: 0.1584, Testing Loss: 0.1761
Best model saved!
Epoch 42/50
loss item: 0.16925044357776642
loss item: 0.14814884960651398
loss item: 0.16160868108272552
loss item: 0.15652982890605927
loss item: 0.17815716564655304
loss item: 0.20865082740783691
Epoch [42/50], Training Loss: 0.1597, Testing Loss: 0.1811
no improvement in test loss for 1 epochs
Epoch 43/50
loss item: 0.16029958426952362
loss item: 0.14513836801052094
loss item: 0.14802251756191254
loss item: 0.1511976420879364
loss item: 0.16995127499103546
loss item: 0.19635172188282013
Epoch [43/50], Training Loss: 0.1512, Testing Loss: 0.1725
Best model saved!
Epoch 44/50
loss item: 0.16047102212905884
loss item: 0.15888866782188416
loss item: 0.14211194217205048
loss item: 0.15389277040958405
loss item: 0.17475321888923645
loss item: 0.20815739035606384
Epoch [44/50], Training Loss: 0.1538, Testing Loss: 0.1789
no improvement in test loss for 1 epochs
Epoch 45/50
loss item: 0.1677158623933792
loss item: 0.14279280602931976
loss item: 0.13918562233448029
loss item: 0.16439414024353027
loss item: 0.19788959622383118
loss item: 0.2403346300125122
Epoch [45/50], Training Loss: 0.1499, Testing Loss: 0.2009
no improvement in test loss for 2 epochs
Epoch 46/50
loss item: 0.1560506671667099
loss item: 0.15040700137615204
loss item: 0.13808313012123108
loss item: 0.14784124493598938
loss item: 0.16482897102832794
loss item: 0.20079831779003143
Epoch [46/50], Training Loss: 0.1482, Testing Loss: 0.1712
Best model saved!
Epoch 47/50
loss item: 0.16316790878772736
loss item: 0.13679413497447968
loss item: 0.13942700624465942
loss item: 0.1548243761062622
loss item: 0.18446864187717438
loss item: 0.22666403651237488
Epoch [47/50], Training Loss: 0.1465, Testing Loss: 0.1887
no improvement in test loss for 1 epochs
Epoch 48/50
loss item: 0.149976909160614
loss item: 0.1342199295759201
loss item: 0.1367526650428772
loss item: 0.1429273635149002
loss item: 0.15986284613609314
loss item: 0.18674185872077942
Epoch [48/50], Training Loss: 0.1403, Testing Loss: 0.1632
Best model saved!
Epoch 49/50
loss item: 0.1466394066810608
loss item: 0.13601981103420258
loss item: 0.13322550058364868
loss item: 0.13787898421287537
loss item: 0.15290838479995728
loss item: 0.17720063030719757
Epoch [49/50], Training Loss: 0.1386, Testing Loss: 0.1560
Best model saved!
Epoch 50/50
loss item: 0.14456118643283844
loss item: 0.13194634020328522
loss item: 0.1303824633359909
loss item: 0.14857414364814758
loss item: 0.1740862876176834
loss item: 0.21159324049949646
Epoch [50/50], Training Loss: 0.1356, Testing Loss: 0.1781
no improvement in test loss for 1 epochs
loss item: 0.15504547953605652
loss item: 0.13010500371456146
Val Loss: 0.2852
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 256
Hyperparameter tuning prediction finished
UNet6 with 1 50 0.0001 256 180 done at Tue Nov 12 05:08:44 CET 2024
SBATCH job finished
