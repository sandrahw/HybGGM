SBATCH job
Started 12/11/2024 16:21:23
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
UNet6 with 1 200 0.0001 128 180 start at Tue Nov 12 16:21:32 CET 2024
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 200, batch size: 128
Epoch 1/200
loss item: 1.314956545829773
loss item: 1.270584225654602
loss item: 1.000308871269226
loss item: 0.8740573525428772
loss item: 0.7180201411247253
loss item: 0.7930599451065063
loss item: 1.0123279094696045
loss item: 1.0499740839004517
loss item: 1.5358933210372925
loss item: 1.0992978811264038
loss item: 1.8920927047729492
loss item: 1.501132845878601
Epoch [1/200], Training Loss: 0.9952, Testing Loss: 1.3485
Best model saved!
Epoch 2/200
loss item: 0.8174898624420166
loss item: 0.8407853841781616
loss item: 0.659397542476654
loss item: 0.6148054003715515
loss item: 0.5695058703422546
loss item: 0.6089639067649841
loss item: 0.9603678584098816
loss item: 0.9906255006790161
loss item: 1.455845832824707
loss item: 1.0515450239181519
loss item: 1.7993911504745483
loss item: 1.427668571472168
Epoch [2/200], Training Loss: 0.6852, Testing Loss: 1.2809
Best model saved!
Epoch 3/200
loss item: 0.6391938328742981
loss item: 0.6839631199836731
loss item: 0.5445468425750732
loss item: 0.5269098281860352
loss item: 0.4834650158882141
loss item: 0.5180936455726624
loss item: 0.8731481432914734
loss item: 0.896729052066803
loss item: 1.3159645795822144
loss item: 0.9661827087402344
loss item: 1.6327660083770752
loss item: 1.2965726852416992
Epoch [3/200], Training Loss: 0.5660, Testing Loss: 1.1636
Best model saved!
Epoch 4/200
loss item: 0.5607158541679382
loss item: 0.6133367419242859
loss item: 0.48262345790863037
loss item: 0.46523723006248474
loss item: 0.4250103533267975
loss item: 0.47485992312431335
loss item: 0.7345860600471497
loss item: 0.7495006322860718
loss item: 1.0894299745559692
loss item: 0.8207690715789795
loss item: 1.337998867034912
loss item: 1.0734004974365234
Epoch [4/200], Training Loss: 0.5036, Testing Loss: 0.9676
Best model saved!
Epoch 5/200
loss item: 0.4968300759792328
loss item: 0.5559338331222534
loss item: 0.4318540394306183
loss item: 0.42628517746925354
loss item: 0.407129168510437
loss item: 0.42925190925598145
loss item: 0.5731611251831055
loss item: 0.5829623341560364
loss item: 0.8299558162689209
loss item: 0.6462810039520264
loss item: 1.003731369972229
loss item: 0.8156558871269226
Epoch [5/200], Training Loss: 0.4579, Testing Loss: 0.7420
Best model saved!
Epoch 6/200
loss item: 0.4582401216030121
loss item: 0.5025803446769714
loss item: 0.39606335759162903
loss item: 0.4031449556350708
loss item: 0.37517213821411133
loss item: 0.4022766351699829
loss item: 0.4594845473766327
loss item: 0.46580770611763
loss item: 0.6540349125862122
loss item: 0.523462176322937
loss item: 0.7754417061805725
loss item: 0.6426147222518921
Epoch [6/200], Training Loss: 0.4229, Testing Loss: 0.5868
Best model saved!
Epoch 7/200
loss item: 0.42897096276283264
loss item: 0.47251659631729126
loss item: 0.3699522912502289
loss item: 0.3719806969165802
loss item: 0.35490232706069946
loss item: 0.37631329894065857
loss item: 0.3738951086997986
loss item: 0.3766155540943146
loss item: 0.5156376361846924
loss item: 0.42701077461242676
loss item: 0.5785046815872192
loss item: 0.5039924383163452
Epoch [7/200], Training Loss: 0.3958, Testing Loss: 0.4626
Best model saved!
Epoch 8/200
loss item: 0.39347803592681885
loss item: 0.43900781869888306
loss item: 0.34138306975364685
loss item: 0.35099250078201294
loss item: 0.33376383781433105
loss item: 0.3499657213687897
loss item: 0.3422190248966217
loss item: 0.3439229130744934
loss item: 0.4695473909378052
loss item: 0.39127117395401
loss item: 0.5248457789421082
loss item: 0.4621865153312683
Epoch [8/200], Training Loss: 0.3681, Testing Loss: 0.4223
Best model saved!
Epoch 9/200
loss item: 0.37901073694229126
loss item: 0.41159704327583313
loss item: 0.3174844980239868
loss item: 0.3325675129890442
loss item: 0.31500765681266785
loss item: 0.3314005732536316
loss item: 0.31126219034194946
loss item: 0.3129207193851471
loss item: 0.4189760982990265
loss item: 0.3521842658519745
loss item: 0.45650410652160645
loss item: 0.4120505452156067
Epoch [9/200], Training Loss: 0.3478, Testing Loss: 0.3773
Best model saved!
Epoch 10/200
loss item: 0.34955310821533203
loss item: 0.3849033713340759
loss item: 0.29742729663848877
loss item: 0.30792781710624695
loss item: 0.29873716831207275
loss item: 0.3095741271972656
loss item: 0.2929357886314392
loss item: 0.2934044599533081
loss item: 0.3904168903827667
loss item: 0.32804837822914124
loss item: 0.42890632152557373
loss item: 0.38721874356269836
Epoch [10/200], Training Loss: 0.3247, Testing Loss: 0.3535
Best model saved!
Epoch 11/200
loss item: 0.32989028096199036
loss item: 0.3606360852718353
loss item: 0.2778743803501129
loss item: 0.29521870613098145
loss item: 0.2861981987953186
loss item: 0.29138779640197754
loss item: 0.27919894456863403
loss item: 0.28017690777778625
loss item: 0.3666410744190216
loss item: 0.3080979585647583
loss item: 0.4045148491859436
loss item: 0.36721229553222656
Epoch [11/200], Training Loss: 0.3069, Testing Loss: 0.3343
Best model saved!
Epoch 12/200
loss item: 0.3118159770965576
loss item: 0.3391401767730713
loss item: 0.26034095883369446
loss item: 0.2791765630245209
loss item: 0.26959478855133057
loss item: 0.2752097547054291
loss item: 0.2654249370098114
loss item: 0.26662424206733704
loss item: 0.34346503019332886
loss item: 0.288222074508667
loss item: 0.3765503764152527
loss item: 0.34462878108024597
Epoch [12/200], Training Loss: 0.2892, Testing Loss: 0.3142
Best model saved!
Epoch 13/200
loss item: 0.2941327691078186
loss item: 0.31849798560142517
loss item: 0.24616168439388275
loss item: 0.26635023951530457
loss item: 0.2566799521446228
loss item: 0.25964853167533875
loss item: 0.25324347615242004
loss item: 0.25456443428993225
loss item: 0.32598721981048584
loss item: 0.2730366289615631
loss item: 0.36293983459472656
loss item: 0.3284109830856323
Epoch [13/200], Training Loss: 0.2736, Testing Loss: 0.2997
Best model saved!
Epoch 14/200
loss item: 0.27941450476646423
loss item: 0.3023635447025299
loss item: 0.23341324925422668
loss item: 0.2522580027580261
loss item: 0.24308669567108154
loss item: 0.24661646783351898
loss item: 0.2359846830368042
loss item: 0.23780982196331024
loss item: 0.29883038997650146
loss item: 0.25189024209976196
loss item: 0.33349090814590454
loss item: 0.30213144421577454
Epoch [14/200], Training Loss: 0.2595, Testing Loss: 0.2767
Best model saved!
Epoch 15/200
loss item: 0.26361334323883057
loss item: 0.2853376567363739
loss item: 0.2214600294828415
loss item: 0.2398667335510254
loss item: 0.23146389424800873
loss item: 0.23549620807170868
loss item: 0.22465689480304718
loss item: 0.22707946598529816
loss item: 0.2814360558986664
loss item: 0.23719914257526398
loss item: 0.3144589960575104
loss item: 0.2844190299510956
Epoch [15/200], Training Loss: 0.2462, Testing Loss: 0.2615
Best model saved!
Epoch 16/200
loss item: 0.2503024637699127
loss item: 0.2723146677017212
loss item: 0.21093791723251343
loss item: 0.23004426062107086
loss item: 0.2220442295074463
loss item: 0.22393754124641418
loss item: 0.2147190272808075
loss item: 0.21764226257801056
loss item: 0.26565584540367126
loss item: 0.22419901192188263
loss item: 0.29184284806251526
loss item: 0.26815301179885864
Epoch [16/200], Training Loss: 0.2349, Testing Loss: 0.2470
Best model saved!
Epoch 17/200
loss item: 0.23802973330020905
loss item: 0.25877606868743896
loss item: 0.20214565098285675
loss item: 0.22184231877326965
loss item: 0.21131697297096252
loss item: 0.21466891467571259
loss item: 0.20908841490745544
loss item: 0.21238376200199127
loss item: 0.25660887360572815
loss item: 0.21587298810482025
loss item: 0.2783318758010864
loss item: 0.258955717086792
Epoch [17/200], Training Loss: 0.2245, Testing Loss: 0.2385
Best model saved!
Epoch 18/200
loss item: 0.22894713282585144
loss item: 0.24715600907802582
loss item: 0.1953994631767273
loss item: 0.21614232659339905
loss item: 0.20193463563919067
loss item: 0.20675598084926605
loss item: 0.20404039323329926
loss item: 0.20730562508106232
loss item: 0.25068435072898865
loss item: 0.2106437385082245
loss item: 0.27534404397010803
loss item: 0.2532957196235657
Epoch [18/200], Training Loss: 0.2161, Testing Loss: 0.2336
Best model saved!
Epoch 19/200
loss item: 0.21990536153316498
loss item: 0.23569075763225555
loss item: 0.1901588886976242
loss item: 0.20804159343242645
loss item: 0.19285908341407776
loss item: 0.19979777932167053
loss item: 0.19814236462116241
loss item: 0.2019602656364441
loss item: 0.24426418542861938
loss item: 0.20450879633426666
loss item: 0.2705639600753784
loss item: 0.2471403330564499
Epoch [19/200], Training Loss: 0.2077, Testing Loss: 0.2278
Best model saved!
Epoch 20/200
loss item: 0.21274009346961975
loss item: 0.22610318660736084
loss item: 0.18642044067382812
loss item: 0.20062322914600372
loss item: 0.18429669737815857
loss item: 0.19403225183486938
loss item: 0.1897711306810379
loss item: 0.19370025396347046
loss item: 0.2330678552389145
loss item: 0.19552847743034363
loss item: 0.25875580310821533
loss item: 0.23603537678718567
Epoch [20/200], Training Loss: 0.2007, Testing Loss: 0.2178
Best model saved!
Epoch 21/200
loss item: 0.20541781187057495
loss item: 0.21581487357616425
loss item: 0.18300122022628784
loss item: 0.19511179625988007
loss item: 0.17731979489326477
loss item: 0.18695376813411713
loss item: 0.18323388695716858
loss item: 0.18630634248256683
loss item: 0.22479769587516785
loss item: 0.18906202912330627
loss item: 0.25223398208618164
loss item: 0.22865030169487
Epoch [21/200], Training Loss: 0.1939, Testing Loss: 0.2107
Best model saved!
Epoch 22/200
loss item: 0.20093198120594025
loss item: 0.21170951426029205
loss item: 0.17699019610881805
loss item: 0.1865122765302658
loss item: 0.17196358740329742
loss item: 0.18096870183944702
loss item: 0.18333640694618225
loss item: 0.1868833750486374
loss item: 0.23243838548660278
loss item: 0.1925952136516571
loss item: 0.2868048846721649
loss item: 0.23796389997005463
Epoch [22/200], Training Loss: 0.1882, Testing Loss: 0.2200
no improvement in test loss for 1 epochs
Epoch 23/200
loss item: 0.19381147623062134
loss item: 0.20309659838676453
loss item: 0.1700921207666397
loss item: 0.17894889414310455
loss item: 0.1662900149822235
loss item: 0.1756121665239334
loss item: 0.17237065732479095
loss item: 0.17559805512428284
loss item: 0.20939743518829346
loss item: 0.1767115294933319
loss item: 0.22784246504306793
loss item: 0.21241459250450134
Epoch [23/200], Training Loss: 0.1813, Testing Loss: 0.1957
Best model saved!
Epoch 24/200
loss item: 0.18794524669647217
loss item: 0.2016197293996811
loss item: 0.1650777906179428
loss item: 0.17621168494224548
loss item: 0.17165309190750122
loss item: 0.17205792665481567
loss item: 0.17351995408535004
loss item: 0.17496615648269653
loss item: 0.2121928632259369
loss item: 0.17822378873825073
loss item: 0.23336927592754364
loss item: 0.21585410833358765
Epoch [24/200], Training Loss: 0.1791, Testing Loss: 0.1980
no improvement in test loss for 1 epochs
Epoch 25/200
loss item: 0.1819947361946106
loss item: 0.19690120220184326
loss item: 0.1640593558549881
loss item: 0.17052017152309418
loss item: 0.16763056814670563
loss item: 0.18055544793605804
loss item: 0.16783380508422852
loss item: 0.17203322052955627
loss item: 0.207285076379776
loss item: 0.17224079370498657
loss item: 0.2218085378408432
loss item: 0.21247150003910065
Epoch [25/200], Training Loss: 0.1769, Testing Loss: 0.1923
Best model saved!
Epoch 26/200
loss item: 0.1813390552997589
loss item: 0.18788886070251465
loss item: 0.1666330248117447
loss item: 0.18178561329841614
loss item: 0.1564084142446518
loss item: 0.17519234120845795
loss item: 0.1833968311548233
loss item: 0.18770073354244232
loss item: 0.23416836559772491
loss item: 0.18639706075191498
loss item: 0.2697369158267975
loss item: 0.24104958772659302
Epoch [26/200], Training Loss: 0.1749, Testing Loss: 0.2171
no improvement in test loss for 1 epochs
Epoch 27/200
loss item: 0.19038590788841248
loss item: 0.18123869597911835
loss item: 0.15630489587783813
loss item: 0.1738806515932083
loss item: 0.16737942397594452
loss item: 0.16623108088970184
loss item: 0.16629502177238464
loss item: 0.17058445513248444
loss item: 0.21433259546756744
loss item: 0.17151665687561035
loss item: 0.23623380064964294
loss item: 0.21625623106956482
Epoch [27/200], Training Loss: 0.1726, Testing Loss: 0.1959
no improvement in test loss for 2 epochs
Epoch 28/200
loss item: 0.1674310564994812
loss item: 0.17519596219062805
loss item: 0.18278217315673828
loss item: 0.16710855066776276
loss item: 0.15200209617614746
loss item: 0.17428117990493774
loss item: 0.18704035878181458
loss item: 0.18804754316806793
loss item: 0.24061685800552368
loss item: 0.19659189879894257
loss item: 0.29196175932884216
loss item: 0.24661721289157867
Epoch [28/200], Training Loss: 0.1698, Testing Loss: 0.2251
no improvement in test loss for 3 epochs
Epoch 29/200
loss item: 0.20008493959903717
loss item: 0.1875532865524292
loss item: 0.16192181408405304
loss item: 0.18444642424583435
loss item: 0.1643044501543045
loss item: 0.16955550014972687
loss item: 0.17258936166763306
loss item: 0.17565876245498657
loss item: 0.21984770894050598
loss item: 0.1788286417722702
loss item: 0.24904829263687134
loss item: 0.22296413779258728
Epoch [29/200], Training Loss: 0.1780, Testing Loss: 0.2032
no improvement in test loss for 4 epochs
Epoch 30/200
loss item: 0.18440279364585876
loss item: 0.17832858860492706
loss item: 0.1587371528148651
loss item: 0.1772146373987198
loss item: 0.1492040902376175
loss item: 0.16953948140144348
loss item: 0.16340111196041107
loss item: 0.1663980633020401
loss item: 0.1987830251455307
loss item: 0.16636188328266144
loss item: 0.21841469407081604
loss item: 0.20252124965190887
Epoch [30/200], Training Loss: 0.1696, Testing Loss: 0.1860
Best model saved!
Epoch 31/200
loss item: 0.17246489226818085
loss item: 0.17914605140686035
loss item: 0.1709839105606079
loss item: 0.15382899343967438
loss item: 0.14143240451812744
loss item: 0.188370943069458
loss item: 0.1601412296295166
loss item: 0.1622220277786255
loss item: 0.19533030688762665
loss item: 0.1629513055086136
loss item: 0.22015012800693512
loss item: 0.19858288764953613
Epoch [31/200], Training Loss: 0.1677, Testing Loss: 0.1832
Best model saved!
Epoch 32/200
loss item: 0.17108850181102753
loss item: 0.17075392603874207
loss item: 0.16113680601119995
loss item: 0.1662844717502594
loss item: 0.15596014261245728
loss item: 0.16660760343074799
loss item: 0.16274595260620117
loss item: 0.1678139865398407
loss item: 0.20301884412765503
loss item: 0.16298899054527283
loss item: 0.21210825443267822
loss item: 0.19863292574882507
Epoch [32/200], Training Loss: 0.1653, Testing Loss: 0.1846
no improvement in test loss for 1 epochs
Epoch 33/200
loss item: 0.16727320849895477
loss item: 0.188912495970726
loss item: 0.14413180947303772
loss item: 0.14397107064723969
loss item: 0.17708905041217804
loss item: 0.15907351672649384
loss item: 0.14355048537254333
loss item: 0.14648370444774628
loss item: 0.17249350249767303
loss item: 0.1453639268875122
loss item: 0.18741239607334137
loss item: 0.17524653673171997
Epoch [33/200], Training Loss: 0.1634, Testing Loss: 0.1618
Best model saved!
Epoch 34/200
loss item: 0.15721066296100616
loss item: 0.17146143317222595
loss item: 0.1665204018354416
loss item: 0.17512977123260498
loss item: 0.14673404395580292
loss item: 0.14582514762878418
loss item: 0.16701404750347137
loss item: 0.1686231791973114
loss item: 0.20883168280124664
loss item: 0.17021030187606812
loss item: 0.2402251660823822
loss item: 0.20978181064128876
Epoch [34/200], Training Loss: 0.1605, Testing Loss: 0.1941
no improvement in test loss for 1 epochs
Epoch 35/200
loss item: 0.17090223729610443
loss item: 0.1666622906923294
loss item: 0.13916771113872528
loss item: 0.14671246707439423
loss item: 0.13813434541225433
loss item: 0.15798409283161163
loss item: 0.13957563042640686
loss item: 0.14241552352905273
loss item: 0.17516972124576569
loss item: 0.144767165184021
loss item: 0.19616469740867615
loss item: 0.1799350380897522
Epoch [35/200], Training Loss: 0.1533, Testing Loss: 0.1630
no improvement in test loss for 2 epochs
Epoch 36/200
loss item: 0.14920201897621155
loss item: 0.15283524990081787
loss item: 0.14123541116714478
loss item: 0.14686240255832672
loss item: 0.13715742528438568
loss item: 0.1464383602142334
loss item: 0.1525883972644806
loss item: 0.1549190729856491
loss item: 0.19648490846157074
loss item: 0.15760071575641632
loss item: 0.21405553817749023
loss item: 0.19782181084156036
Epoch [36/200], Training Loss: 0.1456, Testing Loss: 0.1789
no improvement in test loss for 3 epochs
Epoch 37/200
loss item: 0.15013627707958221
loss item: 0.1513715386390686
loss item: 0.14791584014892578
loss item: 0.1351434588432312
loss item: 0.1476549655199051
loss item: 0.16503353416919708
loss item: 0.13778604567050934
loss item: 0.13837914168834686
loss item: 0.16629205644130707
loss item: 0.14226646721363068
loss item: 0.1893976926803589
loss item: 0.17091213166713715
Epoch [37/200], Training Loss: 0.1495, Testing Loss: 0.1575
Best model saved!
Epoch 38/200
loss item: 0.15485608577728271
loss item: 0.15025103092193604
loss item: 0.15305718779563904
loss item: 0.1733763962984085
loss item: 0.1427987962961197
loss item: 0.13961493968963623
loss item: 0.15216821432113647
loss item: 0.15298593044281006
loss item: 0.1869678795337677
loss item: 0.1558041125535965
loss item: 0.21500468254089355
loss item: 0.1902443915605545
Epoch [38/200], Training Loss: 0.1523, Testing Loss: 0.1755
no improvement in test loss for 1 epochs
Epoch 39/200
loss item: 0.1704123318195343
loss item: 0.17042122781276703
loss item: 0.13222265243530273
loss item: 0.1361965835094452
loss item: 0.13647997379302979
loss item: 0.14172929525375366
loss item: 0.13330312073230743
loss item: 0.13471511006355286
loss item: 0.16201360523700714
loss item: 0.1362006962299347
loss item: 0.17774997651576996
loss item: 0.1648898869752884
Epoch [39/200], Training Loss: 0.1479, Testing Loss: 0.1515
Best model saved!
Epoch 40/200
loss item: 0.14134137332439423
loss item: 0.14129577577114105
loss item: 0.1316513568162918
loss item: 0.13940513134002686
loss item: 0.12659890949726105
loss item: 0.13368336856365204
loss item: 0.13412727415561676
loss item: 0.13675910234451294
loss item: 0.16473111510276794
loss item: 0.13648712635040283
loss item: 0.1813591718673706
loss item: 0.1672932505607605
Epoch [40/200], Training Loss: 0.1357, Testing Loss: 0.1535
no improvement in test loss for 1 epochs
Epoch 41/200
loss item: 0.14363333582878113
loss item: 0.14010083675384521
loss item: 0.14009688794612885
loss item: 0.14236702024936676
loss item: 0.1293049156665802
loss item: 0.15639950335025787
loss item: 0.14526285231113434
loss item: 0.1453286111354828
loss item: 0.1827474981546402
loss item: 0.1525232195854187
loss item: 0.22027429938316345
loss item: 0.18782445788383484
Epoch [41/200], Training Loss: 0.1420, Testing Loss: 0.1723
no improvement in test loss for 2 epochs
Epoch 42/200
loss item: 0.15723374485969543
loss item: 0.15075592696666718
loss item: 0.13452871143817902
loss item: 0.14650416374206543
loss item: 0.12991052865982056
loss item: 0.13542093336582184
loss item: 0.1284889578819275
loss item: 0.12943482398986816
loss item: 0.15238241851329803
loss item: 0.1309758871793747
loss item: 0.17012938857078552
loss item: 0.15511436760425568
Epoch [42/200], Training Loss: 0.1424, Testing Loss: 0.1444
Best model saved!
Epoch 43/200
loss item: 0.14442375302314758
loss item: 0.150535449385643
loss item: 0.12638945877552032
loss item: 0.12591247260570526
loss item: 0.12340936809778214
loss item: 0.1339479386806488
loss item: 0.1304379105567932
loss item: 0.1316555142402649
loss item: 0.16271492838859558
loss item: 0.1354726403951645
loss item: 0.1786193996667862
loss item: 0.16593100130558014
Epoch [43/200], Training Loss: 0.1341, Testing Loss: 0.1508
no improvement in test loss for 1 epochs
Epoch 44/200
loss item: 0.1315901279449463
loss item: 0.1353633850812912
loss item: 0.12440813332796097
loss item: 0.12674656510353088
loss item: 0.12694695591926575
loss item: 0.1304549127817154
loss item: 0.12686237692832947
loss item: 0.1295466423034668
loss item: 0.1551586389541626
loss item: 0.1290172040462494
loss item: 0.17096512019634247
loss item: 0.15758740901947021
Epoch [44/200], Training Loss: 0.1293, Testing Loss: 0.1449
no improvement in test loss for 2 epochs
Epoch 45/200
loss item: 0.1360010802745819
loss item: 0.13302983343601227
loss item: 0.13335061073303223
loss item: 0.13713034987449646
loss item: 0.11942543834447861
loss item: 0.12997569143772125
loss item: 0.14375105500221252
loss item: 0.14644509553909302
loss item: 0.17369943857192993
loss item: 0.14190642535686493
loss item: 0.19194938242435455
loss item: 0.17448459565639496
Epoch [45/200], Training Loss: 0.1315, Testing Loss: 0.1620
no improvement in test loss for 3 epochs
Epoch 46/200
loss item: 0.1499134600162506
loss item: 0.133869007229805
loss item: 0.1252327859401703
loss item: 0.14401832222938538
loss item: 0.11702778190374374
loss item: 0.1308647096157074
loss item: 0.13600985705852509
loss item: 0.1378374844789505
loss item: 0.16321483254432678
loss item: 0.13669517636299133
loss item: 0.18254049122333527
loss item: 0.16630354523658752
Epoch [46/200], Training Loss: 0.1335, Testing Loss: 0.1538
no improvement in test loss for 4 epochs
Epoch 47/200
loss item: 0.14145128428936005
loss item: 0.13948221504688263
loss item: 0.12458052486181259
loss item: 0.1236632838845253
loss item: 0.1152193620800972
loss item: 0.13812293112277985
loss item: 0.12077970802783966
loss item: 0.12210816890001297
loss item: 0.14481239020824432
loss item: 0.1228899136185646
loss item: 0.15713931620121002
loss item: 0.14628955721855164
Epoch [47/200], Training Loss: 0.1304, Testing Loss: 0.1357
Best model saved!
Epoch 48/200
loss item: 0.12504743039608002
loss item: 0.1286744475364685
loss item: 0.12377265840768814
loss item: 0.11813165992498398
loss item: 0.11834307014942169
loss item: 0.12726274132728577
loss item: 0.1323949098587036
loss item: 0.1341685652732849
loss item: 0.15793024003505707
loss item: 0.1311434507369995
loss item: 0.16712428629398346
loss item: 0.1606270968914032
Epoch [48/200], Training Loss: 0.1235, Testing Loss: 0.1472
no improvement in test loss for 1 epochs
Epoch 49/200
loss item: 0.12562395632266998
loss item: 0.13288336992263794
loss item: 0.11764208227396011
loss item: 0.11412166804075241
loss item: 0.12627989053726196
loss item: 0.12552829086780548
loss item: 0.11874610185623169
loss item: 0.12152978777885437
loss item: 0.14353808760643005
loss item: 0.12026415765285492
loss item: 0.15646757185459137
loss item: 0.14479592442512512
Epoch [49/200], Training Loss: 0.1237, Testing Loss: 0.1342
Best model saved!
Epoch 50/200
loss item: 0.12673690915107727
loss item: 0.12859779596328735
loss item: 0.12603065371513367
loss item: 0.13895416259765625
loss item: 0.10985974967479706
loss item: 0.12054122239351273
loss item: 0.14163580536842346
loss item: 0.1433030515909195
loss item: 0.16884011030197144
loss item: 0.1380547434091568
loss item: 0.18135260045528412
loss item: 0.1698358803987503
Epoch [50/200], Training Loss: 0.1251, Testing Loss: 0.1572
no improvement in test loss for 1 epochs
Epoch 51/200
loss item: 0.1479850709438324
loss item: 0.12758304178714752
loss item: 0.11784336715936661
loss item: 0.1356549710035324
loss item: 0.11272916197776794
loss item: 0.1399318426847458
loss item: 0.12019489705562592
loss item: 0.12138565629720688
loss item: 0.1448206901550293
loss item: 0.12364175915718079
loss item: 0.16401401162147522
loss item: 0.14800986647605896
Epoch [51/200], Training Loss: 0.1303, Testing Loss: 0.1370
no improvement in test loss for 2 epochs
Epoch 52/200
loss item: 0.12845274806022644
loss item: 0.12873195111751556
loss item: 0.1322854906320572
loss item: 0.12510353326797485
loss item: 0.11161260306835175
loss item: 0.13312901556491852
loss item: 0.13026440143585205
loss item: 0.12989504635334015
loss item: 0.1618763953447342
loss item: 0.1355045735836029
loss item: 0.19293922185897827
loss item: 0.16674017906188965
Epoch [52/200], Training Loss: 0.1266, Testing Loss: 0.1529
no improvement in test loss for 3 epochs
Epoch 53/200
loss item: 0.13849173486232758
loss item: 0.13813287019729614
loss item: 0.11124738305807114
loss item: 0.11318691819906235
loss item: 0.1285887062549591
loss item: 0.11681635677814484
loss item: 0.1143118366599083
loss item: 0.11490034312009811
loss item: 0.13653606176376343
loss item: 0.11751030385494232
loss item: 0.15282484889030457
loss item: 0.1400095671415329
Epoch [53/200], Training Loss: 0.1244, Testing Loss: 0.1293
Best model saved!
Epoch 54/200
loss item: 0.11880065500736237
loss item: 0.12592647969722748
loss item: 0.12279694527387619
loss item: 0.12406690418720245
loss item: 0.11399661004543304
loss item: 0.12436701357364655
loss item: 0.1299213469028473
loss item: 0.13326965272426605
loss item: 0.158065527677536
loss item: 0.12851582467556
loss item: 0.16816189885139465
loss item: 0.15894165635108948
Epoch [54/200], Training Loss: 0.1217, Testing Loss: 0.1461
no improvement in test loss for 1 epochs
Epoch 55/200
loss item: 0.1448461413383484
loss item: 0.11901835352182388
loss item: 0.11035843193531036
loss item: 0.13239726424217224
loss item: 0.11325433850288391
loss item: 0.12870225310325623
loss item: 0.11911002546548843
loss item: 0.12120799720287323
loss item: 0.15363849699497223
loss item: 0.12360973656177521
loss item: 0.16994783282279968
loss item: 0.1546676605939865
Epoch [55/200], Training Loss: 0.1248, Testing Loss: 0.1404
no improvement in test loss for 2 epochs
Epoch 56/200
loss item: 0.1204414963722229
loss item: 0.1250241994857788
loss item: 0.13939112424850464
loss item: 0.13790586590766907
loss item: 0.12649016082286835
loss item: 0.16260598599910736
loss item: 0.14675594866275787
loss item: 0.14428848028182983
loss item: 0.19720502197742462
loss item: 0.15653158724308014
loss item: 0.2591762840747833
loss item: 0.20270594954490662
Epoch [56/200], Training Loss: 0.1353, Testing Loss: 0.1844
no improvement in test loss for 3 epochs
Epoch 57/200
loss item: 0.16933514177799225
loss item: 0.17781022191047668
loss item: 0.11547508090734482
loss item: 0.12713460624217987
loss item: 0.16266323626041412
loss item: 0.11929463595151901
loss item: 0.11827049404382706
loss item: 0.1186390221118927
loss item: 0.14198718965053558
loss item: 0.11964134871959686
loss item: 0.15572041273117065
loss item: 0.14361968636512756
Epoch [57/200], Training Loss: 0.1453, Testing Loss: 0.1330
no improvement in test loss for 4 epochs
Epoch 58/200
loss item: 0.12673065066337585
loss item: 0.12647652626037598
loss item: 0.10934236645698547
loss item: 0.12344098091125488
loss item: 0.10718045383691788
loss item: 0.12483102083206177
loss item: 0.11377797275781631
loss item: 0.11392197012901306
loss item: 0.13667605817317963
loss item: 0.11607369035482407
loss item: 0.15586893260478973
loss item: 0.13993212580680847
Epoch [58/200], Training Loss: 0.1197, Testing Loss: 0.1294
no improvement in test loss for 5 epochs
Epoch 59/200
loss item: 0.12022596597671509
loss item: 0.12092015147209167
loss item: 0.11556129902601242
loss item: 0.11337490379810333
loss item: 0.10694513469934464
loss item: 0.11738616228103638
loss item: 0.11235588788986206
loss item: 0.11239180713891983
loss item: 0.1353551745414734
loss item: 0.11625279486179352
loss item: 0.15597529709339142
loss item: 0.138824000954628
Epoch [59/200], Training Loss: 0.1157, Testing Loss: 0.1285
Best model saved!
Epoch 60/200
loss item: 0.11843187361955643
loss item: 0.11995808035135269
loss item: 0.10588240623474121
loss item: 0.10668632388114929
loss item: 0.10799956321716309
loss item: 0.10954058170318604
loss item: 0.10813302546739578
loss item: 0.10912957787513733
loss item: 0.12849228084087372
loss item: 0.10990893095731735
loss item: 0.1416366845369339
loss item: 0.13124094903469086
Epoch [60/200], Training Loss: 0.1114, Testing Loss: 0.1214
Best model saved!
Epoch 61/200
loss item: 0.11138209700584412
loss item: 0.11564644426107407
loss item: 0.11317794024944305
loss item: 0.11312585324048996
loss item: 0.10529074817895889
loss item: 0.11385738104581833
loss item: 0.11596794426441193
loss item: 0.11914229393005371
loss item: 0.14571717381477356
loss item: 0.11882875859737396
loss item: 0.1577681303024292
loss item: 0.14524757862091064
Epoch [61/200], Training Loss: 0.1121, Testing Loss: 0.1338
no improvement in test loss for 1 epochs
Epoch 62/200
loss item: 0.12498012185096741
loss item: 0.11259941011667252
loss item: 0.10370179265737534
loss item: 0.11350199580192566
loss item: 0.10769085586071014
loss item: 0.11480191349983215
loss item: 0.11135336011648178
loss item: 0.11381637305021286
loss item: 0.14082513749599457
loss item: 0.11466913670301437
loss item: 0.15816397964954376
loss item: 0.1422443389892578
Epoch [62/200], Training Loss: 0.1129, Testing Loss: 0.1302
no improvement in test loss for 2 epochs
Epoch 63/200
loss item: 0.10895427316427231
loss item: 0.11477258801460266
loss item: 0.12505114078521729
loss item: 0.11847561597824097
loss item: 0.10407601296901703
loss item: 0.132802352309227
loss item: 0.12225024402141571
loss item: 0.12123164534568787
loss item: 0.15613940358161926
loss item: 0.1278824657201767
loss item: 0.1944875866174698
loss item: 0.1607264131307602
Epoch [63/200], Training Loss: 0.1174, Testing Loss: 0.1471
no improvement in test loss for 3 epochs
Epoch 64/200
loss item: 0.13976898789405823
loss item: 0.13650870323181152
loss item: 0.10434742271900177
loss item: 0.11508569866418839
loss item: 0.12270494550466537
loss item: 0.11003427952528
loss item: 0.11116698384284973
loss item: 0.11164011806249619
loss item: 0.13264143466949463
loss item: 0.11319366842508316
loss item: 0.14662934839725494
loss item: 0.13450676202774048
Epoch [64/200], Training Loss: 0.1214, Testing Loss: 0.1250
no improvement in test loss for 4 epochs
Epoch 65/200
loss item: 0.11492215096950531
loss item: 0.1176239624619484
loss item: 0.1073429211974144
loss item: 0.11168336868286133
loss item: 0.09958330541849136
loss item: 0.10590538382530212
loss item: 0.11351249366998672
loss item: 0.11713342368602753
loss item: 0.1373811662197113
loss item: 0.11316504329442978
loss item: 0.14794673025608063
loss item: 0.13797444105148315
Epoch [65/200], Training Loss: 0.1095, Testing Loss: 0.1279
no improvement in test loss for 5 epochs
Epoch 66/200
loss item: 0.11992226541042328
loss item: 0.11176913231611252
loss item: 0.10035186260938644
loss item: 0.10686781257390976
loss item: 0.0998254343867302
loss item: 0.11437661200761795
loss item: 0.10636023432016373
loss item: 0.10774417221546173
loss item: 0.13094861805438995
loss item: 0.10918857157230377
loss item: 0.14066638052463531
loss item: 0.132780522108078
Epoch [66/200], Training Loss: 0.1089, Testing Loss: 0.1213
Best model saved!
Epoch 67/200
loss item: 0.10725147277116776
loss item: 0.10918067395687103
loss item: 0.1086961030960083
loss item: 0.10542598366737366
loss item: 0.09688004851341248
loss item: 0.11740827560424805
loss item: 0.10812737047672272
loss item: 0.10909444838762283
loss item: 0.13147106766700745
loss item: 0.11121296137571335
loss item: 0.14656153321266174
loss item: 0.13300864398479462
Epoch [67/200], Training Loss: 0.1075, Testing Loss: 0.1232
no improvement in test loss for 1 epochs
Epoch 68/200
loss item: 0.11084700375795364
loss item: 0.11379799991846085
loss item: 0.10169146955013275
loss item: 0.09900134801864624
loss item: 0.10568436980247498
loss item: 0.10370918363332748
loss item: 0.10752519220113754
loss item: 0.1082606315612793
loss item: 0.12788717448711395
loss item: 0.10838715732097626
loss item: 0.13711494207382202
loss item: 0.13078880310058594
Epoch [68/200], Training Loss: 0.1058, Testing Loss: 0.1200
Best model saved!
Epoch 69/200
loss item: 0.10431613028049469
loss item: 0.10969895869493484
loss item: 0.10270071774721146
loss item: 0.09922274202108383
loss item: 0.09963182359933853
loss item: 0.10288747400045395
loss item: 0.10567475855350494
loss item: 0.1086626797914505
loss item: 0.1271793097257614
loss item: 0.10594639927148819
loss item: 0.1367405503988266
loss item: 0.1280340552330017
Epoch [69/200], Training Loss: 0.1031, Testing Loss: 0.1187
Best model saved!
Epoch 70/200
loss item: 0.11009804904460907
loss item: 0.10830408334732056
loss item: 0.0970877930521965
loss item: 0.10372263193130493
loss item: 0.09764757007360458
loss item: 0.10098198801279068
loss item: 0.10746359825134277
loss item: 0.10904129594564438
loss item: 0.13131536543369293
loss item: 0.10895445197820663
loss item: 0.14017635583877563
loss item: 0.1328449249267578
Epoch [70/200], Training Loss: 0.1030, Testing Loss: 0.1216
no improvement in test loss for 1 epochs
Epoch 71/200
loss item: 0.10816044360399246
loss item: 0.10494236648082733
loss item: 0.10065699368715286
loss item: 0.10596360266208649
loss item: 0.09214365482330322
loss item: 0.10566145926713943
loss item: 0.11291380971670151
loss item: 0.11380715668201447
loss item: 0.13432727754116058
loss item: 0.11214296519756317
loss item: 0.14507117867469788
loss item: 0.13647674024105072
Epoch [71/200], Training Loss: 0.1029, Testing Loss: 0.1258
no improvement in test loss for 2 epochs
Epoch 72/200
loss item: 0.11007358878850937
loss item: 0.10581820458173752
loss item: 0.09909380972385406
loss item: 0.10395175963640213
loss item: 0.09625646471977234
loss item: 0.10177963972091675
loss item: 0.10846919566392899
loss item: 0.10706648975610733
loss item: 0.13621920347213745
loss item: 0.11519843339920044
loss item: 0.1653904765844345
loss item: 0.14063747227191925
Epoch [72/200], Training Loss: 0.1028, Testing Loss: 0.1288
no improvement in test loss for 3 epochs
Epoch 73/200
loss item: 0.10709642618894577
loss item: 0.10532280057668686
loss item: 0.09918848425149918
loss item: 0.09216852486133575
loss item: 0.09611644595861435
loss item: 0.10069239884614944
loss item: 0.1048908457159996
loss item: 0.10425188392400742
loss item: 0.12512612342834473
loss item: 0.10728676617145538
loss item: 0.13816919922828674
loss item: 0.12891115248203278
Epoch [73/200], Training Loss: 0.1001, Testing Loss: 0.1181
Best model saved!
Epoch 74/200
loss item: 0.10014587640762329
loss item: 0.10608384758234024
loss item: 0.10436882823705673
loss item: 0.0957225114107132
loss item: 0.10423742979764938
loss item: 0.11027319729328156
loss item: 0.10107641667127609
loss item: 0.1028558537364006
loss item: 0.12544426321983337
loss item: 0.10360130667686462
loss item: 0.1373336762189865
loss item: 0.12741470336914062
Epoch [74/200], Training Loss: 0.1035, Testing Loss: 0.1163
Best model saved!
Epoch 75/200
loss item: 0.11103928834199905
loss item: 0.10260897874832153
loss item: 0.10111543536186218
loss item: 0.10810390114784241
loss item: 0.09484900534152985
loss item: 0.10133913904428482
loss item: 0.11965993046760559
loss item: 0.12244194746017456
loss item: 0.16579531133174896
loss item: 0.12802141904830933
loss item: 0.18887537717819214
loss item: 0.16439710557460785
Epoch [75/200], Training Loss: 0.1032, Testing Loss: 0.1482
no improvement in test loss for 1 epochs
Epoch 76/200
loss item: 0.11072485148906708
loss item: 0.11025619506835938
loss item: 0.115449920296669
loss item: 0.11560429632663727
loss item: 0.10487030446529388
loss item: 0.14606277644634247
loss item: 0.13046173751354218
loss item: 0.12626098096370697
loss item: 0.17186282575130463
loss item: 0.1386394053697586
loss item: 0.21332532167434692
loss item: 0.1758822500705719
Epoch [76/200], Training Loss: 0.1172, Testing Loss: 0.1594
no improvement in test loss for 2 epochs
Epoch 77/200
loss item: 0.14881357550621033
loss item: 0.14369656145572662
loss item: 0.10565881431102753
loss item: 0.12258391082286835
loss item: 0.12731067836284637
loss item: 0.10714761912822723
loss item: 0.10877681523561478
loss item: 0.10789673030376434
loss item: 0.1297917515039444
loss item: 0.11205918341875076
loss item: 0.14629797637462616
loss item: 0.13270911574363708
Epoch [77/200], Training Loss: 0.1259, Testing Loss: 0.1229
no improvement in test loss for 3 epochs
Epoch 78/200
loss item: 0.11310502141714096
loss item: 0.11406220495700836
loss item: 0.10340698063373566
loss item: 0.11023411899805069
loss item: 0.09380989521741867
loss item: 0.10034509748220444
loss item: 0.10750360041856766
loss item: 0.11013995110988617
loss item: 0.12907974421977997
loss item: 0.10734178870916367
loss item: 0.1390359252691269
loss item: 0.1315961629152298
Epoch [78/200], Training Loss: 0.1058, Testing Loss: 0.1208
no improvement in test loss for 4 epochs
Epoch 79/200
loss item: 0.11548604816198349
loss item: 0.10652747750282288
loss item: 0.09553628414869308
loss item: 0.10793772339820862
loss item: 0.09580985456705093
loss item: 0.10568759590387344
loss item: 0.10183615982532501
loss item: 0.10376127809286118
loss item: 0.12213300913572311
loss item: 0.10288986563682556
loss item: 0.13299383223056793
loss item: 0.12456315010786057
Epoch [79/200], Training Loss: 0.1045, Testing Loss: 0.1147
Best model saved!
Epoch 80/200
loss item: 0.10302278399467468
loss item: 0.10392429679632187
loss item: 0.1065027266740799
loss item: 0.10424134135246277
loss item: 0.09151872247457504
loss item: 0.11148636788129807
loss item: 0.11025335639715195
loss item: 0.10859993100166321
loss item: 0.14014951884746552
loss item: 0.11619208008050919
loss item: 0.18022890388965607
loss item: 0.14610867202281952
Epoch [80/200], Training Loss: 0.1034, Testing Loss: 0.1336
no improvement in test loss for 1 epochs
Epoch 81/200
loss item: 0.11585069447755814
loss item: 0.11089777946472168
loss item: 0.09505636245012283
loss item: 0.09505510330200195
loss item: 0.10436908900737762
loss item: 0.10100051760673523
loss item: 0.10316069424152374
loss item: 0.10277559608221054
loss item: 0.12241372466087341
loss item: 0.10375247895717621
loss item: 0.13194948434829712
loss item: 0.12508602440357208
Epoch [81/200], Training Loss: 0.1037, Testing Loss: 0.1149
no improvement in test loss for 2 epochs
Epoch 82/200
loss item: 0.0965745821595192
loss item: 0.10463067889213562
loss item: 0.10505197197198868
loss item: 0.10276313126087189
loss item: 0.09177788347005844
loss item: 0.10275645554065704
loss item: 0.11968835443258286
loss item: 0.12086498737335205
loss item: 0.16757526993751526
loss item: 0.12949833273887634
loss item: 0.19693128764629364
loss item: 0.1685287058353424
Epoch [82/200], Training Loss: 0.1006, Testing Loss: 0.1505
no improvement in test loss for 3 epochs
Epoch 83/200
loss item: 0.11726581305265427
loss item: 0.10432632267475128
loss item: 0.0988236591219902
loss item: 0.09468186646699905
loss item: 0.10111551731824875
loss item: 0.12230709195137024
loss item: 0.10063301026821136
loss item: 0.09908425807952881
loss item: 0.12012979388237
loss item: 0.10207086056470871
loss item: 0.13879618048667908
loss item: 0.12447281181812286
Epoch [83/200], Training Loss: 0.1064, Testing Loss: 0.1142
Best model saved!
Epoch 84/200
loss item: 0.11048492044210434
loss item: 0.10621048510074615
loss item: 0.11097262054681778
loss item: 0.1341162770986557
loss item: 0.11558879166841507
loss item: 0.09481852501630783
loss item: 0.1109626442193985
loss item: 0.10855340957641602
loss item: 0.1365545243024826
loss item: 0.11535745859146118
loss item: 0.16484473645687103
loss item: 0.14197774231433868
Epoch [84/200], Training Loss: 0.1120, Testing Loss: 0.1297
no improvement in test loss for 1 epochs
Epoch 85/200
loss item: 0.11780373007059097
loss item: 0.12017500400543213
loss item: 0.09542185813188553
loss item: 0.09705200046300888
loss item: 0.0941762626171112
loss item: 0.09510264545679092
loss item: 0.10012581944465637
loss item: 0.10090309381484985
loss item: 0.12010004371404648
loss item: 0.10073956847190857
loss item: 0.13085199892520905
loss item: 0.1221035048365593
Epoch [85/200], Training Loss: 0.1033, Testing Loss: 0.1125
Best model saved!
Epoch 86/200
loss item: 0.10319190472364426
loss item: 0.09903968870639801
loss item: 0.08770424127578735
loss item: 0.09718294441699982
loss item: 0.09011233597993851
loss item: 0.09234127402305603
loss item: 0.09461355954408646
loss item: 0.09692574292421341
loss item: 0.11525570601224899
loss item: 0.09716390073299408
loss item: 0.1268341839313507
loss item: 0.11773315072059631
Epoch [86/200], Training Loss: 0.0949, Testing Loss: 0.1081
Best model saved!
Epoch 87/200
loss item: 0.09502764046192169
loss item: 0.09714952856302261
loss item: 0.10041431337594986
loss item: 0.09321872144937515
loss item: 0.08423762023448944
loss item: 0.10673106461763382
loss item: 0.10106100887060165
loss item: 0.09914811700582504
loss item: 0.12705302238464355
loss item: 0.10586725175380707
loss item: 0.16347281634807587
loss item: 0.1333158016204834
Epoch [87/200], Training Loss: 0.0961, Testing Loss: 0.1217
no improvement in test loss for 1 epochs
Epoch 88/200
loss item: 0.11079505831003189
loss item: 0.10344167053699493
loss item: 0.09136662632226944
loss item: 0.09490973502397537
loss item: 0.09762130677700043
loss item: 0.09568700939416885
loss item: 0.09659682214260101
loss item: 0.09727456420660019
loss item: 0.11544179916381836
loss item: 0.09755763411521912
loss item: 0.12374342232942581
loss item: 0.11739666759967804
Epoch [88/200], Training Loss: 0.0990, Testing Loss: 0.1080
Best model saved!
Epoch 89/200
loss item: 0.09371581673622131
loss item: 0.09979573637247086
loss item: 0.09285853803157806
loss item: 0.0921505019068718
loss item: 0.08893564343452454
loss item: 0.09445927292108536
loss item: 0.10181090980768204
loss item: 0.10261270403862
loss item: 0.12967410683631897
loss item: 0.10477587580680847
loss item: 0.14289014041423798
loss item: 0.13053934276103973
Epoch [89/200], Training Loss: 0.0937, Testing Loss: 0.1187
no improvement in test loss for 1 epochs
Epoch 90/200
loss item: 0.1013949066400528
loss item: 0.10010867565870285
loss item: 0.08925732970237732
loss item: 0.08866395801305771
loss item: 0.09282886981964111
loss item: 0.09929683059453964
loss item: 0.09543236345052719
loss item: 0.09760204702615738
loss item: 0.11459120362997055
loss item: 0.09570759534835815
loss item: 0.12497659027576447
loss item: 0.11621475219726562
Epoch [90/200], Training Loss: 0.0953, Testing Loss: 0.1074
Best model saved!
Epoch 91/200
loss item: 0.09760931879281998
loss item: 0.09457885473966599
loss item: 0.10270240902900696
loss item: 0.11453951895236969
loss item: 0.08842388540506363
loss item: 0.09567079693078995
loss item: 0.11997507512569427
loss item: 0.11841686069965363
loss item: 0.14922669529914856
loss item: 0.1226971298456192
loss item: 0.18407313525676727
loss item: 0.1550992876291275
Epoch [91/200], Training Loss: 0.0989, Testing Loss: 0.1416
no improvement in test loss for 1 epochs
Epoch 92/200
loss item: 0.12059789896011353
loss item: 0.10967158526182175
loss item: 0.08648893982172012
loss item: 0.09916681051254272
loss item: 0.09222694486379623
loss item: 0.094704270362854
loss item: 0.10388697683811188
loss item: 0.10388371348381042
loss item: 0.12367036193609238
loss item: 0.10424385964870453
loss item: 0.13143561780452728
loss item: 0.12612849473953247
Epoch [92/200], Training Loss: 0.1005, Testing Loss: 0.1155
no improvement in test loss for 2 epochs
Epoch 93/200
loss item: 0.09553731232881546
loss item: 0.09845195710659027
loss item: 0.09090913087129593
loss item: 0.09046323597431183
loss item: 0.0855589434504509
loss item: 0.09757907688617706
loss item: 0.09157619625329971
loss item: 0.09170899540185928
loss item: 0.11162722110748291
loss item: 0.09354349970817566
loss item: 0.12089373171329498
loss item: 0.11266989260911942
Epoch [93/200], Training Loss: 0.0931, Testing Loss: 0.1037
Best model saved!
Epoch 94/200
loss item: 0.09133490920066833
loss item: 0.09321348369121552
loss item: 0.09581714123487473
loss item: 0.08490731567144394
loss item: 0.08975894004106522
loss item: 0.09599067270755768
loss item: 0.10397307574748993
loss item: 0.10397548973560333
loss item: 0.12241191416978836
loss item: 0.10113808512687683
loss item: 0.1294040083885193
loss item: 0.12523658573627472
Epoch [94/200], Training Loss: 0.0918, Testing Loss: 0.1144
no improvement in test loss for 1 epochs
Epoch 95/200
loss item: 0.09868229925632477
loss item: 0.10107450187206268
loss item: 0.0875154435634613
loss item: 0.09079025685787201
loss item: 0.09545345604419708
loss item: 0.08899667859077454
loss item: 0.09124214947223663
loss item: 0.09062113612890244
loss item: 0.10843778401613235
loss item: 0.09291017800569534
loss item: 0.12310345470905304
loss item: 0.11162734776735306
Epoch [95/200], Training Loss: 0.0938, Testing Loss: 0.1030
Best model saved!
Epoch 96/200
loss item: 0.09481432288885117
loss item: 0.10102767497301102
loss item: 0.09171266108751297
loss item: 0.09385528415441513
loss item: 0.08689382672309875
loss item: 0.10112441331148148
loss item: 0.10506444424390793
loss item: 0.10636194795370102
loss item: 0.12586663663387299
loss item: 0.1037532314658165
loss item: 0.13359278440475464
loss item: 0.12723365426063538
Epoch [96/200], Training Loss: 0.0949, Testing Loss: 0.1170
no improvement in test loss for 1 epochs
Epoch 97/200
loss item: 0.10718681663274765
loss item: 0.09146276861429214
loss item: 0.09374473243951797
loss item: 0.11037825793027878
loss item: 0.08397229015827179
loss item: 0.08744627237319946
loss item: 0.09664688259363174
loss item: 0.09975439310073853
loss item: 0.11744935810565948
loss item: 0.09533058851957321
loss item: 0.12507091462612152
loss item: 0.11737401783466339
Epoch [97/200], Training Loss: 0.0957, Testing Loss: 0.1086
no improvement in test loss for 2 epochs
Epoch 98/200
loss item: 0.10354825109243393
loss item: 0.097710520029068
loss item: 0.09891005605459213
loss item: 0.08576486259698868
loss item: 0.08550506085157394
loss item: 0.13579285144805908
loss item: 0.10589592903852463
loss item: 0.10540711879730225
loss item: 0.13384689390659332
loss item: 0.10770701617002487
loss item: 0.16336563229560852
loss item: 0.1363058090209961
Epoch [98/200], Training Loss: 0.1012, Testing Loss: 0.1254
no improvement in test loss for 3 epochs
Epoch 99/200
loss item: 0.11672263592481613
loss item: 0.11832591891288757
loss item: 0.0867442786693573
loss item: 0.10356184095144272
loss item: 0.11902005225419998
loss item: 0.08740704506635666
loss item: 0.09042508155107498
loss item: 0.08985427767038345
loss item: 0.10921293497085571
loss item: 0.0941695123910904
loss item: 0.12417639791965485
loss item: 0.11252442747354507
Epoch [99/200], Training Loss: 0.1053, Testing Loss: 0.1034
no improvement in test loss for 4 epochs
Epoch 100/200
loss item: 0.08809493482112885
loss item: 0.1002119854092598
loss item: 0.08671731501817703
loss item: 0.08723076432943344
loss item: 0.08505663275718689
loss item: 0.08377039432525635
loss item: 0.08965397626161575
loss item: 0.09058589488267899
loss item: 0.11116407811641693
loss item: 0.09285784512758255
loss item: 0.1229618489742279
loss item: 0.11384104192256927
Epoch [100/200], Training Loss: 0.0885, Testing Loss: 0.1035
no improvement in test loss for 5 epochs
Epoch 101/200
loss item: 0.09289625287055969
loss item: 0.09076829254627228
loss item: 0.08195631206035614
loss item: 0.08457554876804352
loss item: 0.08128174394369125
loss item: 0.084959976375103
loss item: 0.08695492148399353
loss item: 0.08891395479440689
loss item: 0.10476835072040558
loss item: 0.08804233372211456
loss item: 0.11430396884679794
loss item: 0.1068255752325058
Epoch [101/200], Training Loss: 0.0861, Testing Loss: 0.0983
Best model saved!
Epoch 102/200
loss item: 0.084306500852108
loss item: 0.08759444206953049
loss item: 0.09003109484910965
loss item: 0.08975514769554138
loss item: 0.0787496417760849
loss item: 0.09398946166038513
loss item: 0.09410732239484787
loss item: 0.09217282384634018
loss item: 0.1166531965136528
loss item: 0.09827643632888794
loss item: 0.14810673892498016
loss item: 0.12238780409097672
Epoch [102/200], Training Loss: 0.0874, Testing Loss: 0.1120
no improvement in test loss for 1 epochs
Epoch 103/200
loss item: 0.0987330973148346
loss item: 0.09421083331108093
loss item: 0.08283837884664536
loss item: 0.08739345520734787
loss item: 0.08894353359937668
loss item: 0.08153755962848663
loss item: 0.09444233775138855
loss item: 0.09276508539915085
loss item: 0.11359162628650665
loss item: 0.0974937230348587
loss item: 0.12669637799263
loss item: 0.11688116192817688
Epoch [103/200], Training Loss: 0.0889, Testing Loss: 0.1070
no improvement in test loss for 2 epochs
Epoch 104/200
loss item: 0.08843084424734116
loss item: 0.09343146532773972
loss item: 0.0839163288474083
loss item: 0.08239962160587311
loss item: 0.08557335287332535
loss item: 0.09001973271369934
loss item: 0.08842668682336807
loss item: 0.0891929641366005
loss item: 0.1061599925160408
loss item: 0.08915572613477707
loss item: 0.11667429655790329
loss item: 0.10790566354990005
Epoch [104/200], Training Loss: 0.0873, Testing Loss: 0.0996
no improvement in test loss for 3 epochs
Epoch 105/200
loss item: 0.09581991285085678
loss item: 0.08713751286268234
loss item: 0.08747125416994095
loss item: 0.09598462283611298
loss item: 0.07973989844322205
loss item: 0.08512081950902939
loss item: 0.09315840899944305
loss item: 0.09593287110328674
loss item: 0.12037293612957001
loss item: 0.09628380835056305
loss item: 0.1294984072446823
loss item: 0.11998353153467178
Epoch [105/200], Training Loss: 0.0885, Testing Loss: 0.1092
no improvement in test loss for 4 epochs
Epoch 106/200
loss item: 0.09721171110868454
loss item: 0.09232905507087708
loss item: 0.09982921183109283
loss item: 0.08931998908519745
loss item: 0.08779781311750412
loss item: 0.13480426371097565
loss item: 0.11692419648170471
loss item: 0.11258076876401901
loss item: 0.15596939623355865
loss item: 0.12379161268472672
loss item: 0.20072081685066223
loss item: 0.1613139808177948
Epoch [106/200], Training Loss: 0.1002, Testing Loss: 0.1452
no improvement in test loss for 5 epochs
Epoch 107/200
loss item: 0.13173913955688477
loss item: 0.12981146574020386
loss item: 0.08423788845539093
loss item: 0.10257188975811005
loss item: 0.1220192238688469
loss item: 0.09064587950706482
loss item: 0.09161399304866791
loss item: 0.09201012551784515
loss item: 0.11307074874639511
loss item: 0.09516461193561554
loss item: 0.12442053854465485
loss item: 0.11597724258899689
Epoch [107/200], Training Loss: 0.1102, Testing Loss: 0.1054
no improvement in test loss for 6 epochs
Epoch 108/200
loss item: 0.0903896689414978
loss item: 0.09664380550384521
loss item: 0.08318368345499039
loss item: 0.08807103335857391
loss item: 0.07889850437641144
loss item: 0.08435273915529251
loss item: 0.08943761885166168
loss item: 0.08864016085863113
loss item: 0.1084597259759903
loss item: 0.09228348731994629
loss item: 0.12069451808929443
loss item: 0.1112992987036705
Epoch [108/200], Training Loss: 0.0869, Testing Loss: 0.1018
no improvement in test loss for 7 epochs
Epoch 109/200
loss item: 0.08725288510322571
loss item: 0.08778281509876251
loss item: 0.08301044255495071
loss item: 0.08164460211992264
loss item: 0.0773116871714592
loss item: 0.08120772987604141
loss item: 0.0876108855009079
loss item: 0.0886230394244194
loss item: 0.10592901706695557
loss item: 0.08924683183431625
loss item: 0.12434996664524078
loss item: 0.10930516570806503
Epoch [109/200], Training Loss: 0.0830, Testing Loss: 0.1008
no improvement in test loss for 8 epochs
Epoch 110/200
loss item: 0.08791733533143997
loss item: 0.08719727396965027
loss item: 0.07972820848226547
loss item: 0.0782206729054451
loss item: 0.07811450213193893
loss item: 0.08176449686288834
loss item: 0.08521028608083725
loss item: 0.08515749871730804
loss item: 0.10247395187616348
loss item: 0.08750467747449875
loss item: 0.1188763976097107
loss item: 0.10614246129989624
Epoch [110/200], Training Loss: 0.0822, Testing Loss: 0.0976
Best model saved!
Epoch 111/200
loss item: 0.08368575572967529
loss item: 0.08608058840036392
loss item: 0.07933545112609863
loss item: 0.07581746578216553
loss item: 0.07916299998760223
loss item: 0.0884547233581543
loss item: 0.08489909768104553
loss item: 0.0843423455953598
loss item: 0.10091018676757812
loss item: 0.08605507016181946
loss item: 0.1118985265493393
loss item: 0.10432790219783783
Epoch [111/200], Training Loss: 0.0821, Testing Loss: 0.0954
Best model saved!
Epoch 112/200
loss item: 0.08333832025527954
loss item: 0.08355403691530228
loss item: 0.08938107639551163
loss item: 0.08849950134754181
loss item: 0.07465775310993195
loss item: 0.09085097163915634
loss item: 0.09846904128789902
loss item: 0.09918250888586044
loss item: 0.13133297860622406
loss item: 0.10279306769371033
loss item: 0.14427953958511353
loss item: 0.12937672436237335
Epoch [112/200], Training Loss: 0.0850, Testing Loss: 0.1176
no improvement in test loss for 1 epochs
Epoch 113/200
loss item: 0.0977204293012619
loss item: 0.08890975266695023
loss item: 0.08384043723344803
loss item: 0.08137448132038116
loss item: 0.08755907416343689
loss item: 0.09654417634010315
loss item: 0.09058815240859985
loss item: 0.08982829749584198
loss item: 0.10726862400770187
loss item: 0.08986713737249374
loss item: 0.11613558977842331
loss item: 0.11030660569667816
Epoch [113/200], Training Loss: 0.0893, Testing Loss: 0.1007
no improvement in test loss for 2 epochs
Epoch 114/200
loss item: 0.08900993317365646
loss item: 0.09558550268411636
loss item: 0.0941612496972084
loss item: 0.1044536903500557
loss item: 0.09459509700536728
loss item: 0.09378112852573395
loss item: 0.09418601542711258
loss item: 0.09279759228229523
loss item: 0.11618317663669586
loss item: 0.09865572303533554
loss item: 0.14948198199272156
loss item: 0.12326106429100037
Epoch [114/200], Training Loss: 0.0953, Testing Loss: 0.1124
no improvement in test loss for 3 epochs
Epoch 115/200
loss item: 0.10349366068840027
loss item: 0.0994231253862381
loss item: 0.08924181014299393
loss item: 0.10000865906476974
loss item: 0.08251335471868515
loss item: 0.088486447930336
loss item: 0.10343121737241745
loss item: 0.10400950163602829
loss item: 0.12385908514261246
loss item: 0.10138232260942459
loss item: 0.12891645729541779
loss item: 0.12507739663124084
Epoch [115/200], Training Loss: 0.0939, Testing Loss: 0.1144
no improvement in test loss for 4 epochs
Epoch 116/200
loss item: 0.10190537571907043
loss item: 0.09200581163167953
loss item: 0.07985176891088486
loss item: 0.09523463994264603
loss item: 0.08142919838428497
loss item: 0.08367536962032318
loss item: 0.08445052057504654
loss item: 0.0851956233382225
loss item: 0.1010703593492508
loss item: 0.08441542088985443
loss item: 0.11317137628793716
loss item: 0.1039641723036766
Epoch [116/200], Training Loss: 0.0890, Testing Loss: 0.0954
Best model saved!
Epoch 117/200
loss item: 0.08433467894792557
loss item: 0.08776932209730148
loss item: 0.09634363651275635
loss item: 0.08205849677324295
loss item: 0.07807394862174988
loss item: 0.11574215441942215
loss item: 0.102325439453125
loss item: 0.1012529730796814
loss item: 0.1296425610780716
loss item: 0.1030014157295227
loss item: 0.15895618498325348
loss item: 0.13303330540657043
Epoch [117/200], Training Loss: 0.0907, Testing Loss: 0.1214
no improvement in test loss for 1 epochs
Epoch 118/200
loss item: 0.11074225604534149
loss item: 0.10925263166427612
loss item: 0.0767478495836258
loss item: 0.08832254260778427
loss item: 0.10364831238985062
loss item: 0.08019643276929855
loss item: 0.08519097417593002
loss item: 0.08570823073387146
loss item: 0.10394492745399475
loss item: 0.08712801337242126
loss item: 0.11423902213573456
loss item: 0.10627982020378113
Epoch [118/200], Training Loss: 0.0948, Testing Loss: 0.0971
no improvement in test loss for 2 epochs
Epoch 119/200
loss item: 0.08380424231290817
loss item: 0.08875244110822678
loss item: 0.07947157323360443
loss item: 0.08633348345756531
loss item: 0.07710674405097961
loss item: 0.07841331511735916
loss item: 0.08282002806663513
loss item: 0.08347103744745255
loss item: 0.10174770653247833
loss item: 0.0852859616279602
loss item: 0.11048731207847595
loss item: 0.10420668870210648
Epoch [119/200], Training Loss: 0.0823, Testing Loss: 0.0947
Best model saved!
Epoch 120/200
loss item: 0.088467076420784
loss item: 0.08347820490598679
loss item: 0.08064004778862
loss item: 0.0786474198102951
loss item: 0.07529138773679733
loss item: 0.07939302921295166
loss item: 0.08538622409105301
loss item: 0.08604864031076431
loss item: 0.10213035345077515
loss item: 0.08568324893712997
loss item: 0.11463898420333862
loss item: 0.10489325225353241
Epoch [120/200], Training Loss: 0.0810, Testing Loss: 0.0965
no improvement in test loss for 1 epochs
Epoch 121/200
loss item: 0.08304357528686523
loss item: 0.08358775079250336
loss item: 0.07943405210971832
loss item: 0.0775776207447052
loss item: 0.07703788578510284
loss item: 0.08238501101732254
loss item: 0.08242479711771011
loss item: 0.08250653743743896
loss item: 0.0998820886015892
loss item: 0.08408968150615692
loss item: 0.11714541167020798
loss item: 0.10286960005760193
Epoch [121/200], Training Loss: 0.0805, Testing Loss: 0.0948
no improvement in test loss for 2 epochs
Epoch 122/200
loss item: 0.08604338765144348
loss item: 0.08297053724527359
loss item: 0.07555053383111954
loss item: 0.07816477119922638
loss item: 0.07613778859376907
loss item: 0.07606449723243713
loss item: 0.08899346739053726
loss item: 0.08835077285766602
loss item: 0.10709522664546967
loss item: 0.09031330049037933
loss item: 0.11740493029356003
loss item: 0.10860169678926468
Epoch [122/200], Training Loss: 0.0792, Testing Loss: 0.1001
no improvement in test loss for 3 epochs
Epoch 123/200
loss item: 0.08051032572984695
loss item: 0.08206360787153244
loss item: 0.07817301154136658
loss item: 0.07616440206766129
loss item: 0.07413876801729202
loss item: 0.08363361656665802
loss item: 0.08114434033632278
loss item: 0.08250170201063156
loss item: 0.10190135985612869
loss item: 0.08320912718772888
loss item: 0.11154168844223022
loss item: 0.10271681845188141
Epoch [123/200], Training Loss: 0.0791, Testing Loss: 0.0938
Best model saved!
Epoch 124/200
loss item: 0.08625320345163345
loss item: 0.07957044988870621
loss item: 0.07793143391609192
loss item: 0.07943945378065109
loss item: 0.07550766319036484
loss item: 0.07546643167734146
loss item: 0.0906553640961647
loss item: 0.09233613312244415
loss item: 0.11260178685188293
loss item: 0.09096246212720871
loss item: 0.11827900260686874
loss item: 0.11270605772733688
Epoch [124/200], Training Loss: 0.0790, Testing Loss: 0.1029
no improvement in test loss for 1 epochs
Epoch 125/200
loss item: 0.08352106064558029
loss item: 0.08442641794681549
loss item: 0.09063199907541275
loss item: 0.08844771981239319
loss item: 0.0825892835855484
loss item: 0.11019884794950485
loss item: 0.10267747938632965
loss item: 0.09870103746652603
loss item: 0.13365477323532104
loss item: 0.10843385756015778
loss item: 0.17614851891994476
loss item: 0.13972681760787964
Epoch [125/200], Training Loss: 0.0900, Testing Loss: 0.1266
no improvement in test loss for 2 epochs
Epoch 126/200
loss item: 0.11341600865125656
loss item: 0.104521244764328
loss item: 0.0779249519109726
loss item: 0.09281466156244278
loss item: 0.09220065921545029
loss item: 0.0782693549990654
loss item: 0.09245063364505768
loss item: 0.09165503084659576
loss item: 0.11144208908081055
loss item: 0.09400074928998947
loss item: 0.12173064798116684
loss item: 0.1129927709698677
Epoch [126/200], Training Loss: 0.0932, Testing Loss: 0.1040
no improvement in test loss for 3 epochs
Epoch 127/200
loss item: 0.08345425128936768
loss item: 0.08369690179824829
loss item: 0.0788845419883728
loss item: 0.07926460355520248
loss item: 0.07189800590276718
loss item: 0.07846149057149887
loss item: 0.08121835440397263
loss item: 0.08241841197013855
loss item: 0.0988643541932106
loss item: 0.0823153704404831
loss item: 0.10899694263935089
loss item: 0.10041739791631699
Epoch [127/200], Training Loss: 0.0793, Testing Loss: 0.0924
Best model saved!
Epoch 128/200
loss item: 0.08231281489133835
loss item: 0.08159574866294861
loss item: 0.0746476948261261
loss item: 0.07249629497528076
loss item: 0.07209029793739319
loss item: 0.08097867667675018
loss item: 0.07976830005645752
loss item: 0.07941772043704987
loss item: 0.09627456963062286
loss item: 0.08099831640720367
loss item: 0.11416804045438766
loss item: 0.10068611055612564
Epoch [128/200], Training Loss: 0.0774, Testing Loss: 0.0919
Best model saved!
Epoch 129/200
loss item: 0.0786205530166626
loss item: 0.08017275482416153
loss item: 0.09240122139453888
loss item: 0.09130379557609558
loss item: 0.07600345462560654
loss item: 0.09697646647691727
loss item: 0.1042972207069397
loss item: 0.10317542403936386
loss item: 0.1351032555103302
loss item: 0.10786621272563934
loss item: 0.1752714365720749
loss item: 0.13801367580890656
Epoch [129/200], Training Loss: 0.0859, Testing Loss: 0.1273
no improvement in test loss for 1 epochs
Epoch 130/200
loss item: 0.1032589003443718
loss item: 0.10170017182826996
loss item: 0.07597725838422775
loss item: 0.07877174019813538
loss item: 0.09276272356510162
loss item: 0.07821834087371826
loss item: 0.08359088748693466
loss item: 0.08365345746278763
loss item: 0.10606361925601959
loss item: 0.08687092363834381
loss item: 0.12211190909147263
loss item: 0.10953998565673828
Epoch [130/200], Training Loss: 0.0884, Testing Loss: 0.0986
no improvement in test loss for 2 epochs
Epoch 131/200
loss item: 0.08289258182048798
loss item: 0.08224476128816605
loss item: 0.07798434793949127
loss item: 0.08650048077106476
loss item: 0.07557043433189392
loss item: 0.07369467616081238
loss item: 0.08349662274122238
loss item: 0.08457235991954803
loss item: 0.10356708616018295
loss item: 0.08478136360645294
loss item: 0.11151248961687088
loss item: 0.10455619543790817
Epoch [131/200], Training Loss: 0.0798, Testing Loss: 0.0954
no improvement in test loss for 3 epochs
Epoch 132/200
loss item: 0.08777900040149689
loss item: 0.08487187325954437
loss item: 0.09273280948400497
loss item: 0.08098497241735458
loss item: 0.0764276385307312
loss item: 0.10770948231220245
loss item: 0.10075320303440094
loss item: 0.0975920706987381
loss item: 0.13121163845062256
loss item: 0.10663009434938431
loss item: 0.1672719120979309
loss item: 0.1369759738445282
Epoch [132/200], Training Loss: 0.0884, Testing Loss: 0.1234
no improvement in test loss for 4 epochs
Epoch 133/200
loss item: 0.1084553524851799
loss item: 0.0955469086766243
loss item: 0.0748782530426979
loss item: 0.09132898598909378
loss item: 0.08962185680866241
loss item: 0.07398618757724762
loss item: 0.0837542712688446
loss item: 0.08428560942411423
loss item: 0.10151077061891556
loss item: 0.08503472805023193
loss item: 0.11027660965919495
loss item: 0.10303191840648651
Epoch [133/200], Training Loss: 0.0890, Testing Loss: 0.0946
no improvement in test loss for 5 epochs
Epoch 134/200
loss item: 0.08023644983768463
loss item: 0.08317320793867111
loss item: 0.07601532340049744
loss item: 0.07642901688814163
loss item: 0.07063522934913635
loss item: 0.07484538108110428
loss item: 0.08052465319633484
loss item: 0.08105833828449249
loss item: 0.09867099672555923
loss item: 0.0819782093167305
loss item: 0.1069442629814148
loss item: 0.10110487043857574
Epoch [134/200], Training Loss: 0.0769, Testing Loss: 0.0917
Best model saved!
Epoch 135/200
loss item: 0.07989132404327393
loss item: 0.08045099675655365
loss item: 0.07172570377588272
loss item: 0.06908778846263885
loss item: 0.07213451713323593
loss item: 0.07841317355632782
loss item: 0.07751969993114471
loss item: 0.07783301174640656
loss item: 0.09390798211097717
loss item: 0.07920610159635544
loss item: 0.1056968942284584
loss item: 0.09760212153196335
Epoch [135/200], Training Loss: 0.0753, Testing Loss: 0.0886
Best model saved!
Epoch 136/200
loss item: 0.07510924339294434
loss item: 0.07540450245141983
loss item: 0.08472814410924911
loss item: 0.08246561884880066
loss item: 0.07170015573501587
loss item: 0.08424565941095352
loss item: 0.09277494251728058
loss item: 0.09141601622104645
loss item: 0.11417671293020248
loss item: 0.09353521466255188
loss item: 0.14160823822021484
loss item: 0.11923602968454361
Epoch [136/200], Training Loss: 0.0789, Testing Loss: 0.1088
no improvement in test loss for 1 epochs
Epoch 137/200
loss item: 0.09272776544094086
loss item: 0.09265154600143433
loss item: 0.07003495842218399
loss item: 0.07444065064191818
loss item: 0.08136993646621704
loss item: 0.07350235432386398
loss item: 0.0810842365026474
loss item: 0.08220582455396652
loss item: 0.10395745933055878
loss item: 0.08412142843008041
loss item: 0.11306353658437729
loss item: 0.10513533651828766
Epoch [137/200], Training Loss: 0.0808, Testing Loss: 0.0949
no improvement in test loss for 2 epochs
Epoch 138/200
loss item: 0.0754326581954956
loss item: 0.08039814978837967
loss item: 0.07300738990306854
loss item: 0.0761374682188034
loss item: 0.07315406203269958
loss item: 0.0782269686460495
loss item: 0.07770588994026184
loss item: 0.07919090241193771
loss item: 0.0957670658826828
loss item: 0.07891257852315903
loss item: 0.10376611351966858
loss item: 0.09683208912611008
Epoch [138/200], Training Loss: 0.0761, Testing Loss: 0.0887
no improvement in test loss for 3 epochs
Epoch 139/200
loss item: 0.08272561430931091
loss item: 0.07858842611312866
loss item: 0.08276552706956863
loss item: 0.08320925384759903
loss item: 0.07051634043455124
loss item: 0.08318296819925308
loss item: 0.09203097969293594
loss item: 0.09180324524641037
loss item: 0.11474771052598953
loss item: 0.09395089000463486
loss item: 0.14005602896213531
loss item: 0.11950881779193878
Epoch [139/200], Training Loss: 0.0802, Testing Loss: 0.1087
no improvement in test loss for 4 epochs
Epoch 140/200
loss item: 0.09302689880132675
loss item: 0.08109184354543686
loss item: 0.07618731260299683
loss item: 0.0887107104063034
loss item: 0.07675041258335114
loss item: 0.08014374226331711
loss item: 0.09356863796710968
loss item: 0.09311559796333313
loss item: 0.11388809978961945
loss item: 0.09373730421066284
loss item: 0.13517481088638306
loss item: 0.11802002787590027
Epoch [140/200], Training Loss: 0.0827, Testing Loss: 0.1079
no improvement in test loss for 5 epochs
Epoch 141/200
loss item: 0.08663780242204666
loss item: 0.0842798724770546
loss item: 0.07393697649240494
loss item: 0.07227406650781631
loss item: 0.07364192605018616
loss item: 0.07847563177347183
loss item: 0.08119337260723114
loss item: 0.08009392023086548
loss item: 0.09847921878099442
loss item: 0.08393143862485886
loss item: 0.10912984609603882
loss item: 0.10063473880290985
Epoch [141/200], Training Loss: 0.0782, Testing Loss: 0.0922
no improvement in test loss for 6 epochs
Epoch 142/200
loss item: 0.07307957857847214
loss item: 0.07691178470849991
loss item: 0.0772763043642044
loss item: 0.07135467231273651
loss item: 0.06712257862091064
loss item: 0.07811645418405533
loss item: 0.09071166068315506
loss item: 0.09228603541851044
loss item: 0.11307888478040695
loss item: 0.0904373899102211
loss item: 0.11709289252758026
loss item: 0.11285033077001572
Epoch [142/200], Training Loss: 0.0740, Testing Loss: 0.1027
no improvement in test loss for 7 epochs
Epoch 143/200
loss item: 0.07910636812448502
loss item: 0.07633961737155914
loss item: 0.0721096396446228
loss item: 0.07004378736019135
loss item: 0.07594069838523865
loss item: 0.06998811662197113
loss item: 0.08149609714746475
loss item: 0.08049929887056351
loss item: 0.09631482511758804
loss item: 0.08024752885103226
loss item: 0.10631992667913437
loss item: 0.09974642843008041
Epoch [143/200], Training Loss: 0.0739, Testing Loss: 0.0908
no improvement in test loss for 8 epochs
Epoch 144/200
loss item: 0.07490109652280807
loss item: 0.08316660672426224
loss item: 0.07413895428180695
loss item: 0.07582904398441315
loss item: 0.07300413399934769
loss item: 0.08141758292913437
loss item: 0.09012000262737274
loss item: 0.08875782042741776
loss item: 0.11082209646701813
loss item: 0.09199880808591843
loss item: 0.13067777454853058
loss item: 0.11309783905744553
Epoch [144/200], Training Loss: 0.0771, Testing Loss: 0.1042
no improvement in test loss for 9 epochs
Epoch 145/200
loss item: 0.08659086376428604
loss item: 0.0771089568734169
loss item: 0.07500199228525162
loss item: 0.08616846054792404
loss item: 0.07069151103496552
loss item: 0.0743972584605217
loss item: 0.08915331959724426
loss item: 0.08975087106227875
loss item: 0.10843849182128906
loss item: 0.08914213627576828
loss item: 0.12281658500432968
loss item: 0.11102325469255447
Epoch [145/200], Training Loss: 0.0783, Testing Loss: 0.1017
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.09478729218244553
loss item: 0.09197382628917694
loss item: 0.07533647865056992
Val Loss: 0.1747
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0001, epochs: 200, batch size: 128
Hyperparameter tuning prediction finished
UNet6 with 1 200 0.0001 128 180 done at Wed Nov 13 16:14:09 CET 2024
SBATCH job finished
