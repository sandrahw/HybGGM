SBATCH job
Started 13/11/2024 15:57:46
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
expandable_segments:True
UNet6 with 1 10 0.0001 2 360 start at Wed Nov 13 15:57:46 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 0.32543858885765076
test loss item: 0.3201671838760376
test loss item: 1.2930320501327515
test loss item: 0.45639359951019287
test loss item: 0.5333396792411804
test loss item: 0.30889764428138733
test loss item: 3.5530126094818115
test loss item: 1.234115719795227
test loss item: 0.476423978805542
test loss item: 0.778984546661377
test loss item: 1.7774710655212402
test loss item: 0.39120641350746155
test loss item: 0.37649041414260864
test loss item: 0.5524864196777344
test loss item: 0.4167979657649994
test loss item: 0.32238027453422546
test loss item: 0.5221328735351562
test loss item: 0.9708770513534546
test loss item: 1.2458000183105469
test loss item: 0.4878620505332947
test loss item: 1.5960745811462402
test loss item: 0.7644118070602417
test loss item: 0.6354523301124573
test loss item: 0.3850398659706116
test loss item: 0.4352385401725769
test loss item: 0.4026394784450531
test loss item: 0.58271324634552
test loss item: 0.41043102741241455
test loss item: 0.6289176940917969
test loss item: 0.6483367681503296
test loss item: 1.7453397512435913
test loss item: 0.31950175762176514
test loss item: 0.35034263134002686
test loss item: 1.12245774269104
test loss item: 0.9462670683860779
test loss item: 1.113990068435669
test loss item: 1.5381397008895874
test loss item: 3.152377128601074
test loss item: 0.9831701517105103
test loss item: 0.5262065529823303
test loss item: 0.5640122890472412
test loss item: 0.3411385416984558
test loss item: 0.6919870972633362
test loss item: 0.4776293933391571
test loss item: 1.2580336332321167
test loss item: 0.7641651034355164
test loss item: 0.5913205146789551
test loss item: 0.427951842546463
test loss item: 1.0075477361679077
test loss item: 1.388818383216858
test loss item: 0.6537537574768066
test loss item: 0.3242349326610565
test loss item: 0.48420798778533936
test loss item: 0.47728821635246277
test loss item: 0.6459164619445801
test loss item: 1.8029687404632568
test loss item: 1.2264267206192017
test loss item: 0.6554515361785889
test loss item: 0.486260324716568
test loss item: 0.39739689230918884
test loss item: 0.8615291118621826
test loss item: 0.5327340364456177
test loss item: 0.38816121220588684
test loss item: 0.4550304114818573
test loss item: 2.000312328338623
test loss item: 0.6046019792556763
test loss item: 0.6398140788078308
test loss item: 0.4611686170101166
test loss item: 1.0433357954025269
test loss item: 0.9037917256355286
test loss item: 0.2714395821094513
test loss item: 2.0580642223358154
test loss item: 0.6133452653884888
test loss item: 0.7100709676742554
test loss item: 0.30532658100128174
test loss item: 0.34291383624076843
test loss item: 0.38030973076820374
test loss item: 3.477576971054077
test loss item: 0.8611140847206116
test loss item: 0.36515647172927856
test loss item: 0.25860074162483215
test loss item: 2.1804089546203613
test loss item: 1.6943840980529785
test loss item: 2.3984882831573486
test loss item: 0.45027413964271545
test loss item: 0.4050922691822052
test loss item: 0.28383657336235046
test loss item: 0.312621533870697
test loss item: 0.28796151280403137
Epoch [1/10], Training Loss: 1.0161, Testing Loss: 0.8409
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8469700217247009
1
train loss item: 2.2568891048431396
2
train loss item: 0.5336769223213196
3
train loss item: 1.237526774406433
4
train loss item: 0.9404008984565735
5
train loss item: 0.6270371675491333
6
train loss item: 0.57844078540802
7
train loss item: 1.4458200931549072
8
train loss item: 0.47675803303718567
9
train loss item: 0.5896623730659485
10
train loss item: 0.7542068362236023
11
train loss item: 0.48272591829299927
12
train loss item: 0.4065133035182953
13
train loss item: 0.9814792275428772
14
train loss item: 0.5562806129455566
15
train loss item: 1.2292604446411133
16
train loss item: 0.3920826315879822
17
train loss item: 0.5793091058731079
18
train loss item: 0.7637796998023987
19
train loss item: 0.5272666811943054
20
train loss item: 0.4833765923976898
21
train loss item: 0.3846867084503174
22
train loss item: 1.8146706819534302
23
train loss item: 1.5029590129852295
24
train loss item: 1.02009916305542
25
train loss item: 0.5557008385658264
26
train loss item: 0.45766282081604004
27
train loss item: 0.6440454125404358
28
train loss item: 0.3889157474040985
29
train loss item: 1.458027958869934
30
train loss item: 3.3603432178497314
31
train loss item: 1.1073217391967773
32
train loss item: 0.4354054033756256
33
train loss item: 0.9232630133628845
34
train loss item: 0.5001205205917358
35
train loss item: 3.199995279312134
36
train loss item: 0.9644607901573181
37
train loss item: 0.5206009149551392
38
train loss item: 1.0942904949188232
39
train loss item: 0.6534966826438904
40
train loss item: 0.4141879081726074
41
train loss item: 0.6332598328590393
42
train loss item: 0.4832932949066162
43
train loss item: 0.49745216965675354
44
train loss item: 1.2244560718536377
45
train loss item: 0.4191514551639557
46
train loss item: 0.4505915939807892
47
train loss item: 0.7244898080825806
48
train loss item: 0.5662857890129089
49
train loss item: 0.45370593667030334
50
train loss item: 0.5387917160987854
51
train loss item: 1.5974620580673218
52
train loss item: 0.4117096960544586
53
train loss item: 0.4850711226463318
54
train loss item: 3.072237253189087
55
train loss item: 0.4860619008541107
56
train loss item: 0.6088640093803406
57
train loss item: 0.5018900632858276
58
train loss item: 0.4447954297065735
59
train loss item: 0.48289012908935547
60
train loss item: 1.7332994937896729
61
train loss item: 3.049617290496826
62
train loss item: 0.5403962731361389
63
train loss item: 0.7169005274772644
64
train loss item: 0.4913247525691986
65
train loss item: 1.0675947666168213
66
train loss item: 0.7613896727561951
67
train loss item: 0.4965679943561554
68
train loss item: 0.700104832649231
69
train loss item: 0.6811779141426086
70
train loss item: 0.5612931847572327
71
train loss item: 0.42531144618988037
72
train loss item: 0.528998851776123
73
train loss item: 0.586263120174408
74
train loss item: 0.46703168749809265
75
train loss item: 0.4403144121170044
76
train loss item: 1.4954246282577515
77
train loss item: 1.9771878719329834
78
train loss item: 0.40473371744155884
79
train loss item: 0.5859912633895874
80
train loss item: 0.4113095700740814
81
train loss item: 0.45442962646484375
82
train loss item: 0.5650709867477417
83
train loss item: 1.2717928886413574
84
train loss item: 0.7470484972000122
85
train loss item: 1.1924268007278442
86
train loss item: 5.400422096252441
87
train loss item: 0.538705587387085
88
train loss item: 0.6909709572792053
epoch train loss: 0.9118570514609304
testing phase
test loss item: 0.32313835620880127
test loss item: 0.33549079298973083
test loss item: 1.2464580535888672
test loss item: 0.4215610921382904
test loss item: 0.545681357383728
test loss item: 0.3143472373485565
test loss item: 3.2590036392211914
test loss item: 1.0636874437332153
test loss item: 0.47387224435806274
test loss item: 0.7689830660820007
test loss item: 1.6702098846435547
test loss item: 0.36385172605514526
test loss item: 0.3599485456943512
test loss item: 0.5972532033920288
test loss item: 0.4212416112422943
test loss item: 0.34016671776771545
test loss item: 0.46121975779533386
test loss item: 0.9875484704971313
test loss item: 1.118828296661377
test loss item: 0.4557102620601654
test loss item: 1.62374746799469
test loss item: 0.6738596558570862
test loss item: 0.6389990448951721
test loss item: 0.3596741855144501
test loss item: 0.4314025938510895
test loss item: 0.3838667869567871
test loss item: 0.5595067143440247
test loss item: 0.4218214452266693
test loss item: 0.6222934722900391
test loss item: 0.6317676305770874
test loss item: 1.6140263080596924
test loss item: 0.32190608978271484
test loss item: 0.33373966813087463
test loss item: 1.109312891960144
test loss item: 0.9489903450012207
test loss item: 1.1102555990219116
test loss item: 1.4203596115112305
test loss item: 2.964846134185791
test loss item: 0.966056764125824
test loss item: 0.4911685287952423
test loss item: 0.5290465950965881
test loss item: 0.32827121019363403
test loss item: 0.7328452467918396
test loss item: 0.4300273656845093
test loss item: 1.2944674491882324
test loss item: 0.6773479580879211
test loss item: 0.5981626510620117
test loss item: 0.4238423705101013
test loss item: 0.9695281982421875
test loss item: 1.2928868532180786
test loss item: 0.690413773059845
test loss item: 0.3104289174079895
test loss item: 0.48790881037712097
test loss item: 0.4154609739780426
test loss item: 0.6776193976402283
test loss item: 1.7218269109725952
test loss item: 1.172100305557251
test loss item: 0.7466410398483276
test loss item: 0.47152912616729736
test loss item: 0.4307118356227875
test loss item: 0.8777498006820679
test loss item: 0.4464675188064575
test loss item: 0.3672596216201782
test loss item: 0.42773938179016113
test loss item: 1.8666683435440063
test loss item: 0.5466116666793823
test loss item: 0.5705507397651672
test loss item: 0.44019070267677307
test loss item: 1.0254302024841309
test loss item: 0.8006142377853394
test loss item: 0.28219568729400635
test loss item: 1.832497477531433
test loss item: 0.6555683016777039
test loss item: 0.617949366569519
test loss item: 0.2844226360321045
test loss item: 0.32915470004081726
test loss item: 0.35920450091362
test loss item: 3.2612061500549316
test loss item: 0.8693538904190063
test loss item: 0.36148953437805176
test loss item: 0.25196540355682373
test loss item: 2.029910087585449
test loss item: 1.5777088403701782
test loss item: 2.250333309173584
test loss item: 0.45082563161849976
test loss item: 0.3806471824645996
test loss item: 0.28600361943244934
test loss item: 0.3300008177757263
test loss item: 0.2796914279460907
Epoch [2/10], Training Loss: 0.9119, Testing Loss: 0.8047
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8339841961860657
1
train loss item: 2.155839443206787
2
train loss item: 0.5232412815093994
3
train loss item: 1.150844693183899
4
train loss item: 0.882523238658905
5
train loss item: 0.6161549687385559
6
train loss item: 0.5675970315933228
7
train loss item: 1.3633010387420654
8
train loss item: 0.4495686888694763
9
train loss item: 0.5440057516098022
10
train loss item: 0.7016858458518982
11
train loss item: 0.45297563076019287
12
train loss item: 0.3669850826263428
13
train loss item: 0.9551968574523926
14
train loss item: 0.5574626326560974
15
train loss item: 1.1836556196212769
16
train loss item: 0.3848850131034851
17
train loss item: 0.5527244806289673
18
train loss item: 0.719939649105072
19
train loss item: 0.48777318000793457
20
train loss item: 0.46295514702796936
21
train loss item: 0.36673852801322937
22
train loss item: 1.7580007314682007
23
train loss item: 1.4418275356292725
24
train loss item: 0.9778796434402466
25
train loss item: 0.5289973616600037
26
train loss item: 0.43923649191856384
27
train loss item: 0.6160111427307129
28
train loss item: 0.37907761335372925
29
train loss item: 1.4136497974395752
30
train loss item: 3.1977977752685547
31
train loss item: 1.0274486541748047
32
train loss item: 0.37705734372138977
33
train loss item: 0.8513282537460327
34
train loss item: 0.5206930041313171
35
train loss item: 3.1048710346221924
36
train loss item: 0.9418485760688782
37
train loss item: 0.4913369119167328
38
train loss item: 1.0372068881988525
39
train loss item: 0.6275733113288879
40
train loss item: 0.3992249369621277
41
train loss item: 0.5987964272499084
42
train loss item: 0.4522729218006134
43
train loss item: 0.4486117362976074
44
train loss item: 1.1767184734344482
45
train loss item: 0.4142310917377472
46
train loss item: 0.4471043050289154
47
train loss item: 0.6793163418769836
48
train loss item: 0.5297558307647705
49
train loss item: 0.4446152448654175
50
train loss item: 0.5057280659675598
51
train loss item: 1.5452731847763062
52
train loss item: 0.36935728788375854
53
train loss item: 0.47329387068748474
54
train loss item: 2.9714455604553223
55
train loss item: 0.49070268869400024
56
train loss item: 0.5764620304107666
57
train loss item: 0.4921422004699707
58
train loss item: 0.39828577637672424
59
train loss item: 0.4151388108730316
60
train loss item: 1.6824674606323242
61
train loss item: 2.940248727798462
62
train loss item: 0.4804028272628784
63
train loss item: 0.6669731140136719
64
train loss item: 0.43764612078666687
65
train loss item: 1.0308862924575806
66
train loss item: 0.7245259881019592
67
train loss item: 0.47396448254585266
68
train loss item: 0.6318886280059814
69
train loss item: 0.6422450542449951
70
train loss item: 0.5253357291221619
71
train loss item: 0.4606528878211975
72
train loss item: 0.4892352223396301
73
train loss item: 0.5586839914321899
74
train loss item: 0.4522111415863037
75
train loss item: 0.38975849747657776
76
train loss item: 1.4339712858200073
77
train loss item: 1.9305144548416138
78
train loss item: 0.368850439786911
79
train loss item: 0.5352991223335266
80
train loss item: 0.4268273413181305
81
train loss item: 0.4208105802536011
82
train loss item: 0.5485832095146179
83
train loss item: 1.2255637645721436
84
train loss item: 0.7117674946784973
85
train loss item: 1.1252810955047607
86
train loss item: 5.23826789855957
87
train loss item: 0.5173043608665466
88
train loss item: 0.6507450342178345
epoch train loss: 0.8714749337582106
testing phase
test loss item: 0.31795457005500793
test loss item: 0.33500340580940247
test loss item: 1.22190260887146
test loss item: 0.3949345052242279
test loss item: 0.5478627681732178
test loss item: 0.3122747540473938
test loss item: 2.9288077354431152
test loss item: 0.889796257019043
test loss item: 0.47539907693862915
test loss item: 0.7647536993026733
test loss item: 1.6291959285736084
test loss item: 0.3499634563922882
test loss item: 0.36035239696502686
test loss item: 0.6533820033073425
test loss item: 0.4128269851207733
test loss item: 0.34199076890945435
test loss item: 0.4320693910121918
test loss item: 0.9891956448554993
test loss item: 1.0085471868515015
test loss item: 0.46115145087242126
test loss item: 1.6226433515548706
test loss item: 0.6145684719085693
test loss item: 0.6501948237419128
test loss item: 0.3369729518890381
test loss item: 0.4258705973625183
test loss item: 0.40289613604545593
test loss item: 0.5507012605667114
test loss item: 0.42514339089393616
test loss item: 0.6126364469528198
test loss item: 0.6209904551506042
test loss item: 1.5354390144348145
test loss item: 0.3173537850379944
test loss item: 0.3136001527309418
test loss item: 1.0968449115753174
test loss item: 0.9422520399093628
test loss item: 1.0225224494934082
test loss item: 1.2986174821853638
test loss item: 2.902078151702881
test loss item: 0.9525632262229919
test loss item: 0.46431851387023926
test loss item: 0.4985174238681793
test loss item: 0.3405885696411133
test loss item: 0.7489770650863647
test loss item: 0.4025125503540039
test loss item: 1.3049724102020264
test loss item: 0.6391319632530212
test loss item: 0.6088792085647583
test loss item: 0.45782670378685
test loss item: 0.947560727596283
test loss item: 1.2390003204345703
test loss item: 0.7077956795692444
test loss item: 0.31042444705963135
test loss item: 0.4959840476512909
test loss item: 0.38483959436416626
test loss item: 0.6994051933288574
test loss item: 1.6884492635726929
test loss item: 1.0632306337356567
test loss item: 0.7790811657905579
test loss item: 0.46323174238204956
test loss item: 0.4554395377635956
test loss item: 0.8789593577384949
test loss item: 0.3961588144302368
test loss item: 0.37443986535072327
test loss item: 0.4060540199279785
test loss item: 1.7633836269378662
test loss item: 0.506710410118103
test loss item: 0.5404588580131531
test loss item: 0.4258936047554016
test loss item: 1.0155770778656006
test loss item: 0.7440217137336731
test loss item: 0.28759053349494934
test loss item: 1.607879877090454
test loss item: 0.680265486240387
test loss item: 0.568448543548584
test loss item: 0.29144391417503357
test loss item: 0.33735382556915283
test loss item: 0.3394831717014313
test loss item: 3.1792073249816895
test loss item: 0.8882248401641846
test loss item: 0.3628036379814148
test loss item: 0.2422766089439392
test loss item: 1.9008512496948242
test loss item: 1.475480318069458
test loss item: 2.1858761310577393
test loss item: 0.4629882574081421
test loss item: 0.39659690856933594
test loss item: 0.2774353623390198
test loss item: 0.3253585696220398
test loss item: 0.31033265590667725
Epoch [3/10], Training Loss: 0.8715, Testing Loss: 0.7791
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8108084201812744
1
train loss item: 2.0759809017181396
2
train loss item: 0.4898815155029297
3
train loss item: 1.092602252960205
4
train loss item: 0.8475688695907593
5
train loss item: 0.6006972789764404
6
train loss item: 0.5378050208091736
7
train loss item: 1.3109055757522583
8
train loss item: 0.4388323426246643
9
train loss item: 0.5080493092536926
10
train loss item: 0.670032262802124
11
train loss item: 0.43226227164268494
12
train loss item: 0.3437403738498688
13
train loss item: 0.9259993433952332
14
train loss item: 0.5493934750556946
15
train loss item: 1.1318696737289429
16
train loss item: 0.36250928044319153
17
train loss item: 0.5233271718025208
18
train loss item: 0.6783027648925781
19
train loss item: 0.4564222991466522
20
train loss item: 0.42156511545181274
21
train loss item: 0.360436350107193
22
train loss item: 1.6809577941894531
23
train loss item: 1.4047471284866333
24
train loss item: 0.9263560175895691
25
train loss item: 0.5049294829368591
26
train loss item: 0.43008047342300415
27
train loss item: 0.5890274047851562
28
train loss item: 0.3583187758922577
29
train loss item: 1.3561855554580688
30
train loss item: 3.10564923286438
31
train loss item: 0.9759548306465149
32
train loss item: 0.3571937680244446
33
train loss item: 0.8014444708824158
34
train loss item: 0.5056254267692566
35
train loss item: 3.045522451400757
36
train loss item: 0.9087722301483154
37
train loss item: 0.4551425874233246
38
train loss item: 0.9830286502838135
39
train loss item: 0.6014152765274048
40
train loss item: 0.3791196048259735
41
train loss item: 0.5738795399665833
42
train loss item: 0.4293659031391144
43
train loss item: 0.4173487722873688
44
train loss item: 1.1409655809402466
45
train loss item: 0.4043237268924713
46
train loss item: 0.43998920917510986
47
train loss item: 0.6404938101768494
48
train loss item: 0.5066149234771729
49
train loss item: 0.4372107684612274
50
train loss item: 0.46831732988357544
51
train loss item: 1.4908002614974976
52
train loss item: 0.3506079614162445
53
train loss item: 0.4517662525177002
54
train loss item: 2.912156581878662
55
train loss item: 0.48277050256729126
56
train loss item: 0.5510663390159607
57
train loss item: 0.47791534662246704
58
train loss item: 0.3733982443809509
59
train loss item: 0.39021700620651245
60
train loss item: 1.6149908304214478
61
train loss item: 2.8774216175079346
62
train loss item: 0.4480277895927429
63
train loss item: 0.6163225769996643
64
train loss item: 0.4062311351299286
65
train loss item: 0.9675815105438232
66
train loss item: 0.6944425106048584
67
train loss item: 0.45582976937294006
68
train loss item: 0.5773131251335144
69
train loss item: 0.6074137687683105
70
train loss item: 0.49719342589378357
71
train loss item: 0.44620922207832336
72
train loss item: 0.469643235206604
73
train loss item: 0.5289588570594788
74
train loss item: 0.44426441192626953
75
train loss item: 0.3619333803653717
76
train loss item: 1.3938376903533936
77
train loss item: 1.8615220785140991
78
train loss item: 0.3491065502166748
79
train loss item: 0.49164482951164246
80
train loss item: 0.41383516788482666
81
train loss item: 0.4007931351661682
82
train loss item: 0.5311732292175293
83
train loss item: 1.1701936721801758
84
train loss item: 0.6768920421600342
85
train loss item: 1.0704846382141113
86
train loss item: 5.145071506500244
87
train loss item: 0.4921460747718811
88
train loss item: 0.6109681129455566
epoch train loss: 0.8370687301908986
testing phase
test loss item: 0.30775806307792664
test loss item: 0.3258143961429596
test loss item: 1.1821327209472656
test loss item: 0.3921280801296234
test loss item: 0.5345216989517212
test loss item: 0.30030298233032227
test loss item: 2.674144983291626
test loss item: 0.7942736148834229
test loss item: 0.4592096507549286
test loss item: 0.738875687122345
test loss item: 1.616614818572998
test loss item: 0.35423293709754944
test loss item: 0.3492778539657593
test loss item: 0.6735019087791443
test loss item: 0.39678722620010376
test loss item: 0.33603009581565857
test loss item: 0.4119952321052551
test loss item: 0.9577990174293518
test loss item: 0.9643687009811401
test loss item: 0.4510314464569092
test loss item: 1.5708104372024536
test loss item: 0.5862696766853333
test loss item: 0.6374735832214355
test loss item: 0.31966790556907654
test loss item: 0.4100848436355591
test loss item: 0.411099910736084
test loss item: 0.5351224541664124
test loss item: 0.4139607548713684
test loss item: 0.5928141474723816
test loss item: 0.5945517420768738
test loss item: 1.4850165843963623
test loss item: 0.31441786885261536
test loss item: 0.29711011052131653
test loss item: 1.06705641746521
test loss item: 0.909639298915863
test loss item: 0.9561935663223267
test loss item: 1.2183877229690552
test loss item: 2.8717055320739746
test loss item: 0.9257088899612427
test loss item: 0.4419702887535095
test loss item: 0.47393158078193665
test loss item: 0.33632317185401917
test loss item: 0.7221086025238037
test loss item: 0.39759790897369385
test loss item: 1.2685260772705078
test loss item: 0.619602382183075
test loss item: 0.5946896076202393
test loss item: 0.4600624144077301
test loss item: 0.9146065711975098
test loss item: 1.2111867666244507
test loss item: 0.6846043467521667
test loss item: 0.2962060272693634
test loss item: 0.4858265817165375
test loss item: 0.403663694858551
test loss item: 0.6865236163139343
test loss item: 1.6551570892333984
test loss item: 0.9967135190963745
test loss item: 0.745629072189331
test loss item: 0.44499170780181885
test loss item: 0.4517505168914795
test loss item: 0.8450803160667419
test loss item: 0.3694184124469757
test loss item: 0.3730672001838684
test loss item: 0.38889753818511963
test loss item: 1.6918002367019653
test loss item: 0.5134384036064148
test loss item: 0.519895613193512
test loss item: 0.4108377695083618
test loss item: 0.9941897392272949
test loss item: 0.7626914978027344
test loss item: 0.28554823994636536
test loss item: 1.4507932662963867
test loss item: 0.6628401875495911
test loss item: 0.5367685556411743
test loss item: 0.28925982117652893
test loss item: 0.3314896821975708
test loss item: 0.3226867914199829
test loss item: 3.137493133544922
test loss item: 0.8804183602333069
test loss item: 0.35482415556907654
test loss item: 0.23323333263397217
test loss item: 1.824426531791687
test loss item: 1.404819369316101
test loss item: 2.1530356407165527
test loss item: 0.46168550848960876
test loss item: 0.4018937349319458
test loss item: 0.2681317925453186
test loss item: 0.31411948800086975
test loss item: 0.3249461054801941
Epoch [4/10], Training Loss: 0.8371, Testing Loss: 0.7544
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7796609401702881
1
train loss item: 2.010059356689453
2
train loss item: 0.44511091709136963
3
train loss item: 1.0517438650131226
4
train loss item: 0.8450306057929993
5
train loss item: 0.57757967710495
6
train loss item: 0.49180009961128235
7
train loss item: 1.2760989665985107
8
train loss item: 0.40773940086364746
9
train loss item: 0.4794023931026459
10
train loss item: 0.6471192836761475
11
train loss item: 0.41555893421173096
12
train loss item: 0.3190993368625641
13
train loss item: 0.8921120166778564
14
train loss item: 0.5288026332855225
15
train loss item: 1.0764939785003662
16
train loss item: 0.32711538672447205
17
train loss item: 0.4874758720397949
18
train loss item: 0.6384450197219849
19
train loss item: 0.42818355560302734
20
train loss item: 0.3809441328048706
21
train loss item: 0.34640902280807495
22
train loss item: 1.5987602472305298
23
train loss item: 1.3802639245986938
24
train loss item: 0.8739868998527527
25
train loss item: 0.47697538137435913
26
train loss item: 0.40358397364616394
27
train loss item: 0.563049852848053
28
train loss item: 0.32396200299263
29
train loss item: 1.2944035530090332
30
train loss item: 3.051302909851074
31
train loss item: 0.9362643361091614
32
train loss item: 0.34588149189949036
33
train loss item: 0.760771632194519
34
train loss item: 0.4560913145542145
35
train loss item: 3.0069806575775146
36
train loss item: 0.8687840700149536
37
train loss item: 0.4212398827075958
38
train loss item: 0.9265044927597046
39
train loss item: 0.5739575028419495
40
train loss item: 0.34593287110328674
41
train loss item: 0.554138720035553
42
train loss item: 0.40638595819473267
43
train loss item: 0.39280709624290466
44
train loss item: 1.1122468709945679
45
train loss item: 0.3839446008205414
46
train loss item: 0.42057302594184875
47
train loss item: 0.6026238799095154
48
train loss item: 0.48460885882377625
49
train loss item: 0.4203546345233917
50
train loss item: 0.43820545077323914
51
train loss item: 1.438658356666565
52
train loss item: 0.32985472679138184
53
train loss item: 0.4154053330421448
54
train loss item: 2.8761720657348633
55
train loss item: 0.4509719908237457
56
train loss item: 0.5292982459068298
57
train loss item: 0.45409220457077026
58
train loss item: 0.3560706079006195
59
train loss item: 0.3754793405532837
60
train loss item: 1.5435209274291992
61
train loss item: 2.839668035507202
62
train loss item: 0.4227515757083893
63
train loss item: 0.5711086988449097
64
train loss item: 0.3833215534687042
65
train loss item: 0.8986271619796753
66
train loss item: 0.6659120321273804
67
train loss item: 0.43268099427223206
68
train loss item: 0.5251824259757996
69
train loss item: 0.5718252062797546
70
train loss item: 0.4679638147354126
71
train loss item: 0.395112007856369
72
train loss item: 0.4398232698440552
73
train loss item: 0.4954840838909149
74
train loss item: 0.40830540657043457
75
train loss item: 0.3373056650161743
76
train loss item: 1.3642897605895996
77
train loss item: 1.792600154876709
78
train loss item: 0.3277115821838379
79
train loss item: 0.45572367310523987
80
train loss item: 0.3728855550289154
81
train loss item: 0.3768095374107361
82
train loss item: 0.5061531066894531
83
train loss item: 1.1126750707626343
84
train loss item: 0.6400269269943237
85
train loss item: 1.0217664241790771
86
train loss item: 5.090869426727295
87
train loss item: 0.45434513688087463
88
train loss item: 0.569412350654602
epoch train loss: 0.8020947856849499
testing phase
test loss item: 0.2944079339504242
test loss item: 0.31115877628326416
test loss item: 1.1197236776351929
test loss item: 0.4002673923969269
test loss item: 0.508098304271698
test loss item: 0.2811153829097748
test loss item: 2.4720258712768555
test loss item: 0.7395989298820496
test loss item: 0.42620962858200073
test loss item: 0.6889616847038269
test loss item: 1.5894813537597656
test loss item: 0.3649256229400635
test loss item: 0.3259153366088867
test loss item: 0.6538464426994324
test loss item: 0.3734178841114044
test loss item: 0.32615044713020325
test loss item: 0.39542409777641296
test loss item: 0.8938087224960327
test loss item: 0.9357021450996399
test loss item: 0.4182967245578766
test loss item: 1.4634835720062256
test loss item: 0.5720834136009216
test loss item: 0.6062527894973755
test loss item: 0.30439653992652893
test loss item: 0.38704171776771545
test loss item: 0.4026276469230652
test loss item: 0.5040755867958069
test loss item: 0.3908088207244873
test loss item: 0.5614749193191528
test loss item: 0.5503042936325073
test loss item: 1.428540587425232
test loss item: 0.30953580141067505
test loss item: 0.28297945857048035
test loss item: 1.0153175592422485
test loss item: 0.8510465025901794
test loss item: 0.89387047290802
test loss item: 1.152208924293518
test loss item: 2.811809778213501
test loss item: 0.8805440664291382
test loss item: 0.42009496688842773
test loss item: 0.4534331262111664
test loss item: 0.32947438955307007
test loss item: 0.6613423228263855
test loss item: 0.4020794928073883
test loss item: 1.1827168464660645
test loss item: 0.597578227519989
test loss item: 0.5653376579284668
test loss item: 0.4178438186645508
test loss item: 0.8647207021713257
test loss item: 1.1736154556274414
test loss item: 0.6257843375205994
test loss item: 0.26680490374565125
test loss item: 0.4597395062446594
test loss item: 0.4372676908969879
test loss item: 0.6427798867225647
test loss item: 1.592572808265686
test loss item: 0.9511065483093262
test loss item: 0.659789502620697
test loss item: 0.41512224078178406
test loss item: 0.4266466200351715
test loss item: 0.7771083116531372
test loss item: 0.35032975673675537
test loss item: 0.3610040843486786
test loss item: 0.37155458331108093
test loss item: 1.620525598526001
test loss item: 0.5392459034919739
test loss item: 0.49479857087135315
test loss item: 0.39421167969703674
test loss item: 0.9604143500328064
test loss item: 0.7655041813850403
test loss item: 0.2775587737560272
test loss item: 1.335054874420166
test loss item: 0.6097002625465393
test loss item: 0.5110036730766296
test loss item: 0.27846789360046387
test loss item: 0.32539108395576477
test loss item: 0.3064116835594177
test loss item: 3.0769379138946533
test loss item: 0.8437519073486328
test loss item: 0.3389020562171936
test loss item: 0.22244851291179657
test loss item: 1.7589613199234009
test loss item: 1.3271862268447876
test loss item: 2.107534170150757
test loss item: 0.4446197748184204
test loss item: 0.39662104845046997
test loss item: 0.2579548954963684
test loss item: 0.3008650243282318
test loss item: 0.3266509771347046
Epoch [5/10], Training Loss: 0.8021, Testing Loss: 0.7204
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.748602569103241
1
train loss item: 1.9517829418182373
2
train loss item: 0.41519537568092346
3
train loss item: 1.0192244052886963
4
train loss item: 0.894048810005188
5
train loss item: 0.5546940565109253
6
train loss item: 0.4568100869655609
7
train loss item: 1.2496094703674316
8
train loss item: 0.381190687417984
9
train loss item: 0.45959967374801636
10
train loss item: 0.6275076270103455
11
train loss item: 0.40392738580703735
12
train loss item: 0.304228812456131
13
train loss item: 0.8573651313781738
14
train loss item: 0.5061242580413818
15
train loss item: 1.0250595808029175
16
train loss item: 0.30560600757598877
17
train loss item: 0.464793860912323
18
train loss item: 0.6037325263023376
19
train loss item: 0.40831005573272705
20
train loss item: 0.3664623498916626
21
train loss item: 0.33752259612083435
22
train loss item: 1.522081732749939
23
train loss item: 1.3595930337905884
24
train loss item: 0.8278939723968506
25
train loss item: 0.45202314853668213
26
train loss item: 0.37200385332107544
27
train loss item: 0.5421493649482727
28
train loss item: 0.30322331190109253
29
train loss item: 1.2347155809402466
30
train loss item: 3.011455535888672
31
train loss item: 0.9026116132736206
32
train loss item: 0.34614595770835876
33
train loss item: 0.7282379865646362
34
train loss item: 0.41544389724731445
35
train loss item: 2.9755706787109375
36
train loss item: 0.825667142868042
37
train loss item: 0.3970089256763458
38
train loss item: 0.8682070970535278
39
train loss item: 0.5498356819152832
40
train loss item: 0.3182787001132965
41
train loss item: 0.5385719537734985
42
train loss item: 0.38787946105003357
43
train loss item: 0.3830243647098541
44
train loss item: 1.0866726636886597
45
train loss item: 0.3660482168197632
46
train loss item: 0.39839762449264526
47
train loss item: 0.5699037909507751
48
train loss item: 0.46495288610458374
49
train loss item: 0.4028517007827759
50
train loss item: 0.42106306552886963
51
train loss item: 1.3907179832458496
52
train loss item: 0.3213968873023987
53
train loss item: 0.38304316997528076
54
train loss item: 2.8478095531463623
55
train loss item: 0.41298386454582214
56
train loss item: 0.5140069127082825
57
train loss item: 0.43129900097846985
58
train loss item: 0.3543808162212372
59
train loss item: 0.36845850944519043
60
train loss item: 1.475396752357483
61
train loss item: 2.8099191188812256
62
train loss item: 0.40563157200813293
63
train loss item: 0.5364493727684021
64
train loss item: 0.3755883276462555
65
train loss item: 0.8417280316352844
66
train loss item: 0.6378605961799622
67
train loss item: 0.41260582208633423
68
train loss item: 0.4824536144733429
69
train loss item: 0.5390900373458862
70
train loss item: 0.4430888891220093
71
train loss item: 0.350946307182312
72
train loss item: 0.41805705428123474
73
train loss item: 0.4664129614830017
74
train loss item: 0.37507736682891846
75
train loss item: 0.32431578636169434
76
train loss item: 1.338376760482788
77
train loss item: 1.7337982654571533
78
train loss item: 0.32134532928466797
79
train loss item: 0.4309845268726349
80
train loss item: 0.34380486607551575
81
train loss item: 0.356802761554718
82
train loss item: 0.47982290387153625
83
train loss item: 1.0581223964691162
84
train loss item: 0.6024861931800842
85
train loss item: 0.9773295521736145
86
train loss item: 5.050403118133545
87
train loss item: 0.42371076345443726
88
train loss item: 0.5321334600448608
epoch train loss: 0.7739410159293185
testing phase
test loss item: 0.28285765647888184
test loss item: 0.2910250723361969
test loss item: 1.038278341293335
test loss item: 0.39673641324043274
test loss item: 0.4713729918003082
test loss item: 0.25869959592819214
test loss item: 2.308614492416382
test loss item: 0.6804385185241699
test loss item: 0.38770467042922974
test loss item: 0.6292113661766052
test loss item: 1.516302466392517
test loss item: 0.35848477482795715
test loss item: 0.3048478960990906
test loss item: 0.5956932306289673
test loss item: 0.34451016783714294
test loss item: 0.3108348846435547
test loss item: 0.38500136137008667
test loss item: 0.8092104196548462
test loss item: 0.8820996284484863
test loss item: 0.388202965259552
test loss item: 1.3188745975494385
test loss item: 0.5528374314308167
test loss item: 0.5582733750343323
test loss item: 0.2905130982398987
test loss item: 0.3622836172580719
test loss item: 0.3818763196468353
test loss item: 0.471523642539978
test loss item: 0.35931968688964844
test loss item: 0.5230212807655334
test loss item: 0.5107801556587219
test loss item: 1.347151756286621
test loss item: 0.29419392347335815
test loss item: 0.27123507857322693
test loss item: 0.9430735111236572
test loss item: 0.7770939469337463
test loss item: 0.8116128444671631
test loss item: 1.0822099447250366
test loss item: 2.6699509620666504
test loss item: 0.8191039562225342
test loss item: 0.3989098370075226
test loss item: 0.4362823963165283
test loss item: 0.3216151297092438
test loss item: 0.5876280069351196
test loss item: 0.3949923813343048
test loss item: 1.0627949237823486
test loss item: 0.5728654265403748
test loss item: 0.523749828338623
test loss item: 0.3899497389793396
test loss item: 0.803936779499054
test loss item: 1.1039834022521973
test loss item: 0.5513961911201477
test loss item: 0.24738220870494843
test loss item: 0.42468276619911194
test loss item: 0.4384826719760895
test loss item: 0.5777075290679932
test loss item: 1.4862524271011353
test loss item: 0.893644392490387
test loss item: 0.5411104559898376
test loss item: 0.3828810751438141
test loss item: 0.3893232047557831
test loss item: 0.6959276795387268
test loss item: 0.33346280455589294
test loss item: 0.3437314033508301
test loss item: 0.35429808497428894
test loss item: 1.5240002870559692
test loss item: 0.5391833186149597
test loss item: 0.4661504626274109
test loss item: 0.37874844670295715
test loss item: 0.9124294519424438
test loss item: 0.6942453384399414
test loss item: 0.2641560733318329
test loss item: 1.2411518096923828
test loss item: 0.5349103808403015
test loss item: 0.4904263913631439
test loss item: 0.2694527208805084
test loss item: 0.3162161409854889
test loss item: 0.2906290590763092
test loss item: 2.945387363433838
test loss item: 0.7804785370826721
test loss item: 0.31965142488479614
test loss item: 0.21171297132968903
test loss item: 1.6681251525878906
test loss item: 1.2281696796417236
test loss item: 2.0102736949920654
test loss item: 0.41459453105926514
test loss item: 0.38791966438293457
test loss item: 0.24808616936206818
test loss item: 0.2868981659412384
test loss item: 0.32191887497901917
Epoch [6/10], Training Loss: 0.7739, Testing Loss: 0.6740
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7250450253486633
1
train loss item: 1.8963671922683716
2
train loss item: 0.40832939743995667
3
train loss item: 0.9848305583000183
4
train loss item: 0.9500287771224976
5
train loss item: 0.5386240482330322
6
train loss item: 0.44654932618141174
7
train loss item: 1.2223066091537476
8
train loss item: 0.3730277717113495
9
train loss item: 0.4458974301815033
10
train loss item: 0.6054260730743408
11
train loss item: 0.3943251967430115
12
train loss item: 0.2974990904331207
13
train loss item: 0.8258436322212219
14
train loss item: 0.4897993803024292
15
train loss item: 0.9829004406929016
16
train loss item: 0.29593533277511597
17
train loss item: 0.45851245522499084
18
train loss item: 0.5749285817146301
19
train loss item: 0.3978850245475769
20
train loss item: 0.3758917450904846
21
train loss item: 0.3357202708721161
22
train loss item: 1.4587929248809814
23
train loss item: 1.33553946018219
24
train loss item: 0.7916880249977112
25
train loss item: 0.4317263066768646
26
train loss item: 0.3518047630786896
27
train loss item: 0.5253665447235107
28
train loss item: 0.29419541358947754
29
train loss item: 1.1824442148208618
30
train loss item: 2.967198371887207
31
train loss item: 0.8705212473869324
32
train loss item: 0.3520706593990326
33
train loss item: 0.6986963748931885
34
train loss item: 0.40041860938072205
35
train loss item: 2.941817283630371
36
train loss item: 0.7837926745414734
37
train loss item: 0.3837820291519165
38
train loss item: 0.8099672794342041
39
train loss item: 0.5299599766731262
40
train loss item: 0.3043278455734253
41
train loss item: 0.522918701171875
42
train loss item: 0.37530380487442017
43
train loss item: 0.38143476843833923
44
train loss item: 1.06053626537323
45
train loss item: 0.3509347438812256
46
train loss item: 0.3800371289253235
47
train loss item: 0.5430422425270081
48
train loss item: 0.44694840908050537
49
train loss item: 0.38815465569496155
50
train loss item: 0.41307199001312256
51
train loss item: 1.3472073078155518
52
train loss item: 0.31587648391723633
53
train loss item: 0.3609805703163147
54
train loss item: 2.815133810043335
55
train loss item: 0.386679470539093
56
train loss item: 0.5028964281082153
57
train loss item: 0.41806337237358093
58
train loss item: 0.36060816049575806
59
train loss item: 0.3603958785533905
60
train loss item: 1.4173498153686523
61
train loss item: 2.7756054401397705
62
train loss item: 0.3934878408908844
63
train loss item: 0.5129815936088562
64
train loss item: 0.3745044469833374
65
train loss item: 0.8056831955909729
66
train loss item: 0.6096500754356384
67
train loss item: 0.3977501094341278
68
train loss item: 0.45496949553489685
69
train loss item: 0.5121408104896545
70
train loss item: 0.4238382875919342
71
train loss item: 0.3328893482685089
72
train loss item: 0.4082969129085541
73
train loss item: 0.44634196162223816
74
train loss item: 0.359056681394577
75
train loss item: 0.31827598810195923
76
train loss item: 1.3105741739273071
77
train loss item: 1.6888480186462402
78
train loss item: 0.3181023597717285
79
train loss item: 0.41537314653396606
80
train loss item: 0.33986547589302063
81
train loss item: 0.34434908628463745
82
train loss item: 0.456859290599823
83
train loss item: 1.0112797021865845
84
train loss item: 0.5650999546051025
85
train loss item: 0.9362911581993103
86
train loss item: 5.005677223205566
87
train loss item: 0.40329083800315857
88
train loss item: 0.5032917261123657
epoch train loss: 0.7529408057753959
testing phase
test loss item: 0.27591967582702637
test loss item: 0.2699817419052124
test loss item: 0.9673385620117188
test loss item: 0.37364232540130615
test loss item: 0.4408826231956482
test loss item: 0.24249021708965302
test loss item: 2.181910514831543
test loss item: 0.615429162979126
test loss item: 0.3620438277721405
test loss item: 0.5900995135307312
test loss item: 1.422059178352356
test loss item: 0.327943354845047
test loss item: 0.2930201590061188
test loss item: 0.5406785607337952
test loss item: 0.32162031531333923
test loss item: 0.28976958990097046
test loss item: 0.3760007619857788
test loss item: 0.7462800145149231
test loss item: 0.8178505897521973
test loss item: 0.3771919012069702
test loss item: 1.2107174396514893
test loss item: 0.5212624669075012
test loss item: 0.5123588442802429
test loss item: 0.27851402759552
test loss item: 0.34486109018325806
test loss item: 0.35856831073760986
test loss item: 0.4585106074810028
test loss item: 0.3340260088443756
test loss item: 0.4934632480144501
test loss item: 0.49297136068344116
test loss item: 1.265183687210083
test loss item: 0.26592785120010376
test loss item: 0.2620905339717865
test loss item: 0.8768433928489685
test loss item: 0.7202975153923035
test loss item: 0.7508471608161926
test loss item: 1.0206356048583984
test loss item: 2.4927735328674316
test loss item: 0.7670969367027283
test loss item: 0.382376492023468
test loss item: 0.4210447371006012
test loss item: 0.30924782156944275
test loss item: 0.5415078997612
test loss item: 0.3671250641345978
test loss item: 0.9785248041152954
test loss item: 0.5499695539474487
test loss item: 0.48527756333351135
test loss item: 0.40325385332107544
test loss item: 0.7559338808059692
test loss item: 1.0360257625579834
test loss item: 0.5068701505661011
test loss item: 0.24543559551239014
test loss item: 0.39430177211761475
test loss item: 0.39271509647369385
test loss item: 0.524873673915863
test loss item: 1.3892714977264404
test loss item: 0.834233283996582
test loss item: 0.47245272994041443
test loss item: 0.3630944788455963
test loss item: 0.3568315804004669
test loss item: 0.6458171010017395
test loss item: 0.3173135221004486
test loss item: 0.32644954323768616
test loss item: 0.3411124050617218
test loss item: 1.4270179271697998
test loss item: 0.4998459815979004
test loss item: 0.4420665204524994
test loss item: 0.3661365807056427
test loss item: 0.8644558191299438
test loss item: 0.5945426225662231
test loss item: 0.2467961460351944
test loss item: 1.1691359281539917
test loss item: 0.48685696721076965
test loss item: 0.4751776158809662
test loss item: 0.2613297402858734
test loss item: 0.29828017950057983
test loss item: 0.27761703729629517
test loss item: 2.767854690551758
test loss item: 0.7287942171096802
test loss item: 0.3045288324356079
test loss item: 0.20229391753673553
test loss item: 1.5624992847442627
test loss item: 1.1428425312042236
test loss item: 1.884889006614685
test loss item: 0.38351893424987793
test loss item: 0.37417367100715637
test loss item: 0.2396904081106186
test loss item: 0.2724437117576599
test loss item: 0.3164465129375458
Epoch [7/10], Training Loss: 0.7529, Testing Loss: 0.6313
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.708001971244812
1
train loss item: 1.8426871299743652
2
train loss item: 0.4030629098415375
3
train loss item: 0.943972110748291
4
train loss item: 0.97047358751297
5
train loss item: 0.5277432203292847
6
train loss item: 0.4432361125946045
7
train loss item: 1.1902735233306885
8
train loss item: 0.361517995595932
9
train loss item: 0.4317360818386078
10
train loss item: 0.5786597728729248
11
train loss item: 0.38301411271095276
12
train loss item: 0.2860371470451355
13
train loss item: 0.79881352186203
14
train loss item: 0.47836148738861084
15
train loss item: 0.952923595905304
16
train loss item: 0.2824687957763672
17
train loss item: 0.45605868101119995
18
train loss item: 0.5502573847770691
19
train loss item: 0.38898152112960815
20
train loss item: 0.3806261718273163
21
train loss item: 0.32999297976493835
22
train loss item: 1.4134951829910278
23
train loss item: 1.3060765266418457
24
train loss item: 0.764419674873352
25
train loss item: 0.4134707748889923
26
train loss item: 0.3408883810043335
27
train loss item: 0.5085408091545105
28
train loss item: 0.28098952770233154
29
train loss item: 1.1426749229431152
30
train loss item: 2.9119691848754883
31
train loss item: 0.8374108076095581
32
train loss item: 0.34395259618759155
33
train loss item: 0.6658126711845398
34
train loss item: 0.3932028114795685
35
train loss item: 2.9015913009643555
36
train loss item: 0.748598575592041
37
train loss item: 0.3769359886646271
38
train loss item: 0.7584856152534485
39
train loss item: 0.5126988887786865
40
train loss item: 0.2944338023662567
41
train loss item: 0.5033056139945984
42
train loss item: 0.36442068219184875
43
train loss item: 0.3730334937572479
44
train loss item: 1.0328166484832764
45
train loss item: 0.3327730596065521
46
train loss item: 0.3618725538253784
47
train loss item: 0.5196734666824341
48
train loss item: 0.4271495044231415
49
train loss item: 0.36904993653297424
50
train loss item: 0.4042545258998871
51
train loss item: 1.309361219406128
52
train loss item: 0.2999815344810486
53
train loss item: 0.3441600799560547
54
train loss item: 2.7744359970092773
55
train loss item: 0.36826080083847046
56
train loss item: 0.489799827337265
57
train loss item: 0.4096318483352661
58
train loss item: 0.3576665222644806
59
train loss item: 0.34152311086654663
60
train loss item: 1.37274968624115
61
train loss item: 2.7326507568359375
62
train loss item: 0.3791086971759796
63
train loss item: 0.4950968325138092
64
train loss item: 0.3623572885990143
65
train loss item: 0.7870754599571228
66
train loss item: 0.5835492610931396
67
train loss item: 0.3836955428123474
68
train loss item: 0.4392319917678833
69
train loss item: 0.4907279908657074
70
train loss item: 0.40771377086639404
71
train loss item: 0.32656651735305786
72
train loss item: 0.39551594853401184
73
train loss item: 0.4330173432826996
74
train loss item: 0.341660737991333
75
train loss item: 0.3042452335357666
76
train loss item: 1.2787985801696777
77
train loss item: 1.6569417715072632
78
train loss item: 0.30156639218330383
79
train loss item: 0.40153080224990845
80
train loss item: 0.34104812145233154
81
train loss item: 0.33177152276039124
82
train loss item: 0.4345642924308777
83
train loss item: 0.9748205542564392
84
train loss item: 0.5324474573135376
85
train loss item: 0.8983108401298523
86
train loss item: 4.949611663818359
87
train loss item: 0.3841167092323303
88
train loss item: 0.48248252272605896
epoch train loss: 0.7324796918402897
testing phase
test loss item: 0.2723909914493561
test loss item: 0.25660935044288635
test loss item: 0.9180955290794373
test loss item: 0.35533270239830017
test loss item: 0.42316484451293945
test loss item: 0.23502807319164276
test loss item: 2.0866940021514893
test loss item: 0.5711057782173157
test loss item: 0.3477770686149597
test loss item: 0.5676054954528809
test loss item: 1.3509900569915771
test loss item: 0.3037613332271576
test loss item: 0.27963685989379883
test loss item: 0.5153923630714417
test loss item: 0.3091460168361664
test loss item: 0.27328523993492126
test loss item: 0.3653457760810852
test loss item: 0.7122204899787903
test loss item: 0.7782200574874878
test loss item: 0.35944491624832153
test loss item: 1.147992730140686
test loss item: 0.4952872693538666
test loss item: 0.4822838604450226
test loss item: 0.2707168459892273
test loss item: 0.33476078510284424
test loss item: 0.34322625398635864
test loss item: 0.4443514347076416
test loss item: 0.3199896812438965
test loss item: 0.47619935870170593
test loss item: 0.47766348719596863
test loss item: 1.1995846033096313
test loss item: 0.24012412130832672
test loss item: 0.25684934854507446
test loss item: 0.8350242376327515
test loss item: 0.6874162554740906
test loss item: 0.7145456671714783
test loss item: 0.9789660573005676
test loss item: 2.3581531047821045
test loss item: 0.7347946166992188
test loss item: 0.3713703155517578
test loss item: 0.40822702646255493
test loss item: 0.29893338680267334
test loss item: 0.5201877951622009
test loss item: 0.34269726276397705
test loss item: 0.9349420666694641
test loss item: 0.5286407470703125
test loss item: 0.45906051993370056
test loss item: 0.3735026717185974
test loss item: 0.7238771915435791
test loss item: 0.9892112612724304
test loss item: 0.4845767915248871
test loss item: 0.23543469607830048
test loss item: 0.3760939836502075
test loss item: 0.35554027557373047
test loss item: 0.49641966819763184
test loss item: 1.3233647346496582
test loss item: 0.7949119210243225
test loss item: 0.4516650438308716
test loss item: 0.3514101505279541
test loss item: 0.33864960074424744
test loss item: 0.6231448650360107
test loss item: 0.303519606590271
test loss item: 0.31428277492523193
test loss item: 0.3323974013328552
test loss item: 1.3530453443527222
test loss item: 0.4677087962627411
test loss item: 0.4247874617576599
test loss item: 0.35687094926834106
test loss item: 0.8293607831001282
test loss item: 0.5396868586540222
test loss item: 0.23341913521289825
test loss item: 1.1175638437271118
test loss item: 0.46755656599998474
test loss item: 0.46265333890914917
test loss item: 0.25186583399772644
test loss item: 0.2838640511035919
test loss item: 0.2694014310836792
test loss item: 2.615596294403076
test loss item: 0.7022935748100281
test loss item: 0.2956833243370056
test loss item: 0.19649259746074677
test loss item: 1.481480360031128
test loss item: 1.0860892534255981
test loss item: 1.7830463647842407
test loss item: 0.3639174699783325
test loss item: 0.36016497015953064
test loss item: 0.23603922128677368
test loss item: 0.26301097869873047
test loss item: 0.3172333240509033
Epoch [8/10], Training Loss: 0.7325, Testing Loss: 0.6019
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.693805456161499
1
train loss item: 1.7919248342514038
2
train loss item: 0.38955801725387573
3
train loss item: 0.9006991386413574
4
train loss item: 0.9439113140106201
5
train loss item: 0.5187687873840332
6
train loss item: 0.43574073910713196
7
train loss item: 1.156151533126831
8
train loss item: 0.3385792076587677
9
train loss item: 0.41702690720558167
10
train loss item: 0.5524259805679321
11
train loss item: 0.371816486120224
12
train loss item: 0.27234598994255066
13
train loss item: 0.7755131125450134
14
train loss item: 0.46885162591934204
15
train loss item: 0.9324030876159668
16
train loss item: 0.26689836382865906
17
train loss item: 0.4525136351585388
18
train loss item: 0.5284718871116638
19
train loss item: 0.37900298833847046
20
train loss item: 0.3748348355293274
21
train loss item: 0.3213857114315033
22
train loss item: 1.3825101852416992
23
train loss item: 1.274193286895752
24
train loss item: 0.7426904439926147
25
train loss item: 0.39694899320602417
26
train loss item: 0.33392104506492615
27
train loss item: 0.4924877882003784
28
train loss item: 0.26545992493629456
29
train loss item: 1.1143289804458618
30
train loss item: 2.8506901264190674
31
train loss item: 0.8055713772773743
32
train loss item: 0.32287776470184326
33
train loss item: 0.631591796875
34
train loss item: 0.383571594953537
35
train loss item: 2.8582541942596436
36
train loss item: 0.7211114168167114
37
train loss item: 0.37341177463531494
38
train loss item: 0.7166354060173035
39
train loss item: 0.49839070439338684
40
train loss item: 0.28340238332748413
41
train loss item: 0.48323291540145874
42
train loss item: 0.35290223360061646
43
train loss item: 0.35629481077194214
44
train loss item: 1.0055241584777832
45
train loss item: 0.31311145424842834
46
train loss item: 0.34218260645866394
47
train loss item: 0.5001187920570374
48
train loss item: 0.4076392650604248
49
train loss item: 0.3478739857673645
50
train loss item: 0.39379534125328064
51
train loss item: 1.277970552444458
52
train loss item: 0.2821103036403656
53
train loss item: 0.33289194107055664
54
train loss item: 2.729457139968872
55
train loss item: 0.3535982072353363
56
train loss item: 0.47511932253837585
57
train loss item: 0.4011613428592682
58
train loss item: 0.3452981114387512
59
train loss item: 0.3189842700958252
60
train loss item: 1.338139295578003
61
train loss item: 2.6850998401641846
62
train loss item: 0.36489546298980713
63
train loss item: 0.47950485348701477
64
train loss item: 0.3397953510284424
65
train loss item: 0.7761136889457703
66
train loss item: 0.5619968175888062
67
train loss item: 0.37151527404785156
68
train loss item: 0.4310392141342163
69
train loss item: 0.4741172790527344
70
train loss item: 0.39502644538879395
71
train loss item: 0.3202055096626282
72
train loss item: 0.37512660026550293
73
train loss item: 0.4237194061279297
74
train loss item: 0.31980329751968384
75
train loss item: 0.28525879979133606
76
train loss item: 1.2454768419265747
77
train loss item: 1.6329997777938843
78
train loss item: 0.27893492579460144
79
train loss item: 0.3873636722564697
80
train loss item: 0.3354424834251404
81
train loss item: 0.317414790391922
82
train loss item: 0.41368788480758667
83
train loss item: 0.9464116096496582
84
train loss item: 0.5080931186676025
85
train loss item: 0.864730715751648
86
train loss item: 4.88687801361084
87
train loss item: 0.3695136308670044
88
train loss item: 0.467318058013916
epoch train loss: 0.7117479577493132
testing phase
test loss item: 0.2709518074989319
test loss item: 0.2509154677391052
test loss item: 0.8919737935066223
test loss item: 0.3418078124523163
test loss item: 0.414585143327713
test loss item: 0.2306593358516693
test loss item: 2.0117831230163574
test loss item: 0.5442878603935242
test loss item: 0.34167271852493286
test loss item: 0.5570569038391113
test loss item: 1.314209222793579
test loss item: 0.2877947986125946
test loss item: 0.26816526055336
test loss item: 0.5036725401878357
test loss item: 0.30185794830322266
test loss item: 0.2638368606567383
test loss item: 0.3557228446006775
test loss item: 0.7017176747322083
test loss item: 0.7569265961647034
test loss item: 0.34550395607948303
test loss item: 1.1208957433700562
test loss item: 0.4767214059829712
test loss item: 0.47462406754493713
test loss item: 0.2636125683784485
test loss item: 0.3294946849346161
test loss item: 0.33806198835372925
test loss item: 0.43424615263938904
test loss item: 0.31355586647987366
test loss item: 0.46749499440193176
test loss item: 0.4661933183670044
test loss item: 1.1571115255355835
test loss item: 0.22426913678646088
test loss item: 0.2510755956172943
test loss item: 0.8178174495697021
test loss item: 0.6750607490539551
test loss item: 0.6885277628898621
test loss item: 0.9523870944976807
test loss item: 2.290499448776245
test loss item: 0.7208658456802368
test loss item: 0.361428827047348
test loss item: 0.39690661430358887
test loss item: 0.29840710759162903
test loss item: 0.5136575102806091
test loss item: 0.3265214264392853
test loss item: 0.9191911816596985
test loss item: 0.5130592584609985
test loss item: 0.4546346068382263
test loss item: 0.3430168330669403
test loss item: 0.7053095102310181
test loss item: 0.9624054431915283
test loss item: 0.476274311542511
test loss item: 0.22355860471725464
test loss item: 0.3672478497028351
test loss item: 0.3333469331264496
test loss item: 0.4859203100204468
test loss item: 1.2921535968780518
test loss item: 0.7690595984458923
test loss item: 0.44757431745529175
test loss item: 0.3443804979324341
test loss item: 0.3319287598133087
test loss item: 0.6176828145980835
test loss item: 0.293352335691452
test loss item: 0.30778956413269043
test loss item: 0.32573428750038147
test loss item: 1.312369704246521
test loss item: 0.4462863504886627
test loss item: 0.4129365086555481
test loss item: 0.3504297137260437
test loss item: 0.8126692771911621
test loss item: 0.5168716311454773
test loss item: 0.22659680247306824
test loss item: 1.0763988494873047
test loss item: 0.46167945861816406
test loss item: 0.4516289532184601
test loss item: 0.24590690433979034
test loss item: 0.29011139273643494
test loss item: 0.26301413774490356
test loss item: 2.5333962440490723
test loss item: 0.6866548657417297
test loss item: 0.2913467288017273
test loss item: 0.19470101594924927
test loss item: 1.432831048965454
test loss item: 1.054911732673645
test loss item: 1.731927752494812
test loss item: 0.35571733117103577
test loss item: 0.35594442486763
test loss item: 0.23550190031528473
test loss item: 0.2568439245223999
test loss item: 0.3223680555820465
Epoch [9/10], Training Loss: 0.7117, Testing Loss: 0.5859
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6795389652252197
1
train loss item: 1.744483470916748
2
train loss item: 0.37328165769577026
3
train loss item: 0.8602427244186401
4
train loss item: 0.8871167898178101
5
train loss item: 0.5109033584594727
6
train loss item: 0.4243994951248169
7
train loss item: 1.1241470575332642
8
train loss item: 0.3196456730365753
9
train loss item: 0.4044058918952942
10
train loss item: 0.5318286418914795
11
train loss item: 0.3635312616825104
12
train loss item: 0.26346930861473083
13
train loss item: 0.7537569999694824
14
train loss item: 0.4616577923297882
15
train loss item: 0.9145956039428711
16
train loss item: 0.2542535662651062
17
train loss item: 0.4480488896369934
18
train loss item: 0.5093443989753723
19
train loss item: 0.3699185848236084
20
train loss item: 0.3669266700744629
21
train loss item: 0.3153225779533386
22
train loss item: 1.3574793338775635
23
train loss item: 1.2450597286224365
24
train loss item: 0.7236095666885376
25
train loss item: 0.3813157379627228
26
train loss item: 0.3321364223957062
27
train loss item: 0.479158878326416
28
train loss item: 0.2528093755245209
29
train loss item: 1.0912914276123047
30
train loss item: 2.7921836376190186
31
train loss item: 0.7782497406005859
32
train loss item: 0.3024356961250305
33
train loss item: 0.6017465591430664
34
train loss item: 0.3748728930950165
35
train loss item: 2.8163812160491943
36
train loss item: 0.6974773406982422
37
train loss item: 0.37137776613235474
38
train loss item: 0.6805316209793091
39
train loss item: 0.48706570267677307
40
train loss item: 0.27569058537483215
41
train loss item: 0.466972678899765
42
train loss item: 0.3421710133552551
43
train loss item: 0.339211106300354
44
train loss item: 0.9804760217666626
45
train loss item: 0.2962047755718231
46
train loss item: 0.3247894048690796
47
train loss item: 0.48477211594581604
48
train loss item: 0.3913288116455078
49
train loss item: 0.33254969120025635
50
train loss item: 0.3848918378353119
51
train loss item: 1.2495883703231812
52
train loss item: 0.27218902111053467
53
train loss item: 0.32744714617729187
54
train loss item: 2.686124086380005
55
train loss item: 0.3425471782684326
56
train loss item: 0.46200260519981384
57
train loss item: 0.394513875246048
58
train loss item: 0.33213692903518677
59
train loss item: 0.30127131938934326
60
train loss item: 1.306086540222168
61
train loss item: 2.639293909072876
62
train loss item: 0.35486677289009094
63
train loss item: 0.4652610719203949
64
train loss item: 0.3177613914012909
65
train loss item: 0.7644497752189636
66
train loss item: 0.545534610748291
67
train loss item: 0.36282768845558167
68
train loss item: 0.42713284492492676
69
train loss item: 0.4614326059818268
70
train loss item: 0.3852913975715637
71
train loss item: 0.3116934597492218
72
train loss item: 0.35746365785598755
73
train loss item: 0.4173537492752075
74
train loss item: 0.3020104467868805
75
train loss item: 0.2709280252456665
76
train loss item: 1.214234471321106
77
train loss item: 1.6116671562194824
78
train loss item: 0.2605406939983368
79
train loss item: 0.37417519092559814
80
train loss item: 0.3236880302429199
81
train loss item: 0.3057347536087036
82
train loss item: 0.396272748708725
83
train loss item: 0.9209794402122498
84
train loss item: 0.4894252419471741
85
train loss item: 0.836685061454773
86
train loss item: 4.825387954711914
87
train loss item: 0.36094486713409424
88
train loss item: 0.4545552730560303
epoch train loss: 0.693219768867064
testing phase
test loss item: 0.2700878381729126
test loss item: 0.24748189747333527
test loss item: 0.8698344826698303
test loss item: 0.3328716456890106
test loss item: 0.4054175913333893
test loss item: 0.22875432670116425
test loss item: 1.9498214721679688
test loss item: 0.5270669460296631
test loss item: 0.33831435441970825
test loss item: 0.5488223433494568
test loss item: 1.2902957201004028
test loss item: 0.2783602774143219
test loss item: 0.26179298758506775
test loss item: 0.48779433965682983
test loss item: 0.293735533952713
test loss item: 0.2580869495868683
test loss item: 0.3486160933971405
test loss item: 0.6875835061073303
test loss item: 0.7441719770431519
test loss item: 0.3368152379989624
test loss item: 1.0830485820770264
test loss item: 0.4638543725013733
test loss item: 0.469673216342926
test loss item: 0.25707516074180603
test loss item: 0.32524147629737854
test loss item: 0.3357155919075012
test loss item: 0.42886725068092346
test loss item: 0.3080400228500366
test loss item: 0.4595695436000824
test loss item: 0.46052253246307373
test loss item: 1.1273330450057983
test loss item: 0.21465589106082916
test loss item: 0.24534954130649567
test loss item: 0.8016854524612427
test loss item: 0.6615177989006042
test loss item: 0.6734914183616638
test loss item: 0.932336688041687
test loss item: 2.2417776584625244
test loss item: 0.7097806930541992
test loss item: 0.3530913293361664
test loss item: 0.3871902823448181
test loss item: 0.3104519546031952
test loss item: 0.5027528405189514
test loss item: 0.31738901138305664
test loss item: 0.8954736590385437
test loss item: 0.5015590190887451
test loss item: 0.4563463032245636
test loss item: 0.3241675794124603
test loss item: 0.6880926489830017
test loss item: 0.9450587630271912
test loss item: 0.46741342544555664
test loss item: 0.21919848024845123
test loss item: 0.359037309885025
test loss item: 0.32251688838005066
test loss item: 0.4723019599914551
test loss item: 1.2716313600540161
test loss item: 0.7497606873512268
test loss item: 0.42401251196861267
test loss item: 0.3379916250705719
test loss item: 0.32571926712989807
test loss item: 0.6129797101020813
test loss item: 0.28669437766075134
test loss item: 0.3020962178707123
test loss item: 0.3201848566532135
test loss item: 1.2794767618179321
test loss item: 0.4332980513572693
test loss item: 0.4036414921283722
test loss item: 0.3454158306121826
test loss item: 0.7989817261695862
test loss item: 0.5090255737304688
test loss item: 0.2233329713344574
test loss item: 1.0426756143569946
test loss item: 0.4461960196495056
test loss item: 0.4424971342086792
test loss item: 0.24369850754737854
test loss item: 0.3095482885837555
test loss item: 0.25741270184516907
test loss item: 2.4705491065979004
test loss item: 0.6673722267150879
test loss item: 0.28961247205734253
test loss item: 0.1948513686656952
test loss item: 1.396102786064148
test loss item: 1.0345771312713623
test loss item: 1.6953939199447632
test loss item: 0.34728777408599854
test loss item: 0.3566955626010895
test loss item: 0.23659154772758484
test loss item: 0.2527189552783966
test loss item: 0.33220693469047546
Epoch [10/10], Training Loss: 0.6932, Testing Loss: 0.5738
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
loss item: 0.520654559135437
loss item: 0.2836773991584778
loss item: 2.5832316875457764
loss item: 1.4078022241592407
loss item: 0.6993505358695984
loss item: 0.47446608543395996
loss item: 0.3572421669960022
loss item: 0.8891713619232178
loss item: 0.26289260387420654
loss item: 0.2811332046985626
loss item: 0.984836220741272
loss item: 0.18921338021755219
loss item: 0.9094855785369873
loss item: 0.32233020663261414
loss item: 0.6422315835952759
loss item: 0.5202890634536743
loss item: 0.3654662072658539
loss item: 1.006027340888977
loss item: 1.2887611389160156
loss item: 0.6206221580505371
loss item: 0.5548881888389587
loss item: 0.31999292969703674
loss item: 0.3387271463871002
loss item: 0.2940678596496582
loss item: 0.46922481060028076
loss item: 0.82526034116745
loss item: 1.6360493898391724
loss item: 0.27586835622787476
loss item: 0.267056405544281
loss item: 0.48996981978416443
loss item: 1.1014221906661987
loss item: 2.3823463916778564
loss item: 0.3026692867279053
loss item: 0.6254226565361023
loss item: 0.3022918105125427
loss item: 0.30257293581962585
loss item: 0.6019411683082581
loss item: 0.29827234148979187
loss item: 0.4913068115711212
loss item: 0.8247531652450562
loss item: 1.3902240991592407
loss item: 0.4019211232662201
loss item: 0.28355053067207336
loss item: 0.26425430178642273
Val Loss: 0.6739
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 10 0.0001 2 360 done at Wed Nov 13 16:05:28 CET 2024
UNet6 with 1 10 0.0005 2 360 start at Wed Nov 13 16:05:28 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 1073.396240234375
test loss item: 1825.4366455078125
test loss item: 593.513916015625
test loss item: 3402.35400390625
test loss item: 1432.8350830078125
test loss item: 1101.7930908203125
test loss item: 4293.38525390625
test loss item: 2056.052001953125
test loss item: 983.393798828125
test loss item: 1080.54150390625
test loss item: 3268.616455078125
test loss item: 3387.968505859375
test loss item: 1415.2587890625
test loss item: 155.1746826171875
test loss item: 1560.358642578125
test loss item: 2054.7509765625
test loss item: 586.7355346679688
test loss item: 1424.037841796875
test loss item: 2285.005615234375
test loss item: 477.49407958984375
test loss item: 490.1462707519531
test loss item: 3241.994384765625
test loss item: 1987.736083984375
test loss item: 1667.1552734375
test loss item: 1189.39404296875
test loss item: 1011.9746704101562
test loss item: 1110.9444580078125
test loss item: 1439.2664794921875
test loss item: 1637.3873291015625
test loss item: 1456.5567626953125
test loss item: 2567.75830078125
test loss item: 2156.354248046875
test loss item: 1647.2252197265625
test loss item: 3415.092041015625
test loss item: 1677.3106689453125
test loss item: 10306.333984375
test loss item: 2520.37939453125
test loss item: 4596.36572265625
test loss item: 2994.80419921875
test loss item: 1459.9661865234375
test loss item: 1574.25341796875
test loss item: 2169.212646484375
test loss item: 314.3674011230469
test loss item: 3197.302978515625
test loss item: 481.6025695800781
test loss item: 1431.2628173828125
test loss item: 1962.573486328125
test loss item: 636.291015625
test loss item: 638.4937133789062
test loss item: 2052.255615234375
test loss item: 1341.2618408203125
test loss item: 1359.8218994140625
test loss item: 943.6686401367188
test loss item: 4905.68896484375
test loss item: 779.1927490234375
test loss item: 1749.71044921875
test loss item: 6549.90380859375
test loss item: 61.08621597290039
test loss item: 1279.8924560546875
test loss item: 1106.2103271484375
test loss item: 1298.221435546875
test loss item: 1257.730712890625
test loss item: 686.1917724609375
test loss item: 1438.11474609375
test loss item: 2255.193603515625
test loss item: 5237.1640625
test loss item: 1227.04248046875
test loss item: 1095.8515625
test loss item: 1473.5120849609375
test loss item: 2248.47998046875
test loss item: 1458.933349609375
test loss item: 2143.240234375
test loss item: 323.953369140625
test loss item: 1194.3221435546875
test loss item: 400.1552734375
test loss item: 1925.527099609375
test loss item: 1530.5855712890625
test loss item: 5113.45458984375
test loss item: 113.53984832763672
test loss item: 994.1921997070312
test loss item: 553.6729125976562
test loss item: 4730.39404296875
test loss item: 2573.75146484375
test loss item: 4917.96240234375
test loss item: 793.8377075195312
test loss item: 783.5877685546875
test loss item: 1389.701171875
test loss item: 1987.3375244140625
test loss item: 1082.837646484375
Epoch [1/10], Training Loss: 1.0161, Testing Loss: 1907.8066
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.9610803723335266
1
train loss item: 2.0869719982147217
2
train loss item: 0.8648231029510498
3
train loss item: 1.1216984987258911
4
train loss item: 1.9628078937530518
5
train loss item: 0.7860296368598938
6
train loss item: 0.9755358695983887
7
train loss item: 1.276835560798645
8
train loss item: 0.9419233202934265
9
train loss item: 0.636870801448822
10
train loss item: 0.7311280369758606
11
train loss item: 0.5714137554168701
12
train loss item: 0.6297969818115234
13
train loss item: 1.0564218759536743
14
train loss item: 0.7491157650947571
15
train loss item: 1.3152027130126953
16
train loss item: 0.7876008749008179
17
train loss item: 0.9731787443161011
18
train loss item: 0.8148528933525085
19
train loss item: 0.6499318480491638
20
train loss item: 0.7342736124992371
21
train loss item: 0.6737383008003235
22
train loss item: 1.9226921796798706
23
train loss item: 1.3755406141281128
24
train loss item: 1.0840805768966675
25
train loss item: 0.7472132444381714
26
train loss item: 0.7659173011779785
27
train loss item: 0.6883385181427002
28
train loss item: 0.7842848896980286
29
train loss item: 1.564386010169983
30
train loss item: 2.917602777481079
31
train loss item: 1.0476430654525757
32
train loss item: 0.5979970693588257
33
train loss item: 0.9200557470321655
34
train loss item: 1.2829920053482056
35
train loss item: 2.950822591781616
36
train loss item: 1.0549070835113525
37
train loss item: 0.6426941156387329
38
train loss item: 1.1503973007202148
39
train loss item: 0.7319750189781189
40
train loss item: 0.7444394826889038
41
train loss item: 0.6483772397041321
42
train loss item: 0.6060624122619629
43
train loss item: 0.6421911716461182
44
train loss item: 1.1402636766433716
45
train loss item: 0.7553742527961731
46
train loss item: 0.681804358959198
47
train loss item: 0.8301006555557251
48
train loss item: 0.6657137274742126
49
train loss item: 0.6807478070259094
50
train loss item: 0.6668230295181274
51
train loss item: 1.6286009550094604
52
train loss item: 0.7506836652755737
53
train loss item: 0.8124781847000122
54
train loss item: 2.7997705936431885
55
train loss item: 0.8023961782455444
56
train loss item: 0.6549271941184998
57
train loss item: 0.679426372051239
58
train loss item: 0.6117108464241028
59
train loss item: 0.6076603531837463
60
train loss item: 1.7864497900009155
61
train loss item: 2.7589123249053955
62
train loss item: 0.667665421962738
63
train loss item: 0.7758030891418457
64
train loss item: 0.612826406955719
65
train loss item: 1.279589056968689
66
train loss item: 0.7979201674461365
67
train loss item: 0.6886866688728333
68
train loss item: 0.8516250848770142
69
train loss item: 0.7631414532661438
70
train loss item: 0.7257243990898132
71
train loss item: 1.0015699863433838
72
train loss item: 0.9294403195381165
73
train loss item: 0.7485255002975464
74
train loss item: 1.0114132165908813
75
train loss item: 0.625966489315033
76
train loss item: 1.3848271369934082
77
train loss item: 2.0647308826446533
78
train loss item: 0.7570294141769409
79
train loss item: 0.6416780352592468
80
train loss item: 0.9463794827461243
81
train loss item: 0.6630517244338989
82
train loss item: 0.7165557146072388
83
train loss item: 1.3105486631393433
84
train loss item: 0.8187755346298218
85
train loss item: 1.1267739534378052
86
train loss item: 4.951118469238281
87
train loss item: 0.9303812384605408
88
train loss item: 0.774116575717926
epoch train loss: 1.0567589991548088
testing phase
test loss item: 1.6952979564666748
test loss item: 9.625849723815918
test loss item: 2.691225051879883
test loss item: 38.27228546142578
test loss item: 7.350315093994141
test loss item: 5.846074104309082
test loss item: 20.474124908447266
test loss item: 6.659194469451904
test loss item: 1.1748534440994263
test loss item: 4.6506266593933105
test loss item: 24.397600173950195
test loss item: 36.54059600830078
test loss item: 5.641790390014648
test loss item: 0.7489233613014221
test loss item: 7.349485397338867
test loss item: 12.024171829223633
test loss item: 1.9126787185668945
test loss item: 6.343292236328125
test loss item: 8.421590805053711
test loss item: 0.6090383529663086
test loss item: 2.897944688796997
test loss item: 37.776153564453125
test loss item: 18.683368682861328
test loss item: 7.812326431274414
test loss item: 5.44108772277832
test loss item: 5.987850189208984
test loss item: 1.3666883707046509
test loss item: 7.144177436828613
test loss item: 7.813586711883545
test loss item: 6.361095905303955
test loss item: 25.833454132080078
test loss item: 11.886795043945312
test loss item: 7.941087245941162
test loss item: 41.5970458984375
test loss item: 8.978658676147461
test loss item: 152.70481872558594
test loss item: 8.280072212219238
test loss item: 40.83656311035156
test loss item: 31.929595947265625
test loss item: 7.145925998687744
test loss item: 7.720831394195557
test loss item: 20.765243530273438
test loss item: 0.8431825041770935
test loss item: 36.8121223449707
test loss item: 2.0887584686279297
test loss item: 7.666717529296875
test loss item: 18.209367752075195
test loss item: 0.7529315948486328
test loss item: 1.4781244993209839
test loss item: 10.07898235321045
test loss item: 5.243545055389404
test loss item: 5.531370162963867
test loss item: 4.027170658111572
test loss item: 60.67716979980469
test loss item: 2.955077886581421
test loss item: 8.937223434448242
test loss item: 83.23029327392578
test loss item: 0.8209882378578186
test loss item: 5.119174003601074
test loss item: 4.177523136138916
test loss item: 6.436301231384277
test loss item: 6.872252464294434
test loss item: 2.8275954723358154
test loss item: 5.022403717041016
test loss item: 11.198412895202637
test loss item: 64.35678100585938
test loss item: 4.291144847869873
test loss item: 4.325949668884277
test loss item: 7.919835567474365
test loss item: 8.365128517150879
test loss item: 8.267951965332031
test loss item: 4.000560283660889
test loss item: 1.0867365598678589
test loss item: 3.7332310676574707
test loss item: 1.4995241165161133
test loss item: 17.838932037353516
test loss item: 7.238837718963623
test loss item: 57.285072326660156
test loss item: 0.9476891160011292
test loss item: 5.287164211273193
test loss item: 2.0927717685699463
test loss item: 34.28313446044922
test loss item: 10.352858543395996
test loss item: 49.220340728759766
test loss item: 3.2549819946289062
test loss item: 6.598217487335205
test loss item: 7.951676368713379
test loss item: 11.18775749206543
test loss item: 9.065872192382812
Epoch [2/10], Training Loss: 1.0568, Testing Loss: 14.5033
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7753306031227112
1
train loss item: 1.9373955726623535
2
train loss item: 0.48450934886932373
3
train loss item: 1.0331743955612183
4
train loss item: 0.9824836850166321
5
train loss item: 0.5950410962104797
6
train loss item: 0.5091562271118164
7
train loss item: 1.2250372171401978
8
train loss item: 0.4754185676574707
9
train loss item: 0.4638817310333252
10
train loss item: 0.6290343999862671
11
train loss item: 0.40699079632759094
12
train loss item: 0.35201478004455566
13
train loss item: 0.8948885798454285
14
train loss item: 0.551002025604248
15
train loss item: 1.0726706981658936
16
train loss item: 0.3707497715950012
17
train loss item: 0.5284109115600586
18
train loss item: 0.6259781718254089
19
train loss item: 0.4379565119743347
20
train loss item: 0.39260342717170715
21
train loss item: 0.44246700406074524
22
train loss item: 1.5754714012145996
23
train loss item: 1.3360466957092285
24
train loss item: 0.8429235816001892
25
train loss item: 0.5052021741867065
26
train loss item: 0.4471554458141327
27
train loss item: 0.5551421046257019
28
train loss item: 0.37232908606529236
29
train loss item: 1.3058303594589233
30
train loss item: 2.943434238433838
31
train loss item: 0.9255861043930054
32
train loss item: 0.366534948348999
33
train loss item: 0.7713114023208618
34
train loss item: 0.6291664838790894
35
train loss item: 2.941950559616089
36
train loss item: 0.8456735014915466
37
train loss item: 0.4106711149215698
38
train loss item: 0.9005528688430786
39
train loss item: 0.5786586999893188
40
train loss item: 0.419023334980011
41
train loss item: 0.532141387462616
42
train loss item: 0.4084606468677521
43
train loss item: 0.43716010451316833
44
train loss item: 1.0760644674301147
45
train loss item: 0.4653486907482147
46
train loss item: 0.47002318501472473
47
train loss item: 0.6124353408813477
48
train loss item: 0.5024266242980957
49
train loss item: 0.4876966178417206
50
train loss item: 0.42818504571914673
51
train loss item: 1.415174961090088
52
train loss item: 0.36160144209861755
53
train loss item: 0.4910452663898468
54
train loss item: 2.8157169818878174
55
train loss item: 0.49821850657463074
56
train loss item: 0.5213576555252075
57
train loss item: 0.4669608771800995
58
train loss item: 0.40954363346099854
59
train loss item: 0.374469131231308
60
train loss item: 1.521458625793457
61
train loss item: 2.801856756210327
62
train loss item: 0.4282427728176117
63
train loss item: 0.5508915781974792
64
train loss item: 0.4252351224422455
65
train loss item: 0.9064849615097046
66
train loss item: 0.6466435790061951
67
train loss item: 0.4837954044342041
68
train loss item: 0.5308824181556702
69
train loss item: 0.568732500076294
70
train loss item: 0.49967238306999207
71
train loss item: 0.48316025733947754
72
train loss item: 0.4887859523296356
73
train loss item: 0.5104274153709412
74
train loss item: 0.49377527832984924
75
train loss item: 0.36806562542915344
76
train loss item: 1.330392599105835
77
train loss item: 1.7725940942764282
78
train loss item: 0.3619401156902313
79
train loss item: 0.4328960180282593
80
train loss item: 0.46722978353500366
81
train loss item: 0.4052654504776001
82
train loss item: 0.5447877645492554
83
train loss item: 1.0891740322113037
84
train loss item: 0.6080710887908936
85
train loss item: 0.9767184853553772
86
train loss item: 4.9969964027404785
87
train loss item: 0.5371173024177551
88
train loss item: 0.5534860491752625
epoch train loss: 0.8136816855227009
testing phase
test loss item: 1.1898895502090454
test loss item: 3.227278470993042
test loss item: 1.703351616859436
test loss item: 6.817262649536133
test loss item: 2.866787910461426
test loss item: 2.747218608856201
test loss item: 5.039423942565918
test loss item: 2.2433838844299316
test loss item: 1.010989785194397
test loss item: 1.4505813121795654
test loss item: 6.24137020111084
test loss item: 6.7986884117126465
test loss item: 1.7276753187179565
test loss item: 0.6354014277458191
test loss item: 2.7934041023254395
test loss item: 3.9495513439178467
test loss item: 0.761549711227417
test loss item: 2.0514755249023438
test loss item: 2.8010435104370117
test loss item: 0.4654821455478668
test loss item: 2.1977763175964355
test loss item: 6.5736775398254395
test loss item: 6.604550361633301
test loss item: 2.591827630996704
test loss item: 2.015840768814087
test loss item: 2.14677357673645
test loss item: 1.139235496520996
test loss item: 2.7506701946258545
test loss item: 2.765331745147705
test loss item: 1.8219664096832275
test loss item: 6.111570358276367
test loss item: 3.866427421569824
test loss item: 2.6664106845855713
test loss item: 7.155632495880127
test loss item: 2.893854856491089
test loss item: 22.10896873474121
test loss item: 2.69307279586792
test loss item: 11.15649127960205
test loss item: 5.8358025550842285
test loss item: 2.7186625003814697
test loss item: 2.518120527267456
test loss item: 6.929379940032959
test loss item: 0.7523263692855835
test loss item: 6.4873456954956055
test loss item: 1.73220694065094
test loss item: 2.571293354034424
test loss item: 6.46089506149292
test loss item: 0.5021698474884033
test loss item: 1.1642178297042847
test loss item: 3.6170618534088135
test loss item: 1.5473241806030273
test loss item: 1.8063280582427979
test loss item: 1.7111142873764038
test loss item: 10.242157936096191
test loss item: 1.8909834623336792
test loss item: 3.651387929916382
test loss item: 12.682930946350098
test loss item: 0.6178389191627502
test loss item: 1.6577080488204956
test loss item: 1.847389817237854
test loss item: 2.2478511333465576
test loss item: 2.198476552963257
test loss item: 1.5555464029312134
test loss item: 1.6990206241607666
test loss item: 4.155920028686523
test loss item: 10.821247100830078
test loss item: 1.6911855936050415
test loss item: 1.5414832830429077
test loss item: 2.787243127822876
test loss item: 2.8590431213378906
test loss item: 2.7159781455993652
test loss item: 1.8706729412078857
test loss item: 0.8868982195854187
test loss item: 1.1505937576293945
test loss item: 0.7609840631484985
test loss item: 6.275387287139893
test loss item: 2.607560396194458
test loss item: 13.385534286499023
test loss item: 0.8619686961174011
test loss item: 2.345057249069214
test loss item: 1.5323015451431274
test loss item: 7.98535680770874
test loss item: 3.431525468826294
test loss item: 10.907723426818848
test loss item: 1.8699524402618408
test loss item: 1.7947497367858887
test loss item: 2.6904611587524414
test loss item: 3.8197081089019775
test loss item: 2.529606342315674
Epoch [3/10], Training Loss: 0.8137, Testing Loss: 3.6596
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6983966827392578
1
train loss item: 1.8895678520202637
2
train loss item: 0.4078570008277893
3
train loss item: 1.0575674772262573
4
train loss item: 1.0385847091674805
5
train loss item: 0.52247154712677
6
train loss item: 0.41971778869628906
7
train loss item: 1.2598832845687866
8
train loss item: 0.4240264296531677
9
train loss item: 0.4619661271572113
10
train loss item: 0.6555545926094055
11
train loss item: 0.3903302252292633
12
train loss item: 0.3221556842327118
13
train loss item: 0.8316524028778076
14
train loss item: 0.49575939774513245
15
train loss item: 0.9327904582023621
16
train loss item: 0.34123098850250244
17
train loss item: 0.456911563873291
18
train loss item: 0.5701507925987244
19
train loss item: 0.400150328874588
20
train loss item: 0.35642391443252563
21
train loss item: 0.37708383798599243
22
train loss item: 1.3951287269592285
23
train loss item: 1.353918194770813
24
train loss item: 0.7554471492767334
25
train loss item: 0.4307234287261963
26
train loss item: 0.38092318177223206
27
train loss item: 0.526859700679779
28
train loss item: 0.33884429931640625
29
train loss item: 1.1439898014068604
30
train loss item: 3.0326292514801025
31
train loss item: 0.9294781684875488
32
train loss item: 0.41547268629074097
33
train loss item: 0.787726879119873
34
train loss item: 0.42948347330093384
35
train loss item: 2.976135492324829
36
train loss item: 0.7441644072532654
37
train loss item: 0.3760562539100647
38
train loss item: 0.8047831654548645
39
train loss item: 0.5277100205421448
40
train loss item: 0.31911784410476685
41
train loss item: 0.5406798124313354
42
train loss item: 0.3650849461555481
43
train loss item: 0.4221801161766052
44
train loss item: 1.0753355026245117
45
train loss item: 0.40256625413894653
46
train loss item: 0.41455337405204773
47
train loss item: 0.5339937806129456
48
train loss item: 0.4749167859554291
49
train loss item: 0.42313259840011597
50
train loss item: 0.4188964366912842
51
train loss item: 1.32359778881073
52
train loss item: 0.3932873606681824
53
train loss item: 0.3888820707798004
54
train loss item: 2.866298198699951
55
train loss item: 0.4193289875984192
56
train loss item: 0.5133644342422485
57
train loss item: 0.4223174750804901
58
train loss item: 0.39009371399879456
59
train loss item: 0.41822704672813416
60
train loss item: 1.3682383298873901
61
train loss item: 2.8778650760650635
62
train loss item: 0.43743205070495605
63
train loss item: 0.4907551407814026
64
train loss item: 0.42146041989326477
65
train loss item: 0.7421570420265198
66
train loss item: 0.6023702025413513
67
train loss item: 0.42771679162979126
68
train loss item: 0.4219704866409302
69
train loss item: 0.50228351354599
70
train loss item: 0.43160462379455566
71
train loss item: 0.31944015622138977
72
train loss item: 0.47537699341773987
73
train loss item: 0.43796253204345703
74
train loss item: 0.42013832926750183
75
train loss item: 0.35526344180107117
76
train loss item: 1.3376119136810303
77
train loss item: 1.6430391073226929
78
train loss item: 0.35548120737075806
79
train loss item: 0.40230482816696167
80
train loss item: 0.3651096820831299
81
train loss item: 0.35108229517936707
82
train loss item: 0.4823961555957794
83
train loss item: 0.9637957215309143
84
train loss item: 0.5152562856674194
85
train loss item: 0.9517197608947754
86
train loss item: 5.090278625488281
87
train loss item: 0.4349687993526459
88
train loss item: 0.48934024572372437
epoch train loss: 0.7674155241987678
testing phase
test loss item: 0.28967922925949097
test loss item: 0.4661613702774048
test loss item: 1.0977962017059326
test loss item: 0.8411714434623718
test loss item: 0.6092407703399658
test loss item: 0.47013771533966064
test loss item: 2.278618812561035
test loss item: 0.6200326681137085
test loss item: 0.37713998556137085
test loss item: 0.6189283728599548
test loss item: 1.831299066543579
test loss item: 0.8438577055931091
test loss item: 0.34918975830078125
test loss item: 0.4146531820297241
test loss item: 0.4850887060165405
test loss item: 0.5186068415641785
test loss item: 0.36682209372520447
test loss item: 0.819593071937561
test loss item: 0.8401731848716736
test loss item: 0.3737275004386902
test loss item: 1.3717535734176636
test loss item: 0.8750786185264587
test loss item: 0.9892051219940186
test loss item: 0.41947486996650696
test loss item: 0.41661784052848816
test loss item: 0.44115975499153137
test loss item: 0.4562559425830841
test loss item: 0.5141705274581909
test loss item: 0.6226191520690918
test loss item: 0.5139089226722717
test loss item: 1.5652313232421875
test loss item: 0.5349465608596802
test loss item: 0.4094506502151489
test loss item: 1.2278848886489868
test loss item: 0.8185349106788635
test loss item: 2.2731616497039795
test loss item: 1.0341012477874756
test loss item: 3.327460765838623
test loss item: 1.0333184003829956
test loss item: 0.5245742797851562
test loss item: 0.4867233335971832
test loss item: 0.8754964470863342
test loss item: 0.5635008215904236
test loss item: 0.7994691133499146
test loss item: 1.0707730054855347
test loss item: 0.6088303327560425
test loss item: 0.9605841636657715
test loss item: 0.4078099727630615
test loss item: 0.7924291491508484
test loss item: 1.206511378288269
test loss item: 0.5406088829040527
test loss item: 0.3122153878211975
test loss item: 0.4157840311527252
test loss item: 1.1872050762176514
test loss item: 0.5935589671134949
test loss item: 1.7029435634613037
test loss item: 1.5778933763504028
test loss item: 0.4830836355686188
test loss item: 0.39540863037109375
test loss item: 0.40097305178642273
test loss item: 0.7240050435066223
test loss item: 0.3896774351596832
test loss item: 0.3439917266368866
test loss item: 0.3831360638141632
test loss item: 1.7959402799606323
test loss item: 1.275413155555725
test loss item: 0.4710361063480377
test loss item: 0.39208316802978516
test loss item: 1.0246944427490234
test loss item: 0.6592327952384949
test loss item: 0.39657318592071533
test loss item: 1.0477616786956787
test loss item: 0.5025136470794678
test loss item: 0.4581690728664398
test loss item: 0.2774539291858673
test loss item: 0.8348803520202637
test loss item: 0.4248865842819214
test loss item: 3.6898858547210693
test loss item: 0.700594425201416
test loss item: 0.45810234546661377
test loss item: 0.27888163924217224
test loss item: 2.071094274520874
test loss item: 1.2470712661743164
test loss item: 2.6188879013061523
test loss item: 0.39289888739585876
test loss item: 0.4359573423862457
test loss item: 0.3628467321395874
test loss item: 0.47481682896614075
test loss item: 0.4011151194572449
Epoch [4/10], Training Loss: 0.7674, Testing Loss: 0.8292
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6756762266159058
1
train loss item: 1.8227037191390991
2
train loss item: 0.37234199047088623
3
train loss item: 0.9910301566123962
4
train loss item: 0.918097198009491
5
train loss item: 0.512028694152832
6
train loss item: 0.4177883267402649
7
train loss item: 1.2159864902496338
8
train loss item: 0.3952226936817169
9
train loss item: 0.4213326573371887
10
train loss item: 0.5899624228477478
11
train loss item: 0.3660014867782593
12
train loss item: 0.28829464316368103
13
train loss item: 0.7883545160293579
14
train loss item: 0.4807130694389343
15
train loss item: 0.8995276093482971
16
train loss item: 0.2694915235042572
17
train loss item: 0.4307445287704468
18
train loss item: 0.5323776006698608
19
train loss item: 0.3909452557563782
20
train loss item: 0.3488242030143738
21
train loss item: 0.333306223154068
22
train loss item: 1.3327043056488037
23
train loss item: 1.2924134731292725
24
train loss item: 0.7219944000244141
25
train loss item: 0.3935707211494446
26
train loss item: 0.38187772035598755
27
train loss item: 0.4978334307670593
28
train loss item: 0.2726540267467499
29
train loss item: 1.0741456747055054
30
train loss item: 2.9715728759765625
31
train loss item: 0.8734990358352661
32
train loss item: 0.3875848054885864
33
train loss item: 0.7251477241516113
34
train loss item: 0.4227859377861023
35
train loss item: 2.9328434467315674
36
train loss item: 0.6845158934593201
37
train loss item: 0.37049177289009094
38
train loss item: 0.7201752066612244
39
train loss item: 0.4930780529975891
40
train loss item: 0.3014034926891327
41
train loss item: 0.49657267332077026
42
train loss item: 0.3604181408882141
43
train loss item: 0.3855047821998596
44
train loss item: 1.0297542810440063
45
train loss item: 0.3466341495513916
46
train loss item: 0.3548533022403717
47
train loss item: 0.49289366602897644
48
train loss item: 0.4337422847747803
49
train loss item: 0.35309314727783203
50
train loss item: 0.4112716615200043
51
train loss item: 1.267536997795105
52
train loss item: 0.3253319263458252
53
train loss item: 0.35252681374549866
54
train loss item: 2.8232924938201904
55
train loss item: 0.41496580839157104
56
train loss item: 0.478279173374176
57
train loss item: 0.4213694632053375
58
train loss item: 0.3638981580734253
59
train loss item: 0.36891600489616394
60
train loss item: 1.3064498901367188
61
train loss item: 2.8205347061157227
62
train loss item: 0.40030649304389954
63
train loss item: 0.47829553484916687
64
train loss item: 0.3820277452468872
65
train loss item: 0.7256078124046326
66
train loss item: 0.5505028963088989
67
train loss item: 0.4006686210632324
68
train loss item: 0.41346731781959534
69
train loss item: 0.4650878608226776
70
train loss item: 0.4030076265335083
71
train loss item: 0.2978228032588959
72
train loss item: 0.41744598746299744
73
train loss item: 0.4164917767047882
74
train loss item: 0.366365522146225
75
train loss item: 0.3059244155883789
76
train loss item: 1.2832101583480835
77
train loss item: 1.5993642807006836
78
train loss item: 0.2903710901737213
79
train loss item: 0.39616137742996216
80
train loss item: 0.3380153477191925
81
train loss item: 0.3419483006000519
82
train loss item: 0.4190782904624939
83
train loss item: 0.9058240056037903
84
train loss item: 0.4595102071762085
85
train loss item: 0.9038756489753723
86
train loss item: 5.041164875030518
87
train loss item: 0.3814472258090973
88
train loss item: 0.4677489101886749
epoch train loss: 0.727748594257269
testing phase
test loss item: 0.2521902620792389
test loss item: 0.2463563233613968
test loss item: 0.9279228448867798
test loss item: 0.4478243589401245
test loss item: 0.44093936681747437
test loss item: 0.26315709948539734
test loss item: 1.881082534790039
test loss item: 0.4942623972892761
test loss item: 0.3242061138153076
test loss item: 0.5410722494125366
test loss item: 1.3805214166641235
test loss item: 0.39780691266059875
test loss item: 0.25827130675315857
test loss item: 0.36585739254951477
test loss item: 0.3131088614463806
test loss item: 0.23211047053337097
test loss item: 0.3411058783531189
test loss item: 0.7314189672470093
test loss item: 0.7001429796218872
test loss item: 0.3340034782886505
test loss item: 1.2429800033569336
test loss item: 0.530864417552948
test loss item: 0.5760958194732666
test loss item: 0.263040691614151
test loss item: 0.32923972606658936
test loss item: 0.32115480303764343
test loss item: 0.41688182950019836
test loss item: 0.334978848695755
test loss item: 0.46883952617645264
test loss item: 0.4418793022632599
test loss item: 1.155320405960083
test loss item: 0.2260134518146515
test loss item: 0.25187963247299194
test loss item: 0.9095188975334167
test loss item: 0.6939302682876587
test loss item: 0.9157507419586182
test loss item: 0.9040374159812927
test loss item: 2.472788095474243
test loss item: 0.762606680393219
test loss item: 0.3699493110179901
test loss item: 0.37357962131500244
test loss item: 0.4297417402267456
test loss item: 0.5317898988723755
test loss item: 0.41653186082839966
test loss item: 0.9710813164710999
test loss item: 0.49325644969940186
test loss item: 0.5541343688964844
test loss item: 0.3550383150577545
test loss item: 0.7064530253410339
test loss item: 0.9429876208305359
test loss item: 0.4762984812259674
test loss item: 0.21357931196689606
test loss item: 0.34673020243644714
test loss item: 0.5554941892623901
test loss item: 0.4891375005245209
test loss item: 1.3449243307113647
test loss item: 0.8914442658424377
test loss item: 0.4740852415561676
test loss item: 0.33222848176956177
test loss item: 0.31106722354888916
test loss item: 0.6115779876708984
test loss item: 0.2753452956676483
test loss item: 0.27454936504364014
test loss item: 0.31695428490638733
test loss item: 1.3981748819351196
test loss item: 0.6524821519851685
test loss item: 0.3997931182384491
test loss item: 0.337953120470047
test loss item: 0.8603289127349854
test loss item: 0.45089611411094666
test loss item: 0.2130456268787384
test loss item: 0.9769094586372375
test loss item: 0.46808573603630066
test loss item: 0.42276740074157715
test loss item: 0.23896542191505432
test loss item: 0.415365070104599
test loss item: 0.2598615884780884
test loss item: 2.823284387588501
test loss item: 0.6321609616279602
test loss item: 0.305255651473999
test loss item: 0.179587721824646
test loss item: 1.5141198635101318
test loss item: 1.013110876083374
test loss item: 1.9094038009643555
test loss item: 0.32573437690734863
test loss item: 0.337069034576416
test loss item: 0.2178996503353119
test loss item: 0.21727725863456726
test loss item: 0.2600052058696747
Epoch [5/10], Training Loss: 0.7277, Testing Loss: 0.6065
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6452210545539856
1
train loss item: 1.7289482355117798
2
train loss item: 0.3383975028991699
3
train loss item: 0.8923723697662354
4
train loss item: 0.6983416676521301
5
train loss item: 0.48326975107192993
6
train loss item: 0.3885626196861267
7
train loss item: 1.1405962705612183
8
train loss item: 0.2940666973590851
9
train loss item: 0.37343961000442505
10
train loss item: 0.5261847972869873
11
train loss item: 0.33319157361984253
12
train loss item: 0.23672565817832947
13
train loss item: 0.7501187920570374
14
train loss item: 0.43800103664398193
15
train loss item: 0.8853161334991455
16
train loss item: 0.19598424434661865
17
train loss item: 0.40613195300102234
18
train loss item: 0.4862695336341858
19
train loss item: 0.35405290126800537
20
train loss item: 0.32285600900650024
21
train loss item: 0.29618796706199646
22
train loss item: 1.2978127002716064
23
train loss item: 1.2209099531173706
24
train loss item: 0.6966726779937744
25
train loss item: 0.36117926239967346
26
train loss item: 0.3067795932292938
27
train loss item: 0.4608197510242462
28
train loss item: 0.19701042771339417
29
train loss item: 1.0397021770477295
30
train loss item: 2.852604627609253
31
train loss item: 0.7977504730224609
32
train loss item: 0.2906121611595154
33
train loss item: 0.6504994630813599
34
train loss item: 0.3805777132511139
35
train loss item: 2.8484134674072266
36
train loss item: 0.6507179141044617
37
train loss item: 0.3445320129394531
38
train loss item: 0.646823525428772
39
train loss item: 0.45959651470184326
40
train loss item: 0.2655152678489685
41
train loss item: 0.4443369209766388
42
train loss item: 0.32348504662513733
43
train loss item: 0.31999507546424866
44
train loss item: 0.9792998433113098
45
train loss item: 0.276140958070755
46
train loss item: 0.2940624952316284
47
train loss item: 0.4554567039012909
48
train loss item: 0.3804987967014313
49
train loss item: 0.30832639336586
50
train loss item: 0.37832367420196533
51
train loss item: 1.2200555801391602
52
train loss item: 0.22142644226551056
53
train loss item: 0.324291855096817
54
train loss item: 2.7330944538116455
55
train loss item: 0.34025338292121887
56
train loss item: 0.43192732334136963
57
train loss item: 0.377086877822876
58
train loss item: 0.30416861176490784
59
train loss item: 0.280572772026062
60
train loss item: 1.261991024017334
61
train loss item: 2.713313579559326
62
train loss item: 0.33034905791282654
63
train loss item: 0.44636857509613037
64
train loss item: 0.30631592869758606
65
train loss item: 0.7223644852638245
66
train loss item: 0.5028720498085022
67
train loss item: 0.3599405884742737
68
train loss item: 0.3869301974773407
69
train loss item: 0.42883527278900146
70
train loss item: 0.3731733560562134
71
train loss item: 0.2536478638648987
72
train loss item: 0.3198274075984955
73
train loss item: 0.3933572471141815
74
train loss item: 0.25255000591278076
75
train loss item: 0.24613520503044128
76
train loss item: 1.2061687707901
77
train loss item: 1.568737268447876
78
train loss item: 0.20533603429794312
79
train loss item: 0.35739952325820923
80
train loss item: 0.2686823904514313
81
train loss item: 0.2959524691104889
82
train loss item: 0.36959120631217957
83
train loss item: 0.8659226298332214
84
train loss item: 0.4310261011123657
85
train loss item: 0.8453577160835266
86
train loss item: 4.91859245300293
87
train loss item: 0.33064746856689453
88
train loss item: 0.4398626685142517
epoch train loss: 0.6716496383541086
testing phase
test loss item: 0.2514267861843109
test loss item: 0.23578743636608124
test loss item: 0.8421409130096436
test loss item: 0.4452724754810333
test loss item: 0.42802539467811584
test loss item: 0.2799590229988098
test loss item: 1.7652606964111328
test loss item: 0.4751644730567932
test loss item: 0.3089240789413452
test loss item: 0.5173994302749634
test loss item: 1.2175014019012451
test loss item: 0.3869268298149109
test loss item: 0.2465045303106308
test loss item: 0.3696826100349426
test loss item: 0.30334359407424927
test loss item: 0.2102905660867691
test loss item: 0.33833515644073486
test loss item: 0.6976087093353271
test loss item: 0.6878243088722229
test loss item: 0.31682783365249634
test loss item: 1.168135643005371
test loss item: 0.5216313004493713
test loss item: 0.6039986610412598
test loss item: 0.2496688812971115
test loss item: 0.3211801052093506
test loss item: 0.2962656021118164
test loss item: 0.3963067829608917
test loss item: 0.32584360241889954
test loss item: 0.44714540243148804
test loss item: 0.4340917766094208
test loss item: 1.024134874343872
test loss item: 0.2076060175895691
test loss item: 0.24558763206005096
test loss item: 0.8633992671966553
test loss item: 0.6510388255119324
test loss item: 0.773166298866272
test loss item: 0.8732166290283203
test loss item: 2.1387643814086914
test loss item: 0.7205466628074646
test loss item: 0.37008607387542725
test loss item: 0.3637576699256897
test loss item: 0.4798930585384369
test loss item: 0.5318541526794434
test loss item: 0.4097404479980469
test loss item: 0.9212838411331177
test loss item: 0.48347416520118713
test loss item: 0.5823826193809509
test loss item: 0.2856253683567047
test loss item: 0.6546012759208679
test loss item: 0.8706822395324707
test loss item: 0.4544416666030884
test loss item: 0.2123052477836609
test loss item: 0.3372083604335785
test loss item: 0.5486108064651489
test loss item: 0.4659050703048706
test loss item: 1.2120914459228516
test loss item: 0.7781188488006592
test loss item: 0.4993182420730591
test loss item: 0.3311591148376465
test loss item: 0.30207526683807373
test loss item: 0.592872679233551
test loss item: 0.2670460343360901
test loss item: 0.26929771900177
test loss item: 0.3131084442138672
test loss item: 1.2296767234802246
test loss item: 0.6468898057937622
test loss item: 0.39008715748786926
test loss item: 0.3257649838924408
test loss item: 0.7924712896347046
test loss item: 0.4600687026977539
test loss item: 0.19059856235980988
test loss item: 0.9367020130157471
test loss item: 0.45986735820770264
test loss item: 0.41702017188072205
test loss item: 0.2349158227443695
test loss item: 0.4681587517261505
test loss item: 0.24304378032684326
test loss item: 2.377206802368164
test loss item: 0.5958420634269714
test loss item: 0.3123306632041931
test loss item: 0.16323167085647583
test loss item: 1.329064965248108
test loss item: 0.9638237953186035
test loss item: 1.6042238473892212
test loss item: 0.3282613754272461
test loss item: 0.3230404853820801
test loss item: 0.21498508751392365
test loss item: 0.21535086631774902
test loss item: 0.2492603063583374
Epoch [6/10], Training Loss: 0.6716, Testing Loss: 0.5685
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6208663582801819
1
train loss item: 1.6327667236328125
2
train loss item: 0.3193853795528412
3
train loss item: 0.8058030605316162
4
train loss item: 0.58958500623703
5
train loss item: 0.4652804136276245
6
train loss item: 0.35918864607810974
7
train loss item: 1.0811164379119873
8
train loss item: 0.25466981530189514
9
train loss item: 0.36075204610824585
10
train loss item: 0.4986518621444702
11
train loss item: 0.32432499527931213
12
train loss item: 0.21677842736244202
13
train loss item: 0.7221936583518982
14
train loss item: 0.4171341359615326
15
train loss item: 0.8644335269927979
16
train loss item: 0.18400153517723083
17
train loss item: 0.4137260317802429
18
train loss item: 0.4535277783870697
19
train loss item: 0.33846673369407654
20
train loss item: 0.29837724566459656
21
train loss item: 0.2901039123535156
22
train loss item: 1.2509926557540894
23
train loss item: 1.1673998832702637
24
train loss item: 0.6697906255722046
25
train loss item: 0.36520665884017944
26
train loss item: 0.28737688064575195
27
train loss item: 0.4359801411628723
28
train loss item: 0.18188732862472534
29
train loss item: 1.0065757036209106
30
train loss item: 2.7441580295562744
31
train loss item: 0.7459144592285156
32
train loss item: 0.21404866874217987
33
train loss item: 0.5948442220687866
34
train loss item: 0.3749246299266815
35
train loss item: 2.774412155151367
36
train loss item: 0.628724217414856
37
train loss item: 0.332899272441864
38
train loss item: 0.5903997421264648
39
train loss item: 0.4397202432155609
40
train loss item: 0.2694013714790344
41
train loss item: 0.41962361335754395
42
train loss item: 0.2992267906665802
43
train loss item: 0.28080520033836365
44
train loss item: 0.9428375959396362
45
train loss item: 0.24122819304466248
46
train loss item: 0.25512638688087463
47
train loss item: 0.44452837109565735
48
train loss item: 0.35549265146255493
49
train loss item: 0.3148382306098938
50
train loss item: 0.35431304574012756
51
train loss item: 1.1735419034957886
52
train loss item: 0.19849374890327454
53
train loss item: 0.3432384133338928
54
train loss item: 2.6534955501556396
55
train loss item: 0.2861960530281067
56
train loss item: 0.40684768557548523
57
train loss item: 0.33878329396247864
58
train loss item: 0.2608513832092285
59
train loss item: 0.23534061014652252
60
train loss item: 1.206522822380066
61
train loss item: 2.6270031929016113
62
train loss item: 0.3084268569946289
63
train loss item: 0.41363388299942017
64
train loss item: 0.24848933517932892
65
train loss item: 0.71045982837677
66
train loss item: 0.47698870301246643
67
train loss item: 0.3393414318561554
68
train loss item: 0.37059080600738525
69
train loss item: 0.41112020611763
70
train loss item: 0.3794271945953369
71
train loss item: 0.24603167176246643
72
train loss item: 0.28612029552459717
73
train loss item: 0.3883107304573059
74
train loss item: 0.24127180874347687
75
train loss item: 0.22147731482982635
76
train loss item: 1.142932653427124
77
train loss item: 1.5296545028686523
78
train loss item: 0.18140393495559692
79
train loss item: 0.32386544346809387
80
train loss item: 0.23611871898174286
81
train loss item: 0.2937258780002594
82
train loss item: 0.35281169414520264
83
train loss item: 0.8258532881736755
84
train loss item: 0.4186643064022064
85
train loss item: 0.8044732809066772
86
train loss item: 4.810916423797607
87
train loss item: 0.3477106988430023
88
train loss item: 0.413939893245697
epoch train loss: 0.6398638892039824
testing phase
test loss item: 0.25328224897384644
test loss item: 0.23399780690670013
test loss item: 0.7863457798957825
test loss item: 0.368974506855011
test loss item: 0.4158589541912079
test loss item: 0.28650444746017456
test loss item: 1.6987099647521973
test loss item: 0.4847869873046875
test loss item: 0.30651775002479553
test loss item: 0.5041671395301819
test loss item: 1.1632639169692993
test loss item: 0.2955278158187866
test loss item: 0.24966846406459808
test loss item: 0.37091028690338135
test loss item: 0.29675668478012085
test loss item: 0.19261586666107178
test loss item: 0.3354567885398865
test loss item: 0.658467710018158
test loss item: 0.7020514011383057
test loss item: 0.3365957736968994
test loss item: 1.0800809860229492
test loss item: 0.4553881585597992
test loss item: 0.5420660376548767
test loss item: 0.24936026334762573
test loss item: 0.3089473247528076
test loss item: 0.2937248945236206
test loss item: 0.4003644585609436
test loss item: 0.32294631004333496
test loss item: 0.43510717153549194
test loss item: 0.4349900484085083
test loss item: 0.980178952217102
test loss item: 0.1922481507062912
test loss item: 0.24669389426708221
test loss item: 0.7876656651496887
test loss item: 0.61049485206604
test loss item: 0.6336287260055542
test loss item: 0.8631623387336731
test loss item: 2.0098345279693604
test loss item: 0.6577877998352051
test loss item: 0.3688564598560333
test loss item: 0.3540785312652588
test loss item: 0.41334807872772217
test loss item: 0.5202460289001465
test loss item: 0.3289024531841278
test loss item: 0.8626096248626709
test loss item: 0.48132169246673584
test loss item: 0.5258878469467163
test loss item: 0.3278862535953522
test loss item: 0.6146120429039001
test loss item: 0.8574888110160828
test loss item: 0.4361375868320465
test loss item: 0.23381556570529938
test loss item: 0.32944661378860474
test loss item: 0.4002256691455841
test loss item: 0.44654610753059387
test loss item: 1.1548115015029907
test loss item: 0.6924795508384705
test loss item: 0.48410564661026
test loss item: 0.32444435358047485
test loss item: 0.2960008680820465
test loss item: 0.575468897819519
test loss item: 0.25710317492485046
test loss item: 0.27240630984306335
test loss item: 0.30408579111099243
test loss item: 1.13593590259552
test loss item: 0.5057934522628784
test loss item: 0.3816291093826294
test loss item: 0.3176214396953583
test loss item: 0.7442411184310913
test loss item: 0.5109080076217651
test loss item: 0.17674438655376434
test loss item: 0.9177349805831909
test loss item: 0.43562421202659607
test loss item: 0.4124358594417572
test loss item: 0.23801030218601227
test loss item: 0.4064955413341522
test loss item: 0.24171008169651031
test loss item: 2.1690943241119385
test loss item: 0.5672817230224609
test loss item: 0.3174498677253723
test loss item: 0.15501831471920013
test loss item: 1.2530807256698608
test loss item: 0.9615751504898071
test loss item: 1.4807672500610352
test loss item: 0.32790207862854004
test loss item: 0.32940152287483215
test loss item: 0.204376220703125
test loss item: 0.20055340230464935
test loss item: 0.25986024737358093
Epoch [7/10], Training Loss: 0.6399, Testing Loss: 0.5389
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6005350351333618
1
train loss item: 1.5514355897903442
2
train loss item: 0.3006862998008728
3
train loss item: 0.7503088712692261
4
train loss item: 0.5332026481628418
5
train loss item: 0.4506199359893799
6
train loss item: 0.33452343940734863
7
train loss item: 1.0390982627868652
8
train loss item: 0.2612323462963104
9
train loss item: 0.3621290922164917
10
train loss item: 0.4872727692127228
11
train loss item: 0.3368585407733917
12
train loss item: 0.2147115021944046
13
train loss item: 0.6922715306282043
14
train loss item: 0.4084062874317169
15
train loss item: 0.8324126601219177
16
train loss item: 0.18377695977687836
17
train loss item: 0.41638991236686707
18
train loss item: 0.4313204288482666
19
train loss item: 0.34050583839416504
20
train loss item: 0.28871989250183105
21
train loss item: 0.28100109100341797
22
train loss item: 1.196636438369751
23
train loss item: 1.130042552947998
24
train loss item: 0.64091956615448
25
train loss item: 0.3553757965564728
26
train loss item: 0.2989475131034851
27
train loss item: 0.41955286264419556
28
train loss item: 0.181097149848938
29
train loss item: 0.9636754989624023
30
train loss item: 2.667633295059204
31
train loss item: 0.7108197808265686
32
train loss item: 0.2119992971420288
33
train loss item: 0.5540957450866699
34
train loss item: 0.34873494505882263
35
train loss item: 2.722177743911743
36
train loss item: 0.6042764782905579
37
train loss item: 0.3363940119743347
38
train loss item: 0.5467432141304016
39
train loss item: 0.42083466053009033
40
train loss item: 0.26340165734291077
41
train loss item: 0.40876612067222595
42
train loss item: 0.29846152663230896
43
train loss item: 0.26552045345306396
44
train loss item: 0.9126308560371399
45
train loss item: 0.2240470051765442
46
train loss item: 0.23971202969551086
47
train loss item: 0.4315193295478821
48
train loss item: 0.3436274826526642
49
train loss item: 0.31174206733703613
50
train loss item: 0.3491704761981964
51
train loss item: 1.1253582239151
52
train loss item: 0.200222447514534
53
train loss item: 0.3259042203426361
54
train loss item: 2.599846601486206
55
train loss item: 0.26549211144447327
56
train loss item: 0.39387747645378113
57
train loss item: 0.3249340057373047
58
train loss item: 0.24916549026966095
59
train loss item: 0.22602930665016174
60
train loss item: 1.139011263847351
61
train loss item: 2.5696566104888916
62
train loss item: 0.31132686138153076
63
train loss item: 0.3979695439338684
64
train loss item: 0.2307855784893036
65
train loss item: 0.6810782551765442
66
train loss item: 0.46563515067100525
67
train loss item: 0.3277639150619507
68
train loss item: 0.36771178245544434
69
train loss item: 0.4009914994239807
70
train loss item: 0.3744887113571167
71
train loss item: 0.2382773756980896
72
train loss item: 0.2837296426296234
73
train loss item: 0.3862657845020294
74
train loss item: 0.24189673364162445
75
train loss item: 0.2092791646718979
76
train loss item: 1.0974056720733643
77
train loss item: 1.4893975257873535
78
train loss item: 0.18096472322940826
79
train loss item: 0.31747496128082275
80
train loss item: 0.22049176692962646
81
train loss item: 0.2882404923439026
82
train loss item: 0.3403073847293854
83
train loss item: 0.7820855975151062
84
train loss item: 0.40775540471076965
85
train loss item: 0.7709012627601624
86
train loss item: 4.7397589683532715
87
train loss item: 0.32996097207069397
88
train loss item: 0.3938354551792145
epoch train loss: 0.6196769936366028
testing phase
test loss item: 0.24664191901683807
test loss item: 0.21502646803855896
test loss item: 0.7236920595169067
test loss item: 0.3011724352836609
test loss item: 0.38219791650772095
test loss item: 0.26222193241119385
test loss item: 1.6663777828216553
test loss item: 0.513744592666626
test loss item: 0.289548397064209
test loss item: 0.46857959032058716
test loss item: 1.129069447517395
test loss item: 0.21964554488658905
test loss item: 0.2255939543247223
test loss item: 0.3554159700870514
test loss item: 0.271467924118042
test loss item: 0.16800333559513092
test loss item: 0.32425421476364136
test loss item: 0.5946148037910461
test loss item: 0.7147129774093628
test loss item: 0.3179295063018799
test loss item: 0.9588596820831299
test loss item: 0.40579938888549805
test loss item: 0.4308619797229767
test loss item: 0.23743177950382233
test loss item: 0.2908378839492798
test loss item: 0.28787317872047424
test loss item: 0.38961929082870483
test loss item: 0.2988411784172058
test loss item: 0.4112653136253357
test loss item: 0.4065406322479248
test loss item: 0.9504793286323547
test loss item: 0.14757773280143738
test loss item: 0.23262788355350494
test loss item: 0.7091859579086304
test loss item: 0.5548900961875916
test loss item: 0.5682107210159302
test loss item: 0.8592382073402405
test loss item: 1.9178292751312256
test loss item: 0.595458447933197
test loss item: 0.34999871253967285
test loss item: 0.34007593989372253
test loss item: 0.30612826347351074
test loss item: 0.4736967086791992
test loss item: 0.26281997561454773
test loss item: 0.7755277752876282
test loss item: 0.45211219787597656
test loss item: 0.42043375968933105
test loss item: 0.31317880749702454
test loss item: 0.5690016150474548
test loss item: 0.8462586998939514
test loss item: 0.3974609673023224
test loss item: 0.20326028764247894
test loss item: 0.3090575635433197
test loss item: 0.26142776012420654
test loss item: 0.40613386034965515
test loss item: 1.106000542640686
test loss item: 0.6547552347183228
test loss item: 0.4023006856441498
test loss item: 0.2969154417514801
test loss item: 0.27714264392852783
test loss item: 0.5277537107467651
test loss item: 0.24254511296749115
test loss item: 0.26397958397865295
test loss item: 0.2910301983356476
test loss item: 1.06386137008667
test loss item: 0.38496270775794983
test loss item: 0.35274308919906616
test loss item: 0.31125450134277344
test loss item: 0.6957356333732605
test loss item: 0.5307685136795044
test loss item: 0.1623942106962204
test loss item: 0.9160824418067932
test loss item: 0.3774813115596771
test loss item: 0.40231260657310486
test loss item: 0.22766444087028503
test loss item: 0.29774338006973267
test loss item: 0.2321077138185501
test loss item: 2.0338950157165527
test loss item: 0.5312429070472717
test loss item: 0.29751288890838623
test loss item: 0.15327829122543335
test loss item: 1.2095121145248413
test loss item: 0.9550616145133972
test loss item: 1.4018468856811523
test loss item: 0.30933329463005066
test loss item: 0.32419922947883606
test loss item: 0.19147741794586182
test loss item: 0.17540690302848816
test loss item: 0.2703246474266052
Epoch [8/10], Training Loss: 0.6197, Testing Loss: 0.5011
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5743954181671143
1
train loss item: 1.4916267395019531
2
train loss item: 0.27790725231170654
3
train loss item: 0.7140593528747559
4
train loss item: 0.49876686930656433
5
train loss item: 0.4275818169116974
6
train loss item: 0.306278258562088
7
train loss item: 1.003696322441101
8
train loss item: 0.233316108584404
9
train loss item: 0.34300264716148376
10
train loss item: 0.46609407663345337
11
train loss item: 0.33860132098197937
12
train loss item: 0.20459496974945068
13
train loss item: 0.6516890525817871
14
train loss item: 0.3909648656845093
15
train loss item: 0.7942982912063599
16
train loss item: 0.16891592741012573
17
train loss item: 0.3754238784313202
18
train loss item: 0.40834012627601624
19
train loss item: 0.3302743136882782
20
train loss item: 0.2852264940738678
21
train loss item: 0.23983778059482574
22
train loss item: 1.1512608528137207
23
train loss item: 1.099772572517395
24
train loss item: 0.6158661246299744
25
train loss item: 0.3123924434185028
26
train loss item: 0.27463477849960327
27
train loss item: 0.3966401219367981
28
train loss item: 0.16410569846630096
29
train loss item: 0.9174605011940002
30
train loss item: 2.614682674407959
31
train loss item: 0.6719673275947571
32
train loss item: 0.20240092277526855
33
train loss item: 0.5133413076400757
34
train loss item: 0.29952138662338257
35
train loss item: 2.682870626449585
36
train loss item: 0.5726163387298584
37
train loss item: 0.3360234200954437
38
train loss item: 0.5089361071586609
39
train loss item: 0.39433014392852783
40
train loss item: 0.22762982547283173
41
train loss item: 0.3863799273967743
42
train loss item: 0.2908063530921936
43
train loss item: 0.24107900261878967
44
train loss item: 0.877792239189148
45
train loss item: 0.20571935176849365
46
train loss item: 0.21620884537696838
47
train loss item: 0.4042266309261322
48
train loss item: 0.3132947087287903
49
train loss item: 0.2678401470184326
50
train loss item: 0.34227150678634644
51
train loss item: 1.0801708698272705
52
train loss item: 0.1831454187631607
53
train loss item: 0.2618120014667511
54
train loss item: 2.561413288116455
55
train loss item: 0.24399928748607635
56
train loss item: 0.3725316524505615
57
train loss item: 0.3198336064815521
58
train loss item: 0.2319193035364151
59
train loss item: 0.2155981808900833
60
train loss item: 1.0776489973068237
61
train loss item: 2.524946689605713
62
train loss item: 0.29267480969429016
63
train loss item: 0.39422693848609924
64
train loss item: 0.21531882882118225
65
train loss item: 0.6449991464614868
66
train loss item: 0.45068392157554626
67
train loss item: 0.3019859790802002
68
train loss item: 0.35489845275878906
69
train loss item: 0.38172784447669983
70
train loss item: 0.33799639344215393
71
train loss item: 0.21700140833854675
72
train loss item: 0.2585693299770355
73
train loss item: 0.36577698588371277
74
train loss item: 0.1993708610534668
75
train loss item: 0.19013698399066925
76
train loss item: 1.0623209476470947
77
train loss item: 1.4598063230514526
78
train loss item: 0.17003242671489716
79
train loss item: 0.31991639733314514
80
train loss item: 0.20348985493183136
81
train loss item: 0.25250622630119324
82
train loss item: 0.30849921703338623
83
train loss item: 0.7397314310073853
84
train loss item: 0.388505756855011
85
train loss item: 0.7360994815826416
86
train loss item: 4.689479351043701
87
train loss item: 0.26612716913223267
88
train loss item: 0.3776043951511383
epoch train loss: 0.5919041564960158
testing phase
test loss item: 0.2374350130558014
test loss item: 0.204989954829216
test loss item: 0.6638544797897339
test loss item: 0.2869490087032318
test loss item: 0.348295658826828
test loss item: 0.23729656636714935
test loss item: 1.6404938697814941
test loss item: 0.5504173040390015
test loss item: 0.27005258202552795
test loss item: 0.4351678192615509
test loss item: 1.0920649766921997
test loss item: 0.22052595019340515
test loss item: 0.21198345720767975
test loss item: 0.3387492597103119
test loss item: 0.24627642333507538
test loss item: 0.17498961091041565
test loss item: 0.3203371465206146
test loss item: 0.533289909362793
test loss item: 0.7220916748046875
test loss item: 0.29822301864624023
test loss item: 0.848271906375885
test loss item: 0.40806519985198975
test loss item: 0.3575718104839325
test loss item: 0.22678734362125397
test loss item: 0.27688032388687134
test loss item: 0.2795330882072449
test loss item: 0.3735771179199219
test loss item: 0.273692786693573
test loss item: 0.3873918056488037
test loss item: 0.3808150887489319
test loss item: 0.9183586835861206
test loss item: 0.13679702579975128
test loss item: 0.21988962590694427
test loss item: 0.6588415503501892
test loss item: 0.5039399862289429
test loss item: 0.5445810556411743
test loss item: 0.8568220734596252
test loss item: 1.8267126083374023
test loss item: 0.5543065071105957
test loss item: 0.33256134390830994
test loss item: 0.33095723390579224
test loss item: 0.26222553849220276
test loss item: 0.42625799775123596
test loss item: 0.25707700848579407
test loss item: 0.694802463054657
test loss item: 0.4406060576438904
test loss item: 0.35480761528015137
test loss item: 0.27570146322250366
test loss item: 0.5318006277084351
test loss item: 0.8268119692802429
test loss item: 0.35652580857276917
test loss item: 0.17673684656620026
test loss item: 0.28669947385787964
test loss item: 0.2484801858663559
test loss item: 0.3621397018432617
test loss item: 1.0510272979736328
test loss item: 0.6378564238548279
test loss item: 0.3073435425758362
test loss item: 0.2734279930591583
test loss item: 0.2589291036128998
test loss item: 0.4817594289779663
test loss item: 0.25409042835235596
test loss item: 0.25339192152023315
test loss item: 0.2826824486255646
test loss item: 0.9994363784790039
test loss item: 0.36520349979400635
test loss item: 0.33251869678497314
test loss item: 0.3075465261936188
test loss item: 0.6540760397911072
test loss item: 0.5299025177955627
test loss item: 0.16828753054141998
test loss item: 0.9232310056686401
test loss item: 0.3201812505722046
test loss item: 0.39648279547691345
test loss item: 0.22276689112186432
test loss item: 0.25015583634376526
test loss item: 0.22374768555164337
test loss item: 1.914823055267334
test loss item: 0.49858883023262024
test loss item: 0.2749374508857727
test loss item: 0.15843002498149872
test loss item: 1.171126365661621
test loss item: 0.9418053030967712
test loss item: 1.330901861190796
test loss item: 0.2835186719894409
test loss item: 0.31664368510246277
test loss item: 0.1920916885137558
test loss item: 0.17714186012744904
test loss item: 0.2690761387348175
Epoch [9/10], Training Loss: 0.5919, Testing Loss: 0.4748
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5508936643600464
1
train loss item: 1.4480639696121216
2
train loss item: 0.26590055227279663
3
train loss item: 0.6869901418685913
4
train loss item: 0.4862743318080902
5
train loss item: 0.41420409083366394
6
train loss item: 0.2989979684352875
7
train loss item: 0.9726355075836182
8
train loss item: 0.19978362321853638
9
train loss item: 0.3225676417350769
10
train loss item: 0.44241952896118164
11
train loss item: 0.33469992876052856
12
train loss item: 0.19037111103534698
13
train loss item: 0.6139525175094604
14
train loss item: 0.38179734349250793
15
train loss item: 0.7639994025230408
16
train loss item: 0.15268348157405853
17
train loss item: 0.325615793466568
18
train loss item: 0.391751229763031
19
train loss item: 0.32109349966049194
20
train loss item: 0.28855350613594055
21
train loss item: 0.1993803083896637
22
train loss item: 1.1175400018692017
23
train loss item: 1.0761607885360718
24
train loss item: 0.5969193577766418
25
train loss item: 0.263967901468277
26
train loss item: 0.24954138696193695
27
train loss item: 0.37520501017570496
28
train loss item: 0.14764048159122467
29
train loss item: 0.8792175650596619
30
train loss item: 2.5720536708831787
31
train loss item: 0.6389164924621582
32
train loss item: 0.18089191615581512
33
train loss item: 0.4808811545372009
34
train loss item: 0.25813862681388855
35
train loss item: 2.648876905441284
36
train loss item: 0.5435669422149658
37
train loss item: 0.3407854437828064
38
train loss item: 0.483424574136734
39
train loss item: 0.36770960688591003
40
train loss item: 0.20145295560359955
41
train loss item: 0.36625486612319946
42
train loss item: 0.28494200110435486
43
train loss item: 0.22571198642253876
44
train loss item: 0.8441744446754456
45
train loss item: 0.19139669835567474
46
train loss item: 0.20340484380722046
47
train loss item: 0.38348519802093506
48
train loss item: 0.28934791684150696
49
train loss item: 0.2280598133802414
50
train loss item: 0.34039679169654846
51
train loss item: 1.0428266525268555
52
train loss item: 0.16741597652435303
53
train loss item: 0.20739056169986725
54
train loss item: 2.5289976596832275
55
train loss item: 0.24627482891082764
56
train loss item: 0.35215142369270325
57
train loss item: 0.32916975021362305
58
train loss item: 0.21596363186836243
59
train loss item: 0.20892031490802765
60
train loss item: 1.0325493812561035
61
train loss item: 2.4843223094940186
62
train loss item: 0.27146753668785095
63
train loss item: 0.3972403407096863
64
train loss item: 0.20149779319763184
65
train loss item: 0.610788106918335
66
train loss item: 0.4359866678714752
67
train loss item: 0.27898016571998596
68
train loss item: 0.3364366590976715
69
train loss item: 0.3648364543914795
70
train loss item: 0.29800036549568176
71
train loss item: 0.19887591898441315
72
train loss item: 0.23473364114761353
73
train loss item: 0.3461650013923645
74
train loss item: 0.1583653837442398
75
train loss item: 0.17535030841827393
76
train loss item: 1.0354362726211548
77
train loss item: 1.438515543937683
78
train loss item: 0.15701203048229218
79
train loss item: 0.3261179029941559
80
train loss item: 0.19260744750499725
81
train loss item: 0.23409849405288696
82
train loss item: 0.28284701704978943
83
train loss item: 0.7068325281143188
84
train loss item: 0.371254563331604
85
train loss item: 0.7038127779960632
86
train loss item: 4.645908832550049
87
train loss item: 0.21204747259616852
88
train loss item: 0.370811402797699
epoch train loss: 0.5689292540041249
testing phase
test loss item: 0.2272849678993225
test loss item: 0.20338794589042664
test loss item: 0.6205271482467651
test loss item: 0.318146675825119
test loss item: 0.32119715213775635
test loss item: 0.21336260437965393
test loss item: 1.6092668771743774
test loss item: 0.5722198486328125
test loss item: 0.2576253414154053
test loss item: 0.42084845900535583
test loss item: 1.0494475364685059
test loss item: 0.2800818383693695
test loss item: 0.21884198486804962
test loss item: 0.3316322863101959
test loss item: 0.2283218502998352
test loss item: 0.19804970920085907
test loss item: 0.3212909400463104
test loss item: 0.4970603585243225
test loss item: 0.7177485227584839
test loss item: 0.2939162254333496
test loss item: 0.7877835631370544
test loss item: 0.44286710023880005
test loss item: 0.32607555389404297
test loss item: 0.21721217036247253
test loss item: 0.27033063769340515
test loss item: 0.26824086904525757
test loss item: 0.36257240176200867
test loss item: 0.2537863552570343
test loss item: 0.3705706000328064
test loss item: 0.37308165431022644
test loss item: 0.884648859500885
test loss item: 0.1620720624923706
test loss item: 0.20786456763744354
test loss item: 0.6470438241958618
test loss item: 0.47367697954177856
test loss item: 0.5441855192184448
test loss item: 0.8496650457382202
test loss item: 1.737194299697876
test loss item: 0.5440074801445007
test loss item: 0.3173810839653015
test loss item: 0.3282066285610199
test loss item: 0.25413253903388977
test loss item: 0.4016309976577759
test loss item: 0.2986319065093994
test loss item: 0.6502663493156433
test loss item: 0.44802579283714294
test loss item: 0.3331123888492584
test loss item: 0.2585006058216095
test loss item: 0.5106247663497925
test loss item: 0.8024330735206604
test loss item: 0.33572646975517273
test loss item: 0.1750064492225647
test loss item: 0.2707447111606598
test loss item: 0.3411376178264618
test loss item: 0.3334020674228668
test loss item: 0.9987852573394775
test loss item: 0.6283557415008545
test loss item: 0.2669852375984192
test loss item: 0.2625662386417389
test loss item: 0.25200918316841125
test loss item: 0.46164005994796753
test loss item: 0.2737477719783783
test loss item: 0.24352115392684937
test loss item: 0.2855801284313202
test loss item: 0.9383442997932434
test loss item: 0.43249285221099854
test loss item: 0.3271367847919464
test loss item: 0.30482470989227295
test loss item: 0.62424236536026
test loss item: 0.5150288343429565
test loss item: 0.18096166849136353
test loss item: 0.9252745509147644
test loss item: 0.29508453607559204
test loss item: 0.3944634795188904
test loss item: 0.21898196637630463
test loss item: 0.24053868651390076
test loss item: 0.2157016396522522
test loss item: 1.8007031679153442
test loss item: 0.4766644835472107
test loss item: 0.25504541397094727
test loss item: 0.15885761380195618
test loss item: 1.1276463270187378
test loss item: 0.9254928827285767
test loss item: 1.261329174041748
test loss item: 0.25902259349823
test loss item: 0.30183276534080505
test loss item: 0.19566300511360168
test loss item: 0.19488726556301117
test loss item: 0.2460114061832428
Epoch [10/10], Training Loss: 0.5689, Testing Loss: 0.4626
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
loss item: 0.4166407883167267
loss item: 0.24728722870349884
loss item: 1.90869140625
loss item: 1.1158548593521118
loss item: 0.5752912163734436
loss item: 0.4006321132183075
loss item: 0.2845951318740845
loss item: 0.7728788256645203
loss item: 0.24514982104301453
loss item: 0.24638724327087402
loss item: 0.8257037997245789
loss item: 0.14009685814380646
loss item: 0.9094370007514954
loss item: 0.27891412377357483
loss item: 0.45340216159820557
loss item: 0.3464288115501404
loss item: 0.3293449878692627
loss item: 0.7911646962165833
loss item: 0.9749323129653931
loss item: 0.5321223735809326
loss item: 0.4192579984664917
loss item: 0.2500498294830322
loss item: 0.3138764798641205
loss item: 0.25829049944877625
loss item: 0.3751330077648163
loss item: 0.7459961175918579
loss item: 1.247761607170105
loss item: 0.23647809028625488
loss item: 0.21603168547153473
loss item: 0.43104004859924316
loss item: 0.9570425152778625
loss item: 1.743283748626709
loss item: 0.20297038555145264
loss item: 0.5811657905578613
loss item: 0.2330128699541092
loss item: 0.25062641501426697
loss item: 0.4521530866622925
loss item: 0.2764604985713959
loss item: 0.45240357518196106
loss item: 0.6810898184776306
loss item: 1.1549954414367676
loss item: 0.27484530210494995
loss item: 0.25175967812538147
loss item: 0.2055540233850479
Val Loss: 0.5456
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 10 0.0005 2 360 done at Wed Nov 13 16:13:04 CET 2024
UNet6 with 1 10 0.001 2 360 start at Wed Nov 13 16:13:04 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 10, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 11785081.0
test loss item: 18044648.0
test loss item: 7167461.0
test loss item: 29383746.0
test loss item: 15124092.0
test loss item: 11692700.0
test loss item: 39257308.0
test loss item: 21983670.0
test loss item: 10956118.0
test loss item: 11253177.0
test loss item: 30624698.0
test loss item: 29517882.0
test loss item: 14048648.0
test loss item: 1793891.75
test loss item: 16510353.0
test loss item: 18418314.0
test loss item: 6508121.5
test loss item: 13564400.0
test loss item: 23912850.0
test loss item: 6264794.0
test loss item: 5424060.0
test loss item: 27085740.0
test loss item: 20075276.0
test loss item: 17504854.0
test loss item: 11419959.0
test loss item: 10714604.0
test loss item: 12563931.0
test loss item: 15127241.0
test loss item: 17282536.0
test loss item: 14532781.0
test loss item: 23636338.0
test loss item: 19461510.0
test loss item: 17369196.0
test loss item: 28206086.0
test loss item: 15426254.0
test loss item: 75933592.0
test loss item: 24528266.0
test loss item: 42413388.0
test loss item: 26005210.0
test loss item: 15361826.0
test loss item: 14713672.0
test loss item: 21589830.0
test loss item: 4337666.0
test loss item: 27008148.0
test loss item: 5460098.0
test loss item: 13491585.0
test loss item: 19726744.0
test loss item: 7888513.5
test loss item: 7950283.0
test loss item: 21157566.0
test loss item: 12844620.0
test loss item: 13379003.0
test loss item: 9847971.0
test loss item: 40478308.0
test loss item: 9069851.0
test loss item: 18914676.0
test loss item: 51207676.0
test loss item: 790203.5
test loss item: 12065969.0
test loss item: 11776603.0
test loss item: 13123707.0
test loss item: 11832058.0
test loss item: 8010527.5
test loss item: 14818182.0
test loss item: 23189776.0
test loss item: 42727972.0
test loss item: 12784839.0
test loss item: 11372064.0
test loss item: 13868499.0
test loss item: 24966456.0
test loss item: 13975702.0
test loss item: 22125188.0
test loss item: 3733051.75
test loss item: 11549237.0
test loss item: 5526398.0
test loss item: 19573080.0
test loss item: 16077742.0
test loss item: 43605664.0
test loss item: 1412052.75
test loss item: 10582447.0
test loss item: 7402180.0
test loss item: 42150504.0
test loss item: 25959800.0
test loss item: 43047772.0
test loss item: 9130282.0
test loss item: 7604744.0
test loss item: 13163716.0
test loss item: 17791828.0
test loss item: 10392790.0
Epoch [1/10], Training Loss: 1.0161, Testing Loss: 18012155.5758
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.1627389192581177
1
train loss item: 2.1412336826324463
2
train loss item: 1.223680019378662
3
train loss item: 1.2127991914749146
4
train loss item: 3.0910515785217285
5
train loss item: 1.0142309665679932
6
train loss item: 1.4223579168319702
7
train loss item: 1.2893645763397217
8
train loss item: 1.440064787864685
9
train loss item: 0.8364047408103943
10
train loss item: 0.8886779546737671
11
train loss item: 0.7996166944503784
12
train loss item: 0.982550323009491
13
train loss item: 1.2329033613204956
14
train loss item: 0.9984112977981567
15
train loss item: 1.5051113367080688
16
train loss item: 1.2095601558685303
17
train loss item: 1.4161232709884644
18
train loss item: 1.012138843536377
19
train loss item: 0.9051920175552368
20
train loss item: 1.0893741846084595
21
train loss item: 1.0338590145111084
22
train loss item: 2.1671197414398193
23
train loss item: 1.3989713191986084
24
train loss item: 1.2572822570800781
25
train loss item: 1.0565353631973267
26
train loss item: 1.1701897382736206
27
train loss item: 0.8683547973632812
28
train loss item: 1.2076148986816406
29
train loss item: 1.7722322940826416
30
train loss item: 2.745358943939209
31
train loss item: 1.216265082359314
32
train loss item: 0.9440435171127319
33
train loss item: 1.1446332931518555
34
train loss item: 1.909136176109314
35
train loss item: 2.8699867725372314
36
train loss item: 1.219748854637146
37
train loss item: 0.8850826025009155
38
train loss item: 1.3808495998382568
39
train loss item: 0.911266565322876
40
train loss item: 1.1082417964935303
41
train loss item: 0.814866304397583
42
train loss item: 0.8350582718849182
43
train loss item: 0.9496601819992065
44
train loss item: 1.1882284879684448
45
train loss item: 1.1230639219284058
46
train loss item: 0.990526556968689
47
train loss item: 1.0901484489440918
48
train loss item: 0.9159326553344727
49
train loss item: 0.9682211875915527
50
train loss item: 0.9414951801300049
51
train loss item: 1.7621641159057617
52
train loss item: 1.1775217056274414
53
train loss item: 1.186757206916809
54
train loss item: 2.708171844482422
55
train loss item: 1.1227338314056396
56
train loss item: 0.8477191925048828
57
train loss item: 0.9238559007644653
58
train loss item: 0.9379908442497253
59
train loss item: 0.9621532559394836
60
train loss item: 1.9530788660049438
61
train loss item: 2.6338388919830322
62
train loss item: 0.9953965544700623
63
train loss item: 0.9847005605697632
64
train loss item: 0.9228894114494324
65
train loss item: 1.5504430532455444
66
train loss item: 0.9608433842658997
67
train loss item: 0.9519791007041931
68
train loss item: 1.1556516885757446
69
train loss item: 0.9736729264259338
70
train loss item: 1.0080184936523438
71
train loss item: 1.4687238931655884
72
train loss item: 1.419049620628357
73
train loss item: 0.9922592639923096
74
train loss item: 1.5344414710998535
75
train loss item: 0.9670674800872803
76
train loss item: 1.4292179346084595
77
train loss item: 2.2641994953155518
78
train loss item: 1.1958861351013184
79
train loss item: 0.8626599311828613
80
train loss item: 1.423616886138916
81
train loss item: 0.9546928405761719
82
train loss item: 0.9756700992584229
83
train loss item: 1.4691296815872192
84
train loss item: 1.007530927658081
85
train loss item: 1.1756672859191895
86
train loss item: 4.784779071807861
87
train loss item: 1.3828245401382446
88
train loss item: 0.9960072040557861
epoch train loss: 1.3143883622094485
testing phase
test loss item: 153.61972045898438
test loss item: 308.9806213378906
test loss item: 183.40676879882812
test loss item: 798.7156982421875
test loss item: 291.8871765136719
test loss item: 292.6216125488281
test loss item: 514.3078002929688
test loss item: 257.57354736328125
test loss item: 94.98118591308594
test loss item: 176.06163024902344
test loss item: 836.6275024414062
test loss item: 727.2073974609375
test loss item: 211.66830444335938
test loss item: 25.58147430419922
test loss item: 304.7413330078125
test loss item: 342.85205078125
test loss item: 102.54563903808594
test loss item: 221.5685577392578
test loss item: 326.33734130859375
test loss item: 61.57472610473633
test loss item: 197.2107391357422
test loss item: 768.4361572265625
test loss item: 412.4140319824219
test loss item: 277.70550537109375
test loss item: 242.00021362304688
test loss item: 215.24026489257812
test loss item: 124.50702667236328
test loss item: 281.31512451171875
test loss item: 278.3996887207031
test loss item: 232.18565368652344
test loss item: 913.3241577148438
test loss item: 322.2038879394531
test loss item: 285.8175354003906
test loss item: 885.0394287109375
test loss item: 284.91851806640625
test loss item: 3124.969482421875
test loss item: 242.1707000732422
test loss item: 1505.26123046875
test loss item: 653.8809204101562
test loss item: 278.1027526855469
test loss item: 238.0672149658203
test loss item: 470.8184814453125
test loss item: 106.63775634765625
test loss item: 764.1487426757812
test loss item: 171.2996368408203
test loss item: 221.57728576660156
test loss item: 394.1563720703125
test loss item: 76.13226318359375
test loss item: 136.9359588623047
test loss item: 377.9566345214844
test loss item: 169.89016723632812
test loss item: 250.63186645507812
test loss item: 187.15399169921875
test loss item: 1265.6878662109375
test loss item: 175.43740844726562
test loss item: 340.31024169921875
test loss item: 1724.4617919921875
test loss item: 28.963336944580078
test loss item: 216.02886962890625
test loss item: 187.63551330566406
test loss item: 270.0807800292969
test loss item: 193.7791748046875
test loss item: 189.17726135253906
test loss item: 176.4593963623047
test loss item: 385.3144226074219
test loss item: 1327.7686767578125
test loss item: 197.02804565429688
test loss item: 177.32077026367188
test loss item: 251.93359375
test loss item: 331.6430358886719
test loss item: 251.57339477539062
test loss item: 170.888916015625
test loss item: 142.28721618652344
test loss item: 162.67970275878906
test loss item: 112.36874389648438
test loss item: 391.0885314941406
test loss item: 294.4483337402344
test loss item: 1991.3853759765625
test loss item: 26.390583038330078
test loss item: 254.71168518066406
test loss item: 218.69187927246094
test loss item: 1090.5208740234375
test loss item: 376.3138427734375
test loss item: 1481.40771484375
test loss item: 188.2561492919922
test loss item: 189.47454833984375
test loss item: 268.1427001953125
test loss item: 354.2879943847656
test loss item: 306.29754638671875
Epoch [2/10], Training Loss: 1.3144, Testing Loss: 416.1080
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7964559197425842
1
train loss item: 1.9164539575576782
2
train loss item: 0.4914293587207794
3
train loss item: 1.0187532901763916
4
train loss item: 1.1584614515304565
5
train loss item: 0.6224740743637085
6
train loss item: 0.5111649632453918
7
train loss item: 1.1942405700683594
8
train loss item: 0.4833643138408661
9
train loss item: 0.4539845883846283
10
train loss item: 0.6110211610794067
11
train loss item: 0.4189457595348358
12
train loss item: 0.3864139914512634
13
train loss item: 0.9050256609916687
14
train loss item: 0.5808258056640625
15
train loss item: 1.0991885662078857
16
train loss item: 0.3893755078315735
17
train loss item: 0.5358197093009949
18
train loss item: 0.6277730464935303
19
train loss item: 0.45866891741752625
20
train loss item: 0.44056186079978943
21
train loss item: 0.5438469648361206
22
train loss item: 1.5875545740127563
23
train loss item: 1.311381220817566
24
train loss item: 0.8389303088188171
25
train loss item: 0.5680174231529236
26
train loss item: 0.5187239646911621
27
train loss item: 0.5514217615127563
28
train loss item: 0.3835359215736389
29
train loss item: 1.335516333580017
30
train loss item: 2.904987096786499
31
train loss item: 0.9224701523780823
32
train loss item: 0.4165094196796417
33
train loss item: 0.8323606848716736
34
train loss item: 0.6988712549209595
35
train loss item: 2.8987181186676025
36
train loss item: 0.8292403221130371
37
train loss item: 0.42480412125587463
38
train loss item: 0.9086219668388367
39
train loss item: 0.5671680569648743
40
train loss item: 0.4864215850830078
41
train loss item: 0.5113524794578552
42
train loss item: 0.4147615432739258
43
train loss item: 0.503864586353302
44
train loss item: 1.0541573762893677
45
train loss item: 0.5304104685783386
46
train loss item: 0.5269127488136292
47
train loss item: 0.6658385396003723
48
train loss item: 0.5114231705665588
49
train loss item: 0.5182555317878723
50
train loss item: 0.43358439207077026
51
train loss item: 1.421248435974121
52
train loss item: 0.36023661494255066
53
train loss item: 0.5486335158348083
54
train loss item: 2.7745676040649414
55
train loss item: 0.532230794429779
56
train loss item: 0.5186665058135986
57
train loss item: 0.4975365102291107
58
train loss item: 0.48291459679603577
59
train loss item: 0.41723525524139404
60
train loss item: 1.522156000137329
61
train loss item: 2.795410394668579
62
train loss item: 0.44293272495269775
63
train loss item: 0.5582072138786316
64
train loss item: 0.5048189163208008
65
train loss item: 0.9101715683937073
66
train loss item: 0.6417673826217651
67
train loss item: 0.5198288559913635
68
train loss item: 0.5356034636497498
69
train loss item: 0.5900068879127502
70
train loss item: 0.5546663999557495
71
train loss item: 0.5127355456352234
72
train loss item: 0.5172411799430847
73
train loss item: 0.5207083821296692
74
train loss item: 0.48122572898864746
75
train loss item: 0.42484378814697266
76
train loss item: 1.3188378810882568
77
train loss item: 1.7620891332626343
78
train loss item: 0.36643823981285095
79
train loss item: 0.43722376227378845
80
train loss item: 0.5526209473609924
81
train loss item: 0.4490346312522888
82
train loss item: 0.5769686698913574
83
train loss item: 1.099683165550232
84
train loss item: 0.6078097820281982
85
train loss item: 0.9380335807800293
86
train loss item: 4.948439598083496
87
train loss item: 0.6036426424980164
88
train loss item: 0.5661624073982239
epoch train loss: 0.8327263288953332
testing phase
test loss item: 77.21778869628906
test loss item: 208.50421142578125
test loss item: 47.77352523803711
test loss item: 235.51731872558594
test loss item: 182.11798095703125
test loss item: 213.9215087890625
test loss item: 222.02711486816406
test loss item: 87.25261688232422
test loss item: 53.35943603515625
test loss item: 61.02340316772461
test loss item: 312.4098815917969
test loss item: 231.70742797851562
test loss item: 89.54730987548828
test loss item: 4.42367696762085
test loss item: 173.25010681152344
test loss item: 289.1364440917969
test loss item: 45.13939666748047
test loss item: 83.5167465209961
test loss item: 124.77787780761719
test loss item: 23.98427391052246
test loss item: 90.908203125
test loss item: 213.01943969726562
test loss item: 164.45269775390625
test loss item: 136.5330352783203
test loss item: 131.49227905273438
test loss item: 122.50988006591797
test loss item: 65.53367614746094
test loss item: 177.1501007080078
test loss item: 141.29454040527344
test loss item: 85.57294464111328
test loss item: 302.2391052246094
test loss item: 288.3783874511719
test loss item: 144.04776000976562
test loss item: 232.099853515625
test loss item: 176.452880859375
test loss item: 552.8222045898438
test loss item: 93.98589324951172
test loss item: 543.9161376953125
test loss item: 188.75015258789062
test loss item: 176.24600219726562
test loss item: 174.4817657470703
test loss item: 186.83718872070312
test loss item: 37.295745849609375
test loss item: 218.11570739746094
test loss item: 87.13880157470703
test loss item: 186.56300354003906
test loss item: 163.24313354492188
test loss item: 20.16522216796875
test loss item: 52.15702819824219
test loss item: 191.0410919189453
test loss item: 64.01798248291016
test loss item: 125.90208435058594
test loss item: 101.59657287597656
test loss item: 335.1656494140625
test loss item: 116.14768981933594
test loss item: 158.6660614013672
test loss item: 348.9639892578125
test loss item: 4.291358470916748
test loss item: 118.71106719970703
test loss item: 107.36035919189453
test loss item: 128.52496337890625
test loss item: 160.34283447265625
test loss item: 112.52493286132812
test loss item: 90.60031127929688
test loss item: 191.66241455078125
test loss item: 349.4522399902344
test loss item: 98.8329086303711
test loss item: 80.69192504882812
test loss item: 176.08963012695312
test loss item: 106.93560791015625
test loss item: 195.76907348632812
test loss item: 111.3395767211914
test loss item: 77.1908187866211
test loss item: 70.4561538696289
test loss item: 49.17377853393555
test loss item: 157.60121154785156
test loss item: 162.60433959960938
test loss item: 669.2105712890625
test loss item: 5.962140083312988
test loss item: 175.30136108398438
test loss item: 134.16542053222656
test loss item: 379.6590270996094
test loss item: 149.61219787597656
test loss item: 484.9559020996094
test loss item: 121.81741333007812
test loss item: 83.13935852050781
test loss item: 196.48019409179688
test loss item: 288.3746032714844
test loss item: 162.40072631835938
Epoch [3/10], Training Loss: 0.8327, Testing Loss: 165.8736
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.709123432636261
1
train loss item: 1.9657634496688843
2
train loss item: 0.5000889301300049
3
train loss item: 1.1529614925384521
4
train loss item: 1.2365509271621704
5
train loss item: 0.5506782531738281
6
train loss item: 0.5767817497253418
7
train loss item: 1.3263064622879028
8
train loss item: 0.6659162640571594
9
train loss item: 0.5278607606887817
10
train loss item: 0.6996232271194458
11
train loss item: 0.4170275032520294
12
train loss item: 0.432915598154068
13
train loss item: 0.8480802178382874
14
train loss item: 0.5367109179496765
15
train loss item: 0.9507414698600769
16
train loss item: 0.4766979515552521
17
train loss item: 0.5460578799247742
18
train loss item: 0.5886713266372681
19
train loss item: 0.4649198055267334
20
train loss item: 0.4338360130786896
21
train loss item: 0.45839133858680725
22
train loss item: 1.4093250036239624
23
train loss item: 1.3946943283081055
24
train loss item: 0.8080911040306091
25
train loss item: 0.431612104177475
26
train loss item: 0.5226308107376099
27
train loss item: 0.5555213689804077
28
train loss item: 0.49275803565979004
29
train loss item: 1.1389988660812378
30
train loss item: 3.1841647624969482
31
train loss item: 0.9783722162246704
32
train loss item: 0.5465304255485535
33
train loss item: 0.9233489036560059
34
train loss item: 0.5387077927589417
35
train loss item: 3.0640652179718018
36
train loss item: 0.7554970383644104
37
train loss item: 0.4328623116016388
38
train loss item: 0.8644354343414307
39
train loss item: 0.568266749382019
40
train loss item: 0.3991055488586426
41
train loss item: 0.5550557374954224
42
train loss item: 0.4180082380771637
43
train loss item: 0.5413540005683899
44
train loss item: 1.1137067079544067
45
train loss item: 0.5068544745445251
46
train loss item: 0.507759153842926
47
train loss item: 0.5719010233879089
48
train loss item: 0.514923095703125
49
train loss item: 0.4595623314380646
50
train loss item: 0.4906263053417206
51
train loss item: 1.3635722398757935
52
train loss item: 0.5539284348487854
53
train loss item: 0.46002376079559326
54
train loss item: 2.9592173099517822
55
train loss item: 0.5699785351753235
56
train loss item: 0.5645855069160461
57
train loss item: 0.498181015253067
58
train loss item: 0.5035938620567322
59
train loss item: 0.5185667872428894
60
train loss item: 1.367958664894104
61
train loss item: 3.005734443664551
62
train loss item: 0.48312562704086304
63
train loss item: 0.5321363210678101
64
train loss item: 0.5615054965019226
65
train loss item: 0.7630597949028015
66
train loss item: 0.6366426348686218
67
train loss item: 0.4929242730140686
68
train loss item: 0.4915876090526581
69
train loss item: 0.5484006404876709
70
train loss item: 0.464326947927475
71
train loss item: 0.46492263674736023
72
train loss item: 0.6935043931007385
73
train loss item: 0.47993430495262146
74
train loss item: 0.6734532713890076
75
train loss item: 0.48015597462654114
76
train loss item: 1.4055583477020264
77
train loss item: 1.6423330307006836
78
train loss item: 0.45913949608802795
79
train loss item: 0.44560879468917847
80
train loss item: 0.5420604348182678
81
train loss item: 0.41636255383491516
82
train loss item: 0.5060976147651672
83
train loss item: 0.9749600887298584
84
train loss item: 0.5251942873001099
85
train loss item: 1.0271364450454712
86
train loss item: 5.249999523162842
87
train loss item: 0.5360144972801208
88
train loss item: 0.5499196648597717
epoch train loss: 0.8445601048094503
testing phase
test loss item: 6.660935878753662
test loss item: 24.572599411010742
test loss item: 1.8816300630569458
test loss item: 15.636756896972656
test loss item: 20.379880905151367
test loss item: 24.810009002685547
test loss item: 8.808095932006836
test loss item: 4.127858638763428
test loss item: 4.2744622230529785
test loss item: 2.802062511444092
test loss item: 12.592875480651855
test loss item: 16.04220962524414
test loss item: 3.3028922080993652
test loss item: 0.3636178970336914
test loss item: 19.045166015625
test loss item: 36.084449768066406
test loss item: 1.4966766834259033
test loss item: 3.636437177658081
test loss item: 8.557174682617188
test loss item: 1.2040942907333374
test loss item: 8.61253547668457
test loss item: 11.08897590637207
test loss item: 9.043803215026855
test loss item: 13.963210105895996
test loss item: 11.813336372375488
test loss item: 10.755029678344727
test loss item: 4.903090953826904
test loss item: 19.74736976623535
test loss item: 14.714142799377441
test loss item: 3.869948625564575
test loss item: 13.102688789367676
test loss item: 36.08054733276367
test loss item: 15.000717163085938
test loss item: 11.8848876953125
test loss item: 20.135011672973633
test loss item: 27.186811447143555
test loss item: 2.567232847213745
test loss item: 20.833059310913086
test loss item: 9.151233673095703
test loss item: 19.78580093383789
test loss item: 20.000221252441406
test loss item: 11.983717918395996
test loss item: 2.0457167625427246
test loss item: 10.980056762695312
test loss item: 8.676756858825684
test loss item: 23.29848289489746
test loss item: 9.357924461364746
test loss item: 1.4813295602798462
test loss item: 0.7262448072433472
test loss item: 8.216689109802246
test loss item: 2.6947197914123535
test loss item: 12.094978332519531
test loss item: 7.204052448272705
test loss item: 17.732025146484375
test loss item: 9.657407760620117
test loss item: 4.905293941497803
test loss item: 16.52268409729004
test loss item: 0.49866342544555664
test loss item: 12.080366134643555
test loss item: 7.50446891784668
test loss item: 12.007767677307129
test loss item: 19.892839431762695
test loss item: 9.91112232208252
test loss item: 2.544482946395874
test loss item: 17.617774963378906
test loss item: 18.56720542907715
test loss item: 7.178098678588867
test loss item: 4.213913917541504
test loss item: 19.94830322265625
test loss item: 1.4496424198150635
test loss item: 24.0888614654541
test loss item: 12.18920612335205
test loss item: 8.134666442871094
test loss item: 5.30729866027832
test loss item: 4.271378517150879
test loss item: 8.73096752166748
test loss item: 17.73681640625
test loss item: 31.24643898010254
test loss item: 0.6571226119995117
test loss item: 19.971622467041016
test loss item: 15.365177154541016
test loss item: 18.052507400512695
test loss item: 3.682587146759033
test loss item: 21.838581085205078
test loss item: 10.503280639648438
test loss item: 7.6168646812438965
test loss item: 24.223745346069336
test loss item: 36.13582229614258
test loss item: 16.724477767944336
Epoch [4/10], Training Loss: 0.8446, Testing Loss: 12.2246
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.656474232673645
1
train loss item: 1.800570011138916
2
train loss item: 0.3560062646865845
3
train loss item: 0.9847120642662048
4
train loss item: 0.7940486073493958
5
train loss item: 0.5169562697410583
6
train loss item: 0.4104469120502472
7
train loss item: 1.1847126483917236
8
train loss item: 0.3739842176437378
9
train loss item: 0.40075042843818665
10
train loss item: 0.5523738861083984
11
train loss item: 0.3472879230976105
12
train loss item: 0.23801134526729584
13
train loss item: 0.7587170004844666
14
train loss item: 0.4528224468231201
15
train loss item: 0.9152129888534546
16
train loss item: 0.21535082161426544
17
train loss item: 0.40149834752082825
18
train loss item: 0.5005670785903931
19
train loss item: 0.37079182267189026
20
train loss item: 0.339496910572052
21
train loss item: 0.3335827589035034
22
train loss item: 1.3347214460372925
23
train loss item: 1.2491713762283325
24
train loss item: 0.7379628419876099
25
train loss item: 0.343426913022995
26
train loss item: 0.3759284019470215
27
train loss item: 0.4623745381832123
28
train loss item: 0.22934478521347046
29
train loss item: 1.0677324533462524
30
train loss item: 2.9919633865356445
31
train loss item: 0.8374354243278503
32
train loss item: 0.3214867413043976
33
train loss item: 0.7213915586471558
34
train loss item: 0.3950727581977844
35
train loss item: 2.934450387954712
36
train loss item: 0.6699051856994629
37
train loss item: 0.362498939037323
38
train loss item: 0.6967411041259766
39
train loss item: 0.4682409167289734
40
train loss item: 0.2849549651145935
41
train loss item: 0.45573320984840393
42
train loss item: 0.34396591782569885
43
train loss item: 0.3803582191467285
44
train loss item: 0.9998792409896851
45
train loss item: 0.2912740111351013
46
train loss item: 0.31111258268356323
47
train loss item: 0.48082560300827026
48
train loss item: 0.3996196687221527
49
train loss item: 0.3362523317337036
50
train loss item: 0.3792833089828491
51
train loss item: 1.28708815574646
52
train loss item: 0.26618140935897827
53
train loss item: 0.3198050260543823
54
train loss item: 2.8222036361694336
55
train loss item: 0.3625915050506592
56
train loss item: 0.4472717046737671
57
train loss item: 0.41129735112190247
58
train loss item: 0.3533138930797577
59
train loss item: 0.315391480922699
60
train loss item: 1.2785871028900146
61
train loss item: 2.816005229949951
62
train loss item: 0.3460095524787903
63
train loss item: 0.4680663049221039
64
train loss item: 0.36661478877067566
65
train loss item: 0.7488129734992981
66
train loss item: 0.5299195647239685
67
train loss item: 0.3824418783187866
68
train loss item: 0.397892028093338
69
train loss item: 0.46232062578201294
70
train loss item: 0.3831198215484619
71
train loss item: 0.28651097416877747
72
train loss item: 0.40339067578315735
73
train loss item: 0.4047895073890686
74
train loss item: 0.3277525305747986
75
train loss item: 0.26563137769699097
76
train loss item: 1.2581586837768555
77
train loss item: 1.5835521221160889
78
train loss item: 0.22450308501720428
79
train loss item: 0.36566492915153503
80
train loss item: 0.2943735122680664
81
train loss item: 0.33074724674224854
82
train loss item: 0.39640501141548157
83
train loss item: 0.8833985328674316
84
train loss item: 0.44848668575286865
85
train loss item: 0.9073538184165955
86
train loss item: 5.070106506347656
87
train loss item: 0.3438168466091156
88
train loss item: 0.4580044746398926
epoch train loss: 0.705450154589803
testing phase
test loss item: 3.071328639984131
test loss item: 13.616459846496582
test loss item: 0.766322910785675
test loss item: 8.478822708129883
test loss item: 11.728034019470215
test loss item: 14.323015213012695
test loss item: 5.163188934326172
test loss item: 2.049639940261841
test loss item: 1.9157134294509888
test loss item: 1.335042953491211
test loss item: 5.78125
test loss item: 8.631380081176758
test loss item: 1.5133655071258545
test loss item: 0.3845938444137573
test loss item: 10.16140365600586
test loss item: 20.250213623046875
test loss item: 0.39778637886047363
test loss item: 1.7710387706756592
test loss item: 4.0674519538879395
test loss item: 0.5138281583786011
test loss item: 4.286327838897705
test loss item: 6.113883972167969
test loss item: 5.429311275482178
test loss item: 7.5079264640808105
test loss item: 6.196392059326172
test loss item: 5.139895915985107
test loss item: 2.209871292114258
test loss item: 11.417559623718262
test loss item: 7.8815836906433105
test loss item: 1.7962192296981812
test loss item: 5.86696720123291
test loss item: 20.271381378173828
test loss item: 8.076258659362793
test loss item: 6.431876182556152
test loss item: 11.261919021606445
test loss item: 15.3003511428833
test loss item: 1.487786054611206
test loss item: 9.078228950500488
test loss item: 4.998075485229492
test loss item: 11.498032569885254
test loss item: 11.209548950195312
test loss item: 6.728250980377197
test loss item: 0.576207160949707
test loss item: 5.94780158996582
test loss item: 4.320725440979004
test loss item: 13.082039833068848
test loss item: 5.596370697021484
test loss item: 0.6087355613708496
test loss item: 0.5747856497764587
test loss item: 3.528599739074707
test loss item: 1.3609898090362549
test loss item: 6.32827615737915
test loss item: 3.4859979152679443
test loss item: 9.641182899475098
test loss item: 4.712542533874512
test loss item: 2.2052555084228516
test loss item: 9.41608715057373
test loss item: 0.5202631950378418
test loss item: 6.324753284454346
test loss item: 3.647731304168701
test loss item: 6.284181594848633
test loss item: 11.170061111450195
test loss item: 4.825756072998047
test loss item: 1.1522243022918701
test loss item: 10.386116027832031
test loss item: 10.110651969909668
test loss item: 3.515901565551758
test loss item: 1.9858249425888062
test loss item: 11.189913749694824
test loss item: 0.5962303280830383
test loss item: 13.457640647888184
test loss item: 6.479706764221191
test loss item: 4.081705093383789
test loss item: 2.5419602394104004
test loss item: 1.9210329055786133
test loss item: 5.3153157234191895
test loss item: 9.452017784118652
test loss item: 14.854684829711914
test loss item: 0.5530092716217041
test loss item: 11.683941841125488
test loss item: 8.03640365600586
test loss item: 9.62680435180664
test loss item: 1.615204930305481
test loss item: 10.97773551940918
test loss item: 5.195173263549805
test loss item: 3.451070547103882
test loss item: 13.525443077087402
test loss item: 20.28662109375
test loss item: 7.902615547180176
Epoch [5/10], Training Loss: 0.7055, Testing Loss: 6.5187
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6391021013259888
1
train loss item: 1.639237403869629
2
train loss item: 0.3429358899593353
3
train loss item: 0.8170899152755737
4
train loss item: 0.8759848475456238
5
train loss item: 0.5290408730506897
6
train loss item: 0.4101920425891876
7
train loss item: 1.0658186674118042
8
train loss item: 0.26959893107414246
9
train loss item: 0.3823898136615753
10
train loss item: 0.47453051805496216
11
train loss item: 0.3356063663959503
12
train loss item: 0.22082394361495972
13
train loss item: 0.715194582939148
14
train loss item: 0.45310723781585693
15
train loss item: 0.9170725345611572
16
train loss item: 0.21727128326892853
17
train loss item: 0.443759560585022
18
train loss item: 0.4572056829929352
19
train loss item: 0.35876598954200745
20
train loss item: 0.4018152952194214
21
train loss item: 0.35585108399391174
22
train loss item: 1.2967512607574463
23
train loss item: 1.1396089792251587
24
train loss item: 0.7108457684516907
25
train loss item: 0.37744468450546265
26
train loss item: 0.346173495054245
27
train loss item: 0.41993069648742676
28
train loss item: 0.21642859280109406
29
train loss item: 1.0451557636260986
30
train loss item: 2.7841145992279053
31
train loss item: 0.7351086139678955
32
train loss item: 0.25223472714424133
33
train loss item: 0.5859820246696472
34
train loss item: 0.44728970527648926
35
train loss item: 2.8024649620056152
36
train loss item: 0.6331271529197693
37
train loss item: 0.37587955594062805
38
train loss item: 0.5830286145210266
39
train loss item: 0.4266641438007355
40
train loss item: 0.30784645676612854
41
train loss item: 0.41317030787467957
42
train loss item: 0.326049268245697
43
train loss item: 0.32871609926223755
44
train loss item: 0.9131677746772766
45
train loss item: 0.25549009442329407
46
train loss item: 0.2909756600856781
47
train loss item: 0.49238601326942444
48
train loss item: 0.37482908368110657
49
train loss item: 0.3591698706150055
50
train loss item: 0.3830867111682892
51
train loss item: 1.2194278240203857
52
train loss item: 0.2368331104516983
53
train loss item: 0.3582583963871002
54
train loss item: 2.6812329292297363
55
train loss item: 0.29224202036857605
56
train loss item: 0.3967297673225403
57
train loss item: 0.35435381531715393
58
train loss item: 0.31150022149086
59
train loss item: 0.2473878562450409
60
train loss item: 1.221575140953064
61
train loss item: 2.634248971939087
62
train loss item: 0.31760451197624207
63
train loss item: 0.4348480999469757
64
train loss item: 0.26101043820381165
65
train loss item: 0.8097649812698364
66
train loss item: 0.4778249263763428
67
train loss item: 0.3611967861652374
68
train loss item: 0.4068447947502136
69
train loss item: 0.4374018609523773
70
train loss item: 0.4210388660430908
71
train loss item: 0.31726300716400146
72
train loss item: 0.2916499376296997
73
train loss item: 0.41536420583724976
74
train loss item: 0.28455474972724915
75
train loss item: 0.2291453778743744
76
train loss item: 1.1371147632598877
77
train loss item: 1.5442936420440674
78
train loss item: 0.2193654328584671
79
train loss item: 0.3264850974082947
80
train loss item: 0.2573302090167999
81
train loss item: 0.3570981025695801
82
train loss item: 0.3807446360588074
83
train loss item: 0.8334577679634094
84
train loss item: 0.4304877519607544
85
train loss item: 0.8020942807197571
86
train loss item: 4.863773822784424
87
train loss item: 0.3696031868457794
88
train loss item: 0.4246833622455597
epoch train loss: 0.666419661781761
testing phase
test loss item: 1.0577601194381714
test loss item: 6.423574447631836
test loss item: 0.738946795463562
test loss item: 2.736870765686035
test loss item: 5.11063814163208
test loss item: 6.373239994049072
test loss item: 1.9180032014846802
test loss item: 1.0632487535476685
test loss item: 0.5858234763145447
test loss item: 0.5959168672561646
test loss item: 1.1751071214675903
test loss item: 3.2047810554504395
test loss item: 0.4170583188533783
test loss item: 0.39405715465545654
test loss item: 4.659904479980469
test loss item: 9.764897346496582
test loss item: 0.33457109332084656
test loss item: 0.8795017004013062
test loss item: 1.8737934827804565
test loss item: 0.35690394043922424
test loss item: 1.9777753353118896
test loss item: 0.6255561709403992
test loss item: 0.9696524143218994
test loss item: 3.2449235916137695
test loss item: 2.9471442699432373
test loss item: 1.8828257322311401
test loss item: 0.7259348034858704
test loss item: 4.918213844299316
test loss item: 3.431366205215454
test loss item: 0.6244915127754211
test loss item: 1.2293422222137451
test loss item: 9.792121887207031
test loss item: 3.55519700050354
test loss item: 0.8820112943649292
test loss item: 5.4340081214904785
test loss item: 1.1870065927505493
test loss item: 1.0405278205871582
test loss item: 1.843719720840454
test loss item: 0.8246949911117554
test loss item: 5.018078327178955
test loss item: 5.40544319152832
test loss item: 1.7435706853866577
test loss item: 0.5188847184181213
test loss item: 0.5094870328903198
test loss item: 1.9160690307617188
test loss item: 6.3292365074157715
test loss item: 1.177905797958374
test loss item: 0.3521985709667206
test loss item: 0.6013098955154419
test loss item: 1.5166527032852173
test loss item: 0.6215004324913025
test loss item: 2.9691545963287354
test loss item: 1.2319600582122803
test loss item: 0.7340617179870605
test loss item: 1.6915589570999146
test loss item: 1.2955483198165894
test loss item: 1.024769902229309
test loss item: 0.5201119780540466
test loss item: 3.0063998699188232
test loss item: 1.3089962005615234
test loss item: 2.996319055557251
test loss item: 5.400940895080566
test loss item: 1.8506605625152588
test loss item: 0.33278852701187134
test loss item: 4.632922172546387
test loss item: 0.8337852358818054
test loss item: 1.226503849029541
test loss item: 0.7690749168395996
test loss item: 5.442905426025391
test loss item: 0.5375396013259888
test loss item: 6.468523979187012
test loss item: 3.2508678436279297
test loss item: 1.7632659673690796
test loss item: 1.058266520500183
test loss item: 0.8058069348335266
test loss item: 0.8926787376403809
test loss item: 4.29213809967041
test loss item: 2.0139477252960205
test loss item: 0.5588880181312561
test loss item: 5.070672988891602
test loss item: 3.805269241333008
test loss item: 2.045292854309082
test loss item: 1.0300495624542236
test loss item: 1.3429975509643555
test loss item: 1.942524790763855
test loss item: 1.3618927001953125
test loss item: 6.502540588378906
test loss item: 9.78781795501709
test loss item: 3.348339080810547
Epoch [6/10], Training Loss: 0.6664, Testing Loss: 2.4456
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6200348138809204
1
train loss item: 1.5878140926361084
2
train loss item: 0.30962854623794556
3
train loss item: 0.7607928514480591
4
train loss item: 0.7289098501205444
5
train loss item: 0.49888530373573303
6
train loss item: 0.3654206395149231
7
train loss item: 1.041635513305664
8
train loss item: 0.27968597412109375
9
train loss item: 0.36295023560523987
10
train loss item: 0.4526933431625366
11
train loss item: 0.3411499857902527
12
train loss item: 0.21076549589633942
13
train loss item: 0.6858928203582764
14
train loss item: 0.4469723701477051
15
train loss item: 0.8926098942756653
16
train loss item: 0.20899783074855804
17
train loss item: 0.4274754524230957
18
train loss item: 0.44106000661849976
19
train loss item: 0.3483508229255676
20
train loss item: 0.36577534675598145
21
train loss item: 0.3057040274143219
22
train loss item: 1.2707300186157227
23
train loss item: 1.114900827407837
24
train loss item: 0.6722890138626099
25
train loss item: 0.38819509744644165
26
train loss item: 0.30865904688835144
27
train loss item: 0.39234593510627747
28
train loss item: 0.20561067759990692
29
train loss item: 1.014880895614624
30
train loss item: 2.728942632675171
31
train loss item: 0.6982608437538147
32
train loss item: 0.2306569516658783
33
train loss item: 0.5514926910400391
34
train loss item: 0.37383994460105896
35
train loss item: 2.764580249786377
36
train loss item: 0.6078891158103943
37
train loss item: 0.38241904973983765
38
train loss item: 0.5403754711151123
39
train loss item: 0.4061603844165802
40
train loss item: 0.31226757168769836
41
train loss item: 0.388174831867218
42
train loss item: 0.31501081585884094
43
train loss item: 0.2810392379760742
44
train loss item: 0.8784637451171875
45
train loss item: 0.23178768157958984
46
train loss item: 0.27487507462501526
47
train loss item: 0.4966577887535095
48
train loss item: 0.34777504205703735
49
train loss item: 0.3331131041049957
50
train loss item: 0.3854750692844391
51
train loss item: 1.177057147026062
52
train loss item: 0.24048033356666565
53
train loss item: 0.3451857268810272
54
train loss item: 2.6438279151916504
55
train loss item: 0.27836570143699646
56
train loss item: 0.37398797273635864
57
train loss item: 0.3433571755886078
58
train loss item: 0.2655278444290161
59
train loss item: 0.24475479125976562
60
train loss item: 1.183359980583191
61
train loss item: 2.592615842819214
62
train loss item: 0.29556283354759216
63
train loss item: 0.4284267723560333
64
train loss item: 0.23731876909732819
65
train loss item: 0.7699821591377258
66
train loss item: 0.46071115136146545
67
train loss item: 0.34364795684814453
68
train loss item: 0.40302079916000366
69
train loss item: 0.42139172554016113
70
train loss item: 0.42172276973724365
71
train loss item: 0.2839595675468445
72
train loss item: 0.2946137487888336
73
train loss item: 0.3977304697036743
74
train loss item: 0.2731129229068756
75
train loss item: 0.21266888082027435
76
train loss item: 1.1076081991195679
77
train loss item: 1.5221227407455444
78
train loss item: 0.20804841816425323
79
train loss item: 0.33172351121902466
80
train loss item: 0.21839678287506104
81
train loss item: 0.351632297039032
82
train loss item: 0.35612407326698303
83
train loss item: 0.7959581613540649
84
train loss item: 0.4223528504371643
85
train loss item: 0.7818775177001953
86
train loss item: 4.81502628326416
87
train loss item: 0.36651235818862915
88
train loss item: 0.4054528772830963
epoch train loss: 0.6426438320888562
testing phase
test loss item: 0.38802918791770935
test loss item: 2.638472557067871
test loss item: 0.8028857707977295
test loss item: 1.1304597854614258
test loss item: 1.9914606809616089
test loss item: 2.5254814624786377
test loss item: 1.858605980873108
test loss item: 0.7784498333930969
test loss item: 0.34693431854248047
test loss item: 0.5310851335525513
test loss item: 1.1863532066345215
test loss item: 1.3871040344238281
test loss item: 0.2529720664024353
test loss item: 0.3968346416950226
test loss item: 1.9261783361434937
test loss item: 4.072983264923096
test loss item: 0.3446253836154938
test loss item: 0.6820122599601746
test loss item: 1.0552799701690674
test loss item: 0.3478519916534424
test loss item: 1.216528058052063
test loss item: 0.4789900481700897
test loss item: 0.5273367762565613
test loss item: 1.2767524719238281
test loss item: 1.3058103322982788
test loss item: 0.6191486120223999
test loss item: 0.4469981789588928
test loss item: 1.8791481256484985
test loss item: 1.3761194944381714
test loss item: 0.4580228924751282
test loss item: 1.059882640838623
test loss item: 4.075713157653809
test loss item: 1.4277174472808838
test loss item: 0.7825371026992798
test loss item: 2.334413766860962
test loss item: 0.6355734467506409
test loss item: 1.0061211585998535
test loss item: 2.0283632278442383
test loss item: 0.6701406240463257
test loss item: 1.9582297801971436
test loss item: 2.2746853828430176
test loss item: 0.6762394905090332
test loss item: 0.5227820873260498
test loss item: 0.31175047159194946
test loss item: 1.036473035812378
test loss item: 2.680877923965454
test loss item: 0.5868505835533142
test loss item: 0.3146210312843323
test loss item: 0.6489301919937134
test loss item: 0.9907814860343933
test loss item: 0.48242461681365967
test loss item: 1.2903096675872803
test loss item: 0.4576944410800934
test loss item: 0.36245375871658325
test loss item: 0.6315300464630127
test loss item: 1.1982518434524536
test loss item: 0.7417598366737366
test loss item: 0.4651305675506592
test loss item: 1.3233507871627808
test loss item: 0.472339391708374
test loss item: 1.396726369857788
test loss item: 2.2687134742736816
test loss item: 0.6518427133560181
test loss item: 0.3054821193218231
test loss item: 2.079056739807129
test loss item: 0.4699942171573639
test loss item: 0.4806821346282959
test loss item: 0.4006553292274475
test loss item: 2.3732693195343018
test loss item: 0.6267842650413513
test loss item: 2.69112491607666
test loss item: 1.7159141302108765
test loss item: 0.7528160214424133
test loss item: 0.5421473383903503
test loss item: 0.37436091899871826
test loss item: 0.4037238657474518
test loss item: 1.767109990119934
test loss item: 2.100757360458374
test loss item: 0.5692365169525146
test loss item: 1.9615751504898071
test loss item: 1.6378083229064941
test loss item: 1.4287892580032349
test loss item: 1.0867952108383179
test loss item: 1.4523329734802246
test loss item: 0.6630635261535645
test loss item: 0.5294273495674133
test loss item: 2.728236436843872
test loss item: 4.107785224914551
test loss item: 1.2903923988342285
Epoch [7/10], Training Loss: 0.6426, Testing Loss: 1.1970
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5896019339561462
1
train loss item: 1.5669695138931274
2
train loss item: 0.275022953748703
3
train loss item: 0.7576500773429871
4
train loss item: 0.5000334978103638
5
train loss item: 0.4450802206993103
6
train loss item: 0.3177390992641449
7
train loss item: 1.042942762374878
8
train loss item: 0.21291495859622955
9
train loss item: 0.33961227536201477
10
train loss item: 0.44778215885162354
11
train loss item: 0.3426865339279175
12
train loss item: 0.16707101464271545
13
train loss item: 0.6555853486061096
14
train loss item: 0.40928974747657776
15
train loss item: 0.8271281719207764
16
train loss item: 0.15081429481506348
17
train loss item: 0.37051695585250854
18
train loss item: 0.42283838987350464
19
train loss item: 0.3267977833747864
20
train loss item: 0.29750242829322815
21
train loss item: 0.21111343801021576
22
train loss item: 1.2241815328598022
23
train loss item: 1.1238276958465576
24
train loss item: 0.641627311706543
25
train loss item: 0.31667542457580566
26
train loss item: 0.2559838593006134
27
train loss item: 0.3665471374988556
28
train loss item: 0.14347729086875916
29
train loss item: 0.9605110287666321
30
train loss item: 2.728264093399048
31
train loss item: 0.689106822013855
32
train loss item: 0.19447310268878937
33
train loss item: 0.5526072978973389
34
train loss item: 0.24949078261852264
35
train loss item: 2.7583937644958496
36
train loss item: 0.5777360200881958
37
train loss item: 0.37219157814979553
38
train loss item: 0.5280889868736267
39
train loss item: 0.3831784725189209
40
train loss item: 0.23187753558158875
41
train loss item: 0.36684951186180115
42
train loss item: 0.2955248951911926
43
train loss item: 0.23407746851444244
44
train loss item: 0.8678393363952637
45
train loss item: 0.20247985422611237
46
train loss item: 0.21737174689769745
47
train loss item: 0.4609992802143097
48
train loss item: 0.3071005642414093
49
train loss item: 0.2663955092430115
50
train loss item: 0.3653506636619568
51
train loss item: 1.1346079111099243
52
train loss item: 0.18458855152130127
53
train loss item: 0.2611144185066223
54
train loss item: 2.6432080268859863
55
train loss item: 0.24771153926849365
56
train loss item: 0.3527018129825592
57
train loss item: 0.32428672909736633
58
train loss item: 0.21555012464523315
59
train loss item: 0.22079895436763763
60
train loss item: 1.136268138885498
61
train loss item: 2.5963563919067383
62
train loss item: 0.25610390305519104
63
train loss item: 0.4248197674751282
64
train loss item: 0.2218853235244751
65
train loss item: 0.6889586448669434
66
train loss item: 0.454006165266037
67
train loss item: 0.312532901763916
68
train loss item: 0.36940839886665344
69
train loss item: 0.39950332045555115
70
train loss item: 0.3722383379936218
71
train loss item: 0.21259087324142456
72
train loss item: 0.2604232430458069
73
train loss item: 0.3665773868560791
74
train loss item: 0.15940728783607483
75
train loss item: 0.16761913895606995
76
train loss item: 1.1102919578552246
77
train loss item: 1.4903334379196167
78
train loss item: 0.1527608186006546
79
train loss item: 0.3363053500652313
80
train loss item: 0.16168056428432465
81
train loss item: 0.27716735005378723
82
train loss item: 0.3117416501045227
83
train loss item: 0.7503841519355774
84
train loss item: 0.40466344356536865
85
train loss item: 0.7871677279472351
86
train loss item: 4.825435638427734
87
train loss item: 0.2738678455352783
88
train loss item: 0.38576844334602356
epoch train loss: 0.6046040202124735
testing phase
test loss item: 0.27669718861579895
test loss item: 1.078012228012085
test loss item: 0.790270209312439
test loss item: 0.5125621557235718
test loss item: 0.828741192817688
test loss item: 1.023531436920166
test loss item: 1.7232950925827026
test loss item: 0.6646913886070251
test loss item: 0.34161749482154846
test loss item: 0.5123708844184875
test loss item: 1.2161338329315186
test loss item: 0.6336113810539246
test loss item: 0.2543029189109802
test loss item: 0.3861972391605377
test loss item: 0.8217871785163879
test loss item: 1.6871647834777832
test loss item: 0.3453383445739746
test loss item: 0.6084635257720947
test loss item: 0.8367019295692444
test loss item: 0.34448134899139404
test loss item: 1.0157572031021118
test loss item: 0.429059773683548
test loss item: 0.4130118787288666
test loss item: 0.5208942294120789
test loss item: 0.6360872983932495
test loss item: 0.319827139377594
test loss item: 0.43587473034858704
test loss item: 0.7399809956550598
test loss item: 0.6529534459114075
test loss item: 0.4373115003108978
test loss item: 1.0245121717453003
test loss item: 1.6786831617355347
test loss item: 0.5916963219642639
test loss item: 0.7244318127632141
test loss item: 1.0945817232131958
test loss item: 0.6026443839073181
test loss item: 0.947495698928833
test loss item: 2.0690126419067383
test loss item: 0.616271436214447
test loss item: 0.8064404726028442
test loss item: 0.9871841073036194
test loss item: 0.32112061977386475
test loss item: 0.4826173484325409
test loss item: 0.2536598742008209
test loss item: 0.8263952732086182
test loss item: 1.2001404762268066
test loss item: 0.42430728673934937
test loss item: 0.2958933711051941
test loss item: 0.6325905919075012
test loss item: 0.9359835386276245
test loss item: 0.434194952249527
test loss item: 0.6010643839836121
test loss item: 0.3198092579841614
test loss item: 0.23071736097335815
test loss item: 0.4273920953273773
test loss item: 1.1911685466766357
test loss item: 0.7058222889900208
test loss item: 0.37593692541122437
test loss item: 0.6416557431221008
test loss item: 0.3066354990005493
test loss item: 0.7921770215034485
test loss item: 0.9733605980873108
test loss item: 0.3140491247177124
test loss item: 0.30573657155036926
test loss item: 1.293429970741272
test loss item: 0.3530803620815277
test loss item: 0.3843154013156891
test loss item: 0.3349571228027344
test loss item: 1.1772863864898682
test loss item: 0.6224725842475891
test loss item: 1.1189714670181274
test loss item: 1.1690607070922852
test loss item: 0.45892128348350525
test loss item: 0.4404182732105255
test loss item: 0.2770061492919922
test loss item: 0.27615267038345337
test loss item: 0.7520979046821594
test loss item: 2.120776414871216
test loss item: 0.5603277087211609
test loss item: 0.7898563742637634
test loss item: 0.7412807941436768
test loss item: 1.2947156429290771
test loss item: 1.0514981746673584
test loss item: 1.4762682914733887
test loss item: 0.3255215585231781
test loss item: 0.3454250395298004
test loss item: 1.1538242101669312
test loss item: 1.7221826314926147
test loss item: 0.5338242650032043
Epoch [8/10], Training Loss: 0.6046, Testing Loss: 0.7348
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5521730184555054
1
train loss item: 1.5158112049102783
2
train loss item: 0.26129990816116333
3
train loss item: 0.7409176826477051
4
train loss item: 0.5277368426322937
5
train loss item: 0.4097363352775574
6
train loss item: 0.33950114250183105
7
train loss item: 1.021833062171936
8
train loss item: 0.2031938135623932
9
train loss item: 0.3324856162071228
10
train loss item: 0.43773865699768066
11
train loss item: 0.3439837694168091
12
train loss item: 0.14943818747997284
13
train loss item: 0.6185780167579651
14
train loss item: 0.3742477595806122
15
train loss item: 0.7508236169815063
16
train loss item: 0.12368039041757584
17
train loss item: 0.3453804552555084
18
train loss item: 0.3966441750526428
19
train loss item: 0.33292582631111145
20
train loss item: 0.2885774075984955
21
train loss item: 0.18596595525741577
22
train loss item: 1.1499179601669312
23
train loss item: 1.1138800382614136
24
train loss item: 0.6238185167312622
25
train loss item: 0.2585318982601166
26
train loss item: 0.24455298483371735
27
train loss item: 0.3443317711353302
28
train loss item: 0.11950286477804184
29
train loss item: 0.8864395618438721
30
train loss item: 2.6945712566375732
31
train loss item: 0.6759207844734192
32
train loss item: 0.16633105278015137
33
train loss item: 0.5380774140357971
34
train loss item: 0.2006891667842865
35
train loss item: 2.735907793045044
36
train loss item: 0.5469059348106384
37
train loss item: 0.3857266306877136
38
train loss item: 0.5134600400924683
39
train loss item: 0.35153988003730774
40
train loss item: 0.19509027898311615
41
train loss item: 0.3482166528701782
42
train loss item: 0.2848406434059143
43
train loss item: 0.222715362906456
44
train loss item: 0.8414042592048645
45
train loss item: 0.18940964341163635
46
train loss item: 0.18272116780281067
47
train loss item: 0.4206703007221222
48
train loss item: 0.28064823150634766
49
train loss item: 0.2205566018819809
50
train loss item: 0.35945838689804077
51
train loss item: 1.074734091758728
52
train loss item: 0.15915103256702423
53
train loss item: 0.21116513013839722
54
train loss item: 2.6221797466278076
55
train loss item: 0.2519567012786865
56
train loss item: 0.33411771059036255
57
train loss item: 0.3126453161239624
58
train loss item: 0.2049228399991989
59
train loss item: 0.20154765248298645
60
train loss item: 1.0695714950561523
61
train loss item: 2.571047306060791
62
train loss item: 0.242630735039711
63
train loss item: 0.4166107475757599
64
train loss item: 0.21152804791927338
65
train loss item: 0.6295230388641357
66
train loss item: 0.4487422704696655
67
train loss item: 0.2918448746204376
68
train loss item: 0.35290709137916565
69
train loss item: 0.38559573888778687
70
train loss item: 0.3261766731739044
71
train loss item: 0.19315367937088013
72
train loss item: 0.26301756501197815
73
train loss item: 0.3552144467830658
74
train loss item: 0.14239391684532166
75
train loss item: 0.14232061803340912
76
train loss item: 1.0946272611618042
77
train loss item: 1.4378310441970825
78
train loss item: 0.12322688847780228
79
train loss item: 0.33847975730895996
80
train loss item: 0.1513366550207138
81
train loss item: 0.2308666855096817
82
train loss item: 0.2768087685108185
83
train loss item: 0.6950972080230713
84
train loss item: 0.39441242814064026
85
train loss item: 0.7680115103721619
86
train loss item: 4.805697441101074
87
train loss item: 0.23141565918922424
88
train loss item: 0.3809422254562378
epoch train loss: 0.5808085609185561
testing phase
test loss item: 0.2425144761800766
test loss item: 0.36953434348106384
test loss item: 0.702391505241394
test loss item: 0.34074866771698
test loss item: 0.400704562664032
test loss item: 0.3693374693393707
test loss item: 1.6047214269638062
test loss item: 0.5535365343093872
test loss item: 0.30182215571403503
test loss item: 0.46622657775878906
test loss item: 1.1279726028442383
test loss item: 0.3436901271343231
test loss item: 0.23544204235076904
test loss item: 0.3783043622970581
test loss item: 0.3442925214767456
test loss item: 0.542753279209137
test loss item: 0.32524362206459045
test loss item: 0.5378843545913696
test loss item: 0.7295980453491211
test loss item: 0.3279336988925934
test loss item: 0.8701073527336121
test loss item: 0.42973145842552185
test loss item: 0.3533802330493927
test loss item: 0.27206864953041077
test loss item: 0.33238694071769714
test loss item: 0.2809692919254303
test loss item: 0.41088637709617615
test loss item: 0.32532185316085815
test loss item: 0.4373731017112732
test loss item: 0.40859487652778625
test loss item: 0.9381274580955505
test loss item: 0.5327112674713135
test loss item: 0.27522167563438416
test loss item: 0.6765502691268921
test loss item: 0.5851287841796875
test loss item: 0.5549617409706116
test loss item: 0.8618279099464417
test loss item: 1.9022084474563599
test loss item: 0.577060878276825
test loss item: 0.3913119435310364
test loss item: 0.43585675954818726
test loss item: 0.22795207798480988
test loss item: 0.4208841323852539
test loss item: 0.2824125587940216
test loss item: 0.7152206301689148
test loss item: 0.593702495098114
test loss item: 0.3602046072483063
test loss item: 0.2849975526332855
test loss item: 0.5645005702972412
test loss item: 0.8675161600112915
test loss item: 0.37631353735923767
test loss item: 0.27943697571754456
test loss item: 0.2813950777053833
test loss item: 0.3210108280181885
test loss item: 0.3667265772819519
test loss item: 1.0877907276153564
test loss item: 0.6461650133132935
test loss item: 0.30131110548973083
test loss item: 0.3410389721393585
test loss item: 0.2660478949546814
test loss item: 0.548910915851593
test loss item: 0.3940275013446808
test loss item: 0.2525935769081116
test loss item: 0.29551002383232117
test loss item: 1.0037236213684082
test loss item: 0.42028436064720154
test loss item: 0.35607388615608215
test loss item: 0.3170929253101349
test loss item: 0.7141545414924622
test loss item: 0.5385869741439819
test loss item: 0.38545799255371094
test loss item: 0.9516217112541199
test loss item: 0.37509268522262573
test loss item: 0.41593804955482483
test loss item: 0.24451640248298645
test loss item: 0.23969106376171112
test loss item: 0.32728010416030884
test loss item: 1.9312973022460938
test loss item: 0.53983074426651
test loss item: 0.3343436121940613
test loss item: 0.31489360332489014
test loss item: 1.160757303237915
test loss item: 0.9598540663719177
test loss item: 1.3406567573547363
test loss item: 0.26706889271736145
test loss item: 0.3095749318599701
test loss item: 0.4138340651988983
test loss item: 0.5705482959747314
test loss item: 0.2502743899822235
Epoch [9/10], Training Loss: 0.5808, Testing Loss: 0.5265
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5248295068740845
1
train loss item: 1.4347851276397705
2
train loss item: 0.26269465684890747
3
train loss item: 0.6879634857177734
4
train loss item: 0.5181117057800293
5
train loss item: 0.40478211641311646
6
train loss item: 0.34585192799568176
7
train loss item: 0.9721053838729858
8
train loss item: 0.19618552923202515
9
train loss item: 0.3178766071796417
10
train loss item: 0.41107049584388733
11
train loss item: 0.34449484944343567
12
train loss item: 0.1549699455499649
13
train loss item: 0.5770439505577087
14
train loss item: 0.36042091250419617
15
train loss item: 0.6927936673164368
16
train loss item: 0.12581202387809753
17
train loss item: 0.33480221033096313
18
train loss item: 0.37775835394859314
19
train loss item: 0.3432520627975464
20
train loss item: 0.29117265343666077
21
train loss item: 0.19779179990291595
22
train loss item: 1.0760868787765503
23
train loss item: 1.0659688711166382
24
train loss item: 0.6130269765853882
25
train loss item: 0.2518022954463959
26
train loss item: 0.2555457055568695
27
train loss item: 0.3360038101673126
28
train loss item: 0.12231921404600143
29
train loss item: 0.8174635767936707
30
train loss item: 2.6052162647247314
31
train loss item: 0.65252685546875
32
train loss item: 0.15413986146450043
33
train loss item: 0.4864993989467621
34
train loss item: 0.1958235204219818
35
train loss item: 2.676034927368164
36
train loss item: 0.5228974223136902
37
train loss item: 0.41367360949516296
38
train loss item: 0.4981403052806854
39
train loss item: 0.3173607289791107
40
train loss item: 0.20021800696849823
41
train loss item: 0.34083014726638794
42
train loss item: 0.2850470244884491
43
train loss item: 0.22232207655906677
44
train loss item: 0.7956061363220215
45
train loss item: 0.17727313935756683
46
train loss item: 0.16787058115005493
47
train loss item: 0.3959692418575287
48
train loss item: 0.28605350852012634
49
train loss item: 0.20475980639457703
50
train loss item: 0.3609507977962494
51
train loss item: 1.0067665576934814
52
train loss item: 0.14309647679328918
53
train loss item: 0.20007263123989105
54
train loss item: 2.5584263801574707
55
train loss item: 0.25631842017173767
56
train loss item: 0.32229509949684143
57
train loss item: 0.3171294033527374
58
train loss item: 0.21410219371318817
59
train loss item: 0.18576781451702118
60
train loss item: 0.9972485899925232
61
train loss item: 2.4980804920196533
62
train loss item: 0.2666541039943695
63
train loss item: 0.40292519330978394
64
train loss item: 0.19677278399467468
65
train loss item: 0.6114200949668884
66
train loss item: 0.44322845339775085
67
train loss item: 0.2765415608882904
68
train loss item: 0.3497740626335144
69
train loss item: 0.38033923506736755
70
train loss item: 0.306244820356369
71
train loss item: 0.20073193311691284
72
train loss item: 0.24088522791862488
73
train loss item: 0.3561534285545349
74
train loss item: 0.15549063682556152
75
train loss item: 0.13656459748744965
76
train loss item: 1.0451632738113403
77
train loss item: 1.381029725074768
78
train loss item: 0.12061396986246109
79
train loss item: 0.3366530239582062
80
train loss item: 0.15221266448497772
81
train loss item: 0.25103703141212463
82
train loss item: 0.26475560665130615
83
train loss item: 0.645088791847229
84
train loss item: 0.40388813614845276
85
train loss item: 0.7186697721481323
86
train loss item: 4.717405319213867
87
train loss item: 0.23205703496932983
88
train loss item: 0.3911639451980591
epoch train loss: 0.5624355971813202
testing phase
test loss item: 0.2081131637096405
test loss item: 0.19806954264640808
test loss item: 0.6187737584114075
test loss item: 0.29102036356925964
test loss item: 0.3126610219478607
test loss item: 0.23360416293144226
test loss item: 1.5366567373275757
test loss item: 0.4853909909725189
test loss item: 0.25515085458755493
test loss item: 0.43276315927505493
test loss item: 1.0078922510147095
test loss item: 0.26891931891441345
test loss item: 0.20621442794799805
test loss item: 0.38814207911491394
test loss item: 0.23014582693576813
test loss item: 0.24921511113643646
test loss item: 0.30595067143440247
test loss item: 0.4921885132789612
test loss item: 0.678895890712738
test loss item: 0.3117353618144989
test loss item: 0.7858961820602417
test loss item: 0.4013650417327881
test loss item: 0.32876113057136536
test loss item: 0.2192227840423584
test loss item: 0.2603682279586792
test loss item: 0.2653612792491913
test loss item: 0.38483360409736633
test loss item: 0.2579718232154846
test loss item: 0.3896220922470093
test loss item: 0.38963398337364197
test loss item: 0.841335117816925
test loss item: 0.24232544004917145
test loss item: 0.20090092718601227
test loss item: 0.6227375268936157
test loss item: 0.4732018709182739
test loss item: 0.5105975866317749
test loss item: 0.8095677495002747
test loss item: 1.6865805387496948
test loss item: 0.5346624255180359
test loss item: 0.3319074213504791
test loss item: 0.3417593240737915
test loss item: 0.21327297389507294
test loss item: 0.3805243968963623
test loss item: 0.257308691740036
test loss item: 0.6556626558303833
test loss item: 0.48515084385871887
test loss item: 0.32572200894355774
test loss item: 0.2810596525669098
test loss item: 0.5078450441360474
test loss item: 0.7859396934509277
test loss item: 0.34123775362968445
test loss item: 0.1956005096435547
test loss item: 0.2578631639480591
test loss item: 0.2832411825656891
test loss item: 0.33343762159347534
test loss item: 0.9689782857894897
test loss item: 0.5861067771911621
test loss item: 0.2726684808731079
test loss item: 0.27008822560310364
test loss item: 0.23985055088996887
test loss item: 0.49642473459243774
test loss item: 0.2686035931110382
test loss item: 0.2368537336587906
test loss item: 0.2876656651496887
test loss item: 0.8691298365592957
test loss item: 0.3944358229637146
test loss item: 0.33516502380371094
test loss item: 0.29448938369750977
test loss item: 0.6041241884231567
test loss item: 0.4642869532108307
test loss item: 0.19555698335170746
test loss item: 0.8942440748214722
test loss item: 0.35588082671165466
test loss item: 0.40990567207336426
test loss item: 0.19562625885009766
test loss item: 0.2032623142004013
test loss item: 0.23564766347408295
test loss item: 1.6846054792404175
test loss item: 0.530469536781311
test loss item: 0.2582375109195709
test loss item: 0.18780313432216644
test loss item: 1.0366326570510864
test loss item: 0.8946876525878906
test loss item: 1.1641852855682373
test loss item: 0.26294589042663574
test loss item: 0.2685449719429016
test loss item: 0.21074450016021729
test loss item: 0.2637544572353363
test loss item: 0.2127024233341217
Epoch [10/10], Training Loss: 0.5624, Testing Loss: 0.4534
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
loss item: 0.42541858553886414
loss item: 0.23234106600284576
loss item: 1.8189910650253296
loss item: 1.105236530303955
loss item: 0.5382937788963318
loss item: 0.397112637758255
loss item: 0.23788364231586456
loss item: 0.7038410305976868
loss item: 0.23575082421302795
loss item: 0.2280689775943756
loss item: 0.7708366513252258
loss item: 0.25880327820777893
loss item: 0.8233518600463867
loss item: 0.2746286988258362
loss item: 0.45596030354499817
loss item: 0.3321952521800995
loss item: 0.2985841929912567
loss item: 0.8003977537155151
loss item: 0.8970220685005188
loss item: 0.588858425617218
loss item: 0.4012098014354706
loss item: 0.29454419016838074
loss item: 0.3244631290435791
loss item: 0.24227090179920197
loss item: 0.3737557530403137
loss item: 0.7001045346260071
loss item: 1.1883821487426758
loss item: 0.22467394173145294
loss item: 0.1917969137430191
loss item: 0.45398932695388794
loss item: 0.8796014785766602
loss item: 1.5872493982315063
loss item: 0.20971296727657318
loss item: 0.4984588325023651
loss item: 0.21245644986629486
loss item: 0.2053067833185196
loss item: 0.480814665555954
loss item: 0.26554960012435913
loss item: 0.4039420187473297
loss item: 0.6332919001579285
loss item: 1.120347499847412
loss item: 0.34182703495025635
loss item: 0.27231258153915405
loss item: 0.25805848836898804
Val Loss: 0.5270
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.001, epochs: 10, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 10 0.001 2 360 done at Wed Nov 13 16:20:42 CET 2024
UNet6 with 1 10 0.005 2 360 start at Wed Nov 13 16:20:42 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 10, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
Epoch [1/10], Training Loss: 1.0161, Testing Loss: inf
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.7337050437927246
1
train loss item: 2.7631168365478516
2
train loss item: 2.234610080718994
3
train loss item: 1.7419995069503784
4
train loss item: 6.1393723487854
5
train loss item: 1.5922759771347046
6
train loss item: 2.5647833347320557
7
train loss item: 1.6451680660247803
8
train loss item: 2.7176425457000732
9
train loss item: 1.492957592010498
10
train loss item: 1.491503357887268
11
train loss item: 1.5420777797698975
12
train loss item: 2.0083630084991455
13
train loss item: 1.8392164707183838
14
train loss item: 1.5706486701965332
15
train loss item: 2.232177257537842
16
train loss item: 2.496960163116455
17
train loss item: 2.4780821800231934
18
train loss item: 1.7222905158996582
19
train loss item: 1.6870818138122559
20
train loss item: 2.118736743927002
21
train loss item: 1.9805856943130493
22
train loss item: 3.185164213180542
23
train loss item: 1.762037992477417
24
train loss item: 1.825776219367981
25
train loss item: 1.7809085845947266
26
train loss item: 2.1128554344177246
27
train loss item: 1.5286165475845337
28
train loss item: 2.4832184314727783
29
train loss item: 2.54193377494812
30
train loss item: 2.50256085395813
31
train loss item: 2.065317153930664
32
train loss item: 2.0945029258728027
33
train loss item: 2.0646257400512695
34
train loss item: 3.4447174072265625
35
train loss item: 2.5013861656188965
36
train loss item: 1.735538363456726
37
train loss item: 1.645919919013977
38
train loss item: 2.2714486122131348
39
train loss item: 1.5122597217559814
40
train loss item: 1.890000820159912
41
train loss item: 1.462815284729004
42
train loss item: 1.4945224523544312
43
train loss item: 1.9924899339675903
44
train loss item: 1.6032381057739258
45
train loss item: 2.0889079570770264
46
train loss item: 1.7946295738220215
47
train loss item: 1.7839832305908203
48
train loss item: 1.6914453506469727
49
train loss item: 1.68925940990448
50
train loss item: 1.7840021848678589
51
train loss item: 2.236063241958618
52
train loss item: 2.3508286476135254
53
train loss item: 2.0815937519073486
54
train loss item: 2.320829391479492
55
train loss item: 1.8811920881271362
56
train loss item: 1.426205039024353
57
train loss item: 1.5302560329437256
58
train loss item: 1.9881020784378052
59
train loss item: 1.9739981889724731
60
train loss item: 2.6819868087768555
61
train loss item: 2.499228000640869
62
train loss item: 1.9953643083572388
63
train loss item: 1.7958790063858032
64
train loss item: 1.933268427848816
65
train loss item: 2.480179786682129
66
train loss item: 1.5023800134658813
67
train loss item: 1.7364012002944946
68
train loss item: 2.1607017517089844
69
train loss item: 1.6429253816604614
70
train loss item: 1.7046711444854736
71
train loss item: 2.773634195327759
72
train loss item: 2.7464749813079834
73
train loss item: 1.6722614765167236
74
train loss item: 2.9682271480560303
75
train loss item: 2.0106396675109863
76
train loss item: 1.8273371458053589
77
train loss item: 2.8965399265289307
78
train loss item: 2.4373278617858887
79
train loss item: 1.687382698059082
80
train loss item: 2.7743425369262695
81
train loss item: 1.6321439743041992
82
train loss item: 1.7260106801986694
83
train loss item: 2.1647098064422607
84
train loss item: 1.6363555192947388
85
train loss item: 1.46220862865448
86
train loss item: 4.096249580383301
87
train loss item: 2.4520556926727295
88
train loss item: 1.618540644645691
epoch train loss: 2.096988020318278
testing phase
test loss item: 64194280.0
test loss item: 77386600.0
test loss item: 37743548.0
test loss item: 117831720.0
test loss item: 73759496.0
test loss item: 67275080.0
test loss item: 52555964.0
test loss item: 53374168.0
test loss item: 50467592.0
test loss item: 28725310.0
test loss item: 94413592.0
test loss item: 114410088.0
test loss item: 36495640.0
test loss item: 6842875.0
test loss item: 71036792.0
test loss item: 80053312.0
test loss item: 27741210.0
test loss item: 42308932.0
test loss item: 52854640.0
test loss item: 24911878.0
test loss item: 38965384.0
test loss item: 105730408.0
test loss item: 51431464.0
test loss item: 73480056.0
test loss item: 38004784.0
test loss item: 45211844.0
test loss item: 54816716.0
test loss item: 72896384.0
test loss item: 73055392.0
test loss item: 30115762.0
test loss item: 81421744.0
test loss item: 82135216.0
test loss item: 73996600.0
test loss item: 114721768.0
test loss item: 57867968.0
test loss item: 192525392.0
test loss item: 46320204.0
test loss item: 148446352.0
test loss item: 97882680.0
test loss item: 71978528.0
test loss item: 53809276.0
test loss item: 53083764.0
test loss item: 23070896.0
test loss item: 106121736.0
test loss item: 38328132.0
test loss item: 56201788.0
test loss item: 42574956.0
test loss item: 27949896.0
test loss item: 28571482.0
test loss item: 56177952.0
test loss item: 39451744.0
test loss item: 33010762.0
test loss item: 34112568.0
test loss item: 165836064.0
test loss item: 32265634.0
test loss item: 80623072.0
test loss item: 126303920.0
test loss item: 6837115.5
test loss item: 39919224.0
test loss item: 37874236.0
test loss item: 33307098.0
test loss item: 47217752.0
test loss item: 44385896.0
test loss item: 41790576.0
test loss item: 105819848.0
test loss item: 169617760.0
test loss item: 31910236.0
test loss item: 48406540.0
test loss item: 60020248.0
test loss item: 45935168.0
test loss item: 70496864.0
test loss item: 38118292.0
test loss item: 34978408.0
test loss item: 47180848.0
test loss item: 41174452.0
test loss item: 51311912.0
test loss item: 69519968.0
test loss item: 192651280.0
test loss item: 6877895.5
test loss item: 67829576.0
test loss item: 57674132.0
test loss item: 135990032.0
test loss item: 47934808.0
test loss item: 185032400.0
test loss item: 32694296.0
test loss item: 40738712.0
test loss item: 69086096.0
test loss item: 78784400.0
test loss item: 69556800.0
Epoch [2/10], Training Loss: 2.0970, Testing Loss: 64871391.8427
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.183565616607666
1
train loss item: 1.9414341449737549
2
train loss item: 0.5925023555755615
3
train loss item: 1.1334564685821533
4
train loss item: 0.8947123289108276
5
train loss item: 0.9950372576713562
6
train loss item: 0.4728458821773529
7
train loss item: 1.4358906745910645
8
train loss item: 0.6126320362091064
9
train loss item: 0.6711855530738831
10
train loss item: 0.7577145099639893
11
train loss item: 0.8863354921340942
12
train loss item: 0.5569525957107544
13
train loss item: 1.0617115497589111
14
train loss item: 0.927487313747406
15
train loss item: 1.350458025932312
16
train loss item: 0.4471089839935303
17
train loss item: 0.5849692225456238
18
train loss item: 1.0702556371688843
19
train loss item: 0.743766188621521
20
train loss item: 0.5721824169158936
21
train loss item: 0.5679368376731873
22
train loss item: 1.8540056943893433
23
train loss item: 1.3585312366485596
24
train loss item: 0.8896396160125732
25
train loss item: 0.892193615436554
26
train loss item: 0.49351125955581665
27
train loss item: 0.989745020866394
28
train loss item: 0.46215173602104187
29
train loss item: 1.5552799701690674
30
train loss item: 2.726870059967041
31
train loss item: 1.151024580001831
32
train loss item: 0.7188815474510193
33
train loss item: 0.8409228324890137
34
train loss item: 0.6987011432647705
35
train loss item: 2.5515308380126953
36
train loss item: 1.1870825290679932
37
train loss item: 0.9118356704711914
38
train loss item: 1.00033438205719
39
train loss item: 0.9232012629508972
40
train loss item: 0.6649325489997864
41
train loss item: 0.9523438215255737
42
train loss item: 0.8555437922477722
43
train loss item: 0.6985820531845093
44
train loss item: 1.3676202297210693
45
train loss item: 0.5383530855178833
46
train loss item: 0.5667073130607605
47
train loss item: 0.974998414516449
48
train loss item: 0.8386710286140442
49
train loss item: 0.7001276612281799
50
train loss item: 0.75501549243927
51
train loss item: 1.569324016571045
52
train loss item: 0.6918904781341553
53
train loss item: 0.7456850409507751
54
train loss item: 2.4733364582061768
55
train loss item: 0.5959522128105164
56
train loss item: 0.9113231301307678
57
train loss item: 0.9146339893341064
58
train loss item: 0.6802918910980225
59
train loss item: 0.6703583002090454
60
train loss item: 1.7469711303710938
61
train loss item: 2.7646543979644775
62
train loss item: 0.8055040836334229
63
train loss item: 1.0253621339797974
64
train loss item: 0.6980629563331604
65
train loss item: 1.037177562713623
66
train loss item: 1.0598479509353638
67
train loss item: 0.7360441088676453
68
train loss item: 0.8391050100326538
69
train loss item: 0.7724520564079285
70
train loss item: 0.8917180895805359
71
train loss item: 0.5594335794448853
72
train loss item: 0.6747870445251465
73
train loss item: 0.7655966281890869
74
train loss item: 0.5394884347915649
75
train loss item: 0.5603901743888855
76
train loss item: 1.4299347400665283
77
train loss item: 1.9654195308685303
78
train loss item: 0.6301231980323792
79
train loss item: 0.9600579142570496
80
train loss item: 0.5262104868888855
81
train loss item: 0.7917017936706543
82
train loss item: 0.8507077097892761
83
train loss item: 1.376380443572998
84
train loss item: 1.0350337028503418
85
train loss item: 1.1629035472869873
86
train loss item: 4.447148323059082
87
train loss item: 0.8393546342849731
88
train loss item: 0.6154994964599609
epoch train loss: 1.021779167518187
testing phase
test loss item: 5521997.0
test loss item: 7138301.5
test loss item: 1392644.75
test loss item: 6179405.0
test loss item: 7189193.5
test loss item: 5434376.5
test loss item: 1869010.375
test loss item: 3627687.0
test loss item: 1355536.375
test loss item: 912160.5625
test loss item: 1723799.0
test loss item: 1830857.5
test loss item: 902500.75
test loss item: 2388472.75
test loss item: 8060358.5
test loss item: 2156714.25
test loss item: 1182667.0
test loss item: 3038765.25
test loss item: 4258468.5
test loss item: 4641197.5
test loss item: 5902174.5
test loss item: 973868.5
test loss item: 5363483.5
test loss item: 7947057.5
test loss item: 1475143.25
test loss item: 5812022.5
test loss item: 4786960.5
test loss item: 6819634.5
test loss item: 8102120.0
test loss item: 1242680.125
test loss item: 3931957.75
test loss item: 2135361.25
test loss item: 8305707.0
test loss item: 1627812.875
test loss item: 2823427.5
test loss item: 5473075.5
test loss item: 2050324.625
test loss item: 1824358.5
test loss item: 2303926.0
test loss item: 6839018.5
test loss item: 1211332.5
test loss item: 4378224.0
test loss item: 1720441.625
test loss item: 957279.3125
test loss item: 5909265.0
test loss item: 5766713.5
test loss item: 3475168.0
test loss item: 7323373.5
test loss item: 320534.03125
test loss item: 4742660.5
test loss item: 2703536.5
test loss item: 1828224.375
test loss item: 3397204.5
test loss item: 1506293.0
test loss item: 4624255.0
test loss item: 4243142.5
test loss item: 2237267.5
test loss item: 2392109.25
test loss item: 3163123.0
test loss item: 3440907.0
test loss item: 1807716.875
test loss item: 1218867.625
test loss item: 6611212.0
test loss item: 303618.21875
test loss item: 4985085.5
test loss item: 1553572.875
test loss item: 3415601.25
test loss item: 3451090.25
test loss item: 1360947.375
test loss item: 637669.125
test loss item: 4361056.5
test loss item: 2325683.0
test loss item: 5529577.5
test loss item: 5857173.0
test loss item: 3813475.25
test loss item: 3666666.25
test loss item: 7401176.0
test loss item: 3399414.5
test loss item: 2390457.75
test loss item: 7059022.0
test loss item: 5227428.5
test loss item: 4832469.0
test loss item: 4552043.5
test loss item: 3629586.5
test loss item: 4753256.5
test loss item: 4514552.5
test loss item: 4661881.5
test loss item: 2165708.5
test loss item: 8545681.0
Epoch [3/10], Training Loss: 1.0218, Testing Loss: 3774348.0098
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.1574124097824097
1
train loss item: 1.9939154386520386
2
train loss item: 0.6851544976234436
3
train loss item: 1.221824049949646
4
train loss item: 0.9709842205047607
5
train loss item: 1.1037614345550537
6
train loss item: 0.5823261141777039
7
train loss item: 1.5786597728729248
8
train loss item: 0.5369793176651001
9
train loss item: 0.6179637312889099
10
train loss item: 0.8371385931968689
11
train loss item: 1.0428433418273926
12
train loss item: 0.3738707900047302
13
train loss item: 0.9614976048469543
14
train loss item: 1.130540370941162
15
train loss item: 1.1000782251358032
16
train loss item: 0.34165799617767334
17
train loss item: 0.6350982785224915
18
train loss item: 1.0526798963546753
19
train loss item: 0.6815463304519653
20
train loss item: 0.5234748721122742
21
train loss item: 0.5844346284866333
22
train loss item: 1.6897159814834595
23
train loss item: 1.4940884113311768
24
train loss item: 0.8623356819152832
25
train loss item: 0.6053005456924438
26
train loss item: 0.5238592028617859
27
train loss item: 1.083116888999939
28
train loss item: 0.31862208247184753
29
train loss item: 1.4278826713562012
30
train loss item: 3.1265909671783447
31
train loss item: 1.3633322715759277
32
train loss item: 1.3678544759750366
33
train loss item: 1.0854909420013428
34
train loss item: 0.5634687542915344
35
train loss item: 3.0801820755004883
36
train loss item: 1.333024501800537
37
train loss item: 1.1170320510864258
38
train loss item: 1.0321985483169556
39
train loss item: 1.071929693222046
40
train loss item: 0.4916936457157135
41
train loss item: 1.0832405090332031
42
train loss item: 1.0191025733947754
43
train loss item: 1.3422534465789795
44
train loss item: 1.4352326393127441
45
train loss item: 0.6774218082427979
46
train loss item: 0.647018551826477
47
train loss item: 1.0861091613769531
48
train loss item: 1.0953893661499023
49
train loss item: 0.7269027233123779
50
train loss item: 0.6388546228408813
51
train loss item: 1.8398010730743408
52
train loss item: 0.5272270441055298
53
train loss item: 0.582594633102417
54
train loss item: 2.9758660793304443
55
train loss item: 0.6146993041038513
56
train loss item: 1.096402883529663
57
train loss item: 1.1103590726852417
58
train loss item: 1.3151277303695679
59
train loss item: 0.43090537190437317
60
train loss item: 1.528467059135437
61
train loss item: 2.9844484329223633
62
train loss item: 0.78636234998703
63
train loss item: 1.1165361404418945
64
train loss item: 1.370872974395752
65
train loss item: 0.8983699679374695
66
train loss item: 1.2378227710723877
67
train loss item: 0.6051691174507141
68
train loss item: 0.621517539024353
69
train loss item: 0.7023487687110901
70
train loss item: 1.0926916599273682
71
train loss item: 0.5507144927978516
72
train loss item: 0.6393551826477051
73
train loss item: 0.6313296556472778
74
train loss item: 0.23827973008155823
75
train loss item: 0.4085358679294586
76
train loss item: 1.4518320560455322
77
train loss item: 1.9775038957595825
78
train loss item: 0.5889081358909607
79
train loss item: 1.0293633937835693
80
train loss item: 0.6876837015151978
81
train loss item: 0.6747007369995117
82
train loss item: 1.0069897174835205
83
train loss item: 1.1776341199874878
84
train loss item: 1.2533090114593506
85
train loss item: 1.1214240789413452
86
train loss item: 5.2202043533325195
87
train loss item: 0.5375616550445557
88
train loss item: 0.6052843332290649
epoch train loss: 1.082486413502961
testing phase
test loss item: 1373.18505859375
test loss item: 189.09327697753906
test loss item: 369.2943115234375
test loss item: 424.96807861328125
test loss item: 211.4586181640625
test loss item: 251.73577880859375
test loss item: 80.72917938232422
test loss item: 185.982421875
test loss item: 16.79558563232422
test loss item: 15.428732872009277
test loss item: 129.42709350585938
test loss item: 507.9722595214844
test loss item: 16.074125289916992
test loss item: 565.6630249023438
test loss item: 267.7524108886719
test loss item: 109.59881591796875
test loss item: 377.2904357910156
test loss item: 384.050537109375
test loss item: 1343.378173828125
test loss item: 489.7862243652344
test loss item: 747.7205200195312
test loss item: 389.63543701171875
test loss item: 1376.2557373046875
test loss item: 52.161598205566406
test loss item: 137.7389373779297
test loss item: 835.73779296875
test loss item: 429.1953125
test loss item: 155.943115234375
test loss item: 225.03160095214844
test loss item: 14.522889137268066
test loss item: 194.5797576904297
test loss item: 109.61671447753906
test loss item: 142.3399200439453
test loss item: 504.4494323730469
test loss item: 290.06817626953125
test loss item: 411.9919128417969
test loss item: 180.49609375
test loss item: 205.38253784179688
test loss item: 422.0642395019531
test loss item: 141.83587646484375
test loss item: 62.18326950073242
test loss item: 1230.7574462890625
test loss item: 493.3901672363281
test loss item: 380.1335754394531
test loss item: 749.6412353515625
test loss item: 534.6477661132812
test loss item: 442.6421813964844
test loss item: 679.5367431640625
test loss item: 16.549957275390625
test loss item: 935.044921875
test loss item: 260.8851013183594
test loss item: 137.5486602783203
test loss item: 16.860403060913086
test loss item: 577.7509765625
test loss item: 162.39450073242188
test loss item: 197.6161651611328
test loss item: 16.391542434692383
test loss item: 566.707275390625
test loss item: 385.5350646972656
test loss item: 33.282684326171875
test loss item: 137.3617706298828
test loss item: 61.86630630493164
test loss item: 1411.269287109375
test loss item: 17.444717407226562
test loss item: 323.91796875
test loss item: 578.991943359375
test loss item: 13.818497657775879
test loss item: 159.61163330078125
test loss item: 62.07839584350586
test loss item: 15.281039237976074
test loss item: 156.96530151367188
test loss item: 159.56690979003906
test loss item: 723.7645874023438
test loss item: 1383.801513671875
test loss item: 447.0059814453125
test loss item: 189.57083129882812
test loss item: 152.9215850830078
test loss item: 574.351318359375
test loss item: 566.7460327148438
test loss item: 1428.2054443359375
test loss item: 298.8756408691406
test loss item: 1321.682861328125
test loss item: 406.78167724609375
test loss item: 557.9059448242188
test loss item: 182.75282287597656
test loss item: 1297.17919921875
test loss item: 248.6237335205078
test loss item: 109.65879821777344
test loss item: 2724.205810546875
Epoch [4/10], Training Loss: 1.0825, Testing Loss: 425.4847
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.669301450252533
1
train loss item: 2.005352735519409
2
train loss item: 0.5108360052108765
3
train loss item: 1.1352429389953613
4
train loss item: 0.5807209610939026
5
train loss item: 0.5794386267662048
6
train loss item: 0.4949324131011963
7
train loss item: 1.2751185894012451
8
train loss item: 0.4077865183353424
9
train loss item: 0.4953464865684509
10
train loss item: 0.6323778629302979
11
train loss item: 0.5133861899375916
12
train loss item: 0.4307023584842682
13
train loss item: 0.8104681968688965
14
train loss item: 0.5151399374008179
15
train loss item: 1.1922504901885986
16
train loss item: 0.3449742794036865
17
train loss item: 0.4205591678619385
18
train loss item: 0.6573119163513184
19
train loss item: 0.5358530282974243
20
train loss item: 0.43036356568336487
21
train loss item: 0.32258933782577515
22
train loss item: 1.8101774454116821
23
train loss item: 1.3432197570800781
24
train loss item: 0.8852701187133789
25
train loss item: 0.5495965480804443
26
train loss item: 0.27381429076194763
27
train loss item: 0.5837677121162415
28
train loss item: 0.3634118139743805
29
train loss item: 1.435518503189087
30
train loss item: 3.0796546936035156
31
train loss item: 0.9577363133430481
32
train loss item: 0.3649596869945526
33
train loss item: 0.8014232516288757
34
train loss item: 0.5286387205123901
35
train loss item: 2.885377883911133
36
train loss item: 0.8664788603782654
37
train loss item: 0.6632768511772156
38
train loss item: 0.9014606475830078
39
train loss item: 0.5859564542770386
40
train loss item: 0.29297399520874023
41
train loss item: 0.6027674078941345
42
train loss item: 0.5684018731117249
43
train loss item: 0.46087899804115295
44
train loss item: 1.0571134090423584
45
train loss item: 0.38469836115837097
46
train loss item: 0.35067543387413025
47
train loss item: 0.6974745988845825
48
train loss item: 0.43393397331237793
49
train loss item: 0.42840883135795593
50
train loss item: 0.6397272348403931
51
train loss item: 1.568054437637329
52
train loss item: 0.3257361352443695
53
train loss item: 0.4465019106864929
54
train loss item: 2.7694408893585205
55
train loss item: 0.3426324129104614
56
train loss item: 0.5977542996406555
57
train loss item: 0.5584379434585571
58
train loss item: 0.42660972476005554
59
train loss item: 0.25844404101371765
60
train loss item: 1.5652803182601929
61
train loss item: 2.8502142429351807
62
train loss item: 0.37750303745269775
63
train loss item: 0.7479260563850403
64
train loss item: 0.43345701694488525
65
train loss item: 0.9394662976264954
66
train loss item: 0.7468425035476685
67
train loss item: 0.5197861194610596
68
train loss item: 0.6439663767814636
69
train loss item: 0.6162663102149963
70
train loss item: 0.5631812810897827
71
train loss item: 0.297536700963974
72
train loss item: 0.49422869086265564
73
train loss item: 0.5071637630462646
74
train loss item: 0.2347545325756073
75
train loss item: 0.40762895345687866
76
train loss item: 1.3740973472595215
77
train loss item: 1.972565770149231
78
train loss item: 0.21327145397663116
79
train loss item: 0.5899575352668762
80
train loss item: 0.22748957574367523
81
train loss item: 0.49369609355926514
82
train loss item: 0.4424087107181549
83
train loss item: 1.1738381385803223
84
train loss item: 0.7521194219589233
85
train loss item: 1.0730184316635132
86
train loss item: 5.010405540466309
87
train loss item: 0.49739310145378113
88
train loss item: 0.5490522980690002
epoch train loss: 0.824325552147426
testing phase
test loss item: 193.53456115722656
test loss item: 194.09320068359375
test loss item: 500.2169494628906
test loss item: 796.852294921875
test loss item: 200.2329864501953
test loss item: 282.4388732910156
test loss item: 182.24461364746094
test loss item: 167.66429138183594
test loss item: 175.3987274169922
test loss item: 125.48291015625
test loss item: 166.9290313720703
test loss item: 1128.321533203125
test loss item: 540.4620361328125
test loss item: 671.693359375
test loss item: 91.36542510986328
test loss item: 351.97174072265625
test loss item: 744.7156372070312
test loss item: 115.01734924316406
test loss item: 117.93062591552734
test loss item: 702.40380859375
test loss item: 807.5352783203125
test loss item: 785.1324462890625
test loss item: 805.044677734375
test loss item: 185.39340209960938
test loss item: 727.920654296875
test loss item: 587.4926147460938
test loss item: 386.82562255859375
test loss item: 253.26596069335938
test loss item: 243.0707244873047
test loss item: 120.10271453857422
test loss item: 117.62374114990234
test loss item: 479.881591796875
test loss item: 136.21083068847656
test loss item: 851.7933349609375
test loss item: 206.7367706298828
test loss item: 366.36102294921875
test loss item: 197.50408935546875
test loss item: 180.21047973632812
test loss item: 863.2252197265625
test loss item: 258.83917236328125
test loss item: 819.5640869140625
test loss item: 834.2333984375
test loss item: 600.8545532226562
test loss item: 1004.1815795898438
test loss item: 850.4442138671875
test loss item: 550.06591796875
test loss item: 984.0051879882812
test loss item: 644.6589965820312
test loss item: 122.55614471435547
test loss item: 316.7966613769531
test loss item: 298.982421875
test loss item: 98.64193725585938
test loss item: 646.3541870117188
test loss item: 1156.1309814453125
test loss item: 481.9346923828125
test loss item: 62.12835693359375
test loss item: 107.43003845214844
test loss item: 709.7845458984375
test loss item: 138.30068969726562
test loss item: 647.699462890625
test loss item: 84.52913665771484
test loss item: 196.31517028808594
test loss item: 283.86846923828125
test loss item: 769.9132080078125
test loss item: 147.8094024658203
test loss item: 1123.41015625
test loss item: 321.3728942871094
test loss item: 724.9478149414062
test loss item: 506.3523254394531
test loss item: 117.76371002197266
test loss item: 237.07940673828125
test loss item: 155.59878540039062
test loss item: 837.0817260742188
test loss item: 144.57643127441406
test loss item: 566.4548950195312
test loss item: 749.6746826171875
test loss item: 171.1521453857422
test loss item: 165.53244018554688
test loss item: 674.7103271484375
test loss item: 219.24473571777344
test loss item: 87.8331298828125
test loss item: 153.9138946533203
test loss item: 353.70050048828125
test loss item: 146.09156799316406
test loss item: 431.7414245605469
test loss item: 616.6219482421875
test loss item: 184.28746032714844
test loss item: 273.68548583984375
test loss item: 121.00711822509766
Epoch [5/10], Training Loss: 0.8243, Testing Loss: 423.0355
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5946231484413147
1
train loss item: 1.9838461875915527
2
train loss item: 0.4009765386581421
3
train loss item: 1.0213115215301514
4
train loss item: 0.5309916734695435
5
train loss item: 0.46336641907691956
6
train loss item: 0.49030694365501404
7
train loss item: 1.1470869779586792
8
train loss item: 0.22655262053012848
9
train loss item: 0.4409114420413971
10
train loss item: 0.5291445851325989
11
train loss item: 0.4629054069519043
12
train loss item: 0.21491840481758118
13
train loss item: 0.6903838515281677
14
train loss item: 0.34871047735214233
15
train loss item: 1.2579970359802246
16
train loss item: 0.18816684186458588
17
train loss item: 0.48879173398017883
18
train loss item: 0.5870199799537659
19
train loss item: 0.5372936129570007
20
train loss item: 0.5211512446403503
21
train loss item: 0.3438786268234253
22
train loss item: 1.8720426559448242
23
train loss item: 1.2079607248306274
24
train loss item: 1.0332306623458862
25
train loss item: 0.3122381269931793
26
train loss item: 0.33172041177749634
27
train loss item: 0.4114626348018646
28
train loss item: 0.1851843148469925
29
train loss item: 1.4455047845840454
30
train loss item: 3.020362615585327
31
train loss item: 0.7786102294921875
32
train loss item: 0.2127753496170044
33
train loss item: 0.6196749806404114
34
train loss item: 0.3363945782184601
35
train loss item: 2.888387441635132
36
train loss item: 0.8179313540458679
37
train loss item: 0.6105154752731323
38
train loss item: 0.8980810642242432
39
train loss item: 0.4164239168167114
40
train loss item: 0.2508063018321991
41
train loss item: 0.42121002078056335
42
train loss item: 0.4569108188152313
43
train loss item: 0.3071165382862091
44
train loss item: 0.8957749009132385
45
train loss item: 0.19424252212047577
46
train loss item: 0.196355938911438
47
train loss item: 0.6809849739074707
48
train loss item: 0.3670964539051056
49
train loss item: 0.2346074879169464
50
train loss item: 0.579245924949646
51
train loss item: 1.5370079278945923
52
train loss item: 0.17673788964748383
53
train loss item: 0.27674761414527893
54
train loss item: 2.758492946624756
55
train loss item: 0.320963978767395
56
train loss item: 0.41256362199783325
57
train loss item: 0.40809956192970276
58
train loss item: 0.30322903394699097
59
train loss item: 0.19452440738677979
60
train loss item: 1.5820327997207642
61
train loss item: 2.6933252811431885
62
train loss item: 0.3721502125263214
63
train loss item: 0.7603291869163513
64
train loss item: 0.27402302622795105
65
train loss item: 1.0804136991500854
66
train loss item: 0.6739026308059692
67
train loss item: 0.426050066947937
68
train loss item: 0.7082470655441284
69
train loss item: 0.5692058205604553
70
train loss item: 0.5310481190681458
71
train loss item: 0.3975130021572113
72
train loss item: 0.30706295371055603
73
train loss item: 0.4843127429485321
74
train loss item: 0.19775870442390442
75
train loss item: 0.19237980246543884
76
train loss item: 1.2383753061294556
77
train loss item: 2.0013647079467773
78
train loss item: 0.1941377818584442
79
train loss item: 0.5912503004074097
80
train loss item: 0.2922463119029999
81
train loss item: 0.34221401810646057
82
train loss item: 0.3371834456920624
83
train loss item: 1.2277854681015015
84
train loss item: 0.7257451415061951
85
train loss item: 1.0315133333206177
86
train loss item: 4.955499649047852
87
train loss item: 0.2893543243408203
88
train loss item: 0.651634156703949
epoch train loss: 0.7524675788839211
testing phase
test loss item: 259.4425964355469
test loss item: 197.48121643066406
test loss item: 98.00985717773438
test loss item: 242.9959716796875
test loss item: 217.9160919189453
test loss item: 236.30177307128906
test loss item: 110.36363220214844
test loss item: 105.30272674560547
test loss item: 154.68600463867188
test loss item: 21.73921775817871
test loss item: 150.54066467285156
test loss item: 202.464599609375
test loss item: 30.069561004638672
test loss item: 283.8904724121094
test loss item: 154.61566162109375
test loss item: 236.31361389160156
test loss item: 111.42536926269531
test loss item: 126.01750183105469
test loss item: 346.5968933105469
test loss item: 106.1366958618164
test loss item: 336.512451171875
test loss item: 215.23597717285156
test loss item: 264.268310546875
test loss item: 120.32202911376953
test loss item: 103.47590637207031
test loss item: 403.9365539550781
test loss item: 214.18618774414062
test loss item: 201.45753479003906
test loss item: 159.6568145751953
test loss item: 14.346186637878418
test loss item: 109.02555084228516
test loss item: 224.5221710205078
test loss item: 139.29971313476562
test loss item: 219.76678466796875
test loss item: 177.98626708984375
test loss item: 89.12076568603516
test loss item: 76.31513977050781
test loss item: 196.98184204101562
test loss item: 185.42982482910156
test loss item: 193.0317840576172
test loss item: 139.58351135253906
test loss item: 392.52044677734375
test loss item: 117.28933715820312
test loss item: 191.39463806152344
test loss item: 317.12896728515625
test loss item: 196.3995361328125
test loss item: 307.9481506347656
test loss item: 153.33250427246094
test loss item: 20.645612716674805
test loss item: 406.4595947265625
test loss item: 147.2521514892578
test loss item: 50.480201721191406
test loss item: 172.25845336914062
test loss item: 311.2869873046875
test loss item: 222.57345581054688
test loss item: 146.69578552246094
test loss item: 168.74209594726562
test loss item: 293.5848693847656
test loss item: 121.58904266357422
test loss item: 146.02207946777344
test loss item: 49.03114318847656
test loss item: 133.844970703125
test loss item: 235.93679809570312
test loss item: 16.317113876342773
test loss item: 204.7295379638672
test loss item: 307.411865234375
test loss item: 128.5391845703125
test loss item: 100.72631072998047
test loss item: 147.0782928466797
test loss item: 12.050564765930176
test loss item: 182.52389526367188
test loss item: 119.85138702392578
test loss item: 329.3778991699219
test loss item: 195.74880981445312
test loss item: 145.92115783691406
test loss item: 221.43455505371094
test loss item: 112.62158203125
test loss item: 306.4727783203125
test loss item: 285.5953369140625
test loss item: 283.4070739746094
test loss item: 134.18812561035156
test loss item: 377.9163818359375
test loss item: 89.43124389648438
test loss item: 234.63430786132812
test loss item: 204.50035095214844
test loss item: 337.8183898925781
test loss item: 206.04635620117188
test loss item: 241.4140625
test loss item: 693.698486328125
Epoch [6/10], Training Loss: 0.7525, Testing Loss: 192.1196
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5607684850692749
1
train loss item: 1.926676630973816
2
train loss item: 0.35329684615135193
3
train loss item: 0.9597423076629639
4
train loss item: 0.5227727890014648
5
train loss item: 0.4508007764816284
6
train loss item: 0.4522921144962311
7
train loss item: 1.1024432182312012
8
train loss item: 0.22012585401535034
9
train loss item: 0.42723026871681213
10
train loss item: 0.49717867374420166
11
train loss item: 0.44841837882995605
12
train loss item: 0.14018264412879944
13
train loss item: 0.6654989719390869
14
train loss item: 0.32522228360176086
15
train loss item: 1.2281792163848877
16
train loss item: 0.13173611462116241
17
train loss item: 0.49172964692115784
18
train loss item: 0.5584751963615417
19
train loss item: 0.521047830581665
20
train loss item: 0.43972429633140564
21
train loss item: 0.2496684342622757
22
train loss item: 1.8391066789627075
23
train loss item: 1.164626121520996
24
train loss item: 0.976655125617981
25
train loss item: 0.24660524725914001
26
train loss item: 0.31871646642684937
27
train loss item: 0.37081149220466614
28
train loss item: 0.13135786354541779
29
train loss item: 1.4184701442718506
30
train loss item: 2.9813385009765625
31
train loss item: 0.7355334162712097
32
train loss item: 0.15874671936035156
33
train loss item: 0.5760723948478699
34
train loss item: 0.21040666103363037
35
train loss item: 2.8834216594696045
36
train loss item: 0.7677138447761536
37
train loss item: 0.6080870628356934
38
train loss item: 0.8013278245925903
39
train loss item: 0.37254300713539124
40
train loss item: 0.23103411495685577
41
train loss item: 0.3911621570587158
42
train loss item: 0.45177802443504333
43
train loss item: 0.2848416268825531
44
train loss item: 0.8446726202964783
45
train loss item: 0.17955805361270905
46
train loss item: 0.16463777422904968
47
train loss item: 0.6861543655395508
48
train loss item: 0.3559110760688782
49
train loss item: 0.21588771045207977
50
train loss item: 0.5786092877388
51
train loss item: 1.5088756084442139
52
train loss item: 0.1717795431613922
53
train loss item: 0.2368287891149521
54
train loss item: 2.7597692012786865
55
train loss item: 0.3183665871620178
56
train loss item: 0.3858959674835205
57
train loss item: 0.3778788149356842
58
train loss item: 0.272002637386322
59
train loss item: 0.22650496661663055
60
train loss item: 1.547382116317749
61
train loss item: 2.6094629764556885
62
train loss item: 0.3693045973777771
63
train loss item: 0.7556576132774353
64
train loss item: 0.24688805639743805
65
train loss item: 1.0776557922363281
66
train loss item: 0.6160284876823425
67
train loss item: 0.38643935322761536
68
train loss item: 0.708397626876831
69
train loss item: 0.5711262822151184
70
train loss item: 0.52189701795578
71
train loss item: 0.2561063766479492
72
train loss item: 0.28796645998954773
73
train loss item: 0.4740075170993805
74
train loss item: 0.17208364605903625
75
train loss item: 0.13727766275405884
76
train loss item: 1.197191596031189
77
train loss item: 1.9920690059661865
78
train loss item: 0.15299877524375916
79
train loss item: 0.5737409591674805
80
train loss item: 0.232942134141922
81
train loss item: 0.3285616636276245
82
train loss item: 0.317914217710495
83
train loss item: 1.215092420578003
84
train loss item: 0.6785671710968018
85
train loss item: 0.9451348781585693
86
train loss item: 4.934544563293457
87
train loss item: 0.2432193160057068
88
train loss item: 0.6013710498809814
epoch train loss: 0.7194149378645286
testing phase
test loss item: 29.274192810058594
test loss item: 18.11981201171875
test loss item: 2.0763919353485107
test loss item: 24.61143684387207
test loss item: 9.505044937133789
test loss item: 11.72424602508545
test loss item: 37.65914535522461
test loss item: 24.45854377746582
test loss item: 2.2086033821105957
test loss item: 3.9273390769958496
test loss item: 7.500892639160156
test loss item: 23.5261287689209
test loss item: 1.2914135456085205
test loss item: 43.845394134521484
test loss item: 11.692344665527344
test loss item: 28.7581787109375
test loss item: 1.8204401731491089
test loss item: 7.640153884887695
test loss item: 66.68626403808594
test loss item: 8.350934982299805
test loss item: 36.640594482421875
test loss item: 23.66779899597168
test loss item: 29.469741821289062
test loss item: 0.3994464874267578
test loss item: 7.319428443908691
test loss item: 50.59745407104492
test loss item: 6.379464626312256
test loss item: 5.975285053253174
test loss item: 14.872284889221191
test loss item: 0.8930281400680542
test loss item: 19.07354736328125
test loss item: 28.844356536865234
test loss item: 5.080907344818115
test loss item: 23.792264938354492
test loss item: 16.936445236206055
test loss item: 11.555089950561523
test loss item: 16.25121307373047
test loss item: 7.270370960235596
test loss item: 17.114681243896484
test loss item: 5.939759731292725
test loss item: 15.971391677856445
test loss item: 65.05948638916016
test loss item: 1.3123375177383423
test loss item: 17.224197387695312
test loss item: 30.896617889404297
test loss item: 21.392221450805664
test loss item: 28.908695220947266
test loss item: 12.208977699279785
test loss item: 2.3289201259613037
test loss item: 63.68441390991211
test loss item: 12.502114295959473
test loss item: 7.260521411895752
test loss item: 5.443305969238281
test loss item: 34.251869201660156
test loss item: 16.423215866088867
test loss item: 10.495035171508789
test loss item: 9.772098541259766
test loss item: 44.502464294433594
test loss item: 9.17160415649414
test loss item: 7.139128684997559
test loss item: 7.255197525024414
test loss item: 16.110315322875977
test loss item: 32.270599365234375
test loss item: 1.2586299180984497
test loss item: 24.13844108581543
test loss item: 34.62247848510742
test loss item: 4.717680931091309
test loss item: 8.049653053283691
test loss item: 15.92336654663086
test loss item: 15.266972541809082
test loss item: 20.055017471313477
test loss item: 37.78230667114258
test loss item: 35.220863342285156
test loss item: 28.76255226135254
test loss item: 9.375167846679688
test loss item: 17.704700469970703
test loss item: 7.635445594787598
test loss item: 13.802908897399902
test loss item: 44.19063949584961
test loss item: 31.40974998474121
test loss item: 14.445944786071777
test loss item: 68.6751480102539
test loss item: 17.49645233154297
test loss item: 8.602810859680176
test loss item: 17.964109420776367
test loss item: 63.051387786865234
test loss item: 22.31927490234375
test loss item: 28.763574600219727
test loss item: 130.95974731445312
Epoch [7/10], Training Loss: 0.7194, Testing Loss: 21.1970
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5261905789375305
1
train loss item: 1.8815093040466309
2
train loss item: 0.334087073802948
3
train loss item: 0.9091936945915222
4
train loss item: 0.4989086091518402
5
train loss item: 0.4167511463165283
6
train loss item: 0.3841474652290344
7
train loss item: 1.0699670314788818
8
train loss item: 0.2012716680765152
9
train loss item: 0.4094078838825226
10
train loss item: 0.4812868535518646
11
train loss item: 0.39548611640930176
12
train loss item: 0.12942124903202057
13
train loss item: 0.6368029713630676
14
train loss item: 0.3064843416213989
15
train loss item: 1.1815521717071533
16
train loss item: 0.09724964946508408
17
train loss item: 0.44703564047813416
18
train loss item: 0.5159271955490112
19
train loss item: 0.49059054255485535
20
train loss item: 0.3897812068462372
21
train loss item: 0.18639805912971497
22
train loss item: 1.785454273223877
23
train loss item: 1.1471267938613892
24
train loss item: 0.9325661063194275
25
train loss item: 0.22641023993492126
26
train loss item: 0.28639379143714905
27
train loss item: 0.34490838646888733
28
train loss item: 0.10615800321102142
29
train loss item: 1.3872405290603638
30
train loss item: 2.936075210571289
31
train loss item: 0.7216778993606567
32
train loss item: 0.16264352202415466
33
train loss item: 0.5739965438842773
34
train loss item: 0.14100129902362823
35
train loss item: 2.854309558868408
36
train loss item: 0.7120509743690491
37
train loss item: 0.5632851123809814
38
train loss item: 0.7622356414794922
39
train loss item: 0.33171844482421875
40
train loss item: 0.20960944890975952
41
train loss item: 0.3644246459007263
42
train loss item: 0.44512781500816345
43
train loss item: 0.2813429534435272
44
train loss item: 0.8206536173820496
45
train loss item: 0.19917233288288116
46
train loss item: 0.1626848727464676
47
train loss item: 0.6730755567550659
48
train loss item: 0.34580668807029724
49
train loss item: 0.20838603377342224
50
train loss item: 0.5450286269187927
51
train loss item: 1.4723633527755737
52
train loss item: 0.139985591173172
53
train loss item: 0.234366312623024
54
train loss item: 2.7319583892822266
55
train loss item: 0.3082907497882843
56
train loss item: 0.35070547461509705
57
train loss item: 0.3520001769065857
58
train loss item: 0.2554933428764343
59
train loss item: 0.20562435686588287
60
train loss item: 1.4962228536605835
61
train loss item: 2.585383653640747
62
train loss item: 0.34352433681488037
63
train loss item: 0.7016330361366272
64
train loss item: 0.25515466928482056
65
train loss item: 1.0155506134033203
66
train loss item: 0.5526156425476074
67
train loss item: 0.3439730703830719
68
train loss item: 0.6679310202598572
69
train loss item: 0.5637957453727722
70
train loss item: 0.4863538444042206
71
train loss item: 0.19932766258716583
72
train loss item: 0.27003246545791626
73
train loss item: 0.45723822712898254
74
train loss item: 0.10960523784160614
75
train loss item: 0.15374159812927246
76
train loss item: 1.1738535165786743
77
train loss item: 1.948042631149292
78
train loss item: 0.11716045439243317
79
train loss item: 0.5077100396156311
80
train loss item: 0.2175857126712799
81
train loss item: 0.31501054763793945
82
train loss item: 0.3138841986656189
83
train loss item: 1.1815367937088013
84
train loss item: 0.6088192462921143
85
train loss item: 0.9161341786384583
86
train loss item: 4.904420852661133
87
train loss item: 0.24947614967823029
88
train loss item: 0.556178092956543
epoch train loss: 0.6896932495946295
testing phase
test loss item: 4.63518762588501
test loss item: 2.1027517318725586
test loss item: 0.7715105414390564
test loss item: 3.2854652404785156
test loss item: 0.871174156665802
test loss item: 1.1470516920089722
test loss item: 7.60451078414917
test loss item: 4.816933631896973
test loss item: 0.3729412853717804
test loss item: 0.581008791923523
test loss item: 1.8923897743225098
test loss item: 3.3355493545532227
test loss item: 0.33144113421440125
test loss item: 7.105724334716797
test loss item: 1.2771002054214478
test loss item: 3.533783197402954
test loss item: 0.5164166688919067
test loss item: 1.4024797677993774
test loss item: 12.181984901428223
test loss item: 1.2082899808883667
test loss item: 5.020742416381836
test loss item: 3.227065324783325
test loss item: 3.9059512615203857
test loss item: 0.35053542256355286
test loss item: 1.0909963846206665
test loss item: 6.682380199432373
test loss item: 0.9084561467170715
test loss item: 0.3776666522026062
test loss item: 2.3321919441223145
test loss item: 0.5854926109313965
test loss item: 3.3928000926971436
test loss item: 3.5741097927093506
test loss item: 0.2939557433128357
test loss item: 3.6733920574188232
test loss item: 2.0331075191497803
test loss item: 1.8788388967514038
test loss item: 3.895296096801758
test loss item: 2.3921728134155273
test loss item: 2.5861284732818604
test loss item: 0.5398607850074768
test loss item: 2.0434210300445557
test loss item: 11.679802894592285
test loss item: 0.5923910140991211
test loss item: 2.567781925201416
test loss item: 3.651742458343506
test loss item: 2.8042993545532227
test loss item: 3.9158105850219727
test loss item: 1.5276432037353516
test loss item: 0.6792353987693787
test loss item: 9.021409034729004
test loss item: 1.9367659091949463
test loss item: 1.0425670146942139
test loss item: 0.44172191619873047
test loss item: 4.61857271194458
test loss item: 1.959934949874878
test loss item: 1.6902002096176147
test loss item: 2.039147138595581
test loss item: 7.037417888641357
test loss item: 1.3253735303878784
test loss item: 0.3171890676021576
test loss item: 1.2351149320602417
test loss item: 2.0091359615325928
test loss item: 4.917812824249268
test loss item: 0.4455571472644806
test loss item: 4.4553632736206055
test loss item: 4.774406433105469
test loss item: 0.593117356300354
test loss item: 0.7088049650192261
test loss item: 2.0743777751922607
test loss item: 3.3786120414733887
test loss item: 2.3479678630828857
test loss item: 6.815426349639893
test loss item: 4.534915924072266
test loss item: 4.2713623046875
test loss item: 0.8313164114952087
test loss item: 1.850317358970642
test loss item: 1.119567632675171
test loss item: 3.253239631652832
test loss item: 7.22829532623291
test loss item: 4.937180042266846
test loss item: 1.4998416900634766
test loss item: 12.178506851196289
test loss item: 3.491798162460327
test loss item: 1.7110826969146729
test loss item: 2.3581387996673584
test loss item: 11.997305870056152
test loss item: 2.555058479309082
test loss item: 3.54068660736084
test loss item: 23.527124404907227
Epoch [8/10], Training Loss: 0.6897, Testing Loss: 3.2949
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5008963346481323
1
train loss item: 1.8419960737228394
2
train loss item: 0.3138033449649811
3
train loss item: 0.8873890042304993
4
train loss item: 0.48258864879608154
5
train loss item: 0.3933088183403015
6
train loss item: 0.34448128938674927
7
train loss item: 1.0430988073349
8
train loss item: 0.18540768325328827
9
train loss item: 0.39656123518943787
10
train loss item: 0.4756363034248352
11
train loss item: 0.3732050955295563
12
train loss item: 0.13575555384159088
13
train loss item: 0.6071041226387024
14
train loss item: 0.28867244720458984
15
train loss item: 1.1371397972106934
16
train loss item: 0.09883623570203781
17
train loss item: 0.41871851682662964
18
train loss item: 0.4848158657550812
19
train loss item: 0.46221861243247986
20
train loss item: 0.34901806712150574
21
train loss item: 0.1561325043439865
22
train loss item: 1.7367268800735474
23
train loss item: 1.1337069272994995
24
train loss item: 0.9032079577445984
25
train loss item: 0.21852272748947144
26
train loss item: 0.2605217397212982
27
train loss item: 0.3265835642814636
28
train loss item: 0.1122811883687973
29
train loss item: 1.3580979108810425
30
train loss item: 2.8994977474212646
31
train loss item: 0.7155803442001343
32
train loss item: 0.15995773673057556
33
train loss item: 0.5629039406776428
34
train loss item: 0.12080159038305283
35
train loss item: 2.821160078048706
36
train loss item: 0.6810175776481628
37
train loss item: 0.5172445178031921
38
train loss item: 0.739145815372467
39
train loss item: 0.30303478240966797
40
train loss item: 0.1969151496887207
41
train loss item: 0.34709519147872925
42
train loss item: 0.43765461444854736
43
train loss item: 0.2768155336380005
44
train loss item: 0.8001705408096313
45
train loss item: 0.21291320025920868
46
train loss item: 0.16017858684062958
47
train loss item: 0.6510107517242432
48
train loss item: 0.3269619643688202
49
train loss item: 0.2089914083480835
50
train loss item: 0.5107414126396179
51
train loss item: 1.442151427268982
52
train loss item: 0.12398794293403625
53
train loss item: 0.23294231295585632
54
train loss item: 2.6995949745178223
55
train loss item: 0.2830786406993866
56
train loss item: 0.32815852761268616
57
train loss item: 0.3377278447151184
58
train loss item: 0.24372504651546478
59
train loss item: 0.18293406069278717
60
train loss item: 1.4498142004013062
61
train loss item: 2.569556951522827
62
train loss item: 0.3226715624332428
63
train loss item: 0.6704931259155273
64
train loss item: 0.2584972083568573
65
train loss item: 0.963245153427124
66
train loss item: 0.5296632051467896
67
train loss item: 0.30656328797340393
68
train loss item: 0.6247704029083252
69
train loss item: 0.551176130771637
70
train loss item: 0.45001107454299927
71
train loss item: 0.16778093576431274
72
train loss item: 0.2517733573913574
73
train loss item: 0.44302549958229065
74
train loss item: 0.11352110654115677
75
train loss item: 0.16641172766685486
76
train loss item: 1.1519765853881836
77
train loss item: 1.913063883781433
78
train loss item: 0.09683462977409363
79
train loss item: 0.46963682770729065
80
train loss item: 0.21475310623645782
81
train loss item: 0.30135852098464966
82
train loss item: 0.2928648293018341
83
train loss item: 1.1569172143936157
84
train loss item: 0.5808102488517761
85
train loss item: 0.896532416343689
86
train loss item: 4.857174873352051
87
train loss item: 0.24816307425498962
88
train loss item: 0.5205845832824707
epoch train loss: 0.6684289016248135
testing phase
test loss item: 1.4153518676757812
test loss item: 0.44596067070961
test loss item: 0.7096584439277649
test loss item: 0.8713239431381226
test loss item: 0.4049721658229828
test loss item: 0.2884518802165985
test loss item: 4.305753231048584
test loss item: 2.0241801738739014
test loss item: 0.2922353148460388
test loss item: 0.5569289326667786
test loss item: 1.2614082098007202
test loss item: 0.9174288511276245
test loss item: 0.26209720969200134
test loss item: 2.5092172622680664
test loss item: 0.3736642003059387
test loss item: 0.7584423422813416
test loss item: 0.468794584274292
test loss item: 0.7025678753852844
test loss item: 4.19722318649292
test loss item: 0.5826073288917542
test loss item: 1.8096455335617065
test loss item: 0.9725279211997986
test loss item: 1.0761992931365967
test loss item: 0.2653380036354065
test loss item: 0.3908248245716095
test loss item: 1.7765145301818848
test loss item: 0.5413155555725098
test loss item: 0.25266095995903015
test loss item: 0.9483507871627808
test loss item: 0.541612446308136
test loss item: 1.738486647605896
test loss item: 0.7786040902137756
test loss item: 0.20718039572238922
test loss item: 1.270975947380066
test loss item: 0.6771445870399475
test loss item: 0.8130353093147278
test loss item: 1.9397577047348022
test loss item: 1.7553690671920776
test loss item: 1.015175700187683
test loss item: 0.44454675912857056
test loss item: 0.6423308253288269
test loss item: 3.7596938610076904
test loss item: 0.5170904397964478
test loss item: 0.8140709400177002
test loss item: 1.2103809118270874
test loss item: 0.992234468460083
test loss item: 1.166764259338379
test loss item: 0.5234195590019226
test loss item: 0.6148073673248291
test loss item: 2.6734230518341064
test loss item: 0.7506895661354065
test loss item: 0.31902915239334106
test loss item: 0.3587283790111542
test loss item: 1.164077639579773
test loss item: 0.7384427785873413
test loss item: 1.0962868928909302
test loss item: 1.1048141717910767
test loss item: 2.3757102489471436
test loss item: 0.4272812604904175
test loss item: 0.2812708914279938
test loss item: 0.6969679594039917
test loss item: 0.551501989364624
test loss item: 1.4734255075454712
test loss item: 0.3533891439437866
test loss item: 2.0861339569091797
test loss item: 1.2734113931655884
test loss item: 0.45461103320121765
test loss item: 0.3936781883239746
test loss item: 0.777823269367218
test loss item: 1.2484816312789917
test loss item: 0.5056605339050293
test loss item: 3.052482843399048
test loss item: 1.330296516418457
test loss item: 1.3492133617401123
test loss item: 0.25860998034477234
test loss item: 0.3479948043823242
test loss item: 0.3698863089084625
test loss item: 2.322598457336426
test loss item: 2.6085593700408936
test loss item: 1.5879076719284058
test loss item: 0.32893168926239014
test loss item: 4.282411575317383
test loss item: 1.838644027709961
test loss item: 1.1728688478469849
test loss item: 0.8391405344009399
test loss item: 3.8644988536834717
test loss item: 0.5252659320831299
test loss item: 0.7721226811408997
test loss item: 7.7544097900390625
Epoch [9/10], Training Loss: 0.6684, Testing Loss: 1.2193
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/10
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4861049950122833
1
train loss item: 1.8051923513412476
2
train loss item: 0.2861803472042084
3
train loss item: 0.8643131256103516
4
train loss item: 0.5868417024612427
5
train loss item: 0.3822873830795288
6
train loss item: 0.3291281759738922
7
train loss item: 1.028601884841919
8
train loss item: 0.1698111891746521
9
train loss item: 0.3847709000110626
10
train loss item: 0.46388959884643555
11
train loss item: 0.3588963747024536
12
train loss item: 0.13874585926532745
13
train loss item: 0.5792500972747803
14
train loss item: 0.2724764049053192
15
train loss item: 1.099242091178894
16
train loss item: 0.09844200313091278
17
train loss item: 0.4011560380458832
18
train loss item: 0.46965551376342773
19
train loss item: 0.4365765452384949
20
train loss item: 0.31845444440841675
21
train loss item: 0.15102438628673553
22
train loss item: 1.692840576171875
23
train loss item: 1.1167936325073242
24
train loss item: 0.8853734135627747
25
train loss item: 0.21264301240444183
26
train loss item: 0.25218862295150757
27
train loss item: 0.30269455909729004
28
train loss item: 0.11220008134841919
29
train loss item: 1.3295471668243408
30
train loss item: 2.863866090774536
31
train loss item: 0.7051288485527039
32
train loss item: 0.15445028245449066
33
train loss item: 0.5357793569564819
34
train loss item: 0.11926575005054474
35
train loss item: 2.7927937507629395
36
train loss item: 0.6644423604011536
37
train loss item: 0.4872170686721802
38
train loss item: 0.7159695029258728
39
train loss item: 0.2851826846599579
40
train loss item: 0.1877748817205429
41
train loss item: 0.33279281854629517
42
train loss item: 0.42753782868385315
43
train loss item: 0.26479968428611755
44
train loss item: 0.7764772772789001
45
train loss item: 0.20859244465827942
46
train loss item: 0.15129093825817108
47
train loss item: 0.6262611746788025
48
train loss item: 0.30695733428001404
49
train loss item: 0.20828574895858765
50
train loss item: 0.4846822917461395
51
train loss item: 1.4159177541732788
52
train loss item: 0.10128758102655411
53
train loss item: 0.21540242433547974
54
train loss item: 2.671515703201294
55
train loss item: 0.2612287104129791
56
train loss item: 0.31787508726119995
57
train loss item: 0.32589322328567505
58
train loss item: 0.23145456612110138
59
train loss item: 0.1629592329263687
60
train loss item: 1.4126642942428589
61
train loss item: 2.5493128299713135
62
train loss item: 0.3154025971889496
63
train loss item: 0.6442998051643372
64
train loss item: 0.2483440637588501
65
train loss item: 0.9285319447517395
66
train loss item: 0.5207637548446655
67
train loss item: 0.2803442180156708
68
train loss item: 0.583650529384613
69
train loss item: 0.5340844988822937
70
train loss item: 0.42642077803611755
71
train loss item: 0.15523545444011688
72
train loss item: 0.22986148297786713
73
train loss item: 0.42720916867256165
74
train loss item: 0.1061815470457077
75
train loss item: 0.16099706292152405
76
train loss item: 1.1286393404006958
77
train loss item: 1.8817641735076904
78
train loss item: 0.0764949843287468
79
train loss item: 0.44626671075820923
80
train loss item: 0.1987297534942627
81
train loss item: 0.29250290989875793
82
train loss item: 0.2622082531452179
83
train loss item: 1.1321706771850586
84
train loss item: 0.5733901858329773
85
train loss item: 0.8783671259880066
86
train loss item: 4.820127010345459
87
train loss item: 0.22807303071022034
88
train loss item: 0.5077831149101257
epoch train loss: 0.6513283840391073
testing phase
test loss item: 0.6465536952018738
test loss item: 0.15147216618061066
test loss item: 0.6569714546203613
test loss item: 0.4261235296726227
test loss item: 0.33469659090042114
test loss item: 0.17306481301784515
test loss item: 3.624080181121826
test loss item: 1.3876558542251587
test loss item: 0.27391454577445984
test loss item: 0.5130000114440918
test loss item: 1.0992029905319214
test loss item: 0.3982168138027191
test loss item: 0.22609767317771912
test loss item: 1.505800485610962
test loss item: 0.22916166484355927
test loss item: 0.17892315983772278
test loss item: 0.4298320412635803
test loss item: 0.5839790105819702
test loss item: 2.2093262672424316
test loss item: 0.49219775199890137
test loss item: 1.5037990808486938
test loss item: 0.6411082744598389
test loss item: 0.528318464756012
test loss item: 0.2596774399280548
test loss item: 0.29709339141845703
test loss item: 0.6996183395385742
test loss item: 0.4996281564235687
test loss item: 0.2432260662317276
test loss item: 0.6783341765403748
test loss item: 0.4740464389324188
test loss item: 1.442176103591919
test loss item: 0.186695396900177
test loss item: 0.20655272901058197
test loss item: 1.0002830028533936
test loss item: 0.5206847190856934
test loss item: 0.6467905044555664
test loss item: 1.528018832206726
test loss item: 1.6357954740524292
test loss item: 0.728415846824646
test loss item: 0.43624648451805115
test loss item: 0.4752655327320099
test loss item: 1.7267876863479614
test loss item: 0.44573211669921875
test loss item: 0.45294708013534546
test loss item: 0.916002631187439
test loss item: 0.7522977590560913
test loss item: 0.7022454142570496
test loss item: 0.4010801613330841
test loss item: 0.5803750157356262
test loss item: 1.4209924936294556
test loss item: 0.5600839853286743
test loss item: 0.1880124807357788
test loss item: 0.34564533829689026
test loss item: 0.4713963568210602
test loss item: 0.5622454881668091
test loss item: 1.03703773021698
test loss item: 0.8961556553840637
test loss item: 1.403232455253601
test loss item: 0.3310844600200653
test loss item: 0.26813390851020813
test loss item: 0.5823677182197571
test loss item: 0.3510696291923523
test loss item: 0.6955950856208801
test loss item: 0.34125328063964844
test loss item: 1.57272469997406
test loss item: 0.5974783897399902
test loss item: 0.4340667426586151
test loss item: 0.3796912133693695
test loss item: 0.6275675296783447
test loss item: 0.8200361132621765
test loss item: 0.133931502699852
test loss item: 2.2748100757598877
test loss item: 0.8419560194015503
test loss item: 0.78729248046875
test loss item: 0.22615092992782593
test loss item: 0.23503464460372925
test loss item: 0.27432429790496826
test loss item: 1.7714563608169556
test loss item: 1.597555160522461
test loss item: 0.781466543674469
test loss item: 0.1398228108882904
test loss item: 2.413733720779419
test loss item: 1.5491507053375244
test loss item: 1.1321934461593628
test loss item: 0.5704789161682129
test loss item: 1.7952923774719238
test loss item: 0.14093667268753052
test loss item: 0.18416984379291534
test loss item: 3.650686025619507
Epoch [10/10], Training Loss: 0.6513, Testing Loss: 0.7925
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
loss item: 0.5081289410591125
loss item: 0.2895171046257019
loss item: 1.780672311782837
loss item: 1.2456928491592407
loss item: 1.2553930282592773
loss item: 0.822643518447876
loss item: 1.8223116397857666
loss item: 1.488970160484314
loss item: 0.271728515625
loss item: 0.5752128958702087
loss item: 2.1577775478363037
loss item: 0.1922420859336853
loss item: 1.9076833724975586
loss item: 0.306434690952301
loss item: 0.5229589343070984
loss item: 0.45249179005622864
loss item: 0.6161803603172302
loss item: 0.9197396039962769
loss item: 1.694383978843689
loss item: 0.9684650897979736
loss item: 0.8147136569023132
loss item: 0.44020241498947144
loss item: 0.5412051677703857
loss item: 0.504138171672821
loss item: 0.6201567649841309
loss item: 1.3687171936035156
loss item: 1.502066731452942
loss item: 0.1921241730451584
loss item: 0.18060120940208435
loss item: 0.7260140180587769
loss item: 1.9285951852798462
loss item: 2.187960147857666
loss item: 0.238819882273674
loss item: 1.0300652980804443
loss item: 0.22654099762439728
loss item: 0.28061607480049133
loss item: 0.8114057779312134
loss item: 0.3496284484863281
loss item: 0.6892244815826416
loss item: 1.3698617219924927
loss item: 1.4465185403823853
loss item: 0.5052787661552429
loss item: 0.30835703015327454
loss item: 0.17475995421409607
Val Loss: 0.8690
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.005, epochs: 10, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 10 0.005 2 360 done at Wed Nov 13 16:28:09 CET 2024
UNet6 with 1 10 0.0001 4 360 start at Wed Nov 13 16:28:09 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 0.28402212262153625
UNet6 with 1 10 0.0001 4 360 done at Wed Nov 13 16:28:44 CET 2024
UNet6 with 1 10 0.0005 4 360 start at Wed Nov 13 16:28:44 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 806.2598876953125
UNet6 with 1 10 0.0005 4 360 done at Wed Nov 13 16:29:18 CET 2024
UNet6 with 1 10 0.001 4 360 start at Wed Nov 13 16:29:18 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 10, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 7438055.5
UNet6 with 1 10 0.001 4 360 done at Wed Nov 13 16:29:54 CET 2024
UNet6 with 1 10 0.005 4 360 start at Wed Nov 13 16:29:54 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 10, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: inf
UNet6 with 1 10 0.005 4 360 done at Wed Nov 13 16:30:29 CET 2024
UNet6 with 1 10 0.0001 8 360 start at Wed Nov 13 16:30:29 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0001 8 360 done at Wed Nov 13 16:31:04 CET 2024
UNet6 with 1 10 0.0005 8 360 start at Wed Nov 13 16:31:04 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0005 8 360 done at Wed Nov 13 16:31:41 CET 2024
UNet6 with 1 10 0.001 8 360 start at Wed Nov 13 16:31:41 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 10, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.001 8 360 done at Wed Nov 13 16:32:17 CET 2024
UNet6 with 1 10 0.005 8 360 start at Wed Nov 13 16:32:17 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 10, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.005 8 360 done at Wed Nov 13 16:32:55 CET 2024
UNet6 with 1 10 0.0001 16 360 start at Wed Nov 13 16:32:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0001 16 360 done at Wed Nov 13 16:33:30 CET 2024
UNet6 with 1 10 0.0005 16 360 start at Wed Nov 13 16:33:30 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0005 16 360 done at Wed Nov 13 16:34:04 CET 2024
UNet6 with 1 10 0.001 16 360 start at Wed Nov 13 16:34:04 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 10, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.001 16 360 done at Wed Nov 13 16:34:40 CET 2024
UNet6 with 1 10 0.005 16 360 start at Wed Nov 13 16:34:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 10, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.005 16 360 done at Wed Nov 13 16:35:17 CET 2024
UNet6 with 1 10 0.0001 32 360 start at Wed Nov 13 16:35:17 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0001 32 360 done at Wed Nov 13 16:35:55 CET 2024
UNet6 with 1 10 0.0005 32 360 start at Wed Nov 13 16:35:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0005 32 360 done at Wed Nov 13 16:36:32 CET 2024
UNet6 with 1 10 0.001 32 360 start at Wed Nov 13 16:36:32 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 10, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.001 32 360 done at Wed Nov 13 16:37:10 CET 2024
UNet6 with 1 10 0.005 32 360 start at Wed Nov 13 16:37:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 10, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.005 32 360 done at Wed Nov 13 16:37:48 CET 2024
UNet6 with 1 10 0.0001 64 360 start at Wed Nov 13 16:37:48 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0001 64 360 done at Wed Nov 13 16:38:25 CET 2024
UNet6 with 1 10 0.0005 64 360 start at Wed Nov 13 16:38:25 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0005 64 360 done at Wed Nov 13 16:39:03 CET 2024
UNet6 with 1 10 0.001 64 360 start at Wed Nov 13 16:39:03 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 10, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.001 64 360 done at Wed Nov 13 16:39:40 CET 2024
UNet6 with 1 10 0.005 64 360 start at Wed Nov 13 16:39:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 10, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.005 64 360 done at Wed Nov 13 16:40:17 CET 2024
UNet6 with 1 10 0.0001 128 360 start at Wed Nov 13 16:40:17 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0001 128 360 done at Wed Nov 13 16:40:55 CET 2024
UNet6 with 1 10 0.0005 128 360 start at Wed Nov 13 16:40:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0005 128 360 done at Wed Nov 13 16:41:32 CET 2024
UNet6 with 1 10 0.001 128 360 start at Wed Nov 13 16:41:32 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 10, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.001 128 360 done at Wed Nov 13 16:42:10 CET 2024
UNet6 with 1 10 0.005 128 360 start at Wed Nov 13 16:42:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 10, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.005 128 360 done at Wed Nov 13 16:42:47 CET 2024
UNet6 with 1 10 0.0001 256 360 start at Wed Nov 13 16:42:47 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 10, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0001 256 360 done at Wed Nov 13 16:43:25 CET 2024
UNet6 with 1 10 0.0005 256 360 start at Wed Nov 13 16:43:25 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 10, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.0005 256 360 done at Wed Nov 13 16:44:03 CET 2024
UNet6 with 1 10 0.001 256 360 start at Wed Nov 13 16:44:03 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 10, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.001 256 360 done at Wed Nov 13 16:44:40 CET 2024
UNet6 with 1 10 0.005 256 360 start at Wed Nov 13 16:44:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 10, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/10
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 10 0.005 256 360 done at Wed Nov 13 16:45:18 CET 2024
UNet6 with 1 50 0.0001 2 360 start at Wed Nov 13 16:45:18 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 0.32543858885765076
test loss item: 0.3201671838760376
test loss item: 1.2930320501327515
test loss item: 0.45639359951019287
test loss item: 0.5333396792411804
test loss item: 0.30889764428138733
test loss item: 3.5530126094818115
test loss item: 1.234115719795227
test loss item: 0.476423978805542
test loss item: 0.778984546661377
test loss item: 1.7774710655212402
test loss item: 0.39120641350746155
test loss item: 0.37649041414260864
test loss item: 0.5524864196777344
test loss item: 0.4167979657649994
test loss item: 0.32238027453422546
test loss item: 0.5221328735351562
test loss item: 0.9708770513534546
test loss item: 1.2458000183105469
test loss item: 0.4878620505332947
test loss item: 1.5960745811462402
test loss item: 0.7644118070602417
test loss item: 0.6354523301124573
test loss item: 0.3850398659706116
test loss item: 0.4352385401725769
test loss item: 0.4026394784450531
test loss item: 0.58271324634552
test loss item: 0.41043102741241455
test loss item: 0.6289176940917969
test loss item: 0.6483367681503296
test loss item: 1.7453397512435913
test loss item: 0.31950175762176514
test loss item: 0.35034263134002686
test loss item: 1.12245774269104
test loss item: 0.9462670683860779
test loss item: 1.113990068435669
test loss item: 1.5381397008895874
test loss item: 3.152377128601074
test loss item: 0.9831701517105103
test loss item: 0.5262065529823303
test loss item: 0.5640122890472412
test loss item: 0.3411385416984558
test loss item: 0.6919870972633362
test loss item: 0.4776293933391571
test loss item: 1.2580336332321167
test loss item: 0.7641651034355164
test loss item: 0.5913205146789551
test loss item: 0.427951842546463
test loss item: 1.0075477361679077
test loss item: 1.388818383216858
test loss item: 0.6537537574768066
test loss item: 0.3242349326610565
test loss item: 0.48420798778533936
test loss item: 0.47728821635246277
test loss item: 0.6459164619445801
test loss item: 1.8029687404632568
test loss item: 1.2264267206192017
test loss item: 0.6554515361785889
test loss item: 0.486260324716568
test loss item: 0.39739689230918884
test loss item: 0.8615291118621826
test loss item: 0.5327340364456177
test loss item: 0.38816121220588684
test loss item: 0.4550304114818573
test loss item: 2.000312328338623
test loss item: 0.6046019792556763
test loss item: 0.6398140788078308
test loss item: 0.4611686170101166
test loss item: 1.0433357954025269
test loss item: 0.9037917256355286
test loss item: 0.2714395821094513
test loss item: 2.0580642223358154
test loss item: 0.6133452653884888
test loss item: 0.7100709676742554
test loss item: 0.30532658100128174
test loss item: 0.34291383624076843
test loss item: 0.38030973076820374
test loss item: 3.477576971054077
test loss item: 0.8611140847206116
test loss item: 0.36515647172927856
test loss item: 0.25860074162483215
test loss item: 2.1804089546203613
test loss item: 1.6943840980529785
test loss item: 2.3984882831573486
test loss item: 0.45027413964271545
test loss item: 0.4050922691822052
test loss item: 0.28383657336235046
test loss item: 0.312621533870697
test loss item: 0.28796151280403137
Epoch [1/50], Training Loss: 1.0161, Testing Loss: 0.8409
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8469700217247009
1
train loss item: 2.2568891048431396
2
train loss item: 0.5336769223213196
3
train loss item: 1.237526774406433
4
train loss item: 0.9404008984565735
5
train loss item: 0.6270371675491333
6
train loss item: 0.57844078540802
7
train loss item: 1.4458200931549072
8
train loss item: 0.47675803303718567
9
train loss item: 0.5896623730659485
10
train loss item: 0.7542068362236023
11
train loss item: 0.48272591829299927
12
train loss item: 0.4065133035182953
13
train loss item: 0.9814792275428772
14
train loss item: 0.5562806129455566
15
train loss item: 1.2292604446411133
16
train loss item: 0.3920826315879822
17
train loss item: 0.5793091058731079
18
train loss item: 0.7637796998023987
19
train loss item: 0.5272666811943054
20
train loss item: 0.4833765923976898
21
train loss item: 0.3846867084503174
22
train loss item: 1.8146706819534302
23
train loss item: 1.5029590129852295
24
train loss item: 1.02009916305542
25
train loss item: 0.5557008385658264
26
train loss item: 0.45766282081604004
27
train loss item: 0.6440454125404358
28
train loss item: 0.3889157474040985
29
train loss item: 1.458027958869934
30
train loss item: 3.3603432178497314
31
train loss item: 1.1073217391967773
32
train loss item: 0.4354054033756256
33
train loss item: 0.9232630133628845
34
train loss item: 0.5001205205917358
35
train loss item: 3.199995279312134
36
train loss item: 0.9644607901573181
37
train loss item: 0.5206009149551392
38
train loss item: 1.0942904949188232
39
train loss item: 0.6534966826438904
40
train loss item: 0.4141879081726074
41
train loss item: 0.6332598328590393
42
train loss item: 0.4832932949066162
43
train loss item: 0.49745216965675354
44
train loss item: 1.2244560718536377
45
train loss item: 0.4191514551639557
46
train loss item: 0.4505915939807892
47
train loss item: 0.7244898080825806
48
train loss item: 0.5662857890129089
49
train loss item: 0.45370593667030334
50
train loss item: 0.5387917160987854
51
train loss item: 1.5974620580673218
52
train loss item: 0.4117096960544586
53
train loss item: 0.4850711226463318
54
train loss item: 3.072237253189087
55
train loss item: 0.4860619008541107
56
train loss item: 0.6088640093803406
57
train loss item: 0.5018900632858276
58
train loss item: 0.4447954297065735
59
train loss item: 0.48289012908935547
60
train loss item: 1.7332994937896729
61
train loss item: 3.049617290496826
62
train loss item: 0.5403962731361389
63
train loss item: 0.7169005274772644
64
train loss item: 0.4913247525691986
65
train loss item: 1.0675947666168213
66
train loss item: 0.7613896727561951
67
train loss item: 0.4965679943561554
68
train loss item: 0.700104832649231
69
train loss item: 0.6811779141426086
70
train loss item: 0.5612931847572327
71
train loss item: 0.42531144618988037
72
train loss item: 0.528998851776123
73
train loss item: 0.586263120174408
74
train loss item: 0.46703168749809265
75
train loss item: 0.4403144121170044
76
train loss item: 1.4954246282577515
77
train loss item: 1.9771878719329834
78
train loss item: 0.40473371744155884
79
train loss item: 0.5859912633895874
80
train loss item: 0.4113095700740814
81
train loss item: 0.45442962646484375
82
train loss item: 0.5650709867477417
83
train loss item: 1.2717928886413574
84
train loss item: 0.7470484972000122
85
train loss item: 1.1924268007278442
86
train loss item: 5.400422096252441
87
train loss item: 0.538705587387085
88
train loss item: 0.6909709572792053
epoch train loss: 0.9118570514609304
testing phase
test loss item: 0.32313835620880127
test loss item: 0.33549079298973083
test loss item: 1.2464580535888672
test loss item: 0.4215610921382904
test loss item: 0.545681357383728
test loss item: 0.3143472373485565
test loss item: 3.2590036392211914
test loss item: 1.0636874437332153
test loss item: 0.47387224435806274
test loss item: 0.7689830660820007
test loss item: 1.6702098846435547
test loss item: 0.36385172605514526
test loss item: 0.3599485456943512
test loss item: 0.5972532033920288
test loss item: 0.4212416112422943
test loss item: 0.34016671776771545
test loss item: 0.46121975779533386
test loss item: 0.9875484704971313
test loss item: 1.118828296661377
test loss item: 0.4557102620601654
test loss item: 1.62374746799469
test loss item: 0.6738596558570862
test loss item: 0.6389990448951721
test loss item: 0.3596741855144501
test loss item: 0.4314025938510895
test loss item: 0.3838667869567871
test loss item: 0.5595067143440247
test loss item: 0.4218214452266693
test loss item: 0.6222934722900391
test loss item: 0.6317676305770874
test loss item: 1.6140263080596924
test loss item: 0.32190608978271484
test loss item: 0.33373966813087463
test loss item: 1.109312891960144
test loss item: 0.9489903450012207
test loss item: 1.1102555990219116
test loss item: 1.4203596115112305
test loss item: 2.964846134185791
test loss item: 0.966056764125824
test loss item: 0.4911685287952423
test loss item: 0.5290465950965881
test loss item: 0.32827121019363403
test loss item: 0.7328452467918396
test loss item: 0.4300273656845093
test loss item: 1.2944674491882324
test loss item: 0.6773479580879211
test loss item: 0.5981626510620117
test loss item: 0.4238423705101013
test loss item: 0.9695281982421875
test loss item: 1.2928868532180786
test loss item: 0.690413773059845
test loss item: 0.3104289174079895
test loss item: 0.48790881037712097
test loss item: 0.4154609739780426
test loss item: 0.6776193976402283
test loss item: 1.7218269109725952
test loss item: 1.172100305557251
test loss item: 0.7466410398483276
test loss item: 0.47152912616729736
test loss item: 0.4307118356227875
test loss item: 0.8777498006820679
test loss item: 0.4464675188064575
test loss item: 0.3672596216201782
test loss item: 0.42773938179016113
test loss item: 1.8666683435440063
test loss item: 0.5466116666793823
test loss item: 0.5705507397651672
test loss item: 0.44019070267677307
test loss item: 1.0254302024841309
test loss item: 0.8006142377853394
test loss item: 0.28219568729400635
test loss item: 1.832497477531433
test loss item: 0.6555683016777039
test loss item: 0.617949366569519
test loss item: 0.2844226360321045
test loss item: 0.32915470004081726
test loss item: 0.35920450091362
test loss item: 3.2612061500549316
test loss item: 0.8693538904190063
test loss item: 0.36148953437805176
test loss item: 0.25196540355682373
test loss item: 2.029910087585449
test loss item: 1.5777088403701782
test loss item: 2.250333309173584
test loss item: 0.45082563161849976
test loss item: 0.3806471824645996
test loss item: 0.28600361943244934
test loss item: 0.3300008177757263
test loss item: 0.2796914279460907
Epoch [2/50], Training Loss: 0.9119, Testing Loss: 0.8047
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8339841961860657
1
train loss item: 2.155839443206787
2
train loss item: 0.5232412815093994
3
train loss item: 1.150844693183899
4
train loss item: 0.882523238658905
5
train loss item: 0.6161549687385559
6
train loss item: 0.5675970315933228
7
train loss item: 1.3633010387420654
8
train loss item: 0.4495686888694763
9
train loss item: 0.5440057516098022
10
train loss item: 0.7016858458518982
11
train loss item: 0.45297563076019287
12
train loss item: 0.3669850826263428
13
train loss item: 0.9551968574523926
14
train loss item: 0.5574626326560974
15
train loss item: 1.1836556196212769
16
train loss item: 0.3848850131034851
17
train loss item: 0.5527244806289673
18
train loss item: 0.719939649105072
19
train loss item: 0.48777318000793457
20
train loss item: 0.46295514702796936
21
train loss item: 0.36673852801322937
22
train loss item: 1.7580007314682007
23
train loss item: 1.4418275356292725
24
train loss item: 0.9778796434402466
25
train loss item: 0.5289973616600037
26
train loss item: 0.43923649191856384
27
train loss item: 0.6160111427307129
28
train loss item: 0.37907761335372925
29
train loss item: 1.4136497974395752
30
train loss item: 3.1977977752685547
31
train loss item: 1.0274486541748047
32
train loss item: 0.37705734372138977
33
train loss item: 0.8513282537460327
34
train loss item: 0.5206930041313171
35
train loss item: 3.1048710346221924
36
train loss item: 0.9418485760688782
37
train loss item: 0.4913369119167328
38
train loss item: 1.0372068881988525
39
train loss item: 0.6275733113288879
40
train loss item: 0.3992249369621277
41
train loss item: 0.5987964272499084
42
train loss item: 0.4522729218006134
43
train loss item: 0.4486117362976074
44
train loss item: 1.1767184734344482
45
train loss item: 0.4142310917377472
46
train loss item: 0.4471043050289154
47
train loss item: 0.6793163418769836
48
train loss item: 0.5297558307647705
49
train loss item: 0.4446152448654175
50
train loss item: 0.5057280659675598
51
train loss item: 1.5452731847763062
52
train loss item: 0.36935728788375854
53
train loss item: 0.47329387068748474
54
train loss item: 2.9714455604553223
55
train loss item: 0.49070268869400024
56
train loss item: 0.5764620304107666
57
train loss item: 0.4921422004699707
58
train loss item: 0.39828577637672424
59
train loss item: 0.4151388108730316
60
train loss item: 1.6824674606323242
61
train loss item: 2.940248727798462
62
train loss item: 0.4804028272628784
63
train loss item: 0.6669731140136719
64
train loss item: 0.43764612078666687
65
train loss item: 1.0308862924575806
66
train loss item: 0.7245259881019592
67
train loss item: 0.47396448254585266
68
train loss item: 0.6318886280059814
69
train loss item: 0.6422450542449951
70
train loss item: 0.5253357291221619
71
train loss item: 0.4606528878211975
72
train loss item: 0.4892352223396301
73
train loss item: 0.5586839914321899
74
train loss item: 0.4522111415863037
75
train loss item: 0.38975849747657776
76
train loss item: 1.4339712858200073
77
train loss item: 1.9305144548416138
78
train loss item: 0.368850439786911
79
train loss item: 0.5352991223335266
80
train loss item: 0.4268273413181305
81
train loss item: 0.4208105802536011
82
train loss item: 0.5485832095146179
83
train loss item: 1.2255637645721436
84
train loss item: 0.7117674946784973
85
train loss item: 1.1252810955047607
86
train loss item: 5.23826789855957
87
train loss item: 0.5173043608665466
88
train loss item: 0.6507450342178345
epoch train loss: 0.8714749337582106
testing phase
test loss item: 0.31795457005500793
test loss item: 0.33500340580940247
test loss item: 1.22190260887146
test loss item: 0.3949345052242279
test loss item: 0.5478627681732178
test loss item: 0.3122747540473938
test loss item: 2.9288077354431152
test loss item: 0.889796257019043
test loss item: 0.47539907693862915
test loss item: 0.7647536993026733
test loss item: 1.6291959285736084
test loss item: 0.3499634563922882
test loss item: 0.36035239696502686
test loss item: 0.6533820033073425
test loss item: 0.4128269851207733
test loss item: 0.34199076890945435
test loss item: 0.4320693910121918
test loss item: 0.9891956448554993
test loss item: 1.0085471868515015
test loss item: 0.46115145087242126
test loss item: 1.6226433515548706
test loss item: 0.6145684719085693
test loss item: 0.6501948237419128
test loss item: 0.3369729518890381
test loss item: 0.4258705973625183
test loss item: 0.40289613604545593
test loss item: 0.5507012605667114
test loss item: 0.42514339089393616
test loss item: 0.6126364469528198
test loss item: 0.6209904551506042
test loss item: 1.5354390144348145
test loss item: 0.3173537850379944
test loss item: 0.3136001527309418
test loss item: 1.0968449115753174
test loss item: 0.9422520399093628
test loss item: 1.0225224494934082
test loss item: 1.2986174821853638
test loss item: 2.902078151702881
test loss item: 0.9525632262229919
test loss item: 0.46431851387023926
test loss item: 0.4985174238681793
test loss item: 0.3405885696411133
test loss item: 0.7489770650863647
test loss item: 0.4025125503540039
test loss item: 1.3049724102020264
test loss item: 0.6391319632530212
test loss item: 0.6088792085647583
test loss item: 0.45782670378685
test loss item: 0.947560727596283
test loss item: 1.2390003204345703
test loss item: 0.7077956795692444
test loss item: 0.31042444705963135
test loss item: 0.4959840476512909
test loss item: 0.38483959436416626
test loss item: 0.6994051933288574
test loss item: 1.6884492635726929
test loss item: 1.0632306337356567
test loss item: 0.7790811657905579
test loss item: 0.46323174238204956
test loss item: 0.4554395377635956
test loss item: 0.8789593577384949
test loss item: 0.3961588144302368
test loss item: 0.37443986535072327
test loss item: 0.4060540199279785
test loss item: 1.7633836269378662
test loss item: 0.506710410118103
test loss item: 0.5404588580131531
test loss item: 0.4258936047554016
test loss item: 1.0155770778656006
test loss item: 0.7440217137336731
test loss item: 0.28759053349494934
test loss item: 1.607879877090454
test loss item: 0.680265486240387
test loss item: 0.568448543548584
test loss item: 0.29144391417503357
test loss item: 0.33735382556915283
test loss item: 0.3394831717014313
test loss item: 3.1792073249816895
test loss item: 0.8882248401641846
test loss item: 0.3628036379814148
test loss item: 0.2422766089439392
test loss item: 1.9008512496948242
test loss item: 1.475480318069458
test loss item: 2.1858761310577393
test loss item: 0.4629882574081421
test loss item: 0.39659690856933594
test loss item: 0.2774353623390198
test loss item: 0.3253585696220398
test loss item: 0.31033265590667725
Epoch [3/50], Training Loss: 0.8715, Testing Loss: 0.7791
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8108084201812744
1
train loss item: 2.0759809017181396
2
train loss item: 0.4898815155029297
3
train loss item: 1.092602252960205
4
train loss item: 0.8475688695907593
5
train loss item: 0.6006972789764404
6
train loss item: 0.5378050208091736
7
train loss item: 1.3109055757522583
8
train loss item: 0.4388323426246643
9
train loss item: 0.5080493092536926
10
train loss item: 0.670032262802124
11
train loss item: 0.43226227164268494
12
train loss item: 0.3437403738498688
13
train loss item: 0.9259993433952332
14
train loss item: 0.5493934750556946
15
train loss item: 1.1318696737289429
16
train loss item: 0.36250928044319153
17
train loss item: 0.5233271718025208
18
train loss item: 0.6783027648925781
19
train loss item: 0.4564222991466522
20
train loss item: 0.42156511545181274
21
train loss item: 0.360436350107193
22
train loss item: 1.6809577941894531
23
train loss item: 1.4047471284866333
24
train loss item: 0.9263560175895691
25
train loss item: 0.5049294829368591
26
train loss item: 0.43008047342300415
27
train loss item: 0.5890274047851562
28
train loss item: 0.3583187758922577
29
train loss item: 1.3561855554580688
30
train loss item: 3.10564923286438
31
train loss item: 0.9759548306465149
32
train loss item: 0.3571937680244446
33
train loss item: 0.8014444708824158
34
train loss item: 0.5056254267692566
35
train loss item: 3.045522451400757
36
train loss item: 0.9087722301483154
37
train loss item: 0.4551425874233246
38
train loss item: 0.9830286502838135
39
train loss item: 0.6014152765274048
40
train loss item: 0.3791196048259735
41
train loss item: 0.5738795399665833
42
train loss item: 0.4293659031391144
43
train loss item: 0.4173487722873688
44
train loss item: 1.1409655809402466
45
train loss item: 0.4043237268924713
46
train loss item: 0.43998920917510986
47
train loss item: 0.6404938101768494
48
train loss item: 0.5066149234771729
49
train loss item: 0.4372107684612274
50
train loss item: 0.46831732988357544
51
train loss item: 1.4908002614974976
52
train loss item: 0.3506079614162445
53
train loss item: 0.4517662525177002
54
train loss item: 2.912156581878662
55
train loss item: 0.48277050256729126
56
train loss item: 0.5510663390159607
57
train loss item: 0.47791534662246704
58
train loss item: 0.3733982443809509
59
train loss item: 0.39021700620651245
60
train loss item: 1.6149908304214478
61
train loss item: 2.8774216175079346
62
train loss item: 0.4480277895927429
63
train loss item: 0.6163225769996643
64
train loss item: 0.4062311351299286
65
train loss item: 0.9675815105438232
66
train loss item: 0.6944425106048584
67
train loss item: 0.45582976937294006
68
train loss item: 0.5773131251335144
69
train loss item: 0.6074137687683105
70
train loss item: 0.49719342589378357
71
train loss item: 0.44620922207832336
72
train loss item: 0.469643235206604
73
train loss item: 0.5289588570594788
74
train loss item: 0.44426441192626953
75
train loss item: 0.3619333803653717
76
train loss item: 1.3938376903533936
77
train loss item: 1.8615220785140991
78
train loss item: 0.3491065502166748
79
train loss item: 0.49164482951164246
80
train loss item: 0.41383516788482666
81
train loss item: 0.4007931351661682
82
train loss item: 0.5311732292175293
83
train loss item: 1.1701936721801758
84
train loss item: 0.6768920421600342
85
train loss item: 1.0704846382141113
86
train loss item: 5.145071506500244
87
train loss item: 0.4921460747718811
88
train loss item: 0.6109681129455566
epoch train loss: 0.8370687301908986
testing phase
test loss item: 0.30775806307792664
test loss item: 0.3258143961429596
test loss item: 1.1821327209472656
test loss item: 0.3921280801296234
test loss item: 0.5345216989517212
test loss item: 0.30030298233032227
test loss item: 2.674144983291626
test loss item: 0.7942736148834229
test loss item: 0.4592096507549286
test loss item: 0.738875687122345
test loss item: 1.616614818572998
test loss item: 0.35423293709754944
test loss item: 0.3492778539657593
test loss item: 0.6735019087791443
test loss item: 0.39678722620010376
test loss item: 0.33603009581565857
test loss item: 0.4119952321052551
test loss item: 0.9577990174293518
test loss item: 0.9643687009811401
test loss item: 0.4510314464569092
test loss item: 1.5708104372024536
test loss item: 0.5862696766853333
test loss item: 0.6374735832214355
test loss item: 0.31966790556907654
test loss item: 0.4100848436355591
test loss item: 0.411099910736084
test loss item: 0.5351224541664124
test loss item: 0.4139607548713684
test loss item: 0.5928141474723816
test loss item: 0.5945517420768738
test loss item: 1.4850165843963623
test loss item: 0.31441786885261536
test loss item: 0.29711011052131653
test loss item: 1.06705641746521
test loss item: 0.909639298915863
test loss item: 0.9561935663223267
test loss item: 1.2183877229690552
test loss item: 2.8717055320739746
test loss item: 0.9257088899612427
test loss item: 0.4419702887535095
test loss item: 0.47393158078193665
test loss item: 0.33632317185401917
test loss item: 0.7221086025238037
test loss item: 0.39759790897369385
test loss item: 1.2685260772705078
test loss item: 0.619602382183075
test loss item: 0.5946896076202393
test loss item: 0.4600624144077301
test loss item: 0.9146065711975098
test loss item: 1.2111867666244507
test loss item: 0.6846043467521667
test loss item: 0.2962060272693634
test loss item: 0.4858265817165375
test loss item: 0.403663694858551
test loss item: 0.6865236163139343
test loss item: 1.6551570892333984
test loss item: 0.9967135190963745
test loss item: 0.745629072189331
test loss item: 0.44499170780181885
test loss item: 0.4517505168914795
test loss item: 0.8450803160667419
test loss item: 0.3694184124469757
test loss item: 0.3730672001838684
test loss item: 0.38889753818511963
test loss item: 1.6918002367019653
test loss item: 0.5134384036064148
test loss item: 0.519895613193512
test loss item: 0.4108377695083618
test loss item: 0.9941897392272949
test loss item: 0.7626914978027344
test loss item: 0.28554823994636536
test loss item: 1.4507932662963867
test loss item: 0.6628401875495911
test loss item: 0.5367685556411743
test loss item: 0.28925982117652893
test loss item: 0.3314896821975708
test loss item: 0.3226867914199829
test loss item: 3.137493133544922
test loss item: 0.8804183602333069
test loss item: 0.35482415556907654
test loss item: 0.23323333263397217
test loss item: 1.824426531791687
test loss item: 1.404819369316101
test loss item: 2.1530356407165527
test loss item: 0.46168550848960876
test loss item: 0.4018937349319458
test loss item: 0.2681317925453186
test loss item: 0.31411948800086975
test loss item: 0.3249461054801941
Epoch [4/50], Training Loss: 0.8371, Testing Loss: 0.7544
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7796609401702881
1
train loss item: 2.010059356689453
2
train loss item: 0.44511091709136963
3
train loss item: 1.0517438650131226
4
train loss item: 0.8450306057929993
5
train loss item: 0.57757967710495
6
train loss item: 0.49180009961128235
7
train loss item: 1.2760989665985107
8
train loss item: 0.40773940086364746
9
train loss item: 0.4794023931026459
10
train loss item: 0.6471192836761475
11
train loss item: 0.41555893421173096
12
train loss item: 0.3190993368625641
13
train loss item: 0.8921120166778564
14
train loss item: 0.5288026332855225
15
train loss item: 1.0764939785003662
16
train loss item: 0.32711538672447205
17
train loss item: 0.4874758720397949
18
train loss item: 0.6384450197219849
19
train loss item: 0.42818355560302734
20
train loss item: 0.3809441328048706
21
train loss item: 0.34640902280807495
22
train loss item: 1.5987602472305298
23
train loss item: 1.3802639245986938
24
train loss item: 0.8739868998527527
25
train loss item: 0.47697538137435913
26
train loss item: 0.40358397364616394
27
train loss item: 0.563049852848053
28
train loss item: 0.32396200299263
29
train loss item: 1.2944035530090332
30
train loss item: 3.051302909851074
31
train loss item: 0.9362643361091614
32
train loss item: 0.34588149189949036
33
train loss item: 0.760771632194519
34
train loss item: 0.4560913145542145
35
train loss item: 3.0069806575775146
36
train loss item: 0.8687840700149536
37
train loss item: 0.4212398827075958
38
train loss item: 0.9265044927597046
39
train loss item: 0.5739575028419495
40
train loss item: 0.34593287110328674
41
train loss item: 0.554138720035553
42
train loss item: 0.40638595819473267
43
train loss item: 0.39280709624290466
44
train loss item: 1.1122468709945679
45
train loss item: 0.3839446008205414
46
train loss item: 0.42057302594184875
47
train loss item: 0.6026238799095154
48
train loss item: 0.48460885882377625
49
train loss item: 0.4203546345233917
50
train loss item: 0.43820545077323914
51
train loss item: 1.438658356666565
52
train loss item: 0.32985472679138184
53
train loss item: 0.4154053330421448
54
train loss item: 2.8761720657348633
55
train loss item: 0.4509719908237457
56
train loss item: 0.5292982459068298
57
train loss item: 0.45409220457077026
58
train loss item: 0.3560706079006195
59
train loss item: 0.3754793405532837
60
train loss item: 1.5435209274291992
61
train loss item: 2.839668035507202
62
train loss item: 0.4227515757083893
63
train loss item: 0.5711086988449097
64
train loss item: 0.3833215534687042
65
train loss item: 0.8986271619796753
66
train loss item: 0.6659120321273804
67
train loss item: 0.43268099427223206
68
train loss item: 0.5251824259757996
69
train loss item: 0.5718252062797546
70
train loss item: 0.4679638147354126
71
train loss item: 0.395112007856369
72
train loss item: 0.4398232698440552
73
train loss item: 0.4954840838909149
74
train loss item: 0.40830540657043457
75
train loss item: 0.3373056650161743
76
train loss item: 1.3642897605895996
77
train loss item: 1.792600154876709
78
train loss item: 0.3277115821838379
79
train loss item: 0.45572367310523987
80
train loss item: 0.3728855550289154
81
train loss item: 0.3768095374107361
82
train loss item: 0.5061531066894531
83
train loss item: 1.1126750707626343
84
train loss item: 0.6400269269943237
85
train loss item: 1.0217664241790771
86
train loss item: 5.090869426727295
87
train loss item: 0.45434513688087463
88
train loss item: 0.569412350654602
epoch train loss: 0.8020947856849499
testing phase
test loss item: 0.2944079339504242
test loss item: 0.31115877628326416
test loss item: 1.1197236776351929
test loss item: 0.4002673923969269
test loss item: 0.508098304271698
test loss item: 0.2811153829097748
test loss item: 2.4720258712768555
test loss item: 0.7395989298820496
test loss item: 0.42620962858200073
test loss item: 0.6889616847038269
test loss item: 1.5894813537597656
test loss item: 0.3649256229400635
test loss item: 0.3259153366088867
test loss item: 0.6538464426994324
test loss item: 0.3734178841114044
test loss item: 0.32615044713020325
test loss item: 0.39542409777641296
test loss item: 0.8938087224960327
test loss item: 0.9357021450996399
test loss item: 0.4182967245578766
test loss item: 1.4634835720062256
test loss item: 0.5720834136009216
test loss item: 0.6062527894973755
test loss item: 0.30439653992652893
test loss item: 0.38704171776771545
test loss item: 0.4026276469230652
test loss item: 0.5040755867958069
test loss item: 0.3908088207244873
test loss item: 0.5614749193191528
test loss item: 0.5503042936325073
test loss item: 1.428540587425232
test loss item: 0.30953580141067505
test loss item: 0.28297945857048035
test loss item: 1.0153175592422485
test loss item: 0.8510465025901794
test loss item: 0.89387047290802
test loss item: 1.152208924293518
test loss item: 2.811809778213501
test loss item: 0.8805440664291382
test loss item: 0.42009496688842773
test loss item: 0.4534331262111664
test loss item: 0.32947438955307007
test loss item: 0.6613423228263855
test loss item: 0.4020794928073883
test loss item: 1.1827168464660645
test loss item: 0.597578227519989
test loss item: 0.5653376579284668
test loss item: 0.4178438186645508
test loss item: 0.8647207021713257
test loss item: 1.1736154556274414
test loss item: 0.6257843375205994
test loss item: 0.26680490374565125
test loss item: 0.4597395062446594
test loss item: 0.4372676908969879
test loss item: 0.6427798867225647
test loss item: 1.592572808265686
test loss item: 0.9511065483093262
test loss item: 0.659789502620697
test loss item: 0.41512224078178406
test loss item: 0.4266466200351715
test loss item: 0.7771083116531372
test loss item: 0.35032975673675537
test loss item: 0.3610040843486786
test loss item: 0.37155458331108093
test loss item: 1.620525598526001
test loss item: 0.5392459034919739
test loss item: 0.49479857087135315
test loss item: 0.39421167969703674
test loss item: 0.9604143500328064
test loss item: 0.7655041813850403
test loss item: 0.2775587737560272
test loss item: 1.335054874420166
test loss item: 0.6097002625465393
test loss item: 0.5110036730766296
test loss item: 0.27846789360046387
test loss item: 0.32539108395576477
test loss item: 0.3064116835594177
test loss item: 3.0769379138946533
test loss item: 0.8437519073486328
test loss item: 0.3389020562171936
test loss item: 0.22244851291179657
test loss item: 1.7589613199234009
test loss item: 1.3271862268447876
test loss item: 2.107534170150757
test loss item: 0.4446197748184204
test loss item: 0.39662104845046997
test loss item: 0.2579548954963684
test loss item: 0.3008650243282318
test loss item: 0.3266509771347046
Epoch [5/50], Training Loss: 0.8021, Testing Loss: 0.7204
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.748602569103241
1
train loss item: 1.9517829418182373
2
train loss item: 0.41519537568092346
3
train loss item: 1.0192244052886963
4
train loss item: 0.894048810005188
5
train loss item: 0.5546940565109253
6
train loss item: 0.4568100869655609
7
train loss item: 1.2496094703674316
8
train loss item: 0.381190687417984
9
train loss item: 0.45959967374801636
10
train loss item: 0.6275076270103455
11
train loss item: 0.40392738580703735
12
train loss item: 0.304228812456131
13
train loss item: 0.8573651313781738
14
train loss item: 0.5061242580413818
15
train loss item: 1.0250595808029175
16
train loss item: 0.30560600757598877
17
train loss item: 0.464793860912323
18
train loss item: 0.6037325263023376
19
train loss item: 0.40831005573272705
20
train loss item: 0.3664623498916626
21
train loss item: 0.33752259612083435
22
train loss item: 1.522081732749939
23
train loss item: 1.3595930337905884
24
train loss item: 0.8278939723968506
25
train loss item: 0.45202314853668213
26
train loss item: 0.37200385332107544
27
train loss item: 0.5421493649482727
28
train loss item: 0.30322331190109253
29
train loss item: 1.2347155809402466
30
train loss item: 3.011455535888672
31
train loss item: 0.9026116132736206
32
train loss item: 0.34614595770835876
33
train loss item: 0.7282379865646362
34
train loss item: 0.41544389724731445
35
train loss item: 2.9755706787109375
36
train loss item: 0.825667142868042
37
train loss item: 0.3970089256763458
38
train loss item: 0.8682070970535278
39
train loss item: 0.5498356819152832
40
train loss item: 0.3182787001132965
41
train loss item: 0.5385719537734985
42
train loss item: 0.38787946105003357
43
train loss item: 0.3830243647098541
44
train loss item: 1.0866726636886597
45
train loss item: 0.3660482168197632
46
train loss item: 0.39839762449264526
47
train loss item: 0.5699037909507751
48
train loss item: 0.46495288610458374
49
train loss item: 0.4028517007827759
50
train loss item: 0.42106306552886963
51
train loss item: 1.3907179832458496
52
train loss item: 0.3213968873023987
53
train loss item: 0.38304316997528076
54
train loss item: 2.8478095531463623
55
train loss item: 0.41298386454582214
56
train loss item: 0.5140069127082825
57
train loss item: 0.43129900097846985
58
train loss item: 0.3543808162212372
59
train loss item: 0.36845850944519043
60
train loss item: 1.475396752357483
61
train loss item: 2.8099191188812256
62
train loss item: 0.40563157200813293
63
train loss item: 0.5364493727684021
64
train loss item: 0.3755883276462555
65
train loss item: 0.8417280316352844
66
train loss item: 0.6378605961799622
67
train loss item: 0.41260582208633423
68
train loss item: 0.4824536144733429
69
train loss item: 0.5390900373458862
70
train loss item: 0.4430888891220093
71
train loss item: 0.350946307182312
72
train loss item: 0.41805705428123474
73
train loss item: 0.4664129614830017
74
train loss item: 0.37507736682891846
75
train loss item: 0.32431578636169434
76
train loss item: 1.338376760482788
77
train loss item: 1.7337982654571533
78
train loss item: 0.32134532928466797
79
train loss item: 0.4309845268726349
80
train loss item: 0.34380486607551575
81
train loss item: 0.356802761554718
82
train loss item: 0.47982290387153625
83
train loss item: 1.0581223964691162
84
train loss item: 0.6024861931800842
85
train loss item: 0.9773295521736145
86
train loss item: 5.050403118133545
87
train loss item: 0.42371076345443726
88
train loss item: 0.5321334600448608
epoch train loss: 0.7739410159293185
testing phase
test loss item: 0.28285765647888184
test loss item: 0.2910250723361969
test loss item: 1.038278341293335
test loss item: 0.39673641324043274
test loss item: 0.4713729918003082
test loss item: 0.25869959592819214
test loss item: 2.308614492416382
test loss item: 0.6804385185241699
test loss item: 0.38770467042922974
test loss item: 0.6292113661766052
test loss item: 1.516302466392517
test loss item: 0.35848477482795715
test loss item: 0.3048478960990906
test loss item: 0.5956932306289673
test loss item: 0.34451016783714294
test loss item: 0.3108348846435547
test loss item: 0.38500136137008667
test loss item: 0.8092104196548462
test loss item: 0.8820996284484863
test loss item: 0.388202965259552
test loss item: 1.3188745975494385
test loss item: 0.5528374314308167
test loss item: 0.5582733750343323
test loss item: 0.2905130982398987
test loss item: 0.3622836172580719
test loss item: 0.3818763196468353
test loss item: 0.471523642539978
test loss item: 0.35931968688964844
test loss item: 0.5230212807655334
test loss item: 0.5107801556587219
test loss item: 1.347151756286621
test loss item: 0.29419392347335815
test loss item: 0.27123507857322693
test loss item: 0.9430735111236572
test loss item: 0.7770939469337463
test loss item: 0.8116128444671631
test loss item: 1.0822099447250366
test loss item: 2.6699509620666504
test loss item: 0.8191039562225342
test loss item: 0.3989098370075226
test loss item: 0.4362823963165283
test loss item: 0.3216151297092438
test loss item: 0.5876280069351196
test loss item: 0.3949923813343048
test loss item: 1.0627949237823486
test loss item: 0.5728654265403748
test loss item: 0.523749828338623
test loss item: 0.3899497389793396
test loss item: 0.803936779499054
test loss item: 1.1039834022521973
test loss item: 0.5513961911201477
test loss item: 0.24738220870494843
test loss item: 0.42468276619911194
test loss item: 0.4384826719760895
test loss item: 0.5777075290679932
test loss item: 1.4862524271011353
test loss item: 0.893644392490387
test loss item: 0.5411104559898376
test loss item: 0.3828810751438141
test loss item: 0.3893232047557831
test loss item: 0.6959276795387268
test loss item: 0.33346280455589294
test loss item: 0.3437314033508301
test loss item: 0.35429808497428894
test loss item: 1.5240002870559692
test loss item: 0.5391833186149597
test loss item: 0.4661504626274109
test loss item: 0.37874844670295715
test loss item: 0.9124294519424438
test loss item: 0.6942453384399414
test loss item: 0.2641560733318329
test loss item: 1.2411518096923828
test loss item: 0.5349103808403015
test loss item: 0.4904263913631439
test loss item: 0.2694527208805084
test loss item: 0.3162161409854889
test loss item: 0.2906290590763092
test loss item: 2.945387363433838
test loss item: 0.7804785370826721
test loss item: 0.31965142488479614
test loss item: 0.21171297132968903
test loss item: 1.6681251525878906
test loss item: 1.2281696796417236
test loss item: 2.0102736949920654
test loss item: 0.41459453105926514
test loss item: 0.38791966438293457
test loss item: 0.24808616936206818
test loss item: 0.2868981659412384
test loss item: 0.32191887497901917
Epoch [6/50], Training Loss: 0.7739, Testing Loss: 0.6740
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7250450253486633
1
train loss item: 1.8963671922683716
2
train loss item: 0.40832939743995667
3
train loss item: 0.9848305583000183
4
train loss item: 0.9500287771224976
5
train loss item: 0.5386240482330322
6
train loss item: 0.44654932618141174
7
train loss item: 1.2223066091537476
8
train loss item: 0.3730277717113495
9
train loss item: 0.4458974301815033
10
train loss item: 0.6054260730743408
11
train loss item: 0.3943251967430115
12
train loss item: 0.2974990904331207
13
train loss item: 0.8258436322212219
14
train loss item: 0.4897993803024292
15
train loss item: 0.9829004406929016
16
train loss item: 0.29593533277511597
17
train loss item: 0.45851245522499084
18
train loss item: 0.5749285817146301
19
train loss item: 0.3978850245475769
20
train loss item: 0.3758917450904846
21
train loss item: 0.3357202708721161
22
train loss item: 1.4587929248809814
23
train loss item: 1.33553946018219
24
train loss item: 0.7916880249977112
25
train loss item: 0.4317263066768646
26
train loss item: 0.3518047630786896
27
train loss item: 0.5253665447235107
28
train loss item: 0.29419541358947754
29
train loss item: 1.1824442148208618
30
train loss item: 2.967198371887207
31
train loss item: 0.8705212473869324
32
train loss item: 0.3520706593990326
33
train loss item: 0.6986963748931885
34
train loss item: 0.40041860938072205
35
train loss item: 2.941817283630371
36
train loss item: 0.7837926745414734
37
train loss item: 0.3837820291519165
38
train loss item: 0.8099672794342041
39
train loss item: 0.5299599766731262
40
train loss item: 0.3043278455734253
41
train loss item: 0.522918701171875
42
train loss item: 0.37530380487442017
43
train loss item: 0.38143476843833923
44
train loss item: 1.06053626537323
45
train loss item: 0.3509347438812256
46
train loss item: 0.3800371289253235
47
train loss item: 0.5430422425270081
48
train loss item: 0.44694840908050537
49
train loss item: 0.38815465569496155
50
train loss item: 0.41307199001312256
51
train loss item: 1.3472073078155518
52
train loss item: 0.31587648391723633
53
train loss item: 0.3609805703163147
54
train loss item: 2.815133810043335
55
train loss item: 0.386679470539093
56
train loss item: 0.5028964281082153
57
train loss item: 0.41806337237358093
58
train loss item: 0.36060816049575806
59
train loss item: 0.3603958785533905
60
train loss item: 1.4173498153686523
61
train loss item: 2.7756054401397705
62
train loss item: 0.3934878408908844
63
train loss item: 0.5129815936088562
64
train loss item: 0.3745044469833374
65
train loss item: 0.8056831955909729
66
train loss item: 0.6096500754356384
67
train loss item: 0.3977501094341278
68
train loss item: 0.45496949553489685
69
train loss item: 0.5121408104896545
70
train loss item: 0.4238382875919342
71
train loss item: 0.3328893482685089
72
train loss item: 0.4082969129085541
73
train loss item: 0.44634196162223816
74
train loss item: 0.359056681394577
75
train loss item: 0.31827598810195923
76
train loss item: 1.3105741739273071
77
train loss item: 1.6888480186462402
78
train loss item: 0.3181023597717285
79
train loss item: 0.41537314653396606
80
train loss item: 0.33986547589302063
81
train loss item: 0.34434908628463745
82
train loss item: 0.456859290599823
83
train loss item: 1.0112797021865845
84
train loss item: 0.5650999546051025
85
train loss item: 0.9362911581993103
86
train loss item: 5.005677223205566
87
train loss item: 0.40329083800315857
88
train loss item: 0.5032917261123657
epoch train loss: 0.7529408057753959
testing phase
test loss item: 0.27591967582702637
test loss item: 0.2699817419052124
test loss item: 0.9673385620117188
test loss item: 0.37364232540130615
test loss item: 0.4408826231956482
test loss item: 0.24249021708965302
test loss item: 2.181910514831543
test loss item: 0.615429162979126
test loss item: 0.3620438277721405
test loss item: 0.5900995135307312
test loss item: 1.422059178352356
test loss item: 0.327943354845047
test loss item: 0.2930201590061188
test loss item: 0.5406785607337952
test loss item: 0.32162031531333923
test loss item: 0.28976958990097046
test loss item: 0.3760007619857788
test loss item: 0.7462800145149231
test loss item: 0.8178505897521973
test loss item: 0.3771919012069702
test loss item: 1.2107174396514893
test loss item: 0.5212624669075012
test loss item: 0.5123588442802429
test loss item: 0.27851402759552
test loss item: 0.34486109018325806
test loss item: 0.35856831073760986
test loss item: 0.4585106074810028
test loss item: 0.3340260088443756
test loss item: 0.4934632480144501
test loss item: 0.49297136068344116
test loss item: 1.265183687210083
test loss item: 0.26592785120010376
test loss item: 0.2620905339717865
test loss item: 0.8768433928489685
test loss item: 0.7202975153923035
test loss item: 0.7508471608161926
test loss item: 1.0206356048583984
test loss item: 2.4927735328674316
test loss item: 0.7670969367027283
test loss item: 0.382376492023468
test loss item: 0.4210447371006012
test loss item: 0.30924782156944275
test loss item: 0.5415078997612
test loss item: 0.3671250641345978
test loss item: 0.9785248041152954
test loss item: 0.5499695539474487
test loss item: 0.48527756333351135
test loss item: 0.40325385332107544
test loss item: 0.7559338808059692
test loss item: 1.0360257625579834
test loss item: 0.5068701505661011
test loss item: 0.24543559551239014
test loss item: 0.39430177211761475
test loss item: 0.39271509647369385
test loss item: 0.524873673915863
test loss item: 1.3892714977264404
test loss item: 0.834233283996582
test loss item: 0.47245272994041443
test loss item: 0.3630944788455963
test loss item: 0.3568315804004669
test loss item: 0.6458171010017395
test loss item: 0.3173135221004486
test loss item: 0.32644954323768616
test loss item: 0.3411124050617218
test loss item: 1.4270179271697998
test loss item: 0.4998459815979004
test loss item: 0.4420665204524994
test loss item: 0.3661365807056427
test loss item: 0.8644558191299438
test loss item: 0.5945426225662231
test loss item: 0.2467961460351944
test loss item: 1.1691359281539917
test loss item: 0.48685696721076965
test loss item: 0.4751776158809662
test loss item: 0.2613297402858734
test loss item: 0.29828017950057983
test loss item: 0.27761703729629517
test loss item: 2.767854690551758
test loss item: 0.7287942171096802
test loss item: 0.3045288324356079
test loss item: 0.20229391753673553
test loss item: 1.5624992847442627
test loss item: 1.1428425312042236
test loss item: 1.884889006614685
test loss item: 0.38351893424987793
test loss item: 0.37417367100715637
test loss item: 0.2396904081106186
test loss item: 0.2724437117576599
test loss item: 0.3164465129375458
Epoch [7/50], Training Loss: 0.7529, Testing Loss: 0.6313
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.708001971244812
1
train loss item: 1.8426871299743652
2
train loss item: 0.4030629098415375
3
train loss item: 0.943972110748291
4
train loss item: 0.97047358751297
5
train loss item: 0.5277432203292847
6
train loss item: 0.4432361125946045
7
train loss item: 1.1902735233306885
8
train loss item: 0.361517995595932
9
train loss item: 0.4317360818386078
10
train loss item: 0.5786597728729248
11
train loss item: 0.38301411271095276
12
train loss item: 0.2860371470451355
13
train loss item: 0.79881352186203
14
train loss item: 0.47836148738861084
15
train loss item: 0.952923595905304
16
train loss item: 0.2824687957763672
17
train loss item: 0.45605868101119995
18
train loss item: 0.5502573847770691
19
train loss item: 0.38898152112960815
20
train loss item: 0.3806261718273163
21
train loss item: 0.32999297976493835
22
train loss item: 1.4134951829910278
23
train loss item: 1.3060765266418457
24
train loss item: 0.764419674873352
25
train loss item: 0.4134707748889923
26
train loss item: 0.3408883810043335
27
train loss item: 0.5085408091545105
28
train loss item: 0.28098952770233154
29
train loss item: 1.1426749229431152
30
train loss item: 2.9119691848754883
31
train loss item: 0.8374108076095581
32
train loss item: 0.34395259618759155
33
train loss item: 0.6658126711845398
34
train loss item: 0.3932028114795685
35
train loss item: 2.9015913009643555
36
train loss item: 0.748598575592041
37
train loss item: 0.3769359886646271
38
train loss item: 0.7584856152534485
39
train loss item: 0.5126988887786865
40
train loss item: 0.2944338023662567
41
train loss item: 0.5033056139945984
42
train loss item: 0.36442068219184875
43
train loss item: 0.3730334937572479
44
train loss item: 1.0328166484832764
45
train loss item: 0.3327730596065521
46
train loss item: 0.3618725538253784
47
train loss item: 0.5196734666824341
48
train loss item: 0.4271495044231415
49
train loss item: 0.36904993653297424
50
train loss item: 0.4042545258998871
51
train loss item: 1.309361219406128
52
train loss item: 0.2999815344810486
53
train loss item: 0.3441600799560547
54
train loss item: 2.7744359970092773
55
train loss item: 0.36826080083847046
56
train loss item: 0.489799827337265
57
train loss item: 0.4096318483352661
58
train loss item: 0.3576665222644806
59
train loss item: 0.34152311086654663
60
train loss item: 1.37274968624115
61
train loss item: 2.7326507568359375
62
train loss item: 0.3791086971759796
63
train loss item: 0.4950968325138092
64
train loss item: 0.3623572885990143
65
train loss item: 0.7870754599571228
66
train loss item: 0.5835492610931396
67
train loss item: 0.3836955428123474
68
train loss item: 0.4392319917678833
69
train loss item: 0.4907279908657074
70
train loss item: 0.40771377086639404
71
train loss item: 0.32656651735305786
72
train loss item: 0.39551594853401184
73
train loss item: 0.4330173432826996
74
train loss item: 0.341660737991333
75
train loss item: 0.3042452335357666
76
train loss item: 1.2787985801696777
77
train loss item: 1.6569417715072632
78
train loss item: 0.30156639218330383
79
train loss item: 0.40153080224990845
80
train loss item: 0.34104812145233154
81
train loss item: 0.33177152276039124
82
train loss item: 0.4345642924308777
83
train loss item: 0.9748205542564392
84
train loss item: 0.5324474573135376
85
train loss item: 0.8983108401298523
86
train loss item: 4.949611663818359
87
train loss item: 0.3841167092323303
88
train loss item: 0.48248252272605896
epoch train loss: 0.7324796918402897
testing phase
test loss item: 0.2723909914493561
test loss item: 0.25660935044288635
test loss item: 0.9180955290794373
test loss item: 0.35533270239830017
test loss item: 0.42316484451293945
test loss item: 0.23502807319164276
test loss item: 2.0866940021514893
test loss item: 0.5711057782173157
test loss item: 0.3477770686149597
test loss item: 0.5676054954528809
test loss item: 1.3509900569915771
test loss item: 0.3037613332271576
test loss item: 0.27963685989379883
test loss item: 0.5153923630714417
test loss item: 0.3091460168361664
test loss item: 0.27328523993492126
test loss item: 0.3653457760810852
test loss item: 0.7122204899787903
test loss item: 0.7782200574874878
test loss item: 0.35944491624832153
test loss item: 1.147992730140686
test loss item: 0.4952872693538666
test loss item: 0.4822838604450226
test loss item: 0.2707168459892273
test loss item: 0.33476078510284424
test loss item: 0.34322625398635864
test loss item: 0.4443514347076416
test loss item: 0.3199896812438965
test loss item: 0.47619935870170593
test loss item: 0.47766348719596863
test loss item: 1.1995846033096313
test loss item: 0.24012412130832672
test loss item: 0.25684934854507446
test loss item: 0.8350242376327515
test loss item: 0.6874162554740906
test loss item: 0.7145456671714783
test loss item: 0.9789660573005676
test loss item: 2.3581531047821045
test loss item: 0.7347946166992188
test loss item: 0.3713703155517578
test loss item: 0.40822702646255493
test loss item: 0.29893338680267334
test loss item: 0.5201877951622009
test loss item: 0.34269726276397705
test loss item: 0.9349420666694641
test loss item: 0.5286407470703125
test loss item: 0.45906051993370056
test loss item: 0.3735026717185974
test loss item: 0.7238771915435791
test loss item: 0.9892112612724304
test loss item: 0.4845767915248871
test loss item: 0.23543469607830048
test loss item: 0.3760939836502075
test loss item: 0.35554027557373047
test loss item: 0.49641966819763184
test loss item: 1.3233647346496582
test loss item: 0.7949119210243225
test loss item: 0.4516650438308716
test loss item: 0.3514101505279541
test loss item: 0.33864960074424744
test loss item: 0.6231448650360107
test loss item: 0.303519606590271
test loss item: 0.31428277492523193
test loss item: 0.3323974013328552
test loss item: 1.3530453443527222
test loss item: 0.4677087962627411
test loss item: 0.4247874617576599
test loss item: 0.35687094926834106
test loss item: 0.8293607831001282
test loss item: 0.5396868586540222
test loss item: 0.23341913521289825
test loss item: 1.1175638437271118
test loss item: 0.46755656599998474
test loss item: 0.46265333890914917
test loss item: 0.25186583399772644
test loss item: 0.2838640511035919
test loss item: 0.2694014310836792
test loss item: 2.615596294403076
test loss item: 0.7022935748100281
test loss item: 0.2956833243370056
test loss item: 0.19649259746074677
test loss item: 1.481480360031128
test loss item: 1.0860892534255981
test loss item: 1.7830463647842407
test loss item: 0.3639174699783325
test loss item: 0.36016497015953064
test loss item: 0.23603922128677368
test loss item: 0.26301097869873047
test loss item: 0.3172333240509033
Epoch [8/50], Training Loss: 0.7325, Testing Loss: 0.6019
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.693805456161499
1
train loss item: 1.7919248342514038
2
train loss item: 0.38955801725387573
3
train loss item: 0.9006991386413574
4
train loss item: 0.9439113140106201
5
train loss item: 0.5187687873840332
6
train loss item: 0.43574073910713196
7
train loss item: 1.156151533126831
8
train loss item: 0.3385792076587677
9
train loss item: 0.41702690720558167
10
train loss item: 0.5524259805679321
11
train loss item: 0.371816486120224
12
train loss item: 0.27234598994255066
13
train loss item: 0.7755131125450134
14
train loss item: 0.46885162591934204
15
train loss item: 0.9324030876159668
16
train loss item: 0.26689836382865906
17
train loss item: 0.4525136351585388
18
train loss item: 0.5284718871116638
19
train loss item: 0.37900298833847046
20
train loss item: 0.3748348355293274
21
train loss item: 0.3213857114315033
22
train loss item: 1.3825101852416992
23
train loss item: 1.274193286895752
24
train loss item: 0.7426904439926147
25
train loss item: 0.39694899320602417
26
train loss item: 0.33392104506492615
27
train loss item: 0.4924877882003784
28
train loss item: 0.26545992493629456
29
train loss item: 1.1143289804458618
30
train loss item: 2.8506901264190674
31
train loss item: 0.8055713772773743
32
train loss item: 0.32287776470184326
33
train loss item: 0.631591796875
34
train loss item: 0.383571594953537
35
train loss item: 2.8582541942596436
36
train loss item: 0.7211114168167114
37
train loss item: 0.37341177463531494
38
train loss item: 0.7166354060173035
39
train loss item: 0.49839070439338684
40
train loss item: 0.28340238332748413
41
train loss item: 0.48323291540145874
42
train loss item: 0.35290223360061646
43
train loss item: 0.35629481077194214
44
train loss item: 1.0055241584777832
45
train loss item: 0.31311145424842834
46
train loss item: 0.34218260645866394
47
train loss item: 0.5001187920570374
48
train loss item: 0.4076392650604248
49
train loss item: 0.3478739857673645
50
train loss item: 0.39379534125328064
51
train loss item: 1.277970552444458
52
train loss item: 0.2821103036403656
53
train loss item: 0.33289194107055664
54
train loss item: 2.729457139968872
55
train loss item: 0.3535982072353363
56
train loss item: 0.47511932253837585
57
train loss item: 0.4011613428592682
58
train loss item: 0.3452981114387512
59
train loss item: 0.3189842700958252
60
train loss item: 1.338139295578003
61
train loss item: 2.6850998401641846
62
train loss item: 0.36489546298980713
63
train loss item: 0.47950485348701477
64
train loss item: 0.3397953510284424
65
train loss item: 0.7761136889457703
66
train loss item: 0.5619968175888062
67
train loss item: 0.37151527404785156
68
train loss item: 0.4310392141342163
69
train loss item: 0.4741172790527344
70
train loss item: 0.39502644538879395
71
train loss item: 0.3202055096626282
72
train loss item: 0.37512660026550293
73
train loss item: 0.4237194061279297
74
train loss item: 0.31980329751968384
75
train loss item: 0.28525879979133606
76
train loss item: 1.2454768419265747
77
train loss item: 1.6329997777938843
78
train loss item: 0.27893492579460144
79
train loss item: 0.3873636722564697
80
train loss item: 0.3354424834251404
81
train loss item: 0.317414790391922
82
train loss item: 0.41368788480758667
83
train loss item: 0.9464116096496582
84
train loss item: 0.5080931186676025
85
train loss item: 0.864730715751648
86
train loss item: 4.88687801361084
87
train loss item: 0.3695136308670044
88
train loss item: 0.467318058013916
epoch train loss: 0.7117479577493132
testing phase
test loss item: 0.2709518074989319
test loss item: 0.2509154677391052
test loss item: 0.8919737935066223
test loss item: 0.3418078124523163
test loss item: 0.414585143327713
test loss item: 0.2306593358516693
test loss item: 2.0117831230163574
test loss item: 0.5442878603935242
test loss item: 0.34167271852493286
test loss item: 0.5570569038391113
test loss item: 1.314209222793579
test loss item: 0.2877947986125946
test loss item: 0.26816526055336
test loss item: 0.5036725401878357
test loss item: 0.30185794830322266
test loss item: 0.2638368606567383
test loss item: 0.3557228446006775
test loss item: 0.7017176747322083
test loss item: 0.7569265961647034
test loss item: 0.34550395607948303
test loss item: 1.1208957433700562
test loss item: 0.4767214059829712
test loss item: 0.47462406754493713
test loss item: 0.2636125683784485
test loss item: 0.3294946849346161
test loss item: 0.33806198835372925
test loss item: 0.43424615263938904
test loss item: 0.31355586647987366
test loss item: 0.46749499440193176
test loss item: 0.4661933183670044
test loss item: 1.1571115255355835
test loss item: 0.22426913678646088
test loss item: 0.2510755956172943
test loss item: 0.8178174495697021
test loss item: 0.6750607490539551
test loss item: 0.6885277628898621
test loss item: 0.9523870944976807
test loss item: 2.290499448776245
test loss item: 0.7208658456802368
test loss item: 0.361428827047348
test loss item: 0.39690661430358887
test loss item: 0.29840710759162903
test loss item: 0.5136575102806091
test loss item: 0.3265214264392853
test loss item: 0.9191911816596985
test loss item: 0.5130592584609985
test loss item: 0.4546346068382263
test loss item: 0.3430168330669403
test loss item: 0.7053095102310181
test loss item: 0.9624054431915283
test loss item: 0.476274311542511
test loss item: 0.22355860471725464
test loss item: 0.3672478497028351
test loss item: 0.3333469331264496
test loss item: 0.4859203100204468
test loss item: 1.2921535968780518
test loss item: 0.7690595984458923
test loss item: 0.44757431745529175
test loss item: 0.3443804979324341
test loss item: 0.3319287598133087
test loss item: 0.6176828145980835
test loss item: 0.293352335691452
test loss item: 0.30778956413269043
test loss item: 0.32573428750038147
test loss item: 1.312369704246521
test loss item: 0.4462863504886627
test loss item: 0.4129365086555481
test loss item: 0.3504297137260437
test loss item: 0.8126692771911621
test loss item: 0.5168716311454773
test loss item: 0.22659680247306824
test loss item: 1.0763988494873047
test loss item: 0.46167945861816406
test loss item: 0.4516289532184601
test loss item: 0.24590690433979034
test loss item: 0.29011139273643494
test loss item: 0.26301413774490356
test loss item: 2.5333962440490723
test loss item: 0.6866548657417297
test loss item: 0.2913467288017273
test loss item: 0.19470101594924927
test loss item: 1.432831048965454
test loss item: 1.054911732673645
test loss item: 1.731927752494812
test loss item: 0.35571733117103577
test loss item: 0.35594442486763
test loss item: 0.23550190031528473
test loss item: 0.2568439245223999
test loss item: 0.3223680555820465
Epoch [9/50], Training Loss: 0.7117, Testing Loss: 0.5859
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6795389652252197
1
train loss item: 1.744483470916748
2
train loss item: 0.37328165769577026
3
train loss item: 0.8602427244186401
4
train loss item: 0.8871167898178101
5
train loss item: 0.5109033584594727
6
train loss item: 0.4243994951248169
7
train loss item: 1.1241470575332642
8
train loss item: 0.3196456730365753
9
train loss item: 0.4044058918952942
10
train loss item: 0.5318286418914795
11
train loss item: 0.3635312616825104
12
train loss item: 0.26346930861473083
13
train loss item: 0.7537569999694824
14
train loss item: 0.4616577923297882
15
train loss item: 0.9145956039428711
16
train loss item: 0.2542535662651062
17
train loss item: 0.4480488896369934
18
train loss item: 0.5093443989753723
19
train loss item: 0.3699185848236084
20
train loss item: 0.3669266700744629
21
train loss item: 0.3153225779533386
22
train loss item: 1.3574793338775635
23
train loss item: 1.2450597286224365
24
train loss item: 0.7236095666885376
25
train loss item: 0.3813157379627228
26
train loss item: 0.3321364223957062
27
train loss item: 0.479158878326416
28
train loss item: 0.2528093755245209
29
train loss item: 1.0912914276123047
30
train loss item: 2.7921836376190186
31
train loss item: 0.7782497406005859
32
train loss item: 0.3024356961250305
33
train loss item: 0.6017465591430664
34
train loss item: 0.3748728930950165
35
train loss item: 2.8163812160491943
36
train loss item: 0.6974773406982422
37
train loss item: 0.37137776613235474
38
train loss item: 0.6805316209793091
39
train loss item: 0.48706570267677307
40
train loss item: 0.27569058537483215
41
train loss item: 0.466972678899765
42
train loss item: 0.3421710133552551
43
train loss item: 0.339211106300354
44
train loss item: 0.9804760217666626
45
train loss item: 0.2962047755718231
46
train loss item: 0.3247894048690796
47
train loss item: 0.48477211594581604
48
train loss item: 0.3913288116455078
49
train loss item: 0.33254969120025635
50
train loss item: 0.3848918378353119
51
train loss item: 1.2495883703231812
52
train loss item: 0.27218902111053467
53
train loss item: 0.32744714617729187
54
train loss item: 2.686124086380005
55
train loss item: 0.3425471782684326
56
train loss item: 0.46200260519981384
57
train loss item: 0.394513875246048
58
train loss item: 0.33213692903518677
59
train loss item: 0.30127131938934326
60
train loss item: 1.306086540222168
61
train loss item: 2.639293909072876
62
train loss item: 0.35486677289009094
63
train loss item: 0.4652610719203949
64
train loss item: 0.3177613914012909
65
train loss item: 0.7644497752189636
66
train loss item: 0.545534610748291
67
train loss item: 0.36282768845558167
68
train loss item: 0.42713284492492676
69
train loss item: 0.4614326059818268
70
train loss item: 0.3852913975715637
71
train loss item: 0.3116934597492218
72
train loss item: 0.35746365785598755
73
train loss item: 0.4173537492752075
74
train loss item: 0.3020104467868805
75
train loss item: 0.2709280252456665
76
train loss item: 1.214234471321106
77
train loss item: 1.6116671562194824
78
train loss item: 0.2605406939983368
79
train loss item: 0.37417519092559814
80
train loss item: 0.3236880302429199
81
train loss item: 0.3057347536087036
82
train loss item: 0.396272748708725
83
train loss item: 0.9209794402122498
84
train loss item: 0.4894252419471741
85
train loss item: 0.836685061454773
86
train loss item: 4.825387954711914
87
train loss item: 0.36094486713409424
88
train loss item: 0.4545552730560303
epoch train loss: 0.693219768867064
testing phase
test loss item: 0.2700878381729126
test loss item: 0.24748189747333527
test loss item: 0.8698344826698303
test loss item: 0.3328716456890106
test loss item: 0.4054175913333893
test loss item: 0.22875432670116425
test loss item: 1.9498214721679688
test loss item: 0.5270669460296631
test loss item: 0.33831435441970825
test loss item: 0.5488223433494568
test loss item: 1.2902957201004028
test loss item: 0.2783602774143219
test loss item: 0.26179298758506775
test loss item: 0.48779433965682983
test loss item: 0.293735533952713
test loss item: 0.2580869495868683
test loss item: 0.3486160933971405
test loss item: 0.6875835061073303
test loss item: 0.7441719770431519
test loss item: 0.3368152379989624
test loss item: 1.0830485820770264
test loss item: 0.4638543725013733
test loss item: 0.469673216342926
test loss item: 0.25707516074180603
test loss item: 0.32524147629737854
test loss item: 0.3357155919075012
test loss item: 0.42886725068092346
test loss item: 0.3080400228500366
test loss item: 0.4595695436000824
test loss item: 0.46052253246307373
test loss item: 1.1273330450057983
test loss item: 0.21465589106082916
test loss item: 0.24534954130649567
test loss item: 0.8016854524612427
test loss item: 0.6615177989006042
test loss item: 0.6734914183616638
test loss item: 0.932336688041687
test loss item: 2.2417776584625244
test loss item: 0.7097806930541992
test loss item: 0.3530913293361664
test loss item: 0.3871902823448181
test loss item: 0.3104519546031952
test loss item: 0.5027528405189514
test loss item: 0.31738901138305664
test loss item: 0.8954736590385437
test loss item: 0.5015590190887451
test loss item: 0.4563463032245636
test loss item: 0.3241675794124603
test loss item: 0.6880926489830017
test loss item: 0.9450587630271912
test loss item: 0.46741342544555664
test loss item: 0.21919848024845123
test loss item: 0.359037309885025
test loss item: 0.32251688838005066
test loss item: 0.4723019599914551
test loss item: 1.2716313600540161
test loss item: 0.7497606873512268
test loss item: 0.42401251196861267
test loss item: 0.3379916250705719
test loss item: 0.32571926712989807
test loss item: 0.6129797101020813
test loss item: 0.28669437766075134
test loss item: 0.3020962178707123
test loss item: 0.3201848566532135
test loss item: 1.2794767618179321
test loss item: 0.4332980513572693
test loss item: 0.4036414921283722
test loss item: 0.3454158306121826
test loss item: 0.7989817261695862
test loss item: 0.5090255737304688
test loss item: 0.2233329713344574
test loss item: 1.0426756143569946
test loss item: 0.4461960196495056
test loss item: 0.4424971342086792
test loss item: 0.24369850754737854
test loss item: 0.3095482885837555
test loss item: 0.25741270184516907
test loss item: 2.4705491065979004
test loss item: 0.6673722267150879
test loss item: 0.28961247205734253
test loss item: 0.1948513686656952
test loss item: 1.396102786064148
test loss item: 1.0345771312713623
test loss item: 1.6953939199447632
test loss item: 0.34728777408599854
test loss item: 0.3566955626010895
test loss item: 0.23659154772758484
test loss item: 0.2527189552783966
test loss item: 0.33220693469047546
Epoch [10/50], Training Loss: 0.6932, Testing Loss: 0.5738
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 11/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6631979942321777
1
train loss item: 1.7018104791641235
2
train loss item: 0.35697460174560547
3
train loss item: 0.8252214193344116
4
train loss item: 0.8161624073982239
5
train loss item: 0.5030182600021362
6
train loss item: 0.4093725383281708
7
train loss item: 1.0966014862060547
8
train loss item: 0.3034951388835907
9
train loss item: 0.3936873972415924
10
train loss item: 0.5165653228759766
11
train loss item: 0.3589249551296234
12
train loss item: 0.2567403018474579
13
train loss item: 0.7307088375091553
14
train loss item: 0.4566310942173004
15
train loss item: 0.8939084410667419
16
train loss item: 0.24156343936920166
17
train loss item: 0.4413280785083771
18
train loss item: 0.49214693903923035
19
train loss item: 0.3618157207965851
20
train loss item: 0.35818153619766235
21
train loss item: 0.3079986870288849
22
train loss item: 1.330594539642334
23
train loss item: 1.2212210893630981
24
train loss item: 0.7054097056388855
25
train loss item: 0.36484962701797485
26
train loss item: 0.3301389515399933
27
train loss item: 0.4691675305366516
28
train loss item: 0.24006839096546173
29
train loss item: 1.067579746246338
30
train loss item: 2.741971492767334
31
train loss item: 0.7563732862472534
32
train loss item: 0.28421732783317566
33
train loss item: 0.5779914259910583
34
train loss item: 0.3659835755825043
35
train loss item: 2.7796154022216797
36
train loss item: 0.6753951907157898
37
train loss item: 0.3681240975856781
38
train loss item: 0.6490561962127686
39
train loss item: 0.4768100380897522
40
train loss item: 0.2710636258125305
41
train loss item: 0.45553267002105713
42
train loss item: 0.3329572081565857
43
train loss item: 0.3242727518081665
44
train loss item: 0.95782870054245
45
train loss item: 0.2821938991546631
46
train loss item: 0.30954983830451965
47
train loss item: 0.47096386551856995
48
train loss item: 0.37813469767570496
49
train loss item: 0.32176828384399414
50
train loss item: 0.3770642578601837
51
train loss item: 1.2221529483795166
52
train loss item: 0.26506972312927246
53
train loss item: 0.3200964033603668
54
train loss item: 2.6480557918548584
55
train loss item: 0.3315720558166504
56
train loss item: 0.45055341720581055
57
train loss item: 0.3911077678203583
58
train loss item: 0.3194454610347748
59
train loss item: 0.28895777463912964
60
train loss item: 1.2728883028030396
61
train loss item: 2.5996267795562744
62
train loss item: 0.3473774194717407
63
train loss item: 0.4517892003059387
64
train loss item: 0.3002089262008667
65
train loss item: 0.7478398084640503
66
train loss item: 0.5335491895675659
67
train loss item: 0.3540925085544586
68
train loss item: 0.42074114084243774
69
train loss item: 0.45017939805984497
70
train loss item: 0.37524691224098206
71
train loss item: 0.3023664653301239
72
train loss item: 0.3429127037525177
73
train loss item: 0.41106265783309937
74
train loss item: 0.28564682602882385
75
train loss item: 0.26093295216560364
76
train loss item: 1.1869419813156128
77
train loss item: 1.5904431343078613
78
train loss item: 0.24481713771820068
79
train loss item: 0.36279305815696716
80
train loss item: 0.3102246820926666
81
train loss item: 0.29846620559692383
82
train loss item: 0.38155773282051086
83
train loss item: 0.8951488137245178
84
train loss item: 0.47381576895713806
85
train loss item: 0.812708854675293
86
train loss item: 4.7711710929870605
87
train loss item: 0.3515401780605316
88
train loss item: 0.4413966238498688
epoch train loss: 0.6762522504235922
testing phase
test loss item: 0.2675439119338989
test loss item: 0.24234779179096222
test loss item: 0.8314087390899658
test loss item: 0.325038343667984
test loss item: 0.3884243071079254
test loss item: 0.22878390550613403
test loss item: 1.8930420875549316
test loss item: 0.5163072347640991
test loss item: 0.3335675895214081
test loss item: 0.5345733165740967
test loss item: 1.256516933441162
test loss item: 0.26857390999794006
test loss item: 0.25731393694877625
test loss item: 0.4622136950492859
test loss item: 0.28153109550476074
test loss item: 0.25173643231391907
test loss item: 0.3432721495628357
test loss item: 0.646588921546936
test loss item: 0.7358732223510742
test loss item: 0.32970431447029114
test loss item: 1.003255009651184
test loss item: 0.45152828097343445
test loss item: 0.4418569505214691
test loss item: 0.2518470883369446
test loss item: 0.3176582157611847
test loss item: 0.32887300848960876
test loss item: 0.4237058460712433
test loss item: 0.29884690046310425
test loss item: 0.4468652307987213
test loss item: 0.4546996057033539
test loss item: 1.0907130241394043
test loss item: 0.20536519587039948
test loss item: 0.24093002080917358
test loss item: 0.7635349035263062
test loss item: 0.6277094483375549
test loss item: 0.6539681553840637
test loss item: 0.9125677347183228
test loss item: 2.160924196243286
test loss item: 0.6841686964035034
test loss item: 0.347527414560318
test loss item: 0.3787633776664734
test loss item: 0.3152298331260681
test loss item: 0.47625622153282166
test loss item: 0.3085049092769623
test loss item: 0.8415428996086121
test loss item: 0.4906494617462158
test loss item: 0.44011759757995605
test loss item: 0.311174213886261
test loss item: 0.6602810621261597
test loss item: 0.9234886169433594
test loss item: 0.4453868567943573
test loss item: 0.22026154398918152
test loss item: 0.3440990149974823
test loss item: 0.31162405014038086
test loss item: 0.4407044053077698
test loss item: 1.2240890264511108
test loss item: 0.727219820022583
test loss item: 0.3692416250705719
test loss item: 0.3267335593700409
test loss item: 0.31089237332344055
test loss item: 0.5948035717010498
test loss item: 0.2816462516784668
test loss item: 0.291927695274353
test loss item: 0.3148222267627716
test loss item: 1.2182857990264893
test loss item: 0.4215557873249054
test loss item: 0.3925435543060303
test loss item: 0.3402543067932129
test loss item: 0.768342912197113
test loss item: 0.5105289220809937
test loss item: 0.2195180207490921
test loss item: 1.0139915943145752
test loss item: 0.4105373024940491
test loss item: 0.4336508512496948
test loss item: 0.2427387237548828
test loss item: 0.3152622580528259
test loss item: 0.252360999584198
test loss item: 2.3620941638946533
test loss item: 0.6362141370773315
test loss item: 0.28700414299964905
test loss item: 0.1946851909160614
test loss item: 1.3517022132873535
test loss item: 1.0122723579406738
test loss item: 1.6329379081726074
test loss item: 0.3292056620121002
test loss item: 0.35388901829719543
test loss item: 0.2377036213874817
test loss item: 0.24900424480438232
test loss item: 0.33972832560539246
Epoch [11/50], Training Loss: 0.6763, Testing Loss: 0.5548
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 12/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6475502252578735
1
train loss item: 1.6643472909927368
2
train loss item: 0.341145783662796
3
train loss item: 0.7960045337677002
4
train loss item: 0.7356011867523193
5
train loss item: 0.49670538306236267
6
train loss item: 0.3908667266368866
7
train loss item: 1.071977972984314
8
train loss item: 0.2874355912208557
9
train loss item: 0.3842523992061615
10
train loss item: 0.5043279528617859
11
train loss item: 0.3575977087020874
12
train loss item: 0.2479580044746399
13
train loss item: 0.7079631686210632
14
train loss item: 0.45332038402557373
15
train loss item: 0.8722982406616211
16
train loss item: 0.2300267219543457
17
train loss item: 0.4306948184967041
18
train loss item: 0.47733554244041443
19
train loss item: 0.35421666502952576
20
train loss item: 0.34835222363471985
21
train loss item: 0.29745373129844666
22
train loss item: 1.3002831935882568
23
train loss item: 1.1997685432434082
24
train loss item: 0.6879733800888062
25
train loss item: 0.34909623861312866
26
train loss item: 0.3265361189842224
27
train loss item: 0.46237611770629883
28
train loss item: 0.22856605052947998
29
train loss item: 1.0435571670532227
30
train loss item: 2.6993889808654785
31
train loss item: 0.7383061647415161
32
train loss item: 0.2654716968536377
33
train loss item: 0.558630645275116
34
train loss item: 0.351447194814682
35
train loss item: 2.74809193611145
36
train loss item: 0.6558130979537964
37
train loss item: 0.36370712518692017
38
train loss item: 0.6240496039390564
39
train loss item: 0.4667186737060547
40
train loss item: 0.2678745985031128
41
train loss item: 0.4486187994480133
42
train loss item: 0.3266015350818634
43
train loss item: 0.31143635511398315
44
train loss item: 0.9371849894523621
45
train loss item: 0.2707662582397461
46
train loss item: 0.29657092690467834
47
train loss item: 0.45733579993247986
48
train loss item: 0.36920592188835144
49
train loss item: 0.31174519658088684
50
train loss item: 0.37050166726112366
51
train loss item: 1.1976007223129272
52
train loss item: 0.25400033593177795
53
train loss item: 0.307020902633667
54
train loss item: 2.6145167350769043
55
train loss item: 0.3206194043159485
56
train loss item: 0.44126030802726746
57
train loss item: 0.3907764256000519
58
train loss item: 0.30684056878089905
59
train loss item: 0.277849018573761
60
train loss item: 1.2396769523620605
61
train loss item: 2.564561128616333
62
train loss item: 0.33973997831344604
63
train loss item: 0.43957623839378357
64
train loss item: 0.2866935431957245
65
train loss item: 0.7268242835998535
66
train loss item: 0.5237646698951721
67
train loss item: 0.3438575565814972
68
train loss item: 0.40788790583610535
69
train loss item: 0.43946602940559387
70
train loss item: 0.36441028118133545
71
train loss item: 0.2921265959739685
72
train loss item: 0.3283900320529938
73
train loss item: 0.404035747051239
74
train loss item: 0.26975125074386597
75
train loss item: 0.2509881258010864
76
train loss item: 1.1622804403305054
77
train loss item: 1.5690237283706665
78
train loss item: 0.23152107000350952
79
train loss item: 0.3540835678577423
80
train loss item: 0.29631128907203674
81
train loss item: 0.2946973741054535
82
train loss item: 0.3698830008506775
83
train loss item: 0.8695254325866699
84
train loss item: 0.46082374453544617
85
train loss item: 0.7907029390335083
86
train loss item: 4.725039958953857
87
train loss item: 0.3366512954235077
88
train loss item: 0.42848068475723267
epoch train loss: 0.6601833202195971
testing phase
test loss item: 0.26365599036216736
test loss item: 0.23586395382881165
test loss item: 0.7769011855125427
test loss item: 0.31773751974105835
test loss item: 0.36960723996162415
test loss item: 0.22517256438732147
test loss item: 1.8419601917266846
test loss item: 0.5105370283126831
test loss item: 0.32574108242988586
test loss item: 0.517092764377594
test loss item: 1.2095136642456055
test loss item: 0.2586674988269806
test loss item: 0.25251060724258423
test loss item: 0.4379633963108063
test loss item: 0.27027463912963867
test loss item: 0.242387056350708
test loss item: 0.33842742443084717
test loss item: 0.6023864150047302
test loss item: 0.7303054332733154
test loss item: 0.32340720295906067
test loss item: 0.9375772476196289
test loss item: 0.4394912123680115
test loss item: 0.41433992981910706
test loss item: 0.24806331098079681
test loss item: 0.3086014688014984
test loss item: 0.31904348731040955
test loss item: 0.41724538803100586
test loss item: 0.2885766327381134
test loss item: 0.43361201882362366
test loss item: 0.44699981808662415
test loss item: 1.043864130973816
test loss item: 0.19493447244167328
test loss item: 0.23771655559539795
test loss item: 0.7191809415817261
test loss item: 0.5876324772834778
test loss item: 0.6345290541648865
test loss item: 0.8949161767959595
test loss item: 2.0390539169311523
test loss item: 0.6510564088821411
test loss item: 0.3414543569087982
test loss item: 0.371114581823349
test loss item: 0.3099709153175354
test loss item: 0.45632630586624146
test loss item: 0.29955077171325684
test loss item: 0.7963654398918152
test loss item: 0.4804638922214508
test loss item: 0.4235517978668213
test loss item: 0.302864134311676
test loss item: 0.6270162463188171
test loss item: 0.8963530659675598
test loss item: 0.4254641532897949
test loss item: 0.22115181386470795
test loss item: 0.3272746205329895
test loss item: 0.29903456568717957
test loss item: 0.40910881757736206
test loss item: 1.148725152015686
test loss item: 0.7013792395591736
test loss item: 0.3534855842590332
test loss item: 0.3166216313838959
test loss item: 0.29409393668174744
test loss item: 0.5712656378746033
test loss item: 0.2761317193508148
test loss item: 0.2803453207015991
test loss item: 0.3099106550216675
test loss item: 1.1253063678741455
test loss item: 0.41069889068603516
test loss item: 0.3807733952999115
test loss item: 0.33409735560417175
test loss item: 0.7224432826042175
test loss item: 0.5180730223655701
test loss item: 0.2124173939228058
test loss item: 0.9900220632553101
test loss item: 0.38858774304389954
test loss item: 0.4258515536785126
test loss item: 0.24029305577278137
test loss item: 0.31020790338516235
test loss item: 0.24781188368797302
test loss item: 2.1918928623199463
test loss item: 0.6060509085655212
test loss item: 0.28095731139183044
test loss item: 0.19183771312236786
test loss item: 1.2971268892288208
test loss item: 0.9918821454048157
test loss item: 1.5361149311065674
test loss item: 0.30846288800239563
test loss item: 0.34529992938041687
test loss item: 0.23610439896583557
test loss item: 0.24310161173343658
test loss item: 0.337007999420166
Epoch [12/50], Training Loss: 0.6602, Testing Loss: 0.5328
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 13/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6338028907775879
1
train loss item: 1.6259372234344482
2
train loss item: 0.3281242251396179
3
train loss item: 0.7680957317352295
4
train loss item: 0.6578861474990845
5
train loss item: 0.49183815717697144
6
train loss item: 0.3723949193954468
7
train loss item: 1.0472813844680786
8
train loss item: 0.2719062864780426
9
train loss item: 0.3755885660648346
10
train loss item: 0.4950910806655884
11
train loss item: 0.35444778203964233
12
train loss item: 0.24145276844501495
13
train loss item: 0.6877991557121277
14
train loss item: 0.4498644769191742
15
train loss item: 0.8536155223846436
16
train loss item: 0.22061359882354736
17
train loss item: 0.4157923758029938
18
train loss item: 0.4641728401184082
19
train loss item: 0.3476641774177551
20
train loss item: 0.3402473032474518
21
train loss item: 0.28668928146362305
22
train loss item: 1.2719683647155762
23
train loss item: 1.1784088611602783
24
train loss item: 0.6722758412361145
25
train loss item: 0.33555763959884644
26
train loss item: 0.3201529085636139
27
train loss item: 0.4559018611907959
28
train loss item: 0.21906426548957825
29
train loss item: 1.0194926261901855
30
train loss item: 2.658964157104492
31
train loss item: 0.7192976474761963
32
train loss item: 0.2515575587749481
33
train loss item: 0.5394845604896545
34
train loss item: 0.3326570987701416
35
train loss item: 2.7173590660095215
36
train loss item: 0.6376978158950806
37
train loss item: 0.3579249680042267
38
train loss item: 0.5944572687149048
39
train loss item: 0.4572778642177582
40
train loss item: 0.2634320855140686
41
train loss item: 0.44267094135284424
42
train loss item: 0.32201042771339417
43
train loss item: 0.29955121874809265
44
train loss item: 0.9179873466491699
45
train loss item: 0.260711133480072
46
train loss item: 0.28428682684898376
47
train loss item: 0.4454324543476105
48
train loss item: 0.36167630553245544
49
train loss item: 0.3011736571788788
50
train loss item: 0.36254045367240906
51
train loss item: 1.1733380556106567
52
train loss item: 0.24120059609413147
53
train loss item: 0.29143133759498596
54
train loss item: 2.581801414489746
55
train loss item: 0.30944210290908813
56
train loss item: 0.4330514371395111
57
train loss item: 0.3900700509548187
58
train loss item: 0.2954271137714386
59
train loss item: 0.2673192024230957
60
train loss item: 1.207442283630371
61
train loss item: 2.529639720916748
62
train loss item: 0.334246963262558
63
train loss item: 0.4276502728462219
64
train loss item: 0.2757145166397095
65
train loss item: 0.7043489217758179
66
train loss item: 0.512606680393219
67
train loss item: 0.334286093711853
68
train loss item: 0.39654067158699036
69
train loss item: 0.4298410713672638
70
train loss item: 0.35435935854911804
71
train loss item: 0.28038984537124634
72
train loss item: 0.312884122133255
73
train loss item: 0.39663198590278625
74
train loss item: 0.2555620074272156
75
train loss item: 0.24158631265163422
76
train loss item: 1.13791823387146
77
train loss item: 1.5483540296554565
78
train loss item: 0.2207234799861908
79
train loss item: 0.34471219778060913
80
train loss item: 0.2827768623828888
81
train loss item: 0.290497750043869
82
train loss item: 0.359139084815979
83
train loss item: 0.8453611135482788
84
train loss item: 0.44880250096321106
85
train loss item: 0.7697592973709106
86
train loss item: 4.681759834289551
87
train loss item: 0.3170328438282013
88
train loss item: 0.41780656576156616
epoch train loss: 0.6446374725089984
testing phase
test loss item: 0.25941699743270874
test loss item: 0.22864766418933868
test loss item: 0.7303681969642639
test loss item: 0.3118220865726471
test loss item: 0.3564627766609192
test loss item: 0.21582910418510437
test loss item: 1.796169638633728
test loss item: 0.5077086091041565
test loss item: 0.3169306218624115
test loss item: 0.5035502314567566
test loss item: 1.1556965112686157
test loss item: 0.25157856941223145
test loss item: 0.24946169555187225
test loss item: 0.4244299530982971
test loss item: 0.26232314109802246
test loss item: 0.23251935839653015
test loss item: 0.3332313597202301
test loss item: 0.5830612778663635
test loss item: 0.7255430817604065
test loss item: 0.3175642490386963
test loss item: 0.9115061163902283
test loss item: 0.4305933117866516
test loss item: 0.3926759362220764
test loss item: 0.2438337355852127
test loss item: 0.30261367559432983
test loss item: 0.3103274405002594
test loss item: 0.4097796082496643
test loss item: 0.2777103781700134
test loss item: 0.42685407400131226
test loss item: 0.4391998052597046
test loss item: 0.9924941658973694
test loss item: 0.18717044591903687
test loss item: 0.2326941043138504
test loss item: 0.6963185667991638
test loss item: 0.5638190507888794
test loss item: 0.6229437589645386
test loss item: 0.8825761079788208
test loss item: 1.9065475463867188
test loss item: 0.6316434144973755
test loss item: 0.3338906764984131
test loss item: 0.36425089836120605
test loss item: 0.29694879055023193
test loss item: 0.45057517290115356
test loss item: 0.29280850291252136
test loss item: 0.781818687915802
test loss item: 0.4701901376247406
test loss item: 0.4052991569042206
test loss item: 0.2950991690158844
test loss item: 0.6036646962165833
test loss item: 0.8677106499671936
test loss item: 0.41977837681770325
test loss item: 0.2191281020641327
test loss item: 0.3172876536846161
test loss item: 0.29220402240753174
test loss item: 0.396064430475235
test loss item: 1.081304907798767
test loss item: 0.6772862672805786
test loss item: 0.34857451915740967
test loss item: 0.3086850345134735
test loss item: 0.28617724776268005
test loss item: 0.5586385130882263
test loss item: 0.270084023475647
test loss item: 0.2731349766254425
test loss item: 0.30642449855804443
test loss item: 1.0426753759384155
test loss item: 0.4045141339302063
test loss item: 0.3719247579574585
test loss item: 0.32783418893814087
test loss item: 0.687068521976471
test loss item: 0.5265148282051086
test loss item: 0.20383799076080322
test loss item: 0.9703630805015564
test loss item: 0.38804346323013306
test loss item: 0.4198932945728302
test loss item: 0.234720841050148
test loss item: 0.29789242148399353
test loss item: 0.24306464195251465
test loss item: 2.0094027519226074
test loss item: 0.5895897746086121
test loss item: 0.27290770411491394
test loss item: 0.18624450266361237
test loss item: 1.2380913496017456
test loss item: 0.9793301224708557
test loss item: 1.4244933128356934
test loss item: 0.2960035800933838
test loss item: 0.33542031049728394
test loss item: 0.23113027215003967
test loss item: 0.23513734340667725
test loss item: 0.3239268958568573
Epoch [13/50], Training Loss: 0.6446, Testing Loss: 0.5144
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 14/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6221196055412292
1
train loss item: 1.5868570804595947
2
train loss item: 0.3195520341396332
3
train loss item: 0.7393050193786621
4
train loss item: 0.5972626805305481
5
train loss item: 0.484883576631546
6
train loss item: 0.35773247480392456
7
train loss item: 1.0234928131103516
8
train loss item: 0.26065322756767273
9
train loss item: 0.36742740869522095
10
train loss item: 0.48742803931236267
11
train loss item: 0.3457397222518921
12
train loss item: 0.239091694355011
13
train loss item: 0.6707234382629395
14
train loss item: 0.44217395782470703
15
train loss item: 0.8403032422065735
16
train loss item: 0.2128932774066925
17
train loss item: 0.39847332239151
18
train loss item: 0.45169106125831604
19
train loss item: 0.3410431444644928
20
train loss item: 0.3359762132167816
21
train loss item: 0.2760087251663208
22
train loss item: 1.2486958503723145
23
train loss item: 1.1563246250152588
24
train loss item: 0.6582047939300537
25
train loss item: 0.3257795572280884
26
train loss item: 0.31379106640815735
27
train loss item: 0.44758331775665283
28
train loss item: 0.21123120188713074
29
train loss item: 0.9983702301979065
30
train loss item: 2.6152946949005127
31
train loss item: 0.7001566886901855
32
train loss item: 0.24343186616897583
33
train loss item: 0.520746111869812
34
train loss item: 0.31314483284950256
35
train loss item: 2.6849794387817383
36
train loss item: 0.622279703617096
37
train loss item: 0.3510647118091583
38
train loss item: 0.5659579634666443
39
train loss item: 0.4485112726688385
40
train loss item: 0.25601136684417725
41
train loss item: 0.43377918004989624
42
train loss item: 0.3154783248901367
43
train loss item: 0.28714266419410706
44
train loss item: 0.8994826078414917
45
train loss item: 0.2517058849334717
46
train loss item: 0.2697298526763916
47
train loss item: 0.4356296956539154
48
train loss item: 0.3507980406284332
49
train loss item: 0.2883504629135132
50
train loss item: 0.353397011756897
51
train loss item: 1.1466799974441528
52
train loss item: 0.23037102818489075
53
train loss item: 0.279602587223053
54
train loss item: 2.5489702224731445
55
train loss item: 0.2990930676460266
56
train loss item: 0.4237418472766876
57
train loss item: 0.38349565863609314
58
train loss item: 0.2854330241680145
59
train loss item: 0.258374959230423
60
train loss item: 1.1781545877456665
61
train loss item: 2.4943900108337402
62
train loss item: 0.3292370140552521
63
train loss item: 0.4151032865047455
64
train loss item: 0.2655649781227112
65
train loss item: 0.6847425699234009
66
train loss item: 0.49803626537323
67
train loss item: 0.32610049843788147
68
train loss item: 0.3939248025417328
69
train loss item: 0.4208059310913086
70
train loss item: 0.3459244966506958
71
train loss item: 0.2670533359050751
72
train loss item: 0.2993297874927521
73
train loss item: 0.3894799053668976
74
train loss item: 0.24466438591480255
75
train loss item: 0.23342908918857574
76
train loss item: 1.1140698194503784
77
train loss item: 1.5295339822769165
78
train loss item: 0.21224676072597504
79
train loss item: 0.333168089389801
80
train loss item: 0.26891839504241943
81
train loss item: 0.2810061275959015
82
train loss item: 0.3459376096725464
83
train loss item: 0.8237900733947754
84
train loss item: 0.43728208541870117
85
train loss item: 0.7504479885101318
86
train loss item: 4.638499736785889
87
train loss item: 0.29981714487075806
88
train loss item: 0.4104558527469635
epoch train loss: 0.6298287840706579
testing phase
test loss item: 0.25661027431488037
test loss item: 0.23109333217144012
test loss item: 0.7266284823417664
test loss item: 0.3095390498638153
test loss item: 0.3677673935890198
test loss item: 0.21675662696361542
test loss item: 1.7576994895935059
test loss item: 0.5075637102127075
test loss item: 0.3157379627227783
test loss item: 0.509379506111145
test loss item: 1.1379156112670898
test loss item: 0.25300177931785583
test loss item: 0.24995142221450806
test loss item: 0.41453972458839417
test loss item: 0.2659813165664673
test loss item: 0.23190335929393768
test loss item: 0.32874947786331177
test loss item: 0.6201907992362976
test loss item: 0.7258239388465881
test loss item: 0.31209897994995117
test loss item: 0.9719940423965454
test loss item: 0.428453266620636
test loss item: 0.4053385555744171
test loss item: 0.23646984994411469
test loss item: 0.3014552593231201
test loss item: 0.3071920871734619
test loss item: 0.4046802818775177
test loss item: 0.2862027883529663
test loss item: 0.44048115611076355
test loss item: 0.4390302896499634
test loss item: 0.9727048873901367
test loss item: 0.1900513619184494
test loss item: 0.2245945781469345
test loss item: 0.7185003161430359
test loss item: 0.5848823189735413
test loss item: 0.6570462584495544
test loss item: 0.8809003233909607
test loss item: 1.8639698028564453
test loss item: 0.6491687297821045
test loss item: 0.3285682797431946
test loss item: 0.3587214946746826
test loss item: 0.29551059007644653
test loss item: 0.47592058777809143
test loss item: 0.2922990918159485
test loss item: 0.8251920938491821
test loss item: 0.4626602232456207
test loss item: 0.4153083264827728
test loss item: 0.2915055453777313
test loss item: 0.6082051992416382
test loss item: 0.8676780462265015
test loss item: 0.4431450664997101
test loss item: 0.2159232199192047
test loss item: 0.323722243309021
test loss item: 0.29942503571510315
test loss item: 0.4151240289211273
test loss item: 1.0795115232467651
test loss item: 0.6781544089317322
test loss item: 0.3719973564147949
test loss item: 0.30932897329330444
test loss item: 0.29679083824157715
test loss item: 0.5769935250282288
test loss item: 0.2660062313079834
test loss item: 0.2695562541484833
test loss item: 0.30462411046028137
test loss item: 1.0237356424331665
test loss item: 0.40510037541389465
test loss item: 0.3680199086666107
test loss item: 0.3246355354785919
test loss item: 0.6825941205024719
test loss item: 0.5406521558761597
test loss item: 0.20162811875343323
test loss item: 0.9527813196182251
test loss item: 0.40005555748939514
test loss item: 0.4134611487388611
test loss item: 0.23199164867401123
test loss item: 0.29812121391296387
test loss item: 0.2374822050333023
test loss item: 1.9410364627838135
test loss item: 0.5796679258346558
test loss item: 0.2739883065223694
test loss item: 0.18121692538261414
test loss item: 1.2121914625167847
test loss item: 0.9877552390098572
test loss item: 1.3927322626113892
test loss item: 0.29905858635902405
test loss item: 0.3425673246383667
test loss item: 0.22696764767169952
test loss item: 0.2300042361021042
test loss item: 0.32681772112846375
Epoch [14/50], Training Loss: 0.6298, Testing Loss: 0.5151
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 15/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.613322913646698
1
train loss item: 1.5520001649856567
2
train loss item: 0.3126515746116638
3
train loss item: 0.7156356573104858
4
train loss item: 0.5510707497596741
5
train loss item: 0.4764559864997864
6
train loss item: 0.34620603919029236
7
train loss item: 1.0039076805114746
8
train loss item: 0.24936309456825256
9
train loss item: 0.3587585985660553
10
train loss item: 0.4773408770561218
11
train loss item: 0.33591586351394653
12
train loss item: 0.22918759286403656
13
train loss item: 0.6572815179824829
14
train loss item: 0.4328542649745941
15
train loss item: 0.8256986737251282
16
train loss item: 0.2055807262659073
17
train loss item: 0.38360825181007385
18
train loss item: 0.44211557507514954
19
train loss item: 0.33329400420188904
20
train loss item: 0.32899078726768494
21
train loss item: 0.2600482702255249
22
train loss item: 1.2184052467346191
23
train loss item: 1.1402626037597656
24
train loss item: 0.641960084438324
25
train loss item: 0.3175637423992157
26
train loss item: 0.3062635660171509
27
train loss item: 0.4374605119228363
28
train loss item: 0.20395877957344055
29
train loss item: 0.9789257645606995
30
train loss item: 2.5765373706817627
31
train loss item: 0.6870110630989075
32
train loss item: 0.2351003885269165
33
train loss item: 0.5084887742996216
34
train loss item: 0.297760546207428
35
train loss item: 2.6556859016418457
36
train loss item: 0.6094329953193665
37
train loss item: 0.3448520004749298
38
train loss item: 0.5489080548286438
39
train loss item: 0.44045814871788025
40
train loss item: 0.24946165084838867
41
train loss item: 0.4250084459781647
42
train loss item: 0.30887001752853394
43
train loss item: 0.27746525406837463
44
train loss item: 0.8830921649932861
45
train loss item: 0.24810223281383514
46
train loss item: 0.2566809356212616
47
train loss item: 0.4264741539955139
48
train loss item: 0.3406502306461334
49
train loss item: 0.2737196981906891
50
train loss item: 0.344745934009552
51
train loss item: 1.123055338859558
52
train loss item: 0.21682773530483246
53
train loss item: 0.26783040165901184
54
train loss item: 2.5191566944122314
55
train loss item: 0.29108041524887085
56
train loss item: 0.4130748510360718
57
train loss item: 0.3736274540424347
58
train loss item: 0.2751363217830658
59
train loss item: 0.24906255304813385
60
train loss item: 1.1533821821212769
61
train loss item: 2.462660551071167
62
train loss item: 0.32034415006637573
63
train loss item: 0.4039531946182251
64
train loss item: 0.25867515802383423
65
train loss item: 0.6630434393882751
66
train loss item: 0.4852280914783478
67
train loss item: 0.31626176834106445
68
train loss item: 0.38275575637817383
69
train loss item: 0.41036152839660645
70
train loss item: 0.3370025157928467
71
train loss item: 0.25485774874687195
72
train loss item: 0.2876698672771454
73
train loss item: 0.3809686303138733
74
train loss item: 0.23472265899181366
75
train loss item: 0.22338098287582397
76
train loss item: 1.0955716371536255
77
train loss item: 1.5112533569335938
78
train loss item: 0.20503926277160645
79
train loss item: 0.3249486982822418
80
train loss item: 0.2545645236968994
81
train loss item: 0.2715134918689728
82
train loss item: 0.33438101410865784
83
train loss item: 0.8036903142929077
84
train loss item: 0.42603763937950134
85
train loss item: 0.7367032766342163
86
train loss item: 4.598629951477051
87
train loss item: 0.28456926345825195
88
train loss item: 0.4027804732322693
epoch train loss: 0.6160494159446673
testing phase
test loss item: 0.2502259314060211
test loss item: 0.22705647349357605
test loss item: 0.7205818295478821
test loss item: 0.3114096224308014
test loss item: 0.3640557825565338
test loss item: 0.2106332927942276
test loss item: 1.7173850536346436
test loss item: 0.5043216943740845
test loss item: 0.3130738139152527
test loss item: 0.5079002380371094
test loss item: 1.1190727949142456
test loss item: 0.25862112641334534
test loss item: 0.24924074113368988
test loss item: 0.3896634578704834
test loss item: 0.26216691732406616
test loss item: 0.22869464755058289
test loss item: 0.324006050825119
test loss item: 0.6286638379096985
test loss item: 0.7262582182884216
test loss item: 0.30561184883117676
test loss item: 0.986400842666626
test loss item: 0.4279489815235138
test loss item: 0.387206107378006
test loss item: 0.23347730934619904
test loss item: 0.30120646953582764
test loss item: 0.30606213212013245
test loss item: 0.39818865060806274
test loss item: 0.28199759125709534
test loss item: 0.437431663274765
test loss item: 0.4350048899650574
test loss item: 0.9528777003288269
test loss item: 0.1913510411977768
test loss item: 0.22036220133304596
test loss item: 0.7324833273887634
test loss item: 0.5935488343238831
test loss item: 0.6956681609153748
test loss item: 0.8730022311210632
test loss item: 1.828191876411438
test loss item: 0.6533556580543518
test loss item: 0.3226899206638336
test loss item: 0.3529708683490753
test loss item: 0.28323644399642944
test loss item: 0.47394877672195435
test loss item: 0.2945300340652466
test loss item: 0.8189955353736877
test loss item: 0.4534316956996918
test loss item: 0.3966931998729706
test loss item: 0.28572067618370056
test loss item: 0.6074174642562866
test loss item: 0.8611058592796326
test loss item: 0.4384509325027466
test loss item: 0.21231088042259216
test loss item: 0.3107808530330658
test loss item: 0.3141270577907562
test loss item: 0.4024869501590729
test loss item: 1.0836061239242554
test loss item: 0.6831770539283752
test loss item: 0.3414144515991211
test loss item: 0.3046364486217499
test loss item: 0.28706589341163635
test loss item: 0.5808762311935425
test loss item: 0.26179999113082886
test loss item: 0.2596147656440735
test loss item: 0.30352967977523804
test loss item: 1.0176517963409424
test loss item: 0.413057804107666
test loss item: 0.36228203773498535
test loss item: 0.3206874430179596
test loss item: 0.6776601672172546
test loss item: 0.546950101852417
test loss item: 0.19828017055988312
test loss item: 0.9346185326576233
test loss item: 0.3797034025192261
test loss item: 0.40744346380233765
test loss item: 0.22818368673324585
test loss item: 0.27741074562072754
test loss item: 0.23500609397888184
test loss item: 1.8882420063018799
test loss item: 0.5532264709472656
test loss item: 0.2673649489879608
test loss item: 0.17821267247200012
test loss item: 1.1879260540008545
test loss item: 0.9795405864715576
test loss item: 1.3703912496566772
test loss item: 0.28253373503685
test loss item: 0.34653013944625854
test loss item: 0.22331735491752625
test loss item: 0.22471249103546143
test loss item: 0.36255407333374023
Epoch [15/50], Training Loss: 0.6160, Testing Loss: 0.5096
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 16/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6057767868041992
1
train loss item: 1.52007257938385
2
train loss item: 0.3047258257865906
3
train loss item: 0.6957603096961975
4
train loss item: 0.5167114734649658
5
train loss item: 0.47012749314308167
6
train loss item: 0.3359247148036957
7
train loss item: 0.9854997992515564
8
train loss item: 0.23978868126869202
9
train loss item: 0.34802645444869995
10
train loss item: 0.4631861746311188
11
train loss item: 0.32929378747940063
12
train loss item: 0.21875740587711334
13
train loss item: 0.6441524028778076
14
train loss item: 0.42576950788497925
15
train loss item: 0.806943416595459
16
train loss item: 0.1989343762397766
17
train loss item: 0.37118908762931824
18
train loss item: 0.4333529472351074
19
train loss item: 0.3252022862434387
20
train loss item: 0.3197583854198456
21
train loss item: 0.24554269015789032
22
train loss item: 1.185865879058838
23
train loss item: 1.1237467527389526
24
train loss item: 0.6267603635787964
25
train loss item: 0.30877992510795593
26
train loss item: 0.29965701699256897
27
train loss item: 0.42890021204948425
28
train loss item: 0.1977696567773819
29
train loss item: 0.9584543704986572
30
train loss item: 2.5401833057403564
31
train loss item: 0.6745011210441589
32
train loss item: 0.22717788815498352
33
train loss item: 0.49970269203186035
34
train loss item: 0.2865610420703888
35
train loss item: 2.627825975418091
36
train loss item: 0.5929980278015137
37
train loss item: 0.3379395604133606
38
train loss item: 0.5385106801986694
39
train loss item: 0.433109849691391
40
train loss item: 0.24490852653980255
41
train loss item: 0.4179847538471222
42
train loss item: 0.3050280213356018
43
train loss item: 0.2704290747642517
44
train loss item: 0.8684536814689636
45
train loss item: 0.24236677587032318
46
train loss item: 0.24687808752059937
47
train loss item: 0.4192661643028259
48
train loss item: 0.33279547095298767
49
train loss item: 0.26117369532585144
50
train loss item: 0.3366793692111969
51
train loss item: 1.1026666164398193
52
train loss item: 0.20795512199401855
53
train loss item: 0.25326770544052124
54
train loss item: 2.4907140731811523
55
train loss item: 0.2858861982822418
56
train loss item: 0.40357398986816406
57
train loss item: 0.3666211664676666
58
train loss item: 0.2642933130264282
59
train loss item: 0.241631418466568
60
train loss item: 1.128230333328247
61
train loss item: 2.4326071739196777
62
train loss item: 0.304815411567688
63
train loss item: 0.39452439546585083
64
train loss item: 0.2543698251247406
65
train loss item: 0.6428737044334412
66
train loss item: 0.47532686591148376
67
train loss item: 0.3051132559776306
68
train loss item: 0.36487340927124023
69
train loss item: 0.40098413825035095
70
train loss item: 0.32944414019584656
71
train loss item: 0.2451266050338745
72
train loss item: 0.279386043548584
73
train loss item: 0.37270256876945496
74
train loss item: 0.2256900519132614
75
train loss item: 0.21585264801979065
76
train loss item: 1.0780986547470093
77
train loss item: 1.4924402236938477
78
train loss item: 0.19897866249084473
79
train loss item: 0.32064148783683777
80
train loss item: 0.24323152005672455
81
train loss item: 0.2665307819843292
82
train loss item: 0.32337191700935364
83
train loss item: 0.7836106419563293
84
train loss item: 0.4141668379306793
85
train loss item: 0.7253148555755615
86
train loss item: 4.560326099395752
87
train loss item: 0.2699679434299469
88
train loss item: 0.39517053961753845
epoch train loss: 0.6033627513084519
testing phase
test loss item: 0.24603688716888428
test loss item: 0.2131241410970688
test loss item: 0.6766113042831421
test loss item: 0.29882124066352844
test loss item: 0.3408430814743042
test loss item: 0.20133242011070251
test loss item: 1.671760082244873
test loss item: 0.4944297969341278
test loss item: 0.30014827847480774
test loss item: 0.4912075996398926
test loss item: 1.038153052330017
test loss item: 0.2453131079673767
test loss item: 0.24490123987197876
test loss item: 0.3799389898777008
test loss item: 0.2483447790145874
test loss item: 0.21157051622867584
test loss item: 0.31798073649406433
test loss item: 0.5781363248825073
test loss item: 0.7193487286567688
test loss item: 0.2987414598464966
test loss item: 0.9051637649536133
test loss item: 0.414266973733902
test loss item: 0.347898006439209
test loss item: 0.2276563197374344
test loss item: 0.2925027310848236
test loss item: 0.3140847086906433
test loss item: 0.3892688751220703
test loss item: 0.26313096284866333
test loss item: 0.41803842782974243
test loss item: 0.42295902967453003
test loss item: 0.8860155344009399
test loss item: 0.1781628429889679
test loss item: 0.21396948397159576
test loss item: 0.6820911169052124
test loss item: 0.5477225184440613
test loss item: 0.630792498588562
test loss item: 0.8523253798484802
test loss item: 1.6727145910263062
test loss item: 0.6129906177520752
test loss item: 0.31628984212875366
test loss item: 0.34570443630218506
test loss item: 0.27630630135536194
test loss item: 0.4455011487007141
test loss item: 0.28027084469795227
test loss item: 0.7687312960624695
test loss item: 0.44444504380226135
test loss item: 0.35827839374542236
test loss item: 0.2787892520427704
test loss item: 0.580182671546936
test loss item: 0.8102620840072632
test loss item: 0.4185437560081482
test loss item: 0.20737139880657196
test loss item: 0.29779425263404846
test loss item: 0.28852492570877075
test loss item: 0.38331520557403564
test loss item: 0.997965395450592
test loss item: 0.6370840668678284
test loss item: 0.3275463581085205
test loss item: 0.2942623198032379
test loss item: 0.2765216827392578
test loss item: 0.5586170554161072
test loss item: 0.2549436688423157
test loss item: 0.258577823638916
test loss item: 0.3020617961883545
test loss item: 0.93590247631073
test loss item: 0.39372187852859497
test loss item: 0.3558392822742462
test loss item: 0.3150680363178253
test loss item: 0.6454435586929321
test loss item: 0.5216370820999146
test loss item: 0.18808101117610931
test loss item: 0.9192679524421692
test loss item: 0.3601630628108978
test loss item: 0.40306365489959717
test loss item: 0.22124633193016052
test loss item: 0.24826760590076447
test loss item: 0.23003734648227692
test loss item: 1.7132771015167236
test loss item: 0.5349519848823547
test loss item: 0.2601895034313202
test loss item: 0.17773835361003876
test loss item: 1.1146800518035889
test loss item: 0.942802369594574
test loss item: 1.2258630990982056
test loss item: 0.2733199894428253
test loss item: 0.3514651358127594
test loss item: 0.21640349924564362
test loss item: 0.21019025146961212
test loss item: 0.43354418873786926
Epoch [16/50], Training Loss: 0.6034, Testing Loss: 0.4841
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 17/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6015756726264954
1
train loss item: 1.4902695417404175
2
train loss item: 0.2979612648487091
3
train loss item: 0.6742128133773804
4
train loss item: 0.49558377265930176
5
train loss item: 0.4621185064315796
6
train loss item: 0.3285011649131775
7
train loss item: 0.96314936876297
8
train loss item: 0.2353680282831192
9
train loss item: 0.33642423152923584
10
train loss item: 0.44692251086235046
11
train loss item: 0.32383468747138977
12
train loss item: 0.21442735195159912
13
train loss item: 0.6293180584907532
14
train loss item: 0.4194466769695282
15
train loss item: 0.7990667223930359
16
train loss item: 0.19102789461612701
17
train loss item: 0.356916218996048
18
train loss item: 0.4245208501815796
19
train loss item: 0.3181978464126587
20
train loss item: 0.3151373863220215
21
train loss item: 0.23745115101337433
22
train loss item: 1.1655491590499878
23
train loss item: 1.0945302248001099
24
train loss item: 0.6146956086158752
25
train loss item: 0.29529622197151184
26
train loss item: 0.29401662945747375
27
train loss item: 0.4203644394874573
28
train loss item: 0.1898554414510727
29
train loss item: 0.9441338777542114
30
train loss item: 2.497232437133789
31
train loss item: 0.6604248881340027
32
train loss item: 0.2197624295949936
33
train loss item: 0.48596540093421936
34
train loss item: 0.2737511992454529
35
train loss item: 2.595776081085205
36
train loss item: 0.5825281143188477
37
train loss item: 0.33133819699287415
38
train loss item: 0.5218076705932617
39
train loss item: 0.42648419737815857
40
train loss item: 0.24039123952388763
41
train loss item: 0.4076651632785797
42
train loss item: 0.30214428901672363
43
train loss item: 0.2607850730419159
44
train loss item: 0.8529361486434937
45
train loss item: 0.22961202263832092
46
train loss item: 0.23282448947429657
47
train loss item: 0.41198617219924927
48
train loss item: 0.3209975063800812
49
train loss item: 0.2514886260032654
50
train loss item: 0.32994934916496277
51
train loss item: 1.0782150030136108
52
train loss item: 0.2039613425731659
53
train loss item: 0.24380742013454437
54
train loss item: 2.4585678577423096
55
train loss item: 0.2789035737514496
56
train loss item: 0.3966563642024994
57
train loss item: 0.35903263092041016
58
train loss item: 0.25446566939353943
59
train loss item: 0.23529158532619476
60
train loss item: 1.1038687229156494
61
train loss item: 2.3976850509643555
62
train loss item: 0.29661688208580017
63
train loss item: 0.38265904784202576
64
train loss item: 0.245491623878479
65
train loss item: 0.6341077089309692
66
train loss item: 0.4648941457271576
67
train loss item: 0.29438382387161255
68
train loss item: 0.36271655559539795
69
train loss item: 0.39437082409858704
70
train loss item: 0.3221856653690338
71
train loss item: 0.2380157709121704
72
train loss item: 0.27229511737823486
73
train loss item: 0.36658915877342224
74
train loss item: 0.21854721009731293
75
train loss item: 0.20686033368110657
76
train loss item: 1.055121898651123
77
train loss item: 1.474784255027771
78
train loss item: 0.19217845797538757
79
train loss item: 0.31064388155937195
80
train loss item: 0.23257534205913544
81
train loss item: 0.2589621841907501
82
train loss item: 0.31307339668273926
83
train loss item: 0.7647987604141235
84
train loss item: 0.4060213267803192
85
train loss item: 0.7090476751327515
86
train loss item: 4.516999244689941
87
train loss item: 0.2614957392215729
88
train loss item: 0.3922458291053772
epoch train loss: 0.5911669786391633
testing phase
test loss item: 0.24301142990589142
test loss item: 0.21815606951713562
test loss item: 0.6974092721939087
test loss item: 0.3115748167037964
test loss item: 0.3502844274044037
test loss item: 0.20158697664737701
test loss item: 1.6417222023010254
test loss item: 0.4910283386707306
test loss item: 0.30532026290893555
test loss item: 0.5054236054420471
test loss item: 1.0577328205108643
test loss item: 0.2655045986175537
test loss item: 0.25423485040664673
test loss item: 0.37460047006607056
test loss item: 0.25341129302978516
test loss item: 0.21516954898834229
test loss item: 0.3148963451385498
test loss item: 0.602117657661438
test loss item: 0.7089093923568726
test loss item: 0.2977100908756256
test loss item: 0.9299212098121643
test loss item: 0.42490726709365845
test loss item: 0.3625929653644562
test loss item: 0.2219403088092804
test loss item: 0.29678231477737427
test loss item: 0.2978668510913849
test loss item: 0.3922543227672577
test loss item: 0.2658984363079071
test loss item: 0.4242272675037384
test loss item: 0.43160176277160645
test loss item: 0.9040058255195618
test loss item: 0.1857561618089676
test loss item: 0.20932617783546448
test loss item: 0.7123333811759949
test loss item: 0.5698484778404236
test loss item: 0.7327540516853333
test loss item: 0.8502950668334961
test loss item: 1.7211164236068726
test loss item: 0.6301508545875549
test loss item: 0.3111205995082855
test loss item: 0.34096240997314453
test loss item: 0.2689589560031891
test loss item: 0.4591892957687378
test loss item: 0.2955029308795929
test loss item: 0.7802335619926453
test loss item: 0.4406859576702118
test loss item: 0.36954525113105774
test loss item: 0.27845993638038635
test loss item: 0.597113847732544
test loss item: 0.821951150894165
test loss item: 0.4317977726459503
test loss item: 0.2120063304901123
test loss item: 0.3029303550720215
test loss item: 0.33148831129074097
test loss item: 0.39499056339263916
test loss item: 1.0416597127914429
test loss item: 0.6658836603164673
test loss item: 0.3301023840904236
test loss item: 0.2955399453639984
test loss item: 0.2894795536994934
test loss item: 0.5783355832099915
test loss item: 0.25458601117134094
test loss item: 0.25349947810173035
test loss item: 0.3078972101211548
test loss item: 0.9799041748046875
test loss item: 0.4227988123893738
test loss item: 0.3528579771518707
test loss item: 0.3136543333530426
test loss item: 0.666029155254364
test loss item: 0.5238271951675415
test loss item: 0.19073697924613953
test loss item: 0.9022262096405029
test loss item: 0.3653569221496582
test loss item: 0.3949506878852844
test loss item: 0.2185739427804947
test loss item: 0.2568238079547882
test loss item: 0.22498849034309387
test loss item: 1.7835330963134766
test loss item: 0.5287282466888428
test loss item: 0.26127809286117554
test loss item: 0.17407211661338806
test loss item: 1.127090573310852
test loss item: 0.943136990070343
test loss item: 1.2980140447616577
test loss item: 0.2750413417816162
test loss item: 0.3400537371635437
test loss item: 0.21393577754497528
test loss item: 0.21016009151935577
test loss item: 0.39430898427963257
Epoch [17/50], Training Loss: 0.5912, Testing Loss: 0.4931
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 18/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5948932766914368
1
train loss item: 1.4550381898880005
2
train loss item: 0.29257988929748535
3
train loss item: 0.6580978035926819
4
train loss item: 0.4805773198604584
5
train loss item: 0.45636385679244995
6
train loss item: 0.3190980553627014
7
train loss item: 0.945465087890625
8
train loss item: 0.2262096405029297
9
train loss item: 0.32834920287132263
10
train loss item: 0.43777862191200256
11
train loss item: 0.32383617758750916
12
train loss item: 0.2073843777179718
13
train loss item: 0.6195913553237915
14
train loss item: 0.41441231966018677
15
train loss item: 0.777105987071991
16
train loss item: 0.18447335064411163
17
train loss item: 0.34907087683677673
18
train loss item: 0.4182552397251129
19
train loss item: 0.31017425656318665
20
train loss item: 0.30484575033187866
21
train loss item: 0.22619956731796265
22
train loss item: 1.1374303102493286
23
train loss item: 1.0782898664474487
24
train loss item: 0.5986884832382202
25
train loss item: 0.2907402217388153
26
train loss item: 0.28866201639175415
27
train loss item: 0.41254928708076477
28
train loss item: 0.18359121680259705
29
train loss item: 0.9195518493652344
30
train loss item: 2.4615256786346436
31
train loss item: 0.648005485534668
32
train loss item: 0.2116176337003708
33
train loss item: 0.47798267006874084
34
train loss item: 0.26381751894950867
35
train loss item: 2.5676395893096924
36
train loss item: 0.5723183751106262
37
train loss item: 0.32583165168762207
38
train loss item: 0.5128411054611206
39
train loss item: 0.4195742607116699
40
train loss item: 0.23247292637825012
41
train loss item: 0.4008966386318207
42
train loss item: 0.29339301586151123
43
train loss item: 0.25462067127227783
44
train loss item: 0.8399662375450134
45
train loss item: 0.22279946506023407
46
train loss item: 0.22515065968036652
47
train loss item: 0.4028106927871704
48
train loss item: 0.3130947947502136
49
train loss item: 0.24451349675655365
50
train loss item: 0.3218427896499634
51
train loss item: 1.053929328918457
52
train loss item: 0.19587348401546478
53
train loss item: 0.23261675238609314
54
train loss item: 2.4301917552948
55
train loss item: 0.2738458514213562
56
train loss item: 0.38987720012664795
57
train loss item: 0.35317474603652954
58
train loss item: 0.24569527804851532
59
train loss item: 0.22772684693336487
60
train loss item: 1.0782043933868408
61
train loss item: 2.3690168857574463
62
train loss item: 0.28819993138313293
63
train loss item: 0.37220191955566406
64
train loss item: 0.24030357599258423
65
train loss item: 0.6163987517356873
66
train loss item: 0.4591594636440277
67
train loss item: 0.28313130140304565
68
train loss item: 0.3493100702762604
69
train loss item: 0.38686591386795044
70
train loss item: 0.31180092692375183
71
train loss item: 0.2315354198217392
72
train loss item: 0.2635060250759125
73
train loss item: 0.3591284453868866
74
train loss item: 0.21062372624874115
75
train loss item: 0.20072676241397858
76
train loss item: 1.0379160642623901
77
train loss item: 1.4512734413146973
78
train loss item: 0.18537436425685883
79
train loss item: 0.3046256899833679
80
train loss item: 0.22355493903160095
81
train loss item: 0.2550220191478729
82
train loss item: 0.30513685941696167
83
train loss item: 0.7430385947227478
84
train loss item: 0.3986201584339142
85
train loss item: 0.6946268081665039
86
train loss item: 4.477944850921631
87
train loss item: 0.25102123618125916
88
train loss item: 0.38792315125465393
epoch train loss: 0.5796757499488552
testing phase
test loss item: 0.23842844367027283
test loss item: 0.21035639941692352
test loss item: 0.6687979698181152
test loss item: 0.297991007566452
test loss item: 0.33984214067459106
test loss item: 0.1993304044008255
test loss item: 1.5942784547805786
test loss item: 0.4780842959880829
test loss item: 0.2906776964664459
test loss item: 0.48820316791534424
test loss item: 0.9765835404396057
test loss item: 0.24794121086597443
test loss item: 0.24880704283714294
test loss item: 0.36438608169555664
test loss item: 0.24405594170093536
test loss item: 0.20460322499275208
test loss item: 0.31221073865890503
test loss item: 0.5815168023109436
test loss item: 0.6876637935638428
test loss item: 0.2932569086551666
test loss item: 0.8900564908981323
test loss item: 0.4116584360599518
test loss item: 0.3473595976829529
test loss item: 0.21813485026359558
test loss item: 0.29179832339286804
test loss item: 0.28794169425964355
test loss item: 0.3815975785255432
test loss item: 0.2590048611164093
test loss item: 0.40988224744796753
test loss item: 0.42054346203804016
test loss item: 0.8390084505081177
test loss item: 0.1741965264081955
test loss item: 0.20490789413452148
test loss item: 0.6886284947395325
test loss item: 0.548048734664917
test loss item: 0.6423752307891846
test loss item: 0.825922966003418
test loss item: 1.577926516532898
test loss item: 0.6019184589385986
test loss item: 0.3062436878681183
test loss item: 0.3343251347541809
test loss item: 0.2593251168727875
test loss item: 0.45069804787635803
test loss item: 0.28048446774482727
test loss item: 0.7473246455192566
test loss item: 0.43313485383987427
test loss item: 0.3563593626022339
test loss item: 0.27302286028862
test loss item: 0.5766695737838745
test loss item: 0.7642732858657837
test loss item: 0.41285842657089233
test loss item: 0.20793692767620087
test loss item: 0.2953680455684662
test loss item: 0.3046450614929199
test loss item: 0.38186171650886536
test loss item: 0.9777759909629822
test loss item: 0.6179184913635254
test loss item: 0.31686022877693176
test loss item: 0.2901724874973297
test loss item: 0.28360453248023987
test loss item: 0.5627772212028503
test loss item: 0.25116539001464844
test loss item: 0.24941641092300415
test loss item: 0.30416613817214966
test loss item: 0.9264793395996094
test loss item: 0.4003139138221741
test loss item: 0.34446582198143005
test loss item: 0.3093259036540985
test loss item: 0.6506435871124268
test loss item: 0.4797220528125763
test loss item: 0.18514159321784973
test loss item: 0.8847754001617432
test loss item: 0.349391907453537
test loss item: 0.38920852541923523
test loss item: 0.21740777790546417
test loss item: 0.24834968149662018
test loss item: 0.22131773829460144
test loss item: 1.6329885721206665
test loss item: 0.5132033228874207
test loss item: 0.2582644522190094
test loss item: 0.17328207194805145
test loss item: 1.0349048376083374
test loss item: 0.8998982906341553
test loss item: 1.1585073471069336
test loss item: 0.2712641656398773
test loss item: 0.32474854588508606
test loss item: 0.21033257246017456
test loss item: 0.2011919617652893
test loss item: 0.3957861363887787
Epoch [18/50], Training Loss: 0.5797, Testing Loss: 0.4709
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 19/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5895503163337708
1
train loss item: 1.4224528074264526
2
train loss item: 0.28772327303886414
3
train loss item: 0.6373059153556824
4
train loss item: 0.46940040588378906
5
train loss item: 0.45125001668930054
6
train loss item: 0.3129631280899048
7
train loss item: 0.9263634085655212
8
train loss item: 0.22038333117961884
9
train loss item: 0.3171229660511017
10
train loss item: 0.4224267303943634
11
train loss item: 0.32252269983291626
12
train loss item: 0.20377804338932037
13
train loss item: 0.6028012633323669
14
train loss item: 0.409780889749527
15
train loss item: 0.7642658352851868
16
train loss item: 0.1775846928358078
17
train loss item: 0.3384348452091217
18
train loss item: 0.4132421612739563
19
train loss item: 0.3046720325946808
20
train loss item: 0.3003292977809906
21
train loss item: 0.2194051444530487
22
train loss item: 1.116457223892212
23
train loss item: 1.051245927810669
24
train loss item: 0.5893245339393616
25
train loss item: 0.2806076407432556
26
train loss item: 0.2815028131008148
27
train loss item: 0.4063929319381714
28
train loss item: 0.17673619091510773
29
train loss item: 0.9010723829269409
30
train loss item: 2.4217400550842285
31
train loss item: 0.6329613924026489
32
train loss item: 0.20366914570331573
33
train loss item: 0.46540457010269165
34
train loss item: 0.2555004060268402
35
train loss item: 2.5382142066955566
36
train loss item: 0.5628037452697754
37
train loss item: 0.3242564797401428
38
train loss item: 0.4997093975543976
39
train loss item: 0.4142982065677643
40
train loss item: 0.23032407462596893
41
train loss item: 0.3935709297657013
42
train loss item: 0.29036396741867065
43
train loss item: 0.24808315932750702
44
train loss item: 0.8267539143562317
45
train loss item: 0.21393857896327972
46
train loss item: 0.21470925211906433
47
train loss item: 0.39296671748161316
48
train loss item: 0.303587406873703
49
train loss item: 0.23667369782924652
50
train loss item: 0.3158290684223175
51
train loss item: 1.0297491550445557
52
train loss item: 0.19071441888809204
53
train loss item: 0.22578881680965424
54
train loss item: 2.4000790119171143
55
train loss item: 0.2686383128166199
56
train loss item: 0.382928729057312
57
train loss item: 0.34645235538482666
58
train loss item: 0.23846463859081268
59
train loss item: 0.22045081853866577
60
train loss item: 1.0539608001708984
61
train loss item: 2.3360509872436523
62
train loss item: 0.2809762954711914
63
train loss item: 0.3640463948249817
64
train loss item: 0.23320645093917847
65
train loss item: 0.6086328625679016
66
train loss item: 0.45248788595199585
67
train loss item: 0.27191001176834106
68
train loss item: 0.3485962152481079
69
train loss item: 0.3819449245929718
70
train loss item: 0.3032011091709137
71
train loss item: 0.22863046824932098
72
train loss item: 0.2551491856575012
73
train loss item: 0.35446974635124207
74
train loss item: 0.2044612169265747
75
train loss item: 0.19566656649112701
76
train loss item: 1.0135051012039185
77
train loss item: 1.4320658445358276
78
train loss item: 0.1796180158853531
79
train loss item: 0.3008049726486206
80
train loss item: 0.21658669412136078
81
train loss item: 0.24899421632289886
82
train loss item: 0.2953161597251892
83
train loss item: 0.7236828207969666
84
train loss item: 0.3922198414802551
85
train loss item: 0.6758854985237122
86
train loss item: 4.436288356781006
87
train loss item: 0.24311257898807526
88
train loss item: 0.38733360171318054
epoch train loss: 0.5688149247611507
testing phase
test loss item: 0.23307490348815918
test loss item: 0.2151002287864685
test loss item: 0.6601956486701965
test loss item: 0.29372406005859375
test loss item: 0.34416264295578003
test loss item: 0.20494970679283142
test loss item: 1.5536906719207764
test loss item: 0.4709863066673279
test loss item: 0.2816661596298218
test loss item: 0.478787899017334
test loss item: 0.9345131516456604
test loss item: 0.23902148008346558
test loss item: 0.2419120818376541
test loss item: 0.3582991659641266
test loss item: 0.24907375872135162
test loss item: 0.20381446182727814
test loss item: 0.30965545773506165
test loss item: 0.5888486504554749
test loss item: 0.6781796216964722
test loss item: 0.28932300209999084
test loss item: 0.8887587189674377
test loss item: 0.40540647506713867
test loss item: 0.3444860279560089
test loss item: 0.21940115094184875
test loss item: 0.29106101393699646
test loss item: 0.28632858395576477
test loss item: 0.3771289885044098
test loss item: 0.26169463992118835
test loss item: 0.40792569518089294
test loss item: 0.4164324104785919
test loss item: 0.8019279837608337
test loss item: 0.17425763607025146
test loss item: 0.2074730545282364
test loss item: 0.690882682800293
test loss item: 0.5535593032836914
test loss item: 0.6458221077919006
test loss item: 0.8131110072135925
test loss item: 1.50735604763031
test loss item: 0.594473659992218
test loss item: 0.30562594532966614
test loss item: 0.3300536274909973
test loss item: 0.25679337978363037
test loss item: 0.45188823342323303
test loss item: 0.27192825078964233
test loss item: 0.7398326396942139
test loss item: 0.42751169204711914
test loss item: 0.35053935647010803
test loss item: 0.26975104212760925
test loss item: 0.5653216242790222
test loss item: 0.7419476509094238
test loss item: 0.4036838710308075
test loss item: 0.20448452234268188
test loss item: 0.2934816777706146
test loss item: 0.2920803725719452
test loss item: 0.3794316351413727
test loss item: 0.9583540558815002
test loss item: 0.6122565269470215
test loss item: 0.3027404248714447
test loss item: 0.2884732484817505
test loss item: 0.2814348042011261
test loss item: 0.5620602369308472
test loss item: 0.24994681775569916
test loss item: 0.24397847056388855
test loss item: 0.2967395484447479
test loss item: 0.9070731401443481
test loss item: 0.38923099637031555
test loss item: 0.3406468331813812
test loss item: 0.30569252371788025
test loss item: 0.650723397731781
test loss item: 0.4664239287376404
test loss item: 0.1848238706588745
test loss item: 0.8653364777565002
test loss item: 0.3392161428928375
test loss item: 0.3825138509273529
test loss item: 0.2172694206237793
test loss item: 0.24309611320495605
test loss item: 0.22246712446212769
test loss item: 1.5610980987548828
test loss item: 0.5023264288902283
test loss item: 0.2576001286506653
test loss item: 0.1739281564950943
test loss item: 0.98719322681427
test loss item: 0.8799199461936951
test loss item: 1.0933998823165894
test loss item: 0.27169889211654663
test loss item: 0.3209911286830902
test loss item: 0.21113160252571106
test loss item: 0.1998130828142166
test loss item: 0.40060386061668396
Epoch [19/50], Training Loss: 0.5688, Testing Loss: 0.4626
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 20/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5839115977287292
1
train loss item: 1.3921500444412231
2
train loss item: 0.2827966511249542
3
train loss item: 0.6187329292297363
4
train loss item: 0.460822194814682
5
train loss item: 0.444957435131073
6
train loss item: 0.30749693512916565
7
train loss item: 0.9092050194740295
8
train loss item: 0.21611393988132477
9
train loss item: 0.30829834938049316
10
train loss item: 0.40844252705574036
11
train loss item: 0.3175061047077179
12
train loss item: 0.1993483006954193
13
train loss item: 0.5893275141716003
14
train loss item: 0.403731107711792
15
train loss item: 0.7477444410324097
16
train loss item: 0.17151357233524323
17
train loss item: 0.3316214680671692
18
train loss item: 0.40934765338897705
19
train loss item: 0.2997370958328247
20
train loss item: 0.2951239049434662
21
train loss item: 0.21319392323493958
22
train loss item: 1.0899510383605957
23
train loss item: 1.03036367893219
24
train loss item: 0.5784717202186584
25
train loss item: 0.2704496383666992
26
train loss item: 0.2746864855289459
27
train loss item: 0.4011985659599304
28
train loss item: 0.17073719203472137
29
train loss item: 0.8819634914398193
30
train loss item: 2.3849308490753174
31
train loss item: 0.6229214072227478
32
train loss item: 0.19702735543251038
33
train loss item: 0.45591410994529724
34
train loss item: 0.24944454431533813
35
train loss item: 2.5096285343170166
36
train loss item: 0.553689181804657
37
train loss item: 0.32333943247795105
38
train loss item: 0.4908140003681183
39
train loss item: 0.40885651111602783
40
train loss item: 0.22859907150268555
41
train loss item: 0.3868095874786377
42
train loss item: 0.28823122382164
43
train loss item: 0.242817223072052
44
train loss item: 0.8146941065788269
45
train loss item: 0.2086631953716278
46
train loss item: 0.20676524937152863
47
train loss item: 0.3817366361618042
48
train loss item: 0.2964032292366028
49
train loss item: 0.22870446741580963
50
train loss item: 0.3106665313243866
51
train loss item: 1.0078179836273193
52
train loss item: 0.18635456264019012
53
train loss item: 0.22151334583759308
54
train loss item: 2.371718168258667
55
train loss item: 0.2636621594429016
56
train loss item: 0.3765715956687927
57
train loss item: 0.34037211537361145
58
train loss item: 0.2320830374956131
59
train loss item: 0.215457946062088
60
train loss item: 1.0304043292999268
61
train loss item: 2.3069732189178467
62
train loss item: 0.27196216583251953
63
train loss item: 0.3557624816894531
64
train loss item: 0.22763648629188538
65
train loss item: 0.5994434952735901
66
train loss item: 0.44787102937698364
67
train loss item: 0.26291900873184204
68
train loss item: 0.3420785963535309
69
train loss item: 0.37466469407081604
70
train loss item: 0.29596173763275146
71
train loss item: 0.22406448423862457
72
train loss item: 0.24927568435668945
73
train loss item: 0.34959617257118225
74
train loss item: 0.1994689404964447
75
train loss item: 0.19073227047920227
76
train loss item: 0.9936506748199463
77
train loss item: 1.4110403060913086
78
train loss item: 0.17470383644104004
79
train loss item: 0.29692867398262024
80
train loss item: 0.21045170724391937
81
train loss item: 0.24340477585792542
82
train loss item: 0.2875173091888428
83
train loss item: 0.7033262848854065
84
train loss item: 0.38333696126937866
85
train loss item: 0.6586160063743591
86
train loss item: 4.396914482116699
87
train loss item: 0.2370891273021698
88
train loss item: 0.38235384225845337
epoch train loss: 0.5586887715237864
testing phase
test loss item: 0.22942708432674408
test loss item: 0.2085864543914795
test loss item: 0.6556540131568909
test loss item: 0.3019341230392456
test loss item: 0.3350445330142975
test loss item: 0.18974795937538147
test loss item: 1.5130994319915771
test loss item: 0.46123671531677246
test loss item: 0.27416083216667175
test loss item: 0.4699430465698242
test loss item: 0.9319619536399841
test loss item: 0.2565716505050659
test loss item: 0.2394622564315796
test loss item: 0.355025976896286
test loss item: 0.2420472949743271
test loss item: 0.20062755048274994
test loss item: 0.3064841628074646
test loss item: 0.5800062417984009
test loss item: 0.6575382947921753
test loss item: 0.28634244203567505
test loss item: 0.874708354473114
test loss item: 0.41195082664489746
test loss item: 0.3471260964870453
test loss item: 0.21431177854537964
test loss item: 0.2887478470802307
test loss item: 0.2751515209674835
test loss item: 0.37063273787498474
test loss item: 0.2504187524318695
test loss item: 0.39928367733955383
test loss item: 0.4091894328594208
test loss item: 0.7906649708747864
test loss item: 0.1715969294309616
test loss item: 0.20086973905563354
test loss item: 0.6914557814598083
test loss item: 0.5452192425727844
test loss item: 0.7078485488891602
test loss item: 0.7990394830703735
test loss item: 1.5212615728378296
test loss item: 0.589708149433136
test loss item: 0.29607468843460083
test loss item: 0.32560062408447266
test loss item: 0.24737094342708588
test loss item: 0.4486299157142639
test loss item: 0.283473402261734
test loss item: 0.727532684803009
test loss item: 0.42229509353637695
test loss item: 0.3536660075187683
test loss item: 0.26578837633132935
test loss item: 0.5520495772361755
test loss item: 0.7324417233467102
test loss item: 0.3946564793586731
test loss item: 0.19947949051856995
test loss item: 0.28625965118408203
test loss item: 0.3207005560398102
test loss item: 0.37118491530418396
test loss item: 0.9648874998092651
test loss item: 0.6240925192832947
test loss item: 0.2984326481819153
test loss item: 0.2833728492259979
test loss item: 0.2769797444343567
test loss item: 0.5541213750839233
test loss item: 0.24799089133739471
test loss item: 0.23866471648216248
test loss item: 0.2944755256175995
test loss item: 0.9143364429473877
test loss item: 0.41160905361175537
test loss item: 0.3343084454536438
test loss item: 0.2992062568664551
test loss item: 0.6561568975448608
test loss item: 0.45482999086380005
test loss item: 0.1787615567445755
test loss item: 0.8449921607971191
test loss item: 0.33440181612968445
test loss item: 0.3771221339702606
test loss item: 0.20922233164310455
test loss item: 0.244028240442276
test loss item: 0.2162349373102188
test loss item: 1.581186294555664
test loss item: 0.4958244860172272
test loss item: 0.2463209331035614
test loss item: 0.16143320500850677
test loss item: 0.9820772409439087
test loss item: 0.8651644587516785
test loss item: 1.127872109413147
test loss item: 0.2638932764530182
test loss item: 0.3029571771621704
test loss item: 0.1984957605600357
test loss item: 0.19557330012321472
test loss item: 0.3221018612384796
Epoch [20/50], Training Loss: 0.5587, Testing Loss: 0.4582
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 21/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5780142545700073
1
train loss item: 1.3621292114257812
2
train loss item: 0.2759101092815399
3
train loss item: 0.6052051782608032
4
train loss item: 0.4555419981479645
5
train loss item: 0.44008615612983704
6
train loss item: 0.29703348875045776
7
train loss item: 0.8936169147491455
8
train loss item: 0.2079550176858902
9
train loss item: 0.3033633828163147
10
train loss item: 0.40346819162368774
11
train loss item: 0.31535643339157104
12
train loss item: 0.19359435141086578
13
train loss item: 0.5800355076789856
14
train loss item: 0.3981442451477051
15
train loss item: 0.7291590571403503
16
train loss item: 0.16720113158226013
17
train loss item: 0.32551684975624084
18
train loss item: 0.40294116735458374
19
train loss item: 0.29382094740867615
20
train loss item: 0.2819775342941284
21
train loss item: 0.20606379210948944
22
train loss item: 1.0626394748687744
23
train loss item: 1.0135854482650757
24
train loss item: 0.5668492317199707
25
train loss item: 0.2659975588321686
26
train loss item: 0.2722831666469574
27
train loss item: 0.39307841658592224
28
train loss item: 0.16669990122318268
29
train loss item: 0.8568603992462158
30
train loss item: 2.3549015522003174
31
train loss item: 0.6139612197875977
32
train loss item: 0.1919316202402115
33
train loss item: 0.4508376121520996
34
train loss item: 0.24152477085590363
35
train loss item: 2.485124111175537
36
train loss item: 0.5434188842773438
37
train loss item: 0.32174521684646606
38
train loss item: 0.48592501878738403
39
train loss item: 0.4035488963127136
40
train loss item: 0.21855707466602325
41
train loss item: 0.37893831729888916
42
train loss item: 0.28271225094795227
43
train loss item: 0.23842009902000427
44
train loss item: 0.8029537796974182
45
train loss item: 0.201940655708313
46
train loss item: 0.2013002634048462
47
train loss item: 0.3755718767642975
48
train loss item: 0.2881261110305786
49
train loss item: 0.2227044403553009
50
train loss item: 0.3056195080280304
51
train loss item: 0.9857311844825745
52
train loss item: 0.1785084307193756
53
train loss item: 0.21231502294540405
54
train loss item: 2.347041130065918
55
train loss item: 0.2573646008968353
56
train loss item: 0.36861124634742737
57
train loss item: 0.3336017429828644
58
train loss item: 0.2266772985458374
59
train loss item: 0.21083270013332367
60
train loss item: 1.0037503242492676
61
train loss item: 2.2814738750457764
62
train loss item: 0.26694315671920776
63
train loss item: 0.3500708341598511
64
train loss item: 0.223905548453331
65
train loss item: 0.5813844799995422
66
train loss item: 0.4437843859195709
67
train loss item: 0.2579214572906494
68
train loss item: 0.32874277234077454
69
train loss item: 0.36807548999786377
70
train loss item: 0.2891642153263092
71
train loss item: 0.21520638465881348
72
train loss item: 0.24202649295330048
73
train loss item: 0.34306734800338745
74
train loss item: 0.19407068192958832
75
train loss item: 0.18611253798007965
76
train loss item: 0.9770328402519226
77
train loss item: 1.3885260820388794
78
train loss item: 0.17027223110198975
79
train loss item: 0.2961883544921875
80
train loss item: 0.2036869078874588
81
train loss item: 0.24257227778434753
82
train loss item: 0.280626505613327
83
train loss item: 0.6828084588050842
84
train loss item: 0.37946805357933044
85
train loss item: 0.6441487669944763
86
train loss item: 4.363705158233643
87
train loss item: 0.2296346127986908
88
train loss item: 0.3805023729801178
epoch train loss: 0.5489825591277541
testing phase
test loss item: 0.21893174946308136
test loss item: 0.18147647380828857
test loss item: 0.5979078412055969
test loss item: 0.27119144797325134
test loss item: 0.31138646602630615
test loss item: 0.1867755502462387
test loss item: 1.4721055030822754
test loss item: 0.44849249720573425
test loss item: 0.25196102261543274
test loss item: 0.4417119324207306
test loss item: 0.8546211123466492
test loss item: 0.21686741709709167
test loss item: 0.22048981487751007
test loss item: 0.35335344076156616
test loss item: 0.2235104739665985
test loss item: 0.16498079895973206
test loss item: 0.29765528440475464
test loss item: 0.5332658886909485
test loss item: 0.64792799949646
test loss item: 0.2790628969669342
test loss item: 0.8177177309989929
test loss item: 0.3808894455432892
test loss item: 0.3156861960887909
test loss item: 0.21080072224140167
test loss item: 0.2715955078601837
test loss item: 0.2692461311817169
test loss item: 0.36148205399513245
test loss item: 0.2379641979932785
test loss item: 0.37654662132263184
test loss item: 0.39239054918289185
test loss item: 0.7343405485153198
test loss item: 0.14615893363952637
test loss item: 0.19566473364830017
test loss item: 0.6251821517944336
test loss item: 0.4940054416656494
test loss item: 0.5862573981285095
test loss item: 0.7746630311012268
test loss item: 1.3579022884368896
test loss item: 0.5448952913284302
test loss item: 0.2952515184879303
test loss item: 0.3191301226615906
test loss item: 0.23386025428771973
test loss item: 0.4104800224304199
test loss item: 0.24629001319408417
test loss item: 0.6913192868232727
test loss item: 0.4136519730091095
test loss item: 0.32729968428611755
test loss item: 0.26293811202049255
test loss item: 0.5089468359947205
test loss item: 0.6789255738258362
test loss item: 0.366227388381958
test loss item: 0.1901412457227707
test loss item: 0.2713451087474823
test loss item: 0.24978652596473694
test loss item: 0.34995537996292114
test loss item: 0.8592384457588196
test loss item: 0.5695106387138367
test loss item: 0.2944261133670807
test loss item: 0.271716445684433
test loss item: 0.256148099899292
test loss item: 0.5165171027183533
test loss item: 0.23521724343299866
test loss item: 0.2339155673980713
test loss item: 0.2822472155094147
test loss item: 0.7998989224433899
test loss item: 0.3622664511203766
test loss item: 0.3244747817516327
test loss item: 0.28822556138038635
test loss item: 0.5873907208442688
test loss item: 0.42762497067451477
test loss item: 0.15527763962745667
test loss item: 0.8255119919776917
test loss item: 0.3188798129558563
test loss item: 0.3712786138057709
test loss item: 0.1960023194551468
test loss item: 0.21649648249149323
test loss item: 0.21130190789699554
test loss item: 1.3905291557312012
test loss item: 0.4884174168109894
test loss item: 0.23504029214382172
test loss item: 0.1557147353887558
test loss item: 0.9060466289520264
test loss item: 0.8321824073791504
test loss item: 0.9471707344055176
test loss item: 0.25496694445610046
test loss item: 0.29003655910491943
test loss item: 0.17587320506572723
test loss item: 0.16150644421577454
test loss item: 0.37257784605026245
Epoch [21/50], Training Loss: 0.5490, Testing Loss: 0.4258
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 22/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5732279419898987
1
train loss item: 1.3459705114364624
2
train loss item: 0.2715245187282562
3
train loss item: 0.5872966647148132
4
train loss item: 0.4499116837978363
5
train loss item: 0.4346265196800232
6
train loss item: 0.2920346260070801
7
train loss item: 0.8786500096321106
8
train loss item: 0.20738625526428223
9
train loss item: 0.2984407842159271
10
train loss item: 0.39266878366470337
11
train loss item: 0.31741681694984436
12
train loss item: 0.19460958242416382
13
train loss item: 0.5702348947525024
14
train loss item: 0.39349237084388733
15
train loss item: 0.7228742837905884
16
train loss item: 0.16195757687091827
17
train loss item: 0.31682854890823364
18
train loss item: 0.40096724033355713
19
train loss item: 0.29056236147880554
20
train loss item: 0.27491044998168945
21
train loss item: 0.20896491408348083
22
train loss item: 1.048682451248169
23
train loss item: 0.9928299784660339
24
train loss item: 0.5596941709518433
25
train loss item: 0.25730201601982117
26
train loss item: 0.2666597068309784
27
train loss item: 0.3876216411590576
28
train loss item: 0.1612459123134613
29
train loss item: 0.8515667915344238
30
train loss item: 2.311206817626953
31
train loss item: 0.6057983040809631
32
train loss item: 0.19101694226264954
33
train loss item: 0.4406367540359497
34
train loss item: 0.2387467622756958
35
train loss item: 2.457662343978882
36
train loss item: 0.5403845906257629
37
train loss item: 0.32074838876724243
38
train loss item: 0.4659547805786133
39
train loss item: 0.3972877562046051
40
train loss item: 0.21608684957027435
41
train loss item: 0.3725467026233673
42
train loss item: 0.2790432572364807
43
train loss item: 0.23435437679290771
44
train loss item: 0.7944360971450806
45
train loss item: 0.196587935090065
46
train loss item: 0.19546020030975342
47
train loss item: 0.365052193403244
48
train loss item: 0.28151631355285645
49
train loss item: 0.21958322823047638
50
train loss item: 0.29873624444007874
51
train loss item: 0.964771032333374
52
train loss item: 0.1759343296289444
53
train loss item: 0.21190492808818817
54
train loss item: 2.319488763809204
55
train loss item: 0.25624239444732666
56
train loss item: 0.36490944027900696
57
train loss item: 0.3301027715206146
58
train loss item: 0.22313031554222107
59
train loss item: 0.21178145706653595
60
train loss item: 0.9848986864089966
61
train loss item: 2.253634214401245
62
train loss item: 0.26911473274230957
63
train loss item: 0.34091436862945557
64
train loss item: 0.21898868680000305
65
train loss item: 0.5735597610473633
66
train loss item: 0.44486820697784424
67
train loss item: 0.25268441438674927
68
train loss item: 0.33204707503318787
69
train loss item: 0.36872372031211853
70
train loss item: 0.2857908010482788
71
train loss item: 0.21623370051383972
72
train loss item: 0.2390608787536621
73
train loss item: 0.34124213457107544
74
train loss item: 0.19247689843177795
75
train loss item: 0.18334029614925385
76
train loss item: 0.9598849415779114
77
train loss item: 1.3693420886993408
78
train loss item: 0.16787992417812347
79
train loss item: 0.29320022463798523
80
train loss item: 0.20233573019504547
81
train loss item: 0.2332344353199005
82
train loss item: 0.27866947650909424
83
train loss item: 0.6666645407676697
84
train loss item: 0.37492889165878296
85
train loss item: 0.628326416015625
86
train loss item: 4.323721885681152
87
train loss item: 0.226630300283432
88
train loss item: 0.3778161108493805
epoch train loss: 0.5414773687887727
testing phase
test loss item: 0.23033347725868225
test loss item: 0.23356305062770844
test loss item: 0.7178133130073547
test loss item: 0.31673869490623474
test loss item: 0.3694768249988556
test loss item: 0.21007023751735687
test loss item: 1.4739207029342651
test loss item: 0.45543918013572693
test loss item: 0.289343923330307
test loss item: 0.4983237683773041
test loss item: 1.033307433128357
test loss item: 0.2728419899940491
test loss item: 0.25466272234916687
test loss item: 0.3494910001754761
test loss item: 0.2725957930088043
test loss item: 0.2177840769290924
test loss item: 0.29743316769599915
test loss item: 0.6369208097457886
test loss item: 0.6675346493721008
test loss item: 0.2868315875530243
test loss item: 0.9517533779144287
test loss item: 0.41596221923828125
test loss item: 0.40420618653297424
test loss item: 0.22333522140979767
test loss item: 0.29515719413757324
test loss item: 0.2885953187942505
test loss item: 0.3821186423301697
test loss item: 0.27957117557525635
test loss item: 0.42236992716789246
test loss item: 0.4361916780471802
test loss item: 0.8546534776687622
test loss item: 0.20697908103466034
test loss item: 0.2115052193403244
test loss item: 0.7521666884422302
test loss item: 0.5988255739212036
test loss item: 0.84732586145401
test loss item: 0.8056879043579102
test loss item: 1.752253770828247
test loss item: 0.6304693818092346
test loss item: 0.3014507591724396
test loss item: 0.3225764334201813
test loss item: 0.2879396975040436
test loss item: 0.4672473073005676
test loss item: 0.2921949326992035
test loss item: 0.7599117755889893
test loss item: 0.41758498549461365
test loss item: 0.4024662375450134
test loss item: 0.27813559770584106
test loss item: 0.5867317318916321
test loss item: 0.8204630017280579
test loss item: 0.4194072484970093
test loss item: 0.21926246583461761
test loss item: 0.30000007152557373
test loss item: 0.3503264784812927
test loss item: 0.3976619243621826
test loss item: 1.1135847568511963
test loss item: 0.7017747163772583
test loss item: 0.29836681485176086
test loss item: 0.29658570885658264
test loss item: 0.3008289635181427
test loss item: 0.5978848338127136
test loss item: 0.24701304733753204
test loss item: 0.24118191003799438
test loss item: 0.30070510506629944
test loss item: 1.0377552509307861
test loss item: 0.43467915058135986
test loss item: 0.34475091099739075
test loss item: 0.2995726466178894
test loss item: 0.7063698768615723
test loss item: 0.5142859816551208
test loss item: 0.19415175914764404
test loss item: 0.811028778553009
test loss item: 0.3378468155860901
test loss item: 0.3682033121585846
test loss item: 0.20591235160827637
test loss item: 0.28847536444664
test loss item: 0.22645771503448486
test loss item: 1.843011498451233
test loss item: 0.493823379278183
test loss item: 0.26150041818618774
test loss item: 0.16404910385608673
test loss item: 1.057257890701294
test loss item: 0.8972605466842651
test loss item: 1.2993149757385254
test loss item: 0.28090769052505493
test loss item: 0.3108808994293213
test loss item: 0.1991988569498062
test loss item: 0.20466630160808563
test loss item: 0.32727134227752686
Epoch [22/50], Training Loss: 0.5415, Testing Loss: 0.4907
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 23/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5671181082725525
1
train loss item: 1.315480351448059
2
train loss item: 0.26664963364601135
3
train loss item: 0.5977994203567505
4
train loss item: 0.4478153586387634
5
train loss item: 0.4329412877559662
6
train loss item: 0.27962788939476013
7
train loss item: 0.8755223155021667
8
train loss item: 0.20016643404960632
9
train loss item: 0.30129000544548035
10
train loss item: 0.39884284138679504
11
train loss item: 0.31505218148231506
12
train loss item: 0.18780112266540527
13
train loss item: 0.5705900192260742
14
train loss item: 0.38949379324913025
15
train loss item: 0.687014102935791
16
train loss item: 0.1640520989894867
17
train loss item: 0.3191944658756256
18
train loss item: 0.39591923356056213
19
train loss item: 0.2877238094806671
20
train loss item: 0.2560310661792755
21
train loss item: 0.1922207623720169
22
train loss item: 1.0013242959976196
23
train loss item: 1.0057481527328491
24
train loss item: 0.5443142056465149
25
train loss item: 0.2587401866912842
26
train loss item: 0.2710709869861603
27
train loss item: 0.3835662603378296
28
train loss item: 0.1640382558107376
29
train loss item: 0.8108867406845093
30
train loss item: 2.3111355304718018
31
train loss item: 0.6057677268981934
32
train loss item: 0.19123248755931854
33
train loss item: 0.4555782079696655
34
train loss item: 0.23658733069896698
35
train loss item: 2.4433233737945557
36
train loss item: 0.5305489897727966
37
train loss item: 0.32287687063217163
38
train loss item: 0.5015018582344055
39
train loss item: 0.39195844531059265
40
train loss item: 0.21171866357326508
41
train loss item: 0.37119588255882263
42
train loss item: 0.2790885269641876
43
train loss item: 0.23916278779506683
44
train loss item: 0.7850433588027954
45
train loss item: 0.20235739648342133
46
train loss item: 0.19943444430828094
47
train loss item: 0.35795313119888306
48
train loss item: 0.29122963547706604
49
train loss item: 0.21706965565681458
50
train loss item: 0.2976609468460083
51
train loss item: 0.946654200553894
52
train loss item: 0.17526590824127197
53
train loss item: 0.20522023737430573
54
train loss item: 2.3079676628112793
55
train loss item: 0.25476810336112976
56
train loss item: 0.35937875509262085
57
train loss item: 0.3313329219818115
58
train loss item: 0.21940721571445465
59
train loss item: 0.20643608272075653
60
train loss item: 0.9593731164932251
61
train loss item: 2.252156972885132
62
train loss item: 0.25196632742881775
63
train loss item: 0.3400692939758301
64
train loss item: 0.22752170264720917
65
train loss item: 0.5534654259681702
66
train loss item: 0.44546404480934143
67
train loss item: 0.2549450099468231
68
train loss item: 0.31207671761512756
69
train loss item: 0.3587794005870819
70
train loss item: 0.2786819338798523
71
train loss item: 0.20283450186252594
72
train loss item: 0.23778261244297028
73
train loss item: 0.33676478266716003
74
train loss item: 0.18783454596996307
75
train loss item: 0.18569312989711761
76
train loss item: 0.9577662944793701
77
train loss item: 1.3417940139770508
78
train loss item: 0.1676623672246933
79
train loss item: 0.2985263168811798
80
train loss item: 0.1958358734846115
81
train loss item: 0.24697059392929077
82
train loss item: 0.2758510112762451
83
train loss item: 0.6461827158927917
84
train loss item: 0.37301260232925415
85
train loss item: 0.6310890913009644
86
train loss item: 4.307393550872803
87
train loss item: 0.226021870970726
88
train loss item: 0.3780740201473236
epoch train loss: 0.5367245119944047
testing phase
test loss item: 0.22930185496807098
test loss item: 0.18659371137619019
test loss item: 0.5790644884109497
test loss item: 0.2715130150318146
test loss item: 0.31119242310523987
test loss item: 0.18206866085529327
test loss item: 1.4087989330291748
test loss item: 0.4390830993652344
test loss item: 0.2374318391084671
test loss item: 0.4227897524833679
test loss item: 0.8721759915351868
test loss item: 0.2196027636528015
test loss item: 0.21728715300559998
test loss item: 0.3446636199951172
test loss item: 0.22145938873291016
test loss item: 0.1697627454996109
test loss item: 0.2932427227497101
test loss item: 0.5348631739616394
test loss item: 0.6553308963775635
test loss item: 0.27328750491142273
test loss item: 0.8142280578613281
test loss item: 0.38585418462753296
test loss item: 0.33681467175483704
test loss item: 0.20239229500293732
test loss item: 0.267681360244751
test loss item: 0.26357895135879517
test loss item: 0.3481701910495758
test loss item: 0.23950761556625366
test loss item: 0.3696379065513611
test loss item: 0.3800206482410431
test loss item: 0.7364718914031982
test loss item: 0.1443895399570465
test loss item: 0.18809597194194794
test loss item: 0.6392892003059387
test loss item: 0.4902878403663635
test loss item: 0.653706431388855
test loss item: 0.7487077713012695
test loss item: 1.4446955919265747
test loss item: 0.5362929701805115
test loss item: 0.28327956795692444
test loss item: 0.3107413351535797
test loss item: 0.2576850950717926
test loss item: 0.4167726933956146
test loss item: 0.24694570899009705
test loss item: 0.6735021471977234
test loss item: 0.40797314047813416
test loss item: 0.34639695286750793
test loss item: 0.2573482096195221
test loss item: 0.4950698912143707
test loss item: 0.6797286868095398
test loss item: 0.3554021418094635
test loss item: 0.18699681758880615
test loss item: 0.2623120844364166
test loss item: 0.2645089626312256
test loss item: 0.33682796359062195
test loss item: 0.8904250264167786
test loss item: 0.5987203121185303
test loss item: 0.29069676995277405
test loss item: 0.2701510787010193
test loss item: 0.2536351978778839
test loss item: 0.5065622329711914
test loss item: 0.23805223405361176
test loss item: 0.23770079016685486
test loss item: 0.2791939973831177
test loss item: 0.8319681882858276
test loss item: 0.3648902177810669
test loss item: 0.31611862778663635
test loss item: 0.2855204641819
test loss item: 0.6014125943183899
test loss item: 0.400163471698761
test loss item: 0.16000232100486755
test loss item: 0.7999746799468994
test loss item: 0.3104938268661499
test loss item: 0.36582455039024353
test loss item: 0.19708898663520813
test loss item: 0.2418607473373413
test loss item: 0.2092980295419693
test loss item: 1.5145479440689087
test loss item: 0.4736727476119995
test loss item: 0.2512653172016144
test loss item: 0.1627618819475174
test loss item: 0.9317181706428528
test loss item: 0.8067644834518433
test loss item: 1.071393609046936
test loss item: 0.24759072065353394
test loss item: 0.3040720224380493
test loss item: 0.18055537343025208
test loss item: 0.16391167044639587
test loss item: 0.48400986194610596
Epoch [23/50], Training Loss: 0.5367, Testing Loss: 0.4301
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 24/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5705767273902893
1
train loss item: 1.2974592447280884
2
train loss item: 0.26436832547187805
3
train loss item: 0.5643680691719055
4
train loss item: 0.44111788272857666
5
train loss item: 0.4293605387210846
6
train loss item: 0.2826695442199707
7
train loss item: 0.8545054197311401
8
train loss item: 0.197299987077713
9
train loss item: 0.28886646032333374
10
train loss item: 0.38283511996269226
11
train loss item: 0.31368136405944824
12
train loss item: 0.1865198165178299
13
train loss item: 0.5467963218688965
14
train loss item: 0.3890475332736969
15
train loss item: 0.7147576212882996
16
train loss item: 0.15285150706768036
17
train loss item: 0.3111218214035034
18
train loss item: 0.4009549021720886
19
train loss item: 0.29021647572517395
20
train loss item: 0.2738049328327179
21
train loss item: 0.19787655770778656
22
train loss item: 1.0111697912216187
23
train loss item: 0.9575379490852356
24
train loss item: 0.5564163327217102
25
train loss item: 0.24551059305667877
26
train loss item: 0.2616056799888611
27
train loss item: 0.380050390958786
28
train loss item: 0.15214747190475464
29
train loss item: 0.8163355588912964
30
train loss item: 2.2559361457824707
31
train loss item: 0.5792062878608704
32
train loss item: 0.1810668706893921
33
train loss item: 0.42404040694236755
34
train loss item: 0.22958408296108246
35
train loss item: 2.4139864444732666
36
train loss item: 0.5285246968269348
37
train loss item: 0.3246351480484009
38
train loss item: 0.4560226798057556
39
train loss item: 0.40153294801712036
40
train loss item: 0.21428431570529938
41
train loss item: 0.36277905106544495
42
train loss item: 0.3063562214374542
43
train loss item: 0.22695370018482208
44
train loss item: 0.7723203897476196
45
train loss item: 0.18548683822155
46
train loss item: 0.18545933067798615
47
train loss item: 0.36570724844932556
48
train loss item: 0.2712733745574951
49
train loss item: 0.2093341052532196
50
train loss item: 0.2983319163322449
51
train loss item: 0.9320563077926636
52
train loss item: 0.16502195596694946
53
train loss item: 0.20570412278175354
54
train loss item: 2.2764246463775635
55
train loss item: 0.2482636272907257
56
train loss item: 0.35499852895736694
57
train loss item: 0.3251555562019348
58
train loss item: 0.21841630339622498
59
train loss item: 0.19661039113998413
60
train loss item: 0.9474573731422424
61
train loss item: 2.2063682079315186
62
train loss item: 0.2603073716163635
63
train loss item: 0.3458828330039978
64
train loss item: 0.21061649918556213
65
train loss item: 0.5674203634262085
66
train loss item: 0.43563684821128845
67
train loss item: 0.24692483246326447
68
train loss item: 0.34710952639579773
69
train loss item: 0.3601498603820801
70
train loss item: 0.28060585260391235
71
train loss item: 0.20533858239650726
72
train loss item: 0.22548715770244598
73
train loss item: 0.3388500213623047
74
train loss item: 0.18128207325935364
75
train loss item: 0.17506980895996094
76
train loss item: 0.930026650428772
77
train loss item: 1.3458449840545654
78
train loss item: 0.15850265324115753
79
train loss item: 0.3013419806957245
80
train loss item: 0.19242613017559052
81
train loss item: 0.23041532933712006
82
train loss item: 0.26453688740730286
83
train loss item: 0.6452032923698425
84
train loss item: 0.3786300718784332
85
train loss item: 0.6002159118652344
86
train loss item: 4.263311862945557
87
train loss item: 0.21787123382091522
88
train loss item: 0.39475017786026
epoch train loss: 0.5292684040712506
testing phase
test loss item: 0.215257927775383
test loss item: 0.18117880821228027
test loss item: 0.5769933462142944
test loss item: 0.26035258173942566
test loss item: 0.30757591128349304
test loss item: 0.18261584639549255
test loss item: 1.4013137817382812
test loss item: 0.4343017637729645
test loss item: 0.23391668498516083
test loss item: 0.4258899390697479
test loss item: 0.8502569794654846
test loss item: 0.20392301678657532
test loss item: 0.21547073125839233
test loss item: 0.34046703577041626
test loss item: 0.22248917818069458
test loss item: 0.15510676801204681
test loss item: 0.2885575592517853
test loss item: 0.5346259474754333
test loss item: 0.6180770397186279
test loss item: 0.2703181207180023
test loss item: 0.8158382773399353
test loss item: 0.3741607666015625
test loss item: 0.31455934047698975
test loss item: 0.20844654738903046
test loss item: 0.25943243503570557
test loss item: 0.25518062710762024
test loss item: 0.3444015681743622
test loss item: 0.23699837923049927
test loss item: 0.3674387037754059
test loss item: 0.3820735514163971
test loss item: 0.7192556262016296
test loss item: 0.13639497756958008
test loss item: 0.19383636116981506
test loss item: 0.6313883662223816
test loss item: 0.4871770739555359
test loss item: 0.5979958772659302
test loss item: 0.7451731562614441
test loss item: 1.4049642086029053
test loss item: 0.5296147465705872
test loss item: 0.2888490557670593
test loss item: 0.30791333317756653
test loss item: 0.2242717295885086
test loss item: 0.4198125898838043
test loss item: 0.23216475546360016
test loss item: 0.6727077960968018
test loss item: 0.40322133898735046
test loss item: 0.32646241784095764
test loss item: 0.2566823959350586
test loss item: 0.49267131090164185
test loss item: 0.6643331050872803
test loss item: 0.35356423258781433
test loss item: 0.18342338502407074
test loss item: 0.2597440481185913
test loss item: 0.23154392838478088
test loss item: 0.33815404772758484
test loss item: 0.8776974678039551
test loss item: 0.5700211524963379
test loss item: 0.29333966970443726
test loss item: 0.26399722695350647
test loss item: 0.25104379653930664
test loss item: 0.5109615921974182
test loss item: 0.2323860228061676
test loss item: 0.229274719953537
test loss item: 0.2768286168575287
test loss item: 0.8148348927497864
test loss item: 0.341109961271286
test loss item: 0.31501978635787964
test loss item: 0.2777388095855713
test loss item: 0.5895788073539734
test loss item: 0.4054528772830963
test loss item: 0.1457529515028
test loss item: 0.7957882285118103
test loss item: 0.3128836154937744
test loss item: 0.36165735125541687
test loss item: 0.18382185697555542
test loss item: 0.2128491997718811
test loss item: 0.20772919058799744
test loss item: 1.4450039863586426
test loss item: 0.4692786633968353
test loss item: 0.234757199883461
test loss item: 0.14342793822288513
test loss item: 0.8920908570289612
test loss item: 0.8052890300750732
test loss item: 1.011350393295288
test loss item: 0.24682185053825378
test loss item: 0.2554456293582916
test loss item: 0.15970566868782043
test loss item: 0.14920470118522644
test loss item: 0.2896752953529358
Epoch [24/50], Training Loss: 0.5293, Testing Loss: 0.4174
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 25/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5628218650817871
1
train loss item: 1.269061803817749
2
train loss item: 0.2611715793609619
3
train loss item: 0.5549126267433167
4
train loss item: 0.4393959939479828
5
train loss item: 0.42296168208122253
6
train loss item: 0.2762382924556732
7
train loss item: 0.8401694297790527
8
train loss item: 0.19292603433132172
9
train loss item: 0.28345710039138794
10
train loss item: 0.3824159801006317
11
train loss item: 0.3081974983215332
12
train loss item: 0.18386010825634003
13
train loss item: 0.5430861115455627
14
train loss item: 0.3829430043697357
15
train loss item: 0.6881237030029297
16
train loss item: 0.1492713987827301
17
train loss item: 0.3063395321369171
18
train loss item: 0.3888646364212036
19
train loss item: 0.2821676731109619
20
train loss item: 0.2644823491573334
21
train loss item: 0.19140386581420898
22
train loss item: 0.9826546311378479
23
train loss item: 0.943648099899292
24
train loss item: 0.5424396395683289
25
train loss item: 0.24193458259105682
26
train loss item: 0.2537775933742523
27
train loss item: 0.37349534034729004
28
train loss item: 0.14839677512645721
29
train loss item: 0.7911974191665649
30
train loss item: 2.224213123321533
31
train loss item: 0.5781471729278564
32
train loss item: 0.17732220888137817
33
train loss item: 0.4214226007461548
34
train loss item: 0.22578394412994385
35
train loss item: 2.391235589981079
36
train loss item: 0.5236363410949707
37
train loss item: 0.3221592307090759
38
train loss item: 0.4607697129249573
39
train loss item: 0.39115291833877563
40
train loss item: 0.207767054438591
41
train loss item: 0.35387685894966125
42
train loss item: 0.27364808320999146
43
train loss item: 0.22277668118476868
44
train loss item: 0.7648559808731079
45
train loss item: 0.18412286043167114
46
train loss item: 0.18150295317173004
47
train loss item: 0.3592683672904968
48
train loss item: 0.26516643166542053
49
train loss item: 0.20804190635681152
50
train loss item: 0.29116904735565186
51
train loss item: 0.9136459231376648
52
train loss item: 0.16391700506210327
53
train loss item: 0.2061716765165329
54
train loss item: 2.254260778427124
55
train loss item: 0.24554648995399475
56
train loss item: 0.3505595028400421
57
train loss item: 0.3181791305541992
58
train loss item: 0.21300843358039856
59
train loss item: 0.1971919983625412
60
train loss item: 0.9300346970558167
61
train loss item: 2.184375524520874
62
train loss item: 0.25745689868927
63
train loss item: 0.3369542062282562
64
train loss item: 0.2062128484249115
65
train loss item: 0.5596261024475098
66
train loss item: 0.4348869025707245
67
train loss item: 0.24225583672523499
68
train loss item: 0.3397686779499054
69
train loss item: 0.35417166352272034
70
train loss item: 0.2759133279323578
71
train loss item: 0.20251703262329102
72
train loss item: 0.22091801464557648
73
train loss item: 0.3323279321193695
74
train loss item: 0.17928922176361084
75
train loss item: 0.17125876247882843
76
train loss item: 0.9168214201927185
77
train loss item: 1.3254611492156982
78
train loss item: 0.1554669886827469
79
train loss item: 0.2940872311592102
80
train loss item: 0.18832843005657196
81
train loss item: 0.2249900847673416
82
train loss item: 0.2646852731704712
83
train loss item: 0.6288261413574219
84
train loss item: 0.370984822511673
85
train loss item: 0.5952325463294983
86
train loss item: 4.231497764587402
87
train loss item: 0.21516107022762299
88
train loss item: 0.38546404242515564
epoch train loss: 0.5209810221463107
testing phase
test loss item: 0.2079194337129593
test loss item: 0.18301799893379211
test loss item: 0.6072392463684082
test loss item: 0.2557135820388794
test loss item: 0.3144371211528778
test loss item: 0.17848597466945648
test loss item: 1.3741718530654907
test loss item: 0.4225093424320221
test loss item: 0.24353370070457458
test loss item: 0.4409564733505249
test loss item: 0.8674308657646179
test loss item: 0.20216992497444153
test loss item: 0.22041113674640656
test loss item: 0.339099258184433
test loss item: 0.22833207249641418
test loss item: 0.1566411554813385
test loss item: 0.2823422849178314
test loss item: 0.5541580319404602
test loss item: 0.6054974794387817
test loss item: 0.2702869176864624
test loss item: 0.8476443886756897
test loss item: 0.3652730882167816
test loss item: 0.3210175633430481
test loss item: 0.20220094919204712
test loss item: 0.2614934742450714
test loss item: 0.24782821536064148
test loss item: 0.34581324458122253
test loss item: 0.2373407781124115
test loss item: 0.3738543689250946
test loss item: 0.3887544274330139
test loss item: 0.7274560332298279
test loss item: 0.1414581686258316
test loss item: 0.188770592212677
test loss item: 0.6476163864135742
test loss item: 0.5065697431564331
test loss item: 0.5978061556816101
test loss item: 0.7409713268280029
test loss item: 1.4485902786254883
test loss item: 0.5417836308479309
test loss item: 0.28249192237854004
test loss item: 0.30297574400901794
test loss item: 0.213692769408226
test loss item: 0.42647749185562134
test loss item: 0.22713065147399902
test loss item: 0.6906129121780396
test loss item: 0.3950890898704529
test loss item: 0.32811078429222107
test loss item: 0.2594315707683563
test loss item: 0.5093819499015808
test loss item: 0.6821098327636719
test loss item: 0.3621439039707184
test loss item: 0.18767493963241577
test loss item: 0.2636364996433258
test loss item: 0.22477436065673828
test loss item: 0.3504244089126587
test loss item: 0.9187349677085876
test loss item: 0.569298505783081
test loss item: 0.27951180934906006
test loss item: 0.26152050495147705
test loss item: 0.25950634479522705
test loss item: 0.5268020033836365
test loss item: 0.22477948665618896
test loss item: 0.21876175701618195
test loss item: 0.2778658866882324
test loss item: 0.8439632654190063
test loss item: 0.33512604236602783
test loss item: 0.3112777769565582
test loss item: 0.27551722526550293
test loss item: 0.6073650121688843
test loss item: 0.4280775189399719
test loss item: 0.14714062213897705
test loss item: 0.7730956077575684
test loss item: 0.3184559941291809
test loss item: 0.3534514605998993
test loss item: 0.1801404058933258
test loss item: 0.20899493992328644
test loss item: 0.20193113386631012
test loss item: 1.4834468364715576
test loss item: 0.4679003357887268
test loss item: 0.22557301819324493
test loss item: 0.13904649019241333
test loss item: 0.8921186923980713
test loss item: 0.8111513257026672
test loss item: 1.0293774604797363
test loss item: 0.24633891880512238
test loss item: 0.2491169422864914
test loss item: 0.1548217535018921
test loss item: 0.14810089766979218
test loss item: 0.20158350467681885
Epoch [25/50], Training Loss: 0.5210, Testing Loss: 0.4198
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 26/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5526483058929443
1
train loss item: 1.2435332536697388
2
train loss item: 0.25521421432495117
3
train loss item: 0.5555591583251953
4
train loss item: 0.4341823160648346
5
train loss item: 0.4170529246330261
6
train loss item: 0.26514798402786255
7
train loss item: 0.8342001438140869
8
train loss item: 0.18799267709255219
9
train loss item: 0.2787608802318573
10
train loss item: 0.38062405586242676
11
train loss item: 0.3066751956939697
12
train loss item: 0.1772022694349289
13
train loss item: 0.5419187545776367
14
train loss item: 0.3745351731777191
15
train loss item: 0.6539400219917297
16
train loss item: 0.14579181373119354
17
train loss item: 0.3010725975036621
18
train loss item: 0.3795230984687805
19
train loss item: 0.2714410424232483
20
train loss item: 0.24742378294467926
21
train loss item: 0.1821756213903427
22
train loss item: 0.9465227127075195
23
train loss item: 0.942455530166626
24
train loss item: 0.5281072854995728
25
train loss item: 0.24160492420196533
26
train loss item: 0.24942108988761902
27
train loss item: 0.3658498227596283
28
train loss item: 0.14523117244243622
29
train loss item: 0.7632571458816528
30
train loss item: 2.2120473384857178
31
train loss item: 0.580613374710083
32
train loss item: 0.17358466982841492
33
train loss item: 0.42873093485832214
34
train loss item: 0.22049979865550995
35
train loss item: 2.3762295246124268
36
train loss item: 0.5162389874458313
37
train loss item: 0.32066819071769714
38
train loss item: 0.48384106159210205
39
train loss item: 0.3783046305179596
40
train loss item: 0.1995820552110672
41
train loss item: 0.3487718105316162
42
train loss item: 0.26499882340431213
43
train loss item: 0.220640167593956
44
train loss item: 0.7596985697746277
45
train loss item: 0.18615369498729706
46
train loss item: 0.1809331327676773
47
train loss item: 0.34672796726226807
48
train loss item: 0.26337188482284546
49
train loss item: 0.2066306173801422
50
train loss item: 0.2815214991569519
51
train loss item: 0.8962636590003967
52
train loss item: 0.1602555513381958
53
train loss item: 0.2035965621471405
54
train loss item: 2.2409040927886963
55
train loss item: 0.23973926901817322
56
train loss item: 0.344777911901474
57
train loss item: 0.31330564618110657
58
train loss item: 0.20421113073825836
59
train loss item: 0.19445735216140747
60
train loss item: 0.9074747562408447
61
train loss item: 2.173297882080078
62
train loss item: 0.2466806024312973
63
train loss item: 0.3261769711971283
64
train loss item: 0.20669223368167877
65
train loss item: 0.5409221649169922
66
train loss item: 0.43807655572891235
67
train loss item: 0.23904284834861755
68
train loss item: 0.311705619096756
69
train loss item: 0.34372323751449585
70
train loss item: 0.26936066150665283
71
train loss item: 0.19412806630134583
72
train loss item: 0.2198840081691742
73
train loss item: 0.3199542462825775
74
train loss item: 0.17354577779769897
75
train loss item: 0.16738396883010864
76
train loss item: 0.9097209572792053
77
train loss item: 1.297088384628296
78
train loss item: 0.15109175443649292
79
train loss item: 0.2887094020843506
80
train loss item: 0.18220937252044678
81
train loss item: 0.22281613945960999
82
train loss item: 0.2626829445362091
83
train loss item: 0.6072249412536621
84
train loss item: 0.3657356798648834
85
train loss item: 0.5960074067115784
86
train loss item: 4.212058067321777
87
train loss item: 0.21255187690258026
88
train loss item: 0.3742387294769287
epoch train loss: 0.513219664438387
testing phase
test loss item: 0.20617946982383728
test loss item: 0.18584857881069183
test loss item: 0.6155879497528076
test loss item: 0.2525149881839752
test loss item: 0.31658875942230225
test loss item: 0.17629319429397583
test loss item: 1.349112629890442
test loss item: 0.41673150658607483
test loss item: 0.24594619870185852
test loss item: 0.4396590292453766
test loss item: 0.8634663820266724
test loss item: 0.1999208778142929
test loss item: 0.2211700975894928
test loss item: 0.3391434848308563
test loss item: 0.23086456954479218
test loss item: 0.16204525530338287
test loss item: 0.27910128235816956
test loss item: 0.552259624004364
test loss item: 0.6001166701316833
test loss item: 0.27108198404312134
test loss item: 0.8460085391998291
test loss item: 0.3591834604740143
test loss item: 0.3244786858558655
test loss item: 0.20002183318138123
test loss item: 0.2625105679035187
test loss item: 0.24889090657234192
test loss item: 0.34655410051345825
test loss item: 0.23729227483272552
test loss item: 0.37547045946121216
test loss item: 0.38548195362091064
test loss item: 0.7211048007011414
test loss item: 0.14789624512195587
test loss item: 0.1865372359752655
test loss item: 0.6476274132728577
test loss item: 0.5078838467597961
test loss item: 0.5676577091217041
test loss item: 0.7331039309501648
test loss item: 1.4443624019622803
test loss item: 0.539898157119751
test loss item: 0.27796682715415955
test loss item: 0.29998719692230225
test loss item: 0.21404263377189636
test loss item: 0.41846969723701477
test loss item: 0.22261102497577667
test loss item: 0.6831494569778442
test loss item: 0.3922853469848633
test loss item: 0.33046871423721313
test loss item: 0.26529765129089355
test loss item: 0.5116080045700073
test loss item: 0.6854146718978882
test loss item: 0.35449016094207764
test loss item: 0.18843044340610504
test loss item: 0.2651248276233673
test loss item: 0.21843746304512024
test loss item: 0.35232025384902954
test loss item: 0.9260603785514832
test loss item: 0.5583380460739136
test loss item: 0.2870025634765625
test loss item: 0.25736483931541443
test loss item: 0.2631029188632965
test loss item: 0.5221994519233704
test loss item: 0.22244276106357574
test loss item: 0.21743200719356537
test loss item: 0.27660343050956726
test loss item: 0.8489636182785034
test loss item: 0.3295712471008301
test loss item: 0.30986759066581726
test loss item: 0.27558740973472595
test loss item: 0.6158532500267029
test loss item: 0.4339519143104553
test loss item: 0.15340319275856018
test loss item: 0.757506251335144
test loss item: 0.3235408067703247
test loss item: 0.35040897130966187
test loss item: 0.18059450387954712
test loss item: 0.21412983536720276
test loss item: 0.2014443725347519
test loss item: 1.4745460748672485
test loss item: 0.47132769227027893
test loss item: 0.22208891808986664
test loss item: 0.14097332954406738
test loss item: 0.8776246309280396
test loss item: 0.8026360869407654
test loss item: 1.0084103345870972
test loss item: 0.25027331709861755
test loss item: 0.25343871116638184
test loss item: 0.15637339651584625
test loss item: 0.15164697170257568
test loss item: 0.2013867199420929
Epoch [26/50], Training Loss: 0.5132, Testing Loss: 0.4182
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 27/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5447974801063538
1
train loss item: 1.2301403284072876
2
train loss item: 0.24997729063034058
3
train loss item: 0.5539482831954956
4
train loss item: 0.43080252408981323
5
train loss item: 0.4130309820175171
6
train loss item: 0.25863125920295715
7
train loss item: 0.8276054859161377
8
train loss item: 0.1841687262058258
9
train loss item: 0.276444673538208
10
train loss item: 0.3749110698699951
11
train loss item: 0.30631229281425476
12
train loss item: 0.1730484962463379
13
train loss item: 0.5378317832946777
14
train loss item: 0.3679939806461334
15
train loss item: 0.6381869316101074
16
train loss item: 0.14341378211975098
17
train loss item: 0.2957647144794464
18
train loss item: 0.3753942847251892
19
train loss item: 0.2683643698692322
20
train loss item: 0.23923811316490173
21
train loss item: 0.17687663435935974
22
train loss item: 0.9212358593940735
23
train loss item: 0.9353905320167542
24
train loss item: 0.5226713418960571
25
train loss item: 0.23905763030052185
26
train loss item: 0.24760904908180237
27
train loss item: 0.36092838644981384
28
train loss item: 0.14309728145599365
29
train loss item: 0.7444886565208435
30
train loss item: 2.2002344131469727
31
train loss item: 0.5780193209648132
32
train loss item: 0.17212408781051636
33
train loss item: 0.42923831939697266
34
train loss item: 0.21667887270450592
35
train loss item: 2.3623454570770264
36
train loss item: 0.5104556679725647
37
train loss item: 0.3212110102176666
38
train loss item: 0.4826721251010895
39
train loss item: 0.3717358112335205
40
train loss item: 0.1979120522737503
41
train loss item: 0.3462428152561188
42
train loss item: 0.2647871673107147
43
train loss item: 0.21907870471477509
44
train loss item: 0.7531711459159851
45
train loss item: 0.18518735468387604
46
train loss item: 0.18013496696949005
47
train loss item: 0.33793947100639343
48
train loss item: 0.2655360996723175
49
train loss item: 0.20365454256534576
50
train loss item: 0.2797107696533203
51
train loss item: 0.8836860656738281
52
train loss item: 0.1564842015504837
53
train loss item: 0.19962342083454132
54
train loss item: 2.2282767295837402
55
train loss item: 0.2343323677778244
56
train loss item: 0.3397056460380554
57
train loss item: 0.3115938603878021
58
train loss item: 0.19972220063209534
59
train loss item: 0.1923181712627411
60
train loss item: 0.8901538848876953
61
train loss item: 2.160883903503418
62
train loss item: 0.23877830803394318
63
train loss item: 0.3242829144001007
64
train loss item: 0.20655767619609833
65
train loss item: 0.5305850505828857
66
train loss item: 0.4380415678024292
67
train loss item: 0.23692186176776886
68
train loss item: 0.2984258532524109
69
train loss item: 0.3388271927833557
70
train loss item: 0.2677665054798126
71
train loss item: 0.18675747513771057
72
train loss item: 0.21938543021678925
73
train loss item: 0.3156897723674774
74
train loss item: 0.16825048625469208
75
train loss item: 0.16534407436847687
76
train loss item: 0.9009388089179993
77
train loss item: 1.2791162729263306
78
train loss item: 0.14818814396858215
79
train loss item: 0.2909241318702698
80
train loss item: 0.17771510779857635
81
train loss item: 0.22485972940921783
82
train loss item: 0.25655704736709595
83
train loss item: 0.5940196514129639
84
train loss item: 0.36766862869262695
85
train loss item: 0.5911749601364136
86
train loss item: 4.194450855255127
87
train loss item: 0.21063396334648132
88
train loss item: 0.36892572045326233
epoch train loss: 0.5078314611416185
testing phase
test loss item: 0.20573550462722778
test loss item: 0.18553408980369568
test loss item: 0.5911127328872681
test loss item: 0.24999688565731049
test loss item: 0.3131706416606903
test loss item: 0.17861752212047577
test loss item: 1.3385764360427856
test loss item: 0.4219008684158325
test loss item: 0.2361760139465332
test loss item: 0.42173707485198975
test loss item: 0.8156572580337524
test loss item: 0.19598473608493805
test loss item: 0.2128431797027588
test loss item: 0.33652085065841675
test loss item: 0.2278776913881302
test loss item: 0.16203653812408447
test loss item: 0.27930742502212524
test loss item: 0.532257616519928
test loss item: 0.5966583490371704
test loss item: 0.26843464374542236
test loss item: 0.8170690536499023
test loss item: 0.35910671949386597
test loss item: 0.3190801739692688
test loss item: 0.19998642802238464
test loss item: 0.2593374252319336
test loss item: 0.24797795712947845
test loss item: 0.3416075110435486
test loss item: 0.23595590889453888
test loss item: 0.3681110143661499
test loss item: 0.37337005138397217
test loss item: 0.687305212020874
test loss item: 0.14523930847644806
test loss item: 0.18616032600402832
test loss item: 0.6297614574432373
test loss item: 0.48976850509643555
test loss item: 0.517920970916748
test loss item: 0.7235535979270935
test loss item: 1.3436633348464966
test loss item: 0.5222965478897095
test loss item: 0.27741721272468567
test loss item: 0.2990489602088928
test loss item: 0.21870501339435577
test loss item: 0.40445852279663086
test loss item: 0.21881499886512756
test loss item: 0.6595363020896912
test loss item: 0.39293408393859863
test loss item: 0.3242108225822449
test loss item: 0.2612765431404114
test loss item: 0.4951438009738922
test loss item: 0.6540324091911316
test loss item: 0.3362690210342407
test loss item: 0.18178816139698029
test loss item: 0.2582896947860718
test loss item: 0.21132376790046692
test loss item: 0.3396865427494049
test loss item: 0.8753829002380371
test loss item: 0.5352749228477478
test loss item: 0.2795141637325287
test loss item: 0.2534247636795044
test loss item: 0.2535814940929413
test loss item: 0.5018398761749268
test loss item: 0.22573067247867584
test loss item: 0.2162562608718872
test loss item: 0.2692037522792816
test loss item: 0.8105489611625671
test loss item: 0.3241327702999115
test loss item: 0.3057449162006378
test loss item: 0.274650901556015
test loss item: 0.6034185290336609
test loss item: 0.40451130270957947
test loss item: 0.1544904112815857
test loss item: 0.7588847875595093
test loss item: 0.3218827247619629
test loss item: 0.3510952293872833
test loss item: 0.18088451027870178
test loss item: 0.21249665319919586
test loss item: 0.20275121927261353
test loss item: 1.3692377805709839
test loss item: 0.46941712498664856
test loss item: 0.22352471947669983
test loss item: 0.14353704452514648
test loss item: 0.8370387554168701
test loss item: 0.7797085642814636
test loss item: 0.9206759929656982
test loss item: 0.24806852638721466
test loss item: 0.2546471059322357
test loss item: 0.15788976848125458
test loss item: 0.1513742208480835
test loss item: 0.25228971242904663
Epoch [27/50], Training Loss: 0.5078, Testing Loss: 0.4067
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 28/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5385247468948364
1
train loss item: 1.2154048681259155
2
train loss item: 0.24609258770942688
3
train loss item: 0.539565920829773
4
train loss item: 0.42721131443977356
5
train loss item: 0.40738168358802795
6
train loss item: 0.2557879090309143
7
train loss item: 0.8146952986717224
8
train loss item: 0.17780475318431854
9
train loss item: 0.26929911971092224
10
train loss item: 0.3616258203983307
11
train loss item: 0.29766544699668884
12
train loss item: 0.17007453739643097
13
train loss item: 0.5243496894836426
14
train loss item: 0.362186998128891
15
train loss item: 0.6330118179321289
16
train loss item: 0.13977044820785522
17
train loss item: 0.28841516375541687
18
train loss item: 0.3710486590862274
19
train loss item: 0.269446462392807
20
train loss item: 0.2408219277858734
21
train loss item: 0.1734575778245926
22
train loss item: 0.9100012183189392
23
train loss item: 0.9106851816177368
24
train loss item: 0.5215966701507568
25
train loss item: 0.22988100349903107
26
train loss item: 0.24132601916790009
27
train loss item: 0.35777658224105835
28
train loss item: 0.13941313326358795
29
train loss item: 0.7303934693336487
30
train loss item: 2.169804811477661
31
train loss item: 0.5660530924797058
32
train loss item: 0.1663939505815506
33
train loss item: 0.41626524925231934
34
train loss item: 0.21181482076644897
35
train loss item: 2.343118667602539
36
train loss item: 0.5019974708557129
37
train loss item: 0.31884536147117615
38
train loss item: 0.44963952898979187
39
train loss item: 0.3665752708911896
40
train loss item: 0.20054891705513
41
train loss item: 0.33724886178970337
42
train loss item: 0.26355835795402527
43
train loss item: 0.2140854001045227
44
train loss item: 0.7437224984169006
45
train loss item: 0.1780623495578766
46
train loss item: 0.17896534502506256
47
train loss item: 0.3369446098804474
48
train loss item: 0.26047101616859436
49
train loss item: 0.19765543937683105
50
train loss item: 0.2812316417694092
51
train loss item: 0.8689810037612915
52
train loss item: 0.15114720165729523
53
train loss item: 0.1941882222890854
54
train loss item: 2.208798885345459
55
train loss item: 0.23129627108573914
56
train loss item: 0.3326474130153656
57
train loss item: 0.3089587688446045
58
train loss item: 0.19716528058052063
59
train loss item: 0.18740609288215637
60
train loss item: 0.8782062530517578
61
train loss item: 2.136687994003296
62
train loss item: 0.2371404469013214
63
train loss item: 0.32438790798187256
64
train loss item: 0.2003146857023239
65
train loss item: 0.5284132361412048
66
train loss item: 0.42847204208374023
67
train loss item: 0.23164093494415283
68
train loss item: 0.3013136684894562
69
train loss item: 0.3336625397205353
70
train loss item: 0.26557448506355286
71
train loss item: 0.18355822563171387
72
train loss item: 0.2110661417245865
73
train loss item: 0.31341317296028137
74
train loss item: 0.16423450410366058
75
train loss item: 0.16142284870147705
76
train loss item: 0.8835029602050781
77
train loss item: 1.2704392671585083
78
train loss item: 0.14483225345611572
79
train loss item: 0.2894853353500366
80
train loss item: 0.1747972071170807
81
train loss item: 0.2196180373430252
82
train loss item: 0.2489587515592575
83
train loss item: 0.5863135457038879
84
train loss item: 0.36387959122657776
85
train loss item: 0.5735277533531189
86
train loss item: 4.165543079376221
87
train loss item: 0.20493601262569427
88
train loss item: 0.3608943521976471
epoch train loss: 0.5003881467862076
testing phase
test loss item: 0.20565733313560486
test loss item: 0.18440738320350647
test loss item: 0.5713787078857422
test loss item: 0.24887773394584656
test loss item: 0.3095433712005615
test loss item: 0.17688076198101044
test loss item: 1.3440181016921997
test loss item: 0.43966060876846313
test loss item: 0.2286996692419052
test loss item: 0.4113355278968811
test loss item: 0.779022216796875
test loss item: 0.19517047703266144
test loss item: 0.20827892422676086
test loss item: 0.324786901473999
test loss item: 0.22489669919013977
test loss item: 0.15984244644641876
test loss item: 0.2790376842021942
test loss item: 0.5190004110336304
test loss item: 0.5993279814720154
test loss item: 0.26386183500289917
test loss item: 0.7995386123657227
test loss item: 0.36276841163635254
test loss item: 0.3231789171695709
test loss item: 0.19881178438663483
test loss item: 0.25641289353370667
test loss item: 0.2451840341091156
test loss item: 0.33720865845680237
test loss item: 0.2339548021554947
test loss item: 0.36054426431655884
test loss item: 0.3688020706176758
test loss item: 0.6658603549003601
test loss item: 0.14165356755256653
test loss item: 0.18472197651863098
test loss item: 0.6180294752120972
test loss item: 0.47675591707229614
test loss item: 0.5039797425270081
test loss item: 0.7241083383560181
test loss item: 1.2663657665252686
test loss item: 0.5098128914833069
test loss item: 0.27613943815231323
test loss item: 0.29900863766670227
test loss item: 0.227643683552742
test loss item: 0.40155380964279175
test loss item: 0.21837516129016876
test loss item: 0.6473430395126343
test loss item: 0.3931761682033539
test loss item: 0.32587864995002747
test loss item: 0.2538274824619293
test loss item: 0.4830287992954254
test loss item: 0.6299657821655273
test loss item: 0.3290084898471832
test loss item: 0.1785072237253189
test loss item: 0.2523716688156128
test loss item: 0.21184717118740082
test loss item: 0.331288605928421
test loss item: 0.8350063562393188
test loss item: 0.525157630443573
test loss item: 0.27039045095443726
test loss item: 0.2535644471645355
test loss item: 0.24618321657180786
test loss item: 0.49200043082237244
test loss item: 0.22893740236759186
test loss item: 0.21442562341690063
test loss item: 0.26607462763786316
test loss item: 0.7839096784591675
test loss item: 0.3232526481151581
test loss item: 0.3030408024787903
test loss item: 0.2738935649394989
test loss item: 0.5934074521064758
test loss item: 0.38156434893608093
test loss item: 0.15176145732402802
test loss item: 0.773078203201294
test loss item: 0.3111264109611511
test loss item: 0.35037514567375183
test loss item: 0.17970338463783264
test loss item: 0.21542349457740784
test loss item: 0.2026723474264145
test loss item: 1.2941665649414062
test loss item: 0.45810893177986145
test loss item: 0.2251637578010559
test loss item: 0.14204539358615875
test loss item: 0.8122125864028931
test loss item: 0.7699756622314453
test loss item: 0.862632691860199
test loss item: 0.24425722658634186
test loss item: 0.2534217834472656
test loss item: 0.1553940623998642
test loss item: 0.1484530121088028
test loss item: 0.27472391724586487
Epoch [28/50], Training Loss: 0.5004, Testing Loss: 0.3992
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Epoch 29/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5349361300468445
1
train loss item: 1.1977906227111816
2
train loss item: 0.24419963359832764
3
train loss item: 0.5243671536445618
4
train loss item: 0.42495083808898926
5
train loss item: 0.40097489953041077
6
train loss item: 0.25440970063209534
7
train loss item: 0.8026009202003479
8
train loss item: 0.17347434163093567
9
train loss item: 0.2641605734825134
10
train loss item: 0.35461899638175964
11
train loss item: 0.2903967797756195
12
train loss item: 0.16868039965629578
13
train loss item: 0.5153038501739502
14
train loss item: 0.35683250427246094
15
train loss item: 0.6314768195152283
16
train loss item: 0.1360928863286972
17
train loss item: 0.2850813567638397
18
train loss item: 0.36825475096702576
19
train loss item: 0.27077698707580566
20
train loss item: 0.24422180652618408
21
train loss item: 0.17317023873329163
22
train loss item: 0.913887619972229
23
train loss item: 0.8892526626586914
24
train loss item: 0.5202410817146301
25
train loss item: 0.2251719981431961
26
train loss item: 0.2373383790254593
27
train loss item: 0.3508448302745819
28
train loss item: 0.13562174141407013
29
train loss item: 0.7201632857322693
30
train loss item: 2.1382224559783936
31
train loss item: 0.5574601888656616
32
train loss item: 0.1623694747686386
33
train loss item: 0.4017472267150879
34
train loss item: 0.20763647556304932
35
train loss item: 2.3242499828338623
36
train loss item: 0.49740007519721985
37
train loss item: 0.3180808126926422
38
train loss item: 0.43838635087013245
39
train loss item: 0.36309149861335754
40
train loss item: 0.1976531594991684
41
train loss item: 0.32746705412864685
42
train loss item: 0.2607237696647644
43
train loss item: 0.21061702072620392
44
train loss item: 0.7349920868873596
45
train loss item: 0.17187094688415527
46
train loss item: 0.17272357642650604
47
train loss item: 0.33637744188308716
48
train loss item: 0.25333890318870544
49
train loss item: 0.19374516606330872
50
train loss item: 0.2814652621746063
51
train loss item: 0.854077935218811
52
train loss item: 0.14597299695014954
53
train loss item: 0.18927286565303802
54
train loss item: 2.1889231204986572
55
train loss item: 0.22973184287548065
56
train loss item: 0.32652807235717773
57
train loss item: 0.3017585277557373
58
train loss item: 0.19811972975730896
59
train loss item: 0.18271833658218384
60
train loss item: 0.868750274181366
61
train loss item: 2.114161729812622
62
train loss item: 0.2403743863105774
63
train loss item: 0.32180115580558777
64
train loss item: 0.19460347294807434
65
train loss item: 0.5305445194244385
66
train loss item: 0.4204360842704773
67
train loss item: 0.2275935411453247
68
train loss item: 0.3102075159549713
69
train loss item: 0.33379074931144714
70
train loss item: 0.2624838352203369
71
train loss item: 0.18106859922409058
72
train loss item: 0.2042929232120514
73
train loss item: 0.3143540918827057
74
train loss item: 0.1611543446779251
75
train loss item: 0.15812815725803375
76
train loss item: 0.8681063055992126
77
train loss item: 1.2645434141159058
78
train loss item: 0.14179684221744537
79
train loss item: 0.2847957909107208
80
train loss item: 0.17179802060127258
81
train loss item: 0.21417354047298431
82
train loss item: 0.24523696303367615
83
train loss item: 0.5798699855804443
84
train loss item: 0.35944026708602905
85
train loss item: 0.5598543286323547
86
train loss item: 4.136931419372559
87
train loss item: 0.19801512360572815
88
train loss item: 0.36009493470191956
epoch train loss: 0.4944316681181447
testing phase
test loss item: 0.2070438414812088
test loss item: 0.18709683418273926
test loss item: 0.5909358859062195
test loss item: 0.2538588047027588
test loss item: 0.3107812702655792
test loss item: 0.17451871931552887
test loss item: 1.3341363668441772
test loss item: 0.4335232675075531
test loss item: 0.23276758193969727
test loss item: 0.41903337836265564
test loss item: 0.8241778016090393
test loss item: 0.20500241219997406
test loss item: 0.21133305132389069
test loss item: 0.3202935755252838
test loss item: 0.22639209032058716
test loss item: 0.1618996262550354
test loss item: 0.27489691972732544
test loss item: 0.5241342782974243
test loss item: 0.5911197662353516
test loss item: 0.2587366998195648
test loss item: 0.8059337735176086
test loss item: 0.36567220091819763
test loss item: 0.3516686260700226
test loss item: 0.19700150191783905
test loss item: 0.25651147961616516
test loss item: 0.24202972650527954
test loss item: 0.33299511671066284
test loss item: 0.23479700088500977
test loss item: 0.35970818996429443
test loss item: 0.37705403566360474
test loss item: 0.6893762350082397
test loss item: 0.14630313217639923
test loss item: 0.18348726630210876
test loss item: 0.630761981010437
test loss item: 0.4835374057292938
test loss item: 0.5698115825653076
test loss item: 0.7206343412399292
test loss item: 1.3788740634918213
test loss item: 0.5162555575370789
test loss item: 0.27218255400657654
test loss item: 0.29646623134613037
test loss item: 0.2480604648590088
test loss item: 0.40996673703193665
test loss item: 0.22447635233402252
test loss item: 0.6548292636871338
test loss item: 0.38654574751853943
test loss item: 0.3549738824367523
test loss item: 0.24259041249752045
test loss item: 0.4892771542072296
test loss item: 0.6480798721313477
test loss item: 0.33731305599212646
test loss item: 0.18362189829349518
test loss item: 0.25213590264320374
test loss item: 0.2317470908164978
test loss item: 0.3355856239795685
test loss item: 0.878888726234436
test loss item: 0.5541154742240906
test loss item: 0.30311623215675354
test loss item: 0.2560438811779022
test loss item: 0.24757760763168335
test loss item: 0.503738522529602
test loss item: 0.2255105823278427
test loss item: 0.21348777413368225
test loss item: 0.2649426758289337
test loss item: 0.8256142735481262
test loss item: 0.33509600162506104
test loss item: 0.2998862564563751
test loss item: 0.2709196209907532
test loss item: 0.6119053959846497
test loss item: 0.38706764578819275
test loss item: 0.15026973187923431
test loss item: 0.7628124356269836
test loss item: 0.30831125378608704
test loss item: 0.3444127142429352
test loss item: 0.17688681185245514
test loss item: 0.24728624522686005
test loss item: 0.20062224566936493
test loss item: 1.434167504310608
test loss item: 0.4549502730369568
test loss item: 0.22683456540107727
test loss item: 0.13682305812835693
test loss item: 0.843514621257782
test loss item: 0.7767931222915649
test loss item: 0.9584622979164124
test loss item: 0.239110067486763
test loss item: 0.251342236995697
test loss item: 0.14987747371196747
test loss item: 0.1481788009405136
test loss item: 0.2215694934129715
Epoch [29/50], Training Loss: 0.4944, Testing Loss: 0.4086
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 30/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5313371419906616
1
train loss item: 1.1760380268096924
2
train loss item: 0.24085643887519836
3
train loss item: 0.5152727365493774
4
train loss item: 0.41727253794670105
5
train loss item: 0.395889014005661
6
train loss item: 0.2482752501964569
7
train loss item: 0.7959157228469849
8
train loss item: 0.16976045072078705
9
train loss item: 0.2594968378543854
10
train loss item: 0.35444211959838867
11
train loss item: 0.2886420786380768
12
train loss item: 0.16664212942123413
13
train loss item: 0.5123354196548462
14
train loss item: 0.3529771864414215
15
train loss item: 0.6176249384880066
16
train loss item: 0.13318432867527008
17
train loss item: 0.2831234335899353
18
train loss item: 0.3642755150794983
19
train loss item: 0.2637639045715332
20
train loss item: 0.23387670516967773
21
train loss item: 0.16822874546051025
22
train loss item: 0.888436496257782
23
train loss item: 0.8788237571716309
24
train loss item: 0.5073632597923279
25
train loss item: 0.22425279021263123
26
train loss item: 0.23320908844470978
27
train loss item: 0.34328046441078186
28
train loss item: 0.1326630711555481
29
train loss item: 0.7032025456428528
30
train loss item: 2.1175127029418945
31
train loss item: 0.5498104095458984
32
train loss item: 0.1604582667350769
33
train loss item: 0.40130263566970825
34
train loss item: 0.20615671575069427
35
train loss item: 2.3100385665893555
36
train loss item: 0.4963168799877167
37
train loss item: 0.31773391366004944
38
train loss item: 0.4334309995174408
39
train loss item: 0.35931897163391113
40
train loss item: 0.18797510862350464
41
train loss item: 0.32176217436790466
42
train loss item: 0.2574194073677063
43
train loss item: 0.20805686712265015
44
train loss item: 0.7289171814918518
45
train loss item: 0.17023663222789764
46
train loss item: 0.16635411977767944
47
train loss item: 0.32782718539237976
48
train loss item: 0.24949169158935547
49
train loss item: 0.19065597653388977
50
train loss item: 0.273383229970932
51
train loss item: 0.841037929058075
52
train loss item: 0.14260825514793396
53
train loss item: 0.1842070072889328
54
train loss item: 2.174640417098999
55
train loss item: 0.2249557226896286
56
train loss item: 0.3224536180496216
57
train loss item: 0.2923262417316437
58
train loss item: 0.1942482888698578
59
train loss item: 0.17725898325443268
60
train loss item: 0.8520182371139526
61
train loss item: 2.0999555587768555
62
train loss item: 0.2381620854139328
63
train loss item: 0.3148113787174225
64
train loss item: 0.1929744929075241
65
train loss item: 0.5255312323570251
66
train loss item: 0.4168151617050171
67
train loss item: 0.22355012595653534
68
train loss item: 0.30436939001083374
69
train loss item: 0.3286330997943878
70
train loss item: 0.2570585310459137
71
train loss item: 0.1764896661043167
72
train loss item: 0.20069089531898499
73
train loss item: 0.30742889642715454
74
train loss item: 0.157444566488266
75
train loss item: 0.15591803193092346
76
train loss item: 0.8588371276855469
77
train loss item: 1.2498619556427002
78
train loss item: 0.13875433802604675
79
train loss item: 0.28114646673202515
80
train loss item: 0.16736197471618652
81
train loss item: 0.21264062821865082
82
train loss item: 0.24500569701194763
83
train loss item: 0.5664152503013611
84
train loss item: 0.3612222671508789
85
train loss item: 0.5514605045318604
86
train loss item: 4.116473197937012
87
train loss item: 0.19397777318954468
88
train loss item: 0.3594522476196289
epoch train loss: 0.4881215619572093
testing phase
test loss item: 0.20372505486011505
test loss item: 0.18010543286800385
test loss item: 0.5886794924736023
test loss item: 0.24788393080234528
test loss item: 0.30097344517707825
test loss item: 0.17015206813812256
test loss item: 1.3166340589523315
test loss item: 0.4159442186355591
test loss item: 0.23122170567512512
test loss item: 0.4159086048603058
test loss item: 0.8537410497665405
test loss item: 0.20000262558460236
test loss item: 0.21037213504314423
test loss item: 0.3236949145793915
test loss item: 0.2202461063861847
test loss item: 0.15330269932746887
test loss item: 0.269655704498291
test loss item: 0.5096534490585327
test loss item: 0.5831401348114014
test loss item: 0.25759169459342957
test loss item: 0.7774743437767029
test loss item: 0.35662177205085754
test loss item: 0.3384430706501007
test loss item: 0.1928759515285492
test loss item: 0.2511277198791504
test loss item: 0.23752374947071075
test loss item: 0.32953375577926636
test loss item: 0.22794604301452637
test loss item: 0.35237231850624084
test loss item: 0.37591928243637085
test loss item: 0.7045896053314209
test loss item: 0.1407233327627182
test loss item: 0.17914460599422455
test loss item: 0.6202078461647034
test loss item: 0.4721737802028656
test loss item: 0.5862211585044861
test loss item: 0.7094642519950867
test loss item: 1.449018120765686
test loss item: 0.5067116618156433
test loss item: 0.26819613575935364
test loss item: 0.291479229927063
test loss item: 0.24200715124607086
test loss item: 0.40142354369163513
test loss item: 0.2176031917333603
test loss item: 0.6381100416183472
test loss item: 0.3760753273963928
test loss item: 0.34434136748313904
test loss item: 0.24257981777191162
test loss item: 0.4816396236419678
test loss item: 0.662281334400177
test loss item: 0.3319225609302521
test loss item: 0.18482139706611633
test loss item: 0.24795229732990265
test loss item: 0.22219401597976685
test loss item: 0.32874685525894165
test loss item: 0.8958344459533691
test loss item: 0.5654246211051941
test loss item: 0.29597601294517517
test loss item: 0.2507089078426361
test loss item: 0.2439887523651123
test loss item: 0.4993186593055725
test loss item: 0.2173587679862976
test loss item: 0.21039113402366638
test loss item: 0.2617610692977905
test loss item: 0.8305638432502747
test loss item: 0.32777121663093567
test loss item: 0.29467764496803284
test loss item: 0.26524749398231506
test loss item: 0.60540771484375
test loss item: 0.3981160819530487
test loss item: 0.14334174990653992
test loss item: 0.7425922155380249
test loss item: 0.2978670597076416
test loss item: 0.3389143645763397
test loss item: 0.17203116416931152
test loss item: 0.24176634848117828
test loss item: 0.19608710706233978
test loss item: 1.498437523841858
test loss item: 0.4517289102077484
test loss item: 0.22121664881706238
test loss item: 0.13217520713806152
test loss item: 0.8636136054992676
test loss item: 0.7783300876617432
test loss item: 1.0086097717285156
test loss item: 0.23210835456848145
test loss item: 0.24067112803459167
test loss item: 0.14150413870811462
test loss item: 0.13935323059558868
test loss item: 0.2034820020198822
Epoch [30/50], Training Loss: 0.4881, Testing Loss: 0.4062
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 31/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5260830521583557
1
train loss item: 1.1590538024902344
2
train loss item: 0.23792245984077454
3
train loss item: 0.513058602809906
4
train loss item: 0.4102801978588104
5
train loss item: 0.39101287722587585
6
train loss item: 0.24263398349285126
7
train loss item: 0.7899150252342224
8
train loss item: 0.16668272018432617
9
train loss item: 0.25784751772880554
10
train loss item: 0.35085004568099976
11
train loss item: 0.2878730595111847
12
train loss item: 0.16342580318450928
13
train loss item: 0.5089389085769653
14
train loss item: 0.3487088978290558
15
train loss item: 0.5996867418289185
16
train loss item: 0.13007968664169312
17
train loss item: 0.27957215905189514
18
train loss item: 0.35881224274635315
19
train loss item: 0.2555292546749115
20
train loss item: 0.22160604596138
21
train loss item: 0.16396717727184296
22
train loss item: 0.8669141530990601
23
train loss item: 0.8709114789962769
24
train loss item: 0.49534836411476135
25
train loss item: 0.2211586982011795
26
train loss item: 0.23003356158733368
27
train loss item: 0.33865055441856384
28
train loss item: 0.12942896783351898
29
train loss item: 0.6875120401382446
30
train loss item: 2.1025588512420654
31
train loss item: 0.5419532060623169
32
train loss item: 0.15884491801261902
33
train loss item: 0.4058440923690796
34
train loss item: 0.20377081632614136
35
train loss item: 2.296689987182617
36
train loss item: 0.49266648292541504
37
train loss item: 0.3156012296676636
38
train loss item: 0.42854636907577515
39
train loss item: 0.35502853989601135
40
train loss item: 0.18421386182308197
41
train loss item: 0.31770792603492737
42
train loss item: 0.2535788416862488
43
train loss item: 0.20616090297698975
44
train loss item: 0.7239372134208679
45
train loss item: 0.16933149099349976
46
train loss item: 0.1633027046918869
47
train loss item: 0.3168584108352661
48
train loss item: 0.24545961618423462
49
train loss item: 0.18773296475410461
50
train loss item: 0.26501592993736267
51
train loss item: 0.8294822573661804
52
train loss item: 0.13997867703437805
53
train loss item: 0.18188375234603882
54
train loss item: 2.161613702774048
55
train loss item: 0.22102615237236023
56
train loss item: 0.31880834698677063
57
train loss item: 0.2866978049278259
58
train loss item: 0.18904997408390045
59
train loss item: 0.1742350459098816
60
train loss item: 0.8355430960655212
61
train loss item: 2.0889127254486084
62
train loss item: 0.23197469115257263
63
train loss item: 0.3080366253852844
64
train loss item: 0.19331955909729004
65
train loss item: 0.5163803696632385
66
train loss item: 0.4173058867454529
67
train loss item: 0.22030265629291534
68
train loss item: 0.29234668612480164
69
train loss item: 0.3229287266731262
70
train loss item: 0.2533172070980072
71
train loss item: 0.17396587133407593
72
train loss item: 0.19834746420383453
73
train loss item: 0.3001650869846344
74
train loss item: 0.1530897468328476
75
train loss item: 0.15403972566127777
76
train loss item: 0.8513299226760864
77
train loss item: 1.2322410345077515
78
train loss item: 0.13505294919013977
79
train loss item: 0.27788904309272766
80
train loss item: 0.16327685117721558
81
train loss item: 0.2093432992696762
82
train loss item: 0.2432185709476471
83
train loss item: 0.553162693977356
84
train loss item: 0.35731345415115356
85
train loss item: 0.5465826988220215
86
train loss item: 4.097512722015381
87
train loss item: 0.1910516917705536
88
train loss item: 0.3570729196071625
epoch train loss: 0.48220339467686213
testing phase
test loss item: 0.20029082894325256
test loss item: 0.1708582043647766
test loss item: 0.5629693269729614
test loss item: 0.23939558863639832
test loss item: 0.2892729341983795
test loss item: 0.16680443286895752
test loss item: 1.31625497341156
test loss item: 0.41461196541786194
test loss item: 0.22379769384860992
test loss item: 0.4015286862850189
test loss item: 0.8179351091384888
test loss item: 0.1886512190103531
test loss item: 0.20496411621570587
test loss item: 0.31673291325569153
test loss item: 0.21193858981132507
test loss item: 0.14344488084316254
test loss item: 0.26780039072036743
test loss item: 0.4866708517074585
test loss item: 0.5839288830757141
test loss item: 0.25518107414245605
test loss item: 0.7413927912712097
test loss item: 0.3492959141731262
test loss item: 0.3106346130371094
test loss item: 0.18861086666584015
test loss item: 0.24412210285663605
test loss item: 0.2354060262441635
test loss item: 0.32439982891082764
test loss item: 0.220380038022995
test loss item: 0.3444121181964874
test loss item: 0.36425477266311646
test loss item: 0.6797666549682617
test loss item: 0.13359616696834564
test loss item: 0.17391380667686462
test loss item: 0.5948794484138489
test loss item: 0.4508216977119446
test loss item: 0.5340556502342224
test loss item: 0.701766312122345
test loss item: 1.3780529499053955
test loss item: 0.48874813318252563
test loss item: 0.2668856680393219
test loss item: 0.2894701063632965
test loss item: 0.2301684468984604
test loss item: 0.3819575905799866
test loss item: 0.20849083364009857
test loss item: 0.611754298210144
test loss item: 0.3711463510990143
test loss item: 0.3186940550804138
test loss item: 0.2391878068447113
test loss item: 0.46492841839790344
test loss item: 0.6490147113800049
test loss item: 0.31726738810539246
test loss item: 0.1804460734128952
test loss item: 0.2438989132642746
test loss item: 0.20081818103790283
test loss item: 0.31732216477394104
test loss item: 0.861681342124939
test loss item: 0.5443641543388367
test loss item: 0.26681193709373474
test loss item: 0.24318242073059082
test loss item: 0.23838797211647034
test loss item: 0.4782787561416626
test loss item: 0.21428978443145752
test loss item: 0.2081875056028366
test loss item: 0.25833573937416077
test loss item: 0.7933260202407837
test loss item: 0.31458523869514465
test loss item: 0.2903597950935364
test loss item: 0.2630015015602112
test loss item: 0.5793007612228394
test loss item: 0.3967074751853943
test loss item: 0.1389954388141632
test loss item: 0.7414960265159607
test loss item: 0.28507402539253235
test loss item: 0.3382241725921631
test loss item: 0.1703864187002182
test loss item: 0.2218332439661026
test loss item: 0.19218100607395172
test loss item: 1.3963546752929688
test loss item: 0.44162285327911377
test loss item: 0.21575883030891418
test loss item: 0.1331690400838852
test loss item: 0.832397997379303
test loss item: 0.7676748633384705
test loss item: 0.9369661211967468
test loss item: 0.22845055162906647
test loss item: 0.2387349158525467
test loss item: 0.1398671567440033
test loss item: 0.1307181864976883
test loss item: 0.2527715563774109
Epoch [31/50], Training Loss: 0.4822, Testing Loss: 0.3929
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Epoch 32/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5188525319099426
1
train loss item: 1.1445025205612183
2
train loss item: 0.23628397285938263
3
train loss item: 0.5075205564498901
4
train loss item: 0.4030161201953888
5
train loss item: 0.38422513008117676
6
train loss item: 0.240171879529953
7
train loss item: 0.7785367965698242
8
train loss item: 0.1640630066394806
9
train loss item: 0.2543337941169739
10
train loss item: 0.3390091061592102
11
train loss item: 0.2819221019744873
12
train loss item: 0.16033005714416504
13
train loss item: 0.4986560046672821
14
train loss item: 0.3415275514125824
15
train loss item: 0.5917158126831055
16
train loss item: 0.12673832476139069
17
train loss item: 0.2737438976764679
18
train loss item: 0.35437631607055664
19
train loss item: 0.2539359927177429
20
train loss item: 0.21827024221420288
21
train loss item: 0.16163916885852814
22
train loss item: 0.8525702953338623
23
train loss item: 0.8562082648277283
24
train loss item: 0.4895194470882416
25
train loss item: 0.2138088494539261
26
train loss item: 0.22639141976833344
27
train loss item: 0.3336934447288513
28
train loss item: 0.1259102076292038
29
train loss item: 0.6793858408927917
30
train loss item: 2.0807363986968994
31
train loss item: 0.5338568091392517
32
train loss item: 0.15569134056568146
33
train loss item: 0.3995838761329651
34
train loss item: 0.1992575228214264
35
train loss item: 2.281052350997925
36
train loss item: 0.48754990100860596
37
train loss item: 0.3117687702178955
38
train loss item: 0.4212348759174347
39
train loss item: 0.34943610429763794
40
train loss item: 0.1802912950515747
41
train loss item: 0.3121075928211212
42
train loss item: 0.24997679889202118
43
train loss item: 0.2035401463508606
44
train loss item: 0.7162954211235046
45
train loss item: 0.16608665883541107
46
train loss item: 0.15691561996936798
47
train loss item: 0.3133699595928192
48
train loss item: 0.24165667593479156
49
train loss item: 0.1856398582458496
50
train loss item: 0.2632913291454315
51
train loss item: 0.8215408325195312
52
train loss item: 0.13832393288612366
53
train loss item: 0.18081572651863098
54
train loss item: 2.1458849906921387
55
train loss item: 0.2191213071346283
56
train loss item: 0.31324347853660583
57
train loss item: 0.2836112678050995
58
train loss item: 0.18621541559696198
59
train loss item: 0.17449204623699188
60
train loss item: 0.8258029222488403
61
train loss item: 2.0717663764953613
62
train loss item: 0.22970303893089294
63
train loss item: 0.3051386773586273
64
train loss item: 0.1903318166732788
65
train loss item: 0.510002613067627
66
train loss item: 0.4129464328289032
67
train loss item: 0.2169272005558014
68
train loss item: 0.289451003074646
69
train loss item: 0.31828707456588745
70
train loss item: 0.253140926361084
71
train loss item: 0.173476904630661
72
train loss item: 0.1954190731048584
73
train loss item: 0.29963621497154236
74
train loss item: 0.1493278592824936
75
train loss item: 0.1509018838405609
76
train loss item: 0.8400650024414062
77
train loss item: 1.22124183177948
78
train loss item: 0.1319154053926468
79
train loss item: 0.27378031611442566
80
train loss item: 0.15977901220321655
81
train loss item: 0.202347993850708
82
train loss item: 0.23704451322555542
83
train loss item: 0.5462486147880554
84
train loss item: 0.35237598419189453
85
train loss item: 0.53934645652771
86
train loss item: 4.073721408843994
87
train loss item: 0.18590177595615387
88
train loss item: 0.34747114777565
epoch train loss: 0.4762578251656522
testing phase
test loss item: 0.200469508767128
test loss item: 0.17264202237129211
test loss item: 0.5538306832313538
test loss item: 0.23869559168815613
test loss item: 0.2895730137825012
test loss item: 0.16792629659175873
test loss item: 1.3366551399230957
test loss item: 0.43226608633995056
test loss item: 0.22085723280906677
test loss item: 0.3938288390636444
test loss item: 0.8025442957878113
test loss item: 0.18820388615131378
test loss item: 0.2014026939868927
test loss item: 0.3098489046096802
test loss item: 0.21310757100582123
test loss item: 0.14427347481250763
test loss item: 0.2697327136993408
test loss item: 0.4819960594177246
test loss item: 0.5952604413032532
test loss item: 0.2575223743915558
test loss item: 0.7357568740844727
test loss item: 0.35328149795532227
test loss item: 0.31490376591682434
test loss item: 0.1891489177942276
test loss item: 0.24199937283992767
test loss item: 0.24242323637008667
test loss item: 0.3241044878959656
test loss item: 0.22102928161621094
test loss item: 0.3474772274494171
test loss item: 0.3566943407058716
test loss item: 0.6765965223312378
test loss item: 0.13574886322021484
test loss item: 0.1735893189907074
test loss item: 0.5880115628242493
test loss item: 0.4459684193134308
test loss item: 0.5031267404556274
test loss item: 0.7057093381881714
test loss item: 1.345772624015808
test loss item: 0.4856634736061096
test loss item: 0.269523948431015
test loss item: 0.29112300276756287
test loss item: 0.24655374884605408
test loss item: 0.37195685505867004
test loss item: 0.20926204323768616
test loss item: 0.6055254936218262
test loss item: 0.3747110068798065
test loss item: 0.3225628137588501
test loss item: 0.23986169695854187
test loss item: 0.4610888361930847
test loss item: 0.6447361707687378
test loss item: 0.3121282160282135
test loss item: 0.17560532689094543
test loss item: 0.24708448350429535
test loss item: 0.19753965735435486
test loss item: 0.3176305592060089
test loss item: 0.8478329181671143
test loss item: 0.5324355959892273
test loss item: 0.2533741891384125
test loss item: 0.24121549725532532
test loss item: 0.24000725150108337
test loss item: 0.46647781133651733
test loss item: 0.2187090963125229
test loss item: 0.2109699696302414
test loss item: 0.2566725015640259
test loss item: 0.7896525859832764
test loss item: 0.3123960494995117
test loss item: 0.2910882234573364
test loss item: 0.2655809819698334
test loss item: 0.5724406242370605
test loss item: 0.38682451844215393
test loss item: 0.14212925732135773
test loss item: 0.7572669386863708
test loss item: 0.28756722807884216
test loss item: 0.3435916006565094
test loss item: 0.1730443686246872
test loss item: 0.23100081086158752
test loss item: 0.19386114180088043
test loss item: 1.377063274383545
test loss item: 0.4397399425506592
test loss item: 0.2166723906993866
test loss item: 0.1387198567390442
test loss item: 0.8283116221427917
test loss item: 0.7639460563659668
test loss item: 0.9162506461143494
test loss item: 0.23278948664665222
test loss item: 0.2534703314304352
test loss item: 0.145314559340477
test loss item: 0.12907589972019196
test loss item: 0.32991498708724976
Epoch [32/50], Training Loss: 0.4763, Testing Loss: 0.3925
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 33/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5128562450408936
1
train loss item: 1.1319243907928467
2
train loss item: 0.2341281920671463
3
train loss item: 0.49866676330566406
4
train loss item: 0.39687836170196533
5
train loss item: 0.3779330849647522
6
train loss item: 0.23757509887218475
7
train loss item: 0.7662494778633118
8
train loss item: 0.16082154214382172
9
train loss item: 0.2517063617706299
10
train loss item: 0.3299875855445862
11
train loss item: 0.27597108483314514
12
train loss item: 0.15855887532234192
13
train loss item: 0.4881228506565094
14
train loss item: 0.33563634753227234
15
train loss item: 0.5861336588859558
16
train loss item: 0.1227039024233818
17
train loss item: 0.2685817778110504
18
train loss item: 0.3506523668766022
19
train loss item: 0.2555263638496399
20
train loss item: 0.2197357416152954
21
train loss item: 0.1575496643781662
22
train loss item: 0.8392946720123291
23
train loss item: 0.8409852981567383
24
train loss item: 0.4862925410270691
25
train loss item: 0.20865540206432343
26
train loss item: 0.22193342447280884
27
train loss item: 0.3286290168762207
28
train loss item: 0.12186939269304276
29
train loss item: 0.6686302423477173
30
train loss item: 2.0599000453948975
31
train loss item: 0.5259811282157898
32
train loss item: 0.15134550631046295
33
train loss item: 0.38829103112220764
34
train loss item: 0.19517427682876587
35
train loss item: 2.265756607055664
36
train loss item: 0.4806276559829712
37
train loss item: 0.3086785078048706
38
train loss item: 0.4128119945526123
39
train loss item: 0.34321659803390503
40
train loss item: 0.181227445602417
41
train loss item: 0.3056254982948303
42
train loss item: 0.24997778236865997
43
train loss item: 0.1994536966085434
44
train loss item: 0.7072362303733826
45
train loss item: 0.16200289130210876
46
train loss item: 0.1532774567604065
47
train loss item: 0.3102996349334717
48
train loss item: 0.24051128327846527
49
train loss item: 0.18257105350494385
50
train loss item: 0.2643066346645355
51
train loss item: 0.8096592426300049
52
train loss item: 0.13433240354061127
53
train loss item: 0.17809443175792694
54
train loss item: 2.1309385299682617
55
train loss item: 0.21857191622257233
56
train loss item: 0.30792251229286194
57
train loss item: 0.2828015089035034
58
train loss item: 0.1837640404701233
59
train loss item: 0.170963853597641
60
train loss item: 0.8164368867874146
61
train loss item: 2.0537526607513428
62
train loss item: 0.22768904268741608
63
train loss item: 0.3052406311035156
64
train loss item: 0.18527649343013763
65
train loss item: 0.5031492114067078
66
train loss item: 0.4034985303878784
67
train loss item: 0.2149832546710968
68
train loss item: 0.28869566321372986
69
train loss item: 0.3167220950126648
70
train loss item: 0.25216951966285706
71
train loss item: 0.16955149173736572
72
train loss item: 0.19124220311641693
73
train loss item: 0.3002461791038513
74
train loss item: 0.14516068994998932
75
train loss item: 0.14793966710567474
76
train loss item: 0.8283860683441162
77
train loss item: 1.2117586135864258
78
train loss item: 0.12788450717926025
79
train loss item: 0.271902859210968
80
train loss item: 0.15609946846961975
81
train loss item: 0.19878773391246796
82
train loss item: 0.23017196357250214
83
train loss item: 0.540471076965332
84
train loss item: 0.35195085406303406
85
train loss item: 0.530377984046936
86
train loss item: 4.051084518432617
87
train loss item: 0.18246138095855713
88
train loss item: 0.341943621635437
epoch train loss: 0.4706128763683726
testing phase
test loss item: 0.19839955866336823
test loss item: 0.1746428906917572
test loss item: 0.5482556819915771
test loss item: 0.24261613190174103
test loss item: 0.29124075174331665
test loss item: 0.16635827720165253
test loss item: 1.3320653438568115
test loss item: 0.446428507566452
test loss item: 0.2206554263830185
test loss item: 0.393615186214447
test loss item: 0.7950920462608337
test loss item: 0.19562402367591858
test loss item: 0.2022305727005005
test loss item: 0.30570459365844727
test loss item: 0.2137976884841919
test loss item: 0.1474260687828064
test loss item: 0.2673110067844391
test loss item: 0.48434576392173767
test loss item: 0.5853413939476013
test loss item: 0.2546274960041046
test loss item: 0.7418950200080872
test loss item: 0.35610491037368774
test loss item: 0.32448214292526245
test loss item: 0.18970660865306854
test loss item: 0.24077104032039642
test loss item: 0.24001535773277283
test loss item: 0.3211670517921448
test loss item: 0.22274541854858398
test loss item: 0.34804868698120117
test loss item: 0.3567202389240265
test loss item: 0.6715419292449951
test loss item: 0.1389303207397461
test loss item: 0.17414502799510956
test loss item: 0.5886245369911194
test loss item: 0.44618508219718933
test loss item: 0.4960467517375946
test loss item: 0.7078683972358704
test loss item: 1.3261433839797974
test loss item: 0.48716843128204346
test loss item: 0.268094003200531
test loss item: 0.2897458076477051
test loss item: 0.23742744326591492
test loss item: 0.3728307783603668
test loss item: 0.2146790474653244
test loss item: 0.6091254353523254
test loss item: 0.37203243374824524
test loss item: 0.3317216634750366
test loss item: 0.23533719778060913
test loss item: 0.46031075716018677
test loss item: 0.6321293711662292
test loss item: 0.3140978217124939
test loss item: 0.17624981701374054
test loss item: 0.2473260909318924
test loss item: 0.21098899841308594
test loss item: 0.3188785910606384
test loss item: 0.834611177444458
test loss item: 0.5272827744483948
test loss item: 0.2541728615760803
test loss item: 0.24183398485183716
test loss item: 0.2411828637123108
test loss item: 0.46757760643959045
test loss item: 0.21926021575927734
test loss item: 0.20835930109024048
test loss item: 0.25582069158554077
test loss item: 0.7883990406990051
test loss item: 0.3208201825618744
test loss item: 0.289184033870697
test loss item: 0.26367512345314026
test loss item: 0.5700454115867615
test loss item: 0.37411561608314514
test loss item: 0.1413530558347702
test loss item: 0.7616453766822815
test loss item: 0.28927335143089294
test loss item: 0.3402799367904663
test loss item: 0.1688648909330368
test loss item: 0.2363981008529663
test loss item: 0.19395548105239868
test loss item: 1.3881686925888062
test loss item: 0.4371162950992584
test loss item: 0.21436327695846558
test loss item: 0.13167276978492737
test loss item: 0.816641628742218
test loss item: 0.7574387788772583
test loss item: 0.9180116653442383
test loss item: 0.23297034204006195
test loss item: 0.2479698807001114
test loss item: 0.1379881203174591
test loss item: 0.13048367202281952
test loss item: 0.24438083171844482
Epoch [33/50], Training Loss: 0.4706, Testing Loss: 0.3908
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 34/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5075811147689819
1
train loss item: 1.1166151762008667
2
train loss item: 0.22875288128852844
3
train loss item: 0.4879100024700165
4
train loss item: 0.39248907566070557
5
train loss item: 0.3725658655166626
6
train loss item: 0.23302392661571503
7
train loss item: 0.7571078538894653
8
train loss item: 0.15712696313858032
9
train loss item: 0.24633847177028656
10
train loss item: 0.32724615931510925
11
train loss item: 0.2739042639732361
12
train loss item: 0.15806889533996582
13
train loss item: 0.48047393560409546
14
train loss item: 0.3308791220188141
15
train loss item: 0.5762272477149963
16
train loss item: 0.12082131952047348
17
train loss item: 0.26587462425231934
18
train loss item: 0.3460557758808136
19
train loss item: 0.24976390600204468
20
train loss item: 0.2169056087732315
21
train loss item: 0.15363672375679016
22
train loss item: 0.8245173096656799
23
train loss item: 0.8282902836799622
24
train loss item: 0.47864481806755066
25
train loss item: 0.2059001922607422
26
train loss item: 0.21755070984363556
27
train loss item: 0.3234609365463257
28
train loss item: 0.12003996968269348
29
train loss item: 0.6548643112182617
30
train loss item: 2.0381197929382324
31
train loss item: 0.5197485685348511
32
train loss item: 0.14779728651046753
33
train loss item: 0.3817179799079895
34
train loss item: 0.19178569316864014
35
train loss item: 2.2533230781555176
36
train loss item: 0.47622254490852356
37
train loss item: 0.3072063624858856
38
train loss item: 0.4053361117839813
39
train loss item: 0.3378872871398926
40
train loss item: 0.1784837245941162
41
train loss item: 0.3007442355155945
42
train loss item: 0.24832883477210999
43
train loss item: 0.19562631845474243
44
train loss item: 0.7005308866500854
45
train loss item: 0.15841467678546906
46
train loss item: 0.1500517874956131
47
train loss item: 0.30160820484161377
48
train loss item: 0.23802681267261505
49
train loss item: 0.1784547120332718
50
train loss item: 0.2592593729496002
51
train loss item: 0.7964708209037781
52
train loss item: 0.1298466920852661
53
train loss item: 0.173132061958313
54
train loss item: 2.118187427520752
55
train loss item: 0.2133895754814148
56
train loss item: 0.30324700474739075
57
train loss item: 0.2772114872932434
58
train loss item: 0.18102139234542847
59
train loss item: 0.16599495708942413
60
train loss item: 0.7985512018203735
61
train loss item: 2.038267135620117
62
train loss item: 0.22445686161518097
63
train loss item: 0.3025033473968506
64
train loss item: 0.18188108503818512
65
train loss item: 0.497345894575119
66
train loss item: 0.3998548090457916
67
train loss item: 0.21266552805900574
68
train loss item: 0.28164535760879517
69
train loss item: 0.31238263845443726
70
train loss item: 0.24697937071323395
71
train loss item: 0.1640232801437378
72
train loss item: 0.18733185529708862
73
train loss item: 0.29434579610824585
74
train loss item: 0.14220578968524933
75
train loss item: 0.14643700420856476
76
train loss item: 0.8181494474411011
77
train loss item: 1.1983476877212524
78
train loss item: 0.1260974258184433
79
train loss item: 0.26965442299842834
80
train loss item: 0.15355128049850464
81
train loss item: 0.19726429879665375
82
train loss item: 0.2270176112651825
83
train loss item: 0.530204176902771
84
train loss item: 0.3534928560256958
85
train loss item: 0.5200077891349792
86
train loss item: 4.0318779945373535
87
train loss item: 0.18051454424858093
88
train loss item: 0.3384014666080475
epoch train loss: 0.46466596734322857
testing phase
test loss item: 0.19623427093029022
test loss item: 0.17441558837890625
test loss item: 0.5317938327789307
test loss item: 0.24079829454421997
test loss item: 0.29266026616096497
test loss item: 0.17945030331611633
test loss item: 1.3138633966445923
test loss item: 0.4413318932056427
test loss item: 0.22014746069908142
test loss item: 0.39276784658432007
test loss item: 0.7629784941673279
test loss item: 0.1924418956041336
test loss item: 0.2030012458562851
test loss item: 0.30149713158607483
test loss item: 0.21522897481918335
test loss item: 0.14454156160354614
test loss item: 0.26209336519241333
test loss item: 0.477460116147995
test loss item: 0.5729689002037048
test loss item: 0.25010716915130615
test loss item: 0.7324942350387573
test loss item: 0.348716139793396
test loss item: 0.3026723265647888
test loss item: 0.19118089973926544
test loss item: 0.2375757396221161
test loss item: 0.22849920392036438
test loss item: 0.3164747953414917
test loss item: 0.22535769641399384
test loss item: 0.34312671422958374
test loss item: 0.3563823997974396
test loss item: 0.6458637118339539
test loss item: 0.1350402981042862
test loss item: 0.17711400985717773
test loss item: 0.5789151787757874
test loss item: 0.4364926218986511
test loss item: 0.48335590958595276
test loss item: 0.7000566720962524
test loss item: 1.2576050758361816
test loss item: 0.4765591323375702
test loss item: 0.27102726697921753
test loss item: 0.2858358919620514
test loss item: 0.21008649468421936
test loss item: 0.3766063153743744
test loss item: 0.2100222408771515
test loss item: 0.5986589193344116
test loss item: 0.3642939627170563
test loss item: 0.31064629554748535
test loss item: 0.2309533953666687
test loss item: 0.4527665674686432
test loss item: 0.6066553592681885
test loss item: 0.30878746509552
test loss item: 0.17912203073501587
test loss item: 0.2395259439945221
test loss item: 0.2040245085954666
test loss item: 0.31065505743026733
test loss item: 0.800150454044342
test loss item: 0.5181326866149902
test loss item: 0.2604200839996338
test loss item: 0.2395746111869812
test loss item: 0.234741672873497
test loss item: 0.46984466910362244
test loss item: 0.21346431970596313
test loss item: 0.20392070710659027
test loss item: 0.254475861787796
test loss item: 0.7594239711761475
test loss item: 0.3158244490623474
test loss item: 0.28286322951316833
test loss item: 0.2593165934085846
test loss item: 0.5551573038101196
test loss item: 0.3710751235485077
test loss item: 0.13813361525535583
test loss item: 0.7537637948989868
test loss item: 0.29089978337287903
test loss item: 0.336703896522522
test loss item: 0.16411353647708893
test loss item: 0.206922709941864
test loss item: 0.19377349317073822
test loss item: 1.3092727661132812
test loss item: 0.431958943605423
test loss item: 0.21909397840499878
test loss item: 0.12778355181217194
test loss item: 0.7866676449775696
test loss item: 0.7449324727058411
test loss item: 0.8677387237548828
test loss item: 0.22534148395061493
test loss item: 0.22538989782333374
test loss item: 0.13039082288742065
test loss item: 0.12890855967998505
test loss item: 0.17978455126285553
Epoch [34/50], Training Loss: 0.4647, Testing Loss: 0.3809
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 35/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5001568794250488
1
train loss item: 1.1006293296813965
2
train loss item: 0.22488164901733398
3
train loss item: 0.4811978042125702
4
train loss item: 0.3886573314666748
5
train loss item: 0.36720216274261475
6
train loss item: 0.2289976328611374
7
train loss item: 0.7487974166870117
8
train loss item: 0.15394528210163116
9
train loss item: 0.2431681752204895
10
train loss item: 0.3274129331111908
11
train loss item: 0.2706473767757416
12
train loss item: 0.15515601634979248
13
train loss item: 0.47841498255729675
14
train loss item: 0.32462188601493835
15
train loss item: 0.5617005825042725
16
train loss item: 0.11932000517845154
17
train loss item: 0.2647404670715332
18
train loss item: 0.3399517834186554
19
train loss item: 0.24273939430713654
20
train loss item: 0.2097834199666977
21
train loss item: 0.15069511532783508
22
train loss item: 0.8088155388832092
23
train loss item: 0.8178110122680664
24
train loss item: 0.47049739956855774
25
train loss item: 0.20649637281894684
26
train loss item: 0.21424540877342224
27
train loss item: 0.31746718287467957
28
train loss item: 0.11858505010604858
29
train loss item: 0.640400767326355
30
train loss item: 2.018467426300049
31
train loss item: 0.5185890793800354
32
train loss item: 0.1469743251800537
33
train loss item: 0.38013923168182373
34
train loss item: 0.190788134932518
35
train loss item: 2.240586519241333
36
train loss item: 0.4720395505428314
37
train loss item: 0.30595073103904724
38
train loss item: 0.404916375875473
39
train loss item: 0.33421462774276733
40
train loss item: 0.17552055418491364
41
train loss item: 0.29479891061782837
42
train loss item: 0.24494852125644684
43
train loss item: 0.1926380842924118
44
train loss item: 0.6951777338981628
45
train loss item: 0.15608008205890656
46
train loss item: 0.14897391200065613
47
train loss item: 0.293406218290329
48
train loss item: 0.23402857780456543
49
train loss item: 0.17497806251049042
50
train loss item: 0.25247448682785034
51
train loss item: 0.7846766710281372
52
train loss item: 0.12624335289001465
53
train loss item: 0.16892801225185394
54
train loss item: 2.1046817302703857
55
train loss item: 0.20842020213603973
56
train loss item: 0.2992697060108185
57
train loss item: 0.26956743001937866
58
train loss item: 0.1778475046157837
59
train loss item: 0.16401687264442444
60
train loss item: 0.7825190424919128
61
train loss item: 2.0242395401000977
62
train loss item: 0.21804846823215485
63
train loss item: 0.29813534021377563
64
train loss item: 0.18048147857189178
65
train loss item: 0.4917982816696167
66
train loss item: 0.39736276865005493
67
train loss item: 0.20834451913833618
68
train loss item: 0.2715734839439392
69
train loss item: 0.30665507912635803
70
train loss item: 0.24688857793807983
71
train loss item: 0.1605949103832245
72
train loss item: 0.18420949578285217
73
train loss item: 0.2856072187423706
74
train loss item: 0.13958634436130524
75
train loss item: 0.14436925947666168
76
train loss item: 0.8083559274673462
77
train loss item: 1.186598539352417
78
train loss item: 0.12453265488147736
79
train loss item: 0.2652357220649719
80
train loss item: 0.15139947831630707
81
train loss item: 0.19714638590812683
82
train loss item: 0.22564134001731873
83
train loss item: 0.5207850337028503
84
train loss item: 0.3500470221042633
85
train loss item: 0.5142340660095215
86
train loss item: 4.013814449310303
87
train loss item: 0.17920136451721191
88
train loss item: 0.3406775891780853
epoch train loss: 0.4592647457055831
testing phase
test loss item: 0.19726917147636414
test loss item: 0.17341022193431854
test loss item: 0.5323925614356995
test loss item: 0.2373913675546646
test loss item: 0.2924579679965973
test loss item: 0.17479367554187775
test loss item: 1.2973318099975586
test loss item: 0.42976275086402893
test loss item: 0.22076815366744995
test loss item: 0.3908315896987915
test loss item: 0.7586882710456848
test loss item: 0.1881149709224701
test loss item: 0.1997879296541214
test loss item: 0.2978435158729553
test loss item: 0.21689794957637787
test loss item: 0.14360769093036652
test loss item: 0.2587995231151581
test loss item: 0.4778667688369751
test loss item: 0.5654703974723816
test loss item: 0.24859674274921417
test loss item: 0.735640823841095
test loss item: 0.34305310249328613
test loss item: 0.2931150496006012
test loss item: 0.19225966930389404
test loss item: 0.23654910922050476
test loss item: 0.22776024043560028
test loss item: 0.31588417291641235
test loss item: 0.22339390218257904
test loss item: 0.3419964909553528
test loss item: 0.3526409864425659
test loss item: 0.6399526596069336
test loss item: 0.13315191864967346
test loss item: 0.1777218133211136
test loss item: 0.5796144604682922
test loss item: 0.43603983521461487
test loss item: 0.4787255525588989
test loss item: 0.6894915699958801
test loss item: 1.2552615404129028
test loss item: 0.47133395075798035
test loss item: 0.2682052254676819
test loss item: 0.28334841132164
test loss item: 0.1975916475057602
test loss item: 0.37893569469451904
test loss item: 0.20459844172000885
test loss item: 0.5927211046218872
test loss item: 0.36105719208717346
test loss item: 0.2989812195301056
test loss item: 0.23144161701202393
test loss item: 0.45129016041755676
test loss item: 0.6031615734100342
test loss item: 0.3029397130012512
test loss item: 0.17975476384162903
test loss item: 0.237644761800766
test loss item: 0.1946195363998413
test loss item: 0.3109467327594757
test loss item: 0.8015275001525879
test loss item: 0.5168493986129761
test loss item: 0.26048994064331055
test loss item: 0.2384936809539795
test loss item: 0.23122510313987732
test loss item: 0.4694421887397766
test loss item: 0.21067088842391968
test loss item: 0.20497214794158936
test loss item: 0.251078724861145
test loss item: 0.7605515122413635
test loss item: 0.3090043067932129
test loss item: 0.28178754448890686
test loss item: 0.2576097249984741
test loss item: 0.5531356930732727
test loss item: 0.37264931201934814
test loss item: 0.13943082094192505
test loss item: 0.7437857985496521
test loss item: 0.2972026765346527
test loss item: 0.337999552488327
test loss item: 0.16507141292095184
test loss item: 0.19038057327270508
test loss item: 0.19530028104782104
test loss item: 1.3034512996673584
test loss item: 0.4299773573875427
test loss item: 0.21606096625328064
test loss item: 0.13293176889419556
test loss item: 0.7821709513664246
test loss item: 0.7364736199378967
test loss item: 0.8650311231613159
test loss item: 0.22564537823200226
test loss item: 0.2216140329837799
test loss item: 0.13467562198638916
test loss item: 0.12899087369441986
test loss item: 0.20415008068084717
Epoch [35/50], Training Loss: 0.4593, Testing Loss: 0.3786
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 36/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.492542028427124
1
train loss item: 1.08714759349823
2
train loss item: 0.223494291305542
3
train loss item: 0.474604994058609
4
train loss item: 0.3825683295726776
5
train loss item: 0.36255261301994324
6
train loss item: 0.22642548382282257
7
train loss item: 0.7399733066558838
8
train loss item: 0.15106254816055298
9
train loss item: 0.239913210272789
10
train loss item: 0.3195975720882416
11
train loss item: 0.26556822657585144
12
train loss item: 0.15258164703845978
13
train loss item: 0.4690186679363251
14
train loss item: 0.3186720609664917
15
train loss item: 0.5525265336036682
16
train loss item: 0.11647585034370422
17
train loss item: 0.2599825859069824
18
train loss item: 0.33364197611808777
19
train loss item: 0.24008628726005554
20
train loss item: 0.20686160027980804
21
train loss item: 0.15002655982971191
22
train loss item: 0.7962993383407593
23
train loss item: 0.8036434054374695
24
train loss item: 0.4671232998371124
25
train loss item: 0.20068950951099396
26
train loss item: 0.2095523476600647
27
train loss item: 0.3125777244567871
28
train loss item: 0.11550874263048172
29
train loss item: 0.6299864649772644
30
train loss item: 1.9984633922576904
31
train loss item: 0.5115145444869995
32
train loss item: 0.14460845291614532
33
train loss item: 0.37185242772102356
34
train loss item: 0.18565593659877777
35
train loss item: 2.2274184226989746
36
train loss item: 0.4678630530834198
37
train loss item: 0.30303680896759033
38
train loss item: 0.39838358759880066
39
train loss item: 0.3315223455429077
40
train loss item: 0.1706811636686325
41
train loss item: 0.2896001636981964
42
train loss item: 0.244760200381279
43
train loss item: 0.1901700645685196
44
train loss item: 0.689258873462677
45
train loss item: 0.15302307903766632
46
train loss item: 0.1460258662700653
47
train loss item: 0.28964975476264954
48
train loss item: 0.23114876449108124
49
train loss item: 0.1735512614250183
50
train loss item: 0.2498418390750885
51
train loss item: 0.7765340209007263
52
train loss item: 0.12301983684301376
53
train loss item: 0.16742950677871704
54
train loss item: 2.091944694519043
55
train loss item: 0.20761612057685852
56
train loss item: 0.29473602771759033
57
train loss item: 0.2669505178928375
58
train loss item: 0.17647482454776764
59
train loss item: 0.1637476533651352
60
train loss item: 0.770443856716156
61
train loss item: 2.0087969303131104
62
train loss item: 0.21546778082847595
63
train loss item: 0.2970692217350006
64
train loss item: 0.17666083574295044
65
train loss item: 0.48392319679260254
66
train loss item: 0.3928380012512207
67
train loss item: 0.20466214418411255
68
train loss item: 0.26921746134757996
69
train loss item: 0.30182814598083496
70
train loss item: 0.23933537304401398
71
train loss item: 0.159785658121109
72
train loss item: 0.18121325969696045
73
train loss item: 0.2865464985370636
74
train loss item: 0.13657446205615997
75
train loss item: 0.1412099450826645
76
train loss item: 0.797419548034668
77
train loss item: 1.1796294450759888
78
train loss item: 0.12123298645019531
79
train loss item: 0.2618025541305542
80
train loss item: 0.14782685041427612
81
train loss item: 0.193571999669075
82
train loss item: 0.22030535340309143
83
train loss item: 0.5172612071037292
84
train loss item: 0.3498755991458893
85
train loss item: 0.5100485682487488
86
train loss item: 3.9947075843811035
87
train loss item: 0.17459841072559357
88
train loss item: 0.3309786319732666
epoch train loss: 0.4539552754565571
testing phase
test loss item: 0.1982845515012741
test loss item: 0.17237606644630432
test loss item: 0.5585246086120605
test loss item: 0.23695166409015656
test loss item: 0.294723242521286
test loss item: 0.1713411808013916
test loss item: 1.298535943031311
test loss item: 0.4315907955169678
test loss item: 0.22195716202259064
test loss item: 0.3940505087375641
test loss item: 0.8071503043174744
test loss item: 0.18864867091178894
test loss item: 0.19525092840194702
test loss item: 0.29475072026252747
test loss item: 0.21734458208084106
test loss item: 0.1427459865808487
test loss item: 0.2569250464439392
test loss item: 0.49083828926086426
test loss item: 0.5797417163848877
test loss item: 0.2441888451576233
test loss item: 0.7585761547088623
test loss item: 0.34432828426361084
test loss item: 0.3143014907836914
test loss item: 0.18857772648334503
test loss item: 0.23785297572612762
test loss item: 0.22963449358940125
test loss item: 0.31330424547195435
test loss item: 0.222136452794075
test loss item: 0.34301644563674927
test loss item: 0.35347485542297363
test loss item: 0.6763917803764343
test loss item: 0.13233692944049835
test loss item: 0.1738816797733307
test loss item: 0.5952466130256653
test loss item: 0.4503396451473236
test loss item: 0.502285361289978
test loss item: 0.6880555152893066
test loss item: 1.3688431978225708
test loss item: 0.481302410364151
test loss item: 0.26373377442359924
test loss item: 0.281745046377182
test loss item: 0.22883974015712738
test loss item: 0.37902969121932983
test loss item: 0.20426523685455322
test loss item: 0.6031425595283508
test loss item: 0.35888880491256714
test loss item: 0.3164251744747162
test loss item: 0.22670818865299225
test loss item: 0.4610291123390198
test loss item: 0.6294023394584656
test loss item: 0.30481982231140137
test loss item: 0.1773408204317093
test loss item: 0.23984724283218384
test loss item: 0.19700969755649567
test loss item: 0.3174254894256592
test loss item: 0.8577541708946228
test loss item: 0.5312214493751526
test loss item: 0.25883749127388
test loss item: 0.23968394100666046
test loss item: 0.23099815845489502
test loss item: 0.475087970495224
test loss item: 0.21201583743095398
test loss item: 0.20396573841571808
test loss item: 0.2466866672039032
test loss item: 0.8110708594322205
test loss item: 0.31055495142936707
test loss item: 0.2814406454563141
test loss item: 0.2579348087310791
test loss item: 0.5707125663757324
test loss item: 0.3700995147228241
test loss item: 0.1400376409292221
test loss item: 0.7388026118278503
test loss item: 0.2961502969264984
test loss item: 0.3334933817386627
test loss item: 0.17048043012619019
test loss item: 0.21621747314929962
test loss item: 0.19363999366760254
test loss item: 1.442557692527771
test loss item: 0.43015941977500916
test loss item: 0.21690458059310913
test loss item: 0.1436942219734192
test loss item: 0.825989305973053
test loss item: 0.7423654794692993
test loss item: 0.955825924873352
test loss item: 0.22543813288211823
test loss item: 0.24296464025974274
test loss item: 0.1483956128358841
test loss item: 0.1262637823820114
test loss item: 0.3362140953540802
Epoch [36/50], Training Loss: 0.4540, Testing Loss: 0.3904
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 37/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4859509766101837
1
train loss item: 1.0747780799865723
2
train loss item: 0.2207472324371338
3
train loss item: 0.46671542525291443
4
train loss item: 0.3770987391471863
5
train loss item: 0.3567569851875305
6
train loss item: 0.2235632985830307
7
train loss item: 0.7323654294013977
8
train loss item: 0.14880086481571198
9
train loss item: 0.23569227755069733
10
train loss item: 0.3112185299396515
11
train loss item: 0.2626451551914215
12
train loss item: 0.15149365365505219
13
train loss item: 0.4579097032546997
14
train loss item: 0.3138106167316437
15
train loss item: 0.5428892374038696
16
train loss item: 0.11397460103034973
17
train loss item: 0.256307452917099
18
train loss item: 0.3276151120662689
19
train loss item: 0.2366153746843338
20
train loss item: 0.20498333871364594
21
train loss item: 0.14682617783546448
22
train loss item: 0.7813012003898621
23
train loss item: 0.7916003465652466
24
train loss item: 0.46265047788619995
25
train loss item: 0.19544389843940735
26
train loss item: 0.20523236691951752
27
train loss item: 0.309118390083313
28
train loss item: 0.11283208429813385
29
train loss item: 0.6170704364776611
30
train loss item: 1.980912685394287
31
train loss item: 0.4975181221961975
32
train loss item: 0.14167273044586182
33
train loss item: 0.36659279465675354
34
train loss item: 0.18282820284366608
35
train loss item: 2.2161786556243896
36
train loss item: 0.4625355005264282
37
train loss item: 0.3015948534011841
38
train loss item: 0.38867825269699097
39
train loss item: 0.32680320739746094
40
train loss item: 0.17136873304843903
41
train loss item: 0.2860068082809448
42
train loss item: 0.24474674463272095
43
train loss item: 0.18739767372608185
44
train loss item: 0.6836808323860168
45
train loss item: 0.14972612261772156
46
train loss item: 0.14085179567337036
47
train loss item: 0.28638720512390137
48
train loss item: 0.22808825969696045
49
train loss item: 0.17031149566173553
50
train loss item: 0.24725916981697083
51
train loss item: 0.7642329931259155
52
train loss item: 0.12020804733037949
53
train loss item: 0.16429074108600616
54
train loss item: 2.0815937519073486
55
train loss item: 0.20632435381412506
56
train loss item: 0.2897928059101105
57
train loss item: 0.26355689764022827
58
train loss item: 0.1738419085741043
59
train loss item: 0.15947511792182922
60
train loss item: 0.7601811289787292
61
train loss item: 1.9965178966522217
62
train loss item: 0.21180503070354462
63
train loss item: 0.2936038076877594
64
train loss item: 0.1739160269498825
65
train loss item: 0.47450223565101624
66
train loss item: 0.38649997115135193
67
train loss item: 0.20247827470302582
68
train loss item: 0.2653333842754364
69
train loss item: 0.3013145923614502
70
train loss item: 0.23653998970985413
71
train loss item: 0.15672455728054047
72
train loss item: 0.17805255949497223
73
train loss item: 0.2853601574897766
74
train loss item: 0.13319657742977142
75
train loss item: 0.13909412920475006
76
train loss item: 0.7882984280586243
77
train loss item: 1.1655837297439575
78
train loss item: 0.11897709220647812
79
train loss item: 0.2592858076095581
80
train loss item: 0.14475445449352264
81
train loss item: 0.18960043787956238
82
train loss item: 0.21343187987804413
83
train loss item: 0.5084632635116577
84
train loss item: 0.3481781780719757
85
train loss item: 0.5010179281234741
86
train loss item: 3.9784903526306152
87
train loss item: 0.171474426984787
88
train loss item: 0.32406073808670044
epoch train loss: 0.4484854040855772
testing phase
test loss item: 0.19145555794239044
test loss item: 0.1616939902305603
test loss item: 0.5356354117393494
test loss item: 0.23047120869159698
test loss item: 0.279893159866333
test loss item: 0.15931552648544312
test loss item: 1.2982368469238281
test loss item: 0.4457390606403351
test loss item: 0.2123824805021286
test loss item: 0.3822047710418701
test loss item: 0.7810697555541992
test loss item: 0.18156737089157104
test loss item: 0.1910475790500641
test loss item: 0.2924702763557434
test loss item: 0.20453579723834991
test loss item: 0.13571299612522125
test loss item: 0.2553565204143524
test loss item: 0.47115927934646606
test loss item: 0.5760476589202881
test loss item: 0.24022309482097626
test loss item: 0.7213467359542847
test loss item: 0.34148406982421875
test loss item: 0.3065594732761383
test loss item: 0.18263019621372223
test loss item: 0.23115526139736176
test loss item: 0.2266523689031601
test loss item: 0.30711597204208374
test loss item: 0.21237212419509888
test loss item: 0.33201470971107483
test loss item: 0.3471418619155884
test loss item: 0.6577966213226318
test loss item: 0.12511739134788513
test loss item: 0.16665545105934143
test loss item: 0.5721917748451233
test loss item: 0.43165528774261475
test loss item: 0.476563423871994
test loss item: 0.6882389783859253
test loss item: 1.3116554021835327
test loss item: 0.46655604243278503
test loss item: 0.2578834593296051
test loss item: 0.279598593711853
test loss item: 0.22316057980060577
test loss item: 0.36133965849876404
test loss item: 0.199278324842453
test loss item: 0.5797958374023438
test loss item: 0.35520631074905396
test loss item: 0.3136759400367737
test loss item: 0.22246350347995758
test loss item: 0.44607335329055786
test loss item: 0.6168009638786316
test loss item: 0.29391926527023315
test loss item: 0.17172834277153015
test loss item: 0.23577266931533813
test loss item: 0.18547993898391724
test loss item: 0.30657723546028137
test loss item: 0.8225662708282471
test loss item: 0.5180379152297974
test loss item: 0.24472540616989136
test loss item: 0.234177365899086
test loss item: 0.22603356838226318
test loss item: 0.45949414372444153
test loss item: 0.2127579152584076
test loss item: 0.19997698068618774
test loss item: 0.24364426732063293
test loss item: 0.7788432836532593
test loss item: 0.3036292791366577
test loss item: 0.27693477272987366
test loss item: 0.2519945204257965
test loss item: 0.5498671531677246
test loss item: 0.36562827229499817
test loss item: 0.12972578406333923
test loss item: 0.7424163222312927
test loss item: 0.2844293415546417
test loss item: 0.3285967707633972
test loss item: 0.16126631200313568
test loss item: 0.2182205319404602
test loss item: 0.18692132830619812
test loss item: 1.3755344152450562
test loss item: 0.4244348704814911
test loss item: 0.20462943613529205
test loss item: 0.12991972267627716
test loss item: 0.798606276512146
test loss item: 0.7346217632293701
test loss item: 0.906374454498291
test loss item: 0.22174930572509766
test loss item: 0.23525796830654144
test loss item: 0.13209111988544464
test loss item: 0.12013459205627441
test loss item: 0.2698327600955963
Epoch [37/50], Training Loss: 0.4485, Testing Loss: 0.3783
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Epoch 38/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4804050028324127
1
train loss item: 1.0623699426651
2
train loss item: 0.21732591092586517
3
train loss item: 0.4593963623046875
4
train loss item: 0.37213757634162903
5
train loss item: 0.3525116443634033
6
train loss item: 0.2202700823545456
7
train loss item: 0.7220376133918762
8
train loss item: 0.14666393399238586
9
train loss item: 0.23240190744400024
10
train loss item: 0.30777549743652344
11
train loss item: 0.2609027028083801
12
train loss item: 0.14964787662029266
13
train loss item: 0.4507302939891815
14
train loss item: 0.30873727798461914
15
train loss item: 0.5351933240890503
16
train loss item: 0.11151450872421265
17
train loss item: 0.2546055316925049
18
train loss item: 0.32489335536956787
19
train loss item: 0.2331644594669342
20
train loss item: 0.20088326930999756
21
train loss item: 0.1434088945388794
22
train loss item: 0.7673650979995728
23
train loss item: 0.7805519104003906
24
train loss item: 0.4548501670360565
25
train loss item: 0.19418177008628845
26
train loss item: 0.20309872925281525
27
train loss item: 0.3038264513015747
28
train loss item: 0.11054152250289917
29
train loss item: 0.6048926711082458
30
train loss item: 1.9604662656784058
31
train loss item: 0.4913672208786011
32
train loss item: 0.13886700570583344
33
train loss item: 0.36146461963653564
34
train loss item: 0.18121108412742615
35
train loss item: 2.204246997833252
36
train loss item: 0.4599543511867523
37
train loss item: 0.30097755789756775
38
train loss item: 0.3839413821697235
39
train loss item: 0.3215567469596863
40
train loss item: 0.16894330084323883
41
train loss item: 0.28126439452171326
42
train loss item: 0.244034543633461
43
train loss item: 0.1846083700656891
44
train loss item: 0.6760590672492981
45
train loss item: 0.1471935212612152
46
train loss item: 0.13838718831539154
47
train loss item: 0.281408429145813
48
train loss item: 0.2245478630065918
49
train loss item: 0.167275533080101
50
train loss item: 0.24392974376678467
51
train loss item: 0.7514023184776306
52
train loss item: 0.11827968806028366
53
train loss item: 0.16050496697425842
54
train loss item: 2.0689198970794678
55
train loss item: 0.20284146070480347
56
train loss item: 0.28553128242492676
57
train loss item: 0.2575661540031433
58
train loss item: 0.17026564478874207
59
train loss item: 0.1559741348028183
60
train loss item: 0.7479977011680603
61
train loss item: 1.9823815822601318
62
train loss item: 0.2071131318807602
63
train loss item: 0.2904028594493866
64
train loss item: 0.17236262559890747
65
train loss item: 0.47015613317489624
66
train loss item: 0.3846340477466583
67
train loss item: 0.20034122467041016
68
train loss item: 0.25882312655448914
69
train loss item: 0.2944088578224182
70
train loss item: 0.23358026146888733
71
train loss item: 0.1532505452632904
72
train loss item: 0.17515859007835388
73
train loss item: 0.2786168158054352
74
train loss item: 0.12967532873153687
75
train loss item: 0.1375589519739151
76
train loss item: 0.777980387210846
77
train loss item: 1.1517413854599
78
train loss item: 0.11761880666017532
79
train loss item: 0.2566870152950287
80
train loss item: 0.14329011738300323
81
train loss item: 0.18558591604232788
82
train loss item: 0.20868155360221863
83
train loss item: 0.4980524182319641
84
train loss item: 0.34760740399360657
85
train loss item: 0.4919546842575073
86
train loss item: 3.960721731185913
87
train loss item: 0.1680854856967926
88
train loss item: 0.32198119163513184
epoch train loss: 0.44321040340353934
testing phase
test loss item: 0.1908932477235794
test loss item: 0.15735936164855957
test loss item: 0.49675121903419495
test loss item: 0.2265319526195526
test loss item: 0.2714996337890625
test loss item: 0.16952870786190033
test loss item: 1.3025535345077515
test loss item: 0.4456169009208679
test loss item: 0.2059844434261322
test loss item: 0.36734911799430847
test loss item: 0.7208383679389954
test loss item: 0.17522284388542175
test loss item: 0.1908033788204193
test loss item: 0.29416555166244507
test loss item: 0.19886967539787292
test loss item: 0.13362111151218414
test loss item: 0.25466328859329224
test loss item: 0.44314277172088623
test loss item: 0.5656880140304565
test loss item: 0.24330618977546692
test loss item: 0.6764047145843506
test loss item: 0.3382970988750458
test loss item: 0.2848358452320099
test loss item: 0.18226616084575653
test loss item: 0.2245982587337494
test loss item: 0.22033549845218658
test loss item: 0.3064195215702057
test loss item: 0.21130119264125824
test loss item: 0.32387682795524597
test loss item: 0.33522918820381165
test loss item: 0.6162101626396179
test loss item: 0.12206709384918213
test loss item: 0.16529223322868347
test loss item: 0.542493999004364
test loss item: 0.40277448296546936
test loss item: 0.4474182724952698
test loss item: 0.6843073964118958
test loss item: 1.1751127243041992
test loss item: 0.4433610737323761
test loss item: 0.2628478705883026
test loss item: 0.2788058817386627
test loss item: 0.20408327877521515
test loss item: 0.3488241732120514
test loss item: 0.19474951922893524
test loss item: 0.5501954555511475
test loss item: 0.35502105951309204
test loss item: 0.29744914174079895
test loss item: 0.228469580411911
test loss item: 0.426090806722641
test loss item: 0.589190661907196
test loss item: 0.28065720200538635
test loss item: 0.16688065230846405
test loss item: 0.22868992388248444
test loss item: 0.17241206765174866
test loss item: 0.2908872961997986
test loss item: 0.7498539090156555
test loss item: 0.501298725605011
test loss item: 0.2383691668510437
test loss item: 0.22812028229236603
test loss item: 0.22144964337348938
test loss item: 0.4397715926170349
test loss item: 0.21274736523628235
test loss item: 0.20228981971740723
test loss item: 0.24402785301208496
test loss item: 0.7150534391403198
test loss item: 0.2963080406188965
test loss item: 0.2724527418613434
test loss item: 0.25047677755355835
test loss item: 0.5209253430366516
test loss item: 0.3675585389137268
test loss item: 0.12813618779182434
test loss item: 0.7485206127166748
test loss item: 0.28510555624961853
test loss item: 0.3340858519077301
test loss item: 0.15564754605293274
test loss item: 0.2029767781496048
test loss item: 0.18546214699745178
test loss item: 1.1953017711639404
test loss item: 0.42173269391059875
test loss item: 0.20752601325511932
test loss item: 0.12208721041679382
test loss item: 0.7572318315505981
test loss item: 0.7270928025245667
test loss item: 0.7914263010025024
test loss item: 0.21851889789104462
test loss item: 0.21559518575668335
test loss item: 0.1210956871509552
test loss item: 0.11948556452989578
test loss item: 0.1963866800069809
Epoch [38/50], Training Loss: 0.4432, Testing Loss: 0.3621
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 39/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4742979109287262
1
train loss item: 1.0481352806091309
2
train loss item: 0.2165054976940155
3
train loss item: 0.45619136095046997
4
train loss item: 0.3665368854999542
5
train loss item: 0.3479464650154114
6
train loss item: 0.2175174057483673
7
train loss item: 0.7106183171272278
8
train loss item: 0.14414434134960175
9
train loss item: 0.23237942159175873
10
train loss item: 0.30710339546203613
11
train loss item: 0.2550683319568634
12
train loss item: 0.14589253067970276
13
train loss item: 0.4506433606147766
14
train loss item: 0.30247172713279724
15
train loss item: 0.5288574695587158
16
train loss item: 0.10905549675226212
17
train loss item: 0.25097039341926575
18
train loss item: 0.32330191135406494
19
train loss item: 0.2321697473526001
20
train loss item: 0.19480694830417633
21
train loss item: 0.14067286252975464
22
train loss item: 0.7566101551055908
23
train loss item: 0.7689160704612732
24
train loss item: 0.44767916202545166
25
train loss item: 0.19478857517242432
26
train loss item: 0.20054864883422852
27
train loss item: 0.2974332273006439
28
train loss item: 0.10845838487148285
29
train loss item: 0.5948066711425781
30
train loss item: 1.9401506185531616
31
train loss item: 0.4931678771972656
32
train loss item: 0.13782189786434174
33
train loss item: 0.35410043597221375
34
train loss item: 0.177906796336174
35
train loss item: 2.190436601638794
36
train loss item: 0.4554363489151001
37
train loss item: 0.2961767911911011
38
train loss item: 0.38140013813972473
39
train loss item: 0.3165515959262848
40
train loss item: 0.16407868266105652
41
train loss item: 0.27559226751327515
42
train loss item: 0.2394707351922989
43
train loss item: 0.18233910202980042
44
train loss item: 0.6682969331741333
45
train loss item: 0.14673738181591034
46
train loss item: 0.1399545818567276
47
train loss item: 0.276570588350296
48
train loss item: 0.2222972810268402
49
train loss item: 0.1656951904296875
50
train loss item: 0.24018709361553192
51
train loss item: 0.742794930934906
52
train loss item: 0.11712012439966202
53
train loss item: 0.15840911865234375
54
train loss item: 2.0539493560791016
55
train loss item: 0.1986297070980072
56
train loss item: 0.2814476490020752
57
train loss item: 0.25298720598220825
58
train loss item: 0.1681387722492218
59
train loss item: 0.15546727180480957
60
train loss item: 0.7330440282821655
61
train loss item: 1.965793251991272
62
train loss item: 0.20478256046772003
63
train loss item: 0.2882041931152344
64
train loss item: 0.17034436762332916
65
train loss item: 0.4653727114200592
66
train loss item: 0.37583228945732117
67
train loss item: 0.1986621916294098
68
train loss item: 0.2530406713485718
69
train loss item: 0.2883640229701996
70
train loss item: 0.2306818813085556
71
train loss item: 0.15302349627017975
72
train loss item: 0.17318622767925262
73
train loss item: 0.2730863094329834
74
train loss item: 0.12722769379615784
75
train loss item: 0.13559751212596893
76
train loss item: 0.7663940787315369
77
train loss item: 1.1460652351379395
78
train loss item: 0.11497869342565536
79
train loss item: 0.2515256106853485
80
train loss item: 0.14193126559257507
81
train loss item: 0.18174485862255096
82
train loss item: 0.206318661570549
83
train loss item: 0.4924478232860565
84
train loss item: 0.34342366456985474
85
train loss item: 0.4895547330379486
86
train loss item: 3.940816640853882
87
train loss item: 0.16450119018554688
88
train loss item: 0.3212449550628662
epoch train loss: 0.4383711444025629
testing phase
test loss item: 0.20022690296173096
test loss item: 0.1879304051399231
test loss item: 0.5594234466552734
test loss item: 0.24001619219779968
test loss item: 0.3050588071346283
test loss item: 0.20918865501880646
test loss item: 1.2823517322540283
test loss item: 0.4327373206615448
test loss item: 0.22123779356479645
test loss item: 0.3882800042629242
test loss item: 0.8343712091445923
test loss item: 0.1902477890253067
test loss item: 0.19803020358085632
test loss item: 0.2907736599445343
test loss item: 0.23268981277942657
test loss item: 0.15306489169597626
test loss item: 0.25109508633613586
test loss item: 0.4859822392463684
test loss item: 0.5822510123252869
test loss item: 0.2367330640554428
test loss item: 0.7420032024383545
test loss item: 0.3427022695541382
test loss item: 0.3289983570575714
test loss item: 0.19150376319885254
test loss item: 0.23346737027168274
test loss item: 0.24050599336624146
test loss item: 0.3057677745819092
test loss item: 0.23467223346233368
test loss item: 0.34326377511024475
test loss item: 0.3484189212322235
test loss item: 0.6986414194107056
test loss item: 0.14552709460258484
test loss item: 0.18094828724861145
test loss item: 0.5901501774787903
test loss item: 0.4454990029335022
test loss item: 0.4979186952114105
test loss item: 0.6772946119308472
test loss item: 1.4241920709609985
test loss item: 0.4750264585018158
test loss item: 0.2768166661262512
test loss item: 0.27729520201683044
test loss item: 0.26241523027420044
test loss item: 0.3752896189689636
test loss item: 0.20086926221847534
test loss item: 0.5894644856452942
test loss item: 0.35225892066955566
test loss item: 0.3302389681339264
test loss item: 0.21596305072307587
test loss item: 0.4590071141719818
test loss item: 0.652124285697937
test loss item: 0.30532413721084595
test loss item: 0.17430995404720306
test loss item: 0.2376192957162857
test loss item: 0.19540798664093018
test loss item: 0.31568440794944763
test loss item: 0.8772408366203308
test loss item: 0.5312386751174927
test loss item: 0.27065205574035645
test loss item: 0.23888768255710602
test loss item: 0.23559284210205078
test loss item: 0.4733787178993225
test loss item: 0.21553584933280945
test loss item: 0.20348212122917175
test loss item: 0.24503418803215027
test loss item: 0.8319177627563477
test loss item: 0.3083130419254303
test loss item: 0.27660050988197327
test loss item: 0.2577780485153198
test loss item: 0.5736302733421326
test loss item: 0.376137375831604
test loss item: 0.15031489729881287
test loss item: 0.7245425581932068
test loss item: 0.2831534743309021
test loss item: 0.32208436727523804
test loss item: 0.17466385662555695
test loss item: 0.24232542514801025
test loss item: 0.19784203171730042
test loss item: 1.5023784637451172
test loss item: 0.42336416244506836
test loss item: 0.23980222642421722
test loss item: 0.15721429884433746
test loss item: 0.8491755723953247
test loss item: 0.737492024898529
test loss item: 0.9891247153282166
test loss item: 0.22601842880249023
test loss item: 0.25755205750465393
test loss item: 0.1666906327009201
test loss item: 0.12999796867370605
test loss item: 0.4048137664794922
Epoch [39/50], Training Loss: 0.4384, Testing Loss: 0.3960
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 40/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46895432472229004
1
train loss item: 1.0363181829452515
2
train loss item: 0.2127557247877121
3
train loss item: 0.44755950570106506
4
train loss item: 0.3616142272949219
5
train loss item: 0.34310969710350037
6
train loss item: 0.21431446075439453
7
train loss item: 0.7068236470222473
8
train loss item: 0.14206528663635254
9
train loss item: 0.22756613790988922
10
train loss item: 0.29713156819343567
11
train loss item: 0.2517092227935791
12
train loss item: 0.14524924755096436
13
train loss item: 0.4395621716976166
14
train loss item: 0.29666244983673096
15
train loss item: 0.517442524433136
16
train loss item: 0.10606782138347626
17
train loss item: 0.24686799943447113
18
train loss item: 0.3144192397594452
19
train loss item: 0.2276235967874527
20
train loss item: 0.19230978190898895
21
train loss item: 0.13835829496383667
22
train loss item: 0.7436214685440063
23
train loss item: 0.7578961849212646
24
train loss item: 0.4435204863548279
25
train loss item: 0.18839898705482483
26
train loss item: 0.19679734110832214
27
train loss item: 0.29519975185394287
28
train loss item: 0.1053897887468338
29
train loss item: 0.5829084515571594
30
train loss item: 1.9272236824035645
31
train loss item: 0.48049482703208923
32
train loss item: 0.1354561150074005
33
train loss item: 0.34607642889022827
34
train loss item: 0.17433221638202667
35
train loss item: 2.1821727752685547
36
train loss item: 0.4538213908672333
37
train loss item: 0.29364386200904846
38
train loss item: 0.3724689483642578
39
train loss item: 0.3114369809627533
40
train loss item: 0.16423319280147552
41
train loss item: 0.2712365388870239
42
train loss item: 0.23748406767845154
43
train loss item: 0.17966824769973755
44
train loss item: 0.6645315885543823
45
train loss item: 0.14375050365924835
46
train loss item: 0.13405095040798187
47
train loss item: 0.2749951481819153
48
train loss item: 0.2194613367319107
49
train loss item: 0.1631118357181549
50
train loss item: 0.23723189532756805
51
train loss item: 0.7295514941215515
52
train loss item: 0.11467581987380981
53
train loss item: 0.1552790105342865
54
train loss item: 2.046649932861328
55
train loss item: 0.19753852486610413
56
train loss item: 0.2766904830932617
57
train loss item: 0.24840407073497772
58
train loss item: 0.16683612763881683
59
train loss item: 0.15355916321277618
60
train loss item: 0.7230812907218933
61
train loss item: 1.955512523651123
62
train loss item: 0.19928501546382904
63
train loss item: 0.2861033082008362
64
train loss item: 0.16666661202907562
65
train loss item: 0.4555191695690155
66
train loss item: 0.37121301889419556
67
train loss item: 0.19743044674396515
68
train loss item: 0.2519890367984772
69
train loss item: 0.2823600769042969
70
train loss item: 0.22564175724983215
71
train loss item: 0.14818933606147766
72
train loss item: 0.17012427747249603
73
train loss item: 0.27220019698143005
74
train loss item: 0.1239122748374939
75
train loss item: 0.13336530327796936
76
train loss item: 0.7607352137565613
77
train loss item: 1.1348390579223633
78
train loss item: 0.11202245205640793
79
train loss item: 0.24937686324119568
80
train loss item: 0.14002250134944916
81
train loss item: 0.18009357154369354
82
train loss item: 0.20359282195568085
83
train loss item: 0.48368406295776367
84
train loss item: 0.3396027684211731
85
train loss item: 0.481054425239563
86
train loss item: 3.9282639026641846
87
train loss item: 0.16228778660297394
88
train loss item: 0.31303170323371887
epoch train loss: 0.43320770235208983
testing phase
test loss item: 0.18489065766334534
test loss item: 0.14723673462867737
test loss item: 0.4999640882015228
test loss item: 0.22282589972019196
test loss item: 0.2636684775352478
test loss item: 0.15573175251483917
test loss item: 1.3146038055419922
test loss item: 0.45633864402770996
test loss item: 0.19838722050189972
test loss item: 0.36054620146751404
test loss item: 0.7450958490371704
test loss item: 0.17354992032051086
test loss item: 0.18705925345420837
test loss item: 0.2839423716068268
test loss item: 0.1907949000597
test loss item: 0.12427400052547455
test loss item: 0.25226107239723206
test loss item: 0.4395243227481842
test loss item: 0.5704529881477356
test loss item: 0.23450666666030884
test loss item: 0.6770496368408203
test loss item: 0.3422047793865204
test loss item: 0.2838948667049408
test loss item: 0.17627276480197906
test loss item: 0.21970179677009583
test loss item: 0.22126786410808563
test loss item: 0.29718729853630066
test loss item: 0.20285217463970184
test loss item: 0.31398552656173706
test loss item: 0.32787632942199707
test loss item: 0.6415402889251709
test loss item: 0.1138429269194603
test loss item: 0.15793216228485107
test loss item: 0.5401902198791504
test loss item: 0.39974433183670044
test loss item: 0.45442846417427063
test loss item: 0.6857790946960449
test loss item: 1.2380892038345337
test loss item: 0.437839537858963
test loss item: 0.25611019134521484
test loss item: 0.27716055512428284
test loss item: 0.19979405403137207
test loss item: 0.34271684288978577
test loss item: 0.1944216638803482
test loss item: 0.5448217988014221
test loss item: 0.3500393331050873
test loss item: 0.2941700518131256
test loss item: 0.21634215116500854
test loss item: 0.4249376356601715
test loss item: 0.5950773358345032
test loss item: 0.2760685384273529
test loss item: 0.15865427255630493
test loss item: 0.22363720834255219
test loss item: 0.17132903635501862
test loss item: 0.28688570857048035
test loss item: 0.7673631310462952
test loss item: 0.5034161806106567
test loss item: 0.2444465011358261
test loss item: 0.22544856369495392
test loss item: 0.21592676639556885
test loss item: 0.42995673418045044
test loss item: 0.215901181101799
test loss item: 0.19763925671577454
test loss item: 0.2411341518163681
test loss item: 0.7462772130966187
test loss item: 0.2957020401954651
test loss item: 0.2700762152671814
test loss item: 0.2461812049150467
test loss item: 0.5213274359703064
test loss item: 0.36830195784568787
test loss item: 0.11933314055204391
test loss item: 0.7559981942176819
test loss item: 0.2703262269496918
test loss item: 0.32887303829193115
test loss item: 0.15159545838832855
test loss item: 0.19559204578399658
test loss item: 0.17950114607810974
test loss item: 1.2991260290145874
test loss item: 0.4107836186885834
test loss item: 0.19738978147506714
test loss item: 0.11883729696273804
test loss item: 0.7818861603736877
test loss item: 0.7299917340278625
test loss item: 0.8535646796226501
test loss item: 0.2114250808954239
test loss item: 0.2205171436071396
test loss item: 0.11857903003692627
test loss item: 0.11083322018384933
test loss item: 0.22736535966396332
Epoch [40/50], Training Loss: 0.4332, Testing Loss: 0.3631
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 41/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4626946747303009
1
train loss item: 1.0243228673934937
2
train loss item: 0.20985516905784607
3
train loss item: 0.4415126442909241
4
train loss item: 0.3558962047100067
5
train loss item: 0.33785319328308105
6
train loss item: 0.2118183970451355
7
train loss item: 0.6974173188209534
8
train loss item: 0.14013922214508057
9
train loss item: 0.22456054389476776
10
train loss item: 0.29385942220687866
11
train loss item: 0.24853581190109253
12
train loss item: 0.14354665577411652
13
train loss item: 0.4325934648513794
14
train loss item: 0.29056453704833984
15
train loss item: 0.5096210241317749
16
train loss item: 0.10410691052675247
17
train loss item: 0.24354730546474457
18
train loss item: 0.3108149468898773
19
train loss item: 0.22368468344211578
20
train loss item: 0.1893550455570221
21
train loss item: 0.13682492077350616
22
train loss item: 0.7325755953788757
23
train loss item: 0.7454346418380737
24
train loss item: 0.4380422830581665
25
train loss item: 0.18715590238571167
26
train loss item: 0.19301173090934753
27
train loss item: 0.28922876715660095
28
train loss item: 0.10341735929250717
29
train loss item: 0.5723134279251099
30
train loss item: 1.907177448272705
31
train loss item: 0.4753522574901581
32
train loss item: 0.13298657536506653
33
train loss item: 0.33852118253707886
34
train loss item: 0.17127197980880737
35
train loss item: 2.1701977252960205
36
train loss item: 0.44548627734184265
37
train loss item: 0.2871004343032837
38
train loss item: 0.3680839240550995
39
train loss item: 0.30597397685050964
40
train loss item: 0.16124999523162842
41
train loss item: 0.2664928436279297
42
train loss item: 0.2338831126689911
43
train loss item: 0.17741069197654724
44
train loss item: 0.6571555733680725
45
train loss item: 0.14124956727027893
46
train loss item: 0.13084889948368073
47
train loss item: 0.2697950601577759
48
train loss item: 0.2161751240491867
49
train loss item: 0.16107861697673798
50
train loss item: 0.23349478840827942
51
train loss item: 0.7227839827537537
52
train loss item: 0.11270033568143845
53
train loss item: 0.15215830504894257
54
train loss item: 2.0340070724487305
55
train loss item: 0.19524416327476501
56
train loss item: 0.27277958393096924
57
train loss item: 0.24244306981563568
58
train loss item: 0.16429460048675537
59
train loss item: 0.1498565971851349
60
train loss item: 0.7112656831741333
61
train loss item: 1.941347599029541
62
train loss item: 0.1979522705078125
63
train loss item: 0.2813683748245239
64
train loss item: 0.16420480608940125
65
train loss item: 0.4490278661251068
66
train loss item: 0.3630901575088501
67
train loss item: 0.19478219747543335
68
train loss item: 0.247928649187088
69
train loss item: 0.2804979681968689
70
train loss item: 0.22121340036392212
71
train loss item: 0.14700543880462646
72
train loss item: 0.16774439811706543
73
train loss item: 0.270209938287735
74
train loss item: 0.1215369924902916
75
train loss item: 0.1311858892440796
76
train loss item: 0.7481266856193542
77
train loss item: 1.1256815195083618
78
train loss item: 0.11001082509756088
79
train loss item: 0.24345187842845917
80
train loss item: 0.13698166608810425
81
train loss item: 0.17916609346866608
82
train loss item: 0.2002444565296173
83
train loss item: 0.4792572259902954
84
train loss item: 0.33540865778923035
85
train loss item: 0.4751255512237549
86
train loss item: 3.91092586517334
87
train loss item: 0.15920956432819366
88
train loss item: 0.3094976544380188
epoch train loss: 0.4280337944961666
testing phase
test loss item: 0.18592263758182526
test loss item: 0.15646177530288696
test loss item: 0.5200233459472656
test loss item: 0.22510284185409546
test loss item: 0.273378849029541
test loss item: 0.15740354359149933
test loss item: 1.2922000885009766
test loss item: 0.43568623065948486
test loss item: 0.2083500623703003
test loss item: 0.37021881341934204
test loss item: 0.7657344937324524
test loss item: 0.17760562896728516
test loss item: 0.19075559079647064
test loss item: 0.2814428508281708
test loss item: 0.20059621334075928
test loss item: 0.13270393013954163
test loss item: 0.24764537811279297
test loss item: 0.4527716040611267
test loss item: 0.5566579699516296
test loss item: 0.2327631264925003
test loss item: 0.6934033632278442
test loss item: 0.33675751090049744
test loss item: 0.2912631034851074
test loss item: 0.17676761746406555
test loss item: 0.22252145409584045
test loss item: 0.21976123750209808
test loss item: 0.29770758748054504
test loss item: 0.20760191977024078
test loss item: 0.3213467001914978
test loss item: 0.33522287011146545
test loss item: 0.6496772766113281
test loss item: 0.1210051029920578
test loss item: 0.1608782410621643
test loss item: 0.5537441968917847
test loss item: 0.4142841696739197
test loss item: 0.465925395488739
test loss item: 0.6772264838218689
test loss item: 1.2840094566345215
test loss item: 0.4471299350261688
test loss item: 0.251593679189682
test loss item: 0.273061066865921
test loss item: 0.19818972051143646
test loss item: 0.3518908619880676
test loss item: 0.19387921690940857
test loss item: 0.551164984703064
test loss item: 0.34278738498687744
test loss item: 0.2994978427886963
test loss item: 0.2139004021883011
test loss item: 0.43474170565605164
test loss item: 0.6022746562957764
test loss item: 0.28219759464263916
test loss item: 0.16429661214351654
test loss item: 0.22614686191082
test loss item: 0.1771637350320816
test loss item: 0.29395386576652527
test loss item: 0.7961950302124023
test loss item: 0.5099902153015137
test loss item: 0.24282127618789673
test loss item: 0.22669091820716858
test loss item: 0.22045888006687164
test loss item: 0.4470924735069275
test loss item: 0.21126201748847961
test loss item: 0.19375820457935333
test loss item: 0.23937924206256866
test loss item: 0.7632041573524475
test loss item: 0.2975599467754364
test loss item: 0.268659383058548
test loss item: 0.24526384472846985
test loss item: 0.5346429347991943
test loss item: 0.36396729946136475
test loss item: 0.12562750279903412
test loss item: 0.7333902716636658
test loss item: 0.27257269620895386
test loss item: 0.32059478759765625
test loss item: 0.15263795852661133
test loss item: 0.1990392506122589
test loss item: 0.18063871562480927
test loss item: 1.3568235635757446
test loss item: 0.4118312895298004
test loss item: 0.19814909994602203
test loss item: 0.11922033876180649
test loss item: 0.7882885932922363
test loss item: 0.7242458462715149
test loss item: 0.8869205117225647
test loss item: 0.21294961869716644
test loss item: 0.22147519886493683
test loss item: 0.11893503367900848
test loss item: 0.11637619882822037
test loss item: 0.19567342102527618
Epoch [41/50], Training Loss: 0.4280, Testing Loss: 0.3673
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 42/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4559524655342102
1
train loss item: 1.0116182565689087
2
train loss item: 0.20765230059623718
3
train loss item: 0.4355200231075287
4
train loss item: 0.35220491886138916
5
train loss item: 0.33364272117614746
6
train loss item: 0.2093811184167862
7
train loss item: 0.6902279257774353
8
train loss item: 0.13833901286125183
9
train loss item: 0.2235369235277176
10
train loss item: 0.29040050506591797
11
train loss item: 0.24668249487876892
12
train loss item: 0.14072708785533905
13
train loss item: 0.4267135262489319
14
train loss item: 0.28489118814468384
15
train loss item: 0.4998903274536133
16
train loss item: 0.10289876163005829
17
train loss item: 0.2434758096933365
18
train loss item: 0.3048444986343384
19
train loss item: 0.22166869044303894
20
train loss item: 0.18387824296951294
21
train loss item: 0.13409386575222015
22
train loss item: 0.7173938155174255
23
train loss item: 0.7367128729820251
24
train loss item: 0.43093767762184143
25
train loss item: 0.18306109309196472
26
train loss item: 0.19243068993091583
27
train loss item: 0.28458258509635925
28
train loss item: 0.1025342047214508
29
train loss item: 0.5608853101730347
30
train loss item: 1.8925840854644775
31
train loss item: 0.469182550907135
32
train loss item: 0.1323503702878952
33
train loss item: 0.3382343351840973
34
train loss item: 0.17003773152828217
35
train loss item: 2.160675525665283
36
train loss item: 0.4403766095638275
37
train loss item: 0.2855413556098938
38
train loss item: 0.3650992512702942
39
train loss item: 0.30265408754348755
40
train loss item: 0.1602717489004135
41
train loss item: 0.2627828121185303
42
train loss item: 0.23472189903259277
43
train loss item: 0.17626433074474335
44
train loss item: 0.6513401865959167
45
train loss item: 0.14056755602359772
46
train loss item: 0.13036680221557617
47
train loss item: 0.2658630609512329
48
train loss item: 0.21359951794147491
49
train loss item: 0.1578485369682312
50
train loss item: 0.23039031028747559
51
train loss item: 0.7114326357841492
52
train loss item: 0.10981222987174988
53
train loss item: 0.1489744633436203
54
train loss item: 2.0238640308380127
55
train loss item: 0.1918782740831375
56
train loss item: 0.26846444606781006
57
train loss item: 0.2385948896408081
58
train loss item: 0.1597236543893814
59
train loss item: 0.14880071580410004
60
train loss item: 0.6990835666656494
61
train loss item: 1.9300458431243896
62
train loss item: 0.1928826868534088
63
train loss item: 0.2790207862854004
64
train loss item: 0.1665256917476654
65
train loss item: 0.4439981281757355
66
train loss item: 0.35958147048950195
67
train loss item: 0.19232942163944244
68
train loss item: 0.24211840331554413
69
train loss item: 0.27883365750312805
70
train loss item: 0.2217087745666504
71
train loss item: 0.14301031827926636
72
train loss item: 0.16653762757778168
73
train loss item: 0.26428690552711487
74
train loss item: 0.11923377215862274
75
train loss item: 0.13114188611507416
76
train loss item: 0.7386126518249512
77
train loss item: 1.1114670038223267
78
train loss item: 0.10820340365171432
79
train loss item: 0.24113468825817108
80
train loss item: 0.1370302140712738
81
train loss item: 0.17499564588069916
82
train loss item: 0.19733554124832153
83
train loss item: 0.4697631597518921
84
train loss item: 0.33384445309638977
85
train loss item: 0.4677690267562866
86
train loss item: 3.896930456161499
87
train loss item: 0.15772759914398193
88
train loss item: 0.30649253726005554
epoch train loss: 0.42360362067316354
testing phase
test loss item: 0.20529566705226898
test loss item: 0.18397675454616547
test loss item: 0.5056021809577942
test loss item: 0.23559848964214325
test loss item: 0.3500553071498871
test loss item: 0.3492918014526367
test loss item: 1.3211373090744019
test loss item: 0.48692014813423157
test loss item: 0.20367605984210968
test loss item: 0.3545195758342743
test loss item: 0.738497793674469
test loss item: 0.17411629855632782
test loss item: 0.17812953889369965
test loss item: 0.27925705909729004
test loss item: 0.23280906677246094
test loss item: 0.1391240805387497
test loss item: 0.2534514367580414
test loss item: 0.4489572048187256
test loss item: 0.6092248558998108
test loss item: 0.23726868629455566
test loss item: 0.6954801678657532
test loss item: 0.34486955404281616
test loss item: 0.2948443293571472
test loss item: 0.18988506495952606
test loss item: 0.22352629899978638
test loss item: 0.24699696898460388
test loss item: 0.3039441406726837
test loss item: 0.2811749577522278
test loss item: 0.3310505151748657
test loss item: 0.32023924589157104
test loss item: 0.6509712338447571
test loss item: 0.12307190150022507
test loss item: 0.18394595384597778
test loss item: 0.5468814969062805
test loss item: 0.408314049243927
test loss item: 0.4521661698818207
test loss item: 0.6848746538162231
test loss item: 1.2404561042785645
test loss item: 0.43796300888061523
test loss item: 0.3609572947025299
test loss item: 0.27834808826446533
test loss item: 0.25445541739463806
test loss item: 0.34205400943756104
test loss item: 0.1916806697845459
test loss item: 0.5452688932418823
test loss item: 0.3582087457180023
test loss item: 0.2957534193992615
test loss item: 0.2252694070339203
test loss item: 0.42631417512893677
test loss item: 0.6106910705566406
test loss item: 0.2700144946575165
test loss item: 0.15771639347076416
test loss item: 0.2249181568622589
test loss item: 0.16664887964725494
test loss item: 0.2926003634929657
test loss item: 0.7802017331123352
test loss item: 0.5041962265968323
test loss item: 0.24421244859695435
test loss item: 0.2298087626695633
test loss item: 0.2117740511894226
test loss item: 0.4228348135948181
test loss item: 0.2256004363298416
test loss item: 0.21026788651943207
test loss item: 0.2351541668176651
test loss item: 0.7965389490127563
test loss item: 0.29088670015335083
test loss item: 0.2746393382549286
test loss item: 0.26172032952308655
test loss item: 0.523812472820282
test loss item: 0.3696943521499634
test loss item: 0.1530298888683319
test loss item: 0.7693588733673096
test loss item: 0.27738243341445923
test loss item: 0.33927351236343384
test loss item: 0.1881476789712906
test loss item: 0.23591943085193634
test loss item: 0.19776245951652527
test loss item: 1.3110442161560059
test loss item: 0.4090106189250946
test loss item: 0.34144532680511475
test loss item: 0.18953141570091248
test loss item: 0.8063337802886963
test loss item: 0.7280827164649963
test loss item: 0.844271719455719
test loss item: 0.2162247896194458
test loss item: 0.2649855315685272
test loss item: 0.20796874165534973
test loss item: 0.1239301785826683
test loss item: 0.498391717672348
Epoch [42/50], Training Loss: 0.4236, Testing Loss: 0.3835
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 43/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45311129093170166
1
train loss item: 1.001147985458374
2
train loss item: 0.20729762315750122
3
train loss item: 0.433893620967865
4
train loss item: 0.3477799594402313
5
train loss item: 0.3292338252067566
6
train loss item: 0.20741654932498932
7
train loss item: 0.685156524181366
8
train loss item: 0.13821157813072205
9
train loss item: 0.22762806713581085
10
train loss item: 0.28683990240097046
11
train loss item: 0.24072203040122986
12
train loss item: 0.14268483221530914
13
train loss item: 0.4153550863265991
14
train loss item: 0.2802288830280304
15
train loss item: 0.5020677447319031
16
train loss item: 0.10188407450914383
17
train loss item: 0.236074760556221
18
train loss item: 0.3044356405735016
19
train loss item: 0.2315339744091034
20
train loss item: 0.18862779438495636
21
train loss item: 0.1370110958814621
22
train loss item: 0.7099452614784241
23
train loss item: 0.7250020503997803
24
train loss item: 0.4357462525367737
25
train loss item: 0.18602049350738525
26
train loss item: 0.19916334748268127
27
train loss item: 0.28233763575553894
28
train loss item: 0.10065976530313492
29
train loss item: 0.5548508167266846
30
train loss item: 1.8750128746032715
31
train loss item: 0.4604586064815521
32
train loss item: 0.13296760618686676
33
train loss item: 0.32144349813461304
34
train loss item: 0.16422338783740997
35
train loss item: 2.150024175643921
36
train loss item: 0.4330739974975586
37
train loss item: 0.2777099013328552
38
train loss item: 0.36463412642478943
39
train loss item: 0.2981724739074707
40
train loss item: 0.16650083661079407
41
train loss item: 0.2592630386352539
42
train loss item: 0.2377023547887802
43
train loss item: 0.1751687228679657
44
train loss item: 0.6441261768341064
45
train loss item: 0.13660180568695068
46
train loss item: 0.1293841451406479
47
train loss item: 0.2690553069114685
48
train loss item: 0.21482284367084503
49
train loss item: 0.16371895372867584
50
train loss item: 0.2354334592819214
51
train loss item: 0.7115795612335205
52
train loss item: 0.10796964913606644
53
train loss item: 0.15095986425876617
54
train loss item: 2.01448130607605
55
train loss item: 0.19647003710269928
56
train loss item: 0.26320695877075195
57
train loss item: 0.24067921936511993
58
train loss item: 0.16712425649166107
59
train loss item: 0.1461603194475174
60
train loss item: 0.6928018927574158
61
train loss item: 1.91632878780365
62
train loss item: 0.19692620635032654
63
train loss item: 0.28714844584465027
64
train loss item: 0.1590958535671234
65
train loss item: 0.4358002841472626
66
train loss item: 0.35702988505363464
67
train loss item: 0.19481121003627777
68
train loss item: 0.24749381840229034
69
train loss item: 0.2818860709667206
70
train loss item: 0.2190530002117157
71
train loss item: 0.14456205070018768
72
train loss item: 0.1648496389389038
73
train loss item: 0.279060035943985
74
train loss item: 0.11845774203538895
75
train loss item: 0.12810955941677094
76
train loss item: 0.7300222516059875
77
train loss item: 1.113939642906189
78
train loss item: 0.10813625901937485
79
train loss item: 0.2426169216632843
80
train loss item: 0.13198408484458923
81
train loss item: 0.1780610829591751
82
train loss item: 0.19328030943870544
83
train loss item: 0.467965692281723
84
train loss item: 0.33355697989463806
85
train loss item: 0.4664662480354309
86
train loss item: 3.8816096782684326
87
train loss item: 0.15620659291744232
88
train loss item: 0.30863380432128906
epoch train loss: 0.4217538422580515
testing phase
test loss item: 0.2054622918367386
test loss item: 0.15820705890655518
test loss item: 0.5611168742179871
test loss item: 0.2352854460477829
test loss item: 0.27420616149902344
test loss item: 0.15338774025440216
test loss item: 1.3174456357955933
test loss item: 0.40278807282447815
test loss item: 0.22376097738742828
test loss item: 0.394273966550827
test loss item: 0.8624486327171326
test loss item: 0.18877074122428894
test loss item: 0.19511644542217255
test loss item: 0.27795732021331787
test loss item: 0.20323263108730316
test loss item: 0.13524571061134338
test loss item: 0.24092784523963928
test loss item: 0.47454768419265747
test loss item: 0.5593344569206238
test loss item: 0.23378422856330872
test loss item: 0.7106180191040039
test loss item: 0.33539527654647827
test loss item: 0.3153429627418518
test loss item: 0.17736758291721344
test loss item: 0.22474715113639832
test loss item: 0.232660174369812
test loss item: 0.3058202862739563
test loss item: 0.20774811506271362
test loss item: 0.3209700286388397
test loss item: 0.3539060354232788
test loss item: 0.7229856252670288
test loss item: 0.12967874109745026
test loss item: 0.162107452750206
test loss item: 0.5763111710548401
test loss item: 0.4358074367046356
test loss item: 0.5421254634857178
test loss item: 0.6739468574523926
test loss item: 1.468421220779419
test loss item: 0.4692903161048889
test loss item: 0.24796831607818604
test loss item: 0.2709648907184601
test loss item: 0.21554087102413177
test loss item: 0.35878050327301025
test loss item: 0.2024325728416443
test loss item: 0.5604758262634277
test loss item: 0.33523476123809814
test loss item: 0.3110063076019287
test loss item: 0.22756989300251007
test loss item: 0.45581743121147156
test loss item: 0.665855884552002
test loss item: 0.2954210937023163
test loss item: 0.17124299705028534
test loss item: 0.23072433471679688
test loss item: 0.20379282534122467
test loss item: 0.3071034550666809
test loss item: 0.8927258253097534
test loss item: 0.547046422958374
test loss item: 0.23362773656845093
test loss item: 0.22872358560562134
test loss item: 0.22670572996139526
test loss item: 0.4824327826499939
test loss item: 0.20365773141384125
test loss item: 0.21785962581634521
test loss item: 0.237993061542511
test loss item: 0.8254975080490112
test loss item: 0.3166118264198303
test loss item: 0.2694277763366699
test loss item: 0.23995475471019745
test loss item: 0.5536748766899109
test loss item: 0.39439234137535095
test loss item: 0.1247127428650856
test loss item: 0.7159069180488586
test loss item: 0.27500447630882263
test loss item: 0.3274679183959961
test loss item: 0.14766736328601837
test loss item: 0.21126733720302582
test loss item: 0.17998050153255463
test loss item: 1.5593082904815674
test loss item: 0.4143299460411072
test loss item: 0.21500246226787567
test loss item: 0.11494424194097519
test loss item: 0.8689091801643372
test loss item: 0.7480685710906982
test loss item: 1.0305100679397583
test loss item: 0.21779492497444153
test loss item: 0.22155018150806427
test loss item: 0.11188988387584686
test loss item: 0.11581668257713318
test loss item: 0.2524418830871582
Epoch [43/50], Training Loss: 0.4218, Testing Loss: 0.3870
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 44/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4508027136325836
1
train loss item: 0.999000072479248
2
train loss item: 0.20760709047317505
3
train loss item: 0.44866880774497986
4
train loss item: 0.35405367612838745
5
train loss item: 0.3342975676059723
6
train loss item: 0.20535613596439362
7
train loss item: 0.6804107427597046
8
train loss item: 0.1390565186738968
9
train loss item: 0.22676947712898254
10
train loss item: 0.2903115749359131
11
train loss item: 0.2557845711708069
12
train loss item: 0.1384337693452835
13
train loss item: 0.4405352473258972
14
train loss item: 0.2811514437198639
15
train loss item: 0.48061394691467285
16
train loss item: 0.09972620010375977
17
train loss item: 0.2406216263771057
18
train loss item: 0.3011449873447418
19
train loss item: 0.21707554161548615
20
train loss item: 0.1752866804599762
21
train loss item: 0.13467346131801605
22
train loss item: 0.6893659830093384
23
train loss item: 0.7270300388336182
24
train loss item: 0.420576810836792
25
train loss item: 0.190579354763031
26
train loss item: 0.19833138585090637
27
train loss item: 0.2814110815525055
28
train loss item: 0.09942542761564255
29
train loss item: 0.5471789240837097
30
train loss item: 1.8848909139633179
31
train loss item: 0.4684608280658722
32
train loss item: 0.1362355798482895
33
train loss item: 0.34774482250213623
34
train loss item: 0.16672316193580627
35
train loss item: 2.150082588195801
36
train loss item: 0.4712611436843872
37
train loss item: 0.29793882369995117
38
train loss item: 0.3791899085044861
39
train loss item: 0.30540940165519714
40
train loss item: 0.15869835019111633
41
train loss item: 0.26738524436950684
42
train loss item: 0.2547486126422882
43
train loss item: 0.17708943784236908
44
train loss item: 0.6451442241668701
45
train loss item: 0.1454087793827057
46
train loss item: 0.13329088687896729
47
train loss item: 0.2617611587047577
48
train loss item: 0.21117131412029266
49
train loss item: 0.16160805523395538
50
train loss item: 0.22495755553245544
51
train loss item: 0.700077474117279
52
train loss item: 0.10639651864767075
53
train loss item: 0.15166594088077545
54
train loss item: 2.009784698486328
55
train loss item: 0.18951526284217834
56
train loss item: 0.27120301127433777
57
train loss item: 0.23375171422958374
58
train loss item: 0.15636061131954193
59
train loss item: 0.14902792870998383
60
train loss item: 0.6906746625900269
61
train loss item: 1.9154324531555176
62
train loss item: 0.18822668492794037
63
train loss item: 0.27806276082992554
64
train loss item: 0.17079974710941315
65
train loss item: 0.43396463990211487
66
train loss item: 0.38289883732795715
67
train loss item: 0.19562971591949463
68
train loss item: 0.23092862963676453
69
train loss item: 0.2823529541492462
70
train loss item: 0.23359765112400055
71
train loss item: 0.13932682573795319
72
train loss item: 0.16934606432914734
73
train loss item: 0.2617255747318268
74
train loss item: 0.11653929203748703
75
train loss item: 0.1303904503583908
76
train loss item: 0.7422719597816467
77
train loss item: 1.0826629400253296
78
train loss item: 0.10565660148859024
79
train loss item: 0.24466143548488617
80
train loss item: 0.13733860850334167
81
train loss item: 0.18389885127544403
82
train loss item: 0.1997695416212082
83
train loss item: 0.45648741722106934
84
train loss item: 0.3676348030567169
85
train loss item: 0.4699791967868805
86
train loss item: 3.8786251544952393
87
train loss item: 0.15834176540374756
88
train loss item: 0.3049585819244385
epoch train loss: 0.42274661362171173
testing phase
test loss item: 0.1836363524198532
test loss item: 0.14450211822986603
test loss item: 0.4604107737541199
test loss item: 0.2209703028202057
test loss item: 0.26528477668762207
test loss item: 0.19411683082580566
test loss item: 1.3236154317855835
test loss item: 0.4537288248538971
test loss item: 0.1871921271085739
test loss item: 0.34408944845199585
test loss item: 0.6797719597816467
test loss item: 0.16197136044502258
test loss item: 0.1828709989786148
test loss item: 0.2703418731689453
test loss item: 0.18753281235694885
test loss item: 0.11495981365442276
test loss item: 0.2440415620803833
test loss item: 0.41257819533348083
test loss item: 0.5594576597213745
test loss item: 0.22794082760810852
test loss item: 0.634705126285553
test loss item: 0.3318285346031189
test loss item: 0.2590925693511963
test loss item: 0.17867816984653473
test loss item: 0.2086055725812912
test loss item: 0.21942636370658875
test loss item: 0.2845577001571655
test loss item: 0.21037665009498596
test loss item: 0.29963400959968567
test loss item: 0.31322386860847473
test loss item: 0.6069492697715759
test loss item: 0.1033162847161293
test loss item: 0.16368231177330017
test loss item: 0.5112670660018921
test loss item: 0.37092551589012146
test loss item: 0.4287048280239105
test loss item: 0.672953188419342
test loss item: 1.1140172481536865
test loss item: 0.41270911693573
test loss item: 0.27177152037620544
test loss item: 0.2705965042114258
test loss item: 0.1897912174463272
test loss item: 0.32934823632240295
test loss item: 0.18602395057678223
test loss item: 0.5108718276023865
test loss item: 0.33830612897872925
test loss item: 0.2696862518787384
test loss item: 0.20892013609409332
test loss item: 0.4009643495082855
test loss item: 0.5583469867706299
test loss item: 0.2607155442237854
test loss item: 0.1510164737701416
test loss item: 0.21628989279270172
test loss item: 0.15541638433933258
test loss item: 0.2728806138038635
test loss item: 0.6938107013702393
test loss item: 0.4863664507865906
test loss item: 0.22445055842399597
test loss item: 0.21663248538970947
test loss item: 0.20997236669063568
test loss item: 0.40603023767471313
test loss item: 0.20918729901313782
test loss item: 0.19807308912277222
test loss item: 0.23373019695281982
test loss item: 0.6841306686401367
test loss item: 0.2878303825855255
test loss item: 0.2641197144985199
test loss item: 0.23637397587299347
test loss item: 0.4910212457180023
test loss item: 0.3594421148300171
test loss item: 0.11530578881502151
test loss item: 0.752953052520752
test loss item: 0.2609165608882904
test loss item: 0.3258785307407379
test loss item: 0.1455969214439392
test loss item: 0.17381484806537628
test loss item: 0.17701908946037292
test loss item: 1.1521875858306885
test loss item: 0.3892776668071747
test loss item: 0.21867001056671143
test loss item: 0.11918896436691284
test loss item: 0.7453020811080933
test loss item: 0.7103500366210938
test loss item: 0.7603123784065247
test loss item: 0.20813298225402832
test loss item: 0.19951418042182922
test loss item: 0.1151813268661499
test loss item: 0.10830552130937576
test loss item: 0.21334697306156158
Epoch [44/50], Training Loss: 0.4227, Testing Loss: 0.3464
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Epoch 45/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4433554708957672
1
train loss item: 0.9805322885513306
2
train loss item: 0.20422665774822235
3
train loss item: 0.42859214544296265
4
train loss item: 0.34011927247047424
5
train loss item: 0.3234212100505829
6
train loss item: 0.2001689374446869
7
train loss item: 0.6661006212234497
8
train loss item: 0.13344456255435944
9
train loss item: 0.21797852218151093
10
train loss item: 0.28360453248023987
11
train loss item: 0.23753777146339417
12
train loss item: 0.13921822607517242
13
train loss item: 0.41433918476104736
14
train loss item: 0.27228736877441406
15
train loss item: 0.48904839158058167
16
train loss item: 0.09814827889204025
17
train loss item: 0.23166237771511078
18
train loss item: 0.2976832985877991
19
train loss item: 0.22746412456035614
20
train loss item: 0.18223527073860168
21
train loss item: 0.1337364763021469
22
train loss item: 0.6930748224258423
23
train loss item: 0.7083001732826233
24
train loss item: 0.4205113351345062
25
train loss item: 0.19229604303836823
26
train loss item: 0.18430458009243011
27
train loss item: 0.27190902829170227
28
train loss item: 0.09724793583154678
29
train loss item: 0.5372992753982544
30
train loss item: 1.8429311513900757
31
train loss item: 0.46743905544281006
32
train loss item: 0.12853176891803741
33
train loss item: 0.3250633180141449
34
train loss item: 0.16171878576278687
35
train loss item: 2.1297192573547363
36
train loss item: 0.42942553758621216
37
train loss item: 0.27866289019584656
38
train loss item: 0.3743879199028015
39
train loss item: 0.29087141156196594
40
train loss item: 0.15720605850219727
41
train loss item: 0.25099092721939087
42
train loss item: 0.23573057353496552
43
train loss item: 0.1685837060213089
44
train loss item: 0.6338744759559631
45
train loss item: 0.13853341341018677
46
train loss item: 0.13028086721897125
47
train loss item: 0.2620556354522705
48
train loss item: 0.20930081605911255
49
train loss item: 0.1567366123199463
50
train loss item: 0.22639314830303192
51
train loss item: 0.7024110555648804
52
train loss item: 0.10533380508422852
53
train loss item: 0.1473715454339981
54
train loss item: 1.9931588172912598
55
train loss item: 0.1885898858308792
56
train loss item: 0.2593041956424713
57
train loss item: 0.2288532257080078
58
train loss item: 0.15835419297218323
59
train loss item: 0.1449737548828125
60
train loss item: 0.6690506935119629
61
train loss item: 1.893715739250183
62
train loss item: 0.19871722161769867
63
train loss item: 0.2801804542541504
64
train loss item: 0.15542824566364288
65
train loss item: 0.42778870463371277
66
train loss item: 0.3524704873561859
67
train loss item: 0.18963143229484558
68
train loss item: 0.24440301954746246
69
train loss item: 0.2731773555278778
70
train loss item: 0.21326716244220734
71
train loss item: 0.1462680846452713
72
train loss item: 0.15885774791240692
73
train loss item: 0.2642097771167755
74
train loss item: 0.11535520106554031
75
train loss item: 0.12497320026159286
76
train loss item: 0.7143412232398987
77
train loss item: 1.0985004901885986
78
train loss item: 0.10427478700876236
79
train loss item: 0.23421894013881683
80
train loss item: 0.13082650303840637
81
train loss item: 0.1730320155620575
82
train loss item: 0.19080397486686707
83
train loss item: 0.4562312364578247
84
train loss item: 0.3314014971256256
85
train loss item: 0.46395352482795715
86
train loss item: 3.8517916202545166
87
train loss item: 0.15223060548305511
88
train loss item: 0.30253130197525024
epoch train loss: 0.4144749240426535
testing phase
test loss item: 0.18435214459896088
test loss item: 0.1525951623916626
test loss item: 0.564020574092865
test loss item: 0.2268933653831482
test loss item: 0.2850991487503052
test loss item: 0.1547057032585144
test loss item: 1.3486578464508057
test loss item: 0.4534853994846344
test loss item: 0.2075304538011551
test loss item: 0.3726080358028412
test loss item: 0.8511563539505005
test loss item: 0.18203216791152954
test loss item: 0.1842295229434967
test loss item: 0.26561424136161804
test loss item: 0.20345336198806763
test loss item: 0.1284901201725006
test loss item: 0.2450442612171173
test loss item: 0.4809413254261017
test loss item: 0.5665704607963562
test loss item: 0.228980153799057
test loss item: 0.7433526515960693
test loss item: 0.3468504548072815
test loss item: 0.32124048471450806
test loss item: 0.1700066775083542
test loss item: 0.22279398143291473
test loss item: 0.217926487326622
test loss item: 0.2908940315246582
test loss item: 0.21199247241020203
test loss item: 0.32620421051979065
test loss item: 0.3279138505458832
test loss item: 0.738210916519165
test loss item: 0.11907920986413956
test loss item: 0.15359711647033691
test loss item: 0.6027786731719971
test loss item: 0.4390472173690796
test loss item: 0.5034415125846863
test loss item: 0.6832410097122192
test loss item: 1.5047690868377686
test loss item: 0.46743243932724
test loss item: 0.24890413880348206
test loss item: 0.2726649045944214
test loss item: 0.21023084223270416
test loss item: 0.3660339415073395
test loss item: 0.19957685470581055
test loss item: 0.5691993832588196
test loss item: 0.34312641620635986
test loss item: 0.32214754819869995
test loss item: 0.20755204558372498
test loss item: 0.4569959342479706
test loss item: 0.6486563682556152
test loss item: 0.2840568423271179
test loss item: 0.1514490842819214
test loss item: 0.2307194322347641
test loss item: 0.1930341273546219
test loss item: 0.3051036596298218
test loss item: 0.906532347202301
test loss item: 0.5347332954406738
test loss item: 0.2478945404291153
test loss item: 0.22397057712078094
test loss item: 0.22396989166736603
test loss item: 0.45765432715415955
test loss item: 0.21544647216796875
test loss item: 0.1932203322649002
test loss item: 0.23324070870876312
test loss item: 0.8829811811447144
test loss item: 0.3082004189491272
test loss item: 0.27096202969551086
test loss item: 0.24399743974208832
test loss item: 0.5791592001914978
test loss item: 0.35947075486183167
test loss item: 0.12567031383514404
test loss item: 0.7588972449302673
test loss item: 0.27967604994773865
test loss item: 0.32249876856803894
test loss item: 0.15402589738368988
test loss item: 0.21671411395072937
test loss item: 0.17664065957069397
test loss item: 1.6428738832473755
test loss item: 0.4045431315898895
test loss item: 0.20097143948078156
test loss item: 0.1269548088312149
test loss item: 0.8710001707077026
test loss item: 0.7424576282501221
test loss item: 1.0700477361679077
test loss item: 0.21813035011291504
test loss item: 0.23785758018493652
test loss item: 0.12573085725307465
test loss item: 0.11011701822280884
test loss item: 0.253610759973526
Epoch [45/50], Training Loss: 0.4145, Testing Loss: 0.3888
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 46/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.43675464391708374
1
train loss item: 0.9668343663215637
2
train loss item: 0.2017124891281128
3
train loss item: 0.41915178298950195
4
train loss item: 0.3362285792827606
5
train loss item: 0.3159821331501007
6
train loss item: 0.19873911142349243
7
train loss item: 0.662796676158905
8
train loss item: 0.1329500377178192
9
train loss item: 0.21610382199287415
10
train loss item: 0.2748703956604004
11
train loss item: 0.23333558440208435
12
train loss item: 0.1398194283246994
13
train loss item: 0.40029293298721313
14
train loss item: 0.2673446834087372
15
train loss item: 0.49134448170661926
16
train loss item: 0.09687690436840057
17
train loss item: 0.23056349158287048
18
train loss item: 0.29100170731544495
19
train loss item: 0.23069988191127777
20
train loss item: 0.1861494779586792
21
train loss item: 0.13387376070022583
22
train loss item: 0.6890031695365906
23
train loss item: 0.6989412307739258
24
train loss item: 0.42031553387641907
25
train loss item: 0.1803704798221588
26
train loss item: 0.18305610120296478
27
train loss item: 0.26990583539009094
28
train loss item: 0.09592549502849579
29
train loss item: 0.5287996530532837
30
train loss item: 1.8321105241775513
31
train loss item: 0.4454497694969177
32
train loss item: 0.1257227659225464
33
train loss item: 0.31400564312934875
34
train loss item: 0.15944541990756989
35
train loss item: 2.1241095066070557
36
train loss item: 0.41968756914138794
37
train loss item: 0.2746429741382599
38
train loss item: 0.3617364466190338
39
train loss item: 0.2865319848060608
40
train loss item: 0.16047066450119019
41
train loss item: 0.24651633203029633
42
train loss item: 0.2353488802909851
43
train loss item: 0.16682571172714233
44
train loss item: 0.6293706893920898
45
train loss item: 0.13261738419532776
46
train loss item: 0.13050641119480133
47
train loss item: 0.2640030086040497
48
train loss item: 0.20642907917499542
49
train loss item: 0.15285693109035492
50
train loss item: 0.22703664004802704
51
train loss item: 0.6981111168861389
52
train loss item: 0.10469188541173935
53
train loss item: 0.14332151412963867
54
train loss item: 1.9874886274337769
55
train loss item: 0.19018076360225677
56
train loss item: 0.25148266553878784
57
train loss item: 0.2258961796760559
58
train loss item: 0.16052281856536865
59
train loss item: 0.13739900290966034
60
train loss item: 0.664413332939148
61
train loss item: 1.8864638805389404
62
train loss item: 0.19447200000286102
63
train loss item: 0.2820098400115967
64
train loss item: 0.15285493433475494
65
train loss item: 0.42509493231773376
66
train loss item: 0.3446696102619171
67
train loss item: 0.1911984533071518
68
train loss item: 0.24635949730873108
69
train loss item: 0.27526822686195374
70
train loss item: 0.21479560434818268
71
train loss item: 0.1409793645143509
72
train loss item: 0.15759244561195374
73
train loss item: 0.2633849084377289
74
train loss item: 0.11327559500932693
75
train loss item: 0.1240067407488823
76
train loss item: 0.7050366401672363
77
train loss item: 1.0916513204574585
78
train loss item: 0.103314608335495
79
train loss item: 0.23424296081066132
80
train loss item: 0.1275939643383026
81
train loss item: 0.17401023209095
82
train loss item: 0.18244746327400208
83
train loss item: 0.45169973373413086
84
train loss item: 0.3273647129535675
85
train loss item: 0.4509160816669464
86
train loss item: 3.842654228210449
87
train loss item: 0.15153715014457703
88
train loss item: 0.3021014332771301
epoch train loss: 0.4106255357017678
testing phase
test loss item: 0.18107375502586365
test loss item: 0.1540721356868744
test loss item: 0.519173264503479
test loss item: 0.22461484372615814
test loss item: 0.27486884593963623
test loss item: 0.1556464433670044
test loss item: 1.2668417692184448
test loss item: 0.41249826550483704
test loss item: 0.1987474411725998
test loss item: 0.3550775647163391
test loss item: 0.7925753593444824
test loss item: 0.17719987034797668
test loss item: 0.17660753428936005
test loss item: 0.26771119236946106
test loss item: 0.20103663206100464
test loss item: 0.1274862140417099
test loss item: 0.23856744170188904
test loss item: 0.4482528865337372
test loss item: 0.5359386801719666
test loss item: 0.22061188519001007
test loss item: 0.6895617842674255
test loss item: 0.3336702585220337
test loss item: 0.2916839122772217
test loss item: 0.1722472757101059
test loss item: 0.21447572112083435
test loss item: 0.2105327695608139
test loss item: 0.2846284806728363
test loss item: 0.20873166620731354
test loss item: 0.31756290793418884
test loss item: 0.3188270926475525
test loss item: 0.6740860342979431
test loss item: 0.11865191906690598
test loss item: 0.15819241106510162
test loss item: 0.5573310852050781
test loss item: 0.4081667959690094
test loss item: 0.4943484961986542
test loss item: 0.6495640873908997
test loss item: 1.3720479011535645
test loss item: 0.4380415976047516
test loss item: 0.24566683173179626
test loss item: 0.26772841811180115
test loss item: 0.1935712695121765
test loss item: 0.34362635016441345
test loss item: 0.19372954964637756
test loss item: 0.5341888666152954
test loss item: 0.3295273184776306
test loss item: 0.2970508635044098
test loss item: 0.20705826580524445
test loss item: 0.4262085556983948
test loss item: 0.6076478958129883
test loss item: 0.2657308280467987
test loss item: 0.15097318589687347
test loss item: 0.22161750495433807
test loss item: 0.18501396477222443
test loss item: 0.2874973714351654
test loss item: 0.8135930895805359
test loss item: 0.5126764178276062
test loss item: 0.2252805233001709
test loss item: 0.21613404154777527
test loss item: 0.2117176502943039
test loss item: 0.4356207251548767
test loss item: 0.20762664079666138
test loss item: 0.18757647275924683
test loss item: 0.22635021805763245
test loss item: 0.7787602543830872
test loss item: 0.3004133999347687
test loss item: 0.25962385535240173
test loss item: 0.2361677885055542
test loss item: 0.5393137335777283
test loss item: 0.3482367992401123
test loss item: 0.11948665976524353
test loss item: 0.7111383676528931
test loss item: 0.27432119846343994
test loss item: 0.31035834550857544
test loss item: 0.14494915306568146
test loss item: 0.19845575094223022
test loss item: 0.17686837911605835
test loss item: 1.479372262954712
test loss item: 0.3995864689350128
test loss item: 0.19627608358860016
test loss item: 0.11277671903371811
test loss item: 0.7963410019874573
test loss item: 0.7037158608436584
test loss item: 0.9583587050437927
test loss item: 0.20951426029205322
test loss item: 0.22441215813159943
test loss item: 0.11305507272481918
test loss item: 0.10949857532978058
test loss item: 0.18941359221935272
Epoch [46/50], Training Loss: 0.4106, Testing Loss: 0.3654
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 47/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4312313497066498
1
train loss item: 0.9542676210403442
2
train loss item: 0.1956409066915512
3
train loss item: 0.4087262749671936
4
train loss item: 0.3333628475666046
5
train loss item: 0.313831090927124
6
train loss item: 0.1945158690214157
7
train loss item: 0.6594948768615723
8
train loss item: 0.1296927034854889
9
train loss item: 0.21289023756980896
10
train loss item: 0.2736184895038605
11
train loss item: 0.2335505336523056
12
train loss item: 0.13636337220668793
13
train loss item: 0.400145560503006
14
train loss item: 0.26549169421195984
15
train loss item: 0.47071215510368347
16
train loss item: 0.09620894491672516
17
train loss item: 0.2296110987663269
18
train loss item: 0.28520262241363525
19
train loss item: 0.2210165560245514
20
train loss item: 0.1746400147676468
21
train loss item: 0.12793198227882385
22
train loss item: 0.6617608070373535
23
train loss item: 0.6955181956291199
24
train loss item: 0.41054609417915344
25
train loss item: 0.17420388758182526
26
train loss item: 0.18041794002056122
27
train loss item: 0.2684418559074402
28
train loss item: 0.09558908641338348
29
train loss item: 0.510471761226654
30
train loss item: 1.8285812139511108
31
train loss item: 0.4409473240375519
32
train loss item: 0.1265603005886078
33
train loss item: 0.3195056617259979
34
train loss item: 0.16003099083900452
35
train loss item: 2.11848783493042
36
train loss item: 0.4249756634235382
37
train loss item: 0.27524298429489136
38
train loss item: 0.3443814516067505
39
train loss item: 0.28342458605766296
40
train loss item: 0.15487146377563477
41
train loss item: 0.24473543465137482
42
train loss item: 0.23383089900016785
43
train loss item: 0.16526052355766296
44
train loss item: 0.6268099546432495
45
train loss item: 0.13704374432563782
46
train loss item: 0.12619803845882416
47
train loss item: 0.25393059849739075
48
train loss item: 0.20160284638404846
49
train loss item: 0.1506665050983429
50
train loss item: 0.21907390654087067
51
train loss item: 0.6695515513420105
52
train loss item: 0.10300295054912567
53
train loss item: 0.141402006149292
54
train loss item: 1.9817578792572021
55
train loss item: 0.18547439575195312
56
train loss item: 0.2498200684785843
57
train loss item: 0.22488129138946533
58
train loss item: 0.15310555696487427
59
train loss item: 0.13688549399375916
60
train loss item: 0.6512396931648254
61
train loss item: 1.8805532455444336
62
train loss item: 0.18691518902778625
63
train loss item: 0.2725347578525543
64
train loss item: 0.1555023193359375
65
train loss item: 0.4172990322113037
66
train loss item: 0.34409812092781067
67
train loss item: 0.18739905953407288
68
train loss item: 0.23117798566818237
69
train loss item: 0.2634241580963135
70
train loss item: 0.21079526841640472
71
train loss item: 0.13669495284557343
72
train loss item: 0.15467716753482819
73
train loss item: 0.25301575660705566
74
train loss item: 0.1111900731921196
75
train loss item: 0.12386419624090195
76
train loss item: 0.6981915831565857
77
train loss item: 1.0647550821304321
78
train loss item: 0.10157022625207901
79
train loss item: 0.2302102893590927
80
train loss item: 0.12897729873657227
81
train loss item: 0.16891589760780334
82
train loss item: 0.18274889886379242
83
train loss item: 0.43590399622917175
84
train loss item: 0.3282279372215271
85
train loss item: 0.4410227835178375
86
train loss item: 3.836176872253418
87
train loss item: 0.15124979615211487
88
train loss item: 0.2947269082069397
epoch train loss: 0.4052831246779206
testing phase
test loss item: 0.1794809252023697
test loss item: 0.13618916273117065
test loss item: 0.45240068435668945
test loss item: 0.21291397511959076
test loss item: 0.24505701661109924
test loss item: 0.1431158483028412
test loss item: 1.2282397747039795
test loss item: 0.40140417218208313
test loss item: 0.18306481838226318
test loss item: 0.33129432797431946
test loss item: 0.6737436652183533
test loss item: 0.15993747115135193
test loss item: 0.16802538931369781
test loss item: 0.27162760496139526
test loss item: 0.17838826775550842
test loss item: 0.11258415132761002
test loss item: 0.23432400822639465
test loss item: 0.40207144618034363
test loss item: 0.525082528591156
test loss item: 0.21563169360160828
test loss item: 0.6200540065765381
test loss item: 0.31987425684928894
test loss item: 0.2538616955280304
test loss item: 0.16306546330451965
test loss item: 0.20307379961013794
test loss item: 0.20374995470046997
test loss item: 0.27549368143081665
test loss item: 0.1885303407907486
test loss item: 0.2927826941013336
test loss item: 0.3041718602180481
test loss item: 0.5825455784797668
test loss item: 0.10408405214548111
test loss item: 0.14894631505012512
test loss item: 0.4981350898742676
test loss item: 0.3637843728065491
test loss item: 0.4316498637199402
test loss item: 0.6319020986557007
test loss item: 1.1153695583343506
test loss item: 0.39916229248046875
test loss item: 0.23757043480873108
test loss item: 0.2645280063152313
test loss item: 0.17447035014629364
test loss item: 0.3129444420337677
test loss item: 0.18238747119903564
test loss item: 0.4961116313934326
test loss item: 0.3191353380680084
test loss item: 0.2638927698135376
test loss item: 0.2076696902513504
test loss item: 0.3861613869667053
test loss item: 0.5451294779777527
test loss item: 0.2473945915699005
test loss item: 0.14762982726097107
test loss item: 0.21145294606685638
test loss item: 0.15584562718868256
test loss item: 0.26495322585105896
test loss item: 0.6846594214439392
test loss item: 0.46894609928131104
test loss item: 0.22188463807106018
test loss item: 0.20709234476089478
test loss item: 0.19695769250392914
test loss item: 0.3963586688041687
test loss item: 0.20088709890842438
test loss item: 0.18818405270576477
test loss item: 0.22061987221240997
test loss item: 0.6531289219856262
test loss item: 0.28334227204322815
test loss item: 0.24913541972637177
test loss item: 0.22760719060897827
test loss item: 0.48032209277153015
test loss item: 0.3419259190559387
test loss item: 0.10428141057491302
test loss item: 0.6945523619651794
test loss item: 0.264834463596344
test loss item: 0.3056674897670746
test loss item: 0.13780294358730316
test loss item: 0.17103311419487
test loss item: 0.16535939276218414
test loss item: 1.1552693843841553
test loss item: 0.38892561197280884
test loss item: 0.18687091767787933
test loss item: 0.10395687073469162
test loss item: 0.7042015194892883
test loss item: 0.6737312078475952
test loss item: 0.758329451084137
test loss item: 0.20031212270259857
test loss item: 0.2004392296075821
test loss item: 0.10430587083101273
test loss item: 0.10014749318361282
test loss item: 0.1831764131784439
Epoch [47/50], Training Loss: 0.4053, Testing Loss: 0.3325
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 48/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4283329248428345
1
train loss item: 0.9489777088165283
2
train loss item: 0.1943981945514679
3
train loss item: 0.405178427696228
4
train loss item: 0.329916387796402
5
train loss item: 0.310667484998703
6
train loss item: 0.19382697343826294
7
train loss item: 0.6523448824882507
8
train loss item: 0.12923942506313324
9
train loss item: 0.20870231091976166
10
train loss item: 0.27133750915527344
11
train loss item: 0.23587508499622345
12
train loss item: 0.1355450600385666
13
train loss item: 0.3987972140312195
14
train loss item: 0.26205477118492126
15
train loss item: 0.46073830127716064
16
train loss item: 0.09353455901145935
17
train loss item: 0.22805844247341156
18
train loss item: 0.2842887043952942
19
train loss item: 0.21217890083789825
20
train loss item: 0.17155912518501282
21
train loss item: 0.12685160338878632
22
train loss item: 0.6475264430046082
23
train loss item: 0.685725212097168
24
train loss item: 0.4037404954433441
25
train loss item: 0.17723916471004486
26
train loss item: 0.17808307707309723
27
train loss item: 0.2641656696796417
28
train loss item: 0.09279735386371613
29
train loss item: 0.506779134273529
30
train loss item: 1.8170616626739502
31
train loss item: 0.4499104619026184
32
train loss item: 0.1254044622182846
33
train loss item: 0.31252092123031616
34
train loss item: 0.15837836265563965
35
train loss item: 2.1088168621063232
36
train loss item: 0.4330344796180725
37
train loss item: 0.2712404131889343
38
train loss item: 0.348225474357605
39
train loss item: 0.27982357144355774
40
train loss item: 0.15174975991249084
41
train loss item: 0.24122828245162964
42
train loss item: 0.22913521528244019
43
train loss item: 0.1632281243801117
44
train loss item: 0.621906578540802
45
train loss item: 0.13265393674373627
46
train loss item: 0.12134295701980591
47
train loss item: 0.25087353587150574
48
train loss item: 0.19642367959022522
49
train loss item: 0.1494665890932083
50
train loss item: 0.21367162466049194
51
train loss item: 0.6560415625572205
52
train loss item: 0.1000455990433693
53
train loss item: 0.1399637758731842
54
train loss item: 1.9716992378234863
55
train loss item: 0.18097038567066193
56
train loss item: 0.2488071769475937
57
train loss item: 0.2210066020488739
58
train loss item: 0.14938804507255554
59
train loss item: 0.1372777223587036
60
train loss item: 0.6369401216506958
61
train loss item: 1.8679859638214111
62
train loss item: 0.18309946358203888
63
train loss item: 0.26656174659729004
64
train loss item: 0.15373753011226654
65
train loss item: 0.40992724895477295
66
train loss item: 0.34486374258995056
67
train loss item: 0.1806739866733551
68
train loss item: 0.22414550185203552
69
train loss item: 0.25889644026756287
70
train loss item: 0.2125861644744873
71
train loss item: 0.1369359791278839
72
train loss item: 0.15331099927425385
73
train loss item: 0.25072574615478516
74
train loss item: 0.11195817589759827
75
train loss item: 0.12267093360424042
76
train loss item: 0.6884108781814575
77
train loss item: 1.0525493621826172
78
train loss item: 0.09815213084220886
79
train loss item: 0.22511617839336395
80
train loss item: 0.12687253952026367
81
train loss item: 0.16598287224769592
82
train loss item: 0.18159694969654083
83
train loss item: 0.4275389313697815
84
train loss item: 0.33157625794410706
85
train loss item: 0.4358101785182953
86
train loss item: 3.824146032333374
87
train loss item: 0.1454268842935562
88
train loss item: 0.2896818220615387
epoch train loss: 0.4014341390032447
testing phase
test loss item: 0.17868639528751373
test loss item: 0.1320018470287323
test loss item: 0.4652763903141022
test loss item: 0.21189582347869873
test loss item: 0.24469715356826782
test loss item: 0.1397899091243744
test loss item: 1.306066632270813
test loss item: 0.44015610218048096
test loss item: 0.18439123034477234
test loss item: 0.33627986907958984
test loss item: 0.6870825290679932
test loss item: 0.15786930918693542
test loss item: 0.17166933417320251
test loss item: 0.2678317129611969
test loss item: 0.17424322664737701
test loss item: 0.10977406799793243
test loss item: 0.2356233149766922
test loss item: 0.40756911039352417
test loss item: 0.550695538520813
test loss item: 0.21866433322429657
test loss item: 0.6277130842208862
test loss item: 0.32772570848464966
test loss item: 0.2609020471572876
test loss item: 0.1606852412223816
test loss item: 0.20291942358016968
test loss item: 0.20482569932937622
test loss item: 0.27498963475227356
test loss item: 0.1866523176431656
test loss item: 0.29145774245262146
test loss item: 0.30469635128974915
test loss item: 0.6056983470916748
test loss item: 0.10087519139051437
test loss item: 0.14458850026130676
test loss item: 0.5055575370788574
test loss item: 0.3696368336677551
test loss item: 0.4327702820301056
test loss item: 0.6592415571212769
test loss item: 1.1427556276321411
test loss item: 0.4041202962398529
test loss item: 0.23945936560630798
test loss item: 0.26678699254989624
test loss item: 0.17770147323608398
test loss item: 0.31854817271232605
test loss item: 0.18360769748687744
test loss item: 0.498716801404953
test loss item: 0.3236137330532074
test loss item: 0.26874929666519165
test loss item: 0.20626898109912872
test loss item: 0.39780908823013306
test loss item: 0.5600215792655945
test loss item: 0.2496928572654724
test loss item: 0.14572905004024506
test loss item: 0.2129317820072174
test loss item: 0.15365682542324066
test loss item: 0.26732945442199707
test loss item: 0.6984928250312805
test loss item: 0.48039811849594116
test loss item: 0.2200399935245514
test loss item: 0.20756927132606506
test loss item: 0.20052218437194824
test loss item: 0.3998958468437195
test loss item: 0.20616072416305542
test loss item: 0.18858784437179565
test loss item: 0.2230132818222046
test loss item: 0.6774595975875854
test loss item: 0.2847445011138916
test loss item: 0.25146737694740295
test loss item: 0.23043261468410492
test loss item: 0.49105483293533325
test loss item: 0.35136690735816956
test loss item: 0.10628875344991684
test loss item: 0.7356058359146118
test loss item: 0.263247549533844
test loss item: 0.31155598163604736
test loss item: 0.1413649469614029
test loss item: 0.17546376585960388
test loss item: 0.1631416529417038
test loss item: 1.191375732421875
test loss item: 0.38935691118240356
test loss item: 0.18671536445617676
test loss item: 0.11260002851486206
test loss item: 0.7427542805671692
test loss item: 0.7000377178192139
test loss item: 0.7840399742126465
test loss item: 0.20098081231117249
test loss item: 0.20317526161670685
test loss item: 0.11485569924116135
test loss item: 0.09646130353212357
test loss item: 0.22575828433036804
Epoch [48/50], Training Loss: 0.4014, Testing Loss: 0.3399
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 49/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4220765233039856
1
train loss item: 0.9355813264846802
2
train loss item: 0.19298017024993896
3
train loss item: 0.40097707509994507
4
train loss item: 0.32511886954307556
5
train loss item: 0.30534595251083374
6
train loss item: 0.18994338810443878
7
train loss item: 0.6436801552772522
8
train loss item: 0.12716689705848694
9
train loss item: 0.2061363160610199
10
train loss item: 0.266826868057251
11
train loss item: 0.2298412173986435
12
train loss item: 0.13415555655956268
13
train loss item: 0.3933088481426239
14
train loss item: 0.25639215111732483
15
train loss item: 0.45540663599967957
16
train loss item: 0.09180286526679993
17
train loss item: 0.2227686643600464
18
train loss item: 0.27976176142692566
19
train loss item: 0.20815183222293854
20
train loss item: 0.1699548363685608
21
train loss item: 0.12430375814437866
22
train loss item: 0.6388735175132751
23
train loss item: 0.6752133369445801
24
train loss item: 0.40118804574012756
25
train loss item: 0.17597998678684235
26
train loss item: 0.17548274993896484
27
train loss item: 0.25849419832229614
28
train loss item: 0.09100925177335739
29
train loss item: 0.5018585920333862
30
train loss item: 1.7987533807754517
31
train loss item: 0.4447536766529083
32
train loss item: 0.12069875746965408
33
train loss item: 0.303305059671402
34
train loss item: 0.15410681068897247
35
train loss item: 2.0990500450134277
36
train loss item: 0.4202103912830353
37
train loss item: 0.2615150511264801
38
train loss item: 0.3417963981628418
39
train loss item: 0.2752580940723419
40
train loss item: 0.15025340020656586
41
train loss item: 0.23498345911502838
42
train loss item: 0.2261725217103958
43
train loss item: 0.16142548620700836
44
train loss item: 0.6166999936103821
45
train loss item: 0.12844645977020264
46
train loss item: 0.1187933087348938
47
train loss item: 0.24509458243846893
48
train loss item: 0.19597883522510529
49
train loss item: 0.14755932986736298
50
train loss item: 0.21252775192260742
51
train loss item: 0.652052640914917
52
train loss item: 0.09903742372989655
53
train loss item: 0.13775715231895447
54
train loss item: 1.96261727809906
55
train loss item: 0.1800282895565033
56
train loss item: 0.24331945180892944
57
train loss item: 0.21548010408878326
58
train loss item: 0.14861391484737396
59
train loss item: 0.1364143341779709
60
train loss item: 0.6267837882041931
61
train loss item: 1.8559647798538208
62
train loss item: 0.18325062096118927
63
train loss item: 0.26481765508651733
64
train loss item: 0.15049222111701965
65
train loss item: 0.4030205011367798
66
train loss item: 0.3318166136741638
67
train loss item: 0.17817296087741852
68
train loss item: 0.2260902225971222
69
train loss item: 0.2562108337879181
70
train loss item: 0.20561043918132782
71
train loss item: 0.13594552874565125
72
train loss item: 0.15073636174201965
73
train loss item: 0.24995671212673187
74
train loss item: 0.11077097803354263
75
train loss item: 0.12040915340185165
76
train loss item: 0.6809468865394592
77
train loss item: 1.0525760650634766
78
train loss item: 0.09653032571077347
79
train loss item: 0.2185211032629013
80
train loss item: 0.12275714427232742
81
train loss item: 0.16228660941123962
82
train loss item: 0.18033722043037415
83
train loss item: 0.420937180519104
84
train loss item: 0.32125362753868103
85
train loss item: 0.4326624572277069
86
train loss item: 3.8098621368408203
87
train loss item: 0.14348582923412323
88
train loss item: 0.28610697388648987
epoch train loss: 0.39675053552295386
testing phase
test loss item: 0.17556707561016083
test loss item: 0.13776463270187378
test loss item: 0.5184394717216492
test loss item: 0.2178906798362732
test loss item: 0.2585521936416626
test loss item: 0.14122074842453003
test loss item: 1.3574658632278442
test loss item: 0.45823413133621216
test loss item: 0.19620919227600098
test loss item: 0.35520121455192566
test loss item: 0.777979850769043
test loss item: 0.17070333659648895
test loss item: 0.18121129274368286
test loss item: 0.2654195725917816
test loss item: 0.1814490705728531
test loss item: 0.11787047237157822
test loss item: 0.23622697591781616
test loss item: 0.4362255334854126
test loss item: 0.5607587695121765
test loss item: 0.22519451379776
test loss item: 0.6705659031867981
test loss item: 0.33808591961860657
test loss item: 0.29173657298088074
test loss item: 0.16177695989608765
test loss item: 0.2094561755657196
test loss item: 0.2054525762796402
test loss item: 0.28049615025520325
test loss item: 0.19576722383499146
test loss item: 0.3015880882740021
test loss item: 0.3123635947704315
test loss item: 0.6742313504219055
test loss item: 0.10975182801485062
test loss item: 0.14407244324684143
test loss item: 0.5449613332748413
test loss item: 0.4004136621952057
test loss item: 0.48431381583213806
test loss item: 0.6781029105186462
test loss item: 1.3265280723571777
test loss item: 0.42975515127182007
test loss item: 0.24232876300811768
test loss item: 0.26791471242904663
test loss item: 0.19082461297512054
test loss item: 0.33931928873062134
test loss item: 0.19238367676734924
test loss item: 0.5223868489265442
test loss item: 0.32907089591026306
test loss item: 0.29701071977615356
test loss item: 0.20805038511753082
test loss item: 0.43068549036979675
test loss item: 0.6109421253204346
test loss item: 0.26204240322113037
test loss item: 0.14697925746440887
test loss item: 0.2187201827764511
test loss item: 0.17518837749958038
test loss item: 0.2836463451385498
test loss item: 0.7851628661155701
test loss item: 0.5120740532875061
test loss item: 0.22645607590675354
test loss item: 0.21189609169960022
test loss item: 0.21267098188400269
test loss item: 0.42598021030426025
test loss item: 0.2115902602672577
test loss item: 0.18615767359733582
test loss item: 0.2289493978023529
test loss item: 0.7569736838340759
test loss item: 0.29763227701187134
test loss item: 0.2568734288215637
test loss item: 0.23336075246334076
test loss item: 0.533995509147644
test loss item: 0.3614521622657776
test loss item: 0.11052537709474564
test loss item: 0.7569143772125244
test loss item: 0.27210596203804016
test loss item: 0.31443294882774353
test loss item: 0.1395730823278427
test loss item: 0.19191160798072815
test loss item: 0.1654694825410843
test loss item: 1.4254473447799683
test loss item: 0.4003446102142334
test loss item: 0.18793518841266632
test loss item: 0.10448718816041946
test loss item: 0.8275271654129028
test loss item: 0.7282240986824036
test loss item: 0.9409163594245911
test loss item: 0.20618805289268494
test loss item: 0.21123769879341125
test loss item: 0.10449876636266708
test loss item: 0.09987962990999222
test loss item: 0.1879379153251648
Epoch [49/50], Training Loss: 0.3968, Testing Loss: 0.3625
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 50/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41462400555610657
1
train loss item: 0.9227582216262817
2
train loss item: 0.19036881625652313
3
train loss item: 0.39408913254737854
4
train loss item: 0.3228859603404999
5
train loss item: 0.29992467164993286
6
train loss item: 0.18642836809158325
7
train loss item: 0.6361663341522217
8
train loss item: 0.12481171637773514
9
train loss item: 0.20558904111385345
10
train loss item: 0.26205286383628845
11
train loss item: 0.22795620560646057
12
train loss item: 0.13198326528072357
13
train loss item: 0.38583147525787354
14
train loss item: 0.2516941726207733
15
train loss item: 0.45190033316612244
16
train loss item: 0.08956870436668396
17
train loss item: 0.21904510259628296
18
train loss item: 0.2743333578109741
19
train loss item: 0.2059837281703949
20
train loss item: 0.16555869579315186
21
train loss item: 0.12124413251876831
22
train loss item: 0.632095456123352
23
train loss item: 0.6672000288963318
24
train loss item: 0.3918991982936859
25
train loss item: 0.16995972394943237
26
train loss item: 0.17532728612422943
27
train loss item: 0.2546178102493286
28
train loss item: 0.08918239176273346
29
train loss item: 0.49385949969291687
30
train loss item: 1.7859352827072144
31
train loss item: 0.4260386824607849
32
train loss item: 0.11824639141559601
33
train loss item: 0.2973405718803406
34
train loss item: 0.1502378135919571
35
train loss item: 2.093550205230713
36
train loss item: 0.4079265594482422
37
train loss item: 0.2579866647720337
38
train loss item: 0.3308252990245819
39
train loss item: 0.2717237174510956
40
train loss item: 0.14851360023021698
41
train loss item: 0.23263432085514069
42
train loss item: 0.22885100543498993
43
train loss item: 0.1594046652317047
44
train loss item: 0.6115933060646057
45
train loss item: 0.12656338512897491
46
train loss item: 0.12062037736177444
47
train loss item: 0.24188050627708435
48
train loss item: 0.19631612300872803
49
train loss item: 0.14537765085697174
50
train loss item: 0.21040955185890198
51
train loss item: 0.6511297225952148
52
train loss item: 0.09628652036190033
53
train loss item: 0.1344079077243805
54
train loss item: 1.9571655988693237
55
train loss item: 0.17951029539108276
56
train loss item: 0.2378753125667572
57
train loss item: 0.21366727352142334
58
train loss item: 0.14711961150169373
59
train loss item: 0.1341482698917389
60
train loss item: 0.6210787892341614
61
train loss item: 1.8472474813461304
62
train loss item: 0.17890223860740662
63
train loss item: 0.2662416696548462
64
train loss item: 0.14864109456539154
65
train loss item: 0.39641866087913513
66
train loss item: 0.3290063738822937
67
train loss item: 0.1778867095708847
68
train loss item: 0.220357745885849
69
train loss item: 0.25200292468070984
70
train loss item: 0.20157575607299805
71
train loss item: 0.13364998996257782
72
train loss item: 0.14897280931472778
73
train loss item: 0.24506667256355286
74
train loss item: 0.10682375729084015
75
train loss item: 0.11979491263628006
76
train loss item: 0.6734769940376282
77
train loss item: 1.0439165830612183
78
train loss item: 0.09461162984371185
79
train loss item: 0.21912994980812073
80
train loss item: 0.12149678170681
81
train loss item: 0.1617133915424347
82
train loss item: 0.17675986886024475
83
train loss item: 0.4167919456958771
84
train loss item: 0.3163435161113739
85
train loss item: 0.4218112826347351
86
train loss item: 3.8004283905029297
87
train loss item: 0.1420886516571045
88
train loss item: 0.281692773103714
epoch train loss: 0.3925410700815447
testing phase
test loss item: 0.17503084242343903
test loss item: 0.13731610774993896
test loss item: 0.5120452642440796
test loss item: 0.21868449449539185
test loss item: 0.25405722856521606
test loss item: 0.14140264689922333
test loss item: 1.3002502918243408
test loss item: 0.4409514367580414
test loss item: 0.19119593501091003
test loss item: 0.3470795452594757
test loss item: 0.7736783027648926
test loss item: 0.17530620098114014
test loss item: 0.17932771146297455
test loss item: 0.2637840807437897
test loss item: 0.17986661195755005
test loss item: 0.11969760805368423
test loss item: 0.23046521842479706
test loss item: 0.4274712800979614
test loss item: 0.5434810519218445
test loss item: 0.22076523303985596
test loss item: 0.6542259454727173
test loss item: 0.3314436972141266
test loss item: 0.2821477949619293
test loss item: 0.1600760668516159
test loss item: 0.206643745303154
test loss item: 0.20472751557826996
test loss item: 0.27734875679016113
test loss item: 0.19127719104290009
test loss item: 0.2957817316055298
test loss item: 0.3070039749145508
test loss item: 0.6618109941482544
test loss item: 0.11096028983592987
test loss item: 0.14330434799194336
test loss item: 0.5386523604393005
test loss item: 0.3933227062225342
test loss item: 0.4902515709400177
test loss item: 0.6557140946388245
test loss item: 1.326411247253418
test loss item: 0.4220796525478363
test loss item: 0.23788611590862274
test loss item: 0.2626205086708069
test loss item: 0.1859116107225418
test loss item: 0.3306116461753845
test loss item: 0.19265776872634888
test loss item: 0.5096880197525024
test loss item: 0.31914398074150085
test loss item: 0.28741979598999023
test loss item: 0.20461510121822357
test loss item: 0.42199522256851196
test loss item: 0.6021066904067993
test loss item: 0.2549581825733185
test loss item: 0.14659325778484344
test loss item: 0.21277748048305511
test loss item: 0.18393592536449432
test loss item: 0.27799391746520996
test loss item: 0.7847025990486145
test loss item: 0.5067967176437378
test loss item: 0.22875605523586273
test loss item: 0.2094140350818634
test loss item: 0.2074827253818512
test loss item: 0.4182963967323303
test loss item: 0.2074047178030014
test loss item: 0.1840832382440567
test loss item: 0.22527742385864258
test loss item: 0.7502838373184204
test loss item: 0.300258994102478
test loss item: 0.2505297064781189
test loss item: 0.22898919880390167
test loss item: 0.5277635455131531
test loss item: 0.3495892286300659
test loss item: 0.11006584018468857
test loss item: 0.7246252298355103
test loss item: 0.26925891637802124
test loss item: 0.30565470457077026
test loss item: 0.13658356666564941
test loss item: 0.18305177986621857
test loss item: 0.16338194906711578
test loss item: 1.4327956438064575
test loss item: 0.39463120698928833
test loss item: 0.18698179721832275
test loss item: 0.10229868441820145
test loss item: 0.8097543716430664
test loss item: 0.7068479061126709
test loss item: 0.9425249099731445
test loss item: 0.2021738737821579
test loss item: 0.20707190036773682
test loss item: 0.103066086769104
test loss item: 0.10187207162380219
test loss item: 0.18930386006832123
Epoch [50/50], Training Loss: 0.3925, Testing Loss: 0.3569
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
loss item: 0.3225267231464386
loss item: 0.1842762678861618
loss item: 1.5106219053268433
loss item: 0.8990745544433594
loss item: 0.46607622504234314
loss item: 0.3100202977657318
loss item: 0.20697081089019775
loss item: 0.5959146618843079
loss item: 0.18441882729530334
loss item: 0.20629459619522095
loss item: 0.6931862831115723
loss item: 0.1070970967411995
loss item: 0.7010113596916199
loss item: 0.2026081383228302
loss item: 0.37054455280303955
loss item: 0.31659695506095886
loss item: 0.26349353790283203
loss item: 0.6415295600891113
loss item: 0.7733200192451477
loss item: 0.39867109060287476
loss item: 0.3329553008079529
loss item: 0.19926196336746216
loss item: 0.23861795663833618
loss item: 0.19664378464221954
loss item: 0.2706342935562134
loss item: 0.5669618844985962
loss item: 0.9582357406616211
loss item: 0.17079107463359833
loss item: 0.1531788557767868
loss item: 0.3390187919139862
loss item: 0.7850334644317627
loss item: 1.3441210985183716
loss item: 0.1594121903181076
loss item: 0.45749613642692566
loss item: 0.17207054793834686
loss item: 0.1855863481760025
loss item: 0.38614407181739807
loss item: 0.18649035692214966
loss item: 0.3384729027748108
loss item: 0.5736880898475647
loss item: 0.8751194477081299
loss item: 0.23227640986442566
loss item: 0.18099723756313324
loss item: 0.10801029950380325
Val Loss: 0.4265
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 50 0.0001 2 360 done at Wed Nov 13 17:20:22 CET 2024
UNet6 with 1 50 0.0005 2 360 start at Wed Nov 13 17:20:22 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 1073.396240234375
test loss item: 1825.4366455078125
test loss item: 593.513916015625
test loss item: 3402.35400390625
test loss item: 1432.8350830078125
test loss item: 1101.7930908203125
test loss item: 4293.38525390625
test loss item: 2056.052001953125
test loss item: 983.393798828125
test loss item: 1080.54150390625
test loss item: 3268.616455078125
test loss item: 3387.968505859375
test loss item: 1415.2587890625
test loss item: 155.1746826171875
test loss item: 1560.358642578125
test loss item: 2054.7509765625
test loss item: 586.7355346679688
test loss item: 1424.037841796875
test loss item: 2285.005615234375
test loss item: 477.49407958984375
test loss item: 490.1462707519531
test loss item: 3241.994384765625
test loss item: 1987.736083984375
test loss item: 1667.1552734375
test loss item: 1189.39404296875
test loss item: 1011.9746704101562
test loss item: 1110.9444580078125
test loss item: 1439.2664794921875
test loss item: 1637.3873291015625
test loss item: 1456.5567626953125
test loss item: 2567.75830078125
test loss item: 2156.354248046875
test loss item: 1647.2252197265625
test loss item: 3415.092041015625
test loss item: 1677.3106689453125
test loss item: 10306.333984375
test loss item: 2520.37939453125
test loss item: 4596.36572265625
test loss item: 2994.80419921875
test loss item: 1459.9661865234375
test loss item: 1574.25341796875
test loss item: 2169.212646484375
test loss item: 314.3674011230469
test loss item: 3197.302978515625
test loss item: 481.6025695800781
test loss item: 1431.2628173828125
test loss item: 1962.573486328125
test loss item: 636.291015625
test loss item: 638.4937133789062
test loss item: 2052.255615234375
test loss item: 1341.2618408203125
test loss item: 1359.8218994140625
test loss item: 943.6686401367188
test loss item: 4905.68896484375
test loss item: 779.1927490234375
test loss item: 1749.71044921875
test loss item: 6549.90380859375
test loss item: 61.08621597290039
test loss item: 1279.8924560546875
test loss item: 1106.2103271484375
test loss item: 1298.221435546875
test loss item: 1257.730712890625
test loss item: 686.1917724609375
test loss item: 1438.11474609375
test loss item: 2255.193603515625
test loss item: 5237.1640625
test loss item: 1227.04248046875
test loss item: 1095.8515625
test loss item: 1473.5120849609375
test loss item: 2248.47998046875
test loss item: 1458.933349609375
test loss item: 2143.240234375
test loss item: 323.953369140625
test loss item: 1194.3221435546875
test loss item: 400.1552734375
test loss item: 1925.527099609375
test loss item: 1530.5855712890625
test loss item: 5113.45458984375
test loss item: 113.53984832763672
test loss item: 994.1921997070312
test loss item: 553.6729125976562
test loss item: 4730.39404296875
test loss item: 2573.75146484375
test loss item: 4917.96240234375
test loss item: 793.8377075195312
test loss item: 783.5877685546875
test loss item: 1389.701171875
test loss item: 1987.3375244140625
test loss item: 1082.837646484375
Epoch [1/50], Training Loss: 1.0161, Testing Loss: 1907.8066
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.9610803723335266
1
train loss item: 2.0869719982147217
2
train loss item: 0.8648231029510498
3
train loss item: 1.1216984987258911
4
train loss item: 1.9628078937530518
5
train loss item: 0.7860296368598938
6
train loss item: 0.9755358695983887
7
train loss item: 1.276835560798645
8
train loss item: 0.9419233202934265
9
train loss item: 0.636870801448822
10
train loss item: 0.7311280369758606
11
train loss item: 0.5714137554168701
12
train loss item: 0.6297969818115234
13
train loss item: 1.0564218759536743
14
train loss item: 0.7491157650947571
15
train loss item: 1.3152027130126953
16
train loss item: 0.7876008749008179
17
train loss item: 0.9731787443161011
18
train loss item: 0.8148528933525085
19
train loss item: 0.6499318480491638
20
train loss item: 0.7342736124992371
21
train loss item: 0.6737383008003235
22
train loss item: 1.9226921796798706
23
train loss item: 1.3755406141281128
24
train loss item: 1.0840805768966675
25
train loss item: 0.7472132444381714
26
train loss item: 0.7659173011779785
27
train loss item: 0.6883385181427002
28
train loss item: 0.7842848896980286
29
train loss item: 1.564386010169983
30
train loss item: 2.917602777481079
31
train loss item: 1.0476430654525757
32
train loss item: 0.5979970693588257
33
train loss item: 0.9200557470321655
34
train loss item: 1.2829920053482056
35
train loss item: 2.950822591781616
36
train loss item: 1.0549070835113525
37
train loss item: 0.6426941156387329
38
train loss item: 1.1503973007202148
39
train loss item: 0.7319750189781189
40
train loss item: 0.7444394826889038
41
train loss item: 0.6483772397041321
42
train loss item: 0.6060624122619629
43
train loss item: 0.6421911716461182
44
train loss item: 1.1402636766433716
45
train loss item: 0.7553742527961731
46
train loss item: 0.681804358959198
47
train loss item: 0.8301006555557251
48
train loss item: 0.6657137274742126
49
train loss item: 0.6807478070259094
50
train loss item: 0.6668230295181274
51
train loss item: 1.6286009550094604
52
train loss item: 0.7506836652755737
53
train loss item: 0.8124781847000122
54
train loss item: 2.7997705936431885
55
train loss item: 0.8023961782455444
56
train loss item: 0.6549271941184998
57
train loss item: 0.679426372051239
58
train loss item: 0.6117108464241028
59
train loss item: 0.6076603531837463
60
train loss item: 1.7864497900009155
61
train loss item: 2.7589123249053955
62
train loss item: 0.667665421962738
63
train loss item: 0.7758030891418457
64
train loss item: 0.612826406955719
65
train loss item: 1.279589056968689
66
train loss item: 0.7979201674461365
67
train loss item: 0.6886866688728333
68
train loss item: 0.8516250848770142
69
train loss item: 0.7631414532661438
70
train loss item: 0.7257243990898132
71
train loss item: 1.0015699863433838
72
train loss item: 0.9294403195381165
73
train loss item: 0.7485255002975464
74
train loss item: 1.0114132165908813
75
train loss item: 0.625966489315033
76
train loss item: 1.3848271369934082
77
train loss item: 2.0647308826446533
78
train loss item: 0.7570294141769409
79
train loss item: 0.6416780352592468
80
train loss item: 0.9463794827461243
81
train loss item: 0.6630517244338989
82
train loss item: 0.7165557146072388
83
train loss item: 1.3105486631393433
84
train loss item: 0.8187755346298218
85
train loss item: 1.1267739534378052
86
train loss item: 4.951118469238281
87
train loss item: 0.9303812384605408
88
train loss item: 0.774116575717926
epoch train loss: 1.0567589991548088
testing phase
test loss item: 1.6952979564666748
test loss item: 9.625849723815918
test loss item: 2.691225051879883
test loss item: 38.27228546142578
test loss item: 7.350315093994141
test loss item: 5.846074104309082
test loss item: 20.474124908447266
test loss item: 6.659194469451904
test loss item: 1.1748534440994263
test loss item: 4.6506266593933105
test loss item: 24.397600173950195
test loss item: 36.54059600830078
test loss item: 5.641790390014648
test loss item: 0.7489233613014221
test loss item: 7.349485397338867
test loss item: 12.024171829223633
test loss item: 1.9126787185668945
test loss item: 6.343292236328125
test loss item: 8.421590805053711
test loss item: 0.6090383529663086
test loss item: 2.897944688796997
test loss item: 37.776153564453125
test loss item: 18.683368682861328
test loss item: 7.812326431274414
test loss item: 5.44108772277832
test loss item: 5.987850189208984
test loss item: 1.3666883707046509
test loss item: 7.144177436828613
test loss item: 7.813586711883545
test loss item: 6.361095905303955
test loss item: 25.833454132080078
test loss item: 11.886795043945312
test loss item: 7.941087245941162
test loss item: 41.5970458984375
test loss item: 8.978658676147461
test loss item: 152.70481872558594
test loss item: 8.280072212219238
test loss item: 40.83656311035156
test loss item: 31.929595947265625
test loss item: 7.145925998687744
test loss item: 7.720831394195557
test loss item: 20.765243530273438
test loss item: 0.8431825041770935
test loss item: 36.8121223449707
test loss item: 2.0887584686279297
test loss item: 7.666717529296875
test loss item: 18.209367752075195
test loss item: 0.7529315948486328
test loss item: 1.4781244993209839
test loss item: 10.07898235321045
test loss item: 5.243545055389404
test loss item: 5.531370162963867
test loss item: 4.027170658111572
test loss item: 60.67716979980469
test loss item: 2.955077886581421
test loss item: 8.937223434448242
test loss item: 83.23029327392578
test loss item: 0.8209882378578186
test loss item: 5.119174003601074
test loss item: 4.177523136138916
test loss item: 6.436301231384277
test loss item: 6.872252464294434
test loss item: 2.8275954723358154
test loss item: 5.022403717041016
test loss item: 11.198412895202637
test loss item: 64.35678100585938
test loss item: 4.291144847869873
test loss item: 4.325949668884277
test loss item: 7.919835567474365
test loss item: 8.365128517150879
test loss item: 8.267951965332031
test loss item: 4.000560283660889
test loss item: 1.0867365598678589
test loss item: 3.7332310676574707
test loss item: 1.4995241165161133
test loss item: 17.838932037353516
test loss item: 7.238837718963623
test loss item: 57.285072326660156
test loss item: 0.9476891160011292
test loss item: 5.287164211273193
test loss item: 2.0927717685699463
test loss item: 34.28313446044922
test loss item: 10.352858543395996
test loss item: 49.220340728759766
test loss item: 3.2549819946289062
test loss item: 6.598217487335205
test loss item: 7.951676368713379
test loss item: 11.18775749206543
test loss item: 9.065872192382812
Epoch [2/50], Training Loss: 1.0568, Testing Loss: 14.5033
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7753306031227112
1
train loss item: 1.9373955726623535
2
train loss item: 0.48450934886932373
3
train loss item: 1.0331743955612183
4
train loss item: 0.9824836850166321
5
train loss item: 0.5950410962104797
6
train loss item: 0.5091562271118164
7
train loss item: 1.2250372171401978
8
train loss item: 0.4754185676574707
9
train loss item: 0.4638817310333252
10
train loss item: 0.6290343999862671
11
train loss item: 0.40699079632759094
12
train loss item: 0.35201478004455566
13
train loss item: 0.8948885798454285
14
train loss item: 0.551002025604248
15
train loss item: 1.0726706981658936
16
train loss item: 0.3707497715950012
17
train loss item: 0.5284109115600586
18
train loss item: 0.6259781718254089
19
train loss item: 0.4379565119743347
20
train loss item: 0.39260342717170715
21
train loss item: 0.44246700406074524
22
train loss item: 1.5754714012145996
23
train loss item: 1.3360466957092285
24
train loss item: 0.8429235816001892
25
train loss item: 0.5052021741867065
26
train loss item: 0.4471554458141327
27
train loss item: 0.5551421046257019
28
train loss item: 0.37232908606529236
29
train loss item: 1.3058303594589233
30
train loss item: 2.943434238433838
31
train loss item: 0.9255861043930054
32
train loss item: 0.366534948348999
33
train loss item: 0.7713114023208618
34
train loss item: 0.6291664838790894
35
train loss item: 2.941950559616089
36
train loss item: 0.8456735014915466
37
train loss item: 0.4106711149215698
38
train loss item: 0.9005528688430786
39
train loss item: 0.5786586999893188
40
train loss item: 0.419023334980011
41
train loss item: 0.532141387462616
42
train loss item: 0.4084606468677521
43
train loss item: 0.43716010451316833
44
train loss item: 1.0760644674301147
45
train loss item: 0.4653486907482147
46
train loss item: 0.47002318501472473
47
train loss item: 0.6124353408813477
48
train loss item: 0.5024266242980957
49
train loss item: 0.4876966178417206
50
train loss item: 0.42818504571914673
51
train loss item: 1.415174961090088
52
train loss item: 0.36160144209861755
53
train loss item: 0.4910452663898468
54
train loss item: 2.8157169818878174
55
train loss item: 0.49821850657463074
56
train loss item: 0.5213576555252075
57
train loss item: 0.4669608771800995
58
train loss item: 0.40954363346099854
59
train loss item: 0.374469131231308
60
train loss item: 1.521458625793457
61
train loss item: 2.801856756210327
62
train loss item: 0.4282427728176117
63
train loss item: 0.5508915781974792
64
train loss item: 0.4252351224422455
65
train loss item: 0.9064849615097046
66
train loss item: 0.6466435790061951
67
train loss item: 0.4837954044342041
68
train loss item: 0.5308824181556702
69
train loss item: 0.568732500076294
70
train loss item: 0.49967238306999207
71
train loss item: 0.48316025733947754
72
train loss item: 0.4887859523296356
73
train loss item: 0.5104274153709412
74
train loss item: 0.49377527832984924
75
train loss item: 0.36806562542915344
76
train loss item: 1.330392599105835
77
train loss item: 1.7725940942764282
78
train loss item: 0.3619401156902313
79
train loss item: 0.4328960180282593
80
train loss item: 0.46722978353500366
81
train loss item: 0.4052654504776001
82
train loss item: 0.5447877645492554
83
train loss item: 1.0891740322113037
84
train loss item: 0.6080710887908936
85
train loss item: 0.9767184853553772
86
train loss item: 4.9969964027404785
87
train loss item: 0.5371173024177551
88
train loss item: 0.5534860491752625
epoch train loss: 0.8136816855227009
testing phase
test loss item: 1.1898895502090454
test loss item: 3.227278470993042
test loss item: 1.703351616859436
test loss item: 6.817262649536133
test loss item: 2.866787910461426
test loss item: 2.747218608856201
test loss item: 5.039423942565918
test loss item: 2.2433838844299316
test loss item: 1.010989785194397
test loss item: 1.4505813121795654
test loss item: 6.24137020111084
test loss item: 6.7986884117126465
test loss item: 1.7276753187179565
test loss item: 0.6354014277458191
test loss item: 2.7934041023254395
test loss item: 3.9495513439178467
test loss item: 0.761549711227417
test loss item: 2.0514755249023438
test loss item: 2.8010435104370117
test loss item: 0.4654821455478668
test loss item: 2.1977763175964355
test loss item: 6.5736775398254395
test loss item: 6.604550361633301
test loss item: 2.591827630996704
test loss item: 2.015840768814087
test loss item: 2.14677357673645
test loss item: 1.139235496520996
test loss item: 2.7506701946258545
test loss item: 2.765331745147705
test loss item: 1.8219664096832275
test loss item: 6.111570358276367
test loss item: 3.866427421569824
test loss item: 2.6664106845855713
test loss item: 7.155632495880127
test loss item: 2.893854856491089
test loss item: 22.10896873474121
test loss item: 2.69307279586792
test loss item: 11.15649127960205
test loss item: 5.8358025550842285
test loss item: 2.7186625003814697
test loss item: 2.518120527267456
test loss item: 6.929379940032959
test loss item: 0.7523263692855835
test loss item: 6.4873456954956055
test loss item: 1.73220694065094
test loss item: 2.571293354034424
test loss item: 6.46089506149292
test loss item: 0.5021698474884033
test loss item: 1.1642178297042847
test loss item: 3.6170618534088135
test loss item: 1.5473241806030273
test loss item: 1.8063280582427979
test loss item: 1.7111142873764038
test loss item: 10.242157936096191
test loss item: 1.8909834623336792
test loss item: 3.651387929916382
test loss item: 12.682930946350098
test loss item: 0.6178389191627502
test loss item: 1.6577080488204956
test loss item: 1.847389817237854
test loss item: 2.2478511333465576
test loss item: 2.198476552963257
test loss item: 1.5555464029312134
test loss item: 1.6990206241607666
test loss item: 4.155920028686523
test loss item: 10.821247100830078
test loss item: 1.6911855936050415
test loss item: 1.5414832830429077
test loss item: 2.787243127822876
test loss item: 2.8590431213378906
test loss item: 2.7159781455993652
test loss item: 1.8706729412078857
test loss item: 0.8868982195854187
test loss item: 1.1505937576293945
test loss item: 0.7609840631484985
test loss item: 6.275387287139893
test loss item: 2.607560396194458
test loss item: 13.385534286499023
test loss item: 0.8619686961174011
test loss item: 2.345057249069214
test loss item: 1.5323015451431274
test loss item: 7.98535680770874
test loss item: 3.431525468826294
test loss item: 10.907723426818848
test loss item: 1.8699524402618408
test loss item: 1.7947497367858887
test loss item: 2.6904611587524414
test loss item: 3.8197081089019775
test loss item: 2.529606342315674
Epoch [3/50], Training Loss: 0.8137, Testing Loss: 3.6596
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6983966827392578
1
train loss item: 1.8895678520202637
2
train loss item: 0.4078570008277893
3
train loss item: 1.0575674772262573
4
train loss item: 1.0385847091674805
5
train loss item: 0.52247154712677
6
train loss item: 0.41971778869628906
7
train loss item: 1.2598832845687866
8
train loss item: 0.4240264296531677
9
train loss item: 0.4619661271572113
10
train loss item: 0.6555545926094055
11
train loss item: 0.3903302252292633
12
train loss item: 0.3221556842327118
13
train loss item: 0.8316524028778076
14
train loss item: 0.49575939774513245
15
train loss item: 0.9327904582023621
16
train loss item: 0.34123098850250244
17
train loss item: 0.456911563873291
18
train loss item: 0.5701507925987244
19
train loss item: 0.400150328874588
20
train loss item: 0.35642391443252563
21
train loss item: 0.37708383798599243
22
train loss item: 1.3951287269592285
23
train loss item: 1.353918194770813
24
train loss item: 0.7554471492767334
25
train loss item: 0.4307234287261963
26
train loss item: 0.38092318177223206
27
train loss item: 0.526859700679779
28
train loss item: 0.33884429931640625
29
train loss item: 1.1439898014068604
30
train loss item: 3.0326292514801025
31
train loss item: 0.9294781684875488
32
train loss item: 0.41547268629074097
33
train loss item: 0.787726879119873
34
train loss item: 0.42948347330093384
35
train loss item: 2.976135492324829
36
train loss item: 0.7441644072532654
37
train loss item: 0.3760562539100647
38
train loss item: 0.8047831654548645
39
train loss item: 0.5277100205421448
40
train loss item: 0.31911784410476685
41
train loss item: 0.5406798124313354
42
train loss item: 0.3650849461555481
43
train loss item: 0.4221801161766052
44
train loss item: 1.0753355026245117
45
train loss item: 0.40256625413894653
46
train loss item: 0.41455337405204773
47
train loss item: 0.5339937806129456
48
train loss item: 0.4749167859554291
49
train loss item: 0.42313259840011597
50
train loss item: 0.4188964366912842
51
train loss item: 1.32359778881073
52
train loss item: 0.3932873606681824
53
train loss item: 0.3888820707798004
54
train loss item: 2.866298198699951
55
train loss item: 0.4193289875984192
56
train loss item: 0.5133644342422485
57
train loss item: 0.4223174750804901
58
train loss item: 0.39009371399879456
59
train loss item: 0.41822704672813416
60
train loss item: 1.3682383298873901
61
train loss item: 2.8778650760650635
62
train loss item: 0.43743205070495605
63
train loss item: 0.4907551407814026
64
train loss item: 0.42146041989326477
65
train loss item: 0.7421570420265198
66
train loss item: 0.6023702025413513
67
train loss item: 0.42771679162979126
68
train loss item: 0.4219704866409302
69
train loss item: 0.50228351354599
70
train loss item: 0.43160462379455566
71
train loss item: 0.31944015622138977
72
train loss item: 0.47537699341773987
73
train loss item: 0.43796253204345703
74
train loss item: 0.42013832926750183
75
train loss item: 0.35526344180107117
76
train loss item: 1.3376119136810303
77
train loss item: 1.6430391073226929
78
train loss item: 0.35548120737075806
79
train loss item: 0.40230482816696167
80
train loss item: 0.3651096820831299
81
train loss item: 0.35108229517936707
82
train loss item: 0.4823961555957794
83
train loss item: 0.9637957215309143
84
train loss item: 0.5152562856674194
85
train loss item: 0.9517197608947754
86
train loss item: 5.090278625488281
87
train loss item: 0.4349687993526459
88
train loss item: 0.48934024572372437
epoch train loss: 0.7674155241987678
testing phase
test loss item: 0.28967922925949097
test loss item: 0.4661613702774048
test loss item: 1.0977962017059326
test loss item: 0.8411714434623718
test loss item: 0.6092407703399658
test loss item: 0.47013771533966064
test loss item: 2.278618812561035
test loss item: 0.6200326681137085
test loss item: 0.37713998556137085
test loss item: 0.6189283728599548
test loss item: 1.831299066543579
test loss item: 0.8438577055931091
test loss item: 0.34918975830078125
test loss item: 0.4146531820297241
test loss item: 0.4850887060165405
test loss item: 0.5186068415641785
test loss item: 0.36682209372520447
test loss item: 0.819593071937561
test loss item: 0.8401731848716736
test loss item: 0.3737275004386902
test loss item: 1.3717535734176636
test loss item: 0.8750786185264587
test loss item: 0.9892051219940186
test loss item: 0.41947486996650696
test loss item: 0.41661784052848816
test loss item: 0.44115975499153137
test loss item: 0.4562559425830841
test loss item: 0.5141705274581909
test loss item: 0.6226191520690918
test loss item: 0.5139089226722717
test loss item: 1.5652313232421875
test loss item: 0.5349465608596802
test loss item: 0.4094506502151489
test loss item: 1.2278848886489868
test loss item: 0.8185349106788635
test loss item: 2.2731616497039795
test loss item: 1.0341012477874756
test loss item: 3.327460765838623
test loss item: 1.0333184003829956
test loss item: 0.5245742797851562
test loss item: 0.4867233335971832
test loss item: 0.8754964470863342
test loss item: 0.5635008215904236
test loss item: 0.7994691133499146
test loss item: 1.0707730054855347
test loss item: 0.6088303327560425
test loss item: 0.9605841636657715
test loss item: 0.4078099727630615
test loss item: 0.7924291491508484
test loss item: 1.206511378288269
test loss item: 0.5406088829040527
test loss item: 0.3122153878211975
test loss item: 0.4157840311527252
test loss item: 1.1872050762176514
test loss item: 0.5935589671134949
test loss item: 1.7029435634613037
test loss item: 1.5778933763504028
test loss item: 0.4830836355686188
test loss item: 0.39540863037109375
test loss item: 0.40097305178642273
test loss item: 0.7240050435066223
test loss item: 0.3896774351596832
test loss item: 0.3439917266368866
test loss item: 0.3831360638141632
test loss item: 1.7959402799606323
test loss item: 1.275413155555725
test loss item: 0.4710361063480377
test loss item: 0.39208316802978516
test loss item: 1.0246944427490234
test loss item: 0.6592327952384949
test loss item: 0.39657318592071533
test loss item: 1.0477616786956787
test loss item: 0.5025136470794678
test loss item: 0.4581690728664398
test loss item: 0.2774539291858673
test loss item: 0.8348803520202637
test loss item: 0.4248865842819214
test loss item: 3.6898858547210693
test loss item: 0.700594425201416
test loss item: 0.45810234546661377
test loss item: 0.27888163924217224
test loss item: 2.071094274520874
test loss item: 1.2470712661743164
test loss item: 2.6188879013061523
test loss item: 0.39289888739585876
test loss item: 0.4359573423862457
test loss item: 0.3628467321395874
test loss item: 0.47481682896614075
test loss item: 0.4011151194572449
Epoch [4/50], Training Loss: 0.7674, Testing Loss: 0.8292
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6756762266159058
1
train loss item: 1.8227037191390991
2
train loss item: 0.37234199047088623
3
train loss item: 0.9910301566123962
4
train loss item: 0.918097198009491
5
train loss item: 0.512028694152832
6
train loss item: 0.4177883267402649
7
train loss item: 1.2159864902496338
8
train loss item: 0.3952226936817169
9
train loss item: 0.4213326573371887
10
train loss item: 0.5899624228477478
11
train loss item: 0.3660014867782593
12
train loss item: 0.28829464316368103
13
train loss item: 0.7883545160293579
14
train loss item: 0.4807130694389343
15
train loss item: 0.8995276093482971
16
train loss item: 0.2694915235042572
17
train loss item: 0.4307445287704468
18
train loss item: 0.5323776006698608
19
train loss item: 0.3909452557563782
20
train loss item: 0.3488242030143738
21
train loss item: 0.333306223154068
22
train loss item: 1.3327043056488037
23
train loss item: 1.2924134731292725
24
train loss item: 0.7219944000244141
25
train loss item: 0.3935707211494446
26
train loss item: 0.38187772035598755
27
train loss item: 0.4978334307670593
28
train loss item: 0.2726540267467499
29
train loss item: 1.0741456747055054
30
train loss item: 2.9715728759765625
31
train loss item: 0.8734990358352661
32
train loss item: 0.3875848054885864
33
train loss item: 0.7251477241516113
34
train loss item: 0.4227859377861023
35
train loss item: 2.9328434467315674
36
train loss item: 0.6845158934593201
37
train loss item: 0.37049177289009094
38
train loss item: 0.7201752066612244
39
train loss item: 0.4930780529975891
40
train loss item: 0.3014034926891327
41
train loss item: 0.49657267332077026
42
train loss item: 0.3604181408882141
43
train loss item: 0.3855047821998596
44
train loss item: 1.0297542810440063
45
train loss item: 0.3466341495513916
46
train loss item: 0.3548533022403717
47
train loss item: 0.49289366602897644
48
train loss item: 0.4337422847747803
49
train loss item: 0.35309314727783203
50
train loss item: 0.4112716615200043
51
train loss item: 1.267536997795105
52
train loss item: 0.3253319263458252
53
train loss item: 0.35252681374549866
54
train loss item: 2.8232924938201904
55
train loss item: 0.41496580839157104
56
train loss item: 0.478279173374176
57
train loss item: 0.4213694632053375
58
train loss item: 0.3638981580734253
59
train loss item: 0.36891600489616394
60
train loss item: 1.3064498901367188
61
train loss item: 2.8205347061157227
62
train loss item: 0.40030649304389954
63
train loss item: 0.47829553484916687
64
train loss item: 0.3820277452468872
65
train loss item: 0.7256078124046326
66
train loss item: 0.5505028963088989
67
train loss item: 0.4006686210632324
68
train loss item: 0.41346731781959534
69
train loss item: 0.4650878608226776
70
train loss item: 0.4030076265335083
71
train loss item: 0.2978228032588959
72
train loss item: 0.41744598746299744
73
train loss item: 0.4164917767047882
74
train loss item: 0.366365522146225
75
train loss item: 0.3059244155883789
76
train loss item: 1.2832101583480835
77
train loss item: 1.5993642807006836
78
train loss item: 0.2903710901737213
79
train loss item: 0.39616137742996216
80
train loss item: 0.3380153477191925
81
train loss item: 0.3419483006000519
82
train loss item: 0.4190782904624939
83
train loss item: 0.9058240056037903
84
train loss item: 0.4595102071762085
85
train loss item: 0.9038756489753723
86
train loss item: 5.041164875030518
87
train loss item: 0.3814472258090973
88
train loss item: 0.4677489101886749
epoch train loss: 0.727748594257269
testing phase
test loss item: 0.2521902620792389
test loss item: 0.2463563233613968
test loss item: 0.9279228448867798
test loss item: 0.4478243589401245
test loss item: 0.44093936681747437
test loss item: 0.26315709948539734
test loss item: 1.881082534790039
test loss item: 0.4942623972892761
test loss item: 0.3242061138153076
test loss item: 0.5410722494125366
test loss item: 1.3805214166641235
test loss item: 0.39780691266059875
test loss item: 0.25827130675315857
test loss item: 0.36585739254951477
test loss item: 0.3131088614463806
test loss item: 0.23211047053337097
test loss item: 0.3411058783531189
test loss item: 0.7314189672470093
test loss item: 0.7001429796218872
test loss item: 0.3340034782886505
test loss item: 1.2429800033569336
test loss item: 0.530864417552948
test loss item: 0.5760958194732666
test loss item: 0.263040691614151
test loss item: 0.32923972606658936
test loss item: 0.32115480303764343
test loss item: 0.41688182950019836
test loss item: 0.334978848695755
test loss item: 0.46883952617645264
test loss item: 0.4418793022632599
test loss item: 1.155320405960083
test loss item: 0.2260134518146515
test loss item: 0.25187963247299194
test loss item: 0.9095188975334167
test loss item: 0.6939302682876587
test loss item: 0.9157507419586182
test loss item: 0.9040374159812927
test loss item: 2.472788095474243
test loss item: 0.762606680393219
test loss item: 0.3699493110179901
test loss item: 0.37357962131500244
test loss item: 0.4297417402267456
test loss item: 0.5317898988723755
test loss item: 0.41653186082839966
test loss item: 0.9710813164710999
test loss item: 0.49325644969940186
test loss item: 0.5541343688964844
test loss item: 0.3550383150577545
test loss item: 0.7064530253410339
test loss item: 0.9429876208305359
test loss item: 0.4762984812259674
test loss item: 0.21357931196689606
test loss item: 0.34673020243644714
test loss item: 0.5554941892623901
test loss item: 0.4891375005245209
test loss item: 1.3449243307113647
test loss item: 0.8914442658424377
test loss item: 0.4740852415561676
test loss item: 0.33222848176956177
test loss item: 0.31106722354888916
test loss item: 0.6115779876708984
test loss item: 0.2753452956676483
test loss item: 0.27454936504364014
test loss item: 0.31695428490638733
test loss item: 1.3981748819351196
test loss item: 0.6524821519851685
test loss item: 0.3997931182384491
test loss item: 0.337953120470047
test loss item: 0.8603289127349854
test loss item: 0.45089611411094666
test loss item: 0.2130456268787384
test loss item: 0.9769094586372375
test loss item: 0.46808573603630066
test loss item: 0.42276740074157715
test loss item: 0.23896542191505432
test loss item: 0.415365070104599
test loss item: 0.2598615884780884
test loss item: 2.823284387588501
test loss item: 0.6321609616279602
test loss item: 0.305255651473999
test loss item: 0.179587721824646
test loss item: 1.5141198635101318
test loss item: 1.013110876083374
test loss item: 1.9094038009643555
test loss item: 0.32573437690734863
test loss item: 0.337069034576416
test loss item: 0.2178996503353119
test loss item: 0.21727725863456726
test loss item: 0.2600052058696747
Epoch [5/50], Training Loss: 0.7277, Testing Loss: 0.6065
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6452210545539856
1
train loss item: 1.7289482355117798
2
train loss item: 0.3383975028991699
3
train loss item: 0.8923723697662354
4
train loss item: 0.6983416676521301
5
train loss item: 0.48326975107192993
6
train loss item: 0.3885626196861267
7
train loss item: 1.1405962705612183
8
train loss item: 0.2940666973590851
9
train loss item: 0.37343961000442505
10
train loss item: 0.5261847972869873
11
train loss item: 0.33319157361984253
12
train loss item: 0.23672565817832947
13
train loss item: 0.7501187920570374
14
train loss item: 0.43800103664398193
15
train loss item: 0.8853161334991455
16
train loss item: 0.19598424434661865
17
train loss item: 0.40613195300102234
18
train loss item: 0.4862695336341858
19
train loss item: 0.35405290126800537
20
train loss item: 0.32285600900650024
21
train loss item: 0.29618796706199646
22
train loss item: 1.2978127002716064
23
train loss item: 1.2209099531173706
24
train loss item: 0.6966726779937744
25
train loss item: 0.36117926239967346
26
train loss item: 0.3067795932292938
27
train loss item: 0.4608197510242462
28
train loss item: 0.19701042771339417
29
train loss item: 1.0397021770477295
30
train loss item: 2.852604627609253
31
train loss item: 0.7977504730224609
32
train loss item: 0.2906121611595154
33
train loss item: 0.6504994630813599
34
train loss item: 0.3805777132511139
35
train loss item: 2.8484134674072266
36
train loss item: 0.6507179141044617
37
train loss item: 0.3445320129394531
38
train loss item: 0.646823525428772
39
train loss item: 0.45959651470184326
40
train loss item: 0.2655152678489685
41
train loss item: 0.4443369209766388
42
train loss item: 0.32348504662513733
43
train loss item: 0.31999507546424866
44
train loss item: 0.9792998433113098
45
train loss item: 0.276140958070755
46
train loss item: 0.2940624952316284
47
train loss item: 0.4554567039012909
48
train loss item: 0.3804987967014313
49
train loss item: 0.30832639336586
50
train loss item: 0.37832367420196533
51
train loss item: 1.2200555801391602
52
train loss item: 0.22142644226551056
53
train loss item: 0.324291855096817
54
train loss item: 2.7330944538116455
55
train loss item: 0.34025338292121887
56
train loss item: 0.43192732334136963
57
train loss item: 0.377086877822876
58
train loss item: 0.30416861176490784
59
train loss item: 0.280572772026062
60
train loss item: 1.261991024017334
61
train loss item: 2.713313579559326
62
train loss item: 0.33034905791282654
63
train loss item: 0.44636857509613037
64
train loss item: 0.30631592869758606
65
train loss item: 0.7223644852638245
66
train loss item: 0.5028720498085022
67
train loss item: 0.3599405884742737
68
train loss item: 0.3869301974773407
69
train loss item: 0.42883527278900146
70
train loss item: 0.3731733560562134
71
train loss item: 0.2536478638648987
72
train loss item: 0.3198274075984955
73
train loss item: 0.3933572471141815
74
train loss item: 0.25255000591278076
75
train loss item: 0.24613520503044128
76
train loss item: 1.2061687707901
77
train loss item: 1.568737268447876
78
train loss item: 0.20533603429794312
79
train loss item: 0.35739952325820923
80
train loss item: 0.2686823904514313
81
train loss item: 0.2959524691104889
82
train loss item: 0.36959120631217957
83
train loss item: 0.8659226298332214
84
train loss item: 0.4310261011123657
85
train loss item: 0.8453577160835266
86
train loss item: 4.91859245300293
87
train loss item: 0.33064746856689453
88
train loss item: 0.4398626685142517
epoch train loss: 0.6716496383541086
testing phase
test loss item: 0.2514267861843109
test loss item: 0.23578743636608124
test loss item: 0.8421409130096436
test loss item: 0.4452724754810333
test loss item: 0.42802539467811584
test loss item: 0.2799590229988098
test loss item: 1.7652606964111328
test loss item: 0.4751644730567932
test loss item: 0.3089240789413452
test loss item: 0.5173994302749634
test loss item: 1.2175014019012451
test loss item: 0.3869268298149109
test loss item: 0.2465045303106308
test loss item: 0.3696826100349426
test loss item: 0.30334359407424927
test loss item: 0.2102905660867691
test loss item: 0.33833515644073486
test loss item: 0.6976087093353271
test loss item: 0.6878243088722229
test loss item: 0.31682783365249634
test loss item: 1.168135643005371
test loss item: 0.5216313004493713
test loss item: 0.6039986610412598
test loss item: 0.2496688812971115
test loss item: 0.3211801052093506
test loss item: 0.2962656021118164
test loss item: 0.3963067829608917
test loss item: 0.32584360241889954
test loss item: 0.44714540243148804
test loss item: 0.4340917766094208
test loss item: 1.024134874343872
test loss item: 0.2076060175895691
test loss item: 0.24558763206005096
test loss item: 0.8633992671966553
test loss item: 0.6510388255119324
test loss item: 0.773166298866272
test loss item: 0.8732166290283203
test loss item: 2.1387643814086914
test loss item: 0.7205466628074646
test loss item: 0.37008607387542725
test loss item: 0.3637576699256897
test loss item: 0.4798930585384369
test loss item: 0.5318541526794434
test loss item: 0.4097404479980469
test loss item: 0.9212838411331177
test loss item: 0.48347416520118713
test loss item: 0.5823826193809509
test loss item: 0.2856253683567047
test loss item: 0.6546012759208679
test loss item: 0.8706822395324707
test loss item: 0.4544416666030884
test loss item: 0.2123052477836609
test loss item: 0.3372083604335785
test loss item: 0.5486108064651489
test loss item: 0.4659050703048706
test loss item: 1.2120914459228516
test loss item: 0.7781188488006592
test loss item: 0.4993182420730591
test loss item: 0.3311591148376465
test loss item: 0.30207526683807373
test loss item: 0.592872679233551
test loss item: 0.2670460343360901
test loss item: 0.26929771900177
test loss item: 0.3131084442138672
test loss item: 1.2296767234802246
test loss item: 0.6468898057937622
test loss item: 0.39008715748786926
test loss item: 0.3257649838924408
test loss item: 0.7924712896347046
test loss item: 0.4600687026977539
test loss item: 0.19059856235980988
test loss item: 0.9367020130157471
test loss item: 0.45986735820770264
test loss item: 0.41702017188072205
test loss item: 0.2349158227443695
test loss item: 0.4681587517261505
test loss item: 0.24304378032684326
test loss item: 2.377206802368164
test loss item: 0.5958420634269714
test loss item: 0.3123306632041931
test loss item: 0.16323167085647583
test loss item: 1.329064965248108
test loss item: 0.9638237953186035
test loss item: 1.6042238473892212
test loss item: 0.3282613754272461
test loss item: 0.3230404853820801
test loss item: 0.21498508751392365
test loss item: 0.21535086631774902
test loss item: 0.2492603063583374
Epoch [6/50], Training Loss: 0.6716, Testing Loss: 0.5685
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6208663582801819
1
train loss item: 1.6327667236328125
2
train loss item: 0.3193853795528412
3
train loss item: 0.8058030605316162
4
train loss item: 0.58958500623703
5
train loss item: 0.4652804136276245
6
train loss item: 0.35918864607810974
7
train loss item: 1.0811164379119873
8
train loss item: 0.25466981530189514
9
train loss item: 0.36075204610824585
10
train loss item: 0.4986518621444702
11
train loss item: 0.32432499527931213
12
train loss item: 0.21677842736244202
13
train loss item: 0.7221936583518982
14
train loss item: 0.4171341359615326
15
train loss item: 0.8644335269927979
16
train loss item: 0.18400153517723083
17
train loss item: 0.4137260317802429
18
train loss item: 0.4535277783870697
19
train loss item: 0.33846673369407654
20
train loss item: 0.29837724566459656
21
train loss item: 0.2901039123535156
22
train loss item: 1.2509926557540894
23
train loss item: 1.1673998832702637
24
train loss item: 0.6697906255722046
25
train loss item: 0.36520665884017944
26
train loss item: 0.28737688064575195
27
train loss item: 0.4359801411628723
28
train loss item: 0.18188732862472534
29
train loss item: 1.0065757036209106
30
train loss item: 2.7441580295562744
31
train loss item: 0.7459144592285156
32
train loss item: 0.21404866874217987
33
train loss item: 0.5948442220687866
34
train loss item: 0.3749246299266815
35
train loss item: 2.774412155151367
36
train loss item: 0.628724217414856
37
train loss item: 0.332899272441864
38
train loss item: 0.5903997421264648
39
train loss item: 0.4397202432155609
40
train loss item: 0.2694013714790344
41
train loss item: 0.41962361335754395
42
train loss item: 0.2992267906665802
43
train loss item: 0.28080520033836365
44
train loss item: 0.9428375959396362
45
train loss item: 0.24122819304466248
46
train loss item: 0.25512638688087463
47
train loss item: 0.44452837109565735
48
train loss item: 0.35549265146255493
49
train loss item: 0.3148382306098938
50
train loss item: 0.35431304574012756
51
train loss item: 1.1735419034957886
52
train loss item: 0.19849374890327454
53
train loss item: 0.3432384133338928
54
train loss item: 2.6534955501556396
55
train loss item: 0.2861960530281067
56
train loss item: 0.40684768557548523
57
train loss item: 0.33878329396247864
58
train loss item: 0.2608513832092285
59
train loss item: 0.23534061014652252
60
train loss item: 1.206522822380066
61
train loss item: 2.6270031929016113
62
train loss item: 0.3084268569946289
63
train loss item: 0.41363388299942017
64
train loss item: 0.24848933517932892
65
train loss item: 0.71045982837677
66
train loss item: 0.47698870301246643
67
train loss item: 0.3393414318561554
68
train loss item: 0.37059080600738525
69
train loss item: 0.41112020611763
70
train loss item: 0.3794271945953369
71
train loss item: 0.24603167176246643
72
train loss item: 0.28612029552459717
73
train loss item: 0.3883107304573059
74
train loss item: 0.24127180874347687
75
train loss item: 0.22147731482982635
76
train loss item: 1.142932653427124
77
train loss item: 1.5296545028686523
78
train loss item: 0.18140393495559692
79
train loss item: 0.32386544346809387
80
train loss item: 0.23611871898174286
81
train loss item: 0.2937258780002594
82
train loss item: 0.35281169414520264
83
train loss item: 0.8258532881736755
84
train loss item: 0.4186643064022064
85
train loss item: 0.8044732809066772
86
train loss item: 4.810916423797607
87
train loss item: 0.3477106988430023
88
train loss item: 0.413939893245697
epoch train loss: 0.6398638892039824
testing phase
test loss item: 0.25328224897384644
test loss item: 0.23399780690670013
test loss item: 0.7863457798957825
test loss item: 0.368974506855011
test loss item: 0.4158589541912079
test loss item: 0.28650444746017456
test loss item: 1.6987099647521973
test loss item: 0.4847869873046875
test loss item: 0.30651775002479553
test loss item: 0.5041671395301819
test loss item: 1.1632639169692993
test loss item: 0.2955278158187866
test loss item: 0.24966846406459808
test loss item: 0.37091028690338135
test loss item: 0.29675668478012085
test loss item: 0.19261586666107178
test loss item: 0.3354567885398865
test loss item: 0.658467710018158
test loss item: 0.7020514011383057
test loss item: 0.3365957736968994
test loss item: 1.0800809860229492
test loss item: 0.4553881585597992
test loss item: 0.5420660376548767
test loss item: 0.24936026334762573
test loss item: 0.3089473247528076
test loss item: 0.2937248945236206
test loss item: 0.4003644585609436
test loss item: 0.32294631004333496
test loss item: 0.43510717153549194
test loss item: 0.4349900484085083
test loss item: 0.980178952217102
test loss item: 0.1922481507062912
test loss item: 0.24669389426708221
test loss item: 0.7876656651496887
test loss item: 0.61049485206604
test loss item: 0.6336287260055542
test loss item: 0.8631623387336731
test loss item: 2.0098345279693604
test loss item: 0.6577877998352051
test loss item: 0.3688564598560333
test loss item: 0.3540785312652588
test loss item: 0.41334807872772217
test loss item: 0.5202460289001465
test loss item: 0.3289024531841278
test loss item: 0.8626096248626709
test loss item: 0.48132169246673584
test loss item: 0.5258878469467163
test loss item: 0.3278862535953522
test loss item: 0.6146120429039001
test loss item: 0.8574888110160828
test loss item: 0.4361375868320465
test loss item: 0.23381556570529938
test loss item: 0.32944661378860474
test loss item: 0.4002256691455841
test loss item: 0.44654610753059387
test loss item: 1.1548115015029907
test loss item: 0.6924795508384705
test loss item: 0.48410564661026
test loss item: 0.32444435358047485
test loss item: 0.2960008680820465
test loss item: 0.575468897819519
test loss item: 0.25710317492485046
test loss item: 0.27240630984306335
test loss item: 0.30408579111099243
test loss item: 1.13593590259552
test loss item: 0.5057934522628784
test loss item: 0.3816291093826294
test loss item: 0.3176214396953583
test loss item: 0.7442411184310913
test loss item: 0.5109080076217651
test loss item: 0.17674438655376434
test loss item: 0.9177349805831909
test loss item: 0.43562421202659607
test loss item: 0.4124358594417572
test loss item: 0.23801030218601227
test loss item: 0.4064955413341522
test loss item: 0.24171008169651031
test loss item: 2.1690943241119385
test loss item: 0.5672817230224609
test loss item: 0.3174498677253723
test loss item: 0.15501831471920013
test loss item: 1.2530807256698608
test loss item: 0.9615751504898071
test loss item: 1.4807672500610352
test loss item: 0.32790207862854004
test loss item: 0.32940152287483215
test loss item: 0.204376220703125
test loss item: 0.20055340230464935
test loss item: 0.25986024737358093
Epoch [7/50], Training Loss: 0.6399, Testing Loss: 0.5389
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6005350351333618
1
train loss item: 1.5514355897903442
2
train loss item: 0.3006862998008728
3
train loss item: 0.7503088712692261
4
train loss item: 0.5332026481628418
5
train loss item: 0.4506199359893799
6
train loss item: 0.33452343940734863
7
train loss item: 1.0390982627868652
8
train loss item: 0.2612323462963104
9
train loss item: 0.3621290922164917
10
train loss item: 0.4872727692127228
11
train loss item: 0.3368585407733917
12
train loss item: 0.2147115021944046
13
train loss item: 0.6922715306282043
14
train loss item: 0.4084062874317169
15
train loss item: 0.8324126601219177
16
train loss item: 0.18377695977687836
17
train loss item: 0.41638991236686707
18
train loss item: 0.4313204288482666
19
train loss item: 0.34050583839416504
20
train loss item: 0.28871989250183105
21
train loss item: 0.28100109100341797
22
train loss item: 1.196636438369751
23
train loss item: 1.130042552947998
24
train loss item: 0.64091956615448
25
train loss item: 0.3553757965564728
26
train loss item: 0.2989475131034851
27
train loss item: 0.41955286264419556
28
train loss item: 0.181097149848938
29
train loss item: 0.9636754989624023
30
train loss item: 2.667633295059204
31
train loss item: 0.7108197808265686
32
train loss item: 0.2119992971420288
33
train loss item: 0.5540957450866699
34
train loss item: 0.34873494505882263
35
train loss item: 2.722177743911743
36
train loss item: 0.6042764782905579
37
train loss item: 0.3363940119743347
38
train loss item: 0.5467432141304016
39
train loss item: 0.42083466053009033
40
train loss item: 0.26340165734291077
41
train loss item: 0.40876612067222595
42
train loss item: 0.29846152663230896
43
train loss item: 0.26552045345306396
44
train loss item: 0.9126308560371399
45
train loss item: 0.2240470051765442
46
train loss item: 0.23971202969551086
47
train loss item: 0.4315193295478821
48
train loss item: 0.3436274826526642
49
train loss item: 0.31174206733703613
50
train loss item: 0.3491704761981964
51
train loss item: 1.1253582239151
52
train loss item: 0.200222447514534
53
train loss item: 0.3259042203426361
54
train loss item: 2.599846601486206
55
train loss item: 0.26549211144447327
56
train loss item: 0.39387747645378113
57
train loss item: 0.3249340057373047
58
train loss item: 0.24916549026966095
59
train loss item: 0.22602930665016174
60
train loss item: 1.139011263847351
61
train loss item: 2.5696566104888916
62
train loss item: 0.31132686138153076
63
train loss item: 0.3979695439338684
64
train loss item: 0.2307855784893036
65
train loss item: 0.6810782551765442
66
train loss item: 0.46563515067100525
67
train loss item: 0.3277639150619507
68
train loss item: 0.36771178245544434
69
train loss item: 0.4009914994239807
70
train loss item: 0.3744887113571167
71
train loss item: 0.2382773756980896
72
train loss item: 0.2837296426296234
73
train loss item: 0.3862657845020294
74
train loss item: 0.24189673364162445
75
train loss item: 0.2092791646718979
76
train loss item: 1.0974056720733643
77
train loss item: 1.4893975257873535
78
train loss item: 0.18096472322940826
79
train loss item: 0.31747496128082275
80
train loss item: 0.22049176692962646
81
train loss item: 0.2882404923439026
82
train loss item: 0.3403073847293854
83
train loss item: 0.7820855975151062
84
train loss item: 0.40775540471076965
85
train loss item: 0.7709012627601624
86
train loss item: 4.7397589683532715
87
train loss item: 0.32996097207069397
88
train loss item: 0.3938354551792145
epoch train loss: 0.6196769936366028
testing phase
test loss item: 0.24664191901683807
test loss item: 0.21502646803855896
test loss item: 0.7236920595169067
test loss item: 0.3011724352836609
test loss item: 0.38219791650772095
test loss item: 0.26222193241119385
test loss item: 1.6663777828216553
test loss item: 0.513744592666626
test loss item: 0.289548397064209
test loss item: 0.46857959032058716
test loss item: 1.129069447517395
test loss item: 0.21964554488658905
test loss item: 0.2255939543247223
test loss item: 0.3554159700870514
test loss item: 0.271467924118042
test loss item: 0.16800333559513092
test loss item: 0.32425421476364136
test loss item: 0.5946148037910461
test loss item: 0.7147129774093628
test loss item: 0.3179295063018799
test loss item: 0.9588596820831299
test loss item: 0.40579938888549805
test loss item: 0.4308619797229767
test loss item: 0.23743177950382233
test loss item: 0.2908378839492798
test loss item: 0.28787317872047424
test loss item: 0.38961929082870483
test loss item: 0.2988411784172058
test loss item: 0.4112653136253357
test loss item: 0.4065406322479248
test loss item: 0.9504793286323547
test loss item: 0.14757773280143738
test loss item: 0.23262788355350494
test loss item: 0.7091859579086304
test loss item: 0.5548900961875916
test loss item: 0.5682107210159302
test loss item: 0.8592382073402405
test loss item: 1.9178292751312256
test loss item: 0.595458447933197
test loss item: 0.34999871253967285
test loss item: 0.34007593989372253
test loss item: 0.30612826347351074
test loss item: 0.4736967086791992
test loss item: 0.26281997561454773
test loss item: 0.7755277752876282
test loss item: 0.45211219787597656
test loss item: 0.42043375968933105
test loss item: 0.31317880749702454
test loss item: 0.5690016150474548
test loss item: 0.8462586998939514
test loss item: 0.3974609673023224
test loss item: 0.20326028764247894
test loss item: 0.3090575635433197
test loss item: 0.26142776012420654
test loss item: 0.40613386034965515
test loss item: 1.106000542640686
test loss item: 0.6547552347183228
test loss item: 0.4023006856441498
test loss item: 0.2969154417514801
test loss item: 0.27714264392852783
test loss item: 0.5277537107467651
test loss item: 0.24254511296749115
test loss item: 0.26397958397865295
test loss item: 0.2910301983356476
test loss item: 1.06386137008667
test loss item: 0.38496270775794983
test loss item: 0.35274308919906616
test loss item: 0.31125450134277344
test loss item: 0.6957356333732605
test loss item: 0.5307685136795044
test loss item: 0.1623942106962204
test loss item: 0.9160824418067932
test loss item: 0.3774813115596771
test loss item: 0.40231260657310486
test loss item: 0.22766444087028503
test loss item: 0.29774338006973267
test loss item: 0.2321077138185501
test loss item: 2.0338950157165527
test loss item: 0.5312429070472717
test loss item: 0.29751288890838623
test loss item: 0.15327829122543335
test loss item: 1.2095121145248413
test loss item: 0.9550616145133972
test loss item: 1.4018468856811523
test loss item: 0.30933329463005066
test loss item: 0.32419922947883606
test loss item: 0.19147741794586182
test loss item: 0.17540690302848816
test loss item: 0.2703246474266052
Epoch [8/50], Training Loss: 0.6197, Testing Loss: 0.5011
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5743954181671143
1
train loss item: 1.4916267395019531
2
train loss item: 0.27790725231170654
3
train loss item: 0.7140593528747559
4
train loss item: 0.49876686930656433
5
train loss item: 0.4275818169116974
6
train loss item: 0.306278258562088
7
train loss item: 1.003696322441101
8
train loss item: 0.233316108584404
9
train loss item: 0.34300264716148376
10
train loss item: 0.46609407663345337
11
train loss item: 0.33860132098197937
12
train loss item: 0.20459496974945068
13
train loss item: 0.6516890525817871
14
train loss item: 0.3909648656845093
15
train loss item: 0.7942982912063599
16
train loss item: 0.16891592741012573
17
train loss item: 0.3754238784313202
18
train loss item: 0.40834012627601624
19
train loss item: 0.3302743136882782
20
train loss item: 0.2852264940738678
21
train loss item: 0.23983778059482574
22
train loss item: 1.1512608528137207
23
train loss item: 1.099772572517395
24
train loss item: 0.6158661246299744
25
train loss item: 0.3123924434185028
26
train loss item: 0.27463477849960327
27
train loss item: 0.3966401219367981
28
train loss item: 0.16410569846630096
29
train loss item: 0.9174605011940002
30
train loss item: 2.614682674407959
31
train loss item: 0.6719673275947571
32
train loss item: 0.20240092277526855
33
train loss item: 0.5133413076400757
34
train loss item: 0.29952138662338257
35
train loss item: 2.682870626449585
36
train loss item: 0.5726163387298584
37
train loss item: 0.3360234200954437
38
train loss item: 0.5089361071586609
39
train loss item: 0.39433014392852783
40
train loss item: 0.22762982547283173
41
train loss item: 0.3863799273967743
42
train loss item: 0.2908063530921936
43
train loss item: 0.24107900261878967
44
train loss item: 0.877792239189148
45
train loss item: 0.20571935176849365
46
train loss item: 0.21620884537696838
47
train loss item: 0.4042266309261322
48
train loss item: 0.3132947087287903
49
train loss item: 0.2678401470184326
50
train loss item: 0.34227150678634644
51
train loss item: 1.0801708698272705
52
train loss item: 0.1831454187631607
53
train loss item: 0.2618120014667511
54
train loss item: 2.561413288116455
55
train loss item: 0.24399928748607635
56
train loss item: 0.3725316524505615
57
train loss item: 0.3198336064815521
58
train loss item: 0.2319193035364151
59
train loss item: 0.2155981808900833
60
train loss item: 1.0776489973068237
61
train loss item: 2.524946689605713
62
train loss item: 0.29267480969429016
63
train loss item: 0.39422693848609924
64
train loss item: 0.21531882882118225
65
train loss item: 0.6449991464614868
66
train loss item: 0.45068392157554626
67
train loss item: 0.3019859790802002
68
train loss item: 0.35489845275878906
69
train loss item: 0.38172784447669983
70
train loss item: 0.33799639344215393
71
train loss item: 0.21700140833854675
72
train loss item: 0.2585693299770355
73
train loss item: 0.36577698588371277
74
train loss item: 0.1993708610534668
75
train loss item: 0.19013698399066925
76
train loss item: 1.0623209476470947
77
train loss item: 1.4598063230514526
78
train loss item: 0.17003242671489716
79
train loss item: 0.31991639733314514
80
train loss item: 0.20348985493183136
81
train loss item: 0.25250622630119324
82
train loss item: 0.30849921703338623
83
train loss item: 0.7397314310073853
84
train loss item: 0.388505756855011
85
train loss item: 0.7360994815826416
86
train loss item: 4.689479351043701
87
train loss item: 0.26612716913223267
88
train loss item: 0.3776043951511383
epoch train loss: 0.5919041564960158
testing phase
test loss item: 0.2374350130558014
test loss item: 0.204989954829216
test loss item: 0.6638544797897339
test loss item: 0.2869490087032318
test loss item: 0.348295658826828
test loss item: 0.23729656636714935
test loss item: 1.6404938697814941
test loss item: 0.5504173040390015
test loss item: 0.27005258202552795
test loss item: 0.4351678192615509
test loss item: 1.0920649766921997
test loss item: 0.22052595019340515
test loss item: 0.21198345720767975
test loss item: 0.3387492597103119
test loss item: 0.24627642333507538
test loss item: 0.17498961091041565
test loss item: 0.3203371465206146
test loss item: 0.533289909362793
test loss item: 0.7220916748046875
test loss item: 0.29822301864624023
test loss item: 0.848271906375885
test loss item: 0.40806519985198975
test loss item: 0.3575718104839325
test loss item: 0.22678734362125397
test loss item: 0.27688032388687134
test loss item: 0.2795330882072449
test loss item: 0.3735771179199219
test loss item: 0.273692786693573
test loss item: 0.3873918056488037
test loss item: 0.3808150887489319
test loss item: 0.9183586835861206
test loss item: 0.13679702579975128
test loss item: 0.21988962590694427
test loss item: 0.6588415503501892
test loss item: 0.5039399862289429
test loss item: 0.5445810556411743
test loss item: 0.8568220734596252
test loss item: 1.8267126083374023
test loss item: 0.5543065071105957
test loss item: 0.33256134390830994
test loss item: 0.33095723390579224
test loss item: 0.26222553849220276
test loss item: 0.42625799775123596
test loss item: 0.25707700848579407
test loss item: 0.694802463054657
test loss item: 0.4406060576438904
test loss item: 0.35480761528015137
test loss item: 0.27570146322250366
test loss item: 0.5318006277084351
test loss item: 0.8268119692802429
test loss item: 0.35652580857276917
test loss item: 0.17673684656620026
test loss item: 0.28669947385787964
test loss item: 0.2484801858663559
test loss item: 0.3621397018432617
test loss item: 1.0510272979736328
test loss item: 0.6378564238548279
test loss item: 0.3073435425758362
test loss item: 0.2734279930591583
test loss item: 0.2589291036128998
test loss item: 0.4817594289779663
test loss item: 0.25409042835235596
test loss item: 0.25339192152023315
test loss item: 0.2826824486255646
test loss item: 0.9994363784790039
test loss item: 0.36520349979400635
test loss item: 0.33251869678497314
test loss item: 0.3075465261936188
test loss item: 0.6540760397911072
test loss item: 0.5299025177955627
test loss item: 0.16828753054141998
test loss item: 0.9232310056686401
test loss item: 0.3201812505722046
test loss item: 0.39648279547691345
test loss item: 0.22276689112186432
test loss item: 0.25015583634376526
test loss item: 0.22374768555164337
test loss item: 1.914823055267334
test loss item: 0.49858883023262024
test loss item: 0.2749374508857727
test loss item: 0.15843002498149872
test loss item: 1.171126365661621
test loss item: 0.9418053030967712
test loss item: 1.330901861190796
test loss item: 0.2835186719894409
test loss item: 0.31664368510246277
test loss item: 0.1920916885137558
test loss item: 0.17714186012744904
test loss item: 0.2690761387348175
Epoch [9/50], Training Loss: 0.5919, Testing Loss: 0.4748
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5508936643600464
1
train loss item: 1.4480639696121216
2
train loss item: 0.26590055227279663
3
train loss item: 0.6869901418685913
4
train loss item: 0.4862743318080902
5
train loss item: 0.41420409083366394
6
train loss item: 0.2989979684352875
7
train loss item: 0.9726355075836182
8
train loss item: 0.19978362321853638
9
train loss item: 0.3225676417350769
10
train loss item: 0.44241952896118164
11
train loss item: 0.33469992876052856
12
train loss item: 0.19037111103534698
13
train loss item: 0.6139525175094604
14
train loss item: 0.38179734349250793
15
train loss item: 0.7639994025230408
16
train loss item: 0.15268348157405853
17
train loss item: 0.325615793466568
18
train loss item: 0.391751229763031
19
train loss item: 0.32109349966049194
20
train loss item: 0.28855350613594055
21
train loss item: 0.1993803083896637
22
train loss item: 1.1175400018692017
23
train loss item: 1.0761607885360718
24
train loss item: 0.5969193577766418
25
train loss item: 0.263967901468277
26
train loss item: 0.24954138696193695
27
train loss item: 0.37520501017570496
28
train loss item: 0.14764048159122467
29
train loss item: 0.8792175650596619
30
train loss item: 2.5720536708831787
31
train loss item: 0.6389164924621582
32
train loss item: 0.18089191615581512
33
train loss item: 0.4808811545372009
34
train loss item: 0.25813862681388855
35
train loss item: 2.648876905441284
36
train loss item: 0.5435669422149658
37
train loss item: 0.3407854437828064
38
train loss item: 0.483424574136734
39
train loss item: 0.36770960688591003
40
train loss item: 0.20145295560359955
41
train loss item: 0.36625486612319946
42
train loss item: 0.28494200110435486
43
train loss item: 0.22571198642253876
44
train loss item: 0.8441744446754456
45
train loss item: 0.19139669835567474
46
train loss item: 0.20340484380722046
47
train loss item: 0.38348519802093506
48
train loss item: 0.28934791684150696
49
train loss item: 0.2280598133802414
50
train loss item: 0.34039679169654846
51
train loss item: 1.0428266525268555
52
train loss item: 0.16741597652435303
53
train loss item: 0.20739056169986725
54
train loss item: 2.5289976596832275
55
train loss item: 0.24627482891082764
56
train loss item: 0.35215142369270325
57
train loss item: 0.32916975021362305
58
train loss item: 0.21596363186836243
59
train loss item: 0.20892031490802765
60
train loss item: 1.0325493812561035
61
train loss item: 2.4843223094940186
62
train loss item: 0.27146753668785095
63
train loss item: 0.3972403407096863
64
train loss item: 0.20149779319763184
65
train loss item: 0.610788106918335
66
train loss item: 0.4359866678714752
67
train loss item: 0.27898016571998596
68
train loss item: 0.3364366590976715
69
train loss item: 0.3648364543914795
70
train loss item: 0.29800036549568176
71
train loss item: 0.19887591898441315
72
train loss item: 0.23473364114761353
73
train loss item: 0.3461650013923645
74
train loss item: 0.1583653837442398
75
train loss item: 0.17535030841827393
76
train loss item: 1.0354362726211548
77
train loss item: 1.438515543937683
78
train loss item: 0.15701203048229218
79
train loss item: 0.3261179029941559
80
train loss item: 0.19260744750499725
81
train loss item: 0.23409849405288696
82
train loss item: 0.28284701704978943
83
train loss item: 0.7068325281143188
84
train loss item: 0.371254563331604
85
train loss item: 0.7038127779960632
86
train loss item: 4.645908832550049
87
train loss item: 0.21204747259616852
88
train loss item: 0.370811402797699
epoch train loss: 0.5689292540041249
testing phase
test loss item: 0.2272849678993225
test loss item: 0.20338794589042664
test loss item: 0.6205271482467651
test loss item: 0.318146675825119
test loss item: 0.32119715213775635
test loss item: 0.21336260437965393
test loss item: 1.6092668771743774
test loss item: 0.5722198486328125
test loss item: 0.2576253414154053
test loss item: 0.42084845900535583
test loss item: 1.0494475364685059
test loss item: 0.2800818383693695
test loss item: 0.21884198486804962
test loss item: 0.3316322863101959
test loss item: 0.2283218502998352
test loss item: 0.19804970920085907
test loss item: 0.3212909400463104
test loss item: 0.4970603585243225
test loss item: 0.7177485227584839
test loss item: 0.2939162254333496
test loss item: 0.7877835631370544
test loss item: 0.44286710023880005
test loss item: 0.32607555389404297
test loss item: 0.21721217036247253
test loss item: 0.27033063769340515
test loss item: 0.26824086904525757
test loss item: 0.36257240176200867
test loss item: 0.2537863552570343
test loss item: 0.3705706000328064
test loss item: 0.37308165431022644
test loss item: 0.884648859500885
test loss item: 0.1620720624923706
test loss item: 0.20786456763744354
test loss item: 0.6470438241958618
test loss item: 0.47367697954177856
test loss item: 0.5441855192184448
test loss item: 0.8496650457382202
test loss item: 1.737194299697876
test loss item: 0.5440074801445007
test loss item: 0.3173810839653015
test loss item: 0.3282066285610199
test loss item: 0.25413253903388977
test loss item: 0.4016309976577759
test loss item: 0.2986319065093994
test loss item: 0.6502663493156433
test loss item: 0.44802579283714294
test loss item: 0.3331123888492584
test loss item: 0.2585006058216095
test loss item: 0.5106247663497925
test loss item: 0.8024330735206604
test loss item: 0.33572646975517273
test loss item: 0.1750064492225647
test loss item: 0.2707447111606598
test loss item: 0.3411376178264618
test loss item: 0.3334020674228668
test loss item: 0.9987852573394775
test loss item: 0.6283557415008545
test loss item: 0.2669852375984192
test loss item: 0.2625662386417389
test loss item: 0.25200918316841125
test loss item: 0.46164005994796753
test loss item: 0.2737477719783783
test loss item: 0.24352115392684937
test loss item: 0.2855801284313202
test loss item: 0.9383442997932434
test loss item: 0.43249285221099854
test loss item: 0.3271367847919464
test loss item: 0.30482470989227295
test loss item: 0.62424236536026
test loss item: 0.5150288343429565
test loss item: 0.18096166849136353
test loss item: 0.9252745509147644
test loss item: 0.29508453607559204
test loss item: 0.3944634795188904
test loss item: 0.21898196637630463
test loss item: 0.24053868651390076
test loss item: 0.2157016396522522
test loss item: 1.8007031679153442
test loss item: 0.4766644835472107
test loss item: 0.25504541397094727
test loss item: 0.15885761380195618
test loss item: 1.1276463270187378
test loss item: 0.9254928827285767
test loss item: 1.261329174041748
test loss item: 0.25902259349823
test loss item: 0.30183276534080505
test loss item: 0.19566300511360168
test loss item: 0.19488726556301117
test loss item: 0.2460114061832428
Epoch [10/50], Training Loss: 0.5689, Testing Loss: 0.4626
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 11/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5346777439117432
1
train loss item: 1.4106807708740234
2
train loss item: 0.2602550685405731
3
train loss item: 0.6625857353210449
4
train loss item: 0.4789712131023407
5
train loss item: 0.41144847869873047
6
train loss item: 0.2935319244861603
7
train loss item: 0.9448906779289246
8
train loss item: 0.19270770251750946
9
train loss item: 0.311654269695282
10
train loss item: 0.4252462685108185
11
train loss item: 0.3259658217430115
12
train loss item: 0.17791089415550232
13
train loss item: 0.5911469459533691
14
train loss item: 0.376517653465271
15
train loss item: 0.7431761026382446
16
train loss item: 0.14155052602291107
17
train loss item: 0.299151211977005
18
train loss item: 0.38288792967796326
19
train loss item: 0.31488484144210815
20
train loss item: 0.28488585352897644
21
train loss item: 0.17724648118019104
22
train loss item: 1.086606502532959
23
train loss item: 1.0569888353347778
24
train loss item: 0.5801804661750793
25
train loss item: 0.2464776486158371
26
train loss item: 0.24067924916744232
27
train loss item: 0.3559446930885315
28
train loss item: 0.14140085875988007
29
train loss item: 0.8501297831535339
30
train loss item: 2.528212070465088
31
train loss item: 0.6223792433738708
32
train loss item: 0.1644730567932129
33
train loss item: 0.4644816517829895
34
train loss item: 0.23012684285640717
35
train loss item: 2.6139113903045654
36
train loss item: 0.5235388875007629
37
train loss item: 0.3482149839401245
38
train loss item: 0.4761417806148529
39
train loss item: 0.3441483676433563
40
train loss item: 0.20465904474258423
41
train loss item: 0.3532889187335968
42
train loss item: 0.28311336040496826
43
train loss item: 0.22281910479068756
44
train loss item: 0.816307783126831
45
train loss item: 0.1832820177078247
46
train loss item: 0.19921737909317017
47
train loss item: 0.37884753942489624
48
train loss item: 0.2811490297317505
49
train loss item: 0.214413121342659
50
train loss item: 0.33820822834968567
51
train loss item: 1.0109350681304932
52
train loss item: 0.1659216284751892
53
train loss item: 0.19522225856781006
54
train loss item: 2.4947662353515625
55
train loss item: 0.2489798367023468
56
train loss item: 0.33846768736839294
57
train loss item: 0.3368053436279297
58
train loss item: 0.20802602171897888
59
train loss item: 0.20775139331817627
60
train loss item: 0.9988077282905579
61
train loss item: 2.4445865154266357
62
train loss item: 0.2618447244167328
63
train loss item: 0.39173707365989685
64
train loss item: 0.19773055613040924
65
train loss item: 0.5843738317489624
66
train loss item: 0.4263222813606262
67
train loss item: 0.2656988203525543
68
train loss item: 0.31875157356262207
69
train loss item: 0.35711610317230225
70
train loss item: 0.28431791067123413
71
train loss item: 0.1842103749513626
72
train loss item: 0.23466195166110992
73
train loss item: 0.3391789197921753
74
train loss item: 0.151005357503891
75
train loss item: 0.16772949695587158
76
train loss item: 1.0139271020889282
77
train loss item: 1.4143823385238647
78
train loss item: 0.14576494693756104
79
train loss item: 0.32379022240638733
80
train loss item: 0.18112219870090485
81
train loss item: 0.2577565312385559
82
train loss item: 0.2725377082824707
83
train loss item: 0.6811457872390747
84
train loss item: 0.36514076590538025
85
train loss item: 0.6760604977607727
86
train loss item: 4.599111557006836
87
train loss item: 0.20130428671836853
88
train loss item: 0.3710324764251709
epoch train loss: 0.5551611355851206
testing phase
test loss item: 0.20947614312171936
test loss item: 0.18972431123256683
test loss item: 0.5876334309577942
test loss item: 0.3333742618560791
test loss item: 0.29524311423301697
test loss item: 0.18569415807724
test loss item: 1.5645729303359985
test loss item: 0.5651399493217468
test loss item: 0.2481924146413803
test loss item: 0.41715648770332336
test loss item: 0.9941172003746033
test loss item: 0.3141297996044159
test loss item: 0.22663743793964386
test loss item: 0.32814428210258484
test loss item: 0.21050433814525604
test loss item: 0.19601358473300934
test loss item: 0.3133164942264557
test loss item: 0.4779893159866333
test loss item: 0.6971263289451599
test loss item: 0.2884930670261383
test loss item: 0.757662832736969
test loss item: 0.45840463042259216
test loss item: 0.30502331256866455
test loss item: 0.20271462202072144
test loss item: 0.2634202241897583
test loss item: 0.25667476654052734
test loss item: 0.3521999716758728
test loss item: 0.23391041159629822
test loss item: 0.3558630347251892
test loss item: 0.37490513920783997
test loss item: 0.8428052663803101
test loss item: 0.17162160575389862
test loss item: 0.18983030319213867
test loss item: 0.6378099918365479
test loss item: 0.45352181792259216
test loss item: 0.5366722345352173
test loss item: 0.830225944519043
test loss item: 1.6403459310531616
test loss item: 0.5397837162017822
test loss item: 0.30220744013786316
test loss item: 0.32448166608810425
test loss item: 0.23582734167575836
test loss item: 0.3812659680843353
test loss item: 0.320247620344162
test loss item: 0.626875102519989
test loss item: 0.44476884603500366
test loss item: 0.3164122998714447
test loss item: 0.25194767117500305
test loss item: 0.4957166016101837
test loss item: 0.7709066867828369
test loss item: 0.33045461773872375
test loss item: 0.18276014924049377
test loss item: 0.25967779755592346
test loss item: 0.3888281285762787
test loss item: 0.31967395544052124
test loss item: 0.9471473693847656
test loss item: 0.6097491979598999
test loss item: 0.2554856240749359
test loss item: 0.25365737080574036
test loss item: 0.25099119544029236
test loss item: 0.45561814308166504
test loss item: 0.27630436420440674
test loss item: 0.23038716614246368
test loss item: 0.2913392186164856
test loss item: 0.872759222984314
test loss item: 0.4710990786552429
test loss item: 0.3232811689376831
test loss item: 0.29708537459373474
test loss item: 0.5970025062561035
test loss item: 0.482783704996109
test loss item: 0.17296947538852692
test loss item: 0.9107962250709534
test loss item: 0.2838728427886963
test loss item: 0.3894382417201996
test loss item: 0.19814233481884003
test loss item: 0.2213549017906189
test loss item: 0.20242351293563843
test loss item: 1.6766092777252197
test loss item: 0.4572284519672394
test loss item: 0.23041820526123047
test loss item: 0.14315074682235718
test loss item: 1.0680073499679565
test loss item: 0.8982592225074768
test loss item: 1.179215669631958
test loss item: 0.24219155311584473
test loss item: 0.2732776403427124
test loss item: 0.17681685090065002
test loss item: 0.18661221861839294
test loss item: 0.21832279860973358
Epoch [11/50], Training Loss: 0.5552, Testing Loss: 0.4465
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 12/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5201162695884705
1
train loss item: 1.3715088367462158
2
train loss item: 0.24862895905971527
3
train loss item: 0.6377956867218018
4
train loss item: 0.4592893123626709
5
train loss item: 0.40052059292793274
6
train loss item: 0.27318274974823
7
train loss item: 0.9179098606109619
8
train loss item: 0.1908685564994812
9
train loss item: 0.2909826338291168
10
train loss item: 0.41053175926208496
11
train loss item: 0.3111651539802551
12
train loss item: 0.17082375288009644
13
train loss item: 0.5812366604804993
14
train loss item: 0.3585137724876404
15
train loss item: 0.717884361743927
16
train loss item: 0.13489140570163727
17
train loss item: 0.2911339998245239
18
train loss item: 0.3733762502670288
19
train loss item: 0.29454925656318665
20
train loss item: 0.26803988218307495
21
train loss item: 0.16406024992465973
22
train loss item: 1.052816390991211
23
train loss item: 1.036767840385437
24
train loss item: 0.5617807507514954
25
train loss item: 0.24803470075130463
26
train loss item: 0.23518501222133636
27
train loss item: 0.33571356534957886
28
train loss item: 0.13928160071372986
29
train loss item: 0.8208200931549072
30
train loss item: 2.4782602787017822
31
train loss item: 0.6179704666137695
32
train loss item: 0.1581811010837555
33
train loss item: 0.46273669600486755
34
train loss item: 0.20511645078659058
35
train loss item: 2.575108766555786
36
train loss item: 0.5085384845733643
37
train loss item: 0.34544920921325684
38
train loss item: 0.48043161630630493
39
train loss item: 0.32554391026496887
40
train loss item: 0.19924652576446533
41
train loss item: 0.3364950120449066
42
train loss item: 0.27233240008354187
43
train loss item: 0.21912337839603424
44
train loss item: 0.7923139929771423
45
train loss item: 0.17911586165428162
46
train loss item: 0.18517403304576874
47
train loss item: 0.37168338894844055
48
train loss item: 0.2697888910770416
49
train loss item: 0.20435592532157898
50
train loss item: 0.3225550651550293
51
train loss item: 0.9785789847373962
52
train loss item: 0.16445617377758026
53
train loss item: 0.196730375289917
54
train loss item: 2.454453229904175
55
train loss item: 0.23012444376945496
56
train loss item: 0.32424935698509216
57
train loss item: 0.3227161467075348
58
train loss item: 0.20272305607795715
59
train loss item: 0.19831804931163788
60
train loss item: 0.9684551358222961
61
train loss item: 2.4044084548950195
62
train loss item: 0.2546623945236206
63
train loss item: 0.3711026608943939
64
train loss item: 0.19975847005844116
65
train loss item: 0.5642712712287903
66
train loss item: 0.41902056336402893
67
train loss item: 0.2562393248081207
68
train loss item: 0.3040890395641327
69
train loss item: 0.3491828739643097
70
train loss item: 0.2784169912338257
71
train loss item: 0.17008984088897705
72
train loss item: 0.23669591546058655
73
train loss item: 0.3280535936355591
74
train loss item: 0.15113328397274017
75
train loss item: 0.16182070970535278
76
train loss item: 0.9919928908348083
77
train loss item: 1.3830137252807617
78
train loss item: 0.1382843554019928
79
train loss item: 0.30811187624931335
80
train loss item: 0.162911057472229
81
train loss item: 0.2637721598148346
82
train loss item: 0.2648991644382477
83
train loss item: 0.6558482646942139
84
train loss item: 0.3625625669956207
85
train loss item: 0.651979386806488
86
train loss item: 4.545409679412842
87
train loss item: 0.20324836671352386
88
train loss item: 0.3720775544643402
epoch train loss: 0.5406830647353376
testing phase
test loss item: 0.19487401843070984
test loss item: 0.16676440834999084
test loss item: 0.5578685402870178
test loss item: 0.31358450651168823
test loss item: 0.2730136215686798
test loss item: 0.16371256113052368
test loss item: 1.5120429992675781
test loss item: 0.5401291847229004
test loss item: 0.24053265154361725
test loss item: 0.41845372319221497
test loss item: 0.9268431067466736
test loss item: 0.2982148826122284
test loss item: 0.23069556057453156
test loss item: 0.32645612955093384
test loss item: 0.1954939365386963
test loss item: 0.16641740500926971
test loss item: 0.2999280095100403
test loss item: 0.4683588147163391
test loss item: 0.6697933673858643
test loss item: 0.281772643327713
test loss item: 0.7376391887664795
test loss item: 0.4405531883239746
test loss item: 0.2896375358104706
test loss item: 0.18882061541080475
test loss item: 0.25429901480674744
test loss item: 0.24992108345031738
test loss item: 0.34474489092826843
test loss item: 0.21719633042812347
test loss item: 0.34268665313720703
test loss item: 0.3868910074234009
test loss item: 0.7912535071372986
test loss item: 0.15182256698608398
test loss item: 0.1729832887649536
test loss item: 0.6131995320320129
test loss item: 0.4372357726097107
test loss item: 0.5165897011756897
test loss item: 0.8028428554534912
test loss item: 1.5291776657104492
test loss item: 0.5241377949714661
test loss item: 0.2902531027793884
test loss item: 0.31561169028282166
test loss item: 0.21444973349571228
test loss item: 0.365600049495697
test loss item: 0.3019711375236511
test loss item: 0.6118362545967102
test loss item: 0.4280623197555542
test loss item: 0.30107471346855164
test loss item: 0.2569841146469116
test loss item: 0.47893330454826355
test loss item: 0.7320478558540344
test loss item: 0.33322787284851074
test loss item: 0.20351335406303406
test loss item: 0.25374531745910645
test loss item: 0.36104893684387207
test loss item: 0.31660303473472595
test loss item: 0.891806423664093
test loss item: 0.5823186635971069
test loss item: 0.2644609212875366
test loss item: 0.2494506537914276
test loss item: 0.24930673837661743
test loss item: 0.46002328395843506
test loss item: 0.2631054222583771
test loss item: 0.21986135840415955
test loss item: 0.28894612193107605
test loss item: 0.8048508167266846
test loss item: 0.4466629922389984
test loss item: 0.3191763460636139
test loss item: 0.2844513952732086
test loss item: 0.5686696171760559
test loss item: 0.4458303153514862
test loss item: 0.14421552419662476
test loss item: 0.885934591293335
test loss item: 0.27836257219314575
test loss item: 0.38255974650382996
test loss item: 0.17332680523395538
test loss item: 0.19745030999183655
test loss item: 0.18937796354293823
test loss item: 1.5388202667236328
test loss item: 0.4413028955459595
test loss item: 0.2096356451511383
test loss item: 0.12049458175897598
test loss item: 0.9960830807685852
test loss item: 0.8626400232315063
test loss item: 1.081794023513794
test loss item: 0.23801839351654053
test loss item: 0.24572284519672394
test loss item: 0.14224837720394135
test loss item: 0.15340742468833923
test loss item: 0.2060813307762146
Epoch [12/50], Training Loss: 0.5407, Testing Loss: 0.4250
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 13/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5053532719612122
1
train loss item: 1.3293442726135254
2
train loss item: 0.24606667459011078
3
train loss item: 0.6140488982200623
4
train loss item: 0.4414489269256592
5
train loss item: 0.38087207078933716
6
train loss item: 0.2608255445957184
7
train loss item: 0.8915334939956665
8
train loss item: 0.1834997832775116
9
train loss item: 0.265426903963089
10
train loss item: 0.39800652861595154
11
train loss item: 0.3036733865737915
12
train loss item: 0.16942965984344482
13
train loss item: 0.5773353576660156
14
train loss item: 0.33576494455337524
15
train loss item: 0.6879717111587524
16
train loss item: 0.13066065311431885
17
train loss item: 0.2967621088027954
18
train loss item: 0.36347681283950806
19
train loss item: 0.2739619016647339
20
train loss item: 0.2545730471611023
21
train loss item: 0.1599932163953781
22
train loss item: 1.0220087766647339
23
train loss item: 1.0121419429779053
24
train loss item: 0.5455015301704407
25
train loss item: 0.24709172546863556
26
train loss item: 0.23420549929141998
27
train loss item: 0.3215292990207672
28
train loss item: 0.1346433013677597
29
train loss item: 0.7912208437919617
30
train loss item: 2.4223484992980957
31
train loss item: 0.6160619258880615
32
train loss item: 0.15822939574718475
33
train loss item: 0.46637341380119324
34
train loss item: 0.18843995034694672
35
train loss item: 2.533461809158325
36
train loss item: 0.4985262155532837
37
train loss item: 0.3425953984260559
38
train loss item: 0.4849840998649597
39
train loss item: 0.3137691915035248
40
train loss item: 0.18261206150054932
41
train loss item: 0.3204578757286072
42
train loss item: 0.2590152621269226
43
train loss item: 0.21518008410930634
44
train loss item: 0.7710758447647095
45
train loss item: 0.1764252781867981
46
train loss item: 0.17571984231472015
47
train loss item: 0.35621270537376404
48
train loss item: 0.2579304277896881
49
train loss item: 0.1979018747806549
50
train loss item: 0.3064740300178528
51
train loss item: 0.9463770389556885
52
train loss item: 0.1559796929359436
53
train loss item: 0.1945285052061081
54
train loss item: 2.4096899032592773
55
train loss item: 0.21304310858249664
56
train loss item: 0.3115324378013611
57
train loss item: 0.29829373955726624
58
train loss item: 0.19976036250591278
59
train loss item: 0.1819356381893158
60
train loss item: 0.940623939037323
61
train loss item: 2.363208770751953
62
train loss item: 0.252760648727417
63
train loss item: 0.3520413339138031
64
train loss item: 0.20218992233276367
65
train loss item: 0.5529670119285583
66
train loss item: 0.41593581438064575
67
train loss item: 0.2506016194820404
68
train loss item: 0.29676875472068787
69
train loss item: 0.33989080786705017
70
train loss item: 0.26567888259887695
71
train loss item: 0.166336327791214
72
train loss item: 0.22686180472373962
73
train loss item: 0.3131464719772339
74
train loss item: 0.14125844836235046
75
train loss item: 0.1557977944612503
76
train loss item: 0.9668840169906616
77
train loss item: 1.352170705795288
78
train loss item: 0.13490620255470276
79
train loss item: 0.296936959028244
80
train loss item: 0.15111462771892548
81
train loss item: 0.24082182347774506
82
train loss item: 0.26239532232284546
83
train loss item: 0.6328084468841553
84
train loss item: 0.3622977137565613
85
train loss item: 0.6305668950080872
86
train loss item: 4.485407829284668
87
train loss item: 0.19692546129226685
88
train loss item: 0.37589725852012634
epoch train loss: 0.5265001046858476
testing phase
test loss item: 0.19505299627780914
test loss item: 0.14854012429714203
test loss item: 0.5309597253799438
test loss item: 0.27444571256637573
test loss item: 0.26029953360557556
test loss item: 0.15551947057247162
test loss item: 1.4688917398452759
test loss item: 0.5128229260444641
test loss item: 0.23150527477264404
test loss item: 0.41690540313720703
test loss item: 0.8600106239318848
test loss item: 0.25075894594192505
test loss item: 0.22842292487621307
test loss item: 0.3284997344017029
test loss item: 0.18761727213859558
test loss item: 0.1316860467195511
test loss item: 0.29062607884407043
test loss item: 0.4639395773410797
test loss item: 0.6448777318000793
test loss item: 0.27665215730667114
test loss item: 0.7245231866836548
test loss item: 0.40679094195365906
test loss item: 0.2959994077682495
test loss item: 0.18017931282520294
test loss item: 0.2459794580936432
test loss item: 0.24548400938510895
test loss item: 0.3400025963783264
test loss item: 0.20935580134391785
test loss item: 0.33406862616539
test loss item: 0.3968541622161865
test loss item: 0.7408803105354309
test loss item: 0.12391898036003113
test loss item: 0.16275335848331451
test loss item: 0.582469642162323
test loss item: 0.4246782064437866
test loss item: 0.4913170039653778
test loss item: 0.7750113010406494
test loss item: 1.419425368309021
test loss item: 0.4999261498451233
test loss item: 0.2837224304676056
test loss item: 0.3067191541194916
test loss item: 0.21821564435958862
test loss item: 0.3613448143005371
test loss item: 0.2611400783061981
test loss item: 0.6024709343910217
test loss item: 0.41331323981285095
test loss item: 0.30791959166526794
test loss item: 0.2655867636203766
test loss item: 0.4591048061847687
test loss item: 0.6914046406745911
test loss item: 0.33335164189338684
test loss item: 0.22033901512622833
test loss item: 0.251816987991333
test loss item: 0.28554317355155945
test loss item: 0.31741243600845337
test loss item: 0.8377663493156433
test loss item: 0.555733859539032
test loss item: 0.3012143671512604
test loss item: 0.25077709555625916
test loss item: 0.24506285786628723
test loss item: 0.46640148758888245
test loss item: 0.24702951312065125
test loss item: 0.21814663708209991
test loss item: 0.2801499664783478
test loss item: 0.7487084865570068
test loss item: 0.384669691324234
test loss item: 0.3161320388317108
test loss item: 0.27386629581451416
test loss item: 0.5449265241622925
test loss item: 0.41715267300605774
test loss item: 0.11572400480508804
test loss item: 0.8639594316482544
test loss item: 0.28070706129074097
test loss item: 0.37934955954551697
test loss item: 0.1632365584373474
test loss item: 0.19716741144657135
test loss item: 0.18182246387004852
test loss item: 1.40938138961792
test loss item: 0.43528562784194946
test loss item: 0.20641028881072998
test loss item: 0.10679097473621368
test loss item: 0.9280533790588379
test loss item: 0.8264409899711609
test loss item: 0.9858759045600891
test loss item: 0.24384517967700958
test loss item: 0.23202846944332123
test loss item: 0.11449888348579407
test loss item: 0.11960478872060776
test loss item: 0.20023928582668304
Epoch [13/50], Training Loss: 0.5265, Testing Loss: 0.4058
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 14/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.49152871966362
1
train loss item: 1.2872766256332397
2
train loss item: 0.255955308675766
3
train loss item: 0.5890719890594482
4
train loss item: 0.4418350160121918
5
train loss item: 0.36348411440849304
6
train loss item: 0.26228320598602295
7
train loss item: 0.865871787071228
8
train loss item: 0.17656517028808594
9
train loss item: 0.2552987039089203
10
train loss item: 0.38741326332092285
11
train loss item: 0.30333438515663147
12
train loss item: 0.16985832154750824
13
train loss item: 0.5708497762680054
14
train loss item: 0.32071492075920105
15
train loss item: 0.6656275391578674
16
train loss item: 0.12766075134277344
17
train loss item: 0.29967162013053894
18
train loss item: 0.3567480742931366
19
train loss item: 0.2671735882759094
20
train loss item: 0.2562195062637329
21
train loss item: 0.15752263367176056
22
train loss item: 1.0029196739196777
23
train loss item: 0.9822925925254822
24
train loss item: 0.5370756387710571
25
train loss item: 0.24203656613826752
26
train loss item: 0.23312561213970184
27
train loss item: 0.3129969835281372
28
train loss item: 0.12803344428539276
29
train loss item: 0.7685827016830444
30
train loss item: 2.365861415863037
31
train loss item: 0.6077572703361511
32
train loss item: 0.15385545790195465
33
train loss item: 0.45995110273361206
34
train loss item: 0.18322336673736572
35
train loss item: 2.491635799407959
36
train loss item: 0.4922442138195038
37
train loss item: 0.3489290177822113
38
train loss item: 0.48161837458610535
39
train loss item: 0.30336734652519226
40
train loss item: 0.1750587671995163
41
train loss item: 0.3093925416469574
42
train loss item: 0.25330954790115356
43
train loss item: 0.21011973917484283
44
train loss item: 0.7504565715789795
45
train loss item: 0.17087247967720032
46
train loss item: 0.1744154840707779
47
train loss item: 0.343872994184494
48
train loss item: 0.2512780427932739
49
train loss item: 0.19502444565296173
50
train loss item: 0.30103838443756104
51
train loss item: 0.9189902544021606
52
train loss item: 0.1475543975830078
53
train loss item: 0.18869590759277344
54
train loss item: 2.3653404712677
55
train loss item: 0.2118685394525528
56
train loss item: 0.3017287850379944
57
train loss item: 0.2811538577079773
58
train loss item: 0.1973726749420166
59
train loss item: 0.1695534884929657
60
train loss item: 0.9162521958351135
61
train loss item: 2.3214099407196045
62
train loss item: 0.25991302728652954
63
train loss item: 0.34515973925590515
64
train loss item: 0.1961202770471573
65
train loss item: 0.5523598194122314
66
train loss item: 0.41468241810798645
67
train loss item: 0.2429104447364807
68
train loss item: 0.2972206473350525
69
train loss item: 0.33263951539993286
70
train loss item: 0.2558046281337738
71
train loss item: 0.1738659292459488
72
train loss item: 0.21162131428718567
73
train loss item: 0.3041399419307709
74
train loss item: 0.13468652963638306
75
train loss item: 0.14938059449195862
76
train loss item: 0.9392292499542236
77
train loss item: 1.3302559852600098
78
train loss item: 0.13300910592079163
79
train loss item: 0.29675909876823425
80
train loss item: 0.15299178659915924
81
train loss item: 0.21393729746341705
82
train loss item: 0.26196619868278503
83
train loss item: 0.6159602999687195
84
train loss item: 0.3663174510002136
85
train loss item: 0.6108761429786682
86
train loss item: 4.424276351928711
87
train loss item: 0.18770240247249603
88
train loss item: 0.3834528625011444
epoch train loss: 0.5158367434914193
testing phase
test loss item: 0.19725722074508667
test loss item: 0.13719405233860016
test loss item: 0.5118351578712463
test loss item: 0.24285322427749634
test loss item: 0.25512781739234924
test loss item: 0.15079821646213531
test loss item: 1.44297194480896
test loss item: 0.48363515734672546
test loss item: 0.22011421620845795
test loss item: 0.4078938663005829
test loss item: 0.8136628270149231
test loss item: 0.20781254768371582
test loss item: 0.217943474650383
test loss item: 0.3323858678340912
test loss item: 0.18277283012866974
test loss item: 0.10970078408718109
test loss item: 0.28575995564460754
test loss item: 0.4598122537136078
test loss item: 0.6219447255134583
test loss item: 0.27098557353019714
test loss item: 0.7161465287208557
test loss item: 0.3819137513637543
test loss item: 0.31265988945961
test loss item: 0.17403799295425415
test loss item: 0.2387729287147522
test loss item: 0.23943933844566345
test loss item: 0.33388152718544006
test loss item: 0.2060449868440628
test loss item: 0.32998692989349365
test loss item: 0.3912162482738495
test loss item: 0.7082080841064453
test loss item: 0.1064906045794487
test loss item: 0.15474259853363037
test loss item: 0.5612194538116455
test loss item: 0.41466382145881653
test loss item: 0.4685974419116974
test loss item: 0.7485137581825256
test loss item: 1.344523549079895
test loss item: 0.4797116219997406
test loss item: 0.280259370803833
test loss item: 0.30129897594451904
test loss item: 0.2296644151210785
test loss item: 0.36025458574295044
test loss item: 0.22775515913963318
test loss item: 0.5946293473243713
test loss item: 0.40626972913742065
test loss item: 0.3209633529186249
test loss item: 0.26237043738365173
test loss item: 0.4424408972263336
test loss item: 0.6608673334121704
test loss item: 0.3237851560115814
test loss item: 0.21518374979496002
test loss item: 0.24927349388599396
test loss item: 0.21711787581443787
test loss item: 0.3147410750389099
test loss item: 0.7995671629905701
test loss item: 0.5347685813903809
test loss item: 0.3223440945148468
test loss item: 0.2485910803079605
test loss item: 0.23912307620048523
test loss item: 0.4642432630062103
test loss item: 0.23550772666931152
test loss item: 0.21832796931266785
test loss item: 0.2723729908466339
test loss item: 0.7146522998809814
test loss item: 0.3336338996887207
test loss item: 0.3131745755672455
test loss item: 0.2686305344104767
test loss item: 0.5309615135192871
test loss item: 0.39606165885925293
test loss item: 0.10058379918336868
test loss item: 0.847646951675415
test loss item: 0.28259918093681335
test loss item: 0.38132715225219727
test loss item: 0.16050201654434204
test loss item: 0.20675773918628693
test loss item: 0.1772543042898178
test loss item: 1.325452208518982
test loss item: 0.43780988454818726
test loss item: 0.20987574756145477
test loss item: 0.09905147552490234
test loss item: 0.8810340166091919
test loss item: 0.7954299449920654
test loss item: 0.918520450592041
test loss item: 0.250367671251297
test loss item: 0.22677838802337646
test loss item: 0.09948474913835526
test loss item: 0.09934132546186447
test loss item: 0.19094383716583252
Epoch [14/50], Training Loss: 0.5158, Testing Loss: 0.3916
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 15/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47835320234298706
1
train loss item: 1.2498692274093628
2
train loss item: 0.25688058137893677
3
train loss item: 0.5633166432380676
4
train loss item: 0.4414224624633789
5
train loss item: 0.35124561190605164
6
train loss item: 0.26332563161849976
7
train loss item: 0.8409239053726196
8
train loss item: 0.16948102414608002
9
train loss item: 0.25645333528518677
10
train loss item: 0.3750241696834564
11
train loss item: 0.29804226756095886
12
train loss item: 0.1687658131122589
13
train loss item: 0.5571946501731873
14
train loss item: 0.30666226148605347
15
train loss item: 0.6535013318061829
16
train loss item: 0.12436453998088837
17
train loss item: 0.28802186250686646
18
train loss item: 0.35008788108825684
19
train loss item: 0.2650895416736603
20
train loss item: 0.26270440220832825
21
train loss item: 0.15119247138500214
22
train loss item: 0.9916755557060242
23
train loss item: 0.9517486691474915
24
train loss item: 0.5367067456245422
25
train loss item: 0.23601199686527252
26
train loss item: 0.22349131107330322
27
train loss item: 0.3006644546985626
28
train loss item: 0.12185530364513397
29
train loss item: 0.753485381603241
30
train loss item: 2.3171770572662354
31
train loss item: 0.5929251909255981
32
train loss item: 0.1474425494670868
33
train loss item: 0.44011256098747253
34
train loss item: 0.1772204339504242
35
train loss item: 2.4546010494232178
36
train loss item: 0.4842691123485565
37
train loss item: 0.3575940430164337
38
train loss item: 0.47563308477401733
39
train loss item: 0.28904008865356445
40
train loss item: 0.17937049269676208
41
train loss item: 0.2960847318172455
42
train loss item: 0.25066617131233215
43
train loss item: 0.20281004905700684
44
train loss item: 0.7288731932640076
45
train loss item: 0.16140985488891602
46
train loss item: 0.16340605914592743
47
train loss item: 0.34016820788383484
48
train loss item: 0.243598073720932
49
train loss item: 0.18491962552070618
50
train loss item: 0.300961971282959
51
train loss item: 0.8974137902259827
52
train loss item: 0.14168637990951538
53
train loss item: 0.1827872097492218
54
train loss item: 2.3277621269226074
55
train loss item: 0.21012872457504272
56
train loss item: 0.28924107551574707
57
train loss item: 0.2701060473918915
58
train loss item: 0.1955680400133133
59
train loss item: 0.16426126658916473
60
train loss item: 0.8934186697006226
61
train loss item: 2.282989978790283
62
train loss item: 0.2654604911804199
63
train loss item: 0.34444355964660645
64
train loss item: 0.18185386061668396
65
train loss item: 0.5558716654777527
66
train loss item: 0.4113875925540924
67
train loss item: 0.23125210404396057
68
train loss item: 0.30075880885124207
69
train loss item: 0.3263847827911377
70
train loss item: 0.25340354442596436
71
train loss item: 0.17898039519786835
72
train loss item: 0.20037205517292023
73
train loss item: 0.2999419569969177
74
train loss item: 0.14047932624816895
75
train loss item: 0.14419087767601013
76
train loss item: 0.9129742980003357
77
train loss item: 1.317050814628601
78
train loss item: 0.13130059838294983
79
train loss item: 0.2973787784576416
80
train loss item: 0.15615609288215637
81
train loss item: 0.20097237825393677
82
train loss item: 0.24996308982372284
83
train loss item: 0.6043196320533752
84
train loss item: 0.3708827495574951
85
train loss item: 0.5945149064064026
86
train loss item: 4.37116003036499
87
train loss item: 0.1843327134847641
88
train loss item: 0.39038729667663574
epoch train loss: 0.5061503769306654
testing phase
test loss item: 0.19177651405334473
test loss item: 0.13320690393447876
test loss item: 0.5060930252075195
test loss item: 0.2309299260377884
test loss item: 0.25520026683807373
test loss item: 0.1441093534231186
test loss item: 1.4247596263885498
test loss item: 0.44872790575027466
test loss item: 0.21371930837631226
test loss item: 0.39890730381011963
test loss item: 0.797954261302948
test loss item: 0.1905725747346878
test loss item: 0.2083340585231781
test loss item: 0.3375515639781952
test loss item: 0.18096515536308289
test loss item: 0.10392209142446518
test loss item: 0.28328919410705566
test loss item: 0.45672351121902466
test loss item: 0.5985924601554871
test loss item: 0.26995933055877686
test loss item: 0.709891676902771
test loss item: 0.37231194972991943
test loss item: 0.32173407077789307
test loss item: 0.1724214106798172
test loss item: 0.23393121361732483
test loss item: 0.2337387502193451
test loss item: 0.3292267918586731
test loss item: 0.20442689955234528
test loss item: 0.33041661977767944
test loss item: 0.37634900212287903
test loss item: 0.699207067489624
test loss item: 0.10111460834741592
test loss item: 0.15081144869327545
test loss item: 0.5542840361595154
test loss item: 0.40891847014427185
test loss item: 0.45499321818351746
test loss item: 0.7238370776176453
test loss item: 1.3228422403335571
test loss item: 0.47039783000946045
test loss item: 0.2788181006908417
test loss item: 0.2980211079120636
test loss item: 0.22545741498470306
test loss item: 0.3594639003276825
test loss item: 0.21514177322387695
test loss item: 0.5878111720085144
test loss item: 0.40318405628204346
test loss item: 0.32135912775993347
test loss item: 0.2544683516025543
test loss item: 0.4358992576599121
test loss item: 0.6491851806640625
test loss item: 0.3132479190826416
test loss item: 0.19610266387462616
test loss item: 0.2458324283361435
test loss item: 0.19092722237110138
test loss item: 0.3094936013221741
test loss item: 0.7861369848251343
test loss item: 0.5197607278823853
test loss item: 0.3094806671142578
test loss item: 0.2426033467054367
test loss item: 0.23612533509731293
test loss item: 0.4593222439289093
test loss item: 0.22894646227359772
test loss item: 0.2143322378396988
test loss item: 0.26951587200164795
test loss item: 0.6986029744148254
test loss item: 0.3141061067581177
test loss item: 0.3114025294780731
test loss item: 0.267607182264328
test loss item: 0.5278794765472412
test loss item: 0.37961700558662415
test loss item: 0.09955431520938873
test loss item: 0.8291621804237366
test loss item: 0.28711608052253723
test loss item: 0.38666728138923645
test loss item: 0.15835712850093842
test loss item: 0.20681022107601166
test loss item: 0.17702621221542358
test loss item: 1.3015788793563843
test loss item: 0.4446747601032257
test loss item: 0.2067803144454956
test loss item: 0.09495857357978821
test loss item: 0.8595606088638306
test loss item: 0.7738432288169861
test loss item: 0.8959629535675049
test loss item: 0.251783162355423
test loss item: 0.22475451231002808
test loss item: 0.09474386274814606
test loss item: 0.0919434130191803
test loss item: 0.1806633621454239
Epoch [15/50], Training Loss: 0.5062, Testing Loss: 0.3838
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 16/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.464773565530777
1
train loss item: 1.2196898460388184
2
train loss item: 0.2481204867362976
3
train loss item: 0.5436679720878601
4
train loss item: 0.4156726896762848
5
train loss item: 0.3412291705608368
6
train loss item: 0.26386362314224243
7
train loss item: 0.8190775513648987
8
train loss item: 0.15949735045433044
9
train loss item: 0.25497499108314514
10
train loss item: 0.36183494329452515
11
train loss item: 0.2878800630569458
12
train loss item: 0.1627093255519867
13
train loss item: 0.5400184988975525
14
train loss item: 0.2875291109085083
15
train loss item: 0.6400689482688904
16
train loss item: 0.11891990900039673
17
train loss item: 0.26867955923080444
18
train loss item: 0.34041619300842285
19
train loss item: 0.2630615532398224
20
train loss item: 0.2628956139087677
21
train loss item: 0.14635610580444336
22
train loss item: 0.973993718624115
23
train loss item: 0.9286383390426636
24
train loss item: 0.5369480848312378
25
train loss item: 0.22872407734394073
26
train loss item: 0.2110707014799118
27
train loss item: 0.28340551257133484
28
train loss item: 0.11611422151327133
29
train loss item: 0.7364981174468994
30
train loss item: 2.2786035537719727
31
train loss item: 0.5797721147537231
32
train loss item: 0.1477176696062088
33
train loss item: 0.4216180741786957
34
train loss item: 0.16465722024440765
35
train loss item: 2.425492763519287
36
train loss item: 0.4733029901981354
37
train loss item: 0.3650241792201996
38
train loss item: 0.47415292263031006
39
train loss item: 0.27226775884628296
40
train loss item: 0.18558090925216675
41
train loss item: 0.27926191687583923
42
train loss item: 0.24734976887702942
43
train loss item: 0.19614210724830627
44
train loss item: 0.7092707753181458
45
train loss item: 0.15330073237419128
46
train loss item: 0.1526465117931366
47
train loss item: 0.33892178535461426
48
train loss item: 0.23360513150691986
49
train loss item: 0.17176073789596558
50
train loss item: 0.30122533440589905
51
train loss item: 0.8789724707603455
52
train loss item: 0.13403373956680298
53
train loss item: 0.17667822539806366
54
train loss item: 2.300100564956665
55
train loss item: 0.20583517849445343
56
train loss item: 0.2746032774448395
57
train loss item: 0.26132825016975403
58
train loss item: 0.19335857033729553
59
train loss item: 0.1598283052444458
60
train loss item: 0.8709737062454224
61
train loss item: 2.251570701599121
62
train loss item: 0.2587108314037323
63
train loss item: 0.3440282642841339
64
train loss item: 0.1695864200592041
65
train loss item: 0.5520545244216919
66
train loss item: 0.40772855281829834
67
train loss item: 0.22132791578769684
68
train loss item: 0.29793524742126465
69
train loss item: 0.31982582807540894
70
train loss item: 0.25221070647239685
71
train loss item: 0.172990620136261
72
train loss item: 0.19297169148921967
73
train loss item: 0.2947462499141693
74
train loss item: 0.14189335703849792
75
train loss item: 0.13882076740264893
76
train loss item: 0.8927563428878784
77
train loss item: 1.3066387176513672
78
train loss item: 0.12756496667861938
79
train loss item: 0.2947693467140198
80
train loss item: 0.1510535478591919
81
train loss item: 0.19757451117038727
82
train loss item: 0.2310369461774826
83
train loss item: 0.5943210124969482
84
train loss item: 0.3741403818130493
85
train loss item: 0.5827512741088867
86
train loss item: 4.332095146179199
87
train loss item: 0.18268625438213348
88
train loss item: 0.39197009801864624
epoch train loss: 0.4958368237601237
testing phase
test loss item: 0.18397650122642517
test loss item: 0.13562947511672974
test loss item: 0.5139370560646057
test loss item: 0.2312324345111847
test loss item: 0.25812169909477234
test loss item: 0.13868825137615204
test loss item: 1.403923511505127
test loss item: 0.41844481229782104
test loss item: 0.21533256769180298
test loss item: 0.3957536518573761
test loss item: 0.8065636157989502
test loss item: 0.19244436919689178
test loss item: 0.2073315978050232
test loss item: 0.34080690145492554
test loss item: 0.182481586933136
test loss item: 0.10948388278484344
test loss item: 0.28269094228744507
test loss item: 0.4566081166267395
test loss item: 0.5795106291770935
test loss item: 0.27574893832206726
test loss item: 0.7063419818878174
test loss item: 0.3697092533111572
test loss item: 0.3251310884952545
test loss item: 0.17607340216636658
test loss item: 0.2328731268644333
test loss item: 0.22984686493873596
test loss item: 0.3278392553329468
test loss item: 0.20473146438598633
test loss item: 0.3328898251056671
test loss item: 0.3630716800689697
test loss item: 0.7057824730873108
test loss item: 0.10417871177196503
test loss item: 0.15299907326698303
test loss item: 0.5565313696861267
test loss item: 0.40885084867477417
test loss item: 0.4536132216453552
test loss item: 0.7046202421188354
test loss item: 1.3438667058944702
test loss item: 0.46917369961738586
test loss item: 0.27796366810798645
test loss item: 0.29531779885292053
test loss item: 0.21597209572792053
test loss item: 0.36147457361221313
test loss item: 0.21527034044265747
test loss item: 0.584181010723114
test loss item: 0.40012481808662415
test loss item: 0.3179818391799927
test loss item: 0.25194671750068665
test loss item: 0.43909841775894165
test loss item: 0.6531807780265808
test loss item: 0.30923470854759216
test loss item: 0.1787232607603073
test loss item: 0.2428516298532486
test loss item: 0.19375881552696228
test loss item: 0.30502021312713623
test loss item: 0.7932475209236145
test loss item: 0.5136035084724426
test loss item: 0.28138062357902527
test loss item: 0.23769061267375946
test loss item: 0.23789355158805847
test loss item: 0.45826148986816406
test loss item: 0.22572188079357147
test loss item: 0.2091565579175949
test loss item: 0.2707344591617584
test loss item: 0.6955534219741821
test loss item: 0.31250184774398804
test loss item: 0.3099532425403595
test loss item: 0.26804786920547485
test loss item: 0.5326263308525085
test loss item: 0.3717906177043915
test loss item: 0.1072002500295639
test loss item: 0.8062686920166016
test loss item: 0.3011566400527954
test loss item: 0.39108139276504517
test loss item: 0.15952658653259277
test loss item: 0.20715174078941345
test loss item: 0.18076983094215393
test loss item: 1.3238039016723633
test loss item: 0.4514056146144867
test loss item: 0.1995958536863327
test loss item: 0.09707459807395935
test loss item: 0.8583367466926575
test loss item: 0.7627687454223633
test loss item: 0.911523163318634
test loss item: 0.24670538306236267
test loss item: 0.22588354349136353
test loss item: 0.09888703376054764
test loss item: 0.0948033556342125
test loss item: 0.17294174432754517
Epoch [16/50], Training Loss: 0.4958, Testing Loss: 0.3826
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 17/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45122796297073364
1
train loss item: 1.1956967115402222
2
train loss item: 0.23951031267642975
3
train loss item: 0.5320448875427246
4
train loss item: 0.39336177706718445
5
train loss item: 0.3327711820602417
6
train loss item: 0.265445351600647
7
train loss item: 0.8026495575904846
8
train loss item: 0.14973831176757812
9
train loss item: 0.24897480010986328
10
train loss item: 0.35124948620796204
11
train loss item: 0.2792186141014099
12
train loss item: 0.15176494419574738
13
train loss item: 0.5249396562576294
14
train loss item: 0.26839056611061096
15
train loss item: 0.6223706603050232
16
train loss item: 0.11161541193723679
17
train loss item: 0.2534288763999939
18
train loss item: 0.32878249883651733
19
train loss item: 0.262153297662735
20
train loss item: 0.2554686665534973
21
train loss item: 0.14157521724700928
22
train loss item: 0.9473239779472351
23
train loss item: 0.9156344532966614
24
train loss item: 0.5309893488883972
25
train loss item: 0.21870490908622742
26
train loss item: 0.20479805767536163
27
train loss item: 0.2668428421020508
28
train loss item: 0.11010421067476273
29
train loss item: 0.7161588668823242
30
train loss item: 2.249130964279175
31
train loss item: 0.5715712904930115
32
train loss item: 0.14541202783584595
33
train loss item: 0.41627100110054016
34
train loss item: 0.15464098751544952
35
train loss item: 2.402010679244995
36
train loss item: 0.46226340532302856
37
train loss item: 0.37202492356300354
38
train loss item: 0.47440478205680847
39
train loss item: 0.2564306855201721
40
train loss item: 0.18679536879062653
41
train loss item: 0.26479387283325195
42
train loss item: 0.24579554796218872
43
train loss item: 0.1891847848892212
44
train loss item: 0.695274293422699
45
train loss item: 0.14999249577522278
46
train loss item: 0.15529337525367737
47
train loss item: 0.3347267806529999
48
train loss item: 0.22654132544994354
49
train loss item: 0.16314677894115448
50
train loss item: 0.2999195158481598
51
train loss item: 0.8616476655006409
52
train loss item: 0.1261640340089798
53
train loss item: 0.1714075803756714
54
train loss item: 2.27927827835083
55
train loss item: 0.20690032839775085
56
train loss item: 0.26236289739608765
57
train loss item: 0.2544708847999573
58
train loss item: 0.18498562276363373
59
train loss item: 0.15416096150875092
60
train loss item: 0.8502624034881592
61
train loss item: 2.2285356521606445
62
train loss item: 0.24060530960559845
63
train loss item: 0.34247860312461853
64
train loss item: 0.1632671058177948
65
train loss item: 0.5368908047676086
66
train loss item: 0.4043624997138977
67
train loss item: 0.21427148580551147
68
train loss item: 0.2858743369579315
69
train loss item: 0.31320497393608093
70
train loss item: 0.24749548733234406
71
train loss item: 0.1598307341337204
72
train loss item: 0.1887725293636322
73
train loss item: 0.2881968915462494
74
train loss item: 0.1311187744140625
75
train loss item: 0.13164761662483215
76
train loss item: 0.8797652721405029
77
train loss item: 1.295104742050171
78
train loss item: 0.11947903782129288
79
train loss item: 0.2909093499183655
80
train loss item: 0.13983331620693207
81
train loss item: 0.19541366398334503
82
train loss item: 0.21794867515563965
83
train loss item: 0.5833433866500854
84
train loss item: 0.3770499527454376
85
train loss item: 0.5739404559135437
86
train loss item: 4.302964210510254
87
train loss item: 0.1797940731048584
88
train loss item: 0.3863813281059265
epoch train loss: 0.48605259809266316
testing phase
test loss item: 0.1795479655265808
test loss item: 0.13809596002101898
test loss item: 0.5278609395027161
test loss item: 0.23533138632774353
test loss item: 0.2602735161781311
test loss item: 0.13624921441078186
test loss item: 1.3871464729309082
test loss item: 0.4086046516895294
test loss item: 0.21884764730930328
test loss item: 0.39607566595077515
test loss item: 0.8196797966957092
test loss item: 0.20172609388828278
test loss item: 0.2114972025156021
test loss item: 0.33692675828933716
test loss item: 0.1832006424665451
test loss item: 0.11691968142986298
test loss item: 0.28241488337516785
test loss item: 0.45856359601020813
test loss item: 0.5687587857246399
test loss item: 0.2807747423648834
test loss item: 0.7078200578689575
test loss item: 0.37008440494537354
test loss item: 0.32585692405700684
test loss item: 0.1791156530380249
test loss item: 0.23365706205368042
test loss item: 0.22641955316066742
test loss item: 0.3259553015232086
test loss item: 0.20516668260097504
test loss item: 0.3329736292362213
test loss item: 0.35421842336654663
test loss item: 0.713898777961731
test loss item: 0.11024224013090134
test loss item: 0.15585260093212128
test loss item: 0.5624617338180542
test loss item: 0.41229066252708435
test loss item: 0.45308616757392883
test loss item: 0.6949927806854248
test loss item: 1.3736852407455444
test loss item: 0.47143444418907166
test loss item: 0.27537375688552856
test loss item: 0.2925967276096344
test loss item: 0.2121889442205429
test loss item: 0.36497995257377625
test loss item: 0.21961109340190887
test loss item: 0.5847718119621277
test loss item: 0.3959158658981323
test loss item: 0.3185783326625824
test loss item: 0.25107866525650024
test loss item: 0.4466138780117035
test loss item: 0.6587359309196472
test loss item: 0.31022095680236816
test loss item: 0.16795580089092255
test loss item: 0.239997997879982
test loss item: 0.20686902105808258
test loss item: 0.30250322818756104
test loss item: 0.8045376539230347
test loss item: 0.5141324996948242
test loss item: 0.2602410316467285
test loss item: 0.23518268764019012
test loss item: 0.24124304950237274
test loss item: 0.4594094455242157
test loss item: 0.22532010078430176
test loss item: 0.2062033861875534
test loss item: 0.2732277810573578
test loss item: 0.7022639513015747
test loss item: 0.31774359941482544
test loss item: 0.3069411814212799
test loss item: 0.26703187823295593
test loss item: 0.5394853353500366
test loss item: 0.3659762740135193
test loss item: 0.11355007439851761
test loss item: 0.7899420857429504
test loss item: 0.317970871925354
test loss item: 0.39068344235420227
test loss item: 0.1621050089597702
test loss item: 0.21219678223133087
test loss item: 0.18271778523921967
test loss item: 1.3599411249160767
test loss item: 0.45254790782928467
test loss item: 0.1947246640920639
test loss item: 0.1001027300953865
test loss item: 0.8637527227401733
test loss item: 0.7588886022567749
test loss item: 0.9377596974372864
test loss item: 0.23732921481132507
test loss item: 0.2277631163597107
test loss item: 0.10412606596946716
test loss item: 0.10055729746818542
test loss item: 0.16884219646453857
Epoch [17/50], Training Loss: 0.4861, Testing Loss: 0.3843
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 18/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4390221834182739
1
train loss item: 1.1762453317642212
2
train loss item: 0.2345958799123764
3
train loss item: 0.5228735208511353
4
train loss item: 0.39249399304389954
5
train loss item: 0.32524147629737854
6
train loss item: 0.26304590702056885
7
train loss item: 0.789982259273529
8
train loss item: 0.14426620304584503
9
train loss item: 0.24288170039653778
10
train loss item: 0.34224626421928406
11
train loss item: 0.27271416783332825
12
train loss item: 0.14229124784469604
13
train loss item: 0.5123371481895447
14
train loss item: 0.2539372444152832
15
train loss item: 0.6071872711181641
16
train loss item: 0.10293794423341751
17
train loss item: 0.24624811112880707
18
train loss item: 0.3175336718559265
19
train loss item: 0.2606341540813446
20
train loss item: 0.2462848722934723
21
train loss item: 0.13717013597488403
22
train loss item: 0.9217588305473328
23
train loss item: 0.9074892401695251
24
train loss item: 0.520194947719574
25
train loss item: 0.2081928551197052
26
train loss item: 0.2028341144323349
27
train loss item: 0.2551409602165222
28
train loss item: 0.10253062099218369
29
train loss item: 0.6988943219184875
30
train loss item: 2.223565101623535
31
train loss item: 0.5653397440910339
32
train loss item: 0.1340428590774536
33
train loss item: 0.4202425181865692
34
train loss item: 0.15067636966705322
35
train loss item: 2.380751132965088
36
train loss item: 0.45251187682151794
37
train loss item: 0.3760129511356354
38
train loss item: 0.46846258640289307
39
train loss item: 0.24441485106945038
40
train loss item: 0.182725727558136
41
train loss item: 0.25552722811698914
42
train loss item: 0.24669769406318665
43
train loss item: 0.18372395634651184
44
train loss item: 0.685674250125885
45
train loss item: 0.1485981047153473
46
train loss item: 0.1583140641450882
47
train loss item: 0.3292545676231384
48
train loss item: 0.22390979528427124
49
train loss item: 0.15824958682060242
50
train loss item: 0.29572731256484985
51
train loss item: 0.8448977470397949
52
train loss item: 0.119322270154953
53
train loss item: 0.16920581459999084
54
train loss item: 2.2603232860565186
55
train loss item: 0.21063648164272308
56
train loss item: 0.2536093592643738
57
train loss item: 0.24745264649391174
58
train loss item: 0.1736958622932434
59
train loss item: 0.1497756391763687
60
train loss item: 0.8330999612808228
61
train loss item: 2.209712266921997
62
train loss item: 0.2195083051919937
63
train loss item: 0.33924436569213867
64
train loss item: 0.16354380548000336
65
train loss item: 0.519386887550354
66
train loss item: 0.39892205595970154
67
train loss item: 0.20854711532592773
68
train loss item: 0.27369093894958496
69
train loss item: 0.3070007562637329
70
train loss item: 0.24126222729682922
71
train loss item: 0.15029756724834442
72
train loss item: 0.19020900130271912
73
train loss item: 0.28319212794303894
74
train loss item: 0.11731366813182831
75
train loss item: 0.12652581930160522
76
train loss item: 0.870657205581665
77
train loss item: 1.28215754032135
78
train loss item: 0.10740377008914948
79
train loss item: 0.2854536473751068
80
train loss item: 0.1301664412021637
81
train loss item: 0.19290316104888916
82
train loss item: 0.21285326778888702
83
train loss item: 0.5707969069480896
84
train loss item: 0.37881115078926086
85
train loss item: 0.5651582479476929
86
train loss item: 4.27729606628418
87
train loss item: 0.18036888539791107
88
train loss item: 0.3754551112651825
epoch train loss: 0.4776796206329646
testing phase
test loss item: 0.17784236371517181
test loss item: 0.13719579577445984
test loss item: 0.5344434976577759
test loss item: 0.23780851066112518
test loss item: 0.2591812014579773
test loss item: 0.13410869240760803
test loss item: 1.3868991136550903
test loss item: 0.4274008870124817
test loss item: 0.21691125631332397
test loss item: 0.3936111629009247
test loss item: 0.8182723522186279
test loss item: 0.20795999467372894
test loss item: 0.21252231299877167
test loss item: 0.3253036141395569
test loss item: 0.1813238561153412
test loss item: 0.11994010210037231
test loss item: 0.2798326909542084
test loss item: 0.45905545353889465
test loss item: 0.5692559480667114
test loss item: 0.27734774351119995
test loss item: 0.7122097015380859
test loss item: 0.3716282546520233
test loss item: 0.3233214318752289
test loss item: 0.17886902391910553
test loss item: 0.23240648210048676
test loss item: 0.2219243049621582
test loss item: 0.31961506605148315
test loss item: 0.2036704421043396
test loss item: 0.328775018453598
test loss item: 0.3469342589378357
test loss item: 0.712917685508728
test loss item: 0.11414667218923569
test loss item: 0.15626105666160583
test loss item: 0.5651819109916687
test loss item: 0.41390299797058105
test loss item: 0.44177761673927307
test loss item: 0.6966418027877808
test loss item: 1.376810908317566
test loss item: 0.4715692698955536
test loss item: 0.2704315483570099
test loss item: 0.289482444524765
test loss item: 0.21186703443527222
test loss item: 0.3647605776786804
test loss item: 0.22189995646476746
test loss item: 0.5865240693092346
test loss item: 0.3901657164096832
test loss item: 0.32002902030944824
test loss item: 0.24481450021266937
test loss item: 0.4502909779548645
test loss item: 0.6533889770507812
test loss item: 0.3103247284889221
test loss item: 0.16060002148151398
test loss item: 0.23583301901817322
test loss item: 0.2171250879764557
test loss item: 0.3004455864429474
test loss item: 0.8017759323120117
test loss item: 0.5163893103599548
test loss item: 0.2517547309398651
test loss item: 0.23312222957611084
test loss item: 0.2411673218011856
test loss item: 0.4570590555667877
test loss item: 0.22643785178661346
test loss item: 0.20346564054489136
test loss item: 0.2725106477737427
test loss item: 0.7088509202003479
test loss item: 0.3224918842315674
test loss item: 0.3015829622745514
test loss item: 0.26261529326438904
test loss item: 0.5415278673171997
test loss item: 0.36118826270103455
test loss item: 0.11281903088092804
test loss item: 0.7920787334442139
test loss item: 0.3259459137916565
test loss item: 0.38400354981422424
test loss item: 0.16074202954769135
test loss item: 0.21558701992034912
test loss item: 0.18125511705875397
test loss item: 1.3737432956695557
test loss item: 0.4443398714065552
test loss item: 0.19168365001678467
test loss item: 0.09991158545017242
test loss item: 0.8633235096931458
test loss item: 0.7584540247917175
test loss item: 0.9453384876251221
test loss item: 0.22707831859588623
test loss item: 0.22610169649124146
test loss item: 0.10495729744434357
test loss item: 0.10309876501560211
test loss item: 0.16651590168476105
Epoch [18/50], Training Loss: 0.4777, Testing Loss: 0.3837
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 19/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.42831242084503174
1
train loss item: 1.158857822418213
2
train loss item: 0.23137085139751434
3
train loss item: 0.5086199641227722
4
train loss item: 0.3800085186958313
5
train loss item: 0.31677472591400146
6
train loss item: 0.2553494870662689
7
train loss item: 0.7767841219902039
8
train loss item: 0.14015249907970428
9
train loss item: 0.23645253479480743
10
train loss item: 0.3300974369049072
11
train loss item: 0.26648569107055664
12
train loss item: 0.13876734673976898
13
train loss item: 0.49888747930526733
14
train loss item: 0.24387311935424805
15
train loss item: 0.5980829000473022
16
train loss item: 0.09620486199855804
17
train loss item: 0.24299080669879913
18
train loss item: 0.30787965655326843
19
train loss item: 0.25727447867393494
20
train loss item: 0.2408812791109085
21
train loss item: 0.1358022689819336
22
train loss item: 0.9045893549919128
23
train loss item: 0.8955429792404175
24
train loss item: 0.509209156036377
25
train loss item: 0.1993635594844818
26
train loss item: 0.1985388845205307
27
train loss item: 0.24744723737239838
28
train loss item: 0.09581281989812851
29
train loss item: 0.6868520975112915
30
train loss item: 2.195094347000122
31
train loss item: 0.5546186566352844
32
train loss item: 0.12126616388559341
33
train loss item: 0.4214247167110443
34
train loss item: 0.14667800068855286
35
train loss item: 2.3589797019958496
36
train loss item: 0.4435369074344635
37
train loss item: 0.3741767704486847
38
train loss item: 0.45176512002944946
39
train loss item: 0.2365693897008896
40
train loss item: 0.1756288707256317
41
train loss item: 0.24806417524814606
42
train loss item: 0.24744853377342224
43
train loss item: 0.18094982206821442
44
train loss item: 0.6752335429191589
45
train loss item: 0.1448419839143753
46
train loss item: 0.1526726335287094
47
train loss item: 0.3251579701900482
48
train loss item: 0.22114652395248413
49
train loss item: 0.15436308085918427
50
train loss item: 0.28938359022140503
51
train loss item: 0.8276521563529968
52
train loss item: 0.11319451779127121
53
train loss item: 0.16655710339546204
54
train loss item: 2.2392354011535645
55
train loss item: 0.2112569808959961
56
train loss item: 0.24531029164791107
57
train loss item: 0.23938170075416565
58
train loss item: 0.16646426916122437
59
train loss item: 0.14496788382530212
60
train loss item: 0.8188905715942383
61
train loss item: 2.188100576400757
62
train loss item: 0.2036476582288742
63
train loss item: 0.33459895849227905
64
train loss item: 0.16624405980110168
65
train loss item: 0.5083129405975342
66
train loss item: 0.39019399881362915
67
train loss item: 0.20367051661014557
68
train loss item: 0.26813334226608276
69
train loss item: 0.30065158009529114
70
train loss item: 0.2359572798013687
71
train loss item: 0.15148890018463135
72
train loss item: 0.19067230820655823
73
train loss item: 0.27904272079467773
74
train loss item: 0.10790514200925827
75
train loss item: 0.1252787858247757
76
train loss item: 0.8594317436218262
77
train loss item: 1.268768548965454
78
train loss item: 0.09791858494281769
79
train loss item: 0.27724575996398926
80
train loss item: 0.12667015194892883
81
train loss item: 0.1893133819103241
82
train loss item: 0.21006657183170319
83
train loss item: 0.5580232739448547
84
train loss item: 0.37813442945480347
85
train loss item: 0.5519635677337646
86
train loss item: 4.248642444610596
87
train loss item: 0.18142352998256683
88
train loss item: 0.3634752929210663
epoch train loss: 0.46948487403687467
testing phase
test loss item: 0.17567424476146698
test loss item: 0.13234689831733704
test loss item: 0.5260275602340698
test loss item: 0.23524479568004608
test loss item: 0.2541215121746063
test loss item: 0.13008540868759155
test loss item: 1.40651535987854
test loss item: 0.4648256301879883
test loss item: 0.20809273421764374
test loss item: 0.38526061177253723
test loss item: 0.7997134923934937
test loss item: 0.20458465814590454
test loss item: 0.2051294445991516
test loss item: 0.3098473846912384
test loss item: 0.1767948716878891
test loss item: 0.11706046015024185
test loss item: 0.2728497385978699
test loss item: 0.4545838534832001
test loss item: 0.5817194581031799
test loss item: 0.26371583342552185
test loss item: 0.7117747664451599
test loss item: 0.3708411455154419
test loss item: 0.3142228424549103
test loss item: 0.17534688115119934
test loss item: 0.2263399064540863
test loss item: 0.21576523780822754
test loss item: 0.30867114663124084
test loss item: 0.199323832988739
test loss item: 0.3206564486026764
test loss item: 0.33893346786499023
test loss item: 0.7026623487472534
test loss item: 0.11390076577663422
test loss item: 0.15355509519577026
test loss item: 0.5590443015098572
test loss item: 0.4092102348804474
test loss item: 0.42755600810050964
test loss item: 0.70731520652771
test loss item: 1.3449952602386475
test loss item: 0.46519210934638977
test loss item: 0.2640156149864197
test loss item: 0.2856847941875458
test loss item: 0.20665568113327026
test loss item: 0.35753121972084045
test loss item: 0.2179039567708969
test loss item: 0.5836395025253296
test loss item: 0.3811851143836975
test loss item: 0.31512582302093506
test loss item: 0.2326991856098175
test loss item: 0.44452598690986633
test loss item: 0.6383587718009949
test loss item: 0.30513817071914673
test loss item: 0.1535254716873169
test loss item: 0.2296796590089798
test loss item: 0.21637646853923798
test loss item: 0.2965923547744751
test loss item: 0.7813876271247864
test loss item: 0.5197597742080688
test loss item: 0.2486822009086609
test loss item: 0.228756844997406
test loss item: 0.23441307246685028
test loss item: 0.4488750994205475
test loss item: 0.22552920877933502
test loss item: 0.19789934158325195
test loss item: 0.26449888944625854
test loss item: 0.7063475251197815
test loss item: 0.32112085819244385
test loss item: 0.2932533919811249
test loss item: 0.2543404996395111
test loss item: 0.5338736772537231
test loss item: 0.3696272075176239
test loss item: 0.10464522987604141
test loss item: 0.8106984496116638
test loss item: 0.3205980956554413
test loss item: 0.3718191981315613
test loss item: 0.15251225233078003
test loss item: 0.20950430631637573
test loss item: 0.1772269457578659
test loss item: 1.3491449356079102
test loss item: 0.4279221296310425
test loss item: 0.18738095462322235
test loss item: 0.09621494263410568
test loss item: 0.8560743927955627
test loss item: 0.7625376582145691
test loss item: 0.9255231618881226
test loss item: 0.21796472370624542
test loss item: 0.21840789914131165
test loss item: 0.10040266811847687
test loss item: 0.10089156031608582
test loss item: 0.16350829601287842
Epoch [19/50], Training Loss: 0.4695, Testing Loss: 0.3784
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 20/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4195750653743744
1
train loss item: 1.1398003101348877
2
train loss item: 0.22668564319610596
3
train loss item: 0.4893135726451874
4
train loss item: 0.35899728536605835
5
train loss item: 0.3078053891658783
6
train loss item: 0.24577835202217102
7
train loss item: 0.7604930400848389
8
train loss item: 0.13750331103801727
9
train loss item: 0.22881609201431274
10
train loss item: 0.31567302346229553
11
train loss item: 0.262103796005249
12
train loss item: 0.1378602832555771
13
train loss item: 0.4837961196899414
14
train loss item: 0.2362784445285797
15
train loss item: 0.593822717666626
16
train loss item: 0.09589242935180664
17
train loss item: 0.24241937696933746
18
train loss item: 0.3007984459400177
19
train loss item: 0.25287166237831116
20
train loss item: 0.23850961029529572
21
train loss item: 0.13613085448741913
22
train loss item: 0.8941177725791931
23
train loss item: 0.8762867450714111
24
train loss item: 0.5002288818359375
25
train loss item: 0.193057119846344
26
train loss item: 0.19066296517848969
27
train loss item: 0.2409401684999466
28
train loss item: 0.0949055477976799
29
train loss item: 0.6780020594596863
30
train loss item: 2.1617324352264404
31
train loss item: 0.5385870933532715
32
train loss item: 0.11407691985368729
33
train loss item: 0.4134261906147003
34
train loss item: 0.14441542327404022
35
train loss item: 2.3358311653137207
36
train loss item: 0.43693941831588745
37
train loss item: 0.36917948722839355
38
train loss item: 0.43242162466049194
39
train loss item: 0.23042257130146027
40
train loss item: 0.16814324259757996
41
train loss item: 0.24019788205623627
42
train loss item: 0.2469116747379303
43
train loss item: 0.17743052542209625
44
train loss item: 0.6611793041229248
45
train loss item: 0.1388126164674759
46
train loss item: 0.14318233728408813
47
train loss item: 0.3221062123775482
48
train loss item: 0.21499000489711761
49
train loss item: 0.15065324306488037
50
train loss item: 0.28265777230262756
51
train loss item: 0.8100708723068237
52
train loss item: 0.11142285168170929
53
train loss item: 0.16001297533512115
54
train loss item: 2.21523380279541
55
train loss item: 0.2062350958585739
56
train loss item: 0.2359377145767212
57
train loss item: 0.23165252804756165
58
train loss item: 0.16239018738269806
59
train loss item: 0.13785438239574432
60
train loss item: 0.8047785758972168
61
train loss item: 2.1608493328094482
62
train loss item: 0.1969069093465805
63
train loss item: 0.3297899663448334
64
train loss item: 0.16516204178333282
65
train loss item: 0.5041583180427551
66
train loss item: 0.3822867274284363
67
train loss item: 0.19891151785850525
68
train loss item: 0.2672577500343323
69
train loss item: 0.2948928475379944
70
train loss item: 0.23251618444919586
71
train loss item: 0.1586131453514099
72
train loss item: 0.1860387772321701
73
train loss item: 0.27406132221221924
74
train loss item: 0.10530591011047363
75
train loss item: 0.12344599515199661
76
train loss item: 0.8425178527832031
77
train loss item: 1.2550443410873413
78
train loss item: 0.09757880121469498
79
train loss item: 0.268226683139801
80
train loss item: 0.12739814817905426
81
train loss item: 0.1842372864484787
82
train loss item: 0.2055894136428833
83
train loss item: 0.5466077327728271
84
train loss item: 0.3777623474597931
85
train loss item: 0.5330870747566223
86
train loss item: 4.215088367462158
87
train loss item: 0.17734459042549133
88
train loss item: 0.3556234538555145
epoch train loss: 0.46117207926980563
testing phase
test loss item: 0.17185135185718536
test loss item: 0.12230392545461655
test loss item: 0.5072982907295227
test loss item: 0.22891902923583984
test loss item: 0.24510382115840912
test loss item: 0.12305336445569992
test loss item: 1.4333094358444214
test loss item: 0.48860663175582886
test loss item: 0.19665023684501648
test loss item: 0.37371426820755005
test loss item: 0.7726402282714844
test loss item: 0.1946025788784027
test loss item: 0.19060413539409637
test loss item: 0.2956204116344452
test loss item: 0.1682789921760559
test loss item: 0.10979831963777542
test loss item: 0.26289406418800354
test loss item: 0.44537076354026794
test loss item: 0.5899032950401306
test loss item: 0.2446053922176361
test loss item: 0.7011533975601196
test loss item: 0.36674994230270386
test loss item: 0.2977793216705322
test loss item: 0.1670476347208023
test loss item: 0.21676725149154663
test loss item: 0.20841073989868164
test loss item: 0.29620638489723206
test loss item: 0.19124044477939606
test loss item: 0.3097192645072937
test loss item: 0.3309396207332611
test loss item: 0.6885261535644531
test loss item: 0.1109333410859108
test loss item: 0.1453302502632141
test loss item: 0.5457643866539001
test loss item: 0.3987344205379486
test loss item: 0.41455402970314026
test loss item: 0.7145816683769226
test loss item: 1.2941831350326538
test loss item: 0.45374423265457153
test loss item: 0.25651559233665466
test loss item: 0.28220370411872864
test loss item: 0.19467271864414215
test loss item: 0.3459825813770294
test loss item: 0.21106088161468506
test loss item: 0.5729683041572571
test loss item: 0.36841100454330444
test loss item: 0.30158039927482605
test loss item: 0.2197207808494568
test loss item: 0.4307021498680115
test loss item: 0.6200262904167175
test loss item: 0.29493746161460876
test loss item: 0.14634865522384644
test loss item: 0.22325770556926727
test loss item: 0.20920200645923615
test loss item: 0.2906550168991089
test loss item: 0.7527592778205872
test loss item: 0.5172214508056641
test loss item: 0.24410055577754974
test loss item: 0.22114048898220062
test loss item: 0.2224608212709427
test loss item: 0.4382052719593048
test loss item: 0.22003532946109772
test loss item: 0.19039806723594666
test loss item: 0.25049614906311035
test loss item: 0.6925988793373108
test loss item: 0.31649526953697205
test loss item: 0.28245028853416443
test loss item: 0.24438099563121796
test loss item: 0.5175665020942688
test loss item: 0.37640729546546936
test loss item: 0.09176822006702423
test loss item: 0.8276894688606262
test loss item: 0.3061959445476532
test loss item: 0.3576662242412567
test loss item: 0.13971570134162903
test loss item: 0.19282203912734985
test loss item: 0.16926637291908264
test loss item: 1.2970921993255615
test loss item: 0.4086992144584656
test loss item: 0.1812957376241684
test loss item: 0.08898446708917618
test loss item: 0.8436911702156067
test loss item: 0.7663775086402893
test loss item: 0.8893364667892456
test loss item: 0.21045401692390442
test loss item: 0.20661412179470062
test loss item: 0.09105405956506729
test loss item: 0.0949273556470871
test loss item: 0.16055811941623688
Epoch [20/50], Training Loss: 0.4612, Testing Loss: 0.3685
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 21/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41321462392807007
1
train loss item: 1.1160110235214233
2
train loss item: 0.21920616924762726
3
train loss item: 0.47114884853363037
4
train loss item: 0.3498256206512451
5
train loss item: 0.30152034759521484
6
train loss item: 0.23370151221752167
7
train loss item: 0.7419186234474182
8
train loss item: 0.13521480560302734
9
train loss item: 0.22240377962589264
10
train loss item: 0.30617639422416687
11
train loss item: 0.26053059101104736
12
train loss item: 0.1341029703617096
13
train loss item: 0.4702145457267761
14
train loss item: 0.23030011355876923
15
train loss item: 0.5877775549888611
16
train loss item: 0.09382672607898712
17
train loss item: 0.24205757677555084
18
train loss item: 0.2958988845348358
19
train loss item: 0.24670028686523438
20
train loss item: 0.232448011636734
21
train loss item: 0.13554899394512177
22
train loss item: 0.8815147280693054
23
train loss item: 0.8534871935844421
24
train loss item: 0.4915226697921753
25
train loss item: 0.19092048704624176
26
train loss item: 0.18304476141929626
27
train loss item: 0.2346057891845703
28
train loss item: 0.09231150895357132
29
train loss item: 0.667817234992981
30
train loss item: 2.126589775085449
31
train loss item: 0.5231520533561707
32
train loss item: 0.11003059148788452
33
train loss item: 0.40045326948165894
34
train loss item: 0.14483220875263214
35
train loss item: 2.312039613723755
36
train loss item: 0.4339663088321686
37
train loss item: 0.3648843765258789
38
train loss item: 0.41980862617492676
39
train loss item: 0.22393901646137238
40
train loss item: 0.16219276189804077
41
train loss item: 0.23351821303367615
42
train loss item: 0.24579273164272308
43
train loss item: 0.1715836077928543
44
train loss item: 0.6456136703491211
45
train loss item: 0.13191844522953033
46
train loss item: 0.1342172920703888
47
train loss item: 0.31816479563713074
48
train loss item: 0.2062070220708847
49
train loss item: 0.14737747609615326
50
train loss item: 0.27449196577072144
51
train loss item: 0.7929558157920837
52
train loss item: 0.10830467939376831
53
train loss item: 0.15239207446575165
54
train loss item: 2.190098285675049
55
train loss item: 0.19526700675487518
56
train loss item: 0.22762833535671234
57
train loss item: 0.2256542146205902
58
train loss item: 0.15763278305530548
59
train loss item: 0.13085505366325378
60
train loss item: 0.787003755569458
61
train loss item: 2.130751609802246
62
train loss item: 0.1967449188232422
63
train loss item: 0.324666827917099
64
train loss item: 0.16046901047229767
65
train loss item: 0.49898990988731384
66
train loss item: 0.378413587808609
67
train loss item: 0.19449365139007568
68
train loss item: 0.26450303196907043
69
train loss item: 0.2904359698295593
70
train loss item: 0.23059362173080444
71
train loss item: 0.15892915427684784
72
train loss item: 0.17812228202819824
73
train loss item: 0.2684905230998993
74
train loss item: 0.10435669869184494
75
train loss item: 0.11736813187599182
76
train loss item: 0.8212052583694458
77
train loss item: 1.2395230531692505
78
train loss item: 0.0974445790052414
79
train loss item: 0.2604455053806305
80
train loss item: 0.12447504699230194
81
train loss item: 0.1799817532300949
82
train loss item: 0.19936510920524597
83
train loss item: 0.5354081988334656
84
train loss item: 0.37934884428977966
85
train loss item: 0.5130003690719604
86
train loss item: 4.179292678833008
87
train loss item: 0.16984470188617706
88
train loss item: 0.3529585003852844
epoch train loss: 0.4526197834965888
testing phase
test loss item: 0.1683543473482132
test loss item: 0.11138671636581421
test loss item: 0.48764941096305847
test loss item: 0.2234656810760498
test loss item: 0.23493874073028564
test loss item: 0.11500705778598785
test loss item: 1.4564363956451416
test loss item: 0.4881495535373688
test loss item: 0.18818451464176178
test loss item: 0.3631379306316376
test loss item: 0.746467649936676
test loss item: 0.18613071739673615
test loss item: 0.17612946033477783
test loss item: 0.28451353311538696
test loss item: 0.159291610121727
test loss item: 0.10349787771701813
test loss item: 0.2547919452190399
test loss item: 0.43430691957473755
test loss item: 0.5855939984321594
test loss item: 0.22906175255775452
test loss item: 0.6822614669799805
test loss item: 0.3622986674308777
test loss item: 0.2789960503578186
test loss item: 0.15751229226589203
test loss item: 0.20816725492477417
test loss item: 0.20164360105991364
test loss item: 0.28642308712005615
test loss item: 0.18171249330043793
test loss item: 0.2995700538158417
test loss item: 0.3245724141597748
test loss item: 0.6760112047195435
test loss item: 0.10948756337165833
test loss item: 0.1350424885749817
test loss item: 0.5312085747718811
test loss item: 0.3864729404449463
test loss item: 0.4010220170021057
test loss item: 0.7124961018562317
test loss item: 1.2431780099868774
test loss item: 0.4416263997554779
test loss item: 0.25006037950515747
test loss item: 0.2809758186340332
test loss item: 0.18189361691474915
test loss item: 0.3353811204433441
test loss item: 0.2073739767074585
test loss item: 0.5564429759979248
test loss item: 0.35612067580223083
test loss item: 0.28455665707588196
test loss item: 0.2122415453195572
test loss item: 0.4148690104484558
test loss item: 0.6030260920524597
test loss item: 0.28328579664230347
test loss item: 0.14138902723789215
test loss item: 0.21896755695343018
test loss item: 0.2043236643075943
test loss item: 0.28388163447380066
test loss item: 0.7257575988769531
test loss item: 0.5059292316436768
test loss item: 0.23574267327785492
test loss item: 0.21283607184886932
test loss item: 0.21066908538341522
test loss item: 0.42891329526901245
test loss item: 0.2128891795873642
test loss item: 0.18422015011310577
test loss item: 0.23725509643554688
test loss item: 0.6730254292488098
test loss item: 0.313850075006485
test loss item: 0.27231043577194214
test loss item: 0.2370278239250183
test loss item: 0.49850645661354065
test loss item: 0.3705465495586395
test loss item: 0.08142700046300888
test loss item: 0.8351743817329407
test loss item: 0.29068294167518616
test loss item: 0.3466785252094269
test loss item: 0.1293504387140274
test loss item: 0.17327894270420074
test loss item: 0.1605319231748581
test loss item: 1.2384921312332153
test loss item: 0.3917493522167206
test loss item: 0.1750228852033615
test loss item: 0.08214008063077927
test loss item: 0.8291839957237244
test loss item: 0.7663650512695312
test loss item: 0.8517988324165344
test loss item: 0.20484121143817902
test loss item: 0.1956903636455536
test loss item: 0.0816216766834259
test loss item: 0.08974015712738037
test loss item: 0.15953102707862854
Epoch [21/50], Training Loss: 0.4526, Testing Loss: 0.3577
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 22/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4084379971027374
1
train loss item: 1.0885963439941406
2
train loss item: 0.21065501868724823
3
train loss item: 0.45885950326919556
4
train loss item: 0.3491537272930145
5
train loss item: 0.29895588755607605
6
train loss item: 0.2200593799352646
7
train loss item: 0.7231674194335938
8
train loss item: 0.13260269165039062
9
train loss item: 0.21841222047805786
10
train loss item: 0.3038291335105896
11
train loss item: 0.2602561116218567
12
train loss item: 0.12903714179992676
13
train loss item: 0.4608546495437622
14
train loss item: 0.22577540576457977
15
train loss item: 0.576767086982727
16
train loss item: 0.08754955232143402
17
train loss item: 0.2384280264377594
18
train loss item: 0.29160642623901367
19
train loss item: 0.2387295514345169
20
train loss item: 0.22074756026268005
21
train loss item: 0.13436058163642883
22
train loss item: 0.8610367774963379
23
train loss item: 0.8319573402404785
24
train loss item: 0.48078206181526184
25
train loss item: 0.19281922280788422
26
train loss item: 0.17829224467277527
27
train loss item: 0.22854475677013397
28
train loss item: 0.0857657641172409
29
train loss item: 0.6545979976654053
30
train loss item: 2.093684196472168
31
train loss item: 0.5120112299919128
32
train loss item: 0.10828467458486557
33
train loss item: 0.3900138735771179
34
train loss item: 0.14429756999015808
35
train loss item: 2.2890048027038574
36
train loss item: 0.4328071177005768
37
train loss item: 0.3611743152141571
38
train loss item: 0.416242390871048
39
train loss item: 0.21736101806163788
40
train loss item: 0.15818752348423004
41
train loss item: 0.22902162373065948
42
train loss item: 0.24515429139137268
43
train loss item: 0.1664593517780304
44
train loss item: 0.6311704516410828
45
train loss item: 0.12698432803153992
46
train loss item: 0.12879739701747894
47
train loss item: 0.3134828209877014
48
train loss item: 0.19790177047252655
49
train loss item: 0.14615319669246674
50
train loss item: 0.26421767473220825
51
train loss item: 0.7771773934364319
52
train loss item: 0.1009734719991684
53
train loss item: 0.14773330092430115
54
train loss item: 2.1661529541015625
55
train loss item: 0.18287807703018188
56
train loss item: 0.22232314944267273
57
train loss item: 0.2217179834842682
58
train loss item: 0.15314076840877533
59
train loss item: 0.1286517232656479
60
train loss item: 0.7652727365493774
61
train loss item: 2.1021547317504883
62
train loss item: 0.19848720729351044
63
train loss item: 0.31911832094192505
64
train loss item: 0.1571030169725418
65
train loss item: 0.485993355512619
66
train loss item: 0.37620559334754944
67
train loss item: 0.19219601154327393
68
train loss item: 0.2563806176185608
69
train loss item: 0.28596562147140503
70
train loss item: 0.23009848594665527
71
train loss item: 0.14997752010822296
72
train loss item: 0.1705433428287506
73
train loss item: 0.26299747824668884
74
train loss item: 0.10392314940690994
75
train loss item: 0.11125772446393967
76
train loss item: 0.7996463179588318
77
train loss item: 1.2225054502487183
78
train loss item: 0.09262824803590775
79
train loss item: 0.25425010919570923
80
train loss item: 0.117293581366539
81
train loss item: 0.17841868102550507
82
train loss item: 0.19336755573749542
83
train loss item: 0.5235248804092407
84
train loss item: 0.38029834628105164
85
train loss item: 0.49675533175468445
86
train loss item: 4.145147323608398
87
train loss item: 0.16374778747558594
88
train loss item: 0.3514791429042816
epoch train loss: 0.444388041502974
testing phase
test loss item: 0.1665818840265274
test loss item: 0.10810831189155579
test loss item: 0.4732655882835388
test loss item: 0.22137634456157684
test loss item: 0.22848986089229584
test loss item: 0.11057984083890915
test loss item: 1.4856714010238647
test loss item: 0.4874964654445648
test loss item: 0.18478263914585114
test loss item: 0.355299174785614
test loss item: 0.7275916337966919
test loss item: 0.18282684683799744
test loss item: 0.16846780478954315
test loss item: 0.27548709511756897
test loss item: 0.15611690282821655
test loss item: 0.1022462323307991
test loss item: 0.2511349618434906
test loss item: 0.42433151602745056
test loss item: 0.5829241275787354
test loss item: 0.22206854820251465
test loss item: 0.6627812385559082
test loss item: 0.3614712357521057
test loss item: 0.2652568221092224
test loss item: 0.1536613255739212
test loss item: 0.20271030068397522
test loss item: 0.19734787940979004
test loss item: 0.2804885506629944
test loss item: 0.17560306191444397
test loss item: 0.2942805588245392
test loss item: 0.3194256126880646
test loss item: 0.6712396740913391
test loss item: 0.11104421317577362
test loss item: 0.1305411159992218
test loss item: 0.5195038318634033
test loss item: 0.37616968154907227
test loss item: 0.3926243782043457
test loss item: 0.7117723822593689
test loss item: 1.203660488128662
test loss item: 0.4316466748714447
test loss item: 0.24775099754333496
test loss item: 0.2816638946533203
test loss item: 0.17448750138282776
test loss item: 0.3280896842479706
test loss item: 0.20714016258716583
test loss item: 0.5396352410316467
test loss item: 0.35010406374931335
test loss item: 0.2712442874908447
test loss item: 0.2086474895477295
test loss item: 0.4035872220993042
test loss item: 0.5922157168388367
test loss item: 0.274128258228302
test loss item: 0.13853342831134796
test loss item: 0.21644823253154755
test loss item: 0.20265786349773407
test loss item: 0.2776835560798645
test loss item: 0.7057148814201355
test loss item: 0.49705350399017334
test loss item: 0.22629043459892273
test loss item: 0.20722664892673492
test loss item: 0.20367051661014557
test loss item: 0.4213297665119171
test loss item: 0.21007472276687622
test loss item: 0.1813265085220337
test loss item: 0.2303784191608429
test loss item: 0.6586197018623352
test loss item: 0.31288942694664
test loss item: 0.26653411984443665
test loss item: 0.23438875377178192
test loss item: 0.48322930932044983
test loss item: 0.3687703013420105
test loss item: 0.0795319527387619
test loss item: 0.8469159007072449
test loss item: 0.27964073419570923
test loss item: 0.34278202056884766
test loss item: 0.1250087171792984
test loss item: 0.1603263020515442
test loss item: 0.15744587779045105
test loss item: 1.190046787261963
test loss item: 0.3789369761943817
test loss item: 0.17024385929107666
test loss item: 0.07942250370979309
test loss item: 0.822006344795227
test loss item: 0.7691519260406494
test loss item: 0.8231832981109619
test loss item: 0.20100361108779907
test loss item: 0.18842852115631104
test loss item: 0.07707291841506958
test loss item: 0.08838310837745667
test loss item: 0.16050921380519867
Epoch [22/50], Training Loss: 0.4444, Testing Loss: 0.3510
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 23/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.40376827120780945
1
train loss item: 1.062140941619873
2
train loss item: 0.20400337874889374
3
train loss item: 0.45109957456588745
4
train loss item: 0.34872961044311523
5
train loss item: 0.2969723641872406
6
train loss item: 0.21020644903182983
7
train loss item: 0.7048766016960144
8
train loss item: 0.13067330420017242
9
train loss item: 0.21512359380722046
10
train loss item: 0.3016147315502167
11
train loss item: 0.2590349316596985
12
train loss item: 0.12570519745349884
13
train loss item: 0.45338496565818787
14
train loss item: 0.22084686160087585
15
train loss item: 0.5659624934196472
16
train loss item: 0.08420896530151367
17
train loss item: 0.23137785494327545
18
train loss item: 0.2867494225502014
19
train loss item: 0.2320692092180252
20
train loss item: 0.20848825573921204
21
train loss item: 0.13214194774627686
22
train loss item: 0.8375900387763977
23
train loss item: 0.8123602867126465
24
train loss item: 0.46942970156669617
25
train loss item: 0.1944604068994522
26
train loss item: 0.17359595000743866
27
train loss item: 0.2213786244392395
28
train loss item: 0.08266659080982208
29
train loss item: 0.6414069533348083
30
train loss item: 2.063993453979492
31
train loss item: 0.50169438123703
32
train loss item: 0.10905490070581436
33
train loss item: 0.38239017128944397
34
train loss item: 0.1431228518486023
35
train loss item: 2.2668895721435547
36
train loss item: 0.43033328652381897
37
train loss item: 0.3568166494369507
38
train loss item: 0.41642364859580994
39
train loss item: 0.21099352836608887
40
train loss item: 0.15532170236110687
41
train loss item: 0.223920077085495
42
train loss item: 0.2452395260334015
43
train loss item: 0.16322365403175354
44
train loss item: 0.6174566745758057
45
train loss item: 0.12609750032424927
46
train loss item: 0.12952183187007904
47
train loss item: 0.3104788362979889
48
train loss item: 0.19223105907440186
49
train loss item: 0.14565294981002808
50
train loss item: 0.2554675042629242
51
train loss item: 0.7635764479637146
52
train loss item: 0.09622703492641449
53
train loss item: 0.14531005918979645
54
train loss item: 2.143878221511841
55
train loss item: 0.17424549162387848
56
train loss item: 0.21829205751419067
57
train loss item: 0.21880540251731873
58
train loss item: 0.15003740787506104
59
train loss item: 0.1307956427335739
60
train loss item: 0.7441900372505188
61
train loss item: 2.0757088661193848
62
train loss item: 0.19905592501163483
63
train loss item: 0.31518182158470154
64
train loss item: 0.15536880493164062
65
train loss item: 0.468499094247818
66
train loss item: 0.3733043968677521
67
train loss item: 0.19100166857242584
68
train loss item: 0.24701565504074097
69
train loss item: 0.28033915162086487
70
train loss item: 0.23014940321445465
71
train loss item: 0.14040300250053406
72
train loss item: 0.16518999636173248
73
train loss item: 0.2585581839084625
74
train loss item: 0.10660948604345322
75
train loss item: 0.10945288091897964
76
train loss item: 0.7805383205413818
77
train loss item: 1.207337498664856
78
train loss item: 0.08880685269832611
79
train loss item: 0.24977435171604156
80
train loss item: 0.11309420317411423
81
train loss item: 0.17819876968860626
82
train loss item: 0.18801523745059967
83
train loss item: 0.5129887461662292
84
train loss item: 0.3789300322532654
85
train loss item: 0.4848366975784302
86
train loss item: 4.113205909729004
87
train loss item: 0.15986445546150208
88
train loss item: 0.34727561473846436
epoch train loss: 0.43721858504113187
testing phase
test loss item: 0.16485944390296936
test loss item: 0.11121440678834915
test loss item: 0.46774882078170776
test loss item: 0.2198721319437027
test loss item: 0.22749397158622742
test loss item: 0.11130204796791077
test loss item: 1.5146290063858032
test loss item: 0.49678152799606323
test loss item: 0.18466497957706451
test loss item: 0.3509098291397095
test loss item: 0.7174950838088989
test loss item: 0.18235716223716736
test loss item: 0.16922996938228607
test loss item: 0.2672101855278015
test loss item: 0.15753434598445892
test loss item: 0.10340014100074768
test loss item: 0.24951674044132233
test loss item: 0.41885530948638916
test loss item: 0.5861037969589233
test loss item: 0.22089806199073792
test loss item: 0.6527665853500366
test loss item: 0.36274588108062744
test loss item: 0.26506951451301575
test loss item: 0.15393446385860443
test loss item: 0.19947296380996704
test loss item: 0.19499388337135315
test loss item: 0.27563607692718506
test loss item: 0.17457278072834015
test loss item: 0.29313045740127563
test loss item: 0.3145681619644165
test loss item: 0.6723928451538086
test loss item: 0.1118890717625618
test loss item: 0.13052570819854736
test loss item: 0.513302743434906
test loss item: 0.37102431058883667
test loss item: 0.3893581032752991
test loss item: 0.7156177163124084
test loss item: 1.181361198425293
test loss item: 0.42516589164733887
test loss item: 0.247934490442276
test loss item: 0.2807757556438446
test loss item: 0.17947883903980255
test loss item: 0.32524701952934265
test loss item: 0.20595213770866394
test loss item: 0.5299283266067505
test loss item: 0.3493320643901825
test loss item: 0.27026116847991943
test loss item: 0.20172177255153656
test loss item: 0.40038949251174927
test loss item: 0.5879027247428894
test loss item: 0.2709377408027649
test loss item: 0.1349657028913498
test loss item: 0.21392227709293365
test loss item: 0.2000754326581955
test loss item: 0.27405795454978943
test loss item: 0.6953388452529907
test loss item: 0.4952228367328644
test loss item: 0.22128717601299286
test loss item: 0.2047731727361679
test loss item: 0.20323361456394196
test loss item: 0.4160365164279938
test loss item: 0.21168272197246552
test loss item: 0.1804129034280777
test loss item: 0.22998690605163574
test loss item: 0.6553042531013489
test loss item: 0.3101958930492401
test loss item: 0.264781653881073
test loss item: 0.23406803607940674
test loss item: 0.4759189188480377
test loss item: 0.3731215298175812
test loss item: 0.08226355165243149
test loss item: 0.8629872798919678
test loss item: 0.2743861973285675
test loss item: 0.343081533908844
test loss item: 0.12345661967992783
test loss item: 0.1641703099012375
test loss item: 0.1581793576478958
test loss item: 1.1631749868392944
test loss item: 0.3695690929889679
test loss item: 0.1678161919116974
test loss item: 0.07749377936124802
test loss item: 0.8230139017105103
test loss item: 0.7746945023536682
test loss item: 0.808958888053894
test loss item: 0.1976221799850464
test loss item: 0.18411295115947723
test loss item: 0.07482387125492096
test loss item: 0.08726535737514496
test loss item: 0.16023240983486176
Epoch [23/50], Training Loss: 0.4372, Testing Loss: 0.3490
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 24/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3976721465587616
1
train loss item: 1.0386806726455688
2
train loss item: 0.20031048357486725
3
train loss item: 0.442023903131485
4
train loss item: 0.3426744341850281
5
train loss item: 0.2920685410499573
6
train loss item: 0.2044340968132019
7
train loss item: 0.6869389414787292
8
train loss item: 0.12594009935855865
9
train loss item: 0.2107296735048294
10
train loss item: 0.2931913435459137
11
train loss item: 0.25464317202568054
12
train loss item: 0.12234722077846527
13
train loss item: 0.4434773027896881
14
train loss item: 0.21339969336986542
15
train loss item: 0.5568757653236389
16
train loss item: 0.08139926940202713
17
train loss item: 0.22237616777420044
18
train loss item: 0.2805638611316681
19
train loss item: 0.2286759316921234
20
train loss item: 0.1991667002439499
21
train loss item: 0.12717607617378235
22
train loss item: 0.8155070543289185
23
train loss item: 0.7932458519935608
24
train loss item: 0.45910218358039856
25
train loss item: 0.19188432395458221
26
train loss item: 0.16761350631713867
27
train loss item: 0.21228161454200745
28
train loss item: 0.0803312212228775
29
train loss item: 0.6271975636482239
30
train loss item: 2.0352768898010254
31
train loss item: 0.4882875382900238
32
train loss item: 0.10777182132005692
33
train loss item: 0.3733452260494232
34
train loss item: 0.14135529100894928
35
train loss item: 2.2448887825012207
36
train loss item: 0.42343419790267944
37
train loss item: 0.3519543409347534
38
train loss item: 0.41153284907341003
39
train loss item: 0.20433256030082703
40
train loss item: 0.15220412611961365
41
train loss item: 0.21559293568134308
42
train loss item: 0.24485652148723602
43
train loss item: 0.15965676307678223
44
train loss item: 0.6034321784973145
45
train loss item: 0.12551382184028625
46
train loss item: 0.13227352499961853
47
train loss item: 0.30876991152763367
48
train loss item: 0.1883644163608551
49
train loss item: 0.1417376697063446
50
train loss item: 0.25093093514442444
51
train loss item: 0.7494478821754456
52
train loss item: 0.09360270202159882
53
train loss item: 0.1423729807138443
54
train loss item: 2.122220277786255
55
train loss item: 0.16928113996982574
56
train loss item: 0.21243706345558167
57
train loss item: 0.21485596895217896
58
train loss item: 0.14663587510585785
59
train loss item: 0.13053593039512634
60
train loss item: 0.7254440784454346
61
train loss item: 2.049576759338379
62
train loss item: 0.19528646767139435
63
train loss item: 0.3128713071346283
64
train loss item: 0.1518225073814392
65
train loss item: 0.45297253131866455
66
train loss item: 0.36670762300491333
67
train loss item: 0.18727989494800568
68
train loss item: 0.241548553109169
69
train loss item: 0.2729836702346802
70
train loss item: 0.22798533737659454
71
train loss item: 0.13512730598449707
72
train loss item: 0.15907201170921326
73
train loss item: 0.2552359104156494
74
train loss item: 0.1066318228840828
75
train loss item: 0.10907100141048431
76
train loss item: 0.7640716433525085
77
train loss item: 1.1938982009887695
78
train loss item: 0.08499756455421448
79
train loss item: 0.2457408607006073
80
train loss item: 0.1124238520860672
81
train loss item: 0.17619957029819489
82
train loss item: 0.1824350655078888
83
train loss item: 0.5032336115837097
84
train loss item: 0.374822199344635
85
train loss item: 0.473758339881897
86
train loss item: 4.0815558433532715
87
train loss item: 0.15632420778274536
88
train loss item: 0.33806514739990234
epoch train loss: 0.42961768345551543
testing phase
test loss item: 0.1625601351261139
test loss item: 0.11396665126085281
test loss item: 0.4751851260662079
test loss item: 0.21691684424877167
test loss item: 0.23090948164463043
test loss item: 0.11596223711967468
test loss item: 1.501278281211853
test loss item: 0.49449971318244934
test loss item: 0.18801264464855194
test loss item: 0.3521493077278137
test loss item: 0.7187616229057312
test loss item: 0.18362009525299072
test loss item: 0.1768442541360855
test loss item: 0.2601955831050873
test loss item: 0.1594720333814621
test loss item: 0.10335230827331543
test loss item: 0.24672973155975342
test loss item: 0.42210233211517334
test loss item: 0.5820043683052063
test loss item: 0.22314591705799103
test loss item: 0.6602274775505066
test loss item: 0.35866305232048035
test loss item: 0.29006943106651306
test loss item: 0.15272098779678345
test loss item: 0.19917450845241547
test loss item: 0.19291256368160248
test loss item: 0.2717130482196808
test loss item: 0.1774541586637497
test loss item: 0.29293859004974365
test loss item: 0.31164178252220154
test loss item: 0.6698879599571228
test loss item: 0.1101638600230217
test loss item: 0.12958790361881256
test loss item: 0.5159222483634949
test loss item: 0.37446069717407227
test loss item: 0.3882204294204712
test loss item: 0.7106329202651978
test loss item: 1.185033917427063
test loss item: 0.4240156412124634
test loss item: 0.24583150446414948
test loss item: 0.2753528952598572
test loss item: 0.2122017741203308
test loss item: 0.3305802345275879
test loss item: 0.20217283070087433
test loss item: 0.5333994626998901
test loss item: 0.34638091921806335
test loss item: 0.29460808634757996
test loss item: 0.19457559287548065
test loss item: 0.40498462319374084
test loss item: 0.5875820517539978
test loss item: 0.2764683961868286
test loss item: 0.13245825469493866
test loss item: 0.21203090250492096
test loss item: 0.19616928696632385
test loss item: 0.2759071886539459
test loss item: 0.7004664540290833
test loss item: 0.493099570274353
test loss item: 0.22376810014247894
test loss item: 0.20439110696315765
test loss item: 0.2090391218662262
test loss item: 0.41760876774787903
test loss item: 0.21096068620681763
test loss item: 0.17867448925971985
test loss item: 0.2340589016675949
test loss item: 0.660805344581604
test loss item: 0.3054199516773224
test loss item: 0.26293426752090454
test loss item: 0.23286794126033783
test loss item: 0.4776689410209656
test loss item: 0.37132006883621216
test loss item: 0.0848844051361084
test loss item: 0.8552865982055664
test loss item: 0.27469494938850403
test loss item: 0.3385051190853119
test loss item: 0.1239561140537262
test loss item: 0.19994118809700012
test loss item: 0.15680870413780212
test loss item: 1.1682404279708862
test loss item: 0.36308956146240234
test loss item: 0.1681463122367859
test loss item: 0.0745738297700882
test loss item: 0.8210781812667847
test loss item: 0.7720504999160767
test loss item: 0.8146181106567383
test loss item: 0.19403965771198273
test loss item: 0.1834629327058792
test loss item: 0.07208779454231262
test loss item: 0.08399705588817596
test loss item: 0.15698635578155518
Epoch [24/50], Training Loss: 0.4296, Testing Loss: 0.3500
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 25/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3902583718299866
1
train loss item: 1.0165319442749023
2
train loss item: 0.19742515683174133
3
train loss item: 0.43054404854774475
4
train loss item: 0.33184367418289185
5
train loss item: 0.2835005223751068
6
train loss item: 0.20039477944374084
7
train loss item: 0.6706831455230713
8
train loss item: 0.11871139705181122
9
train loss item: 0.20554453134536743
10
train loss item: 0.2809920608997345
11
train loss item: 0.248797208070755
12
train loss item: 0.11959687620401382
13
train loss item: 0.43202435970306396
14
train loss item: 0.20499193668365479
15
train loss item: 0.5436276793479919
16
train loss item: 0.0769624337553978
17
train loss item: 0.21515947580337524
18
train loss item: 0.27290403842926025
19
train loss item: 0.22617888450622559
20
train loss item: 0.19445601105690002
21
train loss item: 0.1228906586766243
22
train loss item: 0.7897913455963135
23
train loss item: 0.7761570811271667
24
train loss item: 0.4486120939254761
25
train loss item: 0.18590395152568817
26
train loss item: 0.16223183274269104
27
train loss item: 0.20382177829742432
28
train loss item: 0.07611300051212311
29
train loss item: 0.6056474447250366
30
train loss item: 2.006225824356079
31
train loss item: 0.47431063652038574
32
train loss item: 0.10454030334949493
33
train loss item: 0.3648909032344818
34
train loss item: 0.13869871199131012
35
train loss item: 2.2230777740478516
36
train loss item: 0.4139723479747772
37
train loss item: 0.34924840927124023
38
train loss item: 0.3998027741909027
39
train loss item: 0.1977965235710144
40
train loss item: 0.14782129228115082
41
train loss item: 0.20690713822841644
42
train loss item: 0.2437760978937149
43
train loss item: 0.1565200537443161
44
train loss item: 0.5911412835121155
45
train loss item: 0.1229594498872757
46
train loss item: 0.1312558352947235
47
train loss item: 0.30405306816101074
48
train loss item: 0.18550512194633484
49
train loss item: 0.1360238790512085
50
train loss item: 0.2478359490633011
51
train loss item: 0.7313722372055054
52
train loss item: 0.09043450653553009
53
train loss item: 0.13930252194404602
54
train loss item: 2.100855827331543
55
train loss item: 0.16664615273475647
56
train loss item: 0.20527096092700958
57
train loss item: 0.2093914896249771
58
train loss item: 0.14309389889240265
59
train loss item: 0.12698045372962952
60
train loss item: 0.7057777643203735
61
train loss item: 2.024421215057373
62
train loss item: 0.1853543072938919
63
train loss item: 0.3094368577003479
64
train loss item: 0.14833547174930573
65
train loss item: 0.440658301115036
66
train loss item: 0.357058048248291
67
train loss item: 0.1814860850572586
68
train loss item: 0.23815034329891205
69
train loss item: 0.2642555236816406
70
train loss item: 0.2223915159702301
71
train loss item: 0.1323973834514618
72
train loss item: 0.15221932530403137
73
train loss item: 0.2515944838523865
74
train loss item: 0.1009744182229042
75
train loss item: 0.10874750465154648
76
train loss item: 0.7498637437820435
77
train loss item: 1.1777589321136475
78
train loss item: 0.07993277907371521
79
train loss item: 0.2414059340953827
80
train loss item: 0.11100710928440094
81
train loss item: 0.1705441176891327
82
train loss item: 0.17832942306995392
83
train loss item: 0.4908187985420227
84
train loss item: 0.3709242343902588
85
train loss item: 0.462660551071167
86
train loss item: 4.050101280212402
87
train loss item: 0.15391814708709717
88
train loss item: 0.3242780566215515
epoch train loss: 0.42108776185954555
testing phase
test loss item: 0.16011682152748108
test loss item: 0.11261594295501709
test loss item: 0.4933897852897644
test loss item: 0.21194490790367126
test loss item: 0.23606108129024506
test loss item: 0.12273454666137695
test loss item: 1.427880883216858
test loss item: 0.4643612802028656
test loss item: 0.19330355525016785
test loss item: 0.35697460174560547
test loss item: 0.731417179107666
test loss item: 0.1818525791168213
test loss item: 0.18271154165267944
test loss item: 0.2559642791748047
test loss item: 0.16010171175003052
test loss item: 0.09969040751457214
test loss item: 0.24039575457572937
test loss item: 0.4327731430530548
test loss item: 0.5623134970664978
test loss item: 0.22403833270072937
test loss item: 0.6831314563751221
test loss item: 0.3447764217853546
test loss item: 0.3451991081237793
test loss item: 0.14900946617126465
test loss item: 0.20026321709156036
test loss item: 0.1905100792646408
test loss item: 0.2692641019821167
test loss item: 0.1815820038318634
test loss item: 0.29160556197166443
test loss item: 0.3104008138179779
test loss item: 0.6593828201293945
test loss item: 0.10485173016786575
test loss item: 0.12710799276828766
test loss item: 0.5252296924591064
test loss item: 0.385076105594635
test loss item: 0.3871707320213318
test loss item: 0.688065767288208
test loss item: 1.2146506309509277
test loss item: 0.42672765254974365
test loss item: 0.24057769775390625
test loss item: 0.26559412479400635
test loss item: 0.27694904804229736
test loss item: 0.34081801772117615
test loss item: 0.19481322169303894
test loss item: 0.5480600595474243
test loss item: 0.33641713857650757
test loss item: 0.3493413031101227
test loss item: 0.19047966599464417
test loss item: 0.4124380052089691
test loss item: 0.5886915922164917
test loss item: 0.2861439287662506
test loss item: 0.13081584870815277
test loss item: 0.21093976497650146
test loss item: 0.1888154149055481
test loss item: 0.282595157623291
test loss item: 0.7213398814201355
test loss item: 0.4849461615085602
test loss item: 0.2302026003599167
test loss item: 0.2043219953775406
test loss item: 0.21460790932178497
test loss item: 0.42533376812934875
test loss item: 0.20330913364887238
test loss item: 0.17483282089233398
test loss item: 0.2360759973526001
test loss item: 0.6724326014518738
test loss item: 0.2980959713459015
test loss item: 0.2583908438682556
test loss item: 0.2281741052865982
test loss item: 0.48387113213539124
test loss item: 0.3579326868057251
test loss item: 0.08402455598115921
test loss item: 0.8092831373214722
test loss item: 0.2801523506641388
test loss item: 0.32556861639022827
test loss item: 0.12435448169708252
test loss item: 0.2666633725166321
test loss item: 0.15208686888217926
test loss item: 1.2036817073822021
test loss item: 0.36094698309898376
test loss item: 0.17064175009727478
test loss item: 0.07192754000425339
test loss item: 0.8105161190032959
test loss item: 0.7553820013999939
test loss item: 0.8385831117630005
test loss item: 0.19093641638755798
test loss item: 0.18477259576320648
test loss item: 0.0690803974866867
test loss item: 0.07900980114936829
test loss item: 0.15285401046276093
Epoch [25/50], Training Loss: 0.4211, Testing Loss: 0.3517
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 26/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3827531039714813
1
train loss item: 0.9949776530265808
2
train loss item: 0.19158175587654114
3
train loss item: 0.41973230242729187
4
train loss item: 0.321306973695755
5
train loss item: 0.27336934208869934
6
train loss item: 0.19455492496490479
7
train loss item: 0.6565683484077454
8
train loss item: 0.11387830972671509
9
train loss item: 0.19924773275852203
10
train loss item: 0.2702288329601288
11
train loss item: 0.2448059618473053
12
train loss item: 0.11911386251449585
13
train loss item: 0.42237919569015503
14
train loss item: 0.1993332803249359
15
train loss item: 0.5243560671806335
16
train loss item: 0.07610860466957092
17
train loss item: 0.20945313572883606
18
train loss item: 0.2645593285560608
19
train loss item: 0.22052912414073944
20
train loss item: 0.1902490109205246
21
train loss item: 0.1214357390999794
22
train loss item: 0.7581896781921387
23
train loss item: 0.7618152499198914
24
train loss item: 0.4374721646308899
25
train loss item: 0.1802915334701538
26
train loss item: 0.15911321341991425
27
train loss item: 0.19806675612926483
28
train loss item: 0.07518390566110611
29
train loss item: 0.5768498778343201
30
train loss item: 1.976835012435913
31
train loss item: 0.46366170048713684
32
train loss item: 0.10193236172199249
33
train loss item: 0.35989564657211304
34
train loss item: 0.1373639553785324
35
train loss item: 2.201671838760376
36
train loss item: 0.40799906849861145
37
train loss item: 0.35073330998420715
38
train loss item: 0.3914209008216858
39
train loss item: 0.19254285097122192
40
train loss item: 0.14253519475460052
41
train loss item: 0.201522096991539
42
train loss item: 0.2425239086151123
43
train loss item: 0.15350912511348724
44
train loss item: 0.5822046399116516
45
train loss item: 0.12081483006477356
46
train loss item: 0.1246773898601532
47
train loss item: 0.29417502880096436
48
train loss item: 0.182879239320755
49
train loss item: 0.13269172608852386
50
train loss item: 0.2408614605665207
51
train loss item: 0.7108153104782104
52
train loss item: 0.08972125500440598
53
train loss item: 0.13721010088920593
54
train loss item: 2.079338788986206
55
train loss item: 0.16582335531711578
56
train loss item: 0.19863471388816833
57
train loss item: 0.2046527862548828
58
train loss item: 0.13845771551132202
59
train loss item: 0.12312322109937668
60
train loss item: 0.6840918064117432
61
train loss item: 2.0005791187286377
62
train loss item: 0.17287184298038483
63
train loss item: 0.3036304712295532
64
train loss item: 0.1457594633102417
65
train loss item: 0.4303434491157532
66
train loss item: 0.3502189815044403
67
train loss item: 0.17634464800357819
68
train loss item: 0.23195941746234894
69
train loss item: 0.2558349668979645
70
train loss item: 0.21523064374923706
71
train loss item: 0.1306275874376297
72
train loss item: 0.14838407933712006
73
train loss item: 0.2459145188331604
74
train loss item: 0.09528826922178268
75
train loss item: 0.10870440304279327
76
train loss item: 0.7366687059402466
77
train loss item: 1.1570451259613037
78
train loss item: 0.07919079065322876
79
train loss item: 0.23793897032737732
80
train loss item: 0.10926752537488937
81
train loss item: 0.1633133888244629
82
train loss item: 0.17646124958992004
83
train loss item: 0.4757796823978424
84
train loss item: 0.3722054958343506
85
train loss item: 0.4538011848926544
86
train loss item: 4.0185065269470215
87
train loss item: 0.15331700444221497
88
train loss item: 0.3101872205734253
epoch train loss: 0.41288988811246463
testing phase
test loss item: 0.15812158584594727
test loss item: 0.10653965920209885
test loss item: 0.5057880878448486
test loss item: 0.20481735467910767
test loss item: 0.23779793083667755
test loss item: 0.1277974396944046
test loss item: 1.3513957262039185
test loss item: 0.4276379942893982
test loss item: 0.1938481330871582
test loss item: 0.3556923568248749
test loss item: 0.7405624985694885
test loss item: 0.17069308459758759
test loss item: 0.17728251218795776
test loss item: 0.2513964772224426
test loss item: 0.15731491148471832
test loss item: 0.09225349128246307
test loss item: 0.23326840996742249
test loss item: 0.4381411075592041
test loss item: 0.5396944284439087
test loss item: 0.22057467699050903
test loss item: 0.700065553188324
test loss item: 0.3288179636001587
test loss item: 0.39752212166786194
test loss item: 0.1456606686115265
test loss item: 0.1981518566608429
test loss item: 0.1884520798921585
test loss item: 0.2665579915046692
test loss item: 0.18263933062553406
test loss item: 0.2871858775615692
test loss item: 0.30581068992614746
test loss item: 0.6464084386825562
test loss item: 0.09528098255395889
test loss item: 0.1250590682029724
test loss item: 0.5284048318862915
test loss item: 0.39093437790870667
test loss item: 0.3823106288909912
test loss item: 0.6611130237579346
test loss item: 1.238196849822998
test loss item: 0.4245554506778717
test loss item: 0.23608052730560303
test loss item: 0.25655263662338257
test loss item: 0.33348777890205383
test loss item: 0.34247416257858276
test loss item: 0.18425504863262177
test loss item: 0.5567564368247986
test loss item: 0.3264157772064209
test loss item: 0.4012467563152313
test loss item: 0.18866802752017975
test loss item: 0.41344377398490906
test loss item: 0.5865963101387024
test loss item: 0.2856985330581665
test loss item: 0.1256904900074005
test loss item: 0.20826713740825653
test loss item: 0.17365342378616333
test loss item: 0.28536665439605713
test loss item: 0.7374351620674133
test loss item: 0.4745214283466339
test loss item: 0.2304149568080902
test loss item: 0.20276814699172974
test loss item: 0.21019306778907776
test loss item: 0.4256496727466583
test loss item: 0.1954789012670517
test loss item: 0.17178955674171448
test loss item: 0.22897985577583313
test loss item: 0.6840693354606628
test loss item: 0.2871844172477722
test loss item: 0.2540373206138611
test loss item: 0.22050032019615173
test loss item: 0.4845024347305298
test loss item: 0.34092456102371216
test loss item: 0.07814954966306686
test loss item: 0.7604207396507263
test loss item: 0.2862809896469116
test loss item: 0.3144381642341614
test loss item: 0.12179765105247498
test loss item: 0.3239273726940155
test loss item: 0.14745861291885376
test loss item: 1.2354847192764282
test loss item: 0.36106592416763306
test loss item: 0.17265020310878754
test loss item: 0.07040990889072418
test loss item: 0.7976619601249695
test loss item: 0.7339046001434326
test loss item: 0.8576908707618713
test loss item: 0.18867440521717072
test loss item: 0.18437236547470093
test loss item: 0.06674262136220932
test loss item: 0.07361135631799698
test loss item: 0.14921480417251587
Epoch [26/50], Training Loss: 0.4129, Testing Loss: 0.3501
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 27/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3759630620479584
1
train loss item: 0.9738597869873047
2
train loss item: 0.1848537176847458
3
train loss item: 0.40977755188941956
4
train loss item: 0.31363993883132935
5
train loss item: 0.26492446660995483
6
train loss item: 0.18789184093475342
7
train loss item: 0.6419533491134644
8
train loss item: 0.11201871931552887
9
train loss item: 0.19373197853565216
10
train loss item: 0.26186060905456543
11
train loss item: 0.242828831076622
12
train loss item: 0.11873973906040192
13
train loss item: 0.4130227267742157
14
train loss item: 0.19692394137382507
15
train loss item: 0.5085983872413635
16
train loss item: 0.07698380202054977
17
train loss item: 0.20383577048778534
18
train loss item: 0.258364200592041
19
train loss item: 0.21467988193035126
20
train loss item: 0.1857270449399948
21
train loss item: 0.11944826692342758
22
train loss item: 0.731713056564331
23
train loss item: 0.7448390126228333
24
train loss item: 0.4288330078125
25
train loss item: 0.1776617467403412
26
train loss item: 0.1580059677362442
27
train loss item: 0.19429489970207214
28
train loss item: 0.07591664046049118
29
train loss item: 0.5523719191551208
30
train loss item: 1.9453327655792236
31
train loss item: 0.4541932940483093
32
train loss item: 0.10074440389871597
33
train loss item: 0.3524392247200012
34
train loss item: 0.13825610280036926
35
train loss item: 2.178762197494507
36
train loss item: 0.4054015874862671
37
train loss item: 0.3530443608760834
38
train loss item: 0.38912051916122437
39
train loss item: 0.1886691302061081
40
train loss item: 0.13944678008556366
41
train loss item: 0.19853296875953674
42
train loss item: 0.24166788160800934
43
train loss item: 0.14852868020534515
44
train loss item: 0.5735654234886169
45
train loss item: 0.1196679174900055
46
train loss item: 0.11793030798435211
47
train loss item: 0.28483283519744873
48
train loss item: 0.17994631826877594
49
train loss item: 0.13163842260837555
50
train loss item: 0.23249351978302002
51
train loss item: 0.6929735541343689
52
train loss item: 0.09065715968608856
53
train loss item: 0.13469408452510834
54
train loss item: 2.0554893016815186
55
train loss item: 0.16488125920295715
56
train loss item: 0.1933138370513916
57
train loss item: 0.20295743644237518
58
train loss item: 0.13355091214179993
59
train loss item: 0.11855550110340118
60
train loss item: 0.6643123030662537
61
train loss item: 1.9735621213912964
62
train loss item: 0.16528856754302979
63
train loss item: 0.29838359355926514
64
train loss item: 0.1407061666250229
65
train loss item: 0.42230352759361267
66
train loss item: 0.3468182682991028
67
train loss item: 0.17188583314418793
68
train loss item: 0.22589467465877533
69
train loss item: 0.24983321130275726
70
train loss item: 0.21143832802772522
71
train loss item: 0.12807956337928772
72
train loss item: 0.14573684334754944
73
train loss item: 0.24059244990348816
74
train loss item: 0.09278210252523422
75
train loss item: 0.10601335763931274
76
train loss item: 0.7214694023132324
77
train loss item: 1.1378297805786133
78
train loss item: 0.08194003254175186
79
train loss item: 0.23653997480869293
80
train loss item: 0.10804370790719986
81
train loss item: 0.15933427214622498
82
train loss item: 0.17435896396636963
83
train loss item: 0.46440890431404114
84
train loss item: 0.37572723627090454
85
train loss item: 0.44558900594711304
86
train loss item: 3.9829914569854736
87
train loss item: 0.15109358727931976
88
train loss item: 0.30046385526657104
epoch train loss: 0.4057075578007805
testing phase
test loss item: 0.1579412966966629
test loss item: 0.09913254529237747
test loss item: 0.497882217168808
test loss item: 0.19892004132270813
test loss item: 0.23251070082187653
test loss item: 0.12757667899131775
test loss item: 1.351492166519165
test loss item: 0.42258501052856445
test loss item: 0.18766865134239197
test loss item: 0.3438052833080292
test loss item: 0.7300349473953247
test loss item: 0.1550530344247818
test loss item: 0.16372528672218323
test loss item: 0.2456575334072113
test loss item: 0.15149779617786407
test loss item: 0.08482217788696289
test loss item: 0.2328110933303833
test loss item: 0.4282001554965973
test loss item: 0.5335811972618103
test loss item: 0.21810927987098694
test loss item: 0.6900412440299988
test loss item: 0.3250683546066284
test loss item: 0.4082895517349243
test loss item: 0.1452452540397644
test loss item: 0.19342680275440216
test loss item: 0.1879216730594635
test loss item: 0.2631213665008545
test loss item: 0.17775864899158478
test loss item: 0.28021374344825745
test loss item: 0.29649269580841064
test loss item: 0.6387368440628052
test loss item: 0.08550094068050385
test loss item: 0.12456962466239929
test loss item: 0.5163851976394653
test loss item: 0.38185039162635803
test loss item: 0.37318259477615356
test loss item: 0.6512255668640137
test loss item: 1.2204080820083618
test loss item: 0.4122006297111511
test loss item: 0.23636028170585632
test loss item: 0.25612789392471313
test loss item: 0.34170591831207275
test loss item: 0.33028215169906616
test loss item: 0.1782854199409485
test loss item: 0.5442166328430176
test loss item: 0.32660970091819763
test loss item: 0.410830020904541
test loss item: 0.18959006667137146
test loss item: 0.40391331911087036
test loss item: 0.5788049101829529
test loss item: 0.26936691999435425
test loss item: 0.1185472160577774
test loss item: 0.20458976924419403
test loss item: 0.15607626736164093
test loss item: 0.27754732966423035
test loss item: 0.7272285223007202
test loss item: 0.46862921118736267
test loss item: 0.2206941843032837
test loss item: 0.20068348944187164
test loss item: 0.19628183543682098
test loss item: 0.41012337803840637
test loss item: 0.19812020659446716
test loss item: 0.17376366257667542
test loss item: 0.21765030920505524
test loss item: 0.68459153175354
test loss item: 0.2771220803260803
test loss item: 0.2543487548828125
test loss item: 0.21618568897247314
test loss item: 0.4735044538974762
test loss item: 0.33520960807800293
test loss item: 0.07135048508644104
test loss item: 0.7605789303779602
test loss item: 0.28776127099990845
test loss item: 0.31844964623451233
test loss item: 0.11964447051286697
test loss item: 0.3341839611530304
test loss item: 0.1465417742729187
test loss item: 1.2229459285736084
test loss item: 0.3594217002391815
test loss item: 0.17184190452098846
test loss item: 0.07043002545833588
test loss item: 0.7917110919952393
test loss item: 0.7238073945045471
test loss item: 0.8470420837402344
test loss item: 0.189043328166008
test loss item: 0.1825612485408783
test loss item: 0.06571143120527267
test loss item: 0.06950772553682327
test loss item: 0.1466042846441269
Epoch [27/50], Training Loss: 0.4057, Testing Loss: 0.3448
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 28/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36948341131210327
1
train loss item: 0.9518439769744873
2
train loss item: 0.18115510046482086
3
train loss item: 0.39623817801475525
4
train loss item: 0.3091404438018799
5
train loss item: 0.25868338346481323
6
train loss item: 0.18206210434436798
7
train loss item: 0.6243535280227661
8
train loss item: 0.10894926637411118
9
train loss item: 0.1901882141828537
10
train loss item: 0.25369879603385925
11
train loss item: 0.23858754336833954
12
train loss item: 0.11750951409339905
13
train loss item: 0.4007665812969208
14
train loss item: 0.19371236860752106
15
train loss item: 0.5037709474563599
16
train loss item: 0.07509560137987137
17
train loss item: 0.19744773209095
18
train loss item: 0.2536124587059021
19
train loss item: 0.2117348313331604
20
train loss item: 0.1838611364364624
21
train loss item: 0.1159980520606041
22
train loss item: 0.7186329364776611
23
train loss item: 0.7214509844779968
24
train loss item: 0.42322322726249695
25
train loss item: 0.17694950103759766
26
train loss item: 0.15668600797653198
27
train loss item: 0.18962202966213226
28
train loss item: 0.07386963069438934
29
train loss item: 0.5400457978248596
30
train loss item: 1.9106190204620361
31
train loss item: 0.4400694668292999
32
train loss item: 0.09926998615264893
33
train loss item: 0.33831101655960083
34
train loss item: 0.13829246163368225
35
train loss item: 2.1525752544403076
36
train loss item: 0.3978096842765808
37
train loss item: 0.3483668565750122
38
train loss item: 0.3765946924686432
39
train loss item: 0.18509402871131897
40
train loss item: 0.13934862613677979
41
train loss item: 0.1935291886329651
42
train loss item: 0.24009548127651215
43
train loss item: 0.1422889232635498
44
train loss item: 0.5620088577270508
45
train loss item: 0.11903344839811325
46
train loss item: 0.11484270542860031
47
train loss item: 0.2806154489517212
48
train loss item: 0.1753896027803421
49
train loss item: 0.1300680786371231
50
train loss item: 0.22710292041301727
51
train loss item: 0.6790835857391357
52
train loss item: 0.08827870339155197
53
train loss item: 0.1312868595123291
54
train loss item: 2.0286383628845215
55
train loss item: 0.1607722043991089
56
train loss item: 0.1884499341249466
57
train loss item: 0.2016187310218811
58
train loss item: 0.13103391230106354
59
train loss item: 0.11380496621131897
60
train loss item: 0.6491554379463196
61
train loss item: 1.9415034055709839
62
train loss item: 0.1625928431749344
63
train loss item: 0.2938997745513916
64
train loss item: 0.13335633277893066
65
train loss item: 0.41213491559028625
66
train loss item: 0.33722227811813354
67
train loss item: 0.16697648167610168
68
train loss item: 0.22284230589866638
69
train loss item: 0.2441776692867279
70
train loss item: 0.21019324660301208
71
train loss item: 0.12373854964971542
72
train loss item: 0.13906823098659515
73
train loss item: 0.23769031465053558
74
train loss item: 0.09253691881895065
75
train loss item: 0.10118456184864044
76
train loss item: 0.7023186683654785
77
train loss item: 1.1265289783477783
78
train loss item: 0.08310127258300781
79
train loss item: 0.2323153167963028
80
train loss item: 0.10646510124206543
81
train loss item: 0.15830890834331512
82
train loss item: 0.16962982714176178
83
train loss item: 0.4593903720378876
84
train loss item: 0.37029382586479187
85
train loss item: 0.4341821074485779
86
train loss item: 3.941990613937378
87
train loss item: 0.14602424204349518
88
train loss item: 0.2918192744255066
epoch train loss: 0.3982394165202473
testing phase
test loss item: 0.158411905169487
test loss item: 0.09589081257581711
test loss item: 0.4801222085952759
test loss item: 0.19654230773448944
test loss item: 0.22397328913211823
test loss item: 0.1221509650349617
test loss item: 1.421967625617981
test loss item: 0.44128453731536865
test loss item: 0.18251734972000122
test loss item: 0.3311576545238495
test loss item: 0.7095563411712646
test loss item: 0.14574158191680908
test loss item: 0.1527939885854721
test loss item: 0.24269439280033112
test loss item: 0.14750516414642334
test loss item: 0.08111949265003204
test loss item: 0.2361512929201126
test loss item: 0.412097305059433
test loss item: 0.5399823188781738
test loss item: 0.21881785988807678
test loss item: 0.6639974117279053
test loss item: 0.3317982256412506
test loss item: 0.37611424922943115
test loss item: 0.14643605053424835
test loss item: 0.18958640098571777
test loss item: 0.1881432682275772
test loss item: 0.2604847252368927
test loss item: 0.16942401230335236
test loss item: 0.2750012278556824
test loss item: 0.2886105179786682
test loss item: 0.6426942348480225
test loss item: 0.08028830587863922
test loss item: 0.12464289367198944
test loss item: 0.49907881021499634
test loss item: 0.3664165437221527
test loss item: 0.3659113943576813
test loss item: 0.658398449420929
test loss item: 1.1789571046829224
test loss item: 0.39805394411087036
test loss item: 0.23947101831436157
test loss item: 0.2624163329601288
test loss item: 0.3023020327091217
test loss item: 0.31631600856781006
test loss item: 0.17970748245716095
test loss item: 0.5204451084136963
test loss item: 0.33109572529792786
test loss item: 0.3756380081176758
test loss item: 0.19181594252586365
test loss item: 0.3921720087528229
test loss item: 0.5716593265533447
test loss item: 0.25064054131507874
test loss item: 0.11464614421129227
test loss item: 0.20268596708774567
test loss item: 0.14557787775993347
test loss item: 0.2660602331161499
test loss item: 0.7038061618804932
test loss item: 0.46670106053352356
test loss item: 0.20971561968326569
test loss item: 0.19900235533714294
test loss item: 0.1840735673904419
test loss item: 0.3924413323402405
test loss item: 0.20530015230178833
test loss item: 0.17804381251335144
test loss item: 0.21118906140327454
test loss item: 0.676408588886261
test loss item: 0.27216407656669617
test loss item: 0.2565867006778717
test loss item: 0.217351034283638
test loss item: 0.45807966589927673
test loss item: 0.3393275737762451
test loss item: 0.06830570846796036
test loss item: 0.8013750910758972
test loss item: 0.28416067361831665
test loss item: 0.3318674862384796
test loss item: 0.11875862628221512
test loss item: 0.2971118688583374
test loss item: 0.14828789234161377
test loss item: 1.1797305345535278
test loss item: 0.35604724287986755
test loss item: 0.16755424439907074
test loss item: 0.0701625719666481
test loss item: 0.7962074279785156
test loss item: 0.7307188510894775
test loss item: 0.82024747133255
test loss item: 0.1929699331521988
test loss item: 0.17928345501422882
test loss item: 0.06453977525234222
test loss item: 0.06652645766735077
test loss item: 0.14706987142562866
Epoch [28/50], Training Loss: 0.3982, Testing Loss: 0.3393
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Epoch 29/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36396703124046326
1
train loss item: 0.9299513101577759
2
train loss item: 0.17903149127960205
3
train loss item: 0.3845365643501282
4
train loss item: 0.30707958340644836
5
train loss item: 0.25441256165504456
6
train loss item: 0.1734430193901062
7
train loss item: 0.6061534881591797
8
train loss item: 0.10574167966842651
9
train loss item: 0.18803930282592773
10
train loss item: 0.24779240787029266
11
train loss item: 0.2331380993127823
12
train loss item: 0.11601851135492325
13
train loss item: 0.390057235956192
14
train loss item: 0.18885235488414764
15
train loss item: 0.5042876601219177
16
train loss item: 0.07123059034347534
17
train loss item: 0.19021707773208618
18
train loss item: 0.2488991916179657
19
train loss item: 0.20823734998703003
20
train loss item: 0.17824044823646545
21
train loss item: 0.11576198786497116
22
train loss item: 0.7114145755767822
23
train loss item: 0.6984643340110779
24
train loss item: 0.4172588586807251
25
train loss item: 0.17849716544151306
26
train loss item: 0.15392908453941345
27
train loss item: 0.18382737040519714
28
train loss item: 0.07008607685565948
29
train loss item: 0.5365066528320312
30
train loss item: 1.8784863948822021
31
train loss item: 0.4258383512496948
32
train loss item: 0.09830166399478912
33
train loss item: 0.3267984390258789
34
train loss item: 0.13727568089962006
35
train loss item: 2.12695050239563
36
train loss item: 0.3860328197479248
37
train loss item: 0.3377154767513275
38
train loss item: 0.3570399582386017
39
train loss item: 0.18249066174030304
40
train loss item: 0.1384250819683075
41
train loss item: 0.1874847561120987
42
train loss item: 0.2377070188522339
43
train loss item: 0.13840186595916748
44
train loss item: 0.5502680540084839
45
train loss item: 0.11989401280879974
46
train loss item: 0.11412867903709412
47
train loss item: 0.27886107563972473
48
train loss item: 0.16956448554992676
49
train loss item: 0.12873640656471252
50
train loss item: 0.22268472611904144
51
train loss item: 0.6684109568595886
52
train loss item: 0.08254241943359375
53
train loss item: 0.12914784252643585
54
train loss item: 2.0026683807373047
55
train loss item: 0.15381257236003876
56
train loss item: 0.18475618958473206
57
train loss item: 0.19760657846927643
58
train loss item: 0.1295420229434967
59
train loss item: 0.11269091069698334
60
train loss item: 0.6377166509628296
61
train loss item: 1.9112792015075684
62
train loss item: 0.16160593926906586
63
train loss item: 0.289157509803772
64
train loss item: 0.13025373220443726
65
train loss item: 0.39689916372299194
66
train loss item: 0.32361528277397156
67
train loss item: 0.16394908726215363
68
train loss item: 0.2193765789270401
69
train loss item: 0.23788678646087646
70
train loss item: 0.20816749334335327
71
train loss item: 0.11952811479568481
72
train loss item: 0.13306790590286255
73
train loss item: 0.23548077046871185
74
train loss item: 0.0933830738067627
75
train loss item: 0.09866904467344284
76
train loss item: 0.683235228061676
77
train loss item: 1.1205439567565918
78
train loss item: 0.08129697293043137
79
train loss item: 0.2250453680753708
80
train loss item: 0.10674901306629181
81
train loss item: 0.15757253766059875
82
train loss item: 0.16493114829063416
83
train loss item: 0.4555138349533081
84
train loss item: 0.35594868659973145
85
train loss item: 0.4250302314758301
86
train loss item: 3.902038097381592
87
train loss item: 0.14100338518619537
88
train loss item: 0.28079771995544434
epoch train loss: 0.39100089401341553
testing phase
test loss item: 0.15742716193199158
test loss item: 0.09877999126911163
test loss item: 0.46963435411453247
test loss item: 0.1949828565120697
test loss item: 0.21850521862506866
test loss item: 0.1162235215306282
test loss item: 1.4720579385757446
test loss item: 0.4508519172668457
test loss item: 0.1820020228624344
test loss item: 0.324518620967865
test loss item: 0.6967424750328064
test loss item: 0.1434505730867386
test loss item: 0.14829425513744354
test loss item: 0.23812733590602875
test loss item: 0.14768832921981812
test loss item: 0.0824161246418953
test loss item: 0.23286518454551697
test loss item: 0.4015164375305176
test loss item: 0.5416977405548096
test loss item: 0.21592167019844055
test loss item: 0.6446936130523682
test loss item: 0.3330584168434143
test loss item: 0.3311353623867035
test loss item: 0.1459837704896927
test loss item: 0.18618588149547577
test loss item: 0.18620087206363678
test loss item: 0.25631073117256165
test loss item: 0.16298796236515045
test loss item: 0.2714308202266693
test loss item: 0.2834770679473877
test loss item: 0.6481429934501648
test loss item: 0.08025062084197998
test loss item: 0.12411115318536758
test loss item: 0.4883978068828583
test loss item: 0.3569442927837372
test loss item: 0.3627239763736725
test loss item: 0.6625753045082092
test loss item: 1.1526988744735718
test loss item: 0.38875946402549744
test loss item: 0.23783662915229797
test loss item: 0.2636275291442871
test loss item: 0.24825118482112885
test loss item: 0.3096274137496948
test loss item: 0.1795320361852646
test loss item: 0.5025952458381653
test loss item: 0.32668203115463257
test loss item: 0.3264472484588623
test loss item: 0.18997476994991302
test loss item: 0.38513803482055664
test loss item: 0.5669942498207092
test loss item: 0.2406986504793167
test loss item: 0.11337385326623917
test loss item: 0.20043601095676422
test loss item: 0.14175978302955627
test loss item: 0.25896087288856506
test loss item: 0.691056489944458
test loss item: 0.46393340826034546
test loss item: 0.20243263244628906
test loss item: 0.195634126663208
test loss item: 0.1795215606689453
test loss item: 0.3837045729160309
test loss item: 0.20471280813217163
test loss item: 0.17792658507823944
test loss item: 0.2078799307346344
test loss item: 0.6683120131492615
test loss item: 0.26918721199035645
test loss item: 0.25304532051086426
test loss item: 0.21683739125728607
test loss item: 0.44857314229011536
test loss item: 0.3421669602394104
test loss item: 0.06994393467903137
test loss item: 0.8253742456436157
test loss item: 0.2767012119293213
test loss item: 0.3339441418647766
test loss item: 0.11647004634141922
test loss item: 0.24245207011699677
test loss item: 0.14852391183376312
test loss item: 1.149919867515564
test loss item: 0.3496854901313782
test loss item: 0.16215646266937256
test loss item: 0.06864850968122482
test loss item: 0.799997866153717
test loss item: 0.7378600835800171
test loss item: 0.8036370873451233
test loss item: 0.1939665526151657
test loss item: 0.17382176220417023
test loss item: 0.0630292147397995
test loss item: 0.06474515050649643
test loss item: 0.1497550755739212
Epoch [29/50], Training Loss: 0.3910, Testing Loss: 0.3340
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 30/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36008837819099426
1
train loss item: 0.9099957346916199
2
train loss item: 0.17467467486858368
3
train loss item: 0.37815168499946594
4
train loss item: 0.306513249874115
5
train loss item: 0.25191712379455566
6
train loss item: 0.1648682802915573
7
train loss item: 0.5907726287841797
8
train loss item: 0.10543826222419739
9
train loss item: 0.18472418189048767
10
train loss item: 0.2446848750114441
11
train loss item: 0.23076026141643524
12
train loss item: 0.11404277384281158
13
train loss item: 0.38433536887168884
14
train loss item: 0.185262992978096
15
train loss item: 0.50007563829422
16
train loss item: 0.06835374236106873
17
train loss item: 0.18613749742507935
18
train loss item: 0.24446545541286469
19
train loss item: 0.20140711963176727
20
train loss item: 0.16776926815509796
21
train loss item: 0.11754869669675827
22
train loss item: 0.6979308724403381
23
train loss item: 0.6814780831336975
24
train loss item: 0.40811678767204285
25
train loss item: 0.18147192895412445
26
train loss item: 0.15217405557632446
27
train loss item: 0.17905041575431824
28
train loss item: 0.06765105575323105
29
train loss item: 0.5310750603675842
30
train loss item: 1.851485252380371
31
train loss item: 0.41700127720832825
32
train loss item: 0.0988689735531807
33
train loss item: 0.32372671365737915
34
train loss item: 0.13849608600139618
35
train loss item: 2.105201005935669
36
train loss item: 0.37710192799568176
37
train loss item: 0.33046528697013855
38
train loss item: 0.34491318464279175
39
train loss item: 0.18100102245807648
40
train loss item: 0.13411009311676025
41
train loss item: 0.18362043797969818
42
train loss item: 0.2361692488193512
43
train loss item: 0.13653194904327393
44
train loss item: 0.5415369272232056
45
train loss item: 0.12163197249174118
46
train loss item: 0.11438319832086563
47
train loss item: 0.27500399947166443
48
train loss item: 0.16545987129211426
49
train loss item: 0.12814198434352875
50
train loss item: 0.21651174128055573
51
train loss item: 0.6577393412590027
52
train loss item: 0.07833270728588104
53
train loss item: 0.1280377209186554
54
train loss item: 1.9811880588531494
55
train loss item: 0.14831794798374176
56
train loss item: 0.18333110213279724
57
train loss item: 0.19261354207992554
58
train loss item: 0.12552359700202942
59
train loss item: 0.11478252708911896
60
train loss item: 0.6260163187980652
61
train loss item: 1.887596607208252
62
train loss item: 0.1613103151321411
63
train loss item: 0.2848016917705536
64
train loss item: 0.1321021020412445
65
train loss item: 0.3812258541584015
66
train loss item: 0.31388425827026367
67
train loss item: 0.16283918917179108
68
train loss item: 0.2121918946504593
69
train loss item: 0.23274873197078705
70
train loss item: 0.20544792711734772
71
train loss item: 0.11729186028242111
72
train loss item: 0.13128943741321564
73
train loss item: 0.2305876612663269
74
train loss item: 0.09289117902517319
75
train loss item: 0.09910248219966888
76
train loss item: 0.6672210097312927
77
train loss item: 1.1124283075332642
78
train loss item: 0.07756847143173218
79
train loss item: 0.22060926258563995
80
train loss item: 0.1090925931930542
81
train loss item: 0.15641328692436218
82
train loss item: 0.16372129321098328
83
train loss item: 0.44798651337623596
84
train loss item: 0.3421904444694519
85
train loss item: 0.41872718930244446
86
train loss item: 3.869475841522217
87
train loss item: 0.1374981850385666
88
train loss item: 0.2706317901611328
epoch train loss: 0.3850231072708462
testing phase
test loss item: 0.1551540046930313
test loss item: 0.10230019688606262
test loss item: 0.4654299020767212
test loss item: 0.19226303696632385
test loss item: 0.21417878568172455
test loss item: 0.10817451775074005
test loss item: 1.4398835897445679
test loss item: 0.44530898332595825
test loss item: 0.18067005276679993
test loss item: 0.31817787885665894
test loss item: 0.6882013082504272
test loss item: 0.1447303295135498
test loss item: 0.1488412767648697
test loss item: 0.22804704308509827
test loss item: 0.14696308970451355
test loss item: 0.0874854251742363
test loss item: 0.22381258010864258
test loss item: 0.39364421367645264
test loss item: 0.5333462953567505
test loss item: 0.2089872658252716
test loss item: 0.6350260376930237
test loss item: 0.32429951429367065
test loss item: 0.2955475151538849
test loss item: 0.1416979432106018
test loss item: 0.1827479898929596
test loss item: 0.18170875310897827
test loss item: 0.24819867312908173
test loss item: 0.15763436257839203
test loss item: 0.2645324766635895
test loss item: 0.27604761719703674
test loss item: 0.6353684067726135
test loss item: 0.08321069926023483
test loss item: 0.12134599685668945
test loss item: 0.48162248730659485
test loss item: 0.35158196091651917
test loss item: 0.35783833265304565
test loss item: 0.65196293592453
test loss item: 1.1401113271713257
test loss item: 0.3800547122955322
test loss item: 0.22545777261257172
test loss item: 0.25494492053985596
test loss item: 0.20527087152004242
test loss item: 0.3034067749977112
test loss item: 0.17429669201374054
test loss item: 0.49162763357162476
test loss item: 0.31528836488723755
test loss item: 0.28794071078300476
test loss item: 0.18276749551296234
test loss item: 0.3810241222381592
test loss item: 0.5572590231895447
test loss item: 0.23454780876636505
test loss item: 0.11099976301193237
test loss item: 0.19451841711997986
test loss item: 0.142521932721138
test loss item: 0.25317418575286865
test loss item: 0.685572624206543
test loss item: 0.45935389399528503
test loss item: 0.19665023684501648
test loss item: 0.19082149863243103
test loss item: 0.17827822268009186
test loss item: 0.3736754059791565
test loss item: 0.1998937577009201
test loss item: 0.1729270964860916
test loss item: 0.20422717928886414
test loss item: 0.6614121198654175
test loss item: 0.26616862416267395
test loss item: 0.244929239153862
test loss item: 0.21069267392158508
test loss item: 0.445546418428421
test loss item: 0.33655524253845215
test loss item: 0.07398944348096848
test loss item: 0.8037362694740295
test loss item: 0.2683549225330353
test loss item: 0.31795600056648254
test loss item: 0.11515507102012634
test loss item: 0.19522906839847565
test loss item: 0.14433801174163818
test loss item: 1.1410971879959106
test loss item: 0.3409542739391327
test loss item: 0.15561053156852722
test loss item: 0.06682460755109787
test loss item: 0.787033200263977
test loss item: 0.7255001664161682
test loss item: 0.79618901014328
test loss item: 0.187038853764534
test loss item: 0.17031998932361603
test loss item: 0.06230712682008743
test loss item: 0.06551758199930191
test loss item: 0.1484803706407547
Epoch [30/50], Training Loss: 0.3850, Testing Loss: 0.3263
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 31/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.35581958293914795
1
train loss item: 0.891343891620636
2
train loss item: 0.1698620617389679
3
train loss item: 0.3661664128303528
4
train loss item: 0.3022240698337555
5
train loss item: 0.2486688196659088
6
train loss item: 0.1599198579788208
7
train loss item: 0.5774073600769043
8
train loss item: 0.10332249850034714
9
train loss item: 0.17931170761585236
10
train loss item: 0.23925819993019104
11
train loss item: 0.22763606905937195
12
train loss item: 0.11243303120136261
13
train loss item: 0.3763556480407715
14
train loss item: 0.18132461607456207
15
train loss item: 0.4928445816040039
16
train loss item: 0.06678599864244461
17
train loss item: 0.1851262003183365
18
train loss item: 0.24049444496631622
19
train loss item: 0.19706317782402039
20
train loss item: 0.16078835725784302
21
train loss item: 0.1173899695277214
22
train loss item: 0.6820012331008911
23
train loss item: 0.6648526787757874
24
train loss item: 0.400030255317688
25
train loss item: 0.18330958485603333
26
train loss item: 0.151009663939476
27
train loss item: 0.1735178828239441
28
train loss item: 0.06622785329818726
29
train loss item: 0.5180395841598511
30
train loss item: 1.8224983215332031
31
train loss item: 0.40791085362434387
32
train loss item: 0.09774573892354965
33
train loss item: 0.3150283992290497
34
train loss item: 0.13989371061325073
35
train loss item: 2.0857300758361816
36
train loss item: 0.3708888590335846
37
train loss item: 0.33001983165740967
38
train loss item: 0.33420807123184204
39
train loss item: 0.1793205440044403
40
train loss item: 0.1300429105758667
41
train loss item: 0.17832760512828827
42
train loss item: 0.23492223024368286
43
train loss item: 0.13272173702716827
44
train loss item: 0.5323274731636047
45
train loss item: 0.12067990750074387
46
train loss item: 0.11382841318845749
47
train loss item: 0.26896634697914124
48
train loss item: 0.1617303341627121
49
train loss item: 0.1240302324295044
50
train loss item: 0.21226650476455688
51
train loss item: 0.6426953673362732
52
train loss item: 0.07464766502380371
53
train loss item: 0.12476904690265656
54
train loss item: 1.9624381065368652
55
train loss item: 0.14440515637397766
56
train loss item: 0.1814037263393402
57
train loss item: 0.18943911790847778
58
train loss item: 0.12142814695835114
59
train loss item: 0.11497987061738968
60
train loss item: 0.6120432615280151
61
train loss item: 1.8649555444717407
62
train loss item: 0.1577138453722
63
train loss item: 0.28133389353752136
64
train loss item: 0.13038668036460876
65
train loss item: 0.37344929575920105
66
train loss item: 0.3047603666782379
67
train loss item: 0.16096161305904388
68
train loss item: 0.20505836606025696
69
train loss item: 0.22977665066719055
70
train loss item: 0.20245057344436646
71
train loss item: 0.11678560823202133
72
train loss item: 0.12750768661499023
73
train loss item: 0.22395558655261993
74
train loss item: 0.09052874147891998
75
train loss item: 0.10003706067800522
76
train loss item: 0.6509976387023926
77
train loss item: 1.09981107711792
78
train loss item: 0.07372792810201645
79
train loss item: 0.21870861947536469
80
train loss item: 0.10980680584907532
81
train loss item: 0.15351277589797974
82
train loss item: 0.1603298783302307
83
train loss item: 0.4389322102069855
84
train loss item: 0.3358226418495178
85
train loss item: 0.40472856163978577
86
train loss item: 3.841003894805908
87
train loss item: 0.13289234042167664
88
train loss item: 0.2666851580142975
epoch train loss: 0.37874712250875625
testing phase
test loss item: 0.153206467628479
test loss item: 0.10256288945674896
test loss item: 0.47506511211395264
test loss item: 0.1894281804561615
test loss item: 0.21242068707942963
test loss item: 0.10384588688611984
test loss item: 1.3619939088821411
test loss item: 0.43151795864105225
test loss item: 0.18174462020397186
test loss item: 0.3165909945964813
test loss item: 0.6949393153190613
test loss item: 0.1468275487422943
test loss item: 0.15100187063217163
test loss item: 0.2172810286283493
test loss item: 0.14466871321201324
test loss item: 0.0928494930267334
test loss item: 0.2147434651851654
test loss item: 0.3933534622192383
test loss item: 0.5204607844352722
test loss item: 0.20295612514019012
test loss item: 0.6431121230125427
test loss item: 0.3128090500831604
test loss item: 0.28729161620140076
test loss item: 0.13551940023899078
test loss item: 0.1808464378118515
test loss item: 0.1770940124988556
test loss item: 0.24205142259597778
test loss item: 0.15479253232479095
test loss item: 0.25690770149230957
test loss item: 0.27082914113998413
test loss item: 0.6207100749015808
test loss item: 0.08542625606060028
test loss item: 0.11706940084695816
test loss item: 0.4825083315372467
test loss item: 0.3546087443828583
test loss item: 0.35439586639404297
test loss item: 0.6344297528266907
test loss item: 1.1601046323776245
test loss item: 0.37639734148979187
test loss item: 0.21055176854133606
test loss item: 0.24278970062732697
test loss item: 0.1933005452156067
test loss item: 0.30042997002601624
test loss item: 0.16849614679813385
test loss item: 0.49433135986328125
test loss item: 0.3048938810825348
test loss item: 0.27901598811149597
test loss item: 0.17785663902759552
test loss item: 0.38416656851768494
test loss item: 0.5537152290344238
test loss item: 0.23374506831169128
test loss item: 0.10951977223157883
test loss item: 0.18962711095809937
test loss item: 0.14603807032108307
test loss item: 0.25214090943336487
test loss item: 0.6982969641685486
test loss item: 0.4559730887413025
test loss item: 0.1953713297843933
test loss item: 0.18788298964500427
test loss item: 0.1782868206501007
test loss item: 0.3685702085494995
test loss item: 0.1969124674797058
test loss item: 0.16751423478126526
test loss item: 0.20005986094474792
test loss item: 0.6688111424446106
test loss item: 0.2643486559391022
test loss item: 0.23893624544143677
test loss item: 0.2018248736858368
test loss item: 0.4488385319709778
test loss item: 0.329662561416626
test loss item: 0.07671184092760086
test loss item: 0.7572774887084961
test loss item: 0.26504772901535034
test loss item: 0.2963417172431946
test loss item: 0.11531803011894226
test loss item: 0.17988277971744537
test loss item: 0.13788357377052307
test loss item: 1.1696058511734009
test loss item: 0.3353521227836609
test loss item: 0.15197846293449402
test loss item: 0.06677473336458206
test loss item: 0.7747514247894287
test loss item: 0.7075138688087463
test loss item: 0.8126716613769531
test loss item: 0.17772969603538513
test loss item: 0.17018209397792816
test loss item: 0.06381069123744965
test loss item: 0.06924330443143845
test loss item: 0.14522311091423035
Epoch [31/50], Training Loss: 0.3787, Testing Loss: 0.3221
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Epoch 32/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.34975549578666687
1
train loss item: 0.875616192817688
2
train loss item: 0.16408883035182953
3
train loss item: 0.3545040786266327
4
train loss item: 0.29196587204933167
5
train loss item: 0.24176084995269775
6
train loss item: 0.15596970915794373
7
train loss item: 0.5676847100257874
8
train loss item: 0.09901605546474457
9
train loss item: 0.17465578019618988
10
train loss item: 0.23229743540287018
11
train loss item: 0.2232014238834381
12
train loss item: 0.11136483401060104
13
train loss item: 0.366256982088089
14
train loss item: 0.17743760347366333
15
train loss item: 0.4825955331325531
16
train loss item: 0.065524160861969
17
train loss item: 0.1840483695268631
18
train loss item: 0.23537598550319672
19
train loss item: 0.19454292953014374
20
train loss item: 0.16001689434051514
21
train loss item: 0.11598911881446838
22
train loss item: 0.6627424955368042
23
train loss item: 0.6502511501312256
24
train loss item: 0.39291611313819885
25
train loss item: 0.1802951842546463
26
train loss item: 0.1489480584859848
27
train loss item: 0.1686268448829651
28
train loss item: 0.06459589302539825
29
train loss item: 0.5020390152931213
30
train loss item: 1.7963025569915771
31
train loss item: 0.39728108048439026
32
train loss item: 0.09345665574073792
33
train loss item: 0.30257448554039
34
train loss item: 0.1399896889925003
35
train loss item: 2.0692222118377686
36
train loss item: 0.3660784065723419
37
train loss item: 0.33150729537010193
38
train loss item: 0.32392632961273193
39
train loss item: 0.17682209610939026
40
train loss item: 0.12744687497615814
41
train loss item: 0.1744074672460556
42
train loss item: 0.23362022638320923
43
train loss item: 0.12840695679187775
44
train loss item: 0.5248198509216309
45
train loss item: 0.11697928607463837
46
train loss item: 0.10992727428674698
47
train loss item: 0.2614641785621643
48
train loss item: 0.15781505405902863
49
train loss item: 0.11908569186925888
50
train loss item: 0.20995491743087769
51
train loss item: 0.627007007598877
52
train loss item: 0.0714723989367485
53
train loss item: 0.12010955810546875
54
train loss item: 1.9468797445297241
55
train loss item: 0.141719788312912
56
train loss item: 0.1771720051765442
57
train loss item: 0.18824970722198486
58
train loss item: 0.11920499056577682
59
train loss item: 0.11128426343202591
60
train loss item: 0.5975191593170166
61
train loss item: 1.845123052597046
62
train loss item: 0.15090782940387726
63
train loss item: 0.27645111083984375
64
train loss item: 0.1255190521478653
65
train loss item: 0.3685789108276367
66
train loss item: 0.29626303911209106
67
train loss item: 0.15791283547878265
68
train loss item: 0.20049840211868286
69
train loss item: 0.22715598344802856
70
train loss item: 0.19873937964439392
71
train loss item: 0.11658621579408646
72
train loss item: 0.12213855236768723
73
train loss item: 0.2176358699798584
74
train loss item: 0.08743364363908768
75
train loss item: 0.09910128265619278
76
train loss item: 0.6359274983406067
77
train loss item: 1.0841448307037354
78
train loss item: 0.07093319296836853
79
train loss item: 0.21626408398151398
80
train loss item: 0.10662295669317245
81
train loss item: 0.14858520030975342
82
train loss item: 0.15534040331840515
83
train loss item: 0.42883598804473877
84
train loss item: 0.3357543349266052
85
train loss item: 0.39009031653404236
86
train loss item: 3.8172607421875
87
train loss item: 0.12800505757331848
88
train loss item: 0.2658863663673401
epoch train loss: 0.37224142630113644
testing phase
test loss item: 0.15323875844478607
test loss item: 0.10035955160856247
test loss item: 0.49352848529815674
test loss item: 0.18798960745334625
test loss item: 0.2141813337802887
test loss item: 0.10947215557098389
test loss item: 1.3424534797668457
test loss item: 0.4324125349521637
test loss item: 0.1863255351781845
test loss item: 0.3206346035003662
test loss item: 0.7143802642822266
test loss item: 0.14540939033031464
test loss item: 0.14955510199069977
test loss item: 0.21283702552318573
test loss item: 0.14348576962947845
test loss item: 0.09471281617879868
test loss item: 0.211500346660614
test loss item: 0.39886751770973206
test loss item: 0.516923189163208
test loss item: 0.199321910738945
test loss item: 0.660062313079834
test loss item: 0.3106221556663513
test loss item: 0.32474997639656067
test loss item: 0.13378241658210754
test loss item: 0.18032245337963104
test loss item: 0.17464874684810638
test loss item: 0.24122677743434906
test loss item: 0.15625858306884766
test loss item: 0.2528781592845917
test loss item: 0.27120527625083923
test loss item: 0.6298356056213379
test loss item: 0.08426038175821304
test loss item: 0.11606155335903168
test loss item: 0.4873458445072174
test loss item: 0.363029420375824
test loss item: 0.35615649819374084
test loss item: 0.630864143371582
test loss item: 1.201866865158081
test loss item: 0.37823575735092163
test loss item: 0.2071959227323532
test loss item: 0.23804037272930145
test loss item: 0.23094533383846283
test loss item: 0.30011364817619324
test loss item: 0.1671023815870285
test loss item: 0.5053424835205078
test loss item: 0.30208343267440796
test loss item: 0.3166098892688751
test loss item: 0.17637653648853302
test loss item: 0.3927362859249115
test loss item: 0.5631579160690308
test loss item: 0.23646719753742218
test loss item: 0.11040256172418594
test loss item: 0.18990947306156158
test loss item: 0.1465306133031845
test loss item: 0.2556195855140686
test loss item: 0.7231687903404236
test loss item: 0.45823776721954346
test loss item: 0.19947375357151031
test loss item: 0.18931233882904053
test loss item: 0.1760394275188446
test loss item: 0.3714344799518585
test loss item: 0.20061685144901276
test loss item: 0.1674104481935501
test loss item: 0.19445590674877167
test loss item: 0.6914861798286438
test loss item: 0.26316550374031067
test loss item: 0.2400534451007843
test loss item: 0.1952911615371704
test loss item: 0.45229363441467285
test loss item: 0.33283478021621704
test loss item: 0.0754055380821228
test loss item: 0.743071973323822
test loss item: 0.268481969833374
test loss item: 0.28916770219802856
test loss item: 0.11484939604997635
test loss item: 0.21494171023368835
test loss item: 0.13581232726573944
test loss item: 1.217036247253418
test loss item: 0.3363546133041382
test loss item: 0.15489649772644043
test loss item: 0.06981059908866882
test loss item: 0.7871994972229004
test loss item: 0.7111575603485107
test loss item: 0.8462141752243042
test loss item: 0.17358867824077606
test loss item: 0.17004768550395966
test loss item: 0.06733383238315582
test loss item: 0.07354792952537537
test loss item: 0.14535434544086456
Epoch [32/50], Training Loss: 0.3722, Testing Loss: 0.3266
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 33/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3426404297351837
1
train loss item: 0.858027458190918
2
train loss item: 0.15562686324119568
3
train loss item: 0.3501725494861603
4
train loss item: 0.28015026450157166
5
train loss item: 0.2321147620677948
6
train loss item: 0.15260611474514008
7
train loss item: 0.5619292259216309
8
train loss item: 0.09762120246887207
9
train loss item: 0.17231948673725128
10
train loss item: 0.2265610545873642
11
train loss item: 0.21866436302661896
12
train loss item: 0.11164287477731705
13
train loss item: 0.358353853225708
14
train loss item: 0.17648303508758545
15
train loss item: 0.4702357351779938
16
train loss item: 0.06670541316270828
17
train loss item: 0.1814376711845398
18
train loss item: 0.22814232110977173
19
train loss item: 0.18989060819149017
20
train loss item: 0.16193342208862305
21
train loss item: 0.11363209038972855
22
train loss item: 0.6411030292510986
23
train loss item: 0.6399697065353394
24
train loss item: 0.3824809789657593
25
train loss item: 0.17355412244796753
26
train loss item: 0.1461506336927414
27
train loss item: 0.16741743683815002
28
train loss item: 0.06528151780366898
29
train loss item: 0.4916771352291107
30
train loss item: 1.7785141468048096
31
train loss item: 0.3858044445514679
32
train loss item: 0.0906962975859642
33
train loss item: 0.29778775572776794
34
train loss item: 0.1386265903711319
35
train loss item: 2.055673599243164
36
train loss item: 0.3571496605873108
37
train loss item: 0.3273925185203552
38
train loss item: 0.3121792674064636
39
train loss item: 0.17453327775001526
40
train loss item: 0.12448319047689438
41
train loss item: 0.17497873306274414
42
train loss item: 0.23162102699279785
43
train loss item: 0.12641282379627228
44
train loss item: 0.5220466256141663
45
train loss item: 0.1142984926700592
46
train loss item: 0.10312344133853912
47
train loss item: 0.25403574109077454
48
train loss item: 0.15595859289169312
49
train loss item: 0.11704829335212708
50
train loss item: 0.20701484382152557
51
train loss item: 0.616921067237854
52
train loss item: 0.07298432290554047
53
train loss item: 0.1172715574502945
54
train loss item: 1.9344204664230347
55
train loss item: 0.14153777062892914
56
train loss item: 0.1725836545228958
57
train loss item: 0.18772713840007782
58
train loss item: 0.11775895208120346
59
train loss item: 0.10740736871957779
60
train loss item: 0.5851084589958191
61
train loss item: 1.8302611112594604
62
train loss item: 0.14819544553756714
63
train loss item: 0.2681569755077362
64
train loss item: 0.12233669310808182
65
train loss item: 0.35588371753692627
66
train loss item: 0.28470107913017273
67
train loss item: 0.15437552332878113
68
train loss item: 0.19778403639793396
69
train loss item: 0.2207731306552887
70
train loss item: 0.19339939951896667
71
train loss item: 0.11643264442682266
72
train loss item: 0.12064756453037262
73
train loss item: 0.21229378879070282
74
train loss item: 0.08625932037830353
75
train loss item: 0.09732986986637115
76
train loss item: 0.6236775517463684
77
train loss item: 1.0701496601104736
78
train loss item: 0.07188034802675247
79
train loss item: 0.21067290008068085
80
train loss item: 0.10165480524301529
81
train loss item: 0.1442003846168518
82
train loss item: 0.15458665788173676
83
train loss item: 0.4157487750053406
84
train loss item: 0.32391753792762756
85
train loss item: 0.3847866654396057
86
train loss item: 3.7982184886932373
87
train loss item: 0.12626513838768005
88
train loss item: 0.25764426589012146
epoch train loss: 0.36640290966194666
testing phase
test loss item: 0.1545284390449524
test loss item: 0.09413201361894608
test loss item: 0.4786944091320038
test loss item: 0.18735527992248535
test loss item: 0.20856201648712158
test loss item: 0.10889468342065811
test loss item: 1.3821282386779785
test loss item: 0.45921242237091064
test loss item: 0.18116417527198792
test loss item: 0.3120082914829254
test loss item: 0.6951850056648254
test loss item: 0.13989980518817902
test loss item: 0.1464347243309021
test loss item: 0.21102115511894226
test loss item: 0.13910135626792908
test loss item: 0.08365176618099213
test loss item: 0.21525569260120392
test loss item: 0.38550662994384766
test loss item: 0.5262369513511658
test loss item: 0.20063738524913788
test loss item: 0.6338560581207275
test loss item: 0.3180583715438843
test loss item: 0.36398187279701233
test loss item: 0.136243537068367
test loss item: 0.17644338309764862
test loss item: 0.17427131533622742
test loss item: 0.2386614978313446
test loss item: 0.15240038931369781
test loss item: 0.24684156477451324
test loss item: 0.2673267126083374
test loss item: 0.6303555369377136
test loss item: 0.07527227699756622
test loss item: 0.11818104237318039
test loss item: 0.4704900085926056
test loss item: 0.3499178886413574
test loss item: 0.3542155921459198
test loss item: 0.6403266787528992
test loss item: 1.1664060354232788
test loss item: 0.3662113845348358
test loss item: 0.20931297540664673
test loss item: 0.24002203345298767
test loss item: 0.271236777305603
test loss item: 0.28642067313194275
test loss item: 0.1693425178527832
test loss item: 0.48260217905044556
test loss item: 0.3077962100505829
test loss item: 0.3546024560928345
test loss item: 0.18006671965122223
test loss item: 0.3855378329753876
test loss item: 0.5543205738067627
test loss item: 0.22659990191459656
test loss item: 0.11247735470533371
test loss item: 0.1885252445936203
test loss item: 0.14260220527648926
test loss item: 0.24728690087795258
test loss item: 0.6993980407714844
test loss item: 0.46013182401657104
test loss item: 0.19908009469509125
test loss item: 0.1906932294368744
test loss item: 0.1679232120513916
test loss item: 0.35591164231300354
test loss item: 0.2101520597934723
test loss item: 0.1716100126504898
test loss item: 0.18833263218402863
test loss item: 0.6814841628074646
test loss item: 0.26087716221809387
test loss item: 0.24423885345458984
test loss item: 0.19308659434318542
test loss item: 0.4385673999786377
test loss item: 0.3405916690826416
test loss item: 0.0668068453669548
test loss item: 0.7689189910888672
test loss item: 0.2653021812438965
test loss item: 0.2958334982395172
test loss item: 0.11662044376134872
test loss item: 0.25501495599746704
test loss item: 0.13643303513526917
test loss item: 1.1822052001953125
test loss item: 0.33179235458374023
test loss item: 0.15513260662555695
test loss item: 0.06937593221664429
test loss item: 0.7884505987167358
test loss item: 0.7178369164466858
test loss item: 0.8237128257751465
test loss item: 0.17252026498317719
test loss item: 0.1697455495595932
test loss item: 0.06456825882196426
test loss item: 0.06557300686836243
test loss item: 0.14576181769371033
Epoch [33/50], Training Loss: 0.3664, Testing Loss: 0.3252
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 34/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.33590662479400635
1
train loss item: 0.8374078869819641
2
train loss item: 0.15205080807209015
3
train loss item: 0.34182435274124146
4
train loss item: 0.27322763204574585
5
train loss item: 0.224528506398201
6
train loss item: 0.15272019803524017
7
train loss item: 0.5517632365226746
8
train loss item: 0.09534606337547302
9
train loss item: 0.1680164933204651
10
train loss item: 0.220101460814476
11
train loss item: 0.2136014848947525
12
train loss item: 0.11176357418298721
13
train loss item: 0.34875696897506714
14
train loss item: 0.1731555461883545
15
train loss item: 0.4654533863067627
16
train loss item: 0.06705746799707413
17
train loss item: 0.17754779756069183
18
train loss item: 0.22312821447849274
19
train loss item: 0.18924690783023834
20
train loss item: 0.1658521145582199
21
train loss item: 0.1134079098701477
22
train loss item: 0.6295878291130066
23
train loss item: 0.6227755546569824
24
train loss item: 0.3753490149974823
25
train loss item: 0.17207059264183044
26
train loss item: 0.14245302975177765
27
train loss item: 0.1635332554578781
28
train loss item: 0.06535406410694122
29
train loss item: 0.486439973115921
30
train loss item: 1.7550586462020874
31
train loss item: 0.3730848729610443
32
train loss item: 0.08921293169260025
33
train loss item: 0.28579139709472656
34
train loss item: 0.13569559156894684
35
train loss item: 2.0396828651428223
36
train loss item: 0.34592702984809875
37
train loss item: 0.32117438316345215
38
train loss item: 0.301826149225235
39
train loss item: 0.17290478944778442
40
train loss item: 0.12317030876874924
41
train loss item: 0.17049981653690338
42
train loss item: 0.22905007004737854
43
train loss item: 0.12424298375844955
44
train loss item: 0.5146607160568237
45
train loss item: 0.11191211640834808
46
train loss item: 0.09899421781301498
47
train loss item: 0.2505311369895935
48
train loss item: 0.15198259055614471
49
train loss item: 0.11463199555873871
50
train loss item: 0.20763562619686127
51
train loss item: 0.6070075035095215
52
train loss item: 0.07463058084249496
53
train loss item: 0.11361511051654816
54
train loss item: 1.9189343452453613
55
train loss item: 0.13890409469604492
56
train loss item: 0.16887478530406952
57
train loss item: 0.1862139105796814
58
train loss item: 0.118387870490551
59
train loss item: 0.10473065823316574
60
train loss item: 0.5732138752937317
61
train loss item: 1.8093124628067017
62
train loss item: 0.14871051907539368
63
train loss item: 0.26273173093795776
64
train loss item: 0.1186419129371643
65
train loss item: 0.3457680940628052
66
train loss item: 0.2760654389858246
67
train loss item: 0.15239733457565308
68
train loss item: 0.20016346871852875
69
train loss item: 0.2156732678413391
70
train loss item: 0.18950025737285614
71
train loss item: 0.1158914789557457
72
train loss item: 0.11650648713111877
73
train loss item: 0.20846593379974365
74
train loss item: 0.08665566146373749
75
train loss item: 0.0955067053437233
76
train loss item: 0.6066464185714722
77
train loss item: 1.0605369806289673
78
train loss item: 0.07285688072443008
79
train loss item: 0.20545673370361328
80
train loss item: 0.09938279539346695
81
train loss item: 0.14267335832118988
82
train loss item: 0.15093940496444702
83
train loss item: 0.40659013390541077
84
train loss item: 0.3121577799320221
85
train loss item: 0.37429729104042053
86
train loss item: 3.774843692779541
87
train loss item: 0.12167198210954666
88
train loss item: 0.2522924840450287
epoch train loss: 0.3607185124681237
testing phase
test loss item: 0.1528262495994568
test loss item: 0.09489762037992477
test loss item: 0.4488641619682312
test loss item: 0.18472306430339813
test loss item: 0.20403806865215302
test loss item: 0.11100666224956512
test loss item: 1.3230291604995728
test loss item: 0.44219139218330383
test loss item: 0.17278322577476501
test loss item: 0.298997163772583
test loss item: 0.6530622243881226
test loss item: 0.13752484321594238
test loss item: 0.1426440179347992
test loss item: 0.20685803890228271
test loss item: 0.13742555677890778
test loss item: 0.08428662270307541
test loss item: 0.2085866779088974
test loss item: 0.36766111850738525
test loss item: 0.5100206136703491
test loss item: 0.19474583864212036
test loss item: 0.6047301888465881
test loss item: 0.3083125352859497
test loss item: 0.37735265493392944
test loss item: 0.1339777261018753
test loss item: 0.17038393020629883
test loss item: 0.1708214282989502
test loss item: 0.230666384100914
test loss item: 0.1498771458864212
test loss item: 0.23918776214122772
test loss item: 0.25949448347091675
test loss item: 0.5943195223808289
test loss item: 0.07423505187034607
test loss item: 0.117543064057827
test loss item: 0.4468349516391754
test loss item: 0.33130943775177
test loss item: 0.34379062056541443
test loss item: 0.6189899444580078
test loss item: 1.0904890298843384
test loss item: 0.34789979457855225
test loss item: 0.2036207616329193
test loss item: 0.23317179083824158
test loss item: 0.28114569187164307
test loss item: 0.27329394221305847
test loss item: 0.16453485190868378
test loss item: 0.46140772104263306
test loss item: 0.2985627353191376
test loss item: 0.3657686412334442
test loss item: 0.17775550484657288
test loss item: 0.3674429655075073
test loss item: 0.5238780379295349
test loss item: 0.21726107597351074
test loss item: 0.11295396834611893
test loss item: 0.18287576735019684
test loss item: 0.13846056163311005
test loss item: 0.23682066798210144
test loss item: 0.6540026068687439
test loss item: 0.44311216473579407
test loss item: 0.19595861434936523
test loss item: 0.18797600269317627
test loss item: 0.16241766512393951
test loss item: 0.34041351079940796
test loss item: 0.20530392229557037
test loss item: 0.16840247809886932
test loss item: 0.18200911581516266
test loss item: 0.6393295526504517
test loss item: 0.2566337287425995
test loss item: 0.23768314719200134
test loss item: 0.18710967898368835
test loss item: 0.4197882115840912
test loss item: 0.3271191716194153
test loss item: 0.06599955260753632
test loss item: 0.734795331954956
test loss item: 0.2595331072807312
test loss item: 0.2846408784389496
test loss item: 0.11498282849788666
test loss item: 0.2660808563232422
test loss item: 0.1340416967868805
test loss item: 1.1016829013824463
test loss item: 0.320340633392334
test loss item: 0.1534751057624817
test loss item: 0.06863118708133698
test loss item: 0.7455323338508606
test loss item: 0.6874257922172546
test loss item: 0.7664663195610046
test loss item: 0.16960270702838898
test loss item: 0.16542395949363708
test loss item: 0.06416980177164078
test loss item: 0.0660184696316719
test loss item: 0.14581826329231262
Epoch [34/50], Training Loss: 0.3607, Testing Loss: 0.3129
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 35/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.33066874742507935
1
train loss item: 0.8107200860977173
2
train loss item: 0.14809010922908783
3
train loss item: 0.3295169472694397
4
train loss item: 0.2711840271949768
5
train loss item: 0.22142185270786285
6
train loss item: 0.14906546473503113
7
train loss item: 0.5375996828079224
8
train loss item: 0.09271640330553055
9
train loss item: 0.16285517811775208
10
train loss item: 0.21697333455085754
11
train loss item: 0.21069404482841492
12
train loss item: 0.10976140946149826
13
train loss item: 0.3439144492149353
14
train loss item: 0.1688084453344345
15
train loss item: 0.44909170269966125
16
train loss item: 0.06406861543655396
17
train loss item: 0.1758379191160202
18
train loss item: 0.21928566694259644
19
train loss item: 0.18260683119297028
20
train loss item: 0.16032229363918304
21
train loss item: 0.11149248480796814
22
train loss item: 0.6063730716705322
23
train loss item: 0.603927493095398
24
train loss item: 0.36654114723205566
25
train loss item: 0.17109861969947815
26
train loss item: 0.14044979214668274
27
train loss item: 0.15796777606010437
28
train loss item: 0.06241660192608833
29
train loss item: 0.4661637544631958
30
train loss item: 1.723021388053894
31
train loss item: 0.3681129217147827
32
train loss item: 0.08713103830814362
33
train loss item: 0.27761077880859375
34
train loss item: 0.13369068503379822
35
train loss item: 2.021719217300415
36
train loss item: 0.34614184498786926
37
train loss item: 0.32423365116119385
38
train loss item: 0.3113100826740265
39
train loss item: 0.1705632507801056
40
train loss item: 0.11956072598695755
41
train loss item: 0.16340923309326172
42
train loss item: 0.22618253529071808
43
train loss item: 0.12126032263040543
44
train loss item: 0.5056318044662476
45
train loss item: 0.11115969717502594
46
train loss item: 0.09727463126182556
47
train loss item: 0.2441345453262329
48
train loss item: 0.14605571329593658
49
train loss item: 0.1122598871588707
50
train loss item: 0.20098601281642914
51
train loss item: 0.5898981094360352
52
train loss item: 0.07115551829338074
53
train loss item: 0.11165590584278107
54
train loss item: 1.900581955909729
55
train loss item: 0.13468733429908752
56
train loss item: 0.1665198653936386
57
train loss item: 0.18117763102054596
58
train loss item: 0.11515864729881287
59
train loss item: 0.10510633140802383
60
train loss item: 0.5507200956344604
61
train loss item: 1.7867366075515747
62
train loss item: 0.1472465693950653
63
train loss item: 0.2583164870738983
64
train loss item: 0.11693643033504486
65
train loss item: 0.3432590365409851
66
train loss item: 0.2762207090854645
67
train loss item: 0.14984910190105438
68
train loss item: 0.19419614970684052
69
train loss item: 0.21470539271831512
70
train loss item: 0.18657927215099335
71
train loss item: 0.11254438757896423
72
train loss item: 0.11277744174003601
73
train loss item: 0.20159374177455902
74
train loss item: 0.0849020779132843
75
train loss item: 0.09439544379711151
76
train loss item: 0.5863637328147888
77
train loss item: 1.0457547903060913
78
train loss item: 0.0691230446100235
79
train loss item: 0.20258072018623352
80
train loss item: 0.09912555664777756
81
train loss item: 0.1426667869091034
82
train loss item: 0.1473030000925064
83
train loss item: 0.3951930105686188
84
train loss item: 0.31459537148475647
85
train loss item: 0.35918107628822327
86
train loss item: 3.7494611740112305
87
train loss item: 0.11786843836307526
88
train loss item: 0.2514050602912903
epoch train loss: 0.35438905534951876
testing phase
test loss item: 0.15123793482780457
test loss item: 0.09958580136299133
test loss item: 0.4378755986690521
test loss item: 0.18357475101947784
test loss item: 0.20388305187225342
test loss item: 0.10972228646278381
test loss item: 1.2707526683807373
test loss item: 0.4275059401988983
test loss item: 0.17035402357578278
test loss item: 0.29463204741477966
test loss item: 0.6275166273117065
test loss item: 0.13796067237854004
test loss item: 0.1415136158466339
test loss item: 0.20764517784118652
test loss item: 0.140910342335701
test loss item: 0.08696786314249039
test loss item: 0.20324739813804626
test loss item: 0.36263391375541687
test loss item: 0.4951779246330261
test loss item: 0.19268430769443512
test loss item: 0.5973337292671204
test loss item: 0.3005857467651367
test loss item: 0.355457603931427
test loss item: 0.13455568253993988
test loss item: 0.1666683554649353
test loss item: 0.1696328967809677
test loss item: 0.22667977213859558
test loss item: 0.14833910763263702
test loss item: 0.23874840140342712
test loss item: 0.25549548864364624
test loss item: 0.5706912279129028
test loss item: 0.07588274776935577
test loss item: 0.11918431520462036
test loss item: 0.4373651146888733
test loss item: 0.32584649324417114
test loss item: 0.33702149987220764
test loss item: 0.6016400456428528
test loss item: 1.0491327047348022
test loss item: 0.340493381023407
test loss item: 0.19924019277095795
test loss item: 0.2275458574295044
test loss item: 0.2538001835346222
test loss item: 0.2701438069343567
test loss item: 0.1611781269311905
test loss item: 0.45529499650001526
test loss item: 0.2924981713294983
test loss item: 0.3427852988243103
test loss item: 0.17725887894630432
test loss item: 0.36104437708854675
test loss item: 0.5049528479576111
test loss item: 0.2171471267938614
test loss item: 0.11292929947376251
test loss item: 0.1806035190820694
test loss item: 0.1366642564535141
test loss item: 0.23482021689414978
test loss item: 0.6326469779014587
test loss item: 0.4310600161552429
test loss item: 0.19826042652130127
test loss item: 0.18740218877792358
test loss item: 0.1618705689907074
test loss item: 0.3370087146759033
test loss item: 0.2011197805404663
test loss item: 0.16702991724014282
test loss item: 0.1783832609653473
test loss item: 0.6192935705184937
test loss item: 0.2534993290901184
test loss item: 0.23438607156276703
test loss item: 0.18362313508987427
test loss item: 0.41252005100250244
test loss item: 0.3151088356971741
test loss item: 0.06895744800567627
test loss item: 0.7057729363441467
test loss item: 0.26192590594291687
test loss item: 0.2787714898586273
test loss item: 0.1143701896071434
test loss item: 0.2398989200592041
test loss item: 0.13470014929771423
test loss item: 1.0622432231903076
test loss item: 0.3173489272594452
test loss item: 0.15078935027122498
test loss item: 0.0685713142156601
test loss item: 0.7159262895584106
test loss item: 0.6635938286781311
test loss item: 0.7369622588157654
test loss item: 0.1703965812921524
test loss item: 0.16291286051273346
test loss item: 0.06400184333324432
test loss item: 0.06677607446908951
test loss item: 0.1442936658859253
Epoch [35/50], Training Loss: 0.3544, Testing Loss: 0.3052
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 36/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3243085443973541
1
train loss item: 0.7872336506843567
2
train loss item: 0.14277903735637665
3
train loss item: 0.3186275064945221
4
train loss item: 0.267133504152298
5
train loss item: 0.2183680534362793
6
train loss item: 0.1446818709373474
7
train loss item: 0.5259502530097961
8
train loss item: 0.09128732234239578
9
train loss item: 0.15877462923526764
10
train loss item: 0.21196340024471283
11
train loss item: 0.20752868056297302
12
train loss item: 0.10759969800710678
13
train loss item: 0.33922868967056274
14
train loss item: 0.1661268174648285
15
train loss item: 0.43319833278656006
16
train loss item: 0.06214189901947975
17
train loss item: 0.17365804314613342
18
train loss item: 0.21422143280506134
19
train loss item: 0.17741665244102478
20
train loss item: 0.1519201695919037
21
train loss item: 0.10841958224773407
22
train loss item: 0.583613395690918
23
train loss item: 0.5868464708328247
24
train loss item: 0.35776248574256897
25
train loss item: 0.16720670461654663
26
train loss item: 0.13941673934459686
27
train loss item: 0.15473583340644836
28
train loss item: 0.06075939163565636
29
train loss item: 0.4473252594470978
30
train loss item: 1.6953098773956299
31
train loss item: 0.3624233305454254
32
train loss item: 0.08827023208141327
33
train loss item: 0.27675777673721313
34
train loss item: 0.13131318986415863
35
train loss item: 2.0058186054229736
36
train loss item: 0.34313371777534485
37
train loss item: 0.3252716064453125
38
train loss item: 0.3157059848308563
39
train loss item: 0.16756442189216614
40
train loss item: 0.11590194702148438
41
train loss item: 0.15879280865192413
42
train loss item: 0.22504748404026031
43
train loss item: 0.11951153725385666
44
train loss item: 0.4991005063056946
45
train loss item: 0.11237680166959763
46
train loss item: 0.09790647029876709
47
train loss item: 0.23907704651355743
48
train loss item: 0.14345206320285797
49
train loss item: 0.11051435768604279
50
train loss item: 0.1950840801000595
51
train loss item: 0.5739850997924805
52
train loss item: 0.06827552616596222
53
train loss item: 0.11222407966852188
54
train loss item: 1.8847707509994507
55
train loss item: 0.13278523087501526
56
train loss item: 0.1642673909664154
57
train loss item: 0.17796112596988678
58
train loss item: 0.11044494807720184
59
train loss item: 0.10821406543254852
60
train loss item: 0.5313192009925842
61
train loss item: 1.7681400775909424
62
train loss item: 0.14626333117485046
63
train loss item: 0.25515052676200867
64
train loss item: 0.11754795908927917
65
train loss item: 0.33900001645088196
66
train loss item: 0.27350670099258423
67
train loss item: 0.146637424826622
68
train loss item: 0.1885526329278946
69
train loss item: 0.21323265135288239
70
train loss item: 0.18404394388198853
71
train loss item: 0.10883813351392746
72
train loss item: 0.11202172189950943
73
train loss item: 0.1963575780391693
74
train loss item: 0.0825352892279625
75
train loss item: 0.09462027996778488
76
train loss item: 0.5686143636703491
77
train loss item: 1.0334359407424927
78
train loss item: 0.06635415554046631
79
train loss item: 0.20022514462471008
80
train loss item: 0.10025636851787567
81
train loss item: 0.1428508758544922
82
train loss item: 0.14622001349925995
83
train loss item: 0.3855551481246948
84
train loss item: 0.3147094249725342
85
train loss item: 0.3472624719142914
86
train loss item: 3.7267966270446777
87
train loss item: 0.11870841681957245
88
train loss item: 0.24759338796138763
epoch train loss: 0.34885220137539874
testing phase
test loss item: 0.15077278017997742
test loss item: 0.10277894884347916
test loss item: 0.4449499845504761
test loss item: 0.18352647125720978
test loss item: 0.20870758593082428
test loss item: 0.11515969038009644
test loss item: 1.3306269645690918
test loss item: 0.4573891758918762
test loss item: 0.17190992832183838
test loss item: 0.2964268922805786
test loss item: 0.6253213882446289
test loss item: 0.1413262039422989
test loss item: 0.14358362555503845
test loss item: 0.21550053358078003
test loss item: 0.14443066716194153
test loss item: 0.09169269353151321
test loss item: 0.20803231000900269
test loss item: 0.3649837374687195
test loss item: 0.5065585970878601
test loss item: 0.20099294185638428
test loss item: 0.615388035774231
test loss item: 0.30970749258995056
test loss item: 0.3642163574695587
test loss item: 0.13782218098640442
test loss item: 0.167687326669693
test loss item: 0.1709345579147339
test loss item: 0.2288781702518463
test loss item: 0.15202179551124573
test loss item: 0.24333132803440094
test loss item: 0.2554917633533478
test loss item: 0.5883278250694275
test loss item: 0.0781286433339119
test loss item: 0.12033654749393463
test loss item: 0.43867677450180054
test loss item: 0.32998424768447876
test loss item: 0.33919772505760193
test loss item: 0.6181440949440002
test loss item: 1.0514901876449585
test loss item: 0.34328141808509827
test loss item: 0.20553767681121826
test loss item: 0.23256337642669678
test loss item: 0.2577728033065796
test loss item: 0.27005478739738464
test loss item: 0.1649497151374817
test loss item: 0.4703463912010193
test loss item: 0.3015666604042053
test loss item: 0.35056549310684204
test loss item: 0.18488499522209167
test loss item: 0.3681582808494568
test loss item: 0.5088317394256592
test loss item: 0.21937918663024902
test loss item: 0.11604597419500351
test loss item: 0.1830993890762329
test loss item: 0.1359415054321289
test loss item: 0.23649345338344574
test loss item: 0.6358318328857422
test loss item: 0.43945252895355225
test loss item: 0.2028937190771103
test loss item: 0.19139787554740906
test loss item: 0.1622217893600464
test loss item: 0.3371499478816986
test loss item: 0.20898057520389557
test loss item: 0.17049242556095123
test loss item: 0.17852506041526794
test loss item: 0.6371555328369141
test loss item: 0.25230881571769714
test loss item: 0.24017052352428436
test loss item: 0.18691964447498322
test loss item: 0.4161372184753418
test loss item: 0.3230283260345459
test loss item: 0.07295073568820953
test loss item: 0.744347870349884
test loss item: 0.2744247317314148
test loss item: 0.2925427556037903
test loss item: 0.11739177256822586
test loss item: 0.24116742610931396
test loss item: 0.14082127809524536
test loss item: 1.0772308111190796
test loss item: 0.3263867497444153
test loss item: 0.15287622809410095
test loss item: 0.07262985408306122
test loss item: 0.7338552474975586
test loss item: 0.6785850524902344
test loss item: 0.7465068101882935
test loss item: 0.17542971670627594
test loss item: 0.16546396911144257
test loss item: 0.06522472202777863
test loss item: 0.0698891133069992
test loss item: 0.13572874665260315
Epoch [36/50], Training Loss: 0.3489, Testing Loss: 0.3116
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 37/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3150191307067871
1
train loss item: 0.7713271975517273
2
train loss item: 0.13936136662960052
3
train loss item: 0.3078438937664032
4
train loss item: 0.25881075859069824
5
train loss item: 0.21096394956111908
6
train loss item: 0.1442086547613144
7
train loss item: 0.5177357196807861
8
train loss item: 0.0881112739443779
9
train loss item: 0.15503184497356415
10
train loss item: 0.20189324021339417
11
train loss item: 0.20144152641296387
12
train loss item: 0.10725505650043488
13
train loss item: 0.3285236656665802
14
train loss item: 0.16144555807113647
15
train loss item: 0.431652307510376
16
train loss item: 0.06115226447582245
17
train loss item: 0.16752414405345917
18
train loss item: 0.20694510638713837
19
train loss item: 0.18039460480213165
20
train loss item: 0.1513037234544754
21
train loss item: 0.10690497606992722
22
train loss item: 0.5738537907600403
23
train loss item: 0.567852258682251
24
train loss item: 0.3505617082118988
25
train loss item: 0.16093702614307404
26
train loss item: 0.1376381367444992
27
train loss item: 0.1524137407541275
28
train loss item: 0.05972866341471672
29
train loss item: 0.4437454342842102
30
train loss item: 1.67549729347229
31
train loss item: 0.3504559099674225
32
train loss item: 0.08816992491483688
33
train loss item: 0.26993489265441895
34
train loss item: 0.12696652114391327
35
train loss item: 1.9926530122756958
36
train loss item: 0.3271282911300659
37
train loss item: 0.3143216073513031
38
train loss item: 0.2964410185813904
39
train loss item: 0.16424204409122467
40
train loss item: 0.11673393845558167
41
train loss item: 0.15387284755706787
42
train loss item: 0.22485075891017914
43
train loss item: 0.1184118241071701
44
train loss item: 0.4925922453403473
45
train loss item: 0.11157014220952988
46
train loss item: 0.09786420315504074
47
train loss item: 0.2374209314584732
48
train loss item: 0.1424599438905716
49
train loss item: 0.1077265590429306
50
train loss item: 0.19825516641139984
51
train loss item: 0.5633688569068909
52
train loss item: 0.06746470928192139
53
train loss item: 0.11049607396125793
54
train loss item: 1.8725101947784424
55
train loss item: 0.13208715617656708
56
train loss item: 0.15945129096508026
57
train loss item: 0.1797691136598587
58
train loss item: 0.10958738625049591
59
train loss item: 0.10856284201145172
60
train loss item: 0.5220209956169128
61
train loss item: 1.7506842613220215
62
train loss item: 0.14487969875335693
63
train loss item: 0.2524704933166504
64
train loss item: 0.11581501364707947
65
train loss item: 0.32624682784080505
66
train loss item: 0.2622145712375641
67
train loss item: 0.1450122445821762
68
train loss item: 0.19174529612064362
69
train loss item: 0.20786239206790924
70
train loss item: 0.18049106001853943
71
train loss item: 0.10788016021251678
72
train loss item: 0.10916466265916824
73
train loss item: 0.19562433660030365
74
train loss item: 0.08029805123806
75
train loss item: 0.09407489001750946
76
train loss item: 0.5524857640266418
77
train loss item: 1.028936505317688
78
train loss item: 0.06562314927577972
79
train loss item: 0.19593733549118042
80
train loss item: 0.10108919441699982
81
train loss item: 0.14082355797290802
82
train loss item: 0.14173342287540436
83
train loss item: 0.38041701912879944
84
train loss item: 0.2971641421318054
85
train loss item: 0.3382379710674286
86
train loss item: 3.7065911293029785
87
train loss item: 0.11788730323314667
88
train loss item: 0.23844994604587555
epoch train loss: 0.3434192002070754
testing phase
test loss item: 0.1492895483970642
test loss item: 0.25436392426490784
test loss item: 0.46339479088783264
test loss item: 0.17921824753284454
test loss item: 0.3101233243942261
test loss item: 0.3208375573158264
test loss item: 1.224410057067871
test loss item: 0.41245850920677185
test loss item: 0.17473481595516205
test loss item: 0.2980949580669403
test loss item: 0.6452293395996094
test loss item: 0.20937499403953552
test loss item: 0.14058621227741241
test loss item: 0.2176695019006729
test loss item: 0.20263363420963287
test loss item: 0.40468642115592957
test loss item: 0.19769367575645447
test loss item: 0.36737361550331116
test loss item: 0.47725042700767517
test loss item: 0.19555236399173737
test loss item: 0.7949815392494202
test loss item: 0.2918326258659363
test loss item: 0.7530238628387451
test loss item: 0.1320730745792389
test loss item: 0.21682049334049225
test loss item: 0.16504204273223877
test loss item: 0.22746844589710236
test loss item: 0.2898913323879242
test loss item: 0.24042682349681854
test loss item: 0.2526146471500397
test loss item: 0.5782200694084167
test loss item: 0.37642502784729004
test loss item: 0.11570652574300766
test loss item: 0.4432356357574463
test loss item: 0.4059205651283264
test loss item: 0.3338751196861267
test loss item: 0.5846064686775208
test loss item: 1.1004835367202759
test loss item: 0.34424328804016113
test loss item: 0.28733018040657043
test loss item: 0.302565336227417
test loss item: 0.6302589178085327
test loss item: 0.2704653739929199
test loss item: 0.15764029324054718
test loss item: 0.6520358920097351
test loss item: 0.37399566173553467
test loss item: 0.7684550881385803
test loss item: 0.18294087052345276
test loss item: 0.371511310338974
test loss item: 0.5075993537902832
test loss item: 0.22162994742393494
test loss item: 0.1800520271062851
test loss item: 0.18145932257175446
test loss item: 0.1336704045534134
test loss item: 0.23965893685817719
test loss item: 0.6623510122299194
test loss item: 0.42750945687294006
test loss item: 0.20196156203746796
test loss item: 0.23465271294116974
test loss item: 0.16235759854316711
test loss item: 0.3692561388015747
test loss item: 0.29042911529541016
test loss item: 0.16346748173236847
test loss item: 0.17349371314048767
test loss item: 0.6839188933372498
test loss item: 0.24809134006500244
test loss item: 0.23258017003536224
test loss item: 0.17977450788021088
test loss item: 0.4759376347064972
test loss item: 0.3050714135169983
test loss item: 0.26662495732307434
test loss item: 0.693695068359375
test loss item: 0.3781660795211792
test loss item: 0.2751806080341339
test loss item: 0.11489831656217575
test loss item: 0.6488447785377502
test loss item: 0.20474253594875336
test loss item: 1.1403664350509644
test loss item: 0.33545786142349243
test loss item: 0.28591451048851013
test loss item: 0.18340377509593964
test loss item: 0.7220510244369507
test loss item: 0.6476811766624451
test loss item: 0.7834546566009521
test loss item: 0.17454110085964203
test loss item: 0.16424359381198883
test loss item: 0.26882919669151306
test loss item: 0.3970909118652344
test loss item: 0.1297251433134079
Epoch [37/50], Training Loss: 0.3434, Testing Loss: 0.3661
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Epoch 38/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3072455823421478
1
train loss item: 0.7492884993553162
2
train loss item: 0.13449014723300934
3
train loss item: 0.29828447103500366
4
train loss item: 0.2514066696166992
5
train loss item: 0.20385271310806274
6
train loss item: 0.1456468552350998
7
train loss item: 0.5100728273391724
8
train loss item: 0.08636137843132019
9
train loss item: 0.15427012741565704
10
train loss item: 0.19821274280548096
11
train loss item: 0.1981230080127716
12
train loss item: 0.10757672041654587
13
train loss item: 0.32642048597335815
14
train loss item: 0.1574462354183197
15
train loss item: 0.4093572497367859
16
train loss item: 0.06071850657463074
17
train loss item: 0.16707415878772736
18
train loss item: 0.20222075283527374
19
train loss item: 0.17290322482585907
20
train loss item: 0.1495373547077179
21
train loss item: 0.103474922478199
22
train loss item: 0.5391225814819336
23
train loss item: 0.5537811517715454
24
train loss item: 0.33990785479545593
25
train loss item: 0.15688197314739227
26
train loss item: 0.13625477254390717
27
train loss item: 0.14905525743961334
28
train loss item: 0.059030868113040924
29
train loss item: 0.41895416378974915
30
train loss item: 1.65471351146698
31
train loss item: 0.34262123703956604
32
train loss item: 0.08505133539438248
33
train loss item: 0.26390329003334045
34
train loss item: 0.12563693523406982
35
train loss item: 1.9809412956237793
36
train loss item: 0.33375465869903564
37
train loss item: 0.31733596324920654
38
train loss item: 0.3029254674911499
39
train loss item: 0.16152441501617432
40
train loss item: 0.11685354262590408
41
train loss item: 0.15220747888088226
42
train loss item: 0.22452622652053833
43
train loss item: 0.11616518348455429
44
train loss item: 0.48883023858070374
45
train loss item: 0.10893584042787552
46
train loss item: 0.09563025832176208
47
train loss item: 0.2291831225156784
48
train loss item: 0.14020982384681702
49
train loss item: 0.10623171925544739
50
train loss item: 0.18883715569972992
51
train loss item: 0.5478017926216125
52
train loss item: 0.06738685816526413
53
train loss item: 0.10732376575469971
54
train loss item: 1.8605035543441772
55
train loss item: 0.130886510014534
56
train loss item: 0.1554027646780014
57
train loss item: 0.1792803704738617
58
train loss item: 0.10707583278417587
59
train loss item: 0.10558867454528809
60
train loss item: 0.4976139962673187
61
train loss item: 1.7355588674545288
62
train loss item: 0.14067165553569794
63
train loss item: 0.2443222999572754
64
train loss item: 0.11357712000608444
65
train loss item: 0.32106441259384155
66
train loss item: 0.26042330265045166
67
train loss item: 0.14320357143878937
68
train loss item: 0.18229103088378906
69
train loss item: 0.20694366097450256
70
train loss item: 0.17701327800750732
71
train loss item: 0.10447122156620026
72
train loss item: 0.10679148137569427
73
train loss item: 0.19103209674358368
74
train loss item: 0.0778740867972374
75
train loss item: 0.09247299283742905
76
train loss item: 0.5372442007064819
77
train loss item: 1.0094300508499146
78
train loss item: 0.0649290606379509
79
train loss item: 0.19184677302837372
80
train loss item: 0.09988848865032196
81
train loss item: 0.1348540037870407
82
train loss item: 0.1379479020833969
83
train loss item: 0.3693709075450897
84
train loss item: 0.3056564927101135
85
train loss item: 0.3296683132648468
86
train loss item: 3.689917802810669
87
train loss item: 0.1152813509106636
88
train loss item: 0.23576992750167847
epoch train loss: 0.3377682295408142
testing phase
test loss item: 0.14820298552513123
test loss item: 0.12037253379821777
test loss item: 0.44349271059036255
test loss item: 0.17767664790153503
test loss item: 0.21139869093894958
test loss item: 0.14542856812477112
test loss item: 1.2652678489685059
test loss item: 0.4443299472332001
test loss item: 0.1656872034072876
test loss item: 0.28501269221305847
test loss item: 0.6272281408309937
test loss item: 0.15262183547019958
test loss item: 0.13985398411750793
test loss item: 0.2176322191953659
test loss item: 0.14874231815338135
test loss item: 0.1498081088066101
test loss item: 0.202626034617424
test loss item: 0.3448808789253235
test loss item: 0.49112558364868164
test loss item: 0.19948290288448334
test loss item: 0.6752399802207947
test loss item: 0.30032867193222046
test loss item: 0.3985329568386078
test loss item: 0.13261887431144714
test loss item: 0.17161749303340912
test loss item: 0.16553637385368347
test loss item: 0.22399131953716278
test loss item: 0.16376972198486328
test loss item: 0.23338168859481812
test loss item: 0.2452210634946823
test loss item: 0.5806736946105957
test loss item: 0.12665536999702454
test loss item: 0.1147783026099205
test loss item: 0.4220452904701233
test loss item: 0.32649096846580505
test loss item: 0.32985809445381165
test loss item: 0.5969563126564026
test loss item: 1.0658855438232422
test loss item: 0.33056697249412537
test loss item: 0.20621724426746368
test loss item: 0.2341340035200119
test loss item: 0.2934572994709015
test loss item: 0.2522587180137634
test loss item: 0.16037026047706604
test loss item: 0.5327392816543579
test loss item: 0.3019137382507324
test loss item: 0.3971705138683319
test loss item: 0.18676359951496124
test loss item: 0.36093568801879883
test loss item: 0.49860790371894836
test loss item: 0.20904973149299622
test loss item: 0.12866643071174622
test loss item: 0.17764732241630554
test loss item: 0.1296387016773224
test loss item: 0.22658777236938477
test loss item: 0.634139895439148
test loss item: 0.4319651424884796
test loss item: 0.1960790902376175
test loss item: 0.19506077468395233
test loss item: 0.15493075549602509
test loss item: 0.32321885228157043
test loss item: 0.21341075003147125
test loss item: 0.165493443608284
test loss item: 0.17251534759998322
test loss item: 0.6485308408737183
test loss item: 0.2458288073539734
test loss item: 0.23384889960289001
test loss item: 0.18153859674930573
test loss item: 0.4169009029865265
test loss item: 0.3128042221069336
test loss item: 0.1042013019323349
test loss item: 0.7149887084960938
test loss item: 0.2966989278793335
test loss item: 0.2852977216243744
test loss item: 0.11546068638563156
test loss item: 0.2886146306991577
test loss item: 0.15153685212135315
test loss item: 1.1150524616241455
test loss item: 0.33291876316070557
test loss item: 0.16195443272590637
test loss item: 0.10128891468048096
test loss item: 0.7260236740112305
test loss item: 0.6519736051559448
test loss item: 0.7649065852165222
test loss item: 0.173902228474617
test loss item: 0.1633950173854828
test loss item: 0.10131450742483139
test loss item: 0.1347496509552002
test loss item: 0.12684999406337738
Epoch [38/50], Training Loss: 0.3378, Testing Loss: 0.3148
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 39/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.30128103494644165
1
train loss item: 0.7308756709098816
2
train loss item: 0.13341152667999268
3
train loss item: 0.28715771436691284
4
train loss item: 0.24596205353736877
5
train loss item: 0.19718270003795624
6
train loss item: 0.1487606167793274
7
train loss item: 0.5005027651786804
8
train loss item: 0.08398354798555374
9
train loss item: 0.15196511149406433
10
train loss item: 0.19328242540359497
11
train loss item: 0.19403940439224243
12
train loss item: 0.10820239782333374
13
train loss item: 0.31709545850753784
14
train loss item: 0.15320046246051788
15
train loss item: 0.40595492720603943
16
train loss item: 0.06247060373425484
17
train loss item: 0.16320839524269104
18
train loss item: 0.19878964126110077
19
train loss item: 0.1744069755077362
20
train loss item: 0.15391306579113007
21
train loss item: 0.10274836421012878
22
train loss item: 0.5277628898620605
23
train loss item: 0.534328818321228
24
train loss item: 0.33173471689224243
25
train loss item: 0.15433308482170105
26
train loss item: 0.1367310732603073
27
train loss item: 0.14484496414661407
28
train loss item: 0.06034320965409279
29
train loss item: 0.41128039360046387
30
train loss item: 1.6341419219970703
31
train loss item: 0.33179163932800293
32
train loss item: 0.08196353167295456
33
train loss item: 0.24751579761505127
34
train loss item: 0.12250246107578278
35
train loss item: 1.9684420824050903
36
train loss item: 0.321098268032074
37
train loss item: 0.3064591884613037
38
train loss item: 0.2811461091041565
39
train loss item: 0.15978068113327026
40
train loss item: 0.1191115751862526
41
train loss item: 0.14705799520015717
42
train loss item: 0.2231370210647583
43
train loss item: 0.11414273828268051
44
train loss item: 0.4805774688720703
45
train loss item: 0.10553833097219467
46
train loss item: 0.09388317167758942
47
train loss item: 0.22696833312511444
48
train loss item: 0.13658367097377777
49
train loss item: 0.1045776829123497
50
train loss item: 0.19069170951843262
51
train loss item: 0.5370075106620789
52
train loss item: 0.07075267285108566
53
train loss item: 0.10445000231266022
54
train loss item: 1.8475717306137085
55
train loss item: 0.130484938621521
56
train loss item: 0.1531510055065155
57
train loss item: 0.18035906553268433
58
train loss item: 0.10830629616975784
59
train loss item: 0.10216687619686127
60
train loss item: 0.4849306046962738
61
train loss item: 1.715576410293579
62
train loss item: 0.13988934457302094
63
train loss item: 0.24029363691806793
64
train loss item: 0.10967454314231873
65
train loss item: 0.30901360511779785
66
train loss item: 0.2541826069355011
67
train loss item: 0.14175739884376526
68
train loss item: 0.18719139695167542
69
train loss item: 0.20241691172122955
70
train loss item: 0.17334601283073425
71
train loss item: 0.10541678965091705
72
train loss item: 0.1018703430891037
73
train loss item: 0.18862684071063995
74
train loss item: 0.07737068831920624
75
train loss item: 0.09093350172042847
76
train loss item: 0.5218312740325928
77
train loss item: 1.0003306865692139
78
train loss item: 0.06722540408372879
79
train loss item: 0.18811392784118652
80
train loss item: 0.09750385582447052
81
train loss item: 0.13402581214904785
82
train loss item: 0.13176849484443665
83
train loss item: 0.3631335198879242
84
train loss item: 0.29013070464134216
85
train loss item: 0.31923988461494446
86
train loss item: 3.670358180999756
87
train loss item: 0.11047512292861938
88
train loss item: 0.23029442131519318
epoch train loss: 0.33244985861054965
testing phase
test loss item: 0.14514383673667908
test loss item: 0.09418564289808273
test loss item: 0.45960092544555664
test loss item: 0.1749676913022995
test loss item: 0.20025686919689178
test loss item: 0.11591525375843048
test loss item: 1.2131507396697998
test loss item: 0.4228098392486572
test loss item: 0.16916978359222412
test loss item: 0.2898571193218231
test loss item: 0.6466336846351624
test loss item: 0.14370323717594147
test loss item: 0.13707639276981354
test loss item: 0.2076127827167511
test loss item: 0.1455477923154831
test loss item: 0.08396265655755997
test loss item: 0.19242142140865326
test loss item: 0.3490144908428192
test loss item: 0.4767245054244995
test loss item: 0.18686677515506744
test loss item: 0.6675256490707397
test loss item: 0.2884807884693146
test loss item: 0.32461196184158325
test loss item: 0.1290893703699112
test loss item: 0.16441023349761963
test loss item: 0.162069171667099
test loss item: 0.22047241032123566
test loss item: 0.1422981321811676
test loss item: 0.2313649207353592
test loss item: 0.24551373720169067
test loss item: 0.5840144753456116
test loss item: 0.06919505447149277
test loss item: 0.11305275559425354
test loss item: 0.4276299476623535
test loss item: 0.3269400894641876
test loss item: 0.3295937776565552
test loss item: 0.581851065158844
test loss item: 1.1069306135177612
test loss item: 0.3348299562931061
test loss item: 0.19293685257434845
test loss item: 0.2188640832901001
test loss item: 0.2247064858675003
test loss item: 0.25795045495033264
test loss item: 0.15536603331565857
test loss item: 0.520619809627533
test loss item: 0.2771711051464081
test loss item: 0.320032000541687
test loss item: 0.1738140732049942
test loss item: 0.36460238695144653
test loss item: 0.5011155009269714
test loss item: 0.22008094191551208
test loss item: 0.11824706941843033
test loss item: 0.17686660587787628
test loss item: 0.12748393416404724
test loss item: 0.23263129591941833
test loss item: 0.6582642197608948
test loss item: 0.42698100209236145
test loss item: 0.1987757384777069
test loss item: 0.18724390864372253
test loss item: 0.15691013634204865
test loss item: 0.32904332876205444
test loss item: 0.1906432807445526
test loss item: 0.15808899700641632
test loss item: 0.1692488044500351
test loss item: 0.6635674238204956
test loss item: 0.24267731606960297
test loss item: 0.2240489423274994
test loss item: 0.1761826127767563
test loss item: 0.4164046049118042
test loss item: 0.30576038360595703
test loss item: 0.06672659516334534
test loss item: 0.680079996585846
test loss item: 0.27770423889160156
test loss item: 0.2695668637752533
test loss item: 0.1095649003982544
test loss item: 0.21778330206871033
test loss item: 0.14070913195610046
test loss item: 1.1639082431793213
test loss item: 0.32834628224372864
test loss item: 0.14231549203395844
test loss item: 0.08839821815490723
test loss item: 0.7269492149353027
test loss item: 0.642464816570282
test loss item: 0.7966310381889343
test loss item: 0.1687142550945282
test loss item: 0.1563342660665512
test loss item: 0.06327849626541138
test loss item: 0.06548217684030533
test loss item: 0.13272704184055328
Epoch [39/50], Training Loss: 0.3324, Testing Loss: 0.3048
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 40/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.29731491208076477
1
train loss item: 0.7118470072746277
2
train loss item: 0.12843084335327148
3
train loss item: 0.2826836109161377
4
train loss item: 0.23673273622989655
5
train loss item: 0.1920153945684433
6
train loss item: 0.1405547559261322
7
train loss item: 0.4946407377719879
8
train loss item: 0.08426565676927567
9
train loss item: 0.14703848958015442
10
train loss item: 0.1905640959739685
11
train loss item: 0.1938164085149765
12
train loss item: 0.10566068440675735
13
train loss item: 0.31755149364471436
14
train loss item: 0.15321886539459229
15
train loss item: 0.39025694131851196
16
train loss item: 0.06192893162369728
17
train loss item: 0.16041633486747742
18
train loss item: 0.1941594034433365
19
train loss item: 0.16482365131378174
20
train loss item: 0.14422893524169922
21
train loss item: 0.09957929700613022
22
train loss item: 0.5001820921897888
23
train loss item: 0.5271964073181152
24
train loss item: 0.3144455552101135
25
train loss item: 0.1482538878917694
26
train loss item: 0.13387461006641388
27
train loss item: 0.14586639404296875
28
train loss item: 0.05984936282038689
29
train loss item: 0.3985375165939331
30
train loss item: 1.6201937198638916
31
train loss item: 0.3251870274543762
32
train loss item: 0.08314326405525208
33
train loss item: 0.2558494508266449
34
train loss item: 0.12246011942625046
35
train loss item: 1.957560658454895
36
train loss item: 0.31754258275032043
37
train loss item: 0.30294540524482727
38
train loss item: 0.27122706174850464
39
train loss item: 0.15730279684066772
40
train loss item: 0.11362923681735992
41
train loss item: 0.14728406071662903
42
train loss item: 0.2218112051486969
43
train loss item: 0.11387737095355988
44
train loss item: 0.4804222285747528
45
train loss item: 0.10675454884767532
46
train loss item: 0.09102115780115128
47
train loss item: 0.21959829330444336
48
train loss item: 0.13455058634281158
49
train loss item: 0.10505633801221848
50
train loss item: 0.17861251533031464
51
train loss item: 0.5301288962364197
52
train loss item: 0.07000745087862015
53
train loss item: 0.10516589134931564
54
train loss item: 1.8362979888916016
55
train loss item: 0.12984445691108704
56
train loss item: 0.1511567234992981
57
train loss item: 0.17320115864276886
58
train loss item: 0.10299264639616013
59
train loss item: 0.10274507105350494
60
train loss item: 0.4702906608581543
61
train loss item: 1.7051730155944824
62
train loss item: 0.13767236471176147
63
train loss item: 0.2337464541196823
64
train loss item: 0.11301672458648682
65
train loss item: 0.2918414771556854
66
train loss item: 0.2525123655796051
67
train loss item: 0.13827961683273315
68
train loss item: 0.18065327405929565
69
train loss item: 0.19662562012672424
70
train loss item: 0.1693613976240158
71
train loss item: 0.10408623516559601
72
train loss item: 0.10461835563182831
73
train loss item: 0.1816224455833435
74
train loss item: 0.07493680715560913
75
train loss item: 0.09045539796352386
76
train loss item: 0.5120915174484253
77
train loss item: 0.9843339920043945
78
train loss item: 0.06585226953029633
79
train loss item: 0.1858280599117279
80
train loss item: 0.09423403441905975
81
train loss item: 0.1304939240217209
82
train loss item: 0.13609090447425842
83
train loss item: 0.35351744294166565
84
train loss item: 0.2794383466243744
85
train loss item: 0.3121448755264282
86
train loss item: 3.6557271480560303
87
train loss item: 0.11292137205600739
88
train loss item: 0.2194371521472931
epoch train loss: 0.3273540244678433
testing phase
test loss item: 0.14315226674079895
test loss item: 0.09774580597877502
test loss item: 0.3964467942714691
test loss item: 0.17425255477428436
test loss item: 0.187197744846344
test loss item: 0.12412753701210022
test loss item: 1.2305258512496948
test loss item: 0.46067073941230774
test loss item: 0.1504550576210022
test loss item: 0.26051464676856995
test loss item: 0.5818253755569458
test loss item: 0.14945100247859955
test loss item: 0.13925215601921082
test loss item: 0.20114785432815552
test loss item: 0.14491009712219238
test loss item: 0.09158426523208618
test loss item: 0.19714035093784332
test loss item: 0.2998884618282318
test loss item: 0.493890643119812
test loss item: 0.19469797611236572
test loss item: 0.6121135354042053
test loss item: 0.2947227656841278
test loss item: 0.31808575987815857
test loss item: 0.1311698853969574
test loss item: 0.1593744307756424
test loss item: 0.1634618043899536
test loss item: 0.21273961663246155
test loss item: 0.13812397420406342
test loss item: 0.2209254950284958
test loss item: 0.22933654487133026
test loss item: 0.5533016324043274
test loss item: 0.07627234607934952
test loss item: 0.11492455750703812
test loss item: 0.3772003650665283
test loss item: 0.27979370951652527
test loss item: 0.32062408328056335
test loss item: 0.5907260775566101
test loss item: 0.9767550230026245
test loss item: 0.30008193850517273
test loss item: 0.19508178532123566
test loss item: 0.2206619828939438
test loss item: 0.22978267073631287
test loss item: 0.22105741500854492
test loss item: 0.1554536521434784
test loss item: 0.48746392130851746
test loss item: 0.2887928783893585
test loss item: 0.3174343407154083
test loss item: 0.18445539474487305
test loss item: 0.332518607378006
test loss item: 0.4646546542644501
test loss item: 0.1918943226337433
test loss item: 0.12654785811901093
test loss item: 0.16592258214950562
test loss item: 0.1252458691596985
test loss item: 0.20301152765750885
test loss item: 0.5708395838737488
test loss item: 0.4250446856021881
test loss item: 0.1813810169696808
test loss item: 0.1865205466747284
test loss item: 0.14708591997623444
test loss item: 0.2826811671257019
test loss item: 0.19974587857723236
test loss item: 0.1599472314119339
test loss item: 0.16942766308784485
test loss item: 0.6042556166648865
test loss item: 0.24001656472682953
test loss item: 0.22310136258602142
test loss item: 0.17808376252651215
test loss item: 0.38315412402153015
test loss item: 0.3141680359840393
test loss item: 0.07316194474697113
test loss item: 0.712048351764679
test loss item: 0.2597030997276306
test loss item: 0.2729496955871582
test loss item: 0.11406335979700089
test loss item: 0.22981137037277222
test loss item: 0.1490674614906311
test loss item: 1.0345951318740845
test loss item: 0.31045591831207275
test loss item: 0.14052778482437134
test loss item: 0.09632667154073715
test loss item: 0.6924263834953308
test loss item: 0.6295148134231567
test loss item: 0.705590009689331
test loss item: 0.16544897854328156
test loss item: 0.15591119229793549
test loss item: 0.06547727435827255
test loss item: 0.07129500061273575
test loss item: 0.1311514675617218
Epoch [40/50], Training Loss: 0.3274, Testing Loss: 0.2918
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 41/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.29460564255714417
1
train loss item: 0.6921922564506531
2
train loss item: 0.1326194852590561
3
train loss item: 0.2746736705303192
4
train loss item: 0.23768019676208496
5
train loss item: 0.1904798448085785
6
train loss item: 0.1468999981880188
7
train loss item: 0.4766315817832947
8
train loss item: 0.0811576172709465
9
train loss item: 0.14978726208209991
10
train loss item: 0.1947702318429947
11
train loss item: 0.19011062383651733
12
train loss item: 0.10449011623859406
13
train loss item: 0.30788904428482056
14
train loss item: 0.14480160176753998
15
train loss item: 0.39462265372276306
16
train loss item: 0.059653352946043015
17
train loss item: 0.15528441965579987
18
train loss item: 0.19600597023963928
19
train loss item: 0.1698867827653885
20
train loss item: 0.14886696636676788
21
train loss item: 0.10193562507629395
22
train loss item: 0.4949013292789459
23
train loss item: 0.5038707852363586
24
train loss item: 0.3165034055709839
25
train loss item: 0.15226157009601593
26
train loss item: 0.13018696010112762
27
train loss item: 0.13852190971374512
28
train loss item: 0.05774718523025513
29
train loss item: 0.3896079361438751
30
train loss item: 1.590536117553711
31
train loss item: 0.3285602629184723
32
train loss item: 0.08143698424100876
33
train loss item: 0.229917511343956
34
train loss item: 0.11902809143066406
35
train loss item: 1.9414215087890625
36
train loss item: 0.30981868505477905
37
train loss item: 0.29657259583473206
38
train loss item: 0.26595816016197205
39
train loss item: 0.1581520289182663
40
train loss item: 0.1170053780078888
41
train loss item: 0.13993994891643524
42
train loss item: 0.21932317316532135
43
train loss item: 0.1146586462855339
44
train loss item: 0.4646511971950531
45
train loss item: 0.1039787083864212
46
train loss item: 0.09455057978630066
47
train loss item: 0.2239580899477005
48
train loss item: 0.13088268041610718
49
train loss item: 0.10361415892839432
50
train loss item: 0.18559221923351288
51
train loss item: 0.5130325555801392
52
train loss item: 0.06697626411914825
53
train loss item: 0.10682285577058792
54
train loss item: 1.8189277648925781
55
train loss item: 0.12647128105163574
56
train loss item: 0.15584410727024078
57
train loss item: 0.1726486086845398
58
train loss item: 0.1086152046918869
59
train loss item: 0.10407926887273788
60
train loss item: 0.45183560252189636
61
train loss item: 1.6767009496688843
62
train loss item: 0.13608376681804657
63
train loss item: 0.2355668544769287
64
train loss item: 0.11366208642721176
65
train loss item: 0.28963062167167664
66
train loss item: 0.26031944155693054
67
train loss item: 0.1367366909980774
68
train loss item: 0.18319325149059296
69
train loss item: 0.19875577092170715
70
train loss item: 0.16999654471874237
71
train loss item: 0.1037236824631691
72
train loss item: 0.10026375949382782
73
train loss item: 0.18212437629699707
74
train loss item: 0.0741424709558487
75
train loss item: 0.0900731086730957
76
train loss item: 0.4956306219100952
77
train loss item: 0.972263753414154
78
train loss item: 0.0640883818268776
79
train loss item: 0.18553511798381805
80
train loss item: 0.09310030937194824
81
train loss item: 0.13163556158542633
82
train loss item: 0.1250627189874649
83
train loss item: 0.35020211338996887
84
train loss item: 0.267071932554245
85
train loss item: 0.2948114275932312
86
train loss item: 3.6308515071868896
87
train loss item: 0.10743565857410431
88
train loss item: 0.22437170147895813
epoch train loss: 0.3232189938007446
testing phase
test loss item: 0.14182274043560028
test loss item: 0.09968076646327972
test loss item: 0.5071308612823486
test loss item: 0.17290857434272766
test loss item: 0.2049953043460846
test loss item: 0.09907577931880951
test loss item: 1.1917147636413574
test loss item: 0.40244826674461365
test loss item: 0.18816158175468445
test loss item: 0.31232720613479614
test loss item: 0.7071393132209778
test loss item: 0.13205334544181824
test loss item: 0.13978971540927887
test loss item: 0.2092570960521698
test loss item: 0.14650508761405945
test loss item: 0.0825548842549324
test loss item: 0.18115682899951935
test loss item: 0.3668365776538849
test loss item: 0.4659067392349243
test loss item: 0.18078185617923737
test loss item: 0.6038188338279724
test loss item: 0.2756893038749695
test loss item: 0.2840849459171295
test loss item: 0.12671354413032532
test loss item: 0.15664757788181305
test loss item: 0.15993383526802063
test loss item: 0.22837987542152405
test loss item: 0.14047203958034515
test loss item: 0.24058622121810913
test loss item: 0.25902998447418213
test loss item: 0.6253488063812256
test loss item: 0.07423891872167587
test loss item: 0.11233929544687271
test loss item: 0.4485013484954834
test loss item: 0.3527575433254242
test loss item: 0.35082826018333435
test loss item: 0.5745764374732971
test loss item: 1.224621057510376
test loss item: 0.35574379563331604
test loss item: 0.18878348171710968
test loss item: 0.2123594880104065
test loss item: 0.17948532104492188
test loss item: 0.27355262637138367
test loss item: 0.15220260620117188
test loss item: 0.4564182162284851
test loss item: 0.26002511382102966
test loss item: 0.2679046392440796
test loss item: 0.1776682585477829
test loss item: 0.3850450813770294
test loss item: 0.5321166515350342
test loss item: 0.24744665622711182
test loss item: 0.1108146607875824
test loss item: 0.18191736936569214
test loss item: 0.1298092007637024
test loss item: 0.24956659972667694
test loss item: 0.7305948734283447
test loss item: 0.4336865246295929
test loss item: 0.20833852887153625
test loss item: 0.17928597331047058
test loss item: 0.16438399255275726
test loss item: 0.35419484972953796
test loss item: 0.17288170754909515
test loss item: 0.15007109940052032
test loss item: 0.16709387302398682
test loss item: 0.718860924243927
test loss item: 0.2402464598417282
test loss item: 0.2173927277326584
test loss item: 0.1737520396709442
test loss item: 0.43150100111961365
test loss item: 0.3205830454826355
test loss item: 0.073174387216568
test loss item: 0.6562685966491699
test loss item: 0.25847554206848145
test loss item: 0.2551650106906891
test loss item: 0.10768508911132812
test loss item: 0.18145497143268585
test loss item: 0.12678813934326172
test loss item: 1.2942278385162354
test loss item: 0.34220245480537415
test loss item: 0.1369820237159729
test loss item: 0.06689263135194778
test loss item: 0.7655474543571472
test loss item: 0.6574407815933228
test loss item: 0.887843132019043
test loss item: 0.16884516179561615
test loss item: 0.15227575600147247
test loss item: 0.06123371794819832
test loss item: 0.06123572215437889
test loss item: 0.14226579666137695
Epoch [41/50], Training Loss: 0.3232, Testing Loss: 0.3100
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 42/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2914732098579407
1
train loss item: 0.6780421733856201
2
train loss item: 0.1332525908946991
3
train loss item: 0.2845005393028259
4
train loss item: 0.24205875396728516
5
train loss item: 0.18601906299591064
6
train loss item: 0.13668158650398254
7
train loss item: 0.4821377694606781
8
train loss item: 0.09221529960632324
9
train loss item: 0.1521300971508026
10
train loss item: 0.19124145805835724
11
train loss item: 0.1962735801935196
12
train loss item: 0.10316714644432068
13
train loss item: 0.3174060881137848
14
train loss item: 0.150526762008667
15
train loss item: 0.3653918206691742
16
train loss item: 0.057129647582769394
17
train loss item: 0.1565060168504715
18
train loss item: 0.18848450481891632
19
train loss item: 0.1549341231584549
20
train loss item: 0.13739719986915588
21
train loss item: 0.102058544754982
22
train loss item: 0.46055421233177185
23
train loss item: 0.512895941734314
24
train loss item: 0.2928520143032074
25
train loss item: 0.1413041353225708
26
train loss item: 0.1321011334657669
27
train loss item: 0.15058843791484833
28
train loss item: 0.05566463991999626
29
train loss item: 0.3810102641582489
30
train loss item: 1.5954442024230957
31
train loss item: 0.3162873685359955
32
train loss item: 0.09472960233688354
33
train loss item: 0.2688150703907013
34
train loss item: 0.1217607706785202
35
train loss item: 1.9362479448318481
36
train loss item: 0.31086868047714233
37
train loss item: 0.2963245213031769
38
train loss item: 0.274221807718277
39
train loss item: 0.15812109410762787
40
train loss item: 0.11182483285665512
41
train loss item: 0.15307198464870453
42
train loss item: 0.22286400198936462
43
train loss item: 0.12266789376735687
44
train loss item: 0.47987499833106995
45
train loss item: 0.11086992919445038
46
train loss item: 0.09766466170549393
47
train loss item: 0.2133878767490387
48
train loss item: 0.13762076199054718
49
train loss item: 0.1099758967757225
50
train loss item: 0.16275881230831146
51
train loss item: 0.5236822962760925
52
train loss item: 0.06370751559734344
53
train loss item: 0.10921962559223175
54
train loss item: 1.8150197267532349
55
train loss item: 0.12774431705474854
56
train loss item: 0.15210236608982086
57
train loss item: 0.16342727839946747
58
train loss item: 0.10585780441761017
59
train loss item: 0.10839031636714935
60
train loss item: 0.444879412651062
61
train loss item: 1.6797940731048584
62
train loss item: 0.13670778274536133
63
train loss item: 0.22727154195308685
64
train loss item: 0.12701189517974854
65
train loss item: 0.26916155219078064
66
train loss item: 0.25853949785232544
67
train loss item: 0.13753212988376617
68
train loss item: 0.1695496290922165
69
train loss item: 0.1940833479166031
70
train loss item: 0.16758447885513306
71
train loss item: 0.10028457641601562
72
train loss item: 0.12127096205949783
73
train loss item: 0.17761322855949402
74
train loss item: 0.07265810668468475
75
train loss item: 0.09245197474956512
76
train loss item: 0.4919096529483795
77
train loss item: 0.9579448103904724
78
train loss item: 0.05992479994893074
79
train loss item: 0.18613912165164948
80
train loss item: 0.09474091976881027
81
train loss item: 0.12775005400180817
82
train loss item: 0.1432032436132431
83
train loss item: 0.345361590385437
84
train loss item: 0.26330840587615967
85
train loss item: 0.3085728585720062
86
train loss item: 3.627727508544922
87
train loss item: 0.1196451261639595
88
train loss item: 0.20768088102340698
epoch train loss: 0.32248152671067903
testing phase
test loss item: 0.14421626925468445
test loss item: 0.0933258980512619
test loss item: 0.35299980640411377
test loss item: 0.17258454859256744
test loss item: 0.18368753790855408
test loss item: 0.12847545742988586
test loss item: 1.2871882915496826
test loss item: 0.5018763542175293
test loss item: 0.14566822350025177
test loss item: 0.24592234194278717
test loss item: 0.5450900793075562
test loss item: 0.13695009052753448
test loss item: 0.14573301374912262
test loss item: 0.2231212705373764
test loss item: 0.12852363288402557
test loss item: 0.08137432485818863
test loss item: 0.20737063884735107
test loss item: 0.2613931894302368
test loss item: 0.5184500813484192
test loss item: 0.22036294639110565
test loss item: 0.4985964596271515
test loss item: 0.30132511258125305
test loss item: 0.5657480359077454
test loss item: 0.1344519853591919
test loss item: 0.1434999406337738
test loss item: 0.16680045425891876
test loss item: 0.2243533879518509
test loss item: 0.14859221875667572
test loss item: 0.21894952654838562
test loss item: 0.226405069231987
test loss item: 0.5456652045249939
test loss item: 0.06937616318464279
test loss item: 0.11642143130302429
test loss item: 0.33398035168647766
test loss item: 0.2403205782175064
test loss item: 0.33435001969337463
test loss item: 0.6087641716003418
test loss item: 0.8918948769569397
test loss item: 0.272204726934433
test loss item: 0.20780836045742035
test loss item: 0.22412937879562378
test loss item: 0.46257659792900085
test loss item: 0.1952279657125473
test loss item: 0.1563289612531662
test loss item: 0.40955787897109985
test loss item: 0.311322957277298
test loss item: 0.5728579163551331
test loss item: 0.2279941886663437
test loss item: 0.31057262420654297
test loss item: 0.45115187764167786
test loss item: 0.16996140778064728
test loss item: 0.13242074847221375
test loss item: 0.15993928909301758
test loss item: 0.12147405743598938
test loss item: 0.17861001193523407
test loss item: 0.5084993839263916
test loss item: 0.43455395102500916
test loss item: 0.17475460469722748
test loss item: 0.179756298661232
test loss item: 0.1377408802509308
test loss item: 0.24694745242595673
test loss item: 0.20925001800060272
test loss item: 0.16547344624996185
test loss item: 0.1709597408771515
test loss item: 0.5741932392120361
test loss item: 0.23615260422229767
test loss item: 0.23425427079200745
test loss item: 0.1839095652103424
test loss item: 0.3500116169452667
test loss item: 0.34071606397628784
test loss item: 0.07338297367095947
test loss item: 0.7607257962226868
test loss item: 0.25139477849006653
test loss item: 0.28792816400527954
test loss item: 0.12579160928726196
test loss item: 0.5125238299369812
test loss item: 0.14315739274024963
test loss item: 0.9456102252006531
test loss item: 0.3219427764415741
test loss item: 0.1547665148973465
test loss item: 0.07711734622716904
test loss item: 0.6888394951820374
test loss item: 0.6386013627052307
test loss item: 0.6495265960693359
test loss item: 0.17727309465408325
test loss item: 0.16305460035800934
test loss item: 0.06025794520974159
test loss item: 0.05971122533082962
test loss item: 0.13113661110401154
Epoch [42/50], Training Loss: 0.3225, Testing Loss: 0.2969
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 43/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2875077426433563
1
train loss item: 0.6571650505065918
2
train loss item: 0.15016411244869232
3
train loss item: 0.2812064588069916
4
train loss item: 0.23844687640666962
5
train loss item: 0.18756018579006195
6
train loss item: 0.16818836331367493
7
train loss item: 0.4559135437011719
8
train loss item: 0.08952081948518753
9
train loss item: 0.16577975451946259
10
train loss item: 0.20146866142749786
11
train loss item: 0.18811792135238647
12
train loss item: 0.10885303467512131
13
train loss item: 0.29735854268074036
14
train loss item: 0.1401243507862091
15
train loss item: 0.393344521522522
16
train loss item: 0.059619028121232986
17
train loss item: 0.15211601555347443
18
train loss item: 0.2006722092628479
19
train loss item: 0.17981590330600739
20
train loss item: 0.1657055914402008
21
train loss item: 0.11531136184930801
22
train loss item: 0.4702436029911041
23
train loss item: 0.47043418884277344
24
train loss item: 0.32124075293540955
25
train loss item: 0.1556675285100937
26
train loss item: 0.13096420466899872
27
train loss item: 0.1391524374485016
28
train loss item: 0.05760512501001358
29
train loss item: 0.377887487411499
30
train loss item: 1.5471245050430298
31
train loss item: 0.3363804221153259
32
train loss item: 0.09371441602706909
33
train loss item: 0.20716021955013275
34
train loss item: 0.11730694025754929
35
train loss item: 1.9154620170593262
36
train loss item: 0.30134260654449463
37
train loss item: 0.28621312975883484
38
train loss item: 0.2762732207775116
39
train loss item: 0.16497138142585754
40
train loss item: 0.13261090219020844
41
train loss item: 0.14361245930194855
42
train loss item: 0.21935595571994781
43
train loss item: 0.12806637585163116
44
train loss item: 0.4471481740474701
45
train loss item: 0.10088049620389938
46
train loss item: 0.11466560512781143
47
train loss item: 0.22690775990486145
48
train loss item: 0.1357746422290802
49
train loss item: 0.11367217451334
50
train loss item: 0.1963605433702469
51
train loss item: 0.49783217906951904
52
train loss item: 0.0659281387925148
53
train loss item: 0.11361335217952728
54
train loss item: 1.7918788194656372
55
train loss item: 0.1325843185186386
56
train loss item: 0.165823295712471
57
train loss item: 0.1834021508693695
58
train loss item: 0.1276315599679947
59
train loss item: 0.10630285739898682
60
train loss item: 0.4179880917072296
61
train loss item: 1.632429838180542
62
train loss item: 0.1363278031349182
63
train loss item: 0.2365376353263855
64
train loss item: 0.12435895949602127
65
train loss item: 0.283308744430542
66
train loss item: 0.27086934447288513
67
train loss item: 0.1445050835609436
68
train loss item: 0.18556222319602966
69
train loss item: 0.2028139978647232
70
train loss item: 0.17325107753276825
71
train loss item: 0.10602544248104095
72
train loss item: 0.1099180355668068
73
train loss item: 0.19108116626739502
74
train loss item: 0.07714693248271942
75
train loss item: 0.09307854622602463
76
train loss item: 0.46894216537475586
77
train loss item: 0.9492731094360352
78
train loss item: 0.06606461852788925
79
train loss item: 0.1842803657054901
80
train loss item: 0.0961228460073471
81
train loss item: 0.13893240690231323
82
train loss item: 0.12035363912582397
83
train loss item: 0.34645989537239075
84
train loss item: 0.26134124398231506
85
train loss item: 0.2874416410923004
86
train loss item: 3.5931661128997803
87
train loss item: 0.10896285623311996
88
train loss item: 0.2285914570093155
epoch train loss: 0.3217111379326729
testing phase
test loss item: 0.13991302251815796
test loss item: 0.09872910380363464
test loss item: 0.508592426776886
test loss item: 0.16923095285892487
test loss item: 0.22420427203178406
test loss item: 0.1453305035829544
test loss item: 1.087200403213501
test loss item: 0.3574219048023224
test loss item: 0.19014307856559753
test loss item: 0.31429168581962585
test loss item: 0.7091272473335266
test loss item: 0.1349833756685257
test loss item: 0.13967348635196686
test loss item: 0.20925864577293396
test loss item: 0.14973889291286469
test loss item: 0.08057789504528046
test loss item: 0.176701620221138
test loss item: 0.36711248755455017
test loss item: 0.43888482451438904
test loss item: 0.18081218004226685
test loss item: 0.61546790599823
test loss item: 0.2602003514766693
test loss item: 0.5249649286270142
test loss item: 0.12763531506061554
test loss item: 0.15567448735237122
test loss item: 0.1597781777381897
test loss item: 0.2287282794713974
test loss item: 0.17676469683647156
test loss item: 0.24138660728931427
test loss item: 0.2591570019721985
test loss item: 0.604103684425354
test loss item: 0.06979851424694061
test loss item: 0.11290677636861801
test loss item: 0.4441406726837158
test loss item: 0.35343030095100403
test loss item: 0.3454281985759735
test loss item: 0.5392863750457764
test loss item: 1.2287441492080688
test loss item: 0.3530876934528351
test loss item: 0.20161648094654083
test loss item: 0.2037070393562317
test loss item: 0.40880998969078064
test loss item: 0.2787610590457916
test loss item: 0.14587967097759247
test loss item: 0.47382691502571106
test loss item: 0.256817102432251
test loss item: 0.5240646004676819
test loss item: 0.1747770756483078
test loss item: 0.38363391160964966
test loss item: 0.5262749791145325
test loss item: 0.2545759081840515
test loss item: 0.11328256875276566
test loss item: 0.18040625751018524
test loss item: 0.12711600959300995
test loss item: 0.25197386741638184
test loss item: 0.7281577587127686
test loss item: 0.4206993281841278
test loss item: 0.2172790765762329
test loss item: 0.1817493438720703
test loss item: 0.16442716121673584
test loss item: 0.36023589968681335
test loss item: 0.16566750407218933
test loss item: 0.14721432328224182
test loss item: 0.16357871890068054
test loss item: 0.7162948250770569
test loss item: 0.2346952110528946
test loss item: 0.21783575415611267
test loss item: 0.1694687008857727
test loss item: 0.42708468437194824
test loss item: 0.3027045428752899
test loss item: 0.07104083150625229
test loss item: 0.5982764363288879
test loss item: 0.262861043214798
test loss item: 0.2435353845357895
test loss item: 0.10732964426279068
test loss item: 0.4521245062351227
test loss item: 0.13206462562084198
test loss item: 1.2991632223129272
test loss item: 0.34457340836524963
test loss item: 0.1698889136314392
test loss item: 0.07236197590827942
test loss item: 0.7438494563102722
test loss item: 0.6256190538406372
test loss item: 0.8891414403915405
test loss item: 0.17237044870853424
test loss item: 0.15150713920593262
test loss item: 0.0605458989739418
test loss item: 0.0604483000934124
test loss item: 0.14113973081111908
Epoch [43/50], Training Loss: 0.3217, Testing Loss: 0.3185
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 44/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.27937111258506775
1
train loss item: 0.6511348485946655
2
train loss item: 0.12912698090076447
3
train loss item: 0.27200907468795776
4
train loss item: 0.2303224354982376
5
train loss item: 0.1773754060268402
6
train loss item: 0.1312372386455536
7
train loss item: 0.4713507294654846
8
train loss item: 0.08852442353963852
9
train loss item: 0.1465653032064438
10
train loss item: 0.1829638034105301
11
train loss item: 0.18543162941932678
12
train loss item: 0.1009647324681282
13
train loss item: 0.3046916723251343
14
train loss item: 0.1478794813156128
15
train loss item: 0.35066303610801697
16
train loss item: 0.05707687512040138
17
train loss item: 0.14735889434814453
18
train loss item: 0.17983627319335938
19
train loss item: 0.1487768292427063
20
train loss item: 0.13360686600208282
21
train loss item: 0.0962163656949997
22
train loss item: 0.4243776202201843
23
train loss item: 0.48727095127105713
24
train loss item: 0.28344300389289856
25
train loss item: 0.13667555153369904
26
train loss item: 0.12355461716651917
27
train loss item: 0.1445259004831314
28
train loss item: 0.055301766842603683
29
train loss item: 0.3565095067024231
30
train loss item: 1.5597913265228271
31
train loss item: 0.299124151468277
32
train loss item: 0.0894969031214714
33
train loss item: 0.2599845230579376
34
train loss item: 0.11884518712759018
35
train loss item: 1.914777159690857
36
train loss item: 0.3035062253475189
37
train loss item: 0.28589507937431335
38
train loss item: 0.2624921202659607
39
train loss item: 0.15419253706932068
40
train loss item: 0.1108732521533966
41
train loss item: 0.1486789435148239
42
train loss item: 0.2173343449831009
43
train loss item: 0.11908046901226044
44
train loss item: 0.4725832939147949
45
train loss item: 0.1081445962190628
46
train loss item: 0.09377933293581009
47
train loss item: 0.20694786310195923
48
train loss item: 0.13528434932231903
49
train loss item: 0.10667753964662552
50
train loss item: 0.15657560527324677
51
train loss item: 0.5013091564178467
52
train loss item: 0.06491057574748993
53
train loss item: 0.1080591008067131
54
train loss item: 1.793347716331482
55
train loss item: 0.12556056678295135
56
train loss item: 0.1465727984905243
57
train loss item: 0.16104097664356232
58
train loss item: 0.10277104377746582
59
train loss item: 0.10398849099874496
60
train loss item: 0.41487932205200195
61
train loss item: 1.6497795581817627
62
train loss item: 0.1290358603000641
63
train loss item: 0.21873663365840912
64
train loss item: 0.12322704493999481
65
train loss item: 0.25473302602767944
66
train loss item: 0.2443290799856186
67
train loss item: 0.13154369592666626
68
train loss item: 0.16423329710960388
69
train loss item: 0.189127579331398
70
train loss item: 0.160774365067482
71
train loss item: 0.09896562993526459
72
train loss item: 0.11704239249229431
73
train loss item: 0.17304669320583344
74
train loss item: 0.06994572281837463
75
train loss item: 0.09084780514240265
76
train loss item: 0.46775099635124207
77
train loss item: 0.9302382469177246
78
train loss item: 0.060237400233745575
79
train loss item: 0.17879238724708557
80
train loss item: 0.09254349768161774
81
train loss item: 0.12511928379535675
82
train loss item: 0.1404389590024948
83
train loss item: 0.3356149196624756
84
train loss item: 0.27119141817092896
85
train loss item: 0.29586735367774963
86
train loss item: 3.5936553478240967
87
train loss item: 0.12074543535709381
88
train loss item: 0.19848395884037018
epoch train loss: 0.31344601202212025
testing phase
test loss item: 0.14505968987941742
test loss item: 0.08562308549880981
test loss item: 0.4313160181045532
test loss item: 0.1735883504152298
test loss item: 0.1843288242816925
test loss item: 0.09902630001306534
test loss item: 1.4486027956008911
test loss item: 0.5055508017539978
test loss item: 0.16254587471485138
test loss item: 0.2737300992012024
test loss item: 0.629892110824585
test loss item: 0.12988099455833435
test loss item: 0.13432292640209198
test loss item: 0.2118302285671234
test loss item: 0.12821272015571594
test loss item: 0.07092878967523575
test loss item: 0.20912720263004303
test loss item: 0.3089165687561035
test loss item: 0.5154576301574707
test loss item: 0.2051006704568863
test loss item: 0.5046395063400269
test loss item: 0.31061530113220215
test loss item: 0.3161543309688568
test loss item: 0.13758845627307892
test loss item: 0.14497992396354675
test loss item: 0.1729690134525299
test loss item: 0.22619332373142242
test loss item: 0.13407117128372192
test loss item: 0.23272188007831573
test loss item: 0.23728220164775848
test loss item: 0.6279286742210388
test loss item: 0.06014041230082512
test loss item: 0.116051584482193
test loss item: 0.3860400915145874
test loss item: 0.29324567317962646
test loss item: 0.32991495728492737
test loss item: 0.6263074278831482
test loss item: 1.0650602579116821
test loss item: 0.3172701299190521
test loss item: 0.21437858045101166
test loss item: 0.23976555466651917
test loss item: 0.214645653963089
test loss item: 0.23014605045318604
test loss item: 0.1677442491054535
test loss item: 0.3850071132183075
test loss item: 0.3044140338897705
test loss item: 0.2987616956233978
test loss item: 0.18545407056808472
test loss item: 0.3487074673175812
test loss item: 0.5003616213798523
test loss item: 0.20691585540771484
test loss item: 0.10548729449510574
test loss item: 0.17584358155727386
test loss item: 0.1236204132437706
test loss item: 0.21267180144786835
test loss item: 0.6123760342597961
test loss item: 0.4454309940338135
test loss item: 0.18991392850875854
test loss item: 0.17919501662254333
test loss item: 0.1436544954776764
test loss item: 0.29545116424560547
test loss item: 0.2053333967924118
test loss item: 0.16859500110149384
test loss item: 0.17336083948612213
test loss item: 0.6615858674049377
test loss item: 0.23877082765102386
test loss item: 0.23800107836723328
test loss item: 0.1911199986934662
test loss item: 0.38343295454978943
test loss item: 0.33726444840431213
test loss item: 0.06156463921070099
test loss item: 0.8247200846672058
test loss item: 0.25672268867492676
test loss item: 0.31081461906433105
test loss item: 0.11199429631233215
test loss item: 0.2274349331855774
test loss item: 0.13905979692935944
test loss item: 1.133938193321228
test loss item: 0.3351810574531555
test loss item: 0.14020013809204102
test loss item: 0.06487751007080078
test loss item: 0.7721099853515625
test loss item: 0.6858780980110168
test loss item: 0.7801957130432129
test loss item: 0.18559670448303223
test loss item: 0.15572093427181244
test loss item: 0.05738334730267525
test loss item: 0.054843612015247345
test loss item: 0.13997779786586761
Epoch [44/50], Training Loss: 0.3134, Testing Loss: 0.3046
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Epoch 45/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.27160370349884033
1
train loss item: 0.6307145953178406
2
train loss item: 0.11934813112020493
3
train loss item: 0.2567584812641144
4
train loss item: 0.21326595544815063
5
train loss item: 0.1719607710838318
6
train loss item: 0.13862185180187225
7
train loss item: 0.4585588574409485
8
train loss item: 0.0775088295340538
9
train loss item: 0.13645987212657928
10
train loss item: 0.16649873554706573
11
train loss item: 0.1733010709285736
12
train loss item: 0.10020598024129868
13
train loss item: 0.28322750329971313
14
train loss item: 0.13951684534549713
15
train loss item: 0.37425747513771057
16
train loss item: 0.05868377164006233
17
train loss item: 0.14000968635082245
18
train loss item: 0.17459414899349213
19
train loss item: 0.160791277885437
20
train loss item: 0.14213904738426208
21
train loss item: 0.09300757199525833
22
train loss item: 0.4389232099056244
23
train loss item: 0.45891422033309937
24
train loss item: 0.29274946451187134
25
train loss item: 0.13024300336837769
26
train loss item: 0.11857552826404572
27
train loss item: 0.12994365394115448
28
train loss item: 0.056428130716085434
29
train loss item: 0.36817115545272827
30
train loss item: 1.5363566875457764
31
train loss item: 0.2818077802658081
32
train loss item: 0.07524941116571426
33
train loss item: 0.22491280734539032
34
train loss item: 0.11403437703847885
35
train loss item: 1.9005494117736816
36
train loss item: 0.26925793290138245
37
train loss item: 0.26249319314956665
38
train loss item: 0.22796280682086945
39
train loss item: 0.1459542214870453
40
train loss item: 0.10999074578285217
41
train loss item: 0.13233934342861176
42
train loss item: 0.21429544687271118
43
train loss item: 0.10726113617420197
44
train loss item: 0.45252490043640137
45
train loss item: 0.10053014755249023
46
train loss item: 0.08384840935468674
47
train loss item: 0.21443234384059906
48
train loss item: 0.12542831897735596
49
train loss item: 0.09607534855604172
50
train loss item: 0.17615081369876862
51
train loss item: 0.4858299791812897
52
train loss item: 0.06703176349401474
53
train loss item: 0.09798957407474518
54
train loss item: 1.7792543172836304
55
train loss item: 0.12315601110458374
56
train loss item: 0.138154536485672
57
train loss item: 0.16811515390872955
58
train loss item: 0.0989140123128891
59
train loss item: 0.09932833909988403
60
train loss item: 0.41305169463157654
61
train loss item: 1.623187780380249
62
train loss item: 0.12374281138181686
63
train loss item: 0.22283127903938293
64
train loss item: 0.10519085824489594
65
train loss item: 0.24789142608642578
66
train loss item: 0.21649938821792603
67
train loss item: 0.1280393749475479
68
train loss item: 0.18065567314624786
69
train loss item: 0.17736831307411194
70
train loss item: 0.15850605070590973
71
train loss item: 0.09918785840272903
72
train loss item: 0.09590332210063934
73
train loss item: 0.17462529242038727
74
train loss item: 0.07163219153881073
75
train loss item: 0.08707079291343689
76
train loss item: 0.4494563639163971
77
train loss item: 0.9385029077529907
78
train loss item: 0.06242859736084938
79
train loss item: 0.17264042794704437
80
train loss item: 0.08671867847442627
81
train loss item: 0.1313512772321701
82
train loss item: 0.12058787047863007
83
train loss item: 0.32957446575164795
84
train loss item: 0.22351929545402527
85
train loss item: 0.2861103117465973
86
train loss item: 3.569725513458252
87
train loss item: 0.10623028874397278
88
train loss item: 0.19328200817108154
epoch train loss: 0.30539015634508615
testing phase
test loss item: 0.13778875768184662
test loss item: 0.08517139405012131
test loss item: 0.3449372351169586
test loss item: 0.15983064472675323
test loss item: 0.16766582429409027
test loss item: 0.09337286651134491
test loss item: 0.8863517045974731
test loss item: 0.3126492202281952
test loss item: 0.13788434863090515
test loss item: 0.2307872772216797
test loss item: 0.5251379013061523
test loss item: 0.12031500786542892
test loss item: 0.1269761472940445
test loss item: 0.19760483503341675
test loss item: 0.11600693315267563
test loss item: 0.07347079366445541
test loss item: 0.16876408457756042
test loss item: 0.25575533509254456
test loss item: 0.393053263425827
test loss item: 0.17681986093521118
test loss item: 0.404706746339798
test loss item: 0.23914192616939545
test loss item: 0.26713797450065613
test loss item: 0.11552190780639648
test loss item: 0.12682758271694183
test loss item: 0.15089038014411926
test loss item: 0.19611336290836334
test loss item: 0.12475383281707764
test loss item: 0.1990915983915329
test loss item: 0.20427629351615906
test loss item: 0.443298876285553
test loss item: 0.061497386544942856
test loss item: 0.10391607880592346
test loss item: 0.32381391525268555
test loss item: 0.23666207492351532
test loss item: 0.28763917088508606
test loss item: 0.45596832036972046
test loss item: 0.8814279437065125
test loss item: 0.25555220246315
test loss item: 0.16438648104667664
test loss item: 0.18880046904087067
test loss item: 0.18598179519176483
test loss item: 0.19216714799404144
test loss item: 0.13182897865772247
test loss item: 0.3140263855457306
test loss item: 0.24792078137397766
test loss item: 0.2573794424533844
test loss item: 0.18176187574863434
test loss item: 0.28440189361572266
test loss item: 0.39757412672042847
test loss item: 0.17037393152713776
test loss item: 0.10352165997028351
test loss item: 0.1467127650976181
test loss item: 0.11448505520820618
test loss item: 0.1768580824136734
test loss item: 0.4975561499595642
test loss item: 0.3582378625869751
test loss item: 0.16037176549434662
test loss item: 0.15660008788108826
test loss item: 0.13420015573501587
test loss item: 0.24565540254116058
test loss item: 0.1608191430568695
test loss item: 0.14337310194969177
test loss item: 0.1520927995443344
test loss item: 0.5016802549362183
test loss item: 0.222254678606987
test loss item: 0.19470526278018951
test loss item: 0.15927793085575104
test loss item: 0.3421911299228668
test loss item: 0.2495875358581543
test loss item: 0.06472823023796082
test loss item: 0.5061444640159607
test loss item: 0.22937171161174774
test loss item: 0.22397629916667938
test loss item: 0.10582201182842255
test loss item: 0.19766491651535034
test loss item: 0.11522120237350464
test loss item: 0.9359674453735352
test loss item: 0.29448187351226807
test loss item: 0.12991765141487122
test loss item: 0.06026579067111015
test loss item: 0.556963324546814
test loss item: 0.48397549986839294
test loss item: 0.6241158246994019
test loss item: 0.1571381837129593
test loss item: 0.14521880447864532
test loss item: 0.05541370064020157
test loss item: 0.054447803646326065
test loss item: 0.12634846568107605
Epoch [45/50], Training Loss: 0.3054, Testing Loss: 0.2449
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 46/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2710060775279999
1
train loss item: 0.6308771371841431
2
train loss item: 0.1265907883644104
3
train loss item: 0.30259275436401367
4
train loss item: 0.2341015785932541
5
train loss item: 0.18129859864711761
6
train loss item: 0.14443300664424896
7
train loss item: 0.43321844935417175
8
train loss item: 0.07724332064390182
9
train loss item: 0.1547679305076599
10
train loss item: 0.1894015371799469
11
train loss item: 0.18419921398162842
12
train loss item: 0.1015448197722435
13
train loss item: 0.29517051577568054
14
train loss item: 0.13450957834720612
15
train loss item: 0.3866656422615051
16
train loss item: 0.058474957942962646
17
train loss item: 0.15105347335338593
18
train loss item: 0.20099467039108276
19
train loss item: 0.15855063498020172
20
train loss item: 0.15033918619155884
21
train loss item: 0.10629400610923767
22
train loss item: 0.4119209349155426
23
train loss item: 0.4485265910625458
24
train loss item: 0.32482898235321045
25
train loss item: 0.1441745162010193
26
train loss item: 0.1225099265575409
27
train loss item: 0.12878181040287018
28
train loss item: 0.056257013231515884
29
train loss item: 0.34423986077308655
30
train loss item: 1.4906280040740967
31
train loss item: 0.34162867069244385
32
train loss item: 0.07962654531002045
33
train loss item: 0.20155324041843414
34
train loss item: 0.1213580071926117
35
train loss item: 1.8820313215255737
36
train loss item: 0.32288119196891785
37
train loss item: 0.3024158179759979
38
train loss item: 0.3472059667110443
39
train loss item: 0.15820658206939697
40
train loss item: 0.11657903343439102
41
train loss item: 0.13368584215641022
42
train loss item: 0.2187706083059311
43
train loss item: 0.11094469577074051
44
train loss item: 0.43528488278388977
45
train loss item: 0.0947827398777008
46
train loss item: 0.09407515823841095
47
train loss item: 0.22821944952011108
48
train loss item: 0.12215009331703186
49
train loss item: 0.10050035268068314
50
train loss item: 0.16817714273929596
51
train loss item: 0.45757386088371277
52
train loss item: 0.06575222313404083
53
train loss item: 0.10447856038808823
54
train loss item: 1.7579847574234009
55
train loss item: 0.1228175237774849
56
train loss item: 0.15389519929885864
57
train loss item: 0.17256729304790497
58
train loss item: 0.10914532095193863
59
train loss item: 0.10170398652553558
60
train loss item: 0.37194332480430603
61
train loss item: 1.5910546779632568
62
train loss item: 0.12754133343696594
63
train loss item: 0.234669491648674
64
train loss item: 0.10901283472776413
65
train loss item: 0.30381837487220764
66
train loss item: 0.278079628944397
67
train loss item: 0.13879002630710602
68
train loss item: 0.17302021384239197
69
train loss item: 0.21961958706378937
70
train loss item: 0.1730503886938095
71
train loss item: 0.09713486582040787
72
train loss item: 0.09527165442705154
73
train loss item: 0.1726524978876114
74
train loss item: 0.07439114898443222
75
train loss item: 0.08651863038539886
76
train loss item: 0.45053917169570923
77
train loss item: 0.8825734853744507
78
train loss item: 0.06296572834253311
79
train loss item: 0.18888349831104279
80
train loss item: 0.08964439481496811
81
train loss item: 0.13430847227573395
82
train loss item: 0.11047904193401337
83
train loss item: 0.3472267985343933
84
train loss item: 0.2956870198249817
85
train loss item: 0.26995620131492615
86
train loss item: 3.545527696609497
87
train loss item: 0.10020477324724197
88
train loss item: 0.24148264527320862
epoch train loss: 0.3116543729569805
testing phase
test loss item: 0.1443047821521759
test loss item: 0.08823363482952118
test loss item: 0.4555339813232422
test loss item: 0.1748000830411911
test loss item: 0.18906459212303162
test loss item: 0.1003519594669342
test loss item: 1.4246350526809692
test loss item: 0.4894191026687622
test loss item: 0.1757625937461853
test loss item: 0.29075923562049866
test loss item: 0.6495172381401062
test loss item: 0.13332007825374603
test loss item: 0.1348876804113388
test loss item: 0.21507148444652557
test loss item: 0.1337490975856781
test loss item: 0.07021372020244598
test loss item: 0.21026693284511566
test loss item: 0.32687458395957947
test loss item: 0.49937084317207336
test loss item: 0.20722778141498566
test loss item: 0.5267073512077332
test loss item: 0.309376060962677
test loss item: 0.26020511984825134
test loss item: 0.13923901319503784
test loss item: 0.14798618853092194
test loss item: 0.1759776771068573
test loss item: 0.23457585275173187
test loss item: 0.13475650548934937
test loss item: 0.24071739614009857
test loss item: 0.24789707362651825
test loss item: 0.6385256052017212
test loss item: 0.06048702448606491
test loss item: 0.11713629961013794
test loss item: 0.40150535106658936
test loss item: 0.31044816970825195
test loss item: 0.33728018403053284
test loss item: 0.6124383807182312
test loss item: 1.10469388961792
test loss item: 0.33220675587654114
test loss item: 0.21787136793136597
test loss item: 0.23910069465637207
test loss item: 0.1541016697883606
test loss item: 0.24886873364448547
test loss item: 0.17140944302082062
test loss item: 0.4047751724720001
test loss item: 0.303002268075943
test loss item: 0.2335931658744812
test loss item: 0.18204455077648163
test loss item: 0.3630904257297516
test loss item: 0.5148693919181824
test loss item: 0.22884449362754822
test loss item: 0.10451339185237885
test loss item: 0.18344241380691528
test loss item: 0.1296095997095108
test loss item: 0.22657139599323273
test loss item: 0.642345666885376
test loss item: 0.4396306872367859
test loss item: 0.2010185867547989
test loss item: 0.18388868868350983
test loss item: 0.15183939039707184
test loss item: 0.32311201095581055
test loss item: 0.20338568091392517
test loss item: 0.17105349898338318
test loss item: 0.17343328893184662
test loss item: 0.6741764545440674
test loss item: 0.2399243712425232
test loss item: 0.2405499368906021
test loss item: 0.19114655256271362
test loss item: 0.38983118534088135
test loss item: 0.3331086039543152
test loss item: 0.06372235715389252
test loss item: 0.808989942073822
test loss item: 0.25822991132736206
test loss item: 0.3194185793399811
test loss item: 0.11315758526325226
test loss item: 0.1509571522474289
test loss item: 0.1402348428964615
test loss item: 1.1686077117919922
test loss item: 0.3411215841770172
test loss item: 0.13897323608398438
test loss item: 0.06719864159822464
test loss item: 0.7745081186294556
test loss item: 0.6838756203651428
test loss item: 0.8071975708007812
test loss item: 0.19093695282936096
test loss item: 0.15703272819519043
test loss item: 0.05844882130622864
test loss item: 0.054510489106178284
test loss item: 0.14107386767864227
Epoch [46/50], Training Loss: 0.3117, Testing Loss: 0.3073
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 47/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.26596254110336304
1
train loss item: 0.623318612575531
2
train loss item: 0.11659690737724304
3
train loss item: 0.2702941298484802
4
train loss item: 0.2130649983882904
5
train loss item: 0.16555047035217285
6
train loss item: 0.1275652050971985
7
train loss item: 0.45919686555862427
8
train loss item: 0.0788513571023941
9
train loss item: 0.13485018908977509
10
train loss item: 0.16338904201984406
11
train loss item: 0.16801385581493378
12
train loss item: 0.09752526134252548
13
train loss item: 0.277618408203125
14
train loss item: 0.13894031941890717
15
train loss item: 0.3948877155780792
16
train loss item: 0.055478207767009735
17
train loss item: 0.13200560212135315
18
train loss item: 0.1675758957862854
19
train loss item: 0.15218167006969452
20
train loss item: 0.13344328105449677
21
train loss item: 0.08897152543067932
22
train loss item: 0.43666568398475647
23
train loss item: 0.4531168043613434
24
train loss item: 0.2906579077243805
25
train loss item: 0.12745581567287445
26
train loss item: 0.11511397361755371
27
train loss item: 0.13242323696613312
28
train loss item: 0.05311702564358711
29
train loss item: 0.3897864818572998
30
train loss item: 1.5269218683242798
31
train loss item: 0.26957106590270996
32
train loss item: 0.07750655710697174
33
train loss item: 0.24128790199756622
34
train loss item: 0.1134646013379097
35
train loss item: 1.883660078048706
36
train loss item: 0.26415008306503296
37
train loss item: 0.2511274218559265
38
train loss item: 0.22834061086177826
39
train loss item: 0.14309968054294586
40
train loss item: 0.10726620256900787
41
train loss item: 0.13522684574127197
42
train loss item: 0.21298229694366455
43
train loss item: 0.10857425630092621
44
train loss item: 0.45622870326042175
45
train loss item: 0.10222333669662476
46
train loss item: 0.08449140936136246
47
train loss item: 0.21581779420375824
48
train loss item: 0.12557914853096008
49
train loss item: 0.09658373892307281
50
train loss item: 0.16664695739746094
51
train loss item: 0.4822741746902466
52
train loss item: 0.060603924095630646
53
train loss item: 0.09946877509355545
54
train loss item: 1.766045331954956
55
train loss item: 0.12171212583780289
56
train loss item: 0.13514062762260437
57
train loss item: 0.1602625697851181
58
train loss item: 0.09595038741827011
59
train loss item: 0.09983548521995544
60
train loss item: 0.4217948913574219
61
train loss item: 1.6125202178955078
62
train loss item: 0.11979565769433975
63
train loss item: 0.2186577469110489
64
train loss item: 0.10959344357252121
65
train loss item: 0.23368105292320251
66
train loss item: 0.20684300363063812
67
train loss item: 0.12594152987003326
68
train loss item: 0.17847415804862976
69
train loss item: 0.1724480390548706
70
train loss item: 0.15696771442890167
71
train loss item: 0.09295695275068283
72
train loss item: 0.10224094241857529
73
train loss item: 0.17352139949798584
74
train loss item: 0.06781559437513351
75
train loss item: 0.0875970721244812
76
train loss item: 0.44125115871429443
77
train loss item: 0.9336727857589722
78
train loss item: 0.05792290344834328
79
train loss item: 0.16751456260681152
80
train loss item: 0.0874980017542839
81
train loss item: 0.12761878967285156
82
train loss item: 0.12444733083248138
83
train loss item: 0.3267720937728882
84
train loss item: 0.21766485273838043
85
train loss item: 0.2973974645137787
86
train loss item: 3.546293020248413
87
train loss item: 0.11162108182907104
88
train loss item: 0.18307580053806305
epoch train loss: 0.3029130585910229
testing phase
test loss item: 0.14117109775543213
test loss item: 0.08567888289690018
test loss item: 0.4582974910736084
test loss item: 0.16890786588191986
test loss item: 0.18884116411209106
test loss item: 0.09858101606369019
test loss item: 1.3588145971298218
test loss item: 0.4466123878955841
test loss item: 0.17277845740318298
test loss item: 0.2851623296737671
test loss item: 0.6637246012687683
test loss item: 0.12756246328353882
test loss item: 0.12961474061012268
test loss item: 0.2086292803287506
test loss item: 0.13178052008152008
test loss item: 0.06822910159826279
test loss item: 0.19464029371738434
test loss item: 0.32103675603866577
test loss item: 0.46885430812835693
test loss item: 0.19022499024868011
test loss item: 0.5177103281021118
test loss item: 0.2891598343849182
test loss item: 0.3075062334537506
test loss item: 0.1307017207145691
test loss item: 0.14520716667175293
test loss item: 0.16301566362380981
test loss item: 0.22414670884609222
test loss item: 0.13485237956047058
test loss item: 0.2342311590909958
test loss item: 0.24050551652908325
test loss item: 0.6311275362968445
test loss item: 0.05952993407845497
test loss item: 0.1103171706199646
test loss item: 0.39899924397468567
test loss item: 0.309228777885437
test loss item: 0.32546862959861755
test loss item: 0.5822626948356628
test loss item: 1.1399340629577637
test loss item: 0.3289673626422882
test loss item: 0.20800630748271942
test loss item: 0.22876501083374023
test loss item: 0.20165929198265076
test loss item: 0.2440049648284912
test loss item: 0.16165432333946228
test loss item: 0.39914682507514954
test loss item: 0.2759329080581665
test loss item: 0.2888875901699066
test loss item: 0.17091666162014008
test loss item: 0.35592347383499146
test loss item: 0.5086239576339722
test loss item: 0.2236924022436142
test loss item: 0.10094533860683441
test loss item: 0.17765119671821594
test loss item: 0.12455905973911285
test loss item: 0.22264763712882996
test loss item: 0.6535017490386963
test loss item: 0.42479828000068665
test loss item: 0.19143080711364746
test loss item: 0.17314234375953674
test loss item: 0.14939376711845398
test loss item: 0.31728795170783997
test loss item: 0.1817629486322403
test loss item: 0.15658776462078094
test loss item: 0.1669892817735672
test loss item: 0.670839786529541
test loss item: 0.23456968367099762
test loss item: 0.22080551087856293
test loss item: 0.18377584218978882
test loss item: 0.3953213691711426
test loss item: 0.31079524755477905
test loss item: 0.061450663954019547
test loss item: 0.7561794519424438
test loss item: 0.24924017488956451
test loss item: 0.29587724804878235
test loss item: 0.10620078444480896
test loss item: 0.2152351438999176
test loss item: 0.13268183171749115
test loss item: 1.2129747867584229
test loss item: 0.33739200234413147
test loss item: 0.13578695058822632
test loss item: 0.06365390121936798
test loss item: 0.764228105545044
test loss item: 0.6573858261108398
test loss item: 0.8291643261909485
test loss item: 0.17995451390743256
test loss item: 0.14975108206272125
test loss item: 0.05610547214746475
test loss item: 0.053837236016988754
test loss item: 0.13405092060565948
Epoch [47/50], Training Loss: 0.3029, Testing Loss: 0.3022
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 48/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.26255637407302856
1
train loss item: 0.5860418081283569
2
train loss item: 0.11267504841089249
3
train loss item: 0.24672332406044006
4
train loss item: 0.21131671965122223
5
train loss item: 0.16553954780101776
6
train loss item: 0.12315820157527924
7
train loss item: 0.4453328251838684
8
train loss item: 0.07874270528554916
9
train loss item: 0.12951970100402832
10
train loss item: 0.16430282592773438
11
train loss item: 0.17099617421627045
12
train loss item: 0.09699190407991409
13
train loss item: 0.27892324328422546
14
train loss item: 0.1358567178249359
15
train loss item: 0.3283962905406952
16
train loss item: 0.05456426739692688
17
train loss item: 0.13501772284507751
18
train loss item: 0.1628427803516388
19
train loss item: 0.13829956948757172
20
train loss item: 0.12881289422512054
21
train loss item: 0.08963440358638763
22
train loss item: 0.3744063675403595
23
train loss item: 0.4402915835380554
24
train loss item: 0.26854512095451355
25
train loss item: 0.12587092816829681
26
train loss item: 0.11392810195684433
27
train loss item: 0.13050411641597748
28
train loss item: 0.05237359553575516
29
train loss item: 0.3185473382472992
30
train loss item: 1.5015848875045776
31
train loss item: 0.26741698384284973
32
train loss item: 0.07778073847293854
33
train loss item: 0.2297583520412445
34
train loss item: 0.1176796555519104
35
train loss item: 1.871193289756775
36
train loss item: 0.2721557021141052
37
train loss item: 0.2665393650531769
38
train loss item: 0.21823087334632874
39
train loss item: 0.14075981080532074
40
train loss item: 0.10524314641952515
41
train loss item: 0.13175155222415924
42
train loss item: 0.20973272621631622
43
train loss item: 0.10645483434200287
44
train loss item: 0.4506939649581909
45
train loss item: 0.10080432146787643
46
train loss item: 0.08562695980072021
47
train loss item: 0.20161166787147522
48
train loss item: 0.12204792350530624
49
train loss item: 0.09562511742115021
50
train loss item: 0.14958418905735016
51
train loss item: 0.456142395734787
52
train loss item: 0.05945912376046181
53
train loss item: 0.09710194915533066
54
train loss item: 1.7518784999847412
55
train loss item: 0.1165534183382988
56
train loss item: 0.1334485411643982
57
train loss item: 0.15344898402690887
58
train loss item: 0.09411638975143433
59
train loss item: 0.10026031732559204
60
train loss item: 0.3733889162540436
61
train loss item: 1.593766450881958
62
train loss item: 0.11961236596107483
63
train loss item: 0.20661945641040802
64
train loss item: 0.10836231708526611
65
train loss item: 0.22683867812156677
66
train loss item: 0.21469904482364655
67
train loss item: 0.12437450885772705
68
train loss item: 0.15672381222248077
69
train loss item: 0.17020757496356964
70
train loss item: 0.15084801614284515
71
train loss item: 0.09132802486419678
72
train loss item: 0.09971168637275696
73
train loss item: 0.1608784943819046
74
train loss item: 0.06747155636548996
75
train loss item: 0.08650148659944534
76
train loss item: 0.4264192581176758
77
train loss item: 0.8907419443130493
78
train loss item: 0.05671035498380661
79
train loss item: 0.16426879167556763
80
train loss item: 0.08604046702384949
81
train loss item: 0.12022367864847183
82
train loss item: 0.12203939259052277
83
train loss item: 0.31343552470207214
84
train loss item: 0.23032787442207336
85
train loss item: 0.2719171345233917
86
train loss item: 3.530181407928467
87
train loss item: 0.10787233710289001
88
train loss item: 0.17961643636226654
epoch train loss: 0.2944553356743261
testing phase
test loss item: 0.14045533537864685
test loss item: 0.07969167083501816
test loss item: 0.3421028256416321
test loss item: 0.16169829666614532
test loss item: 0.16126997768878937
test loss item: 0.09039319306612015
test loss item: 1.1182993650436401
test loss item: 0.40795376896858215
test loss item: 0.13597728312015533
test loss item: 0.22535176575183868
test loss item: 0.5250861048698425
test loss item: 0.11922070384025574
test loss item: 0.12751826643943787
test loss item: 0.22305306792259216
test loss item: 0.11199362576007843
test loss item: 0.06745883077383041
test loss item: 0.18932877480983734
test loss item: 0.2416810691356659
test loss item: 0.43598291277885437
test loss item: 0.1971164345741272
test loss item: 0.3780534863471985
test loss item: 0.269228994846344
test loss item: 0.2605116665363312
test loss item: 0.12377780675888062
test loss item: 0.12665881216526031
test loss item: 0.15438121557235718
test loss item: 0.20606352388858795
test loss item: 0.11899854242801666
test loss item: 0.20396074652671814
test loss item: 0.2031489461660385
test loss item: 0.49754852056503296
test loss item: 0.0582113154232502
test loss item: 0.10650179535150528
test loss item: 0.3117138147354126
test loss item: 0.22590024769306183
test loss item: 0.29689621925354004
test loss item: 0.513114869594574
test loss item: 0.8766190409660339
test loss item: 0.2545728385448456
test loss item: 0.1862669140100479
test loss item: 0.2107774317264557
test loss item: 0.1797265261411667
test loss item: 0.17593398690223694
test loss item: 0.1472361981868744
test loss item: 0.29753556847572327
test loss item: 0.2755386233329773
test loss item: 0.24224810302257538
test loss item: 0.20350104570388794
test loss item: 0.28720536828041077
test loss item: 0.412991464138031
test loss item: 0.16047163307666779
test loss item: 0.10708795487880707
test loss item: 0.15284067392349243
test loss item: 0.11428344249725342
test loss item: 0.16780680418014526
test loss item: 0.4896180331707001
test loss item: 0.3819822669029236
test loss item: 0.16346625983715057
test loss item: 0.15919587016105652
test loss item: 0.1280657947063446
test loss item: 0.2277400940656662
test loss item: 0.18189264833927155
test loss item: 0.1537908911705017
test loss item: 0.15853703022003174
test loss item: 0.5254368782043457
test loss item: 0.22399166226387024
test loss item: 0.2102135419845581
test loss item: 0.17178381979465485
test loss item: 0.3352019190788269
test loss item: 0.29049158096313477
test loss item: 0.06015278026461601
test loss item: 0.6501917839050293
test loss item: 0.24161800742149353
test loss item: 0.27129051089286804
test loss item: 0.11072718352079391
test loss item: 0.1891053020954132
test loss item: 0.12468180805444717
test loss item: 0.9398764371871948
test loss item: 0.3139966130256653
test loss item: 0.12844450771808624
test loss item: 0.05897267162799835
test loss item: 0.6188031435012817
test loss item: 0.545121967792511
test loss item: 0.6309746503829956
test loss item: 0.16815467178821564
test loss item: 0.14850664138793945
test loss item: 0.054068438708782196
test loss item: 0.05264686420559883
test loss item: 0.12322574108839035
Epoch [48/50], Training Loss: 0.2945, Testing Loss: 0.2566
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 49/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2614434063434601
1
train loss item: 0.5748866200447083
2
train loss item: 0.1307828575372696
3
train loss item: 0.26969262957572937
4
train loss item: 0.2268410474061966
5
train loss item: 0.1700146347284317
6
train loss item: 0.1397911161184311
7
train loss item: 0.4137483537197113
8
train loss item: 0.0766064003109932
9
train loss item: 0.14508967101573944
10
train loss item: 0.17443639039993286
11
train loss item: 0.17684195935726166
12
train loss item: 0.10017324984073639
13
train loss item: 0.2761983275413513
14
train loss item: 0.12974587082862854
15
train loss item: 0.34948331117630005
16
train loss item: 0.05556061118841171
17
train loss item: 0.14307594299316406
18
train loss item: 0.1811458170413971
19
train loss item: 0.14872516691684723
20
train loss item: 0.14519259333610535
21
train loss item: 0.10621421039104462
22
train loss item: 0.38032060861587524
23
train loss item: 0.41178593039512634
24
train loss item: 0.3036016523838043
25
train loss item: 0.13057652115821838
26
train loss item: 0.11701589077711105
27
train loss item: 0.12569265067577362
28
train loss item: 0.05327896028757095
29
train loss item: 0.3060014545917511
30
train loss item: 1.44779634475708
31
train loss item: 0.30828163027763367
32
train loss item: 0.08468934148550034
33
train loss item: 0.18574853241443634
34
train loss item: 0.11453147232532501
35
train loss item: 1.8524196147918701
36
train loss item: 0.309276819229126
37
train loss item: 0.2902369499206543
38
train loss item: 0.29432496428489685
39
train loss item: 0.1536041647195816
40
train loss item: 0.1167166456580162
41
train loss item: 0.12616673111915588
42
train loss item: 0.20976662635803223
43
train loss item: 0.11082107573747635
44
train loss item: 0.42337387800216675
45
train loss item: 0.09391016513109207
46
train loss item: 0.09653943032026291
47
train loss item: 0.20823581516742706
48
train loss item: 0.11872967332601547
49
train loss item: 0.10053762793540955
50
train loss item: 0.1590600609779358
51
train loss item: 0.42685651779174805
52
train loss item: 0.06041775271296501
53
train loss item: 0.10092093050479889
54
train loss item: 1.7298095226287842
55
train loss item: 0.12114261835813522
56
train loss item: 0.14512109756469727
57
train loss item: 0.16523753106594086
58
train loss item: 0.11085696518421173
59
train loss item: 0.09958281368017197
60
train loss item: 0.3414343595504761
61
train loss item: 1.5530844926834106
62
train loss item: 0.12475647777318954
63
train loss item: 0.21845322847366333
64
train loss item: 0.10789045691490173
65
train loss item: 0.27613943815231323
66
train loss item: 0.2581610381603241
67
train loss item: 0.1350274235010147
68
train loss item: 0.15908312797546387
69
train loss item: 0.19701141119003296
70
train loss item: 0.1576315313577652
71
train loss item: 0.09768129140138626
72
train loss item: 0.09514768421649933
73
train loss item: 0.16321398317813873
74
train loss item: 0.07248678058385849
75
train loss item: 0.08506394177675247
76
train loss item: 0.4107306897640228
77
train loss item: 0.8503351807594299
78
train loss item: 0.05990554019808769
79
train loss item: 0.17386694252490997
80
train loss item: 0.09225619584321976
81
train loss item: 0.12423044443130493
82
train loss item: 0.10628725588321686
83
train loss item: 0.33355870842933655
84
train loss item: 0.27276861667633057
85
train loss item: 0.24634653329849243
86
train loss item: 3.502448797225952
87
train loss item: 0.09801317751407623
88
train loss item: 0.21959742903709412
epoch train loss: 0.2979920151528348
testing phase
test loss item: 0.1401263177394867
test loss item: 0.08237617462873459
test loss item: 0.43991005420684814
test loss item: 0.16484713554382324
test loss item: 0.18106989562511444
test loss item: 0.0931098684668541
test loss item: 1.207863450050354
test loss item: 0.42687034606933594
test loss item: 0.16382759809494019
test loss item: 0.27054134011268616
test loss item: 0.6274271607398987
test loss item: 0.1230987012386322
test loss item: 0.13186608254909515
test loss item: 0.21135933697223663
test loss item: 0.12664704024791718
test loss item: 0.06635387986898422
test loss item: 0.19618412852287292
test loss item: 0.3030669689178467
test loss item: 0.44677576422691345
test loss item: 0.19586125016212463
test loss item: 0.49240642786026
test loss item: 0.28145599365234375
test loss item: 0.283442884683609
test loss item: 0.12787781655788422
test loss item: 0.13971500098705292
test loss item: 0.1597282588481903
test loss item: 0.21862776577472687
test loss item: 0.12769390642642975
test loss item: 0.223779559135437
test loss item: 0.2283284068107605
test loss item: 0.5805611610412598
test loss item: 0.0587320514023304
test loss item: 0.10960221290588379
test loss item: 0.37898197770118713
test loss item: 0.2928200364112854
test loss item: 0.3087063431739807
test loss item: 0.5455390214920044
test loss item: 1.078029751777649
test loss item: 0.3090057373046875
test loss item: 0.19466020166873932
test loss item: 0.21725685894489288
test loss item: 0.18572668731212616
test loss item: 0.22666333615779877
test loss item: 0.15495449304580688
test loss item: 0.37738674879074097
test loss item: 0.28407755494117737
test loss item: 0.26270195841789246
test loss item: 0.18127217888832092
test loss item: 0.34580734372138977
test loss item: 0.4792596399784088
test loss item: 0.2097252905368805
test loss item: 0.0982394888997078
test loss item: 0.17074306309223175
test loss item: 0.11989077180624008
test loss item: 0.21023499965667725
test loss item: 0.6197115182876587
test loss item: 0.4078438878059387
test loss item: 0.183354452252388
test loss item: 0.17143578827381134
test loss item: 0.14500774443149567
test loss item: 0.2936303913593292
test loss item: 0.18874606490135193
test loss item: 0.15772917866706848
test loss item: 0.1629195660352707
test loss item: 0.6423487067222595
test loss item: 0.2279292494058609
test loss item: 0.22462095320224762
test loss item: 0.17546513676643372
test loss item: 0.3829655945301056
test loss item: 0.29664483666419983
test loss item: 0.06026535481214523
test loss item: 0.6919505596160889
test loss item: 0.2505207657814026
test loss item: 0.28493455052375793
test loss item: 0.10966301709413528
test loss item: 0.19660867750644684
test loss item: 0.12801335752010345
test loss item: 1.1565536260604858
test loss item: 0.3320825397968292
test loss item: 0.1312188357114792
test loss item: 0.06067706272006035
test loss item: 0.7126478552818298
test loss item: 0.6049109101295471
test loss item: 0.7854951620101929
test loss item: 0.17642749845981598
test loss item: 0.15066947042942047
test loss item: 0.05471862480044365
test loss item: 0.05319202318787575
test loss item: 0.12781110405921936
Epoch [49/50], Training Loss: 0.2980, Testing Loss: 0.2878
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 50/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2543582022190094
1
train loss item: 0.5545908212661743
2
train loss item: 0.10955299437046051
3
train loss item: 0.22640825808048248
4
train loss item: 0.19780661165714264
5
train loss item: 0.15869347751140594
6
train loss item: 0.12217338383197784
7
train loss item: 0.4268150329589844
8
train loss item: 0.07240710407495499
9
train loss item: 0.12513557076454163
10
train loss item: 0.15213543176651
11
train loss item: 0.16262520849704742
12
train loss item: 0.09578388929367065
13
train loss item: 0.2633261978626251
14
train loss item: 0.13158337771892548
15
train loss item: 0.30944252014160156
16
train loss item: 0.055180300027132034
17
train loss item: 0.12867695093154907
18
train loss item: 0.15859511494636536
19
train loss item: 0.13585174083709717
20
train loss item: 0.12653511762619019
21
train loss item: 0.08803465217351913
22
train loss item: 0.3479292690753937
23
train loss item: 0.4103226959705353
24
train loss item: 0.264344722032547
25
train loss item: 0.11999974399805069
26
train loss item: 0.10744741559028625
27
train loss item: 0.12436701357364655
28
train loss item: 0.05248703435063362
29
train loss item: 0.2820228636264801
30
train loss item: 1.4573827981948853
31
train loss item: 0.2521277368068695
32
train loss item: 0.07217410206794739
33
train loss item: 0.19798798859119415
34
train loss item: 0.10811935365200043
35
train loss item: 1.8502997159957886
36
train loss item: 0.2704867124557495
37
train loss item: 0.2629169225692749
38
train loss item: 0.20281100273132324
39
train loss item: 0.1364811360836029
40
train loss item: 0.10400406271219254
41
train loss item: 0.1243463084101677
42
train loss item: 0.2049705982208252
43
train loss item: 0.10042645037174225
44
train loss item: 0.43739306926727295
45
train loss item: 0.09603322297334671
46
train loss item: 0.08078629523515701
47
train loss item: 0.19648396968841553
48
train loss item: 0.11773742735385895
49
train loss item: 0.08982988446950912
50
train loss item: 0.1488250195980072
51
train loss item: 0.4249971807003021
52
train loss item: 0.0590892992913723
53
train loss item: 0.09117685258388519
54
train loss item: 1.7291574478149414
55
train loss item: 0.1149396225810051
56
train loss item: 0.12844356894493103
57
train loss item: 0.15036393702030182
58
train loss item: 0.09196402877569199
59
train loss item: 0.09631302207708359
60
train loss item: 0.33661434054374695
61
train loss item: 1.5573832988739014
62
train loss item: 0.11574150621891022
63
train loss item: 0.2013198882341385
64
train loss item: 0.0989859402179718
65
train loss item: 0.22643108665943146
66
train loss item: 0.20665216445922852
67
train loss item: 0.11997886747121811
68
train loss item: 0.15495005249977112
69
train loss item: 0.16760952770709991
70
train loss item: 0.14669586718082428
71
train loss item: 0.09441088885068893
72
train loss item: 0.0909019336104393
73
train loss item: 0.15560169517993927
74
train loss item: 0.06672410666942596
75
train loss item: 0.08330193161964417
76
train loss item: 0.40088149905204773
77
train loss item: 0.8530911803245544
78
train loss item: 0.057686448097229004
79
train loss item: 0.1580193191766739
80
train loss item: 0.0808577761054039
81
train loss item: 0.11639012396335602
82
train loss item: 0.11216536164283752
83
train loss item: 0.3111688494682312
84
train loss item: 0.2277008295059204
85
train loss item: 0.24363228678703308
86
train loss item: 3.497851610183716
87
train loss item: 0.10263408720493317
88
train loss item: 0.18008112907409668
epoch train loss: 0.284586124164
testing phase
test loss item: 0.14418043196201324
test loss item: 0.0832495242357254
test loss item: 0.4996222257614136
test loss item: 0.17048107087612152
test loss item: 0.19293420016765594
test loss item: 0.09750840812921524
test loss item: 1.4313709735870361
test loss item: 0.4973304867744446
test loss item: 0.1848689168691635
test loss item: 0.3018015921115875
test loss item: 0.709632933139801
test loss item: 0.12579840421676636
test loss item: 0.13787952065467834
test loss item: 0.2185819149017334
test loss item: 0.13518959283828735
test loss item: 0.06388838589191437
test loss item: 0.21100012958049774
test loss item: 0.3385659456253052
test loss item: 0.49904516339302063
test loss item: 0.207428976893425
test loss item: 0.5547248125076294
test loss item: 0.3078896403312683
test loss item: 0.29116612672805786
test loss item: 0.13635778427124023
test loss item: 0.1504412591457367
test loss item: 0.1693916767835617
test loss item: 0.23650728166103363
test loss item: 0.1345519870519638
test loss item: 0.24096882343292236
test loss item: 0.2506769001483917
test loss item: 0.6774555444717407
test loss item: 0.05743050575256348
test loss item: 0.11471690237522125
test loss item: 0.41889309883117676
test loss item: 0.3316023647785187
test loss item: 0.33756935596466064
test loss item: 0.6189147233963013
test loss item: 1.2234046459197998
test loss item: 0.3471178412437439
test loss item: 0.21296967566013336
test loss item: 0.2355564832687378
test loss item: 0.18264321982860565
test loss item: 0.25610432028770447
test loss item: 0.1680409163236618
test loss item: 0.425159215927124
test loss item: 0.3043653964996338
test loss item: 0.2669721245765686
test loss item: 0.1840992569923401
test loss item: 0.3853813111782074
test loss item: 0.5440201163291931
test loss item: 0.2394149750471115
test loss item: 0.10204225778579712
test loss item: 0.186364084482193
test loss item: 0.1235976442694664
test loss item: 0.2352684587240219
test loss item: 0.7060220837593079
test loss item: 0.4510469138622284
test loss item: 0.208262100815773
test loss item: 0.18433143198490143
test loss item: 0.1536969095468521
test loss item: 0.3304300010204315
test loss item: 0.2049921452999115
test loss item: 0.16811075806617737
test loss item: 0.17099694907665253
test loss item: 0.7368893027305603
test loss item: 0.23447564244270325
test loss item: 0.242780402302742
test loss item: 0.18706442415714264
test loss item: 0.41177210211753845
test loss item: 0.3374158442020416
test loss item: 0.05896207317709923
test loss item: 0.8105743527412415
test loss item: 0.26336804032325745
test loss item: 0.3148077130317688
test loss item: 0.11452954262495041
test loss item: 0.19048301875591278
test loss item: 0.13672581315040588
test loss item: 1.3112759590148926
test loss item: 0.3565398156642914
test loss item: 0.13730663061141968
test loss item: 0.06421488523483276
test loss item: 0.8228890895843506
test loss item: 0.6985432505607605
test loss item: 0.8995584845542908
test loss item: 0.187826007604599
test loss item: 0.15923835337162018
test loss item: 0.058328717947006226
test loss item: 0.054840900003910065
test loss item: 0.1452021300792694
Epoch [50/50], Training Loss: 0.2846, Testing Loss: 0.3193
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
loss item: 0.2688280940055847
loss item: 0.15471407771110535
loss item: 1.3770283460617065
loss item: 0.7612437009811401
loss item: 0.4942827820777893
loss item: 0.3067950904369354
loss item: 0.15590514242649078
loss item: 0.6471807360649109
loss item: 0.16758449375629425
loss item: 0.15500761568546295
loss item: 0.7829314470291138
loss item: 0.04382917284965515
loss item: 0.7201074957847595
loss item: 0.16371522843837738
loss item: 0.34310218691825867
loss item: 0.30338436365127563
loss item: 0.2772294878959656
loss item: 0.5533707141876221
loss item: 0.7224205136299133
loss item: 0.36585983633995056
loss item: 0.2952272593975067
loss item: 0.18384037911891937
loss item: 0.22471363842487335
loss item: 0.20127303898334503
loss item: 0.20765511691570282
loss item: 0.5502290725708008
loss item: 0.9162370562553406
loss item: 0.11471942067146301
loss item: 0.10293654352426529
loss item: 0.34634268283843994
loss item: 0.8436700701713562
loss item: 1.2568202018737793
loss item: 0.13851110637187958
loss item: 0.4382672607898712
loss item: 0.13319708406925201
loss item: 0.1845364272594452
loss item: 0.32234013080596924
loss item: 0.17728528380393982
loss item: 0.34341299533843994
loss item: 0.5856831669807434
loss item: 0.8288362622261047
loss item: 0.29170313477516174
loss item: 0.14921653270721436
loss item: 0.051416266709566116
Val Loss: 0.4012
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 50 0.0005 2 360 done at Wed Nov 13 17:55:33 CET 2024
UNet6 with 1 50 0.001 2 360 start at Wed Nov 13 17:55:33 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 50, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 11785081.0
test loss item: 18044648.0
test loss item: 7167461.0
test loss item: 29383746.0
test loss item: 15124092.0
test loss item: 11692700.0
test loss item: 39257308.0
test loss item: 21983670.0
test loss item: 10956118.0
test loss item: 11253177.0
test loss item: 30624698.0
test loss item: 29517882.0
test loss item: 14048648.0
test loss item: 1793891.75
test loss item: 16510353.0
test loss item: 18418314.0
test loss item: 6508121.5
test loss item: 13564400.0
test loss item: 23912850.0
test loss item: 6264794.0
test loss item: 5424060.0
test loss item: 27085740.0
test loss item: 20075276.0
test loss item: 17504854.0
test loss item: 11419959.0
test loss item: 10714604.0
test loss item: 12563931.0
test loss item: 15127241.0
test loss item: 17282536.0
test loss item: 14532781.0
test loss item: 23636338.0
test loss item: 19461510.0
test loss item: 17369196.0
test loss item: 28206086.0
test loss item: 15426254.0
test loss item: 75933592.0
test loss item: 24528266.0
test loss item: 42413388.0
test loss item: 26005210.0
test loss item: 15361826.0
test loss item: 14713672.0
test loss item: 21589830.0
test loss item: 4337666.0
test loss item: 27008148.0
test loss item: 5460098.0
test loss item: 13491585.0
test loss item: 19726744.0
test loss item: 7888513.5
test loss item: 7950283.0
test loss item: 21157566.0
test loss item: 12844620.0
test loss item: 13379003.0
test loss item: 9847971.0
test loss item: 40478308.0
test loss item: 9069851.0
test loss item: 18914676.0
test loss item: 51207676.0
test loss item: 790203.5
test loss item: 12065969.0
test loss item: 11776603.0
test loss item: 13123707.0
test loss item: 11832058.0
test loss item: 8010527.5
test loss item: 14818182.0
test loss item: 23189776.0
test loss item: 42727972.0
test loss item: 12784839.0
test loss item: 11372064.0
test loss item: 13868499.0
test loss item: 24966456.0
test loss item: 13975702.0
test loss item: 22125188.0
test loss item: 3733051.75
test loss item: 11549237.0
test loss item: 5526398.0
test loss item: 19573080.0
test loss item: 16077742.0
test loss item: 43605664.0
test loss item: 1412052.75
test loss item: 10582447.0
test loss item: 7402180.0
test loss item: 42150504.0
test loss item: 25959800.0
test loss item: 43047772.0
test loss item: 9130282.0
test loss item: 7604744.0
test loss item: 13163716.0
test loss item: 17791828.0
test loss item: 10392790.0
Epoch [1/50], Training Loss: 1.0161, Testing Loss: 18012155.5758
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.1627389192581177
1
train loss item: 2.1412336826324463
2
train loss item: 1.223680019378662
3
train loss item: 1.2127991914749146
4
train loss item: 3.0910515785217285
5
train loss item: 1.0142309665679932
6
train loss item: 1.4223579168319702
7
train loss item: 1.2893645763397217
8
train loss item: 1.440064787864685
9
train loss item: 0.8364047408103943
10
train loss item: 0.8886779546737671
11
train loss item: 0.7996166944503784
12
train loss item: 0.982550323009491
13
train loss item: 1.2329033613204956
14
train loss item: 0.9984112977981567
15
train loss item: 1.5051113367080688
16
train loss item: 1.2095601558685303
17
train loss item: 1.4161232709884644
18
train loss item: 1.012138843536377
19
train loss item: 0.9051920175552368
20
train loss item: 1.0893741846084595
21
train loss item: 1.0338590145111084
22
train loss item: 2.1671197414398193
23
train loss item: 1.3989713191986084
24
train loss item: 1.2572822570800781
25
train loss item: 1.0565353631973267
26
train loss item: 1.1701897382736206
27
train loss item: 0.8683547973632812
28
train loss item: 1.2076148986816406
29
train loss item: 1.7722322940826416
30
train loss item: 2.745358943939209
31
train loss item: 1.216265082359314
32
train loss item: 0.9440435171127319
33
train loss item: 1.1446332931518555
34
train loss item: 1.909136176109314
35
train loss item: 2.8699867725372314
36
train loss item: 1.219748854637146
37
train loss item: 0.8850826025009155
38
train loss item: 1.3808495998382568
39
train loss item: 0.911266565322876
40
train loss item: 1.1082417964935303
41
train loss item: 0.814866304397583
42
train loss item: 0.8350582718849182
43
train loss item: 0.9496601819992065
44
train loss item: 1.1882284879684448
45
train loss item: 1.1230639219284058
46
train loss item: 0.990526556968689
47
train loss item: 1.0901484489440918
48
train loss item: 0.9159326553344727
49
train loss item: 0.9682211875915527
50
train loss item: 0.9414951801300049
51
train loss item: 1.7621641159057617
52
train loss item: 1.1775217056274414
53
train loss item: 1.186757206916809
54
train loss item: 2.708171844482422
55
train loss item: 1.1227338314056396
56
train loss item: 0.8477191925048828
57
train loss item: 0.9238559007644653
58
train loss item: 0.9379908442497253
59
train loss item: 0.9621532559394836
60
train loss item: 1.9530788660049438
61
train loss item: 2.6338388919830322
62
train loss item: 0.9953965544700623
63
train loss item: 0.9847005605697632
64
train loss item: 0.9228894114494324
65
train loss item: 1.5504430532455444
66
train loss item: 0.9608433842658997
67
train loss item: 0.9519791007041931
68
train loss item: 1.1556516885757446
69
train loss item: 0.9736729264259338
70
train loss item: 1.0080184936523438
71
train loss item: 1.4687238931655884
72
train loss item: 1.419049620628357
73
train loss item: 0.9922592639923096
74
train loss item: 1.5344414710998535
75
train loss item: 0.9670674800872803
76
train loss item: 1.4292179346084595
77
train loss item: 2.2641994953155518
78
train loss item: 1.1958861351013184
79
train loss item: 0.8626599311828613
80
train loss item: 1.423616886138916
81
train loss item: 0.9546928405761719
82
train loss item: 0.9756700992584229
83
train loss item: 1.4691296815872192
84
train loss item: 1.007530927658081
85
train loss item: 1.1756672859191895
86
train loss item: 4.784779071807861
87
train loss item: 1.3828245401382446
88
train loss item: 0.9960072040557861
epoch train loss: 1.3143883622094485
testing phase
test loss item: 153.61972045898438
test loss item: 308.9806213378906
test loss item: 183.40676879882812
test loss item: 798.7156982421875
test loss item: 291.8871765136719
test loss item: 292.6216125488281
test loss item: 514.3078002929688
test loss item: 257.57354736328125
test loss item: 94.98118591308594
test loss item: 176.06163024902344
test loss item: 836.6275024414062
test loss item: 727.2073974609375
test loss item: 211.66830444335938
test loss item: 25.58147430419922
test loss item: 304.7413330078125
test loss item: 342.85205078125
test loss item: 102.54563903808594
test loss item: 221.5685577392578
test loss item: 326.33734130859375
test loss item: 61.57472610473633
test loss item: 197.2107391357422
test loss item: 768.4361572265625
test loss item: 412.4140319824219
test loss item: 277.70550537109375
test loss item: 242.00021362304688
test loss item: 215.24026489257812
test loss item: 124.50702667236328
test loss item: 281.31512451171875
test loss item: 278.3996887207031
test loss item: 232.18565368652344
test loss item: 913.3241577148438
test loss item: 322.2038879394531
test loss item: 285.8175354003906
test loss item: 885.0394287109375
test loss item: 284.91851806640625
test loss item: 3124.969482421875
test loss item: 242.1707000732422
test loss item: 1505.26123046875
test loss item: 653.8809204101562
test loss item: 278.1027526855469
test loss item: 238.0672149658203
test loss item: 470.8184814453125
test loss item: 106.63775634765625
test loss item: 764.1487426757812
test loss item: 171.2996368408203
test loss item: 221.57728576660156
test loss item: 394.1563720703125
test loss item: 76.13226318359375
test loss item: 136.9359588623047
test loss item: 377.9566345214844
test loss item: 169.89016723632812
test loss item: 250.63186645507812
test loss item: 187.15399169921875
test loss item: 1265.6878662109375
test loss item: 175.43740844726562
test loss item: 340.31024169921875
test loss item: 1724.4617919921875
test loss item: 28.963336944580078
test loss item: 216.02886962890625
test loss item: 187.63551330566406
test loss item: 270.0807800292969
test loss item: 193.7791748046875
test loss item: 189.17726135253906
test loss item: 176.4593963623047
test loss item: 385.3144226074219
test loss item: 1327.7686767578125
test loss item: 197.02804565429688
test loss item: 177.32077026367188
test loss item: 251.93359375
test loss item: 331.6430358886719
test loss item: 251.57339477539062
test loss item: 170.888916015625
test loss item: 142.28721618652344
test loss item: 162.67970275878906
test loss item: 112.36874389648438
test loss item: 391.0885314941406
test loss item: 294.4483337402344
test loss item: 1991.3853759765625
test loss item: 26.390583038330078
test loss item: 254.71168518066406
test loss item: 218.69187927246094
test loss item: 1090.5208740234375
test loss item: 376.3138427734375
test loss item: 1481.40771484375
test loss item: 188.2561492919922
test loss item: 189.47454833984375
test loss item: 268.1427001953125
test loss item: 354.2879943847656
test loss item: 306.29754638671875
Epoch [2/50], Training Loss: 1.3144, Testing Loss: 416.1080
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7964559197425842
1
train loss item: 1.9164539575576782
2
train loss item: 0.4914293587207794
3
train loss item: 1.0187532901763916
4
train loss item: 1.1584614515304565
5
train loss item: 0.6224740743637085
6
train loss item: 0.5111649632453918
7
train loss item: 1.1942405700683594
8
train loss item: 0.4833643138408661
9
train loss item: 0.4539845883846283
10
train loss item: 0.6110211610794067
11
train loss item: 0.4189457595348358
12
train loss item: 0.3864139914512634
13
train loss item: 0.9050256609916687
14
train loss item: 0.5808258056640625
15
train loss item: 1.0991885662078857
16
train loss item: 0.3893755078315735
17
train loss item: 0.5358197093009949
18
train loss item: 0.6277730464935303
19
train loss item: 0.45866891741752625
20
train loss item: 0.44056186079978943
21
train loss item: 0.5438469648361206
22
train loss item: 1.5875545740127563
23
train loss item: 1.311381220817566
24
train loss item: 0.8389303088188171
25
train loss item: 0.5680174231529236
26
train loss item: 0.5187239646911621
27
train loss item: 0.5514217615127563
28
train loss item: 0.3835359215736389
29
train loss item: 1.335516333580017
30
train loss item: 2.904987096786499
31
train loss item: 0.9224701523780823
32
train loss item: 0.4165094196796417
33
train loss item: 0.8323606848716736
34
train loss item: 0.6988712549209595
35
train loss item: 2.8987181186676025
36
train loss item: 0.8292403221130371
37
train loss item: 0.42480412125587463
38
train loss item: 0.9086219668388367
39
train loss item: 0.5671680569648743
40
train loss item: 0.4864215850830078
41
train loss item: 0.5113524794578552
42
train loss item: 0.4147615432739258
43
train loss item: 0.503864586353302
44
train loss item: 1.0541573762893677
45
train loss item: 0.5304104685783386
46
train loss item: 0.5269127488136292
47
train loss item: 0.6658385396003723
48
train loss item: 0.5114231705665588
49
train loss item: 0.5182555317878723
50
train loss item: 0.43358439207077026
51
train loss item: 1.421248435974121
52
train loss item: 0.36023661494255066
53
train loss item: 0.5486335158348083
54
train loss item: 2.7745676040649414
55
train loss item: 0.532230794429779
56
train loss item: 0.5186665058135986
57
train loss item: 0.4975365102291107
58
train loss item: 0.48291459679603577
59
train loss item: 0.41723525524139404
60
train loss item: 1.522156000137329
61
train loss item: 2.795410394668579
62
train loss item: 0.44293272495269775
63
train loss item: 0.5582072138786316
64
train loss item: 0.5048189163208008
65
train loss item: 0.9101715683937073
66
train loss item: 0.6417673826217651
67
train loss item: 0.5198288559913635
68
train loss item: 0.5356034636497498
69
train loss item: 0.5900068879127502
70
train loss item: 0.5546663999557495
71
train loss item: 0.5127355456352234
72
train loss item: 0.5172411799430847
73
train loss item: 0.5207083821296692
74
train loss item: 0.48122572898864746
75
train loss item: 0.42484378814697266
76
train loss item: 1.3188378810882568
77
train loss item: 1.7620891332626343
78
train loss item: 0.36643823981285095
79
train loss item: 0.43722376227378845
80
train loss item: 0.5526209473609924
81
train loss item: 0.4490346312522888
82
train loss item: 0.5769686698913574
83
train loss item: 1.099683165550232
84
train loss item: 0.6078097820281982
85
train loss item: 0.9380335807800293
86
train loss item: 4.948439598083496
87
train loss item: 0.6036426424980164
88
train loss item: 0.5661624073982239
epoch train loss: 0.8327263288953332
testing phase
test loss item: 77.21778869628906
test loss item: 208.50421142578125
test loss item: 47.77352523803711
test loss item: 235.51731872558594
test loss item: 182.11798095703125
test loss item: 213.9215087890625
test loss item: 222.02711486816406
test loss item: 87.25261688232422
test loss item: 53.35943603515625
test loss item: 61.02340316772461
test loss item: 312.4098815917969
test loss item: 231.70742797851562
test loss item: 89.54730987548828
test loss item: 4.42367696762085
test loss item: 173.25010681152344
test loss item: 289.1364440917969
test loss item: 45.13939666748047
test loss item: 83.5167465209961
test loss item: 124.77787780761719
test loss item: 23.98427391052246
test loss item: 90.908203125
test loss item: 213.01943969726562
test loss item: 164.45269775390625
test loss item: 136.5330352783203
test loss item: 131.49227905273438
test loss item: 122.50988006591797
test loss item: 65.53367614746094
test loss item: 177.1501007080078
test loss item: 141.29454040527344
test loss item: 85.57294464111328
test loss item: 302.2391052246094
test loss item: 288.3783874511719
test loss item: 144.04776000976562
test loss item: 232.099853515625
test loss item: 176.452880859375
test loss item: 552.8222045898438
test loss item: 93.98589324951172
test loss item: 543.9161376953125
test loss item: 188.75015258789062
test loss item: 176.24600219726562
test loss item: 174.4817657470703
test loss item: 186.83718872070312
test loss item: 37.295745849609375
test loss item: 218.11570739746094
test loss item: 87.13880157470703
test loss item: 186.56300354003906
test loss item: 163.24313354492188
test loss item: 20.16522216796875
test loss item: 52.15702819824219
test loss item: 191.0410919189453
test loss item: 64.01798248291016
test loss item: 125.90208435058594
test loss item: 101.59657287597656
test loss item: 335.1656494140625
test loss item: 116.14768981933594
test loss item: 158.6660614013672
test loss item: 348.9639892578125
test loss item: 4.291358470916748
test loss item: 118.71106719970703
test loss item: 107.36035919189453
test loss item: 128.52496337890625
test loss item: 160.34283447265625
test loss item: 112.52493286132812
test loss item: 90.60031127929688
test loss item: 191.66241455078125
test loss item: 349.4522399902344
test loss item: 98.8329086303711
test loss item: 80.69192504882812
test loss item: 176.08963012695312
test loss item: 106.93560791015625
test loss item: 195.76907348632812
test loss item: 111.3395767211914
test loss item: 77.1908187866211
test loss item: 70.4561538696289
test loss item: 49.17377853393555
test loss item: 157.60121154785156
test loss item: 162.60433959960938
test loss item: 669.2105712890625
test loss item: 5.962140083312988
test loss item: 175.30136108398438
test loss item: 134.16542053222656
test loss item: 379.6590270996094
test loss item: 149.61219787597656
test loss item: 484.9559020996094
test loss item: 121.81741333007812
test loss item: 83.13935852050781
test loss item: 196.48019409179688
test loss item: 288.3746032714844
test loss item: 162.40072631835938
Epoch [3/50], Training Loss: 0.8327, Testing Loss: 165.8736
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.709123432636261
1
train loss item: 1.9657634496688843
2
train loss item: 0.5000889301300049
3
train loss item: 1.1529614925384521
4
train loss item: 1.2365509271621704
5
train loss item: 0.5506782531738281
6
train loss item: 0.5767817497253418
7
train loss item: 1.3263064622879028
8
train loss item: 0.6659162640571594
9
train loss item: 0.5278607606887817
10
train loss item: 0.6996232271194458
11
train loss item: 0.4170275032520294
12
train loss item: 0.432915598154068
13
train loss item: 0.8480802178382874
14
train loss item: 0.5367109179496765
15
train loss item: 0.9507414698600769
16
train loss item: 0.4766979515552521
17
train loss item: 0.5460578799247742
18
train loss item: 0.5886713266372681
19
train loss item: 0.4649198055267334
20
train loss item: 0.4338360130786896
21
train loss item: 0.45839133858680725
22
train loss item: 1.4093250036239624
23
train loss item: 1.3946943283081055
24
train loss item: 0.8080911040306091
25
train loss item: 0.431612104177475
26
train loss item: 0.5226308107376099
27
train loss item: 0.5555213689804077
28
train loss item: 0.49275803565979004
29
train loss item: 1.1389988660812378
30
train loss item: 3.1841647624969482
31
train loss item: 0.9783722162246704
32
train loss item: 0.5465304255485535
33
train loss item: 0.9233489036560059
34
train loss item: 0.5387077927589417
35
train loss item: 3.0640652179718018
36
train loss item: 0.7554970383644104
37
train loss item: 0.4328623116016388
38
train loss item: 0.8644354343414307
39
train loss item: 0.568266749382019
40
train loss item: 0.3991055488586426
41
train loss item: 0.5550557374954224
42
train loss item: 0.4180082380771637
43
train loss item: 0.5413540005683899
44
train loss item: 1.1137067079544067
45
train loss item: 0.5068544745445251
46
train loss item: 0.507759153842926
47
train loss item: 0.5719010233879089
48
train loss item: 0.514923095703125
49
train loss item: 0.4595623314380646
50
train loss item: 0.4906263053417206
51
train loss item: 1.3635722398757935
52
train loss item: 0.5539284348487854
53
train loss item: 0.46002376079559326
54
train loss item: 2.9592173099517822
55
train loss item: 0.5699785351753235
56
train loss item: 0.5645855069160461
57
train loss item: 0.498181015253067
58
train loss item: 0.5035938620567322
59
train loss item: 0.5185667872428894
60
train loss item: 1.367958664894104
61
train loss item: 3.005734443664551
62
train loss item: 0.48312562704086304
63
train loss item: 0.5321363210678101
64
train loss item: 0.5615054965019226
65
train loss item: 0.7630597949028015
66
train loss item: 0.6366426348686218
67
train loss item: 0.4929242730140686
68
train loss item: 0.4915876090526581
69
train loss item: 0.5484006404876709
70
train loss item: 0.464326947927475
71
train loss item: 0.46492263674736023
72
train loss item: 0.6935043931007385
73
train loss item: 0.47993430495262146
74
train loss item: 0.6734532713890076
75
train loss item: 0.48015597462654114
76
train loss item: 1.4055583477020264
77
train loss item: 1.6423330307006836
78
train loss item: 0.45913949608802795
79
train loss item: 0.44560879468917847
80
train loss item: 0.5420604348182678
81
train loss item: 0.41636255383491516
82
train loss item: 0.5060976147651672
83
train loss item: 0.9749600887298584
84
train loss item: 0.5251942873001099
85
train loss item: 1.0271364450454712
86
train loss item: 5.249999523162842
87
train loss item: 0.5360144972801208
88
train loss item: 0.5499196648597717
epoch train loss: 0.8445601048094503
testing phase
test loss item: 6.660935878753662
test loss item: 24.572599411010742
test loss item: 1.8816300630569458
test loss item: 15.636756896972656
test loss item: 20.379880905151367
test loss item: 24.810009002685547
test loss item: 8.808095932006836
test loss item: 4.127858638763428
test loss item: 4.2744622230529785
test loss item: 2.802062511444092
test loss item: 12.592875480651855
test loss item: 16.04220962524414
test loss item: 3.3028922080993652
test loss item: 0.3636178970336914
test loss item: 19.045166015625
test loss item: 36.084449768066406
test loss item: 1.4966766834259033
test loss item: 3.636437177658081
test loss item: 8.557174682617188
test loss item: 1.2040942907333374
test loss item: 8.61253547668457
test loss item: 11.08897590637207
test loss item: 9.043803215026855
test loss item: 13.963210105895996
test loss item: 11.813336372375488
test loss item: 10.755029678344727
test loss item: 4.903090953826904
test loss item: 19.74736976623535
test loss item: 14.714142799377441
test loss item: 3.869948625564575
test loss item: 13.102688789367676
test loss item: 36.08054733276367
test loss item: 15.000717163085938
test loss item: 11.8848876953125
test loss item: 20.135011672973633
test loss item: 27.186811447143555
test loss item: 2.567232847213745
test loss item: 20.833059310913086
test loss item: 9.151233673095703
test loss item: 19.78580093383789
test loss item: 20.000221252441406
test loss item: 11.983717918395996
test loss item: 2.0457167625427246
test loss item: 10.980056762695312
test loss item: 8.676756858825684
test loss item: 23.29848289489746
test loss item: 9.357924461364746
test loss item: 1.4813295602798462
test loss item: 0.7262448072433472
test loss item: 8.216689109802246
test loss item: 2.6947197914123535
test loss item: 12.094978332519531
test loss item: 7.204052448272705
test loss item: 17.732025146484375
test loss item: 9.657407760620117
test loss item: 4.905293941497803
test loss item: 16.52268409729004
test loss item: 0.49866342544555664
test loss item: 12.080366134643555
test loss item: 7.50446891784668
test loss item: 12.007767677307129
test loss item: 19.892839431762695
test loss item: 9.91112232208252
test loss item: 2.544482946395874
test loss item: 17.617774963378906
test loss item: 18.56720542907715
test loss item: 7.178098678588867
test loss item: 4.213913917541504
test loss item: 19.94830322265625
test loss item: 1.4496424198150635
test loss item: 24.0888614654541
test loss item: 12.18920612335205
test loss item: 8.134666442871094
test loss item: 5.30729866027832
test loss item: 4.271378517150879
test loss item: 8.73096752166748
test loss item: 17.73681640625
test loss item: 31.24643898010254
test loss item: 0.6571226119995117
test loss item: 19.971622467041016
test loss item: 15.365177154541016
test loss item: 18.052507400512695
test loss item: 3.682587146759033
test loss item: 21.838581085205078
test loss item: 10.503280639648438
test loss item: 7.6168646812438965
test loss item: 24.223745346069336
test loss item: 36.13582229614258
test loss item: 16.724477767944336
Epoch [4/50], Training Loss: 0.8446, Testing Loss: 12.2246
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.656474232673645
1
train loss item: 1.800570011138916
2
train loss item: 0.3560062646865845
3
train loss item: 0.9847120642662048
4
train loss item: 0.7940486073493958
5
train loss item: 0.5169562697410583
6
train loss item: 0.4104469120502472
7
train loss item: 1.1847126483917236
8
train loss item: 0.3739842176437378
9
train loss item: 0.40075042843818665
10
train loss item: 0.5523738861083984
11
train loss item: 0.3472879230976105
12
train loss item: 0.23801134526729584
13
train loss item: 0.7587170004844666
14
train loss item: 0.4528224468231201
15
train loss item: 0.9152129888534546
16
train loss item: 0.21535082161426544
17
train loss item: 0.40149834752082825
18
train loss item: 0.5005670785903931
19
train loss item: 0.37079182267189026
20
train loss item: 0.339496910572052
21
train loss item: 0.3335827589035034
22
train loss item: 1.3347214460372925
23
train loss item: 1.2491713762283325
24
train loss item: 0.7379628419876099
25
train loss item: 0.343426913022995
26
train loss item: 0.3759284019470215
27
train loss item: 0.4623745381832123
28
train loss item: 0.22934478521347046
29
train loss item: 1.0677324533462524
30
train loss item: 2.9919633865356445
31
train loss item: 0.8374354243278503
32
train loss item: 0.3214867413043976
33
train loss item: 0.7213915586471558
34
train loss item: 0.3950727581977844
35
train loss item: 2.934450387954712
36
train loss item: 0.6699051856994629
37
train loss item: 0.362498939037323
38
train loss item: 0.6967411041259766
39
train loss item: 0.4682409167289734
40
train loss item: 0.2849549651145935
41
train loss item: 0.45573320984840393
42
train loss item: 0.34396591782569885
43
train loss item: 0.3803582191467285
44
train loss item: 0.9998792409896851
45
train loss item: 0.2912740111351013
46
train loss item: 0.31111258268356323
47
train loss item: 0.48082560300827026
48
train loss item: 0.3996196687221527
49
train loss item: 0.3362523317337036
50
train loss item: 0.3792833089828491
51
train loss item: 1.28708815574646
52
train loss item: 0.26618140935897827
53
train loss item: 0.3198050260543823
54
train loss item: 2.8222036361694336
55
train loss item: 0.3625915050506592
56
train loss item: 0.4472717046737671
57
train loss item: 0.41129735112190247
58
train loss item: 0.3533138930797577
59
train loss item: 0.315391480922699
60
train loss item: 1.2785871028900146
61
train loss item: 2.816005229949951
62
train loss item: 0.3460095524787903
63
train loss item: 0.4680663049221039
64
train loss item: 0.36661478877067566
65
train loss item: 0.7488129734992981
66
train loss item: 0.5299195647239685
67
train loss item: 0.3824418783187866
68
train loss item: 0.397892028093338
69
train loss item: 0.46232062578201294
70
train loss item: 0.3831198215484619
71
train loss item: 0.28651097416877747
72
train loss item: 0.40339067578315735
73
train loss item: 0.4047895073890686
74
train loss item: 0.3277525305747986
75
train loss item: 0.26563137769699097
76
train loss item: 1.2581586837768555
77
train loss item: 1.5835521221160889
78
train loss item: 0.22450308501720428
79
train loss item: 0.36566492915153503
80
train loss item: 0.2943735122680664
81
train loss item: 0.33074724674224854
82
train loss item: 0.39640501141548157
83
train loss item: 0.8833985328674316
84
train loss item: 0.44848668575286865
85
train loss item: 0.9073538184165955
86
train loss item: 5.070106506347656
87
train loss item: 0.3438168466091156
88
train loss item: 0.4580044746398926
epoch train loss: 0.705450154589803
testing phase
test loss item: 3.071328639984131
test loss item: 13.616459846496582
test loss item: 0.766322910785675
test loss item: 8.478822708129883
test loss item: 11.728034019470215
test loss item: 14.323015213012695
test loss item: 5.163188934326172
test loss item: 2.049639940261841
test loss item: 1.9157134294509888
test loss item: 1.335042953491211
test loss item: 5.78125
test loss item: 8.631380081176758
test loss item: 1.5133655071258545
test loss item: 0.3845938444137573
test loss item: 10.16140365600586
test loss item: 20.250213623046875
test loss item: 0.39778637886047363
test loss item: 1.7710387706756592
test loss item: 4.0674519538879395
test loss item: 0.5138281583786011
test loss item: 4.286327838897705
test loss item: 6.113883972167969
test loss item: 5.429311275482178
test loss item: 7.5079264640808105
test loss item: 6.196392059326172
test loss item: 5.139895915985107
test loss item: 2.209871292114258
test loss item: 11.417559623718262
test loss item: 7.8815836906433105
test loss item: 1.7962192296981812
test loss item: 5.86696720123291
test loss item: 20.271381378173828
test loss item: 8.076258659362793
test loss item: 6.431876182556152
test loss item: 11.261919021606445
test loss item: 15.3003511428833
test loss item: 1.487786054611206
test loss item: 9.078228950500488
test loss item: 4.998075485229492
test loss item: 11.498032569885254
test loss item: 11.209548950195312
test loss item: 6.728250980377197
test loss item: 0.576207160949707
test loss item: 5.94780158996582
test loss item: 4.320725440979004
test loss item: 13.082039833068848
test loss item: 5.596370697021484
test loss item: 0.6087355613708496
test loss item: 0.5747856497764587
test loss item: 3.528599739074707
test loss item: 1.3609898090362549
test loss item: 6.32827615737915
test loss item: 3.4859979152679443
test loss item: 9.641182899475098
test loss item: 4.712542533874512
test loss item: 2.2052555084228516
test loss item: 9.41608715057373
test loss item: 0.5202631950378418
test loss item: 6.324753284454346
test loss item: 3.647731304168701
test loss item: 6.284181594848633
test loss item: 11.170061111450195
test loss item: 4.825756072998047
test loss item: 1.1522243022918701
test loss item: 10.386116027832031
test loss item: 10.110651969909668
test loss item: 3.515901565551758
test loss item: 1.9858249425888062
test loss item: 11.189913749694824
test loss item: 0.5962303280830383
test loss item: 13.457640647888184
test loss item: 6.479706764221191
test loss item: 4.081705093383789
test loss item: 2.5419602394104004
test loss item: 1.9210329055786133
test loss item: 5.3153157234191895
test loss item: 9.452017784118652
test loss item: 14.854684829711914
test loss item: 0.5530092716217041
test loss item: 11.683941841125488
test loss item: 8.03640365600586
test loss item: 9.62680435180664
test loss item: 1.615204930305481
test loss item: 10.97773551940918
test loss item: 5.195173263549805
test loss item: 3.451070547103882
test loss item: 13.525443077087402
test loss item: 20.28662109375
test loss item: 7.902615547180176
Epoch [5/50], Training Loss: 0.7055, Testing Loss: 6.5187
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6391021013259888
1
train loss item: 1.639237403869629
2
train loss item: 0.3429358899593353
3
train loss item: 0.8170899152755737
4
train loss item: 0.8759848475456238
5
train loss item: 0.5290408730506897
6
train loss item: 0.4101920425891876
7
train loss item: 1.0658186674118042
8
train loss item: 0.26959893107414246
9
train loss item: 0.3823898136615753
10
train loss item: 0.47453051805496216
11
train loss item: 0.3356063663959503
12
train loss item: 0.22082394361495972
13
train loss item: 0.715194582939148
14
train loss item: 0.45310723781585693
15
train loss item: 0.9170725345611572
16
train loss item: 0.21727128326892853
17
train loss item: 0.443759560585022
18
train loss item: 0.4572056829929352
19
train loss item: 0.35876598954200745
20
train loss item: 0.4018152952194214
21
train loss item: 0.35585108399391174
22
train loss item: 1.2967512607574463
23
train loss item: 1.1396089792251587
24
train loss item: 0.7108457684516907
25
train loss item: 0.37744468450546265
26
train loss item: 0.346173495054245
27
train loss item: 0.41993069648742676
28
train loss item: 0.21642859280109406
29
train loss item: 1.0451557636260986
30
train loss item: 2.7841145992279053
31
train loss item: 0.7351086139678955
32
train loss item: 0.25223472714424133
33
train loss item: 0.5859820246696472
34
train loss item: 0.44728970527648926
35
train loss item: 2.8024649620056152
36
train loss item: 0.6331271529197693
37
train loss item: 0.37587955594062805
38
train loss item: 0.5830286145210266
39
train loss item: 0.4266641438007355
40
train loss item: 0.30784645676612854
41
train loss item: 0.41317030787467957
42
train loss item: 0.326049268245697
43
train loss item: 0.32871609926223755
44
train loss item: 0.9131677746772766
45
train loss item: 0.25549009442329407
46
train loss item: 0.2909756600856781
47
train loss item: 0.49238601326942444
48
train loss item: 0.37482908368110657
49
train loss item: 0.3591698706150055
50
train loss item: 0.3830867111682892
51
train loss item: 1.2194278240203857
52
train loss item: 0.2368331104516983
53
train loss item: 0.3582583963871002
54
train loss item: 2.6812329292297363
55
train loss item: 0.29224202036857605
56
train loss item: 0.3967297673225403
57
train loss item: 0.35435381531715393
58
train loss item: 0.31150022149086
59
train loss item: 0.2473878562450409
60
train loss item: 1.221575140953064
61
train loss item: 2.634248971939087
62
train loss item: 0.31760451197624207
63
train loss item: 0.4348480999469757
64
train loss item: 0.26101043820381165
65
train loss item: 0.8097649812698364
66
train loss item: 0.4778249263763428
67
train loss item: 0.3611967861652374
68
train loss item: 0.4068447947502136
69
train loss item: 0.4374018609523773
70
train loss item: 0.4210388660430908
71
train loss item: 0.31726300716400146
72
train loss item: 0.2916499376296997
73
train loss item: 0.41536420583724976
74
train loss item: 0.28455474972724915
75
train loss item: 0.2291453778743744
76
train loss item: 1.1371147632598877
77
train loss item: 1.5442936420440674
78
train loss item: 0.2193654328584671
79
train loss item: 0.3264850974082947
80
train loss item: 0.2573302090167999
81
train loss item: 0.3570981025695801
82
train loss item: 0.3807446360588074
83
train loss item: 0.8334577679634094
84
train loss item: 0.4304877519607544
85
train loss item: 0.8020942807197571
86
train loss item: 4.863773822784424
87
train loss item: 0.3696031868457794
88
train loss item: 0.4246833622455597
epoch train loss: 0.666419661781761
testing phase
test loss item: 1.0577601194381714
test loss item: 6.423574447631836
test loss item: 0.738946795463562
test loss item: 2.736870765686035
test loss item: 5.11063814163208
test loss item: 6.373239994049072
test loss item: 1.9180032014846802
test loss item: 1.0632487535476685
test loss item: 0.5858234763145447
test loss item: 0.5959168672561646
test loss item: 1.1751071214675903
test loss item: 3.2047810554504395
test loss item: 0.4170583188533783
test loss item: 0.39405715465545654
test loss item: 4.659904479980469
test loss item: 9.764897346496582
test loss item: 0.33457109332084656
test loss item: 0.8795017004013062
test loss item: 1.8737934827804565
test loss item: 0.35690394043922424
test loss item: 1.9777753353118896
test loss item: 0.6255561709403992
test loss item: 0.9696524143218994
test loss item: 3.2449235916137695
test loss item: 2.9471442699432373
test loss item: 1.8828257322311401
test loss item: 0.7259348034858704
test loss item: 4.918213844299316
test loss item: 3.431366205215454
test loss item: 0.6244915127754211
test loss item: 1.2293422222137451
test loss item: 9.792121887207031
test loss item: 3.55519700050354
test loss item: 0.8820112943649292
test loss item: 5.4340081214904785
test loss item: 1.1870065927505493
test loss item: 1.0405278205871582
test loss item: 1.843719720840454
test loss item: 0.8246949911117554
test loss item: 5.018078327178955
test loss item: 5.40544319152832
test loss item: 1.7435706853866577
test loss item: 0.5188847184181213
test loss item: 0.5094870328903198
test loss item: 1.9160690307617188
test loss item: 6.3292365074157715
test loss item: 1.177905797958374
test loss item: 0.3521985709667206
test loss item: 0.6013098955154419
test loss item: 1.5166527032852173
test loss item: 0.6215004324913025
test loss item: 2.9691545963287354
test loss item: 1.2319600582122803
test loss item: 0.7340617179870605
test loss item: 1.6915589570999146
test loss item: 1.2955483198165894
test loss item: 1.024769902229309
test loss item: 0.5201119780540466
test loss item: 3.0063998699188232
test loss item: 1.3089962005615234
test loss item: 2.996319055557251
test loss item: 5.400940895080566
test loss item: 1.8506605625152588
test loss item: 0.33278852701187134
test loss item: 4.632922172546387
test loss item: 0.8337852358818054
test loss item: 1.226503849029541
test loss item: 0.7690749168395996
test loss item: 5.442905426025391
test loss item: 0.5375396013259888
test loss item: 6.468523979187012
test loss item: 3.2508678436279297
test loss item: 1.7632659673690796
test loss item: 1.058266520500183
test loss item: 0.8058069348335266
test loss item: 0.8926787376403809
test loss item: 4.29213809967041
test loss item: 2.0139477252960205
test loss item: 0.5588880181312561
test loss item: 5.070672988891602
test loss item: 3.805269241333008
test loss item: 2.045292854309082
test loss item: 1.0300495624542236
test loss item: 1.3429975509643555
test loss item: 1.942524790763855
test loss item: 1.3618927001953125
test loss item: 6.502540588378906
test loss item: 9.78781795501709
test loss item: 3.348339080810547
Epoch [6/50], Training Loss: 0.6664, Testing Loss: 2.4456
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6200348138809204
1
train loss item: 1.5878140926361084
2
train loss item: 0.30962854623794556
3
train loss item: 0.7607928514480591
4
train loss item: 0.7289098501205444
5
train loss item: 0.49888530373573303
6
train loss item: 0.3654206395149231
7
train loss item: 1.041635513305664
8
train loss item: 0.27968597412109375
9
train loss item: 0.36295023560523987
10
train loss item: 0.4526933431625366
11
train loss item: 0.3411499857902527
12
train loss item: 0.21076549589633942
13
train loss item: 0.6858928203582764
14
train loss item: 0.4469723701477051
15
train loss item: 0.8926098942756653
16
train loss item: 0.20899783074855804
17
train loss item: 0.4274754524230957
18
train loss item: 0.44106000661849976
19
train loss item: 0.3483508229255676
20
train loss item: 0.36577534675598145
21
train loss item: 0.3057040274143219
22
train loss item: 1.2707300186157227
23
train loss item: 1.114900827407837
24
train loss item: 0.6722890138626099
25
train loss item: 0.38819509744644165
26
train loss item: 0.30865904688835144
27
train loss item: 0.39234593510627747
28
train loss item: 0.20561067759990692
29
train loss item: 1.014880895614624
30
train loss item: 2.728942632675171
31
train loss item: 0.6982608437538147
32
train loss item: 0.2306569516658783
33
train loss item: 0.5514926910400391
34
train loss item: 0.37383994460105896
35
train loss item: 2.764580249786377
36
train loss item: 0.6078891158103943
37
train loss item: 0.38241904973983765
38
train loss item: 0.5403754711151123
39
train loss item: 0.4061603844165802
40
train loss item: 0.31226757168769836
41
train loss item: 0.388174831867218
42
train loss item: 0.31501081585884094
43
train loss item: 0.2810392379760742
44
train loss item: 0.8784637451171875
45
train loss item: 0.23178768157958984
46
train loss item: 0.27487507462501526
47
train loss item: 0.4966577887535095
48
train loss item: 0.34777504205703735
49
train loss item: 0.3331131041049957
50
train loss item: 0.3854750692844391
51
train loss item: 1.177057147026062
52
train loss item: 0.24048033356666565
53
train loss item: 0.3451857268810272
54
train loss item: 2.6438279151916504
55
train loss item: 0.27836570143699646
56
train loss item: 0.37398797273635864
57
train loss item: 0.3433571755886078
58
train loss item: 0.2655278444290161
59
train loss item: 0.24475479125976562
60
train loss item: 1.183359980583191
61
train loss item: 2.592615842819214
62
train loss item: 0.29556283354759216
63
train loss item: 0.4284267723560333
64
train loss item: 0.23731876909732819
65
train loss item: 0.7699821591377258
66
train loss item: 0.46071115136146545
67
train loss item: 0.34364795684814453
68
train loss item: 0.40302079916000366
69
train loss item: 0.42139172554016113
70
train loss item: 0.42172276973724365
71
train loss item: 0.2839595675468445
72
train loss item: 0.2946137487888336
73
train loss item: 0.3977304697036743
74
train loss item: 0.2731129229068756
75
train loss item: 0.21266888082027435
76
train loss item: 1.1076081991195679
77
train loss item: 1.5221227407455444
78
train loss item: 0.20804841816425323
79
train loss item: 0.33172351121902466
80
train loss item: 0.21839678287506104
81
train loss item: 0.351632297039032
82
train loss item: 0.35612407326698303
83
train loss item: 0.7959581613540649
84
train loss item: 0.4223528504371643
85
train loss item: 0.7818775177001953
86
train loss item: 4.81502628326416
87
train loss item: 0.36651235818862915
88
train loss item: 0.4054528772830963
epoch train loss: 0.6426438320888562
testing phase
test loss item: 0.38802918791770935
test loss item: 2.638472557067871
test loss item: 0.8028857707977295
test loss item: 1.1304597854614258
test loss item: 1.9914606809616089
test loss item: 2.5254814624786377
test loss item: 1.858605980873108
test loss item: 0.7784498333930969
test loss item: 0.34693431854248047
test loss item: 0.5310851335525513
test loss item: 1.1863532066345215
test loss item: 1.3871040344238281
test loss item: 0.2529720664024353
test loss item: 0.3968346416950226
test loss item: 1.9261783361434937
test loss item: 4.072983264923096
test loss item: 0.3446253836154938
test loss item: 0.6820122599601746
test loss item: 1.0552799701690674
test loss item: 0.3478519916534424
test loss item: 1.216528058052063
test loss item: 0.4789900481700897
test loss item: 0.5273367762565613
test loss item: 1.2767524719238281
test loss item: 1.3058103322982788
test loss item: 0.6191486120223999
test loss item: 0.4469981789588928
test loss item: 1.8791481256484985
test loss item: 1.3761194944381714
test loss item: 0.4580228924751282
test loss item: 1.059882640838623
test loss item: 4.075713157653809
test loss item: 1.4277174472808838
test loss item: 0.7825371026992798
test loss item: 2.334413766860962
test loss item: 0.6355734467506409
test loss item: 1.0061211585998535
test loss item: 2.0283632278442383
test loss item: 0.6701406240463257
test loss item: 1.9582297801971436
test loss item: 2.2746853828430176
test loss item: 0.6762394905090332
test loss item: 0.5227820873260498
test loss item: 0.31175047159194946
test loss item: 1.036473035812378
test loss item: 2.680877923965454
test loss item: 0.5868505835533142
test loss item: 0.3146210312843323
test loss item: 0.6489301919937134
test loss item: 0.9907814860343933
test loss item: 0.48242461681365967
test loss item: 1.2903096675872803
test loss item: 0.4576944410800934
test loss item: 0.36245375871658325
test loss item: 0.6315300464630127
test loss item: 1.1982518434524536
test loss item: 0.7417598366737366
test loss item: 0.4651305675506592
test loss item: 1.3233507871627808
test loss item: 0.472339391708374
test loss item: 1.396726369857788
test loss item: 2.2687134742736816
test loss item: 0.6518427133560181
test loss item: 0.3054821193218231
test loss item: 2.079056739807129
test loss item: 0.4699942171573639
test loss item: 0.4806821346282959
test loss item: 0.4006553292274475
test loss item: 2.3732693195343018
test loss item: 0.6267842650413513
test loss item: 2.69112491607666
test loss item: 1.7159141302108765
test loss item: 0.7528160214424133
test loss item: 0.5421473383903503
test loss item: 0.37436091899871826
test loss item: 0.4037238657474518
test loss item: 1.767109990119934
test loss item: 2.100757360458374
test loss item: 0.5692365169525146
test loss item: 1.9615751504898071
test loss item: 1.6378083229064941
test loss item: 1.4287892580032349
test loss item: 1.0867952108383179
test loss item: 1.4523329734802246
test loss item: 0.6630635261535645
test loss item: 0.5294273495674133
test loss item: 2.728236436843872
test loss item: 4.107785224914551
test loss item: 1.2903923988342285
Epoch [7/50], Training Loss: 0.6426, Testing Loss: 1.1970
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5896019339561462
1
train loss item: 1.5669695138931274
2
train loss item: 0.275022953748703
3
train loss item: 0.7576500773429871
4
train loss item: 0.5000334978103638
5
train loss item: 0.4450802206993103
6
train loss item: 0.3177390992641449
7
train loss item: 1.042942762374878
8
train loss item: 0.21291495859622955
9
train loss item: 0.33961227536201477
10
train loss item: 0.44778215885162354
11
train loss item: 0.3426865339279175
12
train loss item: 0.16707101464271545
13
train loss item: 0.6555853486061096
14
train loss item: 0.40928974747657776
15
train loss item: 0.8271281719207764
16
train loss item: 0.15081429481506348
17
train loss item: 0.37051695585250854
18
train loss item: 0.42283838987350464
19
train loss item: 0.3267977833747864
20
train loss item: 0.29750242829322815
21
train loss item: 0.21111343801021576
22
train loss item: 1.2241815328598022
23
train loss item: 1.1238276958465576
24
train loss item: 0.641627311706543
25
train loss item: 0.31667542457580566
26
train loss item: 0.2559838593006134
27
train loss item: 0.3665471374988556
28
train loss item: 0.14347729086875916
29
train loss item: 0.9605110287666321
30
train loss item: 2.728264093399048
31
train loss item: 0.689106822013855
32
train loss item: 0.19447310268878937
33
train loss item: 0.5526072978973389
34
train loss item: 0.24949078261852264
35
train loss item: 2.7583937644958496
36
train loss item: 0.5777360200881958
37
train loss item: 0.37219157814979553
38
train loss item: 0.5280889868736267
39
train loss item: 0.3831784725189209
40
train loss item: 0.23187753558158875
41
train loss item: 0.36684951186180115
42
train loss item: 0.2955248951911926
43
train loss item: 0.23407746851444244
44
train loss item: 0.8678393363952637
45
train loss item: 0.20247985422611237
46
train loss item: 0.21737174689769745
47
train loss item: 0.4609992802143097
48
train loss item: 0.3071005642414093
49
train loss item: 0.2663955092430115
50
train loss item: 0.3653506636619568
51
train loss item: 1.1346079111099243
52
train loss item: 0.18458855152130127
53
train loss item: 0.2611144185066223
54
train loss item: 2.6432080268859863
55
train loss item: 0.24771153926849365
56
train loss item: 0.3527018129825592
57
train loss item: 0.32428672909736633
58
train loss item: 0.21555012464523315
59
train loss item: 0.22079895436763763
60
train loss item: 1.136268138885498
61
train loss item: 2.5963563919067383
62
train loss item: 0.25610390305519104
63
train loss item: 0.4248197674751282
64
train loss item: 0.2218853235244751
65
train loss item: 0.6889586448669434
66
train loss item: 0.454006165266037
67
train loss item: 0.312532901763916
68
train loss item: 0.36940839886665344
69
train loss item: 0.39950332045555115
70
train loss item: 0.3722383379936218
71
train loss item: 0.21259087324142456
72
train loss item: 0.2604232430458069
73
train loss item: 0.3665773868560791
74
train loss item: 0.15940728783607483
75
train loss item: 0.16761913895606995
76
train loss item: 1.1102919578552246
77
train loss item: 1.4903334379196167
78
train loss item: 0.1527608186006546
79
train loss item: 0.3363053500652313
80
train loss item: 0.16168056428432465
81
train loss item: 0.27716735005378723
82
train loss item: 0.3117416501045227
83
train loss item: 0.7503841519355774
84
train loss item: 0.40466344356536865
85
train loss item: 0.7871677279472351
86
train loss item: 4.825435638427734
87
train loss item: 0.2738678455352783
88
train loss item: 0.38576844334602356
epoch train loss: 0.6046040202124735
testing phase
test loss item: 0.27669718861579895
test loss item: 1.078012228012085
test loss item: 0.790270209312439
test loss item: 0.5125621557235718
test loss item: 0.828741192817688
test loss item: 1.023531436920166
test loss item: 1.7232950925827026
test loss item: 0.6646913886070251
test loss item: 0.34161749482154846
test loss item: 0.5123708844184875
test loss item: 1.2161338329315186
test loss item: 0.6336113810539246
test loss item: 0.2543029189109802
test loss item: 0.3861972391605377
test loss item: 0.8217871785163879
test loss item: 1.6871647834777832
test loss item: 0.3453383445739746
test loss item: 0.6084635257720947
test loss item: 0.8367019295692444
test loss item: 0.34448134899139404
test loss item: 1.0157572031021118
test loss item: 0.429059773683548
test loss item: 0.4130118787288666
test loss item: 0.5208942294120789
test loss item: 0.6360872983932495
test loss item: 0.319827139377594
test loss item: 0.43587473034858704
test loss item: 0.7399809956550598
test loss item: 0.6529534459114075
test loss item: 0.4373115003108978
test loss item: 1.0245121717453003
test loss item: 1.6786831617355347
test loss item: 0.5916963219642639
test loss item: 0.7244318127632141
test loss item: 1.0945817232131958
test loss item: 0.6026443839073181
test loss item: 0.947495698928833
test loss item: 2.0690126419067383
test loss item: 0.616271436214447
test loss item: 0.8064404726028442
test loss item: 0.9871841073036194
test loss item: 0.32112061977386475
test loss item: 0.4826173484325409
test loss item: 0.2536598742008209
test loss item: 0.8263952732086182
test loss item: 1.2001404762268066
test loss item: 0.42430728673934937
test loss item: 0.2958933711051941
test loss item: 0.6325905919075012
test loss item: 0.9359835386276245
test loss item: 0.434194952249527
test loss item: 0.6010643839836121
test loss item: 0.3198092579841614
test loss item: 0.23071736097335815
test loss item: 0.4273920953273773
test loss item: 1.1911685466766357
test loss item: 0.7058222889900208
test loss item: 0.37593692541122437
test loss item: 0.6416557431221008
test loss item: 0.3066354990005493
test loss item: 0.7921770215034485
test loss item: 0.9733605980873108
test loss item: 0.3140491247177124
test loss item: 0.30573657155036926
test loss item: 1.293429970741272
test loss item: 0.3530803620815277
test loss item: 0.3843154013156891
test loss item: 0.3349571228027344
test loss item: 1.1772863864898682
test loss item: 0.6224725842475891
test loss item: 1.1189714670181274
test loss item: 1.1690607070922852
test loss item: 0.45892128348350525
test loss item: 0.4404182732105255
test loss item: 0.2770061492919922
test loss item: 0.27615267038345337
test loss item: 0.7520979046821594
test loss item: 2.120776414871216
test loss item: 0.5603277087211609
test loss item: 0.7898563742637634
test loss item: 0.7412807941436768
test loss item: 1.2947156429290771
test loss item: 1.0514981746673584
test loss item: 1.4762682914733887
test loss item: 0.3255215585231781
test loss item: 0.3454250395298004
test loss item: 1.1538242101669312
test loss item: 1.7221826314926147
test loss item: 0.5338242650032043
Epoch [8/50], Training Loss: 0.6046, Testing Loss: 0.7348
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5521730184555054
1
train loss item: 1.5158112049102783
2
train loss item: 0.26129990816116333
3
train loss item: 0.7409176826477051
4
train loss item: 0.5277368426322937
5
train loss item: 0.4097363352775574
6
train loss item: 0.33950114250183105
7
train loss item: 1.021833062171936
8
train loss item: 0.2031938135623932
9
train loss item: 0.3324856162071228
10
train loss item: 0.43773865699768066
11
train loss item: 0.3439837694168091
12
train loss item: 0.14943818747997284
13
train loss item: 0.6185780167579651
14
train loss item: 0.3742477595806122
15
train loss item: 0.7508236169815063
16
train loss item: 0.12368039041757584
17
train loss item: 0.3453804552555084
18
train loss item: 0.3966441750526428
19
train loss item: 0.33292582631111145
20
train loss item: 0.2885774075984955
21
train loss item: 0.18596595525741577
22
train loss item: 1.1499179601669312
23
train loss item: 1.1138800382614136
24
train loss item: 0.6238185167312622
25
train loss item: 0.2585318982601166
26
train loss item: 0.24455298483371735
27
train loss item: 0.3443317711353302
28
train loss item: 0.11950286477804184
29
train loss item: 0.8864395618438721
30
train loss item: 2.6945712566375732
31
train loss item: 0.6759207844734192
32
train loss item: 0.16633105278015137
33
train loss item: 0.5380774140357971
34
train loss item: 0.2006891667842865
35
train loss item: 2.735907793045044
36
train loss item: 0.5469059348106384
37
train loss item: 0.3857266306877136
38
train loss item: 0.5134600400924683
39
train loss item: 0.35153988003730774
40
train loss item: 0.19509027898311615
41
train loss item: 0.3482166528701782
42
train loss item: 0.2848406434059143
43
train loss item: 0.222715362906456
44
train loss item: 0.8414042592048645
45
train loss item: 0.18940964341163635
46
train loss item: 0.18272116780281067
47
train loss item: 0.4206703007221222
48
train loss item: 0.28064823150634766
49
train loss item: 0.2205566018819809
50
train loss item: 0.35945838689804077
51
train loss item: 1.074734091758728
52
train loss item: 0.15915103256702423
53
train loss item: 0.21116513013839722
54
train loss item: 2.6221797466278076
55
train loss item: 0.2519567012786865
56
train loss item: 0.33411771059036255
57
train loss item: 0.3126453161239624
58
train loss item: 0.2049228399991989
59
train loss item: 0.20154765248298645
60
train loss item: 1.0695714950561523
61
train loss item: 2.571047306060791
62
train loss item: 0.242630735039711
63
train loss item: 0.4166107475757599
64
train loss item: 0.21152804791927338
65
train loss item: 0.6295230388641357
66
train loss item: 0.4487422704696655
67
train loss item: 0.2918448746204376
68
train loss item: 0.35290709137916565
69
train loss item: 0.38559573888778687
70
train loss item: 0.3261766731739044
71
train loss item: 0.19315367937088013
72
train loss item: 0.26301756501197815
73
train loss item: 0.3552144467830658
74
train loss item: 0.14239391684532166
75
train loss item: 0.14232061803340912
76
train loss item: 1.0946272611618042
77
train loss item: 1.4378310441970825
78
train loss item: 0.12322688847780228
79
train loss item: 0.33847975730895996
80
train loss item: 0.1513366550207138
81
train loss item: 0.2308666855096817
82
train loss item: 0.2768087685108185
83
train loss item: 0.6950972080230713
84
train loss item: 0.39441242814064026
85
train loss item: 0.7680115103721619
86
train loss item: 4.805697441101074
87
train loss item: 0.23141565918922424
88
train loss item: 0.3809422254562378
epoch train loss: 0.5808085609185561
testing phase
test loss item: 0.2425144761800766
test loss item: 0.36953434348106384
test loss item: 0.702391505241394
test loss item: 0.34074866771698
test loss item: 0.400704562664032
test loss item: 0.3693374693393707
test loss item: 1.6047214269638062
test loss item: 0.5535365343093872
test loss item: 0.30182215571403503
test loss item: 0.46622657775878906
test loss item: 1.1279726028442383
test loss item: 0.3436901271343231
test loss item: 0.23544204235076904
test loss item: 0.3783043622970581
test loss item: 0.3442925214767456
test loss item: 0.542753279209137
test loss item: 0.32524362206459045
test loss item: 0.5378843545913696
test loss item: 0.7295980453491211
test loss item: 0.3279336988925934
test loss item: 0.8701073527336121
test loss item: 0.42973145842552185
test loss item: 0.3533802330493927
test loss item: 0.27206864953041077
test loss item: 0.33238694071769714
test loss item: 0.2809692919254303
test loss item: 0.41088637709617615
test loss item: 0.32532185316085815
test loss item: 0.4373731017112732
test loss item: 0.40859487652778625
test loss item: 0.9381274580955505
test loss item: 0.5327112674713135
test loss item: 0.27522167563438416
test loss item: 0.6765502691268921
test loss item: 0.5851287841796875
test loss item: 0.5549617409706116
test loss item: 0.8618279099464417
test loss item: 1.9022084474563599
test loss item: 0.577060878276825
test loss item: 0.3913119435310364
test loss item: 0.43585675954818726
test loss item: 0.22795207798480988
test loss item: 0.4208841323852539
test loss item: 0.2824125587940216
test loss item: 0.7152206301689148
test loss item: 0.593702495098114
test loss item: 0.3602046072483063
test loss item: 0.2849975526332855
test loss item: 0.5645005702972412
test loss item: 0.8675161600112915
test loss item: 0.37631353735923767
test loss item: 0.27943697571754456
test loss item: 0.2813950777053833
test loss item: 0.3210108280181885
test loss item: 0.3667265772819519
test loss item: 1.0877907276153564
test loss item: 0.6461650133132935
test loss item: 0.30131110548973083
test loss item: 0.3410389721393585
test loss item: 0.2660478949546814
test loss item: 0.548910915851593
test loss item: 0.3940275013446808
test loss item: 0.2525935769081116
test loss item: 0.29551002383232117
test loss item: 1.0037236213684082
test loss item: 0.42028436064720154
test loss item: 0.35607388615608215
test loss item: 0.3170929253101349
test loss item: 0.7141545414924622
test loss item: 0.5385869741439819
test loss item: 0.38545799255371094
test loss item: 0.9516217112541199
test loss item: 0.37509268522262573
test loss item: 0.41593804955482483
test loss item: 0.24451640248298645
test loss item: 0.23969106376171112
test loss item: 0.32728010416030884
test loss item: 1.9312973022460938
test loss item: 0.53983074426651
test loss item: 0.3343436121940613
test loss item: 0.31489360332489014
test loss item: 1.160757303237915
test loss item: 0.9598540663719177
test loss item: 1.3406567573547363
test loss item: 0.26706889271736145
test loss item: 0.3095749318599701
test loss item: 0.4138340651988983
test loss item: 0.5705482959747314
test loss item: 0.2502743899822235
Epoch [9/50], Training Loss: 0.5808, Testing Loss: 0.5265
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5248295068740845
1
train loss item: 1.4347851276397705
2
train loss item: 0.26269465684890747
3
train loss item: 0.6879634857177734
4
train loss item: 0.5181117057800293
5
train loss item: 0.40478211641311646
6
train loss item: 0.34585192799568176
7
train loss item: 0.9721053838729858
8
train loss item: 0.19618552923202515
9
train loss item: 0.3178766071796417
10
train loss item: 0.41107049584388733
11
train loss item: 0.34449484944343567
12
train loss item: 0.1549699455499649
13
train loss item: 0.5770439505577087
14
train loss item: 0.36042091250419617
15
train loss item: 0.6927936673164368
16
train loss item: 0.12581202387809753
17
train loss item: 0.33480221033096313
18
train loss item: 0.37775835394859314
19
train loss item: 0.3432520627975464
20
train loss item: 0.29117265343666077
21
train loss item: 0.19779179990291595
22
train loss item: 1.0760868787765503
23
train loss item: 1.0659688711166382
24
train loss item: 0.6130269765853882
25
train loss item: 0.2518022954463959
26
train loss item: 0.2555457055568695
27
train loss item: 0.3360038101673126
28
train loss item: 0.12231921404600143
29
train loss item: 0.8174635767936707
30
train loss item: 2.6052162647247314
31
train loss item: 0.65252685546875
32
train loss item: 0.15413986146450043
33
train loss item: 0.4864993989467621
34
train loss item: 0.1958235204219818
35
train loss item: 2.676034927368164
36
train loss item: 0.5228974223136902
37
train loss item: 0.41367360949516296
38
train loss item: 0.4981403052806854
39
train loss item: 0.3173607289791107
40
train loss item: 0.20021800696849823
41
train loss item: 0.34083014726638794
42
train loss item: 0.2850470244884491
43
train loss item: 0.22232207655906677
44
train loss item: 0.7956061363220215
45
train loss item: 0.17727313935756683
46
train loss item: 0.16787058115005493
47
train loss item: 0.3959692418575287
48
train loss item: 0.28605350852012634
49
train loss item: 0.20475980639457703
50
train loss item: 0.3609507977962494
51
train loss item: 1.0067665576934814
52
train loss item: 0.14309647679328918
53
train loss item: 0.20007263123989105
54
train loss item: 2.5584263801574707
55
train loss item: 0.25631842017173767
56
train loss item: 0.32229509949684143
57
train loss item: 0.3171294033527374
58
train loss item: 0.21410219371318817
59
train loss item: 0.18576781451702118
60
train loss item: 0.9972485899925232
61
train loss item: 2.4980804920196533
62
train loss item: 0.2666541039943695
63
train loss item: 0.40292519330978394
64
train loss item: 0.19677278399467468
65
train loss item: 0.6114200949668884
66
train loss item: 0.44322845339775085
67
train loss item: 0.2765415608882904
68
train loss item: 0.3497740626335144
69
train loss item: 0.38033923506736755
70
train loss item: 0.306244820356369
71
train loss item: 0.20073193311691284
72
train loss item: 0.24088522791862488
73
train loss item: 0.3561534285545349
74
train loss item: 0.15549063682556152
75
train loss item: 0.13656459748744965
76
train loss item: 1.0451632738113403
77
train loss item: 1.381029725074768
78
train loss item: 0.12061396986246109
79
train loss item: 0.3366530239582062
80
train loss item: 0.15221266448497772
81
train loss item: 0.25103703141212463
82
train loss item: 0.26475560665130615
83
train loss item: 0.645088791847229
84
train loss item: 0.40388813614845276
85
train loss item: 0.7186697721481323
86
train loss item: 4.717405319213867
87
train loss item: 0.23205703496932983
88
train loss item: 0.3911639451980591
epoch train loss: 0.5624355971813202
testing phase
test loss item: 0.2081131637096405
test loss item: 0.19806954264640808
test loss item: 0.6187737584114075
test loss item: 0.29102036356925964
test loss item: 0.3126610219478607
test loss item: 0.23360416293144226
test loss item: 1.5366567373275757
test loss item: 0.4853909909725189
test loss item: 0.25515085458755493
test loss item: 0.43276315927505493
test loss item: 1.0078922510147095
test loss item: 0.26891931891441345
test loss item: 0.20621442794799805
test loss item: 0.38814207911491394
test loss item: 0.23014582693576813
test loss item: 0.24921511113643646
test loss item: 0.30595067143440247
test loss item: 0.4921885132789612
test loss item: 0.678895890712738
test loss item: 0.3117353618144989
test loss item: 0.7858961820602417
test loss item: 0.4013650417327881
test loss item: 0.32876113057136536
test loss item: 0.2192227840423584
test loss item: 0.2603682279586792
test loss item: 0.2653612792491913
test loss item: 0.38483360409736633
test loss item: 0.2579718232154846
test loss item: 0.3896220922470093
test loss item: 0.38963398337364197
test loss item: 0.841335117816925
test loss item: 0.24232544004917145
test loss item: 0.20090092718601227
test loss item: 0.6227375268936157
test loss item: 0.4732018709182739
test loss item: 0.5105975866317749
test loss item: 0.8095677495002747
test loss item: 1.6865805387496948
test loss item: 0.5346624255180359
test loss item: 0.3319074213504791
test loss item: 0.3417593240737915
test loss item: 0.21327297389507294
test loss item: 0.3805243968963623
test loss item: 0.257308691740036
test loss item: 0.6556626558303833
test loss item: 0.48515084385871887
test loss item: 0.32572200894355774
test loss item: 0.2810596525669098
test loss item: 0.5078450441360474
test loss item: 0.7859396934509277
test loss item: 0.34123775362968445
test loss item: 0.1956005096435547
test loss item: 0.2578631639480591
test loss item: 0.2832411825656891
test loss item: 0.33343762159347534
test loss item: 0.9689782857894897
test loss item: 0.5861067771911621
test loss item: 0.2726684808731079
test loss item: 0.27008822560310364
test loss item: 0.23985055088996887
test loss item: 0.49642473459243774
test loss item: 0.2686035931110382
test loss item: 0.2368537336587906
test loss item: 0.2876656651496887
test loss item: 0.8691298365592957
test loss item: 0.3944358229637146
test loss item: 0.33516502380371094
test loss item: 0.29448938369750977
test loss item: 0.6041241884231567
test loss item: 0.4642869532108307
test loss item: 0.19555698335170746
test loss item: 0.8942440748214722
test loss item: 0.35588082671165466
test loss item: 0.40990567207336426
test loss item: 0.19562625885009766
test loss item: 0.2032623142004013
test loss item: 0.23564766347408295
test loss item: 1.6846054792404175
test loss item: 0.530469536781311
test loss item: 0.2582375109195709
test loss item: 0.18780313432216644
test loss item: 1.0366326570510864
test loss item: 0.8946876525878906
test loss item: 1.1641852855682373
test loss item: 0.26294589042663574
test loss item: 0.2685449719429016
test loss item: 0.21074450016021729
test loss item: 0.2637544572353363
test loss item: 0.2127024233341217
Epoch [10/50], Training Loss: 0.5624, Testing Loss: 0.4534
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 11/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5123652815818787
1
train loss item: 1.3690329790115356
2
train loss item: 0.2587543725967407
3
train loss item: 0.6388407349586487
4
train loss item: 0.4794364273548126
5
train loss item: 0.40230169892311096
6
train loss item: 0.3063432276248932
7
train loss item: 0.9253485202789307
8
train loss item: 0.1698775589466095
9
train loss item: 0.29699382185935974
10
train loss item: 0.3921285569667816
11
train loss item: 0.3346822261810303
12
train loss item: 0.15546055138111115
13
train loss item: 0.5544769167900085
14
train loss item: 0.3434143662452698
15
train loss item: 0.665632426738739
16
train loss item: 0.12292711436748505
17
train loss item: 0.33275142312049866
18
train loss item: 0.3721317648887634
19
train loss item: 0.32170459628105164
20
train loss item: 0.2654482126235962
21
train loss item: 0.18887072801589966
22
train loss item: 1.0425933599472046
23
train loss item: 1.014412760734558
24
train loss item: 0.6060618162155151
25
train loss item: 0.2427358627319336
26
train loss item: 0.2619002163410187
27
train loss item: 0.33387356996536255
28
train loss item: 0.1177884042263031
29
train loss item: 0.7865092158317566
30
train loss item: 2.5142338275909424
31
train loss item: 0.6401506066322327
32
train loss item: 0.14229582250118256
33
train loss item: 0.44871923327445984
34
train loss item: 0.18134845793247223
35
train loss item: 2.605752944946289
36
train loss item: 0.5106983780860901
37
train loss item: 0.4169371724128723
38
train loss item: 0.4983259439468384
39
train loss item: 0.29724210500717163
40
train loss item: 0.18186558783054352
41
train loss item: 0.34056979417800903
42
train loss item: 0.28347963094711304
43
train loss item: 0.2138245552778244
44
train loss item: 0.7608292698860168
45
train loss item: 0.16045653820037842
46
train loss item: 0.15855467319488525
47
train loss item: 0.3789508640766144
48
train loss item: 0.2920096218585968
49
train loss item: 0.18761757016181946
50
train loss item: 0.34512341022491455
51
train loss item: 0.9653012752532959
52
train loss item: 0.13282956182956696
53
train loss item: 0.17233695089817047
54
train loss item: 2.485609531402588
55
train loss item: 0.2299855649471283
56
train loss item: 0.3220829665660858
57
train loss item: 0.31168878078460693
58
train loss item: 0.21063703298568726
59
train loss item: 0.17083708941936493
60
train loss item: 0.9536478519439697
61
train loss item: 2.421983242034912
62
train loss item: 0.2818709909915924
63
train loss item: 0.3823307156562805
64
train loss item: 0.1821526437997818
65
train loss item: 0.6125639081001282
66
train loss item: 0.44556501507759094
67
train loss item: 0.2590852379798889
68
train loss item: 0.33669736981391907
69
train loss item: 0.3727704882621765
70
train loss item: 0.28798699378967285
71
train loss item: 0.19407802820205688
72
train loss item: 0.21099300682544708
73
train loss item: 0.34841668605804443
74
train loss item: 0.13682745397090912
75
train loss item: 0.1344846934080124
76
train loss item: 0.995848536491394
77
train loss item: 1.3503124713897705
78
train loss item: 0.11501243710517883
79
train loss item: 0.3223038911819458
80
train loss item: 0.14304938912391663
81
train loss item: 0.24156230688095093
82
train loss item: 0.2551526129245758
83
train loss item: 0.6232026219367981
84
train loss item: 0.4182448983192444
85
train loss item: 0.6799301505088806
86
train loss item: 4.606853485107422
87
train loss item: 0.19625318050384521
88
train loss item: 0.4008730351924896
epoch train loss: 0.5425297395232018
testing phase
test loss item: 0.19794514775276184
test loss item: 0.13727989792823792
test loss item: 0.5824955701828003
test loss item: 0.24565717577934265
test loss item: 0.2766890823841095
test loss item: 0.19674904644489288
test loss item: 1.5255414247512817
test loss item: 0.4856317341327667
test loss item: 0.2419290542602539
test loss item: 0.43010398745536804
test loss item: 0.927722692489624
test loss item: 0.20845353603363037
test loss item: 0.20470735430717468
test loss item: 0.39188358187675476
test loss item: 0.19415342807769775
test loss item: 0.15477405488491058
test loss item: 0.3037641644477844
test loss item: 0.47775372862815857
test loss item: 0.6666301488876343
test loss item: 0.30997833609580994
test loss item: 0.7563616633415222
test loss item: 0.37597742676734924
test loss item: 0.3218543827533722
test loss item: 0.19484499096870422
test loss item: 0.24702894687652588
test loss item: 0.26067328453063965
test loss item: 0.38115978240966797
test loss item: 0.22841782867908478
test loss item: 0.36741846799850464
test loss item: 0.39820200204849243
test loss item: 0.7813946008682251
test loss item: 0.15045161545276642
test loss item: 0.17235122621059418
test loss item: 0.588207483291626
test loss item: 0.4425903558731079
test loss item: 0.4852491021156311
test loss item: 0.8026238083839417
test loss item: 1.5370969772338867
test loss item: 0.5096042156219482
test loss item: 0.32078078389167786
test loss item: 0.32812735438346863
test loss item: 0.1943158358335495
test loss item: 0.37316158413887024
test loss item: 0.21914419531822205
test loss item: 0.6338117718696594
test loss item: 0.4610394537448883
test loss item: 0.30429282784461975
test loss item: 0.2828768193721771
test loss item: 0.49123919010162354
test loss item: 0.7350594401359558
test loss item: 0.3414248824119568
test loss item: 0.1904596984386444
test loss item: 0.2528643012046814
test loss item: 0.18697766959667206
test loss item: 0.32308635115623474
test loss item: 0.8966279029846191
test loss item: 0.5601392984390259
test loss item: 0.2727746069431305
test loss item: 0.2575339674949646
test loss item: 0.23330329358577728
test loss item: 0.4978371560573578
test loss item: 0.24261894822120667
test loss item: 0.23091840744018555
test loss item: 0.2909444272518158
test loss item: 0.8121833801269531
test loss item: 0.3320457339286804
test loss item: 0.33232179284095764
test loss item: 0.28538721799850464
test loss item: 0.568239152431488
test loss item: 0.4262051284313202
test loss item: 0.12072684615850449
test loss item: 0.9033914804458618
test loss item: 0.33775410056114197
test loss item: 0.41770148277282715
test loss item: 0.165103480219841
test loss item: 0.17207741737365723
test loss item: 0.2058880776166916
test loss item: 1.5172098875045776
test loss item: 0.5208992958068848
test loss item: 0.2335033267736435
test loss item: 0.14125913381576538
test loss item: 0.9659310579299927
test loss item: 0.8722563982009888
test loss item: 1.0493652820587158
test loss item: 0.2743372619152069
test loss item: 0.24327261745929718
test loss item: 0.13569116592407227
test loss item: 0.16474072635173798
test loss item: 0.2128152847290039
Epoch [11/50], Training Loss: 0.5425, Testing Loss: 0.4235
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 12/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.49833446741104126
1
train loss item: 1.3303005695343018
2
train loss item: 0.2560933232307434
3
train loss item: 0.613364040851593
4
train loss item: 0.4811212122440338
5
train loss item: 0.3836899697780609
6
train loss item: 0.28870052099227905
7
train loss item: 0.8925052285194397
8
train loss item: 0.16548961400985718
9
train loss item: 0.28259313106536865
10
train loss item: 0.3832276165485382
11
train loss item: 0.3212198317050934
12
train loss item: 0.1501157134771347
13
train loss item: 0.5491105318069458
14
train loss item: 0.31813085079193115
15
train loss item: 0.6616432070732117
16
train loss item: 0.11579859256744385
17
train loss item: 0.34652334451675415
18
train loss item: 0.36322683095932007
19
train loss item: 0.2962478995323181
20
train loss item: 0.2460484504699707
21
train loss item: 0.18480484187602997
22
train loss item: 1.0452181100845337
23
train loss item: 0.982474684715271
24
train loss item: 0.6035612225532532
25
train loss item: 0.23105944693088531
26
train loss item: 0.2740562856197357
27
train loss item: 0.31047311425209045
28
train loss item: 0.10951151698827744
29
train loss item: 0.7886316776275635
30
train loss item: 2.4493248462677
31
train loss item: 0.6328853368759155
32
train loss item: 0.13431128859519958
33
train loss item: 0.4508541226387024
34
train loss item: 0.17933647334575653
35
train loss item: 2.552471399307251
36
train loss item: 0.49850860238075256
37
train loss item: 0.39929184317588806
38
train loss item: 0.4921709895133972
39
train loss item: 0.2778360843658447
40
train loss item: 0.1834898144006729
41
train loss item: 0.3223375380039215
42
train loss item: 0.27371522784233093
43
train loss item: 0.20807556807994843
44
train loss item: 0.7348858714103699
45
train loss item: 0.15259866416454315
46
train loss item: 0.15646333992481232
47
train loss item: 0.37769630551338196
48
train loss item: 0.27127382159233093
49
train loss item: 0.1918404996395111
50
train loss item: 0.32790616154670715
51
train loss item: 0.9545526504516602
52
train loss item: 0.1411316841840744
53
train loss item: 0.16509132087230682
54
train loss item: 2.431443691253662
55
train loss item: 0.23308050632476807
56
train loss item: 0.314472496509552
57
train loss item: 0.2873608469963074
58
train loss item: 0.20128005743026733
59
train loss item: 0.16452720761299133
60
train loss item: 0.9436159729957581
61
train loss item: 2.369905471801758
62
train loss item: 0.2746528685092926
63
train loss item: 0.37208062410354614
64
train loss item: 0.18369245529174805
65
train loss item: 0.616676390171051
66
train loss item: 0.4398670494556427
67
train loss item: 0.24639679491519928
68
train loss item: 0.3292655050754547
69
train loss item: 0.36260563135147095
70
train loss item: 0.27790337800979614
71
train loss item: 0.18805335462093353
72
train loss item: 0.20032456517219543
73
train loss item: 0.33717596530914307
74
train loss item: 0.1225651279091835
75
train loss item: 0.13611602783203125
76
train loss item: 0.9661290645599365
77
train loss item: 1.3510702848434448
78
train loss item: 0.10798705369234085
79
train loss item: 0.30883464217185974
80
train loss item: 0.1450108289718628
81
train loss item: 0.21019743382930756
82
train loss item: 0.2448732554912567
83
train loss item: 0.6275009512901306
84
train loss item: 0.41599172353744507
85
train loss item: 0.6639044880867004
86
train loss item: 4.523440361022949
87
train loss item: 0.17992562055587769
88
train loss item: 0.39909160137176514
epoch train loss: 0.5300937595494678
testing phase
test loss item: 0.19402894377708435
test loss item: 0.12997645139694214
test loss item: 0.5716665387153625
test loss item: 0.2355535328388214
test loss item: 0.26495909690856934
test loss item: 0.17668747901916504
test loss item: 1.561914324760437
test loss item: 0.5288452506065369
test loss item: 0.23863200843334198
test loss item: 0.4335874021053314
test loss item: 0.8879066109657288
test loss item: 0.19154739379882812
test loss item: 0.21475377678871155
test loss item: 0.38736048340797424
test loss item: 0.19043806195259094
test loss item: 0.13265955448150635
test loss item: 0.3064650297164917
test loss item: 0.47829216718673706
test loss item: 0.678716242313385
test loss item: 0.3115267753601074
test loss item: 0.7520469427108765
test loss item: 0.3791866600513458
test loss item: 0.32683923840522766
test loss item: 0.19209754467010498
test loss item: 0.24499477446079254
test loss item: 0.263814777135849
test loss item: 0.37740597128868103
test loss item: 0.2171468585729599
test loss item: 0.364374577999115
test loss item: 0.4065154790878296
test loss item: 0.7581112384796143
test loss item: 0.12987589836120605
test loss item: 0.1681361347436905
test loss item: 0.5809662342071533
test loss item: 0.4375457465648651
test loss item: 0.47698527574539185
test loss item: 0.8209900259971619
test loss item: 1.4584587812423706
test loss item: 0.5057045221328735
test loss item: 0.31676822900772095
test loss item: 0.3269329071044922
test loss item: 0.19196099042892456
test loss item: 0.3786719739437103
test loss item: 0.21137085556983948
test loss item: 0.6317558884620667
test loss item: 0.4611400067806244
test loss item: 0.3087984621524811
test loss item: 0.2781152129173279
test loss item: 0.4925488531589508
test loss item: 0.7120316624641418
test loss item: 0.3553679287433624
test loss item: 0.19787701964378357
test loss item: 0.2558552920818329
test loss item: 0.15849606692790985
test loss item: 0.32689622044563293
test loss item: 0.8602720499038696
test loss item: 0.5629755258560181
test loss item: 0.3034721910953522
test loss item: 0.264023095369339
test loss item: 0.24091608822345734
test loss item: 0.5048071146011353
test loss item: 0.24653829634189606
test loss item: 0.23300139605998993
test loss item: 0.2945421040058136
test loss item: 0.8010873794555664
test loss item: 0.3163521885871887
test loss item: 0.33945250511169434
test loss item: 0.28653743863105774
test loss item: 0.5619221329689026
test loss item: 0.4235648512840271
test loss item: 0.104702889919281
test loss item: 0.9428268074989319
test loss item: 0.3260344862937927
test loss item: 0.4277234375476837
test loss item: 0.15917161107063293
test loss item: 0.17136573791503906
test loss item: 0.20156735181808472
test loss item: 1.4381372928619385
test loss item: 0.5109464526176453
test loss item: 0.2185589224100113
test loss item: 0.12735329568386078
test loss item: 0.9460206627845764
test loss item: 0.8753387331962585
test loss item: 0.9969172477722168
test loss item: 0.28404948115348816
test loss item: 0.2374732792377472
test loss item: 0.11673001199960709
test loss item: 0.13860474526882172
test loss item: 0.20267628133296967
Epoch [12/50], Training Loss: 0.5301, Testing Loss: 0.4185
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 13/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4786674976348877
1
train loss item: 1.306564211845398
2
train loss item: 0.2593452036380768
3
train loss item: 0.5940048694610596
4
train loss item: 0.4690301716327667
5
train loss item: 0.3592414855957031
6
train loss item: 0.29148778319358826
7
train loss item: 0.8693650960922241
8
train loss item: 0.16644679009914398
9
train loss item: 0.27664247155189514
10
train loss item: 0.3708086907863617
11
train loss item: 0.3064700961112976
12
train loss item: 0.13919620215892792
13
train loss item: 0.5393052697181702
14
train loss item: 0.29985642433166504
15
train loss item: 0.6642366051673889
16
train loss item: 0.10277161002159119
17
train loss item: 0.34205830097198486
18
train loss item: 0.3516216576099396
19
train loss item: 0.2842755615711212
20
train loss item: 0.24562442302703857
21
train loss item: 0.1790558248758316
22
train loss item: 1.0557949542999268
23
train loss item: 0.9634101390838623
24
train loss item: 0.5988480448722839
25
train loss item: 0.23158645629882812
26
train loss item: 0.26235947012901306
27
train loss item: 0.2825986444950104
28
train loss item: 0.09702577441930771
29
train loss item: 0.7962101697921753
30
train loss item: 2.403266429901123
31
train loss item: 0.6159782409667969
32
train loss item: 0.13718228042125702
33
train loss item: 0.4562183618545532
34
train loss item: 0.17837455868721008
35
train loss item: 2.5141592025756836
36
train loss item: 0.47743090987205505
37
train loss item: 0.38704124093055725
38
train loss item: 0.46687981486320496
39
train loss item: 0.26068049669265747
40
train loss item: 0.19533351063728333
41
train loss item: 0.29962846636772156
42
train loss item: 0.26755768060684204
43
train loss item: 0.21004515886306763
44
train loss item: 0.7118398547172546
45
train loss item: 0.15221351385116577
46
train loss item: 0.15087191760540009
47
train loss item: 0.3878282606601715
48
train loss item: 0.2527364194393158
49
train loss item: 0.19694672524929047
50
train loss item: 0.32408490777015686
51
train loss item: 0.953069269657135
52
train loss item: 0.1383458971977234
53
train loss item: 0.17817257344722748
54
train loss item: 2.393482208251953
55
train loss item: 0.24967238306999207
56
train loss item: 0.2980732023715973
57
train loss item: 0.26725584268569946
58
train loss item: 0.19655953347682953
59
train loss item: 0.15426020324230194
60
train loss item: 0.9418643712997437
61
train loss item: 2.3346548080444336
62
train loss item: 0.2645653188228607
63
train loss item: 0.3736870288848877
64
train loss item: 0.188102126121521
65
train loss item: 0.6062149405479431
66
train loss item: 0.41576698422431946
67
train loss item: 0.23666006326675415
68
train loss item: 0.3286359906196594
69
train loss item: 0.35310056805610657
70
train loss item: 0.28158873319625854
71
train loss item: 0.18006756901741028
72
train loss item: 0.1965351700782776
73
train loss item: 0.32727479934692383
74
train loss item: 0.11710938066244125
75
train loss item: 0.1326652616262436
76
train loss item: 0.9498312473297119
77
train loss item: 1.3630610704421997
78
train loss item: 0.10020049661397934
79
train loss item: 0.3010464310646057
80
train loss item: 0.15024273097515106
81
train loss item: 0.2020156979560852
82
train loss item: 0.2451367974281311
83
train loss item: 0.6346476078033447
84
train loss item: 0.40016624331474304
85
train loss item: 0.6490973830223083
86
train loss item: 4.46697473526001
87
train loss item: 0.19056768715381622
88
train loss item: 0.3863535523414612
epoch train loss: 0.5210891433813599
testing phase
test loss item: 0.18804481625556946
test loss item: 0.1423303335905075
test loss item: 0.5690496563911438
test loss item: 0.2379433661699295
test loss item: 0.2730867862701416
test loss item: 0.17758096754550934
test loss item: 1.5522270202636719
test loss item: 0.5246695876121521
test loss item: 0.2316741645336151
test loss item: 0.4254428446292877
test loss item: 0.8760364651679993
test loss item: 0.19300857186317444
test loss item: 0.21112392842769623
test loss item: 0.3768777549266815
test loss item: 0.1990119218826294
test loss item: 0.13379627466201782
test loss item: 0.30370426177978516
test loss item: 0.4780329465866089
test loss item: 0.668286144733429
test loss item: 0.3047899007797241
test loss item: 0.7588523626327515
test loss item: 0.38098418712615967
test loss item: 0.32979515194892883
test loss item: 0.19478969275951385
test loss item: 0.24053972959518433
test loss item: 0.2586526870727539
test loss item: 0.36671388149261475
test loss item: 0.22325171530246735
test loss item: 0.3686828315258026
test loss item: 0.3937934935092926
test loss item: 0.7496753931045532
test loss item: 0.12829023599624634
test loss item: 0.17147250473499298
test loss item: 0.5824422836303711
test loss item: 0.43639376759529114
test loss item: 0.466123104095459
test loss item: 0.8121260404586792
test loss item: 1.4390348196029663
test loss item: 0.5045530200004578
test loss item: 0.3148980140686035
test loss item: 0.32291895151138306
test loss item: 0.188913494348526
test loss item: 0.3802575170993805
test loss item: 0.2117169201374054
test loss item: 0.6363735198974609
test loss item: 0.4571232795715332
test loss item: 0.31770333647727966
test loss item: 0.26377642154693604
test loss item: 0.49041101336479187
test loss item: 0.7012403607368469
test loss item: 0.35845887660980225
test loss item: 0.17967402935028076
test loss item: 0.25310760736465454
test loss item: 0.1696283221244812
test loss item: 0.3266962170600891
test loss item: 0.8507899641990662
test loss item: 0.5566427707672119
test loss item: 0.3271796703338623
test loss item: 0.2617373764514923
test loss item: 0.2425588071346283
test loss item: 0.4964700937271118
test loss item: 0.24568159878253937
test loss item: 0.22756697237491608
test loss item: 0.2908358871936798
test loss item: 0.7960110902786255
test loss item: 0.3182377219200134
test loss item: 0.33783552050590515
test loss item: 0.2866946756839752
test loss item: 0.5625922679901123
test loss item: 0.4143865704536438
test loss item: 0.11434603482484818
test loss item: 0.9343523383140564
test loss item: 0.3234015107154846
test loss item: 0.42400532960891724
test loss item: 0.16015402972698212
test loss item: 0.17711135745048523
test loss item: 0.20398257672786713
test loss item: 1.4251186847686768
test loss item: 0.5013182163238525
test loss item: 0.2179032415151596
test loss item: 0.12548500299453735
test loss item: 0.9340231418609619
test loss item: 0.8649967908859253
test loss item: 0.9850152134895325
test loss item: 0.2753259241580963
test loss item: 0.23799291253089905
test loss item: 0.11658994108438492
test loss item: 0.13374540209770203
test loss item: 0.18271268904209137
Epoch [13/50], Training Loss: 0.5211, Testing Loss: 0.4157
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 14/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45918893814086914
1
train loss item: 1.2836228609085083
2
train loss item: 0.24718473851680756
3
train loss item: 0.5751398205757141
4
train loss item: 0.4350069463253021
5
train loss item: 0.340617835521698
6
train loss item: 0.2778984308242798
7
train loss item: 0.8495064973831177
8
train loss item: 0.15068942308425903
9
train loss item: 0.26765573024749756
10
train loss item: 0.3568853437900543
11
train loss item: 0.2926076650619507
12
train loss item: 0.1295720487833023
13
train loss item: 0.5200155973434448
14
train loss item: 0.28133463859558105
15
train loss item: 0.6567124724388123
16
train loss item: 0.08386076241731644
17
train loss item: 0.3146308660507202
18
train loss item: 0.3389701843261719
19
train loss item: 0.2770211398601532
20
train loss item: 0.23831751942634583
21
train loss item: 0.15559813380241394
22
train loss item: 1.051973819732666
23
train loss item: 0.9507569074630737
24
train loss item: 0.5880767107009888
25
train loss item: 0.22062407433986664
26
train loss item: 0.22848767042160034
27
train loss item: 0.2579261362552643
28
train loss item: 0.08011943846940994
29
train loss item: 0.7864688634872437
30
train loss item: 2.3659658432006836
31
train loss item: 0.5947364568710327
32
train loss item: 0.13405022025108337
33
train loss item: 0.44532111287117004
34
train loss item: 0.16018417477607727
35
train loss item: 2.4837167263031006
36
train loss item: 0.455759733915329
37
train loss item: 0.3875757157802582
38
train loss item: 0.43993180990219116
39
train loss item: 0.24676679074764252
40
train loss item: 0.18080861866474152
41
train loss item: 0.27873095870018005
42
train loss item: 0.2656467854976654
43
train loss item: 0.20169487595558167
44
train loss item: 0.6918095350265503
45
train loss item: 0.14743517339229584
46
train loss item: 0.1314847618341446
47
train loss item: 0.3873908817768097
48
train loss item: 0.23951426148414612
49
train loss item: 0.18122458457946777
50
train loss item: 0.3198333978652954
51
train loss item: 0.9447899460792542
52
train loss item: 0.11235155910253525
53
train loss item: 0.16821321845054626
54
train loss item: 2.364572048187256
55
train loss item: 0.23277698457241058
56
train loss item: 0.27457478642463684
57
train loss item: 0.25539514422416687
58
train loss item: 0.18534299731254578
59
train loss item: 0.13547490537166595
60
train loss item: 0.9294266700744629
61
train loss item: 2.3073761463165283
62
train loss item: 0.2531006634235382
63
train loss item: 0.3757057189941406
64
train loss item: 0.17580829560756683
65
train loss item: 0.581342875957489
66
train loss item: 0.3944733738899231
67
train loss item: 0.2258872091770172
68
train loss item: 0.3214765787124634
69
train loss item: 0.34228289127349854
70
train loss item: 0.28111347556114197
71
train loss item: 0.16298039257526398
72
train loss item: 0.18661057949066162
73
train loss item: 0.3134826421737671
74
train loss item: 0.11139001697301865
75
train loss item: 0.12048851698637009
76
train loss item: 0.937389612197876
77
train loss item: 1.3656859397888184
78
train loss item: 0.08680517971515656
79
train loss item: 0.2964363992214203
80
train loss item: 0.14116209745407104
81
train loss item: 0.1960214227437973
82
train loss item: 0.2343258559703827
83
train loss item: 0.6318908333778381
84
train loss item: 0.39066505432128906
85
train loss item: 0.6263948082923889
86
train loss item: 4.426102161407471
87
train loss item: 0.17947471141815186
88
train loss item: 0.37466439604759216
epoch train loss: 0.506511345422
testing phase
test loss item: 0.18403910100460052
test loss item: 0.1484271138906479
test loss item: 0.5701863765716553
test loss item: 0.24897001683712006
test loss item: 0.27848100662231445
test loss item: 0.1742822825908661
test loss item: 1.4757965803146362
test loss item: 0.44975942373275757
test loss item: 0.22645466029644012
test loss item: 0.4127286672592163
test loss item: 0.88206547498703
test loss item: 0.20436426997184753
test loss item: 0.20179304480552673
test loss item: 0.3573664426803589
test loss item: 0.20414961874485016
test loss item: 0.12988753616809845
test loss item: 0.2969244122505188
test loss item: 0.47442519664764404
test loss item: 0.6231599450111389
test loss item: 0.29242977499961853
test loss item: 0.757746696472168
test loss item: 0.3791596591472626
test loss item: 0.31947770714759827
test loss item: 0.1971999853849411
test loss item: 0.23251688480377197
test loss item: 0.24981547892093658
test loss item: 0.35625919699668884
test loss item: 0.22673507034778595
test loss item: 0.36832934617996216
test loss item: 0.37557122111320496
test loss item: 0.7436042428016663
test loss item: 0.12787923216819763
test loss item: 0.17484985291957855
test loss item: 0.5861554741859436
test loss item: 0.43273088335990906
test loss item: 0.45266231894493103
test loss item: 0.7659470438957214
test loss item: 1.4581290483474731
test loss item: 0.5026366710662842
test loss item: 0.30709993839263916
test loss item: 0.31545770168304443
test loss item: 0.17831389605998993
test loss item: 0.3740222156047821
test loss item: 0.22089266777038574
test loss item: 0.6314566731452942
test loss item: 0.44052547216415405
test loss item: 0.31365883350372314
test loss item: 0.25001299381256104
test loss item: 0.48255693912506104
test loss item: 0.696151077747345
test loss item: 0.3472828269004822
test loss item: 0.1579674929380417
test loss item: 0.24657286703586578
test loss item: 0.20779360830783844
test loss item: 0.31942734122276306
test loss item: 0.8577413558959961
test loss item: 0.5329227447509766
test loss item: 0.31184685230255127
test loss item: 0.2519937753677368
test loss item: 0.23493418097496033
test loss item: 0.4806840121746063
test loss item: 0.23711423575878143
test loss item: 0.21710637211799622
test loss item: 0.27981117367744446
test loss item: 0.7836898565292358
test loss item: 0.3373579978942871
test loss item: 0.3313984274864197
test loss item: 0.28092923760414124
test loss item: 0.5596953630447388
test loss item: 0.38014841079711914
test loss item: 0.12071548402309418
test loss item: 0.8642764091491699
test loss item: 0.3216630220413208
test loss item: 0.4092830419540405
test loss item: 0.16097788512706757
test loss item: 0.17290709912776947
test loss item: 0.20411767065525055
test loss item: 1.449654459953308
test loss item: 0.48785632848739624
test loss item: 0.21455232799053192
test loss item: 0.1218404695391655
test loss item: 0.9157609343528748
test loss item: 0.8324825763702393
test loss item: 0.998673677444458
test loss item: 0.2549437880516052
test loss item: 0.24174168705940247
test loss item: 0.11200869083404541
test loss item: 0.12271092087030411
test loss item: 0.1679159551858902
Epoch [14/50], Training Loss: 0.5065, Testing Loss: 0.4077
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 15/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4473196864128113
1
train loss item: 1.2545645236968994
2
train loss item: 0.23177091777324677
3
train loss item: 0.5624193549156189
4
train loss item: 0.424691379070282
5
train loss item: 0.3347819447517395
6
train loss item: 0.27085772156715393
7
train loss item: 0.8302279114723206
8
train loss item: 0.13916990160942078
9
train loss item: 0.25638318061828613
10
train loss item: 0.35071414709091187
11
train loss item: 0.288695752620697
12
train loss item: 0.1342693418264389
13
train loss item: 0.5020378232002258
14
train loss item: 0.2645169794559479
15
train loss item: 0.6368269324302673
16
train loss item: 0.08203846961259842
17
train loss item: 0.28725168108940125
18
train loss item: 0.32819297909736633
19
train loss item: 0.2788366973400116
20
train loss item: 0.23073774576187134
21
train loss item: 0.14569173753261566
22
train loss item: 1.025895595550537
23
train loss item: 0.9427366256713867
24
train loss item: 0.5751320719718933
25
train loss item: 0.21013197302818298
26
train loss item: 0.20901177823543549
27
train loss item: 0.24010348320007324
28
train loss item: 0.07986767590045929
29
train loss item: 0.7582225203514099
30
train loss item: 2.3321657180786133
31
train loss item: 0.5823222994804382
32
train loss item: 0.12861527502536774
33
train loss item: 0.43305647373199463
34
train loss item: 0.16041173040866852
35
train loss item: 2.4564571380615234
36
train loss item: 0.44265469908714294
37
train loss item: 0.39927953481674194
38
train loss item: 0.42999494075775146
39
train loss item: 0.23655591905117035
40
train loss item: 0.1698177605867386
41
train loss item: 0.2623911499977112
42
train loss item: 0.26951298117637634
43
train loss item: 0.1929260939359665
44
train loss item: 0.6752143502235413
45
train loss item: 0.1441110521554947
46
train loss item: 0.12004120647907257
47
train loss item: 0.3768748342990875
48
train loss item: 0.22924314439296722
49
train loss item: 0.1682889759540558
50
train loss item: 0.30998730659484863
51
train loss item: 0.9278894066810608
52
train loss item: 0.08607835322618484
53
train loss item: 0.16218675673007965
54
train loss item: 2.339623212814331
55
train loss item: 0.21342617273330688
56
train loss item: 0.25609639286994934
57
train loss item: 0.2513728141784668
58
train loss item: 0.17796717584133148
59
train loss item: 0.12312137335538864
60
train loss item: 0.9030113816261292
61
train loss item: 2.2846107482910156
62
train loss item: 0.2413981854915619
63
train loss item: 0.3757813274860382
64
train loss item: 0.1670142263174057
65
train loss item: 0.5527905821800232
66
train loss item: 0.3910748064517975
67
train loss item: 0.22300347685813904
68
train loss item: 0.3093530535697937
69
train loss item: 0.3344486951828003
70
train loss item: 0.2776038646697998
71
train loss item: 0.15232990682125092
72
train loss item: 0.18191371858119965
73
train loss item: 0.3033839464187622
74
train loss item: 0.11650200933218002
75
train loss item: 0.11591681838035583
76
train loss item: 0.925003707408905
77
train loss item: 1.3535710573196411
78
train loss item: 0.08660639822483063
79
train loss item: 0.29773274064064026
80
train loss item: 0.13299815356731415
81
train loss item: 0.1978553980588913
82
train loss item: 0.21769419312477112
83
train loss item: 0.6207811832427979
84
train loss item: 0.3953973650932312
85
train loss item: 0.6042669415473938
86
train loss item: 4.391199588775635
87
train loss item: 0.17579367756843567
88
train loss item: 0.37479349970817566
epoch train loss: 0.4953327351406719
testing phase
test loss item: 0.17853711545467377
test loss item: 0.13444052636623383
test loss item: 0.5697702169418335
test loss item: 0.2520030438899994
test loss item: 0.2677278220653534
test loss item: 0.1573498696088791
test loss item: 1.4068697690963745
test loss item: 0.3864237368106842
test loss item: 0.2198103666305542
test loss item: 0.4021907150745392
test loss item: 0.8906673192977905
test loss item: 0.20743528008460999
test loss item: 0.19627448916435242
test loss item: 0.33814263343811035
test loss item: 0.19201108813285828
test loss item: 0.11809379607439041
test loss item: 0.29418686032295227
test loss item: 0.4661654233932495
test loss item: 0.5931261777877808
test loss item: 0.28369006514549255
test loss item: 0.7408790588378906
test loss item: 0.3769323229789734
test loss item: 0.3023996651172638
test loss item: 0.1882036030292511
test loss item: 0.22676250338554382
test loss item: 0.24161523580551147
test loss item: 0.3466092646121979
test loss item: 0.214641734957695
test loss item: 0.354861319065094
test loss item: 0.36400970816612244
test loss item: 0.7397197484970093
test loss item: 0.11989365518093109
test loss item: 0.165959894657135
test loss item: 0.5841007232666016
test loss item: 0.4245847463607788
test loss item: 0.4505523145198822
test loss item: 0.7281216382980347
test loss item: 1.4807225465774536
test loss item: 0.4944241940975189
test loss item: 0.29149535298347473
test loss item: 0.30952170491218567
test loss item: 0.17322693765163422
test loss item: 0.364952027797699
test loss item: 0.22793187201023102
test loss item: 0.6133552193641663
test loss item: 0.4229867458343506
test loss item: 0.30268433690071106
test loss item: 0.24498048424720764
test loss item: 0.4739578366279602
test loss item: 0.6972958445549011
test loss item: 0.32744812965393066
test loss item: 0.15191297233104706
test loss item: 0.24069449305534363
test loss item: 0.2282739281654358
test loss item: 0.3072853088378906
test loss item: 0.8615310192108154
test loss item: 0.5180269479751587
test loss item: 0.2751699686050415
test loss item: 0.24418886005878448
test loss item: 0.22347140312194824
test loss item: 0.4664039611816406
test loss item: 0.23384183645248413
test loss item: 0.21095602214336395
test loss item: 0.26857197284698486
test loss item: 0.770389199256897
test loss item: 0.34947317838668823
test loss item: 0.32759514451026917
test loss item: 0.2708784341812134
test loss item: 0.5517417192459106
test loss item: 0.37282830476760864
test loss item: 0.10830414295196533
test loss item: 0.8016299605369568
test loss item: 0.3200436532497406
test loss item: 0.3961401879787445
test loss item: 0.15985994040966034
test loss item: 0.16523043811321259
test loss item: 0.19311724603176117
test loss item: 1.4689228534698486
test loss item: 0.47464606165885925
test loss item: 0.2037181854248047
test loss item: 0.1073027104139328
test loss item: 0.9091289043426514
test loss item: 0.8094527125358582
test loss item: 1.0134133100509644
test loss item: 0.2367708384990692
test loss item: 0.24498538672924042
test loss item: 0.09863202273845673
test loss item: 0.108912892639637
test loss item: 0.1617375612258911
Epoch [15/50], Training Loss: 0.4953, Testing Loss: 0.3978
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 16/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.44363638758659363
1
train loss item: 1.2234601974487305
2
train loss item: 0.22555367648601532
3
train loss item: 0.5536231398582458
4
train loss item: 0.43453946709632874
5
train loss item: 0.33521780371665955
6
train loss item: 0.2770938277244568
7
train loss item: 0.811414361000061
8
train loss item: 0.1334514617919922
9
train loss item: 0.2529667317867279
10
train loss item: 0.3505399823188782
11
train loss item: 0.29183170199394226
12
train loss item: 0.14124226570129395
13
train loss item: 0.4888868033885956
14
train loss item: 0.2508033215999603
15
train loss item: 0.6191627383232117
16
train loss item: 0.0906086340546608
17
train loss item: 0.2813085913658142
18
train loss item: 0.3226020932197571
19
train loss item: 0.28445854783058167
20
train loss item: 0.23577052354812622
21
train loss item: 0.14903278648853302
22
train loss item: 0.9939418435096741
23
train loss item: 0.9329277276992798
24
train loss item: 0.5666717886924744
25
train loss item: 0.21135063469409943
26
train loss item: 0.2091846466064453
27
train loss item: 0.22952520847320557
28
train loss item: 0.08737614005804062
29
train loss item: 0.7311697006225586
30
train loss item: 2.3000144958496094
31
train loss item: 0.5764925479888916
32
train loss item: 0.11900613456964493
33
train loss item: 0.4224812686443329
34
train loss item: 0.1766267865896225
35
train loss item: 2.4299285411834717
36
train loss item: 0.43787986040115356
37
train loss item: 0.41199877858161926
38
train loss item: 0.4360898435115814
39
train loss item: 0.2280084639787674
40
train loss item: 0.17637883126735687
41
train loss item: 0.25334829092025757
42
train loss item: 0.2755627930164337
43
train loss item: 0.18846477568149567
44
train loss item: 0.6598522067070007
45
train loss item: 0.1388724446296692
46
train loss item: 0.11843431740999222
47
train loss item: 0.3666413426399231
48
train loss item: 0.22342102229595184
49
train loss item: 0.1629854440689087
50
train loss item: 0.3015003800392151
51
train loss item: 0.9115359783172607
52
train loss item: 0.08060355484485626
53
train loss item: 0.1653306484222412
54
train loss item: 2.3148772716522217
55
train loss item: 0.21199077367782593
56
train loss item: 0.24804428219795227
57
train loss item: 0.24865929782390594
58
train loss item: 0.1756119728088379
59
train loss item: 0.1199721246957779
60
train loss item: 0.8749993443489075
61
train loss item: 2.261009693145752
62
train loss item: 0.23137980699539185
63
train loss item: 0.3748140037059784
64
train loss item: 0.16676753759384155
65
train loss item: 0.5346808433532715
66
train loss item: 0.39652949571609497
67
train loss item: 0.22310957312583923
68
train loss item: 0.2993336021900177
69
train loss item: 0.3313390016555786
70
train loss item: 0.27671703696250916
71
train loss item: 0.15000081062316895
72
train loss item: 0.1783258616924286
73
train loss item: 0.3021039664745331
74
train loss item: 0.11340732127428055
75
train loss item: 0.11722344905138016
76
train loss item: 0.9093571901321411
77
train loss item: 1.3382073640823364
78
train loss item: 0.09201084822416306
79
train loss item: 0.3007946014404297
80
train loss item: 0.1251685470342636
81
train loss item: 0.20983749628067017
82
train loss item: 0.20607459545135498
83
train loss item: 0.6099333763122559
84
train loss item: 0.40495380759239197
85
train loss item: 0.5892690420150757
86
train loss item: 4.3553009033203125
87
train loss item: 0.18216992914676666
88
train loss item: 0.38468411564826965
epoch train loss: 0.48965697049090035
testing phase
test loss item: 0.177863210439682
test loss item: 0.11513277888298035
test loss item: 0.5607450008392334
test loss item: 0.23919978737831116
test loss item: 0.2510773539543152
test loss item: 0.1397779881954193
test loss item: 1.3836325407028198
test loss item: 0.3863307535648346
test loss item: 0.21176102757453918
test loss item: 0.3930239975452423
test loss item: 0.8737178444862366
test loss item: 0.18795377016067505
test loss item: 0.19378644227981567
test loss item: 0.32850325107574463
test loss item: 0.17425650358200073
test loss item: 0.10270952433347702
test loss item: 0.2965267598628998
test loss item: 0.4540393054485321
test loss item: 0.5884522199630737
test loss item: 0.2810806930065155
test loss item: 0.716772735118866
test loss item: 0.37130022048950195
test loss item: 0.28893139958381653
test loss item: 0.17913900315761566
test loss item: 0.2234487682580948
test loss item: 0.23452703654766083
test loss item: 0.33943045139312744
test loss item: 0.1973395049571991
test loss item: 0.33707141876220703
test loss item: 0.35732805728912354
test loss item: 0.7240968346595764
test loss item: 0.1020750105381012
test loss item: 0.1583695262670517
test loss item: 0.5699732899665833
test loss item: 0.41209763288497925
test loss item: 0.4289450943470001
test loss item: 0.7171913981437683
test loss item: 1.4568430185317993
test loss item: 0.47641119360923767
test loss item: 0.27903425693511963
test loss item: 0.306739866733551
test loss item: 0.1746993213891983
test loss item: 0.35656166076660156
test loss item: 0.21768426895141602
test loss item: 0.5909709930419922
test loss item: 0.4163654148578644
test loss item: 0.29362571239471436
test loss item: 0.2443181425333023
test loss item: 0.4657948613166809
test loss item: 0.6850652098655701
test loss item: 0.30679863691329956
test loss item: 0.1530485302209854
test loss item: 0.2348160296678543
test loss item: 0.19947722554206848
test loss item: 0.29313763976097107
test loss item: 0.8386333584785461
test loss item: 0.5103219151496887
test loss item: 0.2514640688896179
test loss item: 0.24175511300563812
test loss item: 0.2125520557165146
test loss item: 0.4546099901199341
test loss item: 0.23975451290607452
test loss item: 0.2119765430688858
test loss item: 0.26207199692726135
test loss item: 0.7510258555412292
test loss item: 0.33029869198799133
test loss item: 0.3278360962867737
test loss item: 0.26311710476875305
test loss item: 0.5394567251205444
test loss item: 0.36969849467277527
test loss item: 0.08649715781211853
test loss item: 0.7893864512443542
test loss item: 0.3191329836845398
test loss item: 0.392598956823349
test loss item: 0.1593049019575119
test loss item: 0.162811741232872
test loss item: 0.18177559971809387
test loss item: 1.440283179283142
test loss item: 0.46501684188842773
test loss item: 0.19423729181289673
test loss item: 0.09619645774364471
test loss item: 0.8971507549285889
test loss item: 0.7956821918487549
test loss item: 0.9926247596740723
test loss item: 0.2267395257949829
test loss item: 0.2425791621208191
test loss item: 0.09167207777500153
test loss item: 0.09832713007926941
test loss item: 0.16146206855773926
Epoch [16/50], Training Loss: 0.4897, Testing Loss: 0.3870
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 17/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4366638958454132
1
train loss item: 1.197843074798584
2
train loss item: 0.22529740631580353
3
train loss item: 0.5378106832504272
4
train loss item: 0.4147859811782837
5
train loss item: 0.3274303078651428
6
train loss item: 0.276743084192276
7
train loss item: 0.7924052476882935
8
train loss item: 0.1271401196718216
9
train loss item: 0.25129419565200806
10
train loss item: 0.34312763810157776
11
train loss item: 0.2877536118030548
12
train loss item: 0.13820745050907135
13
train loss item: 0.47471946477890015
14
train loss item: 0.23796935379505157
15
train loss item: 0.6125990748405457
16
train loss item: 0.0929488092660904
17
train loss item: 0.28415584564208984
18
train loss item: 0.3164084851741791
19
train loss item: 0.28231269121170044
20
train loss item: 0.2382020503282547
21
train loss item: 0.1419064998626709
22
train loss item: 0.9776265621185303
23
train loss item: 0.9134973883628845
24
train loss item: 0.5595595240592957
25
train loss item: 0.2022017240524292
26
train loss item: 0.20040956139564514
27
train loss item: 0.22136960923671722
28
train loss item: 0.08780965954065323
29
train loss item: 0.7189124822616577
30
train loss item: 2.2673070430755615
31
train loss item: 0.5644242167472839
32
train loss item: 0.1053696870803833
33
train loss item: 0.40957167744636536
34
train loss item: 0.16972008347511292
35
train loss item: 2.4028921127319336
36
train loss item: 0.4312320053577423
37
train loss item: 0.4122551679611206
38
train loss item: 0.43458861112594604
39
train loss item: 0.21883097290992737
40
train loss item: 0.1736224889755249
41
train loss item: 0.2469377964735031
42
train loss item: 0.27592623233795166
43
train loss item: 0.18278944492340088
44
train loss item: 0.643157958984375
45
train loss item: 0.12625068426132202
46
train loss item: 0.11387300491333008
47
train loss item: 0.35922548174858093
48
train loss item: 0.21840877830982208
49
train loss item: 0.15393823385238647
50
train loss item: 0.29477593302726746
51
train loss item: 0.8996672630310059
52
train loss item: 0.08921709656715393
53
train loss item: 0.15357822179794312
54
train loss item: 2.2879738807678223
55
train loss item: 0.20832034945487976
56
train loss item: 0.24086230993270874
57
train loss item: 0.2409176230430603
58
train loss item: 0.16954617202281952
59
train loss item: 0.11731193959712982
60
train loss item: 0.8574489951133728
61
train loss item: 2.231877088546753
62
train loss item: 0.2227070927619934
63
train loss item: 0.37179064750671387
64
train loss item: 0.16404283046722412
65
train loss item: 0.5260545611381531
66
train loss item: 0.3927144408226013
67
train loss item: 0.21522685885429382
68
train loss item: 0.2943854033946991
69
train loss item: 0.3261343538761139
70
train loss item: 0.2708817422389984
71
train loss item: 0.15071700513362885
72
train loss item: 0.16989636421203613
73
train loss item: 0.29978522658348083
74
train loss item: 0.09449274837970734
75
train loss item: 0.11463886499404907
76
train loss item: 0.8882274031639099
77
train loss item: 1.331472635269165
78
train loss item: 0.08973798155784607
79
train loss item: 0.29462501406669617
80
train loss item: 0.11124818027019501
81
train loss item: 0.20496860146522522
82
train loss item: 0.19806842505931854
83
train loss item: 0.6041463017463684
84
train loss item: 0.4050963521003723
85
train loss item: 0.5723462104797363
86
train loss item: 4.3153510093688965
87
train loss item: 0.16795450448989868
88
train loss item: 0.39054998755455017
epoch train loss: 0.480990907700544
testing phase
test loss item: 0.18238741159439087
test loss item: 0.11399554461240768
test loss item: 0.5481221675872803
test loss item: 0.22866380214691162
test loss item: 0.243124857544899
test loss item: 0.13355600833892822
test loss item: 1.4020297527313232
test loss item: 0.43318888545036316
test loss item: 0.20789426565170288
test loss item: 0.38710108399391174
test loss item: 0.842759370803833
test loss item: 0.16506949067115784
test loss item: 0.1887156367301941
test loss item: 0.3193768858909607
test loss item: 0.17256787419319153
test loss item: 0.09518064558506012
test loss item: 0.2963367700576782
test loss item: 0.44516146183013916
test loss item: 0.602202296257019
test loss item: 0.27561870217323303
test loss item: 0.6971915364265442
test loss item: 0.36614713072776794
test loss item: 0.27625375986099243
test loss item: 0.18212354183197021
test loss item: 0.2208559364080429
test loss item: 0.23073790967464447
test loss item: 0.3349018096923828
test loss item: 0.19016137719154358
test loss item: 0.3278796076774597
test loss item: 0.35277339816093445
test loss item: 0.7064369916915894
test loss item: 0.09010008722543716
test loss item: 0.16524194180965424
test loss item: 0.5547662377357483
test loss item: 0.4023861289024353
test loss item: 0.4052676558494568
test loss item: 0.7292435765266418
test loss item: 1.405637264251709
test loss item: 0.45998042821884155
test loss item: 0.2759688198566437
test loss item: 0.3050348162651062
test loss item: 0.17184005677700043
test loss item: 0.3529527187347412
test loss item: 0.20189829170703888
test loss item: 0.5732019543647766
test loss item: 0.41423144936561584
test loss item: 0.2840707302093506
test loss item: 0.23852665722370148
test loss item: 0.4596809148788452
test loss item: 0.6690424680709839
test loss item: 0.29571858048439026
test loss item: 0.15003472566604614
test loss item: 0.23059074580669403
test loss item: 0.15378065407276154
test loss item: 0.2845779061317444
test loss item: 0.8052603602409363
test loss item: 0.5140092968940735
test loss item: 0.2448589950799942
test loss item: 0.24136357009410858
test loss item: 0.20692594349384308
test loss item: 0.45023319125175476
test loss item: 0.24462652206420898
test loss item: 0.21348008513450623
test loss item: 0.2581883370876312
test loss item: 0.7340138554573059
test loss item: 0.3045552372932434
test loss item: 0.32558247447013855
test loss item: 0.25924816727638245
test loss item: 0.527254045009613
test loss item: 0.3692021071910858
test loss item: 0.07783879339694977
test loss item: 0.8170253038406372
test loss item: 0.3102131187915802
test loss item: 0.390521764755249
test loss item: 0.15644954144954681
test loss item: 0.1586257815361023
test loss item: 0.18273060023784637
test loss item: 1.383838176727295
test loss item: 0.4499775171279907
test loss item: 0.18965251743793488
test loss item: 0.10052447021007538
test loss item: 0.8849273920059204
test loss item: 0.7940348982810974
test loss item: 0.9512173533439636
test loss item: 0.22210444509983063
test loss item: 0.23399804532527924
test loss item: 0.09874849766492844
test loss item: 0.09870617091655731
test loss item: 0.17032888531684875
Epoch [17/50], Training Loss: 0.4810, Testing Loss: 0.3799
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 18/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4262981414794922
1
train loss item: 1.1776529550552368
2
train loss item: 0.22743920981884003
3
train loss item: 0.5183477401733398
4
train loss item: 0.3957895040512085
5
train loss item: 0.31403103470802307
6
train loss item: 0.262953519821167
7
train loss item: 0.7747655510902405
8
train loss item: 0.13089270889759064
9
train loss item: 0.2451736181974411
10
train loss item: 0.33031177520751953
11
train loss item: 0.27780812978744507
12
train loss item: 0.1306387037038803
13
train loss item: 0.46164533495903015
14
train loss item: 0.2301425337791443
15
train loss item: 0.6123236417770386
16
train loss item: 0.09576097130775452
17
train loss item: 0.2856474220752716
18
train loss item: 0.3092009723186493
19
train loss item: 0.27329301834106445
20
train loss item: 0.23181676864624023
21
train loss item: 0.13390418887138367
22
train loss item: 0.9727742671966553
23
train loss item: 0.8899762034416199
24
train loss item: 0.5489933490753174
25
train loss item: 0.19189727306365967
26
train loss item: 0.18529058992862701
27
train loss item: 0.21451787650585175
28
train loss item: 0.08972897380590439
29
train loss item: 0.7168521881103516
30
train loss item: 2.2351272106170654
31
train loss item: 0.5490198731422424
32
train loss item: 0.09685631841421127
33
train loss item: 0.403408020734787
34
train loss item: 0.16087408363819122
35
train loss item: 2.3763365745544434
36
train loss item: 0.42096149921417236
37
train loss item: 0.4036487936973572
38
train loss item: 0.42236897349357605
39
train loss item: 0.21224157512187958
40
train loss item: 0.17197953164577484
41
train loss item: 0.24126121401786804
42
train loss item: 0.27099063992500305
43
train loss item: 0.17738878726959229
44
train loss item: 0.6273206472396851
45
train loss item: 0.11679742485284805
46
train loss item: 0.10755547136068344
47
train loss item: 0.35630759596824646
48
train loss item: 0.21105434000492096
49
train loss item: 0.1471274346113205
50
train loss item: 0.28953617811203003
51
train loss item: 0.8902939558029175
52
train loss item: 0.09824545681476593
53
train loss item: 0.1461273729801178
54
train loss item: 2.260432004928589
55
train loss item: 0.19929270446300507
56
train loss item: 0.23348575830459595
57
train loss item: 0.2301606684923172
58
train loss item: 0.16005335748195648
59
train loss item: 0.11388082802295685
60
train loss item: 0.8489227890968323
61
train loss item: 2.201129198074341
62
train loss item: 0.21511805057525635
63
train loss item: 0.36784783005714417
64
train loss item: 0.16179658472537994
65
train loss item: 0.5209292769432068
66
train loss item: 0.3803030252456665
67
train loss item: 0.20467345416545868
68
train loss item: 0.2940838932991028
69
train loss item: 0.3174760043621063
70
train loss item: 0.2646987736225128
71
train loss item: 0.15597966313362122
72
train loss item: 0.16873344779014587
73
train loss item: 0.29317888617515564
74
train loss item: 0.0891968160867691
75
train loss item: 0.11274521052837372
76
train loss item: 0.8659021854400635
77
train loss item: 1.3304613828659058
78
train loss item: 0.08660560101270676
79
train loss item: 0.2819216549396515
80
train loss item: 0.10489638894796371
81
train loss item: 0.19271573424339294
82
train loss item: 0.19334614276885986
83
train loss item: 0.6004809737205505
84
train loss item: 0.3960920572280884
85
train loss item: 0.5515540838241577
86
train loss item: 4.274360179901123
87
train loss item: 0.1591634750366211
88
train loss item: 0.3880052864551544
epoch train loss: 0.4720036012403081
testing phase
test loss item: 0.18348433077335358
test loss item: 0.11510562151670456
test loss item: 0.5419729351997375
test loss item: 0.22665712237358093
test loss item: 0.23980066180229187
test loss item: 0.1293797343969345
test loss item: 1.4342507123947144
test loss item: 0.4809249937534332
test loss item: 0.2085464894771576
test loss item: 0.3866567015647888
test loss item: 0.8251644372940063
test loss item: 0.1554478257894516
test loss item: 0.17949530482292175
test loss item: 0.3037634789943695
test loss item: 0.17468437552452087
test loss item: 0.09083236008882523
test loss item: 0.2920038104057312
test loss item: 0.4433206021785736
test loss item: 0.6218668222427368
test loss item: 0.26290416717529297
test loss item: 0.6864579916000366
test loss item: 0.3642052412033081
test loss item: 0.26166555285453796
test loss item: 0.18257519602775574
test loss item: 0.21825212240219116
test loss item: 0.2265649437904358
test loss item: 0.3297727704048157
test loss item: 0.18748043477535248
test loss item: 0.3232249319553375
test loss item: 0.3504441976547241
test loss item: 0.7019555568695068
test loss item: 0.08420228213071823
test loss item: 0.1672554910182953
test loss item: 0.5485177040100098
test loss item: 0.3991730809211731
test loss item: 0.40678176283836365
test loss item: 0.748294472694397
test loss item: 1.37649405002594
test loss item: 0.4534584879875183
test loss item: 0.27293187379837036
test loss item: 0.30285653471946716
test loss item: 0.16441881656646729
test loss item: 0.3552872836589813
test loss item: 0.19664917886257172
test loss item: 0.5627227425575256
test loss item: 0.40645602345466614
test loss item: 0.2742393910884857
test loss item: 0.22596998512744904
test loss item: 0.45694252848625183
test loss item: 0.6654991507530212
test loss item: 0.2952052056789398
test loss item: 0.14104680716991425
test loss item: 0.23023276031017303
test loss item: 0.13874505460262299
test loss item: 0.28362956643104553
test loss item: 0.7875688076019287
test loss item: 0.5275540351867676
test loss item: 0.24544750154018402
test loss item: 0.23779217898845673
test loss item: 0.20549727976322174
test loss item: 0.45427918434143066
test loss item: 0.24179457128047943
test loss item: 0.20912206172943115
test loss item: 0.2532021701335907
test loss item: 0.7266286015510559
test loss item: 0.2982771098613739
test loss item: 0.3166309595108032
test loss item: 0.2560988962650299
test loss item: 0.5175477266311646
test loss item: 0.38463422656059265
test loss item: 0.07660068571567535
test loss item: 0.8480150103569031
test loss item: 0.2936350703239441
test loss item: 0.3820117712020874
test loss item: 0.1507181078195572
test loss item: 0.14905855059623718
test loss item: 0.18213635683059692
test loss item: 1.346431016921997
test loss item: 0.4284701645374298
test loss item: 0.18537011742591858
test loss item: 0.10206563770771027
test loss item: 0.8871627449989319
test loss item: 0.8057780861854553
test loss item: 0.9271189570426941
test loss item: 0.2159537971019745
test loss item: 0.22424805164337158
test loss item: 0.10247793793678284
test loss item: 0.09984402358531952
test loss item: 0.17993974685668945
Epoch [18/50], Training Loss: 0.4720, Testing Loss: 0.3768
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 19/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.42053520679473877
1
train loss item: 1.1597177982330322
2
train loss item: 0.22819824516773224
3
train loss item: 0.5061456561088562
4
train loss item: 0.3910525143146515
5
train loss item: 0.30629444122314453
6
train loss item: 0.24850471317768097
7
train loss item: 0.7605426907539368
8
train loss item: 0.13789153099060059
9
train loss item: 0.2382347285747528
10
train loss item: 0.32329806685447693
11
train loss item: 0.27076056599617004
12
train loss item: 0.12450102716684341
13
train loss item: 0.4545871317386627
14
train loss item: 0.22854416072368622
15
train loss item: 0.6111112833023071
16
train loss item: 0.09031890332698822
17
train loss item: 0.2871676981449127
18
train loss item: 0.3047541379928589
19
train loss item: 0.2636529505252838
20
train loss item: 0.2248612642288208
21
train loss item: 0.14158283174037933
22
train loss item: 0.9635106921195984
23
train loss item: 0.871817409992218
24
train loss item: 0.5351500511169434
25
train loss item: 0.19524738192558289
26
train loss item: 0.1800796538591385
27
train loss item: 0.21134576201438904
28
train loss item: 0.08475852012634277
29
train loss item: 0.7140378952026367
30
train loss item: 2.2067222595214844
31
train loss item: 0.5397144556045532
32
train loss item: 0.09930341690778732
33
train loss item: 0.4078303873538971
34
train loss item: 0.16798558831214905
35
train loss item: 2.352930784225464
36
train loss item: 0.414813756942749
37
train loss item: 0.3965860605239868
38
train loss item: 0.4137406647205353
39
train loss item: 0.21000978350639343
40
train loss item: 0.1795577108860016
41
train loss item: 0.2398437112569809
42
train loss item: 0.2658243179321289
43
train loss item: 0.17831212282180786
44
train loss item: 0.6160845756530762
45
train loss item: 0.11417913436889648
46
train loss item: 0.10610344260931015
47
train loss item: 0.3542323410511017
48
train loss item: 0.20489002764225006
49
train loss item: 0.15109537541866302
50
train loss item: 0.28608036041259766
51
train loss item: 0.8806806206703186
52
train loss item: 0.09407838433980942
53
train loss item: 0.15465781092643738
54
train loss item: 2.2359819412231445
55
train loss item: 0.19288288056850433
56
train loss item: 0.23091502487659454
57
train loss item: 0.22123248875141144
58
train loss item: 0.1564403623342514
59
train loss item: 0.11114335060119629
60
train loss item: 0.8411253690719604
61
train loss item: 2.174906015396118
62
train loss item: 0.21062704920768738
63
train loss item: 0.3633391559123993
64
train loss item: 0.16799022257328033
65
train loss item: 0.5154494643211365
66
train loss item: 0.3719746172428131
67
train loss item: 0.20122112333774567
68
train loss item: 0.2931426465511322
69
train loss item: 0.3091174364089966
70
train loss item: 0.2617826461791992
71
train loss item: 0.15526650846004486
72
train loss item: 0.172787144780159
73
train loss item: 0.2870462238788605
74
train loss item: 0.09384359419345856
75
train loss item: 0.11185240000486374
76
train loss item: 0.8474799394607544
77
train loss item: 1.3258366584777832
78
train loss item: 0.07973498851060867
79
train loss item: 0.2708095610141754
80
train loss item: 0.10327880084514618
81
train loss item: 0.19125685095787048
82
train loss item: 0.19442255795001984
83
train loss item: 0.594285786151886
84
train loss item: 0.3889940083026886
85
train loss item: 0.5348948836326599
86
train loss item: 4.238255977630615
87
train loss item: 0.17319731414318085
88
train loss item: 0.3827841281890869
epoch train loss: 0.46650293402457504
testing phase
test loss item: 0.1796455681324005
test loss item: 0.10374832898378372
test loss item: 0.541679859161377
test loss item: 0.2224833369255066
test loss item: 0.23402677476406097
test loss item: 0.11975046247243881
test loss item: 1.4531331062316895
test loss item: 0.5038288831710815
test loss item: 0.20977464318275452
test loss item: 0.38745802640914917
test loss item: 0.8212665915489197
test loss item: 0.15104606747627258
test loss item: 0.17191623151302338
test loss item: 0.2901327311992645
test loss item: 0.16748641431331635
test loss item: 0.08334480226039886
test loss item: 0.28896117210388184
test loss item: 0.44328126311302185
test loss item: 0.6309736371040344
test loss item: 0.2518691122531891
test loss item: 0.6790294051170349
test loss item: 0.3632264733314514
test loss item: 0.2506265938282013
test loss item: 0.17258775234222412
test loss item: 0.21607932448387146
test loss item: 0.21940480172634125
test loss item: 0.3238063156604767
test loss item: 0.18153886497020721
test loss item: 0.3169734477996826
test loss item: 0.3491976261138916
test loss item: 0.7044740915298462
test loss item: 0.07789845764636993
test loss item: 0.15528123080730438
test loss item: 0.546210527420044
test loss item: 0.3979688286781311
test loss item: 0.4128987789154053
test loss item: 0.7577526569366455
test loss item: 1.3739778995513916
test loss item: 0.45050546526908875
test loss item: 0.2648037374019623
test loss item: 0.30080801248550415
test loss item: 0.1587146520614624
test loss item: 0.3572981655597687
test loss item: 0.1979953944683075
test loss item: 0.555185079574585
test loss item: 0.39714571833610535
test loss item: 0.267363578081131
test loss item: 0.21641327440738678
test loss item: 0.45507586002349854
test loss item: 0.6680450439453125
test loss item: 0.2947753071784973
test loss item: 0.1333453208208084
test loss item: 0.23160165548324585
test loss item: 0.1428762972354889
test loss item: 0.2838182747364044
test loss item: 0.7832555174827576
test loss item: 0.5355265140533447
test loss item: 0.2432313859462738
test loss item: 0.23146764934062958
test loss item: 0.20379875600337982
test loss item: 0.4573417603969574
test loss item: 0.2370515614748001
test loss item: 0.20120738446712494
test loss item: 0.24815773963928223
test loss item: 0.7228171825408936
test loss item: 0.29937613010406494
test loss item: 0.30751505494117737
test loss item: 0.253542423248291
test loss item: 0.5094723701477051
test loss item: 0.3956661820411682
test loss item: 0.07332807034254074
test loss item: 0.8620200157165527
test loss item: 0.2808469533920288
test loss item: 0.37167903780937195
test loss item: 0.14801114797592163
test loss item: 0.14070846140384674
test loss item: 0.1730032116174698
test loss item: 1.336911916732788
test loss item: 0.41249388456344604
test loss item: 0.17959333956241608
test loss item: 0.09374852478504181
test loss item: 0.8953176140785217
test loss item: 0.8155618906021118
test loss item: 0.9239270091056824
test loss item: 0.20737913250923157
test loss item: 0.21958525478839874
test loss item: 0.09593568742275238
test loss item: 0.09451410174369812
test loss item: 0.18001437187194824
Epoch [19/50], Training Loss: 0.4665, Testing Loss: 0.3738
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 20/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4186345934867859
1
train loss item: 1.14072847366333
2
train loss item: 0.22305162250995636
3
train loss item: 0.49804890155792236
4
train loss item: 0.38286036252975464
5
train loss item: 0.3049800992012024
6
train loss item: 0.24090026319026947
7
train loss item: 0.7480016350746155
8
train loss item: 0.1365986317396164
9
train loss item: 0.23364688456058502
10
train loss item: 0.3198690116405487
11
train loss item: 0.2651454508304596
12
train loss item: 0.12351397424936295
13
train loss item: 0.44853460788726807
14
train loss item: 0.22549749910831451
15
train loss item: 0.6042059063911438
16
train loss item: 0.07724828273057938
17
train loss item: 0.28413689136505127
18
train loss item: 0.30238479375839233
19
train loss item: 0.25632598996162415
20
train loss item: 0.22084854543209076
21
train loss item: 0.14506244659423828
22
train loss item: 0.9424607157707214
23
train loss item: 0.8559910655021667
24
train loss item: 0.5218068957328796
25
train loss item: 0.194849893450737
26
train loss item: 0.18023507297039032
27
train loss item: 0.20797622203826904
28
train loss item: 0.07312483340501785
29
train loss item: 0.704007089138031
30
train loss item: 2.1808135509490967
31
train loss item: 0.5339425802230835
32
train loss item: 0.10330215096473694
33
train loss item: 0.4074437916278839
34
train loss item: 0.1725003570318222
35
train loss item: 2.3324530124664307
36
train loss item: 0.4123521149158478
37
train loss item: 0.39061862230300903
38
train loss item: 0.40906599164009094
39
train loss item: 0.2073066085577011
40
train loss item: 0.17681756615638733
41
train loss item: 0.23905211687088013
42
train loss item: 0.26270338892936707
43
train loss item: 0.17740729451179504
44
train loss item: 0.6071147918701172
45
train loss item: 0.11381304264068604
46
train loss item: 0.10771660506725311
47
train loss item: 0.3470659554004669
48
train loss item: 0.20009371638298035
49
train loss item: 0.15323320031166077
50
train loss item: 0.2829109728336334
51
train loss item: 0.8678979277610779
52
train loss item: 0.08056525886058807
53
train loss item: 0.15257522463798523
54
train loss item: 2.214986801147461
55
train loss item: 0.18609443306922913
56
train loss item: 0.2285756915807724
57
train loss item: 0.21740703284740448
58
train loss item: 0.15467624366283417
59
train loss item: 0.10771612077951431
60
train loss item: 0.8286632895469666
61
train loss item: 2.1508615016937256
62
train loss item: 0.20810087025165558
63
train loss item: 0.35649722814559937
64
train loss item: 0.16970032453536987
65
train loss item: 0.5061180591583252
66
train loss item: 0.3694486916065216
67
train loss item: 0.19986878335475922
68
train loss item: 0.28714361786842346
69
train loss item: 0.3021252453327179
70
train loss item: 0.25553786754608154
71
train loss item: 0.14888355135917664
72
train loss item: 0.17220531404018402
73
train loss item: 0.282903254032135
74
train loss item: 0.09262540191411972
75
train loss item: 0.10944978892803192
76
train loss item: 0.8313612937927246
77
train loss item: 1.3142672777175903
78
train loss item: 0.07139579206705093
79
train loss item: 0.2619238495826721
80
train loss item: 0.10329551249742508
81
train loss item: 0.1909336894750595
82
train loss item: 0.19223318994045258
83
train loss item: 0.5837317109107971
84
train loss item: 0.3853146731853485
85
train loss item: 0.52237868309021
86
train loss item: 4.207267761230469
87
train loss item: 0.17198409140110016
88
train loss item: 0.37978923320770264
epoch train loss: 0.46027986931332043
testing phase
test loss item: 0.17638766765594482
test loss item: 0.0940273255109787
test loss item: 0.5388562679290771
test loss item: 0.2234748899936676
test loss item: 0.22935692965984344
test loss item: 0.11344993114471436
test loss item: 1.4535800218582153
test loss item: 0.5060348510742188
test loss item: 0.2078380286693573
test loss item: 0.3824102580547333
test loss item: 0.8197760581970215
test loss item: 0.1570892035961151
test loss item: 0.1685282289981842
test loss item: 0.2803095281124115
test loss item: 0.16028301417827606
test loss item: 0.07765846699476242
test loss item: 0.28758683800697327
test loss item: 0.4384598731994629
test loss item: 0.629286527633667
test loss item: 0.24640630185604095
test loss item: 0.6677966713905334
test loss item: 0.36567485332489014
test loss item: 0.2447827160358429
test loss item: 0.1641080230474472
test loss item: 0.21379433572292328
test loss item: 0.21242733299732208
test loss item: 0.31710976362228394
test loss item: 0.17727747559547424
test loss item: 0.31169962882995605
test loss item: 0.3442082107067108
test loss item: 0.7043434381484985
test loss item: 0.07516776770353317
test loss item: 0.14390939474105835
test loss item: 0.5437762141227722
test loss item: 0.39322659373283386
test loss item: 0.4072454869747162
test loss item: 0.7550532817840576
test loss item: 1.3760794401168823
test loss item: 0.4458667039871216
test loss item: 0.25771966576576233
test loss item: 0.29783323407173157
test loss item: 0.15919135510921478
test loss item: 0.3522144556045532
test loss item: 0.2056010216474533
test loss item: 0.544457733631134
test loss item: 0.3909681439399719
test loss item: 0.26399046182632446
test loss item: 0.21014505624771118
test loss item: 0.44915199279785156
test loss item: 0.6670264601707458
test loss item: 0.28594326972961426
test loss item: 0.12953145802021027
test loss item: 0.23069459199905396
test loss item: 0.16773642599582672
test loss item: 0.2803969979286194
test loss item: 0.7787526249885559
test loss item: 0.5339746475219727
test loss item: 0.23363865911960602
test loss item: 0.22521740198135376
test loss item: 0.20066827535629272
test loss item: 0.4504713714122772
test loss item: 0.2344314157962799
test loss item: 0.19604410231113434
test loss item: 0.2445070445537567
test loss item: 0.7182873487472534
test loss item: 0.30990585684776306
test loss item: 0.3025413453578949
test loss item: 0.2517513930797577
test loss item: 0.5020843744277954
test loss item: 0.39718174934387207
test loss item: 0.0733160525560379
test loss item: 0.861126720905304
test loss item: 0.2758985161781311
test loss item: 0.3652048707008362
test loss item: 0.14916865527629852
test loss item: 0.14017851650714874
test loss item: 0.16602113842964172
test loss item: 1.3371585607528687
test loss item: 0.4050317108631134
test loss item: 0.176937535405159
test loss item: 0.08630380779504776
test loss item: 0.8992632031440735
test loss item: 0.8139707446098328
test loss item: 0.9248888492584229
test loss item: 0.19998522102832794
test loss item: 0.2190178781747818
test loss item: 0.08759597688913345
test loss item: 0.08628212660551071
test loss item: 0.17455610632896423
Epoch [20/50], Training Loss: 0.4603, Testing Loss: 0.3704
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 21/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41640374064445496
1
train loss item: 1.119391918182373
2
train loss item: 0.21440869569778442
3
train loss item: 0.48775598406791687
4
train loss item: 0.3719550669193268
5
train loss item: 0.3045963943004608
6
train loss item: 0.2375873327255249
7
train loss item: 0.7348705530166626
8
train loss item: 0.12609289586544037
9
train loss item: 0.23164218664169312
10
train loss item: 0.3127095699310303
11
train loss item: 0.25894322991371155
12
train loss item: 0.12733158469200134
13
train loss item: 0.4394032955169678
14
train loss item: 0.2166285663843155
15
train loss item: 0.5920383930206299
16
train loss item: 0.07065881043672562
17
train loss item: 0.27498817443847656
18
train loss item: 0.30056464672088623
19
train loss item: 0.2519527077674866
20
train loss item: 0.21859842538833618
21
train loss item: 0.13032877445220947
22
train loss item: 0.9152283668518066
23
train loss item: 0.8363592624664307
24
train loss item: 0.5120636224746704
25
train loss item: 0.18966348469257355
26
train loss item: 0.17588409781455994
27
train loss item: 0.20096588134765625
28
train loss item: 0.06780070811510086
29
train loss item: 0.6862668395042419
30
train loss item: 2.1548123359680176
31
train loss item: 0.5269570350646973
32
train loss item: 0.10596298426389694
33
train loss item: 0.3920802175998688
34
train loss item: 0.1646507829427719
35
train loss item: 2.312899351119995
36
train loss item: 0.41017064452171326
37
train loss item: 0.3832356631755829
38
train loss item: 0.4064844846725464
39
train loss item: 0.20255962014198303
40
train loss item: 0.16542890667915344
41
train loss item: 0.23442009091377258
42
train loss item: 0.2627905309200287
43
train loss item: 0.16837994754314423
44
train loss item: 0.5973713397979736
45
train loss item: 0.11351708322763443
46
train loss item: 0.10392486304044724
47
train loss item: 0.33713704347610474
48
train loss item: 0.1957883983850479
49
train loss item: 0.1453767567873001
50
train loss item: 0.2792120575904846
51
train loss item: 0.8515661954879761
52
train loss item: 0.06956356018781662
53
train loss item: 0.14045172929763794
54
train loss item: 2.1955366134643555
55
train loss item: 0.17828109860420227
56
train loss item: 0.22141538560390472
57
train loss item: 0.218672975897789
58
train loss item: 0.1482677310705185
59
train loss item: 0.10485632717609406
60
train loss item: 0.8110052347183228
61
train loss item: 2.125281572341919
62
train loss item: 0.20549090206623077
63
train loss item: 0.3482033312320709
64
train loss item: 0.15755510330200195
65
train loss item: 0.4946193993091583
66
train loss item: 0.36996790766716003
67
train loss item: 0.195303812623024
68
train loss item: 0.27865079045295715
69
train loss item: 0.2969950735569
70
train loss item: 0.24781212210655212
71
train loss item: 0.1449149250984192
72
train loss item: 0.16481146216392517
73
train loss item: 0.2803807258605957
74
train loss item: 0.09140443056821823
75
train loss item: 0.10661496967077255
76
train loss item: 0.8145416975021362
77
train loss item: 1.2978779077529907
78
train loss item: 0.07096793502569199
79
train loss item: 0.25466981530189514
80
train loss item: 0.10985112190246582
81
train loss item: 0.18901485204696655
82
train loss item: 0.18055026233196259
83
train loss item: 0.5704338550567627
84
train loss item: 0.383442223072052
85
train loss item: 0.5103241801261902
86
train loss item: 4.17891263961792
87
train loss item: 0.15461629629135132
88
train loss item: 0.3801606297492981
epoch train loss: 0.4520138218329194
testing phase
test loss item: 0.1750878393650055
test loss item: 0.0940389558672905
test loss item: 0.5341463088989258
test loss item: 0.23342886567115784
test loss item: 0.2266819179058075
test loss item: 0.11051688343286514
test loss item: 1.43315589427948
test loss item: 0.48335331678390503
test loss item: 0.20382845401763916
test loss item: 0.37451618909835815
test loss item: 0.8165093064308167
test loss item: 0.17438682913780212
test loss item: 0.1693757176399231
test loss item: 0.2731770873069763
test loss item: 0.15784607827663422
test loss item: 0.07544548809528351
test loss item: 0.28203532099723816
test loss item: 0.43146106600761414
test loss item: 0.6152457594871521
test loss item: 0.24437710642814636
test loss item: 0.6574458479881287
test loss item: 0.36871659755706787
test loss item: 0.24414674937725067
test loss item: 0.16092433035373688
test loss item: 0.20927020907402039
test loss item: 0.20822200179100037
test loss item: 0.31049689650535583
test loss item: 0.17456874251365662
test loss item: 0.30854225158691406
test loss item: 0.3368338644504547
test loss item: 0.6991448402404785
test loss item: 0.07632358372211456
test loss item: 0.13988447189331055
test loss item: 0.5441704988479614
test loss item: 0.3874330222606659
test loss item: 0.3944566249847412
test loss item: 0.739166259765625
test loss item: 1.3762325048446655
test loss item: 0.441924124956131
test loss item: 0.25273868441581726
test loss item: 0.2905353903770447
test loss item: 0.16726747155189514
test loss item: 0.34466493129730225
test loss item: 0.2161770910024643
test loss item: 0.5344182252883911
test loss item: 0.3838872015476227
test loss item: 0.2654845416545868
test loss item: 0.20875176787376404
test loss item: 0.4404197931289673
test loss item: 0.6601808667182922
test loss item: 0.2753627300262451
test loss item: 0.1288079470396042
test loss item: 0.22555068135261536
test loss item: 0.20747199654579163
test loss item: 0.2761628329753876
test loss item: 0.7730901837348938
test loss item: 0.5223067998886108
test loss item: 0.2260216623544693
test loss item: 0.2195744812488556
test loss item: 0.19945475459098816
test loss item: 0.43994325399398804
test loss item: 0.2277563512325287
test loss item: 0.19467602670192719
test loss item: 0.24292440712451935
test loss item: 0.7115687727928162
test loss item: 0.3319358825683594
test loss item: 0.298123300075531
test loss item: 0.24757352471351624
test loss item: 0.4970852732658386
test loss item: 0.3869020342826843
test loss item: 0.07339438050985336
test loss item: 0.8416044116020203
test loss item: 0.27713248133659363
test loss item: 0.36070623993873596
test loss item: 0.1473676562309265
test loss item: 0.14661496877670288
test loss item: 0.16301290690898895
test loss item: 1.340161919593811
test loss item: 0.40266719460487366
test loss item: 0.17666909098625183
test loss item: 0.08088276535272598
test loss item: 0.8942016363143921
test loss item: 0.8002728819847107
test loss item: 0.9255331754684448
test loss item: 0.19453150033950806
test loss item: 0.2173181176185608
test loss item: 0.0804792270064354
test loss item: 0.07678651809692383
test loss item: 0.17436207830905914
Epoch [21/50], Training Loss: 0.4520, Testing Loss: 0.3669
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 22/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41144654154777527
1
train loss item: 1.094984531402588
2
train loss item: 0.2121330201625824
3
train loss item: 0.47851625084877014
4
train loss item: 0.362591952085495
5
train loss item: 0.3016619384288788
6
train loss item: 0.24170048534870148
7
train loss item: 0.7217493653297424
8
train loss item: 0.11658535897731781
9
train loss item: 0.23130053281784058
10
train loss item: 0.3030007481575012
11
train loss item: 0.2530536353588104
12
train loss item: 0.12788181006908417
13
train loss item: 0.4315733015537262
14
train loss item: 0.20675233006477356
15
train loss item: 0.5740087032318115
16
train loss item: 0.06723037362098694
17
train loss item: 0.2672814428806305
18
train loss item: 0.296733558177948
19
train loss item: 0.24788926541805267
20
train loss item: 0.2169010192155838
21
train loss item: 0.11954618990421295
22
train loss item: 0.8821003437042236
23
train loss item: 0.8162115812301636
24
train loss item: 0.5027693510055542
25
train loss item: 0.19164541363716125
26
train loss item: 0.17384153604507446
27
train loss item: 0.1950889527797699
28
train loss item: 0.06470195949077606
29
train loss item: 0.6623509526252747
30
train loss item: 2.1286048889160156
31
train loss item: 0.5206362009048462
32
train loss item: 0.11222147941589355
33
train loss item: 0.37518903613090515
34
train loss item: 0.1522759050130844
35
train loss item: 2.293508291244507
36
train loss item: 0.40955638885498047
37
train loss item: 0.377056747674942
38
train loss item: 0.41084516048431396
39
train loss item: 0.19852013885974884
40
train loss item: 0.16488471627235413
41
train loss item: 0.22943717241287231
42
train loss item: 0.26447972655296326
43
train loss item: 0.16216230392456055
44
train loss item: 0.5891748666763306
45
train loss item: 0.11222483962774277
46
train loss item: 0.10673341155052185
47
train loss item: 0.32848474383354187
48
train loss item: 0.19527842104434967
49
train loss item: 0.13888679444789886
50
train loss item: 0.2725711464881897
51
train loss item: 0.8329513072967529
52
train loss item: 0.06434579938650131
53
train loss item: 0.13917198777198792
54
train loss item: 2.1768670082092285
55
train loss item: 0.17697839438915253
56
train loss item: 0.21474523842334747
57
train loss item: 0.22070923447608948
58
train loss item: 0.14543955028057098
59
train loss item: 0.10570409148931503
60
train loss item: 0.7885749936103821
61
train loss item: 2.1018354892730713
62
train loss item: 0.20023974776268005
63
train loss item: 0.3387199640274048
64
train loss item: 0.14757339656352997
65
train loss item: 0.48160815238952637
66
train loss item: 0.3718363642692566
67
train loss item: 0.19213774800300598
68
train loss item: 0.2697829306125641
69
train loss item: 0.2924641966819763
70
train loss item: 0.24292965233325958
71
train loss item: 0.14076396822929382
72
train loss item: 0.15681767463684082
73
train loss item: 0.27878326177597046
74
train loss item: 0.0913882628083229
75
train loss item: 0.1034194678068161
76
train loss item: 0.7981931567192078
77
train loss item: 1.2788671255111694
78
train loss item: 0.07204973697662354
79
train loss item: 0.24791033565998077
80
train loss item: 0.11600466817617416
81
train loss item: 0.19130583107471466
82
train loss item: 0.17084261775016785
83
train loss item: 0.5553798675537109
84
train loss item: 0.38318607211112976
85
train loss item: 0.49885618686676025
86
train loss item: 4.153322219848633
87
train loss item: 0.14908504486083984
88
train loss item: 0.3792281150817871
epoch train loss: 0.4447863335522373
testing phase
test loss item: 0.17490990459918976
test loss item: 0.09828004986047745
test loss item: 0.5347983837127686
test loss item: 0.23852965235710144
test loss item: 0.2252814918756485
test loss item: 0.10791128128767014
test loss item: 1.4027206897735596
test loss item: 0.4470648467540741
test loss item: 0.20181144773960114
test loss item: 0.37047430872917175
test loss item: 0.8132152557373047
test loss item: 0.18451017141342163
test loss item: 0.1713368445634842
test loss item: 0.2656124532222748
test loss item: 0.158780038356781
test loss item: 0.07503098994493484
test loss item: 0.2711729407310486
test loss item: 0.4298671782016754
test loss item: 0.5957632064819336
test loss item: 0.2409614771604538
test loss item: 0.6582663059234619
test loss item: 0.3637545108795166
test loss item: 0.2451055347919464
test loss item: 0.15900951623916626
test loss item: 0.20462173223495483
test loss item: 0.20567554235458374
test loss item: 0.30527201294898987
test loss item: 0.17064891755580902
test loss item: 0.30630630254745483
test loss item: 0.33004677295684814
test loss item: 0.692979097366333
test loss item: 0.07696942985057831
test loss item: 0.13968785107135773
test loss item: 0.5469610691070557
test loss item: 0.386927992105484
test loss item: 0.38511788845062256
test loss item: 0.7181383967399597
test loss item: 1.377922534942627
test loss item: 0.4400263726711273
test loss item: 0.24856245517730713
test loss item: 0.28056955337524414
test loss item: 0.1720297634601593
test loss item: 0.3434559106826782
test loss item: 0.2171040028333664
test loss item: 0.5324289798736572
test loss item: 0.37217986583709717
test loss item: 0.26722726225852966
test loss item: 0.2062830924987793
test loss item: 0.43519124388694763
test loss item: 0.6518807411193848
test loss item: 0.2729450464248657
test loss item: 0.12529495358467102
test loss item: 0.2185308337211609
test loss item: 0.22552520036697388
test loss item: 0.27506014704704285
test loss item: 0.7727529406547546
test loss item: 0.5072575211524963
test loss item: 0.22385947406291962
test loss item: 0.21484489738941193
test loss item: 0.2026137262582779
test loss item: 0.4369010627269745
test loss item: 0.2142941951751709
test loss item: 0.19290068745613098
test loss item: 0.24495618045330048
test loss item: 0.7087470293045044
test loss item: 0.34221214056015015
test loss item: 0.289747029542923
test loss item: 0.24146169424057007
test loss item: 0.4972084164619446
test loss item: 0.37062928080558777
test loss item: 0.0701814591884613
test loss item: 0.8113690614700317
test loss item: 0.2771163880825043
test loss item: 0.3552256226539612
test loss item: 0.13956347107887268
test loss item: 0.14867530763149261
test loss item: 0.15997396409511566
test loss item: 1.348995327949524
test loss item: 0.3979899287223816
test loss item: 0.17526116967201233
test loss item: 0.07795408368110657
test loss item: 0.8837649822235107
test loss item: 0.78306645154953
test loss item: 0.928276538848877
test loss item: 0.18933448195457458
test loss item: 0.21208912134170532
test loss item: 0.07742633670568466
test loss item: 0.06883101165294647
test loss item: 0.18475103378295898
Epoch [22/50], Training Loss: 0.4448, Testing Loss: 0.3631
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 23/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.40396958589553833
1
train loss item: 1.0697921514511108
2
train loss item: 0.2083192765712738
3
train loss item: 0.47421130537986755
4
train loss item: 0.35291537642478943
5
train loss item: 0.2936881184577942
6
train loss item: 0.23852969706058502
7
train loss item: 0.7101091146469116
8
train loss item: 0.1126876175403595
9
train loss item: 0.22881536185741425
10
train loss item: 0.29500579833984375
11
train loss item: 0.2478584498167038
12
train loss item: 0.12140058726072311
13
train loss item: 0.4295419156551361
14
train loss item: 0.1996072232723236
15
train loss item: 0.5521791577339172
16
train loss item: 0.062461525201797485
17
train loss item: 0.2606273591518402
18
train loss item: 0.28810158371925354
19
train loss item: 0.23911117017269135
20
train loss item: 0.20631492137908936
21
train loss item: 0.11996061354875565
22
train loss item: 0.8488545417785645
23
train loss item: 0.802066445350647
24
train loss item: 0.4885416626930237
25
train loss item: 0.19137711822986603
26
train loss item: 0.17298883199691772
27
train loss item: 0.1918407529592514
28
train loss item: 0.060359012335538864
29
train loss item: 0.638282835483551
30
train loss item: 2.1033506393432617
31
train loss item: 0.5156278610229492
32
train loss item: 0.11111721396446228
33
train loss item: 0.3714994788169861
34
train loss item: 0.140583798289299
35
train loss item: 2.2748570442199707
36
train loss item: 0.4125477373600006
37
train loss item: 0.3734102249145508
38
train loss item: 0.4223651885986328
39
train loss item: 0.1925494223833084
40
train loss item: 0.1637251079082489
41
train loss item: 0.2251165509223938
42
train loss item: 0.2615961730480194
43
train loss item: 0.15958504378795624
44
train loss item: 0.5849887132644653
45
train loss item: 0.11088026314973831
46
train loss item: 0.10747332125902176
47
train loss item: 0.3194408714771271
48
train loss item: 0.19341328740119934
49
train loss item: 0.13717733323574066
50
train loss item: 0.26113155484199524
51
train loss item: 0.8143702149391174
52
train loss item: 0.0634276419878006
53
train loss item: 0.14183209836483002
54
train loss item: 2.159266233444214
55
train loss item: 0.1742973029613495
56
train loss item: 0.21013231575489044
57
train loss item: 0.21578603982925415
58
train loss item: 0.14193402230739594
59
train loss item: 0.1086384654045105
60
train loss item: 0.7666960954666138
61
train loss item: 2.0855090618133545
62
train loss item: 0.18950140476226807
63
train loss item: 0.32789531350135803
64
train loss item: 0.1457996666431427
65
train loss item: 0.4689347743988037
66
train loss item: 0.3752027153968811
67
train loss item: 0.18887493014335632
68
train loss item: 0.26047632098197937
69
train loss item: 0.2853661775588989
70
train loss item: 0.23567864298820496
71
train loss item: 0.13013975322246552
72
train loss item: 0.1536162793636322
73
train loss item: 0.27455684542655945
74
train loss item: 0.09045331180095673
75
train loss item: 0.10077333450317383
76
train loss item: 0.7851982116699219
77
train loss item: 1.260197401046753
78
train loss item: 0.06623996794223785
79
train loss item: 0.2400447279214859
80
train loss item: 0.11045979708433151
81
train loss item: 0.1891849786043167
82
train loss item: 0.16870316863059998
83
train loss item: 0.5401811003684998
84
train loss item: 0.3849189877510071
85
train loss item: 0.4884636700153351
86
train loss item: 4.130306243896484
87
train loss item: 0.15096493065357208
88
train loss item: 0.3699875771999359
epoch train loss: 0.437595119846336
testing phase
test loss item: 0.17677919566631317
test loss item: 0.10886308550834656
test loss item: 0.5367026925086975
test loss item: 0.23387488722801208
test loss item: 0.23080217838287354
test loss item: 0.1176082044839859
test loss item: 1.389513373374939
test loss item: 0.43039652705192566
test loss item: 0.20097039639949799
test loss item: 0.3690469264984131
test loss item: 0.7986257672309875
test loss item: 0.1776563823223114
test loss item: 0.17236541211605072
test loss item: 0.2569037079811096
test loss item: 0.16653388738632202
test loss item: 0.07796615362167358
test loss item: 0.2628238797187805
test loss item: 0.4350190758705139
test loss item: 0.5825244188308716
test loss item: 0.23588629066944122
test loss item: 0.6736553311347961
test loss item: 0.3538987934589386
test loss item: 0.2468380481004715
test loss item: 0.1645895093679428
test loss item: 0.20357608795166016
test loss item: 0.20596732199192047
test loss item: 0.3016108274459839
test loss item: 0.1741466522216797
test loss item: 0.30727115273475647
test loss item: 0.32529494166374207
test loss item: 0.6840456128120422
test loss item: 0.07432079315185547
test loss item: 0.14823344349861145
test loss item: 0.5464152097702026
test loss item: 0.3914646506309509
test loss item: 0.3747623860836029
test loss item: 0.7063478231430054
test loss item: 1.3598662614822388
test loss item: 0.4379795491695404
test loss item: 0.2517440617084503
test loss item: 0.2749323546886444
test loss item: 0.16449078917503357
test loss item: 0.3466549515724182
test loss item: 0.20567110180854797
test loss item: 0.5408523678779602
test loss item: 0.3630850613117218
test loss item: 0.26625436544418335
test loss item: 0.19846510887145996
test loss item: 0.434152215719223
test loss item: 0.6381962895393372
test loss item: 0.278500497341156
test loss item: 0.12169289588928223
test loss item: 0.21480692923069
test loss item: 0.2083144187927246
test loss item: 0.27829793095588684
test loss item: 0.7671810984611511
test loss item: 0.4971947968006134
test loss item: 0.22920681536197662
test loss item: 0.2158188819885254
test loss item: 0.20693030953407288
test loss item: 0.43883100152015686
test loss item: 0.20577310025691986
test loss item: 0.1916610598564148
test loss item: 0.24762839078903198
test loss item: 0.7130694389343262
test loss item: 0.3291553556919098
test loss item: 0.2834886312484741
test loss item: 0.23849496245384216
test loss item: 0.49987849593162537
test loss item: 0.34787923097610474
test loss item: 0.07062672078609467
test loss item: 0.7982630729675293
test loss item: 0.27472397685050964
test loss item: 0.3532652258872986
test loss item: 0.13249137997627258
test loss item: 0.1418474167585373
test loss item: 0.16386139392852783
test loss item: 1.3466038703918457
test loss item: 0.38879725337028503
test loss item: 0.1771746575832367
test loss item: 0.0857318639755249
test loss item: 0.8691940903663635
test loss item: 0.7683973908424377
test loss item: 0.9194093942642212
test loss item: 0.1879858374595642
test loss item: 0.2064230591058731
test loss item: 0.08472379297018051
test loss item: 0.06912067532539368
test loss item: 0.19566494226455688
Epoch [23/50], Training Loss: 0.4376, Testing Loss: 0.3604
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 24/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.39592599868774414
1
train loss item: 1.046249270439148
2
train loss item: 0.19854527711868286
3
train loss item: 0.4648132920265198
4
train loss item: 0.3410126864910126
5
train loss item: 0.2823214530944824
6
train loss item: 0.2232942283153534
7
train loss item: 0.6995419859886169
8
train loss item: 0.11131785809993744
9
train loss item: 0.22316370904445648
10
train loss item: 0.2867104411125183
11
train loss item: 0.2446112185716629
12
train loss item: 0.11644453555345535
13
train loss item: 0.42839398980140686
14
train loss item: 0.19743861258029938
15
train loss item: 0.5357208847999573
16
train loss item: 0.0626877173781395
17
train loss item: 0.2532864809036255
18
train loss item: 0.2789056599140167
19
train loss item: 0.22790250182151794
20
train loss item: 0.19052277505397797
21
train loss item: 0.11667834222316742
22
train loss item: 0.8299567699432373
23
train loss item: 0.7885937094688416
24
train loss item: 0.47421520948410034
25
train loss item: 0.18140219151973724
26
train loss item: 0.1692994236946106
27
train loss item: 0.19143442809581757
28
train loss item: 0.06087560951709747
29
train loss item: 0.6190337538719177
30
train loss item: 2.0756936073303223
31
train loss item: 0.5063213109970093
32
train loss item: 0.10308672487735748
33
train loss item: 0.3732779920101166
34
train loss item: 0.13223038613796234
35
train loss item: 2.2556469440460205
36
train loss item: 0.4123340845108032
37
train loss item: 0.36971315741539
38
train loss item: 0.42000263929367065
39
train loss item: 0.1860656887292862
40
train loss item: 0.1514400988817215
41
train loss item: 0.22029532492160797
42
train loss item: 0.2535567879676819
43
train loss item: 0.15782108902931213
44
train loss item: 0.5814718008041382
45
train loss item: 0.11159379035234451
46
train loss item: 0.09927099198102951
47
train loss item: 0.3107220530509949
48
train loss item: 0.1885484755039215
49
train loss item: 0.13587546348571777
50
train loss item: 0.2504183053970337
51
train loss item: 0.7964437007904053
52
train loss item: 0.065742127597332
53
train loss item: 0.13660021126270294
54
train loss item: 2.1406054496765137
55
train loss item: 0.1699807345867157
56
train loss item: 0.20595525205135345
57
train loss item: 0.20658189058303833
58
train loss item: 0.13674895465373993
59
train loss item: 0.10943669825792313
60
train loss item: 0.7508423924446106
61
train loss item: 2.069103479385376
62
train loss item: 0.17900820076465607
63
train loss item: 0.31982919573783875
64
train loss item: 0.14558711647987366
65
train loss item: 0.4632696807384491
66
train loss item: 0.37578389048576355
67
train loss item: 0.18354974687099457
68
train loss item: 0.2572925388813019
69
train loss item: 0.2767814099788666
70
train loss item: 0.22405143082141876
71
train loss item: 0.11821425706148148
72
train loss item: 0.15307308733463287
73
train loss item: 0.26719939708709717
74
train loss item: 0.08870068937540054
75
train loss item: 0.10240151733160019
76
train loss item: 0.7733653783798218
77
train loss item: 1.2454347610473633
78
train loss item: 0.05957573652267456
79
train loss item: 0.2340283840894699
80
train loss item: 0.09980976581573486
81
train loss item: 0.17706675827503204
82
train loss item: 0.1710996776819229
83
train loss item: 0.527061939239502
84
train loss item: 0.38797491788864136
85
train loss item: 0.47443532943725586
86
train loss item: 4.1062822341918945
87
train loss item: 0.14662949740886688
88
train loss item: 0.3543721139431
epoch train loss: 0.42961355365729065
testing phase
test loss item: 0.17734253406524658
test loss item: 0.11772558093070984
test loss item: 0.5337733626365662
test loss item: 0.22367221117019653
test loss item: 0.23575545847415924
test loss item: 0.12422296404838562
test loss item: 1.4046651124954224
test loss item: 0.44038358330726624
test loss item: 0.19812636077404022
test loss item: 0.36696988344192505
test loss item: 0.7771496772766113
test loss item: 0.15942150354385376
test loss item: 0.1687149554491043
test loss item: 0.25228598713874817
test loss item: 0.17109858989715576
test loss item: 0.09059527516365051
test loss item: 0.2606584131717682
test loss item: 0.4417225122451782
test loss item: 0.5821595788002014
test loss item: 0.23123779892921448
test loss item: 0.6951053142547607
test loss item: 0.3468326926231384
test loss item: 0.2523978352546692
test loss item: 0.16992118954658508
test loss item: 0.2043106108903885
test loss item: 0.20687703788280487
test loss item: 0.29825159907341003
test loss item: 0.17834804952144623
test loss item: 0.30839213728904724
test loss item: 0.32259348034858704
test loss item: 0.6762375831604004
test loss item: 0.07840819656848907
test loss item: 0.15417279303073883
test loss item: 0.5412547588348389
test loss item: 0.3964274823665619
test loss item: 0.36961105465888977
test loss item: 0.7074423432350159
test loss item: 1.3248850107192993
test loss item: 0.434978723526001
test loss item: 0.2566364109516144
test loss item: 0.27647942304611206
test loss item: 0.15103614330291748
test loss item: 0.3488738238811493
test loss item: 0.19169053435325623
test loss item: 0.5547590851783752
test loss item: 0.3613303005695343
test loss item: 0.2673793137073517
test loss item: 0.19165655970573425
test loss item: 0.4328043758869171
test loss item: 0.6236802935600281
test loss item: 0.2854766249656677
test loss item: 0.1202666163444519
test loss item: 0.21568872034549713
test loss item: 0.17135345935821533
test loss item: 0.28350454568862915
test loss item: 0.754561722278595
test loss item: 0.494485467672348
test loss item: 0.24547035992145538
test loss item: 0.22019022703170776
test loss item: 0.20631170272827148
test loss item: 0.4394228458404541
test loss item: 0.20714180171489716
test loss item: 0.1910116970539093
test loss item: 0.24453970789909363
test loss item: 0.7182806730270386
test loss item: 0.3062303364276886
test loss item: 0.2822071611881256
test loss item: 0.2381887137889862
test loss item: 0.49985039234161377
test loss item: 0.34042128920555115
test loss item: 0.07595407217741013
test loss item: 0.8096973896026611
test loss item: 0.2763490080833435
test loss item: 0.3564966320991516
test loss item: 0.12904642522335052
test loss item: 0.1331547498703003
test loss item: 0.1687326729297638
test loss item: 1.3270128965377808
test loss item: 0.3821896016597748
test loss item: 0.17758941650390625
test loss item: 0.0924815684556961
test loss item: 0.8585107326507568
test loss item: 0.764039933681488
test loss item: 0.900074303150177
test loss item: 0.1903432011604309
test loss item: 0.20262673497200012
test loss item: 0.09372925013303757
test loss item: 0.08158332109451294
test loss item: 0.19136440753936768
Epoch [24/50], Training Loss: 0.4296, Testing Loss: 0.3591
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 25/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.38886937499046326
1
train loss item: 1.0258938074111938
2
train loss item: 0.18992914259433746
3
train loss item: 0.4450570344924927
4
train loss item: 0.33018043637275696
5
train loss item: 0.2723155617713928
6
train loss item: 0.2100948542356491
7
train loss item: 0.6879774928092957
8
train loss item: 0.10820861905813217
9
train loss item: 0.2165578454732895
10
train loss item: 0.27759453654289246
11
train loss item: 0.2419058382511139
12
train loss item: 0.11523307114839554
13
train loss item: 0.42281192541122437
14
train loss item: 0.19880786538124084
15
train loss item: 0.5361902713775635
16
train loss item: 0.06239146739244461
17
train loss item: 0.24785414338111877
18
train loss item: 0.2728177607059479
19
train loss item: 0.2181529402732849
20
train loss item: 0.18013903498649597
21
train loss item: 0.11029455810785294
22
train loss item: 0.8308714628219604
23
train loss item: 0.7692240476608276
24
train loss item: 0.46516314148902893
25
train loss item: 0.17210394144058228
26
train loss item: 0.16593371331691742
27
train loss item: 0.19156910479068756
28
train loss item: 0.05984686315059662
29
train loss item: 0.6064866185188293
30
train loss item: 2.044583797454834
31
train loss item: 0.49122241139411926
32
train loss item: 0.09685537964105606
33
train loss item: 0.3670729696750641
34
train loss item: 0.1285056173801422
35
train loss item: 2.2350456714630127
36
train loss item: 0.4112798273563385
37
train loss item: 0.3644225299358368
38
train loss item: 0.40765371918678284
39
train loss item: 0.1822328120470047
40
train loss item: 0.14332272112369537
41
train loss item: 0.21563832461833954
42
train loss item: 0.24513529241085052
43
train loss item: 0.15599988400936127
44
train loss item: 0.5741807222366333
45
train loss item: 0.1122502014040947
46
train loss item: 0.09547460079193115
47
train loss item: 0.30306655168533325
48
train loss item: 0.18451927602291107
49
train loss item: 0.13474076986312866
50
train loss item: 0.24320822954177856
51
train loss item: 0.7808226943016052
52
train loss item: 0.06551279872655869
53
train loss item: 0.12860722839832306
54
train loss item: 2.1197893619537354
55
train loss item: 0.1693536639213562
56
train loss item: 0.2017667293548584
57
train loss item: 0.1996225267648697
58
train loss item: 0.1350645273923874
59
train loss item: 0.10534755140542984
60
train loss item: 0.7405447959899902
61
train loss item: 2.0445973873138428
62
train loss item: 0.17452247440814972
63
train loss item: 0.31418490409851074
64
train loss item: 0.1432681381702423
65
train loss item: 0.4689277708530426
66
train loss item: 0.37651127576828003
67
train loss item: 0.17901751399040222
68
train loss item: 0.26005005836486816
69
train loss item: 0.269075870513916
70
train loss item: 0.21244744956493378
71
train loss item: 0.11154966801404953
72
train loss item: 0.14876346290111542
73
train loss item: 0.259390264749527
74
train loss item: 0.08286484330892563
75
train loss item: 0.10134658962488174
76
train loss item: 0.7582020163536072
77
train loss item: 1.2339563369750977
78
train loss item: 0.05809611827135086
79
train loss item: 0.22950749099254608
80
train loss item: 0.09507441520690918
81
train loss item: 0.16593270003795624
82
train loss item: 0.17467069625854492
83
train loss item: 0.5172245502471924
84
train loss item: 0.39591285586357117
85
train loss item: 0.4576246440410614
86
train loss item: 4.078161716461182
87
train loss item: 0.1422886699438095
88
train loss item: 0.34241369366645813
epoch train loss: 0.4224595869525095
testing phase
test loss item: 0.17349529266357422
test loss item: 0.11248848587274551
test loss item: 0.5350766777992249
test loss item: 0.2148132622241974
test loss item: 0.23277004063129425
test loss item: 0.11587153375148773
test loss item: 1.4230339527130127
test loss item: 0.4307827651500702
test loss item: 0.19923458993434906
test loss item: 0.36786985397338867
test loss item: 0.7695202231407166
test loss item: 0.14678098261356354
test loss item: 0.1612873673439026
test loss item: 0.250143438577652
test loss item: 0.16449667513370514
test loss item: 0.09973020106554031
test loss item: 0.2606044411659241
test loss item: 0.4468555450439453
test loss item: 0.5749044418334961
test loss item: 0.22874528169631958
test loss item: 0.7057313919067383
test loss item: 0.34304434061050415
test loss item: 0.25701719522476196
test loss item: 0.16406092047691345
test loss item: 0.20489230751991272
test loss item: 0.20452627539634705
test loss item: 0.2968865931034088
test loss item: 0.17405536770820618
test loss item: 0.30636143684387207
test loss item: 0.32224756479263306
test loss item: 0.6778993010520935
test loss item: 0.08616922795772552
test loss item: 0.14556802809238434
test loss item: 0.538801372051239
test loss item: 0.4002563953399658
test loss item: 0.36779674887657166
test loss item: 0.7032516598701477
test loss item: 1.3141257762908936
test loss item: 0.43412262201309204
test loss item: 0.25537198781967163
test loss item: 0.2811585068702698
test loss item: 0.14302073419094086
test loss item: 0.3523517847061157
test loss item: 0.1866900771856308
test loss item: 0.5617043375968933
test loss item: 0.3596738278865814
test loss item: 0.2686833441257477
test loss item: 0.19174475967884064
test loss item: 0.4317328631877899
test loss item: 0.620707094669342
test loss item: 0.28931090235710144
test loss item: 0.11788953840732574
test loss item: 0.21917767822742462
test loss item: 0.14701209962368011
test loss item: 0.28750231862068176
test loss item: 0.7526713013648987
test loss item: 0.4869268834590912
test loss item: 0.25518599152565
test loss item: 0.22035828232765198
test loss item: 0.20255574584007263
test loss item: 0.44313251972198486
test loss item: 0.20695772767066956
test loss item: 0.1876765936613083
test loss item: 0.23935918509960175
test loss item: 0.7181392908096313
test loss item: 0.2941373288631439
test loss item: 0.280244380235672
test loss item: 0.23870056867599487
test loss item: 0.4963534474372864
test loss item: 0.33291733264923096
test loss item: 0.07811785489320755
test loss item: 0.8162254691123962
test loss item: 0.27956968545913696
test loss item: 0.3606082797050476
test loss item: 0.12747733294963837
test loss item: 0.12769313156604767
test loss item: 0.16483142971992493
test loss item: 1.3172053098678589
test loss item: 0.38062483072280884
test loss item: 0.172181636095047
test loss item: 0.08969441056251526
test loss item: 0.8573231101036072
test loss item: 0.7646890878677368
test loss item: 0.8949189186096191
test loss item: 0.19128115475177765
test loss item: 0.2017155885696411
test loss item: 0.09374085813760757
test loss item: 0.09175210446119308
test loss item: 0.1791069507598877
Epoch [25/50], Training Loss: 0.4225, Testing Loss: 0.3575
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 26/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3834299147129059
1
train loss item: 1.0004634857177734
2
train loss item: 0.1824285089969635
3
train loss item: 0.4298737645149231
4
train loss item: 0.3287825286388397
5
train loss item: 0.2662425935268402
6
train loss item: 0.20374539494514465
7
train loss item: 0.6749088168144226
8
train loss item: 0.10561252385377884
9
train loss item: 0.20954491198062897
10
train loss item: 0.2723766267299652
11
train loss item: 0.23889575898647308
12
train loss item: 0.11617270112037659
13
train loss item: 0.41677433252334595
14
train loss item: 0.19821155071258545
15
train loss item: 0.5198978781700134
16
train loss item: 0.05977078527212143
17
train loss item: 0.23859506845474243
18
train loss item: 0.268422394990921
19
train loss item: 0.20820657908916473
20
train loss item: 0.16715015470981598
21
train loss item: 0.10907775908708572
22
train loss item: 0.8066458702087402
23
train loss item: 0.7490767240524292
24
train loss item: 0.45687609910964966
25
train loss item: 0.17203472554683685
26
train loss item: 0.16339270770549774
27
train loss item: 0.18860621750354767
28
train loss item: 0.05712735280394554
29
train loss item: 0.5908965468406677
30
train loss item: 2.0159859657287598
31
train loss item: 0.47989293932914734
32
train loss item: 0.09233138710260391
33
train loss item: 0.3563457131385803
34
train loss item: 0.12644866108894348
35
train loss item: 2.2155282497406006
36
train loss item: 0.4114159047603607
37
train loss item: 0.35601991415023804
38
train loss item: 0.4082103967666626
39
train loss item: 0.17956802248954773
40
train loss item: 0.14769352972507477
41
train loss item: 0.2130344659090042
42
train loss item: 0.23940736055374146
43
train loss item: 0.15271857380867004
44
train loss item: 0.5652453303337097
45
train loss item: 0.11185713112354279
46
train loss item: 0.09552948921918869
47
train loss item: 0.2940140664577484
48
train loss item: 0.18033920228481293
49
train loss item: 0.13493964076042175
50
train loss item: 0.23390258848667145
51
train loss item: 0.7646350860595703
52
train loss item: 0.06182662397623062
53
train loss item: 0.1263832300901413
54
train loss item: 2.0996713638305664
55
train loss item: 0.16649003326892853
56
train loss item: 0.19741041958332062
57
train loss item: 0.195948526263237
58
train loss item: 0.13554339110851288
59
train loss item: 0.10085165500640869
60
train loss item: 0.7239329218864441
61
train loss item: 2.0174789428710938
62
train loss item: 0.17274655401706696
63
train loss item: 0.30520573258399963
64
train loss item: 0.13981114327907562
65
train loss item: 0.4557555317878723
66
train loss item: 0.37318071722984314
67
train loss item: 0.17557330429553986
68
train loss item: 0.25395503640174866
69
train loss item: 0.260480135679245
70
train loss item: 0.2050056755542755
71
train loss item: 0.10878533124923706
72
train loss item: 0.14297285676002502
73
train loss item: 0.25316429138183594
74
train loss item: 0.0820441022515297
75
train loss item: 0.09777369350194931
76
train loss item: 0.7403085827827454
77
train loss item: 1.2196065187454224
78
train loss item: 0.05998248979449272
79
train loss item: 0.22377105057239532
80
train loss item: 0.09588827937841415
81
train loss item: 0.16312360763549805
82
train loss item: 0.1738204061985016
83
train loss item: 0.5039704442024231
84
train loss item: 0.3904474675655365
85
train loss item: 0.4452822208404541
86
train loss item: 4.049330234527588
87
train loss item: 0.14639021456241608
88
train loss item: 0.3351738452911377
epoch train loss: 0.4152515783403697
testing phase
test loss item: 0.16706183552742004
test loss item: 0.10474364459514618
test loss item: 0.5264284014701843
test loss item: 0.20981474220752716
test loss item: 0.22585438191890717
test loss item: 0.10553926229476929
test loss item: 1.4492994546890259
test loss item: 0.44383686780929565
test loss item: 0.19682592153549194
test loss item: 0.3613482415676117
test loss item: 0.7595275640487671
test loss item: 0.14365920424461365
test loss item: 0.16076424717903137
test loss item: 0.24418382346630096
test loss item: 0.15519030392169952
test loss item: 0.10406514257192612
test loss item: 0.2651386559009552
test loss item: 0.4366813600063324
test loss item: 0.5822161436080933
test loss item: 0.2355794906616211
test loss item: 0.6896794438362122
test loss item: 0.3484085500240326
test loss item: 0.2542603015899658
test loss item: 0.15925869345664978
test loss item: 0.20177629590034485
test loss item: 0.20534823834896088
test loss item: 0.29389166831970215
test loss item: 0.1687009185552597
test loss item: 0.30246561765670776
test loss item: 0.3173338770866394
test loss item: 0.6783021688461304
test loss item: 0.09288936853408813
test loss item: 0.13675861060619354
test loss item: 0.527286946773529
test loss item: 0.3913109004497528
test loss item: 0.370239794254303
test loss item: 0.7071390151977539
test loss item: 1.2921998500823975
test loss item: 0.42484766244888306
test loss item: 0.2545848786830902
test loss item: 0.28507351875305176
test loss item: 0.14306068420410156
test loss item: 0.3428124785423279
test loss item: 0.1869809627532959
test loss item: 0.5476696491241455
test loss item: 0.3681911528110504
test loss item: 0.2647040784358978
test loss item: 0.19567646086215973
test loss item: 0.4261045753955841
test loss item: 0.6188704967498779
test loss item: 0.27920034527778625
test loss item: 0.117276132106781
test loss item: 0.21755963563919067
test loss item: 0.13833926618099213
test loss item: 0.2807794511318207
test loss item: 0.7403576970100403
test loss item: 0.48599973320961
test loss item: 0.24512088298797607
test loss item: 0.2185487002134323
test loss item: 0.1967199295759201
test loss item: 0.43104180693626404
test loss item: 0.21667130291461945
test loss item: 0.19025760889053345
test loss item: 0.23873953521251678
test loss item: 0.7143338322639465
test loss item: 0.28932204842567444
test loss item: 0.28556713461875916
test loss item: 0.24115097522735596
test loss item: 0.48659810423851013
test loss item: 0.34691011905670166
test loss item: 0.08107932657003403
test loss item: 0.837066113948822
test loss item: 0.2780745029449463
test loss item: 0.37143006920814514
test loss item: 0.1309627890586853
test loss item: 0.12589313089847565
test loss item: 0.1620183289051056
test loss item: 1.2906494140625
test loss item: 0.37762686610221863
test loss item: 0.16722804307937622
test loss item: 0.08211123198270798
test loss item: 0.8609626889228821
test loss item: 0.7687721848487854
test loss item: 0.8815733194351196
test loss item: 0.19100254774093628
test loss item: 0.2044808715581894
test loss item: 0.08704204112291336
test loss item: 0.09434457123279572
test loss item: 0.17183338105678558
Epoch [26/50], Training Loss: 0.4153, Testing Loss: 0.3550
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 27/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3781145215034485
1
train loss item: 0.9745936989784241
2
train loss item: 0.17802870273590088
3
train loss item: 0.41014227271080017
4
train loss item: 0.3320058584213257
5
train loss item: 0.26273947954177856
6
train loss item: 0.20280437171459198
7
train loss item: 0.6585060358047485
8
train loss item: 0.10097531229257584
9
train loss item: 0.20537137985229492
10
train loss item: 0.2631172835826874
11
train loss item: 0.23214860260486603
12
train loss item: 0.11832115054130554
13
train loss item: 0.4032759368419647
14
train loss item: 0.19097557663917542
15
train loss item: 0.5037447810173035
16
train loss item: 0.058800384402275085
17
train loss item: 0.23030969500541687
18
train loss item: 0.2643621563911438
19
train loss item: 0.20597048103809357
20
train loss item: 0.1630466878414154
21
train loss item: 0.1054186001420021
22
train loss item: 0.780686616897583
23
train loss item: 0.7220965027809143
24
train loss item: 0.4555414021015167
25
train loss item: 0.17384564876556396
26
train loss item: 0.1641688346862793
27
train loss item: 0.18025483191013336
28
train loss item: 0.05656836926937103
29
train loss item: 0.5741254091262817
30
train loss item: 1.9851181507110596
31
train loss item: 0.46562665700912476
32
train loss item: 0.09582199901342392
33
train loss item: 0.3304656445980072
34
train loss item: 0.12366113066673279
35
train loss item: 2.1947178840637207
36
train loss item: 0.4060031771659851
37
train loss item: 0.3467629551887512
38
train loss item: 0.4104650914669037
39
train loss item: 0.1766795814037323
40
train loss item: 0.15373444557189941
41
train loss item: 0.20620755851268768
42
train loss item: 0.239867702126503
43
train loss item: 0.14567886292934418
44
train loss item: 0.5500105023384094
45
train loss item: 0.10937613248825073
46
train loss item: 0.09371267259120941
47
train loss item: 0.28799107670783997
48
train loss item: 0.17607372999191284
49
train loss item: 0.12754711508750916
50
train loss item: 0.22893431782722473
51
train loss item: 0.7463327050209045
52
train loss item: 0.059408560395240784
53
train loss item: 0.1248883530497551
54
train loss item: 2.0785858631134033
55
train loss item: 0.1583426594734192
56
train loss item: 0.18986505270004272
57
train loss item: 0.19634881615638733
58
train loss item: 0.1352008432149887
59
train loss item: 0.10303191095590591
60
train loss item: 0.7036382555961609
61
train loss item: 1.9841980934143066
62
train loss item: 0.17216742038726807
63
train loss item: 0.29711946845054626
64
train loss item: 0.12953603267669678
65
train loss item: 0.4419063329696655
66
train loss item: 0.3673344552516937
67
train loss item: 0.17266392707824707
68
train loss item: 0.2491813600063324
69
train loss item: 0.2562267482280731
70
train loss item: 0.20117713510990143
71
train loss item: 0.10936951637268066
72
train loss item: 0.13529963791370392
73
train loss item: 0.2490241825580597
74
train loss item: 0.08731929212808609
75
train loss item: 0.09609244018793106
76
train loss item: 0.7197718620300293
77
train loss item: 1.2042102813720703
78
train loss item: 0.061945103108882904
79
train loss item: 0.21893249452114105
80
train loss item: 0.09680674970149994
81
train loss item: 0.1620299071073532
82
train loss item: 0.16313302516937256
83
train loss item: 0.49234724044799805
84
train loss item: 0.3837014436721802
85
train loss item: 0.43232911825180054
86
train loss item: 4.017520427703857
87
train loss item: 0.1477072387933731
88
train loss item: 0.33708855509757996
epoch train loss: 0.4077112301346961
testing phase
test loss item: 0.16202881932258606
test loss item: 0.10578969866037369
test loss item: 0.5229548215866089
test loss item: 0.20726893842220306
test loss item: 0.22391244769096375
test loss item: 0.1049228310585022
test loss item: 1.4450774192810059
test loss item: 0.4546207785606384
test loss item: 0.19791951775550842
test loss item: 0.35712164640426636
test loss item: 0.7563952207565308
test loss item: 0.14512169361114502
test loss item: 0.1665724515914917
test loss item: 0.23974862694740295
test loss item: 0.1537291258573532
test loss item: 0.10770012438297272
test loss item: 0.26545029878616333
test loss item: 0.4254615306854248
test loss item: 0.5873845815658569
test loss item: 0.2425115704536438
test loss item: 0.6732279658317566
test loss item: 0.3508312702178955
test loss item: 0.2491646260023117
test loss item: 0.15978002548217773
test loss item: 0.1965475082397461
test loss item: 0.20766936242580414
test loss item: 0.2908892333507538
test loss item: 0.16938453912734985
test loss item: 0.3005494773387909
test loss item: 0.31268301606178284
test loss item: 0.6765511631965637
test loss item: 0.09910911321640015
test loss item: 0.13565848767757416
test loss item: 0.5171228051185608
test loss item: 0.3834567368030548
test loss item: 0.37628936767578125
test loss item: 0.7071845531463623
test loss item: 1.2823587656021118
test loss item: 0.4156250059604645
test loss item: 0.25358521938323975
test loss item: 0.28162893652915955
test loss item: 0.14771024882793427
test loss item: 0.3330110013484955
test loss item: 0.18408212065696716
test loss item: 0.5335948467254639
test loss item: 0.375237375497818
test loss item: 0.2605375051498413
test loss item: 0.19999352097511292
test loss item: 0.42451193928718567
test loss item: 0.618864893913269
test loss item: 0.2733795642852783
test loss item: 0.12023195624351501
test loss item: 0.2126869112253189
test loss item: 0.13740500807762146
test loss item: 0.2750604450702667
test loss item: 0.7354655265808105
test loss item: 0.48618271946907043
test loss item: 0.2347627878189087
test loss item: 0.2171846330165863
test loss item: 0.19506530463695526
test loss item: 0.41967013478279114
test loss item: 0.2243940532207489
test loss item: 0.194717675447464
test loss item: 0.23902209103107452
test loss item: 0.7139679789543152
test loss item: 0.285432368516922
test loss item: 0.2897331118583679
test loss item: 0.24059313535690308
test loss item: 0.47915032505989075
test loss item: 0.3606879413127899
test loss item: 0.0876617580652237
test loss item: 0.8410941362380981
test loss item: 0.275849312543869
test loss item: 0.3757280111312866
test loss item: 0.13507167994976044
test loss item: 0.1269107460975647
test loss item: 0.16301384568214417
test loss item: 1.2761468887329102
test loss item: 0.373247891664505
test loss item: 0.1670437455177307
test loss item: 0.07772549986839294
test loss item: 0.8617393374443054
test loss item: 0.7689619660377502
test loss item: 0.8776789307594299
test loss item: 0.18901024758815765
test loss item: 0.20615021884441376
test loss item: 0.08181220293045044
test loss item: 0.09436896443367004
test loss item: 0.17336539924144745
Epoch [27/50], Training Loss: 0.4077, Testing Loss: 0.3537
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 28/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.37319236993789673
1
train loss item: 0.9513962864875793
2
train loss item: 0.17568345367908478
3
train loss item: 0.3935128450393677
4
train loss item: 0.33313918113708496
5
train loss item: 0.26069191098213196
6
train loss item: 0.20027202367782593
7
train loss item: 0.6446107625961304
8
train loss item: 0.0984860211610794
9
train loss item: 0.20321163535118103
10
train loss item: 0.25363248586654663
11
train loss item: 0.22682559490203857
12
train loss item: 0.11622520536184311
13
train loss item: 0.39011135697364807
14
train loss item: 0.1844272017478943
15
train loss item: 0.49142691493034363
16
train loss item: 0.05698112025856972
17
train loss item: 0.22360292077064514
18
train loss item: 0.2603151202201843
19
train loss item: 0.20871655642986298
20
train loss item: 0.1593835949897766
21
train loss item: 0.10468020290136337
22
train loss item: 0.7547134160995483
23
train loss item: 0.6995294690132141
24
train loss item: 0.4518773853778839
25
train loss item: 0.17110104858875275
26
train loss item: 0.16586200892925262
27
train loss item: 0.17440079152584076
28
train loss item: 0.05499344319105148
29
train loss item: 0.555998682975769
30
train loss item: 1.9567835330963135
31
train loss item: 0.4532668888568878
32
train loss item: 0.09885438531637192
33
train loss item: 0.3103482723236084
34
train loss item: 0.12693755328655243
35
train loss item: 2.175245523452759
36
train loss item: 0.397121399641037
37
train loss item: 0.3431602716445923
38
train loss item: 0.40781959891319275
39
train loss item: 0.17354704439640045
40
train loss item: 0.14935359358787537
41
train loss item: 0.20021028816699982
42
train loss item: 0.24369437992572784
43
train loss item: 0.14064569771289825
44
train loss item: 0.5368865132331848
45
train loss item: 0.10925499349832535
46
train loss item: 0.09881015121936798
47
train loss item: 0.28121766448020935
48
train loss item: 0.17363087832927704
49
train loss item: 0.12131558358669281
50
train loss item: 0.22633494436740875
51
train loss item: 0.7275682687759399
52
train loss item: 0.059602100402116776
53
train loss item: 0.1191272884607315
54
train loss item: 2.0596365928649902
55
train loss item: 0.15290430188179016
56
train loss item: 0.1855964958667755
57
train loss item: 0.19802477955818176
58
train loss item: 0.13354481756687164
59
train loss item: 0.10948409140110016
60
train loss item: 0.6848163604736328
61
train loss item: 1.9569928646087646
62
train loss item: 0.16849389672279358
63
train loss item: 0.29132381081581116
64
train loss item: 0.1242615282535553
65
train loss item: 0.42833855748176575
66
train loss item: 0.3605160713195801
67
train loss item: 0.17049087584018707
68
train loss item: 0.24157170951366425
69
train loss item: 0.2547752559185028
70
train loss item: 0.19673946499824524
71
train loss item: 0.1090058758854866
72
train loss item: 0.13164681196212769
73
train loss item: 0.24615082144737244
74
train loss item: 0.0867420956492424
75
train loss item: 0.09509773552417755
76
train loss item: 0.7031105756759644
77
train loss item: 1.1878448724746704
78
train loss item: 0.06001052260398865
79
train loss item: 0.2176753729581833
80
train loss item: 0.09794982522726059
81
train loss item: 0.1563849300146103
82
train loss item: 0.15577411651611328
83
train loss item: 0.4838525354862213
84
train loss item: 0.38079479336738586
85
train loss item: 0.4192596971988678
86
train loss item: 3.988041877746582
87
train loss item: 0.1385253369808197
88
train loss item: 0.33736300468444824
epoch train loss: 0.40092674274457973
testing phase
test loss item: 0.15954962372779846
test loss item: 0.10695233196020126
test loss item: 0.5385382771492004
test loss item: 0.20724612474441528
test loss item: 0.22456559538841248
test loss item: 0.10484755039215088
test loss item: 1.408096194267273
test loss item: 0.4440157115459442
test loss item: 0.20662622153759003
test loss item: 0.3621954023838043
test loss item: 0.7757552266120911
test loss item: 0.15023022890090942
test loss item: 0.16719001531600952
test loss item: 0.24227240681648254
test loss item: 0.15569978952407837
test loss item: 0.10749746859073639
test loss item: 0.25757959485054016
test loss item: 0.427021861076355
test loss item: 0.5811343789100647
test loss item: 0.23739483952522278
test loss item: 0.6785872578620911
test loss item: 0.34531858563423157
test loss item: 0.24738089740276337
test loss item: 0.1576855480670929
test loss item: 0.1939302235841751
test loss item: 0.20589952170848846
test loss item: 0.2890823185443878
test loss item: 0.16928665339946747
test loss item: 0.29910582304000854
test loss item: 0.31102097034454346
test loss item: 0.6837547421455383
test loss item: 0.10020434111356735
test loss item: 0.13425345718860626
test loss item: 0.5207127928733826
test loss item: 0.38900288939476013
test loss item: 0.39011451601982117
test loss item: 0.6972867250442505
test loss item: 1.3183672428131104
test loss item: 0.41757580637931824
test loss item: 0.24826385080814362
test loss item: 0.27361705899238586
test loss item: 0.14947880804538727
test loss item: 0.3348844349384308
test loss item: 0.18246960639953613
test loss item: 0.5367892980575562
test loss item: 0.3656909763813019
test loss item: 0.2584502398967743
test loss item: 0.19613990187644958
test loss item: 0.4317852556705475
test loss item: 0.6290849447250366
test loss item: 0.28179097175598145
test loss item: 0.11810459941625595
test loss item: 0.21074967086315155
test loss item: 0.14824959635734558
test loss item: 0.2793571650981903
test loss item: 0.7596953511238098
test loss item: 0.4862399697303772
test loss item: 0.23582588136196136
test loss item: 0.21444249153137207
test loss item: 0.19715358316898346
test loss item: 0.4242735505104065
test loss item: 0.2191912829875946
test loss item: 0.19361086189746857
test loss item: 0.23650501668453217
test loss item: 0.7267951965332031
test loss item: 0.2870756685733795
test loss item: 0.2841465473175049
test loss item: 0.23544490337371826
test loss item: 0.47978949546813965
test loss item: 0.3705044686794281
test loss item: 0.08958370983600616
test loss item: 0.8155534267425537
test loss item: 0.2756984829902649
test loss item: 0.3676062524318695
test loss item: 0.1329350769519806
test loss item: 0.1255929172039032
test loss item: 0.1607404500246048
test loss item: 1.3089033365249634
test loss item: 0.371931254863739
test loss item: 0.16597218811511993
test loss item: 0.07705005258321762
test loss item: 0.867035984992981
test loss item: 0.7690133452415466
test loss item: 0.9062169790267944
test loss item: 0.18578708171844482
test loss item: 0.20208021998405457
test loss item: 0.08007366210222244
test loss item: 0.09312508255243301
test loss item: 0.17849627137184143
Epoch [28/50], Training Loss: 0.4009, Testing Loss: 0.3549
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Epoch 29/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36731091141700745
1
train loss item: 0.9326038360595703
2
train loss item: 0.16657394170761108
3
train loss item: 0.38922297954559326
4
train loss item: 0.32888805866241455
5
train loss item: 0.2551914155483246
6
train loss item: 0.191889688372612
7
train loss item: 0.6361575722694397
8
train loss item: 0.09772432595491409
9
train loss item: 0.19756467640399933
10
train loss item: 0.24754367768764496
11
train loss item: 0.22492238879203796
12
train loss item: 0.111416295170784
13
train loss item: 0.3830171227455139
14
train loss item: 0.18058301508426666
15
train loss item: 0.47754985094070435
16
train loss item: 0.05743652209639549
17
train loss item: 0.2182520031929016
18
train loss item: 0.252162367105484
19
train loss item: 0.20195643603801727
20
train loss item: 0.155581533908844
21
train loss item: 0.10243500769138336
22
train loss item: 0.724821925163269
23
train loss item: 0.6907150149345398
24
train loss item: 0.43658724427223206
25
train loss item: 0.1669609546661377
26
train loss item: 0.16278935968875885
27
train loss item: 0.17217662930488586
28
train loss item: 0.05523640289902687
29
train loss item: 0.5393355488777161
30
train loss item: 1.9386155605316162
31
train loss item: 0.4442041516304016
32
train loss item: 0.0891624167561531
33
train loss item: 0.31171441078186035
34
train loss item: 0.1348559558391571
35
train loss item: 2.1602768898010254
36
train loss item: 0.3919623792171478
37
train loss item: 0.3445332646369934
38
train loss item: 0.40128082036972046
39
train loss item: 0.16789725422859192
40
train loss item: 0.13648028671741486
41
train loss item: 0.19619609415531158
42
train loss item: 0.2418522983789444
43
train loss item: 0.13734017312526703
44
train loss item: 0.5322074890136719
45
train loss item: 0.11136447638273239
46
train loss item: 0.09575185924768448
47
train loss item: 0.2699089050292969
48
train loss item: 0.16807276010513306
49
train loss item: 0.12180550396442413
50
train loss item: 0.21723489463329315
51
train loss item: 0.7140358090400696
52
train loss item: 0.06092317774891853
53
train loss item: 0.11598239094018936
54
train loss item: 2.045841693878174
55
train loss item: 0.14991869032382965
56
train loss item: 0.18397480249404907
57
train loss item: 0.19231382012367249
58
train loss item: 0.12663820385932922
59
train loss item: 0.11112672835588455
60
train loss item: 0.6710049510002136
61
train loss item: 1.9441829919815063
62
train loss item: 0.1583530753850937
63
train loss item: 0.28325438499450684
64
train loss item: 0.12535248696804047
65
train loss item: 0.41242608428001404
66
train loss item: 0.35143041610717773
67
train loss item: 0.16504070162773132
68
train loss item: 0.22519898414611816
69
train loss item: 0.24693027138710022
70
train loss item: 0.19014707207679749
71
train loss item: 0.10420941561460495
72
train loss item: 0.13125568628311157
73
train loss item: 0.23988744616508484
74
train loss item: 0.0816107988357544
75
train loss item: 0.0947166457772255
76
train loss item: 0.6922959089279175
77
train loss item: 1.171653389930725
78
train loss item: 0.0568990632891655
79
train loss item: 0.21549324691295624
80
train loss item: 0.0971081480383873
81
train loss item: 0.14908196032047272
82
train loss item: 0.1555289328098297
83
train loss item: 0.47502610087394714
84
train loss item: 0.3788571059703827
85
train loss item: 0.40990152955055237
86
train loss item: 3.9656190872192383
87
train loss item: 0.13306763768196106
88
train loss item: 0.32202571630477905
epoch train loss: 0.39422066413452117
testing phase
test loss item: 0.1579446792602539
test loss item: 0.10418128967285156
test loss item: 0.5398536920547485
test loss item: 0.20805275440216064
test loss item: 0.2217545211315155
test loss item: 0.10361489653587341
test loss item: 1.4148725271224976
test loss item: 0.46739667654037476
test loss item: 0.203828826546669
test loss item: 0.3575412333011627
test loss item: 0.766609251499176
test loss item: 0.15332359075546265
test loss item: 0.1647683084011078
test loss item: 0.2418353110551834
test loss item: 0.1530706137418747
test loss item: 0.1050192266702652
test loss item: 0.2565382421016693
test loss item: 0.422744482755661
test loss item: 0.5808491706848145
test loss item: 0.23490431904792786
test loss item: 0.6819095611572266
test loss item: 0.3510882258415222
test loss item: 0.24761733412742615
test loss item: 0.15532462298870087
test loss item: 0.19193512201309204
test loss item: 0.20405979454517365
test loss item: 0.28491896390914917
test loss item: 0.16593670845031738
test loss item: 0.29442280530929565
test loss item: 0.3065919280052185
test loss item: 0.6816253066062927
test loss item: 0.09706751257181168
test loss item: 0.1321270614862442
test loss item: 0.5169655084609985
test loss item: 0.38758406043052673
test loss item: 0.37671220302581787
test loss item: 0.6993169188499451
test loss item: 1.3072901964187622
test loss item: 0.41508951783180237
test loss item: 0.2465222179889679
test loss item: 0.2724796533584595
test loss item: 0.14487537741661072
test loss item: 0.3276602625846863
test loss item: 0.18631473183631897
test loss item: 0.5370925068855286
test loss item: 0.365888774394989
test loss item: 0.25487977266311646
test loss item: 0.19145984947681427
test loss item: 0.43304893374443054
test loss item: 0.6226094365119934
test loss item: 0.28028354048728943
test loss item: 0.116971455514431
test loss item: 0.2087613344192505
test loss item: 0.15790465474128723
test loss item: 0.27792638540267944
test loss item: 0.7558697462081909
test loss item: 0.4875514805316925
test loss item: 0.23687385022640228
test loss item: 0.21382124722003937
test loss item: 0.19160878658294678
test loss item: 0.41552814841270447
test loss item: 0.22642533481121063
test loss item: 0.1933153122663498
test loss item: 0.2321266084909439
test loss item: 0.7409854531288147
test loss item: 0.29025739431381226
test loss item: 0.2853914201259613
test loss item: 0.23255093395709991
test loss item: 0.4764963984489441
test loss item: 0.35665401816368103
test loss item: 0.08599334210157394
test loss item: 0.8295713067054749
test loss item: 0.27605554461479187
test loss item: 0.3686487376689911
test loss item: 0.13092981278896332
test loss item: 0.12118697166442871
test loss item: 0.15865416824817657
test loss item: 1.3130627870559692
test loss item: 0.3711887300014496
test loss item: 0.16317342221736908
test loss item: 0.07567087560892105
test loss item: 0.8666024804115295
test loss item: 0.7659900784492493
test loss item: 0.9064193964004517
test loss item: 0.1851256787776947
test loss item: 0.19754387438297272
test loss item: 0.07942768186330795
test loss item: 0.091883085668087
test loss item: 0.17539553344249725
Epoch [29/50], Training Loss: 0.3942, Testing Loss: 0.3537
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 30/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36034882068634033
1
train loss item: 0.9165389537811279
2
train loss item: 0.16212913393974304
3
train loss item: 0.3744274973869324
4
train loss item: 0.3130091428756714
5
train loss item: 0.248446524143219
6
train loss item: 0.18612556159496307
7
train loss item: 0.6255545020103455
8
train loss item: 0.09409883618354797
9
train loss item: 0.19038733839988708
10
train loss item: 0.23761823773384094
11
train loss item: 0.22116287052631378
12
train loss item: 0.11277987062931061
13
train loss item: 0.36955970525741577
14
train loss item: 0.1778772920370102
15
train loss item: 0.47858625650405884
16
train loss item: 0.06159219145774841
17
train loss item: 0.217027485370636
18
train loss item: 0.24522764980793
19
train loss item: 0.19657155871391296
20
train loss item: 0.16066579520702362
21
train loss item: 0.10602546483278275
22
train loss item: 0.7226999998092651
23
train loss item: 0.6714286208152771
24
train loss item: 0.4304174482822418
25
train loss item: 0.16480466723442078
26
train loss item: 0.1629006564617157
27
train loss item: 0.16890357434749603
28
train loss item: 0.05815919116139412
29
train loss item: 0.5336197018623352
30
train loss item: 1.9152958393096924
31
train loss item: 0.4255421459674835
32
train loss item: 0.083079993724823
33
train loss item: 0.29986345767974854
34
train loss item: 0.12889668345451355
35
train loss item: 2.143216133117676
36
train loss item: 0.37815460562705994
37
train loss item: 0.3395789861679077
38
train loss item: 0.37376847863197327
39
train loss item: 0.16448438167572021
40
train loss item: 0.13398733735084534
41
train loss item: 0.19002923369407654
42
train loss item: 0.2364213913679123
43
train loss item: 0.1363367736339569
44
train loss item: 0.5230177044868469
45
train loss item: 0.10627797245979309
46
train loss item: 0.09270410239696503
47
train loss item: 0.26471951603889465
48
train loss item: 0.16188348829746246
49
train loss item: 0.11738987267017365
50
train loss item: 0.21337153017520905
51
train loss item: 0.7005702257156372
52
train loss item: 0.06203213706612587
53
train loss item: 0.11612393707036972
54
train loss item: 2.029327392578125
55
train loss item: 0.147736594080925
56
train loss item: 0.178969606757164
57
train loss item: 0.1864166110754013
58
train loss item: 0.12747155129909515
59
train loss item: 0.1056758463382721
60
train loss item: 0.6646850109100342
61
train loss item: 1.9242494106292725
62
train loss item: 0.15335237979888916
63
train loss item: 0.276747465133667
64
train loss item: 0.12285272032022476
65
train loss item: 0.40585383772850037
66
train loss item: 0.3404916822910309
67
train loss item: 0.16140148043632507
68
train loss item: 0.22818762063980103
69
train loss item: 0.24086980521678925
70
train loss item: 0.18654534220695496
71
train loss item: 0.10260745137929916
72
train loss item: 0.1263446807861328
73
train loss item: 0.23342420160770416
74
train loss item: 0.0732552632689476
75
train loss item: 0.09499715268611908
76
train loss item: 0.6758061647415161
77
train loss item: 1.1606523990631104
78
train loss item: 0.0563463531434536
79
train loss item: 0.2110053300857544
80
train loss item: 0.09137978404760361
81
train loss item: 0.14886662364006042
82
train loss item: 0.153006911277771
83
train loss item: 0.46816304326057434
84
train loss item: 0.37106817960739136
85
train loss item: 0.39635902643203735
86
train loss item: 3.94020938873291
87
train loss item: 0.13254742324352264
88
train loss item: 0.3126775324344635
epoch train loss: 0.38769653644622043
testing phase
test loss item: 0.15958838164806366
test loss item: 0.09568615257740021
test loss item: 0.5359131693840027
test loss item: 0.2069164663553238
test loss item: 0.2163820117712021
test loss item: 0.10130345076322556
test loss item: 1.4302409887313843
test loss item: 0.46399274468421936
test loss item: 0.20294611155986786
test loss item: 0.350835382938385
test loss item: 0.7611181735992432
test loss item: 0.14997516572475433
test loss item: 0.1535717099905014
test loss item: 0.23702551424503326
test loss item: 0.1477317065000534
test loss item: 0.09328988939523697
test loss item: 0.25258851051330566
test loss item: 0.4166177809238434
test loss item: 0.5738036036491394
test loss item: 0.22643321752548218
test loss item: 0.6720647215843201
test loss item: 0.34867915511131287
test loss item: 0.24650409817695618
test loss item: 0.15205924212932587
test loss item: 0.19089920818805695
test loss item: 0.19671140611171722
test loss item: 0.2820127308368683
test loss item: 0.1601807177066803
test loss item: 0.2889447808265686
test loss item: 0.30117473006248474
test loss item: 0.6835126876831055
test loss item: 0.08513476699590683
test loss item: 0.1286982148885727
test loss item: 0.509497344493866
test loss item: 0.3825622498989105
test loss item: 0.3696802854537964
test loss item: 0.6927178502082825
test loss item: 1.2985128164291382
test loss item: 0.4098707139492035
test loss item: 0.2465863972902298
test loss item: 0.2743084728717804
test loss item: 0.1409052163362503
test loss item: 0.3218647241592407
test loss item: 0.1893879771232605
test loss item: 0.5272014737129211
test loss item: 0.3511689007282257
test loss item: 0.24848544597625732
test loss item: 0.1853996366262436
test loss item: 0.4256036579608917
test loss item: 0.6177836656570435
test loss item: 0.2731699049472809
test loss item: 0.11167001724243164
test loss item: 0.2089666873216629
test loss item: 0.1570834219455719
test loss item: 0.2736608684062958
test loss item: 0.752018928527832
test loss item: 0.4835544228553772
test loss item: 0.22905902564525604
test loss item: 0.20810486376285553
test loss item: 0.18263834714889526
test loss item: 0.4089551270008087
test loss item: 0.21978788077831268
test loss item: 0.18684805929660797
test loss item: 0.2257116138935089
test loss item: 0.7417951822280884
test loss item: 0.28947243094444275
test loss item: 0.2794433534145355
test loss item: 0.23032262921333313
test loss item: 0.46699076890945435
test loss item: 0.3540603816509247
test loss item: 0.07497872412204742
test loss item: 0.8318762183189392
test loss item: 0.2731306850910187
test loss item: 0.3682158887386322
test loss item: 0.12609915435314178
test loss item: 0.11845017969608307
test loss item: 0.15607482194900513
test loss item: 1.3060187101364136
test loss item: 0.36890968680381775
test loss item: 0.16017332673072815
test loss item: 0.07706744968891144
test loss item: 0.8676353096961975
test loss item: 0.7636110782623291
test loss item: 0.9033622741699219
test loss item: 0.18409910798072815
test loss item: 0.18991832435131073
test loss item: 0.07854166626930237
test loss item: 0.08486909419298172
test loss item: 0.17228932678699493
Epoch [30/50], Training Loss: 0.3877, Testing Loss: 0.3494
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 31/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3546921908855438
1
train loss item: 0.896126925945282
2
train loss item: 0.15897049009799957
3
train loss item: 0.36870309710502625
4
train loss item: 0.2973933219909668
5
train loss item: 0.24376825988292694
6
train loss item: 0.18566302955150604
7
train loss item: 0.6135778427124023
8
train loss item: 0.094399094581604
9
train loss item: 0.18518780171871185
10
train loss item: 0.23505957424640656
11
train loss item: 0.22220715880393982
12
train loss item: 0.11778794229030609
13
train loss item: 0.363520085811615
14
train loss item: 0.1772768348455429
15
train loss item: 0.466782808303833
16
train loss item: 0.06670908629894257
17
train loss item: 0.2158176600933075
18
train loss item: 0.23909243941307068
19
train loss item: 0.18312184512615204
20
train loss item: 0.16337694227695465
21
train loss item: 0.10784459859132767
22
train loss item: 0.7034399509429932
23
train loss item: 0.6545329093933105
24
train loss item: 0.41609200835227966
25
train loss item: 0.16392020881175995
26
train loss item: 0.16424572467803955
27
train loss item: 0.1655566543340683
28
train loss item: 0.06310361623764038
29
train loss item: 0.5257018208503723
30
train loss item: 1.8968539237976074
31
train loss item: 0.41488170623779297
32
train loss item: 0.07911980897188187
33
train loss item: 0.2930485010147095
34
train loss item: 0.1246907040476799
35
train loss item: 2.1284828186035156
36
train loss item: 0.37170830368995667
37
train loss item: 0.3354067802429199
38
train loss item: 0.3624565601348877
39
train loss item: 0.16308371722698212
40
train loss item: 0.13480731844902039
41
train loss item: 0.187172994017601
42
train loss item: 0.22826792299747467
43
train loss item: 0.13695071637630463
44
train loss item: 0.5152370929718018
45
train loss item: 0.10173672437667847
46
train loss item: 0.09254762530326843
47
train loss item: 0.2572305202484131
48
train loss item: 0.15621502697467804
49
train loss item: 0.11645496636629105
50
train loss item: 0.20311672985553741
51
train loss item: 0.6915866732597351
52
train loss item: 0.06330353766679764
53
train loss item: 0.11579395830631256
54
train loss item: 2.014232873916626
55
train loss item: 0.14487719535827637
56
train loss item: 0.1749095916748047
57
train loss item: 0.1807064712047577
58
train loss item: 0.1305249035358429
59
train loss item: 0.09902993589639664
60
train loss item: 0.653200089931488
61
train loss item: 1.905738115310669
62
train loss item: 0.15068751573562622
63
train loss item: 0.2687053978443146
64
train loss item: 0.12230376154184341
65
train loss item: 0.39150679111480713
66
train loss item: 0.3323279917240143
67
train loss item: 0.1585986465215683
68
train loss item: 0.22123900055885315
69
train loss item: 0.2302902340888977
70
train loss item: 0.18249046802520752
71
train loss item: 0.10345446318387985
72
train loss item: 0.1217169463634491
73
train loss item: 0.2269679307937622
74
train loss item: 0.072913758456707
75
train loss item: 0.09677957743406296
76
train loss item: 0.6556273698806763
77
train loss item: 1.1503970623016357
78
train loss item: 0.05941585451364517
79
train loss item: 0.2076568454504013
80
train loss item: 0.08830193430185318
81
train loss item: 0.15037575364112854
82
train loss item: 0.15058250725269318
83
train loss item: 0.45691466331481934
84
train loss item: 0.36073338985443115
85
train loss item: 0.3871409296989441
86
train loss item: 3.917354106903076
87
train loss item: 0.1306036412715912
88
train loss item: 0.2994997501373291
epoch train loss: 0.38181609015786244
testing phase
test loss item: 0.1589951068162918
test loss item: 0.08943033218383789
test loss item: 0.5159515738487244
test loss item: 0.20370836555957794
test loss item: 0.20935118198394775
test loss item: 0.09877286851406097
test loss item: 1.4564995765686035
test loss item: 0.47205251455307007
test loss item: 0.1960570216178894
test loss item: 0.3368741273880005
test loss item: 0.7364901900291443
test loss item: 0.14515496790409088
test loss item: 0.1521638184785843
test loss item: 0.2347368746995926
test loss item: 0.14240244030952454
test loss item: 0.08363370597362518
test loss item: 0.25238037109375
test loss item: 0.39900684356689453
test loss item: 0.5729759931564331
test loss item: 0.2289174497127533
test loss item: 0.6418747901916504
test loss item: 0.3494563400745392
test loss item: 0.24422653019428253
test loss item: 0.151638925075531
test loss item: 0.18677493929862976
test loss item: 0.19320619106292725
test loss item: 0.27694767713546753
test loss item: 0.15506702661514282
test loss item: 0.28307831287384033
test loss item: 0.2938217520713806
test loss item: 0.6748611330986023
test loss item: 0.07749617099761963
test loss item: 0.1272023469209671
test loss item: 0.4898653030395508
test loss item: 0.36606284976005554
test loss item: 0.35735565423965454
test loss item: 0.6906023621559143
test loss item: 1.2513638734817505
test loss item: 0.3948250412940979
test loss item: 0.24806107580661774
test loss item: 0.2762397527694702
test loss item: 0.14455951750278473
test loss item: 0.3060198128223419
test loss item: 0.18903455138206482
test loss item: 0.5017740726470947
test loss item: 0.34861046075820923
test loss item: 0.24197015166282654
test loss item: 0.18837155401706696
test loss item: 0.4109719693660736
test loss item: 0.602017879486084
test loss item: 0.2557307779788971
test loss item: 0.11472872644662857
test loss item: 0.20534200966358185
test loss item: 0.14774666726589203
test loss item: 0.2611599862575531
test loss item: 0.7240301370620728
test loss item: 0.4789355397224426
test loss item: 0.21355588734149933
test loss item: 0.2038758546113968
test loss item: 0.1744157373905182
test loss item: 0.3883463144302368
test loss item: 0.22090835869312286
test loss item: 0.186385378241539
test loss item: 0.22394560277462006
test loss item: 0.7291982769966125
test loss item: 0.28332218527793884
test loss item: 0.2796873152256012
test loss item: 0.23054972290992737
test loss item: 0.4519118070602417
test loss item: 0.3523014783859253
test loss item: 0.06845647841691971
test loss item: 0.8469951748847961
test loss item: 0.26906251907348633
test loss item: 0.3733274042606354
test loss item: 0.1267527937889099
test loss item: 0.12117169797420502
test loss item: 0.15619437396526337
test loss item: 1.2614545822143555
test loss item: 0.3656933307647705
test loss item: 0.15834376215934753
test loss item: 0.07535476982593536
test loss item: 0.8589698076248169
test loss item: 0.7563163042068481
test loss item: 0.873477041721344
test loss item: 0.1865633726119995
test loss item: 0.18602512776851654
test loss item: 0.07400666922330856
test loss item: 0.07684695720672607
test loss item: 0.1715620458126068
Epoch [31/50], Training Loss: 0.3818, Testing Loss: 0.3425
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Epoch 32/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3507055938243866
1
train loss item: 0.8743043541908264
2
train loss item: 0.16103078424930573
3
train loss item: 0.35684671998023987
4
train loss item: 0.28867852687835693
5
train loss item: 0.2419794499874115
6
train loss item: 0.186737060546875
7
train loss item: 0.5968044400215149
8
train loss item: 0.09039497375488281
9
train loss item: 0.1832067221403122
10
train loss item: 0.22959484159946442
11
train loss item: 0.22259515523910522
12
train loss item: 0.11797892302274704
13
train loss item: 0.3561367392539978
14
train loss item: 0.17583777010440826
15
train loss item: 0.457342267036438
16
train loss item: 0.06477763503789902
17
train loss item: 0.21365641057491302
18
train loss item: 0.23457595705986023
19
train loss item: 0.17953039705753326
20
train loss item: 0.1628982126712799
21
train loss item: 0.11058435589075089
22
train loss item: 0.685893714427948
23
train loss item: 0.631270170211792
24
train loss item: 0.4080531597137451
25
train loss item: 0.16110429167747498
26
train loss item: 0.1675468236207962
27
train loss item: 0.16187350451946259
28
train loss item: 0.061748865991830826
29
train loss item: 0.5154974460601807
30
train loss item: 1.8733347654342651
31
train loss item: 0.4055803120136261
32
train loss item: 0.08253275603055954
33
train loss item: 0.27616119384765625
34
train loss item: 0.12566117942333221
35
train loss item: 2.112034320831299
36
train loss item: 0.3628869652748108
37
train loss item: 0.3330719470977783
38
train loss item: 0.35913369059562683
39
train loss item: 0.16267746686935425
40
train loss item: 0.1363837569952011
41
train loss item: 0.18392951786518097
42
train loss item: 0.22658376395702362
43
train loss item: 0.13594041764736176
44
train loss item: 0.5019979476928711
45
train loss item: 0.09823064506053925
46
train loss item: 0.09362642467021942
47
train loss item: 0.2523987889289856
48
train loss item: 0.15379564464092255
49
train loss item: 0.11340893059968948
50
train loss item: 0.19762618839740753
51
train loss item: 0.6805935502052307
52
train loss item: 0.06114182248711586
53
train loss item: 0.1126500740647316
54
train loss item: 1.9971702098846436
55
train loss item: 0.1405310183763504
56
train loss item: 0.170911967754364
57
train loss item: 0.1801055669784546
58
train loss item: 0.13253334164619446
59
train loss item: 0.09925836324691772
60
train loss item: 0.6374118328094482
61
train loss item: 1.8817487955093384
62
train loss item: 0.1480809897184372
63
train loss item: 0.2647440433502197
64
train loss item: 0.11965160071849823
65
train loss item: 0.38741376996040344
66
train loss item: 0.3284623324871063
67
train loss item: 0.15705999732017517
68
train loss item: 0.21637707948684692
69
train loss item: 0.22701714932918549
70
train loss item: 0.17934942245483398
71
train loss item: 0.1039939895272255
72
train loss item: 0.1152253970503807
73
train loss item: 0.22305509448051453
74
train loss item: 0.07447680085897446
75
train loss item: 0.09553761035203934
76
train loss item: 0.6332582831382751
77
train loss item: 1.1406121253967285
78
train loss item: 0.05858362838625908
79
train loss item: 0.20756329596042633
80
train loss item: 0.0851258635520935
81
train loss item: 0.14792051911354065
82
train loss item: 0.14484167098999023
83
train loss item: 0.4496632218360901
84
train loss item: 0.35231706500053406
85
train loss item: 0.3756643831729889
86
train loss item: 3.892944812774658
87
train loss item: 0.12457524985074997
88
train loss item: 0.2987433671951294
epoch train loss: 0.3762078336701634
testing phase
test loss item: 0.15547576546669006
test loss item: 0.0877688005566597
test loss item: 0.508309543132782
test loss item: 0.19899588823318481
test loss item: 0.20838132500648499
test loss item: 0.09859322011470795
test loss item: 1.4386816024780273
test loss item: 0.46153154969215393
test loss item: 0.19554974138736725
test loss item: 0.33178219199180603
test loss item: 0.7253214120864868
test loss item: 0.14070217311382294
test loss item: 0.15439178049564362
test loss item: 0.23639914393424988
test loss item: 0.14211240410804749
test loss item: 0.07511423528194427
test loss item: 0.24566195905208588
test loss item: 0.39073196053504944
test loss item: 0.563417911529541
test loss item: 0.22861425578594208
test loss item: 0.6272593140602112
test loss item: 0.34227144718170166
test loss item: 0.2424333244562149
test loss item: 0.15015625953674316
test loss item: 0.1809348165988922
test loss item: 0.19040526449680328
test loss item: 0.27281373739242554
test loss item: 0.15480630099773407
test loss item: 0.2802464962005615
test loss item: 0.28913435339927673
test loss item: 0.6667138934135437
test loss item: 0.07137203961610794
test loss item: 0.12553246319293976
test loss item: 0.4792788028717041
test loss item: 0.3590227961540222
test loss item: 0.35315006971359253
test loss item: 0.6793827414512634
test loss item: 1.230579137802124
test loss item: 0.38579756021499634
test loss item: 0.2441020905971527
test loss item: 0.2687848210334778
test loss item: 0.14878439903259277
test loss item: 0.2994081676006317
test loss item: 0.18177112936973572
test loss item: 0.48933178186416626
test loss item: 0.3425065577030182
test loss item: 0.23910585045814514
test loss item: 0.19050179421901703
test loss item: 0.40460875630378723
test loss item: 0.5935867428779602
test loss item: 0.2512356638908386
test loss item: 0.11635341495275497
test loss item: 0.20065654814243317
test loss item: 0.13805286586284637
test loss item: 0.25655922293663025
test loss item: 0.7151698470115662
test loss item: 0.47047701478004456
test loss item: 0.20848852396011353
test loss item: 0.200327530503273
test loss item: 0.17340229451656342
test loss item: 0.380028635263443
test loss item: 0.2157415896654129
test loss item: 0.1847938597202301
test loss item: 0.22036923468112946
test loss item: 0.7195348143577576
test loss item: 0.2751609981060028
test loss item: 0.27564167976379395
test loss item: 0.22621312737464905
test loss item: 0.4440070688724518
test loss item: 0.3474782109260559
test loss item: 0.0668732225894928
test loss item: 0.8325710296630859
test loss item: 0.26805540919303894
test loss item: 0.3678533732891083
test loss item: 0.1262376606464386
test loss item: 0.12315066158771515
test loss item: 0.15467581152915955
test loss item: 1.24014151096344
test loss item: 0.36294642090797424
test loss item: 0.15800228714942932
test loss item: 0.07208062708377838
test loss item: 0.8451789021492004
test loss item: 0.7451779246330261
test loss item: 0.8599172830581665
test loss item: 0.18560859560966492
test loss item: 0.18258695304393768
test loss item: 0.06733077764511108
test loss item: 0.06684844940900803
test loss item: 0.17613394558429718
Epoch [32/50], Training Loss: 0.3762, Testing Loss: 0.3370
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 33/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.34626248478889465
1
train loss item: 0.8533000349998474
2
train loss item: 0.15971466898918152
3
train loss item: 0.34951692819595337
4
train loss item: 0.2802634537220001
5
train loss item: 0.23752890527248383
6
train loss item: 0.18094182014465332
7
train loss item: 0.5832763910293579
8
train loss item: 0.08840049803256989
9
train loss item: 0.18004325032234192
10
train loss item: 0.223910853266716
11
train loss item: 0.22214773297309875
12
train loss item: 0.11146649718284607
13
train loss item: 0.35018542408943176
14
train loss item: 0.17377766966819763
15
train loss item: 0.44337770342826843
16
train loss item: 0.057646121829748154
17
train loss item: 0.2091720700263977
18
train loss item: 0.22935903072357178
19
train loss item: 0.17900846898555756
20
train loss item: 0.1568583846092224
21
train loss item: 0.106326624751091
22
train loss item: 0.6623676419258118
23
train loss item: 0.6151700019836426
24
train loss item: 0.3964803218841553
25
train loss item: 0.157808318734169
26
train loss item: 0.1638490855693817
27
train loss item: 0.16101078689098358
28
train loss item: 0.055549874901771545
29
train loss item: 0.49993807077407837
30
train loss item: 1.8521627187728882
31
train loss item: 0.399419903755188
32
train loss item: 0.08740422129631042
33
train loss item: 0.269759863615036
34
train loss item: 0.12840047478675842
35
train loss item: 2.096942901611328
36
train loss item: 0.35605955123901367
37
train loss item: 0.3335220515727997
38
train loss item: 0.35879892110824585
39
train loss item: 0.16002418100833893
40
train loss item: 0.1339409053325653
41
train loss item: 0.18264536559581757
42
train loss item: 0.22816739976406097
43
train loss item: 0.1338604986667633
44
train loss item: 0.49259960651397705
45
train loss item: 0.09963227808475494
46
train loss item: 0.09645040333271027
47
train loss item: 0.2458999902009964
48
train loss item: 0.15308301150798798
49
train loss item: 0.1130584329366684
50
train loss item: 0.1927465945482254
51
train loss item: 0.6690737009048462
52
train loss item: 0.05792322754859924
53
train loss item: 0.11310919374227524
54
train loss item: 1.9823542833328247
55
train loss item: 0.13774096965789795
56
train loss item: 0.17067861557006836
57
train loss item: 0.17991164326667786
58
train loss item: 0.12871196866035461
59
train loss item: 0.10483206063508987
60
train loss item: 0.6198706030845642
61
train loss item: 1.8637183904647827
62
train loss item: 0.1419769823551178
63
train loss item: 0.26247239112854004
64
train loss item: 0.12052682042121887
65
train loss item: 0.38259145617485046
66
train loss item: 0.3244319558143616
67
train loss item: 0.1523858606815338
68
train loss item: 0.20556855201721191
69
train loss item: 0.2246982455253601
70
train loss item: 0.1760922521352768
71
train loss item: 0.10168302804231644
72
train loss item: 0.11480052024126053
73
train loss item: 0.2183261513710022
74
train loss item: 0.07490433752536774
75
train loss item: 0.09246796369552612
76
train loss item: 0.6167716383934021
77
train loss item: 1.1291825771331787
78
train loss item: 0.05547009035944939
79
train loss item: 0.2085203379392624
80
train loss item: 0.0863901823759079
81
train loss item: 0.14131119847297668
82
train loss item: 0.14279773831367493
83
train loss item: 0.44476279616355896
84
train loss item: 0.34849080443382263
85
train loss item: 0.3634168803691864
86
train loss item: 3.8720996379852295
87
train loss item: 0.12292901426553726
88
train loss item: 0.296512633562088
epoch train loss: 0.3707724168394389
testing phase
test loss item: 0.1527113914489746
test loss item: 0.088907890021801
test loss item: 0.5159359574317932
test loss item: 0.19627124071121216
test loss item: 0.2123660147190094
test loss item: 0.10133246332406998
test loss item: 1.4013806581497192
test loss item: 0.45139750838279724
test loss item: 0.19992117583751678
test loss item: 0.33532750606536865
test loss item: 0.7307170629501343
test loss item: 0.13848429918289185
test loss item: 0.15513181686401367
test loss item: 0.23542453348636627
test loss item: 0.14516927301883698
test loss item: 0.0697479397058487
test loss item: 0.23910310864448547
test loss item: 0.39522451162338257
test loss item: 0.5532603859901428
test loss item: 0.2251872420310974
test loss item: 0.6364747881889343
test loss item: 0.3349919617176056
test loss item: 0.24177932739257812
test loss item: 0.14904828369617462
test loss item: 0.17847824096679688
test loss item: 0.18823155760765076
test loss item: 0.27177008986473083
test loss item: 0.15831288695335388
test loss item: 0.2799675166606903
test loss item: 0.2878277003765106
test loss item: 0.6665135025978088
test loss item: 0.06741994619369507
test loss item: 0.12517274916172028
test loss item: 0.48136621713638306
test loss item: 0.3644298017024994
test loss item: 0.35534989833831787
test loss item: 0.6683205962181091
test loss item: 1.2435554265975952
test loss item: 0.38675081729888916
test loss item: 0.2386394441127777
test loss item: 0.25938302278518677
test loss item: 0.1455826461315155
test loss item: 0.30315762758255005
test loss item: 0.17595286667346954
test loss item: 0.4949054718017578
test loss item: 0.33647847175598145
test loss item: 0.2385541945695877
test loss item: 0.1877657026052475
test loss item: 0.40853652358055115
test loss item: 0.5957701802253723
test loss item: 0.25861459970474243
test loss item: 0.11380226910114288
test loss item: 0.19961033761501312
test loss item: 0.1346873790025711
test loss item: 0.2613603174686432
test loss item: 0.7279863953590393
test loss item: 0.4650837481021881
test loss item: 0.21374844014644623
test loss item: 0.20032823085784912
test loss item: 0.1760864406824112
test loss item: 0.38476401567459106
test loss item: 0.21180251240730286
test loss item: 0.18245168030261993
test loss item: 0.21560265123844147
test loss item: 0.7247185111045837
test loss item: 0.2700730264186859
test loss item: 0.2709050476551056
test loss item: 0.21988238394260406
test loss item: 0.4447373151779175
test loss item: 0.3435249328613281
test loss item: 0.06641419231891632
test loss item: 0.8084352016448975
test loss item: 0.26938754320144653
test loss item: 0.3584893047809601
test loss item: 0.1253717839717865
test loss item: 0.11980468779802322
test loss item: 0.15287864208221436
test loss item: 1.2568140029907227
test loss item: 0.3593323230743408
test loss item: 0.1590147763490677
test loss item: 0.07039579749107361
test loss item: 0.8376748561859131
test loss item: 0.7385361194610596
test loss item: 0.8708856701850891
test loss item: 0.18253643810749054
test loss item: 0.18112392723560333
test loss item: 0.06324276328086853
test loss item: 0.059932418167591095
test loss item: 0.1772363930940628
Epoch [33/50], Training Loss: 0.3708, Testing Loss: 0.3359
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 34/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3383950889110565
1
train loss item: 0.8343450427055359
2
train loss item: 0.15381765365600586
3
train loss item: 0.3446573317050934
4
train loss item: 0.27250370383262634
5
train loss item: 0.2289656698703766
6
train loss item: 0.17241041362285614
7
train loss item: 0.5751549601554871
8
train loss item: 0.087681345641613
9
train loss item: 0.1751694679260254
10
train loss item: 0.21774768829345703
11
train loss item: 0.2177121639251709
12
train loss item: 0.10715611279010773
13
train loss item: 0.34255659580230713
14
train loss item: 0.16878877580165863
15
train loss item: 0.43378040194511414
16
train loss item: 0.05611984059214592
17
train loss item: 0.20362260937690735
18
train loss item: 0.22390824556350708
19
train loss item: 0.17748266458511353
20
train loss item: 0.15277200937271118
21
train loss item: 0.10112300515174866
22
train loss item: 0.6454415917396545
23
train loss item: 0.6025400161743164
24
train loss item: 0.3858150839805603
25
train loss item: 0.15188910067081451
26
train loss item: 0.15553520619869232
27
train loss item: 0.1577124297618866
28
train loss item: 0.053998805582523346
29
train loss item: 0.4889460802078247
30
train loss item: 1.8327432870864868
31
train loss item: 0.3901086151599884
32
train loss item: 0.08491440117359161
33
train loss item: 0.2677094638347626
34
train loss item: 0.12595345079898834
35
train loss item: 2.083374500274658
36
train loss item: 0.34902918338775635
37
train loss item: 0.329495370388031
38
train loss item: 0.3481232225894928
39
train loss item: 0.1556336134672165
40
train loss item: 0.12876877188682556
41
train loss item: 0.1784774363040924
42
train loss item: 0.22826138138771057
43
train loss item: 0.12961691617965698
44
train loss item: 0.4868956506252289
45
train loss item: 0.10107655823230743
46
train loss item: 0.09198474884033203
47
train loss item: 0.24077081680297852
48
train loss item: 0.14951135218143463
49
train loss item: 0.11243369430303574
50
train loss item: 0.18974041938781738
51
train loss item: 0.6584458351135254
52
train loss item: 0.05702345073223114
53
train loss item: 0.11470844596624374
54
train loss item: 1.9696425199508667
55
train loss item: 0.13561420142650604
56
train loss item: 0.16953054070472717
57
train loss item: 0.17598193883895874
58
train loss item: 0.12222738564014435
59
train loss item: 0.10630471259355545
60
train loss item: 0.6064860224723816
61
train loss item: 1.8480298519134521
62
train loss item: 0.1359308660030365
63
train loss item: 0.2584596872329712
64
train loss item: 0.118737131357193
65
train loss item: 0.37356916069984436
66
train loss item: 0.31861612200737
67
train loss item: 0.14738698303699493
68
train loss item: 0.1994030773639679
69
train loss item: 0.22007331252098083
70
train loss item: 0.17197497189044952
71
train loss item: 0.09859933704137802
72
train loss item: 0.11496730148792267
73
train loss item: 0.21323361992835999
74
train loss item: 0.07390347123146057
75
train loss item: 0.09197279065847397
76
train loss item: 0.604030191898346
77
train loss item: 1.1191284656524658
78
train loss item: 0.05522127449512482
79
train loss item: 0.20521047711372375
80
train loss item: 0.08517539501190186
81
train loss item: 0.13669823110103607
82
train loss item: 0.1412009298801422
83
train loss item: 0.4398149251937866
84
train loss item: 0.34270790219306946
85
train loss item: 0.35155126452445984
86
train loss item: 3.8529183864593506
87
train loss item: 0.12421610951423645
88
train loss item: 0.2892426550388336
epoch train loss: 0.36494731354746923
testing phase
test loss item: 0.15216317772865295
test loss item: 0.08776948601007462
test loss item: 0.5110057592391968
test loss item: 0.19602257013320923
test loss item: 0.21406076848506927
test loss item: 0.11031529307365417
test loss item: 1.3832545280456543
test loss item: 0.45708537101745605
test loss item: 0.19685132801532745
test loss item: 0.3319680392742157
test loss item: 0.7209712862968445
test loss item: 0.13608311116695404
test loss item: 0.15305429697036743
test loss item: 0.23432345688343048
test loss item: 0.14353404939174652
test loss item: 0.06692696362733841
test loss item: 0.2387249916791916
test loss item: 0.39326924085617065
test loss item: 0.5502296686172485
test loss item: 0.2244146317243576
test loss item: 0.6364955902099609
test loss item: 0.3348817825317383
test loss item: 0.2402740865945816
test loss item: 0.1491401046514511
test loss item: 0.17735610902309418
test loss item: 0.18772463500499725
test loss item: 0.2701932489871979
test loss item: 0.16194848716259003
test loss item: 0.2763209939002991
test loss item: 0.2850978672504425
test loss item: 0.6602169275283813
test loss item: 0.06508708745241165
test loss item: 0.12574778497219086
test loss item: 0.476567804813385
test loss item: 0.362455815076828
test loss item: 0.35398563742637634
test loss item: 0.6631960272789001
test loss item: 1.2278931140899658
test loss item: 0.38291096687316895
test loss item: 0.23828692734241486
test loss item: 0.255825400352478
test loss item: 0.13967646658420563
test loss item: 0.30021554231643677
test loss item: 0.1765270084142685
test loss item: 0.49330294132232666
test loss item: 0.33693861961364746
test loss item: 0.2370380163192749
test loss item: 0.18862491846084595
test loss item: 0.4053274989128113
test loss item: 0.5893410444259644
test loss item: 0.2573259472846985
test loss item: 0.11325602233409882
test loss item: 0.1999305635690689
test loss item: 0.13563023507595062
test loss item: 0.2614261209964752
test loss item: 0.7210845351219177
test loss item: 0.4613783061504364
test loss item: 0.21704009175300598
test loss item: 0.20196805894374847
test loss item: 0.1736232042312622
test loss item: 0.3806440234184265
test loss item: 0.2157360464334488
test loss item: 0.18238680064678192
test loss item: 0.21031536161899567
test loss item: 0.7245466113090515
test loss item: 0.26882851123809814
test loss item: 0.26947206258773804
test loss item: 0.21514928340911865
test loss item: 0.4394463002681732
test loss item: 0.3409419357776642
test loss item: 0.06355874240398407
test loss item: 0.8022014498710632
test loss item: 0.2697230279445648
test loss item: 0.35540181398391724
test loss item: 0.12611855566501617
test loss item: 0.11719762533903122
test loss item: 0.15153242647647858
test loss item: 1.249303936958313
test loss item: 0.3544187545776367
test loss item: 0.16349917650222778
test loss item: 0.07051374763250351
test loss item: 0.8266322612762451
test loss item: 0.7315372824668884
test loss item: 0.8633863925933838
test loss item: 0.1815275400876999
test loss item: 0.18187952041625977
test loss item: 0.06431009620428085
test loss item: 0.05938594043254852
test loss item: 0.1706535667181015
Epoch [34/50], Training Loss: 0.3649, Testing Loss: 0.3336
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 35/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3298273980617523
1
train loss item: 0.814149796962738
2
train loss item: 0.14900629222393036
3
train loss item: 0.3335427939891815
4
train loss item: 0.2620668411254883
5
train loss item: 0.2211177498102188
6
train loss item: 0.17141160368919373
7
train loss item: 0.5666597485542297
8
train loss item: 0.08720748126506805
9
train loss item: 0.17084971070289612
10
train loss item: 0.21136723458766937
11
train loss item: 0.21117793023586273
12
train loss item: 0.10948175191879272
13
train loss item: 0.33197352290153503
14
train loss item: 0.16196559369564056
15
train loss item: 0.43347597122192383
16
train loss item: 0.058587562292814255
17
train loss item: 0.20014546811580658
18
train loss item: 0.2203996628522873
19
train loss item: 0.17646950483322144
20
train loss item: 0.15355883538722992
21
train loss item: 0.10420887172222137
22
train loss item: 0.6387283205986023
23
train loss item: 0.5827214121818542
24
train loss item: 0.38253673911094666
25
train loss item: 0.1460699886083603
26
train loss item: 0.15001828968524933
27
train loss item: 0.14977669715881348
28
train loss item: 0.05526930093765259
29
train loss item: 0.4847725033760071
30
train loss item: 1.8085304498672485
31
train loss item: 0.3774227797985077
32
train loss item: 0.08013799786567688
33
train loss item: 0.25450602173805237
34
train loss item: 0.12124140560626984
35
train loss item: 2.0691964626312256
36
train loss item: 0.34107935428619385
37
train loss item: 0.32118940353393555
38
train loss item: 0.33282196521759033
39
train loss item: 0.15455229580402374
40
train loss item: 0.129623681306839
41
train loss item: 0.17069214582443237
42
train loss item: 0.22666575014591217
43
train loss item: 0.12602710723876953
44
train loss item: 0.47890669107437134
45
train loss item: 0.09633421897888184
46
train loss item: 0.08590978384017944
47
train loss item: 0.23955486714839935
48
train loss item: 0.14497509598731995
49
train loss item: 0.10890337824821472
50
train loss item: 0.18997302651405334
51
train loss item: 0.6472919583320618
52
train loss item: 0.057956211268901825
53
train loss item: 0.11113394796848297
54
train loss item: 1.9558383226394653
55
train loss item: 0.1345950812101364
56
train loss item: 0.16496042907238007
57
train loss item: 0.17427822947502136
58
train loss item: 0.12183928489685059
59
train loss item: 0.10126592963933945
60
train loss item: 0.594139814376831
61
train loss item: 1.8249027729034424
62
train loss item: 0.13529141247272491
63
train loss item: 0.25364115834236145
64
train loss item: 0.1131184920668602
65
train loss item: 0.3646323084831238
66
train loss item: 0.31736811995506287
67
train loss item: 0.14615054428577423
68
train loss item: 0.20298467576503754
69
train loss item: 0.2162708193063736
70
train loss item: 0.16845591366291046
71
train loss item: 0.0969633236527443
72
train loss item: 0.11025978624820709
73
train loss item: 0.21035195887088776
74
train loss item: 0.0692414939403534
75
train loss item: 0.09244202822446823
76
train loss item: 0.5878804922103882
77
train loss item: 1.1110576391220093
78
train loss item: 0.05700637400150299
79
train loss item: 0.1991046965122223
80
train loss item: 0.08133547008037567
81
train loss item: 0.13616377115249634
82
train loss item: 0.13722307980060577
83
train loss item: 0.43256470561027527
84
train loss item: 0.33235910534858704
85
train loss item: 0.3391326665878296
86
train loss item: 3.8305158615112305
87
train loss item: 0.12122160196304321
88
train loss item: 0.2859697639942169
epoch train loss: 0.3591426708473918
testing phase
test loss item: 0.15678448975086212
test loss item: 0.0870608240365982
test loss item: 0.49731943011283875
test loss item: 0.1980113536119461
test loss item: 0.2063576728105545
test loss item: 0.10774020105600357
test loss item: 1.352445125579834
test loss item: 0.43033942580223083
test loss item: 0.19278323650360107
test loss item: 0.32304203510284424
test loss item: 0.7048460841178894
test loss item: 0.13539953529834747
test loss item: 0.1445208489894867
test loss item: 0.23738698661327362
test loss item: 0.13838906586170197
test loss item: 0.07537975162267685
test loss item: 0.2373344600200653
test loss item: 0.38373664021492004
test loss item: 0.5332949757575989
test loss item: 0.21833060681819916
test loss item: 0.6167954206466675
test loss item: 0.3296626806259155
test loss item: 0.23685979843139648
test loss item: 0.1470762938261032
test loss item: 0.17761392891407013
test loss item: 0.1829821616411209
test loss item: 0.26711875200271606
test loss item: 0.1548624187707901
test loss item: 0.2682212293148041
test loss item: 0.27831387519836426
test loss item: 0.6466318368911743
test loss item: 0.07248890399932861
test loss item: 0.12489226460456848
test loss item: 0.4654492139816284
test loss item: 0.35358136892318726
test loss item: 0.3481150269508362
test loss item: 0.6432570219039917
test loss item: 1.197690725326538
test loss item: 0.3736379146575928
test loss item: 0.2346304953098297
test loss item: 0.2552511692047119
test loss item: 0.14271622896194458
test loss item: 0.29349464178085327
test loss item: 0.18123620748519897
test loss item: 0.4771691560745239
test loss item: 0.3262225091457367
test loss item: 0.23467838764190674
test loss item: 0.18704640865325928
test loss item: 0.39201292395591736
test loss item: 0.5753118991851807
test loss item: 0.24704882502555847
test loss item: 0.11019068211317062
test loss item: 0.1996602565050125
test loss item: 0.1425953507423401
test loss item: 0.25439488887786865
test loss item: 0.7048637270927429
test loss item: 0.4452451467514038
test loss item: 0.21103043854236603
test loss item: 0.1997675746679306
test loss item: 0.16669905185699463
test loss item: 0.37226924300193787
test loss item: 0.21093375980854034
test loss item: 0.18064071238040924
test loss item: 0.20379804074764252
test loss item: 0.7052172422409058
test loss item: 0.2718592584133148
test loss item: 0.26026293635368347
test loss item: 0.21034380793571472
test loss item: 0.4278489351272583
test loss item: 0.33190616965293884
test loss item: 0.06337041407823563
test loss item: 0.7755434513092041
test loss item: 0.2690909504890442
test loss item: 0.3506487309932709
test loss item: 0.12692399322986603
test loss item: 0.12248433381319046
test loss item: 0.14843161404132843
test loss item: 1.217677116394043
test loss item: 0.35075944662094116
test loss item: 0.16280272603034973
test loss item: 0.0739474669098854
test loss item: 0.8036185503005981
test loss item: 0.7128780484199524
test loss item: 0.8411875367164612
test loss item: 0.17872846126556396
test loss item: 0.18125374615192413
test loss item: 0.07326163351535797
test loss item: 0.07141396403312683
test loss item: 0.16865220665931702
Epoch [35/50], Training Loss: 0.3591, Testing Loss: 0.3269
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 36/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3251832127571106
1
train loss item: 0.7903741002082825
2
train loss item: 0.14440932869911194
3
train loss item: 0.32645756006240845
4
train loss item: 0.2593182921409607
5
train loss item: 0.2161182463169098
6
train loss item: 0.16744385659694672
7
train loss item: 0.5566900372505188
8
train loss item: 0.08994244784116745
9
train loss item: 0.16731856763362885
10
train loss item: 0.21062517166137695
11
train loss item: 0.20958806574344635
12
train loss item: 0.11194818466901779
13
train loss item: 0.3293660283088684
14
train loss item: 0.15913113951683044
15
train loss item: 0.4209864139556885
16
train loss item: 0.05919033661484718
17
train loss item: 0.1954764872789383
18
train loss item: 0.2167893946170807
19
train loss item: 0.1681901216506958
20
train loss item: 0.14731831848621368
21
train loss item: 0.10279685258865356
22
train loss item: 0.6162389516830444
23
train loss item: 0.5671816468238831
24
train loss item: 0.3721398413181305
25
train loss item: 0.1438080072402954
26
train loss item: 0.14513126015663147
27
train loss item: 0.1442333459854126
28
train loss item: 0.05592288821935654
29
train loss item: 0.47238561511039734
30
train loss item: 1.7862433195114136
31
train loss item: 0.3738720118999481
32
train loss item: 0.0777253657579422
33
train loss item: 0.24978512525558472
34
train loss item: 0.11940490454435349
35
train loss item: 2.0553455352783203
36
train loss item: 0.3411647379398346
37
train loss item: 0.3208501636981964
38
train loss item: 0.34092074632644653
39
train loss item: 0.15465092658996582
40
train loss item: 0.1281728446483612
41
train loss item: 0.16542871296405792
42
train loss item: 0.22319696843624115
43
train loss item: 0.12426222115755081
44
train loss item: 0.47295284271240234
45
train loss item: 0.09419755637645721
46
train loss item: 0.08289968967437744
47
train loss item: 0.23462055623531342
48
train loss item: 0.14135709404945374
49
train loss item: 0.10809817910194397
50
train loss item: 0.18315112590789795
51
train loss item: 0.6387620568275452
52
train loss item: 0.05894960090517998
53
train loss item: 0.10678399354219437
54
train loss item: 1.941724419593811
55
train loss item: 0.13349401950836182
56
train loss item: 0.15976902842521667
57
train loss item: 0.17256765067577362
58
train loss item: 0.12164018303155899
59
train loss item: 0.09768928587436676
60
train loss item: 0.5754099488258362
61
train loss item: 1.80460786819458
62
train loss item: 0.13376207649707794
63
train loss item: 0.24917608499526978
64
train loss item: 0.11111252754926682
65
train loss item: 0.35925620794296265
66
train loss item: 0.31343477964401245
67
train loss item: 0.1440948247909546
68
train loss item: 0.19392313063144684
69
train loss item: 0.21098920702934265
70
train loss item: 0.16730479896068573
71
train loss item: 0.09334440529346466
72
train loss item: 0.10761361569166183
73
train loss item: 0.20588088035583496
74
train loss item: 0.06877463310956955
75
train loss item: 0.09298314899206161
76
train loss item: 0.5712776780128479
77
train loss item: 1.1017460823059082
78
train loss item: 0.05854738503694534
79
train loss item: 0.19637133181095123
80
train loss item: 0.08170752972364426
81
train loss item: 0.1348559409379959
82
train loss item: 0.1336323469877243
83
train loss item: 0.42570704221725464
84
train loss item: 0.3318120241165161
85
train loss item: 0.3296058773994446
86
train loss item: 3.8089144229888916
87
train loss item: 0.11767804622650146
88
train loss item: 0.27780771255493164
epoch train loss: 0.3539631027686462
testing phase
test loss item: 0.15532925724983215
test loss item: 0.09700269252061844
test loss item: 0.46120545268058777
test loss item: 0.19740207493305206
test loss item: 0.1962636560201645
test loss item: 0.0992974266409874
test loss item: 1.3701497316360474
test loss item: 0.47833549976348877
test loss item: 0.17606034874916077
test loss item: 0.30371350049972534
test loss item: 0.655599057674408
test loss item: 0.1350429505109787
test loss item: 0.15522484481334686
test loss item: 0.24743802845478058
test loss item: 0.13620999455451965
test loss item: 0.10040219873189926
test loss item: 0.24487842619419098
test loss item: 0.36013317108154297
test loss item: 0.5558981895446777
test loss item: 0.23585377633571625
test loss item: 0.5819482803344727
test loss item: 0.3395289480686188
test loss item: 0.23577217757701874
test loss item: 0.14959895610809326
test loss item: 0.172538623213768
test loss item: 0.1847381442785263
test loss item: 0.26235273480415344
test loss item: 0.1456165760755539
test loss item: 0.26065942645072937
test loss item: 0.27100592851638794
test loss item: 0.6202352643013
test loss item: 0.09470558911561966
test loss item: 0.12778428196907043
test loss item: 0.43833252787590027
test loss item: 0.33123916387557983
test loss item: 0.3454935848712921
test loss item: 0.6571228504180908
test loss item: 1.1013721227645874
test loss item: 0.3521430790424347
test loss item: 0.231794074177742
test loss item: 0.2577522397041321
test loss item: 0.14784559607505798
test loss item: 0.26866596937179565
test loss item: 0.18221643567085266
test loss item: 0.44886377453804016
test loss item: 0.3494277596473694
test loss item: 0.2326635867357254
test loss item: 0.21403613686561584
test loss item: 0.37608417868614197
test loss item: 0.5471439957618713
test loss item: 0.2245432287454605
test loss item: 0.12519913911819458
test loss item: 0.19232535362243652
test loss item: 0.14061298966407776
test loss item: 0.23566268384456635
test loss item: 0.6481253504753113
test loss item: 0.4526870548725128
test loss item: 0.20145940780639648
test loss item: 0.2040105015039444
test loss item: 0.15889249742031097
test loss item: 0.33822867274284363
test loss item: 0.2314939796924591
test loss item: 0.1875973343849182
test loss item: 0.20395421981811523
test loss item: 0.6850835084915161
test loss item: 0.2688281536102295
test loss item: 0.26976415514945984
test loss item: 0.21051456034183502
test loss item: 0.4134162366390228
test loss item: 0.3528810739517212
test loss item: 0.07756959646940231
test loss item: 0.8088502883911133
test loss item: 0.27136319875717163
test loss item: 0.35767367482185364
test loss item: 0.1346837878227234
test loss item: 0.12910474836826324
test loss item: 0.15079165995121002
test loss item: 1.134121060371399
test loss item: 0.3507702052593231
test loss item: 0.15634572505950928
test loss item: 0.07006395608186722
test loss item: 0.7819668054580688
test loss item: 0.7037683725357056
test loss item: 0.7797707319259644
test loss item: 0.18304836750030518
test loss item: 0.1847793608903885
test loss item: 0.07833018153905869
test loss item: 0.09195581078529358
test loss item: 0.15940089523792267
Epoch [36/50], Training Loss: 0.3540, Testing Loss: 0.3218
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 37/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.31853240728378296
1
train loss item: 0.7759101986885071
2
train loss item: 0.14460746943950653
3
train loss item: 0.3082740902900696
4
train loss item: 0.25724032521247864
5
train loss item: 0.21054776012897491
6
train loss item: 0.16729924082756042
7
train loss item: 0.5404170751571655
8
train loss item: 0.08134938776493073
9
train loss item: 0.17049665749073029
10
train loss item: 0.20499953627586365
11
train loss item: 0.2012096643447876
12
train loss item: 0.10828914493322372
13
train loss item: 0.31745290756225586
14
train loss item: 0.1546761393547058
15
train loss item: 0.42846396565437317
16
train loss item: 0.054682645946741104
17
train loss item: 0.1923249512910843
18
train loss item: 0.21329966187477112
19
train loss item: 0.17714858055114746
20
train loss item: 0.1515328735113144
21
train loss item: 0.10654883831739426
22
train loss item: 0.6204910278320312
23
train loss item: 0.5384794473648071
24
train loss item: 0.37802162766456604
25
train loss item: 0.14013926684856415
26
train loss item: 0.14128199219703674
27
train loss item: 0.14140772819519043
28
train loss item: 0.052281949669122696
29
train loss item: 0.4685411751270294
30
train loss item: 1.7519031763076782
31
train loss item: 0.3606243431568146
32
train loss item: 0.0821257010102272
33
train loss item: 0.23014676570892334
34
train loss item: 0.11334031075239182
35
train loss item: 2.0378851890563965
36
train loss item: 0.3323673903942108
37
train loss item: 0.3174646198749542
38
train loss item: 0.3278200924396515
39
train loss item: 0.15508148074150085
40
train loss item: 0.12926220893859863
41
train loss item: 0.16185034811496735
42
train loss item: 0.2231961339712143
43
train loss item: 0.12897565960884094
44
train loss item: 0.45917975902557373
45
train loss item: 0.09220559149980545
46
train loss item: 0.08692110329866409
47
train loss item: 0.23611223697662354
48
train loss item: 0.14419549703598022
49
train loss item: 0.10517287999391556
50
train loss item: 0.18983212113380432
51
train loss item: 0.6237196326255798
52
train loss item: 0.0565321259200573
53
train loss item: 0.102313332259655
54
train loss item: 1.9230390787124634
55
train loss item: 0.13327327370643616
56
train loss item: 0.1590787172317505
57
train loss item: 0.17228570580482483
58
train loss item: 0.12771883606910706
59
train loss item: 0.09867846965789795
60
train loss item: 0.5647619366645813
61
train loss item: 1.7778197526931763
62
train loss item: 0.13052473962306976
63
train loss item: 0.24943037331104279
64
train loss item: 0.11434176564216614
65
train loss item: 0.36138680577278137
66
train loss item: 0.32147204875946045
67
train loss item: 0.14319844543933868
68
train loss item: 0.2014150172472
69
train loss item: 0.2152024358510971
70
train loss item: 0.16479898989200592
71
train loss item: 0.09050742536783218
72
train loss item: 0.10552563518285751
73
train loss item: 0.20765741169452667
74
train loss item: 0.0693422481417656
75
train loss item: 0.08782026171684265
76
train loss item: 0.5527299046516418
77
train loss item: 1.0942538976669312
78
train loss item: 0.05490008369088173
79
train loss item: 0.19073060154914856
80
train loss item: 0.08442263305187225
81
train loss item: 0.13310569524765015
82
train loss item: 0.1280740648508072
83
train loss item: 0.42413365840911865
84
train loss item: 0.32785627245903015
85
train loss item: 0.31618863344192505
86
train loss item: 3.7838268280029297
87
train loss item: 0.11415895819664001
88
train loss item: 0.28601354360580444
epoch train loss: 0.3497061751196893
testing phase
test loss item: 0.1603594571352005
test loss item: 0.09840667247772217
test loss item: 0.5096865296363831
test loss item: 0.19939157366752625
test loss item: 0.20823994278907776
test loss item: 0.10967382043600082
test loss item: 1.2775338888168335
test loss item: 0.39377379417419434
test loss item: 0.20201413333415985
test loss item: 0.32757753133773804
test loss item: 0.732940673828125
test loss item: 0.13579802215099335
test loss item: 0.1363840252161026
test loss item: 0.2528029978275299
test loss item: 0.1466100513935089
test loss item: 0.09656701236963272
test loss item: 0.22241392731666565
test loss item: 0.3908594250679016
test loss item: 0.530246913433075
test loss item: 0.20722608268260956
test loss item: 0.6177622675895691
test loss item: 0.30794546008110046
test loss item: 0.2395259439945221
test loss item: 0.14325487613677979
test loss item: 0.17691448330879211
test loss item: 0.1718587577342987
test loss item: 0.26645052433013916
test loss item: 0.15129339694976807
test loss item: 0.26542913913726807
test loss item: 0.2754586338996887
test loss item: 0.6530573964118958
test loss item: 0.09261424094438553
test loss item: 0.12545764446258545
test loss item: 0.4701501131057739
test loss item: 0.3635092079639435
test loss item: 0.38534700870513916
test loss item: 0.6219346523284912
test loss item: 1.2428812980651855
test loss item: 0.37555477023124695
test loss item: 0.22125640511512756
test loss item: 0.24544845521450043
test loss item: 0.15118207037448883
test loss item: 0.3006318509578705
test loss item: 0.17888997495174408
test loss item: 0.4757075905799866
test loss item: 0.2983418107032776
test loss item: 0.23525699973106384
test loss item: 0.19673261046409607
test loss item: 0.39202210307121277
test loss item: 0.5848957896232605
test loss item: 0.250019907951355
test loss item: 0.1078973188996315
test loss item: 0.20016151666641235
test loss item: 0.15179097652435303
test loss item: 0.2583702504634857
test loss item: 0.7383396625518799
test loss item: 0.44400081038475037
test loss item: 0.21133556962013245
test loss item: 0.19401027262210846
test loss item: 0.16726821660995483
test loss item: 0.3810400366783142
test loss item: 0.1887717992067337
test loss item: 0.1706097573041916
test loss item: 0.19229952991008759
test loss item: 0.7080491185188293
test loss item: 0.2736610174179077
test loss item: 0.23943737149238586
test loss item: 0.199905663728714
test loss item: 0.4311957061290741
test loss item: 0.3918567895889282
test loss item: 0.07746001332998276
test loss item: 0.7088039517402649
test loss item: 0.27585142850875854
test loss item: 0.32196661829948425
test loss item: 0.1284603774547577
test loss item: 0.1297592967748642
test loss item: 0.14465737342834473
test loss item: 1.2528570890426636
test loss item: 0.3576356768608093
test loss item: 0.1613636165857315
test loss item: 0.08020589500665665
test loss item: 0.8021414279937744
test loss item: 0.7093833088874817
test loss item: 0.8692834377288818
test loss item: 0.1775825321674347
test loss item: 0.178574338555336
test loss item: 0.08734216541051865
test loss item: 0.09564889967441559
test loss item: 0.17743265628814697
Epoch [37/50], Training Loss: 0.3497, Testing Loss: 0.3281
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Epoch 38/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.32128867506980896
1
train loss item: 0.7642226815223694
2
train loss item: 0.14421512186527252
3
train loss item: 0.3456166088581085
4
train loss item: 0.2711879014968872
5
train loss item: 0.20200665295124054
6
train loss item: 0.16498492658138275
7
train loss item: 0.5415709018707275
8
train loss item: 0.09512202441692352
9
train loss item: 0.16877542436122894
10
train loss item: 0.21372509002685547
11
train loss item: 0.21502764523029327
12
train loss item: 0.10598254203796387
13
train loss item: 0.33735135197639465
14
train loss item: 0.16312168538570404
15
train loss item: 0.40382689237594604
16
train loss item: 0.05342122167348862
17
train loss item: 0.1989677995443344
18
train loss item: 0.21204863488674164
19
train loss item: 0.15342824161052704
20
train loss item: 0.1475888043642044
21
train loss item: 0.11012931168079376
22
train loss item: 0.5866531729698181
23
train loss item: 0.5558226704597473
24
train loss item: 0.3488560914993286
25
train loss item: 0.1400025337934494
26
train loss item: 0.13945770263671875
27
train loss item: 0.1496468484401703
28
train loss item: 0.05334235355257988
29
train loss item: 0.4626542925834656
30
train loss item: 1.7543604373931885
31
train loss item: 0.3765052556991577
32
train loss item: 0.08801742643117905
33
train loss item: 0.2711355984210968
34
train loss item: 0.12264425307512283
35
train loss item: 2.030421257019043
36
train loss item: 0.36519742012023926
37
train loss item: 0.3334791958332062
38
train loss item: 0.396528035402298
39
train loss item: 0.14922408759593964
40
train loss item: 0.1184951663017273
41
train loss item: 0.17263710498809814
42
train loss item: 0.2163853943347931
43
train loss item: 0.12617555260658264
44
train loss item: 0.4719393253326416
45
train loss item: 0.10189493000507355
46
train loss item: 0.08617857843637466
47
train loss item: 0.22387424111366272
48
train loss item: 0.14278757572174072
49
train loss item: 0.11939633637666702
50
train loss item: 0.1707768589258194
51
train loss item: 0.6361883282661438
52
train loss item: 0.05368565022945404
53
train loss item: 0.11524996906518936
54
train loss item: 1.9160921573638916
55
train loss item: 0.13380923867225647
56
train loss item: 0.1585017889738083
57
train loss item: 0.16113066673278809
58
train loss item: 0.11815740913152695
59
train loss item: 0.10043773800134659
60
train loss item: 0.555637001991272
61
train loss item: 1.7869887351989746
62
train loss item: 0.12536074221134186
63
train loss item: 0.24671709537506104
64
train loss item: 0.12081481516361237
65
train loss item: 0.37328800559043884
66
train loss item: 0.3265360891819
67
train loss item: 0.14325301349163055
68
train loss item: 0.1737985461950302
69
train loss item: 0.20553043484687805
70
train loss item: 0.1726129800081253
71
train loss item: 0.08508612215518951
72
train loss item: 0.11445125192403793
73
train loss item: 0.19975163042545319
74
train loss item: 0.0761975422501564
75
train loss item: 0.0899711474776268
76
train loss item: 0.5502173900604248
77
train loss item: 1.0881900787353516
78
train loss item: 0.053852662444114685
79
train loss item: 0.19867341220378876
80
train loss item: 0.08808087557554245
81
train loss item: 0.12790842354297638
82
train loss item: 0.13743026554584503
83
train loss item: 0.4361586570739746
84
train loss item: 0.3634355068206787
85
train loss item: 0.32584574818611145
86
train loss item: 3.775428295135498
87
train loss item: 0.12769785523414612
88
train loss item: 0.2647109031677246
epoch train loss: 0.3520784046124206
testing phase
test loss item: 0.14915302395820618
test loss item: 0.08646722137928009
test loss item: 0.4616415798664093
test loss item: 0.19240093231201172
test loss item: 0.20416496694087982
test loss item: 0.11257903277873993
test loss item: 1.4361037015914917
test loss item: 0.5584259629249573
test loss item: 0.17436790466308594
test loss item: 0.30274954438209534
test loss item: 0.6667549014091492
test loss item: 0.13373316824436188
test loss item: 0.17118500173091888
test loss item: 0.2638084888458252
test loss item: 0.13603746891021729
test loss item: 0.06855539977550507
test loss item: 0.25095319747924805
test loss item: 0.35476019978523254
test loss item: 0.6074562072753906
test loss item: 0.260694682598114
test loss item: 0.5755850672721863
test loss item: 0.3513631224632263
test loss item: 0.23933570086956024
test loss item: 0.1485735923051834
test loss item: 0.16801127791404724
test loss item: 0.18803814053535461
test loss item: 0.26949411630630493
test loss item: 0.15454889833927155
test loss item: 0.25762975215911865
test loss item: 0.2752567231655121
test loss item: 0.6420837044715881
test loss item: 0.06262382864952087
test loss item: 0.12491489201784134
test loss item: 0.4324854612350464
test loss item: 0.3255636394023895
test loss item: 0.3756560981273651
test loss item: 0.7002341151237488
test loss item: 1.113625407218933
test loss item: 0.34551241993904114
test loss item: 0.230564147233963
test loss item: 0.2526778280735016
test loss item: 0.14175012707710266
test loss item: 0.26017001271247864
test loss item: 0.1789671927690506
test loss item: 0.43928855657577515
test loss item: 0.3736186623573303
test loss item: 0.22744432091712952
test loss item: 0.25410154461860657
test loss item: 0.3855750560760498
test loss item: 0.563489556312561
test loss item: 0.21674136817455292
test loss item: 0.14122265577316284
test loss item: 0.18937073647975922
test loss item: 0.135543093085289
test loss item: 0.23061244189739227
test loss item: 0.6529507637023926
test loss item: 0.4908272624015808
test loss item: 0.19754847884178162
test loss item: 0.20730376243591309
test loss item: 0.1588188260793686
test loss item: 0.3226826786994934
test loss item: 0.2481512427330017
test loss item: 0.18708913028240204
test loss item: 0.20529116690158844
test loss item: 0.7191216349601746
test loss item: 0.26269882917404175
test loss item: 0.28725001215934753
test loss item: 0.21237501502037048
test loss item: 0.41503098607063293
test loss item: 0.4185444712638855
test loss item: 0.06972561031579971
test loss item: 0.872800350189209
test loss item: 0.27597758173942566
test loss item: 0.3566339612007141
test loss item: 0.14412666857242584
test loss item: 0.12632189691066742
test loss item: 0.15113407373428345
test loss item: 1.1636559963226318
test loss item: 0.3620336949825287
test loss item: 0.1596328169107437
test loss item: 0.0750272274017334
test loss item: 0.8224195241928101
test loss item: 0.7383449673652649
test loss item: 0.8010193705558777
test loss item: 0.19344277679920197
test loss item: 0.19012446701526642
test loss item: 0.06623683869838715
test loss item: 0.05607597157359123
test loss item: 0.15407618880271912
Epoch [38/50], Training Loss: 0.3521, Testing Loss: 0.3295
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 39/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.30965808033943176
1
train loss item: 0.7634860873222351
2
train loss item: 0.15656068921089172
3
train loss item: 0.30765408277511597
4
train loss item: 0.2647102475166321
5
train loss item: 0.1977422684431076
6
train loss item: 0.18053685128688812
7
train loss item: 0.5235047340393066
8
train loss item: 0.090627521276474
9
train loss item: 0.1865069568157196
10
train loss item: 0.20440466701984406
11
train loss item: 0.20053929090499878
12
train loss item: 0.11114536970853806
13
train loss item: 0.30279475450515747
14
train loss item: 0.15125752985477448
15
train loss item: 0.4510619044303894
16
train loss item: 0.059785958379507065
17
train loss item: 0.19423030316829681
18
train loss item: 0.2158936709165573
19
train loss item: 0.19483114778995514
20
train loss item: 0.17338620126247406
21
train loss item: 0.12131136655807495
22
train loss item: 0.6372620463371277
23
train loss item: 0.5026381611824036
24
train loss item: 0.38247817754745483
25
train loss item: 0.13904696702957153
26
train loss item: 0.13969525694847107
27
train loss item: 0.14400964975357056
28
train loss item: 0.05648048594594002
29
train loss item: 0.4898286461830139
30
train loss item: 1.7108322381973267
31
train loss item: 0.3443913757801056
32
train loss item: 0.09874686598777771
33
train loss item: 0.20933178067207336
34
train loss item: 0.11215619742870331
35
train loss item: 2.013779878616333
36
train loss item: 0.3275381028652191
37
train loss item: 0.30990493297576904
38
train loss item: 0.31411996483802795
39
train loss item: 0.15928804874420166
40
train loss item: 0.14908266067504883
41
train loss item: 0.16368386149406433
42
train loss item: 0.2255515456199646
43
train loss item: 0.14061392843723297
44
train loss item: 0.4471530318260193
45
train loss item: 0.0858984962105751
46
train loss item: 0.10732158273458481
47
train loss item: 0.24082624912261963
48
train loss item: 0.1503465324640274
49
train loss item: 0.10990745574235916
50
train loss item: 0.20984980463981628
51
train loss item: 0.6159409284591675
52
train loss item: 0.06171542406082153
53
train loss item: 0.1019897311925888
54
train loss item: 1.8970364332199097
55
train loss item: 0.1402318924665451
56
train loss item: 0.1610555350780487
57
train loss item: 0.17511172592639923
58
train loss item: 0.1426289677619934
59
train loss item: 0.10237552970647812
60
train loss item: 0.5617437362670898
61
train loss item: 1.7422713041305542
62
train loss item: 0.13448400795459747
63
train loss item: 0.255330890417099
64
train loss item: 0.12398292869329453
65
train loss item: 0.35021403431892395
66
train loss item: 0.32755178213119507
67
train loss item: 0.14852769672870636
68
train loss item: 0.22244641184806824
69
train loss item: 0.2180393785238266
70
train loss item: 0.167030930519104
71
train loss item: 0.10182920843362808
72
train loss item: 0.12266027927398682
73
train loss item: 0.21976691484451294
74
train loss item: 0.06574784219264984
75
train loss item: 0.09040280431509018
76
train loss item: 0.5235229134559631
77
train loss item: 1.0879385471343994
78
train loss item: 0.06020462512969971
79
train loss item: 0.19145037233829498
80
train loss item: 0.0942697748541832
81
train loss item: 0.13229578733444214
82
train loss item: 0.12775972485542297
83
train loss item: 0.4294368326663971
84
train loss item: 0.31312644481658936
85
train loss item: 0.3081502616405487
86
train loss item: 3.746380090713501
87
train loss item: 0.11073994636535645
88
train loss item: 0.2907857298851013
epoch train loss: 0.3499951795413253
testing phase
test loss item: 0.1451290100812912
test loss item: 0.13774512708187103
test loss item: 0.5124046206474304
test loss item: 0.1856088936328888
test loss item: 0.20850218832492828
test loss item: 0.11157966405153275
test loss item: 1.2672604322433472
test loss item: 0.4160792827606201
test loss item: 0.19436216354370117
test loss item: 0.32504040002822876
test loss item: 0.7247404456138611
test loss item: 0.13499659299850464
test loss item: 0.14275667071342468
test loss item: 0.22782652080059052
test loss item: 0.15010343492031097
test loss item: 0.21888189017772675
test loss item: 0.2154800146818161
test loss item: 0.39196455478668213
test loss item: 0.5209213495254517
test loss item: 0.20011496543884277
test loss item: 0.6313165426254272
test loss item: 0.3010201156139374
test loss item: 0.23347467184066772
test loss item: 0.12940701842308044
test loss item: 0.1777089536190033
test loss item: 0.1712934821844101
test loss item: 0.2547639310359955
test loss item: 0.14955124258995056
test loss item: 0.2545807659626007
test loss item: 0.2727883756160736
test loss item: 0.641097903251648
test loss item: 0.19742469489574432
test loss item: 0.1110980287194252
test loss item: 0.46749448776245117
test loss item: 0.38519755005836487
test loss item: 0.3497520089149475
test loss item: 0.6238091588020325
test loss item: 1.2376008033752441
test loss item: 0.3701949715614319
test loss item: 0.2029360830783844
test loss item: 0.25461095571517944
test loss item: 0.13302181661128998
test loss item: 0.29702723026275635
test loss item: 0.16350199282169342
test loss item: 0.48043161630630493
test loss item: 0.3263876438140869
test loss item: 0.22621148824691772
test loss item: 0.18192969262599945
test loss item: 0.3971734046936035
test loss item: 0.5729785561561584
test loss item: 0.2530736029148102
test loss item: 0.11922837048768997
test loss item: 0.1940895915031433
test loss item: 0.1351548731327057
test loss item: 0.2599306106567383
test loss item: 0.7358071804046631
test loss item: 0.4412432909011841
test loss item: 0.21518929302692413
test loss item: 0.19929060339927673
test loss item: 0.1683931052684784
test loss item: 0.37641024589538574
test loss item: 0.22270013391971588
test loss item: 0.15516093373298645
test loss item: 0.18785417079925537
test loss item: 0.725675642490387
test loss item: 0.25978437066078186
test loss item: 0.24301640689373016
test loss item: 0.19226747751235962
test loss item: 0.44965338706970215
test loss item: 0.34585246443748474
test loss item: 0.15018165111541748
test loss item: 0.7215211987495422
test loss item: 0.2628304064273834
test loss item: 0.2933371365070343
test loss item: 0.12329508364200592
test loss item: 0.11074182391166687
test loss item: 0.14309872686862946
test loss item: 1.2773898839950562
test loss item: 0.3394862115383148
test loss item: 0.1468428075313568
test loss item: 0.10000559687614441
test loss item: 0.8001329302787781
test loss item: 0.6981924176216125
test loss item: 0.877837061882019
test loss item: 0.1712285578250885
test loss item: 0.1763291358947754
test loss item: 0.1663961112499237
test loss item: 0.23607636988162994
test loss item: 0.17635633051395416
Epoch [39/50], Training Loss: 0.3500, Testing Loss: 0.3312
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 40/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2982482314109802
1
train loss item: 0.7239372134208679
2
train loss item: 0.1401209831237793
3
train loss item: 0.3007007837295532
4
train loss item: 0.23931856453418732
5
train loss item: 0.19132040441036224
6
train loss item: 0.1473432183265686
7
train loss item: 0.5270059108734131
8
train loss item: 0.08846965432167053
9
train loss item: 0.15595920383930206
10
train loss item: 0.19460196793079376
11
train loss item: 0.1881813406944275
12
train loss item: 0.10427501797676086
13
train loss item: 0.30823323130607605
14
train loss item: 0.15909378230571747
15
train loss item: 0.3897123634815216
16
train loss item: 0.05104697868227959
17
train loss item: 0.17410048842430115
18
train loss item: 0.19825351238250732
19
train loss item: 0.15259729325771332
20
train loss item: 0.129755899310112
21
train loss item: 0.09529226273298264
22
train loss item: 0.5681819319725037
23
train loss item: 0.5178381204605103
24
train loss item: 0.33716586232185364
25
train loss item: 0.12856407463550568
26
train loss item: 0.12012312561273575
27
train loss item: 0.14268271625041962
28
train loss item: 0.048975273966789246
29
train loss item: 0.4400498867034912
30
train loss item: 1.7044435739517212
31
train loss item: 0.339254230260849
32
train loss item: 0.07770739495754242
33
train loss item: 0.2425675392150879
34
train loss item: 0.10498227179050446
35
train loss item: 2.0050342082977295
36
train loss item: 0.3257940113544464
37
train loss item: 0.3221166729927063
38
train loss item: 0.29812008142471313
39
train loss item: 0.14418698847293854
40
train loss item: 0.11761502176523209
41
train loss item: 0.1595078706741333
42
train loss item: 0.2091730386018753
43
train loss item: 0.11473667621612549
44
train loss item: 0.4596492052078247
45
train loss item: 0.09499073773622513
46
train loss item: 0.07893639802932739
47
train loss item: 0.21410591900348663
48
train loss item: 0.1344618946313858
49
train loss item: 0.10753978788852692
50
train loss item: 0.16967523097991943
51
train loss item: 0.603602409362793
52
train loss item: 0.05656896531581879
53
train loss item: 0.10999342799186707
54
train loss item: 1.8897303342819214
55
train loss item: 0.1321384161710739
56
train loss item: 0.14555910229682922
57
train loss item: 0.1590358316898346
58
train loss item: 0.1085808128118515
59
train loss item: 0.09761232137680054
60
train loss item: 0.52198326587677
61
train loss item: 1.7489556074142456
62
train loss item: 0.1254800260066986
63
train loss item: 0.2338494062423706
64
train loss item: 0.10800221562385559
65
train loss item: 0.34260374307632446
66
train loss item: 0.2777293026447296
67
train loss item: 0.1300889253616333
68
train loss item: 0.1736670583486557
69
train loss item: 0.1943116933107376
70
train loss item: 0.16051198542118073
71
train loss item: 0.09059859067201614
72
train loss item: 0.11022713780403137
73
train loss item: 0.1894536167383194
74
train loss item: 0.06505192071199417
75
train loss item: 0.08556248992681503
76
train loss item: 0.5165865421295166
77
train loss item: 1.0636472702026367
78
train loss item: 0.055261868983507156
79
train loss item: 0.17782731354236603
80
train loss item: 0.081822969019413
81
train loss item: 0.12587550282478333
82
train loss item: 0.1304500252008438
83
train loss item: 0.41235601902008057
84
train loss item: 0.32486793398857117
85
train loss item: 0.2931899130344391
86
train loss item: 3.7371463775634766
87
train loss item: 0.11791648715734482
88
train loss item: 0.25595003366470337
epoch train loss: 0.3352757855580094
testing phase
test loss item: 0.14904804527759552
test loss item: 0.11935976892709732
test loss item: 0.4976799190044403
test loss item: 0.18693400919437408
test loss item: 0.19974148273468018
test loss item: 0.1023295670747757
test loss item: 1.2145638465881348
test loss item: 0.38120612502098083
test loss item: 0.18510086834430695
test loss item: 0.3089335858821869
test loss item: 0.7227197885513306
test loss item: 0.12747886776924133
test loss item: 0.13626427948474884
test loss item: 0.22625239193439484
test loss item: 0.14069363474845886
test loss item: 0.1802218109369278
test loss item: 0.20880985260009766
test loss item: 0.37158823013305664
test loss item: 0.500920295715332
test loss item: 0.18944048881530762
test loss item: 0.598863959312439
test loss item: 0.28982898592948914
test loss item: 0.2236153483390808
test loss item: 0.1278945803642273
test loss item: 0.16974496841430664
test loss item: 0.16277191042900085
test loss item: 0.24521854519844055
test loss item: 0.14203700423240662
test loss item: 0.24379278719425201
test loss item: 0.26107388734817505
test loss item: 0.6283345818519592
test loss item: 0.16732200980186462
test loss item: 0.1120961531996727
test loss item: 0.4531470835208893
test loss item: 0.36335307359695435
test loss item: 0.3394835591316223
test loss item: 0.5964478254318237
test loss item: 1.2338485717773438
test loss item: 0.3560406267642975
test loss item: 0.19779051840305328
test loss item: 0.242959126830101
test loss item: 0.1354794204235077
test loss item: 0.2806641459465027
test loss item: 0.16360065340995789
test loss item: 0.4538344144821167
test loss item: 0.3006369173526764
test loss item: 0.21686378121376038
test loss item: 0.177031010389328
test loss item: 0.3798395097255707
test loss item: 0.555327296257019
test loss item: 0.2351374477148056
test loss item: 0.10964463651180267
test loss item: 0.18737541139125824
test loss item: 0.13878224790096283
test loss item: 0.2463424801826477
test loss item: 0.7241292595863342
test loss item: 0.42695069313049316
test loss item: 0.19970214366912842
test loss item: 0.18687361478805542
test loss item: 0.15887205302715302
test loss item: 0.3541843891143799
test loss item: 0.20166605710983276
test loss item: 0.15386049449443817
test loss item: 0.18116585910320282
test loss item: 0.711986780166626
test loss item: 0.2607548236846924
test loss item: 0.2294306457042694
test loss item: 0.1852346807718277
test loss item: 0.4366511404514313
test loss item: 0.33918172121047974
test loss item: 0.12285060435533524
test loss item: 0.6768360137939453
test loss item: 0.2553166449069977
test loss item: 0.28226056694984436
test loss item: 0.12002689391374588
test loss item: 0.11013028025627136
test loss item: 0.13396680355072021
test loss item: 1.283172607421875
test loss item: 0.3355106711387634
test loss item: 0.14555031061172485
test loss item: 0.08053307980298996
test loss item: 0.7838852405548096
test loss item: 0.6721252799034119
test loss item: 0.8758015632629395
test loss item: 0.16486035287380219
test loss item: 0.16888780891895294
test loss item: 0.13907809555530548
test loss item: 0.19605118036270142
test loss item: 0.1726393699645996
Epoch [40/50], Training Loss: 0.3353, Testing Loss: 0.3186
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 41/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.30010056495666504
1
train loss item: 0.6967504620552063
2
train loss item: 0.13826249539852142
3
train loss item: 0.29368001222610474
4
train loss item: 0.24442271888256073
5
train loss item: 0.18980394303798676
6
train loss item: 0.14545130729675293
7
train loss item: 0.5130791664123535
8
train loss item: 0.08892084658145905
9
train loss item: 0.15767914056777954
10
train loss item: 0.19798800349235535
11
train loss item: 0.1905413568019867
12
train loss item: 0.10119219124317169
13
train loss item: 0.30898556113243103
14
train loss item: 0.15433211624622345
15
train loss item: 0.3780190646648407
16
train loss item: 0.05081437528133392
17
train loss item: 0.17719581723213196
18
train loss item: 0.1957198679447174
19
train loss item: 0.1477782279253006
20
train loss item: 0.1301080584526062
21
train loss item: 0.0990852564573288
22
train loss item: 0.5408230423927307
23
train loss item: 0.5011926889419556
24
train loss item: 0.33250701427459717
25
train loss item: 0.12786418199539185
26
train loss item: 0.12048409134149551
27
train loss item: 0.13462084531784058
28
train loss item: 0.04935379698872566
29
train loss item: 0.41939663887023926
30
train loss item: 1.6810362339019775
31
train loss item: 0.3433757424354553
32
train loss item: 0.08258963376283646
33
train loss item: 0.23908908665180206
34
train loss item: 0.1067291870713234
35
train loss item: 1.9928748607635498
36
train loss item: 0.3341321647167206
37
train loss item: 0.32893291115760803
38
train loss item: 0.32395392656326294
39
train loss item: 0.1437259465456009
40
train loss item: 0.11419685930013657
41
train loss item: 0.15399089455604553
42
train loss item: 0.20690631866455078
43
train loss item: 0.1133057177066803
44
train loss item: 0.45002588629722595
45
train loss item: 0.09428960829973221
46
train loss item: 0.08019112050533295
47
train loss item: 0.20773564279079437
48
train loss item: 0.13002248108386993
49
train loss item: 0.10809038579463959
50
train loss item: 0.16388878226280212
51
train loss item: 0.5862196087837219
52
train loss item: 0.055976323783397675
53
train loss item: 0.10447043925523758
54
train loss item: 1.8766523599624634
55
train loss item: 0.1281154751777649
56
train loss item: 0.14655084908008575
57
train loss item: 0.15677814185619354
58
train loss item: 0.10513843595981598
59
train loss item: 0.09877435117959976
60
train loss item: 0.4902293384075165
61
train loss item: 1.727344274520874
62
train loss item: 0.12160791456699371
63
train loss item: 0.22942078113555908
64
train loss item: 0.10857842862606049
65
train loss item: 0.35055723786354065
66
train loss item: 0.28971949219703674
67
train loss item: 0.1279355138540268
68
train loss item: 0.16457892954349518
69
train loss item: 0.1981504112482071
70
train loss item: 0.1636638343334198
71
train loss item: 0.08975093811750412
72
train loss item: 0.10739175975322723
73
train loss item: 0.18596230447292328
74
train loss item: 0.06544170528650284
75
train loss item: 0.08588945865631104
76
train loss item: 0.49814388155937195
77
train loss item: 1.0471519231796265
78
train loss item: 0.053205456584692
79
train loss item: 0.17953908443450928
80
train loss item: 0.08379536122083664
81
train loss item: 0.12498293817043304
82
train loss item: 0.12689924240112305
83
train loss item: 0.39827480912208557
84
train loss item: 0.33596283197402954
85
train loss item: 0.28582239151000977
86
train loss item: 3.7171289920806885
87
train loss item: 0.11416143923997879
88
train loss item: 0.2641725242137909
epoch train loss: 0.3316783756017685
testing phase
test loss item: 0.1479879915714264
test loss item: 0.12353216856718063
test loss item: 0.4108967185020447
test loss item: 0.1864001452922821
test loss item: 0.18495716154575348
test loss item: 0.10751045495271683
test loss item: 1.3842010498046875
test loss item: 0.48030251264572144
test loss item: 0.15514132380485535
test loss item: 0.2691600024700165
test loss item: 0.6103112697601318
test loss item: 0.1290488839149475
test loss item: 0.15748576819896698
test loss item: 0.25391262769699097
test loss item: 0.12794652581214905
test loss item: 0.17667213082313538
test loss item: 0.2306896448135376
test loss item: 0.3070189356803894
test loss item: 0.5439194440841675
test loss item: 0.231119766831398
test loss item: 0.49424588680267334
test loss item: 0.3246420919895172
test loss item: 0.21611298620700836
test loss item: 0.14056815207004547
test loss item: 0.15503627061843872
test loss item: 0.1747955083847046
test loss item: 0.24224765598773956
test loss item: 0.14046910405158997
test loss item: 0.2351473569869995
test loss item: 0.2498456835746765
test loss item: 0.5959991216659546
test loss item: 0.17880208790302277
test loss item: 0.11903268843889236
test loss item: 0.38734549283981323
test loss item: 0.2977335453033447
test loss item: 0.3144422769546509
test loss item: 0.6424598097801208
test loss item: 1.0090677738189697
test loss item: 0.3082606792449951
test loss item: 0.21940398216247559
test loss item: 0.2581532895565033
test loss item: 0.1438240259885788
test loss item: 0.22607620060443878
test loss item: 0.16865691542625427
test loss item: 0.37627607583999634
test loss item: 0.34941011667251587
test loss item: 0.2070319950580597
test loss item: 0.22110208868980408
test loss item: 0.3417018949985504
test loss item: 0.5009777545928955
test loss item: 0.18835768103599548
test loss item: 0.13195377588272095
test loss item: 0.17423401772975922
test loss item: 0.12480589747428894
test loss item: 0.20252129435539246
test loss item: 0.583711564540863
test loss item: 0.4323972463607788
test loss item: 0.1789611428976059
test loss item: 0.1914949119091034
test loss item: 0.14631609618663788
test loss item: 0.2841508984565735
test loss item: 0.23800227046012878
test loss item: 0.1760421097278595
test loss item: 0.19174207746982574
test loss item: 0.6522553563117981
test loss item: 0.25454089045524597
test loss item: 0.2582540512084961
test loss item: 0.19911833107471466
test loss item: 0.39132142066955566
test loss item: 0.3416057229042053
test loss item: 0.12564674019813538
test loss item: 0.8100528717041016
test loss item: 0.2578522861003876
test loss item: 0.3306838274002075
test loss item: 0.1308416873216629
test loss item: 0.12206526845693588
test loss item: 0.14595723152160645
test loss item: 1.0675071477890015
test loss item: 0.33842357993125916
test loss item: 0.15049931406974792
test loss item: 0.07376621663570404
test loss item: 0.7556717395782471
test loss item: 0.675750195980072
test loss item: 0.7282548546791077
test loss item: 0.18023525178432465
test loss item: 0.17347539961338043
test loss item: 0.12211978435516357
test loss item: 0.17351806163787842
test loss item: 0.1587926745414734
Epoch [41/50], Training Loss: 0.3317, Testing Loss: 0.3070
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 42/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2970939576625824
1
train loss item: 0.6840699911117554
2
train loss item: 0.14077970385551453
3
train loss item: 0.27412718534469604
4
train loss item: 0.23405088484287262
5
train loss item: 0.18886716663837433
6
train loss item: 0.15591475367546082
7
train loss item: 0.4924458861351013
8
train loss item: 0.07841280102729797
9
train loss item: 0.17078445851802826
10
train loss item: 0.20558449625968933
11
train loss item: 0.18425177037715912
12
train loss item: 0.100670725107193
13
train loss item: 0.29359492659568787
14
train loss item: 0.1455351710319519
15
train loss item: 0.41088977456092834
16
train loss item: 0.05477677658200264
17
train loss item: 0.16658179461956024
18
train loss item: 0.20599238574504852
19
train loss item: 0.1770821362733841
20
train loss item: 0.1451549082994461
21
train loss item: 0.10453066974878311
22
train loss item: 0.5702921152114868
23
train loss item: 0.4561361074447632
24
train loss item: 0.35893020033836365
25
train loss item: 0.13887453079223633
26
train loss item: 0.12488681823015213
27
train loss item: 0.13374698162078857
28
train loss item: 0.05227265506982803
29
train loss item: 0.44172465801239014
30
train loss item: 1.6466304063796997
31
train loss item: 0.3418947160243988
32
train loss item: 0.07997827976942062
33
train loss item: 0.20777003467082977
34
train loss item: 0.10588766634464264
35
train loss item: 1.9790723323822021
36
train loss item: 0.3173328638076782
37
train loss item: 0.30166134238243103
38
train loss item: 0.3115418553352356
39
train loss item: 0.1637016385793686
40
train loss item: 0.1386234164237976
41
train loss item: 0.14948436617851257
42
train loss item: 0.2187497913837433
43
train loss item: 0.12975148856639862
44
train loss item: 0.42963117361068726
45
train loss item: 0.08290962129831314
46
train loss item: 0.0999348908662796
47
train loss item: 0.22731737792491913
48
train loss item: 0.13786673545837402
49
train loss item: 0.1037374883890152
50
train loss item: 0.19018256664276123
51
train loss item: 0.5714454650878906
52
train loss item: 0.05922483652830124
53
train loss item: 0.09809179604053497
54
train loss item: 1.8610634803771973
55
train loss item: 0.1299886256456375
56
train loss item: 0.16077551245689392
57
train loss item: 0.1713148057460785
58
train loss item: 0.1244269534945488
59
train loss item: 0.10089126229286194
60
train loss item: 0.48822981119155884
61
train loss item: 1.6878055334091187
62
train loss item: 0.12305853515863419
63
train loss item: 0.23719309270381927
64
train loss item: 0.11739864945411682
65
train loss item: 0.31439408659935
66
train loss item: 0.3110800087451935
67
train loss item: 0.13557206094264984
68
train loss item: 0.19486938416957855
69
train loss item: 0.21287626028060913
70
train loss item: 0.16004525125026703
71
train loss item: 0.09451992809772491
72
train loss item: 0.10874782502651215
73
train loss item: 0.20141549408435822
74
train loss item: 0.06392394751310349
75
train loss item: 0.08622521162033081
76
train loss item: 0.47302648425102234
77
train loss item: 1.049514651298523
78
train loss item: 0.054542168974876404
79
train loss item: 0.17709434032440186
80
train loss item: 0.09684653580188751
81
train loss item: 0.1338765025138855
82
train loss item: 0.11649027466773987
83
train loss item: 0.39603516459465027
84
train loss item: 0.29614537954330444
85
train loss item: 0.2870338261127472
86
train loss item: 3.6899609565734863
87
train loss item: 0.11336631327867508
88
train loss item: 0.28285127878189087
epoch train loss: 0.33183233862679995
testing phase
test loss item: 0.14403119683265686
test loss item: 0.11144993454217911
test loss item: 0.4645397961139679
test loss item: 0.18329903483390808
test loss item: 0.1936124563217163
test loss item: 0.09852902591228485
test loss item: 1.3376774787902832
test loss item: 0.40648192167282104
test loss item: 0.17091666162014008
test loss item: 0.2890479266643524
test loss item: 0.6644967794418335
test loss item: 0.12122195959091187
test loss item: 0.14012733101844788
test loss item: 0.22249791026115417
test loss item: 0.13695450127124786
test loss item: 0.16021740436553955
test loss item: 0.20846207439899445
test loss item: 0.34626516699790955
test loss item: 0.49992817640304565
test loss item: 0.1932923048734665
test loss item: 0.5659180283546448
test loss item: 0.29855984449386597
test loss item: 0.22056640684604645
test loss item: 0.13231828808784485
test loss item: 0.15667641162872314
test loss item: 0.16022971272468567
test loss item: 0.2326754331588745
test loss item: 0.13778485357761383
test loss item: 0.24094761908054352
test loss item: 0.24652855098247528
test loss item: 0.6216421127319336
test loss item: 0.1456882655620575
test loss item: 0.11347862333059311
test loss item: 0.4252859950065613
test loss item: 0.3374803364276886
test loss item: 0.3149845600128174
test loss item: 0.6083758473396301
test loss item: 1.1263697147369385
test loss item: 0.33838438987731934
test loss item: 0.20595982670783997
test loss item: 0.2438841611146927
test loss item: 0.12987357378005981
test loss item: 0.255825400352478
test loss item: 0.16092950105667114
test loss item: 0.42610254883766174
test loss item: 0.3000296950340271
test loss item: 0.21125075221061707
test loss item: 0.17783300578594208
test loss item: 0.36325785517692566
test loss item: 0.5163588523864746
test loss item: 0.2220897674560547
test loss item: 0.1055004671216011
test loss item: 0.17914246022701263
test loss item: 0.12311874330043793
test loss item: 0.22990012168884277
test loss item: 0.6637139916419983
test loss item: 0.4137219488620758
test loss item: 0.19215983152389526
test loss item: 0.18048684298992157
test loss item: 0.15464094281196594
test loss item: 0.3229213058948517
test loss item: 0.19907228648662567
test loss item: 0.15455280244350433
test loss item: 0.18200011551380157
test loss item: 0.6895775198936462
test loss item: 0.2523173689842224
test loss item: 0.22954429686069489
test loss item: 0.190097838640213
test loss item: 0.41790932416915894
test loss item: 0.31408435106277466
test loss item: 0.11308854818344116
test loss item: 0.739799439907074
test loss item: 0.25467368960380554
test loss item: 0.2991752326488495
test loss item: 0.11697258055210114
test loss item: 0.11104517430067062
test loss item: 0.1358010470867157
test loss item: 1.1923094987869263
test loss item: 0.32637548446655273
test loss item: 0.1394350230693817
test loss item: 0.06903275847434998
test loss item: 0.7662712931632996
test loss item: 0.6680843234062195
test loss item: 0.8100115656852722
test loss item: 0.1662968546152115
test loss item: 0.16193057596683502
test loss item: 0.12626002728939056
test loss item: 0.1766069531440735
test loss item: 0.15228278934955597
Epoch [42/50], Training Loss: 0.3318, Testing Loss: 0.3084
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 43/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2841572165489197
1
train loss item: 0.6652160882949829
2
train loss item: 0.132877379655838
3
train loss item: 0.26256924867630005
4
train loss item: 0.22993068397045135
5
train loss item: 0.17596593499183655
6
train loss item: 0.1377037912607193
7
train loss item: 0.4965456426143646
8
train loss item: 0.08150669932365417
9
train loss item: 0.1443021148443222
10
train loss item: 0.17885757982730865
11
train loss item: 0.1739797443151474
12
train loss item: 0.09739233553409576
13
train loss item: 0.29235053062438965
14
train loss item: 0.15199273824691772
15
train loss item: 0.3684234023094177
16
train loss item: 0.04908716306090355
17
train loss item: 0.15339644253253937
18
train loss item: 0.1837383359670639
19
train loss item: 0.14569631218910217
20
train loss item: 0.12047236412763596
21
train loss item: 0.08761085569858551
22
train loss item: 0.5213093757629395
23
train loss item: 0.4720732569694519
24
train loss item: 0.31642481684684753
25
train loss item: 0.11738325655460358
26
train loss item: 0.11023378372192383
27
train loss item: 0.13577498495578766
28
train loss item: 0.04828483238816261
29
train loss item: 0.4117593467235565
30
train loss item: 1.6453499794006348
31
train loss item: 0.31587693095207214
32
train loss item: 0.07746598869562149
33
train loss item: 0.22247414290905
34
train loss item: 0.09891963005065918
35
train loss item: 1.9707190990447998
36
train loss item: 0.29601001739501953
37
train loss item: 0.3046659827232361
38
train loss item: 0.26570144295692444
39
train loss item: 0.13769221305847168
40
train loss item: 0.11020252108573914
41
train loss item: 0.149169921875
42
train loss item: 0.206634059548378
43
train loss item: 0.10941284894943237
44
train loss item: 0.4398542046546936
45
train loss item: 0.09483890980482101
46
train loss item: 0.07940822094678879
47
train loss item: 0.21029512584209442
48
train loss item: 0.12938839197158813
49
train loss item: 0.09868994355201721
50
train loss item: 0.16229824721813202
51
train loss item: 0.5643665790557861
52
train loss item: 0.05400140583515167
53
train loss item: 0.10038663446903229
54
train loss item: 1.8543508052825928
55
train loss item: 0.12495563924312592
56
train loss item: 0.13944396376609802
57
train loss item: 0.1515597254037857
58
train loss item: 0.10130402445793152
59
train loss item: 0.0994950458407402
60
train loss item: 0.4783967435359955
61
train loss item: 1.700655221939087
62
train loss item: 0.11894319206476212
63
train loss item: 0.22127023339271545
64
train loss item: 0.10451805591583252
65
train loss item: 0.3041948676109314
66
train loss item: 0.25431063771247864
67
train loss item: 0.12435000389814377
68
train loss item: 0.1668744832277298
69
train loss item: 0.18423078954219818
70
train loss item: 0.15049052238464355
71
train loss item: 0.08222724497318268
72
train loss item: 0.10688597708940506
73
train loss item: 0.17855043709278107
74
train loss item: 0.06680744141340256
75
train loss item: 0.08259744197130203
76
train loss item: 0.4746394753456116
77
train loss item: 1.036952018737793
78
train loss item: 0.04977535456418991
79
train loss item: 0.1653509885072708
80
train loss item: 0.0880545824766159
81
train loss item: 0.11845102161169052
82
train loss item: 0.12241964787244797
83
train loss item: 0.3881853520870209
84
train loss item: 0.2928556203842163
85
train loss item: 0.27395662665367126
86
train loss item: 3.682673454284668
87
train loss item: 0.11217819899320602
88
train loss item: 0.23024490475654602
epoch train loss: 0.31935942072546886
testing phase
test loss item: 0.14349490404129028
test loss item: 0.16125071048736572
test loss item: 0.4963420331478119
test loss item: 0.18188026547431946
test loss item: 0.19732566177845
test loss item: 0.09520850330591202
test loss item: 1.2816880941390991
test loss item: 0.365455687046051
test loss item: 0.1726875603199005
test loss item: 0.29406484961509705
test loss item: 0.7039244174957275
test loss item: 0.12110991030931473
test loss item: 0.13374727964401245
test loss item: 0.2170499861240387
test loss item: 0.13847045600414276
test loss item: 0.2745446264743805
test loss item: 0.20237500965595245
test loss item: 0.36263781785964966
test loss item: 0.47083964943885803
test loss item: 0.179666668176651
test loss item: 0.6005370616912842
test loss item: 0.28685057163238525
test loss item: 0.22509899735450745
test loss item: 0.1255117654800415
test loss item: 0.1652952879667282
test loss item: 0.1549917608499527
test loss item: 0.2279457151889801
test loss item: 0.1358574777841568
test loss item: 0.23878781497478485
test loss item: 0.24653638899326324
test loss item: 0.6367098093032837
test loss item: 0.25640666484832764
test loss item: 0.10731273144483566
test loss item: 0.4463483989238739
test loss item: 0.3807532489299774
test loss item: 0.3121708929538727
test loss item: 0.5806823372840881
test loss item: 1.217399001121521
test loss item: 0.3536261320114136
test loss item: 0.1966213583946228
test loss item: 0.26811379194259644
test loss item: 0.12255163490772247
test loss item: 0.262274831533432
test loss item: 0.16190195083618164
test loss item: 0.4496390223503113
test loss item: 0.3147064745426178
test loss item: 0.21224570274353027
test loss item: 0.1691988855600357
test loss item: 0.37455764412879944
test loss item: 0.5241395831108093
test loss item: 0.22737273573875427
test loss item: 0.10699140280485153
test loss item: 0.18239451944828033
test loss item: 0.12977388501167297
test loss item: 0.23981241881847382
test loss item: 0.7128661870956421
test loss item: 0.41053497791290283
test loss item: 0.19553044438362122
test loss item: 0.17876401543617249
test loss item: 0.15145939588546753
test loss item: 0.3312973082065582
test loss item: 0.22355279326438904
test loss item: 0.145705908536911
test loss item: 0.17343682050704956
test loss item: 0.7297846078872681
test loss item: 0.25340911746025085
test loss item: 0.22143669426441193
test loss item: 0.18413467705249786
test loss item: 0.45869001746177673
test loss item: 0.2886793613433838
test loss item: 0.18211695551872253
test loss item: 0.6897475719451904
test loss item: 0.25685063004493713
test loss item: 0.28164365887641907
test loss item: 0.1161864846944809
test loss item: 0.10526343435049057
test loss item: 0.1317974328994751
test loss item: 1.3129404783248901
test loss item: 0.33516332507133484
test loss item: 0.1354902982711792
test loss item: 0.07483891397714615
test loss item: 0.778949499130249
test loss item: 0.6497569680213928
test loss item: 0.8803632259368896
test loss item: 0.16236181557178497
test loss item: 0.16328996419906616
test loss item: 0.2027275711297989
test loss item: 0.29929545521736145
test loss item: 0.14561422169208527
Epoch [43/50], Training Loss: 0.3194, Testing Loss: 0.3191
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 44/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2838755249977112
1
train loss item: 0.6464474201202393
2
train loss item: 0.13074199855327606
3
train loss item: 0.2555050849914551
4
train loss item: 0.21938635408878326
5
train loss item: 0.1753160059452057
6
train loss item: 0.135250985622406
7
train loss item: 0.4889727532863617
8
train loss item: 0.08390333503484726
9
train loss item: 0.14374634623527527
10
train loss item: 0.179001584649086
11
train loss item: 0.17834816873073578
12
train loss item: 0.10167042911052704
13
train loss item: 0.29578402638435364
14
train loss item: 0.15357814729213715
15
train loss item: 0.3499603569507599
16
train loss item: 0.050811804831027985
17
train loss item: 0.1543572098016739
18
train loss item: 0.18413040041923523
19
train loss item: 0.13617676496505737
20
train loss item: 0.12165698409080505
21
train loss item: 0.09182082116603851
22
train loss item: 0.4900146424770355
23
train loss item: 0.4653380215167999
24
train loss item: 0.3082018792629242
25
train loss item: 0.11844254285097122
26
train loss item: 0.11035803705453873
27
train loss item: 0.13838247954845428
28
train loss item: 0.04906770959496498
29
train loss item: 0.388467937707901
30
train loss item: 1.6267606019973755
31
train loss item: 0.31266945600509644
32
train loss item: 0.07872114330530167
33
train loss item: 0.21853387355804443
34
train loss item: 0.1040370985865593
35
train loss item: 1.9592770338058472
36
train loss item: 0.3053205907344818
37
train loss item: 0.31494173407554626
38
train loss item: 0.27930310368537903
39
train loss item: 0.13769973814487457
40
train loss item: 0.10966595262289047
41
train loss item: 0.15092535316944122
42
train loss item: 0.20176374912261963
43
train loss item: 0.10740599036216736
44
train loss item: 0.4389598071575165
45
train loss item: 0.0941937267780304
46
train loss item: 0.08155560493469238
47
train loss item: 0.20014049112796783
48
train loss item: 0.12702473998069763
49
train loss item: 0.09795506298542023
50
train loss item: 0.15047724545001984
51
train loss item: 0.5484699010848999
52
train loss item: 0.05468793958425522
53
train loss item: 0.09746850281953812
54
train loss item: 1.8426284790039062
55
train loss item: 0.12276964634656906
56
train loss item: 0.13964997231960297
57
train loss item: 0.14590278267860413
58
train loss item: 0.10097426176071167
59
train loss item: 0.09550776332616806
60
train loss item: 0.4612571895122528
61
train loss item: 1.6897683143615723
62
train loss item: 0.12046608328819275
63
train loss item: 0.21560215950012207
64
train loss item: 0.10244572162628174
65
train loss item: 0.3125342130661011
66
train loss item: 0.2587643265724182
67
train loss item: 0.12487106770277023
68
train loss item: 0.15718919038772583
69
train loss item: 0.1848064363002777
70
train loss item: 0.15241923928260803
71
train loss item: 0.08524637669324875
72
train loss item: 0.10496392101049423
73
train loss item: 0.17292994260787964
74
train loss item: 0.062461551278829575
75
train loss item: 0.08394426107406616
76
train loss item: 0.46607309579849243
77
train loss item: 1.0158203840255737
78
train loss item: 0.05399547517299652
79
train loss item: 0.1680840700864792
80
train loss item: 0.09087686240673065
81
train loss item: 0.11936239898204803
82
train loss item: 0.12314695119857788
83
train loss item: 0.37756311893463135
84
train loss item: 0.3104245364665985
85
train loss item: 0.26633545756340027
86
train loss item: 3.6665737628936768
87
train loss item: 0.10841759294271469
88
train loss item: 0.22613415122032166
epoch train loss: 0.3163661230983359
testing phase
test loss item: 0.14168138802051544
test loss item: 0.1130201518535614
test loss item: 0.42050448060035706
test loss item: 0.1807442605495453
test loss item: 0.18040673434734344
test loss item: 0.0924362763762474
test loss item: 1.38489830493927
test loss item: 0.44410240650177
test loss item: 0.15079373121261597
test loss item: 0.26256313920021057
test loss item: 0.6204739809036255
test loss item: 0.12142946571111679
test loss item: 0.14865288138389587
test loss item: 0.23296761512756348
test loss item: 0.123308926820755
test loss item: 0.17332151532173157
test loss item: 0.21747048199176788
test loss item: 0.30734655261039734
test loss item: 0.5122495889663696
test loss item: 0.2140006721019745
test loss item: 0.5048379302024841
test loss item: 0.3117969334125519
test loss item: 0.212342768907547
test loss item: 0.13437829911708832
test loss item: 0.15158849954605103
test loss item: 0.1645861566066742
test loss item: 0.22794628143310547
test loss item: 0.13133715093135834
test loss item: 0.22701522707939148
test loss item: 0.23894017934799194
test loss item: 0.6110222935676575
test loss item: 0.16884148120880127
test loss item: 0.11188727617263794
test loss item: 0.38877153396606445
test loss item: 0.3045618534088135
test loss item: 0.3079227805137634
test loss item: 0.6125527024269104
test loss item: 1.039182424545288
test loss item: 0.31136444211006165
test loss item: 0.20952805876731873
test loss item: 0.25298750400543213
test loss item: 0.12538625299930573
test loss item: 0.21771593391895294
test loss item: 0.16497141122817993
test loss item: 0.3781582713127136
test loss item: 0.32231405377388
test loss item: 0.19838395714759827
test loss item: 0.21194571256637573
test loss item: 0.3394857347011566
test loss item: 0.4860176742076874
test loss item: 0.18597477674484253
test loss item: 0.12663625180721283
test loss item: 0.17081588506698608
test loss item: 0.12138766795396805
test loss item: 0.2020566612482071
test loss item: 0.60196453332901
test loss item: 0.4165361523628235
test loss item: 0.17070677876472473
test loss item: 0.1801733374595642
test loss item: 0.13857673108577728
test loss item: 0.27435824275016785
test loss item: 0.22004903852939606
test loss item: 0.16171695291996002
test loss item: 0.17975756525993347
test loss item: 0.6651104092597961
test loss item: 0.2487950623035431
test loss item: 0.24335598945617676
test loss item: 0.19219255447387695
test loss item: 0.4013046324253082
test loss item: 0.33445462584495544
test loss item: 0.1191275492310524
test loss item: 0.7791240215301514
test loss item: 0.24940308928489685
test loss item: 0.31405186653137207
test loss item: 0.12337684631347656
test loss item: 0.10976888984441757
test loss item: 0.13904206454753876
test loss item: 1.1311230659484863
test loss item: 0.32844462990760803
test loss item: 0.13569757342338562
test loss item: 0.06656071543693542
test loss item: 0.7534205317497253
test loss item: 0.6561189293861389
test loss item: 0.7592033743858337
test loss item: 0.1725952923297882
test loss item: 0.16559264063835144
test loss item: 0.12862902879714966
test loss item: 0.1851935237646103
test loss item: 0.13445746898651123
Epoch [44/50], Training Loss: 0.3164, Testing Loss: 0.3011
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Epoch 45/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.280320942401886
1
train loss item: 0.6344465017318726
2
train loss item: 0.12560683488845825
3
train loss item: 0.2557273507118225
4
train loss item: 0.2283662110567093
5
train loss item: 0.1733921468257904
6
train loss item: 0.1466650366783142
7
train loss item: 0.46153658628463745
8
train loss item: 0.076289102435112
9
train loss item: 0.15276435017585754
10
train loss item: 0.1904037594795227
11
train loss item: 0.17332063615322113
12
train loss item: 0.10335220396518707
13
train loss item: 0.28179460763931274
14
train loss item: 0.1356854885816574
15
train loss item: 0.38482099771499634
16
train loss item: 0.05691526085138321
17
train loss item: 0.15583471953868866
18
train loss item: 0.1889074593782425
19
train loss item: 0.15614469349384308
20
train loss item: 0.13531890511512756
21
train loss item: 0.10345759987831116
22
train loss item: 0.5211396813392639
23
train loss item: 0.4230937063694
24
train loss item: 0.3378773033618927
25
train loss item: 0.1290997564792633
26
train loss item: 0.11565177142620087
27
train loss item: 0.1252264529466629
28
train loss item: 0.05387009680271149
29
train loss item: 0.4007302522659302
30
train loss item: 1.5924996137619019
31
train loss item: 0.3164600133895874
32
train loss item: 0.07142838090658188
33
train loss item: 0.18813760578632355
34
train loss item: 0.09854032099246979
35
train loss item: 1.9448384046554565
36
train loss item: 0.3017862141132355
37
train loss item: 0.2968669831752777
38
train loss item: 0.2981404662132263
39
train loss item: 0.15197357535362244
40
train loss item: 0.12188394367694855
41
train loss item: 0.1389354169368744
42
train loss item: 0.20582525432109833
43
train loss item: 0.11753933876752853
44
train loss item: 0.41552746295928955
45
train loss item: 0.07789132744073868
46
train loss item: 0.08235028386116028
47
train loss item: 0.2087232768535614
48
train loss item: 0.12492449581623077
49
train loss item: 0.0939767137169838
50
train loss item: 0.16817158460617065
51
train loss item: 0.5337843894958496
52
train loss item: 0.0616970919072628
53
train loss item: 0.08753462880849838
54
train loss item: 1.8263746500015259
55
train loss item: 0.12240468710660934
56
train loss item: 0.14585590362548828
57
train loss item: 0.15262798964977264
58
train loss item: 0.11475013196468353
59
train loss item: 0.09374290704727173
60
train loss item: 0.4528612792491913
61
train loss item: 1.6502883434295654
62
train loss item: 0.11801781505346298
63
train loss item: 0.21868261694908142
64
train loss item: 0.10607785731554031
65
train loss item: 0.3008333146572113
66
train loss item: 0.2950987219810486
67
train loss item: 0.13006141781806946
68
train loss item: 0.1790880560874939
69
train loss item: 0.1988694816827774
70
train loss item: 0.14709514379501343
71
train loss item: 0.09417320042848587
72
train loss item: 0.10134275257587433
73
train loss item: 0.1829734593629837
74
train loss item: 0.06144070252776146
75
train loss item: 0.08582804352045059
76
train loss item: 0.4399423897266388
77
train loss item: 1.007361650466919
78
train loss item: 0.060345765203237534
79
train loss item: 0.16393239796161652
80
train loss item: 0.09531566500663757
81
train loss item: 0.12479128688573837
82
train loss item: 0.10680794715881348
83
train loss item: 0.3784119188785553
84
train loss item: 0.3005591928958893
85
train loss item: 0.2722865343093872
86
train loss item: 3.639523506164551
87
train loss item: 0.10211380571126938
88
train loss item: 0.24600762128829956
epoch train loss: 0.31598972315701207
testing phase
test loss item: 0.14060236513614655
test loss item: 0.1584155559539795
test loss item: 0.4680326581001282
test loss item: 0.17697028815746307
test loss item: 0.1871068775653839
test loss item: 0.09320331364870071
test loss item: 1.3051509857177734
test loss item: 0.3799154758453369
test loss item: 0.17060846090316772
test loss item: 0.2841341197490692
test loss item: 0.671786904335022
test loss item: 0.11926942318677902
test loss item: 0.1305253952741623
test loss item: 0.21486641466617584
test loss item: 0.13255561888217926
test loss item: 0.2684074640274048
test loss item: 0.1963847130537033
test loss item: 0.3375645577907562
test loss item: 0.47600510716438293
test loss item: 0.18163050711154938
test loss item: 0.5456305146217346
test loss item: 0.2848675847053528
test loss item: 0.2123284786939621
test loss item: 0.12543992698192596
test loss item: 0.15354080498218536
test loss item: 0.15281236171722412
test loss item: 0.22348661720752716
test loss item: 0.13034284114837646
test loss item: 0.23004679381847382
test loss item: 0.23821905255317688
test loss item: 0.6241896152496338
test loss item: 0.25767338275909424
test loss item: 0.10671696066856384
test loss item: 0.41786888241767883
test loss item: 0.3563745319843292
test loss item: 0.3161660134792328
test loss item: 0.580597996711731
test loss item: 1.1459461450576782
test loss item: 0.33335137367248535
test loss item: 0.1973400115966797
test loss item: 0.26529568433761597
test loss item: 0.12443295866250992
test loss item: 0.2479579597711563
test loss item: 0.15494757890701294
test loss item: 0.4097308814525604
test loss item: 0.3135621249675751
test loss item: 0.20076002180576324
test loss item: 0.17197178304195404
test loss item: 0.35915103554725647
test loss item: 0.5114005208015442
test loss item: 0.21619723737239838
test loss item: 0.10217217355966568
test loss item: 0.1737305372953415
test loss item: 0.12018785625696182
test loss item: 0.22394850850105286
test loss item: 0.6700187921524048
test loss item: 0.4048919975757599
test loss item: 0.18375004827976227
test loss item: 0.1715458333492279
test loss item: 0.14714659750461578
test loss item: 0.31686973571777344
test loss item: 0.2169930785894394
test loss item: 0.1453433632850647
test loss item: 0.17120003700256348
test loss item: 0.6851881742477417
test loss item: 0.24540172517299652
test loss item: 0.21661093831062317
test loss item: 0.18170125782489777
test loss item: 0.4333137571811676
test loss item: 0.31112366914749146
test loss item: 0.1768980622291565
test loss item: 0.7027962803840637
test loss item: 0.245611310005188
test loss item: 0.2838757634162903
test loss item: 0.11113862693309784
test loss item: 0.1047772690653801
test loss item: 0.13130931556224823
test loss item: 1.2187769412994385
test loss item: 0.3200484812259674
test loss item: 0.13224004209041595
test loss item: 0.07092583924531937
test loss item: 0.76092529296875
test loss item: 0.6475539207458496
test loss item: 0.8250473141670227
test loss item: 0.1581198275089264
test loss item: 0.1547321081161499
test loss item: 0.1946103423833847
test loss item: 0.2887575328350067
test loss item: 0.14631116390228271
Epoch [45/50], Training Loss: 0.3160, Testing Loss: 0.3090
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 46/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2722688615322113
1
train loss item: 0.6132110953330994
2
train loss item: 0.12749704718589783
3
train loss item: 0.24587103724479675
4
train loss item: 0.20456679165363312
5
train loss item: 0.16574671864509583
6
train loss item: 0.12857882678508759
7
train loss item: 0.4652647376060486
8
train loss item: 0.07697811722755432
9
train loss item: 0.13540887832641602
10
train loss item: 0.1691674292087555
11
train loss item: 0.17280541360378265
12
train loss item: 0.09527197480201721
13
train loss item: 0.28786700963974
14
train loss item: 0.1404518038034439
15
train loss item: 0.33810943365097046
16
train loss item: 0.05041208863258362
17
train loss item: 0.14766354858875275
18
train loss item: 0.17659762501716614
19
train loss item: 0.13123396039009094
20
train loss item: 0.11355821043252945
21
train loss item: 0.09072082489728928
22
train loss item: 0.45362037420272827
23
train loss item: 0.43369919061660767
24
train loss item: 0.29478567838668823
25
train loss item: 0.11519522964954376
26
train loss item: 0.10710396617650986
27
train loss item: 0.1263185441493988
28
train loss item: 0.04932013899087906
29
train loss item: 0.3697023391723633
30
train loss item: 1.588441252708435
31
train loss item: 0.29966166615486145
32
train loss item: 0.077633336186409
33
train loss item: 0.21267879009246826
34
train loss item: 0.09350398182868958
35
train loss item: 1.935070276260376
36
train loss item: 0.2936999499797821
37
train loss item: 0.30260318517684937
38
train loss item: 0.268761545419693
39
train loss item: 0.13209939002990723
40
train loss item: 0.10164681077003479
41
train loss item: 0.1395217776298523
42
train loss item: 0.20100609958171844
43
train loss item: 0.1036718487739563
44
train loss item: 0.42590203881263733
45
train loss item: 0.08635302633047104
46
train loss item: 0.07846972346305847
47
train loss item: 0.1941814124584198
48
train loss item: 0.12059250473976135
49
train loss item: 0.09461827576160431
50
train loss item: 0.1453617811203003
51
train loss item: 0.5247414708137512
52
train loss item: 0.053628385066986084
53
train loss item: 0.09457956999540329
54
train loss item: 1.818589687347412
55
train loss item: 0.11881637573242188
56
train loss item: 0.1360638290643692
57
train loss item: 0.14394091069698334
58
train loss item: 0.09478134661912918
59
train loss item: 0.09502925723791122
60
train loss item: 0.43353453278541565
61
train loss item: 1.6575841903686523
62
train loss item: 0.11473861336708069
63
train loss item: 0.20719073712825775
64
train loss item: 0.10136374086141586
65
train loss item: 0.2950185537338257
66
train loss item: 0.24604684114456177
67
train loss item: 0.11928129196166992
68
train loss item: 0.14923061430454254
69
train loss item: 0.17930814623832703
70
train loss item: 0.1481611281633377
71
train loss item: 0.0821036547422409
72
train loss item: 0.0958985984325409
73
train loss item: 0.1656702607870102
74
train loss item: 0.06254405528306961
75
train loss item: 0.08295904844999313
76
train loss item: 0.4365626871585846
77
train loss item: 0.9877220988273621
78
train loss item: 0.04849084094166756
79
train loss item: 0.1616484373807907
80
train loss item: 0.07966458797454834
81
train loss item: 0.1142844557762146
82
train loss item: 0.11670158058404922
83
train loss item: 0.3652111887931824
84
train loss item: 0.2981816530227661
85
train loss item: 0.2571479082107544
86
train loss item: 3.628528118133545
87
train loss item: 0.10739822685718536
88
train loss item: 0.21015197038650513
epoch train loss: 0.3059210580135329
testing phase
test loss item: 0.14210771024227142
test loss item: 0.0773978903889656
test loss item: 0.48474618792533875
test loss item: 0.1795106828212738
test loss item: 0.18826377391815186
test loss item: 0.08889257162809372
test loss item: 1.367919921875
test loss item: 0.4212305247783661
test loss item: 0.17536887526512146
test loss item: 0.28954434394836426
test loss item: 0.6992212533950806
test loss item: 0.11893629282712936
test loss item: 0.13562531769275665
test loss item: 0.2253851741552353
test loss item: 0.12998314201831818
test loss item: 0.0594516396522522
test loss item: 0.21206064522266388
test loss item: 0.34098106622695923
test loss item: 0.49358227849006653
test loss item: 0.19820266962051392
test loss item: 0.5472999215126038
test loss item: 0.3043692111968994
test loss item: 0.21917134523391724
test loss item: 0.1310739815235138
test loss item: 0.1557786911725998
test loss item: 0.15818604826927185
test loss item: 0.23121081292629242
test loss item: 0.13088621199131012
test loss item: 0.23441295325756073
test loss item: 0.2457893192768097
test loss item: 0.6564440131187439
test loss item: 0.05474405735731125
test loss item: 0.11021162569522858
test loss item: 0.42464083433151245
test loss item: 0.3280390202999115
test loss item: 0.31881675124168396
test loss item: 0.6031691431999207
test loss item: 1.1975151300430298
test loss item: 0.33954039216041565
test loss item: 0.2041936218738556
test loss item: 0.2317497730255127
test loss item: 0.12932682037353516
test loss item: 0.24839332699775696
test loss item: 0.16506452858448029
test loss item: 0.41036900877952576
test loss item: 0.28812193870544434
test loss item: 0.20404571294784546
test loss item: 0.18290044367313385
test loss item: 0.37304580211639404
test loss item: 0.5358483791351318
test loss item: 0.21353909373283386
test loss item: 0.10624948889017105
test loss item: 0.17917929589748383
test loss item: 0.1258946806192398
test loss item: 0.2248774617910385
test loss item: 0.6927233338356018
test loss item: 0.42336827516555786
test loss item: 0.18532812595367432
test loss item: 0.17747090756893158
test loss item: 0.14314261078834534
test loss item: 0.31668564677238464
test loss item: 0.19064584374427795
test loss item: 0.1570233702659607
test loss item: 0.1730099320411682
test loss item: 0.715385913848877
test loss item: 0.2477995902299881
test loss item: 0.236299529671669
test loss item: 0.18736107647418976
test loss item: 0.41462016105651855
test loss item: 0.3211926519870758
test loss item: 0.05443470552563667
test loss item: 0.7499544024467468
test loss item: 0.2552223801612854
test loss item: 0.30535078048706055
test loss item: 0.12035250663757324
test loss item: 0.11062344163656235
test loss item: 0.13392318785190582
test loss item: 1.278544306755066
test loss item: 0.3353938162326813
test loss item: 0.13447150588035583
test loss item: 0.0627216249704361
test loss item: 0.8040801882743835
test loss item: 0.6745215654373169
test loss item: 0.8676618933677673
test loss item: 0.16694797575473785
test loss item: 0.16294027864933014
test loss item: 0.05712461471557617
test loss item: 0.05045156925916672
test loss item: 0.1426858752965927
Epoch [46/50], Training Loss: 0.3059, Testing Loss: 0.3067
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 47/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2635231018066406
1
train loss item: 0.6017780303955078
2
train loss item: 0.12381144613027573
3
train loss item: 0.2409008890390396
4
train loss item: 0.19697460532188416
5
train loss item: 0.16051864624023438
6
train loss item: 0.12721283733844757
7
train loss item: 0.45881420373916626
8
train loss item: 0.07372862100601196
9
train loss item: 0.13053520023822784
10
train loss item: 0.16142870485782623
11
train loss item: 0.1626463383436203
12
train loss item: 0.09534362703561783
13
train loss item: 0.27316024899482727
14
train loss item: 0.13720671832561493
15
train loss item: 0.34016451239585876
16
train loss item: 0.04824500158429146
17
train loss item: 0.13758805394172668
18
train loss item: 0.16838586330413818
19
train loss item: 0.1336280107498169
20
train loss item: 0.11387334018945694
21
train loss item: 0.08551009744405746
22
train loss item: 0.4497048556804657
23
train loss item: 0.41848844289779663
24
train loss item: 0.29229193925857544
25
train loss item: 0.1115775927901268
26
train loss item: 0.10246101021766663
27
train loss item: 0.12268849462270737
28
train loss item: 0.04722261056303978
29
train loss item: 0.3707925081253052
30
train loss item: 1.5712882280349731
31
train loss item: 0.28241634368896484
32
train loss item: 0.07437504827976227
33
train loss item: 0.20264190435409546
34
train loss item: 0.08996599912643433
35
train loss item: 1.9229164123535156
36
train loss item: 0.2764153480529785
37
train loss item: 0.2858258783817291
38
train loss item: 0.2350454181432724
39
train loss item: 0.13250742852687836
40
train loss item: 0.10130517929792404
41
train loss item: 0.13628597557544708
42
train loss item: 0.19897250831127167
43
train loss item: 0.1007649227976799
44
train loss item: 0.4207130968570709
45
train loss item: 0.08262114226818085
46
train loss item: 0.07354938238859177
47
train loss item: 0.19353774189949036
48
train loss item: 0.11862599849700928
49
train loss item: 0.09068611264228821
50
train loss item: 0.14819534122943878
51
train loss item: 0.5194830894470215
52
train loss item: 0.05243522301316261
53
train loss item: 0.09088640660047531
54
train loss item: 1.8064826726913452
55
train loss item: 0.11781495064496994
56
train loss item: 0.13046160340309143
57
train loss item: 0.14447008073329926
58
train loss item: 0.09466554969549179
59
train loss item: 0.09264466166496277
60
train loss item: 0.4300161600112915
61
train loss item: 1.6419949531555176
62
train loss item: 0.11179377883672714
63
train loss item: 0.20262078940868378
64
train loss item: 0.09786379337310791
65
train loss item: 0.27051231265068054
66
train loss item: 0.22973354160785675
67
train loss item: 0.11643800139427185
68
train loss item: 0.1516415923833847
69
train loss item: 0.1691957712173462
70
train loss item: 0.1398322731256485
71
train loss item: 0.08218193054199219
72
train loss item: 0.09376460313796997
73
train loss item: 0.16348424553871155
74
train loss item: 0.06226186454296112
75
train loss item: 0.07984350621700287
76
train loss item: 0.42461690306663513
77
train loss item: 0.9780316948890686
78
train loss item: 0.04881153255701065
79
train loss item: 0.15410980582237244
80
train loss item: 0.07706116884946823
81
train loss item: 0.11380942910909653
82
train loss item: 0.10993804782629013
83
train loss item: 0.36056163907051086
84
train loss item: 0.2735936939716339
85
train loss item: 0.2565290331840515
86
train loss item: 3.60850191116333
87
train loss item: 0.10334929078817368
88
train loss item: 0.19780287146568298
epoch train loss: 0.29986630719196933
testing phase
test loss item: 0.13761118054389954
test loss item: 0.0767645314335823
test loss item: 0.4281314015388489
test loss item: 0.17576929926872253
test loss item: 0.1780674159526825
test loss item: 0.09087008982896805
test loss item: 1.3777695894241333
test loss item: 0.4611016511917114
test loss item: 0.15811076760292053
test loss item: 0.2653726637363434
test loss item: 0.6307455897331238
test loss item: 0.11626037955284119
test loss item: 0.1447216123342514
test loss item: 0.22848351299762726
test loss item: 0.12062130123376846
test loss item: 0.059634018689394
test loss item: 0.2190985530614853
test loss item: 0.3025658428668976
test loss item: 0.5078169703483582
test loss item: 0.21419785916805267
test loss item: 0.4779876172542572
test loss item: 0.3137461245059967
test loss item: 0.20590829849243164
test loss item: 0.13345971703529358
test loss item: 0.14667756855487823
test loss item: 0.16209401190280914
test loss item: 0.2268969863653183
test loss item: 0.12992335855960846
test loss item: 0.22394594550132751
test loss item: 0.23968155682086945
test loss item: 0.6159660220146179
test loss item: 0.052957020699977875
test loss item: 0.11101782321929932
test loss item: 0.38101422786712646
test loss item: 0.28780364990234375
test loss item: 0.30244627594947815
test loss item: 0.6106442213058472
test loss item: 1.0616415739059448
test loss item: 0.3051539659500122
test loss item: 0.20536267757415771
test loss item: 0.23199345171451569
test loss item: 0.12322781980037689
test loss item: 0.21738702058792114
test loss item: 0.16334816813468933
test loss item: 0.3589875102043152
test loss item: 0.3092068135738373
test loss item: 0.19204917550086975
test loss item: 0.20406414568424225
test loss item: 0.34535250067710876
test loss item: 0.49997928738594055
test loss item: 0.18433372676372528
test loss item: 0.12091369181871414
test loss item: 0.17117825150489807
test loss item: 0.11823276430368423
test loss item: 0.19994255900382996
test loss item: 0.6062906384468079
test loss item: 0.41933926939964294
test loss item: 0.1701737493276596
test loss item: 0.17795495688915253
test loss item: 0.13460789620876312
test loss item: 0.27732735872268677
test loss item: 0.21074259281158447
test loss item: 0.16145436465740204
test loss item: 0.17423543334007263
test loss item: 0.6595802903175354
test loss item: 0.24148866534233093
test loss item: 0.24788732826709747
test loss item: 0.18852046132087708
test loss item: 0.38010188937187195
test loss item: 0.3228049576282501
test loss item: 0.05579368770122528
test loss item: 0.7809218168258667
test loss item: 0.24480047821998596
test loss item: 0.31072479486465454
test loss item: 0.12400200217962265
test loss item: 0.10971540957689285
test loss item: 0.13623546063899994
test loss item: 1.1391606330871582
test loss item: 0.32090646028518677
test loss item: 0.133332297205925
test loss item: 0.059551507234573364
test loss item: 0.7653457522392273
test loss item: 0.6593672633171082
test loss item: 0.7724378108978271
test loss item: 0.16895486414432526
test loss item: 0.1637003868818283
test loss item: 0.05352950841188431
test loss item: 0.04829822853207588
test loss item: 0.12305106967687607
Epoch [47/50], Training Loss: 0.2999, Testing Loss: 0.2929
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 48/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2643705904483795
1
train loss item: 0.5813817977905273
2
train loss item: 0.11601348221302032
3
train loss item: 0.23780015110969543
4
train loss item: 0.20500199496746063
5
train loss item: 0.16357971727848053
6
train loss item: 0.1375424861907959
7
train loss item: 0.43617475032806396
8
train loss item: 0.0691886618733406
9
train loss item: 0.13628189265727997
10
train loss item: 0.17213623225688934
11
train loss item: 0.16184315085411072
12
train loss item: 0.10235141962766647
13
train loss item: 0.2644193172454834
14
train loss item: 0.12860499322414398
15
train loss item: 0.3459022045135498
16
train loss item: 0.0498020201921463
17
train loss item: 0.14037936925888062
18
train loss item: 0.1769045889377594
19
train loss item: 0.14587169885635376
20
train loss item: 0.13304167985916138
21
train loss item: 0.09314243495464325
22
train loss item: 0.4522686004638672
23
train loss item: 0.3867381513118744
24
train loss item: 0.30907729268074036
25
train loss item: 0.12246639281511307
26
train loss item: 0.10570758581161499
27
train loss item: 0.1152888610959053
28
train loss item: 0.047192707657814026
29
train loss item: 0.3567081689834595
30
train loss item: 1.5334973335266113
31
train loss item: 0.28947362303733826
32
train loss item: 0.07122129946947098
33
train loss item: 0.17786167562007904
34
train loss item: 0.09506046772003174
35
train loss item: 1.9043045043945312
36
train loss item: 0.2758280634880066
37
train loss item: 0.2795505225658417
38
train loss item: 0.2454531341791153
39
train loss item: 0.14758971333503723
40
train loss item: 0.11039964854717255
41
train loss item: 0.12770302593708038
42
train loss item: 0.19920511543750763
43
train loss item: 0.1054188683629036
44
train loss item: 0.4016322195529938
45
train loss item: 0.07550094276666641
46
train loss item: 0.07485715299844742
47
train loss item: 0.19378869235515594
48
train loss item: 0.1170620322227478
49
train loss item: 0.08832915127277374
50
train loss item: 0.15712597966194153
51
train loss item: 0.4991189241409302
52
train loss item: 0.05620504915714264
53
train loss item: 0.0824318677186966
54
train loss item: 1.7854118347167969
55
train loss item: 0.11828292906284332
56
train loss item: 0.13164131343364716
57
train loss item: 0.14880706369876862
58
train loss item: 0.10535810142755508
59
train loss item: 0.08910513669252396
60
train loss item: 0.4086029529571533
61
train loss item: 1.6048117876052856
62
train loss item: 0.112505242228508
63
train loss item: 0.20395112037658691
64
train loss item: 0.09487727284431458
65
train loss item: 0.2665490508079529
66
train loss item: 0.2504511773586273
67
train loss item: 0.12422826141119003
68
train loss item: 0.16420750319957733
69
train loss item: 0.1796501725912094
70
train loss item: 0.13923676311969757
71
train loss item: 0.09149803966283798
72
train loss item: 0.09229335933923721
73
train loss item: 0.16909874975681305
74
train loss item: 0.061888083815574646
75
train loss item: 0.0805041715502739
76
train loss item: 0.40237393975257874
77
train loss item: 0.955787718296051
78
train loss item: 0.0579838901758194
79
train loss item: 0.15495987236499786
80
train loss item: 0.08815257251262665
81
train loss item: 0.12079140543937683
82
train loss item: 0.09798731654882431
83
train loss item: 0.35441258549690247
84
train loss item: 0.2618134319782257
85
train loss item: 0.2489439994096756
86
train loss item: 3.5783982276916504
87
train loss item: 0.09393726289272308
88
train loss item: 0.21993818879127502
epoch train loss: 0.29802518990937243
testing phase
test loss item: 0.13410361111164093
test loss item: 0.07399141788482666
test loss item: 0.46220263838768005
test loss item: 0.16867290437221527
test loss item: 0.18225008249282837
test loss item: 0.08692743629217148
test loss item: 1.202042579650879
test loss item: 0.36941248178482056
test loss item: 0.16842007637023926
test loss item: 0.2793913781642914
test loss item: 0.6568660736083984
test loss item: 0.1092393770813942
test loss item: 0.1281753033399582
test loss item: 0.20359311997890472
test loss item: 0.12514235079288483
test loss item: 0.056959591805934906
test loss item: 0.1925971508026123
test loss item: 0.33155637979507446
test loss item: 0.44722044467926025
test loss item: 0.17650552093982697
test loss item: 0.5306732654571533
test loss item: 0.27565276622772217
test loss item: 0.20686832070350647
test loss item: 0.11764063686132431
test loss item: 0.14674176275730133
test loss item: 0.1452249139547348
test loss item: 0.2148807942867279
test loss item: 0.1255297064781189
test loss item: 0.21949885785579681
test loss item: 0.23558205366134644
test loss item: 0.5939240455627441
test loss item: 0.051979295909404755
test loss item: 0.10073935985565186
test loss item: 0.4069022536277771
test loss item: 0.3164840042591095
test loss item: 0.30092987418174744
test loss item: 0.5492954254150391
test loss item: 1.126304268836975
test loss item: 0.3208398222923279
test loss item: 0.18197348713874817
test loss item: 0.21078936755657196
test loss item: 0.11260761320590973
test loss item: 0.24411961436271667
test loss item: 0.14886979758739471
test loss item: 0.3982129395008087
test loss item: 0.2599784731864929
test loss item: 0.1959439218044281
test loss item: 0.1631810963153839
test loss item: 0.35525232553482056
test loss item: 0.4958314001560211
test loss item: 0.21261698007583618
test loss item: 0.10017526149749756
test loss item: 0.1696649193763733
test loss item: 0.1155143529176712
test loss item: 0.21934469044208527
test loss item: 0.654370903968811
test loss item: 0.39124318957328796
test loss item: 0.18819156289100647
test loss item: 0.16826887428760529
test loss item: 0.14055103063583374
test loss item: 0.3112748861312866
test loss item: 0.17248989641666412
test loss item: 0.1394960731267929
test loss item: 0.1602894365787506
test loss item: 0.6646673679351807
test loss item: 0.23534055054187775
test loss item: 0.214419424533844
test loss item: 0.1707291156053543
test loss item: 0.39678481221199036
test loss item: 0.28121432662010193
test loss item: 0.050095681101083755
test loss item: 0.654010534286499
test loss item: 0.23907458782196045
test loss item: 0.26383325457572937
test loss item: 0.1104704812169075
test loss item: 0.10159286856651306
test loss item: 0.11934500932693481
test loss item: 1.2024409770965576
test loss item: 0.30429601669311523
test loss item: 0.12573325634002686
test loss item: 0.05940144136548042
test loss item: 0.731635570526123
test loss item: 0.6149546504020691
test loss item: 0.8111844658851624
test loss item: 0.149202361702919
test loss item: 0.15264064073562622
test loss item: 0.05562051013112068
test loss item: 0.049445509910583496
test loss item: 0.11874735355377197
Epoch [48/50], Training Loss: 0.2980, Testing Loss: 0.2846
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 49/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2589779794216156
1
train loss item: 0.5597927570343018
2
train loss item: 0.12002462148666382
3
train loss item: 0.22112689912319183
4
train loss item: 0.19634613394737244
5
train loss item: 0.15953703224658966
6
train loss item: 0.119439035654068
7
train loss item: 0.4308137893676758
8
train loss item: 0.07315809279680252
9
train loss item: 0.12828561663627625
10
train loss item: 0.1616942435503006
11
train loss item: 0.16185887157917023
12
train loss item: 0.09761666506528854
13
train loss item: 0.26947250962257385
14
train loss item: 0.1338849663734436
15
train loss item: 0.31007590889930725
16
train loss item: 0.04906375706195831
17
train loss item: 0.13870476186275482
18
train loss item: 0.16138410568237305
19
train loss item: 0.12213139981031418
20
train loss item: 0.11333594471216202
21
train loss item: 0.08733081817626953
22
train loss item: 0.4029127359390259
23
train loss item: 0.39285609126091003
24
train loss item: 0.2791655659675598
25
train loss item: 0.11401643604040146
26
train loss item: 0.10270906984806061
27
train loss item: 0.11836971342563629
28
train loss item: 0.04766367748379707
29
train loss item: 0.32224181294441223
30
train loss item: 1.51608407497406
31
train loss item: 0.2732846140861511
32
train loss item: 0.07320282608270645
33
train loss item: 0.1907016783952713
34
train loss item: 0.0943150520324707
35
train loss item: 1.8893862962722778
36
train loss item: 0.2859835922718048
37
train loss item: 0.29783564805984497
38
train loss item: 0.2523661255836487
39
train loss item: 0.1285403072834015
40
train loss item: 0.10184524953365326
41
train loss item: 0.13390454649925232
42
train loss item: 0.18790389597415924
43
train loss item: 0.09667221456766129
44
train loss item: 0.406055212020874
45
train loss item: 0.08247751742601395
46
train loss item: 0.07565861195325851
47
train loss item: 0.1785746067762375
48
train loss item: 0.11049048602581024
49
train loss item: 0.08981714397668839
50
train loss item: 0.13257552683353424
51
train loss item: 0.48910513520240784
52
train loss item: 0.05257585272192955
53
train loss item: 0.08720733225345612
54
train loss item: 1.7698912620544434
55
train loss item: 0.11038941890001297
56
train loss item: 0.12982413172721863
57
train loss item: 0.13394291698932648
58
train loss item: 0.09150682389736176
59
train loss item: 0.088524729013443
60
train loss item: 0.3902759552001953
61
train loss item: 1.6003559827804565
62
train loss item: 0.11124860495328903
63
train loss item: 0.19712433218955994
64
train loss item: 0.09375078231096268
65
train loss item: 0.2958027422428131
66
train loss item: 0.23037801682949066
67
train loss item: 0.1147226095199585
68
train loss item: 0.1450369656085968
69
train loss item: 0.17289935052394867
70
train loss item: 0.14230141043663025
71
train loss item: 0.07879491150379181
72
train loss item: 0.08976081758737564
73
train loss item: 0.15217572450637817
74
train loss item: 0.06058085709810257
75
train loss item: 0.08008599281311035
76
train loss item: 0.3951215445995331
77
train loss item: 0.9250423312187195
78
train loss item: 0.05220172181725502
79
train loss item: 0.15578190982341766
80
train loss item: 0.0772070586681366
81
train loss item: 0.11261026561260223
82
train loss item: 0.10685856640338898
83
train loss item: 0.34766462445259094
84
train loss item: 0.29009270668029785
85
train loss item: 0.22679220139980316
86
train loss item: 3.5598642826080322
87
train loss item: 0.09931134432554245
88
train loss item: 0.20330533385276794
epoch train loss: 0.29114362685365625
testing phase
test loss item: 0.14025895297527313
test loss item: 0.07394692301750183
test loss item: 0.4644780457019806
test loss item: 0.1762455850839615
test loss item: 0.1821426898241043
test loss item: 0.08867929130792618
test loss item: 1.4183310270309448
test loss item: 0.46253108978271484
test loss item: 0.16774091124534607
test loss item: 0.2798641324043274
test loss item: 0.6547395586967468
test loss item: 0.11677747219800949
test loss item: 0.1364341527223587
test loss item: 0.22183440625667572
test loss item: 0.12560760974884033
test loss item: 0.056456826627254486
test loss item: 0.21578752994537354
test loss item: 0.32964733242988586
test loss item: 0.49739474058151245
test loss item: 0.20578192174434662
test loss item: 0.5289731621742249
test loss item: 0.31396111845970154
test loss item: 0.2241407334804535
test loss item: 0.13345971703529358
test loss item: 0.14939287304878235
test loss item: 0.15780267119407654
test loss item: 0.226261168718338
test loss item: 0.1260911077260971
test loss item: 0.22977742552757263
test loss item: 0.23955711722373962
test loss item: 0.6460816264152527
test loss item: 0.05179525166749954
test loss item: 0.11103116720914841
test loss item: 0.4088687002658844
test loss item: 0.31451958417892456
test loss item: 0.30969199538230896
test loss item: 0.610819399356842
test loss item: 1.1185173988342285
test loss item: 0.327552855014801
test loss item: 0.20828430354595184
test loss item: 0.23249243199825287
test loss item: 0.12781120836734772
test loss item: 0.24044594168663025
test loss item: 0.16630776226520538
test loss item: 0.3955601453781128
test loss item: 0.29995232820510864
test loss item: 0.20638588070869446
test loss item: 0.18498337268829346
test loss item: 0.36694449186325073
test loss item: 0.5143745541572571
test loss item: 0.2079651802778244
test loss item: 0.10635398328304291
test loss item: 0.17574483156204224
test loss item: 0.1197294220328331
test loss item: 0.2162688672542572
test loss item: 0.6484984159469604
test loss item: 0.4202788472175598
test loss item: 0.19147229194641113
test loss item: 0.18034644424915314
test loss item: 0.13868992030620575
test loss item: 0.3063306212425232
test loss item: 0.20610807836055756
test loss item: 0.1626572459936142
test loss item: 0.16990207135677338
test loss item: 0.691939651966095
test loss item: 0.24127551913261414
test loss item: 0.24016156792640686
test loss item: 0.18530809879302979
test loss item: 0.3986642360687256
test loss item: 0.31617939472198486
test loss item: 0.04947374761104584
test loss item: 0.7909688353538513
test loss item: 0.257829874753952
test loss item: 0.3180476129055023
test loss item: 0.1183227002620697
test loss item: 0.11441318690776825
test loss item: 0.13436992466449738
test loss item: 1.2056008577346802
test loss item: 0.32442784309387207
test loss item: 0.13333874940872192
test loss item: 0.06145733594894409
test loss item: 0.7899267673492432
test loss item: 0.6748484373092651
test loss item: 0.8167106509208679
test loss item: 0.16801710426807404
test loss item: 0.161887526512146
test loss item: 0.056325387209653854
test loss item: 0.04937700182199478
test loss item: 0.12872374057769775
Epoch [49/50], Training Loss: 0.2911, Testing Loss: 0.3018
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 50/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.25509074330329895
1
train loss item: 0.5497947931289673
2
train loss item: 0.11859447509050369
3
train loss item: 0.21548153460025787
4
train loss item: 0.17933322489261627
5
train loss item: 0.1535261869430542
6
train loss item: 0.1167699471116066
7
train loss item: 0.4195615351200104
8
train loss item: 0.06753592193126678
9
train loss item: 0.12162649631500244
10
train loss item: 0.1541822999715805
11
train loss item: 0.15165318548679352
12
train loss item: 0.09262187778949738
13
train loss item: 0.26042747497558594
14
train loss item: 0.13106845319271088
15
train loss item: 0.3186790347099304
16
train loss item: 0.04886708781123161
17
train loss item: 0.12945911288261414
18
train loss item: 0.16126631200313568
19
train loss item: 0.1282186210155487
20
train loss item: 0.11462631076574326
21
train loss item: 0.08315841853618622
22
train loss item: 0.4068281352519989
23
train loss item: 0.3740187883377075
24
train loss item: 0.2657287120819092
25
train loss item: 0.10724541544914246
26
train loss item: 0.09918330609798431
27
train loss item: 0.11706411838531494
28
train loss item: 0.04769425839185715
29
train loss item: 0.3378004729747772
30
train loss item: 1.4999806880950928
31
train loss item: 0.2619248330593109
32
train loss item: 0.06822418421506882
33
train loss item: 0.18546928465366364
34
train loss item: 0.09014514833688736
35
train loss item: 1.876121997833252
36
train loss item: 0.24984827637672424
37
train loss item: 0.2640615403652191
38
train loss item: 0.20873931050300598
39
train loss item: 0.12661266326904297
40
train loss item: 0.09727589786052704
41
train loss item: 0.13165368139743805
42
train loss item: 0.1916748285293579
43
train loss item: 0.09590433537960052
44
train loss item: 0.39782068133354187
45
train loss item: 0.08162848651409149
46
train loss item: 0.07031160593032837
47
train loss item: 0.18656621873378754
48
train loss item: 0.1110033243894577
49
train loss item: 0.08741281181573868
50
train loss item: 0.14342285692691803
51
train loss item: 0.49283838272094727
52
train loss item: 0.05436735972762108
53
train loss item: 0.08728847652673721
54
train loss item: 1.7552835941314697
55
train loss item: 0.11227061599493027
56
train loss item: 0.1295294165611267
57
train loss item: 0.13807253539562225
58
train loss item: 0.09022006392478943
59
train loss item: 0.09017724543809891
60
train loss item: 0.40125802159309387
61
train loss item: 1.5791171789169312
62
train loss item: 0.1086881160736084
63
train loss item: 0.19105911254882812
64
train loss item: 0.09241856634616852
65
train loss item: 0.2387418895959854
66
train loss item: 0.21073774993419647
67
train loss item: 0.11364129185676575
68
train loss item: 0.15258082747459412
69
train loss item: 0.15700304508209229
70
train loss item: 0.1296100914478302
71
train loss item: 0.07767457515001297
72
train loss item: 0.0868377685546875
73
train loss item: 0.15267272293567657
74
train loss item: 0.06021806597709656
75
train loss item: 0.07849089801311493
76
train loss item: 0.3789374828338623
77
train loss item: 0.9328526854515076
78
train loss item: 0.049361452460289
79
train loss item: 0.14478935301303864
80
train loss item: 0.07703305035829544
81
train loss item: 0.11010865122079849
82
train loss item: 0.1034088060259819
83
train loss item: 0.34675514698028564
84
train loss item: 0.23201800882816315
85
train loss item: 0.23187926411628723
86
train loss item: 3.537924289703369
87
train loss item: 0.10010076314210892
88
train loss item: 0.18264585733413696
epoch train loss: 0.28496091385905664
testing phase
test loss item: 0.1336524933576584
test loss item: 0.07417997717857361
test loss item: 0.4220253825187683
test loss item: 0.16811707615852356
test loss item: 0.174449160695076
test loss item: 0.08591549098491669
test loss item: 1.3371573686599731
test loss item: 0.3975319266319275
test loss item: 0.1527324765920639
test loss item: 0.25504687428474426
test loss item: 0.6044148802757263
test loss item: 0.11200997233390808
test loss item: 0.13064438104629517
test loss item: 0.21619731187820435
test loss item: 0.11847378313541412
test loss item: 0.05768447369337082
test loss item: 0.1986546516418457
test loss item: 0.30017781257629395
test loss item: 0.45317402482032776
test loss item: 0.1915612518787384
test loss item: 0.4769885540008545
test loss item: 0.29025208950042725
test loss item: 0.2083912193775177
test loss item: 0.12583309412002563
test loss item: 0.13793015480041504
test loss item: 0.15081408619880676
test loss item: 0.2093888521194458
test loss item: 0.12417279928922653
test loss item: 0.2185927927494049
test loss item: 0.22165243327617645
test loss item: 0.5959373712539673
test loss item: 0.051291294395923615
test loss item: 0.10357247292995453
test loss item: 0.37699994444847107
test loss item: 0.28547200560569763
test loss item: 0.28140386939048767
test loss item: 0.5613752603530884
test loss item: 1.0259993076324463
test loss item: 0.2999812662601471
test loss item: 0.19582056999206543
test loss item: 0.22070220112800598
test loss item: 0.1194942444562912
test loss item: 0.21796241402626038
test loss item: 0.1541629284620285
test loss item: 0.3558605909347534
test loss item: 0.27454298734664917
test loss item: 0.19246533513069153
test loss item: 0.17676515877246857
test loss item: 0.3317584991455078
test loss item: 0.4671518802642822
test loss item: 0.18724367022514343
test loss item: 0.10316286981105804
test loss item: 0.1665051132440567
test loss item: 0.10996495187282562
test loss item: 0.20120297372341156
test loss item: 0.5918090343475342
test loss item: 0.38226521015167236
test loss item: 0.17162668704986572
test loss item: 0.16554901003837585
test loss item: 0.13621149957180023
test loss item: 0.2785598635673523
test loss item: 0.18240045011043549
test loss item: 0.15051287412643433
test loss item: 0.1631678342819214
test loss item: 0.6301547884941101
test loss item: 0.23220546543598175
test loss item: 0.2211591750383377
test loss item: 0.17805325984954834
test loss item: 0.37549132108688354
test loss item: 0.27583953738212585
test loss item: 0.05347574129700661
test loss item: 0.7285168170928955
test loss item: 0.24254199862480164
test loss item: 0.29282650351524353
test loss item: 0.11029297858476639
test loss item: 0.10877063870429993
test loss item: 0.12830635905265808
test loss item: 1.1108261346817017
test loss item: 0.30631211400032043
test loss item: 0.1284705400466919
test loss item: 0.057812005281448364
test loss item: 0.7238088250160217
test loss item: 0.6182176470756531
test loss item: 0.7456198334693909
test loss item: 0.16122405230998993
test loss item: 0.15228886902332306
test loss item: 0.05211561173200607
test loss item: 0.047204237431287766
test loss item: 0.1125587448477745
Epoch [50/50], Training Loss: 0.2850, Testing Loss: 0.2789
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
loss item: 0.23819467425346375
loss item: 0.1448255330324173
loss item: 1.1646742820739746
loss item: 0.6350857615470886
loss item: 0.4065198600292206
loss item: 0.2827746272087097
loss item: 0.14890067279338837
loss item: 0.5805264711380005
loss item: 0.1543155312538147
loss item: 0.14319029450416565
loss item: 0.7269256114959717
loss item: 0.04327407851815224
loss item: 0.6190714240074158
loss item: 0.15277473628520966
loss item: 0.2278350442647934
loss item: 0.19014987349510193
loss item: 0.2464536428451538
loss item: 0.4578778147697449
loss item: 0.6239275336265564
loss item: 0.31557512283325195
loss item: 0.25551944971084595
loss item: 0.17516164481639862
loss item: 0.21282321214675903
loss item: 0.18054208159446716
loss item: 0.18992123007774353
loss item: 0.47960567474365234
loss item: 0.7604398727416992
loss item: 0.11257515847682953
loss item: 0.09503223747015
loss item: 0.28772974014282227
loss item: 0.7758765816688538
loss item: 1.0853065252304077
loss item: 0.11687231063842773
loss item: 0.3782188594341278
loss item: 0.12142669409513474
loss item: 0.11981270462274551
loss item: 0.2708645761013031
loss item: 0.1634373515844345
loss item: 0.2882968783378601
loss item: 0.5084710717201233
loss item: 0.7082042694091797
loss item: 0.2060117870569229
loss item: 0.13854214549064636
loss item: 0.04409640654921532
Val Loss: 0.3449
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.001, epochs: 50, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 50 0.001 2 360 done at Wed Nov 13 18:31:29 CET 2024
UNet6 with 1 50 0.005 2 360 start at Wed Nov 13 18:31:29 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 50, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
Epoch [1/50], Training Loss: 1.0161, Testing Loss: inf
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.7337050437927246
1
train loss item: 2.7631168365478516
2
train loss item: 2.234610080718994
3
train loss item: 1.7419995069503784
4
train loss item: 6.1393723487854
5
train loss item: 1.5922759771347046
6
train loss item: 2.5647833347320557
7
train loss item: 1.6451680660247803
8
train loss item: 2.7176425457000732
9
train loss item: 1.492957592010498
10
train loss item: 1.491503357887268
11
train loss item: 1.5420777797698975
12
train loss item: 2.0083630084991455
13
train loss item: 1.8392164707183838
14
train loss item: 1.5706486701965332
15
train loss item: 2.232177257537842
16
train loss item: 2.496960163116455
17
train loss item: 2.4780821800231934
18
train loss item: 1.7222905158996582
19
train loss item: 1.6870818138122559
20
train loss item: 2.118736743927002
21
train loss item: 1.9805856943130493
22
train loss item: 3.185164213180542
23
train loss item: 1.762037992477417
24
train loss item: 1.825776219367981
25
train loss item: 1.7809085845947266
26
train loss item: 2.1128554344177246
27
train loss item: 1.5286165475845337
28
train loss item: 2.4832184314727783
29
train loss item: 2.54193377494812
30
train loss item: 2.50256085395813
31
train loss item: 2.065317153930664
32
train loss item: 2.0945029258728027
33
train loss item: 2.0646257400512695
34
train loss item: 3.4447174072265625
35
train loss item: 2.5013861656188965
36
train loss item: 1.735538363456726
37
train loss item: 1.645919919013977
38
train loss item: 2.2714486122131348
39
train loss item: 1.5122597217559814
40
train loss item: 1.890000820159912
41
train loss item: 1.462815284729004
42
train loss item: 1.4945224523544312
43
train loss item: 1.9924899339675903
44
train loss item: 1.6032381057739258
45
train loss item: 2.0889079570770264
46
train loss item: 1.7946295738220215
47
train loss item: 1.7839832305908203
48
train loss item: 1.6914453506469727
49
train loss item: 1.68925940990448
50
train loss item: 1.7840021848678589
51
train loss item: 2.236063241958618
52
train loss item: 2.3508286476135254
53
train loss item: 2.0815937519073486
54
train loss item: 2.320829391479492
55
train loss item: 1.8811920881271362
56
train loss item: 1.426205039024353
57
train loss item: 1.5302560329437256
58
train loss item: 1.9881020784378052
59
train loss item: 1.9739981889724731
60
train loss item: 2.6819868087768555
61
train loss item: 2.499228000640869
62
train loss item: 1.9953643083572388
63
train loss item: 1.7958790063858032
64
train loss item: 1.933268427848816
65
train loss item: 2.480179786682129
66
train loss item: 1.5023800134658813
67
train loss item: 1.7364012002944946
68
train loss item: 2.1607017517089844
69
train loss item: 1.6429253816604614
70
train loss item: 1.7046711444854736
71
train loss item: 2.773634195327759
72
train loss item: 2.7464749813079834
73
train loss item: 1.6722614765167236
74
train loss item: 2.9682271480560303
75
train loss item: 2.0106396675109863
76
train loss item: 1.8273371458053589
77
train loss item: 2.8965399265289307
78
train loss item: 2.4373278617858887
79
train loss item: 1.687382698059082
80
train loss item: 2.7743425369262695
81
train loss item: 1.6321439743041992
82
train loss item: 1.7260106801986694
83
train loss item: 2.1647098064422607
84
train loss item: 1.6363555192947388
85
train loss item: 1.46220862865448
86
train loss item: 4.096249580383301
87
train loss item: 2.4520556926727295
88
train loss item: 1.618540644645691
epoch train loss: 2.096988020318278
testing phase
test loss item: 64194280.0
test loss item: 77386600.0
test loss item: 37743548.0
test loss item: 117831720.0
test loss item: 73759496.0
test loss item: 67275080.0
test loss item: 52555964.0
test loss item: 53374168.0
test loss item: 50467592.0
test loss item: 28725310.0
test loss item: 94413592.0
test loss item: 114410088.0
test loss item: 36495640.0
test loss item: 6842875.0
test loss item: 71036792.0
test loss item: 80053312.0
test loss item: 27741210.0
test loss item: 42308932.0
test loss item: 52854640.0
test loss item: 24911878.0
test loss item: 38965384.0
test loss item: 105730408.0
test loss item: 51431464.0
test loss item: 73480056.0
test loss item: 38004784.0
test loss item: 45211844.0
test loss item: 54816716.0
test loss item: 72896384.0
test loss item: 73055392.0
test loss item: 30115762.0
test loss item: 81421744.0
test loss item: 82135216.0
test loss item: 73996600.0
test loss item: 114721768.0
test loss item: 57867968.0
test loss item: 192525392.0
test loss item: 46320204.0
test loss item: 148446352.0
test loss item: 97882680.0
test loss item: 71978528.0
test loss item: 53809276.0
test loss item: 53083764.0
test loss item: 23070896.0
test loss item: 106121736.0
test loss item: 38328132.0
test loss item: 56201788.0
test loss item: 42574956.0
test loss item: 27949896.0
test loss item: 28571482.0
test loss item: 56177952.0
test loss item: 39451744.0
test loss item: 33010762.0
test loss item: 34112568.0
test loss item: 165836064.0
test loss item: 32265634.0
test loss item: 80623072.0
test loss item: 126303920.0
test loss item: 6837115.5
test loss item: 39919224.0
test loss item: 37874236.0
test loss item: 33307098.0
test loss item: 47217752.0
test loss item: 44385896.0
test loss item: 41790576.0
test loss item: 105819848.0
test loss item: 169617760.0
test loss item: 31910236.0
test loss item: 48406540.0
test loss item: 60020248.0
test loss item: 45935168.0
test loss item: 70496864.0
test loss item: 38118292.0
test loss item: 34978408.0
test loss item: 47180848.0
test loss item: 41174452.0
test loss item: 51311912.0
test loss item: 69519968.0
test loss item: 192651280.0
test loss item: 6877895.5
test loss item: 67829576.0
test loss item: 57674132.0
test loss item: 135990032.0
test loss item: 47934808.0
test loss item: 185032400.0
test loss item: 32694296.0
test loss item: 40738712.0
test loss item: 69086096.0
test loss item: 78784400.0
test loss item: 69556800.0
Epoch [2/50], Training Loss: 2.0970, Testing Loss: 64871391.8427
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.183565616607666
1
train loss item: 1.9414341449737549
2
train loss item: 0.5925023555755615
3
train loss item: 1.1334564685821533
4
train loss item: 0.8947123289108276
5
train loss item: 0.9950372576713562
6
train loss item: 0.4728458821773529
7
train loss item: 1.4358906745910645
8
train loss item: 0.6126320362091064
9
train loss item: 0.6711855530738831
10
train loss item: 0.7577145099639893
11
train loss item: 0.8863354921340942
12
train loss item: 0.5569525957107544
13
train loss item: 1.0617115497589111
14
train loss item: 0.927487313747406
15
train loss item: 1.350458025932312
16
train loss item: 0.4471089839935303
17
train loss item: 0.5849692225456238
18
train loss item: 1.0702556371688843
19
train loss item: 0.743766188621521
20
train loss item: 0.5721824169158936
21
train loss item: 0.5679368376731873
22
train loss item: 1.8540056943893433
23
train loss item: 1.3585312366485596
24
train loss item: 0.8896396160125732
25
train loss item: 0.892193615436554
26
train loss item: 0.49351125955581665
27
train loss item: 0.989745020866394
28
train loss item: 0.46215173602104187
29
train loss item: 1.5552799701690674
30
train loss item: 2.726870059967041
31
train loss item: 1.151024580001831
32
train loss item: 0.7188815474510193
33
train loss item: 0.8409228324890137
34
train loss item: 0.6987011432647705
35
train loss item: 2.5515308380126953
36
train loss item: 1.1870825290679932
37
train loss item: 0.9118356704711914
38
train loss item: 1.00033438205719
39
train loss item: 0.9232012629508972
40
train loss item: 0.6649325489997864
41
train loss item: 0.9523438215255737
42
train loss item: 0.8555437922477722
43
train loss item: 0.6985820531845093
44
train loss item: 1.3676202297210693
45
train loss item: 0.5383530855178833
46
train loss item: 0.5667073130607605
47
train loss item: 0.974998414516449
48
train loss item: 0.8386710286140442
49
train loss item: 0.7001276612281799
50
train loss item: 0.75501549243927
51
train loss item: 1.569324016571045
52
train loss item: 0.6918904781341553
53
train loss item: 0.7456850409507751
54
train loss item: 2.4733364582061768
55
train loss item: 0.5959522128105164
56
train loss item: 0.9113231301307678
57
train loss item: 0.9146339893341064
58
train loss item: 0.6802918910980225
59
train loss item: 0.6703583002090454
60
train loss item: 1.7469711303710938
61
train loss item: 2.7646543979644775
62
train loss item: 0.8055040836334229
63
train loss item: 1.0253621339797974
64
train loss item: 0.6980629563331604
65
train loss item: 1.037177562713623
66
train loss item: 1.0598479509353638
67
train loss item: 0.7360441088676453
68
train loss item: 0.8391050100326538
69
train loss item: 0.7724520564079285
70
train loss item: 0.8917180895805359
71
train loss item: 0.5594335794448853
72
train loss item: 0.6747870445251465
73
train loss item: 0.7655966281890869
74
train loss item: 0.5394884347915649
75
train loss item: 0.5603901743888855
76
train loss item: 1.4299347400665283
77
train loss item: 1.9654195308685303
78
train loss item: 0.6301231980323792
79
train loss item: 0.9600579142570496
80
train loss item: 0.5262104868888855
81
train loss item: 0.7917017936706543
82
train loss item: 0.8507077097892761
83
train loss item: 1.376380443572998
84
train loss item: 1.0350337028503418
85
train loss item: 1.1629035472869873
86
train loss item: 4.447148323059082
87
train loss item: 0.8393546342849731
88
train loss item: 0.6154994964599609
epoch train loss: 1.021779167518187
testing phase
test loss item: 5521997.0
test loss item: 7138301.5
test loss item: 1392644.75
test loss item: 6179405.0
test loss item: 7189193.5
test loss item: 5434376.5
test loss item: 1869010.375
test loss item: 3627687.0
test loss item: 1355536.375
test loss item: 912160.5625
test loss item: 1723799.0
test loss item: 1830857.5
test loss item: 902500.75
test loss item: 2388472.75
test loss item: 8060358.5
test loss item: 2156714.25
test loss item: 1182667.0
test loss item: 3038765.25
test loss item: 4258468.5
test loss item: 4641197.5
test loss item: 5902174.5
test loss item: 973868.5
test loss item: 5363483.5
test loss item: 7947057.5
test loss item: 1475143.25
test loss item: 5812022.5
test loss item: 4786960.5
test loss item: 6819634.5
test loss item: 8102120.0
test loss item: 1242680.125
test loss item: 3931957.75
test loss item: 2135361.25
test loss item: 8305707.0
test loss item: 1627812.875
test loss item: 2823427.5
test loss item: 5473075.5
test loss item: 2050324.625
test loss item: 1824358.5
test loss item: 2303926.0
test loss item: 6839018.5
test loss item: 1211332.5
test loss item: 4378224.0
test loss item: 1720441.625
test loss item: 957279.3125
test loss item: 5909265.0
test loss item: 5766713.5
test loss item: 3475168.0
test loss item: 7323373.5
test loss item: 320534.03125
test loss item: 4742660.5
test loss item: 2703536.5
test loss item: 1828224.375
test loss item: 3397204.5
test loss item: 1506293.0
test loss item: 4624255.0
test loss item: 4243142.5
test loss item: 2237267.5
test loss item: 2392109.25
test loss item: 3163123.0
test loss item: 3440907.0
test loss item: 1807716.875
test loss item: 1218867.625
test loss item: 6611212.0
test loss item: 303618.21875
test loss item: 4985085.5
test loss item: 1553572.875
test loss item: 3415601.25
test loss item: 3451090.25
test loss item: 1360947.375
test loss item: 637669.125
test loss item: 4361056.5
test loss item: 2325683.0
test loss item: 5529577.5
test loss item: 5857173.0
test loss item: 3813475.25
test loss item: 3666666.25
test loss item: 7401176.0
test loss item: 3399414.5
test loss item: 2390457.75
test loss item: 7059022.0
test loss item: 5227428.5
test loss item: 4832469.0
test loss item: 4552043.5
test loss item: 3629586.5
test loss item: 4753256.5
test loss item: 4514552.5
test loss item: 4661881.5
test loss item: 2165708.5
test loss item: 8545681.0
Epoch [3/50], Training Loss: 1.0218, Testing Loss: 3774348.0098
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.1574124097824097
1
train loss item: 1.9939154386520386
2
train loss item: 0.6851544976234436
3
train loss item: 1.221824049949646
4
train loss item: 0.9709842205047607
5
train loss item: 1.1037614345550537
6
train loss item: 0.5823261141777039
7
train loss item: 1.5786597728729248
8
train loss item: 0.5369793176651001
9
train loss item: 0.6179637312889099
10
train loss item: 0.8371385931968689
11
train loss item: 1.0428433418273926
12
train loss item: 0.3738707900047302
13
train loss item: 0.9614976048469543
14
train loss item: 1.130540370941162
15
train loss item: 1.1000782251358032
16
train loss item: 0.34165799617767334
17
train loss item: 0.6350982785224915
18
train loss item: 1.0526798963546753
19
train loss item: 0.6815463304519653
20
train loss item: 0.5234748721122742
21
train loss item: 0.5844346284866333
22
train loss item: 1.6897159814834595
23
train loss item: 1.4940884113311768
24
train loss item: 0.8623356819152832
25
train loss item: 0.6053005456924438
26
train loss item: 0.5238592028617859
27
train loss item: 1.083116888999939
28
train loss item: 0.31862208247184753
29
train loss item: 1.4278826713562012
30
train loss item: 3.1265909671783447
31
train loss item: 1.3633322715759277
32
train loss item: 1.3678544759750366
33
train loss item: 1.0854909420013428
34
train loss item: 0.5634687542915344
35
train loss item: 3.0801820755004883
36
train loss item: 1.333024501800537
37
train loss item: 1.1170320510864258
38
train loss item: 1.0321985483169556
39
train loss item: 1.071929693222046
40
train loss item: 0.4916936457157135
41
train loss item: 1.0832405090332031
42
train loss item: 1.0191025733947754
43
train loss item: 1.3422534465789795
44
train loss item: 1.4352326393127441
45
train loss item: 0.6774218082427979
46
train loss item: 0.647018551826477
47
train loss item: 1.0861091613769531
48
train loss item: 1.0953893661499023
49
train loss item: 0.7269027233123779
50
train loss item: 0.6388546228408813
51
train loss item: 1.8398010730743408
52
train loss item: 0.5272270441055298
53
train loss item: 0.582594633102417
54
train loss item: 2.9758660793304443
55
train loss item: 0.6146993041038513
56
train loss item: 1.096402883529663
57
train loss item: 1.1103590726852417
58
train loss item: 1.3151277303695679
59
train loss item: 0.43090537190437317
60
train loss item: 1.528467059135437
61
train loss item: 2.9844484329223633
62
train loss item: 0.78636234998703
63
train loss item: 1.1165361404418945
64
train loss item: 1.370872974395752
65
train loss item: 0.8983699679374695
66
train loss item: 1.2378227710723877
67
train loss item: 0.6051691174507141
68
train loss item: 0.621517539024353
69
train loss item: 0.7023487687110901
70
train loss item: 1.0926916599273682
71
train loss item: 0.5507144927978516
72
train loss item: 0.6393551826477051
73
train loss item: 0.6313296556472778
74
train loss item: 0.23827973008155823
75
train loss item: 0.4085358679294586
76
train loss item: 1.4518320560455322
77
train loss item: 1.9775038957595825
78
train loss item: 0.5889081358909607
79
train loss item: 1.0293633937835693
80
train loss item: 0.6876837015151978
81
train loss item: 0.6747007369995117
82
train loss item: 1.0069897174835205
83
train loss item: 1.1776341199874878
84
train loss item: 1.2533090114593506
85
train loss item: 1.1214240789413452
86
train loss item: 5.2202043533325195
87
train loss item: 0.5375616550445557
88
train loss item: 0.6052843332290649
epoch train loss: 1.082486413502961
testing phase
test loss item: 1373.18505859375
test loss item: 189.09327697753906
test loss item: 369.2943115234375
test loss item: 424.96807861328125
test loss item: 211.4586181640625
test loss item: 251.73577880859375
test loss item: 80.72917938232422
test loss item: 185.982421875
test loss item: 16.79558563232422
test loss item: 15.428732872009277
test loss item: 129.42709350585938
test loss item: 507.9722595214844
test loss item: 16.074125289916992
test loss item: 565.6630249023438
test loss item: 267.7524108886719
test loss item: 109.59881591796875
test loss item: 377.2904357910156
test loss item: 384.050537109375
test loss item: 1343.378173828125
test loss item: 489.7862243652344
test loss item: 747.7205200195312
test loss item: 389.63543701171875
test loss item: 1376.2557373046875
test loss item: 52.161598205566406
test loss item: 137.7389373779297
test loss item: 835.73779296875
test loss item: 429.1953125
test loss item: 155.943115234375
test loss item: 225.03160095214844
test loss item: 14.522889137268066
test loss item: 194.5797576904297
test loss item: 109.61671447753906
test loss item: 142.3399200439453
test loss item: 504.4494323730469
test loss item: 290.06817626953125
test loss item: 411.9919128417969
test loss item: 180.49609375
test loss item: 205.38253784179688
test loss item: 422.0642395019531
test loss item: 141.83587646484375
test loss item: 62.18326950073242
test loss item: 1230.7574462890625
test loss item: 493.3901672363281
test loss item: 380.1335754394531
test loss item: 749.6412353515625
test loss item: 534.6477661132812
test loss item: 442.6421813964844
test loss item: 679.5367431640625
test loss item: 16.549957275390625
test loss item: 935.044921875
test loss item: 260.8851013183594
test loss item: 137.5486602783203
test loss item: 16.860403060913086
test loss item: 577.7509765625
test loss item: 162.39450073242188
test loss item: 197.6161651611328
test loss item: 16.391542434692383
test loss item: 566.707275390625
test loss item: 385.5350646972656
test loss item: 33.282684326171875
test loss item: 137.3617706298828
test loss item: 61.86630630493164
test loss item: 1411.269287109375
test loss item: 17.444717407226562
test loss item: 323.91796875
test loss item: 578.991943359375
test loss item: 13.818497657775879
test loss item: 159.61163330078125
test loss item: 62.07839584350586
test loss item: 15.281039237976074
test loss item: 156.96530151367188
test loss item: 159.56690979003906
test loss item: 723.7645874023438
test loss item: 1383.801513671875
test loss item: 447.0059814453125
test loss item: 189.57083129882812
test loss item: 152.9215850830078
test loss item: 574.351318359375
test loss item: 566.7460327148438
test loss item: 1428.2054443359375
test loss item: 298.8756408691406
test loss item: 1321.682861328125
test loss item: 406.78167724609375
test loss item: 557.9059448242188
test loss item: 182.75282287597656
test loss item: 1297.17919921875
test loss item: 248.6237335205078
test loss item: 109.65879821777344
test loss item: 2724.205810546875
Epoch [4/50], Training Loss: 1.0825, Testing Loss: 425.4847
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.669301450252533
1
train loss item: 2.005352735519409
2
train loss item: 0.5108360052108765
3
train loss item: 1.1352429389953613
4
train loss item: 0.5807209610939026
5
train loss item: 0.5794386267662048
6
train loss item: 0.4949324131011963
7
train loss item: 1.2751185894012451
8
train loss item: 0.4077865183353424
9
train loss item: 0.4953464865684509
10
train loss item: 0.6323778629302979
11
train loss item: 0.5133861899375916
12
train loss item: 0.4307023584842682
13
train loss item: 0.8104681968688965
14
train loss item: 0.5151399374008179
15
train loss item: 1.1922504901885986
16
train loss item: 0.3449742794036865
17
train loss item: 0.4205591678619385
18
train loss item: 0.6573119163513184
19
train loss item: 0.5358530282974243
20
train loss item: 0.43036356568336487
21
train loss item: 0.32258933782577515
22
train loss item: 1.8101774454116821
23
train loss item: 1.3432197570800781
24
train loss item: 0.8852701187133789
25
train loss item: 0.5495965480804443
26
train loss item: 0.27381429076194763
27
train loss item: 0.5837677121162415
28
train loss item: 0.3634118139743805
29
train loss item: 1.435518503189087
30
train loss item: 3.0796546936035156
31
train loss item: 0.9577363133430481
32
train loss item: 0.3649596869945526
33
train loss item: 0.8014232516288757
34
train loss item: 0.5286387205123901
35
train loss item: 2.885377883911133
36
train loss item: 0.8664788603782654
37
train loss item: 0.6632768511772156
38
train loss item: 0.9014606475830078
39
train loss item: 0.5859564542770386
40
train loss item: 0.29297399520874023
41
train loss item: 0.6027674078941345
42
train loss item: 0.5684018731117249
43
train loss item: 0.46087899804115295
44
train loss item: 1.0571134090423584
45
train loss item: 0.38469836115837097
46
train loss item: 0.35067543387413025
47
train loss item: 0.6974745988845825
48
train loss item: 0.43393397331237793
49
train loss item: 0.42840883135795593
50
train loss item: 0.6397272348403931
51
train loss item: 1.568054437637329
52
train loss item: 0.3257361352443695
53
train loss item: 0.4465019106864929
54
train loss item: 2.7694408893585205
55
train loss item: 0.3426324129104614
56
train loss item: 0.5977542996406555
57
train loss item: 0.5584379434585571
58
train loss item: 0.42660972476005554
59
train loss item: 0.25844404101371765
60
train loss item: 1.5652803182601929
61
train loss item: 2.8502142429351807
62
train loss item: 0.37750303745269775
63
train loss item: 0.7479260563850403
64
train loss item: 0.43345701694488525
65
train loss item: 0.9394662976264954
66
train loss item: 0.7468425035476685
67
train loss item: 0.5197861194610596
68
train loss item: 0.6439663767814636
69
train loss item: 0.6162663102149963
70
train loss item: 0.5631812810897827
71
train loss item: 0.297536700963974
72
train loss item: 0.49422869086265564
73
train loss item: 0.5071637630462646
74
train loss item: 0.2347545325756073
75
train loss item: 0.40762895345687866
76
train loss item: 1.3740973472595215
77
train loss item: 1.972565770149231
78
train loss item: 0.21327145397663116
79
train loss item: 0.5899575352668762
80
train loss item: 0.22748957574367523
81
train loss item: 0.49369609355926514
82
train loss item: 0.4424087107181549
83
train loss item: 1.1738381385803223
84
train loss item: 0.7521194219589233
85
train loss item: 1.0730184316635132
86
train loss item: 5.010405540466309
87
train loss item: 0.49739310145378113
88
train loss item: 0.5490522980690002
epoch train loss: 0.824325552147426
testing phase
test loss item: 193.53456115722656
test loss item: 194.09320068359375
test loss item: 500.2169494628906
test loss item: 796.852294921875
test loss item: 200.2329864501953
test loss item: 282.4388732910156
test loss item: 182.24461364746094
test loss item: 167.66429138183594
test loss item: 175.3987274169922
test loss item: 125.48291015625
test loss item: 166.9290313720703
test loss item: 1128.321533203125
test loss item: 540.4620361328125
test loss item: 671.693359375
test loss item: 91.36542510986328
test loss item: 351.97174072265625
test loss item: 744.7156372070312
test loss item: 115.01734924316406
test loss item: 117.93062591552734
test loss item: 702.40380859375
test loss item: 807.5352783203125
test loss item: 785.1324462890625
test loss item: 805.044677734375
test loss item: 185.39340209960938
test loss item: 727.920654296875
test loss item: 587.4926147460938
test loss item: 386.82562255859375
test loss item: 253.26596069335938
test loss item: 243.0707244873047
test loss item: 120.10271453857422
test loss item: 117.62374114990234
test loss item: 479.881591796875
test loss item: 136.21083068847656
test loss item: 851.7933349609375
test loss item: 206.7367706298828
test loss item: 366.36102294921875
test loss item: 197.50408935546875
test loss item: 180.21047973632812
test loss item: 863.2252197265625
test loss item: 258.83917236328125
test loss item: 819.5640869140625
test loss item: 834.2333984375
test loss item: 600.8545532226562
test loss item: 1004.1815795898438
test loss item: 850.4442138671875
test loss item: 550.06591796875
test loss item: 984.0051879882812
test loss item: 644.6589965820312
test loss item: 122.55614471435547
test loss item: 316.7966613769531
test loss item: 298.982421875
test loss item: 98.64193725585938
test loss item: 646.3541870117188
test loss item: 1156.1309814453125
test loss item: 481.9346923828125
test loss item: 62.12835693359375
test loss item: 107.43003845214844
test loss item: 709.7845458984375
test loss item: 138.30068969726562
test loss item: 647.699462890625
test loss item: 84.52913665771484
test loss item: 196.31517028808594
test loss item: 283.86846923828125
test loss item: 769.9132080078125
test loss item: 147.8094024658203
test loss item: 1123.41015625
test loss item: 321.3728942871094
test loss item: 724.9478149414062
test loss item: 506.3523254394531
test loss item: 117.76371002197266
test loss item: 237.07940673828125
test loss item: 155.59878540039062
test loss item: 837.0817260742188
test loss item: 144.57643127441406
test loss item: 566.4548950195312
test loss item: 749.6746826171875
test loss item: 171.1521453857422
test loss item: 165.53244018554688
test loss item: 674.7103271484375
test loss item: 219.24473571777344
test loss item: 87.8331298828125
test loss item: 153.9138946533203
test loss item: 353.70050048828125
test loss item: 146.09156799316406
test loss item: 431.7414245605469
test loss item: 616.6219482421875
test loss item: 184.28746032714844
test loss item: 273.68548583984375
test loss item: 121.00711822509766
Epoch [5/50], Training Loss: 0.8243, Testing Loss: 423.0355
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5946231484413147
1
train loss item: 1.9838461875915527
2
train loss item: 0.4009765386581421
3
train loss item: 1.0213115215301514
4
train loss item: 0.5309916734695435
5
train loss item: 0.46336641907691956
6
train loss item: 0.49030694365501404
7
train loss item: 1.1470869779586792
8
train loss item: 0.22655262053012848
9
train loss item: 0.4409114420413971
10
train loss item: 0.5291445851325989
11
train loss item: 0.4629054069519043
12
train loss item: 0.21491840481758118
13
train loss item: 0.6903838515281677
14
train loss item: 0.34871047735214233
15
train loss item: 1.2579970359802246
16
train loss item: 0.18816684186458588
17
train loss item: 0.48879173398017883
18
train loss item: 0.5870199799537659
19
train loss item: 0.5372936129570007
20
train loss item: 0.5211512446403503
21
train loss item: 0.3438786268234253
22
train loss item: 1.8720426559448242
23
train loss item: 1.2079607248306274
24
train loss item: 1.0332306623458862
25
train loss item: 0.3122381269931793
26
train loss item: 0.33172041177749634
27
train loss item: 0.4114626348018646
28
train loss item: 0.1851843148469925
29
train loss item: 1.4455047845840454
30
train loss item: 3.020362615585327
31
train loss item: 0.7786102294921875
32
train loss item: 0.2127753496170044
33
train loss item: 0.6196749806404114
34
train loss item: 0.3363945782184601
35
train loss item: 2.888387441635132
36
train loss item: 0.8179313540458679
37
train loss item: 0.6105154752731323
38
train loss item: 0.8980810642242432
39
train loss item: 0.4164239168167114
40
train loss item: 0.2508063018321991
41
train loss item: 0.42121002078056335
42
train loss item: 0.4569108188152313
43
train loss item: 0.3071165382862091
44
train loss item: 0.8957749009132385
45
train loss item: 0.19424252212047577
46
train loss item: 0.196355938911438
47
train loss item: 0.6809849739074707
48
train loss item: 0.3670964539051056
49
train loss item: 0.2346074879169464
50
train loss item: 0.579245924949646
51
train loss item: 1.5370079278945923
52
train loss item: 0.17673788964748383
53
train loss item: 0.27674761414527893
54
train loss item: 2.758492946624756
55
train loss item: 0.320963978767395
56
train loss item: 0.41256362199783325
57
train loss item: 0.40809956192970276
58
train loss item: 0.30322903394699097
59
train loss item: 0.19452440738677979
60
train loss item: 1.5820327997207642
61
train loss item: 2.6933252811431885
62
train loss item: 0.3721502125263214
63
train loss item: 0.7603291869163513
64
train loss item: 0.27402302622795105
65
train loss item: 1.0804136991500854
66
train loss item: 0.6739026308059692
67
train loss item: 0.426050066947937
68
train loss item: 0.7082470655441284
69
train loss item: 0.5692058205604553
70
train loss item: 0.5310481190681458
71
train loss item: 0.3975130021572113
72
train loss item: 0.30706295371055603
73
train loss item: 0.4843127429485321
74
train loss item: 0.19775870442390442
75
train loss item: 0.19237980246543884
76
train loss item: 1.2383753061294556
77
train loss item: 2.0013647079467773
78
train loss item: 0.1941377818584442
79
train loss item: 0.5912503004074097
80
train loss item: 0.2922463119029999
81
train loss item: 0.34221401810646057
82
train loss item: 0.3371834456920624
83
train loss item: 1.2277854681015015
84
train loss item: 0.7257451415061951
85
train loss item: 1.0315133333206177
86
train loss item: 4.955499649047852
87
train loss item: 0.2893543243408203
88
train loss item: 0.651634156703949
epoch train loss: 0.7524675788839211
testing phase
test loss item: 259.4425964355469
test loss item: 197.48121643066406
test loss item: 98.00985717773438
test loss item: 242.9959716796875
test loss item: 217.9160919189453
test loss item: 236.30177307128906
test loss item: 110.36363220214844
test loss item: 105.30272674560547
test loss item: 154.68600463867188
test loss item: 21.73921775817871
test loss item: 150.54066467285156
test loss item: 202.464599609375
test loss item: 30.069561004638672
test loss item: 283.8904724121094
test loss item: 154.61566162109375
test loss item: 236.31361389160156
test loss item: 111.42536926269531
test loss item: 126.01750183105469
test loss item: 346.5968933105469
test loss item: 106.1366958618164
test loss item: 336.512451171875
test loss item: 215.23597717285156
test loss item: 264.268310546875
test loss item: 120.32202911376953
test loss item: 103.47590637207031
test loss item: 403.9365539550781
test loss item: 214.18618774414062
test loss item: 201.45753479003906
test loss item: 159.6568145751953
test loss item: 14.346186637878418
test loss item: 109.02555084228516
test loss item: 224.5221710205078
test loss item: 139.29971313476562
test loss item: 219.76678466796875
test loss item: 177.98626708984375
test loss item: 89.12076568603516
test loss item: 76.31513977050781
test loss item: 196.98184204101562
test loss item: 185.42982482910156
test loss item: 193.0317840576172
test loss item: 139.58351135253906
test loss item: 392.52044677734375
test loss item: 117.28933715820312
test loss item: 191.39463806152344
test loss item: 317.12896728515625
test loss item: 196.3995361328125
test loss item: 307.9481506347656
test loss item: 153.33250427246094
test loss item: 20.645612716674805
test loss item: 406.4595947265625
test loss item: 147.2521514892578
test loss item: 50.480201721191406
test loss item: 172.25845336914062
test loss item: 311.2869873046875
test loss item: 222.57345581054688
test loss item: 146.69578552246094
test loss item: 168.74209594726562
test loss item: 293.5848693847656
test loss item: 121.58904266357422
test loss item: 146.02207946777344
test loss item: 49.03114318847656
test loss item: 133.844970703125
test loss item: 235.93679809570312
test loss item: 16.317113876342773
test loss item: 204.7295379638672
test loss item: 307.411865234375
test loss item: 128.5391845703125
test loss item: 100.72631072998047
test loss item: 147.0782928466797
test loss item: 12.050564765930176
test loss item: 182.52389526367188
test loss item: 119.85138702392578
test loss item: 329.3778991699219
test loss item: 195.74880981445312
test loss item: 145.92115783691406
test loss item: 221.43455505371094
test loss item: 112.62158203125
test loss item: 306.4727783203125
test loss item: 285.5953369140625
test loss item: 283.4070739746094
test loss item: 134.18812561035156
test loss item: 377.9163818359375
test loss item: 89.43124389648438
test loss item: 234.63430786132812
test loss item: 204.50035095214844
test loss item: 337.8183898925781
test loss item: 206.04635620117188
test loss item: 241.4140625
test loss item: 693.698486328125
Epoch [6/50], Training Loss: 0.7525, Testing Loss: 192.1196
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5607684850692749
1
train loss item: 1.926676630973816
2
train loss item: 0.35329684615135193
3
train loss item: 0.9597423076629639
4
train loss item: 0.5227727890014648
5
train loss item: 0.4508007764816284
6
train loss item: 0.4522921144962311
7
train loss item: 1.1024432182312012
8
train loss item: 0.22012585401535034
9
train loss item: 0.42723026871681213
10
train loss item: 0.49717867374420166
11
train loss item: 0.44841837882995605
12
train loss item: 0.14018264412879944
13
train loss item: 0.6654989719390869
14
train loss item: 0.32522228360176086
15
train loss item: 1.2281792163848877
16
train loss item: 0.13173611462116241
17
train loss item: 0.49172964692115784
18
train loss item: 0.5584751963615417
19
train loss item: 0.521047830581665
20
train loss item: 0.43972429633140564
21
train loss item: 0.2496684342622757
22
train loss item: 1.8391066789627075
23
train loss item: 1.164626121520996
24
train loss item: 0.976655125617981
25
train loss item: 0.24660524725914001
26
train loss item: 0.31871646642684937
27
train loss item: 0.37081149220466614
28
train loss item: 0.13135786354541779
29
train loss item: 1.4184701442718506
30
train loss item: 2.9813385009765625
31
train loss item: 0.7355334162712097
32
train loss item: 0.15874671936035156
33
train loss item: 0.5760723948478699
34
train loss item: 0.21040666103363037
35
train loss item: 2.8834216594696045
36
train loss item: 0.7677138447761536
37
train loss item: 0.6080870628356934
38
train loss item: 0.8013278245925903
39
train loss item: 0.37254300713539124
40
train loss item: 0.23103411495685577
41
train loss item: 0.3911621570587158
42
train loss item: 0.45177802443504333
43
train loss item: 0.2848416268825531
44
train loss item: 0.8446726202964783
45
train loss item: 0.17955805361270905
46
train loss item: 0.16463777422904968
47
train loss item: 0.6861543655395508
48
train loss item: 0.3559110760688782
49
train loss item: 0.21588771045207977
50
train loss item: 0.5786092877388
51
train loss item: 1.5088756084442139
52
train loss item: 0.1717795431613922
53
train loss item: 0.2368287891149521
54
train loss item: 2.7597692012786865
55
train loss item: 0.3183665871620178
56
train loss item: 0.3858959674835205
57
train loss item: 0.3778788149356842
58
train loss item: 0.272002637386322
59
train loss item: 0.22650496661663055
60
train loss item: 1.547382116317749
61
train loss item: 2.6094629764556885
62
train loss item: 0.3693045973777771
63
train loss item: 0.7556576132774353
64
train loss item: 0.24688805639743805
65
train loss item: 1.0776557922363281
66
train loss item: 0.6160284876823425
67
train loss item: 0.38643935322761536
68
train loss item: 0.708397626876831
69
train loss item: 0.5711262822151184
70
train loss item: 0.52189701795578
71
train loss item: 0.2561063766479492
72
train loss item: 0.28796645998954773
73
train loss item: 0.4740075170993805
74
train loss item: 0.17208364605903625
75
train loss item: 0.13727766275405884
76
train loss item: 1.197191596031189
77
train loss item: 1.9920690059661865
78
train loss item: 0.15299877524375916
79
train loss item: 0.5737409591674805
80
train loss item: 0.232942134141922
81
train loss item: 0.3285616636276245
82
train loss item: 0.317914217710495
83
train loss item: 1.215092420578003
84
train loss item: 0.6785671710968018
85
train loss item: 0.9451348781585693
86
train loss item: 4.934544563293457
87
train loss item: 0.2432193160057068
88
train loss item: 0.6013710498809814
epoch train loss: 0.7194149378645286
testing phase
test loss item: 29.274192810058594
test loss item: 18.11981201171875
test loss item: 2.0763919353485107
test loss item: 24.61143684387207
test loss item: 9.505044937133789
test loss item: 11.72424602508545
test loss item: 37.65914535522461
test loss item: 24.45854377746582
test loss item: 2.2086033821105957
test loss item: 3.9273390769958496
test loss item: 7.500892639160156
test loss item: 23.5261287689209
test loss item: 1.2914135456085205
test loss item: 43.845394134521484
test loss item: 11.692344665527344
test loss item: 28.7581787109375
test loss item: 1.8204401731491089
test loss item: 7.640153884887695
test loss item: 66.68626403808594
test loss item: 8.350934982299805
test loss item: 36.640594482421875
test loss item: 23.66779899597168
test loss item: 29.469741821289062
test loss item: 0.3994464874267578
test loss item: 7.319428443908691
test loss item: 50.59745407104492
test loss item: 6.379464626312256
test loss item: 5.975285053253174
test loss item: 14.872284889221191
test loss item: 0.8930281400680542
test loss item: 19.07354736328125
test loss item: 28.844356536865234
test loss item: 5.080907344818115
test loss item: 23.792264938354492
test loss item: 16.936445236206055
test loss item: 11.555089950561523
test loss item: 16.25121307373047
test loss item: 7.270370960235596
test loss item: 17.114681243896484
test loss item: 5.939759731292725
test loss item: 15.971391677856445
test loss item: 65.05948638916016
test loss item: 1.3123375177383423
test loss item: 17.224197387695312
test loss item: 30.896617889404297
test loss item: 21.392221450805664
test loss item: 28.908695220947266
test loss item: 12.208977699279785
test loss item: 2.3289201259613037
test loss item: 63.68441390991211
test loss item: 12.502114295959473
test loss item: 7.260521411895752
test loss item: 5.443305969238281
test loss item: 34.251869201660156
test loss item: 16.423215866088867
test loss item: 10.495035171508789
test loss item: 9.772098541259766
test loss item: 44.502464294433594
test loss item: 9.17160415649414
test loss item: 7.139128684997559
test loss item: 7.255197525024414
test loss item: 16.110315322875977
test loss item: 32.270599365234375
test loss item: 1.2586299180984497
test loss item: 24.13844108581543
test loss item: 34.62247848510742
test loss item: 4.717680931091309
test loss item: 8.049653053283691
test loss item: 15.92336654663086
test loss item: 15.266972541809082
test loss item: 20.055017471313477
test loss item: 37.78230667114258
test loss item: 35.220863342285156
test loss item: 28.76255226135254
test loss item: 9.375167846679688
test loss item: 17.704700469970703
test loss item: 7.635445594787598
test loss item: 13.802908897399902
test loss item: 44.19063949584961
test loss item: 31.40974998474121
test loss item: 14.445944786071777
test loss item: 68.6751480102539
test loss item: 17.49645233154297
test loss item: 8.602810859680176
test loss item: 17.964109420776367
test loss item: 63.051387786865234
test loss item: 22.31927490234375
test loss item: 28.763574600219727
test loss item: 130.95974731445312
Epoch [7/50], Training Loss: 0.7194, Testing Loss: 21.1970
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5261905789375305
1
train loss item: 1.8815093040466309
2
train loss item: 0.334087073802948
3
train loss item: 0.9091936945915222
4
train loss item: 0.4989086091518402
5
train loss item: 0.4167511463165283
6
train loss item: 0.3841474652290344
7
train loss item: 1.0699670314788818
8
train loss item: 0.2012716680765152
9
train loss item: 0.4094078838825226
10
train loss item: 0.4812868535518646
11
train loss item: 0.39548611640930176
12
train loss item: 0.12942124903202057
13
train loss item: 0.6368029713630676
14
train loss item: 0.3064843416213989
15
train loss item: 1.1815521717071533
16
train loss item: 0.09724964946508408
17
train loss item: 0.44703564047813416
18
train loss item: 0.5159271955490112
19
train loss item: 0.49059054255485535
20
train loss item: 0.3897812068462372
21
train loss item: 0.18639805912971497
22
train loss item: 1.785454273223877
23
train loss item: 1.1471267938613892
24
train loss item: 0.9325661063194275
25
train loss item: 0.22641023993492126
26
train loss item: 0.28639379143714905
27
train loss item: 0.34490838646888733
28
train loss item: 0.10615800321102142
29
train loss item: 1.3872405290603638
30
train loss item: 2.936075210571289
31
train loss item: 0.7216778993606567
32
train loss item: 0.16264352202415466
33
train loss item: 0.5739965438842773
34
train loss item: 0.14100129902362823
35
train loss item: 2.854309558868408
36
train loss item: 0.7120509743690491
37
train loss item: 0.5632851123809814
38
train loss item: 0.7622356414794922
39
train loss item: 0.33171844482421875
40
train loss item: 0.20960944890975952
41
train loss item: 0.3644246459007263
42
train loss item: 0.44512781500816345
43
train loss item: 0.2813429534435272
44
train loss item: 0.8206536173820496
45
train loss item: 0.19917233288288116
46
train loss item: 0.1626848727464676
47
train loss item: 0.6730755567550659
48
train loss item: 0.34580668807029724
49
train loss item: 0.20838603377342224
50
train loss item: 0.5450286269187927
51
train loss item: 1.4723633527755737
52
train loss item: 0.139985591173172
53
train loss item: 0.234366312623024
54
train loss item: 2.7319583892822266
55
train loss item: 0.3082907497882843
56
train loss item: 0.35070547461509705
57
train loss item: 0.3520001769065857
58
train loss item: 0.2554933428764343
59
train loss item: 0.20562435686588287
60
train loss item: 1.4962228536605835
61
train loss item: 2.585383653640747
62
train loss item: 0.34352433681488037
63
train loss item: 0.7016330361366272
64
train loss item: 0.25515466928482056
65
train loss item: 1.0155506134033203
66
train loss item: 0.5526156425476074
67
train loss item: 0.3439730703830719
68
train loss item: 0.6679310202598572
69
train loss item: 0.5637957453727722
70
train loss item: 0.4863538444042206
71
train loss item: 0.19932766258716583
72
train loss item: 0.27003246545791626
73
train loss item: 0.45723822712898254
74
train loss item: 0.10960523784160614
75
train loss item: 0.15374159812927246
76
train loss item: 1.1738535165786743
77
train loss item: 1.948042631149292
78
train loss item: 0.11716045439243317
79
train loss item: 0.5077100396156311
80
train loss item: 0.2175857126712799
81
train loss item: 0.31501054763793945
82
train loss item: 0.3138841986656189
83
train loss item: 1.1815367937088013
84
train loss item: 0.6088192462921143
85
train loss item: 0.9161341786384583
86
train loss item: 4.904420852661133
87
train loss item: 0.24947614967823029
88
train loss item: 0.556178092956543
epoch train loss: 0.6896932495946295
testing phase
test loss item: 4.63518762588501
test loss item: 2.1027517318725586
test loss item: 0.7715105414390564
test loss item: 3.2854652404785156
test loss item: 0.871174156665802
test loss item: 1.1470516920089722
test loss item: 7.60451078414917
test loss item: 4.816933631896973
test loss item: 0.3729412853717804
test loss item: 0.581008791923523
test loss item: 1.8923897743225098
test loss item: 3.3355493545532227
test loss item: 0.33144113421440125
test loss item: 7.105724334716797
test loss item: 1.2771002054214478
test loss item: 3.533783197402954
test loss item: 0.5164166688919067
test loss item: 1.4024797677993774
test loss item: 12.181984901428223
test loss item: 1.2082899808883667
test loss item: 5.020742416381836
test loss item: 3.227065324783325
test loss item: 3.9059512615203857
test loss item: 0.35053542256355286
test loss item: 1.0909963846206665
test loss item: 6.682380199432373
test loss item: 0.9084561467170715
test loss item: 0.3776666522026062
test loss item: 2.3321919441223145
test loss item: 0.5854926109313965
test loss item: 3.3928000926971436
test loss item: 3.5741097927093506
test loss item: 0.2939557433128357
test loss item: 3.6733920574188232
test loss item: 2.0331075191497803
test loss item: 1.8788388967514038
test loss item: 3.895296096801758
test loss item: 2.3921728134155273
test loss item: 2.5861284732818604
test loss item: 0.5398607850074768
test loss item: 2.0434210300445557
test loss item: 11.679802894592285
test loss item: 0.5923910140991211
test loss item: 2.567781925201416
test loss item: 3.651742458343506
test loss item: 2.8042993545532227
test loss item: 3.9158105850219727
test loss item: 1.5276432037353516
test loss item: 0.6792353987693787
test loss item: 9.021409034729004
test loss item: 1.9367659091949463
test loss item: 1.0425670146942139
test loss item: 0.44172191619873047
test loss item: 4.61857271194458
test loss item: 1.959934949874878
test loss item: 1.6902002096176147
test loss item: 2.039147138595581
test loss item: 7.037417888641357
test loss item: 1.3253735303878784
test loss item: 0.3171890676021576
test loss item: 1.2351149320602417
test loss item: 2.0091359615325928
test loss item: 4.917812824249268
test loss item: 0.4455571472644806
test loss item: 4.4553632736206055
test loss item: 4.774406433105469
test loss item: 0.593117356300354
test loss item: 0.7088049650192261
test loss item: 2.0743777751922607
test loss item: 3.3786120414733887
test loss item: 2.3479678630828857
test loss item: 6.815426349639893
test loss item: 4.534915924072266
test loss item: 4.2713623046875
test loss item: 0.8313164114952087
test loss item: 1.850317358970642
test loss item: 1.119567632675171
test loss item: 3.253239631652832
test loss item: 7.22829532623291
test loss item: 4.937180042266846
test loss item: 1.4998416900634766
test loss item: 12.178506851196289
test loss item: 3.491798162460327
test loss item: 1.7110826969146729
test loss item: 2.3581387996673584
test loss item: 11.997305870056152
test loss item: 2.555058479309082
test loss item: 3.54068660736084
test loss item: 23.527124404907227
Epoch [8/50], Training Loss: 0.6897, Testing Loss: 3.2949
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5008963346481323
1
train loss item: 1.8419960737228394
2
train loss item: 0.3138033449649811
3
train loss item: 0.8873890042304993
4
train loss item: 0.48258864879608154
5
train loss item: 0.3933088183403015
6
train loss item: 0.34448128938674927
7
train loss item: 1.0430988073349
8
train loss item: 0.18540768325328827
9
train loss item: 0.39656123518943787
10
train loss item: 0.4756363034248352
11
train loss item: 0.3732050955295563
12
train loss item: 0.13575555384159088
13
train loss item: 0.6071041226387024
14
train loss item: 0.28867244720458984
15
train loss item: 1.1371397972106934
16
train loss item: 0.09883623570203781
17
train loss item: 0.41871851682662964
18
train loss item: 0.4848158657550812
19
train loss item: 0.46221861243247986
20
train loss item: 0.34901806712150574
21
train loss item: 0.1561325043439865
22
train loss item: 1.7367268800735474
23
train loss item: 1.1337069272994995
24
train loss item: 0.9032079577445984
25
train loss item: 0.21852272748947144
26
train loss item: 0.2605217397212982
27
train loss item: 0.3265835642814636
28
train loss item: 0.1122811883687973
29
train loss item: 1.3580979108810425
30
train loss item: 2.8994977474212646
31
train loss item: 0.7155803442001343
32
train loss item: 0.15995773673057556
33
train loss item: 0.5629039406776428
34
train loss item: 0.12080159038305283
35
train loss item: 2.821160078048706
36
train loss item: 0.6810175776481628
37
train loss item: 0.5172445178031921
38
train loss item: 0.739145815372467
39
train loss item: 0.30303478240966797
40
train loss item: 0.1969151496887207
41
train loss item: 0.34709519147872925
42
train loss item: 0.43765461444854736
43
train loss item: 0.2768155336380005
44
train loss item: 0.8001705408096313
45
train loss item: 0.21291320025920868
46
train loss item: 0.16017858684062958
47
train loss item: 0.6510107517242432
48
train loss item: 0.3269619643688202
49
train loss item: 0.2089914083480835
50
train loss item: 0.5107414126396179
51
train loss item: 1.442151427268982
52
train loss item: 0.12398794293403625
53
train loss item: 0.23294231295585632
54
train loss item: 2.6995949745178223
55
train loss item: 0.2830786406993866
56
train loss item: 0.32815852761268616
57
train loss item: 0.3377278447151184
58
train loss item: 0.24372504651546478
59
train loss item: 0.18293406069278717
60
train loss item: 1.4498142004013062
61
train loss item: 2.569556951522827
62
train loss item: 0.3226715624332428
63
train loss item: 0.6704931259155273
64
train loss item: 0.2584972083568573
65
train loss item: 0.963245153427124
66
train loss item: 0.5296632051467896
67
train loss item: 0.30656328797340393
68
train loss item: 0.6247704029083252
69
train loss item: 0.551176130771637
70
train loss item: 0.45001107454299927
71
train loss item: 0.16778093576431274
72
train loss item: 0.2517733573913574
73
train loss item: 0.44302549958229065
74
train loss item: 0.11352110654115677
75
train loss item: 0.16641172766685486
76
train loss item: 1.1519765853881836
77
train loss item: 1.913063883781433
78
train loss item: 0.09683462977409363
79
train loss item: 0.46963682770729065
80
train loss item: 0.21475310623645782
81
train loss item: 0.30135852098464966
82
train loss item: 0.2928648293018341
83
train loss item: 1.1569172143936157
84
train loss item: 0.5808102488517761
85
train loss item: 0.896532416343689
86
train loss item: 4.857174873352051
87
train loss item: 0.24816307425498962
88
train loss item: 0.5205845832824707
epoch train loss: 0.6684289016248135
testing phase
test loss item: 1.4153518676757812
test loss item: 0.44596067070961
test loss item: 0.7096584439277649
test loss item: 0.8713239431381226
test loss item: 0.4049721658229828
test loss item: 0.2884518802165985
test loss item: 4.305753231048584
test loss item: 2.0241801738739014
test loss item: 0.2922353148460388
test loss item: 0.5569289326667786
test loss item: 1.2614082098007202
test loss item: 0.9174288511276245
test loss item: 0.26209720969200134
test loss item: 2.5092172622680664
test loss item: 0.3736642003059387
test loss item: 0.7584423422813416
test loss item: 0.468794584274292
test loss item: 0.7025678753852844
test loss item: 4.19722318649292
test loss item: 0.5826073288917542
test loss item: 1.8096455335617065
test loss item: 0.9725279211997986
test loss item: 1.0761992931365967
test loss item: 0.2653380036354065
test loss item: 0.3908248245716095
test loss item: 1.7765145301818848
test loss item: 0.5413155555725098
test loss item: 0.25266095995903015
test loss item: 0.9483507871627808
test loss item: 0.541612446308136
test loss item: 1.738486647605896
test loss item: 0.7786040902137756
test loss item: 0.20718039572238922
test loss item: 1.270975947380066
test loss item: 0.6771445870399475
test loss item: 0.8130353093147278
test loss item: 1.9397577047348022
test loss item: 1.7553690671920776
test loss item: 1.015175700187683
test loss item: 0.44454675912857056
test loss item: 0.6423308253288269
test loss item: 3.7596938610076904
test loss item: 0.5170904397964478
test loss item: 0.8140709400177002
test loss item: 1.2103809118270874
test loss item: 0.992234468460083
test loss item: 1.166764259338379
test loss item: 0.5234195590019226
test loss item: 0.6148073673248291
test loss item: 2.6734230518341064
test loss item: 0.7506895661354065
test loss item: 0.31902915239334106
test loss item: 0.3587283790111542
test loss item: 1.164077639579773
test loss item: 0.7384427785873413
test loss item: 1.0962868928909302
test loss item: 1.1048141717910767
test loss item: 2.3757102489471436
test loss item: 0.4272812604904175
test loss item: 0.2812708914279938
test loss item: 0.6969679594039917
test loss item: 0.551501989364624
test loss item: 1.4734255075454712
test loss item: 0.3533891439437866
test loss item: 2.0861339569091797
test loss item: 1.2734113931655884
test loss item: 0.45461103320121765
test loss item: 0.3936781883239746
test loss item: 0.777823269367218
test loss item: 1.2484816312789917
test loss item: 0.5056605339050293
test loss item: 3.052482843399048
test loss item: 1.330296516418457
test loss item: 1.3492133617401123
test loss item: 0.25860998034477234
test loss item: 0.3479948043823242
test loss item: 0.3698863089084625
test loss item: 2.322598457336426
test loss item: 2.6085593700408936
test loss item: 1.5879076719284058
test loss item: 0.32893168926239014
test loss item: 4.282411575317383
test loss item: 1.838644027709961
test loss item: 1.1728688478469849
test loss item: 0.8391405344009399
test loss item: 3.8644988536834717
test loss item: 0.5252659320831299
test loss item: 0.7721226811408997
test loss item: 7.7544097900390625
Epoch [9/50], Training Loss: 0.6684, Testing Loss: 1.2193
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4861049950122833
1
train loss item: 1.8051923513412476
2
train loss item: 0.2861803472042084
3
train loss item: 0.8643131256103516
4
train loss item: 0.5868417024612427
5
train loss item: 0.3822873830795288
6
train loss item: 0.3291281759738922
7
train loss item: 1.028601884841919
8
train loss item: 0.1698111891746521
9
train loss item: 0.3847709000110626
10
train loss item: 0.46388959884643555
11
train loss item: 0.3588963747024536
12
train loss item: 0.13874585926532745
13
train loss item: 0.5792500972747803
14
train loss item: 0.2724764049053192
15
train loss item: 1.099242091178894
16
train loss item: 0.09844200313091278
17
train loss item: 0.4011560380458832
18
train loss item: 0.46965551376342773
19
train loss item: 0.4365765452384949
20
train loss item: 0.31845444440841675
21
train loss item: 0.15102438628673553
22
train loss item: 1.692840576171875
23
train loss item: 1.1167936325073242
24
train loss item: 0.8853734135627747
25
train loss item: 0.21264301240444183
26
train loss item: 0.25218862295150757
27
train loss item: 0.30269455909729004
28
train loss item: 0.11220008134841919
29
train loss item: 1.3295471668243408
30
train loss item: 2.863866090774536
31
train loss item: 0.7051288485527039
32
train loss item: 0.15445028245449066
33
train loss item: 0.5357793569564819
34
train loss item: 0.11926575005054474
35
train loss item: 2.7927937507629395
36
train loss item: 0.6644423604011536
37
train loss item: 0.4872170686721802
38
train loss item: 0.7159695029258728
39
train loss item: 0.2851826846599579
40
train loss item: 0.1877748817205429
41
train loss item: 0.33279281854629517
42
train loss item: 0.42753782868385315
43
train loss item: 0.26479968428611755
44
train loss item: 0.7764772772789001
45
train loss item: 0.20859244465827942
46
train loss item: 0.15129093825817108
47
train loss item: 0.6262611746788025
48
train loss item: 0.30695733428001404
49
train loss item: 0.20828574895858765
50
train loss item: 0.4846822917461395
51
train loss item: 1.4159177541732788
52
train loss item: 0.10128758102655411
53
train loss item: 0.21540242433547974
54
train loss item: 2.671515703201294
55
train loss item: 0.2612287104129791
56
train loss item: 0.31787508726119995
57
train loss item: 0.32589322328567505
58
train loss item: 0.23145456612110138
59
train loss item: 0.1629592329263687
60
train loss item: 1.4126642942428589
61
train loss item: 2.5493128299713135
62
train loss item: 0.3154025971889496
63
train loss item: 0.6442998051643372
64
train loss item: 0.2483440637588501
65
train loss item: 0.9285319447517395
66
train loss item: 0.5207637548446655
67
train loss item: 0.2803442180156708
68
train loss item: 0.583650529384613
69
train loss item: 0.5340844988822937
70
train loss item: 0.42642077803611755
71
train loss item: 0.15523545444011688
72
train loss item: 0.22986148297786713
73
train loss item: 0.42720916867256165
74
train loss item: 0.1061815470457077
75
train loss item: 0.16099706292152405
76
train loss item: 1.1286393404006958
77
train loss item: 1.8817641735076904
78
train loss item: 0.0764949843287468
79
train loss item: 0.44626671075820923
80
train loss item: 0.1987297534942627
81
train loss item: 0.29250290989875793
82
train loss item: 0.2622082531452179
83
train loss item: 1.1321706771850586
84
train loss item: 0.5733901858329773
85
train loss item: 0.8783671259880066
86
train loss item: 4.820127010345459
87
train loss item: 0.22807303071022034
88
train loss item: 0.5077831149101257
epoch train loss: 0.6513283840391073
testing phase
test loss item: 0.6465536952018738
test loss item: 0.15147216618061066
test loss item: 0.6569714546203613
test loss item: 0.4261235296726227
test loss item: 0.33469659090042114
test loss item: 0.17306481301784515
test loss item: 3.624080181121826
test loss item: 1.3876558542251587
test loss item: 0.27391454577445984
test loss item: 0.5130000114440918
test loss item: 1.0992029905319214
test loss item: 0.3982168138027191
test loss item: 0.22609767317771912
test loss item: 1.505800485610962
test loss item: 0.22916166484355927
test loss item: 0.17892315983772278
test loss item: 0.4298320412635803
test loss item: 0.5839790105819702
test loss item: 2.2093262672424316
test loss item: 0.49219775199890137
test loss item: 1.5037990808486938
test loss item: 0.6411082744598389
test loss item: 0.528318464756012
test loss item: 0.2596774399280548
test loss item: 0.29709339141845703
test loss item: 0.6996183395385742
test loss item: 0.4996281564235687
test loss item: 0.2432260662317276
test loss item: 0.6783341765403748
test loss item: 0.4740464389324188
test loss item: 1.442176103591919
test loss item: 0.186695396900177
test loss item: 0.20655272901058197
test loss item: 1.0002830028533936
test loss item: 0.5206847190856934
test loss item: 0.6467905044555664
test loss item: 1.528018832206726
test loss item: 1.6357954740524292
test loss item: 0.728415846824646
test loss item: 0.43624648451805115
test loss item: 0.4752655327320099
test loss item: 1.7267876863479614
test loss item: 0.44573211669921875
test loss item: 0.45294708013534546
test loss item: 0.916002631187439
test loss item: 0.7522977590560913
test loss item: 0.7022454142570496
test loss item: 0.4010801613330841
test loss item: 0.5803750157356262
test loss item: 1.4209924936294556
test loss item: 0.5600839853286743
test loss item: 0.1880124807357788
test loss item: 0.34564533829689026
test loss item: 0.4713963568210602
test loss item: 0.5622454881668091
test loss item: 1.03703773021698
test loss item: 0.8961556553840637
test loss item: 1.403232455253601
test loss item: 0.3310844600200653
test loss item: 0.26813390851020813
test loss item: 0.5823677182197571
test loss item: 0.3510696291923523
test loss item: 0.6955950856208801
test loss item: 0.34125328063964844
test loss item: 1.57272469997406
test loss item: 0.5974783897399902
test loss item: 0.4340667426586151
test loss item: 0.3796912133693695
test loss item: 0.6275675296783447
test loss item: 0.8200361132621765
test loss item: 0.133931502699852
test loss item: 2.2748100757598877
test loss item: 0.8419560194015503
test loss item: 0.78729248046875
test loss item: 0.22615092992782593
test loss item: 0.23503464460372925
test loss item: 0.27432429790496826
test loss item: 1.7714563608169556
test loss item: 1.597555160522461
test loss item: 0.781466543674469
test loss item: 0.1398228108882904
test loss item: 2.413733720779419
test loss item: 1.5491507053375244
test loss item: 1.1321934461593628
test loss item: 0.5704789161682129
test loss item: 1.7952923774719238
test loss item: 0.14093667268753052
test loss item: 0.18416984379291534
test loss item: 3.650686025619507
Epoch [10/50], Training Loss: 0.6513, Testing Loss: 0.7925
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 11/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47880256175994873
1
train loss item: 1.7698723077774048
2
train loss item: 0.2748635709285736
3
train loss item: 0.8396556973457336
4
train loss item: 0.8638654947280884
5
train loss item: 0.38379397988319397
6
train loss item: 0.3207000494003296
7
train loss item: 1.0131804943084717
8
train loss item: 0.15946650505065918
9
train loss item: 0.3763669729232788
10
train loss item: 0.4552488923072815
11
train loss item: 0.3571434020996094
12
train loss item: 0.13109199702739716
13
train loss item: 0.5618051886558533
14
train loss item: 0.27132245898246765
15
train loss item: 1.065374493598938
16
train loss item: 0.08973803371191025
17
train loss item: 0.38557854294776917
18
train loss item: 0.4622604548931122
19
train loss item: 0.4142487049102783
20
train loss item: 0.29838308691978455
21
train loss item: 0.16383737325668335
22
train loss item: 1.6406463384628296
23
train loss item: 1.1020007133483887
24
train loss item: 0.8733376264572144
25
train loss item: 0.21081377565860748
26
train loss item: 0.2648095488548279
27
train loss item: 0.28732118010520935
28
train loss item: 0.09622316062450409
29
train loss item: 1.2989521026611328
30
train loss item: 2.8345329761505127
31
train loss item: 0.695460319519043
32
train loss item: 0.15607501566410065
33
train loss item: 0.5120772123336792
34
train loss item: 0.12558221817016602
35
train loss item: 2.7670841217041016
36
train loss item: 0.6485993266105652
37
train loss item: 0.47543662786483765
38
train loss item: 0.692664384841919
39
train loss item: 0.2800928056240082
40
train loss item: 0.1881055384874344
41
train loss item: 0.3297402858734131
42
train loss item: 0.41965410113334656
43
train loss item: 0.26091262698173523
44
train loss item: 0.7567780017852783
45
train loss item: 0.19810399413108826
46
train loss item: 0.14541266858577728
47
train loss item: 0.6041041612625122
48
train loss item: 0.29756489396095276
49
train loss item: 0.20887179672718048
50
train loss item: 0.4607560932636261
51
train loss item: 1.3884148597717285
52
train loss item: 0.08343155682086945
53
train loss item: 0.1994096040725708
54
train loss item: 2.6443004608154297
55
train loss item: 0.2485935539007187
56
train loss item: 0.32177475094795227
57
train loss item: 0.32242146134376526
58
train loss item: 0.23139061033725739
59
train loss item: 0.1460118442773819
60
train loss item: 1.3835688829421997
61
train loss item: 2.528242826461792
62
train loss item: 0.31875312328338623
63
train loss item: 0.6244175434112549
64
train loss item: 0.2413223385810852
65
train loss item: 0.8971490859985352
66
train loss item: 0.513041615486145
67
train loss item: 0.27983558177948
68
train loss item: 0.5457920432090759
69
train loss item: 0.5197794437408447
70
train loss item: 0.41119346022605896
71
train loss item: 0.15316027402877808
72
train loss item: 0.22377552092075348
73
train loss item: 0.416474848985672
74
train loss item: 0.09228436648845673
75
train loss item: 0.13887563347816467
76
train loss item: 1.1096526384353638
77
train loss item: 1.8529149293899536
78
train loss item: 0.07270421087741852
79
train loss item: 0.43265974521636963
80
train loss item: 0.17963330447673798
81
train loss item: 0.29014694690704346
82
train loss item: 0.24315577745437622
83
train loss item: 1.104414701461792
84
train loss item: 0.5705301761627197
85
train loss item: 0.8594452142715454
86
train loss item: 4.789554119110107
87
train loss item: 0.21253737807273865
88
train loss item: 0.5167037844657898
epoch train loss: 0.6413009224480457
testing phase
test loss item: 0.4205678701400757
test loss item: 0.11946181952953339
test loss item: 0.645322859287262
test loss item: 0.3283005654811859
test loss item: 0.2967665493488312
test loss item: 0.15626901388168335
test loss item: 3.301083564758301
test loss item: 1.1462585926055908
test loss item: 0.2621173858642578
test loss item: 0.49216851592063904
test loss item: 1.0321385860443115
test loss item: 0.2805926501750946
test loss item: 0.2129136323928833
test loss item: 1.2618756294250488
test loss item: 0.20633843541145325
test loss item: 0.07536020129919052
test loss item: 0.42091062664985657
test loss item: 0.5635349154472351
test loss item: 1.6612327098846436
test loss item: 0.44647926092147827
test loss item: 1.618263602256775
test loss item: 0.5793203711509705
test loss item: 0.41905856132507324
test loss item: 0.2538583278656006
test loss item: 0.28772255778312683
test loss item: 0.442613422870636
test loss item: 0.48352107405662537
test loss item: 0.23409892618656158
test loss item: 0.599484920501709
test loss item: 0.4502743184566498
test loss item: 1.3300952911376953
test loss item: 0.07584112137556076
test loss item: 0.2041272073984146
test loss item: 1.0012903213500977
test loss item: 0.5038327574729919
test loss item: 0.6063831448554993
test loss item: 1.3806700706481934
test loss item: 1.6196837425231934
test loss item: 0.6600843071937561
test loss item: 0.422985315322876
test loss item: 0.4572887122631073
test loss item: 1.1270439624786377
test loss item: 0.4234200716018677
test loss item: 0.36552566289901733
test loss item: 0.9149624109268188
test loss item: 0.6810210943222046
test loss item: 0.599886953830719
test loss item: 0.3576340973377228
test loss item: 0.565489649772644
test loss item: 1.1572086811065674
test loss item: 0.5739619731903076
test loss item: 0.16299821436405182
test loss item: 0.33877432346343994
test loss item: 0.2998683452606201
test loss item: 0.5938148498535156
test loss item: 1.0214797258377075
test loss item: 0.8099382519721985
test loss item: 1.2968326807022095
test loss item: 0.3142494857311249
test loss item: 0.25952523946762085
test loss item: 0.5487867593765259
test loss item: 0.325582355260849
test loss item: 0.47073042392730713
test loss item: 0.33265846967697144
test loss item: 1.3787603378295898
test loss item: 0.4439701735973358
test loss item: 0.41791799664497375
test loss item: 0.3693528175354004
test loss item: 0.6055952310562134
test loss item: 0.7163074612617493
test loss item: 0.07108129560947418
test loss item: 1.9711494445800781
test loss item: 0.8450144529342651
test loss item: 0.6541281342506409
test loss item: 0.2204584926366806
test loss item: 0.23115818202495575
test loss item: 0.25846216082572937
test loss item: 1.5975009202957153
test loss item: 1.3226642608642578
test loss item: 0.5440574884414673
test loss item: 0.11123376339673996
test loss item: 1.8780162334442139
test loss item: 1.4417592287063599
test loss item: 1.1113187074661255
test loss item: 0.4669135808944702
test loss item: 1.2693816423416138
test loss item: 0.09006297588348389
test loss item: 0.07715752720832825
test loss item: 2.450878143310547
Epoch [11/50], Training Loss: 0.6413, Testing Loss: 0.6859
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 12/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47094079852104187
1
train loss item: 1.7383192777633667
2
train loss item: 0.27455633878707886
3
train loss item: 0.8162466287612915
4
train loss item: 0.7688180804252625
5
train loss item: 0.3888839781284332
6
train loss item: 0.31486067175865173
7
train loss item: 0.9978872537612915
8
train loss item: 0.15468265116214752
9
train loss item: 0.36157578229904175
10
train loss item: 0.4486105144023895
11
train loss item: 0.3611766993999481
12
train loss item: 0.12029904872179031
13
train loss item: 0.5566061735153198
14
train loss item: 0.27717235684394836
15
train loss item: 1.0248780250549316
16
train loss item: 0.0869559496641159
17
train loss item: 0.37068355083465576
18
train loss item: 0.4494868814945221
19
train loss item: 0.3924252688884735
20
train loss item: 0.28655582666397095
21
train loss item: 0.16706091165542603
22
train loss item: 1.6123361587524414
23
train loss item: 1.096030831336975
24
train loss item: 0.8407382965087891
25
train loss item: 0.2084980607032776
26
train loss item: 0.25063854455947876
27
train loss item: 0.28336092829704285
28
train loss item: 0.08616667985916138
29
train loss item: 1.2593430280685425
30
train loss item: 2.801752805709839
31
train loss item: 0.6885546445846558
32
train loss item: 0.1504344791173935
33
train loss item: 0.5065780878067017
34
train loss item: 0.12792833149433136
35
train loss item: 2.7497451305389404
36
train loss item: 0.6291542649269104
37
train loss item: 0.4788488447666168
38
train loss item: 0.6655318737030029
39
train loss item: 0.2774782180786133
40
train loss item: 0.18409600853919983
41
train loss item: 0.3304053843021393
42
train loss item: 0.4141924977302551
43
train loss item: 0.25594362616539
44
train loss item: 0.7456105947494507
45
train loss item: 0.19578750431537628
46
train loss item: 0.14800381660461426
47
train loss item: 0.5810253620147705
48
train loss item: 0.2907106876373291
49
train loss item: 0.2088581770658493
50
train loss item: 0.4380030333995819
51
train loss item: 1.3579853773117065
52
train loss item: 0.085069939494133
53
train loss item: 0.1875554323196411
54
train loss item: 2.6246144771575928
55
train loss item: 0.2440977245569229
56
train loss item: 0.32630813121795654
57
train loss item: 0.3248763680458069
58
train loss item: 0.2290232926607132
59
train loss item: 0.13516949117183685
60
train loss item: 1.3611289262771606
61
train loss item: 2.51208758354187
62
train loss item: 0.3195035457611084
63
train loss item: 0.6054546236991882
64
train loss item: 0.2324831783771515
65
train loss item: 0.853663980960846
66
train loss item: 0.5016343593597412
67
train loss item: 0.272278755903244
68
train loss item: 0.5110476613044739
69
train loss item: 0.49989181756973267
70
train loss item: 0.3948966860771179
71
train loss item: 0.1501179039478302
72
train loss item: 0.21799947321414948
73
train loss item: 0.40251171588897705
74
train loss item: 0.08062136173248291
75
train loss item: 0.11757057160139084
76
train loss item: 1.099491000175476
77
train loss item: 1.8209456205368042
78
train loss item: 0.08480589836835861
79
train loss item: 0.41757574677467346
80
train loss item: 0.16966544091701508
81
train loss item: 0.28263506293296814
82
train loss item: 0.23931613564491272
83
train loss item: 1.0710368156433105
84
train loss item: 0.5601944923400879
85
train loss item: 0.8385640382766724
86
train loss item: 4.77608585357666
87
train loss item: 0.19847732782363892
88
train loss item: 0.5090752840042114
epoch train loss: 0.6286505580450712
testing phase
test loss item: 0.39493870735168457
test loss item: 0.10988331586122513
test loss item: 0.6487072706222534
test loss item: 0.3210059404373169
test loss item: 0.2879922091960907
test loss item: 0.1510932892560959
test loss item: 3.051313638687134
test loss item: 0.9560933709144592
test loss item: 0.2612771689891815
test loss item: 0.4925437271595001
test loss item: 1.0210219621658325
test loss item: 0.2738308012485504
test loss item: 0.21126769483089447
test loss item: 1.507859468460083
test loss item: 0.2019781917333603
test loss item: 0.07592138648033142
test loss item: 0.41293463110923767
test loss item: 0.5651660561561584
test loss item: 1.5734111070632935
test loss item: 0.3869779407978058
test loss item: 1.6983110904693604
test loss item: 0.5571568012237549
test loss item: 0.38428640365600586
test loss item: 0.24570995569229126
test loss item: 0.28909561038017273
test loss item: 0.3845244348049164
test loss item: 0.44637563824653625
test loss item: 0.23049476742744446
test loss item: 0.6361116766929626
test loss item: 0.44838544726371765
test loss item: 1.1484291553497314
test loss item: 0.08254929631948471
test loss item: 0.1978992521762848
test loss item: 0.9313223361968994
test loss item: 0.5087602138519287
test loss item: 0.5567909479141235
test loss item: 1.236987829208374
test loss item: 1.621719479560852
test loss item: 0.6536835432052612
test loss item: 0.40604642033576965
test loss item: 0.44780775904655457
test loss item: 1.080437421798706
test loss item: 0.4253149926662445
test loss item: 0.35490214824676514
test loss item: 0.9640694260597229
test loss item: 0.6081406474113464
test loss item: 0.6286302208900452
test loss item: 0.3159903883934021
test loss item: 0.5668401718139648
test loss item: 0.9701012372970581
test loss item: 0.6518033742904663
test loss item: 0.15931442379951477
test loss item: 0.3352523148059845
test loss item: 0.29218077659606934
test loss item: 0.6713932156562805
test loss item: 1.0027741193771362
test loss item: 0.7147861123085022
test loss item: 1.6098246574401855
test loss item: 0.31086117029190063
test loss item: 0.2543102204799652
test loss item: 0.5466068983078003
test loss item: 0.31437355279922485
test loss item: 0.43698254227638245
test loss item: 0.3228181004524231
test loss item: 1.182982325553894
test loss item: 0.42984476685523987
test loss item: 0.4042126536369324
test loss item: 0.35886624455451965
test loss item: 0.6058881878852844
test loss item: 0.5833759307861328
test loss item: 0.06761837750673294
test loss item: 1.7766047716140747
test loss item: 0.9698097109794617
test loss item: 0.607168972492218
test loss item: 0.2180759459733963
test loss item: 0.22456541657447815
test loss item: 0.24822691082954407
test loss item: 1.5965267419815063
test loss item: 1.5427311658859253
test loss item: 0.5423285961151123
test loss item: 0.11202066391706467
test loss item: 1.7499266862869263
test loss item: 1.2886139154434204
test loss item: 1.1073274612426758
test loss item: 0.4865458309650421
test loss item: 1.288103461265564
test loss item: 0.09813551604747772
test loss item: 0.08666641265153885
test loss item: 2.496262788772583
Epoch [12/50], Training Loss: 0.6287, Testing Loss: 0.6700
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 13/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4653775691986084
1
train loss item: 1.6991956233978271
2
train loss item: 0.2767004072666168
3
train loss item: 0.7929020524024963
4
train loss item: 0.5450616478919983
5
train loss item: 0.3920633792877197
6
train loss item: 0.3103664219379425
7
train loss item: 0.9840892553329468
8
train loss item: 0.15234021842479706
9
train loss item: 0.34072259068489075
10
train loss item: 0.44235965609550476
11
train loss item: 0.36258554458618164
12
train loss item: 0.11888422071933746
13
train loss item: 0.5560132265090942
14
train loss item: 0.2833858132362366
15
train loss item: 0.9744027256965637
16
train loss item: 0.09058521687984467
17
train loss item: 0.35889166593551636
18
train loss item: 0.4318784773349762
19
train loss item: 0.3708280920982361
20
train loss item: 0.2777349352836609
21
train loss item: 0.1592184603214264
22
train loss item: 1.5531402826309204
23
train loss item: 1.0954101085662842
24
train loss item: 0.7937746047973633
25
train loss item: 0.20087680220603943
26
train loss item: 0.22710704803466797
27
train loss item: 0.28428560495376587
28
train loss item: 0.08641105890274048
29
train loss item: 1.2100507020950317
30
train loss item: 2.766017436981201
31
train loss item: 0.6840894222259521
32
train loss item: 0.12384791672229767
33
train loss item: 0.5119659900665283
34
train loss item: 0.12131699174642563
35
train loss item: 2.7302470207214355
36
train loss item: 0.6089964509010315
37
train loss item: 0.4863284230232239
38
train loss item: 0.6293615698814392
39
train loss item: 0.2738727927207947
40
train loss item: 0.17653533816337585
41
train loss item: 0.3265036940574646
42
train loss item: 0.40686100721359253
43
train loss item: 0.24198272824287415
44
train loss item: 0.7395463585853577
45
train loss item: 0.1940280795097351
46
train loss item: 0.14757734537124634
47
train loss item: 0.5566232204437256
48
train loss item: 0.2825188636779785
49
train loss item: 0.20574912428855896
50
train loss item: 0.41665124893188477
51
train loss item: 1.325804352760315
52
train loss item: 0.09274286776781082
53
train loss item: 0.18124885857105255
54
train loss item: 2.6035258769989014
55
train loss item: 0.23937535285949707
56
train loss item: 0.3260173797607422
57
train loss item: 0.3194534480571747
58
train loss item: 0.2169296145439148
59
train loss item: 0.12709835171699524
60
train loss item: 1.3397070169448853
61
train loss item: 2.501042604446411
62
train loss item: 0.3141319453716278
63
train loss item: 0.5846328735351562
64
train loss item: 0.2153371125459671
65
train loss item: 0.8064279556274414
66
train loss item: 0.486355721950531
67
train loss item: 0.2560179531574249
68
train loss item: 0.4770757555961609
69
train loss item: 0.4730130434036255
70
train loss item: 0.3739515542984009
71
train loss item: 0.1427018791437149
72
train loss item: 0.2123609185218811
73
train loss item: 0.3856925666332245
74
train loss item: 0.07215413451194763
75
train loss item: 0.10460011661052704
76
train loss item: 1.0960248708724976
77
train loss item: 1.785562515258789
78
train loss item: 0.09736332297325134
79
train loss item: 0.39815428853034973
80
train loss item: 0.15826988220214844
81
train loss item: 0.26758894324302673
82
train loss item: 0.24032984673976898
83
train loss item: 1.0311726331710815
84
train loss item: 0.5445387363433838
85
train loss item: 0.8135591745376587
86
train loss item: 4.74826717376709
87
train loss item: 0.1845472902059555
88
train loss item: 0.48056960105895996
epoch train loss: 0.612254067083423
testing phase
test loss item: 0.34739235043525696
test loss item: 0.10503038018941879
test loss item: 0.659711480140686
test loss item: 0.32348430156707764
test loss item: 0.28747785091400146
test loss item: 0.1478041708469391
test loss item: 2.7548272609710693
test loss item: 0.8150598406791687
test loss item: 0.26224491000175476
test loss item: 0.49989888072013855
test loss item: 1.0485020875930786
test loss item: 0.27238503098487854
test loss item: 0.21597601473331451
test loss item: 1.4922653436660767
test loss item: 0.20025621354579926
test loss item: 0.08027024567127228
test loss item: 0.4011165499687195
test loss item: 0.5756645202636719
test loss item: 1.4206962585449219
test loss item: 0.3674444854259491
test loss item: 1.5634958744049072
test loss item: 0.5391802191734314
test loss item: 0.35582733154296875
test loss item: 0.2327078878879547
test loss item: 0.28859013319015503
test loss item: 0.32584547996520996
test loss item: 0.43588149547576904
test loss item: 0.23016852140426636
test loss item: 0.6281235814094543
test loss item: 0.4530644118785858
test loss item: 1.1092860698699951
test loss item: 0.08586975187063217
test loss item: 0.19049324095249176
test loss item: 0.8084245324134827
test loss item: 0.5213995575904846
test loss item: 0.550311803817749
test loss item: 1.1551424264907837
test loss item: 1.632997751235962
test loss item: 0.6603198051452637
test loss item: 0.38478317856788635
test loss item: 0.4330407679080963
test loss item: 0.8676664233207703
test loss item: 0.4263591170310974
test loss item: 0.34835273027420044
test loss item: 0.953911304473877
test loss item: 0.5678756833076477
test loss item: 0.5815979838371277
test loss item: 0.3010970950126648
test loss item: 0.5773335695266724
test loss item: 0.9009358882904053
test loss item: 0.6465846300125122
test loss item: 0.16251297295093536
test loss item: 0.33046960830688477
test loss item: 0.30951982736587524
test loss item: 0.6540035009384155
test loss item: 1.006831407546997
test loss item: 0.7074677348136902
test loss item: 1.590842366218567
test loss item: 0.30888083577156067
test loss item: 0.25447967648506165
test loss item: 0.5481722950935364
test loss item: 0.30690598487854004
test loss item: 0.3754459023475647
test loss item: 0.3147597908973694
test loss item: 1.0137717723846436
test loss item: 0.4394529461860657
test loss item: 0.3968612253665924
test loss item: 0.34783172607421875
test loss item: 0.6136714816093445
test loss item: 0.6024249792098999
test loss item: 0.06967026740312576
test loss item: 1.5387619733810425
test loss item: 0.9329805374145508
test loss item: 0.5579429268836975
test loss item: 0.21612338721752167
test loss item: 0.21379461884498596
test loss item: 0.23382259905338287
test loss item: 1.6137551069259644
test loss item: 1.5280348062515259
test loss item: 0.4812176525592804
test loss item: 0.11387604475021362
test loss item: 1.600174069404602
test loss item: 1.261572003364563
test loss item: 1.1166815757751465
test loss item: 0.477364718914032
test loss item: 1.1158367395401
test loss item: 0.10663972795009613
test loss item: 0.0947813168168068
test loss item: 2.179331064224243
Epoch [13/50], Training Loss: 0.6123, Testing Loss: 0.6379
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 14/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46337440609931946
1
train loss item: 1.6636788845062256
2
train loss item: 0.2877391576766968
3
train loss item: 0.7679114937782288
4
train loss item: 0.5641341805458069
5
train loss item: 0.39510685205459595
6
train loss item: 0.31181299686431885
7
train loss item: 0.9736213684082031
8
train loss item: 0.1554025113582611
9
train loss item: 0.3269082307815552
10
train loss item: 0.434547483921051
11
train loss item: 0.36677226424217224
12
train loss item: 0.12498635798692703
13
train loss item: 0.5578727722167969
14
train loss item: 0.286415159702301
15
train loss item: 0.9311413764953613
16
train loss item: 0.09579605609178543
17
train loss item: 0.3563084900379181
18
train loss item: 0.4185711741447449
19
train loss item: 0.35659119486808777
20
train loss item: 0.2766818106174469
21
train loss item: 0.1606214940547943
22
train loss item: 1.4884966611862183
23
train loss item: 1.0927784442901611
24
train loss item: 0.7567883729934692
25
train loss item: 0.19348573684692383
26
train loss item: 0.2271917313337326
27
train loss item: 0.28654909133911133
28
train loss item: 0.0897597074508667
29
train loss item: 1.1620821952819824
30
train loss item: 2.731220006942749
31
train loss item: 0.6781851649284363
32
train loss item: 0.10251927375793457
33
train loss item: 0.516555905342102
34
train loss item: 0.12370705604553223
35
train loss item: 2.7098450660705566
36
train loss item: 0.5973879098892212
37
train loss item: 0.4899696707725525
38
train loss item: 0.6019194722175598
39
train loss item: 0.2719094455242157
40
train loss item: 0.17602872848510742
41
train loss item: 0.3224095404148102
42
train loss item: 0.4027976989746094
43
train loss item: 0.2307867407798767
44
train loss item: 0.7342685461044312
45
train loss item: 0.1866464465856552
46
train loss item: 0.1464252769947052
47
train loss item: 0.5351840853691101
48
train loss item: 0.27964895963668823
49
train loss item: 0.20507504045963287
50
train loss item: 0.405370831489563
51
train loss item: 1.2941930294036865
52
train loss item: 0.10186681896448135
53
train loss item: 0.1820446401834488
54
train loss item: 2.5812389850616455
55
train loss item: 0.23812727630138397
56
train loss item: 0.324186235666275
57
train loss item: 0.318546324968338
58
train loss item: 0.20790624618530273
59
train loss item: 0.12204328924417496
60
train loss item: 1.307517170906067
61
train loss item: 2.488013505935669
62
train loss item: 0.3088012933731079
63
train loss item: 0.5665850043296814
64
train loss item: 0.20002378523349762
65
train loss item: 0.7741435766220093
66
train loss item: 0.4865225553512573
67
train loss item: 0.24952363967895508
68
train loss item: 0.44797348976135254
69
train loss item: 0.4531756341457367
70
train loss item: 0.35888078808784485
71
train loss item: 0.13696204125881195
72
train loss item: 0.2177838534116745
73
train loss item: 0.37534019351005554
74
train loss item: 0.06578528136014938
75
train loss item: 0.10253192484378815
76
train loss item: 1.0947905778884888
77
train loss item: 1.7496130466461182
78
train loss item: 0.10474231094121933
79
train loss item: 0.38540270924568176
80
train loss item: 0.14152365922927856
81
train loss item: 0.25205495953559875
82
train loss item: 0.24322381615638733
83
train loss item: 0.9939858913421631
84
train loss item: 0.5350879430770874
85
train loss item: 0.7914992570877075
86
train loss item: 4.715451717376709
87
train loss item: 0.18286778032779694
88
train loss item: 0.45632854104042053
epoch train loss: 0.6019918799735187
testing phase
test loss item: 0.27382349967956543
test loss item: 0.10970687121152878
test loss item: 0.673638105392456
test loss item: 0.30280300974845886
test loss item: 0.2947285771369934
test loss item: 0.1426885724067688
test loss item: 2.628673791885376
test loss item: 0.7862502336502075
test loss item: 0.26435744762420654
test loss item: 0.5062341690063477
test loss item: 1.0482728481292725
test loss item: 0.22335121035575867
test loss item: 0.22012142837047577
test loss item: 1.198886513710022
test loss item: 0.2022228240966797
test loss item: 0.08383843302726746
test loss item: 0.38613155484199524
test loss item: 0.5869778394699097
test loss item: 1.157399296760559
test loss item: 0.35017940402030945
test loss item: 1.2315505743026733
test loss item: 0.5054593682289124
test loss item: 0.33329737186431885
test loss item: 0.22322827577590942
test loss item: 0.285268098115921
test loss item: 0.28050610423088074
test loss item: 0.4245698153972626
test loss item: 0.2323366105556488
test loss item: 0.5733597874641418
test loss item: 0.4539468288421631
test loss item: 1.0738685131072998
test loss item: 0.08888615667819977
test loss item: 0.18731580674648285
test loss item: 0.6952001452445984
test loss item: 0.5338625907897949
test loss item: 0.5536512136459351
test loss item: 1.1283351182937622
test loss item: 1.6550347805023193
test loss item: 0.6612187623977661
test loss item: 0.3634587228298187
test loss item: 0.4151546359062195
test loss item: 0.5455780625343323
test loss item: 0.43067386746406555
test loss item: 0.32048577070236206
test loss item: 0.8530557751655579
test loss item: 0.5516111254692078
test loss item: 0.46718987822532654
test loss item: 0.29102054238319397
test loss item: 0.5841556191444397
test loss item: 0.862114429473877
test loss item: 0.5540733337402344
test loss item: 0.16483794152736664
test loss item: 0.32294225692749023
test loss item: 0.2643316388130188
test loss item: 0.5397099256515503
test loss item: 1.0200539827346802
test loss item: 0.701271116733551
test loss item: 1.2200310230255127
test loss item: 0.3043910562992096
test loss item: 0.25528913736343384
test loss item: 0.5560805797576904
test loss item: 0.29558777809143066
test loss item: 0.293182909488678
test loss item: 0.30781471729278564
test loss item: 1.0135616064071655
test loss item: 0.4115482568740845
test loss item: 0.3875446021556854
test loss item: 0.336248517036438
test loss item: 0.6254360675811768
test loss item: 0.6478581428527832
test loss item: 0.07187813520431519
test loss item: 1.4726136922836304
test loss item: 0.7101463079452515
test loss item: 0.5039674639701843
test loss item: 0.21139110624790192
test loss item: 0.19685088098049164
test loss item: 0.22327405214309692
test loss item: 1.640952706336975
test loss item: 1.266340970993042
test loss item: 0.35719063878059387
test loss item: 0.112299345433712
test loss item: 1.3725968599319458
test loss item: 1.2355495691299438
test loss item: 1.1322309970855713
test loss item: 0.4334522485733032
test loss item: 0.7615363001823425
test loss item: 0.10964728891849518
test loss item: 0.10046902298927307
test loss item: 1.452043890953064
Epoch [14/50], Training Loss: 0.6020, Testing Loss: 0.5824
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 15/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4671632647514343
1
train loss item: 1.6363542079925537
2
train loss item: 0.294514924287796
3
train loss item: 0.7445893883705139
4
train loss item: 0.6161081790924072
5
train loss item: 0.39956575632095337
6
train loss item: 0.3231945037841797
7
train loss item: 0.965021550655365
8
train loss item: 0.16085736453533173
9
train loss item: 0.32382696866989136
10
train loss item: 0.4299605190753937
11
train loss item: 0.3760101795196533
12
train loss item: 0.12984272837638855
13
train loss item: 0.5603998899459839
14
train loss item: 0.28711453080177307
15
train loss item: 0.9007739424705505
16
train loss item: 0.09588437527418137
17
train loss item: 0.3671416938304901
18
train loss item: 0.41169360280036926
19
train loss item: 0.353965699672699
20
train loss item: 0.2886165380477905
21
train loss item: 0.18350285291671753
22
train loss item: 1.4397776126861572
23
train loss item: 1.0860620737075806
24
train loss item: 0.7380911111831665
25
train loss item: 0.1909811943769455
26
train loss item: 0.24864600598812103
27
train loss item: 0.2861214876174927
28
train loss item: 0.08995570242404938
29
train loss item: 1.1189498901367188
30
train loss item: 2.699876308441162
31
train loss item: 0.6723579168319702
32
train loss item: 0.10043226182460785
33
train loss item: 0.515288233757019
34
train loss item: 0.13910908997058868
35
train loss item: 2.6931495666503906
36
train loss item: 0.5833277702331543
37
train loss item: 0.5047433376312256
38
train loss item: 0.5811029672622681
39
train loss item: 0.26984548568725586
40
train loss item: 0.17939510941505432
41
train loss item: 0.32017990946769714
42
train loss item: 0.4064119756221771
43
train loss item: 0.22461596131324768
44
train loss item: 0.7289320826530457
45
train loss item: 0.17203806340694427
46
train loss item: 0.141169011592865
47
train loss item: 0.5156086087226868
48
train loss item: 0.2802336513996124
49
train loss item: 0.2058941125869751
50
train loss item: 0.40659669041633606
51
train loss item: 1.2635612487792969
52
train loss item: 0.10468022525310516
53
train loss item: 0.18026794493198395
54
train loss item: 2.563450336456299
55
train loss item: 0.24000194668769836
56
train loss item: 0.3248046934604645
57
train loss item: 0.323066383600235
58
train loss item: 0.20487678050994873
59
train loss item: 0.11820376664400101
60
train loss item: 1.2744256258010864
61
train loss item: 2.4724087715148926
62
train loss item: 0.3051838278770447
63
train loss item: 0.5543348789215088
64
train loss item: 0.1902787685394287
65
train loss item: 0.7699298858642578
66
train loss item: 0.4863245189189911
67
train loss item: 0.2595745623111725
68
train loss item: 0.4281807839870453
69
train loss item: 0.4448907971382141
70
train loss item: 0.3552982807159424
71
train loss item: 0.13765911757946014
72
train loss item: 0.2214297652244568
73
train loss item: 0.37323781847953796
74
train loss item: 0.06210971623659134
75
train loss item: 0.10431613773107529
76
train loss item: 1.0915470123291016
77
train loss item: 1.7168787717819214
78
train loss item: 0.10588204860687256
79
train loss item: 0.3818494975566864
80
train loss item: 0.1245567798614502
81
train loss item: 0.24525146186351776
82
train loss item: 0.24159380793571472
83
train loss item: 0.9596534967422485
84
train loss item: 0.5202537775039673
85
train loss item: 0.7717361450195312
86
train loss item: 4.693483352661133
87
train loss item: 0.1844433844089508
88
train loss item: 0.45420071482658386
epoch train loss: 0.5967283448141613
testing phase
test loss item: 0.2937057316303253
test loss item: 0.2050788253545761
test loss item: 0.685018002986908
test loss item: 0.3928086757659912
test loss item: 0.3155716359615326
test loss item: 0.13687077164649963
test loss item: 2.507080554962158
test loss item: 0.738501787185669
test loss item: 0.29370635747909546
test loss item: 0.5078092813491821
test loss item: 1.0533883571624756
test loss item: 0.2517540752887726
test loss item: 0.21918271481990814
test loss item: 1.5527437925338745
test loss item: 0.20426127314567566
test loss item: 0.08379261195659637
test loss item: 0.37122687697410583
test loss item: 0.5958406925201416
test loss item: 1.1863040924072266
test loss item: 0.34012290835380554
test loss item: 1.0726346969604492
test loss item: 0.5076042413711548
test loss item: 0.3292783200740814
test loss item: 0.34421828389167786
test loss item: 0.28283631801605225
test loss item: 0.2683730125427246
test loss item: 0.41785988211631775
test loss item: 0.23286794126033783
test loss item: 0.6640123724937439
test loss item: 0.4486837685108185
test loss item: 1.0433646440505981
test loss item: 0.08869513124227524
test loss item: 0.32391512393951416
test loss item: 0.718652069568634
test loss item: 0.5422134399414062
test loss item: 0.5569838285446167
test loss item: 1.0932296514511108
test loss item: 1.6826751232147217
test loss item: 0.6833974123001099
test loss item: 0.34694594144821167
test loss item: 0.3997476398944855
test loss item: 0.5091981887817383
test loss item: 0.434465229511261
test loss item: 0.3482458293437958
test loss item: 0.8334608674049377
test loss item: 0.5360052585601807
test loss item: 0.46824780106544495
test loss item: 0.28632837533950806
test loss item: 0.5869936943054199
test loss item: 0.852077305316925
test loss item: 0.5746470093727112
test loss item: 0.16402553021907806
test loss item: 0.3149334490299225
test loss item: 0.3605082631111145
test loss item: 0.5547536611557007
test loss item: 1.0367257595062256
test loss item: 0.7036380171775818
test loss item: 1.5047889947891235
test loss item: 0.29673290252685547
test loss item: 0.25394558906555176
test loss item: 0.5610641241073608
test loss item: 0.2779533863067627
test loss item: 0.2980986535549164
test loss item: 0.3036331236362457
test loss item: 1.013183355331421
test loss item: 0.4851837456226349
test loss item: 0.3775193989276886
test loss item: 0.3275214731693268
test loss item: 0.6345304250717163
test loss item: 0.7025851607322693
test loss item: 0.0717175230383873
test loss item: 1.4025776386260986
test loss item: 0.7158656120300293
test loss item: 0.47913873195648193
test loss item: 0.20340465009212494
test loss item: 0.1828548014163971
test loss item: 0.32862553000450134
test loss item: 1.6755143404006958
test loss item: 1.6407166719436646
test loss item: 0.39458009600639343
test loss item: 0.10870867967605591
test loss item: 1.35980224609375
test loss item: 1.2113233804702759
test loss item: 1.1497231721878052
test loss item: 0.543754518032074
test loss item: 0.7322296500205994
test loss item: 0.10573327541351318
test loss item: 0.10061360895633698
test loss item: 1.5927914381027222
Epoch [15/50], Training Loss: 0.5967, Testing Loss: 0.6021
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 16/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47178319096565247
1
train loss item: 1.6106553077697754
2
train loss item: 0.2905922830104828
3
train loss item: 0.7255096435546875
4
train loss item: 0.6254229545593262
5
train loss item: 0.40398213267326355
6
train loss item: 0.3342418372631073
7
train loss item: 0.9593371748924255
8
train loss item: 0.1638084352016449
9
train loss item: 0.32680365443229675
10
train loss item: 0.4297567903995514
11
train loss item: 0.3839309513568878
12
train loss item: 0.12910236418247223
13
train loss item: 0.5610338449478149
14
train loss item: 0.281326562166214
15
train loss item: 0.8745598793029785
16
train loss item: 0.08972012251615524
17
train loss item: 0.3785754144191742
18
train loss item: 0.40734976530075073
19
train loss item: 0.3562255799770355
20
train loss item: 0.2987995743751526
21
train loss item: 0.21018843352794647
22
train loss item: 1.3919627666473389
23
train loss item: 1.0779942274093628
24
train loss item: 0.7292196154594421
25
train loss item: 0.1908639669418335
26
train loss item: 0.2722064256668091
27
train loss item: 0.28335312008857727
28
train loss item: 0.08379834145307541
29
train loss item: 1.0776660442352295
30
train loss item: 2.676081895828247
31
train loss item: 0.6687386631965637
32
train loss item: 0.10419218242168427
33
train loss item: 0.5105835199356079
34
train loss item: 0.15415824949741364
35
train loss item: 2.6781365871429443
36
train loss item: 0.5637863874435425
37
train loss item: 0.5200514793395996
38
train loss item: 0.5621607899665833
39
train loss item: 0.2670113146305084
40
train loss item: 0.18295301496982574
41
train loss item: 0.31820085644721985
42
train loss item: 0.41251692175865173
43
train loss item: 0.22080929577350616
44
train loss item: 0.7256225943565369
45
train loss item: 0.15349480509757996
46
train loss item: 0.13965286314487457
47
train loss item: 0.49897271394729614
48
train loss item: 0.2791667580604553
49
train loss item: 0.2009335160255432
50
train loss item: 0.4117847979068756
51
train loss item: 1.2361608743667603
52
train loss item: 0.10014623403549194
53
train loss item: 0.17495793104171753
54
train loss item: 2.5482490062713623
55
train loss item: 0.24288977682590485
56
train loss item: 0.3269749581813812
57
train loss item: 0.32928532361984253
58
train loss item: 0.20363271236419678
59
train loss item: 0.11332597583532333
60
train loss item: 1.2394236326217651
61
train loss item: 2.4584274291992188
62
train loss item: 0.29960963129997253
63
train loss item: 0.5431960821151733
64
train loss item: 0.18512922525405884
65
train loss item: 0.7711639404296875
66
train loss item: 0.4807363450527191
67
train loss item: 0.2726135551929474
68
train loss item: 0.41561293601989746
69
train loss item: 0.4456692039966583
70
train loss item: 0.3555145561695099
71
train loss item: 0.14358972012996674
72
train loss item: 0.2191215604543686
73
train loss item: 0.374493271112442
74
train loss item: 0.06017114967107773
75
train loss item: 0.10456345975399017
76
train loss item: 1.0871490240097046
77
train loss item: 1.686781883239746
78
train loss item: 0.09912825375795364
79
train loss item: 0.3802109956741333
80
train loss item: 0.11510106921195984
81
train loss item: 0.24307720363140106
82
train loss item: 0.23767946660518646
83
train loss item: 0.9270601868629456
84
train loss item: 0.5043560862541199
85
train loss item: 0.757418692111969
86
train loss item: 4.672129154205322
87
train loss item: 0.184274822473526
88
train loss item: 0.46314653754234314
epoch train loss: 0.5918084435750929
testing phase
test loss item: 0.5236892700195312
test loss item: 0.40198272466659546
test loss item: 0.6920490264892578
test loss item: 0.6881552934646606
test loss item: 0.3704150915145874
test loss item: 0.13516037166118622
test loss item: 2.396550416946411
test loss item: 0.664077639579773
test loss item: 0.5536640286445618
test loss item: 0.5047097206115723
test loss item: 1.1247332096099854
test loss item: 0.46700742840766907
test loss item: 0.2124261111021042
test loss item: 2.1270132064819336
test loss item: 0.20503678917884827
test loss item: 0.08484891057014465
test loss item: 0.3586787283420563
test loss item: 0.5967658162117004
test loss item: 1.21761953830719
test loss item: 0.33205631375312805
test loss item: 1.0707261562347412
test loss item: 0.6328165531158447
test loss item: 0.3449479937553406
test loss item: 0.6298605799674988
test loss item: 0.2802462875843048
test loss item: 0.2643652856349945
test loss item: 0.4283195734024048
test loss item: 0.27629953622817993
test loss item: 0.8077201843261719
test loss item: 0.44108325242996216
test loss item: 1.018245816230774
test loss item: 0.09086402505636215
test loss item: 0.6215677857398987
test loss item: 0.8440428972244263
test loss item: 0.545583963394165
test loss item: 0.5358047485351562
test loss item: 1.047266960144043
test loss item: 1.7075612545013428
test loss item: 0.7830570936203003
test loss item: 0.33698275685310364
test loss item: 0.3884979784488678
test loss item: 0.46617773175239563
test loss item: 0.4358076751232147
test loss item: 0.5179856419563293
test loss item: 0.8800713419914246
test loss item: 0.5176689624786377
test loss item: 0.508940577507019
test loss item: 0.28306975960731506
test loss item: 0.5830430388450623
test loss item: 0.846513569355011
test loss item: 0.6831695437431335
test loss item: 0.15840516984462738
test loss item: 0.3074721395969391
test loss item: 0.7154531478881836
test loss item: 0.6723880767822266
test loss item: 1.0531034469604492
test loss item: 0.8452835083007812
test loss item: 2.077418565750122
test loss item: 0.2882629632949829
test loss item: 0.25122421979904175
test loss item: 0.5667965412139893
test loss item: 0.2532656192779541
test loss item: 0.3871164619922638
test loss item: 0.30088695883750916
test loss item: 1.0058485269546509
test loss item: 0.7958754301071167
test loss item: 0.36683958768844604
test loss item: 0.32204174995422363
test loss item: 0.6397978663444519
test loss item: 0.6515925526618958
test loss item: 0.07423264533281326
test loss item: 1.3272583484649658
test loss item: 0.9272853136062622
test loss item: 0.5042009353637695
test loss item: 0.210954949259758
test loss item: 0.20487675070762634
test loss item: 0.5989401936531067
test loss item: 1.7601640224456787
test loss item: 2.214028835296631
test loss item: 0.5121932625770569
test loss item: 0.10923033207654953
test loss item: 1.3622411489486694
test loss item: 1.160287857055664
test loss item: 1.1639991998672485
test loss item: 0.694328784942627
test loss item: 0.6750561594963074
test loss item: 0.14667709171772003
test loss item: 0.10110187530517578
test loss item: 1.8132339715957642
Epoch [16/50], Training Loss: 0.5918, Testing Loss: 0.6707
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 17/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4741816222667694
1
train loss item: 1.5831904411315918
2
train loss item: 0.278838574886322
3
train loss item: 0.7122685313224792
4
train loss item: 0.5877336263656616
5
train loss item: 0.40719231963157654
6
train loss item: 0.3373106122016907
7
train loss item: 0.9563984274864197
8
train loss item: 0.1620555967092514
9
train loss item: 0.328779011964798
10
train loss item: 0.43246516585350037
11
train loss item: 0.3864893317222595
12
train loss item: 0.12289568781852722
13
train loss item: 0.5590303540229797
14
train loss item: 0.28060591220855713
15
train loss item: 0.8471096158027649
16
train loss item: 0.07900825887918472
17
train loss item: 0.3786787688732147
18
train loss item: 0.4039078652858734
19
train loss item: 0.3564578890800476
20
train loss item: 0.29809170961380005
21
train loss item: 0.2256886512041092
22
train loss item: 1.3441338539123535
23
train loss item: 1.0737004280090332
24
train loss item: 0.7216583490371704
25
train loss item: 0.19144952297210693
26
train loss item: 0.2843727767467499
27
train loss item: 0.2809247076511383
28
train loss item: 0.07260557264089584
29
train loss item: 1.0386797189712524
30
train loss item: 2.656083106994629
31
train loss item: 0.6709092855453491
32
train loss item: 0.10496176034212112
33
train loss item: 0.5068352818489075
34
train loss item: 0.161063089966774
35
train loss item: 2.664412021636963
36
train loss item: 0.5446515083312988
37
train loss item: 0.5309215784072876
38
train loss item: 0.5452092289924622
39
train loss item: 0.26543790102005005
40
train loss item: 0.18857350945472717
41
train loss item: 0.31625694036483765
42
train loss item: 0.4135817289352417
43
train loss item: 0.21812543272972107
44
train loss item: 0.7262997031211853
45
train loss item: 0.13815976679325104
46
train loss item: 0.14156079292297363
47
train loss item: 0.4850063621997833
48
train loss item: 0.2747229039669037
49
train loss item: 0.18941114842891693
50
train loss item: 0.4087645709514618
51
train loss item: 1.2115269899368286
52
train loss item: 0.09220170229673386
53
train loss item: 0.16933731734752655
54
train loss item: 2.5336241722106934
55
train loss item: 0.24377493560314178
56
train loss item: 0.33357539772987366
57
train loss item: 0.33281370997428894
58
train loss item: 0.2011183202266693
59
train loss item: 0.11087584495544434
60
train loss item: 1.2051295042037964
61
train loss item: 2.450059175491333
62
train loss item: 0.2912934422492981
63
train loss item: 0.5302965044975281
64
train loss item: 0.18289758265018463
65
train loss item: 0.758758544921875
66
train loss item: 0.4696449041366577
67
train loss item: 0.27928802371025085
68
train loss item: 0.40240466594696045
69
train loss item: 0.4478578567504883
70
train loss item: 0.35304343700408936
71
train loss item: 0.14890560507774353
72
train loss item: 0.21429337561130524
73
train loss item: 0.37934601306915283
74
train loss item: 0.05936463549733162
75
train loss item: 0.10332164913415909
76
train loss item: 1.0816720724105835
77
train loss item: 1.657785415649414
78
train loss item: 0.08514221757650375
79
train loss item: 0.37528321146965027
80
train loss item: 0.11313781142234802
81
train loss item: 0.2393043339252472
82
train loss item: 0.2319851517677307
83
train loss item: 0.8985320329666138
84
train loss item: 0.4926140308380127
85
train loss item: 0.7505854368209839
86
train loss item: 4.653926849365234
87
train loss item: 0.1838158369064331
88
train loss item: 0.46791353821754456
epoch train loss: 0.5853179974920963
testing phase
test loss item: 0.778448224067688
test loss item: 0.45115724205970764
test loss item: 0.696083664894104
test loss item: 0.9102843403816223
test loss item: 0.37663888931274414
test loss item: 0.1392698884010315
test loss item: 2.3118319511413574
test loss item: 0.6728098392486572
test loss item: 0.8505887389183044
test loss item: 0.5015709400177002
test loss item: 1.2733540534973145
test loss item: 0.733497679233551
test loss item: 0.20503486692905426
test loss item: 2.1018781661987305
test loss item: 0.2055562138557434
test loss item: 0.08378063142299652
test loss item: 0.34956875443458557
test loss item: 0.5923557877540588
test loss item: 1.0549850463867188
test loss item: 0.32722851634025574
test loss item: 1.1041219234466553
test loss item: 0.8051728010177612
test loss item: 0.36097201704978943
test loss item: 0.7180910110473633
test loss item: 0.2772563695907593
test loss item: 0.2628060579299927
test loss item: 0.5338261723518372
test loss item: 0.3493165075778961
test loss item: 0.7936413288116455
test loss item: 0.43482163548469543
test loss item: 1.033223032951355
test loss item: 0.09009508043527603
test loss item: 0.7133759260177612
test loss item: 1.1185729503631592
test loss item: 0.5457256436347961
test loss item: 0.5206199884414673
test loss item: 1.0039705038070679
test loss item: 1.7317662239074707
test loss item: 0.9283127784729004
test loss item: 0.33260247111320496
test loss item: 0.38167905807495117
test loss item: 0.31040364503860474
test loss item: 0.43555715680122375
test loss item: 0.7186704874038696
test loss item: 0.9281030893325806
test loss item: 0.5034196376800537
test loss item: 0.5416565537452698
test loss item: 0.2862633168697357
test loss item: 0.5783008933067322
test loss item: 0.8424529433250427
test loss item: 0.6725457906723022
test loss item: 0.15154412388801575
test loss item: 0.30192604660987854
test loss item: 1.0612187385559082
test loss item: 0.6599470376968384
test loss item: 1.0705195665359497
test loss item: 1.058255910873413
test loss item: 2.0336363315582275
test loss item: 0.2810119688510895
test loss item: 0.2493419647216797
test loss item: 0.5653489828109741
test loss item: 0.23149126768112183
test loss item: 0.4094878137111664
test loss item: 0.3005349338054657
test loss item: 0.9971536993980408
test loss item: 1.1245999336242676
test loss item: 0.35930490493774414
test loss item: 0.334946870803833
test loss item: 0.6442634463310242
test loss item: 0.47860923409461975
test loss item: 0.07600229233503342
test loss item: 1.2646701335906982
test loss item: 0.9631553888320923
test loss item: 0.5216453075408936
test loss item: 0.40884730219841003
test loss item: 0.4691760241985321
test loss item: 0.6909782290458679
test loss item: 1.879669427871704
test loss item: 2.1873714923858643
test loss item: 0.4959357976913452
test loss item: 0.12093138694763184
test loss item: 1.2729016542434692
test loss item: 1.1063077449798584
test loss item: 1.179098129272461
test loss item: 0.6908490061759949
test loss item: 0.41248032450675964
test loss item: 0.48618730902671814
test loss item: 0.09941166639328003
test loss item: 1.4256088733673096
Epoch [17/50], Training Loss: 0.5853, Testing Loss: 0.7027
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 18/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4768312871456146
1
train loss item: 1.5584571361541748
2
train loss item: 0.27231377363204956
3
train loss item: 0.7046030759811401
4
train loss item: 0.5275874733924866
5
train loss item: 0.40858718752861023
6
train loss item: 0.3298797607421875
7
train loss item: 0.9554533958435059
8
train loss item: 0.1575060486793518
9
train loss item: 0.3289421796798706
10
train loss item: 0.4364463686943054
11
train loss item: 0.38396361470222473
12
train loss item: 0.11500533670186996
13
train loss item: 0.5555550456047058
14
train loss item: 0.276787132024765
15
train loss item: 0.8212077617645264
16
train loss item: 0.06680203229188919
17
train loss item: 0.37070736289024353
18
train loss item: 0.4016857445240021
19
train loss item: 0.35322725772857666
20
train loss item: 0.289168119430542
21
train loss item: 0.22728081047534943
22
train loss item: 1.302729606628418
23
train loss item: 1.0732463598251343
24
train loss item: 0.7210332155227661
25
train loss item: 0.18810659646987915
26
train loss item: 0.28082412481307983
27
train loss item: 0.2800900340080261
28
train loss item: 0.059930045157670975
29
train loss item: 1.0075794458389282
30
train loss item: 2.6427321434020996
31
train loss item: 0.6775880455970764
32
train loss item: 0.10244054347276688
33
train loss item: 0.5054564476013184
34
train loss item: 0.1596183329820633
35
train loss item: 2.65579891204834
36
train loss item: 0.5325554013252258
37
train loss item: 0.5372017025947571
38
train loss item: 0.5362136960029602
39
train loss item: 0.26618364453315735
40
train loss item: 0.19260847568511963
41
train loss item: 0.3168686032295227
42
train loss item: 0.4076680541038513
43
train loss item: 0.2171536684036255
44
train loss item: 0.7306571006774902
45
train loss item: 0.1317499727010727
46
train loss item: 0.1452709287405014
47
train loss item: 0.47395479679107666
48
train loss item: 0.2703343629837036
49
train loss item: 0.1784634292125702
50
train loss item: 0.40231242775917053
51
train loss item: 1.1896438598632812
52
train loss item: 0.08419718593358994
53
train loss item: 0.16717574000358582
54
train loss item: 2.523463010787964
55
train loss item: 0.24287880957126617
56
train loss item: 0.34256717562675476
57
train loss item: 0.3315661549568176
58
train loss item: 0.19713470339775085
59
train loss item: 0.11450671404600143
60
train loss item: 1.1771377325057983
61
train loss item: 2.447265148162842
62
train loss item: 0.2835659086704254
63
train loss item: 0.5172621011734009
64
train loss item: 0.1846424639225006
65
train loss item: 0.7466301918029785
66
train loss item: 0.4606435000896454
67
train loss item: 0.27768397331237793
68
train loss item: 0.3894059360027313
69
train loss item: 0.4474147856235504
70
train loss item: 0.3477148413658142
71
train loss item: 0.15128056704998016
72
train loss item: 0.2124711573123932
73
train loss item: 0.3796289265155792
74
train loss item: 0.06160629540681839
75
train loss item: 0.10370463877916336
76
train loss item: 1.077339768409729
77
train loss item: 1.6301170587539673
78
train loss item: 0.06980431824922562
79
train loss item: 0.3687571883201599
80
train loss item: 0.11449875682592392
81
train loss item: 0.23322255909442902
82
train loss item: 0.22726097702980042
83
train loss item: 0.8752715587615967
84
train loss item: 0.4830400347709656
85
train loss item: 0.750203013420105
86
train loss item: 4.644121170043945
87
train loss item: 0.18549089133739471
88
train loss item: 0.46429798007011414
epoch train loss: 0.5788649979853229
testing phase
test loss item: 0.6705775260925293
test loss item: 0.30422496795654297
test loss item: 0.6966654062271118
test loss item: 0.7728142738342285
test loss item: 0.3289653956890106
test loss item: 0.14786195755004883
test loss item: 2.2664482593536377
test loss item: 0.649376630783081
test loss item: 0.7394468784332275
test loss item: 0.4991703927516937
test loss item: 1.2354031801223755
test loss item: 0.6812174916267395
test loss item: 0.20223310589790344
test loss item: 1.3099993467330933
test loss item: 0.20583952963352203
test loss item: 0.08055263757705688
test loss item: 0.3446890413761139
test loss item: 0.5869736671447754
test loss item: 0.8404855132102966
test loss item: 0.33118271827697754
test loss item: 1.0321807861328125
test loss item: 0.7357768416404724
test loss item: 0.36082035303115845
test loss item: 0.504401683807373
test loss item: 0.2741978168487549
test loss item: 0.2639910578727722
test loss item: 0.5461609959602356
test loss item: 0.31813594698905945
test loss item: 0.5891938805580139
test loss item: 0.43152081966400146
test loss item: 1.0347167253494263
test loss item: 0.08652359992265701
test loss item: 0.49769309163093567
test loss item: 1.0869114398956299
test loss item: 0.5432525277137756
test loss item: 0.520534098148346
test loss item: 0.9812160134315491
test loss item: 1.7445318698883057
test loss item: 0.8860728740692139
test loss item: 0.3339292109012604
test loss item: 0.37862324714660645
test loss item: 0.2126161903142929
test loss item: 0.44114625453948975
test loss item: 0.6541360020637512
test loss item: 0.8656798005104065
test loss item: 0.5004228949546814
test loss item: 0.4615764021873474
test loss item: 0.3017268776893616
test loss item: 0.5752807855606079
test loss item: 0.8413575291633606
test loss item: 0.512520968914032
test loss item: 0.1482972800731659
test loss item: 0.2983468174934387
test loss item: 0.9465591311454773
test loss item: 0.4831976592540741
test loss item: 1.0795255899429321
test loss item: 0.9447394013404846
test loss item: 1.2234464883804321
test loss item: 0.27743595838546753
test loss item: 0.24894697964191437
test loss item: 0.5640102624893188
test loss item: 0.22131359577178955
test loss item: 0.31922006607055664
test loss item: 0.3029499650001526
test loss item: 0.9934269785881042
test loss item: 1.014504075050354
test loss item: 0.35709816217422485
test loss item: 0.34152767062187195
test loss item: 0.6466010808944702
test loss item: 0.46954500675201416
test loss item: 0.0740082859992981
test loss item: 1.2349761724472046
test loss item: 0.6777136325836182
test loss item: 0.48497676849365234
test loss item: 0.41339996457099915
test loss item: 0.47615915536880493
test loss item: 0.4918529689311981
test loss item: 1.8445993661880493
test loss item: 1.4040696620941162
test loss item: 0.33785396814346313
test loss item: 0.13830842077732086
test loss item: 1.1787488460540771
test loss item: 1.090083360671997
test loss item: 1.1875786781311035
test loss item: 0.4882241189479828
test loss item: 0.27988705039024353
test loss item: 0.4988635778427124
test loss item: 0.09480553865432739
test loss item: 0.694891631603241
Epoch [18/50], Training Loss: 0.5789, Testing Loss: 0.6223
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 19/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.482753187417984
1
train loss item: 1.5394679307937622
2
train loss item: 0.2771599590778351
3
train loss item: 0.7006429433822632
4
train loss item: 0.47966432571411133
5
train loss item: 0.4081529378890991
6
train loss item: 0.3199339210987091
7
train loss item: 0.9552167654037476
8
train loss item: 0.15332067012786865
9
train loss item: 0.33051690459251404
10
train loss item: 0.4395042359828949
11
train loss item: 0.3766477406024933
12
train loss item: 0.11107536405324936
13
train loss item: 0.5527011752128601
14
train loss item: 0.27088862657546997
15
train loss item: 0.8012568950653076
16
train loss item: 0.05905230715870857
17
train loss item: 0.36274632811546326
18
train loss item: 0.4022640585899353
19
train loss item: 0.3475485146045685
20
train loss item: 0.2798481285572052
21
train loss item: 0.21885396540164948
22
train loss item: 1.2748079299926758
23
train loss item: 1.0743286609649658
24
train loss item: 0.7282713651657104
25
train loss item: 0.18607604503631592
26
train loss item: 0.2704872786998749
27
train loss item: 0.27981138229370117
28
train loss item: 0.05229675769805908
29
train loss item: 0.9894734621047974
30
train loss item: 2.6336565017700195
31
train loss item: 0.6844327449798584
32
train loss item: 0.10295959562063217
33
train loss item: 0.5050162672996521
34
train loss item: 0.1520448625087738
35
train loss item: 2.6518242359161377
36
train loss item: 0.5305816531181335
37
train loss item: 0.5385941863059998
38
train loss item: 0.539892315864563
39
train loss item: 0.26929771900177
40
train loss item: 0.19277054071426392
41
train loss item: 0.3216620981693268
42
train loss item: 0.3950452208518982
43
train loss item: 0.2185748964548111
44
train loss item: 0.7369364500045776
45
train loss item: 0.13415385782718658
46
train loss item: 0.14834457635879517
47
train loss item: 0.4668557345867157
48
train loss item: 0.27021101117134094
49
train loss item: 0.17433661222457886
50
train loss item: 0.39669135212898254
51
train loss item: 1.1713874340057373
52
train loss item: 0.07673970609903336
53
train loss item: 0.16934806108474731
54
train loss item: 2.5170178413391113
55
train loss item: 0.24282026290893555
56
train loss item: 0.3508146107196808
57
train loss item: 0.3254255950450897
58
train loss item: 0.19379931688308716
59
train loss item: 0.11736885458230972
60
train loss item: 1.1577776670455933
61
train loss item: 2.4455618858337402
62
train loss item: 0.2781938314437866
63
train loss item: 0.5047089457511902
64
train loss item: 0.19007325172424316
65
train loss item: 0.7500156760215759
66
train loss item: 0.45646926760673523
67
train loss item: 0.2709132134914398
68
train loss item: 0.3800494372844696
69
train loss item: 0.44504135847091675
70
train loss item: 0.342147558927536
71
train loss item: 0.150846928358078
72
train loss item: 0.21330279111862183
73
train loss item: 0.378251850605011
74
train loss item: 0.06635107845067978
75
train loss item: 0.10878245532512665
76
train loss item: 1.0728076696395874
77
train loss item: 1.6067345142364502
78
train loss item: 0.059995137155056
79
train loss item: 0.36090973019599915
80
train loss item: 0.11605889350175858
81
train loss item: 0.22719699144363403
82
train loss item: 0.22602635622024536
83
train loss item: 0.8588120341300964
84
train loss item: 0.47507426142692566
85
train loss item: 0.753808856010437
86
train loss item: 4.637316703796387
87
train loss item: 0.1898706704378128
88
train loss item: 0.4604547917842865
epoch train loss: 0.574572221239966
testing phase
test loss item: 0.343805193901062
test loss item: 0.149579256772995
test loss item: 0.6946437358856201
test loss item: 0.42766761779785156
test loss item: 0.30688101053237915
test loss item: 0.15658310055732727
test loss item: 2.2577173709869385
test loss item: 0.5508029460906982
test loss item: 0.40217044949531555
test loss item: 0.4974578320980072
test loss item: 1.1030362844467163
test loss item: 0.39405664801597595
test loss item: 0.2054988443851471
test loss item: 0.5396341681480408
test loss item: 0.20579111576080322
test loss item: 0.07606495171785355
test loss item: 0.343936562538147
test loss item: 0.5827085971832275
test loss item: 0.7765547037124634
test loss item: 0.34184566140174866
test loss item: 0.96269690990448
test loss item: 0.5101994872093201
test loss item: 0.3631771206855774
test loss item: 0.2654804587364197
test loss item: 0.27165287733078003
test loss item: 0.26819702982902527
test loss item: 0.451542466878891
test loss item: 0.2543186545372009
test loss item: 0.44131094217300415
test loss item: 0.4308575689792633
test loss item: 1.0015003681182861
test loss item: 0.08084855228662491
test loss item: 0.24616938829421997
test loss item: 0.8074705004692078
test loss item: 0.5398759841918945
test loss item: 0.5249394178390503
test loss item: 0.9786133170127869
test loss item: 1.7417374849319458
test loss item: 0.7141444087028503
test loss item: 0.3386189937591553
test loss item: 0.3782244622707367
test loss item: 0.2203417718410492
test loss item: 0.44182029366493225
test loss item: 0.3925826847553253
test loss item: 0.8067881464958191
test loss item: 0.5052306652069092
test loss item: 0.3711021840572357
test loss item: 0.3168467879295349
test loss item: 0.5734863877296448
test loss item: 0.840575098991394
test loss item: 0.4259977340698242
test loss item: 0.14999382197856903
test loss item: 0.2965923249721527
test loss item: 0.48418736457824707
test loss item: 0.3879862427711487
test loss item: 1.070515751838684
test loss item: 0.6894058585166931
test loss item: 0.46822065114974976
test loss item: 0.278480589389801
test loss item: 0.2502273619174957
test loss item: 0.5614140629768372
test loss item: 0.22003574669361115
test loss item: 0.2543838620185852
test loss item: 0.3077516257762909
test loss item: 0.9950470924377441
test loss item: 0.5786739587783813
test loss item: 0.35993924736976624
test loss item: 0.3231230080127716
test loss item: 0.6481091976165771
test loss item: 0.4785112738609314
test loss item: 0.0714411735534668
test loss item: 1.2334593534469604
test loss item: 0.47377535700798035
test loss item: 0.46635347604751587
test loss item: 0.23656606674194336
test loss item: 0.2647184729576111
test loss item: 0.26614055037498474
test loss item: 1.7469197511672974
test loss item: 0.6795587539672852
test loss item: 0.24476845562458038
test loss item: 0.10844258964061737
test loss item: 1.1539764404296875
test loss item: 1.0848748683929443
test loss item: 1.1865828037261963
test loss item: 0.3140411674976349
test loss item: 0.27417147159576416
test loss item: 0.2169419527053833
test loss item: 0.0885683074593544
test loss item: 0.25415223836898804
Epoch [19/50], Training Loss: 0.5746, Testing Loss: 0.5168
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 20/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.48939967155456543
1
train loss item: 1.5246821641921997
2
train loss item: 0.28371766209602356
3
train loss item: 0.6976882219314575
4
train loss item: 0.4569762647151947
5
train loss item: 0.4059332311153412
6
train loss item: 0.31324103474617004
7
train loss item: 0.9552748203277588
8
train loss item: 0.15135686099529266
9
train loss item: 0.3347167372703552
10
train loss item: 0.43986427783966064
11
train loss item: 0.36285242438316345
12
train loss item: 0.11211765557527542
13
train loss item: 0.5481806993484497
14
train loss item: 0.2648284137248993
15
train loss item: 0.7839811444282532
16
train loss item: 0.05749807506799698
17
train loss item: 0.35715100169181824
18
train loss item: 0.40432998538017273
19
train loss item: 0.34015366435050964
20
train loss item: 0.2717386782169342
21
train loss item: 0.20293676853179932
22
train loss item: 1.2567894458770752
23
train loss item: 1.07242751121521
24
train loss item: 0.7353664040565491
25
train loss item: 0.18500030040740967
26
train loss item: 0.2553699016571045
27
train loss item: 0.27930372953414917
28
train loss item: 0.05166681110858917
29
train loss item: 0.9775183200836182
30
train loss item: 2.6259427070617676
31
train loss item: 0.6860136985778809
32
train loss item: 0.10700583457946777
33
train loss item: 0.503474235534668
34
train loss item: 0.14132538437843323
35
train loss item: 2.6507503986358643
36
train loss item: 0.5348930954933167
37
train loss item: 0.5339813828468323
38
train loss item: 0.5432106256484985
39
train loss item: 0.2734401822090149
40
train loss item: 0.19074232876300812
41
train loss item: 0.32787230610847473
42
train loss item: 0.3768487572669983
43
train loss item: 0.2211753875017166
44
train loss item: 0.7423034310340881
45
train loss item: 0.13620978593826294
46
train loss item: 0.1495346873998642
47
train loss item: 0.4636385142803192
48
train loss item: 0.27307650446891785
49
train loss item: 0.1733849197626114
50
train loss item: 0.3915206789970398
51
train loss item: 1.1554447412490845
52
train loss item: 0.07041579484939575
53
train loss item: 0.17332781851291656
54
train loss item: 2.5141193866729736
55
train loss item: 0.24515558779239655
56
train loss item: 0.3564786911010742
57
train loss item: 0.3150367736816406
58
train loss item: 0.19204361736774445
59
train loss item: 0.12071958184242249
60
train loss item: 1.1451561450958252
61
train loss item: 2.4419827461242676
62
train loss item: 0.27532657980918884
63
train loss item: 0.49108755588531494
64
train loss item: 0.19546331465244293
65
train loss item: 0.7579318284988403
66
train loss item: 0.45438194274902344
67
train loss item: 0.26148200035095215
68
train loss item: 0.37761834263801575
69
train loss item: 0.4424722194671631
70
train loss item: 0.3365217447280884
71
train loss item: 0.14776726067066193
72
train loss item: 0.21375560760498047
73
train loss item: 0.3767361044883728
74
train loss item: 0.07071921229362488
75
train loss item: 0.1166478618979454
76
train loss item: 1.067589282989502
77
train loss item: 1.5847749710083008
78
train loss item: 0.05725032091140747
79
train loss item: 0.3502150774002075
80
train loss item: 0.11638422310352325
81
train loss item: 0.22318468987941742
82
train loss item: 0.2269350290298462
83
train loss item: 0.8460553884506226
84
train loss item: 0.46761849522590637
85
train loss item: 0.758484423160553
86
train loss item: 4.631710529327393
87
train loss item: 0.19475005567073822
88
train loss item: 0.4580650329589844
epoch train loss: 0.5713395135623686
testing phase
test loss item: 0.391771137714386
test loss item: 0.15524700284004211
test loss item: 0.692388653755188
test loss item: 0.5024934411048889
test loss item: 0.3109913170337677
test loss item: 0.1610231101512909
test loss item: 2.2666537761688232
test loss item: 0.560066282749176
test loss item: 0.47303250432014465
test loss item: 0.49715456366539
test loss item: 1.1227302551269531
test loss item: 0.5597252249717712
test loss item: 0.2129753679037094
test loss item: 0.4334922134876251
test loss item: 0.20529022812843323
test loss item: 0.07178797572851181
test loss item: 0.34668517112731934
test loss item: 0.5810911059379578
test loss item: 0.7782292366027832
test loss item: 0.3535667955875397
test loss item: 0.957983136177063
test loss item: 0.5966699123382568
test loss item: 0.3722187578678131
test loss item: 0.2631656527519226
test loss item: 0.27011552453041077
test loss item: 0.27440109848976135
test loss item: 0.4658481776714325
test loss item: 0.26057004928588867
test loss item: 0.425971120595932
test loss item: 0.4321559965610504
test loss item: 1.0001474618911743
test loss item: 0.07477760314941406
test loss item: 0.24650520086288452
test loss item: 0.9242777228355408
test loss item: 0.537639319896698
test loss item: 0.518890917301178
test loss item: 0.983187735080719
test loss item: 1.726510763168335
test loss item: 0.734376072883606
test loss item: 0.34415149688720703
test loss item: 0.3787110149860382
test loss item: 0.22546584904193878
test loss item: 0.45135512948036194
test loss item: 0.4639163315296173
test loss item: 0.8124517202377319
test loss item: 0.5140026807785034
test loss item: 0.381468802690506
test loss item: 0.32614657282829285
test loss item: 0.5737559795379639
test loss item: 0.8371501564979553
test loss item: 0.42484772205352783
test loss item: 0.15356256067752838
test loss item: 0.2965649962425232
test loss item: 0.648077130317688
test loss item: 0.38450518250465393
test loss item: 1.0617027282714844
test loss item: 0.7258303761482239
test loss item: 0.38633325695991516
test loss item: 0.2832624018192291
test loss item: 0.25359123945236206
test loss item: 0.5591334104537964
test loss item: 0.22574105858802795
test loss item: 0.26529213786125183
test loss item: 0.3133350908756256
test loss item: 0.99847811460495
test loss item: 0.6969916224479675
test loss item: 0.36736443638801575
test loss item: 0.324733167886734
test loss item: 0.6547371745109558
test loss item: 0.4740505814552307
test loss item: 0.06913955509662628
test loss item: 1.2437704801559448
test loss item: 0.47956445813179016
test loss item: 0.48185497522354126
test loss item: 0.24080362915992737
test loss item: 0.26864397525787354
test loss item: 0.26534804701805115
test loss item: 1.746785044670105
test loss item: 0.5834906101226807
test loss item: 0.25244206190109253
test loss item: 0.10414069890975952
test loss item: 1.1510558128356934
test loss item: 1.082732081413269
test loss item: 1.1779106855392456
test loss item: 0.2968882620334625
test loss item: 0.2771972417831421
test loss item: 0.21119000017642975
test loss item: 0.08218269050121307
test loss item: 0.22806097567081451
Epoch [20/50], Training Loss: 0.5713, Testing Loss: 0.5257
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 21/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4939647614955902
1
train loss item: 1.512141227722168
2
train loss item: 0.2856897711753845
3
train loss item: 0.6924282312393188
4
train loss item: 0.4494308531284332
5
train loss item: 0.40217283368110657
6
train loss item: 0.311532586812973
7
train loss item: 0.9558128118515015
8
train loss item: 0.15155771374702454
9
train loss item: 0.33960291743278503
10
train loss item: 0.43553563952445984
11
train loss item: 0.34316325187683105
12
train loss item: 0.11408211290836334
13
train loss item: 0.5416112542152405
14
train loss item: 0.2609574496746063
15
train loss item: 0.7667596340179443
16
train loss item: 0.05731065571308136
17
train loss item: 0.35561561584472656
18
train loss item: 0.40712299942970276
19
train loss item: 0.3329003155231476
20
train loss item: 0.2645132839679718
21
train loss item: 0.18152950704097748
22
train loss item: 1.2402105331420898
23
train loss item: 1.0659898519515991
24
train loss item: 0.7373067736625671
25
train loss item: 0.18499115109443665
26
train loss item: 0.23979324102401733
27
train loss item: 0.2789268493652344
28
train loss item: 0.052636630833148956
29
train loss item: 0.9631258249282837
30
train loss item: 2.6163806915283203
31
train loss item: 0.6796251535415649
32
train loss item: 0.11066696047782898
33
train loss item: 0.5014747977256775
34
train loss item: 0.13049840927124023
35
train loss item: 2.6498847007751465
36
train loss item: 0.5400064587593079
37
train loss item: 0.5246185660362244
38
train loss item: 0.5348193049430847
39
train loss item: 0.27764979004859924
40
train loss item: 0.1864052563905716
41
train loss item: 0.3318631947040558
42
train loss item: 0.35722237825393677
43
train loss item: 0.22341403365135193
44
train loss item: 0.7456300854682922
45
train loss item: 0.1389000117778778
46
train loss item: 0.1478511542081833
47
train loss item: 0.4627317786216736
48
train loss item: 0.2757631540298462
49
train loss item: 0.1714070439338684
50
train loss item: 0.38696253299713135
51
train loss item: 1.1415691375732422
52
train loss item: 0.06771393865346909
53
train loss item: 0.1769731342792511
54
train loss item: 2.511569023132324
55
train loss item: 0.2496914267539978
56
train loss item: 0.3595021367073059
57
train loss item: 0.30174699425697327
58
train loss item: 0.19154369831085205
59
train loss item: 0.12229151278734207
60
train loss item: 1.1347445249557495
61
train loss item: 2.435509204864502
62
train loss item: 0.2732947766780853
63
train loss item: 0.4765929579734802
64
train loss item: 0.19782565534114838
65
train loss item: 0.7560012936592102
66
train loss item: 0.4526321291923523
67
train loss item: 0.2519223988056183
68
train loss item: 0.3812035024166107
69
train loss item: 0.43940961360931396
70
train loss item: 0.3316360414028168
71
train loss item: 0.14310322701931
72
train loss item: 0.2141856551170349
73
train loss item: 0.37522828578948975
74
train loss item: 0.07159517705440521
75
train loss item: 0.12276998907327652
76
train loss item: 1.0625088214874268
77
train loss item: 1.56325364112854
78
train loss item: 0.05735132470726967
79
train loss item: 0.337118536233902
80
train loss item: 0.11663361638784409
81
train loss item: 0.22104349732398987
82
train loss item: 0.22815042734146118
83
train loss item: 0.8344643115997314
84
train loss item: 0.4594496488571167
85
train loss item: 0.7596615552902222
86
train loss item: 4.623538970947266
87
train loss item: 0.19801947474479675
88
train loss item: 0.4540916681289673
epoch train loss: 0.567502614278137
testing phase
test loss item: 0.4520205557346344
test loss item: 0.13105788826942444
test loss item: 0.6939586400985718
test loss item: 0.5844814777374268
test loss item: 0.3053952157497406
test loss item: 0.1600944697856903
test loss item: 2.2715070247650146
test loss item: 0.5648982524871826
test loss item: 0.5478432178497314
test loss item: 0.5003023147583008
test loss item: 1.1490176916122437
test loss item: 0.6773325800895691
test loss item: 0.22111298143863678
test loss item: 0.4490189850330353
test loss item: 0.20506872236728668
test loss item: 0.06932321935892105
test loss item: 0.35036569833755493
test loss item: 0.5840477347373962
test loss item: 0.7819253206253052
test loss item: 0.36145663261413574
test loss item: 0.9588027596473694
test loss item: 0.6755943298339844
test loss item: 0.38269224762916565
test loss item: 0.24474363029003143
test loss item: 0.2700205147266388
test loss item: 0.27998554706573486
test loss item: 0.47909364104270935
test loss item: 0.25571882724761963
test loss item: 0.42994871735572815
test loss item: 0.4354156255722046
test loss item: 0.9937969446182251
test loss item: 0.06991493701934814
test loss item: 0.2248678356409073
test loss item: 1.052412986755371
test loss item: 0.5392690896987915
test loss item: 0.5133099555969238
test loss item: 0.9902231097221375
test loss item: 1.7151955366134644
test loss item: 0.77956622838974
test loss item: 0.34720492362976074
test loss item: 0.3783659040927887
test loss item: 0.22284038364887238
test loss item: 0.46022748947143555
test loss item: 0.5419220328330994
test loss item: 0.8131000995635986
test loss item: 0.5257501006126404
test loss item: 0.3838260769844055
test loss item: 0.3261807858943939
test loss item: 0.578473687171936
test loss item: 0.8364759087562561
test loss item: 0.4263831377029419
test loss item: 0.15666180849075317
test loss item: 0.29851317405700684
test loss item: 0.7933008670806885
test loss item: 0.3791581988334656
test loss item: 1.0555247068405151
test loss item: 0.7731379866600037
test loss item: 0.36760270595550537
test loss item: 0.2893446981906891
test loss item: 0.2592960596084595
test loss item: 0.5598635673522949
test loss item: 0.23626452684402466
test loss item: 0.2853245437145233
test loss item: 0.31758230924606323
test loss item: 1.003798484802246
test loss item: 0.8272594809532166
test loss item: 0.37556472420692444
test loss item: 0.3228091895580292
test loss item: 0.6639189720153809
test loss item: 0.46756690740585327
test loss item: 0.06742113083600998
test loss item: 1.2530372142791748
test loss item: 0.44679883122444153
test loss item: 0.49689313769340515
test loss item: 0.21397799253463745
test loss item: 0.2396727055311203
test loss item: 0.24813491106033325
test loss item: 1.7533155679702759
test loss item: 0.5992151498794556
test loss item: 0.26775455474853516
test loss item: 0.10234475135803223
test loss item: 1.1472097635269165
test loss item: 1.08455228805542
test loss item: 1.172318458557129
test loss item: 0.3006960153579712
test loss item: 0.2797783613204956
test loss item: 0.15873245894908905
test loss item: 0.07785319536924362
test loss item: 0.21201948821544647
Epoch [21/50], Training Loss: 0.5675, Testing Loss: 0.5365
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 22/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4980311691761017
1
train loss item: 1.5016156435012817
2
train loss item: 0.28388532996177673
3
train loss item: 0.6884694695472717
4
train loss item: 0.44686955213546753
5
train loss item: 0.3974917232990265
6
train loss item: 0.31402599811553955
7
train loss item: 0.9560467600822449
8
train loss item: 0.15312817692756653
9
train loss item: 0.3410256803035736
10
train loss item: 0.429959774017334
11
train loss item: 0.32586243748664856
12
train loss item: 0.11447371542453766
13
train loss item: 0.537125289440155
14
train loss item: 0.2609211206436157
15
train loss item: 0.7556833624839783
16
train loss item: 0.05580736696720123
17
train loss item: 0.3592541217803955
18
train loss item: 0.41026633977890015
19
train loss item: 0.3276149332523346
20
train loss item: 0.2614450454711914
21
train loss item: 0.1628720909357071
22
train loss item: 1.2249171733856201
23
train loss item: 1.0594755411148071
24
train loss item: 0.7334761619567871
25
train loss item: 0.1860567331314087
26
train loss item: 0.22927390038967133
27
train loss item: 0.2790462076663971
28
train loss item: 0.05203265696763992
29
train loss item: 0.948707640171051
30
train loss item: 2.6067309379577637
31
train loss item: 0.6717613339424133
32
train loss item: 0.11129100620746613
33
train loss item: 0.5015873312950134
34
train loss item: 0.12086405605077744
35
train loss item: 2.646437644958496
36
train loss item: 0.5460311770439148
37
train loss item: 0.5146533250808716
38
train loss item: 0.5233686566352844
39
train loss item: 0.2809610664844513
40
train loss item: 0.18077170848846436
41
train loss item: 0.33253705501556396
42
train loss item: 0.3418886065483093
43
train loss item: 0.22480878233909607
44
train loss item: 0.7479206323623657
45
train loss item: 0.14376170933246613
46
train loss item: 0.14438238739967346
47
train loss item: 0.4616328477859497
48
train loss item: 0.2770470976829529
49
train loss item: 0.1708378791809082
50
train loss item: 0.3841199576854706
51
train loss item: 1.1281607151031494
52
train loss item: 0.06891083717346191
53
train loss item: 0.1799413412809372
54
train loss item: 2.506694793701172
55
train loss item: 0.25474870204925537
56
train loss item: 0.3604440987110138
57
train loss item: 0.2881815433502197
58
train loss item: 0.19149823486804962
59
train loss item: 0.12084826081991196
60
train loss item: 1.125378966331482
61
train loss item: 2.4286155700683594
62
train loss item: 0.2711167335510254
63
train loss item: 0.4638775587081909
64
train loss item: 0.1975826472043991
65
train loss item: 0.7458823919296265
66
train loss item: 0.45359599590301514
67
train loss item: 0.24617885053157806
68
train loss item: 0.3883344531059265
69
train loss item: 0.43652164936065674
70
train loss item: 0.327992707490921
71
train loss item: 0.1390150636434555
72
train loss item: 0.21555444598197937
73
train loss item: 0.37287595868110657
74
train loss item: 0.06963831186294556
75
train loss item: 0.1248607188463211
76
train loss item: 1.0586010217666626
77
train loss item: 1.5485886335372925
78
train loss item: 0.05786275863647461
79
train loss item: 0.32603201270103455
80
train loss item: 0.11961778998374939
81
train loss item: 0.21912504732608795
82
train loss item: 0.2304716259241104
83
train loss item: 0.8234267234802246
84
train loss item: 0.45496633648872375
85
train loss item: 0.7561872005462646
86
train loss item: 4.612399101257324
87
train loss item: 0.1992795467376709
88
train loss item: 0.44788044691085815
epoch train loss: 0.5639229787701971
testing phase
test loss item: 0.4624606668949127
test loss item: 0.10648034512996674
test loss item: 0.7008268237113953
test loss item: 0.5502788424491882
test loss item: 0.3030354082584381
test loss item: 0.156355619430542
test loss item: 2.2587625980377197
test loss item: 0.5665462017059326
test loss item: 0.5476011633872986
test loss item: 0.5069231390953064
test loss item: 1.1521486043930054
test loss item: 0.6432160139083862
test loss item: 0.22700393199920654
test loss item: 0.44332170486450195
test loss item: 0.20627371966838837
test loss item: 0.06987614184617996
test loss item: 0.35191085934638977
test loss item: 0.5915235877037048
test loss item: 0.7842848300933838
test loss item: 0.36259639263153076
test loss item: 0.9639335870742798
test loss item: 0.6538915038108826
test loss item: 0.3986186385154724
test loss item: 0.21703886985778809
test loss item: 0.2714855372905731
test loss item: 0.28328844904899597
test loss item: 0.4786279797554016
test loss item: 0.24563731253147125
test loss item: 0.432320237159729
test loss item: 0.4398992657661438
test loss item: 0.9911603927612305
test loss item: 0.06806592643260956
test loss item: 0.18747130036354065
test loss item: 1.1122212409973145
test loss item: 0.5456960797309875
test loss item: 0.5139905214309692
test loss item: 0.9943363666534424
test loss item: 1.718544363975525
test loss item: 0.7685448527336121
test loss item: 0.3468904495239258
test loss item: 0.37671875953674316
test loss item: 0.21774739027023315
test loss item: 0.4930110275745392
test loss item: 0.5145771503448486
test loss item: 0.8170994520187378
test loss item: 0.5323832035064697
test loss item: 0.3755050599575043
test loss item: 0.3215354382991791
test loss item: 0.586215615272522
test loss item: 0.8404274582862854
test loss item: 0.43621647357940674
test loss item: 0.15906023979187012
test loss item: 0.3023934066295624
test loss item: 0.746951162815094
test loss item: 0.38614389300346375
test loss item: 1.0610077381134033
test loss item: 0.7701499462127686
test loss item: 0.38117310404777527
test loss item: 0.29442596435546875
test loss item: 0.2664894163608551
test loss item: 0.5648738741874695
test loss item: 0.24399596452713013
test loss item: 0.30769866704940796
test loss item: 0.3194271922111511
test loss item: 1.009702444076538
test loss item: 0.784938633441925
test loss item: 0.37999722361564636
test loss item: 0.3221990764141083
test loss item: 0.6855090856552124
test loss item: 0.46509021520614624
test loss item: 0.06657300889492035
test loss item: 1.2505019903182983
test loss item: 0.42763635516166687
test loss item: 0.5072425603866577
test loss item: 0.18938571214675903
test loss item: 0.20644332468509674
test loss item: 0.21974895894527435
test loss item: 1.7551076412200928
test loss item: 0.591159462928772
test loss item: 0.28817442059516907
test loss item: 0.10338117927312851
test loss item: 1.1441020965576172
test loss item: 1.0864917039871216
test loss item: 1.176656723022461
test loss item: 0.2958366274833679
test loss item: 0.2817167341709137
test loss item: 0.0991017296910286
test loss item: 0.07821116596460342
test loss item: 0.2024534046649933
Epoch [22/50], Training Loss: 0.5639, Testing Loss: 0.5343
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 23/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5025433897972107
1
train loss item: 1.4895392656326294
2
train loss item: 0.2792688012123108
3
train loss item: 0.6837813258171082
4
train loss item: 0.44642385840415955
5
train loss item: 0.3925798237323761
6
train loss item: 0.316100537776947
7
train loss item: 0.9538612961769104
8
train loss item: 0.15507997572422028
9
train loss item: 0.3365848958492279
10
train loss item: 0.42684558033943176
11
train loss item: 0.3192255198955536
12
train loss item: 0.11380600184202194
13
train loss item: 0.5368900895118713
14
train loss item: 0.2642548084259033
15
train loss item: 0.7500891089439392
16
train loss item: 0.054296039044857025
17
train loss item: 0.36350002884864807
18
train loss item: 0.41208288073539734
19
train loss item: 0.3238029479980469
20
train loss item: 0.2613484859466553
21
train loss item: 0.15294422209262848
22
train loss item: 1.2138088941574097
23
train loss item: 1.0552259683609009
24
train loss item: 0.7233902812004089
25
train loss item: 0.18802997469902039
26
train loss item: 0.22360406816005707
27
train loss item: 0.2796221077442169
28
train loss item: 0.050927743315696716
29
train loss item: 0.9332760572433472
30
train loss item: 2.5911200046539307
31
train loss item: 0.6684035062789917
32
train loss item: 0.10913759469985962
33
train loss item: 0.5047118663787842
34
train loss item: 0.11367769539356232
35
train loss item: 2.638807773590088
36
train loss item: 0.550945520401001
37
train loss item: 0.508276104927063
38
train loss item: 0.5199576616287231
39
train loss item: 0.282545268535614
40
train loss item: 0.17452472448349
41
train loss item: 0.33015725016593933
42
train loss item: 0.3329906463623047
43
train loss item: 0.22522395849227905
44
train loss item: 0.7495964169502258
45
train loss item: 0.14995554089546204
46
train loss item: 0.141484335064888
47
train loss item: 0.458052396774292
48
train loss item: 0.27677279710769653
49
train loss item: 0.1736694723367691
50
train loss item: 0.3814779818058014
51
train loss item: 1.1117877960205078
52
train loss item: 0.07173114269971848
53
train loss item: 0.1825849562883377
54
train loss item: 2.4986135959625244
55
train loss item: 0.2589278817176819
56
train loss item: 0.3598337471485138
57
train loss item: 0.277994304895401
58
train loss item: 0.19128799438476562
59
train loss item: 0.11751332134008408
60
train loss item: 1.1118957996368408
61
train loss item: 2.41892147064209
62
train loss item: 0.2689664661884308
63
train loss item: 0.45509764552116394
64
train loss item: 0.19682975113391876
65
train loss item: 0.7358296513557434
66
train loss item: 0.4584414064884186
67
train loss item: 0.24474094808101654
68
train loss item: 0.39291033148765564
69
train loss item: 0.43308064341545105
70
train loss item: 0.32475972175598145
71
train loss item: 0.13667315244674683
72
train loss item: 0.21780051290988922
73
train loss item: 0.3687688708305359
74
train loss item: 0.06563475728034973
75
train loss item: 0.1236976608633995
76
train loss item: 1.0552749633789062
77
train loss item: 1.5318145751953125
78
train loss item: 0.059605538845062256
79
train loss item: 0.31977713108062744
80
train loss item: 0.1268244832754135
81
train loss item: 0.21656116843223572
82
train loss item: 0.23432625830173492
83
train loss item: 0.8106464147567749
84
train loss item: 0.45711275935173035
85
train loss item: 0.7488872408866882
86
train loss item: 4.59924840927124
87
train loss item: 0.19935233891010284
88
train loss item: 0.4421118497848511
epoch train loss: 0.5607875186238396
testing phase
test loss item: 0.43088212609291077
test loss item: 0.1018301472067833
test loss item: 0.7087657451629639
test loss item: 0.48783206939697266
test loss item: 0.3032066822052002
test loss item: 0.15311981737613678
test loss item: 2.2229528427124023
test loss item: 0.5595898628234863
test loss item: 0.5015149116516113
test loss item: 0.5134168863296509
test loss item: 1.1356523036956787
test loss item: 0.5667547583580017
test loss item: 0.22958478331565857
test loss item: 0.43810173869132996
test loss item: 0.2081134170293808
test loss item: 0.07240061461925507
test loss item: 0.3508926331996918
test loss item: 0.5996566414833069
test loss item: 0.7783116102218628
test loss item: 0.358143150806427
test loss item: 0.9751555323600769
test loss item: 0.6029917597770691
test loss item: 0.4043584167957306
test loss item: 0.21050530672073364
test loss item: 0.2734123468399048
test loss item: 0.2841208875179291
test loss item: 0.4649636745452881
test loss item: 0.23838096857070923
test loss item: 0.43366214632987976
test loss item: 0.44393637776374817
test loss item: 0.9882838129997253
test loss item: 0.06869453191757202
test loss item: 0.17776769399642944
test loss item: 1.1296557188034058
test loss item: 0.5532603859901428
test loss item: 0.5161473155021667
test loss item: 0.989274263381958
test loss item: 1.7283300161361694
test loss item: 0.7426361441612244
test loss item: 0.34414127469062805
test loss item: 0.37381622195243835
test loss item: 0.2139088213443756
test loss item: 0.5297205448150635
test loss item: 0.4589562714099884
test loss item: 0.827484667301178
test loss item: 0.5313152074813843
test loss item: 0.37369731068611145
test loss item: 0.3147023916244507
test loss item: 0.5921560525894165
test loss item: 0.8437741994857788
test loss item: 0.44754427671432495
test loss item: 0.1606222689151764
test loss item: 0.30646151304244995
test loss item: 0.6466403603553772
test loss item: 0.3954705595970154
test loss item: 1.0719540119171143
test loss item: 0.737325131893158
test loss item: 0.3929901123046875
test loss item: 0.29728949069976807
test loss item: 0.27265116572380066
test loss item: 0.5712624788284302
test loss item: 0.24507635831832886
test loss item: 0.31497448682785034
test loss item: 0.3187965452671051
test loss item: 1.01181960105896
test loss item: 0.6950752139091492
test loss item: 0.3796563446521759
test loss item: 0.31994879245758057
test loss item: 0.7047215104103088
test loss item: 0.4597194790840149
test loss item: 0.0671868771314621
test loss item: 1.2308385372161865
test loss item: 0.4235553443431854
test loss item: 0.5051237940788269
test loss item: 0.1887146532535553
test loss item: 0.20481246709823608
test loss item: 0.21092002093791962
test loss item: 1.7537840604782104
test loss item: 0.5833038091659546
test loss item: 0.2960876226425171
test loss item: 0.10368035733699799
test loss item: 1.1358956098556519
test loss item: 1.0824956893920898
test loss item: 1.1841439008712769
test loss item: 0.28890278935432434
test loss item: 0.28207406401634216
test loss item: 0.1014472246170044
test loss item: 0.08162405341863632
test loss item: 0.19296391308307648
Epoch [23/50], Training Loss: 0.5608, Testing Loss: 0.5283
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 24/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5069891214370728
1
train loss item: 1.472987174987793
2
train loss item: 0.2736656963825226
3
train loss item: 0.6814820170402527
4
train loss item: 0.4499583840370178
5
train loss item: 0.3893507421016693
6
train loss item: 0.3155139684677124
7
train loss item: 0.9481762051582336
8
train loss item: 0.15669190883636475
9
train loss item: 0.32850053906440735
10
train loss item: 0.42644819617271423
11
train loss item: 0.3213672637939453
12
train loss item: 0.1127266138792038
13
train loss item: 0.5386587977409363
14
train loss item: 0.26889681816101074
15
train loss item: 0.7335904240608215
16
train loss item: 0.05350017547607422
17
train loss item: 0.3641468286514282
18
train loss item: 0.41165825724601746
19
train loss item: 0.3210561275482178
20
train loss item: 0.26019755005836487
21
train loss item: 0.1512884944677353
22
train loss item: 1.193786382675171
23
train loss item: 1.0526574850082397
24
train loss item: 0.7078704833984375
25
train loss item: 0.1908891499042511
26
train loss item: 0.22073636949062347
27
train loss item: 0.28028690814971924
28
train loss item: 0.050270311534404755
29
train loss item: 0.9115948677062988
30
train loss item: 2.571614980697632
31
train loss item: 0.6706039905548096
32
train loss item: 0.10624058544635773
33
train loss item: 0.5086815357208252
34
train loss item: 0.10981351882219315
35
train loss item: 2.6269619464874268
36
train loss item: 0.5533453226089478
37
train loss item: 0.5086363554000854
38
train loss item: 0.5256958603858948
39
train loss item: 0.28234240412712097
40
train loss item: 0.16958700120449066
41
train loss item: 0.3267822861671448
42
train loss item: 0.3293718993663788
43
train loss item: 0.2243979126214981
44
train loss item: 0.7504889369010925
45
train loss item: 0.15662389993667603
46
train loss item: 0.14044632017612457
47
train loss item: 0.45141977071762085
48
train loss item: 0.2755424976348877
49
train loss item: 0.17854037880897522
50
train loss item: 0.37828147411346436
51
train loss item: 1.0898030996322632
52
train loss item: 0.07423965632915497
53
train loss item: 0.18487226963043213
54
train loss item: 2.4871203899383545
55
train loss item: 0.26148703694343567
56
train loss item: 0.35827144980430603
57
train loss item: 0.27388888597488403
58
train loss item: 0.19057033956050873
59
train loss item: 0.1138700619339943
60
train loss item: 1.0923963785171509
61
train loss item: 2.4096574783325195
62
train loss item: 0.26633119583129883
63
train loss item: 0.44996097683906555
64
train loss item: 0.19627809524536133
65
train loss item: 0.7300354838371277
66
train loss item: 0.4654296934604645
67
train loss item: 0.24470533430576324
68
train loss item: 0.39019596576690674
69
train loss item: 0.4288589358329773
70
train loss item: 0.3223215639591217
71
train loss item: 0.13600070774555206
72
train loss item: 0.21940618753433228
73
train loss item: 0.36403852701187134
74
train loss item: 0.06184074282646179
75
train loss item: 0.12079679220914841
76
train loss item: 1.0512524843215942
77
train loss item: 1.5109940767288208
78
train loss item: 0.06297626346349716
79
train loss item: 0.31823524832725525
80
train loss item: 0.13503442704677582
81
train loss item: 0.2140217423439026
82
train loss item: 0.2386140525341034
83
train loss item: 0.7945712804794312
84
train loss item: 0.4637037217617035
85
train loss item: 0.7386285066604614
86
train loss item: 4.584137916564941
87
train loss item: 0.19880858063697815
88
train loss item: 0.43747857213020325
epoch train loss: 0.5575415310397577
testing phase
test loss item: 0.399794340133667
test loss item: 0.10290473699569702
test loss item: 0.7134826183319092
test loss item: 0.42236387729644775
test loss item: 0.30349770188331604
test loss item: 0.15162606537342072
test loss item: 2.1721320152282715
test loss item: 0.5411580204963684
test loss item: 0.4524209201335907
test loss item: 0.5165863037109375
test loss item: 1.1159400939941406
test loss item: 0.48116400837898254
test loss item: 0.22936657071113586
test loss item: 0.4335981011390686
test loss item: 0.20948737859725952
test loss item: 0.0749421939253807
test loss item: 0.34931644797325134
test loss item: 0.6045266389846802
test loss item: 0.7665690183639526
test loss item: 0.351969450712204
test loss item: 0.9829308390617371
test loss item: 0.5480042695999146
test loss item: 0.3990035057067871
test loss item: 0.20964646339416504
test loss item: 0.27478933334350586
test loss item: 0.28326302766799927
test loss item: 0.45905324816703796
test loss item: 0.2373386025428772
test loss item: 0.43350037932395935
test loss item: 0.4460921287536621
test loss item: 0.9802089929580688
test loss item: 0.07015100866556168
test loss item: 0.17769594490528107
test loss item: 1.1297619342803955
test loss item: 0.5579448342323303
test loss item: 0.5152299404144287
test loss item: 0.9767887592315674
test loss item: 1.7344236373901367
test loss item: 0.7158021926879883
test loss item: 0.34054356813430786
test loss item: 0.37036946415901184
test loss item: 0.21272197365760803
test loss item: 0.6053506135940552
test loss item: 0.39992499351501465
test loss item: 0.8343489170074463
test loss item: 0.5270500779151917
test loss item: 0.3755948543548584
test loss item: 0.3080311119556427
test loss item: 0.5936556458473206
test loss item: 0.8426950573921204
test loss item: 0.4538775384426117
test loss item: 0.16094912588596344
test loss item: 0.30909252166748047
test loss item: 0.5351572036743164
test loss item: 0.4010604918003082
test loss item: 1.0802440643310547
test loss item: 0.7024268507957458
test loss item: 0.3985937833786011
test loss item: 0.29829418659210205
test loss item: 0.2757585346698761
test loss item: 0.5746611952781677
test loss item: 0.2426249384880066
test loss item: 0.30869996547698975
test loss item: 0.3164166212081909
test loss item: 1.0096838474273682
test loss item: 0.5985195636749268
test loss item: 0.376931369304657
test loss item: 0.31697678565979004
test loss item: 0.7348189353942871
test loss item: 0.44977498054504395
test loss item: 0.0690079852938652
test loss item: 1.2008929252624512
test loss item: 0.42129752039909363
test loss item: 0.4945860207080841
test loss item: 0.18889473378658295
test loss item: 0.20465300977230072
test loss item: 0.20899447798728943
test loss item: 1.7508671283721924
test loss item: 0.5765234231948853
test loss item: 0.2908296585083008
test loss item: 0.10588743537664413
test loss item: 1.1215146780014038
test loss item: 1.0717685222625732
test loss item: 1.1872882843017578
test loss item: 0.28144371509552
test loss item: 0.2820064425468445
test loss item: 0.1038476750254631
test loss item: 0.08523834496736526
test loss item: 0.18760983645915985
Epoch [24/50], Training Loss: 0.5575, Testing Loss: 0.5204
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 25/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.510908305644989
1
train loss item: 1.4538071155548096
2
train loss item: 0.26882582902908325
3
train loss item: 0.6761133074760437
4
train loss item: 0.4602917730808258
5
train loss item: 0.388760507106781
6
train loss item: 0.31285834312438965
7
train loss item: 0.9411873817443848
8
train loss item: 0.15710850059986115
9
train loss item: 0.32163694500923157
10
train loss item: 0.427827388048172
11
train loss item: 0.32860180735588074
12
train loss item: 0.11113499104976654
13
train loss item: 0.5398615598678589
14
train loss item: 0.2724302411079407
15
train loss item: 0.7198497653007507
16
train loss item: 0.05369811877608299
17
train loss item: 0.36168143153190613
18
train loss item: 0.4112855792045593
19
train loss item: 0.3203185796737671
20
train loss item: 0.25911465287208557
21
train loss item: 0.1559973657131195
22
train loss item: 1.1683529615402222
23
train loss item: 1.0505894422531128
24
train loss item: 0.6918585896492004
25
train loss item: 0.19331547617912292
26
train loss item: 0.2198781967163086
27
train loss item: 0.28048813343048096
28
train loss item: 0.05038018152117729
29
train loss item: 0.8860724568367004
30
train loss item: 2.5501387119293213
31
train loss item: 0.6769306659698486
32
train loss item: 0.10323582589626312
33
train loss item: 0.5094811916351318
34
train loss item: 0.11049783229827881
35
train loss item: 2.612727165222168
36
train loss item: 0.5545278787612915
37
train loss item: 0.517039954662323
38
train loss item: 0.5391358733177185
39
train loss item: 0.28237655758857727
40
train loss item: 0.16637484729290009
41
train loss item: 0.32525646686553955
42
train loss item: 0.3291586637496948
43
train loss item: 0.2223048359155655
44
train loss item: 0.749719500541687
45
train loss item: 0.16071482002735138
46
train loss item: 0.1410825252532959
47
train loss item: 0.4428146779537201
48
train loss item: 0.27360108494758606
49
train loss item: 0.18271349370479584
50
train loss item: 0.37622570991516113
51
train loss item: 1.0666922330856323
52
train loss item: 0.07578190416097641
53
train loss item: 0.1852126568555832
54
train loss item: 2.473775863647461
55
train loss item: 0.26127442717552185
56
train loss item: 0.3579990863800049
57
train loss item: 0.27532583475112915
58
train loss item: 0.18946987390518188
59
train loss item: 0.11158444732427597
60
train loss item: 1.0742933750152588
61
train loss item: 2.4003870487213135
62
train loss item: 0.264935165643692
63
train loss item: 0.44748654961586
64
train loss item: 0.1946765035390854
65
train loss item: 0.7304058074951172
66
train loss item: 0.4757687747478485
67
train loss item: 0.2441769540309906
68
train loss item: 0.38334786891937256
69
train loss item: 0.42567235231399536
70
train loss item: 0.320269376039505
71
train loss item: 0.13583946228027344
72
train loss item: 0.21943554282188416
73
train loss item: 0.361219584941864
74
train loss item: 0.05864781513810158
75
train loss item: 0.11589445173740387
76
train loss item: 1.0459860563278198
77
train loss item: 1.4884114265441895
78
train loss item: 0.06686241179704666
79
train loss item: 0.3207663595676422
80
train loss item: 0.13958582282066345
81
train loss item: 0.21193836629390717
82
train loss item: 0.24113690853118896
83
train loss item: 0.7762879729270935
84
train loss item: 0.4737851321697235
85
train loss item: 0.7278509140014648
86
train loss item: 4.566713809967041
87
train loss item: 0.1963045448064804
88
train loss item: 0.43592941761016846
epoch train loss: 0.5546227563381865
testing phase
test loss item: 0.34138548374176025
test loss item: 0.10362237691879272
test loss item: 0.7100619077682495
test loss item: 0.3580130636692047
test loss item: 0.30184629559516907
test loss item: 0.1508852243423462
test loss item: 2.11971378326416
test loss item: 0.5230593681335449
test loss item: 0.384980708360672
test loss item: 0.5130731463432312
test loss item: 1.0863734483718872
test loss item: 0.39203134179115295
test loss item: 0.22658802568912506
test loss item: 0.42887797951698303
test loss item: 0.2091759443283081
test loss item: 0.07780370861291885
test loss item: 0.348895788192749
test loss item: 0.6019103527069092
test loss item: 0.7548049688339233
test loss item: 0.3465043604373932
test loss item: 0.9799205660820007
test loss item: 0.49520379304885864
test loss item: 0.38417848944664
test loss item: 0.20892967283725739
test loss item: 0.27502530813217163
test loss item: 0.28095993399620056
test loss item: 0.4433934986591339
test loss item: 0.23574364185333252
test loss item: 0.4310056269168854
test loss item: 0.4437244236469269
test loss item: 0.9662551283836365
test loss item: 0.07294796407222748
test loss item: 0.1784401535987854
test loss item: 1.0345457792282104
test loss item: 0.5560032725334167
test loss item: 0.5075026154518127
test loss item: 0.9615284204483032
test loss item: 1.7274532318115234
test loss item: 0.6877362728118896
test loss item: 0.3369050621986389
test loss item: 0.36749330163002014
test loss item: 0.21409347653388977
test loss item: 0.6018284559249878
test loss item: 0.3428039252758026
test loss item: 0.8319681286811829
test loss item: 0.5237234830856323
test loss item: 0.375085711479187
test loss item: 0.3023216128349304
test loss item: 0.5883527398109436
test loss item: 0.8346801400184631
test loss item: 0.4506151080131531
test loss item: 0.15940028429031372
test loss item: 0.3085867166519165
test loss item: 0.41688111424446106
test loss item: 0.39967745542526245
test loss item: 1.076531171798706
test loss item: 0.6590911746025085
test loss item: 0.3968522250652313
test loss item: 0.29732850193977356
test loss item: 0.27371424436569214
test loss item: 0.5692604184150696
test loss item: 0.2414083480834961
test loss item: 0.2930068373680115
test loss item: 0.31290650367736816
test loss item: 1.0014917850494385
test loss item: 0.5021211504936218
test loss item: 0.37358012795448303
test loss item: 0.31417107582092285
test loss item: 0.7254956364631653
test loss item: 0.4377981424331665
test loss item: 0.07218365371227264
test loss item: 1.1715697050094604
test loss item: 0.4172004461288452
test loss item: 0.4803619980812073
test loss item: 0.1903037428855896
test loss item: 0.2058383971452713
test loss item: 0.2077062577009201
test loss item: 1.735943078994751
test loss item: 0.5696591138839722
test loss item: 0.2752660810947418
test loss item: 0.10916607081890106
test loss item: 1.1026628017425537
test loss item: 1.055243968963623
test loss item: 1.1797423362731934
test loss item: 0.273514986038208
test loss item: 0.28200191259384155
test loss item: 0.10745050013065338
test loss item: 0.08942808955907822
test loss item: 0.18711458146572113
Epoch [25/50], Training Loss: 0.5546, Testing Loss: 0.5066
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 26/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5135985016822815
1
train loss item: 1.4353488683700562
2
train loss item: 0.2654285430908203
3
train loss item: 0.6686073541641235
4
train loss item: 0.47430726885795593
5
train loss item: 0.3896835446357727
6
train loss item: 0.31092751026153564
7
train loss item: 0.9336065649986267
8
train loss item: 0.15615059435367584
9
train loss item: 0.3187076151371002
10
train loss item: 0.42868611216545105
11
train loss item: 0.3366226553916931
12
train loss item: 0.1093873530626297
13
train loss item: 0.5384936928749084
14
train loss item: 0.27244964241981506
15
train loss item: 0.7073487043380737
16
train loss item: 0.054566409438848495
17
train loss item: 0.3590944707393646
18
train loss item: 0.412616491317749
19
train loss item: 0.321601539850235
20
train loss item: 0.2604770064353943
21
train loss item: 0.1609206199645996
22
train loss item: 1.1485322713851929
23
train loss item: 1.0461331605911255
24
train loss item: 0.6814826130867004
25
train loss item: 0.19368652999401093
26
train loss item: 0.22034141421318054
27
train loss item: 0.27985668182373047
28
train loss item: 0.05089616775512695
29
train loss item: 0.8617539405822754
30
train loss item: 2.5281503200531006
31
train loss item: 0.6836369037628174
32
train loss item: 0.10042034089565277
33
train loss item: 0.5045998692512512
34
train loss item: 0.11800019443035126
35
train loss item: 2.5970587730407715
36
train loss item: 0.5557015538215637
37
train loss item: 0.5294389128684998
38
train loss item: 0.5553178787231445
39
train loss item: 0.28309935331344604
40
train loss item: 0.1641288697719574
41
train loss item: 0.3247651755809784
42
train loss item: 0.33110180497169495
43
train loss item: 0.21924415230751038
44
train loss item: 0.7455812692642212
45
train loss item: 0.1604742407798767
46
train loss item: 0.14061975479125977
47
train loss item: 0.43483105301856995
48
train loss item: 0.27141353487968445
49
train loss item: 0.1833670735359192
50
train loss item: 0.37648317217826843
51
train loss item: 1.044715404510498
52
train loss item: 0.07509313523769379
53
train loss item: 0.18240191042423248
54
train loss item: 2.459392786026001
55
train loss item: 0.25851553678512573
56
train loss item: 0.3601689040660858
57
train loss item: 0.2779959738254547
58
train loss item: 0.18831102550029755
59
train loss item: 0.10872793942689896
60
train loss item: 1.056222915649414
61
train loss item: 2.389415740966797
62
train loss item: 0.2643803656101227
63
train loss item: 0.4480155110359192
64
train loss item: 0.1908109486103058
65
train loss item: 0.7377299070358276
66
train loss item: 0.4868484139442444
67
train loss item: 0.2425035834312439
68
train loss item: 0.3771652579307556
69
train loss item: 0.4259255826473236
70
train loss item: 0.3188125193119049
71
train loss item: 0.13574278354644775
72
train loss item: 0.21713963150978088
73
train loss item: 0.36122196912765503
74
train loss item: 0.056019142270088196
75
train loss item: 0.10941101610660553
76
train loss item: 1.0390759706497192
77
train loss item: 1.46739661693573
78
train loss item: 0.0701322928071022
79
train loss item: 0.3268003761768341
80
train loss item: 0.13842131197452545
81
train loss item: 0.21104112267494202
82
train loss item: 0.24008610844612122
83
train loss item: 0.7584925889968872
84
train loss item: 0.48385143280029297
85
train loss item: 0.718193531036377
86
train loss item: 4.548459529876709
87
train loss item: 0.19126245379447937
88
train loss item: 0.4388958811759949
epoch train loss: 0.5519499456865734
testing phase
test loss item: 0.2720414698123932
test loss item: 0.10089975595474243
test loss item: 0.702284038066864
test loss item: 0.306037575006485
test loss item: 0.2993154525756836
test loss item: 0.14912296831607819
test loss item: 2.080472707748413
test loss item: 0.5145322680473328
test loss item: 0.31937113404273987
test loss item: 0.5059956312179565
test loss item: 1.056520700454712
test loss item: 0.3090948760509491
test loss item: 0.22329770028591156
test loss item: 0.4248116910457611
test loss item: 0.20662100613117218
test loss item: 0.07442167401313782
test loss item: 0.3509506583213806
test loss item: 0.5955469608306885
test loss item: 0.74853515625
test loss item: 0.34517306089401245
test loss item: 0.9687163233757019
test loss item: 0.45495232939720154
test loss item: 0.36713266372680664
test loss item: 0.2078072875738144
test loss item: 0.27424073219299316
test loss item: 0.2789526879787445
test loss item: 0.4260675311088562
test loss item: 0.23425443470478058
test loss item: 0.4273700714111328
test loss item: 0.4398106336593628
test loss item: 0.9506693482398987
test loss item: 0.07080015540122986
test loss item: 0.1779305338859558
test loss item: 0.8780891299247742
test loss item: 0.5499762296676636
test loss item: 0.4978022575378418
test loss item: 0.9497600793838501
test loss item: 1.7108519077301025
test loss item: 0.6644770503044128
test loss item: 0.3338136076927185
test loss item: 0.3657970130443573
test loss item: 0.21813635528087616
test loss item: 0.5048087239265442
test loss item: 0.2978277802467346
test loss item: 0.8217728137969971
test loss item: 0.5248779654502869
test loss item: 0.3736446499824524
test loss item: 0.30066874623298645
test loss item: 0.5802901387214661
test loss item: 0.8246901035308838
test loss item: 0.4404069483280182
test loss item: 0.15656021237373352
test loss item: 0.30601271986961365
test loss item: 0.30716025829315186
test loss item: 0.39366620779037476
test loss item: 1.06565523147583
test loss item: 0.6235416531562805
test loss item: 0.3897787630558014
test loss item: 0.295704185962677
test loss item: 0.26803866028785706
test loss item: 0.5596581101417542
test loss item: 0.2437378615140915
test loss item: 0.2749289274215698
test loss item: 0.3096455931663513
test loss item: 0.990653395652771
test loss item: 0.42269888520240784
test loss item: 0.3724163770675659
test loss item: 0.3122694790363312
test loss item: 0.6776674389839172
test loss item: 0.42952078580856323
test loss item: 0.07031752169132233
test loss item: 1.1523845195770264
test loss item: 0.4138551652431488
test loss item: 0.46858689188957214
test loss item: 0.19242577254772186
test loss item: 0.20730803906917572
test loss item: 0.20561693608760834
test loss item: 1.7127189636230469
test loss item: 0.5649290084838867
test loss item: 0.25564661622047424
test loss item: 0.10763359814882278
test loss item: 1.0859296321868896
test loss item: 1.0397934913635254
test loss item: 1.1648622751235962
test loss item: 0.2673115134239197
test loss item: 0.28379446268081665
test loss item: 0.10412988811731339
test loss item: 0.08496686816215515
test loss item: 0.19143234193325043
Epoch [26/50], Training Loss: 0.5519, Testing Loss: 0.4907
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 27/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5124244689941406
1
train loss item: 1.4207640886306763
2
train loss item: 0.2630388140678406
3
train loss item: 0.6603029370307922
4
train loss item: 0.483570396900177
5
train loss item: 0.3892080783843994
6
train loss item: 0.3108215928077698
7
train loss item: 0.9262811541557312
8
train loss item: 0.15404154360294342
9
train loss item: 0.3181103467941284
10
train loss item: 0.42734768986701965
11
train loss item: 0.34018704295158386
12
train loss item: 0.1078023687005043
13
train loss item: 0.5337966084480286
14
train loss item: 0.26854050159454346
15
train loss item: 0.7001413106918335
16
train loss item: 0.055045321583747864
17
train loss item: 0.35796311497688293
18
train loss item: 0.41464391350746155
19
train loss item: 0.32293540239334106
20
train loss item: 0.2629636228084564
21
train loss item: 0.1598563939332962
22
train loss item: 1.1382725238800049
23
train loss item: 1.0386184453964233
24
train loss item: 0.6795700192451477
25
train loss item: 0.1912243813276291
26
train loss item: 0.21970747411251068
27
train loss item: 0.2777409851551056
28
train loss item: 0.050895966589450836
29
train loss item: 0.8441814184188843
30
train loss item: 2.507871627807617
31
train loss item: 0.6854121685028076
32
train loss item: 0.09832413494586945
33
train loss item: 0.49600228667259216
34
train loss item: 0.1328418254852295
35
train loss item: 2.581582546234131
36
train loss item: 0.5556140542030334
37
train loss item: 0.5392529964447021
38
train loss item: 0.5667382478713989
39
train loss item: 0.2832481563091278
40
train loss item: 0.16297608613967896
41
train loss item: 0.322945237159729
42
train loss item: 0.33354029059410095
43
train loss item: 0.21597422659397125
44
train loss item: 0.7385210394859314
45
train loss item: 0.15649689733982086
46
train loss item: 0.13770882785320282
47
train loss item: 0.4291979670524597
48
train loss item: 0.26950955390930176
49
train loss item: 0.18002767860889435
50
train loss item: 0.37724533677101135
51
train loss item: 1.027608036994934
52
train loss item: 0.0720425546169281
53
train loss item: 0.17746736109256744
54
train loss item: 2.4451332092285156
55
train loss item: 0.2550651431083679
56
train loss item: 0.36229249835014343
57
train loss item: 0.27798590064048767
58
train loss item: 0.18703097105026245
59
train loss item: 0.1048634946346283
60
train loss item: 1.0387858152389526
61
train loss item: 2.374141216278076
62
train loss item: 0.2635475993156433
63
train loss item: 0.4504494071006775
64
train loss item: 0.18568523228168488
65
train loss item: 0.7454497218132019
66
train loss item: 0.4935740828514099
67
train loss item: 0.23936901986598969
68
train loss item: 0.3738133907318115
69
train loss item: 0.42838922142982483
70
train loss item: 0.3168858587741852
71
train loss item: 0.13593968749046326
72
train loss item: 0.21298567950725555
73
train loss item: 0.3621470034122467
74
train loss item: 0.054736025631427765
75
train loss item: 0.10294482111930847
76
train loss item: 1.0316238403320312
77
train loss item: 1.4524980783462524
78
train loss item: 0.07154962420463562
79
train loss item: 0.3327304720878601
80
train loss item: 0.1337602138519287
81
train loss item: 0.21110697090625763
82
train loss item: 0.2356177568435669
83
train loss item: 0.7456235289573669
84
train loss item: 0.4897085130214691
85
train loss item: 0.7114600539207458
86
train loss item: 4.530601978302002
87
train loss item: 0.18541114032268524
88
train loss item: 0.4437439739704132
epoch train loss: 0.5490426765231604
testing phase
test loss item: 0.2279251366853714
test loss item: 0.09817498922348022
test loss item: 0.694449782371521
test loss item: 0.27552512288093567
test loss item: 0.29685840010643005
test loss item: 0.14800028502941132
test loss item: 2.062439441680908
test loss item: 0.5167209506034851
test loss item: 0.2790856659412384
test loss item: 0.49877816438674927
test loss item: 1.037927508354187
test loss item: 0.2399081438779831
test loss item: 0.2206868976354599
test loss item: 0.42270582914352417
test loss item: 0.20363283157348633
test loss item: 0.0710630714893341
test loss item: 0.3548815846443176
test loss item: 0.5880479216575623
test loss item: 0.7488152980804443
test loss item: 0.3484600782394409
test loss item: 0.9535231590270996
test loss item: 0.43208834528923035
test loss item: 0.3523828387260437
test loss item: 0.20826567709445953
test loss item: 0.2733401656150818
test loss item: 0.2781636118888855
test loss item: 0.41978612542152405
test loss item: 0.23296986520290375
test loss item: 0.42433488368988037
test loss item: 0.43617159128189087
test loss item: 0.9403409957885742
test loss item: 0.06878289580345154
test loss item: 0.17833779752254486
test loss item: 0.7583848237991333
test loss item: 0.5429887175559998
test loss item: 0.4910443127155304
test loss item: 0.9444524049758911
test loss item: 1.6967277526855469
test loss item: 0.6497567892074585
test loss item: 0.33261850476264954
test loss item: 0.3659171164035797
test loss item: 0.2238679975271225
test loss item: 0.440824031829834
test loss item: 0.2719900608062744
test loss item: 0.8081209063529968
test loss item: 0.5303004384040833
test loss item: 0.3720043897628784
test loss item: 0.3036477267742157
test loss item: 0.572812020778656
test loss item: 0.8178346753120422
test loss item: 0.42622655630111694
test loss item: 0.15487496554851532
test loss item: 0.30282846093177795
test loss item: 0.22250419855117798
test loss item: 0.38519370555877686
test loss item: 1.0540318489074707
test loss item: 0.6067968010902405
test loss item: 0.3791729509830475
test loss item: 0.29500246047973633
test loss item: 0.2609254717826843
test loss item: 0.5495963096618652
test loss item: 0.2499013990163803
test loss item: 0.2620150148868561
test loss item: 0.30759692192077637
test loss item: 0.9829292297363281
test loss item: 0.3736351430416107
test loss item: 0.3740551173686981
test loss item: 0.3119608163833618
test loss item: 0.6459168791770935
test loss item: 0.42749112844467163
test loss item: 0.06901013106107712
test loss item: 1.1464972496032715
test loss item: 0.41175609827041626
test loss item: 0.4639817476272583
test loss item: 0.19545800983905792
test loss item: 0.20995379984378815
test loss item: 0.205173522233963
test loss item: 1.6952179670333862
test loss item: 0.5640373229980469
test loss item: 0.24014273285865784
test loss item: 0.1053803488612175
test loss item: 1.0777007341384888
test loss item: 1.0300509929656982
test loss item: 1.1523715257644653
test loss item: 0.26428547501564026
test loss item: 0.2867499589920044
test loss item: 0.10015963762998581
test loss item: 0.08052060008049011
test loss item: 0.1973714977502823
Epoch [27/50], Training Loss: 0.5490, Testing Loss: 0.4800
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 28/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5051310658454895
1
train loss item: 1.410439372062683
2
train loss item: 0.2608356177806854
3
train loss item: 0.6529178619384766
4
train loss item: 0.4816891551017761
5
train loss item: 0.38614532351493835
6
train loss item: 0.31233322620391846
7
train loss item: 0.9197772741317749
8
train loss item: 0.15196137130260468
9
train loss item: 0.31741851568222046
10
train loss item: 0.4246583580970764
11
train loss item: 0.3376149833202362
12
train loss item: 0.1065310686826706
13
train loss item: 0.5274086594581604
14
train loss item: 0.2627201974391937
15
train loss item: 0.6959718465805054
16
train loss item: 0.054259173572063446
17
train loss item: 0.3582419157028198
18
train loss item: 0.4151594042778015
19
train loss item: 0.32298576831817627
20
train loss item: 0.26416200399398804
21
train loss item: 0.15129713714122772
22
train loss item: 1.1341325044631958
23
train loss item: 1.0302324295043945
24
train loss item: 0.6842151284217834
25
train loss item: 0.18673743307590485
26
train loss item: 0.2178790420293808
27
train loss item: 0.27508050203323364
28
train loss item: 0.04975968599319458
29
train loss item: 0.8356858491897583
30
train loss item: 2.491602659225464
31
train loss item: 0.6808386445045471
32
train loss item: 0.0974678248167038
33
train loss item: 0.48858511447906494
34
train loss item: 0.12441544234752655
35
train loss item: 2.5689308643341064
36
train loss item: 0.5534789562225342
37
train loss item: 0.5417615175247192
38
train loss item: 0.5693347454071045
39
train loss item: 0.28019312024116516
40
train loss item: 0.1631840318441391
41
train loss item: 0.31772327423095703
42
train loss item: 0.33572033047676086
43
train loss item: 0.21350902318954468
44
train loss item: 0.7301788330078125
45
train loss item: 0.15005925297737122
46
train loss item: 0.1334981471300125
47
train loss item: 0.426568865776062
48
train loss item: 0.268245130777359
49
train loss item: 0.17487883567810059
50
train loss item: 0.37647825479507446
51
train loss item: 1.017350673675537
52
train loss item: 0.06860186159610748
53
train loss item: 0.17288663983345032
54
train loss item: 2.433666467666626
55
train loss item: 0.2531728148460388
56
train loss item: 0.3608998954296112
57
train loss item: 0.2753833532333374
58
train loss item: 0.18580643832683563
59
train loss item: 0.10097905248403549
60
train loss item: 1.0240665674209595
61
train loss item: 2.360218048095703
62
train loss item: 0.261089563369751
63
train loss item: 0.4532482922077179
64
train loss item: 0.18154823780059814
65
train loss item: 0.7443352937698364
66
train loss item: 0.49422070384025574
67
train loss item: 0.23536503314971924
68
train loss item: 0.37198102474212646
69
train loss item: 0.42935141921043396
70
train loss item: 0.31713712215423584
71
train loss item: 0.1345798671245575
72
train loss item: 0.2094005048274994
73
train loss item: 0.36211228370666504
74
train loss item: 0.055672649294137955
75
train loss item: 0.09831811487674713
76
train loss item: 1.0260785818099976
77
train loss item: 1.4447141885757446
78
train loss item: 0.07015899568796158
79
train loss item: 0.33522990345954895
80
train loss item: 0.12731534242630005
81
train loss item: 0.21155717968940735
82
train loss item: 0.2299957275390625
83
train loss item: 0.7406117916107178
84
train loss item: 0.49044767022132874
85
train loss item: 0.7088740468025208
86
train loss item: 4.514196872711182
87
train loss item: 0.1811068207025528
88
train loss item: 0.4464043080806732
epoch train loss: 0.5454844729870223
testing phase
test loss item: 0.21559493243694305
test loss item: 0.09602852910757065
test loss item: 0.693695604801178
test loss item: 0.2686383128166199
test loss item: 0.2968144416809082
test loss item: 0.14693039655685425
test loss item: 2.0655736923217773
test loss item: 0.5238122940063477
test loss item: 0.26647478342056274
test loss item: 0.4964387118816376
test loss item: 1.0347517728805542
test loss item: 0.20537959039211273
test loss item: 0.2196090668439865
test loss item: 0.42416509985923767
test loss item: 0.20203377306461334
test loss item: 0.06643074750900269
test loss item: 0.35967305302619934
test loss item: 0.5856037735939026
test loss item: 0.7533619999885559
test loss item: 0.3563506007194519
test loss item: 0.9440110921859741
test loss item: 0.4274887442588806
test loss item: 0.3488982021808624
test loss item: 0.20978331565856934
test loss item: 0.2731524705886841
test loss item: 0.27923935651779175
test loss item: 0.422645628452301
test loss item: 0.2321058064699173
test loss item: 0.4242662787437439
test loss item: 0.4355952739715576
test loss item: 0.9404839873313904
test loss item: 0.06517168879508972
test loss item: 0.1790885329246521
test loss item: 0.7045953869819641
test loss item: 0.5406240820884705
test loss item: 0.49201130867004395
test loss item: 0.9459540843963623
test loss item: 1.6975160837173462
test loss item: 0.6464982032775879
test loss item: 0.3334414064884186
test loss item: 0.3675326704978943
test loss item: 0.2303498238325119
test loss item: 0.42869681119918823
test loss item: 0.26717397570610046
test loss item: 0.7982434630393982
test loss item: 0.5386258959770203
test loss item: 0.3728468418121338
test loss item: 0.31117022037506104
test loss item: 0.5712604522705078
test loss item: 0.8198198676109314
test loss item: 0.4153698980808258
test loss item: 0.1546057164669037
test loss item: 0.30122673511505127
test loss item: 0.1892787516117096
test loss item: 0.37980949878692627
test loss item: 1.05237877368927
test loss item: 0.6052302718162537
test loss item: 0.36957964301109314
test loss item: 0.2962040305137634
test loss item: 0.2555968761444092
test loss item: 0.5460312962532043
test loss item: 0.25714001059532166
test loss item: 0.26121869683265686
test loss item: 0.307461678981781
test loss item: 0.9836947917938232
test loss item: 0.36044761538505554
test loss item: 0.3791934549808502
test loss item: 0.3132188022136688
test loss item: 0.6352689862251282
test loss item: 0.43239545822143555
test loss item: 0.06628203392028809
test loss item: 1.1515370607376099
test loss item: 0.41412153840065
test loss item: 0.469331830739975
test loss item: 0.19840100407600403
test loss item: 0.2129029929637909
test loss item: 0.20619294047355652
test loss item: 1.6934586763381958
test loss item: 0.5690406560897827
test loss item: 0.23649750649929047
test loss item: 0.10004120320081711
test loss item: 1.0826138257980347
test loss item: 1.0298142433166504
test loss item: 1.1524568796157837
test loss item: 0.266273558139801
test loss item: 0.29012224078178406
test loss item: 0.09251603484153748
test loss item: 0.07281137257814407
test loss item: 0.20355799794197083
Epoch [28/50], Training Loss: 0.5455, Testing Loss: 0.4779
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Epoch 29/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.493114709854126
1
train loss item: 1.402592420578003
2
train loss item: 0.2600298225879669
3
train loss item: 0.6481642127037048
4
train loss item: 0.4716619849205017
5
train loss item: 0.3821987509727478
6
train loss item: 0.3148873448371887
7
train loss item: 0.9142255783081055
8
train loss item: 0.1507245898246765
9
train loss item: 0.31676408648490906
10
train loss item: 0.4232165813446045
11
train loss item: 0.3314163386821747
12
train loss item: 0.10539418458938599
13
train loss item: 0.5220233201980591
14
train loss item: 0.25760942697525024
15
train loss item: 0.7009552717208862
16
train loss item: 0.05208964645862579
17
train loss item: 0.3592614531517029
18
train loss item: 0.4134014844894409
19
train loss item: 0.32245051860809326
20
train loss item: 0.2637919485569
21
train loss item: 0.13928145170211792
22
train loss item: 1.128479242324829
23
train loss item: 1.02458655834198
24
train loss item: 0.6914876699447632
25
train loss item: 0.1818680763244629
26
train loss item: 0.21597640216350555
27
train loss item: 0.2732059955596924
28
train loss item: 0.04770491272211075
29
train loss item: 0.8348551392555237
30
train loss item: 2.478257179260254
31
train loss item: 0.6732803583145142
32
train loss item: 0.09741642326116562
33
train loss item: 0.48625877499580383
34
train loss item: 0.10893762856721878
35
train loss item: 2.557591676712036
36
train loss item: 0.5495901107788086
37
train loss item: 0.5362539887428284
38
train loss item: 0.5653735995292664
39
train loss item: 0.27349570393562317
40
train loss item: 0.16475950181484222
41
train loss item: 0.3100234270095825
42
train loss item: 0.3383437395095825
43
train loss item: 0.2121400684118271
44
train loss item: 0.7227582931518555
45
train loss item: 0.1431918889284134
46
train loss item: 0.12969261407852173
47
train loss item: 0.4263726472854614
48
train loss item: 0.26756131649017334
49
train loss item: 0.1705806702375412
50
train loss item: 0.3746771812438965
51
train loss item: 1.0139511823654175
52
train loss item: 0.06217498704791069
53
train loss item: 0.16979937255382538
54
train loss item: 2.4229838848114014
55
train loss item: 0.2536340057849884
56
train loss item: 0.3545627295970917
57
train loss item: 0.27268481254577637
58
train loss item: 0.18489930033683777
59
train loss item: 0.09865497797727585
60
train loss item: 1.0191375017166138
61
train loss item: 2.3495349884033203
62
train loss item: 0.2570396661758423
63
train loss item: 0.4552990198135376
64
train loss item: 0.17974954843521118
65
train loss item: 0.7330703139305115
66
train loss item: 0.49033045768737793
67
train loss item: 0.2311704009771347
68
train loss item: 0.370891809463501
69
train loss item: 0.42717987298965454
70
train loss item: 0.31670066714286804
71
train loss item: 0.13323341310024261
72
train loss item: 0.20826523005962372
73
train loss item: 0.36135125160217285
74
train loss item: 0.05970589444041252
75
train loss item: 0.09666302800178528
76
train loss item: 1.0236343145370483
77
train loss item: 1.4424474239349365
78
train loss item: 0.06608676165342331
79
train loss item: 0.33388009667396545
80
train loss item: 0.12270621955394745
81
train loss item: 0.2120986133813858
82
train loss item: 0.2253817468881607
83
train loss item: 0.7420154213905334
84
train loss item: 0.48684123158454895
85
train loss item: 0.7103362679481506
86
train loss item: 4.497814178466797
87
train loss item: 0.17919541895389557
88
train loss item: 0.44604170322418213
epoch train loss: 0.542035096984231
testing phase
test loss item: 0.21437563002109528
test loss item: 0.0956152155995369
test loss item: 0.6989486813545227
test loss item: 0.26936671137809753
test loss item: 0.2980992794036865
test loss item: 0.145578533411026
test loss item: 2.0819015502929688
test loss item: 0.5309363603591919
test loss item: 0.26605498790740967
test loss item: 0.49775105714797974
test loss item: 1.041966199874878
test loss item: 0.19478698074817657
test loss item: 0.2190995216369629
test loss item: 0.4272240996360779
test loss item: 0.20173972845077515
test loss item: 0.06378965824842453
test loss item: 0.36363810300827026
test loss item: 0.5876384377479553
test loss item: 0.7590888738632202
test loss item: 0.36551499366760254
test loss item: 0.9398382902145386
test loss item: 0.42985406517982483
test loss item: 0.3521195352077484
test loss item: 0.21189150214195251
test loss item: 0.2733619809150696
test loss item: 0.2809024751186371
test loss item: 0.42837652564048767
test loss item: 0.23201218247413635
test loss item: 0.4262009263038635
test loss item: 0.43711328506469727
test loss item: 0.9488676190376282
test loss item: 0.06257646530866623
test loss item: 0.1800474375486374
test loss item: 0.6901973485946655
test loss item: 0.5426207184791565
test loss item: 0.49769672751426697
test loss item: 0.9510160684585571
test loss item: 1.7131109237670898
test loss item: 0.6481816172599792
test loss item: 0.335711807012558
test loss item: 0.36992520093917847
test loss item: 0.23595918715000153
test loss item: 0.4228821098804474
test loss item: 0.26881757378578186
test loss item: 0.792317271232605
test loss item: 0.5467207431793213
test loss item: 0.374489963054657
test loss item: 0.31936028599739075
test loss item: 0.5739417672157288
test loss item: 0.8283711671829224
test loss item: 0.4081282615661621
test loss item: 0.154836967587471
test loss item: 0.30069446563720703
test loss item: 0.1831844449043274
test loss item: 0.3770875930786133
test loss item: 1.0600895881652832
test loss item: 0.6097639203071594
test loss item: 0.36008140444755554
test loss item: 0.29806604981422424
test loss item: 0.2522852122783661
test loss item: 0.5479974150657654
test loss item: 0.262611985206604
test loss item: 0.26504284143447876
test loss item: 0.30879589915275574
test loss item: 0.9919099807739258
test loss item: 0.3597911596298218
test loss item: 0.38536202907562256
test loss item: 0.31538230180740356
test loss item: 0.6362854242324829
test loss item: 0.44072338938713074
test loss item: 0.06438462436199188
test loss item: 1.162174940109253
test loss item: 0.4179673492908478
test loss item: 0.4789661765098572
test loss item: 0.20018084347248077
test loss item: 0.2153882086277008
test loss item: 0.20814363658428192
test loss item: 1.706592321395874
test loss item: 0.5773895978927612
test loss item: 0.2373054325580597
test loss item: 0.09459483623504639
test loss item: 1.0977264642715454
test loss item: 1.035956859588623
test loss item: 1.1649881601333618
test loss item: 0.27180078625679016
test loss item: 0.2918470799922943
test loss item: 0.08457370102405548
test loss item: 0.06552089005708694
test loss item: 0.20870116353034973
Epoch [29/50], Training Loss: 0.5420, Testing Loss: 0.4802
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 30/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.48140138387680054
1
train loss item: 1.394365906715393
2
train loss item: 0.2608802318572998
3
train loss item: 0.646105945110321
4
train loss item: 0.46055516600608826
5
train loss item: 0.3792787790298462
6
train loss item: 0.31658121943473816
7
train loss item: 0.9083985686302185
8
train loss item: 0.1501954346895218
9
train loss item: 0.31728678941726685
10
train loss item: 0.4239759147167206
11
train loss item: 0.3271031081676483
12
train loss item: 0.10440293699502945
13
train loss item: 0.5190014243125916
14
train loss item: 0.25452759861946106
15
train loss item: 0.7036194205284119
16
train loss item: 0.049627635627985
17
train loss item: 0.3597053587436676
18
train loss item: 0.41072797775268555
19
train loss item: 0.3225748538970947
20
train loss item: 0.26240912079811096
21
train loss item: 0.12983514368534088
22
train loss item: 1.1191301345825195
23
train loss item: 1.0219244956970215
24
train loss item: 0.6987088322639465
25
train loss item: 0.1786428987979889
26
train loss item: 0.21502326428890228
27
train loss item: 0.27248382568359375
28
train loss item: 0.04567847028374672
29
train loss item: 0.8363722562789917
30
train loss item: 2.4656076431274414
31
train loss item: 0.6681861281394958
32
train loss item: 0.09811682999134064
33
train loss item: 0.4870814085006714
34
train loss item: 0.10427086800336838
35
train loss item: 2.546294689178467
36
train loss item: 0.5459383130073547
37
train loss item: 0.5298298001289368
38
train loss item: 0.5613007545471191
39
train loss item: 0.2662945091724396
40
train loss item: 0.16668732464313507
41
train loss item: 0.30439549684524536
42
train loss item: 0.34253907203674316
43
train loss item: 0.2116313874721527
44
train loss item: 0.7169264554977417
45
train loss item: 0.1373472958803177
46
train loss item: 0.1269601434469223
47
train loss item: 0.42695748805999756
48
train loss item: 0.2670772075653076
49
train loss item: 0.16803006827831268
50
train loss item: 0.37322133779525757
51
train loss item: 1.0126595497131348
52
train loss item: 0.056179627776145935
53
train loss item: 0.1679827868938446
54
train loss item: 2.411921977996826
55
train loss item: 0.25430160760879517
56
train loss item: 0.34674322605133057
57
train loss item: 0.2718164026737213
58
train loss item: 0.1844327300786972
59
train loss item: 0.09769383817911148
60
train loss item: 1.0176807641983032
61
train loss item: 2.340857982635498
62
train loss item: 0.25304168462753296
63
train loss item: 0.45747849345207214
64
train loss item: 0.1799045205116272
65
train loss item: 0.7182745933532715
66
train loss item: 0.48645010590553284
67
train loss item: 0.22800104320049286
68
train loss item: 0.37042102217674255
69
train loss item: 0.42436715960502625
70
train loss item: 0.3161582946777344
71
train loss item: 0.13304102420806885
72
train loss item: 0.2089664340019226
73
train loss item: 0.36124908924102783
74
train loss item: 0.06513895839452744
75
train loss item: 0.09682455658912659
76
train loss item: 1.0226938724517822
77
train loss item: 1.4414563179016113
78
train loss item: 0.06064603850245476
79
train loss item: 0.3323899805545807
80
train loss item: 0.1216789111495018
81
train loss item: 0.2124580293893814
82
train loss item: 0.22232086956501007
83
train loss item: 0.7450476884841919
84
train loss item: 0.48387402296066284
85
train loss item: 0.7135350108146667
86
train loss item: 4.481125354766846
87
train loss item: 0.17852528393268585
88
train loss item: 0.443602979183197
epoch train loss: 0.5393950578788024
testing phase
test loss item: 0.21458233892917633
test loss item: 0.09519270807504654
test loss item: 0.7029592990875244
test loss item: 0.26961588859558105
test loss item: 0.2975931167602539
test loss item: 0.14263948798179626
test loss item: 2.0966808795928955
test loss item: 0.5349147319793701
test loss item: 0.26760637760162354
test loss item: 0.4974810779094696
test loss item: 1.0494948625564575
test loss item: 0.19261159002780914
test loss item: 0.21709692478179932
test loss item: 0.42917466163635254
test loss item: 0.20119516551494598
test loss item: 0.06338607519865036
test loss item: 0.3649810254573822
test loss item: 0.5869598984718323
test loss item: 0.7629746198654175
test loss item: 0.37077200412750244
test loss item: 0.9346367716789246
test loss item: 0.4315280318260193
test loss item: 0.354732871055603
test loss item: 0.2132631540298462
test loss item: 0.2731773555278778
test loss item: 0.2814317047595978
test loss item: 0.4314231872558594
test loss item: 0.23008958995342255
test loss item: 0.42685917019844055
test loss item: 0.4367329180240631
test loss item: 0.9563589096069336
test loss item: 0.06275998055934906
test loss item: 0.1806470900774002
test loss item: 0.6893620491027832
test loss item: 0.5435235500335693
test loss item: 0.4995153546333313
test loss item: 0.9542566537857056
test loss item: 1.7287118434906006
test loss item: 0.6475858092308044
test loss item: 0.3372046947479248
test loss item: 0.3716749846935272
test loss item: 0.2396564781665802
test loss item: 0.4223353862762451
test loss item: 0.2694278359413147
test loss item: 0.7860485911369324
test loss item: 0.5503448247909546
test loss item: 0.37365350127220154
test loss item: 0.3235552906990051
test loss item: 0.5745202302932739
test loss item: 0.834966778755188
test loss item: 0.4001131057739258
test loss item: 0.15414413809776306
test loss item: 0.2993636429309845
test loss item: 0.18147651851177216
test loss item: 0.3738549053668976
test loss item: 1.0664687156677246
test loss item: 0.6138145327568054
test loss item: 0.3496915102005005
test loss item: 0.29791027307510376
test loss item: 0.24890336394309998
test loss item: 0.5475035905838013
test loss item: 0.2643861174583435
test loss item: 0.2676909565925598
test loss item: 0.31016236543655396
test loss item: 0.99992436170578
test loss item: 0.3594213128089905
test loss item: 0.38846418261528015
test loss item: 0.31705111265182495
test loss item: 0.6367272734642029
test loss item: 0.4468174874782562
test loss item: 0.06402111053466797
test loss item: 1.1709040403366089
test loss item: 0.41886967420578003
test loss item: 0.48637619614601135
test loss item: 0.19963660836219788
test loss item: 0.21646708250045776
test loss item: 0.2100326269865036
test loss item: 1.721067190170288
test loss item: 0.5842068195343018
test loss item: 0.23681846261024475
test loss item: 0.09160158783197403
test loss item: 1.1116564273834229
test loss item: 1.040302038192749
test loss item: 1.1772689819335938
test loss item: 0.2769281268119812
test loss item: 0.29061490297317505
test loss item: 0.08027181774377823
test loss item: 0.0635930523276329
test loss item: 0.21292218565940857
Epoch [30/50], Training Loss: 0.5394, Testing Loss: 0.4820
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 31/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.473084956407547
1
train loss item: 1.3841134309768677
2
train loss item: 0.262138694524765
3
train loss item: 0.6444418430328369
4
train loss item: 0.452515184879303
5
train loss item: 0.37708398699760437
6
train loss item: 0.3156689703464508
7
train loss item: 0.9009659290313721
8
train loss item: 0.14971406757831573
9
train loss item: 0.3179338872432709
10
train loss item: 0.42517387866973877
11
train loss item: 0.3269282281398773
12
train loss item: 0.10354238003492355
13
train loss item: 0.5171881318092346
14
train loss item: 0.2532999515533447
15
train loss item: 0.7036271691322327
16
train loss item: 0.0479503870010376
17
train loss item: 0.3586445152759552
18
train loss item: 0.4075218141078949
19
train loss item: 0.322686105966568
20
train loss item: 0.2597551643848419
21
train loss item: 0.12552598118782043
22
train loss item: 1.1081733703613281
23
train loss item: 1.0195459127426147
24
train loss item: 0.7041078805923462
25
train loss item: 0.17538899183273315
26
train loss item: 0.21522702276706696
27
train loss item: 0.27222657203674316
28
train loss item: 0.0443873256444931
29
train loss item: 0.8351550698280334
30
train loss item: 2.451545000076294
31
train loss item: 0.6663832664489746
32
train loss item: 0.09863147884607315
33
train loss item: 0.4869725704193115
34
train loss item: 0.10460633039474487
35
train loss item: 2.534149408340454
36
train loss item: 0.5436293482780457
37
train loss item: 0.527703583240509
38
train loss item: 0.5613130331039429
39
train loss item: 0.2607058882713318
40
train loss item: 0.16823743283748627
41
train loss item: 0.3024367690086365
42
train loss item: 0.34667906165122986
43
train loss item: 0.21141280233860016
44
train loss item: 0.7118057012557983
45
train loss item: 0.1316583752632141
46
train loss item: 0.1252806931734085
47
train loss item: 0.4264168441295624
48
train loss item: 0.2659975588321686
49
train loss item: 0.16738346219062805
50
train loss item: 0.3720982074737549
51
train loss item: 1.0088914632797241
52
train loss item: 0.05246932432055473
53
train loss item: 0.16543981432914734
54
train loss item: 2.399846315383911
55
train loss item: 0.25290238857269287
56
train loss item: 0.3411601781845093
57
train loss item: 0.27243825793266296
58
train loss item: 0.18401511013507843
59
train loss item: 0.09776109457015991
60
train loss item: 1.0141880512237549
61
train loss item: 2.331458330154419
62
train loss item: 0.24987578392028809
63
train loss item: 0.45988988876342773
64
train loss item: 0.18079639971256256
65
train loss item: 0.7081605792045593
66
train loss item: 0.4850202798843384
67
train loss item: 0.22534213960170746
68
train loss item: 0.369285523891449
69
train loss item: 0.42223063111305237
70
train loss item: 0.31543222069740295
71
train loss item: 0.13283780217170715
72
train loss item: 0.20999231934547424
73
train loss item: 0.36122557520866394
74
train loss item: 0.06879421323537827
75
train loss item: 0.09733469784259796
76
train loss item: 1.0207431316375732
77
train loss item: 1.4367210865020752
78
train loss item: 0.055735453963279724
79
train loss item: 0.33269062638282776
80
train loss item: 0.1206846609711647
81
train loss item: 0.21227651834487915
82
train loss item: 0.2205650508403778
83
train loss item: 0.7444208860397339
84
train loss item: 0.4844137132167816
85
train loss item: 0.7154751420021057
86
train loss item: 4.46336555480957
87
train loss item: 0.17749546468257904
88
train loss item: 0.44037240743637085
epoch train loss: 0.5370844011142683
testing phase
test loss item: 0.21431168913841248
test loss item: 0.09336135536432266
test loss item: 0.702540397644043
test loss item: 0.26833781599998474
test loss item: 0.2955052852630615
test loss item: 0.13833074271678925
test loss item: 2.100023031234741
test loss item: 0.5346800088882446
test loss item: 0.2671829164028168
test loss item: 0.4942513108253479
test loss item: 1.0506784915924072
test loss item: 0.19276493787765503
test loss item: 0.21348829567432404
test loss item: 0.42840734124183655
test loss item: 0.19975848495960236
test loss item: 0.06330371648073196
test loss item: 0.36316928267478943
test loss item: 0.5824891924858093
test loss item: 0.7633745670318604
test loss item: 0.3703726828098297
test loss item: 0.9281437993049622
test loss item: 0.4304454028606415
test loss item: 0.35495975613594055
test loss item: 0.2130555957555771
test loss item: 0.2721286714076996
test loss item: 0.2805531919002533
test loss item: 0.4301909804344177
test loss item: 0.22657404839992523
test loss item: 0.42507636547088623
test loss item: 0.433743953704834
test loss item: 0.9568033218383789
test loss item: 0.06418489664793015
test loss item: 0.18015506863594055
test loss item: 0.6864255666732788
test loss item: 0.5419472455978394
test loss item: 0.49485763907432556
test loss item: 0.9531940817832947
test loss item: 1.7330015897750854
test loss item: 0.643851101398468
test loss item: 0.3366169035434723
test loss item: 0.371652752161026
test loss item: 0.24067501723766327
test loss item: 0.4178526699542999
test loss item: 0.2677713632583618
test loss item: 0.7789734601974487
test loss item: 0.5489409565925598
test loss item: 0.3703864514827728
test loss item: 0.3226291835308075
test loss item: 0.5713004469871521
test loss item: 0.8350487947463989
test loss item: 0.3912317454814911
test loss item: 0.1521374136209488
test loss item: 0.2965772747993469
test loss item: 0.17969736456871033
test loss item: 0.3698291778564453
test loss item: 1.0657423734664917
test loss item: 0.6144306063652039
test loss item: 0.33975735306739807
test loss item: 0.29532650113105774
test loss item: 0.2452072948217392
test loss item: 0.5427204966545105
test loss item: 0.2622554898262024
test loss item: 0.267796128988266
test loss item: 0.310647189617157
test loss item: 1.0022104978561401
test loss item: 0.3578818142414093
test loss item: 0.3873912990093231
test loss item: 0.3173640966415405
test loss item: 0.6355539560317993
test loss item: 0.44748836755752563
test loss item: 0.06363826990127563
test loss item: 1.1731090545654297
test loss item: 0.41584476828575134
test loss item: 0.4882935881614685
test loss item: 0.19651934504508972
test loss item: 0.21538233757019043
test loss item: 0.21014656126499176
test loss item: 1.7257407903671265
test loss item: 0.5866717100143433
test loss item: 0.23439152538776398
test loss item: 0.08984105288982391
test loss item: 1.116381049156189
test loss item: 1.0389589071273804
test loss item: 1.1800956726074219
test loss item: 0.27920594811439514
test loss item: 0.2869729697704315
test loss item: 0.07831859588623047
test loss item: 0.0646689161658287
test loss item: 0.21636337041854858
Epoch [31/50], Training Loss: 0.5371, Testing Loss: 0.4808
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Epoch 32/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46875104308128357
1
train loss item: 1.371289610862732
2
train loss item: 0.26266786456108093
3
train loss item: 0.6404750943183899
4
train loss item: 0.4490983188152313
5
train loss item: 0.37516501545906067
6
train loss item: 0.31217527389526367
7
train loss item: 0.8914986848831177
8
train loss item: 0.1488368660211563
9
train loss item: 0.31684455275535583
10
train loss item: 0.42491090297698975
11
train loss item: 0.3293740451335907
12
train loss item: 0.10330966860055923
13
train loss item: 0.5154709815979004
14
train loss item: 0.2529878318309784
15
train loss item: 0.6991344690322876
16
train loss item: 0.04757179319858551
17
train loss item: 0.3561277985572815
18
train loss item: 0.4046730101108551
19
train loss item: 0.32186803221702576
20
train loss item: 0.2558565139770508
21
train loss item: 0.1270337849855423
22
train loss item: 1.094765067100525
23
train loss item: 1.014751672744751
24
train loss item: 0.7054380178451538
25
train loss item: 0.17341560125350952
26
train loss item: 0.21691453456878662
27
train loss item: 0.27114883065223694
28
train loss item: 0.0442025363445282
29
train loss item: 0.8270798921585083
30
train loss item: 2.4343159198760986
31
train loss item: 0.6668242812156677
32
train loss item: 0.09865584224462509
33
train loss item: 0.4829770624637604
34
train loss item: 0.10618381947278976
35
train loss item: 2.520704984664917
36
train loss item: 0.5436233878135681
37
train loss item: 0.5303105711936951
38
train loss item: 0.5670133829116821
39
train loss item: 0.2574058175086975
40
train loss item: 0.16911624372005463
41
train loss item: 0.30199989676475525
42
train loss item: 0.34905490279197693
43
train loss item: 0.21139736473560333
44
train loss item: 0.7058507204055786
45
train loss item: 0.1261667013168335
46
train loss item: 0.1242603287100792
47
train loss item: 0.42356958985328674
48
train loss item: 0.26384299993515015
49
train loss item: 0.1682833582162857
50
train loss item: 0.37030163407325745
51
train loss item: 1.0001493692398071
52
train loss item: 0.05131842568516731
53
train loss item: 0.16285210847854614
54
train loss item: 2.386328935623169
55
train loss item: 0.24879416823387146
56
train loss item: 0.33970755338668823
57
train loss item: 0.27289631962776184
58
train loss item: 0.18385282158851624
59
train loss item: 0.09795371443033218
60
train loss item: 1.0049068927764893
61
train loss item: 2.318666934967041
62
train loss item: 0.24780024588108063
63
train loss item: 0.4613262116909027
64
train loss item: 0.18170210719108582
65
train loss item: 0.705316424369812
66
train loss item: 0.48727571964263916
67
train loss item: 0.22336408495903015
68
train loss item: 0.3664405643939972
69
train loss item: 0.4212172329425812
70
train loss item: 0.31368207931518555
71
train loss item: 0.13161051273345947
72
train loss item: 0.21001778542995453
73
train loss item: 0.3601881265640259
74
train loss item: 0.06893251836299896
75
train loss item: 0.09745637327432632
76
train loss item: 1.0156919956207275
77
train loss item: 1.4258241653442383
78
train loss item: 0.052718259394168854
79
train loss item: 0.3340289890766144
80
train loss item: 0.11893969029188156
81
train loss item: 0.2113940566778183
82
train loss item: 0.21948625147342682
83
train loss item: 0.7371718287467957
84
train loss item: 0.4907810688018799
85
train loss item: 0.7129371166229248
86
train loss item: 4.444091320037842
87
train loss item: 0.17599371075630188
88
train loss item: 0.43731528520584106
epoch train loss: 0.534436259418726
testing phase
test loss item: 0.21322408318519592
test loss item: 0.09056093543767929
test loss item: 0.6980222463607788
test loss item: 0.26643508672714233
test loss item: 0.2924511432647705
test loss item: 0.1337374895811081
test loss item: 2.0897672176361084
test loss item: 0.5324380993843079
test loss item: 0.26398733258247375
test loss item: 0.4892127513885498
test loss item: 1.0441844463348389
test loss item: 0.1930304765701294
test loss item: 0.20950473845005035
test loss item: 0.4241456687450409
test loss item: 0.1975497603416443
test loss item: 0.06321871280670166
test loss item: 0.3595794439315796
test loss item: 0.5768218040466309
test loss item: 0.7609959840774536
test loss item: 0.3659694194793701
test loss item: 0.9213863015174866
test loss item: 0.4272571802139282
test loss item: 0.3522065579891205
test loss item: 0.21094752848148346
test loss item: 0.27046817541122437
test loss item: 0.2786099314689636
test loss item: 0.4259400963783264
test loss item: 0.22308558225631714
test loss item: 0.42111754417419434
test loss item: 0.42998841404914856
test loss item: 0.9488487839698792
test loss item: 0.06549810618162155
test loss item: 0.1782560497522354
test loss item: 0.6815588474273682
test loss item: 0.5390059947967529
test loss item: 0.48673081398010254
test loss item: 0.9485250115394592
test loss item: 1.7233667373657227
test loss item: 0.63861083984375
test loss item: 0.33404141664505005
test loss item: 0.3697167932987213
test loss item: 0.23867011070251465
test loss item: 0.41299739480018616
test loss item: 0.2648250162601471
test loss item: 0.7711830735206604
test loss item: 0.5452760457992554
test loss item: 0.36533522605895996
test loss item: 0.31777507066726685
test loss item: 0.5656611323356628
test loss item: 0.8289831876754761
test loss item: 0.3827969431877136
test loss item: 0.14944221079349518
test loss item: 0.2927356958389282
test loss item: 0.1784561574459076
test loss item: 0.3654463589191437
test loss item: 1.0582911968231201
test loss item: 0.611945390701294
test loss item: 0.3312739431858063
test loss item: 0.2913554310798645
test loss item: 0.24143187701702118
test loss item: 0.5363078713417053
test loss item: 0.2581363320350647
test loss item: 0.2656671404838562
test loss item: 0.30992209911346436
test loss item: 0.9976875185966492
test loss item: 0.3561897575855255
test loss item: 0.38361313939094543
test loss item: 0.3162411153316498
test loss item: 0.6328487396240234
test loss item: 0.44318878650665283
test loss item: 0.0628235936164856
test loss item: 1.1685736179351807
test loss item: 0.40882548689842224
test loss item: 0.4844459891319275
test loss item: 0.1921301931142807
test loss item: 0.21212118864059448
test loss item: 0.2083870768547058
test loss item: 1.7165883779525757
test loss item: 0.5835737586021423
test loss item: 0.2308838665485382
test loss item: 0.08866384625434875
test loss item: 1.110513687133789
test loss item: 1.0325345993041992
test loss item: 1.1714292764663696
test loss item: 0.27756941318511963
test loss item: 0.2821944057941437
test loss item: 0.07738424092531204
test loss item: 0.06598050892353058
test loss item: 0.21819821000099182
Epoch [32/50], Training Loss: 0.5344, Testing Loss: 0.4769
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 33/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46680909395217896
1
train loss item: 1.3576240539550781
2
train loss item: 0.2623305022716522
3
train loss item: 0.6341454982757568
4
train loss item: 0.4501779079437256
5
train loss item: 0.3735646605491638
6
train loss item: 0.3080396056175232
7
train loss item: 0.8807194232940674
8
train loss item: 0.14797347784042358
9
train loss item: 0.3137100636959076
10
train loss item: 0.4220535159111023
11
train loss item: 0.3310345709323883
12
train loss item: 0.10437484830617905
13
train loss item: 0.5138350129127502
14
train loss item: 0.2530885934829712
15
train loss item: 0.6914716362953186
16
train loss item: 0.04863834008574486
17
train loss item: 0.35342642664909363
18
train loss item: 0.40189817547798157
19
train loss item: 0.3203124403953552
20
train loss item: 0.2520489990711212
21
train loss item: 0.1330597996711731
22
train loss item: 1.0803883075714111
23
train loss item: 1.0074158906936646
24
train loss item: 0.7021379470825195
25
train loss item: 0.1723640114068985
26
train loss item: 0.22040331363677979
27
train loss item: 0.26881882548332214
28
train loss item: 0.04523034393787384
29
train loss item: 0.8131545782089233
30
train loss item: 2.41428804397583
31
train loss item: 0.6680176258087158
32
train loss item: 0.09813179820775986
33
train loss item: 0.47652775049209595
34
train loss item: 0.11190389841794968
35
train loss item: 2.506554126739502
36
train loss item: 0.545390784740448
37
train loss item: 0.5347265601158142
38
train loss item: 0.5760960578918457
39
train loss item: 0.25581440329551697
40
train loss item: 0.16928593814373016
41
train loss item: 0.30050569772720337
42
train loss item: 0.34920734167099
43
train loss item: 0.21210849285125732
44
train loss item: 0.6988185048103333
45
train loss item: 0.12194468080997467
46
train loss item: 0.12343920022249222
47
train loss item: 0.41942745447158813
48
train loss item: 0.26111069321632385
49
train loss item: 0.1704501062631607
50
train loss item: 0.3679521679878235
51
train loss item: 0.9882592558860779
52
train loss item: 0.0528588704764843
53
train loss item: 0.16157133877277374
54
train loss item: 2.3719325065612793
55
train loss item: 0.24336741864681244
56
train loss item: 0.34076404571533203
57
train loss item: 0.27229809761047363
58
train loss item: 0.18480443954467773
59
train loss item: 0.09764841943979263
60
train loss item: 0.9907062649726868
61
train loss item: 2.3029799461364746
62
train loss item: 0.24668088555335999
63
train loss item: 0.46083927154541016
64
train loss item: 0.18259301781654358
65
train loss item: 0.7081428170204163
66
train loss item: 0.4910017251968384
67
train loss item: 0.223114013671875
68
train loss item: 0.36313915252685547
69
train loss item: 0.4212265610694885
70
train loss item: 0.3112548589706421
71
train loss item: 0.13014677166938782
72
train loss item: 0.20900613069534302
73
train loss item: 0.3582913875579834
74
train loss item: 0.06609977781772614
75
train loss item: 0.09726172685623169
76
train loss item: 1.008003830909729
77
train loss item: 1.410060167312622
78
train loss item: 0.05297960713505745
79
train loss item: 0.3342128098011017
80
train loss item: 0.11780177801847458
81
train loss item: 0.21042349934577942
82
train loss item: 0.2191656529903412
83
train loss item: 0.7243845462799072
84
train loss item: 0.49935001134872437
85
train loss item: 0.7057446241378784
86
train loss item: 4.423738956451416
87
train loss item: 0.17566169798374176
88
train loss item: 0.43617576360702515
epoch train loss: 0.5315240768485525
testing phase
test loss item: 0.2121126800775528
test loss item: 0.08773484826087952
test loss item: 0.6942959427833557
test loss item: 0.2640652358531952
test loss item: 0.2900402247905731
test loss item: 0.13015949726104736
test loss item: 2.07247257232666
test loss item: 0.5336565375328064
test loss item: 0.26075419783592224
test loss item: 0.4856571853160858
test loss item: 1.035740852355957
test loss item: 0.19392763078212738
test loss item: 0.20681430399417877
test loss item: 0.4173305332660675
test loss item: 0.19554629921913147
test loss item: 0.0628867819905281
test loss item: 0.3564499616622925
test loss item: 0.5744712948799133
test loss item: 0.759372353553772
test loss item: 0.36074337363243103
test loss item: 0.9195004105567932
test loss item: 0.4242754280567169
test loss item: 0.34931525588035583
test loss item: 0.20801469683647156
test loss item: 0.26925674080848694
test loss item: 0.2766006588935852
test loss item: 0.4212419092655182
test loss item: 0.22111815214157104
test loss item: 0.41693541407585144
test loss item: 0.42752018570899963
test loss item: 0.9375218749046326
test loss item: 0.06610026955604553
test loss item: 0.17584221065044403
test loss item: 0.6816200017929077
test loss item: 0.5387147665023804
test loss item: 0.48069244623184204
test loss item: 0.9442917108535767
test loss item: 1.7102316617965698
test loss item: 0.6344912648200989
test loss item: 0.33072179555892944
test loss item: 0.3668084442615509
test loss item: 0.2344134896993637
test loss item: 0.4098605811595917
test loss item: 0.2614176869392395
test loss item: 0.7663179636001587
test loss item: 0.5426968932151794
test loss item: 0.36074119806289673
test loss item: 0.31156685948371887
test loss item: 0.5621086955070496
test loss item: 0.8227744698524475
test loss item: 0.3773632347583771
test loss item: 0.14719517529010773
test loss item: 0.2893458604812622
test loss item: 0.17776454985141754
test loss item: 0.3627459704875946
test loss item: 1.0522595643997192
test loss item: 0.6101230978965759
test loss item: 0.3273577392101288
test loss item: 0.2880443334579468
test loss item: 0.23851065337657928
test loss item: 0.5318987369537354
test loss item: 0.25521740317344666
test loss item: 0.26315441727638245
test loss item: 0.308397114276886
test loss item: 0.9921493530273438
test loss item: 0.35432112216949463
test loss item: 0.3800372779369354
test loss item: 0.31437864899635315
test loss item: 0.6313114166259766
test loss item: 0.4391718804836273
test loss item: 0.061286114156246185
test loss item: 1.1616588830947876
test loss item: 0.40029558539390564
test loss item: 0.47771143913269043
test loss item: 0.18845272064208984
test loss item: 0.20774520933628082
test loss item: 0.20576530694961548
test loss item: 1.7026242017745972
test loss item: 0.5768478512763977
test loss item: 0.22791720926761627
test loss item: 0.08736211061477661
test loss item: 1.1013727188110352
test loss item: 1.025728702545166
test loss item: 1.160254955291748
test loss item: 0.2729704678058624
test loss item: 0.2786133885383606
test loss item: 0.07637952268123627
test loss item: 0.06578245759010315
test loss item: 0.2173609584569931
Epoch [33/50], Training Loss: 0.5315, Testing Loss: 0.4731
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 34/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46555644273757935
1
train loss item: 1.3461148738861084
2
train loss item: 0.26093849539756775
3
train loss item: 0.6278906464576721
4
train loss item: 0.45113593339920044
5
train loss item: 0.3725840151309967
6
train loss item: 0.3055669367313385
7
train loss item: 0.8704041242599487
8
train loss item: 0.14786186814308167
9
train loss item: 0.3099324703216553
10
train loss item: 0.416943222284317
11
train loss item: 0.32899904251098633
12
train loss item: 0.1062963679432869
13
train loss item: 0.5124423503875732
14
train loss item: 0.25382518768310547
15
train loss item: 0.6844896674156189
16
train loss item: 0.05039737746119499
17
train loss item: 0.3519582450389862
18
train loss item: 0.3984069228172302
19
train loss item: 0.31857141852378845
20
train loss item: 0.25087204575538635
21
train loss item: 0.1389053612947464
22
train loss item: 1.067869782447815
23
train loss item: 0.9993776082992554
24
train loss item: 0.695021390914917
25
train loss item: 0.1713784784078598
26
train loss item: 0.22374968230724335
27
train loss item: 0.26683691143989563
28
train loss item: 0.04682835936546326
29
train loss item: 0.7985316514968872
30
train loss item: 2.3941078186035156
31
train loss item: 0.6667744517326355
32
train loss item: 0.09648626297712326
33
train loss item: 0.47201797366142273
34
train loss item: 0.11737147718667984
35
train loss item: 2.492886543273926
36
train loss item: 0.546667754650116
37
train loss item: 0.5337917804718018
38
train loss item: 0.5805773735046387
39
train loss item: 0.2542440891265869
40
train loss item: 0.16793225705623627
41
train loss item: 0.29725924134254456
42
train loss item: 0.34737950563430786
43
train loss item: 0.21249228715896606
44
train loss item: 0.692136287689209
45
train loss item: 0.11924678832292557
46
train loss item: 0.1223892793059349
47
train loss item: 0.41615307331085205
48
train loss item: 0.25895068049430847
49
train loss item: 0.17318442463874817
50
train loss item: 0.3657841682434082
51
train loss item: 0.9775030016899109
52
train loss item: 0.05626699700951576
53
train loss item: 0.160780131816864
54
train loss item: 2.3577349185943604
55
train loss item: 0.2391819804906845
56
train loss item: 0.3402162790298462
57
train loss item: 0.2704581022262573
58
train loss item: 0.1862265020608902
59
train loss item: 0.0973379835486412
60
train loss item: 0.9763846397399902
61
train loss item: 2.2873473167419434
62
train loss item: 0.24612480401992798
63
train loss item: 0.45819732546806335
64
train loss item: 0.18277451395988464
65
train loss item: 0.7145614624023438
66
train loss item: 0.4920523166656494
67
train loss item: 0.2241639643907547
68
train loss item: 0.3620467483997345
69
train loss item: 0.421249657869339
70
train loss item: 0.3090074360370636
71
train loss item: 0.12929284572601318
72
train loss item: 0.2074398398399353
73
train loss item: 0.35620734095573425
74
train loss item: 0.062333159148693085
75
train loss item: 0.09737809747457504
76
train loss item: 1.0003572702407837
77
train loss item: 1.3936809301376343
78
train loss item: 0.05595863610506058
79
train loss item: 0.3312074840068817
80
train loss item: 0.11619656533002853
81
train loss item: 0.20975524187088013
82
train loss item: 0.21949650347232819
83
train loss item: 0.7111291289329529
84
train loss item: 0.5022298693656921
85
train loss item: 0.6972664594650269
86
train loss item: 4.403139114379883
87
train loss item: 0.17557752132415771
88
train loss item: 0.4372000992298126
epoch train loss: 0.5284604785147677
testing phase
test loss item: 0.2135738581418991
test loss item: 0.08602975308895111
test loss item: 0.6993212699890137
test loss item: 0.26289549469947815
test loss item: 0.2903444766998291
test loss item: 0.12897561490535736
test loss item: 2.060167074203491
test loss item: 0.541650116443634
test loss item: 0.26124367117881775
test loss item: 0.4887375235557556
test loss item: 1.0351508855819702
test loss item: 0.1996924877166748
test loss item: 0.20744790136814117
test loss item: 0.4095540940761566
test loss item: 0.1949087381362915
test loss item: 0.061074160039424896
test loss item: 0.3565589487552643
test loss item: 0.5846208333969116
test loss item: 0.7619704604148865
test loss item: 0.35951605439186096
test loss item: 0.9303681254386902
test loss item: 0.4248899817466736
test loss item: 0.35288316011428833
test loss item: 0.20531639456748962
test loss item: 0.27030667662620544
test loss item: 0.2755753993988037
test loss item: 0.4206170439720154
test loss item: 0.2229664921760559
test loss item: 0.41547733545303345
test loss item: 0.43025943636894226
test loss item: 0.9323461055755615
test loss item: 0.06305443495512009
test loss item: 0.1733192652463913
test loss item: 0.6898053884506226
test loss item: 0.5462710857391357
test loss item: 0.48515212535858154
test loss item: 0.9457820653915405
test loss item: 1.7109050750732422
test loss item: 0.6378495693206787
test loss item: 0.3289725184440613
test loss item: 0.36456185579299927
test loss item: 0.22936472296714783
test loss item: 0.41549158096313477
test loss item: 0.2603921890258789
test loss item: 0.769135057926178
test loss item: 0.5450847148895264
test loss item: 0.36010435223579407
test loss item: 0.308362752199173
test loss item: 0.5672712922096252
test loss item: 0.8250425457954407
test loss item: 0.3789769113063812
test loss item: 0.1466452032327652
test loss item: 0.2889263331890106
test loss item: 0.1825673133134842
test loss item: 0.3647565245628357
test loss item: 1.0590828657150269
test loss item: 0.613541305065155
test loss item: 0.3282800316810608
test loss item: 0.2877277135848999
test loss item: 0.2381104826927185
test loss item: 0.537801206111908
test loss item: 0.25559067726135254
test loss item: 0.26378536224365234
test loss item: 0.306956022977829
test loss item: 0.9937819242477417
test loss item: 0.3546923100948334
test loss item: 0.38033726811408997
test loss item: 0.31301599740982056
test loss item: 0.6356155276298523
test loss item: 0.4430946409702301
test loss item: 0.05952470004558563
test loss item: 1.1583211421966553
test loss item: 0.39438700675964355
test loss item: 0.47327256202697754
test loss item: 0.1881854385137558
test loss item: 0.2040715217590332
test loss item: 0.2034207284450531
test loss item: 1.7000830173492432
test loss item: 0.5707409381866455
test loss item: 0.22918882966041565
test loss item: 0.08561751246452332
test loss item: 1.10053551197052
test loss item: 1.0262519121170044
test loss item: 1.1601979732513428
test loss item: 0.26808977127075195
test loss item: 0.2787185311317444
test loss item: 0.07455826550722122
test loss item: 0.06195615604519844
test loss item: 0.21289333701133728
Epoch [34/50], Training Loss: 0.5285, Testing Loss: 0.4734
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 35/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46597394347190857
1
train loss item: 1.3388044834136963
2
train loss item: 0.25807690620422363
3
train loss item: 0.6249806880950928
4
train loss item: 0.4456847310066223
5
train loss item: 0.3713756799697876
6
train loss item: 0.3052600622177124
7
train loss item: 0.8631782531738281
8
train loss item: 0.14820124208927155
9
train loss item: 0.3071218729019165
10
train loss item: 0.41178303956985474
11
train loss item: 0.32227376103401184
12
train loss item: 0.10709524899721146
13
train loss item: 0.5109976530075073
14
train loss item: 0.25603172183036804
15
train loss item: 0.6817131042480469
16
train loss item: 0.05057249963283539
17
train loss item: 0.35218068957328796
18
train loss item: 0.3934715986251831
19
train loss item: 0.3169139623641968
20
train loss item: 0.2536817491054535
21
train loss item: 0.1369817554950714
22
train loss item: 1.0598398447036743
23
train loss item: 0.9923452734947205
24
train loss item: 0.687374472618103
25
train loss item: 0.17162741720676422
26
train loss item: 0.22321948409080505
27
train loss item: 0.2669871151447296
28
train loss item: 0.047015056014060974
29
train loss item: 0.7906100749969482
30
train loss item: 2.37687087059021
31
train loss item: 0.6606408953666687
32
train loss item: 0.09468928724527359
33
train loss item: 0.47299718856811523
34
train loss item: 0.11488327383995056
35
train loss item: 2.480698823928833
36
train loss item: 0.545962393283844
37
train loss item: 0.5216296911239624
38
train loss item: 0.5764504671096802
39
train loss item: 0.2510504424571991
40
train loss item: 0.16371212899684906
41
train loss item: 0.29362449049949646
42
train loss item: 0.3426751494407654
43
train loss item: 0.21079155802726746
44
train loss item: 0.6890969276428223
45
train loss item: 0.11753960698843002
46
train loss item: 0.12126723676919937
47
train loss item: 0.41429445147514343
48
train loss item: 0.25861823558807373
49
train loss item: 0.17526070773601532
50
train loss item: 0.36454784870147705
51
train loss item: 0.9715594053268433
52
train loss item: 0.05905195325613022
53
train loss item: 0.15963409841060638
54
train loss item: 2.3447983264923096
55
train loss item: 0.23835508525371552
56
train loss item: 0.3326733112335205
57
train loss item: 0.26807984709739685
58
train loss item: 0.18558837473392487
59
train loss item: 0.09734433144330978
60
train loss item: 0.9677563309669495
61
train loss item: 2.274996280670166
62
train loss item: 0.2462247759103775
63
train loss item: 0.4533918797969818
64
train loss item: 0.18100093305110931
65
train loss item: 0.7183769941329956
66
train loss item: 0.48749861121177673
67
train loss item: 0.22377122938632965
68
train loss item: 0.3641466200351715
69
train loss item: 0.4193195402622223
70
train loss item: 0.3069128096103668
71
train loss item: 0.12803003191947937
72
train loss item: 0.20576119422912598
73
train loss item: 0.35417526960372925
74
train loss item: 0.05944427102804184
75
train loss item: 0.09694977849721909
76
train loss item: 0.9959499835968018
77
train loss item: 1.3816370964050293
78
train loss item: 0.05813152715563774
79
train loss item: 0.32386109232902527
80
train loss item: 0.11165192723274231
81
train loss item: 0.20897479355335236
82
train loss item: 0.22002984583377838
83
train loss item: 0.7044963836669922
84
train loss item: 0.4953834116458893
85
train loss item: 0.6916280388832092
86
train loss item: 4.383851528167725
87
train loss item: 0.17291715741157532
88
train loss item: 0.43739548325538635
epoch train loss: 0.5251620742963271
testing phase
test loss item: 0.21527057886123657
test loss item: 0.0855872705578804
test loss item: 0.707159698009491
test loss item: 0.26246023178100586
test loss item: 0.29108306765556335
test loss item: 0.12860535085201263
test loss item: 2.0581822395324707
test loss item: 0.5523665547370911
test loss item: 0.2622254490852356
test loss item: 0.49178218841552734
test loss item: 1.040955662727356
test loss item: 0.1997842639684677
test loss item: 0.20805323123931885
test loss item: 0.40302762389183044
test loss item: 0.1950339674949646
test loss item: 0.061663467437028885
test loss item: 0.3565795421600342
test loss item: 0.5907928347587585
test loss item: 0.7661576867103577
test loss item: 0.35805991291999817
test loss item: 0.9411194324493408
test loss item: 0.42626291513442993
test loss item: 0.3539638817310333
test loss item: 0.20481768250465393
test loss item: 0.2710685729980469
test loss item: 0.2751956284046173
test loss item: 0.42010441422462463
test loss item: 0.2238040417432785
test loss item: 0.41506344079971313
test loss item: 0.43235769867897034
test loss item: 0.9355181455612183
test loss item: 0.06280957162380219
test loss item: 0.17310045659542084
test loss item: 0.6933038830757141
test loss item: 0.5533448457717896
test loss item: 0.49037298560142517
test loss item: 0.9499889612197876
test loss item: 1.7229634523391724
test loss item: 0.6413147449493408
test loss item: 0.3282091021537781
test loss item: 0.36336201429367065
test loss item: 0.2240249365568161
test loss item: 0.4190147817134857
test loss item: 0.2596273124217987
test loss item: 0.7765637636184692
test loss item: 0.5471388697624207
test loss item: 0.35960060358047485
test loss item: 0.3042542040348053
test loss item: 0.5724186897277832
test loss item: 0.8297107815742493
test loss item: 0.3831971287727356
test loss item: 0.1461508721113205
test loss item: 0.2893275022506714
test loss item: 0.18309620022773743
test loss item: 0.36789461970329285
test loss item: 1.071425199508667
test loss item: 0.6188662648200989
test loss item: 0.33289676904678345
test loss item: 0.2885749042034149
test loss item: 0.23884418606758118
test loss item: 0.5415264964103699
test loss item: 0.2578224837779999
test loss item: 0.26485198736190796
test loss item: 0.3063426911830902
test loss item: 1.0070042610168457
test loss item: 0.35402822494506836
test loss item: 0.38080573081970215
test loss item: 0.3120076060295105
test loss item: 0.6403165459632874
test loss item: 0.4475812613964081
test loss item: 0.05969718098640442
test loss item: 1.1601101160049438
test loss item: 0.3901323974132538
test loss item: 0.4716534912586212
test loss item: 0.18739335238933563
test loss item: 0.2005314826965332
test loss item: 0.20262271165847778
test loss item: 1.715500831604004
test loss item: 0.5667243003845215
test loss item: 0.23104576766490936
test loss item: 0.08650179207324982
test loss item: 1.1058765649795532
test loss item: 1.0304852724075317
test loss item: 1.1718921661376953
test loss item: 0.2645270824432373
test loss item: 0.2782149910926819
test loss item: 0.07762686908245087
test loss item: 0.0654597356915474
test loss item: 0.20738033950328827
Epoch [35/50], Training Loss: 0.5252, Testing Loss: 0.4754
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 36/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4670104384422302
1
train loss item: 1.3340102434158325
2
train loss item: 0.2552347481250763
3
train loss item: 0.6235569715499878
4
train loss item: 0.43865102529525757
5
train loss item: 0.3704874813556671
6
train loss item: 0.306098610162735
7
train loss item: 0.858638346195221
8
train loss item: 0.14895620942115784
9
train loss item: 0.3055882453918457
10
train loss item: 0.4079172909259796
11
train loss item: 0.31496402621269226
12
train loss item: 0.10669046640396118
13
train loss item: 0.5105096101760864
14
train loss item: 0.2583344876766205
15
train loss item: 0.6813209056854248
16
train loss item: 0.04982461780309677
17
train loss item: 0.3532407581806183
18
train loss item: 0.38834118843078613
19
train loss item: 0.31596052646636963
20
train loss item: 0.2585130035877228
21
train loss item: 0.13197065889835358
22
train loss item: 1.0535850524902344
23
train loss item: 0.9879844784736633
24
train loss item: 0.6823132634162903
25
train loss item: 0.17214149236679077
26
train loss item: 0.22107002139091492
27
train loss item: 0.269107848405838
28
train loss item: 0.04607902839779854
29
train loss item: 0.7868509292602539
30
train loss item: 2.3624939918518066
31
train loss item: 0.6527245044708252
32
train loss item: 0.09260858595371246
33
train loss item: 0.475447416305542
34
train loss item: 0.10924854129552841
35
train loss item: 2.470440626144409
36
train loss item: 0.5432591438293457
37
train loss item: 0.5045233964920044
38
train loss item: 0.5711463093757629
39
train loss item: 0.2481335550546646
40
train loss item: 0.15923050045967102
41
train loss item: 0.291416198015213
42
train loss item: 0.33721426129341125
43
train loss item: 0.20810247957706451
44
train loss item: 0.6891940236091614
45
train loss item: 0.11636020243167877
46
train loss item: 0.12064026296138763
47
train loss item: 0.4134993553161621
48
train loss item: 0.25970426201820374
49
train loss item: 0.17621691524982452
50
train loss item: 0.36374351382255554
51
train loss item: 0.9693316221237183
52
train loss item: 0.06020338833332062
53
train loss item: 0.15840911865234375
54
train loss item: 2.3339755535125732
55
train loss item: 0.23873023688793182
56
train loss item: 0.32312071323394775
57
train loss item: 0.2662785053253174
58
train loss item: 0.1839803159236908
59
train loss item: 0.09689724445343018
60
train loss item: 0.9645538330078125
61
train loss item: 2.266578435897827
62
train loss item: 0.24652199447155
63
train loss item: 0.4484213888645172
64
train loss item: 0.17786066234111786
65
train loss item: 0.7184419631958008
66
train loss item: 0.48024851083755493
67
train loss item: 0.22284796833992004
68
train loss item: 0.3676844537258148
69
train loss item: 0.41660869121551514
70
train loss item: 0.3048064112663269
71
train loss item: 0.12663479149341583
72
train loss item: 0.20519204437732697
73
train loss item: 0.35276034474372864
74
train loss item: 0.056919973343610764
75
train loss item: 0.09503403306007385
76
train loss item: 0.9949825406074524
77
train loss item: 1.3721328973770142
78
train loss item: 0.05941995605826378
79
train loss item: 0.3159898519515991
80
train loss item: 0.10805921256542206
81
train loss item: 0.2083161473274231
82
train loss item: 0.22112135589122772
83
train loss item: 0.7021482586860657
84
train loss item: 0.4833115041255951
85
train loss item: 0.6892872452735901
86
train loss item: 4.366738319396973
87
train loss item: 0.1691499650478363
88
train loss item: 0.435453861951828
epoch train loss: 0.5222298127463024
testing phase
test loss item: 0.2147471159696579
test loss item: 0.08639627695083618
test loss item: 0.7128705382347107
test loss item: 0.2614278495311737
test loss item: 0.2920358180999756
test loss item: 0.12980374693870544
test loss item: 2.056966543197632
test loss item: 0.5527920126914978
test loss item: 0.2626112401485443
test loss item: 0.4921233057975769
test loss item: 1.0470572710037231
test loss item: 0.19459272921085358
test loss item: 0.20723651349544525
test loss item: 0.3992040455341339
test loss item: 0.1954074501991272
test loss item: 0.0638885423541069
test loss item: 0.35608428716659546
test loss item: 0.5913576483726501
test loss item: 0.7651968598365784
test loss item: 0.3555019199848175
test loss item: 0.9473943710327148
test loss item: 0.42585813999176025
test loss item: 0.35200658440589905
test loss item: 0.20567724108695984
test loss item: 0.2716846168041229
test loss item: 0.2749846279621124
test loss item: 0.41844239830970764
test loss item: 0.22424571216106415
test loss item: 0.4153877794742584
test loss item: 0.43175196647644043
test loss item: 0.9400811791419983
test loss item: 0.0646032989025116
test loss item: 0.17408840358257294
test loss item: 0.6958996057510376
test loss item: 0.5564098358154297
test loss item: 0.49159273505210876
test loss item: 0.9499384760856628
test loss item: 1.735824704170227
test loss item: 0.6420255303382874
test loss item: 0.32863906025886536
test loss item: 0.363017737865448
test loss item: 0.22056032717227936
test loss item: 0.41795769333839417
test loss item: 0.2585895359516144
test loss item: 0.7820171117782593
test loss item: 0.546261191368103
test loss item: 0.3588547110557556
test loss item: 0.2991984188556671
test loss item: 0.5742630362510681
test loss item: 0.8314672112464905
test loss item: 0.38512641191482544
test loss item: 0.1450389325618744
test loss item: 0.2897384464740753
test loss item: 0.17845918238162994
test loss item: 0.36989229917526245
test loss item: 1.0810052156448364
test loss item: 0.6199844479560852
test loss item: 0.3363475799560547
test loss item: 0.28843754529953003
test loss item: 0.23906098306179047
test loss item: 0.5402076244354248
test loss item: 0.2582288682460785
test loss item: 0.2638740539550781
test loss item: 0.30615895986557007
test loss item: 1.0195530652999878
test loss item: 0.3513789772987366
test loss item: 0.37984371185302734
test loss item: 0.31173115968704224
test loss item: 0.6430706977844238
test loss item: 0.4457709491252899
test loss item: 0.06197585165500641
test loss item: 1.1587945222854614
test loss item: 0.3877587914466858
test loss item: 0.47104594111442566
test loss item: 0.18626265227794647
test loss item: 0.19853436946868896
test loss item: 0.20310524106025696
test loss item: 1.734510064125061
test loss item: 0.565481960773468
test loss item: 0.2310221642255783
test loss item: 0.08832559734582901
test loss item: 1.1104259490966797
test loss item: 1.031696081161499
test loss item: 1.1848286390304565
test loss item: 0.26242828369140625
test loss item: 0.27705544233322144
test loss item: 0.08197923004627228
test loss item: 0.07094967365264893
test loss item: 0.2033858746290207
Epoch [36/50], Training Loss: 0.5222, Testing Loss: 0.4764
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 37/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4684250056743622
1
train loss item: 1.3239905834197998
2
train loss item: 0.25373515486717224
3
train loss item: 0.6179819703102112
4
train loss item: 0.43556657433509827
5
train loss item: 0.37051692605018616
6
train loss item: 0.3066895008087158
7
train loss item: 0.8535974025726318
8
train loss item: 0.14939723908901215
9
train loss item: 0.3044009804725647
10
train loss item: 0.40558797121047974
11
train loss item: 0.3097904324531555
12
train loss item: 0.10581528395414352
13
train loss item: 0.5091315507888794
14
train loss item: 0.2584748864173889
15
train loss item: 0.6768943071365356
16
train loss item: 0.04962433502078056
17
train loss item: 0.35363978147506714
18
train loss item: 0.3861408233642578
19
train loss item: 0.3158210515975952
20
train loss item: 0.2612403631210327
21
train loss item: 0.12936672568321228
22
train loss item: 1.0451226234436035
23
train loss item: 0.9822224378585815
24
train loss item: 0.6785905957221985
25
train loss item: 0.17084570229053497
26
train loss item: 0.21948909759521484
27
train loss item: 0.2694540023803711
28
train loss item: 0.045496273785829544
29
train loss item: 0.7776012420654297
30
train loss item: 2.345094680786133
31
train loss item: 0.6490197777748108
32
train loss item: 0.09122143685817719
33
train loss item: 0.47200098633766174
34
train loss item: 0.10678794234991074
35
train loss item: 2.4581212997436523
36
train loss item: 0.5415804386138916
37
train loss item: 0.4934827983379364
38
train loss item: 0.5699388980865479
39
train loss item: 0.2480938881635666
40
train loss item: 0.15680567920207977
41
train loss item: 0.29042091965675354
42
train loss item: 0.33302658796310425
43
train loss item: 0.20624719560146332
44
train loss item: 0.687552273273468
45
train loss item: 0.1170143187046051
46
train loss item: 0.12128177285194397
47
train loss item: 0.4127374589443207
48
train loss item: 0.25973638892173767
49
train loss item: 0.17631086707115173
50
train loss item: 0.36279022693634033
51
train loss item: 0.962473452091217
52
train loss item: 0.06033795326948166
53
train loss item: 0.1577092409133911
54
train loss item: 2.3222482204437256
55
train loss item: 0.23808233439922333
56
train loss item: 0.319137841463089
57
train loss item: 0.26427239179611206
58
train loss item: 0.18298812210559845
59
train loss item: 0.09598059207201004
60
train loss item: 0.9568381309509277
61
train loss item: 2.252469301223755
62
train loss item: 0.2463388293981552
63
train loss item: 0.44478142261505127
64
train loss item: 0.17476314306259155
65
train loss item: 0.7175611853599548
66
train loss item: 0.4756612181663513
67
train loss item: 0.22244039177894592
68
train loss item: 0.36923110485076904
69
train loss item: 0.4159410893917084
70
train loss item: 0.3035539984703064
71
train loss item: 0.1262698918581009
72
train loss item: 0.2048627883195877
73
train loss item: 0.3518209755420685
74
train loss item: 0.05487941950559616
75
train loss item: 0.09260989725589752
76
train loss item: 0.9914841651916504
77
train loss item: 1.3602080345153809
78
train loss item: 0.06050850823521614
79
train loss item: 0.31104743480682373
80
train loss item: 0.10851190239191055
81
train loss item: 0.20794300734996796
82
train loss item: 0.22124195098876953
83
train loss item: 0.6961494088172913
84
train loss item: 0.4759843349456787
85
train loss item: 0.6853296160697937
86
train loss item: 4.347936630249023
87
train loss item: 0.16629177331924438
88
train loss item: 0.43260863423347473
epoch train loss: 0.5192406179613611
testing phase
test loss item: 0.21284744143486023
test loss item: 0.08691522479057312
test loss item: 0.7109091877937317
test loss item: 0.26117193698883057
test loss item: 0.2917864918708801
test loss item: 0.13209721446037292
test loss item: 2.048264741897583
test loss item: 0.5398992896080017
test loss item: 0.26125332713127136
test loss item: 0.4879131615161896
test loss item: 1.045328140258789
test loss item: 0.18987122178077698
test loss item: 0.2049601674079895
test loss item: 0.39747753739356995
test loss item: 0.1950371265411377
test loss item: 0.06645134836435318
test loss item: 0.3553137481212616
test loss item: 0.5844355225563049
test loss item: 0.757698118686676
test loss item: 0.3528825044631958
test loss item: 0.9431663751602173
test loss item: 0.42408376932144165
test loss item: 0.347912460565567
test loss item: 0.20651774108409882
test loss item: 0.2714081108570099
test loss item: 0.27493032813072205
test loss item: 0.4154827892780304
test loss item: 0.22371578216552734
test loss item: 0.4149433672428131
test loss item: 0.42793118953704834
test loss item: 0.9382807612419128
test loss item: 0.06590664386749268
test loss item: 0.17491574585437775
test loss item: 0.6942754983901978
test loss item: 0.5525220036506653
test loss item: 0.48580312728881836
test loss item: 0.9427017569541931
test loss item: 1.7326760292053223
test loss item: 0.6383700966835022
test loss item: 0.3295460641384125
test loss item: 0.3629973828792572
test loss item: 0.22041501104831696
test loss item: 0.41251593828201294
test loss item: 0.2584384083747864
test loss item: 0.779159426689148
test loss item: 0.5433213710784912
test loss item: 0.3570161759853363
test loss item: 0.29484832286834717
test loss item: 0.569692850112915
test loss item: 0.8256514072418213
test loss item: 0.382158488035202
test loss item: 0.14325293898582458
test loss item: 0.28908559679985046
test loss item: 0.17469555139541626
test loss item: 0.36809104681015015
test loss item: 1.0782630443572998
test loss item: 0.6138072609901428
test loss item: 0.3354228138923645
test loss item: 0.2868805527687073
test loss item: 0.23766979575157166
test loss item: 0.5324896574020386
test loss item: 0.25613492727279663
test loss item: 0.2622840404510498
test loss item: 0.3060467541217804
test loss item: 1.020646095275879
test loss item: 0.3501289486885071
test loss item: 0.37749776244163513
test loss item: 0.3119744062423706
test loss item: 0.6406533718109131
test loss item: 0.43718865513801575
test loss item: 0.06576953828334808
test loss item: 1.1508166790008545
test loss item: 0.38551065325737
test loss item: 0.47141456604003906
test loss item: 0.1852373480796814
test loss item: 0.19817373156547546
test loss item: 0.20367205142974854
test loss item: 1.736236810684204
test loss item: 0.5644840598106384
test loss item: 0.23048262298107147
test loss item: 0.09020163118839264
test loss item: 1.1056010723114014
test loss item: 1.0259286165237427
test loss item: 1.183725118637085
test loss item: 0.2612740099430084
test loss item: 0.27588558197021484
test loss item: 0.08572111278772354
test loss item: 0.07623422145843506
test loss item: 0.20476721227169037
Epoch [37/50], Training Loss: 0.5192, Testing Loss: 0.4744
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Epoch 38/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46964165568351746
1
train loss item: 1.3091051578521729
2
train loss item: 0.2534249722957611
3
train loss item: 0.6096603870391846
4
train loss item: 0.43487274646759033
5
train loss item: 0.3710400462150574
6
train loss item: 0.30636489391326904
7
train loss item: 0.8477939367294312
8
train loss item: 0.14888592064380646
9
train loss item: 0.3036239445209503
10
train loss item: 0.40482407808303833
11
train loss item: 0.3051079511642456
12
train loss item: 0.10441970825195312
13
train loss item: 0.5071349143981934
14
train loss item: 0.25692132115364075
15
train loss item: 0.6690755486488342
16
train loss item: 0.04897527024149895
17
train loss item: 0.35281994938850403
18
train loss item: 0.38648080825805664
19
train loss item: 0.3159807622432709
20
train loss item: 0.2602846920490265
21
train loss item: 0.12767094373703003
22
train loss item: 1.0343273878097534
23
train loss item: 0.9755727052688599
24
train loss item: 0.674744725227356
25
train loss item: 0.1677771508693695
26
train loss item: 0.21834947168827057
27
train loss item: 0.2677011489868164
28
train loss item: 0.044594306498765945
29
train loss item: 0.7649485468864441
30
train loss item: 2.325730562210083
31
train loss item: 0.6504552960395813
32
train loss item: 0.09020183980464935
33
train loss item: 0.4640016257762909
34
train loss item: 0.10463449358940125
35
train loss item: 2.4445111751556396
36
train loss item: 0.5401342511177063
37
train loss item: 0.48749834299087524
38
train loss item: 0.5791316628456116
39
train loss item: 0.2508031129837036
40
train loss item: 0.15606866776943207
41
train loss item: 0.29029107093811035
42
train loss item: 0.3290957808494568
43
train loss item: 0.20541994273662567
44
train loss item: 0.6842055320739746
45
train loss item: 0.11783341318368912
46
train loss item: 0.12250062078237534
47
train loss item: 0.4115506708621979
48
train loss item: 0.2585923671722412
49
train loss item: 0.17565041780471802
50
train loss item: 0.3613637685775757
51
train loss item: 0.9516581892967224
52
train loss item: 0.0593094639480114
53
train loss item: 0.15648092329502106
54
train loss item: 2.309464693069458
55
train loss item: 0.2368292212486267
56
train loss item: 0.3198651075363159
57
train loss item: 0.2616579234600067
58
train loss item: 0.18223504722118378
59
train loss item: 0.09470558166503906
60
train loss item: 0.9450834393501282
61
train loss item: 2.2333407402038574
62
train loss item: 0.24511811137199402
63
train loss item: 0.44170457124710083
64
train loss item: 0.172620952129364
65
train loss item: 0.7144718170166016
66
train loss item: 0.4722590744495392
67
train loss item: 0.22122111916542053
68
train loss item: 0.3676265776157379
69
train loss item: 0.41685304045677185
70
train loss item: 0.3022112548351288
71
train loss item: 0.1259772628545761
72
train loss item: 0.2042127102613449
73
train loss item: 0.351432204246521
74
train loss item: 0.053680650889873505
75
train loss item: 0.09098752588033676
76
train loss item: 0.9841054677963257
77
train loss item: 1.3462917804718018
78
train loss item: 0.059715386480093
79
train loss item: 0.3076864182949066
80
train loss item: 0.10938900709152222
81
train loss item: 0.20744267106056213
82
train loss item: 0.2203546166419983
83
train loss item: 0.6864747405052185
84
train loss item: 0.47181203961372375
85
train loss item: 0.6796913146972656
86
train loss item: 4.327578544616699
87
train loss item: 0.16494950652122498
88
train loss item: 0.428585022687912
epoch train loss: 0.5159200380524892
testing phase
test loss item: 0.20906858146190643
test loss item: 0.08636034280061722
test loss item: 0.7060216069221497
test loss item: 0.2606455981731415
test loss item: 0.29071104526519775
test loss item: 0.13384082913398743
test loss item: 2.0408987998962402
test loss item: 0.5253251791000366
test loss item: 0.2581460475921631
test loss item: 0.48255977034568787
test loss item: 1.0396184921264648
test loss item: 0.18521949648857117
test loss item: 0.2027716487646103
test loss item: 0.3973841369152069
test loss item: 0.19403795897960663
test loss item: 0.06676995009183884
test loss item: 0.35528767108917236
test loss item: 0.5761723518371582
test loss item: 0.7503476738929749
test loss item: 0.3527543544769287
test loss item: 0.9342373013496399
test loss item: 0.42273059487342834
test loss item: 0.34357950091362
test loss item: 0.2069571167230606
test loss item: 0.2704358398914337
test loss item: 0.2753957211971283
test loss item: 0.4134843945503235
test loss item: 0.2225978970527649
test loss item: 0.4144030809402466
test loss item: 0.42400285601615906
test loss item: 0.9343225955963135
test loss item: 0.06403307616710663
test loss item: 0.17490920424461365
test loss item: 0.6906628012657166
test loss item: 0.5465537309646606
test loss item: 0.47874873876571655
test loss item: 0.9349891543388367
test loss item: 1.7216452360153198
test loss item: 0.6332330107688904
test loss item: 0.33098164200782776
test loss item: 0.3633998930454254
test loss item: 0.2229050248861313
test loss item: 0.4074230194091797
test loss item: 0.2586485743522644
test loss item: 0.771185040473938
test loss item: 0.5420390367507935
test loss item: 0.35498541593551636
test loss item: 0.29376715421676636
test loss item: 0.563641369342804
test loss item: 0.8182204961776733
test loss item: 0.3762635290622711
test loss item: 0.1415531486272812
test loss item: 0.28776484727859497
test loss item: 0.17113333940505981
test loss item: 0.36392128467559814
test loss item: 1.0707741975784302
test loss item: 0.6062119603157043
test loss item: 0.33063754439353943
test loss item: 0.2851269841194153
test loss item: 0.23522262275218964
test loss item: 0.524200439453125
test loss item: 0.25430750846862793
test loss item: 0.2607307732105255
test loss item: 0.30633142590522766
test loss item: 1.0171010494232178
test loss item: 0.3485623300075531
test loss item: 0.3763355016708374
test loss item: 0.31284868717193604
test loss item: 0.6364971995353699
test loss item: 0.43023818731307983
test loss item: 0.06898185610771179
test loss item: 1.1439709663391113
test loss item: 0.3837806284427643
test loss item: 0.473797470331192
test loss item: 0.18459446728229523
test loss item: 0.19885021448135376
test loss item: 0.20408232510089874
test loss item: 1.7272297143936157
test loss item: 0.5642828941345215
test loss item: 0.22904185950756073
test loss item: 0.09020189195871353
test loss item: 1.0987669229507446
test loss item: 1.019544005393982
test loss item: 1.175374150276184
test loss item: 0.2616749107837677
test loss item: 0.27486544847488403
test loss item: 0.08632821589708328
test loss item: 0.07821046561002731
test loss item: 0.20943380892276764
Epoch [38/50], Training Loss: 0.5159, Testing Loss: 0.4714
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 39/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4700948894023895
1
train loss item: 1.2936890125274658
2
train loss item: 0.25370413064956665
3
train loss item: 0.6024110317230225
4
train loss item: 0.4349433183670044
5
train loss item: 0.37175253033638
6
train loss item: 0.30549871921539307
7
train loss item: 0.8426723480224609
8
train loss item: 0.14794208109378815
9
train loss item: 0.30384448170661926
10
train loss item: 0.4055205285549164
11
train loss item: 0.29930081963539124
12
train loss item: 0.10267692059278488
13
train loss item: 0.5058469772338867
14
train loss item: 0.2550974488258362
15
train loss item: 0.6612449884414673
16
train loss item: 0.047490544617176056
17
train loss item: 0.3514496386051178
18
train loss item: 0.38694843649864197
19
train loss item: 0.31637611985206604
20
train loss item: 0.25670963525772095
21
train loss item: 0.1264924854040146
22
train loss item: 1.0217889547348022
23
train loss item: 0.9700987339019775
24
train loss item: 0.6711823344230652
25
train loss item: 0.16584645211696625
26
train loss item: 0.21746036410331726
27
train loss item: 0.2669369578361511
28
train loss item: 0.04323798045516014
29
train loss item: 0.7529692053794861
30
train loss item: 2.3064446449279785
31
train loss item: 0.654204249382019
32
train loss item: 0.08924397081136703
33
train loss item: 0.4568347930908203
34
train loss item: 0.10267944633960724
35
train loss item: 2.431328296661377
36
train loss item: 0.5371590256690979
37
train loss item: 0.4821884334087372
38
train loss item: 0.5894729495048523
39
train loss item: 0.254160612821579
40
train loss item: 0.15614311397075653
41
train loss item: 0.2909766435623169
42
train loss item: 0.3245261311531067
43
train loss item: 0.20507410168647766
44
train loss item: 0.6812314391136169
45
train loss item: 0.11765817552804947
46
train loss item: 0.12331853061914444
47
train loss item: 0.4103619456291199
48
train loss item: 0.25822189450263977
49
train loss item: 0.17433485388755798
50
train loss item: 0.3601796627044678
51
train loss item: 0.9416354298591614
52
train loss item: 0.05772602558135986
53
train loss item: 0.15486861765384674
54
train loss item: 2.2967138290405273
55
train loss item: 0.23569828271865845
56
train loss item: 0.3211267292499542
57
train loss item: 0.25914233922958374
58
train loss item: 0.18150396645069122
59
train loss item: 0.09466661512851715
60
train loss item: 0.9348835945129395
61
train loss item: 2.214961528778076
62
train loss item: 0.24293622374534607
63
train loss item: 0.43816468119621277
64
train loss item: 0.17175300419330597
65
train loss item: 0.709136962890625
66
train loss item: 0.4685196578502655
67
train loss item: 0.21921633183956146
68
train loss item: 0.36436375975608826
69
train loss item: 0.41767922043800354
70
train loss item: 0.2999153435230255
71
train loss item: 0.12569336593151093
72
train loss item: 0.20429541170597076
73
train loss item: 0.3516596853733063
74
train loss item: 0.05347011238336563
75
train loss item: 0.09073896706104279
76
train loss item: 0.9777178168296814
77
train loss item: 1.3327494859695435
78
train loss item: 0.05739814043045044
79
train loss item: 0.30405646562576294
80
train loss item: 0.10940693318843842
81
train loss item: 0.207048699259758
82
train loss item: 0.21970809996128082
83
train loss item: 0.6755462884902954
84
train loss item: 0.4672408699989319
85
train loss item: 0.6752967238426208
86
train loss item: 4.306973934173584
87
train loss item: 0.1645989716053009
88
train loss item: 0.42469683289527893
epoch train loss: 0.5126952801443888
testing phase
test loss item: 0.20583869516849518
test loss item: 0.08526328206062317
test loss item: 0.7040218710899353
test loss item: 0.2599204182624817
test loss item: 0.2895691692829132
test loss item: 0.13398048281669617
test loss item: 2.040675163269043
test loss item: 0.5205041170120239
test loss item: 0.2557171583175659
test loss item: 0.47882041335105896
test loss item: 1.0351930856704712
test loss item: 0.18248909711837769
test loss item: 0.2017439752817154
test loss item: 0.3987741768360138
test loss item: 0.19303591549396515
test loss item: 0.0643138512969017
test loss item: 0.35653936862945557
test loss item: 0.5712814927101135
test loss item: 0.7485951781272888
test loss item: 0.35578128695487976
test loss item: 0.9274695515632629
test loss item: 0.4238216280937195
test loss item: 0.3418251872062683
test loss item: 0.2073514312505722
test loss item: 0.2692885398864746
test loss item: 0.276403546333313
test loss item: 0.4134809374809265
test loss item: 0.22149249911308289
test loss item: 0.4145171046257019
test loss item: 0.4218568503856659
test loss item: 0.9321480393409729
test loss item: 0.06001242995262146
test loss item: 0.17471161484718323
test loss item: 0.6879988312721252
test loss item: 0.5432141423225403
test loss item: 0.4754943251609802
test loss item: 0.9321283102035522
test loss item: 1.7136545181274414
test loss item: 0.6289551854133606
test loss item: 0.3327518701553345
test loss item: 0.3642144203186035
test loss item: 0.22623808681964874
test loss item: 0.40329962968826294
test loss item: 0.2589079737663269
test loss item: 0.7639895081520081
test loss item: 0.5446703433990479
test loss item: 0.3540230989456177
test loss item: 0.2959345579147339
test loss item: 0.5608134865760803
test loss item: 0.8141809105873108
test loss item: 0.3702410161495209
test loss item: 0.14086610078811646
test loss item: 0.28615128993988037
test loss item: 0.169041708111763
test loss item: 0.35989633202552795
test loss item: 1.0674023628234863
test loss item: 0.6033121347427368
test loss item: 0.3254157602787018
test loss item: 0.2846735417842865
test loss item: 0.23235519230365753
test loss item: 0.5188779830932617
test loss item: 0.2557990550994873
test loss item: 0.2612980604171753
test loss item: 0.30717071890830994
test loss item: 1.0177464485168457
test loss item: 0.34680086374282837
test loss item: 0.37804561853408813
test loss item: 0.31412047147750854
test loss item: 0.6345252394676208
test loss item: 0.42995232343673706
test loss item: 0.07004132121801376
test loss item: 1.1440234184265137
test loss item: 0.38406264781951904
test loss item: 0.4789230525493622
test loss item: 0.18419049680233002
test loss item: 0.20000313222408295
test loss item: 0.20464226603507996
test loss item: 1.7198894023895264
test loss item: 0.5660215616226196
test loss item: 0.22809918224811554
test loss item: 0.08796707540750504
test loss item: 1.0970722436904907
test loss item: 1.0171170234680176
test loss item: 1.1697564125061035
test loss item: 0.2638169527053833
test loss item: 0.27362871170043945
test loss item: 0.083448126912117
test loss item: 0.07591749727725983
test loss item: 0.2137334942817688
Epoch [39/50], Training Loss: 0.5127, Testing Loss: 0.4700
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 40/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4700167179107666
1
train loss item: 1.2798293828964233
2
train loss item: 0.2538650929927826
3
train loss item: 0.5959044694900513
4
train loss item: 0.4345550239086151
5
train loss item: 0.37251970171928406
6
train loss item: 0.3053044378757477
7
train loss item: 0.8373734354972839
8
train loss item: 0.14737439155578613
9
train loss item: 0.3045518696308136
10
train loss item: 0.405845582485199
11
train loss item: 0.2929307222366333
12
train loss item: 0.10086767375469208
13
train loss item: 0.5050116777420044
14
train loss item: 0.25437110662460327
15
train loss item: 0.6562674641609192
16
train loss item: 0.04589886963367462
17
train loss item: 0.3507324755191803
18
train loss item: 0.38860663771629333
19
train loss item: 0.31702920794487
20
train loss item: 0.25371241569519043
21
train loss item: 0.12436641752719879
22
train loss item: 1.0122162103652954
23
train loss item: 0.9634298086166382
24
train loss item: 0.6675650477409363
25
train loss item: 0.16371077299118042
26
train loss item: 0.21589195728302002
27
train loss item: 0.2669592499732971
28
train loss item: 0.04220573231577873
29
train loss item: 0.7442746162414551
30
train loss item: 2.287405252456665
31
train loss item: 0.6568980813026428
32
train loss item: 0.08957210928201675
33
train loss item: 0.4515770971775055
34
train loss item: 0.1026921272277832
35
train loss item: 2.418034791946411
36
train loss item: 0.5325314998626709
37
train loss item: 0.47471871972084045
38
train loss item: 0.5976244211196899
39
train loss item: 0.25709396600723267
40
train loss item: 0.15637318789958954
41
train loss item: 0.29158052802085876
42
train loss item: 0.32021185755729675
43
train loss item: 0.20502303540706635
44
train loss item: 0.6775383949279785
45
train loss item: 0.11778508871793747
46
train loss item: 0.12295147031545639
47
train loss item: 0.4093969166278839
48
train loss item: 0.2583518922328949
49
train loss item: 0.17216582596302032
50
train loss item: 0.3597145974636078
51
train loss item: 0.9337173700332642
52
train loss item: 0.056219130754470825
53
train loss item: 0.1538103073835373
54
train loss item: 2.2835428714752197
55
train loss item: 0.23546937108039856
56
train loss item: 0.32181432843208313
57
train loss item: 0.2569742500782013
58
train loss item: 0.18085332214832306
59
train loss item: 0.09480313956737518
60
train loss item: 0.9263434410095215
61
train loss item: 2.196211814880371
62
train loss item: 0.24094203114509583
63
train loss item: 0.43454650044441223
64
train loss item: 0.1719423234462738
65
train loss item: 0.705099880695343
66
train loss item: 0.4628463387489319
67
train loss item: 0.2171049565076828
68
train loss item: 0.36274588108062744
69
train loss item: 0.41824018955230713
70
train loss item: 0.2980848550796509
71
train loss item: 0.12564128637313843
72
train loss item: 0.20500506460666656
73
train loss item: 0.35206544399261475
74
train loss item: 0.05471450462937355
75
train loss item: 0.09221062809228897
76
train loss item: 0.9703794717788696
77
train loss item: 1.3202407360076904
78
train loss item: 0.05411933735013008
79
train loss item: 0.29995208978652954
80
train loss item: 0.10992622375488281
81
train loss item: 0.20640800893306732
82
train loss item: 0.21919706463813782
83
train loss item: 0.6659218072891235
84
train loss item: 0.4602939486503601
85
train loss item: 0.6708110570907593
86
train loss item: 4.286009311676025
87
train loss item: 0.16468746960163116
88
train loss item: 0.4230748116970062
epoch train loss: 0.509712355064877
testing phase
test loss item: 0.20296534895896912
test loss item: 0.08400304615497589
test loss item: 0.7033016681671143
test loss item: 0.25690802931785583
test loss item: 0.28753411769866943
test loss item: 0.13127575814723969
test loss item: 2.0474648475646973
test loss item: 0.5265036225318909
test loss item: 0.2525961101055145
test loss item: 0.47597014904022217
test loss item: 1.0329467058181763
test loss item: 0.18090207874774933
test loss item: 0.20194460451602936
test loss item: 0.3998733460903168
test loss item: 0.1921265870332718
test loss item: 0.061118438839912415
test loss item: 0.35812968015670776
test loss item: 0.5681566596031189
test loss item: 0.7512774467468262
test loss item: 0.3601855933666229
test loss item: 0.9220811724662781
test loss item: 0.4266602694988251
test loss item: 0.34121057391166687
test loss item: 0.20737482607364655
test loss item: 0.26747941970825195
test loss item: 0.27735263109207153
test loss item: 0.41418105363845825
test loss item: 0.2197936475276947
test loss item: 0.414612740278244
test loss item: 0.4211573004722595
test loss item: 0.9319425821304321
test loss item: 0.05615263432264328
test loss item: 0.17393450438976288
test loss item: 0.6838772296905518
test loss item: 0.540799617767334
test loss item: 0.4740307033061981
test loss item: 0.9336240887641907
test loss item: 1.7115105390548706
test loss item: 0.62331223487854
test loss item: 0.33397141098976135
test loss item: 0.364892840385437
test loss item: 0.22720761597156525
test loss item: 0.3995937407016754
test loss item: 0.2568412721157074
test loss item: 0.7579978108406067
test loss item: 0.550453245639801
test loss item: 0.3531217873096466
test loss item: 0.298700749874115
test loss item: 0.559918224811554
test loss item: 0.8120140433311462
test loss item: 0.3650417625904083
test loss item: 0.14111578464508057
test loss item: 0.2839122414588928
test loss item: 0.16501069068908691
test loss item: 0.35634100437164307
test loss item: 1.0660666227340698
test loss item: 0.604747474193573
test loss item: 0.3219175338745117
test loss item: 0.2852244973182678
test loss item: 0.22979916632175446
test loss item: 0.5156018137931824
test loss item: 0.2604045271873474
test loss item: 0.2627823054790497
test loss item: 0.3084757626056671
test loss item: 1.0250626802444458
test loss item: 0.3425524830818176
test loss item: 0.38160085678100586
test loss item: 0.3153335154056549
test loss item: 0.6345266103744507
test loss item: 0.43204379081726074
test loss item: 0.06949819624423981
test loss item: 1.151291012763977
test loss item: 0.3841465413570404
test loss item: 0.48460325598716736
test loss item: 0.18305081129074097
test loss item: 0.19997641444206238
test loss item: 0.2049768716096878
test loss item: 1.7220710515975952
test loss item: 0.5672341585159302
test loss item: 0.2263094037771225
test loss item: 0.08406151831150055
test loss item: 1.1006735563278198
test loss item: 1.0178579092025757
test loss item: 1.1706922054290771
test loss item: 0.26643460988998413
test loss item: 0.27156201004981995
test loss item: 0.07822326570749283
test loss item: 0.07105349749326706
test loss item: 0.21218305826187134
Epoch [40/50], Training Loss: 0.5097, Testing Loss: 0.4696
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 41/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4685818552970886
1
train loss item: 1.2684019804000854
2
train loss item: 0.2535218894481659
3
train loss item: 0.5894598960876465
4
train loss item: 0.4334017336368561
5
train loss item: 0.37252944707870483
6
train loss item: 0.3060610592365265
7
train loss item: 0.832069456577301
8
train loss item: 0.14790815114974976
9
train loss item: 0.3052666485309601
10
train loss item: 0.4038861393928528
11
train loss item: 0.28542986512184143
12
train loss item: 0.1000458151102066
13
train loss item: 0.5041652917861938
14
train loss item: 0.25540003180503845
15
train loss item: 0.6531948447227478
16
train loss item: 0.046129871159791946
17
train loss item: 0.3507423400878906
18
train loss item: 0.3897722661495209
19
train loss item: 0.3173462152481079
20
train loss item: 0.2529836595058441
21
train loss item: 0.12142349034547806
22
train loss item: 1.0052458047866821
23
train loss item: 0.9556427001953125
24
train loss item: 0.6646100878715515
25
train loss item: 0.1617927849292755
26
train loss item: 0.21404027938842773
27
train loss item: 0.26875555515289307
28
train loss item: 0.04286797717213631
29
train loss item: 0.7370572090148926
30
train loss item: 2.26763653755188
31
train loss item: 0.6532837152481079
32
train loss item: 0.0911637470126152
33
train loss item: 0.44843751192092896
34
train loss item: 0.10348515957593918
35
train loss item: 2.4051074981689453
36
train loss item: 0.5260107517242432
37
train loss item: 0.4620884656906128
38
train loss item: 0.5953261256217957
39
train loss item: 0.2568894922733307
40
train loss item: 0.15623995661735535
41
train loss item: 0.2919022738933563
42
train loss item: 0.3156359791755676
43
train loss item: 0.20450372993946075
44
train loss item: 0.6739248037338257
45
train loss item: 0.11776859313249588
46
train loss item: 0.121237613260746
47
train loss item: 0.4085645079612732
48
train loss item: 0.25915297865867615
49
train loss item: 0.16899622976779938
50
train loss item: 0.3596705496311188
51
train loss item: 0.9285956025123596
52
train loss item: 0.0547046922147274
53
train loss item: 0.15425869822502136
54
train loss item: 2.270012855529785
55
train loss item: 0.23598824441432953
56
train loss item: 0.3187084197998047
57
train loss item: 0.2554701864719391
58
train loss item: 0.18028613924980164
59
train loss item: 0.09443864971399307
60
train loss item: 0.9219655990600586
61
train loss item: 2.177603006362915
62
train loss item: 0.23951111733913422
63
train loss item: 0.43039169907569885
64
train loss item: 0.17180438339710236
65
train loss item: 0.7021515369415283
66
train loss item: 0.45409879088401794
67
train loss item: 0.21505945920944214
68
train loss item: 0.3644271194934845
69
train loss item: 0.41675201058387756
70
train loss item: 0.29643648862838745
71
train loss item: 0.12511484324932098
72
train loss item: 0.20711180567741394
73
train loss item: 0.3517634868621826
74
train loss item: 0.05628253519535065
75
train loss item: 0.09413894265890121
76
train loss item: 0.9651755690574646
77
train loss item: 1.3104630708694458
78
train loss item: 0.05184314399957657
79
train loss item: 0.2945060133934021
80
train loss item: 0.10968128591775894
81
train loss item: 0.205134779214859
82
train loss item: 0.2188979983329773
83
train loss item: 0.6593502759933472
84
train loss item: 0.4480409324169159
85
train loss item: 0.6668189167976379
86
train loss item: 4.26458215713501
87
train loss item: 0.16347776353359222
88
train loss item: 0.4206535220146179
epoch train loss: 0.5066344079592925
testing phase
test loss item: 0.2003091722726822
test loss item: 0.08287666738033295
test loss item: 0.7078964710235596
test loss item: 0.24959425628185272
test loss item: 0.28626611828804016
test loss item: 0.12689000368118286
test loss item: 2.0528838634490967
test loss item: 0.5351472496986389
test loss item: 0.2510303854942322
test loss item: 0.474826842546463
test loss item: 1.0352792739868164
test loss item: 0.17898660898208618
test loss item: 0.20204585790634155
test loss item: 0.39971303939819336
test loss item: 0.19195277988910675
test loss item: 0.059437938034534454
test loss item: 0.3586858808994293
test loss item: 0.5678653120994568
test loss item: 0.7544671297073364
test loss item: 0.36286741495132446
test loss item: 0.9219375252723694
test loss item: 0.42780596017837524
test loss item: 0.3413364887237549
test loss item: 0.2066008299589157
test loss item: 0.2660781741142273
test loss item: 0.27758657932281494
test loss item: 0.4146100878715515
test loss item: 0.21800537407398224
test loss item: 0.4143311679363251
test loss item: 0.42117735743522644
test loss item: 0.9335861802101135
test loss item: 0.05481678992509842
test loss item: 0.17330870032310486
test loss item: 0.6810069680213928
test loss item: 0.5418632626533508
test loss item: 0.47374996542930603
test loss item: 0.9359610080718994
test loss item: 1.7211822271347046
test loss item: 0.6158208847045898
test loss item: 0.33383697271347046
test loss item: 0.36473366618156433
test loss item: 0.22484557330608368
test loss item: 0.3981783390045166
test loss item: 0.2496890425682068
test loss item: 0.7556474804878235
test loss item: 0.5552099347114563
test loss item: 0.3519878089427948
test loss item: 0.2997351288795471
test loss item: 0.5619308948516846
test loss item: 0.8126808404922485
test loss item: 0.36184149980545044
test loss item: 0.14128725230693817
test loss item: 0.2818398177623749
test loss item: 0.15478092432022095
test loss item: 0.35502859950065613
test loss item: 1.0715292692184448
test loss item: 0.6085888147354126
test loss item: 0.32080498337745667
test loss item: 0.2855512499809265
test loss item: 0.22802527248859406
test loss item: 0.5148013234138489
test loss item: 0.26423710584640503
test loss item: 0.2630142271518707
test loss item: 0.3092501759529114
test loss item: 1.0402553081512451
test loss item: 0.33347687125205994
test loss item: 0.3843431770801544
test loss item: 0.31567999720573425
test loss item: 0.63886958360672
test loss item: 0.4331718683242798
test loss item: 0.06808402389287949
test loss item: 1.1586220264434814
test loss item: 0.38330262899398804
test loss item: 0.48714467883110046
test loss item: 0.18109259009361267
test loss item: 0.19813412427902222
test loss item: 0.20510144531726837
test loss item: 1.739518165588379
test loss item: 0.5681176781654358
test loss item: 0.22345969080924988
test loss item: 0.08040405064821243
test loss item: 1.1084409952163696
test loss item: 1.0194693803787231
test loss item: 1.1816169023513794
test loss item: 0.26817256212234497
test loss item: 0.2692805826663971
test loss item: 0.0734630674123764
test loss item: 0.0675647109746933
test loss item: 0.2078360915184021
Epoch [41/50], Training Loss: 0.5066, Testing Loss: 0.4699
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 42/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46771395206451416
1
train loss item: 1.2583909034729004
2
train loss item: 0.25268980860710144
3
train loss item: 0.5826579332351685
4
train loss item: 0.4318195581436157
5
train loss item: 0.3728638291358948
6
train loss item: 0.30441394448280334
7
train loss item: 0.8259637951850891
8
train loss item: 0.14888933300971985
9
train loss item: 0.30528831481933594
10
train loss item: 0.4000932574272156
11
train loss item: 0.279295414686203
12
train loss item: 0.09998194128274918
13
train loss item: 0.5036956071853638
14
train loss item: 0.25757721066474915
15
train loss item: 0.6501902937889099
16
train loss item: 0.046862438321113586
17
train loss item: 0.35083651542663574
18
train loss item: 0.3904995620250702
19
train loss item: 0.3169418275356293
20
train loss item: 0.2530732750892639
21
train loss item: 0.12006815522909164
22
train loss item: 0.9987584352493286
23
train loss item: 0.9485964179039001
24
train loss item: 0.6614689230918884
25
train loss item: 0.16026750206947327
26
train loss item: 0.21296997368335724
27
train loss item: 0.2712514400482178
28
train loss item: 0.04361259564757347
29
train loss item: 0.7295438051223755
30
train loss item: 2.246706485748291
31
train loss item: 0.6453221440315247
32
train loss item: 0.09123730659484863
33
train loss item: 0.44664645195007324
34
train loss item: 0.10500810295343399
35
train loss item: 2.391288995742798
36
train loss item: 0.5200411081314087
37
train loss item: 0.450287401676178
38
train loss item: 0.5852744579315186
39
train loss item: 0.25438040494918823
40
train loss item: 0.15564464032649994
41
train loss item: 0.291987806558609
42
train loss item: 0.3122340738773346
43
train loss item: 0.2035742998123169
44
train loss item: 0.6708610653877258
45
train loss item: 0.11701027303934097
46
train loss item: 0.11910822242498398
47
train loss item: 0.40721505880355835
48
train loss item: 0.25999516248703003
49
train loss item: 0.16649211943149567
50
train loss item: 0.3597375750541687
51
train loss item: 0.9236632585525513
52
train loss item: 0.05391259863972664
53
train loss item: 0.15591484308242798
54
train loss item: 2.2552342414855957
55
train loss item: 0.2365981936454773
56
train loss item: 0.31326234340667725
57
train loss item: 0.254655659198761
58
train loss item: 0.1796521544456482
59
train loss item: 0.09375806897878647
60
train loss item: 0.9194812178611755
61
train loss item: 2.158449172973633
62
train loss item: 0.23881873488426208
63
train loss item: 0.426435649394989
64
train loss item: 0.17112573981285095
65
train loss item: 0.701531171798706
66
train loss item: 0.44605380296707153
67
train loss item: 0.21427223086357117
68
train loss item: 0.3673746883869171
69
train loss item: 0.4140612483024597
70
train loss item: 0.29550161957740784
71
train loss item: 0.12362860888242722
72
train loss item: 0.2098391056060791
73
train loss item: 0.3507384955883026
74
train loss item: 0.05540821701288223
75
train loss item: 0.09498558938503265
76
train loss item: 0.9602823257446289
77
train loss item: 1.3007171154022217
78
train loss item: 0.05148730427026749
79
train loss item: 0.28965872526168823
80
train loss item: 0.10813496261835098
81
train loss item: 0.20420695841312408
82
train loss item: 0.21885180473327637
83
train loss item: 0.6530282497406006
84
train loss item: 0.4357723891735077
85
train loss item: 0.6626946926116943
86
train loss item: 4.242317199707031
87
train loss item: 0.16104815900325775
88
train loss item: 0.4171653985977173
epoch train loss: 0.5034387759613187
testing phase
test loss item: 0.1984301209449768
test loss item: 0.08191976696252823
test loss item: 0.7136807441711426
test loss item: 0.24189738929271698
test loss item: 0.2854061424732208
test loss item: 0.12238694727420807
test loss item: 2.0458407402038574
test loss item: 0.5362072587013245
test loss item: 0.24972033500671387
test loss item: 0.47332435846328735
test loss item: 1.0379265546798706
test loss item: 0.17488309741020203
test loss item: 0.20005005598068237
test loss item: 0.3982866108417511
test loss item: 0.19142572581768036
test loss item: 0.05944991111755371
test loss item: 0.3565974235534668
test loss item: 0.5671892166137695
test loss item: 0.7537935376167297
test loss item: 0.361264169216156
test loss item: 0.9229166507720947
test loss item: 0.42531466484069824
test loss item: 0.3405247926712036
test loss item: 0.20512862503528595
test loss item: 0.2650032639503479
test loss item: 0.27622389793395996
test loss item: 0.4132007360458374
test loss item: 0.21587418019771576
test loss item: 0.4124774932861328
test loss item: 0.42009639739990234
test loss item: 0.9323174953460693
test loss item: 0.05467879772186279
test loss item: 0.17276088893413544
test loss item: 0.6797747611999512
test loss item: 0.5437784790992737
test loss item: 0.47278451919555664
test loss item: 0.933876097202301
test loss item: 1.7331236600875854
test loss item: 0.6070814728736877
test loss item: 0.3315907120704651
test loss item: 0.3630903959274292
test loss item: 0.2205168753862381
test loss item: 0.3975783884525299
test loss item: 0.24051569402217865
test loss item: 0.7544800639152527
test loss item: 0.5544238686561584
test loss item: 0.3501390814781189
test loss item: 0.29778987169265747
test loss item: 0.5628941059112549
test loss item: 0.8122650980949402
test loss item: 0.359623521566391
test loss item: 0.14033131301403046
test loss item: 0.27984723448753357
test loss item: 0.14620646834373474
test loss item: 0.35498154163360596
test loss item: 1.0785071849822998
test loss item: 0.6104963421821594
test loss item: 0.32062390446662903
test loss item: 0.2841804325580597
test loss item: 0.2265109121799469
test loss item: 0.5141608715057373
test loss item: 0.26309314370155334
test loss item: 0.26073887944221497
test loss item: 0.3085022568702698
test loss item: 1.0534062385559082
test loss item: 0.32543447613716125
test loss item: 0.3829978108406067
test loss item: 0.3143827021121979
test loss item: 0.6444736123085022
test loss item: 0.43121519684791565
test loss item: 0.06525427848100662
test loss item: 1.1570547819137573
test loss item: 0.3807779550552368
test loss item: 0.48407748341560364
test loss item: 0.17792633175849915
test loss item: 0.1949668526649475
test loss item: 0.20424234867095947
test loss item: 1.758618950843811
test loss item: 0.5678464770317078
test loss item: 0.22019843757152557
test loss item: 0.07795129716396332
test loss item: 1.1124588251113892
test loss item: 1.0172721147537231
test loss item: 1.1927168369293213
test loss item: 0.2682204842567444
test loss item: 0.2665046155452728
test loss item: 0.07143804430961609
test loss item: 0.06816250830888748
test loss item: 0.20432662963867188
Epoch [42/50], Training Loss: 0.5034, Testing Loss: 0.4691
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 43/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4691305160522461
1
train loss item: 1.246895432472229
2
train loss item: 0.2512916326522827
3
train loss item: 0.5757781267166138
4
train loss item: 0.43023255467414856
5
train loss item: 0.37407347559928894
6
train loss item: 0.30293965339660645
7
train loss item: 0.8174657821655273
8
train loss item: 0.1492953598499298
9
train loss item: 0.3033727705478668
10
train loss item: 0.39625129103660583
11
train loss item: 0.27832359075546265
12
train loss item: 0.10031004250049591
13
train loss item: 0.5043044686317444
14
train loss item: 0.2598329186439514
15
train loss item: 0.645091712474823
16
train loss item: 0.04746482893824577
17
train loss item: 0.35015857219696045
18
train loss item: 0.3904980719089508
19
train loss item: 0.31495770812034607
20
train loss item: 0.2507011294364929
21
train loss item: 0.12519554793834686
22
train loss item: 0.9896277189254761
23
train loss item: 0.9405713677406311
24
train loss item: 0.6558198928833008
25
train loss item: 0.16020551323890686
26
train loss item: 0.21382836997509003
27
train loss item: 0.27401113510131836
28
train loss item: 0.04378435015678406
29
train loss item: 0.7185810804367065
30
train loss item: 2.2245352268218994
31
train loss item: 0.6407901644706726
32
train loss item: 0.09034708142280579
33
train loss item: 0.44341301918029785
34
train loss item: 0.10806582868099213
35
train loss item: 2.3751015663146973
36
train loss item: 0.5137121677398682
37
train loss item: 0.44553321599960327
38
train loss item: 0.5770227313041687
39
train loss item: 0.2512744963169098
40
train loss item: 0.15470780432224274
41
train loss item: 0.2918287217617035
42
train loss item: 0.3115270733833313
43
train loss item: 0.20205284655094147
44
train loss item: 0.6653721928596497
45
train loss item: 0.1150084137916565
46
train loss item: 0.11798311024904251
47
train loss item: 0.40413588285446167
48
train loss item: 0.2598514258861542
49
train loss item: 0.1668233424425125
50
train loss item: 0.35861101746559143
51
train loss item: 0.9174148440361023
52
train loss item: 0.0547344945371151
53
train loss item: 0.15721778571605682
54
train loss item: 2.239077568054199
55
train loss item: 0.23560898005962372
56
train loss item: 0.3067246377468109
57
train loss item: 0.2541903257369995
58
train loss item: 0.1787777692079544
59
train loss item: 0.09294869750738144
60
train loss item: 0.9130287766456604
61
train loss item: 2.137361764907837
62
train loss item: 0.23845097422599792
63
train loss item: 0.42413103580474854
64
train loss item: 0.16941767930984497
65
train loss item: 0.7068749666213989
66
train loss item: 0.44095513224601746
67
train loss item: 0.2149859368801117
68
train loss item: 0.36731448769569397
69
train loss item: 0.41250136494636536
70
train loss item: 0.2942037284374237
71
train loss item: 0.12220993638038635
72
train loss item: 0.21143580973148346
73
train loss item: 0.34867286682128906
74
train loss item: 0.051877956837415695
75
train loss item: 0.0937943384051323
76
train loss item: 0.9524059891700745
77
train loss item: 1.2878743410110474
78
train loss item: 0.05435744673013687
79
train loss item: 0.2884502112865448
80
train loss item: 0.10687660425901413
81
train loss item: 0.20387287437915802
82
train loss item: 0.21854494512081146
83
train loss item: 0.6418945789337158
84
train loss item: 0.4310108721256256
85
train loss item: 0.6560578942298889
86
train loss item: 4.218190670013428
87
train loss item: 0.15772518515586853
88
train loss item: 0.4152505695819855
epoch train loss: 0.5001586065784599
testing phase
test loss item: 0.19765156507492065
test loss item: 0.08095419406890869
test loss item: 0.7201941609382629
test loss item: 0.23926211893558502
test loss item: 0.2838517725467682
test loss item: 0.11872007697820663
test loss item: 2.022857904434204
test loss item: 0.5277148485183716
test loss item: 0.2476413995027542
test loss item: 0.46977895498275757
test loss item: 1.0389816761016846
test loss item: 0.17275704443454742
test loss item: 0.1954997479915619
test loss item: 0.3952849209308624
test loss item: 0.18976590037345886
test loss item: 0.06193684786558151
test loss item: 0.3521605134010315
test loss item: 0.5638343691825867
test loss item: 0.7479708790779114
test loss item: 0.35551878809928894
test loss item: 0.9192724227905273
test loss item: 0.419240802526474
test loss item: 0.3380213677883148
test loss item: 0.20291750133037567
test loss item: 0.2637912333011627
test loss item: 0.2729140818119049
test loss item: 0.40989598631858826
test loss item: 0.21278434991836548
test loss item: 0.4081026017665863
test loss item: 0.41713541746139526
test loss item: 0.9257698655128479
test loss item: 0.05663098767399788
test loss item: 0.17144764959812164
test loss item: 0.6807737946510315
test loss item: 0.5450807809829712
test loss item: 0.46846047043800354
test loss item: 0.9255411624908447
test loss item: 1.7442224025726318
test loss item: 0.6019042134284973
test loss item: 0.32745984196662903
test loss item: 0.3600962162017822
test loss item: 0.21600571274757385
test loss item: 0.3955669105052948
test loss item: 0.23628488183021545
test loss item: 0.7485525608062744
test loss item: 0.5483259558677673
test loss item: 0.34587326645851135
test loss item: 0.293155699968338
test loss item: 0.5608388185501099
test loss item: 0.8089407086372375
test loss item: 0.3544246256351471
test loss item: 0.13846783339977264
test loss item: 0.2770487368106842
test loss item: 0.14410141110420227
test loss item: 0.3536544144153595
test loss item: 1.0880059003829956
test loss item: 0.6093559265136719
test loss item: 0.3173208236694336
test loss item: 0.2803634703159332
test loss item: 0.22368347644805908
test loss item: 0.51153165102005
test loss item: 0.25735199451446533
test loss item: 0.25644317269325256
test loss item: 0.3062286674976349
test loss item: 1.0651780366897583
test loss item: 0.32284173369407654
test loss item: 0.37751495838165283
test loss item: 0.3115818500518799
test loss item: 0.6501971483230591
test loss item: 0.42580413818359375
test loss item: 0.062325332313776016
test loss item: 1.1444849967956543
test loss item: 0.37453627586364746
test loss item: 0.4762285351753235
test loss item: 0.17377816140651703
test loss item: 0.1913461536169052
test loss item: 0.20187677443027496
test loss item: 1.774082899093628
test loss item: 0.5653688907623291
test loss item: 0.21671533584594727
test loss item: 0.07683545351028442
test loss item: 1.1103144884109497
test loss item: 1.0096344947814941
test loss item: 1.2006677389144897
test loss item: 0.2658092975616455
test loss item: 0.2619960308074951
test loss item: 0.072971411049366
test loss item: 0.0733463242650032
test loss item: 0.2011096328496933
Epoch [43/50], Training Loss: 0.5002, Testing Loss: 0.4667
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 44/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47272634506225586
1
train loss item: 1.2327717542648315
2
train loss item: 0.2505003809928894
3
train loss item: 0.5730944871902466
4
train loss item: 0.42750924825668335
5
train loss item: 0.37440016865730286
6
train loss item: 0.3024067282676697
7
train loss item: 0.8077921271324158
8
train loss item: 0.1486770212650299
9
train loss item: 0.3003508448600769
10
train loss item: 0.3944476842880249
11
train loss item: 0.27742093801498413
12
train loss item: 0.10075182467699051
13
train loss item: 0.5030669569969177
14
train loss item: 0.2614830434322357
15
train loss item: 0.640933096408844
16
train loss item: 0.047955095767974854
17
train loss item: 0.3495689332485199
18
train loss item: 0.39344266057014465
19
train loss item: 0.3130221366882324
20
train loss item: 0.24907462298870087
21
train loss item: 0.13019737601280212
22
train loss item: 0.9802741408348083
23
train loss item: 0.9328736066818237
24
train loss item: 0.6515891551971436
25
train loss item: 0.15863770246505737
26
train loss item: 0.21410124003887177
27
train loss item: 0.2699393928050995
28
train loss item: 0.044024091213941574
29
train loss item: 0.710545003414154
30
train loss item: 2.1981706619262695
31
train loss item: 0.6416637897491455
32
train loss item: 0.08814191073179245
33
train loss item: 0.437385618686676
34
train loss item: 0.10724098235368729
35
train loss item: 2.35603928565979
36
train loss item: 0.5158904194831848
37
train loss item: 0.44347894191741943
38
train loss item: 0.5705984234809875
39
train loss item: 0.25036710500717163
40
train loss item: 0.15337780117988586
41
train loss item: 0.2914668321609497
42
train loss item: 0.3106965124607086
43
train loss item: 0.20071379840373993
44
train loss item: 0.6593020558357239
45
train loss item: 0.11372848600149155
46
train loss item: 0.11741414666175842
47
train loss item: 0.400515615940094
48
train loss item: 0.2580333948135376
49
train loss item: 0.16891038417816162
50
train loss item: 0.3572656810283661
51
train loss item: 0.9076199531555176
52
train loss item: 0.055355727672576904
53
train loss item: 0.15489928424358368
54
train loss item: 2.2200212478637695
55
train loss item: 0.23566947877407074
56
train loss item: 0.30616533756256104
57
train loss item: 0.25352567434310913
58
train loss item: 0.17808403074741364
59
train loss item: 0.09167911857366562
60
train loss item: 0.9042400121688843
61
train loss item: 2.1142680644989014
62
train loss item: 0.2382943034172058
63
train loss item: 0.42047929763793945
64
train loss item: 0.1674659103155136
65
train loss item: 0.7086629271507263
66
train loss item: 0.4433802664279938
67
train loss item: 0.21549902856349945
68
train loss item: 0.3657822906970978
69
train loss item: 0.41079646348953247
70
train loss item: 0.2925335764884949
71
train loss item: 0.12229131907224655
72
train loss item: 0.2082216441631317
73
train loss item: 0.3467786908149719
74
train loss item: 0.050303854048252106
75
train loss item: 0.09231898933649063
76
train loss item: 0.9428414702415466
77
train loss item: 1.2712321281433105
78
train loss item: 0.0564771331846714
79
train loss item: 0.28537383675575256
80
train loss item: 0.10473556816577911
81
train loss item: 0.20270003378391266
82
train loss item: 0.21870499849319458
83
train loss item: 0.6298121809959412
84
train loss item: 0.43120068311691284
85
train loss item: 0.6495764255523682
86
train loss item: 4.190769672393799
87
train loss item: 0.1553170382976532
88
train loss item: 0.41238775849342346
epoch train loss: 0.4967353379123666
testing phase
test loss item: 0.19708333909511566
test loss item: 0.0812860056757927
test loss item: 0.7080780863761902
test loss item: 0.2386007308959961
test loss item: 0.2816148102283478
test loss item: 0.1176907941699028
test loss item: 2.0084240436553955
test loss item: 0.5228936076164246
test loss item: 0.24475234746932983
test loss item: 0.46616771817207336
test loss item: 1.0269029140472412
test loss item: 0.172255277633667
test loss item: 0.1923651099205017
test loss item: 0.39548176527023315
test loss item: 0.18840190768241882
test loss item: 0.06401564925909042
test loss item: 0.3495815694332123
test loss item: 0.5599138140678406
test loss item: 0.7443708777427673
test loss item: 0.35250040888786316
test loss item: 0.913658857345581
test loss item: 0.41598185896873474
test loss item: 0.3370767831802368
test loss item: 0.20203503966331482
test loss item: 0.2625514566898346
test loss item: 0.2712072730064392
test loss item: 0.40802204608917236
test loss item: 0.21117061376571655
test loss item: 0.40622398257255554
test loss item: 0.415357768535614
test loss item: 0.9150943160057068
test loss item: 0.05961593613028526
test loss item: 0.1706557273864746
test loss item: 0.6741898059844971
test loss item: 0.5383574962615967
test loss item: 0.46447044610977173
test loss item: 0.920345664024353
test loss item: 1.7211288213729858
test loss item: 0.5966964364051819
test loss item: 0.32543954253196716
test loss item: 0.3589192032814026
test loss item: 0.21370632946491241
test loss item: 0.3954979181289673
test loss item: 0.23483987152576447
test loss item: 0.7465180158615112
test loss item: 0.5447196364402771
test loss item: 0.34524500370025635
test loss item: 0.2910654544830322
test loss item: 0.5530267953872681
test loss item: 0.8007068634033203
test loss item: 0.3541421890258789
test loss item: 0.13756446540355682
test loss item: 0.27590975165367126
test loss item: 0.14395229518413544
test loss item: 0.35280805826187134
test loss item: 1.070564866065979
test loss item: 0.604973316192627
test loss item: 0.31841906905174255
test loss item: 0.27888527512550354
test loss item: 0.22326412796974182
test loss item: 0.5102659463882446
test loss item: 0.25377464294433594
test loss item: 0.25403907895088196
test loss item: 0.3049432933330536
test loss item: 1.0468353033065796
test loss item: 0.3220280408859253
test loss item: 0.37360069155693054
test loss item: 0.31014102697372437
test loss item: 0.6434294581413269
test loss item: 0.42351070046424866
test loss item: 0.06125630810856819
test loss item: 1.1375813484191895
test loss item: 0.37308844923973083
test loss item: 0.4721193313598633
test loss item: 0.1714283972978592
test loss item: 0.18969035148620605
test loss item: 0.20045703649520874
test loss item: 1.748388409614563
test loss item: 0.5612123012542725
test loss item: 0.21540947258472443
test loss item: 0.0773865133523941
test loss item: 1.0981907844543457
test loss item: 1.0037693977355957
test loss item: 1.1808502674102783
test loss item: 0.2656867206096649
test loss item: 0.25942882895469666
test loss item: 0.07511278241872787
test loss item: 0.07707928121089935
test loss item: 0.1991569846868515
Epoch [44/50], Training Loss: 0.4967, Testing Loss: 0.4629
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Epoch 45/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4718796908855438
1
train loss item: 1.2195123434066772
2
train loss item: 0.25013238191604614
3
train loss item: 0.5725029706954956
4
train loss item: 0.4271085262298584
5
train loss item: 0.37363171577453613
6
train loss item: 0.3016493022441864
7
train loss item: 0.7987880110740662
8
train loss item: 0.14818938076496124
9
train loss item: 0.29869508743286133
10
train loss item: 0.39382416009902954
11
train loss item: 0.2767864465713501
12
train loss item: 0.10110104829072952
13
train loss item: 0.501650333404541
14
train loss item: 0.26189371943473816
15
train loss item: 0.6378042697906494
16
train loss item: 0.04832640290260315
17
train loss item: 0.3487798273563385
18
train loss item: 0.39193224906921387
19
train loss item: 0.3118794560432434
20
train loss item: 0.24775414168834686
21
train loss item: 0.13446369767189026
22
train loss item: 0.968078076839447
23
train loss item: 0.9273216724395752
24
train loss item: 0.6476789116859436
25
train loss item: 0.1585022360086441
26
train loss item: 0.2143116295337677
27
train loss item: 0.26784998178482056
28
train loss item: 0.044524211436510086
29
train loss item: 0.7057270407676697
30
train loss item: 2.174098253250122
31
train loss item: 0.6415513157844543
32
train loss item: 0.08470084518194199
33
train loss item: 0.4344119131565094
34
train loss item: 0.10403143614530563
35
train loss item: 2.337467670440674
36
train loss item: 0.5175031423568726
37
train loss item: 0.44176217913627625
38
train loss item: 0.563278317451477
39
train loss item: 0.24832426011562347
40
train loss item: 0.152273491024971
41
train loss item: 0.29012513160705566
42
train loss item: 0.30963465571403503
43
train loss item: 0.19989457726478577
44
train loss item: 0.6548500061035156
45
train loss item: 0.11317142844200134
46
train loss item: 0.11797843873500824
47
train loss item: 0.3975088596343994
48
train loss item: 0.2572801411151886
49
train loss item: 0.17240726947784424
50
train loss item: 0.35608088970184326
51
train loss item: 0.8998625874519348
52
train loss item: 0.055104609578847885
53
train loss item: 0.15319299697875977
54
train loss item: 2.2007224559783936
55
train loss item: 0.23629938066005707
56
train loss item: 0.3028741180896759
57
train loss item: 0.25284045934677124
58
train loss item: 0.17725001275539398
59
train loss item: 0.09045781195163727
60
train loss item: 0.8986892104148865
61
train loss item: 2.094268321990967
62
train loss item: 0.2380245327949524
63
train loss item: 0.4179441034793854
64
train loss item: 0.1663718968629837
65
train loss item: 0.705994725227356
66
train loss item: 0.44607362151145935
67
train loss item: 0.21575625240802765
68
train loss item: 0.362784743309021
69
train loss item: 0.40706002712249756
70
train loss item: 0.29018792510032654
71
train loss item: 0.12278474867343903
72
train loss item: 0.20634494721889496
73
train loss item: 0.34552302956581116
74
train loss item: 0.05185488238930702
75
train loss item: 0.0913466140627861
76
train loss item: 0.9367955327033997
77
train loss item: 1.258081316947937
78
train loss item: 0.056786537170410156
79
train loss item: 0.282942533493042
80
train loss item: 0.10267665237188339
81
train loss item: 0.20155544579029083
82
train loss item: 0.21989040076732635
83
train loss item: 0.6193221211433411
84
train loss item: 0.4329354465007782
85
train loss item: 0.6465681791305542
86
train loss item: 4.162266254425049
87
train loss item: 0.15368540585041046
88
train loss item: 0.40554752945899963
epoch train loss: 0.4935874215253953
testing phase
test loss item: 0.19679975509643555
test loss item: 0.08232532441616058
test loss item: 0.7029528021812439
test loss item: 0.23848973214626312
test loss item: 0.28184816241264343
test loss item: 0.11833199858665466
test loss item: 2.00370192527771
test loss item: 0.5250093340873718
test loss item: 0.24459823966026306
test loss item: 0.4660102128982544
test loss item: 1.0193778276443481
test loss item: 0.17286069691181183
test loss item: 0.19142872095108032
test loss item: 0.3973659873008728
test loss item: 0.18853822350502014
test loss item: 0.06417582929134369
test loss item: 0.3493238091468811
test loss item: 0.5598498582839966
test loss item: 0.7445108294487
test loss item: 0.35255271196365356
test loss item: 0.9137069582939148
test loss item: 0.4158448874950409
test loss item: 0.3386942148208618
test loss item: 0.20146623253822327
test loss item: 0.2623694837093353
test loss item: 0.27111396193504333
test loss item: 0.4078945517539978
test loss item: 0.21105113625526428
test loss item: 0.4067818820476532
test loss item: 0.4154042899608612
test loss item: 0.910142719745636
test loss item: 0.0604831762611866
test loss item: 0.16970312595367432
test loss item: 0.6717827916145325
test loss item: 0.5356078147888184
test loss item: 0.4633064568042755
test loss item: 0.9199026226997375
test loss item: 1.706896424293518
test loss item: 0.5954522490501404
test loss item: 0.3250262439250946
test loss item: 0.3588646650314331
test loss item: 0.21404904127120972
test loss item: 0.3972634971141815
test loss item: 0.234880730509758
test loss item: 0.7480599880218506
test loss item: 0.5448257327079773
test loss item: 0.34669119119644165
test loss item: 0.2911860942840576
test loss item: 0.5509041547775269
test loss item: 0.7978113889694214
test loss item: 0.3558984100818634
test loss item: 0.13728214800357819
test loss item: 0.27623075246810913
test loss item: 0.1444881111383438
test loss item: 0.3537697494029999
test loss item: 1.0613884925842285
test loss item: 0.6040752530097961
test loss item: 0.32045671343803406
test loss item: 0.2791614830493927
test loss item: 0.22393165528774261
test loss item: 0.5117170810699463
test loss item: 0.25397759675979614
test loss item: 0.25391915440559387
test loss item: 0.30459097027778625
test loss item: 1.036898136138916
test loss item: 0.32177111506462097
test loss item: 0.37326371669769287
test loss item: 0.31009888648986816
test loss item: 0.6400892734527588
test loss item: 0.4242230951786041
test loss item: 0.061949774622917175
test loss item: 1.1371488571166992
test loss item: 0.37477821111679077
test loss item: 0.4718678593635559
test loss item: 0.17116138339042664
test loss item: 0.1895100325345993
test loss item: 0.1998853236436844
test loss item: 1.7305138111114502
test loss item: 0.5604622960090637
test loss item: 0.21570035815238953
test loss item: 0.0772576853632927
test loss item: 1.0918861627578735
test loss item: 1.0025017261505127
test loss item: 1.1684496402740479
test loss item: 0.26676633954048157
test loss item: 0.2589873671531677
test loss item: 0.07427257299423218
test loss item: 0.07559093832969666
test loss item: 0.2010461688041687
Epoch [45/50], Training Loss: 0.4936, Testing Loss: 0.4618
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 46/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4687288701534271
1
train loss item: 1.2055350542068481
2
train loss item: 0.24944308400154114
3
train loss item: 0.5673647522926331
4
train loss item: 0.42780858278274536
5
train loss item: 0.3740580677986145
6
train loss item: 0.30094707012176514
7
train loss item: 0.7880194783210754
8
train loss item: 0.1475200206041336
9
train loss item: 0.29716166853904724
10
train loss item: 0.3918231427669525
11
train loss item: 0.27915194630622864
12
train loss item: 0.10086245834827423
13
train loss item: 0.5009718537330627
14
train loss item: 0.26046574115753174
15
train loss item: 0.6346084475517273
16
train loss item: 0.047370314598083496
17
train loss item: 0.3477634787559509
18
train loss item: 0.3891860246658325
19
train loss item: 0.3112041652202606
20
train loss item: 0.246529683470726
21
train loss item: 0.13726671040058136
22
train loss item: 0.9570786952972412
23
train loss item: 0.9189397692680359
24
train loss item: 0.6421659588813782
25
train loss item: 0.15861199796199799
26
train loss item: 0.2149987369775772
27
train loss item: 0.2682851552963257
28
train loss item: 0.043875034898519516
29
train loss item: 0.6992231607437134
30
train loss item: 2.148082971572876
31
train loss item: 0.6404109001159668
32
train loss item: 0.08415209501981735
33
train loss item: 0.4311634600162506
34
train loss item: 0.10317611694335938
35
train loss item: 2.3177149295806885
36
train loss item: 0.5106973648071289
37
train loss item: 0.44114136695861816
38
train loss item: 0.558200478553772
39
train loss item: 0.2455863356590271
40
train loss item: 0.15137118101119995
41
train loss item: 0.28737354278564453
42
train loss item: 0.3105703890323639
43
train loss item: 0.19928574562072754
44
train loss item: 0.6455002427101135
45
train loss item: 0.1131339892745018
46
train loss item: 0.11947331577539444
47
train loss item: 0.39567282795906067
48
train loss item: 0.2565566301345825
49
train loss item: 0.17441774904727936
50
train loss item: 0.3553985357284546
51
train loss item: 0.8950431942939758
52
train loss item: 0.054593998938798904
53
train loss item: 0.15195296704769135
54
train loss item: 2.180893898010254
55
train loss item: 0.23540358245372772
56
train loss item: 0.2956124544143677
57
train loss item: 0.25177818536758423
58
train loss item: 0.17683270573616028
59
train loss item: 0.09030827134847641
60
train loss item: 0.888590931892395
61
train loss item: 2.0726912021636963
62
train loss item: 0.23750066757202148
63
train loss item: 0.4187433123588562
64
train loss item: 0.16563530266284943
65
train loss item: 0.7080637216567993
66
train loss item: 0.44624778628349304
67
train loss item: 0.21536579728126526
68
train loss item: 0.358732670545578
69
train loss item: 0.40553227066993713
70
train loss item: 0.28895655274391174
71
train loss item: 0.12301631271839142
72
train loss item: 0.20570442080497742
73
train loss item: 0.34449291229248047
74
train loss item: 0.052569326013326645
75
train loss item: 0.0910186842083931
76
train loss item: 0.9273656010627747
77
train loss item: 1.2459454536437988
78
train loss item: 0.05637865513563156
79
train loss item: 0.28513631224632263
80
train loss item: 0.10310754179954529
81
train loss item: 0.20091289281845093
82
train loss item: 0.21915818750858307
83
train loss item: 0.6072995066642761
84
train loss item: 0.4384004473686218
85
train loss item: 0.6410716772079468
86
train loss item: 4.133400917053223
87
train loss item: 0.15274886786937714
88
train loss item: 0.4023192524909973
epoch train loss: 0.49027613186266983
testing phase
test loss item: 0.19594009220600128
test loss item: 0.0823981910943985
test loss item: 0.7103433012962341
test loss item: 0.23750317096710205
test loss item: 0.2814655601978302
test loss item: 0.11969821900129318
test loss item: 1.9965039491653442
test loss item: 0.5347847938537598
test loss item: 0.24302762746810913
test loss item: 0.46305152773857117
test loss item: 1.0177838802337646
test loss item: 0.17256750166416168
test loss item: 0.19093115627765656
test loss item: 0.39583197236061096
test loss item: 0.1876010149717331
test loss item: 0.06121794506907463
test loss item: 0.3502163589000702
test loss item: 0.5552420020103455
test loss item: 0.7475582361221313
test loss item: 0.3528546988964081
test loss item: 0.9068976044654846
test loss item: 0.4169101119041443
test loss item: 0.33611851930618286
test loss item: 0.20029513537883759
test loss item: 0.2615576386451721
test loss item: 0.27078136801719666
test loss item: 0.4065217077732086
test loss item: 0.21052874624729156
test loss item: 0.4049827456474304
test loss item: 0.4133577346801758
test loss item: 0.9059094190597534
test loss item: 0.0577191486954689
test loss item: 0.16808806359767914
test loss item: 0.6731069087982178
test loss item: 0.5349531769752502
test loss item: 0.46079087257385254
test loss item: 0.9198322892189026
test loss item: 1.7123229503631592
test loss item: 0.5916075706481934
test loss item: 0.3243753910064697
test loss item: 0.35784798860549927
test loss item: 0.21468880772590637
test loss item: 0.39343294501304626
test loss item: 0.23429875075817108
test loss item: 0.7396087646484375
test loss item: 0.5473803877830505
test loss item: 0.3440685272216797
test loss item: 0.2902967035770416
test loss item: 0.5511226058006287
test loss item: 0.7959136366844177
test loss item: 0.3494861125946045
test loss item: 0.13674578070640564
test loss item: 0.27423882484436035
test loss item: 0.14425405859947205
test loss item: 0.3510740399360657
test loss item: 1.0720618963241577
test loss item: 0.6081225275993347
test loss item: 0.3164486587047577
test loss item: 0.2778276801109314
test loss item: 0.22147837281227112
test loss item: 0.5073699951171875
test loss item: 0.25692516565322876
test loss item: 0.2549595534801483
test loss item: 0.30393195152282715
test loss item: 1.0550612211227417
test loss item: 0.3206143379211426
test loss item: 0.37381842732429504
test loss item: 0.3100450038909912
test loss item: 0.6452895998954773
test loss item: 0.42621898651123047
test loss item: 0.06275381147861481
test loss item: 1.138588786125183
test loss item: 0.371065229177475
test loss item: 0.47176632285118103
test loss item: 0.17191560566425323
test loss item: 0.18936340510845184
test loss item: 0.19861428439617157
test loss item: 1.7398126125335693
test loss item: 0.5591884255409241
test loss item: 0.2170584797859192
test loss item: 0.07673425227403641
test loss item: 1.0916500091552734
test loss item: 1.0003342628479004
test loss item: 1.172747015953064
test loss item: 0.26459041237831116
test loss item: 0.2580336034297943
test loss item: 0.07138453423976898
test loss item: 0.0709555372595787
test loss item: 0.20224809646606445
Epoch [46/50], Training Loss: 0.4903, Testing Loss: 0.4615
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 47/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4672273099422455
1
train loss item: 1.1956051588058472
2
train loss item: 0.2492455244064331
3
train loss item: 0.56120765209198
4
train loss item: 0.43336498737335205
5
train loss item: 0.3738784193992615
6
train loss item: 0.3009825646877289
7
train loss item: 0.7797484993934631
8
train loss item: 0.14653021097183228
9
train loss item: 0.2955852448940277
10
train loss item: 0.38899528980255127
11
train loss item: 0.27699926495552063
12
train loss item: 0.09967690706253052
13
train loss item: 0.4969537854194641
14
train loss item: 0.2571108341217041
15
train loss item: 0.6361027956008911
16
train loss item: 0.0453120619058609
17
train loss item: 0.34754690527915955
18
train loss item: 0.3920731842517853
19
train loss item: 0.3118186891078949
20
train loss item: 0.24785882234573364
21
train loss item: 0.13062341511249542
22
train loss item: 0.9549892544746399
23
train loss item: 0.9077890515327454
24
train loss item: 0.6421476602554321
25
train loss item: 0.15794463455677032
26
train loss item: 0.21288205683231354
27
train loss item: 0.26292353868484497
28
train loss item: 0.04218762367963791
29
train loss item: 0.6964930295944214
30
train loss item: 2.122305393218994
31
train loss item: 0.6399907469749451
32
train loss item: 0.08300639688968658
33
train loss item: 0.425065279006958
34
train loss item: 0.10232684761285782
35
train loss item: 2.2979865074157715
36
train loss item: 0.5079294443130493
37
train loss item: 0.43600618839263916
38
train loss item: 0.5573211312294006
39
train loss item: 0.24678193032741547
40
train loss item: 0.15062154829502106
41
train loss item: 0.28322723507881165
42
train loss item: 0.3082979917526245
43
train loss item: 0.1990594118833542
44
train loss item: 0.6351656317710876
45
train loss item: 0.11374352127313614
46
train loss item: 0.11792807281017303
47
train loss item: 0.39553260803222656
48
train loss item: 0.2550923824310303
49
train loss item: 0.1701563447713852
50
train loss item: 0.3563287854194641
51
train loss item: 0.8852853178977966
52
train loss item: 0.052634358406066895
53
train loss item: 0.14907962083816528
54
train loss item: 2.1612823009490967
55
train loss item: 0.2355145663022995
56
train loss item: 0.29610639810562134
57
train loss item: 0.25087130069732666
58
train loss item: 0.176677405834198
59
train loss item: 0.09009170532226562
60
train loss item: 0.8813557624816895
61
train loss item: 2.0468854904174805
62
train loss item: 0.23712508380413055
63
train loss item: 0.4183101952075958
64
train loss item: 0.16483096778392792
65
train loss item: 0.7038793563842773
66
train loss item: 0.4431801736354828
67
train loss item: 0.2128978669643402
68
train loss item: 0.35878416895866394
69
train loss item: 0.4057019352912903
70
train loss item: 0.2889362573623657
71
train loss item: 0.12201301753520966
72
train loss item: 0.20301441848278046
73
train loss item: 0.3447284698486328
74
train loss item: 0.05227426812052727
75
train loss item: 0.09177519381046295
76
train loss item: 0.9176745414733887
77
train loss item: 1.2339493036270142
78
train loss item: 0.05263993516564369
79
train loss item: 0.2844146490097046
80
train loss item: 0.10389262437820435
81
train loss item: 0.20170331001281738
82
train loss item: 0.21643605828285217
83
train loss item: 0.5987602472305298
84
train loss item: 0.43422436714172363
85
train loss item: 0.636337161064148
86
train loss item: 4.102947235107422
87
train loss item: 0.15331843495368958
88
train loss item: 0.40163707733154297
epoch train loss: 0.48681852045688734
testing phase
test loss item: 0.19558635354042053
test loss item: 0.08364515006542206
test loss item: 0.7052639126777649
test loss item: 0.23714080452919006
test loss item: 0.2809465229511261
test loss item: 0.12216335535049438
test loss item: 1.997435212135315
test loss item: 0.544975221157074
test loss item: 0.24235279858112335
test loss item: 0.4620019197463989
test loss item: 1.0064254999160767
test loss item: 0.17273356020450592
test loss item: 0.1916360706090927
test loss item: 0.3955671787261963
test loss item: 0.18735376000404358
test loss item: 0.057992760092020035
test loss item: 0.35183021426200867
test loss item: 0.553308367729187
test loss item: 0.7513638138771057
test loss item: 0.3544745147228241
test loss item: 0.902320384979248
test loss item: 0.4196060299873352
test loss item: 0.33483174443244934
test loss item: 0.20069091022014618
test loss item: 0.26094403862953186
test loss item: 0.2715030610561371
test loss item: 0.4066515266895294
test loss item: 0.21114951372146606
test loss item: 0.405265748500824
test loss item: 0.4131529629230499
test loss item: 0.8997066617012024
test loss item: 0.05496782436966896
test loss item: 0.16826921701431274
test loss item: 0.6710172891616821
test loss item: 0.5315507054328918
test loss item: 0.461855947971344
test loss item: 0.9225171804428101
test loss item: 1.690194010734558
test loss item: 0.5887743830680847
test loss item: 0.3253874182701111
test loss item: 0.35768699645996094
test loss item: 0.21543428301811218
test loss item: 0.3928873836994171
test loss item: 0.23456570506095886
test loss item: 0.7361775636672974
test loss item: 0.550614595413208
test loss item: 0.34420591592788696
test loss item: 0.2905653119087219
test loss item: 0.5492674112319946
test loss item: 0.7915993928909302
test loss item: 0.3482850193977356
test loss item: 0.13698789477348328
test loss item: 0.27362728118896484
test loss item: 0.1443498581647873
test loss item: 0.34983474016189575
test loss item: 1.0641539096832275
test loss item: 0.6081359386444092
test loss item: 0.31617769598960876
test loss item: 0.27828019857406616
test loss item: 0.22148534655570984
test loss item: 0.5068950057029724
test loss item: 0.26045313477516174
test loss item: 0.25677546858787537
test loss item: 0.30374518036842346
test loss item: 1.0483472347259521
test loss item: 0.3199799656867981
test loss item: 0.37509405612945557
test loss item: 0.3106756806373596
test loss item: 0.6415154337882996
test loss item: 0.4305894374847412
test loss item: 0.06457741558551788
test loss item: 1.1441287994384766
test loss item: 0.3706924021244049
test loss item: 0.47395065426826477
test loss item: 0.17348410189151764
test loss item: 0.1901940405368805
test loss item: 0.19943416118621826
test loss item: 1.7123767137527466
test loss item: 0.5565137267112732
test loss item: 0.21888966858386993
test loss item: 0.07778698951005936
test loss item: 1.0834165811538696
test loss item: 1.0009247064590454
test loss item: 1.1548964977264404
test loss item: 0.26378798484802246
test loss item: 0.25849461555480957
test loss item: 0.06881629675626755
test loss item: 0.06493175029754639
test loss item: 0.20099681615829468
Epoch [47/50], Training Loss: 0.4868, Testing Loss: 0.4604
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 48/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4622245728969574
1
train loss item: 1.1871285438537598
2
train loss item: 0.24836885929107666
3
train loss item: 0.5559802651405334
4
train loss item: 0.43568548560142517
5
train loss item: 0.37283089756965637
6
train loss item: 0.30098235607147217
7
train loss item: 0.7711357474327087
8
train loss item: 0.1466183364391327
9
train loss item: 0.2959379255771637
10
train loss item: 0.38637733459472656
11
train loss item: 0.27514421939849854
12
train loss item: 0.09892831742763519
13
train loss item: 0.4948233664035797
14
train loss item: 0.2541767656803131
15
train loss item: 0.6370018720626831
16
train loss item: 0.04429866001009941
17
train loss item: 0.34735849499702454
18
train loss item: 0.39068853855133057
19
train loss item: 0.3130788207054138
20
train loss item: 0.24951809644699097
21
train loss item: 0.12395315617322922
22
train loss item: 0.9502680897712708
23
train loss item: 0.8990392088890076
24
train loss item: 0.6403329968452454
25
train loss item: 0.1568906158208847
26
train loss item: 0.21038749814033508
27
train loss item: 0.264105886220932
28
train loss item: 0.04151373729109764
29
train loss item: 0.6954116821289062
30
train loss item: 2.097189426422119
31
train loss item: 0.6359408497810364
32
train loss item: 0.08304199576377869
33
train loss item: 0.423702210187912
34
train loss item: 0.10026692599058151
35
train loss item: 2.277872323989868
36
train loss item: 0.5033901929855347
37
train loss item: 0.42906448245048523
38
train loss item: 0.5451372265815735
39
train loss item: 0.2448999583721161
40
train loss item: 0.14961281418800354
41
train loss item: 0.2805575728416443
42
train loss item: 0.3082001209259033
43
train loss item: 0.19921723008155823
44
train loss item: 0.6267650127410889
45
train loss item: 0.11368586868047714
46
train loss item: 0.11695387959480286
47
train loss item: 0.3955698013305664
48
train loss item: 0.2554015815258026
49
train loss item: 0.1657707393169403
50
train loss item: 0.357342928647995
51
train loss item: 0.8795899748802185
52
train loss item: 0.05180812254548073
53
train loss item: 0.14912278950214386
54
train loss item: 2.141547918319702
55
train loss item: 0.23610658943653107
56
train loss item: 0.2922010123729706
57
train loss item: 0.25017547607421875
58
train loss item: 0.1766449362039566
59
train loss item: 0.09240859001874924
60
train loss item: 0.878178060054779
61
train loss item: 2.023674726486206
62
train loss item: 0.2366795539855957
63
train loss item: 0.4182511270046234
64
train loss item: 0.1652013659477234
65
train loss item: 0.6970722079277039
66
train loss item: 0.44023796916007996
67
train loss item: 0.2105235606431961
68
train loss item: 0.3596034646034241
69
train loss item: 0.4037575423717499
70
train loss item: 0.28908923268318176
71
train loss item: 0.11959458142518997
72
train loss item: 0.20390480756759644
73
train loss item: 0.34496283531188965
74
train loss item: 0.052433110773563385
75
train loss item: 0.0931171104311943
76
train loss item: 0.9116978049278259
77
train loss item: 1.2256947755813599
78
train loss item: 0.04961960017681122
79
train loss item: 0.2843311131000519
80
train loss item: 0.1034519374370575
81
train loss item: 0.20205436646938324
82
train loss item: 0.21499037742614746
83
train loss item: 0.5925068259239197
84
train loss item: 0.43192580342292786
85
train loss item: 0.634312093257904
86
train loss item: 4.07211971282959
87
train loss item: 0.15366196632385254
88
train loss item: 0.3978637754917145
epoch train loss: 0.48359427312284375
testing phase
test loss item: 0.19573120772838593
test loss item: 0.08378124982118607
test loss item: 0.7133553624153137
test loss item: 0.23734579980373383
test loss item: 0.28119462728500366
test loss item: 0.12224731594324112
test loss item: 1.993927001953125
test loss item: 0.5441047549247742
test loss item: 0.24486976861953735
test loss item: 0.4639187157154083
test loss item: 1.0069231986999512
test loss item: 0.17294533550739288
test loss item: 0.1914655864238739
test loss item: 0.39449751377105713
test loss item: 0.18723779916763306
test loss item: 0.058747339993715286
test loss item: 0.3519185185432434
test loss item: 0.5560876727104187
test loss item: 0.7499551773071289
test loss item: 0.3540157973766327
test loss item: 0.905386209487915
test loss item: 0.4201525151729584
test loss item: 0.33456316590309143
test loss item: 0.20142200589179993
test loss item: 0.2615266740322113
test loss item: 0.27113795280456543
test loss item: 0.40700799226760864
test loss item: 0.21083693206310272
test loss item: 0.4053054749965668
test loss item: 0.4138084352016449
test loss item: 0.8997203707695007
test loss item: 0.05433649569749832
test loss item: 0.16919547319412231
test loss item: 0.6765860915184021
test loss item: 0.5354191660881042
test loss item: 0.4634862244129181
test loss item: 0.9219100475311279
test loss item: 1.6938294172286987
test loss item: 0.5900932550430298
test loss item: 0.325742244720459
test loss item: 0.35749855637550354
test loss item: 0.21534806489944458
test loss item: 0.39525511860847473
test loss item: 0.23479683697223663
test loss item: 0.7364215850830078
test loss item: 0.5503198504447937
test loss item: 0.34432220458984375
test loss item: 0.2896273136138916
test loss item: 0.5524348020553589
test loss item: 0.7925235033035278
test loss item: 0.34855878353118896
test loss item: 0.13695867359638214
test loss item: 0.2738190293312073
test loss item: 0.14521029591560364
test loss item: 0.3515283763408661
test loss item: 1.0753440856933594
test loss item: 0.6073596477508545
test loss item: 0.31562167406082153
test loss item: 0.27794528007507324
test loss item: 0.22179588675498962
test loss item: 0.5104418396949768
test loss item: 0.26062703132629395
test loss item: 0.2572716474533081
test loss item: 0.30324211716651917
test loss item: 1.0557382106781006
test loss item: 0.31999436020851135
test loss item: 0.37460246682167053
test loss item: 0.3103266954421997
test loss item: 0.6453907489776611
test loss item: 0.43130263686180115
test loss item: 0.06444240361452103
test loss item: 1.1425952911376953
test loss item: 0.3704281449317932
test loss item: 0.47438347339630127
test loss item: 0.17340219020843506
test loss item: 0.190439373254776
test loss item: 0.2001425176858902
test loss item: 1.712638020515442
test loss item: 0.5562788248062134
test loss item: 0.21949777007102966
test loss item: 0.07768099009990692
test loss item: 1.0819454193115234
test loss item: 1.0023152828216553
test loss item: 1.1566411256790161
test loss item: 0.26225534081459045
test loss item: 0.2582552433013916
test loss item: 0.06879835575819016
test loss item: 0.06393922120332718
test loss item: 0.19921010732650757
Epoch [48/50], Training Loss: 0.4836, Testing Loss: 0.4610
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 49/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4588276147842407
1
train loss item: 1.1748186349868774
2
train loss item: 0.24712704122066498
3
train loss item: 0.5529473423957825
4
train loss item: 0.43658411502838135
5
train loss item: 0.3719191551208496
6
train loss item: 0.3002637028694153
7
train loss item: 0.7604627013206482
8
train loss item: 0.1461268663406372
9
train loss item: 0.29571470618247986
10
train loss item: 0.38546451926231384
11
train loss item: 0.2755163013935089
12
train loss item: 0.0985996276140213
13
train loss item: 0.49387702345848083
14
train loss item: 0.25211483240127563
15
train loss item: 0.6339821815490723
16
train loss item: 0.044012416154146194
17
train loss item: 0.34666264057159424
18
train loss item: 0.38990697264671326
19
train loss item: 0.3132942020893097
20
train loss item: 0.24964474141597748
21
train loss item: 0.12060649693012238
22
train loss item: 0.9414970874786377
23
train loss item: 0.8916018605232239
24
train loss item: 0.6358116865158081
25
train loss item: 0.1560547947883606
26
train loss item: 0.20883062481880188
27
train loss item: 0.2644055485725403
28
train loss item: 0.04098721966147423
29
train loss item: 0.6904619336128235
30
train loss item: 2.0701746940612793
31
train loss item: 0.6360701322555542
32
train loss item: 0.08241701126098633
33
train loss item: 0.42185235023498535
34
train loss item: 0.09869679808616638
35
train loss item: 2.2556450366973877
36
train loss item: 0.5036366581916809
37
train loss item: 0.4284709393978119
38
train loss item: 0.5347872376441956
39
train loss item: 0.24354679882526398
40
train loss item: 0.14851224422454834
41
train loss item: 0.2796953618526459
42
train loss item: 0.30701982975006104
43
train loss item: 0.19870024919509888
44
train loss item: 0.6189091205596924
45
train loss item: 0.11227542906999588
46
train loss item: 0.11624899506568909
47
train loss item: 0.39369499683380127
48
train loss item: 0.2551048994064331
49
train loss item: 0.16381235420703888
50
train loss item: 0.3570229709148407
51
train loss item: 0.87014240026474
52
train loss item: 0.05204182118177414
53
train loss item: 0.14879658818244934
54
train loss item: 2.1197283267974854
55
train loss item: 0.23598456382751465
56
train loss item: 0.29160118103027344
57
train loss item: 0.24958465993404388
58
train loss item: 0.176234170794487
59
train loss item: 0.09586335718631744
60
train loss item: 0.8694173097610474
61
train loss item: 1.9991346597671509
62
train loss item: 0.2360377162694931
63
train loss item: 0.4168757200241089
64
train loss item: 0.16477996110916138
65
train loss item: 0.6921850442886353
66
train loss item: 0.4434233009815216
67
train loss item: 0.20902296900749207
68
train loss item: 0.35941290855407715
69
train loss item: 0.4014348089694977
70
train loss item: 0.28817737102508545
71
train loss item: 0.11811135709285736
72
train loss item: 0.20328621566295624
73
train loss item: 0.34457242488861084
74
train loss item: 0.051041293889284134
75
train loss item: 0.09249144047498703
76
train loss item: 0.9038493633270264
77
train loss item: 1.2119494676589966
78
train loss item: 0.04890196770429611
79
train loss item: 0.28344616293907166
80
train loss item: 0.10182671993970871
81
train loss item: 0.202037051320076
82
train loss item: 0.2141246646642685
83
train loss item: 0.5840066075325012
84
train loss item: 0.43494999408721924
85
train loss item: 0.6312738060951233
86
train loss item: 4.040257930755615
87
train loss item: 0.15376964211463928
88
train loss item: 0.39468440413475037
epoch train loss: 0.4802121129514796
testing phase
test loss item: 0.19643981754779816
test loss item: 0.08344275504350662
test loss item: 0.7091019153594971
test loss item: 0.2381289303302765
test loss item: 0.2783309519290924
test loss item: 0.12090550363063812
test loss item: 1.9824100732803345
test loss item: 0.5376021265983582
test loss item: 0.24469666182994843
test loss item: 0.46250954270362854
test loss item: 0.99749356508255
test loss item: 0.17328955233097076
test loss item: 0.1900477409362793
test loss item: 0.3927290439605713
test loss item: 0.18499641120433807
test loss item: 0.0622134655714035
test loss item: 0.35123226046562195
test loss item: 0.5550811290740967
test loss item: 0.7455233931541443
test loss item: 0.3521445691585541
test loss item: 0.9017556309700012
test loss item: 0.4191364347934723
test loss item: 0.3326699435710907
test loss item: 0.20218470692634583
test loss item: 0.261384516954422
test loss item: 0.2700839340686798
test loss item: 0.4062519967556
test loss item: 0.20863303542137146
test loss item: 0.40324240922927856
test loss item: 0.41325807571411133
test loss item: 0.892153263092041
test loss item: 0.056116607040166855
test loss item: 0.17058901488780975
test loss item: 0.6758986115455627
test loss item: 0.5331442952156067
test loss item: 0.4620983898639679
test loss item: 0.9172253012657166
test loss item: 1.6748067140579224
test loss item: 0.5875871181488037
test loss item: 0.32524433732032776
test loss item: 0.3570108413696289
test loss item: 0.21488146483898163
test loss item: 0.3959386348724365
test loss item: 0.23526671528816223
test loss item: 0.7333142757415771
test loss item: 0.5478450059890747
test loss item: 0.34341999888420105
test loss item: 0.28813332319259644
test loss item: 0.5491170883178711
test loss item: 0.7871363759040833
test loss item: 0.34706857800483704
test loss item: 0.13690637052059174
test loss item: 0.2729908227920532
test loss item: 0.14660339057445526
test loss item: 0.3503502905368805
test loss item: 1.069325566291809
test loss item: 0.6019219160079956
test loss item: 0.3137062191963196
test loss item: 0.2770080864429474
test loss item: 0.2208290547132492
test loss item: 0.5113689303398132
test loss item: 0.2593781650066376
test loss item: 0.25708678364753723
test loss item: 0.30244123935699463
test loss item: 1.0445226430892944
test loss item: 0.32053446769714355
test loss item: 0.37199363112449646
test loss item: 0.3090452253818512
test loss item: 0.6416252255439758
test loss item: 0.42960330843925476
test loss item: 0.06260041892528534
test loss item: 1.1355540752410889
test loss item: 0.3687214255332947
test loss item: 0.47339335083961487
test loss item: 0.17236793041229248
test loss item: 0.19050216674804688
test loss item: 0.20027366280555725
test loss item: 1.6868282556533813
test loss item: 0.5531566739082336
test loss item: 0.21903708577156067
test loss item: 0.07800444215536118
test loss item: 1.0702588558197021
test loss item: 0.9990216493606567
test loss item: 1.1401008367538452
test loss item: 0.2598932683467865
test loss item: 0.2572850286960602
test loss item: 0.07197552174329758
test loss item: 0.06887893378734589
test loss item: 0.19585570693016052
Epoch [49/50], Training Loss: 0.4802, Testing Loss: 0.4586
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 50/50
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45822107791900635
1
train loss item: 1.157315731048584
2
train loss item: 0.24627915024757385
3
train loss item: 0.5534001588821411
4
train loss item: 0.43761560320854187
5
train loss item: 0.3704790771007538
6
train loss item: 0.2994113564491272
7
train loss item: 0.749790608882904
8
train loss item: 0.1446761041879654
9
train loss item: 0.2943773567676544
10
train loss item: 0.3854338228702545
11
train loss item: 0.27643412351608276
12
train loss item: 0.09895520657300949
13
train loss item: 0.49206042289733887
14
train loss item: 0.2505815029144287
15
train loss item: 0.6298236846923828
16
train loss item: 0.04477976635098457
17
train loss item: 0.34587788581848145
18
train loss item: 0.39114806056022644
19
train loss item: 0.3128107786178589
20
train loss item: 0.2494928389787674
21
train loss item: 0.11824355274438858
22
train loss item: 0.932783305644989
23
train loss item: 0.8830408453941345
24
train loss item: 0.6322814226150513
25
train loss item: 0.15738454461097717
26
train loss item: 0.20747436583042145
27
train loss item: 0.25949108600616455
28
train loss item: 0.04097926244139671
29
train loss item: 0.6833733916282654
30
train loss item: 2.042390823364258
31
train loss item: 0.640704870223999
32
train loss item: 0.08074234426021576
33
train loss item: 0.4189673066139221
34
train loss item: 0.09715317189693451
35
train loss item: 2.23299241065979
36
train loss item: 0.5105676054954529
37
train loss item: 0.43162834644317627
38
train loss item: 0.5310907363891602
39
train loss item: 0.24424302577972412
40
train loss item: 0.14768308401107788
41
train loss item: 0.27981919050216675
42
train loss item: 0.30559778213500977
43
train loss item: 0.1978556364774704
44
train loss item: 0.6126071810722351
45
train loss item: 0.10922174155712128
46
train loss item: 0.11511782556772232
47
train loss item: 0.39040040969848633
48
train loss item: 0.2535397410392761
49
train loss item: 0.16343800723552704
50
train loss item: 0.3558403253555298
51
train loss item: 0.8573405742645264
52
train loss item: 0.05236642435193062
53
train loss item: 0.14551544189453125
54
train loss item: 2.0969736576080322
55
train loss item: 0.23533689975738525
56
train loss item: 0.29691359400749207
57
train loss item: 0.24893321096897125
58
train loss item: 0.1757732331752777
59
train loss item: 0.09445879608392715
60
train loss item: 0.8576052188873291
61
train loss item: 1.9734265804290771
62
train loss item: 0.2355227768421173
63
train loss item: 0.41370105743408203
64
train loss item: 0.1635967493057251
65
train loss item: 0.6883822679519653
66
train loss item: 0.45122966170310974
67
train loss item: 0.2076379954814911
68
train loss item: 0.35899588465690613
69
train loss item: 0.3991992175579071
70
train loss item: 0.28674817085266113
71
train loss item: 0.11831069737672806
72
train loss item: 0.19986623525619507
73
train loss item: 0.3439919352531433
74
train loss item: 0.047327395528554916
75
train loss item: 0.09037323296070099
76
train loss item: 0.8948491215705872
77
train loss item: 1.1927473545074463
78
train loss item: 0.05042709410190582
79
train loss item: 0.28066208958625793
80
train loss item: 0.09898878633975983
81
train loss item: 0.20152506232261658
82
train loss item: 0.21345210075378418
83
train loss item: 0.5752015709877014
84
train loss item: 0.4378719925880432
85
train loss item: 0.6275674700737
86
train loss item: 4.0080885887146
87
train loss item: 0.15327180922031403
88
train loss item: 0.3932173550128937
epoch train loss: 0.4767754490623313
testing phase
test loss item: 0.19817475974559784
test loss item: 0.08439958840608597
test loss item: 0.7162110209465027
test loss item: 0.23968954384326935
test loss item: 0.28177300095558167
test loss item: 0.12260885536670685
test loss item: 1.9754588603973389
test loss item: 0.5359905958175659
test loss item: 0.25106531381607056
test loss item: 0.4702002704143524
test loss item: 0.9929602742195129
test loss item: 0.17468573153018951
test loss item: 0.19117222726345062
test loss item: 0.39380064606666565
test loss item: 0.1869855523109436
test loss item: 0.06736637651920319
test loss item: 0.3523674011230469
test loss item: 0.5692597031593323
test loss item: 0.744677722454071
test loss item: 0.3532862961292267
test loss item: 0.922767698764801
test loss item: 0.4198714792728424
test loss item: 0.34052136540412903
test loss item: 0.2040863186120987
test loss item: 0.2646273970603943
test loss item: 0.2708680331707001
test loss item: 0.4092969000339508
test loss item: 0.2107795923948288
test loss item: 0.40575289726257324
test loss item: 0.4177018105983734
test loss item: 0.8894621729850769
test loss item: 0.06070800870656967
test loss item: 0.173090398311615
test loss item: 0.6867395043373108
test loss item: 0.5430349111557007
test loss item: 0.4667726159095764
test loss item: 0.9181634783744812
test loss item: 1.663649559020996
test loss item: 0.5955311059951782
test loss item: 0.32610753178596497
test loss item: 0.35770681500434875
test loss item: 0.21600353717803955
test loss item: 0.4062972664833069
test loss item: 0.23694376647472382
test loss item: 0.7471621632575989
test loss item: 0.5484790802001953
test loss item: 0.3480468690395355
test loss item: 0.2889062464237213
test loss item: 0.557843804359436
test loss item: 0.7910370230674744
test loss item: 0.35429033637046814
test loss item: 0.1377655416727066
test loss item: 0.27562808990478516
test loss item: 0.1488664448261261
test loss item: 0.35695379972457886
test loss item: 1.073257565498352
test loss item: 0.6009395718574524
test loss item: 0.3181440234184265
test loss item: 0.2796781361103058
test loss item: 0.22277353703975677
test loss item: 0.524603545665741
test loss item: 0.2611807882785797
test loss item: 0.2587733566761017
test loss item: 0.30261582136154175
test loss item: 1.0366787910461426
test loss item: 0.32165172696113586
test loss item: 0.3745185136795044
test loss item: 0.30898135900497437
test loss item: 0.6433897018432617
test loss item: 0.43233150243759155
test loss item: 0.06355488300323486
test loss item: 1.1316440105438232
test loss item: 0.3752817213535309
test loss item: 0.47489967942237854
test loss item: 0.17363454401493073
test loss item: 0.19184066355228424
test loss item: 0.20172154903411865
test loss item: 1.6632000207901
test loss item: 0.5551758408546448
test loss item: 0.22079713642597198
test loss item: 0.08000001311302185
test loss item: 1.0646127462387085
test loss item: 1.0027824640274048
test loss item: 1.1290721893310547
test loss item: 0.26098424196243286
test loss item: 0.26016929745674133
test loss item: 0.0751400962471962
test loss item: 0.07278726994991302
test loss item: 0.19678431749343872
Epoch [50/50], Training Loss: 0.4768, Testing Loss: 0.4609
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
loss item: 0.45030245184898376
loss item: 0.23555688560009003
loss item: 1.8063366413116455
loss item: 1.3098965883255005
loss item: 0.6131597757339478
loss item: 0.47334185242652893
loss item: 0.19331634044647217
loss item: 0.8383352756500244
loss item: 0.2060096114873886
loss item: 0.21343310177326202
loss item: 0.9857197999954224
loss item: 0.03964827209711075
loss item: 0.9309833645820618
loss item: 0.2688017189502716
loss item: 0.47620120644569397
loss item: 0.3450849652290344
loss item: 0.3489571213722229
loss item: 0.9396778345108032
loss item: 1.0398550033569336
loss item: 0.6222038865089417
loss item: 0.45189332962036133
loss item: 0.27983346581459045
loss item: 0.3578595817089081
loss item: 0.26371949911117554
loss item: 0.3819081783294678
loss item: 0.7691279649734497
loss item: 1.2114909887313843
loss item: 0.16050706803798676
loss item: 0.1314857304096222
loss item: 0.525833010673523
loss item: 1.086763858795166
loss item: 1.6480610370635986
loss item: 0.19136245548725128
loss item: 0.538063645362854
loss item: 0.18988992273807526
loss item: 0.21562957763671875
loss item: 0.5142043232917786
loss item: 0.26553428173065186
loss item: 0.4373858869075775
loss item: 0.7274006009101868
loss item: 1.1123638153076172
loss item: 0.3266838788986206
loss item: 0.2186453640460968
loss item: 0.06297049671411514
Val Loss: 0.5547
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.005, epochs: 50, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 50 0.005 2 360 done at Wed Nov 13 19:06:30 CET 2024
UNet6 with 1 50 0.0001 4 360 start at Wed Nov 13 19:06:30 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 0.28402212262153625
UNet6 with 1 50 0.0001 4 360 done at Wed Nov 13 19:07:07 CET 2024
UNet6 with 1 50 0.0005 4 360 start at Wed Nov 13 19:07:07 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 806.2598876953125
UNet6 with 1 50 0.0005 4 360 done at Wed Nov 13 19:07:40 CET 2024
UNet6 with 1 50 0.001 4 360 start at Wed Nov 13 19:07:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 50, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 7438055.5
UNet6 with 1 50 0.001 4 360 done at Wed Nov 13 19:08:16 CET 2024
UNet6 with 1 50 0.005 4 360 start at Wed Nov 13 19:08:16 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 50, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: inf
UNet6 with 1 50 0.005 4 360 done at Wed Nov 13 19:08:52 CET 2024
UNet6 with 1 50 0.0001 8 360 start at Wed Nov 13 19:08:52 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0001 8 360 done at Wed Nov 13 19:09:29 CET 2024
UNet6 with 1 50 0.0005 8 360 start at Wed Nov 13 19:09:29 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0005 8 360 done at Wed Nov 13 19:10:07 CET 2024
UNet6 with 1 50 0.001 8 360 start at Wed Nov 13 19:10:07 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 50, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.001 8 360 done at Wed Nov 13 19:10:44 CET 2024
UNet6 with 1 50 0.005 8 360 start at Wed Nov 13 19:10:44 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 50, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.005 8 360 done at Wed Nov 13 19:11:19 CET 2024
UNet6 with 1 50 0.0001 16 360 start at Wed Nov 13 19:11:19 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0001 16 360 done at Wed Nov 13 19:11:56 CET 2024
UNet6 with 1 50 0.0005 16 360 start at Wed Nov 13 19:11:56 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0005 16 360 done at Wed Nov 13 19:12:32 CET 2024
UNet6 with 1 50 0.001 16 360 start at Wed Nov 13 19:12:32 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 50, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.001 16 360 done at Wed Nov 13 19:13:10 CET 2024
UNet6 with 1 50 0.005 16 360 start at Wed Nov 13 19:13:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 50, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.005 16 360 done at Wed Nov 13 19:13:46 CET 2024
UNet6 with 1 50 0.0001 32 360 start at Wed Nov 13 19:13:46 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0001 32 360 done at Wed Nov 13 19:14:22 CET 2024
UNet6 with 1 50 0.0005 32 360 start at Wed Nov 13 19:14:22 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0005 32 360 done at Wed Nov 13 19:14:58 CET 2024
UNet6 with 1 50 0.001 32 360 start at Wed Nov 13 19:14:58 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 50, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.001 32 360 done at Wed Nov 13 19:15:34 CET 2024
UNet6 with 1 50 0.005 32 360 start at Wed Nov 13 19:15:34 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 50, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.005 32 360 done at Wed Nov 13 19:16:10 CET 2024
UNet6 with 1 50 0.0001 64 360 start at Wed Nov 13 19:16:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0001 64 360 done at Wed Nov 13 19:16:46 CET 2024
UNet6 with 1 50 0.0005 64 360 start at Wed Nov 13 19:16:46 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0005 64 360 done at Wed Nov 13 19:17:22 CET 2024
UNet6 with 1 50 0.001 64 360 start at Wed Nov 13 19:17:22 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 50, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.001 64 360 done at Wed Nov 13 19:17:59 CET 2024
UNet6 with 1 50 0.005 64 360 start at Wed Nov 13 19:17:59 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 50, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.005 64 360 done at Wed Nov 13 19:18:37 CET 2024
UNet6 with 1 50 0.0001 128 360 start at Wed Nov 13 19:18:37 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0001 128 360 done at Wed Nov 13 19:19:14 CET 2024
UNet6 with 1 50 0.0005 128 360 start at Wed Nov 13 19:19:14 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0005 128 360 done at Wed Nov 13 19:19:52 CET 2024
UNet6 with 1 50 0.001 128 360 start at Wed Nov 13 19:19:52 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 50, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.001 128 360 done at Wed Nov 13 19:20:29 CET 2024
UNet6 with 1 50 0.005 128 360 start at Wed Nov 13 19:20:29 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 50, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.005 128 360 done at Wed Nov 13 19:21:07 CET 2024
UNet6 with 1 50 0.0001 256 360 start at Wed Nov 13 19:21:07 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0001 256 360 done at Wed Nov 13 19:21:43 CET 2024
UNet6 with 1 50 0.0005 256 360 start at Wed Nov 13 19:21:43 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 50, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.0005 256 360 done at Wed Nov 13 19:22:22 CET 2024
UNet6 with 1 50 0.001 256 360 start at Wed Nov 13 19:22:22 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 50, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.001 256 360 done at Wed Nov 13 19:22:58 CET 2024
UNet6 with 1 50 0.005 256 360 start at Wed Nov 13 19:22:58 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 50, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/50
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 50 0.005 256 360 done at Wed Nov 13 19:23:35 CET 2024
UNet6 with 1 100 0.0001 2 360 start at Wed Nov 13 19:23:35 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 0.32543858885765076
test loss item: 0.3201671838760376
test loss item: 1.2930320501327515
test loss item: 0.45639359951019287
test loss item: 0.5333396792411804
test loss item: 0.30889764428138733
test loss item: 3.5530126094818115
test loss item: 1.234115719795227
test loss item: 0.476423978805542
test loss item: 0.778984546661377
test loss item: 1.7774710655212402
test loss item: 0.39120641350746155
test loss item: 0.37649041414260864
test loss item: 0.5524864196777344
test loss item: 0.4167979657649994
test loss item: 0.32238027453422546
test loss item: 0.5221328735351562
test loss item: 0.9708770513534546
test loss item: 1.2458000183105469
test loss item: 0.4878620505332947
test loss item: 1.5960745811462402
test loss item: 0.7644118070602417
test loss item: 0.6354523301124573
test loss item: 0.3850398659706116
test loss item: 0.4352385401725769
test loss item: 0.4026394784450531
test loss item: 0.58271324634552
test loss item: 0.41043102741241455
test loss item: 0.6289176940917969
test loss item: 0.6483367681503296
test loss item: 1.7453397512435913
test loss item: 0.31950175762176514
test loss item: 0.35034263134002686
test loss item: 1.12245774269104
test loss item: 0.9462670683860779
test loss item: 1.113990068435669
test loss item: 1.5381397008895874
test loss item: 3.152377128601074
test loss item: 0.9831701517105103
test loss item: 0.5262065529823303
test loss item: 0.5640122890472412
test loss item: 0.3411385416984558
test loss item: 0.6919870972633362
test loss item: 0.4776293933391571
test loss item: 1.2580336332321167
test loss item: 0.7641651034355164
test loss item: 0.5913205146789551
test loss item: 0.427951842546463
test loss item: 1.0075477361679077
test loss item: 1.388818383216858
test loss item: 0.6537537574768066
test loss item: 0.3242349326610565
test loss item: 0.48420798778533936
test loss item: 0.47728821635246277
test loss item: 0.6459164619445801
test loss item: 1.8029687404632568
test loss item: 1.2264267206192017
test loss item: 0.6554515361785889
test loss item: 0.486260324716568
test loss item: 0.39739689230918884
test loss item: 0.8615291118621826
test loss item: 0.5327340364456177
test loss item: 0.38816121220588684
test loss item: 0.4550304114818573
test loss item: 2.000312328338623
test loss item: 0.6046019792556763
test loss item: 0.6398140788078308
test loss item: 0.4611686170101166
test loss item: 1.0433357954025269
test loss item: 0.9037917256355286
test loss item: 0.2714395821094513
test loss item: 2.0580642223358154
test loss item: 0.6133452653884888
test loss item: 0.7100709676742554
test loss item: 0.30532658100128174
test loss item: 0.34291383624076843
test loss item: 0.38030973076820374
test loss item: 3.477576971054077
test loss item: 0.8611140847206116
test loss item: 0.36515647172927856
test loss item: 0.25860074162483215
test loss item: 2.1804089546203613
test loss item: 1.6943840980529785
test loss item: 2.3984882831573486
test loss item: 0.45027413964271545
test loss item: 0.4050922691822052
test loss item: 0.28383657336235046
test loss item: 0.312621533870697
test loss item: 0.28796151280403137
Epoch [1/100], Training Loss: 1.0161, Testing Loss: 0.8409
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8469700217247009
1
train loss item: 2.2568891048431396
2
train loss item: 0.5336769223213196
3
train loss item: 1.237526774406433
4
train loss item: 0.9404008984565735
5
train loss item: 0.6270371675491333
6
train loss item: 0.57844078540802
7
train loss item: 1.4458200931549072
8
train loss item: 0.47675803303718567
9
train loss item: 0.5896623730659485
10
train loss item: 0.7542068362236023
11
train loss item: 0.48272591829299927
12
train loss item: 0.4065133035182953
13
train loss item: 0.9814792275428772
14
train loss item: 0.5562806129455566
15
train loss item: 1.2292604446411133
16
train loss item: 0.3920826315879822
17
train loss item: 0.5793091058731079
18
train loss item: 0.7637796998023987
19
train loss item: 0.5272666811943054
20
train loss item: 0.4833765923976898
21
train loss item: 0.3846867084503174
22
train loss item: 1.8146706819534302
23
train loss item: 1.5029590129852295
24
train loss item: 1.02009916305542
25
train loss item: 0.5557008385658264
26
train loss item: 0.45766282081604004
27
train loss item: 0.6440454125404358
28
train loss item: 0.3889157474040985
29
train loss item: 1.458027958869934
30
train loss item: 3.3603432178497314
31
train loss item: 1.1073217391967773
32
train loss item: 0.4354054033756256
33
train loss item: 0.9232630133628845
34
train loss item: 0.5001205205917358
35
train loss item: 3.199995279312134
36
train loss item: 0.9644607901573181
37
train loss item: 0.5206009149551392
38
train loss item: 1.0942904949188232
39
train loss item: 0.6534966826438904
40
train loss item: 0.4141879081726074
41
train loss item: 0.6332598328590393
42
train loss item: 0.4832932949066162
43
train loss item: 0.49745216965675354
44
train loss item: 1.2244560718536377
45
train loss item: 0.4191514551639557
46
train loss item: 0.4505915939807892
47
train loss item: 0.7244898080825806
48
train loss item: 0.5662857890129089
49
train loss item: 0.45370593667030334
50
train loss item: 0.5387917160987854
51
train loss item: 1.5974620580673218
52
train loss item: 0.4117096960544586
53
train loss item: 0.4850711226463318
54
train loss item: 3.072237253189087
55
train loss item: 0.4860619008541107
56
train loss item: 0.6088640093803406
57
train loss item: 0.5018900632858276
58
train loss item: 0.4447954297065735
59
train loss item: 0.48289012908935547
60
train loss item: 1.7332994937896729
61
train loss item: 3.049617290496826
62
train loss item: 0.5403962731361389
63
train loss item: 0.7169005274772644
64
train loss item: 0.4913247525691986
65
train loss item: 1.0675947666168213
66
train loss item: 0.7613896727561951
67
train loss item: 0.4965679943561554
68
train loss item: 0.700104832649231
69
train loss item: 0.6811779141426086
70
train loss item: 0.5612931847572327
71
train loss item: 0.42531144618988037
72
train loss item: 0.528998851776123
73
train loss item: 0.586263120174408
74
train loss item: 0.46703168749809265
75
train loss item: 0.4403144121170044
76
train loss item: 1.4954246282577515
77
train loss item: 1.9771878719329834
78
train loss item: 0.40473371744155884
79
train loss item: 0.5859912633895874
80
train loss item: 0.4113095700740814
81
train loss item: 0.45442962646484375
82
train loss item: 0.5650709867477417
83
train loss item: 1.2717928886413574
84
train loss item: 0.7470484972000122
85
train loss item: 1.1924268007278442
86
train loss item: 5.400422096252441
87
train loss item: 0.538705587387085
88
train loss item: 0.6909709572792053
epoch train loss: 0.9118570514609304
testing phase
test loss item: 0.32313835620880127
test loss item: 0.33549079298973083
test loss item: 1.2464580535888672
test loss item: 0.4215610921382904
test loss item: 0.545681357383728
test loss item: 0.3143472373485565
test loss item: 3.2590036392211914
test loss item: 1.0636874437332153
test loss item: 0.47387224435806274
test loss item: 0.7689830660820007
test loss item: 1.6702098846435547
test loss item: 0.36385172605514526
test loss item: 0.3599485456943512
test loss item: 0.5972532033920288
test loss item: 0.4212416112422943
test loss item: 0.34016671776771545
test loss item: 0.46121975779533386
test loss item: 0.9875484704971313
test loss item: 1.118828296661377
test loss item: 0.4557102620601654
test loss item: 1.62374746799469
test loss item: 0.6738596558570862
test loss item: 0.6389990448951721
test loss item: 0.3596741855144501
test loss item: 0.4314025938510895
test loss item: 0.3838667869567871
test loss item: 0.5595067143440247
test loss item: 0.4218214452266693
test loss item: 0.6222934722900391
test loss item: 0.6317676305770874
test loss item: 1.6140263080596924
test loss item: 0.32190608978271484
test loss item: 0.33373966813087463
test loss item: 1.109312891960144
test loss item: 0.9489903450012207
test loss item: 1.1102555990219116
test loss item: 1.4203596115112305
test loss item: 2.964846134185791
test loss item: 0.966056764125824
test loss item: 0.4911685287952423
test loss item: 0.5290465950965881
test loss item: 0.32827121019363403
test loss item: 0.7328452467918396
test loss item: 0.4300273656845093
test loss item: 1.2944674491882324
test loss item: 0.6773479580879211
test loss item: 0.5981626510620117
test loss item: 0.4238423705101013
test loss item: 0.9695281982421875
test loss item: 1.2928868532180786
test loss item: 0.690413773059845
test loss item: 0.3104289174079895
test loss item: 0.48790881037712097
test loss item: 0.4154609739780426
test loss item: 0.6776193976402283
test loss item: 1.7218269109725952
test loss item: 1.172100305557251
test loss item: 0.7466410398483276
test loss item: 0.47152912616729736
test loss item: 0.4307118356227875
test loss item: 0.8777498006820679
test loss item: 0.4464675188064575
test loss item: 0.3672596216201782
test loss item: 0.42773938179016113
test loss item: 1.8666683435440063
test loss item: 0.5466116666793823
test loss item: 0.5705507397651672
test loss item: 0.44019070267677307
test loss item: 1.0254302024841309
test loss item: 0.8006142377853394
test loss item: 0.28219568729400635
test loss item: 1.832497477531433
test loss item: 0.6555683016777039
test loss item: 0.617949366569519
test loss item: 0.2844226360321045
test loss item: 0.32915470004081726
test loss item: 0.35920450091362
test loss item: 3.2612061500549316
test loss item: 0.8693538904190063
test loss item: 0.36148953437805176
test loss item: 0.25196540355682373
test loss item: 2.029910087585449
test loss item: 1.5777088403701782
test loss item: 2.250333309173584
test loss item: 0.45082563161849976
test loss item: 0.3806471824645996
test loss item: 0.28600361943244934
test loss item: 0.3300008177757263
test loss item: 0.2796914279460907
Epoch [2/100], Training Loss: 0.9119, Testing Loss: 0.8047
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8339841961860657
1
train loss item: 2.155839443206787
2
train loss item: 0.5232412815093994
3
train loss item: 1.150844693183899
4
train loss item: 0.882523238658905
5
train loss item: 0.6161549687385559
6
train loss item: 0.5675970315933228
7
train loss item: 1.3633010387420654
8
train loss item: 0.4495686888694763
9
train loss item: 0.5440057516098022
10
train loss item: 0.7016858458518982
11
train loss item: 0.45297563076019287
12
train loss item: 0.3669850826263428
13
train loss item: 0.9551968574523926
14
train loss item: 0.5574626326560974
15
train loss item: 1.1836556196212769
16
train loss item: 0.3848850131034851
17
train loss item: 0.5527244806289673
18
train loss item: 0.719939649105072
19
train loss item: 0.48777318000793457
20
train loss item: 0.46295514702796936
21
train loss item: 0.36673852801322937
22
train loss item: 1.7580007314682007
23
train loss item: 1.4418275356292725
24
train loss item: 0.9778796434402466
25
train loss item: 0.5289973616600037
26
train loss item: 0.43923649191856384
27
train loss item: 0.6160111427307129
28
train loss item: 0.37907761335372925
29
train loss item: 1.4136497974395752
30
train loss item: 3.1977977752685547
31
train loss item: 1.0274486541748047
32
train loss item: 0.37705734372138977
33
train loss item: 0.8513282537460327
34
train loss item: 0.5206930041313171
35
train loss item: 3.1048710346221924
36
train loss item: 0.9418485760688782
37
train loss item: 0.4913369119167328
38
train loss item: 1.0372068881988525
39
train loss item: 0.6275733113288879
40
train loss item: 0.3992249369621277
41
train loss item: 0.5987964272499084
42
train loss item: 0.4522729218006134
43
train loss item: 0.4486117362976074
44
train loss item: 1.1767184734344482
45
train loss item: 0.4142310917377472
46
train loss item: 0.4471043050289154
47
train loss item: 0.6793163418769836
48
train loss item: 0.5297558307647705
49
train loss item: 0.4446152448654175
50
train loss item: 0.5057280659675598
51
train loss item: 1.5452731847763062
52
train loss item: 0.36935728788375854
53
train loss item: 0.47329387068748474
54
train loss item: 2.9714455604553223
55
train loss item: 0.49070268869400024
56
train loss item: 0.5764620304107666
57
train loss item: 0.4921422004699707
58
train loss item: 0.39828577637672424
59
train loss item: 0.4151388108730316
60
train loss item: 1.6824674606323242
61
train loss item: 2.940248727798462
62
train loss item: 0.4804028272628784
63
train loss item: 0.6669731140136719
64
train loss item: 0.43764612078666687
65
train loss item: 1.0308862924575806
66
train loss item: 0.7245259881019592
67
train loss item: 0.47396448254585266
68
train loss item: 0.6318886280059814
69
train loss item: 0.6422450542449951
70
train loss item: 0.5253357291221619
71
train loss item: 0.4606528878211975
72
train loss item: 0.4892352223396301
73
train loss item: 0.5586839914321899
74
train loss item: 0.4522111415863037
75
train loss item: 0.38975849747657776
76
train loss item: 1.4339712858200073
77
train loss item: 1.9305144548416138
78
train loss item: 0.368850439786911
79
train loss item: 0.5352991223335266
80
train loss item: 0.4268273413181305
81
train loss item: 0.4208105802536011
82
train loss item: 0.5485832095146179
83
train loss item: 1.2255637645721436
84
train loss item: 0.7117674946784973
85
train loss item: 1.1252810955047607
86
train loss item: 5.23826789855957
87
train loss item: 0.5173043608665466
88
train loss item: 0.6507450342178345
epoch train loss: 0.8714749337582106
testing phase
test loss item: 0.31795457005500793
test loss item: 0.33500340580940247
test loss item: 1.22190260887146
test loss item: 0.3949345052242279
test loss item: 0.5478627681732178
test loss item: 0.3122747540473938
test loss item: 2.9288077354431152
test loss item: 0.889796257019043
test loss item: 0.47539907693862915
test loss item: 0.7647536993026733
test loss item: 1.6291959285736084
test loss item: 0.3499634563922882
test loss item: 0.36035239696502686
test loss item: 0.6533820033073425
test loss item: 0.4128269851207733
test loss item: 0.34199076890945435
test loss item: 0.4320693910121918
test loss item: 0.9891956448554993
test loss item: 1.0085471868515015
test loss item: 0.46115145087242126
test loss item: 1.6226433515548706
test loss item: 0.6145684719085693
test loss item: 0.6501948237419128
test loss item: 0.3369729518890381
test loss item: 0.4258705973625183
test loss item: 0.40289613604545593
test loss item: 0.5507012605667114
test loss item: 0.42514339089393616
test loss item: 0.6126364469528198
test loss item: 0.6209904551506042
test loss item: 1.5354390144348145
test loss item: 0.3173537850379944
test loss item: 0.3136001527309418
test loss item: 1.0968449115753174
test loss item: 0.9422520399093628
test loss item: 1.0225224494934082
test loss item: 1.2986174821853638
test loss item: 2.902078151702881
test loss item: 0.9525632262229919
test loss item: 0.46431851387023926
test loss item: 0.4985174238681793
test loss item: 0.3405885696411133
test loss item: 0.7489770650863647
test loss item: 0.4025125503540039
test loss item: 1.3049724102020264
test loss item: 0.6391319632530212
test loss item: 0.6088792085647583
test loss item: 0.45782670378685
test loss item: 0.947560727596283
test loss item: 1.2390003204345703
test loss item: 0.7077956795692444
test loss item: 0.31042444705963135
test loss item: 0.4959840476512909
test loss item: 0.38483959436416626
test loss item: 0.6994051933288574
test loss item: 1.6884492635726929
test loss item: 1.0632306337356567
test loss item: 0.7790811657905579
test loss item: 0.46323174238204956
test loss item: 0.4554395377635956
test loss item: 0.8789593577384949
test loss item: 0.3961588144302368
test loss item: 0.37443986535072327
test loss item: 0.4060540199279785
test loss item: 1.7633836269378662
test loss item: 0.506710410118103
test loss item: 0.5404588580131531
test loss item: 0.4258936047554016
test loss item: 1.0155770778656006
test loss item: 0.7440217137336731
test loss item: 0.28759053349494934
test loss item: 1.607879877090454
test loss item: 0.680265486240387
test loss item: 0.568448543548584
test loss item: 0.29144391417503357
test loss item: 0.33735382556915283
test loss item: 0.3394831717014313
test loss item: 3.1792073249816895
test loss item: 0.8882248401641846
test loss item: 0.3628036379814148
test loss item: 0.2422766089439392
test loss item: 1.9008512496948242
test loss item: 1.475480318069458
test loss item: 2.1858761310577393
test loss item: 0.4629882574081421
test loss item: 0.39659690856933594
test loss item: 0.2774353623390198
test loss item: 0.3253585696220398
test loss item: 0.31033265590667725
Epoch [3/100], Training Loss: 0.8715, Testing Loss: 0.7791
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8108084201812744
1
train loss item: 2.0759809017181396
2
train loss item: 0.4898815155029297
3
train loss item: 1.092602252960205
4
train loss item: 0.8475688695907593
5
train loss item: 0.6006972789764404
6
train loss item: 0.5378050208091736
7
train loss item: 1.3109055757522583
8
train loss item: 0.4388323426246643
9
train loss item: 0.5080493092536926
10
train loss item: 0.670032262802124
11
train loss item: 0.43226227164268494
12
train loss item: 0.3437403738498688
13
train loss item: 0.9259993433952332
14
train loss item: 0.5493934750556946
15
train loss item: 1.1318696737289429
16
train loss item: 0.36250928044319153
17
train loss item: 0.5233271718025208
18
train loss item: 0.6783027648925781
19
train loss item: 0.4564222991466522
20
train loss item: 0.42156511545181274
21
train loss item: 0.360436350107193
22
train loss item: 1.6809577941894531
23
train loss item: 1.4047471284866333
24
train loss item: 0.9263560175895691
25
train loss item: 0.5049294829368591
26
train loss item: 0.43008047342300415
27
train loss item: 0.5890274047851562
28
train loss item: 0.3583187758922577
29
train loss item: 1.3561855554580688
30
train loss item: 3.10564923286438
31
train loss item: 0.9759548306465149
32
train loss item: 0.3571937680244446
33
train loss item: 0.8014444708824158
34
train loss item: 0.5056254267692566
35
train loss item: 3.045522451400757
36
train loss item: 0.9087722301483154
37
train loss item: 0.4551425874233246
38
train loss item: 0.9830286502838135
39
train loss item: 0.6014152765274048
40
train loss item: 0.3791196048259735
41
train loss item: 0.5738795399665833
42
train loss item: 0.4293659031391144
43
train loss item: 0.4173487722873688
44
train loss item: 1.1409655809402466
45
train loss item: 0.4043237268924713
46
train loss item: 0.43998920917510986
47
train loss item: 0.6404938101768494
48
train loss item: 0.5066149234771729
49
train loss item: 0.4372107684612274
50
train loss item: 0.46831732988357544
51
train loss item: 1.4908002614974976
52
train loss item: 0.3506079614162445
53
train loss item: 0.4517662525177002
54
train loss item: 2.912156581878662
55
train loss item: 0.48277050256729126
56
train loss item: 0.5510663390159607
57
train loss item: 0.47791534662246704
58
train loss item: 0.3733982443809509
59
train loss item: 0.39021700620651245
60
train loss item: 1.6149908304214478
61
train loss item: 2.8774216175079346
62
train loss item: 0.4480277895927429
63
train loss item: 0.6163225769996643
64
train loss item: 0.4062311351299286
65
train loss item: 0.9675815105438232
66
train loss item: 0.6944425106048584
67
train loss item: 0.45582976937294006
68
train loss item: 0.5773131251335144
69
train loss item: 0.6074137687683105
70
train loss item: 0.49719342589378357
71
train loss item: 0.44620922207832336
72
train loss item: 0.469643235206604
73
train loss item: 0.5289588570594788
74
train loss item: 0.44426441192626953
75
train loss item: 0.3619333803653717
76
train loss item: 1.3938376903533936
77
train loss item: 1.8615220785140991
78
train loss item: 0.3491065502166748
79
train loss item: 0.49164482951164246
80
train loss item: 0.41383516788482666
81
train loss item: 0.4007931351661682
82
train loss item: 0.5311732292175293
83
train loss item: 1.1701936721801758
84
train loss item: 0.6768920421600342
85
train loss item: 1.0704846382141113
86
train loss item: 5.145071506500244
87
train loss item: 0.4921460747718811
88
train loss item: 0.6109681129455566
epoch train loss: 0.8370687301908986
testing phase
test loss item: 0.30775806307792664
test loss item: 0.3258143961429596
test loss item: 1.1821327209472656
test loss item: 0.3921280801296234
test loss item: 0.5345216989517212
test loss item: 0.30030298233032227
test loss item: 2.674144983291626
test loss item: 0.7942736148834229
test loss item: 0.4592096507549286
test loss item: 0.738875687122345
test loss item: 1.616614818572998
test loss item: 0.35423293709754944
test loss item: 0.3492778539657593
test loss item: 0.6735019087791443
test loss item: 0.39678722620010376
test loss item: 0.33603009581565857
test loss item: 0.4119952321052551
test loss item: 0.9577990174293518
test loss item: 0.9643687009811401
test loss item: 0.4510314464569092
test loss item: 1.5708104372024536
test loss item: 0.5862696766853333
test loss item: 0.6374735832214355
test loss item: 0.31966790556907654
test loss item: 0.4100848436355591
test loss item: 0.411099910736084
test loss item: 0.5351224541664124
test loss item: 0.4139607548713684
test loss item: 0.5928141474723816
test loss item: 0.5945517420768738
test loss item: 1.4850165843963623
test loss item: 0.31441786885261536
test loss item: 0.29711011052131653
test loss item: 1.06705641746521
test loss item: 0.909639298915863
test loss item: 0.9561935663223267
test loss item: 1.2183877229690552
test loss item: 2.8717055320739746
test loss item: 0.9257088899612427
test loss item: 0.4419702887535095
test loss item: 0.47393158078193665
test loss item: 0.33632317185401917
test loss item: 0.7221086025238037
test loss item: 0.39759790897369385
test loss item: 1.2685260772705078
test loss item: 0.619602382183075
test loss item: 0.5946896076202393
test loss item: 0.4600624144077301
test loss item: 0.9146065711975098
test loss item: 1.2111867666244507
test loss item: 0.6846043467521667
test loss item: 0.2962060272693634
test loss item: 0.4858265817165375
test loss item: 0.403663694858551
test loss item: 0.6865236163139343
test loss item: 1.6551570892333984
test loss item: 0.9967135190963745
test loss item: 0.745629072189331
test loss item: 0.44499170780181885
test loss item: 0.4517505168914795
test loss item: 0.8450803160667419
test loss item: 0.3694184124469757
test loss item: 0.3730672001838684
test loss item: 0.38889753818511963
test loss item: 1.6918002367019653
test loss item: 0.5134384036064148
test loss item: 0.519895613193512
test loss item: 0.4108377695083618
test loss item: 0.9941897392272949
test loss item: 0.7626914978027344
test loss item: 0.28554823994636536
test loss item: 1.4507932662963867
test loss item: 0.6628401875495911
test loss item: 0.5367685556411743
test loss item: 0.28925982117652893
test loss item: 0.3314896821975708
test loss item: 0.3226867914199829
test loss item: 3.137493133544922
test loss item: 0.8804183602333069
test loss item: 0.35482415556907654
test loss item: 0.23323333263397217
test loss item: 1.824426531791687
test loss item: 1.404819369316101
test loss item: 2.1530356407165527
test loss item: 0.46168550848960876
test loss item: 0.4018937349319458
test loss item: 0.2681317925453186
test loss item: 0.31411948800086975
test loss item: 0.3249461054801941
Epoch [4/100], Training Loss: 0.8371, Testing Loss: 0.7544
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7796609401702881
1
train loss item: 2.010059356689453
2
train loss item: 0.44511091709136963
3
train loss item: 1.0517438650131226
4
train loss item: 0.8450306057929993
5
train loss item: 0.57757967710495
6
train loss item: 0.49180009961128235
7
train loss item: 1.2760989665985107
8
train loss item: 0.40773940086364746
9
train loss item: 0.4794023931026459
10
train loss item: 0.6471192836761475
11
train loss item: 0.41555893421173096
12
train loss item: 0.3190993368625641
13
train loss item: 0.8921120166778564
14
train loss item: 0.5288026332855225
15
train loss item: 1.0764939785003662
16
train loss item: 0.32711538672447205
17
train loss item: 0.4874758720397949
18
train loss item: 0.6384450197219849
19
train loss item: 0.42818355560302734
20
train loss item: 0.3809441328048706
21
train loss item: 0.34640902280807495
22
train loss item: 1.5987602472305298
23
train loss item: 1.3802639245986938
24
train loss item: 0.8739868998527527
25
train loss item: 0.47697538137435913
26
train loss item: 0.40358397364616394
27
train loss item: 0.563049852848053
28
train loss item: 0.32396200299263
29
train loss item: 1.2944035530090332
30
train loss item: 3.051302909851074
31
train loss item: 0.9362643361091614
32
train loss item: 0.34588149189949036
33
train loss item: 0.760771632194519
34
train loss item: 0.4560913145542145
35
train loss item: 3.0069806575775146
36
train loss item: 0.8687840700149536
37
train loss item: 0.4212398827075958
38
train loss item: 0.9265044927597046
39
train loss item: 0.5739575028419495
40
train loss item: 0.34593287110328674
41
train loss item: 0.554138720035553
42
train loss item: 0.40638595819473267
43
train loss item: 0.39280709624290466
44
train loss item: 1.1122468709945679
45
train loss item: 0.3839446008205414
46
train loss item: 0.42057302594184875
47
train loss item: 0.6026238799095154
48
train loss item: 0.48460885882377625
49
train loss item: 0.4203546345233917
50
train loss item: 0.43820545077323914
51
train loss item: 1.438658356666565
52
train loss item: 0.32985472679138184
53
train loss item: 0.4154053330421448
54
train loss item: 2.8761720657348633
55
train loss item: 0.4509719908237457
56
train loss item: 0.5292982459068298
57
train loss item: 0.45409220457077026
58
train loss item: 0.3560706079006195
59
train loss item: 0.3754793405532837
60
train loss item: 1.5435209274291992
61
train loss item: 2.839668035507202
62
train loss item: 0.4227515757083893
63
train loss item: 0.5711086988449097
64
train loss item: 0.3833215534687042
65
train loss item: 0.8986271619796753
66
train loss item: 0.6659120321273804
67
train loss item: 0.43268099427223206
68
train loss item: 0.5251824259757996
69
train loss item: 0.5718252062797546
70
train loss item: 0.4679638147354126
71
train loss item: 0.395112007856369
72
train loss item: 0.4398232698440552
73
train loss item: 0.4954840838909149
74
train loss item: 0.40830540657043457
75
train loss item: 0.3373056650161743
76
train loss item: 1.3642897605895996
77
train loss item: 1.792600154876709
78
train loss item: 0.3277115821838379
79
train loss item: 0.45572367310523987
80
train loss item: 0.3728855550289154
81
train loss item: 0.3768095374107361
82
train loss item: 0.5061531066894531
83
train loss item: 1.1126750707626343
84
train loss item: 0.6400269269943237
85
train loss item: 1.0217664241790771
86
train loss item: 5.090869426727295
87
train loss item: 0.45434513688087463
88
train loss item: 0.569412350654602
epoch train loss: 0.8020947856849499
testing phase
test loss item: 0.2944079339504242
test loss item: 0.31115877628326416
test loss item: 1.1197236776351929
test loss item: 0.4002673923969269
test loss item: 0.508098304271698
test loss item: 0.2811153829097748
test loss item: 2.4720258712768555
test loss item: 0.7395989298820496
test loss item: 0.42620962858200073
test loss item: 0.6889616847038269
test loss item: 1.5894813537597656
test loss item: 0.3649256229400635
test loss item: 0.3259153366088867
test loss item: 0.6538464426994324
test loss item: 0.3734178841114044
test loss item: 0.32615044713020325
test loss item: 0.39542409777641296
test loss item: 0.8938087224960327
test loss item: 0.9357021450996399
test loss item: 0.4182967245578766
test loss item: 1.4634835720062256
test loss item: 0.5720834136009216
test loss item: 0.6062527894973755
test loss item: 0.30439653992652893
test loss item: 0.38704171776771545
test loss item: 0.4026276469230652
test loss item: 0.5040755867958069
test loss item: 0.3908088207244873
test loss item: 0.5614749193191528
test loss item: 0.5503042936325073
test loss item: 1.428540587425232
test loss item: 0.30953580141067505
test loss item: 0.28297945857048035
test loss item: 1.0153175592422485
test loss item: 0.8510465025901794
test loss item: 0.89387047290802
test loss item: 1.152208924293518
test loss item: 2.811809778213501
test loss item: 0.8805440664291382
test loss item: 0.42009496688842773
test loss item: 0.4534331262111664
test loss item: 0.32947438955307007
test loss item: 0.6613423228263855
test loss item: 0.4020794928073883
test loss item: 1.1827168464660645
test loss item: 0.597578227519989
test loss item: 0.5653376579284668
test loss item: 0.4178438186645508
test loss item: 0.8647207021713257
test loss item: 1.1736154556274414
test loss item: 0.6257843375205994
test loss item: 0.26680490374565125
test loss item: 0.4597395062446594
test loss item: 0.4372676908969879
test loss item: 0.6427798867225647
test loss item: 1.592572808265686
test loss item: 0.9511065483093262
test loss item: 0.659789502620697
test loss item: 0.41512224078178406
test loss item: 0.4266466200351715
test loss item: 0.7771083116531372
test loss item: 0.35032975673675537
test loss item: 0.3610040843486786
test loss item: 0.37155458331108093
test loss item: 1.620525598526001
test loss item: 0.5392459034919739
test loss item: 0.49479857087135315
test loss item: 0.39421167969703674
test loss item: 0.9604143500328064
test loss item: 0.7655041813850403
test loss item: 0.2775587737560272
test loss item: 1.335054874420166
test loss item: 0.6097002625465393
test loss item: 0.5110036730766296
test loss item: 0.27846789360046387
test loss item: 0.32539108395576477
test loss item: 0.3064116835594177
test loss item: 3.0769379138946533
test loss item: 0.8437519073486328
test loss item: 0.3389020562171936
test loss item: 0.22244851291179657
test loss item: 1.7589613199234009
test loss item: 1.3271862268447876
test loss item: 2.107534170150757
test loss item: 0.4446197748184204
test loss item: 0.39662104845046997
test loss item: 0.2579548954963684
test loss item: 0.3008650243282318
test loss item: 0.3266509771347046
Epoch [5/100], Training Loss: 0.8021, Testing Loss: 0.7204
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.748602569103241
1
train loss item: 1.9517829418182373
2
train loss item: 0.41519537568092346
3
train loss item: 1.0192244052886963
4
train loss item: 0.894048810005188
5
train loss item: 0.5546940565109253
6
train loss item: 0.4568100869655609
7
train loss item: 1.2496094703674316
8
train loss item: 0.381190687417984
9
train loss item: 0.45959967374801636
10
train loss item: 0.6275076270103455
11
train loss item: 0.40392738580703735
12
train loss item: 0.304228812456131
13
train loss item: 0.8573651313781738
14
train loss item: 0.5061242580413818
15
train loss item: 1.0250595808029175
16
train loss item: 0.30560600757598877
17
train loss item: 0.464793860912323
18
train loss item: 0.6037325263023376
19
train loss item: 0.40831005573272705
20
train loss item: 0.3664623498916626
21
train loss item: 0.33752259612083435
22
train loss item: 1.522081732749939
23
train loss item: 1.3595930337905884
24
train loss item: 0.8278939723968506
25
train loss item: 0.45202314853668213
26
train loss item: 0.37200385332107544
27
train loss item: 0.5421493649482727
28
train loss item: 0.30322331190109253
29
train loss item: 1.2347155809402466
30
train loss item: 3.011455535888672
31
train loss item: 0.9026116132736206
32
train loss item: 0.34614595770835876
33
train loss item: 0.7282379865646362
34
train loss item: 0.41544389724731445
35
train loss item: 2.9755706787109375
36
train loss item: 0.825667142868042
37
train loss item: 0.3970089256763458
38
train loss item: 0.8682070970535278
39
train loss item: 0.5498356819152832
40
train loss item: 0.3182787001132965
41
train loss item: 0.5385719537734985
42
train loss item: 0.38787946105003357
43
train loss item: 0.3830243647098541
44
train loss item: 1.0866726636886597
45
train loss item: 0.3660482168197632
46
train loss item: 0.39839762449264526
47
train loss item: 0.5699037909507751
48
train loss item: 0.46495288610458374
49
train loss item: 0.4028517007827759
50
train loss item: 0.42106306552886963
51
train loss item: 1.3907179832458496
52
train loss item: 0.3213968873023987
53
train loss item: 0.38304316997528076
54
train loss item: 2.8478095531463623
55
train loss item: 0.41298386454582214
56
train loss item: 0.5140069127082825
57
train loss item: 0.43129900097846985
58
train loss item: 0.3543808162212372
59
train loss item: 0.36845850944519043
60
train loss item: 1.475396752357483
61
train loss item: 2.8099191188812256
62
train loss item: 0.40563157200813293
63
train loss item: 0.5364493727684021
64
train loss item: 0.3755883276462555
65
train loss item: 0.8417280316352844
66
train loss item: 0.6378605961799622
67
train loss item: 0.41260582208633423
68
train loss item: 0.4824536144733429
69
train loss item: 0.5390900373458862
70
train loss item: 0.4430888891220093
71
train loss item: 0.350946307182312
72
train loss item: 0.41805705428123474
73
train loss item: 0.4664129614830017
74
train loss item: 0.37507736682891846
75
train loss item: 0.32431578636169434
76
train loss item: 1.338376760482788
77
train loss item: 1.7337982654571533
78
train loss item: 0.32134532928466797
79
train loss item: 0.4309845268726349
80
train loss item: 0.34380486607551575
81
train loss item: 0.356802761554718
82
train loss item: 0.47982290387153625
83
train loss item: 1.0581223964691162
84
train loss item: 0.6024861931800842
85
train loss item: 0.9773295521736145
86
train loss item: 5.050403118133545
87
train loss item: 0.42371076345443726
88
train loss item: 0.5321334600448608
epoch train loss: 0.7739410159293185
testing phase
test loss item: 0.28285765647888184
test loss item: 0.2910250723361969
test loss item: 1.038278341293335
test loss item: 0.39673641324043274
test loss item: 0.4713729918003082
test loss item: 0.25869959592819214
test loss item: 2.308614492416382
test loss item: 0.6804385185241699
test loss item: 0.38770467042922974
test loss item: 0.6292113661766052
test loss item: 1.516302466392517
test loss item: 0.35848477482795715
test loss item: 0.3048478960990906
test loss item: 0.5956932306289673
test loss item: 0.34451016783714294
test loss item: 0.3108348846435547
test loss item: 0.38500136137008667
test loss item: 0.8092104196548462
test loss item: 0.8820996284484863
test loss item: 0.388202965259552
test loss item: 1.3188745975494385
test loss item: 0.5528374314308167
test loss item: 0.5582733750343323
test loss item: 0.2905130982398987
test loss item: 0.3622836172580719
test loss item: 0.3818763196468353
test loss item: 0.471523642539978
test loss item: 0.35931968688964844
test loss item: 0.5230212807655334
test loss item: 0.5107801556587219
test loss item: 1.347151756286621
test loss item: 0.29419392347335815
test loss item: 0.27123507857322693
test loss item: 0.9430735111236572
test loss item: 0.7770939469337463
test loss item: 0.8116128444671631
test loss item: 1.0822099447250366
test loss item: 2.6699509620666504
test loss item: 0.8191039562225342
test loss item: 0.3989098370075226
test loss item: 0.4362823963165283
test loss item: 0.3216151297092438
test loss item: 0.5876280069351196
test loss item: 0.3949923813343048
test loss item: 1.0627949237823486
test loss item: 0.5728654265403748
test loss item: 0.523749828338623
test loss item: 0.3899497389793396
test loss item: 0.803936779499054
test loss item: 1.1039834022521973
test loss item: 0.5513961911201477
test loss item: 0.24738220870494843
test loss item: 0.42468276619911194
test loss item: 0.4384826719760895
test loss item: 0.5777075290679932
test loss item: 1.4862524271011353
test loss item: 0.893644392490387
test loss item: 0.5411104559898376
test loss item: 0.3828810751438141
test loss item: 0.3893232047557831
test loss item: 0.6959276795387268
test loss item: 0.33346280455589294
test loss item: 0.3437314033508301
test loss item: 0.35429808497428894
test loss item: 1.5240002870559692
test loss item: 0.5391833186149597
test loss item: 0.4661504626274109
test loss item: 0.37874844670295715
test loss item: 0.9124294519424438
test loss item: 0.6942453384399414
test loss item: 0.2641560733318329
test loss item: 1.2411518096923828
test loss item: 0.5349103808403015
test loss item: 0.4904263913631439
test loss item: 0.2694527208805084
test loss item: 0.3162161409854889
test loss item: 0.2906290590763092
test loss item: 2.945387363433838
test loss item: 0.7804785370826721
test loss item: 0.31965142488479614
test loss item: 0.21171297132968903
test loss item: 1.6681251525878906
test loss item: 1.2281696796417236
test loss item: 2.0102736949920654
test loss item: 0.41459453105926514
test loss item: 0.38791966438293457
test loss item: 0.24808616936206818
test loss item: 0.2868981659412384
test loss item: 0.32191887497901917
Epoch [6/100], Training Loss: 0.7739, Testing Loss: 0.6740
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7250450253486633
1
train loss item: 1.8963671922683716
2
train loss item: 0.40832939743995667
3
train loss item: 0.9848305583000183
4
train loss item: 0.9500287771224976
5
train loss item: 0.5386240482330322
6
train loss item: 0.44654932618141174
7
train loss item: 1.2223066091537476
8
train loss item: 0.3730277717113495
9
train loss item: 0.4458974301815033
10
train loss item: 0.6054260730743408
11
train loss item: 0.3943251967430115
12
train loss item: 0.2974990904331207
13
train loss item: 0.8258436322212219
14
train loss item: 0.4897993803024292
15
train loss item: 0.9829004406929016
16
train loss item: 0.29593533277511597
17
train loss item: 0.45851245522499084
18
train loss item: 0.5749285817146301
19
train loss item: 0.3978850245475769
20
train loss item: 0.3758917450904846
21
train loss item: 0.3357202708721161
22
train loss item: 1.4587929248809814
23
train loss item: 1.33553946018219
24
train loss item: 0.7916880249977112
25
train loss item: 0.4317263066768646
26
train loss item: 0.3518047630786896
27
train loss item: 0.5253665447235107
28
train loss item: 0.29419541358947754
29
train loss item: 1.1824442148208618
30
train loss item: 2.967198371887207
31
train loss item: 0.8705212473869324
32
train loss item: 0.3520706593990326
33
train loss item: 0.6986963748931885
34
train loss item: 0.40041860938072205
35
train loss item: 2.941817283630371
36
train loss item: 0.7837926745414734
37
train loss item: 0.3837820291519165
38
train loss item: 0.8099672794342041
39
train loss item: 0.5299599766731262
40
train loss item: 0.3043278455734253
41
train loss item: 0.522918701171875
42
train loss item: 0.37530380487442017
43
train loss item: 0.38143476843833923
44
train loss item: 1.06053626537323
45
train loss item: 0.3509347438812256
46
train loss item: 0.3800371289253235
47
train loss item: 0.5430422425270081
48
train loss item: 0.44694840908050537
49
train loss item: 0.38815465569496155
50
train loss item: 0.41307199001312256
51
train loss item: 1.3472073078155518
52
train loss item: 0.31587648391723633
53
train loss item: 0.3609805703163147
54
train loss item: 2.815133810043335
55
train loss item: 0.386679470539093
56
train loss item: 0.5028964281082153
57
train loss item: 0.41806337237358093
58
train loss item: 0.36060816049575806
59
train loss item: 0.3603958785533905
60
train loss item: 1.4173498153686523
61
train loss item: 2.7756054401397705
62
train loss item: 0.3934878408908844
63
train loss item: 0.5129815936088562
64
train loss item: 0.3745044469833374
65
train loss item: 0.8056831955909729
66
train loss item: 0.6096500754356384
67
train loss item: 0.3977501094341278
68
train loss item: 0.45496949553489685
69
train loss item: 0.5121408104896545
70
train loss item: 0.4238382875919342
71
train loss item: 0.3328893482685089
72
train loss item: 0.4082969129085541
73
train loss item: 0.44634196162223816
74
train loss item: 0.359056681394577
75
train loss item: 0.31827598810195923
76
train loss item: 1.3105741739273071
77
train loss item: 1.6888480186462402
78
train loss item: 0.3181023597717285
79
train loss item: 0.41537314653396606
80
train loss item: 0.33986547589302063
81
train loss item: 0.34434908628463745
82
train loss item: 0.456859290599823
83
train loss item: 1.0112797021865845
84
train loss item: 0.5650999546051025
85
train loss item: 0.9362911581993103
86
train loss item: 5.005677223205566
87
train loss item: 0.40329083800315857
88
train loss item: 0.5032917261123657
epoch train loss: 0.7529408057753959
testing phase
test loss item: 0.27591967582702637
test loss item: 0.2699817419052124
test loss item: 0.9673385620117188
test loss item: 0.37364232540130615
test loss item: 0.4408826231956482
test loss item: 0.24249021708965302
test loss item: 2.181910514831543
test loss item: 0.615429162979126
test loss item: 0.3620438277721405
test loss item: 0.5900995135307312
test loss item: 1.422059178352356
test loss item: 0.327943354845047
test loss item: 0.2930201590061188
test loss item: 0.5406785607337952
test loss item: 0.32162031531333923
test loss item: 0.28976958990097046
test loss item: 0.3760007619857788
test loss item: 0.7462800145149231
test loss item: 0.8178505897521973
test loss item: 0.3771919012069702
test loss item: 1.2107174396514893
test loss item: 0.5212624669075012
test loss item: 0.5123588442802429
test loss item: 0.27851402759552
test loss item: 0.34486109018325806
test loss item: 0.35856831073760986
test loss item: 0.4585106074810028
test loss item: 0.3340260088443756
test loss item: 0.4934632480144501
test loss item: 0.49297136068344116
test loss item: 1.265183687210083
test loss item: 0.26592785120010376
test loss item: 0.2620905339717865
test loss item: 0.8768433928489685
test loss item: 0.7202975153923035
test loss item: 0.7508471608161926
test loss item: 1.0206356048583984
test loss item: 2.4927735328674316
test loss item: 0.7670969367027283
test loss item: 0.382376492023468
test loss item: 0.4210447371006012
test loss item: 0.30924782156944275
test loss item: 0.5415078997612
test loss item: 0.3671250641345978
test loss item: 0.9785248041152954
test loss item: 0.5499695539474487
test loss item: 0.48527756333351135
test loss item: 0.40325385332107544
test loss item: 0.7559338808059692
test loss item: 1.0360257625579834
test loss item: 0.5068701505661011
test loss item: 0.24543559551239014
test loss item: 0.39430177211761475
test loss item: 0.39271509647369385
test loss item: 0.524873673915863
test loss item: 1.3892714977264404
test loss item: 0.834233283996582
test loss item: 0.47245272994041443
test loss item: 0.3630944788455963
test loss item: 0.3568315804004669
test loss item: 0.6458171010017395
test loss item: 0.3173135221004486
test loss item: 0.32644954323768616
test loss item: 0.3411124050617218
test loss item: 1.4270179271697998
test loss item: 0.4998459815979004
test loss item: 0.4420665204524994
test loss item: 0.3661365807056427
test loss item: 0.8644558191299438
test loss item: 0.5945426225662231
test loss item: 0.2467961460351944
test loss item: 1.1691359281539917
test loss item: 0.48685696721076965
test loss item: 0.4751776158809662
test loss item: 0.2613297402858734
test loss item: 0.29828017950057983
test loss item: 0.27761703729629517
test loss item: 2.767854690551758
test loss item: 0.7287942171096802
test loss item: 0.3045288324356079
test loss item: 0.20229391753673553
test loss item: 1.5624992847442627
test loss item: 1.1428425312042236
test loss item: 1.884889006614685
test loss item: 0.38351893424987793
test loss item: 0.37417367100715637
test loss item: 0.2396904081106186
test loss item: 0.2724437117576599
test loss item: 0.3164465129375458
Epoch [7/100], Training Loss: 0.7529, Testing Loss: 0.6313
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.708001971244812
1
train loss item: 1.8426871299743652
2
train loss item: 0.4030629098415375
3
train loss item: 0.943972110748291
4
train loss item: 0.97047358751297
5
train loss item: 0.5277432203292847
6
train loss item: 0.4432361125946045
7
train loss item: 1.1902735233306885
8
train loss item: 0.361517995595932
9
train loss item: 0.4317360818386078
10
train loss item: 0.5786597728729248
11
train loss item: 0.38301411271095276
12
train loss item: 0.2860371470451355
13
train loss item: 0.79881352186203
14
train loss item: 0.47836148738861084
15
train loss item: 0.952923595905304
16
train loss item: 0.2824687957763672
17
train loss item: 0.45605868101119995
18
train loss item: 0.5502573847770691
19
train loss item: 0.38898152112960815
20
train loss item: 0.3806261718273163
21
train loss item: 0.32999297976493835
22
train loss item: 1.4134951829910278
23
train loss item: 1.3060765266418457
24
train loss item: 0.764419674873352
25
train loss item: 0.4134707748889923
26
train loss item: 0.3408883810043335
27
train loss item: 0.5085408091545105
28
train loss item: 0.28098952770233154
29
train loss item: 1.1426749229431152
30
train loss item: 2.9119691848754883
31
train loss item: 0.8374108076095581
32
train loss item: 0.34395259618759155
33
train loss item: 0.6658126711845398
34
train loss item: 0.3932028114795685
35
train loss item: 2.9015913009643555
36
train loss item: 0.748598575592041
37
train loss item: 0.3769359886646271
38
train loss item: 0.7584856152534485
39
train loss item: 0.5126988887786865
40
train loss item: 0.2944338023662567
41
train loss item: 0.5033056139945984
42
train loss item: 0.36442068219184875
43
train loss item: 0.3730334937572479
44
train loss item: 1.0328166484832764
45
train loss item: 0.3327730596065521
46
train loss item: 0.3618725538253784
47
train loss item: 0.5196734666824341
48
train loss item: 0.4271495044231415
49
train loss item: 0.36904993653297424
50
train loss item: 0.4042545258998871
51
train loss item: 1.309361219406128
52
train loss item: 0.2999815344810486
53
train loss item: 0.3441600799560547
54
train loss item: 2.7744359970092773
55
train loss item: 0.36826080083847046
56
train loss item: 0.489799827337265
57
train loss item: 0.4096318483352661
58
train loss item: 0.3576665222644806
59
train loss item: 0.34152311086654663
60
train loss item: 1.37274968624115
61
train loss item: 2.7326507568359375
62
train loss item: 0.3791086971759796
63
train loss item: 0.4950968325138092
64
train loss item: 0.3623572885990143
65
train loss item: 0.7870754599571228
66
train loss item: 0.5835492610931396
67
train loss item: 0.3836955428123474
68
train loss item: 0.4392319917678833
69
train loss item: 0.4907279908657074
70
train loss item: 0.40771377086639404
71
train loss item: 0.32656651735305786
72
train loss item: 0.39551594853401184
73
train loss item: 0.4330173432826996
74
train loss item: 0.341660737991333
75
train loss item: 0.3042452335357666
76
train loss item: 1.2787985801696777
77
train loss item: 1.6569417715072632
78
train loss item: 0.30156639218330383
79
train loss item: 0.40153080224990845
80
train loss item: 0.34104812145233154
81
train loss item: 0.33177152276039124
82
train loss item: 0.4345642924308777
83
train loss item: 0.9748205542564392
84
train loss item: 0.5324474573135376
85
train loss item: 0.8983108401298523
86
train loss item: 4.949611663818359
87
train loss item: 0.3841167092323303
88
train loss item: 0.48248252272605896
epoch train loss: 0.7324796918402897
testing phase
test loss item: 0.2723909914493561
test loss item: 0.25660935044288635
test loss item: 0.9180955290794373
test loss item: 0.35533270239830017
test loss item: 0.42316484451293945
test loss item: 0.23502807319164276
test loss item: 2.0866940021514893
test loss item: 0.5711057782173157
test loss item: 0.3477770686149597
test loss item: 0.5676054954528809
test loss item: 1.3509900569915771
test loss item: 0.3037613332271576
test loss item: 0.27963685989379883
test loss item: 0.5153923630714417
test loss item: 0.3091460168361664
test loss item: 0.27328523993492126
test loss item: 0.3653457760810852
test loss item: 0.7122204899787903
test loss item: 0.7782200574874878
test loss item: 0.35944491624832153
test loss item: 1.147992730140686
test loss item: 0.4952872693538666
test loss item: 0.4822838604450226
test loss item: 0.2707168459892273
test loss item: 0.33476078510284424
test loss item: 0.34322625398635864
test loss item: 0.4443514347076416
test loss item: 0.3199896812438965
test loss item: 0.47619935870170593
test loss item: 0.47766348719596863
test loss item: 1.1995846033096313
test loss item: 0.24012412130832672
test loss item: 0.25684934854507446
test loss item: 0.8350242376327515
test loss item: 0.6874162554740906
test loss item: 0.7145456671714783
test loss item: 0.9789660573005676
test loss item: 2.3581531047821045
test loss item: 0.7347946166992188
test loss item: 0.3713703155517578
test loss item: 0.40822702646255493
test loss item: 0.29893338680267334
test loss item: 0.5201877951622009
test loss item: 0.34269726276397705
test loss item: 0.9349420666694641
test loss item: 0.5286407470703125
test loss item: 0.45906051993370056
test loss item: 0.3735026717185974
test loss item: 0.7238771915435791
test loss item: 0.9892112612724304
test loss item: 0.4845767915248871
test loss item: 0.23543469607830048
test loss item: 0.3760939836502075
test loss item: 0.35554027557373047
test loss item: 0.49641966819763184
test loss item: 1.3233647346496582
test loss item: 0.7949119210243225
test loss item: 0.4516650438308716
test loss item: 0.3514101505279541
test loss item: 0.33864960074424744
test loss item: 0.6231448650360107
test loss item: 0.303519606590271
test loss item: 0.31428277492523193
test loss item: 0.3323974013328552
test loss item: 1.3530453443527222
test loss item: 0.4677087962627411
test loss item: 0.4247874617576599
test loss item: 0.35687094926834106
test loss item: 0.8293607831001282
test loss item: 0.5396868586540222
test loss item: 0.23341913521289825
test loss item: 1.1175638437271118
test loss item: 0.46755656599998474
test loss item: 0.46265333890914917
test loss item: 0.25186583399772644
test loss item: 0.2838640511035919
test loss item: 0.2694014310836792
test loss item: 2.615596294403076
test loss item: 0.7022935748100281
test loss item: 0.2956833243370056
test loss item: 0.19649259746074677
test loss item: 1.481480360031128
test loss item: 1.0860892534255981
test loss item: 1.7830463647842407
test loss item: 0.3639174699783325
test loss item: 0.36016497015953064
test loss item: 0.23603922128677368
test loss item: 0.26301097869873047
test loss item: 0.3172333240509033
Epoch [8/100], Training Loss: 0.7325, Testing Loss: 0.6019
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.693805456161499
1
train loss item: 1.7919248342514038
2
train loss item: 0.38955801725387573
3
train loss item: 0.9006991386413574
4
train loss item: 0.9439113140106201
5
train loss item: 0.5187687873840332
6
train loss item: 0.43574073910713196
7
train loss item: 1.156151533126831
8
train loss item: 0.3385792076587677
9
train loss item: 0.41702690720558167
10
train loss item: 0.5524259805679321
11
train loss item: 0.371816486120224
12
train loss item: 0.27234598994255066
13
train loss item: 0.7755131125450134
14
train loss item: 0.46885162591934204
15
train loss item: 0.9324030876159668
16
train loss item: 0.26689836382865906
17
train loss item: 0.4525136351585388
18
train loss item: 0.5284718871116638
19
train loss item: 0.37900298833847046
20
train loss item: 0.3748348355293274
21
train loss item: 0.3213857114315033
22
train loss item: 1.3825101852416992
23
train loss item: 1.274193286895752
24
train loss item: 0.7426904439926147
25
train loss item: 0.39694899320602417
26
train loss item: 0.33392104506492615
27
train loss item: 0.4924877882003784
28
train loss item: 0.26545992493629456
29
train loss item: 1.1143289804458618
30
train loss item: 2.8506901264190674
31
train loss item: 0.8055713772773743
32
train loss item: 0.32287776470184326
33
train loss item: 0.631591796875
34
train loss item: 0.383571594953537
35
train loss item: 2.8582541942596436
36
train loss item: 0.7211114168167114
37
train loss item: 0.37341177463531494
38
train loss item: 0.7166354060173035
39
train loss item: 0.49839070439338684
40
train loss item: 0.28340238332748413
41
train loss item: 0.48323291540145874
42
train loss item: 0.35290223360061646
43
train loss item: 0.35629481077194214
44
train loss item: 1.0055241584777832
45
train loss item: 0.31311145424842834
46
train loss item: 0.34218260645866394
47
train loss item: 0.5001187920570374
48
train loss item: 0.4076392650604248
49
train loss item: 0.3478739857673645
50
train loss item: 0.39379534125328064
51
train loss item: 1.277970552444458
52
train loss item: 0.2821103036403656
53
train loss item: 0.33289194107055664
54
train loss item: 2.729457139968872
55
train loss item: 0.3535982072353363
56
train loss item: 0.47511932253837585
57
train loss item: 0.4011613428592682
58
train loss item: 0.3452981114387512
59
train loss item: 0.3189842700958252
60
train loss item: 1.338139295578003
61
train loss item: 2.6850998401641846
62
train loss item: 0.36489546298980713
63
train loss item: 0.47950485348701477
64
train loss item: 0.3397953510284424
65
train loss item: 0.7761136889457703
66
train loss item: 0.5619968175888062
67
train loss item: 0.37151527404785156
68
train loss item: 0.4310392141342163
69
train loss item: 0.4741172790527344
70
train loss item: 0.39502644538879395
71
train loss item: 0.3202055096626282
72
train loss item: 0.37512660026550293
73
train loss item: 0.4237194061279297
74
train loss item: 0.31980329751968384
75
train loss item: 0.28525879979133606
76
train loss item: 1.2454768419265747
77
train loss item: 1.6329997777938843
78
train loss item: 0.27893492579460144
79
train loss item: 0.3873636722564697
80
train loss item: 0.3354424834251404
81
train loss item: 0.317414790391922
82
train loss item: 0.41368788480758667
83
train loss item: 0.9464116096496582
84
train loss item: 0.5080931186676025
85
train loss item: 0.864730715751648
86
train loss item: 4.88687801361084
87
train loss item: 0.3695136308670044
88
train loss item: 0.467318058013916
epoch train loss: 0.7117479577493132
testing phase
test loss item: 0.2709518074989319
test loss item: 0.2509154677391052
test loss item: 0.8919737935066223
test loss item: 0.3418078124523163
test loss item: 0.414585143327713
test loss item: 0.2306593358516693
test loss item: 2.0117831230163574
test loss item: 0.5442878603935242
test loss item: 0.34167271852493286
test loss item: 0.5570569038391113
test loss item: 1.314209222793579
test loss item: 0.2877947986125946
test loss item: 0.26816526055336
test loss item: 0.5036725401878357
test loss item: 0.30185794830322266
test loss item: 0.2638368606567383
test loss item: 0.3557228446006775
test loss item: 0.7017176747322083
test loss item: 0.7569265961647034
test loss item: 0.34550395607948303
test loss item: 1.1208957433700562
test loss item: 0.4767214059829712
test loss item: 0.47462406754493713
test loss item: 0.2636125683784485
test loss item: 0.3294946849346161
test loss item: 0.33806198835372925
test loss item: 0.43424615263938904
test loss item: 0.31355586647987366
test loss item: 0.46749499440193176
test loss item: 0.4661933183670044
test loss item: 1.1571115255355835
test loss item: 0.22426913678646088
test loss item: 0.2510755956172943
test loss item: 0.8178174495697021
test loss item: 0.6750607490539551
test loss item: 0.6885277628898621
test loss item: 0.9523870944976807
test loss item: 2.290499448776245
test loss item: 0.7208658456802368
test loss item: 0.361428827047348
test loss item: 0.39690661430358887
test loss item: 0.29840710759162903
test loss item: 0.5136575102806091
test loss item: 0.3265214264392853
test loss item: 0.9191911816596985
test loss item: 0.5130592584609985
test loss item: 0.4546346068382263
test loss item: 0.3430168330669403
test loss item: 0.7053095102310181
test loss item: 0.9624054431915283
test loss item: 0.476274311542511
test loss item: 0.22355860471725464
test loss item: 0.3672478497028351
test loss item: 0.3333469331264496
test loss item: 0.4859203100204468
test loss item: 1.2921535968780518
test loss item: 0.7690595984458923
test loss item: 0.44757431745529175
test loss item: 0.3443804979324341
test loss item: 0.3319287598133087
test loss item: 0.6176828145980835
test loss item: 0.293352335691452
test loss item: 0.30778956413269043
test loss item: 0.32573428750038147
test loss item: 1.312369704246521
test loss item: 0.4462863504886627
test loss item: 0.4129365086555481
test loss item: 0.3504297137260437
test loss item: 0.8126692771911621
test loss item: 0.5168716311454773
test loss item: 0.22659680247306824
test loss item: 1.0763988494873047
test loss item: 0.46167945861816406
test loss item: 0.4516289532184601
test loss item: 0.24590690433979034
test loss item: 0.29011139273643494
test loss item: 0.26301413774490356
test loss item: 2.5333962440490723
test loss item: 0.6866548657417297
test loss item: 0.2913467288017273
test loss item: 0.19470101594924927
test loss item: 1.432831048965454
test loss item: 1.054911732673645
test loss item: 1.731927752494812
test loss item: 0.35571733117103577
test loss item: 0.35594442486763
test loss item: 0.23550190031528473
test loss item: 0.2568439245223999
test loss item: 0.3223680555820465
Epoch [9/100], Training Loss: 0.7117, Testing Loss: 0.5859
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6795389652252197
1
train loss item: 1.744483470916748
2
train loss item: 0.37328165769577026
3
train loss item: 0.8602427244186401
4
train loss item: 0.8871167898178101
5
train loss item: 0.5109033584594727
6
train loss item: 0.4243994951248169
7
train loss item: 1.1241470575332642
8
train loss item: 0.3196456730365753
9
train loss item: 0.4044058918952942
10
train loss item: 0.5318286418914795
11
train loss item: 0.3635312616825104
12
train loss item: 0.26346930861473083
13
train loss item: 0.7537569999694824
14
train loss item: 0.4616577923297882
15
train loss item: 0.9145956039428711
16
train loss item: 0.2542535662651062
17
train loss item: 0.4480488896369934
18
train loss item: 0.5093443989753723
19
train loss item: 0.3699185848236084
20
train loss item: 0.3669266700744629
21
train loss item: 0.3153225779533386
22
train loss item: 1.3574793338775635
23
train loss item: 1.2450597286224365
24
train loss item: 0.7236095666885376
25
train loss item: 0.3813157379627228
26
train loss item: 0.3321364223957062
27
train loss item: 0.479158878326416
28
train loss item: 0.2528093755245209
29
train loss item: 1.0912914276123047
30
train loss item: 2.7921836376190186
31
train loss item: 0.7782497406005859
32
train loss item: 0.3024356961250305
33
train loss item: 0.6017465591430664
34
train loss item: 0.3748728930950165
35
train loss item: 2.8163812160491943
36
train loss item: 0.6974773406982422
37
train loss item: 0.37137776613235474
38
train loss item: 0.6805316209793091
39
train loss item: 0.48706570267677307
40
train loss item: 0.27569058537483215
41
train loss item: 0.466972678899765
42
train loss item: 0.3421710133552551
43
train loss item: 0.339211106300354
44
train loss item: 0.9804760217666626
45
train loss item: 0.2962047755718231
46
train loss item: 0.3247894048690796
47
train loss item: 0.48477211594581604
48
train loss item: 0.3913288116455078
49
train loss item: 0.33254969120025635
50
train loss item: 0.3848918378353119
51
train loss item: 1.2495883703231812
52
train loss item: 0.27218902111053467
53
train loss item: 0.32744714617729187
54
train loss item: 2.686124086380005
55
train loss item: 0.3425471782684326
56
train loss item: 0.46200260519981384
57
train loss item: 0.394513875246048
58
train loss item: 0.33213692903518677
59
train loss item: 0.30127131938934326
60
train loss item: 1.306086540222168
61
train loss item: 2.639293909072876
62
train loss item: 0.35486677289009094
63
train loss item: 0.4652610719203949
64
train loss item: 0.3177613914012909
65
train loss item: 0.7644497752189636
66
train loss item: 0.545534610748291
67
train loss item: 0.36282768845558167
68
train loss item: 0.42713284492492676
69
train loss item: 0.4614326059818268
70
train loss item: 0.3852913975715637
71
train loss item: 0.3116934597492218
72
train loss item: 0.35746365785598755
73
train loss item: 0.4173537492752075
74
train loss item: 0.3020104467868805
75
train loss item: 0.2709280252456665
76
train loss item: 1.214234471321106
77
train loss item: 1.6116671562194824
78
train loss item: 0.2605406939983368
79
train loss item: 0.37417519092559814
80
train loss item: 0.3236880302429199
81
train loss item: 0.3057347536087036
82
train loss item: 0.396272748708725
83
train loss item: 0.9209794402122498
84
train loss item: 0.4894252419471741
85
train loss item: 0.836685061454773
86
train loss item: 4.825387954711914
87
train loss item: 0.36094486713409424
88
train loss item: 0.4545552730560303
epoch train loss: 0.693219768867064
testing phase
test loss item: 0.2700878381729126
test loss item: 0.24748189747333527
test loss item: 0.8698344826698303
test loss item: 0.3328716456890106
test loss item: 0.4054175913333893
test loss item: 0.22875432670116425
test loss item: 1.9498214721679688
test loss item: 0.5270669460296631
test loss item: 0.33831435441970825
test loss item: 0.5488223433494568
test loss item: 1.2902957201004028
test loss item: 0.2783602774143219
test loss item: 0.26179298758506775
test loss item: 0.48779433965682983
test loss item: 0.293735533952713
test loss item: 0.2580869495868683
test loss item: 0.3486160933971405
test loss item: 0.6875835061073303
test loss item: 0.7441719770431519
test loss item: 0.3368152379989624
test loss item: 1.0830485820770264
test loss item: 0.4638543725013733
test loss item: 0.469673216342926
test loss item: 0.25707516074180603
test loss item: 0.32524147629737854
test loss item: 0.3357155919075012
test loss item: 0.42886725068092346
test loss item: 0.3080400228500366
test loss item: 0.4595695436000824
test loss item: 0.46052253246307373
test loss item: 1.1273330450057983
test loss item: 0.21465589106082916
test loss item: 0.24534954130649567
test loss item: 0.8016854524612427
test loss item: 0.6615177989006042
test loss item: 0.6734914183616638
test loss item: 0.932336688041687
test loss item: 2.2417776584625244
test loss item: 0.7097806930541992
test loss item: 0.3530913293361664
test loss item: 0.3871902823448181
test loss item: 0.3104519546031952
test loss item: 0.5027528405189514
test loss item: 0.31738901138305664
test loss item: 0.8954736590385437
test loss item: 0.5015590190887451
test loss item: 0.4563463032245636
test loss item: 0.3241675794124603
test loss item: 0.6880926489830017
test loss item: 0.9450587630271912
test loss item: 0.46741342544555664
test loss item: 0.21919848024845123
test loss item: 0.359037309885025
test loss item: 0.32251688838005066
test loss item: 0.4723019599914551
test loss item: 1.2716313600540161
test loss item: 0.7497606873512268
test loss item: 0.42401251196861267
test loss item: 0.3379916250705719
test loss item: 0.32571926712989807
test loss item: 0.6129797101020813
test loss item: 0.28669437766075134
test loss item: 0.3020962178707123
test loss item: 0.3201848566532135
test loss item: 1.2794767618179321
test loss item: 0.4332980513572693
test loss item: 0.4036414921283722
test loss item: 0.3454158306121826
test loss item: 0.7989817261695862
test loss item: 0.5090255737304688
test loss item: 0.2233329713344574
test loss item: 1.0426756143569946
test loss item: 0.4461960196495056
test loss item: 0.4424971342086792
test loss item: 0.24369850754737854
test loss item: 0.3095482885837555
test loss item: 0.25741270184516907
test loss item: 2.4705491065979004
test loss item: 0.6673722267150879
test loss item: 0.28961247205734253
test loss item: 0.1948513686656952
test loss item: 1.396102786064148
test loss item: 1.0345771312713623
test loss item: 1.6953939199447632
test loss item: 0.34728777408599854
test loss item: 0.3566955626010895
test loss item: 0.23659154772758484
test loss item: 0.2527189552783966
test loss item: 0.33220693469047546
Epoch [10/100], Training Loss: 0.6932, Testing Loss: 0.5738
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 11/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6631979942321777
1
train loss item: 1.7018104791641235
2
train loss item: 0.35697460174560547
3
train loss item: 0.8252214193344116
4
train loss item: 0.8161624073982239
5
train loss item: 0.5030182600021362
6
train loss item: 0.4093725383281708
7
train loss item: 1.0966014862060547
8
train loss item: 0.3034951388835907
9
train loss item: 0.3936873972415924
10
train loss item: 0.5165653228759766
11
train loss item: 0.3589249551296234
12
train loss item: 0.2567403018474579
13
train loss item: 0.7307088375091553
14
train loss item: 0.4566310942173004
15
train loss item: 0.8939084410667419
16
train loss item: 0.24156343936920166
17
train loss item: 0.4413280785083771
18
train loss item: 0.49214693903923035
19
train loss item: 0.3618157207965851
20
train loss item: 0.35818153619766235
21
train loss item: 0.3079986870288849
22
train loss item: 1.330594539642334
23
train loss item: 1.2212210893630981
24
train loss item: 0.7054097056388855
25
train loss item: 0.36484962701797485
26
train loss item: 0.3301389515399933
27
train loss item: 0.4691675305366516
28
train loss item: 0.24006839096546173
29
train loss item: 1.067579746246338
30
train loss item: 2.741971492767334
31
train loss item: 0.7563732862472534
32
train loss item: 0.28421732783317566
33
train loss item: 0.5779914259910583
34
train loss item: 0.3659835755825043
35
train loss item: 2.7796154022216797
36
train loss item: 0.6753951907157898
37
train loss item: 0.3681240975856781
38
train loss item: 0.6490561962127686
39
train loss item: 0.4768100380897522
40
train loss item: 0.2710636258125305
41
train loss item: 0.45553267002105713
42
train loss item: 0.3329572081565857
43
train loss item: 0.3242727518081665
44
train loss item: 0.95782870054245
45
train loss item: 0.2821938991546631
46
train loss item: 0.30954983830451965
47
train loss item: 0.47096386551856995
48
train loss item: 0.37813469767570496
49
train loss item: 0.32176828384399414
50
train loss item: 0.3770642578601837
51
train loss item: 1.2221529483795166
52
train loss item: 0.26506972312927246
53
train loss item: 0.3200964033603668
54
train loss item: 2.6480557918548584
55
train loss item: 0.3315720558166504
56
train loss item: 0.45055341720581055
57
train loss item: 0.3911077678203583
58
train loss item: 0.3194454610347748
59
train loss item: 0.28895777463912964
60
train loss item: 1.2728883028030396
61
train loss item: 2.5996267795562744
62
train loss item: 0.3473774194717407
63
train loss item: 0.4517892003059387
64
train loss item: 0.3002089262008667
65
train loss item: 0.7478398084640503
66
train loss item: 0.5335491895675659
67
train loss item: 0.3540925085544586
68
train loss item: 0.42074114084243774
69
train loss item: 0.45017939805984497
70
train loss item: 0.37524691224098206
71
train loss item: 0.3023664653301239
72
train loss item: 0.3429127037525177
73
train loss item: 0.41106265783309937
74
train loss item: 0.28564682602882385
75
train loss item: 0.26093295216560364
76
train loss item: 1.1869419813156128
77
train loss item: 1.5904431343078613
78
train loss item: 0.24481713771820068
79
train loss item: 0.36279305815696716
80
train loss item: 0.3102246820926666
81
train loss item: 0.29846620559692383
82
train loss item: 0.38155773282051086
83
train loss item: 0.8951488137245178
84
train loss item: 0.47381576895713806
85
train loss item: 0.812708854675293
86
train loss item: 4.7711710929870605
87
train loss item: 0.3515401780605316
88
train loss item: 0.4413966238498688
epoch train loss: 0.6762522504235922
testing phase
test loss item: 0.2675439119338989
test loss item: 0.24234779179096222
test loss item: 0.8314087390899658
test loss item: 0.325038343667984
test loss item: 0.3884243071079254
test loss item: 0.22878390550613403
test loss item: 1.8930420875549316
test loss item: 0.5163072347640991
test loss item: 0.3335675895214081
test loss item: 0.5345733165740967
test loss item: 1.256516933441162
test loss item: 0.26857390999794006
test loss item: 0.25731393694877625
test loss item: 0.4622136950492859
test loss item: 0.28153109550476074
test loss item: 0.25173643231391907
test loss item: 0.3432721495628357
test loss item: 0.646588921546936
test loss item: 0.7358732223510742
test loss item: 0.32970431447029114
test loss item: 1.003255009651184
test loss item: 0.45152828097343445
test loss item: 0.4418569505214691
test loss item: 0.2518470883369446
test loss item: 0.3176582157611847
test loss item: 0.32887300848960876
test loss item: 0.4237058460712433
test loss item: 0.29884690046310425
test loss item: 0.4468652307987213
test loss item: 0.4546996057033539
test loss item: 1.0907130241394043
test loss item: 0.20536519587039948
test loss item: 0.24093002080917358
test loss item: 0.7635349035263062
test loss item: 0.6277094483375549
test loss item: 0.6539681553840637
test loss item: 0.9125677347183228
test loss item: 2.160924196243286
test loss item: 0.6841686964035034
test loss item: 0.347527414560318
test loss item: 0.3787633776664734
test loss item: 0.3152298331260681
test loss item: 0.47625622153282166
test loss item: 0.3085049092769623
test loss item: 0.8415428996086121
test loss item: 0.4906494617462158
test loss item: 0.44011759757995605
test loss item: 0.311174213886261
test loss item: 0.6602810621261597
test loss item: 0.9234886169433594
test loss item: 0.4453868567943573
test loss item: 0.22026154398918152
test loss item: 0.3440990149974823
test loss item: 0.31162405014038086
test loss item: 0.4407044053077698
test loss item: 1.2240890264511108
test loss item: 0.727219820022583
test loss item: 0.3692416250705719
test loss item: 0.3267335593700409
test loss item: 0.31089237332344055
test loss item: 0.5948035717010498
test loss item: 0.2816462516784668
test loss item: 0.291927695274353
test loss item: 0.3148222267627716
test loss item: 1.2182857990264893
test loss item: 0.4215557873249054
test loss item: 0.3925435543060303
test loss item: 0.3402543067932129
test loss item: 0.768342912197113
test loss item: 0.5105289220809937
test loss item: 0.2195180207490921
test loss item: 1.0139915943145752
test loss item: 0.4105373024940491
test loss item: 0.4336508512496948
test loss item: 0.2427387237548828
test loss item: 0.3152622580528259
test loss item: 0.252360999584198
test loss item: 2.3620941638946533
test loss item: 0.6362141370773315
test loss item: 0.28700414299964905
test loss item: 0.1946851909160614
test loss item: 1.3517022132873535
test loss item: 1.0122723579406738
test loss item: 1.6329379081726074
test loss item: 0.3292056620121002
test loss item: 0.35388901829719543
test loss item: 0.2377036213874817
test loss item: 0.24900424480438232
test loss item: 0.33972832560539246
Epoch [11/100], Training Loss: 0.6763, Testing Loss: 0.5548
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 12/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6475502252578735
1
train loss item: 1.6643472909927368
2
train loss item: 0.341145783662796
3
train loss item: 0.7960045337677002
4
train loss item: 0.7356011867523193
5
train loss item: 0.49670538306236267
6
train loss item: 0.3908667266368866
7
train loss item: 1.071977972984314
8
train loss item: 0.2874355912208557
9
train loss item: 0.3842523992061615
10
train loss item: 0.5043279528617859
11
train loss item: 0.3575977087020874
12
train loss item: 0.2479580044746399
13
train loss item: 0.7079631686210632
14
train loss item: 0.45332038402557373
15
train loss item: 0.8722982406616211
16
train loss item: 0.2300267219543457
17
train loss item: 0.4306948184967041
18
train loss item: 0.47733554244041443
19
train loss item: 0.35421666502952576
20
train loss item: 0.34835222363471985
21
train loss item: 0.29745373129844666
22
train loss item: 1.3002831935882568
23
train loss item: 1.1997685432434082
24
train loss item: 0.6879733800888062
25
train loss item: 0.34909623861312866
26
train loss item: 0.3265361189842224
27
train loss item: 0.46237611770629883
28
train loss item: 0.22856605052947998
29
train loss item: 1.0435571670532227
30
train loss item: 2.6993889808654785
31
train loss item: 0.7383061647415161
32
train loss item: 0.2654716968536377
33
train loss item: 0.558630645275116
34
train loss item: 0.351447194814682
35
train loss item: 2.74809193611145
36
train loss item: 0.6558130979537964
37
train loss item: 0.36370712518692017
38
train loss item: 0.6240496039390564
39
train loss item: 0.4667186737060547
40
train loss item: 0.2678745985031128
41
train loss item: 0.4486187994480133
42
train loss item: 0.3266015350818634
43
train loss item: 0.31143635511398315
44
train loss item: 0.9371849894523621
45
train loss item: 0.2707662582397461
46
train loss item: 0.29657092690467834
47
train loss item: 0.45733579993247986
48
train loss item: 0.36920592188835144
49
train loss item: 0.31174519658088684
50
train loss item: 0.37050166726112366
51
train loss item: 1.1976007223129272
52
train loss item: 0.25400033593177795
53
train loss item: 0.307020902633667
54
train loss item: 2.6145167350769043
55
train loss item: 0.3206194043159485
56
train loss item: 0.44126030802726746
57
train loss item: 0.3907764256000519
58
train loss item: 0.30684056878089905
59
train loss item: 0.277849018573761
60
train loss item: 1.2396769523620605
61
train loss item: 2.564561128616333
62
train loss item: 0.33973997831344604
63
train loss item: 0.43957623839378357
64
train loss item: 0.2866935431957245
65
train loss item: 0.7268242835998535
66
train loss item: 0.5237646698951721
67
train loss item: 0.3438575565814972
68
train loss item: 0.40788790583610535
69
train loss item: 0.43946602940559387
70
train loss item: 0.36441028118133545
71
train loss item: 0.2921265959739685
72
train loss item: 0.3283900320529938
73
train loss item: 0.404035747051239
74
train loss item: 0.26975125074386597
75
train loss item: 0.2509881258010864
76
train loss item: 1.1622804403305054
77
train loss item: 1.5690237283706665
78
train loss item: 0.23152107000350952
79
train loss item: 0.3540835678577423
80
train loss item: 0.29631128907203674
81
train loss item: 0.2946973741054535
82
train loss item: 0.3698830008506775
83
train loss item: 0.8695254325866699
84
train loss item: 0.46082374453544617
85
train loss item: 0.7907029390335083
86
train loss item: 4.725039958953857
87
train loss item: 0.3366512954235077
88
train loss item: 0.42848068475723267
epoch train loss: 0.6601833202195971
testing phase
test loss item: 0.26365599036216736
test loss item: 0.23586395382881165
test loss item: 0.7769011855125427
test loss item: 0.31773751974105835
test loss item: 0.36960723996162415
test loss item: 0.22517256438732147
test loss item: 1.8419601917266846
test loss item: 0.5105370283126831
test loss item: 0.32574108242988586
test loss item: 0.517092764377594
test loss item: 1.2095136642456055
test loss item: 0.2586674988269806
test loss item: 0.25251060724258423
test loss item: 0.4379633963108063
test loss item: 0.27027463912963867
test loss item: 0.242387056350708
test loss item: 0.33842742443084717
test loss item: 0.6023864150047302
test loss item: 0.7303054332733154
test loss item: 0.32340720295906067
test loss item: 0.9375772476196289
test loss item: 0.4394912123680115
test loss item: 0.41433992981910706
test loss item: 0.24806331098079681
test loss item: 0.3086014688014984
test loss item: 0.31904348731040955
test loss item: 0.41724538803100586
test loss item: 0.2885766327381134
test loss item: 0.43361201882362366
test loss item: 0.44699981808662415
test loss item: 1.043864130973816
test loss item: 0.19493447244167328
test loss item: 0.23771655559539795
test loss item: 0.7191809415817261
test loss item: 0.5876324772834778
test loss item: 0.6345290541648865
test loss item: 0.8949161767959595
test loss item: 2.0390539169311523
test loss item: 0.6510564088821411
test loss item: 0.3414543569087982
test loss item: 0.371114581823349
test loss item: 0.3099709153175354
test loss item: 0.45632630586624146
test loss item: 0.29955077171325684
test loss item: 0.7963654398918152
test loss item: 0.4804638922214508
test loss item: 0.4235517978668213
test loss item: 0.302864134311676
test loss item: 0.6270162463188171
test loss item: 0.8963530659675598
test loss item: 0.4254641532897949
test loss item: 0.22115181386470795
test loss item: 0.3272746205329895
test loss item: 0.29903456568717957
test loss item: 0.40910881757736206
test loss item: 1.148725152015686
test loss item: 0.7013792395591736
test loss item: 0.3534855842590332
test loss item: 0.3166216313838959
test loss item: 0.29409393668174744
test loss item: 0.5712656378746033
test loss item: 0.2761317193508148
test loss item: 0.2803453207015991
test loss item: 0.3099106550216675
test loss item: 1.1253063678741455
test loss item: 0.41069889068603516
test loss item: 0.3807733952999115
test loss item: 0.33409735560417175
test loss item: 0.7224432826042175
test loss item: 0.5180730223655701
test loss item: 0.2124173939228058
test loss item: 0.9900220632553101
test loss item: 0.38858774304389954
test loss item: 0.4258515536785126
test loss item: 0.24029305577278137
test loss item: 0.31020790338516235
test loss item: 0.24781188368797302
test loss item: 2.1918928623199463
test loss item: 0.6060509085655212
test loss item: 0.28095731139183044
test loss item: 0.19183771312236786
test loss item: 1.2971268892288208
test loss item: 0.9918821454048157
test loss item: 1.5361149311065674
test loss item: 0.30846288800239563
test loss item: 0.34529992938041687
test loss item: 0.23610439896583557
test loss item: 0.24310161173343658
test loss item: 0.337007999420166
Epoch [12/100], Training Loss: 0.6602, Testing Loss: 0.5328
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 13/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6338028907775879
1
train loss item: 1.6259372234344482
2
train loss item: 0.3281242251396179
3
train loss item: 0.7680957317352295
4
train loss item: 0.6578861474990845
5
train loss item: 0.49183815717697144
6
train loss item: 0.3723949193954468
7
train loss item: 1.0472813844680786
8
train loss item: 0.2719062864780426
9
train loss item: 0.3755885660648346
10
train loss item: 0.4950910806655884
11
train loss item: 0.35444778203964233
12
train loss item: 0.24145276844501495
13
train loss item: 0.6877991557121277
14
train loss item: 0.4498644769191742
15
train loss item: 0.8536155223846436
16
train loss item: 0.22061359882354736
17
train loss item: 0.4157923758029938
18
train loss item: 0.4641728401184082
19
train loss item: 0.3476641774177551
20
train loss item: 0.3402473032474518
21
train loss item: 0.28668928146362305
22
train loss item: 1.2719683647155762
23
train loss item: 1.1784088611602783
24
train loss item: 0.6722758412361145
25
train loss item: 0.33555763959884644
26
train loss item: 0.3201529085636139
27
train loss item: 0.4559018611907959
28
train loss item: 0.21906426548957825
29
train loss item: 1.0194926261901855
30
train loss item: 2.658964157104492
31
train loss item: 0.7192976474761963
32
train loss item: 0.2515575587749481
33
train loss item: 0.5394845604896545
34
train loss item: 0.3326570987701416
35
train loss item: 2.7173590660095215
36
train loss item: 0.6376978158950806
37
train loss item: 0.3579249680042267
38
train loss item: 0.5944572687149048
39
train loss item: 0.4572778642177582
40
train loss item: 0.2634320855140686
41
train loss item: 0.44267094135284424
42
train loss item: 0.32201042771339417
43
train loss item: 0.29955121874809265
44
train loss item: 0.9179873466491699
45
train loss item: 0.260711133480072
46
train loss item: 0.28428682684898376
47
train loss item: 0.4454324543476105
48
train loss item: 0.36167630553245544
49
train loss item: 0.3011736571788788
50
train loss item: 0.36254045367240906
51
train loss item: 1.1733380556106567
52
train loss item: 0.24120059609413147
53
train loss item: 0.29143133759498596
54
train loss item: 2.581801414489746
55
train loss item: 0.30944210290908813
56
train loss item: 0.4330514371395111
57
train loss item: 0.3900700509548187
58
train loss item: 0.2954271137714386
59
train loss item: 0.2673192024230957
60
train loss item: 1.207442283630371
61
train loss item: 2.529639720916748
62
train loss item: 0.334246963262558
63
train loss item: 0.4276502728462219
64
train loss item: 0.2757145166397095
65
train loss item: 0.7043489217758179
66
train loss item: 0.512606680393219
67
train loss item: 0.334286093711853
68
train loss item: 0.39654067158699036
69
train loss item: 0.4298410713672638
70
train loss item: 0.35435935854911804
71
train loss item: 0.28038984537124634
72
train loss item: 0.312884122133255
73
train loss item: 0.39663198590278625
74
train loss item: 0.2555620074272156
75
train loss item: 0.24158631265163422
76
train loss item: 1.13791823387146
77
train loss item: 1.5483540296554565
78
train loss item: 0.2207234799861908
79
train loss item: 0.34471219778060913
80
train loss item: 0.2827768623828888
81
train loss item: 0.290497750043869
82
train loss item: 0.359139084815979
83
train loss item: 0.8453611135482788
84
train loss item: 0.44880250096321106
85
train loss item: 0.7697592973709106
86
train loss item: 4.681759834289551
87
train loss item: 0.3170328438282013
88
train loss item: 0.41780656576156616
epoch train loss: 0.6446374725089984
testing phase
test loss item: 0.25941699743270874
test loss item: 0.22864766418933868
test loss item: 0.7303681969642639
test loss item: 0.3118220865726471
test loss item: 0.3564627766609192
test loss item: 0.21582910418510437
test loss item: 1.796169638633728
test loss item: 0.5077086091041565
test loss item: 0.3169306218624115
test loss item: 0.5035502314567566
test loss item: 1.1556965112686157
test loss item: 0.25157856941223145
test loss item: 0.24946169555187225
test loss item: 0.4244299530982971
test loss item: 0.26232314109802246
test loss item: 0.23251935839653015
test loss item: 0.3332313597202301
test loss item: 0.5830612778663635
test loss item: 0.7255430817604065
test loss item: 0.3175642490386963
test loss item: 0.9115061163902283
test loss item: 0.4305933117866516
test loss item: 0.3926759362220764
test loss item: 0.2438337355852127
test loss item: 0.30261367559432983
test loss item: 0.3103274405002594
test loss item: 0.4097796082496643
test loss item: 0.2777103781700134
test loss item: 0.42685407400131226
test loss item: 0.4391998052597046
test loss item: 0.9924941658973694
test loss item: 0.18717044591903687
test loss item: 0.2326941043138504
test loss item: 0.6963185667991638
test loss item: 0.5638190507888794
test loss item: 0.6229437589645386
test loss item: 0.8825761079788208
test loss item: 1.9065475463867188
test loss item: 0.6316434144973755
test loss item: 0.3338906764984131
test loss item: 0.36425089836120605
test loss item: 0.29694879055023193
test loss item: 0.45057517290115356
test loss item: 0.29280850291252136
test loss item: 0.781818687915802
test loss item: 0.4701901376247406
test loss item: 0.4052991569042206
test loss item: 0.2950991690158844
test loss item: 0.6036646962165833
test loss item: 0.8677106499671936
test loss item: 0.41977837681770325
test loss item: 0.2191281020641327
test loss item: 0.3172876536846161
test loss item: 0.29220402240753174
test loss item: 0.396064430475235
test loss item: 1.081304907798767
test loss item: 0.6772862672805786
test loss item: 0.34857451915740967
test loss item: 0.3086850345134735
test loss item: 0.28617724776268005
test loss item: 0.5586385130882263
test loss item: 0.270084023475647
test loss item: 0.2731349766254425
test loss item: 0.30642449855804443
test loss item: 1.0426753759384155
test loss item: 0.4045141339302063
test loss item: 0.3719247579574585
test loss item: 0.32783418893814087
test loss item: 0.687068521976471
test loss item: 0.5265148282051086
test loss item: 0.20383799076080322
test loss item: 0.9703630805015564
test loss item: 0.38804346323013306
test loss item: 0.4198932945728302
test loss item: 0.234720841050148
test loss item: 0.29789242148399353
test loss item: 0.24306464195251465
test loss item: 2.0094027519226074
test loss item: 0.5895897746086121
test loss item: 0.27290770411491394
test loss item: 0.18624450266361237
test loss item: 1.2380913496017456
test loss item: 0.9793301224708557
test loss item: 1.4244933128356934
test loss item: 0.2960035800933838
test loss item: 0.33542031049728394
test loss item: 0.23113027215003967
test loss item: 0.23513734340667725
test loss item: 0.3239268958568573
Epoch [13/100], Training Loss: 0.6446, Testing Loss: 0.5144
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 14/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6221196055412292
1
train loss item: 1.5868570804595947
2
train loss item: 0.3195520341396332
3
train loss item: 0.7393050193786621
4
train loss item: 0.5972626805305481
5
train loss item: 0.484883576631546
6
train loss item: 0.35773247480392456
7
train loss item: 1.0234928131103516
8
train loss item: 0.26065322756767273
9
train loss item: 0.36742740869522095
10
train loss item: 0.48742803931236267
11
train loss item: 0.3457397222518921
12
train loss item: 0.239091694355011
13
train loss item: 0.6707234382629395
14
train loss item: 0.44217395782470703
15
train loss item: 0.8403032422065735
16
train loss item: 0.2128932774066925
17
train loss item: 0.39847332239151
18
train loss item: 0.45169106125831604
19
train loss item: 0.3410431444644928
20
train loss item: 0.3359762132167816
21
train loss item: 0.2760087251663208
22
train loss item: 1.2486958503723145
23
train loss item: 1.1563246250152588
24
train loss item: 0.6582047939300537
25
train loss item: 0.3257795572280884
26
train loss item: 0.31379106640815735
27
train loss item: 0.44758331775665283
28
train loss item: 0.21123120188713074
29
train loss item: 0.9983702301979065
30
train loss item: 2.6152946949005127
31
train loss item: 0.7001566886901855
32
train loss item: 0.24343186616897583
33
train loss item: 0.520746111869812
34
train loss item: 0.31314483284950256
35
train loss item: 2.6849794387817383
36
train loss item: 0.622279703617096
37
train loss item: 0.3510647118091583
38
train loss item: 0.5659579634666443
39
train loss item: 0.4485112726688385
40
train loss item: 0.25601136684417725
41
train loss item: 0.43377918004989624
42
train loss item: 0.3154783248901367
43
train loss item: 0.28714266419410706
44
train loss item: 0.8994826078414917
45
train loss item: 0.2517058849334717
46
train loss item: 0.2697298526763916
47
train loss item: 0.4356296956539154
48
train loss item: 0.3507980406284332
49
train loss item: 0.2883504629135132
50
train loss item: 0.353397011756897
51
train loss item: 1.1466799974441528
52
train loss item: 0.23037102818489075
53
train loss item: 0.279602587223053
54
train loss item: 2.5489702224731445
55
train loss item: 0.2990930676460266
56
train loss item: 0.4237418472766876
57
train loss item: 0.38349565863609314
58
train loss item: 0.2854330241680145
59
train loss item: 0.258374959230423
60
train loss item: 1.1781545877456665
61
train loss item: 2.4943900108337402
62
train loss item: 0.3292370140552521
63
train loss item: 0.4151032865047455
64
train loss item: 0.2655649781227112
65
train loss item: 0.6847425699234009
66
train loss item: 0.49803626537323
67
train loss item: 0.32610049843788147
68
train loss item: 0.3939248025417328
69
train loss item: 0.4208059310913086
70
train loss item: 0.3459244966506958
71
train loss item: 0.2670533359050751
72
train loss item: 0.2993297874927521
73
train loss item: 0.3894799053668976
74
train loss item: 0.24466438591480255
75
train loss item: 0.23342908918857574
76
train loss item: 1.1140698194503784
77
train loss item: 1.5295339822769165
78
train loss item: 0.21224676072597504
79
train loss item: 0.333168089389801
80
train loss item: 0.26891839504241943
81
train loss item: 0.2810061275959015
82
train loss item: 0.3459376096725464
83
train loss item: 0.8237900733947754
84
train loss item: 0.43728208541870117
85
train loss item: 0.7504479885101318
86
train loss item: 4.638499736785889
87
train loss item: 0.29981714487075806
88
train loss item: 0.4104558527469635
epoch train loss: 0.6298287840706579
testing phase
test loss item: 0.25661027431488037
test loss item: 0.23109333217144012
test loss item: 0.7266284823417664
test loss item: 0.3095390498638153
test loss item: 0.3677673935890198
test loss item: 0.21675662696361542
test loss item: 1.7576994895935059
test loss item: 0.5075637102127075
test loss item: 0.3157379627227783
test loss item: 0.509379506111145
test loss item: 1.1379156112670898
test loss item: 0.25300177931785583
test loss item: 0.24995142221450806
test loss item: 0.41453972458839417
test loss item: 0.2659813165664673
test loss item: 0.23190335929393768
test loss item: 0.32874947786331177
test loss item: 0.6201907992362976
test loss item: 0.7258239388465881
test loss item: 0.31209897994995117
test loss item: 0.9719940423965454
test loss item: 0.428453266620636
test loss item: 0.4053385555744171
test loss item: 0.23646984994411469
test loss item: 0.3014552593231201
test loss item: 0.3071920871734619
test loss item: 0.4046802818775177
test loss item: 0.2862027883529663
test loss item: 0.44048115611076355
test loss item: 0.4390302896499634
test loss item: 0.9727048873901367
test loss item: 0.1900513619184494
test loss item: 0.2245945781469345
test loss item: 0.7185003161430359
test loss item: 0.5848823189735413
test loss item: 0.6570462584495544
test loss item: 0.8809003233909607
test loss item: 1.8639698028564453
test loss item: 0.6491687297821045
test loss item: 0.3285682797431946
test loss item: 0.3587214946746826
test loss item: 0.29551059007644653
test loss item: 0.47592058777809143
test loss item: 0.2922990918159485
test loss item: 0.8251920938491821
test loss item: 0.4626602232456207
test loss item: 0.4153083264827728
test loss item: 0.2915055453777313
test loss item: 0.6082051992416382
test loss item: 0.8676780462265015
test loss item: 0.4431450664997101
test loss item: 0.2159232199192047
test loss item: 0.323722243309021
test loss item: 0.29942503571510315
test loss item: 0.4151240289211273
test loss item: 1.0795115232467651
test loss item: 0.6781544089317322
test loss item: 0.3719973564147949
test loss item: 0.30932897329330444
test loss item: 0.29679083824157715
test loss item: 0.5769935250282288
test loss item: 0.2660062313079834
test loss item: 0.2695562541484833
test loss item: 0.30462411046028137
test loss item: 1.0237356424331665
test loss item: 0.40510037541389465
test loss item: 0.3680199086666107
test loss item: 0.3246355354785919
test loss item: 0.6825941205024719
test loss item: 0.5406521558761597
test loss item: 0.20162811875343323
test loss item: 0.9527813196182251
test loss item: 0.40005555748939514
test loss item: 0.4134611487388611
test loss item: 0.23199164867401123
test loss item: 0.29812121391296387
test loss item: 0.2374822050333023
test loss item: 1.9410364627838135
test loss item: 0.5796679258346558
test loss item: 0.2739883065223694
test loss item: 0.18121692538261414
test loss item: 1.2121914625167847
test loss item: 0.9877552390098572
test loss item: 1.3927322626113892
test loss item: 0.29905858635902405
test loss item: 0.3425673246383667
test loss item: 0.22696764767169952
test loss item: 0.2300042361021042
test loss item: 0.32681772112846375
Epoch [14/100], Training Loss: 0.6298, Testing Loss: 0.5151
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 15/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.613322913646698
1
train loss item: 1.5520001649856567
2
train loss item: 0.3126515746116638
3
train loss item: 0.7156356573104858
4
train loss item: 0.5510707497596741
5
train loss item: 0.4764559864997864
6
train loss item: 0.34620603919029236
7
train loss item: 1.0039076805114746
8
train loss item: 0.24936309456825256
9
train loss item: 0.3587585985660553
10
train loss item: 0.4773408770561218
11
train loss item: 0.33591586351394653
12
train loss item: 0.22918759286403656
13
train loss item: 0.6572815179824829
14
train loss item: 0.4328542649745941
15
train loss item: 0.8256986737251282
16
train loss item: 0.2055807262659073
17
train loss item: 0.38360825181007385
18
train loss item: 0.44211557507514954
19
train loss item: 0.33329400420188904
20
train loss item: 0.32899078726768494
21
train loss item: 0.2600482702255249
22
train loss item: 1.2184052467346191
23
train loss item: 1.1402626037597656
24
train loss item: 0.641960084438324
25
train loss item: 0.3175637423992157
26
train loss item: 0.3062635660171509
27
train loss item: 0.4374605119228363
28
train loss item: 0.20395877957344055
29
train loss item: 0.9789257645606995
30
train loss item: 2.5765373706817627
31
train loss item: 0.6870110630989075
32
train loss item: 0.2351003885269165
33
train loss item: 0.5084887742996216
34
train loss item: 0.297760546207428
35
train loss item: 2.6556859016418457
36
train loss item: 0.6094329953193665
37
train loss item: 0.3448520004749298
38
train loss item: 0.5489080548286438
39
train loss item: 0.44045814871788025
40
train loss item: 0.24946165084838867
41
train loss item: 0.4250084459781647
42
train loss item: 0.30887001752853394
43
train loss item: 0.27746525406837463
44
train loss item: 0.8830921649932861
45
train loss item: 0.24810223281383514
46
train loss item: 0.2566809356212616
47
train loss item: 0.4264741539955139
48
train loss item: 0.3406502306461334
49
train loss item: 0.2737196981906891
50
train loss item: 0.344745934009552
51
train loss item: 1.123055338859558
52
train loss item: 0.21682773530483246
53
train loss item: 0.26783040165901184
54
train loss item: 2.5191566944122314
55
train loss item: 0.29108041524887085
56
train loss item: 0.4130748510360718
57
train loss item: 0.3736274540424347
58
train loss item: 0.2751363217830658
59
train loss item: 0.24906255304813385
60
train loss item: 1.1533821821212769
61
train loss item: 2.462660551071167
62
train loss item: 0.32034415006637573
63
train loss item: 0.4039531946182251
64
train loss item: 0.25867515802383423
65
train loss item: 0.6630434393882751
66
train loss item: 0.4852280914783478
67
train loss item: 0.31626176834106445
68
train loss item: 0.38275575637817383
69
train loss item: 0.41036152839660645
70
train loss item: 0.3370025157928467
71
train loss item: 0.25485774874687195
72
train loss item: 0.2876698672771454
73
train loss item: 0.3809686303138733
74
train loss item: 0.23472265899181366
75
train loss item: 0.22338098287582397
76
train loss item: 1.0955716371536255
77
train loss item: 1.5112533569335938
78
train loss item: 0.20503926277160645
79
train loss item: 0.3249486982822418
80
train loss item: 0.2545645236968994
81
train loss item: 0.2715134918689728
82
train loss item: 0.33438101410865784
83
train loss item: 0.8036903142929077
84
train loss item: 0.42603763937950134
85
train loss item: 0.7367032766342163
86
train loss item: 4.598629951477051
87
train loss item: 0.28456926345825195
88
train loss item: 0.4027804732322693
epoch train loss: 0.6160494159446673
testing phase
test loss item: 0.2502259314060211
test loss item: 0.22705647349357605
test loss item: 0.7205818295478821
test loss item: 0.3114096224308014
test loss item: 0.3640557825565338
test loss item: 0.2106332927942276
test loss item: 1.7173850536346436
test loss item: 0.5043216943740845
test loss item: 0.3130738139152527
test loss item: 0.5079002380371094
test loss item: 1.1190727949142456
test loss item: 0.25862112641334534
test loss item: 0.24924074113368988
test loss item: 0.3896634578704834
test loss item: 0.26216691732406616
test loss item: 0.22869464755058289
test loss item: 0.324006050825119
test loss item: 0.6286638379096985
test loss item: 0.7262582182884216
test loss item: 0.30561184883117676
test loss item: 0.986400842666626
test loss item: 0.4279489815235138
test loss item: 0.387206107378006
test loss item: 0.23347730934619904
test loss item: 0.30120646953582764
test loss item: 0.30606213212013245
test loss item: 0.39818865060806274
test loss item: 0.28199759125709534
test loss item: 0.437431663274765
test loss item: 0.4350048899650574
test loss item: 0.9528777003288269
test loss item: 0.1913510411977768
test loss item: 0.22036220133304596
test loss item: 0.7324833273887634
test loss item: 0.5935488343238831
test loss item: 0.6956681609153748
test loss item: 0.8730022311210632
test loss item: 1.828191876411438
test loss item: 0.6533556580543518
test loss item: 0.3226899206638336
test loss item: 0.3529708683490753
test loss item: 0.28323644399642944
test loss item: 0.47394877672195435
test loss item: 0.2945300340652466
test loss item: 0.8189955353736877
test loss item: 0.4534316956996918
test loss item: 0.3966931998729706
test loss item: 0.28572067618370056
test loss item: 0.6074174642562866
test loss item: 0.8611058592796326
test loss item: 0.4384509325027466
test loss item: 0.21231088042259216
test loss item: 0.3107808530330658
test loss item: 0.3141270577907562
test loss item: 0.4024869501590729
test loss item: 1.0836061239242554
test loss item: 0.6831770539283752
test loss item: 0.3414144515991211
test loss item: 0.3046364486217499
test loss item: 0.28706589341163635
test loss item: 0.5808762311935425
test loss item: 0.26179999113082886
test loss item: 0.2596147656440735
test loss item: 0.30352967977523804
test loss item: 1.0176517963409424
test loss item: 0.413057804107666
test loss item: 0.36228203773498535
test loss item: 0.3206874430179596
test loss item: 0.6776601672172546
test loss item: 0.546950101852417
test loss item: 0.19828017055988312
test loss item: 0.9346185326576233
test loss item: 0.3797034025192261
test loss item: 0.40744346380233765
test loss item: 0.22818368673324585
test loss item: 0.27741074562072754
test loss item: 0.23500609397888184
test loss item: 1.8882420063018799
test loss item: 0.5532264709472656
test loss item: 0.2673649489879608
test loss item: 0.17821267247200012
test loss item: 1.1879260540008545
test loss item: 0.9795405864715576
test loss item: 1.3703912496566772
test loss item: 0.28253373503685
test loss item: 0.34653013944625854
test loss item: 0.22331735491752625
test loss item: 0.22471249103546143
test loss item: 0.36255407333374023
Epoch [15/100], Training Loss: 0.6160, Testing Loss: 0.5096
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 16/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6057767868041992
1
train loss item: 1.52007257938385
2
train loss item: 0.3047258257865906
3
train loss item: 0.6957603096961975
4
train loss item: 0.5167114734649658
5
train loss item: 0.47012749314308167
6
train loss item: 0.3359247148036957
7
train loss item: 0.9854997992515564
8
train loss item: 0.23978868126869202
9
train loss item: 0.34802645444869995
10
train loss item: 0.4631861746311188
11
train loss item: 0.32929378747940063
12
train loss item: 0.21875740587711334
13
train loss item: 0.6441524028778076
14
train loss item: 0.42576950788497925
15
train loss item: 0.806943416595459
16
train loss item: 0.1989343762397766
17
train loss item: 0.37118908762931824
18
train loss item: 0.4333529472351074
19
train loss item: 0.3252022862434387
20
train loss item: 0.3197583854198456
21
train loss item: 0.24554269015789032
22
train loss item: 1.185865879058838
23
train loss item: 1.1237467527389526
24
train loss item: 0.6267603635787964
25
train loss item: 0.30877992510795593
26
train loss item: 0.29965701699256897
27
train loss item: 0.42890021204948425
28
train loss item: 0.1977696567773819
29
train loss item: 0.9584543704986572
30
train loss item: 2.5401833057403564
31
train loss item: 0.6745011210441589
32
train loss item: 0.22717788815498352
33
train loss item: 0.49970269203186035
34
train loss item: 0.2865610420703888
35
train loss item: 2.627825975418091
36
train loss item: 0.5929980278015137
37
train loss item: 0.3379395604133606
38
train loss item: 0.5385106801986694
39
train loss item: 0.433109849691391
40
train loss item: 0.24490852653980255
41
train loss item: 0.4179847538471222
42
train loss item: 0.3050280213356018
43
train loss item: 0.2704290747642517
44
train loss item: 0.8684536814689636
45
train loss item: 0.24236677587032318
46
train loss item: 0.24687808752059937
47
train loss item: 0.4192661643028259
48
train loss item: 0.33279547095298767
49
train loss item: 0.26117369532585144
50
train loss item: 0.3366793692111969
51
train loss item: 1.1026666164398193
52
train loss item: 0.20795512199401855
53
train loss item: 0.25326770544052124
54
train loss item: 2.4907140731811523
55
train loss item: 0.2858861982822418
56
train loss item: 0.40357398986816406
57
train loss item: 0.3666211664676666
58
train loss item: 0.2642933130264282
59
train loss item: 0.241631418466568
60
train loss item: 1.128230333328247
61
train loss item: 2.4326071739196777
62
train loss item: 0.304815411567688
63
train loss item: 0.39452439546585083
64
train loss item: 0.2543698251247406
65
train loss item: 0.6428737044334412
66
train loss item: 0.47532686591148376
67
train loss item: 0.3051132559776306
68
train loss item: 0.36487340927124023
69
train loss item: 0.40098413825035095
70
train loss item: 0.32944414019584656
71
train loss item: 0.2451266050338745
72
train loss item: 0.279386043548584
73
train loss item: 0.37270256876945496
74
train loss item: 0.2256900519132614
75
train loss item: 0.21585264801979065
76
train loss item: 1.0780986547470093
77
train loss item: 1.4924402236938477
78
train loss item: 0.19897866249084473
79
train loss item: 0.32064148783683777
80
train loss item: 0.24323152005672455
81
train loss item: 0.2665307819843292
82
train loss item: 0.32337191700935364
83
train loss item: 0.7836106419563293
84
train loss item: 0.4141668379306793
85
train loss item: 0.7253148555755615
86
train loss item: 4.560326099395752
87
train loss item: 0.2699679434299469
88
train loss item: 0.39517053961753845
epoch train loss: 0.6033627513084519
testing phase
test loss item: 0.24603688716888428
test loss item: 0.2131241410970688
test loss item: 0.6766113042831421
test loss item: 0.29882124066352844
test loss item: 0.3408430814743042
test loss item: 0.20133242011070251
test loss item: 1.671760082244873
test loss item: 0.4944297969341278
test loss item: 0.30014827847480774
test loss item: 0.4912075996398926
test loss item: 1.038153052330017
test loss item: 0.2453131079673767
test loss item: 0.24490123987197876
test loss item: 0.3799389898777008
test loss item: 0.2483447790145874
test loss item: 0.21157051622867584
test loss item: 0.31798073649406433
test loss item: 0.5781363248825073
test loss item: 0.7193487286567688
test loss item: 0.2987414598464966
test loss item: 0.9051637649536133
test loss item: 0.414266973733902
test loss item: 0.347898006439209
test loss item: 0.2276563197374344
test loss item: 0.2925027310848236
test loss item: 0.3140847086906433
test loss item: 0.3892688751220703
test loss item: 0.26313096284866333
test loss item: 0.41803842782974243
test loss item: 0.42295902967453003
test loss item: 0.8860155344009399
test loss item: 0.1781628429889679
test loss item: 0.21396948397159576
test loss item: 0.6820911169052124
test loss item: 0.5477225184440613
test loss item: 0.630792498588562
test loss item: 0.8523253798484802
test loss item: 1.6727145910263062
test loss item: 0.6129906177520752
test loss item: 0.31628984212875366
test loss item: 0.34570443630218506
test loss item: 0.27630630135536194
test loss item: 0.4455011487007141
test loss item: 0.28027084469795227
test loss item: 0.7687312960624695
test loss item: 0.44444504380226135
test loss item: 0.35827839374542236
test loss item: 0.2787892520427704
test loss item: 0.580182671546936
test loss item: 0.8102620840072632
test loss item: 0.4185437560081482
test loss item: 0.20737139880657196
test loss item: 0.29779425263404846
test loss item: 0.28852492570877075
test loss item: 0.38331520557403564
test loss item: 0.997965395450592
test loss item: 0.6370840668678284
test loss item: 0.3275463581085205
test loss item: 0.2942623198032379
test loss item: 0.2765216827392578
test loss item: 0.5586170554161072
test loss item: 0.2549436688423157
test loss item: 0.258577823638916
test loss item: 0.3020617961883545
test loss item: 0.93590247631073
test loss item: 0.39372187852859497
test loss item: 0.3558392822742462
test loss item: 0.3150680363178253
test loss item: 0.6454435586929321
test loss item: 0.5216370820999146
test loss item: 0.18808101117610931
test loss item: 0.9192679524421692
test loss item: 0.3601630628108978
test loss item: 0.40306365489959717
test loss item: 0.22124633193016052
test loss item: 0.24826760590076447
test loss item: 0.23003734648227692
test loss item: 1.7132771015167236
test loss item: 0.5349519848823547
test loss item: 0.2601895034313202
test loss item: 0.17773835361003876
test loss item: 1.1146800518035889
test loss item: 0.942802369594574
test loss item: 1.2258630990982056
test loss item: 0.2733199894428253
test loss item: 0.3514651358127594
test loss item: 0.21640349924564362
test loss item: 0.21019025146961212
test loss item: 0.43354418873786926
Epoch [16/100], Training Loss: 0.6034, Testing Loss: 0.4841
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 17/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6015756726264954
1
train loss item: 1.4902695417404175
2
train loss item: 0.2979612648487091
3
train loss item: 0.6742128133773804
4
train loss item: 0.49558377265930176
5
train loss item: 0.4621185064315796
6
train loss item: 0.3285011649131775
7
train loss item: 0.96314936876297
8
train loss item: 0.2353680282831192
9
train loss item: 0.33642423152923584
10
train loss item: 0.44692251086235046
11
train loss item: 0.32383468747138977
12
train loss item: 0.21442735195159912
13
train loss item: 0.6293180584907532
14
train loss item: 0.4194466769695282
15
train loss item: 0.7990667223930359
16
train loss item: 0.19102789461612701
17
train loss item: 0.356916218996048
18
train loss item: 0.4245208501815796
19
train loss item: 0.3181978464126587
20
train loss item: 0.3151373863220215
21
train loss item: 0.23745115101337433
22
train loss item: 1.1655491590499878
23
train loss item: 1.0945302248001099
24
train loss item: 0.6146956086158752
25
train loss item: 0.29529622197151184
26
train loss item: 0.29401662945747375
27
train loss item: 0.4203644394874573
28
train loss item: 0.1898554414510727
29
train loss item: 0.9441338777542114
30
train loss item: 2.497232437133789
31
train loss item: 0.6604248881340027
32
train loss item: 0.2197624295949936
33
train loss item: 0.48596540093421936
34
train loss item: 0.2737511992454529
35
train loss item: 2.595776081085205
36
train loss item: 0.5825281143188477
37
train loss item: 0.33133819699287415
38
train loss item: 0.5218076705932617
39
train loss item: 0.42648419737815857
40
train loss item: 0.24039123952388763
41
train loss item: 0.4076651632785797
42
train loss item: 0.30214428901672363
43
train loss item: 0.2607850730419159
44
train loss item: 0.8529361486434937
45
train loss item: 0.22961202263832092
46
train loss item: 0.23282448947429657
47
train loss item: 0.41198617219924927
48
train loss item: 0.3209975063800812
49
train loss item: 0.2514886260032654
50
train loss item: 0.32994934916496277
51
train loss item: 1.0782150030136108
52
train loss item: 0.2039613425731659
53
train loss item: 0.24380742013454437
54
train loss item: 2.4585678577423096
55
train loss item: 0.2789035737514496
56
train loss item: 0.3966563642024994
57
train loss item: 0.35903263092041016
58
train loss item: 0.25446566939353943
59
train loss item: 0.23529158532619476
60
train loss item: 1.1038687229156494
61
train loss item: 2.3976850509643555
62
train loss item: 0.29661688208580017
63
train loss item: 0.38265904784202576
64
train loss item: 0.245491623878479
65
train loss item: 0.6341077089309692
66
train loss item: 0.4648941457271576
67
train loss item: 0.29438382387161255
68
train loss item: 0.36271655559539795
69
train loss item: 0.39437082409858704
70
train loss item: 0.3221856653690338
71
train loss item: 0.2380157709121704
72
train loss item: 0.27229511737823486
73
train loss item: 0.36658915877342224
74
train loss item: 0.21854721009731293
75
train loss item: 0.20686033368110657
76
train loss item: 1.055121898651123
77
train loss item: 1.474784255027771
78
train loss item: 0.19217845797538757
79
train loss item: 0.31064388155937195
80
train loss item: 0.23257534205913544
81
train loss item: 0.2589621841907501
82
train loss item: 0.31307339668273926
83
train loss item: 0.7647987604141235
84
train loss item: 0.4060213267803192
85
train loss item: 0.7090476751327515
86
train loss item: 4.516999244689941
87
train loss item: 0.2614957392215729
88
train loss item: 0.3922458291053772
epoch train loss: 0.5911669786391633
testing phase
test loss item: 0.24301142990589142
test loss item: 0.21815606951713562
test loss item: 0.6974092721939087
test loss item: 0.3115748167037964
test loss item: 0.3502844274044037
test loss item: 0.20158697664737701
test loss item: 1.6417222023010254
test loss item: 0.4910283386707306
test loss item: 0.30532026290893555
test loss item: 0.5054236054420471
test loss item: 1.0577328205108643
test loss item: 0.2655045986175537
test loss item: 0.25423485040664673
test loss item: 0.37460047006607056
test loss item: 0.25341129302978516
test loss item: 0.21516954898834229
test loss item: 0.3148963451385498
test loss item: 0.602117657661438
test loss item: 0.7089093923568726
test loss item: 0.2977100908756256
test loss item: 0.9299212098121643
test loss item: 0.42490726709365845
test loss item: 0.3625929653644562
test loss item: 0.2219403088092804
test loss item: 0.29678231477737427
test loss item: 0.2978668510913849
test loss item: 0.3922543227672577
test loss item: 0.2658984363079071
test loss item: 0.4242272675037384
test loss item: 0.43160176277160645
test loss item: 0.9040058255195618
test loss item: 0.1857561618089676
test loss item: 0.20932617783546448
test loss item: 0.7123333811759949
test loss item: 0.5698484778404236
test loss item: 0.7327540516853333
test loss item: 0.8502950668334961
test loss item: 1.7211164236068726
test loss item: 0.6301508545875549
test loss item: 0.3111205995082855
test loss item: 0.34096240997314453
test loss item: 0.2689589560031891
test loss item: 0.4591892957687378
test loss item: 0.2955029308795929
test loss item: 0.7802335619926453
test loss item: 0.4406859576702118
test loss item: 0.36954525113105774
test loss item: 0.27845993638038635
test loss item: 0.597113847732544
test loss item: 0.821951150894165
test loss item: 0.4317977726459503
test loss item: 0.2120063304901123
test loss item: 0.3029303550720215
test loss item: 0.33148831129074097
test loss item: 0.39499056339263916
test loss item: 1.0416597127914429
test loss item: 0.6658836603164673
test loss item: 0.3301023840904236
test loss item: 0.2955399453639984
test loss item: 0.2894795536994934
test loss item: 0.5783355832099915
test loss item: 0.25458601117134094
test loss item: 0.25349947810173035
test loss item: 0.3078972101211548
test loss item: 0.9799041748046875
test loss item: 0.4227988123893738
test loss item: 0.3528579771518707
test loss item: 0.3136543333530426
test loss item: 0.666029155254364
test loss item: 0.5238271951675415
test loss item: 0.19073697924613953
test loss item: 0.9022262096405029
test loss item: 0.3653569221496582
test loss item: 0.3949506878852844
test loss item: 0.2185739427804947
test loss item: 0.2568238079547882
test loss item: 0.22498849034309387
test loss item: 1.7835330963134766
test loss item: 0.5287282466888428
test loss item: 0.26127809286117554
test loss item: 0.17407211661338806
test loss item: 1.127090573310852
test loss item: 0.943136990070343
test loss item: 1.2980140447616577
test loss item: 0.2750413417816162
test loss item: 0.3400537371635437
test loss item: 0.21393577754497528
test loss item: 0.21016009151935577
test loss item: 0.39430898427963257
Epoch [17/100], Training Loss: 0.5912, Testing Loss: 0.4931
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 18/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5948932766914368
1
train loss item: 1.4550381898880005
2
train loss item: 0.29257988929748535
3
train loss item: 0.6580978035926819
4
train loss item: 0.4805773198604584
5
train loss item: 0.45636385679244995
6
train loss item: 0.3190980553627014
7
train loss item: 0.945465087890625
8
train loss item: 0.2262096405029297
9
train loss item: 0.32834920287132263
10
train loss item: 0.43777862191200256
11
train loss item: 0.32383617758750916
12
train loss item: 0.2073843777179718
13
train loss item: 0.6195913553237915
14
train loss item: 0.41441231966018677
15
train loss item: 0.777105987071991
16
train loss item: 0.18447335064411163
17
train loss item: 0.34907087683677673
18
train loss item: 0.4182552397251129
19
train loss item: 0.31017425656318665
20
train loss item: 0.30484575033187866
21
train loss item: 0.22619956731796265
22
train loss item: 1.1374303102493286
23
train loss item: 1.0782898664474487
24
train loss item: 0.5986884832382202
25
train loss item: 0.2907402217388153
26
train loss item: 0.28866201639175415
27
train loss item: 0.41254928708076477
28
train loss item: 0.18359121680259705
29
train loss item: 0.9195518493652344
30
train loss item: 2.4615256786346436
31
train loss item: 0.648005485534668
32
train loss item: 0.2116176337003708
33
train loss item: 0.47798267006874084
34
train loss item: 0.26381751894950867
35
train loss item: 2.5676395893096924
36
train loss item: 0.5723183751106262
37
train loss item: 0.32583165168762207
38
train loss item: 0.5128411054611206
39
train loss item: 0.4195742607116699
40
train loss item: 0.23247292637825012
41
train loss item: 0.4008966386318207
42
train loss item: 0.29339301586151123
43
train loss item: 0.25462067127227783
44
train loss item: 0.8399662375450134
45
train loss item: 0.22279946506023407
46
train loss item: 0.22515065968036652
47
train loss item: 0.4028106927871704
48
train loss item: 0.3130947947502136
49
train loss item: 0.24451349675655365
50
train loss item: 0.3218427896499634
51
train loss item: 1.053929328918457
52
train loss item: 0.19587348401546478
53
train loss item: 0.23261675238609314
54
train loss item: 2.4301917552948
55
train loss item: 0.2738458514213562
56
train loss item: 0.38987720012664795
57
train loss item: 0.35317474603652954
58
train loss item: 0.24569527804851532
59
train loss item: 0.22772684693336487
60
train loss item: 1.0782043933868408
61
train loss item: 2.3690168857574463
62
train loss item: 0.28819993138313293
63
train loss item: 0.37220191955566406
64
train loss item: 0.24030357599258423
65
train loss item: 0.6163987517356873
66
train loss item: 0.4591594636440277
67
train loss item: 0.28313130140304565
68
train loss item: 0.3493100702762604
69
train loss item: 0.38686591386795044
70
train loss item: 0.31180092692375183
71
train loss item: 0.2315354198217392
72
train loss item: 0.2635060250759125
73
train loss item: 0.3591284453868866
74
train loss item: 0.21062372624874115
75
train loss item: 0.20072676241397858
76
train loss item: 1.0379160642623901
77
train loss item: 1.4512734413146973
78
train loss item: 0.18537436425685883
79
train loss item: 0.3046256899833679
80
train loss item: 0.22355493903160095
81
train loss item: 0.2550220191478729
82
train loss item: 0.30513685941696167
83
train loss item: 0.7430385947227478
84
train loss item: 0.3986201584339142
85
train loss item: 0.6946268081665039
86
train loss item: 4.477944850921631
87
train loss item: 0.25102123618125916
88
train loss item: 0.38792315125465393
epoch train loss: 0.5796757499488552
testing phase
test loss item: 0.23842844367027283
test loss item: 0.21035639941692352
test loss item: 0.6687979698181152
test loss item: 0.297991007566452
test loss item: 0.33984214067459106
test loss item: 0.1993304044008255
test loss item: 1.5942784547805786
test loss item: 0.4780842959880829
test loss item: 0.2906776964664459
test loss item: 0.48820316791534424
test loss item: 0.9765835404396057
test loss item: 0.24794121086597443
test loss item: 0.24880704283714294
test loss item: 0.36438608169555664
test loss item: 0.24405594170093536
test loss item: 0.20460322499275208
test loss item: 0.31221073865890503
test loss item: 0.5815168023109436
test loss item: 0.6876637935638428
test loss item: 0.2932569086551666
test loss item: 0.8900564908981323
test loss item: 0.4116584360599518
test loss item: 0.3473595976829529
test loss item: 0.21813485026359558
test loss item: 0.29179832339286804
test loss item: 0.28794169425964355
test loss item: 0.3815975785255432
test loss item: 0.2590048611164093
test loss item: 0.40988224744796753
test loss item: 0.42054346203804016
test loss item: 0.8390084505081177
test loss item: 0.1741965264081955
test loss item: 0.20490789413452148
test loss item: 0.6886284947395325
test loss item: 0.548048734664917
test loss item: 0.6423752307891846
test loss item: 0.825922966003418
test loss item: 1.577926516532898
test loss item: 0.6019184589385986
test loss item: 0.3062436878681183
test loss item: 0.3343251347541809
test loss item: 0.2593251168727875
test loss item: 0.45069804787635803
test loss item: 0.28048446774482727
test loss item: 0.7473246455192566
test loss item: 0.43313485383987427
test loss item: 0.3563593626022339
test loss item: 0.27302286028862
test loss item: 0.5766695737838745
test loss item: 0.7642732858657837
test loss item: 0.41285842657089233
test loss item: 0.20793692767620087
test loss item: 0.2953680455684662
test loss item: 0.3046450614929199
test loss item: 0.38186171650886536
test loss item: 0.9777759909629822
test loss item: 0.6179184913635254
test loss item: 0.31686022877693176
test loss item: 0.2901724874973297
test loss item: 0.28360453248023987
test loss item: 0.5627772212028503
test loss item: 0.25116539001464844
test loss item: 0.24941641092300415
test loss item: 0.30416613817214966
test loss item: 0.9264793395996094
test loss item: 0.4003139138221741
test loss item: 0.34446582198143005
test loss item: 0.3093259036540985
test loss item: 0.6506435871124268
test loss item: 0.4797220528125763
test loss item: 0.18514159321784973
test loss item: 0.8847754001617432
test loss item: 0.349391907453537
test loss item: 0.38920852541923523
test loss item: 0.21740777790546417
test loss item: 0.24834968149662018
test loss item: 0.22131773829460144
test loss item: 1.6329885721206665
test loss item: 0.5132033228874207
test loss item: 0.2582644522190094
test loss item: 0.17328207194805145
test loss item: 1.0349048376083374
test loss item: 0.8998982906341553
test loss item: 1.1585073471069336
test loss item: 0.2712641656398773
test loss item: 0.32474854588508606
test loss item: 0.21033257246017456
test loss item: 0.2011919617652893
test loss item: 0.3957861363887787
Epoch [18/100], Training Loss: 0.5797, Testing Loss: 0.4709
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 19/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5895503163337708
1
train loss item: 1.4224528074264526
2
train loss item: 0.28772327303886414
3
train loss item: 0.6373059153556824
4
train loss item: 0.46940040588378906
5
train loss item: 0.45125001668930054
6
train loss item: 0.3129631280899048
7
train loss item: 0.9263634085655212
8
train loss item: 0.22038333117961884
9
train loss item: 0.3171229660511017
10
train loss item: 0.4224267303943634
11
train loss item: 0.32252269983291626
12
train loss item: 0.20377804338932037
13
train loss item: 0.6028012633323669
14
train loss item: 0.409780889749527
15
train loss item: 0.7642658352851868
16
train loss item: 0.1775846928358078
17
train loss item: 0.3384348452091217
18
train loss item: 0.4132421612739563
19
train loss item: 0.3046720325946808
20
train loss item: 0.3003292977809906
21
train loss item: 0.2194051444530487
22
train loss item: 1.116457223892212
23
train loss item: 1.051245927810669
24
train loss item: 0.5893245339393616
25
train loss item: 0.2806076407432556
26
train loss item: 0.2815028131008148
27
train loss item: 0.4063929319381714
28
train loss item: 0.17673619091510773
29
train loss item: 0.9010723829269409
30
train loss item: 2.4217400550842285
31
train loss item: 0.6329613924026489
32
train loss item: 0.20366914570331573
33
train loss item: 0.46540457010269165
34
train loss item: 0.2555004060268402
35
train loss item: 2.5382142066955566
36
train loss item: 0.5628037452697754
37
train loss item: 0.3242564797401428
38
train loss item: 0.4997093975543976
39
train loss item: 0.4142982065677643
40
train loss item: 0.23032407462596893
41
train loss item: 0.3935709297657013
42
train loss item: 0.29036396741867065
43
train loss item: 0.24808315932750702
44
train loss item: 0.8267539143562317
45
train loss item: 0.21393857896327972
46
train loss item: 0.21470925211906433
47
train loss item: 0.39296671748161316
48
train loss item: 0.303587406873703
49
train loss item: 0.23667369782924652
50
train loss item: 0.3158290684223175
51
train loss item: 1.0297491550445557
52
train loss item: 0.19071441888809204
53
train loss item: 0.22578881680965424
54
train loss item: 2.4000790119171143
55
train loss item: 0.2686383128166199
56
train loss item: 0.382928729057312
57
train loss item: 0.34645235538482666
58
train loss item: 0.23846463859081268
59
train loss item: 0.22045081853866577
60
train loss item: 1.0539608001708984
61
train loss item: 2.3360509872436523
62
train loss item: 0.2809762954711914
63
train loss item: 0.3640463948249817
64
train loss item: 0.23320645093917847
65
train loss item: 0.6086328625679016
66
train loss item: 0.45248788595199585
67
train loss item: 0.27191001176834106
68
train loss item: 0.3485962152481079
69
train loss item: 0.3819449245929718
70
train loss item: 0.3032011091709137
71
train loss item: 0.22863046824932098
72
train loss item: 0.2551491856575012
73
train loss item: 0.35446974635124207
74
train loss item: 0.2044612169265747
75
train loss item: 0.19566656649112701
76
train loss item: 1.0135051012039185
77
train loss item: 1.4320658445358276
78
train loss item: 0.1796180158853531
79
train loss item: 0.3008049726486206
80
train loss item: 0.21658669412136078
81
train loss item: 0.24899421632289886
82
train loss item: 0.2953161597251892
83
train loss item: 0.7236828207969666
84
train loss item: 0.3922198414802551
85
train loss item: 0.6758854985237122
86
train loss item: 4.436288356781006
87
train loss item: 0.24311257898807526
88
train loss item: 0.38733360171318054
epoch train loss: 0.5688149247611507
testing phase
test loss item: 0.23307490348815918
test loss item: 0.2151002287864685
test loss item: 0.6601956486701965
test loss item: 0.29372406005859375
test loss item: 0.34416264295578003
test loss item: 0.20494970679283142
test loss item: 1.5536906719207764
test loss item: 0.4709863066673279
test loss item: 0.2816661596298218
test loss item: 0.478787899017334
test loss item: 0.9345131516456604
test loss item: 0.23902148008346558
test loss item: 0.2419120818376541
test loss item: 0.3582991659641266
test loss item: 0.24907375872135162
test loss item: 0.20381446182727814
test loss item: 0.30965545773506165
test loss item: 0.5888486504554749
test loss item: 0.6781796216964722
test loss item: 0.28932300209999084
test loss item: 0.8887587189674377
test loss item: 0.40540647506713867
test loss item: 0.3444860279560089
test loss item: 0.21940115094184875
test loss item: 0.29106101393699646
test loss item: 0.28632858395576477
test loss item: 0.3771289885044098
test loss item: 0.26169463992118835
test loss item: 0.40792569518089294
test loss item: 0.4164324104785919
test loss item: 0.8019279837608337
test loss item: 0.17425763607025146
test loss item: 0.2074730545282364
test loss item: 0.690882682800293
test loss item: 0.5535593032836914
test loss item: 0.6458221077919006
test loss item: 0.8131110072135925
test loss item: 1.50735604763031
test loss item: 0.594473659992218
test loss item: 0.30562594532966614
test loss item: 0.3300536274909973
test loss item: 0.25679337978363037
test loss item: 0.45188823342323303
test loss item: 0.27192825078964233
test loss item: 0.7398326396942139
test loss item: 0.42751169204711914
test loss item: 0.35053935647010803
test loss item: 0.26975104212760925
test loss item: 0.5653216242790222
test loss item: 0.7419476509094238
test loss item: 0.4036838710308075
test loss item: 0.20448452234268188
test loss item: 0.2934816777706146
test loss item: 0.2920803725719452
test loss item: 0.3794316351413727
test loss item: 0.9583540558815002
test loss item: 0.6122565269470215
test loss item: 0.3027404248714447
test loss item: 0.2884732484817505
test loss item: 0.2814348042011261
test loss item: 0.5620602369308472
test loss item: 0.24994681775569916
test loss item: 0.24397847056388855
test loss item: 0.2967395484447479
test loss item: 0.9070731401443481
test loss item: 0.38923099637031555
test loss item: 0.3406468331813812
test loss item: 0.30569252371788025
test loss item: 0.650723397731781
test loss item: 0.4664239287376404
test loss item: 0.1848238706588745
test loss item: 0.8653364777565002
test loss item: 0.3392161428928375
test loss item: 0.3825138509273529
test loss item: 0.2172694206237793
test loss item: 0.24309611320495605
test loss item: 0.22246712446212769
test loss item: 1.5610980987548828
test loss item: 0.5023264288902283
test loss item: 0.2576001286506653
test loss item: 0.1739281564950943
test loss item: 0.98719322681427
test loss item: 0.8799199461936951
test loss item: 1.0933998823165894
test loss item: 0.27169889211654663
test loss item: 0.3209911286830902
test loss item: 0.21113160252571106
test loss item: 0.1998130828142166
test loss item: 0.40060386061668396
Epoch [19/100], Training Loss: 0.5688, Testing Loss: 0.4626
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 20/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5839115977287292
1
train loss item: 1.3921500444412231
2
train loss item: 0.2827966511249542
3
train loss item: 0.6187329292297363
4
train loss item: 0.460822194814682
5
train loss item: 0.444957435131073
6
train loss item: 0.30749693512916565
7
train loss item: 0.9092050194740295
8
train loss item: 0.21611393988132477
9
train loss item: 0.30829834938049316
10
train loss item: 0.40844252705574036
11
train loss item: 0.3175061047077179
12
train loss item: 0.1993483006954193
13
train loss item: 0.5893275141716003
14
train loss item: 0.403731107711792
15
train loss item: 0.7477444410324097
16
train loss item: 0.17151357233524323
17
train loss item: 0.3316214680671692
18
train loss item: 0.40934765338897705
19
train loss item: 0.2997370958328247
20
train loss item: 0.2951239049434662
21
train loss item: 0.21319392323493958
22
train loss item: 1.0899510383605957
23
train loss item: 1.03036367893219
24
train loss item: 0.5784717202186584
25
train loss item: 0.2704496383666992
26
train loss item: 0.2746864855289459
27
train loss item: 0.4011985659599304
28
train loss item: 0.17073719203472137
29
train loss item: 0.8819634914398193
30
train loss item: 2.3849308490753174
31
train loss item: 0.6229214072227478
32
train loss item: 0.19702735543251038
33
train loss item: 0.45591410994529724
34
train loss item: 0.24944454431533813
35
train loss item: 2.5096285343170166
36
train loss item: 0.553689181804657
37
train loss item: 0.32333943247795105
38
train loss item: 0.4908140003681183
39
train loss item: 0.40885651111602783
40
train loss item: 0.22859907150268555
41
train loss item: 0.3868095874786377
42
train loss item: 0.28823122382164
43
train loss item: 0.242817223072052
44
train loss item: 0.8146941065788269
45
train loss item: 0.2086631953716278
46
train loss item: 0.20676524937152863
47
train loss item: 0.3817366361618042
48
train loss item: 0.2964032292366028
49
train loss item: 0.22870446741580963
50
train loss item: 0.3106665313243866
51
train loss item: 1.0078179836273193
52
train loss item: 0.18635456264019012
53
train loss item: 0.22151334583759308
54
train loss item: 2.371718168258667
55
train loss item: 0.2636621594429016
56
train loss item: 0.3765715956687927
57
train loss item: 0.34037211537361145
58
train loss item: 0.2320830374956131
59
train loss item: 0.215457946062088
60
train loss item: 1.0304043292999268
61
train loss item: 2.3069732189178467
62
train loss item: 0.27196216583251953
63
train loss item: 0.3557624816894531
64
train loss item: 0.22763648629188538
65
train loss item: 0.5994434952735901
66
train loss item: 0.44787102937698364
67
train loss item: 0.26291900873184204
68
train loss item: 0.3420785963535309
69
train loss item: 0.37466469407081604
70
train loss item: 0.29596173763275146
71
train loss item: 0.22406448423862457
72
train loss item: 0.24927568435668945
73
train loss item: 0.34959617257118225
74
train loss item: 0.1994689404964447
75
train loss item: 0.19073227047920227
76
train loss item: 0.9936506748199463
77
train loss item: 1.4110403060913086
78
train loss item: 0.17470383644104004
79
train loss item: 0.29692867398262024
80
train loss item: 0.21045170724391937
81
train loss item: 0.24340477585792542
82
train loss item: 0.2875173091888428
83
train loss item: 0.7033262848854065
84
train loss item: 0.38333696126937866
85
train loss item: 0.6586160063743591
86
train loss item: 4.396914482116699
87
train loss item: 0.2370891273021698
88
train loss item: 0.38235384225845337
epoch train loss: 0.5586887715237864
testing phase
test loss item: 0.22942708432674408
test loss item: 0.2085864543914795
test loss item: 0.6556540131568909
test loss item: 0.3019341230392456
test loss item: 0.3350445330142975
test loss item: 0.18974795937538147
test loss item: 1.5130994319915771
test loss item: 0.46123671531677246
test loss item: 0.27416083216667175
test loss item: 0.4699430465698242
test loss item: 0.9319619536399841
test loss item: 0.2565716505050659
test loss item: 0.2394622564315796
test loss item: 0.355025976896286
test loss item: 0.2420472949743271
test loss item: 0.20062755048274994
test loss item: 0.3064841628074646
test loss item: 0.5800062417984009
test loss item: 0.6575382947921753
test loss item: 0.28634244203567505
test loss item: 0.874708354473114
test loss item: 0.41195082664489746
test loss item: 0.3471260964870453
test loss item: 0.21431177854537964
test loss item: 0.2887478470802307
test loss item: 0.2751515209674835
test loss item: 0.37063273787498474
test loss item: 0.2504187524318695
test loss item: 0.39928367733955383
test loss item: 0.4091894328594208
test loss item: 0.7906649708747864
test loss item: 0.1715969294309616
test loss item: 0.20086973905563354
test loss item: 0.6914557814598083
test loss item: 0.5452192425727844
test loss item: 0.7078485488891602
test loss item: 0.7990394830703735
test loss item: 1.5212615728378296
test loss item: 0.589708149433136
test loss item: 0.29607468843460083
test loss item: 0.32560062408447266
test loss item: 0.24737094342708588
test loss item: 0.4486299157142639
test loss item: 0.283473402261734
test loss item: 0.727532684803009
test loss item: 0.42229509353637695
test loss item: 0.3536660075187683
test loss item: 0.26578837633132935
test loss item: 0.5520495772361755
test loss item: 0.7324417233467102
test loss item: 0.3946564793586731
test loss item: 0.19947949051856995
test loss item: 0.28625965118408203
test loss item: 0.3207005560398102
test loss item: 0.37118491530418396
test loss item: 0.9648874998092651
test loss item: 0.6240925192832947
test loss item: 0.2984326481819153
test loss item: 0.2833728492259979
test loss item: 0.2769797444343567
test loss item: 0.5541213750839233
test loss item: 0.24799089133739471
test loss item: 0.23866471648216248
test loss item: 0.2944755256175995
test loss item: 0.9143364429473877
test loss item: 0.41160905361175537
test loss item: 0.3343084454536438
test loss item: 0.2992062568664551
test loss item: 0.6561568975448608
test loss item: 0.45482999086380005
test loss item: 0.1787615567445755
test loss item: 0.8449921607971191
test loss item: 0.33440181612968445
test loss item: 0.3771221339702606
test loss item: 0.20922233164310455
test loss item: 0.244028240442276
test loss item: 0.2162349373102188
test loss item: 1.581186294555664
test loss item: 0.4958244860172272
test loss item: 0.2463209331035614
test loss item: 0.16143320500850677
test loss item: 0.9820772409439087
test loss item: 0.8651644587516785
test loss item: 1.127872109413147
test loss item: 0.2638932764530182
test loss item: 0.3029571771621704
test loss item: 0.1984957605600357
test loss item: 0.19557330012321472
test loss item: 0.3221018612384796
Epoch [20/100], Training Loss: 0.5587, Testing Loss: 0.4582
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 21/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5780142545700073
1
train loss item: 1.3621292114257812
2
train loss item: 0.2759101092815399
3
train loss item: 0.6052051782608032
4
train loss item: 0.4555419981479645
5
train loss item: 0.44008615612983704
6
train loss item: 0.29703348875045776
7
train loss item: 0.8936169147491455
8
train loss item: 0.2079550176858902
9
train loss item: 0.3033633828163147
10
train loss item: 0.40346819162368774
11
train loss item: 0.31535643339157104
12
train loss item: 0.19359435141086578
13
train loss item: 0.5800355076789856
14
train loss item: 0.3981442451477051
15
train loss item: 0.7291590571403503
16
train loss item: 0.16720113158226013
17
train loss item: 0.32551684975624084
18
train loss item: 0.40294116735458374
19
train loss item: 0.29382094740867615
20
train loss item: 0.2819775342941284
21
train loss item: 0.20606379210948944
22
train loss item: 1.0626394748687744
23
train loss item: 1.0135854482650757
24
train loss item: 0.5668492317199707
25
train loss item: 0.2659975588321686
26
train loss item: 0.2722831666469574
27
train loss item: 0.39307841658592224
28
train loss item: 0.16669990122318268
29
train loss item: 0.8568603992462158
30
train loss item: 2.3549015522003174
31
train loss item: 0.6139612197875977
32
train loss item: 0.1919316202402115
33
train loss item: 0.4508376121520996
34
train loss item: 0.24152477085590363
35
train loss item: 2.485124111175537
36
train loss item: 0.5434188842773438
37
train loss item: 0.32174521684646606
38
train loss item: 0.48592501878738403
39
train loss item: 0.4035488963127136
40
train loss item: 0.21855707466602325
41
train loss item: 0.37893831729888916
42
train loss item: 0.28271225094795227
43
train loss item: 0.23842009902000427
44
train loss item: 0.8029537796974182
45
train loss item: 0.201940655708313
46
train loss item: 0.2013002634048462
47
train loss item: 0.3755718767642975
48
train loss item: 0.2881261110305786
49
train loss item: 0.2227044403553009
50
train loss item: 0.3056195080280304
51
train loss item: 0.9857311844825745
52
train loss item: 0.1785084307193756
53
train loss item: 0.21231502294540405
54
train loss item: 2.347041130065918
55
train loss item: 0.2573646008968353
56
train loss item: 0.36861124634742737
57
train loss item: 0.3336017429828644
58
train loss item: 0.2266772985458374
59
train loss item: 0.21083270013332367
60
train loss item: 1.0037503242492676
61
train loss item: 2.2814738750457764
62
train loss item: 0.26694315671920776
63
train loss item: 0.3500708341598511
64
train loss item: 0.223905548453331
65
train loss item: 0.5813844799995422
66
train loss item: 0.4437843859195709
67
train loss item: 0.2579214572906494
68
train loss item: 0.32874277234077454
69
train loss item: 0.36807548999786377
70
train loss item: 0.2891642153263092
71
train loss item: 0.21520638465881348
72
train loss item: 0.24202649295330048
73
train loss item: 0.34306734800338745
74
train loss item: 0.19407068192958832
75
train loss item: 0.18611253798007965
76
train loss item: 0.9770328402519226
77
train loss item: 1.3885260820388794
78
train loss item: 0.17027223110198975
79
train loss item: 0.2961883544921875
80
train loss item: 0.2036869078874588
81
train loss item: 0.24257227778434753
82
train loss item: 0.280626505613327
83
train loss item: 0.6828084588050842
84
train loss item: 0.37946805357933044
85
train loss item: 0.6441487669944763
86
train loss item: 4.363705158233643
87
train loss item: 0.2296346127986908
88
train loss item: 0.3805023729801178
epoch train loss: 0.5489825591277541
testing phase
test loss item: 0.21893174946308136
test loss item: 0.18147647380828857
test loss item: 0.5979078412055969
test loss item: 0.27119144797325134
test loss item: 0.31138646602630615
test loss item: 0.1867755502462387
test loss item: 1.4721055030822754
test loss item: 0.44849249720573425
test loss item: 0.25196102261543274
test loss item: 0.4417119324207306
test loss item: 0.8546211123466492
test loss item: 0.21686741709709167
test loss item: 0.22048981487751007
test loss item: 0.35335344076156616
test loss item: 0.2235104739665985
test loss item: 0.16498079895973206
test loss item: 0.29765528440475464
test loss item: 0.5332658886909485
test loss item: 0.64792799949646
test loss item: 0.2790628969669342
test loss item: 0.8177177309989929
test loss item: 0.3808894455432892
test loss item: 0.3156861960887909
test loss item: 0.21080072224140167
test loss item: 0.2715955078601837
test loss item: 0.2692461311817169
test loss item: 0.36148205399513245
test loss item: 0.2379641979932785
test loss item: 0.37654662132263184
test loss item: 0.39239054918289185
test loss item: 0.7343405485153198
test loss item: 0.14615893363952637
test loss item: 0.19566473364830017
test loss item: 0.6251821517944336
test loss item: 0.4940054416656494
test loss item: 0.5862573981285095
test loss item: 0.7746630311012268
test loss item: 1.3579022884368896
test loss item: 0.5448952913284302
test loss item: 0.2952515184879303
test loss item: 0.3191301226615906
test loss item: 0.23386025428771973
test loss item: 0.4104800224304199
test loss item: 0.24629001319408417
test loss item: 0.6913192868232727
test loss item: 0.4136519730091095
test loss item: 0.32729968428611755
test loss item: 0.26293811202049255
test loss item: 0.5089468359947205
test loss item: 0.6789255738258362
test loss item: 0.366227388381958
test loss item: 0.1901412457227707
test loss item: 0.2713451087474823
test loss item: 0.24978652596473694
test loss item: 0.34995537996292114
test loss item: 0.8592384457588196
test loss item: 0.5695106387138367
test loss item: 0.2944261133670807
test loss item: 0.271716445684433
test loss item: 0.256148099899292
test loss item: 0.5165171027183533
test loss item: 0.23521724343299866
test loss item: 0.2339155673980713
test loss item: 0.2822472155094147
test loss item: 0.7998989224433899
test loss item: 0.3622664511203766
test loss item: 0.3244747817516327
test loss item: 0.28822556138038635
test loss item: 0.5873907208442688
test loss item: 0.42762497067451477
test loss item: 0.15527763962745667
test loss item: 0.8255119919776917
test loss item: 0.3188798129558563
test loss item: 0.3712786138057709
test loss item: 0.1960023194551468
test loss item: 0.21649648249149323
test loss item: 0.21130190789699554
test loss item: 1.3905291557312012
test loss item: 0.4884174168109894
test loss item: 0.23504029214382172
test loss item: 0.1557147353887558
test loss item: 0.9060466289520264
test loss item: 0.8321824073791504
test loss item: 0.9471707344055176
test loss item: 0.25496694445610046
test loss item: 0.29003655910491943
test loss item: 0.17587320506572723
test loss item: 0.16150644421577454
test loss item: 0.37257784605026245
Epoch [21/100], Training Loss: 0.5490, Testing Loss: 0.4258
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 22/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5732279419898987
1
train loss item: 1.3459705114364624
2
train loss item: 0.2715245187282562
3
train loss item: 0.5872966647148132
4
train loss item: 0.4499116837978363
5
train loss item: 0.4346265196800232
6
train loss item: 0.2920346260070801
7
train loss item: 0.8786500096321106
8
train loss item: 0.20738625526428223
9
train loss item: 0.2984407842159271
10
train loss item: 0.39266878366470337
11
train loss item: 0.31741681694984436
12
train loss item: 0.19460958242416382
13
train loss item: 0.5702348947525024
14
train loss item: 0.39349237084388733
15
train loss item: 0.7228742837905884
16
train loss item: 0.16195757687091827
17
train loss item: 0.31682854890823364
18
train loss item: 0.40096724033355713
19
train loss item: 0.29056236147880554
20
train loss item: 0.27491044998168945
21
train loss item: 0.20896491408348083
22
train loss item: 1.048682451248169
23
train loss item: 0.9928299784660339
24
train loss item: 0.5596941709518433
25
train loss item: 0.25730201601982117
26
train loss item: 0.2666597068309784
27
train loss item: 0.3876216411590576
28
train loss item: 0.1612459123134613
29
train loss item: 0.8515667915344238
30
train loss item: 2.311206817626953
31
train loss item: 0.6057983040809631
32
train loss item: 0.19101694226264954
33
train loss item: 0.4406367540359497
34
train loss item: 0.2387467622756958
35
train loss item: 2.457662343978882
36
train loss item: 0.5403845906257629
37
train loss item: 0.32074838876724243
38
train loss item: 0.4659547805786133
39
train loss item: 0.3972877562046051
40
train loss item: 0.21608684957027435
41
train loss item: 0.3725467026233673
42
train loss item: 0.2790432572364807
43
train loss item: 0.23435437679290771
44
train loss item: 0.7944360971450806
45
train loss item: 0.196587935090065
46
train loss item: 0.19546020030975342
47
train loss item: 0.365052193403244
48
train loss item: 0.28151631355285645
49
train loss item: 0.21958322823047638
50
train loss item: 0.29873624444007874
51
train loss item: 0.964771032333374
52
train loss item: 0.1759343296289444
53
train loss item: 0.21190492808818817
54
train loss item: 2.319488763809204
55
train loss item: 0.25624239444732666
56
train loss item: 0.36490944027900696
57
train loss item: 0.3301027715206146
58
train loss item: 0.22313031554222107
59
train loss item: 0.21178145706653595
60
train loss item: 0.9848986864089966
61
train loss item: 2.253634214401245
62
train loss item: 0.26911473274230957
63
train loss item: 0.34091436862945557
64
train loss item: 0.21898868680000305
65
train loss item: 0.5735597610473633
66
train loss item: 0.44486820697784424
67
train loss item: 0.25268441438674927
68
train loss item: 0.33204707503318787
69
train loss item: 0.36872372031211853
70
train loss item: 0.2857908010482788
71
train loss item: 0.21623370051383972
72
train loss item: 0.2390608787536621
73
train loss item: 0.34124213457107544
74
train loss item: 0.19247689843177795
75
train loss item: 0.18334029614925385
76
train loss item: 0.9598849415779114
77
train loss item: 1.3693420886993408
78
train loss item: 0.16787992417812347
79
train loss item: 0.29320022463798523
80
train loss item: 0.20233573019504547
81
train loss item: 0.2332344353199005
82
train loss item: 0.27866947650909424
83
train loss item: 0.6666645407676697
84
train loss item: 0.37492889165878296
85
train loss item: 0.628326416015625
86
train loss item: 4.323721885681152
87
train loss item: 0.226630300283432
88
train loss item: 0.3778161108493805
epoch train loss: 0.5414773687887727
testing phase
test loss item: 0.23033347725868225
test loss item: 0.23356305062770844
test loss item: 0.7178133130073547
test loss item: 0.31673869490623474
test loss item: 0.3694768249988556
test loss item: 0.21007023751735687
test loss item: 1.4739207029342651
test loss item: 0.45543918013572693
test loss item: 0.289343923330307
test loss item: 0.4983237683773041
test loss item: 1.033307433128357
test loss item: 0.2728419899940491
test loss item: 0.25466272234916687
test loss item: 0.3494910001754761
test loss item: 0.2725957930088043
test loss item: 0.2177840769290924
test loss item: 0.29743316769599915
test loss item: 0.6369208097457886
test loss item: 0.6675346493721008
test loss item: 0.2868315875530243
test loss item: 0.9517533779144287
test loss item: 0.41596221923828125
test loss item: 0.40420618653297424
test loss item: 0.22333522140979767
test loss item: 0.29515719413757324
test loss item: 0.2885953187942505
test loss item: 0.3821186423301697
test loss item: 0.27957117557525635
test loss item: 0.42236992716789246
test loss item: 0.4361916780471802
test loss item: 0.8546534776687622
test loss item: 0.20697908103466034
test loss item: 0.2115052193403244
test loss item: 0.7521666884422302
test loss item: 0.5988255739212036
test loss item: 0.84732586145401
test loss item: 0.8056879043579102
test loss item: 1.752253770828247
test loss item: 0.6304693818092346
test loss item: 0.3014507591724396
test loss item: 0.3225764334201813
test loss item: 0.2879396975040436
test loss item: 0.4672473073005676
test loss item: 0.2921949326992035
test loss item: 0.7599117755889893
test loss item: 0.41758498549461365
test loss item: 0.4024662375450134
test loss item: 0.27813559770584106
test loss item: 0.5867317318916321
test loss item: 0.8204630017280579
test loss item: 0.4194072484970093
test loss item: 0.21926246583461761
test loss item: 0.30000007152557373
test loss item: 0.3503264784812927
test loss item: 0.3976619243621826
test loss item: 1.1135847568511963
test loss item: 0.7017747163772583
test loss item: 0.29836681485176086
test loss item: 0.29658570885658264
test loss item: 0.3008289635181427
test loss item: 0.5978848338127136
test loss item: 0.24701304733753204
test loss item: 0.24118191003799438
test loss item: 0.30070510506629944
test loss item: 1.0377552509307861
test loss item: 0.43467915058135986
test loss item: 0.34475091099739075
test loss item: 0.2995726466178894
test loss item: 0.7063698768615723
test loss item: 0.5142859816551208
test loss item: 0.19415175914764404
test loss item: 0.811028778553009
test loss item: 0.3378468155860901
test loss item: 0.3682033121585846
test loss item: 0.20591235160827637
test loss item: 0.28847536444664
test loss item: 0.22645771503448486
test loss item: 1.843011498451233
test loss item: 0.493823379278183
test loss item: 0.26150041818618774
test loss item: 0.16404910385608673
test loss item: 1.057257890701294
test loss item: 0.8972605466842651
test loss item: 1.2993149757385254
test loss item: 0.28090769052505493
test loss item: 0.3108808994293213
test loss item: 0.1991988569498062
test loss item: 0.20466630160808563
test loss item: 0.32727134227752686
Epoch [22/100], Training Loss: 0.5415, Testing Loss: 0.4907
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 23/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5671181082725525
1
train loss item: 1.315480351448059
2
train loss item: 0.26664963364601135
3
train loss item: 0.5977994203567505
4
train loss item: 0.4478153586387634
5
train loss item: 0.4329412877559662
6
train loss item: 0.27962788939476013
7
train loss item: 0.8755223155021667
8
train loss item: 0.20016643404960632
9
train loss item: 0.30129000544548035
10
train loss item: 0.39884284138679504
11
train loss item: 0.31505218148231506
12
train loss item: 0.18780112266540527
13
train loss item: 0.5705900192260742
14
train loss item: 0.38949379324913025
15
train loss item: 0.687014102935791
16
train loss item: 0.1640520989894867
17
train loss item: 0.3191944658756256
18
train loss item: 0.39591923356056213
19
train loss item: 0.2877238094806671
20
train loss item: 0.2560310661792755
21
train loss item: 0.1922207623720169
22
train loss item: 1.0013242959976196
23
train loss item: 1.0057481527328491
24
train loss item: 0.5443142056465149
25
train loss item: 0.2587401866912842
26
train loss item: 0.2710709869861603
27
train loss item: 0.3835662603378296
28
train loss item: 0.1640382558107376
29
train loss item: 0.8108867406845093
30
train loss item: 2.3111355304718018
31
train loss item: 0.6057677268981934
32
train loss item: 0.19123248755931854
33
train loss item: 0.4555782079696655
34
train loss item: 0.23658733069896698
35
train loss item: 2.4433233737945557
36
train loss item: 0.5305489897727966
37
train loss item: 0.32287687063217163
38
train loss item: 0.5015018582344055
39
train loss item: 0.39195844531059265
40
train loss item: 0.21171866357326508
41
train loss item: 0.37119588255882263
42
train loss item: 0.2790885269641876
43
train loss item: 0.23916278779506683
44
train loss item: 0.7850433588027954
45
train loss item: 0.20235739648342133
46
train loss item: 0.19943444430828094
47
train loss item: 0.35795313119888306
48
train loss item: 0.29122963547706604
49
train loss item: 0.21706965565681458
50
train loss item: 0.2976609468460083
51
train loss item: 0.946654200553894
52
train loss item: 0.17526590824127197
53
train loss item: 0.20522023737430573
54
train loss item: 2.3079676628112793
55
train loss item: 0.25476810336112976
56
train loss item: 0.35937875509262085
57
train loss item: 0.3313329219818115
58
train loss item: 0.21940721571445465
59
train loss item: 0.20643608272075653
60
train loss item: 0.9593731164932251
61
train loss item: 2.252156972885132
62
train loss item: 0.25196632742881775
63
train loss item: 0.3400692939758301
64
train loss item: 0.22752170264720917
65
train loss item: 0.5534654259681702
66
train loss item: 0.44546404480934143
67
train loss item: 0.2549450099468231
68
train loss item: 0.31207671761512756
69
train loss item: 0.3587794005870819
70
train loss item: 0.2786819338798523
71
train loss item: 0.20283450186252594
72
train loss item: 0.23778261244297028
73
train loss item: 0.33676478266716003
74
train loss item: 0.18783454596996307
75
train loss item: 0.18569312989711761
76
train loss item: 0.9577662944793701
77
train loss item: 1.3417940139770508
78
train loss item: 0.1676623672246933
79
train loss item: 0.2985263168811798
80
train loss item: 0.1958358734846115
81
train loss item: 0.24697059392929077
82
train loss item: 0.2758510112762451
83
train loss item: 0.6461827158927917
84
train loss item: 0.37301260232925415
85
train loss item: 0.6310890913009644
86
train loss item: 4.307393550872803
87
train loss item: 0.226021870970726
88
train loss item: 0.3780740201473236
epoch train loss: 0.5367245119944047
testing phase
test loss item: 0.22930185496807098
test loss item: 0.18659371137619019
test loss item: 0.5790644884109497
test loss item: 0.2715130150318146
test loss item: 0.31119242310523987
test loss item: 0.18206866085529327
test loss item: 1.4087989330291748
test loss item: 0.4390830993652344
test loss item: 0.2374318391084671
test loss item: 0.4227897524833679
test loss item: 0.8721759915351868
test loss item: 0.2196027636528015
test loss item: 0.21728715300559998
test loss item: 0.3446636199951172
test loss item: 0.22145938873291016
test loss item: 0.1697627454996109
test loss item: 0.2932427227497101
test loss item: 0.5348631739616394
test loss item: 0.6553308963775635
test loss item: 0.27328750491142273
test loss item: 0.8142280578613281
test loss item: 0.38585418462753296
test loss item: 0.33681467175483704
test loss item: 0.20239229500293732
test loss item: 0.267681360244751
test loss item: 0.26357895135879517
test loss item: 0.3481701910495758
test loss item: 0.23950761556625366
test loss item: 0.3696379065513611
test loss item: 0.3800206482410431
test loss item: 0.7364718914031982
test loss item: 0.1443895399570465
test loss item: 0.18809597194194794
test loss item: 0.6392892003059387
test loss item: 0.4902878403663635
test loss item: 0.653706431388855
test loss item: 0.7487077713012695
test loss item: 1.4446955919265747
test loss item: 0.5362929701805115
test loss item: 0.28327956795692444
test loss item: 0.3107413351535797
test loss item: 0.2576850950717926
test loss item: 0.4167726933956146
test loss item: 0.24694570899009705
test loss item: 0.6735021471977234
test loss item: 0.40797314047813416
test loss item: 0.34639695286750793
test loss item: 0.2573482096195221
test loss item: 0.4950698912143707
test loss item: 0.6797286868095398
test loss item: 0.3554021418094635
test loss item: 0.18699681758880615
test loss item: 0.2623120844364166
test loss item: 0.2645089626312256
test loss item: 0.33682796359062195
test loss item: 0.8904250264167786
test loss item: 0.5987203121185303
test loss item: 0.29069676995277405
test loss item: 0.2701510787010193
test loss item: 0.2536351978778839
test loss item: 0.5065622329711914
test loss item: 0.23805223405361176
test loss item: 0.23770079016685486
test loss item: 0.2791939973831177
test loss item: 0.8319681882858276
test loss item: 0.3648902177810669
test loss item: 0.31611862778663635
test loss item: 0.2855204641819
test loss item: 0.6014125943183899
test loss item: 0.400163471698761
test loss item: 0.16000232100486755
test loss item: 0.7999746799468994
test loss item: 0.3104938268661499
test loss item: 0.36582455039024353
test loss item: 0.19708898663520813
test loss item: 0.2418607473373413
test loss item: 0.2092980295419693
test loss item: 1.5145479440689087
test loss item: 0.4736727476119995
test loss item: 0.2512653172016144
test loss item: 0.1627618819475174
test loss item: 0.9317181706428528
test loss item: 0.8067644834518433
test loss item: 1.071393609046936
test loss item: 0.24759072065353394
test loss item: 0.3040720224380493
test loss item: 0.18055537343025208
test loss item: 0.16391167044639587
test loss item: 0.48400986194610596
Epoch [23/100], Training Loss: 0.5367, Testing Loss: 0.4301
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 24/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5705767273902893
1
train loss item: 1.2974592447280884
2
train loss item: 0.26436832547187805
3
train loss item: 0.5643680691719055
4
train loss item: 0.44111788272857666
5
train loss item: 0.4293605387210846
6
train loss item: 0.2826695442199707
7
train loss item: 0.8545054197311401
8
train loss item: 0.197299987077713
9
train loss item: 0.28886646032333374
10
train loss item: 0.38283511996269226
11
train loss item: 0.31368136405944824
12
train loss item: 0.1865198165178299
13
train loss item: 0.5467963218688965
14
train loss item: 0.3890475332736969
15
train loss item: 0.7147576212882996
16
train loss item: 0.15285150706768036
17
train loss item: 0.3111218214035034
18
train loss item: 0.4009549021720886
19
train loss item: 0.29021647572517395
20
train loss item: 0.2738049328327179
21
train loss item: 0.19787655770778656
22
train loss item: 1.0111697912216187
23
train loss item: 0.9575379490852356
24
train loss item: 0.5564163327217102
25
train loss item: 0.24551059305667877
26
train loss item: 0.2616056799888611
27
train loss item: 0.380050390958786
28
train loss item: 0.15214747190475464
29
train loss item: 0.8163355588912964
30
train loss item: 2.2559361457824707
31
train loss item: 0.5792062878608704
32
train loss item: 0.1810668706893921
33
train loss item: 0.42404040694236755
34
train loss item: 0.22958408296108246
35
train loss item: 2.4139864444732666
36
train loss item: 0.5285246968269348
37
train loss item: 0.3246351480484009
38
train loss item: 0.4560226798057556
39
train loss item: 0.40153294801712036
40
train loss item: 0.21428431570529938
41
train loss item: 0.36277905106544495
42
train loss item: 0.3063562214374542
43
train loss item: 0.22695370018482208
44
train loss item: 0.7723203897476196
45
train loss item: 0.18548683822155
46
train loss item: 0.18545933067798615
47
train loss item: 0.36570724844932556
48
train loss item: 0.2712733745574951
49
train loss item: 0.2093341052532196
50
train loss item: 0.2983319163322449
51
train loss item: 0.9320563077926636
52
train loss item: 0.16502195596694946
53
train loss item: 0.20570412278175354
54
train loss item: 2.2764246463775635
55
train loss item: 0.2482636272907257
56
train loss item: 0.35499852895736694
57
train loss item: 0.3251555562019348
58
train loss item: 0.21841630339622498
59
train loss item: 0.19661039113998413
60
train loss item: 0.9474573731422424
61
train loss item: 2.2063682079315186
62
train loss item: 0.2603073716163635
63
train loss item: 0.3458828330039978
64
train loss item: 0.21061649918556213
65
train loss item: 0.5674203634262085
66
train loss item: 0.43563684821128845
67
train loss item: 0.24692483246326447
68
train loss item: 0.34710952639579773
69
train loss item: 0.3601498603820801
70
train loss item: 0.28060585260391235
71
train loss item: 0.20533858239650726
72
train loss item: 0.22548715770244598
73
train loss item: 0.3388500213623047
74
train loss item: 0.18128207325935364
75
train loss item: 0.17506980895996094
76
train loss item: 0.930026650428772
77
train loss item: 1.3458449840545654
78
train loss item: 0.15850265324115753
79
train loss item: 0.3013419806957245
80
train loss item: 0.19242613017559052
81
train loss item: 0.23041532933712006
82
train loss item: 0.26453688740730286
83
train loss item: 0.6452032923698425
84
train loss item: 0.3786300718784332
85
train loss item: 0.6002159118652344
86
train loss item: 4.263311862945557
87
train loss item: 0.21787123382091522
88
train loss item: 0.39475017786026
epoch train loss: 0.5292684040712506
testing phase
test loss item: 0.215257927775383
test loss item: 0.18117880821228027
test loss item: 0.5769933462142944
test loss item: 0.26035258173942566
test loss item: 0.30757591128349304
test loss item: 0.18261584639549255
test loss item: 1.4013137817382812
test loss item: 0.4343017637729645
test loss item: 0.23391668498516083
test loss item: 0.4258899390697479
test loss item: 0.8502569794654846
test loss item: 0.20392301678657532
test loss item: 0.21547073125839233
test loss item: 0.34046703577041626
test loss item: 0.22248917818069458
test loss item: 0.15510676801204681
test loss item: 0.2885575592517853
test loss item: 0.5346259474754333
test loss item: 0.6180770397186279
test loss item: 0.2703181207180023
test loss item: 0.8158382773399353
test loss item: 0.3741607666015625
test loss item: 0.31455934047698975
test loss item: 0.20844654738903046
test loss item: 0.25943243503570557
test loss item: 0.25518062710762024
test loss item: 0.3444015681743622
test loss item: 0.23699837923049927
test loss item: 0.3674387037754059
test loss item: 0.3820735514163971
test loss item: 0.7192556262016296
test loss item: 0.13639497756958008
test loss item: 0.19383636116981506
test loss item: 0.6313883662223816
test loss item: 0.4871770739555359
test loss item: 0.5979958772659302
test loss item: 0.7451731562614441
test loss item: 1.4049642086029053
test loss item: 0.5296147465705872
test loss item: 0.2888490557670593
test loss item: 0.30791333317756653
test loss item: 0.2242717295885086
test loss item: 0.4198125898838043
test loss item: 0.23216475546360016
test loss item: 0.6727077960968018
test loss item: 0.40322133898735046
test loss item: 0.32646241784095764
test loss item: 0.2566823959350586
test loss item: 0.49267131090164185
test loss item: 0.6643331050872803
test loss item: 0.35356423258781433
test loss item: 0.18342338502407074
test loss item: 0.2597440481185913
test loss item: 0.23154392838478088
test loss item: 0.33815404772758484
test loss item: 0.8776974678039551
test loss item: 0.5700211524963379
test loss item: 0.29333966970443726
test loss item: 0.26399722695350647
test loss item: 0.25104379653930664
test loss item: 0.5109615921974182
test loss item: 0.2323860228061676
test loss item: 0.229274719953537
test loss item: 0.2768286168575287
test loss item: 0.8148348927497864
test loss item: 0.341109961271286
test loss item: 0.31501978635787964
test loss item: 0.2777388095855713
test loss item: 0.5895788073539734
test loss item: 0.4054528772830963
test loss item: 0.1457529515028
test loss item: 0.7957882285118103
test loss item: 0.3128836154937744
test loss item: 0.36165735125541687
test loss item: 0.18382185697555542
test loss item: 0.2128491997718811
test loss item: 0.20772919058799744
test loss item: 1.4450039863586426
test loss item: 0.4692786633968353
test loss item: 0.234757199883461
test loss item: 0.14342793822288513
test loss item: 0.8920908570289612
test loss item: 0.8052890300750732
test loss item: 1.011350393295288
test loss item: 0.24682185053825378
test loss item: 0.2554456293582916
test loss item: 0.15970566868782043
test loss item: 0.14920470118522644
test loss item: 0.2896752953529358
Epoch [24/100], Training Loss: 0.5293, Testing Loss: 0.4174
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 25/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5628218650817871
1
train loss item: 1.269061803817749
2
train loss item: 0.2611715793609619
3
train loss item: 0.5549126267433167
4
train loss item: 0.4393959939479828
5
train loss item: 0.42296168208122253
6
train loss item: 0.2762382924556732
7
train loss item: 0.8401694297790527
8
train loss item: 0.19292603433132172
9
train loss item: 0.28345710039138794
10
train loss item: 0.3824159801006317
11
train loss item: 0.3081974983215332
12
train loss item: 0.18386010825634003
13
train loss item: 0.5430861115455627
14
train loss item: 0.3829430043697357
15
train loss item: 0.6881237030029297
16
train loss item: 0.1492713987827301
17
train loss item: 0.3063395321369171
18
train loss item: 0.3888646364212036
19
train loss item: 0.2821676731109619
20
train loss item: 0.2644823491573334
21
train loss item: 0.19140386581420898
22
train loss item: 0.9826546311378479
23
train loss item: 0.943648099899292
24
train loss item: 0.5424396395683289
25
train loss item: 0.24193458259105682
26
train loss item: 0.2537775933742523
27
train loss item: 0.37349534034729004
28
train loss item: 0.14839677512645721
29
train loss item: 0.7911974191665649
30
train loss item: 2.224213123321533
31
train loss item: 0.5781471729278564
32
train loss item: 0.17732220888137817
33
train loss item: 0.4214226007461548
34
train loss item: 0.22578394412994385
35
train loss item: 2.391235589981079
36
train loss item: 0.5236363410949707
37
train loss item: 0.3221592307090759
38
train loss item: 0.4607697129249573
39
train loss item: 0.39115291833877563
40
train loss item: 0.207767054438591
41
train loss item: 0.35387685894966125
42
train loss item: 0.27364808320999146
43
train loss item: 0.22277668118476868
44
train loss item: 0.7648559808731079
45
train loss item: 0.18412286043167114
46
train loss item: 0.18150295317173004
47
train loss item: 0.3592683672904968
48
train loss item: 0.26516643166542053
49
train loss item: 0.20804190635681152
50
train loss item: 0.29116904735565186
51
train loss item: 0.9136459231376648
52
train loss item: 0.16391700506210327
53
train loss item: 0.2061716765165329
54
train loss item: 2.254260778427124
55
train loss item: 0.24554648995399475
56
train loss item: 0.3505595028400421
57
train loss item: 0.3181791305541992
58
train loss item: 0.21300843358039856
59
train loss item: 0.1971919983625412
60
train loss item: 0.9300346970558167
61
train loss item: 2.184375524520874
62
train loss item: 0.25745689868927
63
train loss item: 0.3369542062282562
64
train loss item: 0.2062128484249115
65
train loss item: 0.5596261024475098
66
train loss item: 0.4348869025707245
67
train loss item: 0.24225583672523499
68
train loss item: 0.3397686779499054
69
train loss item: 0.35417166352272034
70
train loss item: 0.2759133279323578
71
train loss item: 0.20251703262329102
72
train loss item: 0.22091801464557648
73
train loss item: 0.3323279321193695
74
train loss item: 0.17928922176361084
75
train loss item: 0.17125876247882843
76
train loss item: 0.9168214201927185
77
train loss item: 1.3254611492156982
78
train loss item: 0.1554669886827469
79
train loss item: 0.2940872311592102
80
train loss item: 0.18832843005657196
81
train loss item: 0.2249900847673416
82
train loss item: 0.2646852731704712
83
train loss item: 0.6288261413574219
84
train loss item: 0.370984822511673
85
train loss item: 0.5952325463294983
86
train loss item: 4.231497764587402
87
train loss item: 0.21516107022762299
88
train loss item: 0.38546404242515564
epoch train loss: 0.5209810221463107
testing phase
test loss item: 0.2079194337129593
test loss item: 0.18301799893379211
test loss item: 0.6072392463684082
test loss item: 0.2557135820388794
test loss item: 0.3144371211528778
test loss item: 0.17848597466945648
test loss item: 1.3741718530654907
test loss item: 0.4225093424320221
test loss item: 0.24353370070457458
test loss item: 0.4409564733505249
test loss item: 0.8674308657646179
test loss item: 0.20216992497444153
test loss item: 0.22041113674640656
test loss item: 0.339099258184433
test loss item: 0.22833207249641418
test loss item: 0.1566411554813385
test loss item: 0.2823422849178314
test loss item: 0.5541580319404602
test loss item: 0.6054974794387817
test loss item: 0.2702869176864624
test loss item: 0.8476443886756897
test loss item: 0.3652730882167816
test loss item: 0.3210175633430481
test loss item: 0.20220094919204712
test loss item: 0.2614934742450714
test loss item: 0.24782821536064148
test loss item: 0.34581324458122253
test loss item: 0.2373407781124115
test loss item: 0.3738543689250946
test loss item: 0.3887544274330139
test loss item: 0.7274560332298279
test loss item: 0.1414581686258316
test loss item: 0.188770592212677
test loss item: 0.6476163864135742
test loss item: 0.5065697431564331
test loss item: 0.5978061556816101
test loss item: 0.7409713268280029
test loss item: 1.4485902786254883
test loss item: 0.5417836308479309
test loss item: 0.28249192237854004
test loss item: 0.30297574400901794
test loss item: 0.213692769408226
test loss item: 0.42647749185562134
test loss item: 0.22713065147399902
test loss item: 0.6906129121780396
test loss item: 0.3950890898704529
test loss item: 0.32811078429222107
test loss item: 0.2594315707683563
test loss item: 0.5093819499015808
test loss item: 0.6821098327636719
test loss item: 0.3621439039707184
test loss item: 0.18767493963241577
test loss item: 0.2636364996433258
test loss item: 0.22477436065673828
test loss item: 0.3504244089126587
test loss item: 0.9187349677085876
test loss item: 0.569298505783081
test loss item: 0.27951180934906006
test loss item: 0.26152050495147705
test loss item: 0.25950634479522705
test loss item: 0.5268020033836365
test loss item: 0.22477948665618896
test loss item: 0.21876175701618195
test loss item: 0.2778658866882324
test loss item: 0.8439632654190063
test loss item: 0.33512604236602783
test loss item: 0.3112777769565582
test loss item: 0.27551722526550293
test loss item: 0.6073650121688843
test loss item: 0.4280775189399719
test loss item: 0.14714062213897705
test loss item: 0.7730956077575684
test loss item: 0.3184559941291809
test loss item: 0.3534514605998993
test loss item: 0.1801404058933258
test loss item: 0.20899493992328644
test loss item: 0.20193113386631012
test loss item: 1.4834468364715576
test loss item: 0.4679003357887268
test loss item: 0.22557301819324493
test loss item: 0.13904649019241333
test loss item: 0.8921186923980713
test loss item: 0.8111513257026672
test loss item: 1.0293774604797363
test loss item: 0.24633891880512238
test loss item: 0.2491169422864914
test loss item: 0.1548217535018921
test loss item: 0.14810089766979218
test loss item: 0.20158350467681885
Epoch [25/100], Training Loss: 0.5210, Testing Loss: 0.4198
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 26/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5526483058929443
1
train loss item: 1.2435332536697388
2
train loss item: 0.25521421432495117
3
train loss item: 0.5555591583251953
4
train loss item: 0.4341823160648346
5
train loss item: 0.4170529246330261
6
train loss item: 0.26514798402786255
7
train loss item: 0.8342001438140869
8
train loss item: 0.18799267709255219
9
train loss item: 0.2787608802318573
10
train loss item: 0.38062405586242676
11
train loss item: 0.3066751956939697
12
train loss item: 0.1772022694349289
13
train loss item: 0.5419187545776367
14
train loss item: 0.3745351731777191
15
train loss item: 0.6539400219917297
16
train loss item: 0.14579181373119354
17
train loss item: 0.3010725975036621
18
train loss item: 0.3795230984687805
19
train loss item: 0.2714410424232483
20
train loss item: 0.24742378294467926
21
train loss item: 0.1821756213903427
22
train loss item: 0.9465227127075195
23
train loss item: 0.942455530166626
24
train loss item: 0.5281072854995728
25
train loss item: 0.24160492420196533
26
train loss item: 0.24942108988761902
27
train loss item: 0.3658498227596283
28
train loss item: 0.14523117244243622
29
train loss item: 0.7632571458816528
30
train loss item: 2.2120473384857178
31
train loss item: 0.580613374710083
32
train loss item: 0.17358466982841492
33
train loss item: 0.42873093485832214
34
train loss item: 0.22049979865550995
35
train loss item: 2.3762295246124268
36
train loss item: 0.5162389874458313
37
train loss item: 0.32066819071769714
38
train loss item: 0.48384106159210205
39
train loss item: 0.3783046305179596
40
train loss item: 0.1995820552110672
41
train loss item: 0.3487718105316162
42
train loss item: 0.26499882340431213
43
train loss item: 0.220640167593956
44
train loss item: 0.7596985697746277
45
train loss item: 0.18615369498729706
46
train loss item: 0.1809331327676773
47
train loss item: 0.34672796726226807
48
train loss item: 0.26337188482284546
49
train loss item: 0.2066306173801422
50
train loss item: 0.2815214991569519
51
train loss item: 0.8962636590003967
52
train loss item: 0.1602555513381958
53
train loss item: 0.2035965621471405
54
train loss item: 2.2409040927886963
55
train loss item: 0.23973926901817322
56
train loss item: 0.344777911901474
57
train loss item: 0.31330564618110657
58
train loss item: 0.20421113073825836
59
train loss item: 0.19445735216140747
60
train loss item: 0.9074747562408447
61
train loss item: 2.173297882080078
62
train loss item: 0.2466806024312973
63
train loss item: 0.3261769711971283
64
train loss item: 0.20669223368167877
65
train loss item: 0.5409221649169922
66
train loss item: 0.43807655572891235
67
train loss item: 0.23904284834861755
68
train loss item: 0.311705619096756
69
train loss item: 0.34372323751449585
70
train loss item: 0.26936066150665283
71
train loss item: 0.19412806630134583
72
train loss item: 0.2198840081691742
73
train loss item: 0.3199542462825775
74
train loss item: 0.17354577779769897
75
train loss item: 0.16738396883010864
76
train loss item: 0.9097209572792053
77
train loss item: 1.297088384628296
78
train loss item: 0.15109175443649292
79
train loss item: 0.2887094020843506
80
train loss item: 0.18220937252044678
81
train loss item: 0.22281613945960999
82
train loss item: 0.2626829445362091
83
train loss item: 0.6072249412536621
84
train loss item: 0.3657356798648834
85
train loss item: 0.5960074067115784
86
train loss item: 4.212058067321777
87
train loss item: 0.21255187690258026
88
train loss item: 0.3742387294769287
epoch train loss: 0.513219664438387
testing phase
test loss item: 0.20617946982383728
test loss item: 0.18584857881069183
test loss item: 0.6155879497528076
test loss item: 0.2525149881839752
test loss item: 0.31658875942230225
test loss item: 0.17629319429397583
test loss item: 1.349112629890442
test loss item: 0.41673150658607483
test loss item: 0.24594619870185852
test loss item: 0.4396590292453766
test loss item: 0.8634663820266724
test loss item: 0.1999208778142929
test loss item: 0.2211700975894928
test loss item: 0.3391434848308563
test loss item: 0.23086456954479218
test loss item: 0.16204525530338287
test loss item: 0.27910128235816956
test loss item: 0.552259624004364
test loss item: 0.6001166701316833
test loss item: 0.27108198404312134
test loss item: 0.8460085391998291
test loss item: 0.3591834604740143
test loss item: 0.3244786858558655
test loss item: 0.20002183318138123
test loss item: 0.2625105679035187
test loss item: 0.24889090657234192
test loss item: 0.34655410051345825
test loss item: 0.23729227483272552
test loss item: 0.37547045946121216
test loss item: 0.38548195362091064
test loss item: 0.7211048007011414
test loss item: 0.14789624512195587
test loss item: 0.1865372359752655
test loss item: 0.6476274132728577
test loss item: 0.5078838467597961
test loss item: 0.5676577091217041
test loss item: 0.7331039309501648
test loss item: 1.4443624019622803
test loss item: 0.539898157119751
test loss item: 0.27796682715415955
test loss item: 0.29998719692230225
test loss item: 0.21404263377189636
test loss item: 0.41846969723701477
test loss item: 0.22261102497577667
test loss item: 0.6831494569778442
test loss item: 0.3922853469848633
test loss item: 0.33046871423721313
test loss item: 0.26529765129089355
test loss item: 0.5116080045700073
test loss item: 0.6854146718978882
test loss item: 0.35449016094207764
test loss item: 0.18843044340610504
test loss item: 0.2651248276233673
test loss item: 0.21843746304512024
test loss item: 0.35232025384902954
test loss item: 0.9260603785514832
test loss item: 0.5583380460739136
test loss item: 0.2870025634765625
test loss item: 0.25736483931541443
test loss item: 0.2631029188632965
test loss item: 0.5221994519233704
test loss item: 0.22244276106357574
test loss item: 0.21743200719356537
test loss item: 0.27660343050956726
test loss item: 0.8489636182785034
test loss item: 0.3295712471008301
test loss item: 0.30986759066581726
test loss item: 0.27558740973472595
test loss item: 0.6158532500267029
test loss item: 0.4339519143104553
test loss item: 0.15340319275856018
test loss item: 0.757506251335144
test loss item: 0.3235408067703247
test loss item: 0.35040897130966187
test loss item: 0.18059450387954712
test loss item: 0.21412983536720276
test loss item: 0.2014443725347519
test loss item: 1.4745460748672485
test loss item: 0.47132769227027893
test loss item: 0.22208891808986664
test loss item: 0.14097332954406738
test loss item: 0.8776246309280396
test loss item: 0.8026360869407654
test loss item: 1.0084103345870972
test loss item: 0.25027331709861755
test loss item: 0.25343871116638184
test loss item: 0.15637339651584625
test loss item: 0.15164697170257568
test loss item: 0.2013867199420929
Epoch [26/100], Training Loss: 0.5132, Testing Loss: 0.4182
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 27/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5447974801063538
1
train loss item: 1.2301403284072876
2
train loss item: 0.24997729063034058
3
train loss item: 0.5539482831954956
4
train loss item: 0.43080252408981323
5
train loss item: 0.4130309820175171
6
train loss item: 0.25863125920295715
7
train loss item: 0.8276054859161377
8
train loss item: 0.1841687262058258
9
train loss item: 0.276444673538208
10
train loss item: 0.3749110698699951
11
train loss item: 0.30631229281425476
12
train loss item: 0.1730484962463379
13
train loss item: 0.5378317832946777
14
train loss item: 0.3679939806461334
15
train loss item: 0.6381869316101074
16
train loss item: 0.14341378211975098
17
train loss item: 0.2957647144794464
18
train loss item: 0.3753942847251892
19
train loss item: 0.2683643698692322
20
train loss item: 0.23923811316490173
21
train loss item: 0.17687663435935974
22
train loss item: 0.9212358593940735
23
train loss item: 0.9353905320167542
24
train loss item: 0.5226713418960571
25
train loss item: 0.23905763030052185
26
train loss item: 0.24760904908180237
27
train loss item: 0.36092838644981384
28
train loss item: 0.14309728145599365
29
train loss item: 0.7444886565208435
30
train loss item: 2.2002344131469727
31
train loss item: 0.5780193209648132
32
train loss item: 0.17212408781051636
33
train loss item: 0.42923831939697266
34
train loss item: 0.21667887270450592
35
train loss item: 2.3623454570770264
36
train loss item: 0.5104556679725647
37
train loss item: 0.3212110102176666
38
train loss item: 0.4826721251010895
39
train loss item: 0.3717358112335205
40
train loss item: 0.1979120522737503
41
train loss item: 0.3462428152561188
42
train loss item: 0.2647871673107147
43
train loss item: 0.21907870471477509
44
train loss item: 0.7531711459159851
45
train loss item: 0.18518735468387604
46
train loss item: 0.18013496696949005
47
train loss item: 0.33793947100639343
48
train loss item: 0.2655360996723175
49
train loss item: 0.20365454256534576
50
train loss item: 0.2797107696533203
51
train loss item: 0.8836860656738281
52
train loss item: 0.1564842015504837
53
train loss item: 0.19962342083454132
54
train loss item: 2.2282767295837402
55
train loss item: 0.2343323677778244
56
train loss item: 0.3397056460380554
57
train loss item: 0.3115938603878021
58
train loss item: 0.19972220063209534
59
train loss item: 0.1923181712627411
60
train loss item: 0.8901538848876953
61
train loss item: 2.160883903503418
62
train loss item: 0.23877830803394318
63
train loss item: 0.3242829144001007
64
train loss item: 0.20655767619609833
65
train loss item: 0.5305850505828857
66
train loss item: 0.4380415678024292
67
train loss item: 0.23692186176776886
68
train loss item: 0.2984258532524109
69
train loss item: 0.3388271927833557
70
train loss item: 0.2677665054798126
71
train loss item: 0.18675747513771057
72
train loss item: 0.21938543021678925
73
train loss item: 0.3156897723674774
74
train loss item: 0.16825048625469208
75
train loss item: 0.16534407436847687
76
train loss item: 0.9009388089179993
77
train loss item: 1.2791162729263306
78
train loss item: 0.14818814396858215
79
train loss item: 0.2909241318702698
80
train loss item: 0.17771510779857635
81
train loss item: 0.22485972940921783
82
train loss item: 0.25655704736709595
83
train loss item: 0.5940196514129639
84
train loss item: 0.36766862869262695
85
train loss item: 0.5911749601364136
86
train loss item: 4.194450855255127
87
train loss item: 0.21063396334648132
88
train loss item: 0.36892572045326233
epoch train loss: 0.5078314611416185
testing phase
test loss item: 0.20573550462722778
test loss item: 0.18553408980369568
test loss item: 0.5911127328872681
test loss item: 0.24999688565731049
test loss item: 0.3131706416606903
test loss item: 0.17861752212047577
test loss item: 1.3385764360427856
test loss item: 0.4219008684158325
test loss item: 0.2361760139465332
test loss item: 0.42173707485198975
test loss item: 0.8156572580337524
test loss item: 0.19598473608493805
test loss item: 0.2128431797027588
test loss item: 0.33652085065841675
test loss item: 0.2278776913881302
test loss item: 0.16203653812408447
test loss item: 0.27930742502212524
test loss item: 0.532257616519928
test loss item: 0.5966583490371704
test loss item: 0.26843464374542236
test loss item: 0.8170690536499023
test loss item: 0.35910671949386597
test loss item: 0.3190801739692688
test loss item: 0.19998642802238464
test loss item: 0.2593374252319336
test loss item: 0.24797795712947845
test loss item: 0.3416075110435486
test loss item: 0.23595590889453888
test loss item: 0.3681110143661499
test loss item: 0.37337005138397217
test loss item: 0.687305212020874
test loss item: 0.14523930847644806
test loss item: 0.18616032600402832
test loss item: 0.6297614574432373
test loss item: 0.48976850509643555
test loss item: 0.517920970916748
test loss item: 0.7235535979270935
test loss item: 1.3436633348464966
test loss item: 0.5222965478897095
test loss item: 0.27741721272468567
test loss item: 0.2990489602088928
test loss item: 0.21870501339435577
test loss item: 0.40445852279663086
test loss item: 0.21881499886512756
test loss item: 0.6595363020896912
test loss item: 0.39293408393859863
test loss item: 0.3242108225822449
test loss item: 0.2612765431404114
test loss item: 0.4951438009738922
test loss item: 0.6540324091911316
test loss item: 0.3362690210342407
test loss item: 0.18178816139698029
test loss item: 0.2582896947860718
test loss item: 0.21132376790046692
test loss item: 0.3396865427494049
test loss item: 0.8753829002380371
test loss item: 0.5352749228477478
test loss item: 0.2795141637325287
test loss item: 0.2534247636795044
test loss item: 0.2535814940929413
test loss item: 0.5018398761749268
test loss item: 0.22573067247867584
test loss item: 0.2162562608718872
test loss item: 0.2692037522792816
test loss item: 0.8105489611625671
test loss item: 0.3241327702999115
test loss item: 0.3057449162006378
test loss item: 0.274650901556015
test loss item: 0.6034185290336609
test loss item: 0.40451130270957947
test loss item: 0.1544904112815857
test loss item: 0.7588847875595093
test loss item: 0.3218827247619629
test loss item: 0.3510952293872833
test loss item: 0.18088451027870178
test loss item: 0.21249665319919586
test loss item: 0.20275121927261353
test loss item: 1.3692377805709839
test loss item: 0.46941712498664856
test loss item: 0.22352471947669983
test loss item: 0.14353704452514648
test loss item: 0.8370387554168701
test loss item: 0.7797085642814636
test loss item: 0.9206759929656982
test loss item: 0.24806852638721466
test loss item: 0.2546471059322357
test loss item: 0.15788976848125458
test loss item: 0.1513742208480835
test loss item: 0.25228971242904663
Epoch [27/100], Training Loss: 0.5078, Testing Loss: 0.4067
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 28/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5385247468948364
1
train loss item: 1.2154048681259155
2
train loss item: 0.24609258770942688
3
train loss item: 0.539565920829773
4
train loss item: 0.42721131443977356
5
train loss item: 0.40738168358802795
6
train loss item: 0.2557879090309143
7
train loss item: 0.8146952986717224
8
train loss item: 0.17780475318431854
9
train loss item: 0.26929911971092224
10
train loss item: 0.3616258203983307
11
train loss item: 0.29766544699668884
12
train loss item: 0.17007453739643097
13
train loss item: 0.5243496894836426
14
train loss item: 0.362186998128891
15
train loss item: 0.6330118179321289
16
train loss item: 0.13977044820785522
17
train loss item: 0.28841516375541687
18
train loss item: 0.3710486590862274
19
train loss item: 0.269446462392807
20
train loss item: 0.2408219277858734
21
train loss item: 0.1734575778245926
22
train loss item: 0.9100012183189392
23
train loss item: 0.9106851816177368
24
train loss item: 0.5215966701507568
25
train loss item: 0.22988100349903107
26
train loss item: 0.24132601916790009
27
train loss item: 0.35777658224105835
28
train loss item: 0.13941313326358795
29
train loss item: 0.7303934693336487
30
train loss item: 2.169804811477661
31
train loss item: 0.5660530924797058
32
train loss item: 0.1663939505815506
33
train loss item: 0.41626524925231934
34
train loss item: 0.21181482076644897
35
train loss item: 2.343118667602539
36
train loss item: 0.5019974708557129
37
train loss item: 0.31884536147117615
38
train loss item: 0.44963952898979187
39
train loss item: 0.3665752708911896
40
train loss item: 0.20054891705513
41
train loss item: 0.33724886178970337
42
train loss item: 0.26355835795402527
43
train loss item: 0.2140854001045227
44
train loss item: 0.7437224984169006
45
train loss item: 0.1780623495578766
46
train loss item: 0.17896534502506256
47
train loss item: 0.3369446098804474
48
train loss item: 0.26047101616859436
49
train loss item: 0.19765543937683105
50
train loss item: 0.2812316417694092
51
train loss item: 0.8689810037612915
52
train loss item: 0.15114720165729523
53
train loss item: 0.1941882222890854
54
train loss item: 2.208798885345459
55
train loss item: 0.23129627108573914
56
train loss item: 0.3326474130153656
57
train loss item: 0.3089587688446045
58
train loss item: 0.19716528058052063
59
train loss item: 0.18740609288215637
60
train loss item: 0.8782062530517578
61
train loss item: 2.136687994003296
62
train loss item: 0.2371404469013214
63
train loss item: 0.32438790798187256
64
train loss item: 0.2003146857023239
65
train loss item: 0.5284132361412048
66
train loss item: 0.42847204208374023
67
train loss item: 0.23164093494415283
68
train loss item: 0.3013136684894562
69
train loss item: 0.3336625397205353
70
train loss item: 0.26557448506355286
71
train loss item: 0.18355822563171387
72
train loss item: 0.2110661417245865
73
train loss item: 0.31341317296028137
74
train loss item: 0.16423450410366058
75
train loss item: 0.16142284870147705
76
train loss item: 0.8835029602050781
77
train loss item: 1.2704392671585083
78
train loss item: 0.14483225345611572
79
train loss item: 0.2894853353500366
80
train loss item: 0.1747972071170807
81
train loss item: 0.2196180373430252
82
train loss item: 0.2489587515592575
83
train loss item: 0.5863135457038879
84
train loss item: 0.36387959122657776
85
train loss item: 0.5735277533531189
86
train loss item: 4.165543079376221
87
train loss item: 0.20493601262569427
88
train loss item: 0.3608943521976471
epoch train loss: 0.5003881467862076
testing phase
test loss item: 0.20565733313560486
test loss item: 0.18440738320350647
test loss item: 0.5713787078857422
test loss item: 0.24887773394584656
test loss item: 0.3095433712005615
test loss item: 0.17688076198101044
test loss item: 1.3440181016921997
test loss item: 0.43966060876846313
test loss item: 0.2286996692419052
test loss item: 0.4113355278968811
test loss item: 0.779022216796875
test loss item: 0.19517047703266144
test loss item: 0.20827892422676086
test loss item: 0.324786901473999
test loss item: 0.22489669919013977
test loss item: 0.15984244644641876
test loss item: 0.2790376842021942
test loss item: 0.5190004110336304
test loss item: 0.5993279814720154
test loss item: 0.26386183500289917
test loss item: 0.7995386123657227
test loss item: 0.36276841163635254
test loss item: 0.3231789171695709
test loss item: 0.19881178438663483
test loss item: 0.25641289353370667
test loss item: 0.2451840341091156
test loss item: 0.33720865845680237
test loss item: 0.2339548021554947
test loss item: 0.36054426431655884
test loss item: 0.3688020706176758
test loss item: 0.6658603549003601
test loss item: 0.14165356755256653
test loss item: 0.18472197651863098
test loss item: 0.6180294752120972
test loss item: 0.47675591707229614
test loss item: 0.5039797425270081
test loss item: 0.7241083383560181
test loss item: 1.2663657665252686
test loss item: 0.5098128914833069
test loss item: 0.27613943815231323
test loss item: 0.29900863766670227
test loss item: 0.227643683552742
test loss item: 0.40155380964279175
test loss item: 0.21837516129016876
test loss item: 0.6473430395126343
test loss item: 0.3931761682033539
test loss item: 0.32587864995002747
test loss item: 0.2538274824619293
test loss item: 0.4830287992954254
test loss item: 0.6299657821655273
test loss item: 0.3290084898471832
test loss item: 0.1785072237253189
test loss item: 0.2523716688156128
test loss item: 0.21184717118740082
test loss item: 0.331288605928421
test loss item: 0.8350063562393188
test loss item: 0.525157630443573
test loss item: 0.27039045095443726
test loss item: 0.2535644471645355
test loss item: 0.24618321657180786
test loss item: 0.49200043082237244
test loss item: 0.22893740236759186
test loss item: 0.21442562341690063
test loss item: 0.26607462763786316
test loss item: 0.7839096784591675
test loss item: 0.3232526481151581
test loss item: 0.3030408024787903
test loss item: 0.2738935649394989
test loss item: 0.5934074521064758
test loss item: 0.38156434893608093
test loss item: 0.15176145732402802
test loss item: 0.773078203201294
test loss item: 0.3111264109611511
test loss item: 0.35037514567375183
test loss item: 0.17970338463783264
test loss item: 0.21542349457740784
test loss item: 0.2026723474264145
test loss item: 1.2941665649414062
test loss item: 0.45810893177986145
test loss item: 0.2251637578010559
test loss item: 0.14204539358615875
test loss item: 0.8122125864028931
test loss item: 0.7699756622314453
test loss item: 0.862632691860199
test loss item: 0.24425722658634186
test loss item: 0.2534217834472656
test loss item: 0.1553940623998642
test loss item: 0.1484530121088028
test loss item: 0.27472391724586487
Epoch [28/100], Training Loss: 0.5004, Testing Loss: 0.3992
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Epoch 29/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5349361300468445
1
train loss item: 1.1977906227111816
2
train loss item: 0.24419963359832764
3
train loss item: 0.5243671536445618
4
train loss item: 0.42495083808898926
5
train loss item: 0.40097489953041077
6
train loss item: 0.25440970063209534
7
train loss item: 0.8026009202003479
8
train loss item: 0.17347434163093567
9
train loss item: 0.2641605734825134
10
train loss item: 0.35461899638175964
11
train loss item: 0.2903967797756195
12
train loss item: 0.16868039965629578
13
train loss item: 0.5153038501739502
14
train loss item: 0.35683250427246094
15
train loss item: 0.6314768195152283
16
train loss item: 0.1360928863286972
17
train loss item: 0.2850813567638397
18
train loss item: 0.36825475096702576
19
train loss item: 0.27077698707580566
20
train loss item: 0.24422180652618408
21
train loss item: 0.17317023873329163
22
train loss item: 0.913887619972229
23
train loss item: 0.8892526626586914
24
train loss item: 0.5202410817146301
25
train loss item: 0.2251719981431961
26
train loss item: 0.2373383790254593
27
train loss item: 0.3508448302745819
28
train loss item: 0.13562174141407013
29
train loss item: 0.7201632857322693
30
train loss item: 2.1382224559783936
31
train loss item: 0.5574601888656616
32
train loss item: 0.1623694747686386
33
train loss item: 0.4017472267150879
34
train loss item: 0.20763647556304932
35
train loss item: 2.3242499828338623
36
train loss item: 0.49740007519721985
37
train loss item: 0.3180808126926422
38
train loss item: 0.43838635087013245
39
train loss item: 0.36309149861335754
40
train loss item: 0.1976531594991684
41
train loss item: 0.32746705412864685
42
train loss item: 0.2607237696647644
43
train loss item: 0.21061702072620392
44
train loss item: 0.7349920868873596
45
train loss item: 0.17187094688415527
46
train loss item: 0.17272357642650604
47
train loss item: 0.33637744188308716
48
train loss item: 0.25333890318870544
49
train loss item: 0.19374516606330872
50
train loss item: 0.2814652621746063
51
train loss item: 0.854077935218811
52
train loss item: 0.14597299695014954
53
train loss item: 0.18927286565303802
54
train loss item: 2.1889231204986572
55
train loss item: 0.22973184287548065
56
train loss item: 0.32652807235717773
57
train loss item: 0.3017585277557373
58
train loss item: 0.19811972975730896
59
train loss item: 0.18271833658218384
60
train loss item: 0.868750274181366
61
train loss item: 2.114161729812622
62
train loss item: 0.2403743863105774
63
train loss item: 0.32180115580558777
64
train loss item: 0.19460347294807434
65
train loss item: 0.5305445194244385
66
train loss item: 0.4204360842704773
67
train loss item: 0.2275935411453247
68
train loss item: 0.3102075159549713
69
train loss item: 0.33379074931144714
70
train loss item: 0.2624838352203369
71
train loss item: 0.18106859922409058
72
train loss item: 0.2042929232120514
73
train loss item: 0.3143540918827057
74
train loss item: 0.1611543446779251
75
train loss item: 0.15812815725803375
76
train loss item: 0.8681063055992126
77
train loss item: 1.2645434141159058
78
train loss item: 0.14179684221744537
79
train loss item: 0.2847957909107208
80
train loss item: 0.17179802060127258
81
train loss item: 0.21417354047298431
82
train loss item: 0.24523696303367615
83
train loss item: 0.5798699855804443
84
train loss item: 0.35944026708602905
85
train loss item: 0.5598543286323547
86
train loss item: 4.136931419372559
87
train loss item: 0.19801512360572815
88
train loss item: 0.36009493470191956
epoch train loss: 0.4944316681181447
testing phase
test loss item: 0.2070438414812088
test loss item: 0.18709683418273926
test loss item: 0.5909358859062195
test loss item: 0.2538588047027588
test loss item: 0.3107812702655792
test loss item: 0.17451871931552887
test loss item: 1.3341363668441772
test loss item: 0.4335232675075531
test loss item: 0.23276758193969727
test loss item: 0.41903337836265564
test loss item: 0.8241778016090393
test loss item: 0.20500241219997406
test loss item: 0.21133305132389069
test loss item: 0.3202935755252838
test loss item: 0.22639209032058716
test loss item: 0.1618996262550354
test loss item: 0.27489691972732544
test loss item: 0.5241342782974243
test loss item: 0.5911197662353516
test loss item: 0.2587366998195648
test loss item: 0.8059337735176086
test loss item: 0.36567220091819763
test loss item: 0.3516686260700226
test loss item: 0.19700150191783905
test loss item: 0.25651147961616516
test loss item: 0.24202972650527954
test loss item: 0.33299511671066284
test loss item: 0.23479700088500977
test loss item: 0.35970818996429443
test loss item: 0.37705403566360474
test loss item: 0.6893762350082397
test loss item: 0.14630313217639923
test loss item: 0.18348726630210876
test loss item: 0.630761981010437
test loss item: 0.4835374057292938
test loss item: 0.5698115825653076
test loss item: 0.7206343412399292
test loss item: 1.3788740634918213
test loss item: 0.5162555575370789
test loss item: 0.27218255400657654
test loss item: 0.29646623134613037
test loss item: 0.2480604648590088
test loss item: 0.40996673703193665
test loss item: 0.22447635233402252
test loss item: 0.6548292636871338
test loss item: 0.38654574751853943
test loss item: 0.3549738824367523
test loss item: 0.24259041249752045
test loss item: 0.4892771542072296
test loss item: 0.6480798721313477
test loss item: 0.33731305599212646
test loss item: 0.18362189829349518
test loss item: 0.25213590264320374
test loss item: 0.2317470908164978
test loss item: 0.3355856239795685
test loss item: 0.878888726234436
test loss item: 0.5541154742240906
test loss item: 0.30311623215675354
test loss item: 0.2560438811779022
test loss item: 0.24757760763168335
test loss item: 0.503738522529602
test loss item: 0.2255105823278427
test loss item: 0.21348777413368225
test loss item: 0.2649426758289337
test loss item: 0.8256142735481262
test loss item: 0.33509600162506104
test loss item: 0.2998862564563751
test loss item: 0.2709196209907532
test loss item: 0.6119053959846497
test loss item: 0.38706764578819275
test loss item: 0.15026973187923431
test loss item: 0.7628124356269836
test loss item: 0.30831125378608704
test loss item: 0.3444127142429352
test loss item: 0.17688681185245514
test loss item: 0.24728624522686005
test loss item: 0.20062224566936493
test loss item: 1.434167504310608
test loss item: 0.4549502730369568
test loss item: 0.22683456540107727
test loss item: 0.13682305812835693
test loss item: 0.843514621257782
test loss item: 0.7767931222915649
test loss item: 0.9584622979164124
test loss item: 0.239110067486763
test loss item: 0.251342236995697
test loss item: 0.14987747371196747
test loss item: 0.1481788009405136
test loss item: 0.2215694934129715
Epoch [29/100], Training Loss: 0.4944, Testing Loss: 0.4086
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 30/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5313371419906616
1
train loss item: 1.1760380268096924
2
train loss item: 0.24085643887519836
3
train loss item: 0.5152727365493774
4
train loss item: 0.41727253794670105
5
train loss item: 0.395889014005661
6
train loss item: 0.2482752501964569
7
train loss item: 0.7959157228469849
8
train loss item: 0.16976045072078705
9
train loss item: 0.2594968378543854
10
train loss item: 0.35444211959838867
11
train loss item: 0.2886420786380768
12
train loss item: 0.16664212942123413
13
train loss item: 0.5123354196548462
14
train loss item: 0.3529771864414215
15
train loss item: 0.6176249384880066
16
train loss item: 0.13318432867527008
17
train loss item: 0.2831234335899353
18
train loss item: 0.3642755150794983
19
train loss item: 0.2637639045715332
20
train loss item: 0.23387670516967773
21
train loss item: 0.16822874546051025
22
train loss item: 0.888436496257782
23
train loss item: 0.8788237571716309
24
train loss item: 0.5073632597923279
25
train loss item: 0.22425279021263123
26
train loss item: 0.23320908844470978
27
train loss item: 0.34328046441078186
28
train loss item: 0.1326630711555481
29
train loss item: 0.7032025456428528
30
train loss item: 2.1175127029418945
31
train loss item: 0.5498104095458984
32
train loss item: 0.1604582667350769
33
train loss item: 0.40130263566970825
34
train loss item: 0.20615671575069427
35
train loss item: 2.3100385665893555
36
train loss item: 0.4963168799877167
37
train loss item: 0.31773391366004944
38
train loss item: 0.4334309995174408
39
train loss item: 0.35931897163391113
40
train loss item: 0.18797510862350464
41
train loss item: 0.32176217436790466
42
train loss item: 0.2574194073677063
43
train loss item: 0.20805686712265015
44
train loss item: 0.7289171814918518
45
train loss item: 0.17023663222789764
46
train loss item: 0.16635411977767944
47
train loss item: 0.32782718539237976
48
train loss item: 0.24949169158935547
49
train loss item: 0.19065597653388977
50
train loss item: 0.273383229970932
51
train loss item: 0.841037929058075
52
train loss item: 0.14260825514793396
53
train loss item: 0.1842070072889328
54
train loss item: 2.174640417098999
55
train loss item: 0.2249557226896286
56
train loss item: 0.3224536180496216
57
train loss item: 0.2923262417316437
58
train loss item: 0.1942482888698578
59
train loss item: 0.17725898325443268
60
train loss item: 0.8520182371139526
61
train loss item: 2.0999555587768555
62
train loss item: 0.2381620854139328
63
train loss item: 0.3148113787174225
64
train loss item: 0.1929744929075241
65
train loss item: 0.5255312323570251
66
train loss item: 0.4168151617050171
67
train loss item: 0.22355012595653534
68
train loss item: 0.30436939001083374
69
train loss item: 0.3286330997943878
70
train loss item: 0.2570585310459137
71
train loss item: 0.1764896661043167
72
train loss item: 0.20069089531898499
73
train loss item: 0.30742889642715454
74
train loss item: 0.157444566488266
75
train loss item: 0.15591803193092346
76
train loss item: 0.8588371276855469
77
train loss item: 1.2498619556427002
78
train loss item: 0.13875433802604675
79
train loss item: 0.28114646673202515
80
train loss item: 0.16736197471618652
81
train loss item: 0.21264062821865082
82
train loss item: 0.24500569701194763
83
train loss item: 0.5664152503013611
84
train loss item: 0.3612222671508789
85
train loss item: 0.5514605045318604
86
train loss item: 4.116473197937012
87
train loss item: 0.19397777318954468
88
train loss item: 0.3594522476196289
epoch train loss: 0.4881215619572093
testing phase
test loss item: 0.20372505486011505
test loss item: 0.18010543286800385
test loss item: 0.5886794924736023
test loss item: 0.24788393080234528
test loss item: 0.30097344517707825
test loss item: 0.17015206813812256
test loss item: 1.3166340589523315
test loss item: 0.4159442186355591
test loss item: 0.23122170567512512
test loss item: 0.4159086048603058
test loss item: 0.8537410497665405
test loss item: 0.20000262558460236
test loss item: 0.21037213504314423
test loss item: 0.3236949145793915
test loss item: 0.2202461063861847
test loss item: 0.15330269932746887
test loss item: 0.269655704498291
test loss item: 0.5096534490585327
test loss item: 0.5831401348114014
test loss item: 0.25759169459342957
test loss item: 0.7774743437767029
test loss item: 0.35662177205085754
test loss item: 0.3384430706501007
test loss item: 0.1928759515285492
test loss item: 0.2511277198791504
test loss item: 0.23752374947071075
test loss item: 0.32953375577926636
test loss item: 0.22794604301452637
test loss item: 0.35237231850624084
test loss item: 0.37591928243637085
test loss item: 0.7045896053314209
test loss item: 0.1407233327627182
test loss item: 0.17914460599422455
test loss item: 0.6202078461647034
test loss item: 0.4721737802028656
test loss item: 0.5862211585044861
test loss item: 0.7094642519950867
test loss item: 1.449018120765686
test loss item: 0.5067116618156433
test loss item: 0.26819613575935364
test loss item: 0.291479229927063
test loss item: 0.24200715124607086
test loss item: 0.40142354369163513
test loss item: 0.2176031917333603
test loss item: 0.6381100416183472
test loss item: 0.3760753273963928
test loss item: 0.34434136748313904
test loss item: 0.24257981777191162
test loss item: 0.4816396236419678
test loss item: 0.662281334400177
test loss item: 0.3319225609302521
test loss item: 0.18482139706611633
test loss item: 0.24795229732990265
test loss item: 0.22219401597976685
test loss item: 0.32874685525894165
test loss item: 0.8958344459533691
test loss item: 0.5654246211051941
test loss item: 0.29597601294517517
test loss item: 0.2507089078426361
test loss item: 0.2439887523651123
test loss item: 0.4993186593055725
test loss item: 0.2173587679862976
test loss item: 0.21039113402366638
test loss item: 0.2617610692977905
test loss item: 0.8305638432502747
test loss item: 0.32777121663093567
test loss item: 0.29467764496803284
test loss item: 0.26524749398231506
test loss item: 0.60540771484375
test loss item: 0.3981160819530487
test loss item: 0.14334174990653992
test loss item: 0.7425922155380249
test loss item: 0.2978670597076416
test loss item: 0.3389143645763397
test loss item: 0.17203116416931152
test loss item: 0.24176634848117828
test loss item: 0.19608710706233978
test loss item: 1.498437523841858
test loss item: 0.4517289102077484
test loss item: 0.22121664881706238
test loss item: 0.13217520713806152
test loss item: 0.8636136054992676
test loss item: 0.7783300876617432
test loss item: 1.0086097717285156
test loss item: 0.23210835456848145
test loss item: 0.24067112803459167
test loss item: 0.14150413870811462
test loss item: 0.13935323059558868
test loss item: 0.2034820020198822
Epoch [30/100], Training Loss: 0.4881, Testing Loss: 0.4062
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 31/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5260830521583557
1
train loss item: 1.1590538024902344
2
train loss item: 0.23792245984077454
3
train loss item: 0.513058602809906
4
train loss item: 0.4102801978588104
5
train loss item: 0.39101287722587585
6
train loss item: 0.24263398349285126
7
train loss item: 0.7899150252342224
8
train loss item: 0.16668272018432617
9
train loss item: 0.25784751772880554
10
train loss item: 0.35085004568099976
11
train loss item: 0.2878730595111847
12
train loss item: 0.16342580318450928
13
train loss item: 0.5089389085769653
14
train loss item: 0.3487088978290558
15
train loss item: 0.5996867418289185
16
train loss item: 0.13007968664169312
17
train loss item: 0.27957215905189514
18
train loss item: 0.35881224274635315
19
train loss item: 0.2555292546749115
20
train loss item: 0.22160604596138
21
train loss item: 0.16396717727184296
22
train loss item: 0.8669141530990601
23
train loss item: 0.8709114789962769
24
train loss item: 0.49534836411476135
25
train loss item: 0.2211586982011795
26
train loss item: 0.23003356158733368
27
train loss item: 0.33865055441856384
28
train loss item: 0.12942896783351898
29
train loss item: 0.6875120401382446
30
train loss item: 2.1025588512420654
31
train loss item: 0.5419532060623169
32
train loss item: 0.15884491801261902
33
train loss item: 0.4058440923690796
34
train loss item: 0.20377081632614136
35
train loss item: 2.296689987182617
36
train loss item: 0.49266648292541504
37
train loss item: 0.3156012296676636
38
train loss item: 0.42854636907577515
39
train loss item: 0.35502853989601135
40
train loss item: 0.18421386182308197
41
train loss item: 0.31770792603492737
42
train loss item: 0.2535788416862488
43
train loss item: 0.20616090297698975
44
train loss item: 0.7239372134208679
45
train loss item: 0.16933149099349976
46
train loss item: 0.1633027046918869
47
train loss item: 0.3168584108352661
48
train loss item: 0.24545961618423462
49
train loss item: 0.18773296475410461
50
train loss item: 0.26501592993736267
51
train loss item: 0.8294822573661804
52
train loss item: 0.13997867703437805
53
train loss item: 0.18188375234603882
54
train loss item: 2.161613702774048
55
train loss item: 0.22102615237236023
56
train loss item: 0.31880834698677063
57
train loss item: 0.2866978049278259
58
train loss item: 0.18904997408390045
59
train loss item: 0.1742350459098816
60
train loss item: 0.8355430960655212
61
train loss item: 2.0889127254486084
62
train loss item: 0.23197469115257263
63
train loss item: 0.3080366253852844
64
train loss item: 0.19331955909729004
65
train loss item: 0.5163803696632385
66
train loss item: 0.4173058867454529
67
train loss item: 0.22030265629291534
68
train loss item: 0.29234668612480164
69
train loss item: 0.3229287266731262
70
train loss item: 0.2533172070980072
71
train loss item: 0.17396587133407593
72
train loss item: 0.19834746420383453
73
train loss item: 0.3001650869846344
74
train loss item: 0.1530897468328476
75
train loss item: 0.15403972566127777
76
train loss item: 0.8513299226760864
77
train loss item: 1.2322410345077515
78
train loss item: 0.13505294919013977
79
train loss item: 0.27788904309272766
80
train loss item: 0.16327685117721558
81
train loss item: 0.2093432992696762
82
train loss item: 0.2432185709476471
83
train loss item: 0.553162693977356
84
train loss item: 0.35731345415115356
85
train loss item: 0.5465826988220215
86
train loss item: 4.097512722015381
87
train loss item: 0.1910516917705536
88
train loss item: 0.3570729196071625
epoch train loss: 0.48220339467686213
testing phase
test loss item: 0.20029082894325256
test loss item: 0.1708582043647766
test loss item: 0.5629693269729614
test loss item: 0.23939558863639832
test loss item: 0.2892729341983795
test loss item: 0.16680443286895752
test loss item: 1.31625497341156
test loss item: 0.41461196541786194
test loss item: 0.22379769384860992
test loss item: 0.4015286862850189
test loss item: 0.8179351091384888
test loss item: 0.1886512190103531
test loss item: 0.20496411621570587
test loss item: 0.31673291325569153
test loss item: 0.21193858981132507
test loss item: 0.14344488084316254
test loss item: 0.26780039072036743
test loss item: 0.4866708517074585
test loss item: 0.5839288830757141
test loss item: 0.25518107414245605
test loss item: 0.7413927912712097
test loss item: 0.3492959141731262
test loss item: 0.3106346130371094
test loss item: 0.18861086666584015
test loss item: 0.24412210285663605
test loss item: 0.2354060262441635
test loss item: 0.32439982891082764
test loss item: 0.220380038022995
test loss item: 0.3444121181964874
test loss item: 0.36425477266311646
test loss item: 0.6797666549682617
test loss item: 0.13359616696834564
test loss item: 0.17391380667686462
test loss item: 0.5948794484138489
test loss item: 0.4508216977119446
test loss item: 0.5340556502342224
test loss item: 0.701766312122345
test loss item: 1.3780529499053955
test loss item: 0.48874813318252563
test loss item: 0.2668856680393219
test loss item: 0.2894701063632965
test loss item: 0.2301684468984604
test loss item: 0.3819575905799866
test loss item: 0.20849083364009857
test loss item: 0.611754298210144
test loss item: 0.3711463510990143
test loss item: 0.3186940550804138
test loss item: 0.2391878068447113
test loss item: 0.46492841839790344
test loss item: 0.6490147113800049
test loss item: 0.31726738810539246
test loss item: 0.1804460734128952
test loss item: 0.2438989132642746
test loss item: 0.20081818103790283
test loss item: 0.31732216477394104
test loss item: 0.861681342124939
test loss item: 0.5443641543388367
test loss item: 0.26681193709373474
test loss item: 0.24318242073059082
test loss item: 0.23838797211647034
test loss item: 0.4782787561416626
test loss item: 0.21428978443145752
test loss item: 0.2081875056028366
test loss item: 0.25833573937416077
test loss item: 0.7933260202407837
test loss item: 0.31458523869514465
test loss item: 0.2903597950935364
test loss item: 0.2630015015602112
test loss item: 0.5793007612228394
test loss item: 0.3967074751853943
test loss item: 0.1389954388141632
test loss item: 0.7414960265159607
test loss item: 0.28507402539253235
test loss item: 0.3382241725921631
test loss item: 0.1703864187002182
test loss item: 0.2218332439661026
test loss item: 0.19218100607395172
test loss item: 1.3963546752929688
test loss item: 0.44162285327911377
test loss item: 0.21575883030891418
test loss item: 0.1331690400838852
test loss item: 0.832397997379303
test loss item: 0.7676748633384705
test loss item: 0.9369661211967468
test loss item: 0.22845055162906647
test loss item: 0.2387349158525467
test loss item: 0.1398671567440033
test loss item: 0.1307181864976883
test loss item: 0.2527715563774109
Epoch [31/100], Training Loss: 0.4822, Testing Loss: 0.3929
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Epoch 32/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5188525319099426
1
train loss item: 1.1445025205612183
2
train loss item: 0.23628397285938263
3
train loss item: 0.5075205564498901
4
train loss item: 0.4030161201953888
5
train loss item: 0.38422513008117676
6
train loss item: 0.240171879529953
7
train loss item: 0.7785367965698242
8
train loss item: 0.1640630066394806
9
train loss item: 0.2543337941169739
10
train loss item: 0.3390091061592102
11
train loss item: 0.2819221019744873
12
train loss item: 0.16033005714416504
13
train loss item: 0.4986560046672821
14
train loss item: 0.3415275514125824
15
train loss item: 0.5917158126831055
16
train loss item: 0.12673832476139069
17
train loss item: 0.2737438976764679
18
train loss item: 0.35437631607055664
19
train loss item: 0.2539359927177429
20
train loss item: 0.21827024221420288
21
train loss item: 0.16163916885852814
22
train loss item: 0.8525702953338623
23
train loss item: 0.8562082648277283
24
train loss item: 0.4895194470882416
25
train loss item: 0.2138088494539261
26
train loss item: 0.22639141976833344
27
train loss item: 0.3336934447288513
28
train loss item: 0.1259102076292038
29
train loss item: 0.6793858408927917
30
train loss item: 2.0807363986968994
31
train loss item: 0.5338568091392517
32
train loss item: 0.15569134056568146
33
train loss item: 0.3995838761329651
34
train loss item: 0.1992575228214264
35
train loss item: 2.281052350997925
36
train loss item: 0.48754990100860596
37
train loss item: 0.3117687702178955
38
train loss item: 0.4212348759174347
39
train loss item: 0.34943610429763794
40
train loss item: 0.1802912950515747
41
train loss item: 0.3121075928211212
42
train loss item: 0.24997679889202118
43
train loss item: 0.2035401463508606
44
train loss item: 0.7162954211235046
45
train loss item: 0.16608665883541107
46
train loss item: 0.15691561996936798
47
train loss item: 0.3133699595928192
48
train loss item: 0.24165667593479156
49
train loss item: 0.1856398582458496
50
train loss item: 0.2632913291454315
51
train loss item: 0.8215408325195312
52
train loss item: 0.13832393288612366
53
train loss item: 0.18081572651863098
54
train loss item: 2.1458849906921387
55
train loss item: 0.2191213071346283
56
train loss item: 0.31324347853660583
57
train loss item: 0.2836112678050995
58
train loss item: 0.18621541559696198
59
train loss item: 0.17449204623699188
60
train loss item: 0.8258029222488403
61
train loss item: 2.0717663764953613
62
train loss item: 0.22970303893089294
63
train loss item: 0.3051386773586273
64
train loss item: 0.1903318166732788
65
train loss item: 0.510002613067627
66
train loss item: 0.4129464328289032
67
train loss item: 0.2169272005558014
68
train loss item: 0.289451003074646
69
train loss item: 0.31828707456588745
70
train loss item: 0.253140926361084
71
train loss item: 0.173476904630661
72
train loss item: 0.1954190731048584
73
train loss item: 0.29963621497154236
74
train loss item: 0.1493278592824936
75
train loss item: 0.1509018838405609
76
train loss item: 0.8400650024414062
77
train loss item: 1.22124183177948
78
train loss item: 0.1319154053926468
79
train loss item: 0.27378031611442566
80
train loss item: 0.15977901220321655
81
train loss item: 0.202347993850708
82
train loss item: 0.23704451322555542
83
train loss item: 0.5462486147880554
84
train loss item: 0.35237598419189453
85
train loss item: 0.53934645652771
86
train loss item: 4.073721408843994
87
train loss item: 0.18590177595615387
88
train loss item: 0.34747114777565
epoch train loss: 0.4762578251656522
testing phase
test loss item: 0.200469508767128
test loss item: 0.17264202237129211
test loss item: 0.5538306832313538
test loss item: 0.23869559168815613
test loss item: 0.2895730137825012
test loss item: 0.16792629659175873
test loss item: 1.3366551399230957
test loss item: 0.43226608633995056
test loss item: 0.22085723280906677
test loss item: 0.3938288390636444
test loss item: 0.8025442957878113
test loss item: 0.18820388615131378
test loss item: 0.2014026939868927
test loss item: 0.3098489046096802
test loss item: 0.21310757100582123
test loss item: 0.14427347481250763
test loss item: 0.2697327136993408
test loss item: 0.4819960594177246
test loss item: 0.5952604413032532
test loss item: 0.2575223743915558
test loss item: 0.7357568740844727
test loss item: 0.35328149795532227
test loss item: 0.31490376591682434
test loss item: 0.1891489177942276
test loss item: 0.24199937283992767
test loss item: 0.24242323637008667
test loss item: 0.3241044878959656
test loss item: 0.22102928161621094
test loss item: 0.3474772274494171
test loss item: 0.3566943407058716
test loss item: 0.6765965223312378
test loss item: 0.13574886322021484
test loss item: 0.1735893189907074
test loss item: 0.5880115628242493
test loss item: 0.4459684193134308
test loss item: 0.5031267404556274
test loss item: 0.7057093381881714
test loss item: 1.345772624015808
test loss item: 0.4856634736061096
test loss item: 0.269523948431015
test loss item: 0.29112300276756287
test loss item: 0.24655374884605408
test loss item: 0.37195685505867004
test loss item: 0.20926204323768616
test loss item: 0.6055254936218262
test loss item: 0.3747110068798065
test loss item: 0.3225628137588501
test loss item: 0.23986169695854187
test loss item: 0.4610888361930847
test loss item: 0.6447361707687378
test loss item: 0.3121282160282135
test loss item: 0.17560532689094543
test loss item: 0.24708448350429535
test loss item: 0.19753965735435486
test loss item: 0.3176305592060089
test loss item: 0.8478329181671143
test loss item: 0.5324355959892273
test loss item: 0.2533741891384125
test loss item: 0.24121549725532532
test loss item: 0.24000725150108337
test loss item: 0.46647781133651733
test loss item: 0.2187090963125229
test loss item: 0.2109699696302414
test loss item: 0.2566725015640259
test loss item: 0.7896525859832764
test loss item: 0.3123960494995117
test loss item: 0.2910882234573364
test loss item: 0.2655809819698334
test loss item: 0.5724406242370605
test loss item: 0.38682451844215393
test loss item: 0.14212925732135773
test loss item: 0.7572669386863708
test loss item: 0.28756722807884216
test loss item: 0.3435916006565094
test loss item: 0.1730443686246872
test loss item: 0.23100081086158752
test loss item: 0.19386114180088043
test loss item: 1.377063274383545
test loss item: 0.4397399425506592
test loss item: 0.2166723906993866
test loss item: 0.1387198567390442
test loss item: 0.8283116221427917
test loss item: 0.7639460563659668
test loss item: 0.9162506461143494
test loss item: 0.23278948664665222
test loss item: 0.2534703314304352
test loss item: 0.145314559340477
test loss item: 0.12907589972019196
test loss item: 0.32991498708724976
Epoch [32/100], Training Loss: 0.4763, Testing Loss: 0.3925
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 33/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5128562450408936
1
train loss item: 1.1319243907928467
2
train loss item: 0.2341281920671463
3
train loss item: 0.49866676330566406
4
train loss item: 0.39687836170196533
5
train loss item: 0.3779330849647522
6
train loss item: 0.23757509887218475
7
train loss item: 0.7662494778633118
8
train loss item: 0.16082154214382172
9
train loss item: 0.2517063617706299
10
train loss item: 0.3299875855445862
11
train loss item: 0.27597108483314514
12
train loss item: 0.15855887532234192
13
train loss item: 0.4881228506565094
14
train loss item: 0.33563634753227234
15
train loss item: 0.5861336588859558
16
train loss item: 0.1227039024233818
17
train loss item: 0.2685817778110504
18
train loss item: 0.3506523668766022
19
train loss item: 0.2555263638496399
20
train loss item: 0.2197357416152954
21
train loss item: 0.1575496643781662
22
train loss item: 0.8392946720123291
23
train loss item: 0.8409852981567383
24
train loss item: 0.4862925410270691
25
train loss item: 0.20865540206432343
26
train loss item: 0.22193342447280884
27
train loss item: 0.3286290168762207
28
train loss item: 0.12186939269304276
29
train loss item: 0.6686302423477173
30
train loss item: 2.0599000453948975
31
train loss item: 0.5259811282157898
32
train loss item: 0.15134550631046295
33
train loss item: 0.38829103112220764
34
train loss item: 0.19517427682876587
35
train loss item: 2.265756607055664
36
train loss item: 0.4806276559829712
37
train loss item: 0.3086785078048706
38
train loss item: 0.4128119945526123
39
train loss item: 0.34321659803390503
40
train loss item: 0.181227445602417
41
train loss item: 0.3056254982948303
42
train loss item: 0.24997778236865997
43
train loss item: 0.1994536966085434
44
train loss item: 0.7072362303733826
45
train loss item: 0.16200289130210876
46
train loss item: 0.1532774567604065
47
train loss item: 0.3102996349334717
48
train loss item: 0.24051128327846527
49
train loss item: 0.18257105350494385
50
train loss item: 0.2643066346645355
51
train loss item: 0.8096592426300049
52
train loss item: 0.13433240354061127
53
train loss item: 0.17809443175792694
54
train loss item: 2.1309385299682617
55
train loss item: 0.21857191622257233
56
train loss item: 0.30792251229286194
57
train loss item: 0.2828015089035034
58
train loss item: 0.1837640404701233
59
train loss item: 0.170963853597641
60
train loss item: 0.8164368867874146
61
train loss item: 2.0537526607513428
62
train loss item: 0.22768904268741608
63
train loss item: 0.3052406311035156
64
train loss item: 0.18527649343013763
65
train loss item: 0.5031492114067078
66
train loss item: 0.4034985303878784
67
train loss item: 0.2149832546710968
68
train loss item: 0.28869566321372986
69
train loss item: 0.3167220950126648
70
train loss item: 0.25216951966285706
71
train loss item: 0.16955149173736572
72
train loss item: 0.19124220311641693
73
train loss item: 0.3002461791038513
74
train loss item: 0.14516068994998932
75
train loss item: 0.14793966710567474
76
train loss item: 0.8283860683441162
77
train loss item: 1.2117586135864258
78
train loss item: 0.12788450717926025
79
train loss item: 0.271902859210968
80
train loss item: 0.15609946846961975
81
train loss item: 0.19878773391246796
82
train loss item: 0.23017196357250214
83
train loss item: 0.540471076965332
84
train loss item: 0.35195085406303406
85
train loss item: 0.530377984046936
86
train loss item: 4.051084518432617
87
train loss item: 0.18246138095855713
88
train loss item: 0.341943621635437
epoch train loss: 0.4706128763683726
testing phase
test loss item: 0.19839955866336823
test loss item: 0.1746428906917572
test loss item: 0.5482556819915771
test loss item: 0.24261613190174103
test loss item: 0.29124075174331665
test loss item: 0.16635827720165253
test loss item: 1.3320653438568115
test loss item: 0.446428507566452
test loss item: 0.2206554263830185
test loss item: 0.393615186214447
test loss item: 0.7950920462608337
test loss item: 0.19562402367591858
test loss item: 0.2022305727005005
test loss item: 0.30570459365844727
test loss item: 0.2137976884841919
test loss item: 0.1474260687828064
test loss item: 0.2673110067844391
test loss item: 0.48434576392173767
test loss item: 0.5853413939476013
test loss item: 0.2546274960041046
test loss item: 0.7418950200080872
test loss item: 0.35610491037368774
test loss item: 0.32448214292526245
test loss item: 0.18970660865306854
test loss item: 0.24077104032039642
test loss item: 0.24001535773277283
test loss item: 0.3211670517921448
test loss item: 0.22274541854858398
test loss item: 0.34804868698120117
test loss item: 0.3567202389240265
test loss item: 0.6715419292449951
test loss item: 0.1389303207397461
test loss item: 0.17414502799510956
test loss item: 0.5886245369911194
test loss item: 0.44618508219718933
test loss item: 0.4960467517375946
test loss item: 0.7078683972358704
test loss item: 1.3261433839797974
test loss item: 0.48716843128204346
test loss item: 0.268094003200531
test loss item: 0.2897458076477051
test loss item: 0.23742744326591492
test loss item: 0.3728307783603668
test loss item: 0.2146790474653244
test loss item: 0.6091254353523254
test loss item: 0.37203243374824524
test loss item: 0.3317216634750366
test loss item: 0.23533719778060913
test loss item: 0.46031075716018677
test loss item: 0.6321293711662292
test loss item: 0.3140978217124939
test loss item: 0.17624981701374054
test loss item: 0.2473260909318924
test loss item: 0.21098899841308594
test loss item: 0.3188785910606384
test loss item: 0.834611177444458
test loss item: 0.5272827744483948
test loss item: 0.2541728615760803
test loss item: 0.24183398485183716
test loss item: 0.2411828637123108
test loss item: 0.46757760643959045
test loss item: 0.21926021575927734
test loss item: 0.20835930109024048
test loss item: 0.25582069158554077
test loss item: 0.7883990406990051
test loss item: 0.3208201825618744
test loss item: 0.289184033870697
test loss item: 0.26367512345314026
test loss item: 0.5700454115867615
test loss item: 0.37411561608314514
test loss item: 0.1413530558347702
test loss item: 0.7616453766822815
test loss item: 0.28927335143089294
test loss item: 0.3402799367904663
test loss item: 0.1688648909330368
test loss item: 0.2363981008529663
test loss item: 0.19395548105239868
test loss item: 1.3881686925888062
test loss item: 0.4371162950992584
test loss item: 0.21436327695846558
test loss item: 0.13167276978492737
test loss item: 0.816641628742218
test loss item: 0.7574387788772583
test loss item: 0.9180116653442383
test loss item: 0.23297034204006195
test loss item: 0.2479698807001114
test loss item: 0.1379881203174591
test loss item: 0.13048367202281952
test loss item: 0.24438083171844482
Epoch [33/100], Training Loss: 0.4706, Testing Loss: 0.3908
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 34/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5075811147689819
1
train loss item: 1.1166151762008667
2
train loss item: 0.22875288128852844
3
train loss item: 0.4879100024700165
4
train loss item: 0.39248907566070557
5
train loss item: 0.3725658655166626
6
train loss item: 0.23302392661571503
7
train loss item: 0.7571078538894653
8
train loss item: 0.15712696313858032
9
train loss item: 0.24633847177028656
10
train loss item: 0.32724615931510925
11
train loss item: 0.2739042639732361
12
train loss item: 0.15806889533996582
13
train loss item: 0.48047393560409546
14
train loss item: 0.3308791220188141
15
train loss item: 0.5762272477149963
16
train loss item: 0.12082131952047348
17
train loss item: 0.26587462425231934
18
train loss item: 0.3460557758808136
19
train loss item: 0.24976390600204468
20
train loss item: 0.2169056087732315
21
train loss item: 0.15363672375679016
22
train loss item: 0.8245173096656799
23
train loss item: 0.8282902836799622
24
train loss item: 0.47864481806755066
25
train loss item: 0.2059001922607422
26
train loss item: 0.21755070984363556
27
train loss item: 0.3234609365463257
28
train loss item: 0.12003996968269348
29
train loss item: 0.6548643112182617
30
train loss item: 2.0381197929382324
31
train loss item: 0.5197485685348511
32
train loss item: 0.14779728651046753
33
train loss item: 0.3817179799079895
34
train loss item: 0.19178569316864014
35
train loss item: 2.2533230781555176
36
train loss item: 0.47622254490852356
37
train loss item: 0.3072063624858856
38
train loss item: 0.4053361117839813
39
train loss item: 0.3378872871398926
40
train loss item: 0.1784837245941162
41
train loss item: 0.3007442355155945
42
train loss item: 0.24832883477210999
43
train loss item: 0.19562631845474243
44
train loss item: 0.7005308866500854
45
train loss item: 0.15841467678546906
46
train loss item: 0.1500517874956131
47
train loss item: 0.30160820484161377
48
train loss item: 0.23802681267261505
49
train loss item: 0.1784547120332718
50
train loss item: 0.2592593729496002
51
train loss item: 0.7964708209037781
52
train loss item: 0.1298466920852661
53
train loss item: 0.173132061958313
54
train loss item: 2.118187427520752
55
train loss item: 0.2133895754814148
56
train loss item: 0.30324700474739075
57
train loss item: 0.2772114872932434
58
train loss item: 0.18102139234542847
59
train loss item: 0.16599495708942413
60
train loss item: 0.7985512018203735
61
train loss item: 2.038267135620117
62
train loss item: 0.22445686161518097
63
train loss item: 0.3025033473968506
64
train loss item: 0.18188108503818512
65
train loss item: 0.497345894575119
66
train loss item: 0.3998548090457916
67
train loss item: 0.21266552805900574
68
train loss item: 0.28164535760879517
69
train loss item: 0.31238263845443726
70
train loss item: 0.24697937071323395
71
train loss item: 0.1640232801437378
72
train loss item: 0.18733185529708862
73
train loss item: 0.29434579610824585
74
train loss item: 0.14220578968524933
75
train loss item: 0.14643700420856476
76
train loss item: 0.8181494474411011
77
train loss item: 1.1983476877212524
78
train loss item: 0.1260974258184433
79
train loss item: 0.26965442299842834
80
train loss item: 0.15355128049850464
81
train loss item: 0.19726429879665375
82
train loss item: 0.2270176112651825
83
train loss item: 0.530204176902771
84
train loss item: 0.3534928560256958
85
train loss item: 0.5200077891349792
86
train loss item: 4.0318779945373535
87
train loss item: 0.18051454424858093
88
train loss item: 0.3384014666080475
epoch train loss: 0.46466596734322857
testing phase
test loss item: 0.19623427093029022
test loss item: 0.17441558837890625
test loss item: 0.5317938327789307
test loss item: 0.24079829454421997
test loss item: 0.29266026616096497
test loss item: 0.17945030331611633
test loss item: 1.3138633966445923
test loss item: 0.4413318932056427
test loss item: 0.22014746069908142
test loss item: 0.39276784658432007
test loss item: 0.7629784941673279
test loss item: 0.1924418956041336
test loss item: 0.2030012458562851
test loss item: 0.30149713158607483
test loss item: 0.21522897481918335
test loss item: 0.14454156160354614
test loss item: 0.26209336519241333
test loss item: 0.477460116147995
test loss item: 0.5729689002037048
test loss item: 0.25010716915130615
test loss item: 0.7324942350387573
test loss item: 0.348716139793396
test loss item: 0.3026723265647888
test loss item: 0.19118089973926544
test loss item: 0.2375757396221161
test loss item: 0.22849920392036438
test loss item: 0.3164747953414917
test loss item: 0.22535769641399384
test loss item: 0.34312671422958374
test loss item: 0.3563823997974396
test loss item: 0.6458637118339539
test loss item: 0.1350402981042862
test loss item: 0.17711400985717773
test loss item: 0.5789151787757874
test loss item: 0.4364926218986511
test loss item: 0.48335590958595276
test loss item: 0.7000566720962524
test loss item: 1.2576050758361816
test loss item: 0.4765591323375702
test loss item: 0.27102726697921753
test loss item: 0.2858358919620514
test loss item: 0.21008649468421936
test loss item: 0.3766063153743744
test loss item: 0.2100222408771515
test loss item: 0.5986589193344116
test loss item: 0.3642939627170563
test loss item: 0.31064629554748535
test loss item: 0.2309533953666687
test loss item: 0.4527665674686432
test loss item: 0.6066553592681885
test loss item: 0.30878746509552
test loss item: 0.17912203073501587
test loss item: 0.2395259439945221
test loss item: 0.2040245085954666
test loss item: 0.31065505743026733
test loss item: 0.800150454044342
test loss item: 0.5181326866149902
test loss item: 0.2604200839996338
test loss item: 0.2395746111869812
test loss item: 0.234741672873497
test loss item: 0.46984466910362244
test loss item: 0.21346431970596313
test loss item: 0.20392070710659027
test loss item: 0.254475861787796
test loss item: 0.7594239711761475
test loss item: 0.3158244490623474
test loss item: 0.28286322951316833
test loss item: 0.2593165934085846
test loss item: 0.5551573038101196
test loss item: 0.3710751235485077
test loss item: 0.13813361525535583
test loss item: 0.7537637948989868
test loss item: 0.29089978337287903
test loss item: 0.336703896522522
test loss item: 0.16411353647708893
test loss item: 0.206922709941864
test loss item: 0.19377349317073822
test loss item: 1.3092727661132812
test loss item: 0.431958943605423
test loss item: 0.21909397840499878
test loss item: 0.12778355181217194
test loss item: 0.7866676449775696
test loss item: 0.7449324727058411
test loss item: 0.8677387237548828
test loss item: 0.22534148395061493
test loss item: 0.22538989782333374
test loss item: 0.13039082288742065
test loss item: 0.12890855967998505
test loss item: 0.17978455126285553
Epoch [34/100], Training Loss: 0.4647, Testing Loss: 0.3809
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 35/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5001568794250488
1
train loss item: 1.1006293296813965
2
train loss item: 0.22488164901733398
3
train loss item: 0.4811978042125702
4
train loss item: 0.3886573314666748
5
train loss item: 0.36720216274261475
6
train loss item: 0.2289976328611374
7
train loss item: 0.7487974166870117
8
train loss item: 0.15394528210163116
9
train loss item: 0.2431681752204895
10
train loss item: 0.3274129331111908
11
train loss item: 0.2706473767757416
12
train loss item: 0.15515601634979248
13
train loss item: 0.47841498255729675
14
train loss item: 0.32462188601493835
15
train loss item: 0.5617005825042725
16
train loss item: 0.11932000517845154
17
train loss item: 0.2647404670715332
18
train loss item: 0.3399517834186554
19
train loss item: 0.24273939430713654
20
train loss item: 0.2097834199666977
21
train loss item: 0.15069511532783508
22
train loss item: 0.8088155388832092
23
train loss item: 0.8178110122680664
24
train loss item: 0.47049739956855774
25
train loss item: 0.20649637281894684
26
train loss item: 0.21424540877342224
27
train loss item: 0.31746718287467957
28
train loss item: 0.11858505010604858
29
train loss item: 0.640400767326355
30
train loss item: 2.018467426300049
31
train loss item: 0.5185890793800354
32
train loss item: 0.1469743251800537
33
train loss item: 0.38013923168182373
34
train loss item: 0.190788134932518
35
train loss item: 2.240586519241333
36
train loss item: 0.4720395505428314
37
train loss item: 0.30595073103904724
38
train loss item: 0.404916375875473
39
train loss item: 0.33421462774276733
40
train loss item: 0.17552055418491364
41
train loss item: 0.29479891061782837
42
train loss item: 0.24494852125644684
43
train loss item: 0.1926380842924118
44
train loss item: 0.6951777338981628
45
train loss item: 0.15608008205890656
46
train loss item: 0.14897391200065613
47
train loss item: 0.293406218290329
48
train loss item: 0.23402857780456543
49
train loss item: 0.17497806251049042
50
train loss item: 0.25247448682785034
51
train loss item: 0.7846766710281372
52
train loss item: 0.12624335289001465
53
train loss item: 0.16892801225185394
54
train loss item: 2.1046817302703857
55
train loss item: 0.20842020213603973
56
train loss item: 0.2992697060108185
57
train loss item: 0.26956743001937866
58
train loss item: 0.1778475046157837
59
train loss item: 0.16401687264442444
60
train loss item: 0.7825190424919128
61
train loss item: 2.0242395401000977
62
train loss item: 0.21804846823215485
63
train loss item: 0.29813534021377563
64
train loss item: 0.18048147857189178
65
train loss item: 0.4917982816696167
66
train loss item: 0.39736276865005493
67
train loss item: 0.20834451913833618
68
train loss item: 0.2715734839439392
69
train loss item: 0.30665507912635803
70
train loss item: 0.24688857793807983
71
train loss item: 0.1605949103832245
72
train loss item: 0.18420949578285217
73
train loss item: 0.2856072187423706
74
train loss item: 0.13958634436130524
75
train loss item: 0.14436925947666168
76
train loss item: 0.8083559274673462
77
train loss item: 1.186598539352417
78
train loss item: 0.12453265488147736
79
train loss item: 0.2652357220649719
80
train loss item: 0.15139947831630707
81
train loss item: 0.19714638590812683
82
train loss item: 0.22564134001731873
83
train loss item: 0.5207850337028503
84
train loss item: 0.3500470221042633
85
train loss item: 0.5142340660095215
86
train loss item: 4.013814449310303
87
train loss item: 0.17920136451721191
88
train loss item: 0.3406775891780853
epoch train loss: 0.4592647457055831
testing phase
test loss item: 0.19726917147636414
test loss item: 0.17341022193431854
test loss item: 0.5323925614356995
test loss item: 0.2373913675546646
test loss item: 0.2924579679965973
test loss item: 0.17479367554187775
test loss item: 1.2973318099975586
test loss item: 0.42976275086402893
test loss item: 0.22076815366744995
test loss item: 0.3908315896987915
test loss item: 0.7586882710456848
test loss item: 0.1881149709224701
test loss item: 0.1997879296541214
test loss item: 0.2978435158729553
test loss item: 0.21689794957637787
test loss item: 0.14360769093036652
test loss item: 0.2587995231151581
test loss item: 0.4778667688369751
test loss item: 0.5654703974723816
test loss item: 0.24859674274921417
test loss item: 0.735640823841095
test loss item: 0.34305310249328613
test loss item: 0.2931150496006012
test loss item: 0.19225966930389404
test loss item: 0.23654910922050476
test loss item: 0.22776024043560028
test loss item: 0.31588417291641235
test loss item: 0.22339390218257904
test loss item: 0.3419964909553528
test loss item: 0.3526409864425659
test loss item: 0.6399526596069336
test loss item: 0.13315191864967346
test loss item: 0.1777218133211136
test loss item: 0.5796144604682922
test loss item: 0.43603983521461487
test loss item: 0.4787255525588989
test loss item: 0.6894915699958801
test loss item: 1.2552615404129028
test loss item: 0.47133395075798035
test loss item: 0.2682052254676819
test loss item: 0.28334841132164
test loss item: 0.1975916475057602
test loss item: 0.37893569469451904
test loss item: 0.20459844172000885
test loss item: 0.5927211046218872
test loss item: 0.36105719208717346
test loss item: 0.2989812195301056
test loss item: 0.23144161701202393
test loss item: 0.45129016041755676
test loss item: 0.6031615734100342
test loss item: 0.3029397130012512
test loss item: 0.17975476384162903
test loss item: 0.237644761800766
test loss item: 0.1946195363998413
test loss item: 0.3109467327594757
test loss item: 0.8015275001525879
test loss item: 0.5168493986129761
test loss item: 0.26048994064331055
test loss item: 0.2384936809539795
test loss item: 0.23122510313987732
test loss item: 0.4694421887397766
test loss item: 0.21067088842391968
test loss item: 0.20497214794158936
test loss item: 0.251078724861145
test loss item: 0.7605515122413635
test loss item: 0.3090043067932129
test loss item: 0.28178754448890686
test loss item: 0.2576097249984741
test loss item: 0.5531356930732727
test loss item: 0.37264931201934814
test loss item: 0.13943082094192505
test loss item: 0.7437857985496521
test loss item: 0.2972026765346527
test loss item: 0.337999552488327
test loss item: 0.16507141292095184
test loss item: 0.19038057327270508
test loss item: 0.19530028104782104
test loss item: 1.3034512996673584
test loss item: 0.4299773573875427
test loss item: 0.21606096625328064
test loss item: 0.13293176889419556
test loss item: 0.7821709513664246
test loss item: 0.7364736199378967
test loss item: 0.8650311231613159
test loss item: 0.22564537823200226
test loss item: 0.2216140329837799
test loss item: 0.13467562198638916
test loss item: 0.12899087369441986
test loss item: 0.20415008068084717
Epoch [35/100], Training Loss: 0.4593, Testing Loss: 0.3786
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 36/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.492542028427124
1
train loss item: 1.08714759349823
2
train loss item: 0.223494291305542
3
train loss item: 0.474604994058609
4
train loss item: 0.3825683295726776
5
train loss item: 0.36255261301994324
6
train loss item: 0.22642548382282257
7
train loss item: 0.7399733066558838
8
train loss item: 0.15106254816055298
9
train loss item: 0.239913210272789
10
train loss item: 0.3195975720882416
11
train loss item: 0.26556822657585144
12
train loss item: 0.15258164703845978
13
train loss item: 0.4690186679363251
14
train loss item: 0.3186720609664917
15
train loss item: 0.5525265336036682
16
train loss item: 0.11647585034370422
17
train loss item: 0.2599825859069824
18
train loss item: 0.33364197611808777
19
train loss item: 0.24008628726005554
20
train loss item: 0.20686160027980804
21
train loss item: 0.15002655982971191
22
train loss item: 0.7962993383407593
23
train loss item: 0.8036434054374695
24
train loss item: 0.4671232998371124
25
train loss item: 0.20068950951099396
26
train loss item: 0.2095523476600647
27
train loss item: 0.3125777244567871
28
train loss item: 0.11550874263048172
29
train loss item: 0.6299864649772644
30
train loss item: 1.9984633922576904
31
train loss item: 0.5115145444869995
32
train loss item: 0.14460845291614532
33
train loss item: 0.37185242772102356
34
train loss item: 0.18565593659877777
35
train loss item: 2.2274184226989746
36
train loss item: 0.4678630530834198
37
train loss item: 0.30303680896759033
38
train loss item: 0.39838358759880066
39
train loss item: 0.3315223455429077
40
train loss item: 0.1706811636686325
41
train loss item: 0.2896001636981964
42
train loss item: 0.244760200381279
43
train loss item: 0.1901700645685196
44
train loss item: 0.689258873462677
45
train loss item: 0.15302307903766632
46
train loss item: 0.1460258662700653
47
train loss item: 0.28964975476264954
48
train loss item: 0.23114876449108124
49
train loss item: 0.1735512614250183
50
train loss item: 0.2498418390750885
51
train loss item: 0.7765340209007263
52
train loss item: 0.12301983684301376
53
train loss item: 0.16742950677871704
54
train loss item: 2.091944694519043
55
train loss item: 0.20761612057685852
56
train loss item: 0.29473602771759033
57
train loss item: 0.2669505178928375
58
train loss item: 0.17647482454776764
59
train loss item: 0.1637476533651352
60
train loss item: 0.770443856716156
61
train loss item: 2.0087969303131104
62
train loss item: 0.21546778082847595
63
train loss item: 0.2970692217350006
64
train loss item: 0.17666083574295044
65
train loss item: 0.48392319679260254
66
train loss item: 0.3928380012512207
67
train loss item: 0.20466214418411255
68
train loss item: 0.26921746134757996
69
train loss item: 0.30182814598083496
70
train loss item: 0.23933537304401398
71
train loss item: 0.159785658121109
72
train loss item: 0.18121325969696045
73
train loss item: 0.2865464985370636
74
train loss item: 0.13657446205615997
75
train loss item: 0.1412099450826645
76
train loss item: 0.797419548034668
77
train loss item: 1.1796294450759888
78
train loss item: 0.12123298645019531
79
train loss item: 0.2618025541305542
80
train loss item: 0.14782685041427612
81
train loss item: 0.193571999669075
82
train loss item: 0.22030535340309143
83
train loss item: 0.5172612071037292
84
train loss item: 0.3498755991458893
85
train loss item: 0.5100485682487488
86
train loss item: 3.9947075843811035
87
train loss item: 0.17459841072559357
88
train loss item: 0.3309786319732666
epoch train loss: 0.4539552754565571
testing phase
test loss item: 0.1982845515012741
test loss item: 0.17237606644630432
test loss item: 0.5585246086120605
test loss item: 0.23695166409015656
test loss item: 0.294723242521286
test loss item: 0.1713411808013916
test loss item: 1.298535943031311
test loss item: 0.4315907955169678
test loss item: 0.22195716202259064
test loss item: 0.3940505087375641
test loss item: 0.8071503043174744
test loss item: 0.18864867091178894
test loss item: 0.19525092840194702
test loss item: 0.29475072026252747
test loss item: 0.21734458208084106
test loss item: 0.1427459865808487
test loss item: 0.2569250464439392
test loss item: 0.49083828926086426
test loss item: 0.5797417163848877
test loss item: 0.2441888451576233
test loss item: 0.7585761547088623
test loss item: 0.34432828426361084
test loss item: 0.3143014907836914
test loss item: 0.18857772648334503
test loss item: 0.23785297572612762
test loss item: 0.22963449358940125
test loss item: 0.31330424547195435
test loss item: 0.222136452794075
test loss item: 0.34301644563674927
test loss item: 0.35347485542297363
test loss item: 0.6763917803764343
test loss item: 0.13233692944049835
test loss item: 0.1738816797733307
test loss item: 0.5952466130256653
test loss item: 0.4503396451473236
test loss item: 0.502285361289978
test loss item: 0.6880555152893066
test loss item: 1.3688431978225708
test loss item: 0.481302410364151
test loss item: 0.26373377442359924
test loss item: 0.281745046377182
test loss item: 0.22883974015712738
test loss item: 0.37902969121932983
test loss item: 0.20426523685455322
test loss item: 0.6031425595283508
test loss item: 0.35888880491256714
test loss item: 0.3164251744747162
test loss item: 0.22670818865299225
test loss item: 0.4610291123390198
test loss item: 0.6294023394584656
test loss item: 0.30481982231140137
test loss item: 0.1773408204317093
test loss item: 0.23984724283218384
test loss item: 0.19700969755649567
test loss item: 0.3174254894256592
test loss item: 0.8577541708946228
test loss item: 0.5312214493751526
test loss item: 0.25883749127388
test loss item: 0.23968394100666046
test loss item: 0.23099815845489502
test loss item: 0.475087970495224
test loss item: 0.21201583743095398
test loss item: 0.20396573841571808
test loss item: 0.2466866672039032
test loss item: 0.8110708594322205
test loss item: 0.31055495142936707
test loss item: 0.2814406454563141
test loss item: 0.2579348087310791
test loss item: 0.5707125663757324
test loss item: 0.3700995147228241
test loss item: 0.1400376409292221
test loss item: 0.7388026118278503
test loss item: 0.2961502969264984
test loss item: 0.3334933817386627
test loss item: 0.17048043012619019
test loss item: 0.21621747314929962
test loss item: 0.19363999366760254
test loss item: 1.442557692527771
test loss item: 0.43015941977500916
test loss item: 0.21690458059310913
test loss item: 0.1436942219734192
test loss item: 0.825989305973053
test loss item: 0.7423654794692993
test loss item: 0.955825924873352
test loss item: 0.22543813288211823
test loss item: 0.24296464025974274
test loss item: 0.1483956128358841
test loss item: 0.1262637823820114
test loss item: 0.3362140953540802
Epoch [36/100], Training Loss: 0.4540, Testing Loss: 0.3904
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 37/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4859509766101837
1
train loss item: 1.0747780799865723
2
train loss item: 0.2207472324371338
3
train loss item: 0.46671542525291443
4
train loss item: 0.3770987391471863
5
train loss item: 0.3567569851875305
6
train loss item: 0.2235632985830307
7
train loss item: 0.7323654294013977
8
train loss item: 0.14880086481571198
9
train loss item: 0.23569227755069733
10
train loss item: 0.3112185299396515
11
train loss item: 0.2626451551914215
12
train loss item: 0.15149365365505219
13
train loss item: 0.4579097032546997
14
train loss item: 0.3138106167316437
15
train loss item: 0.5428892374038696
16
train loss item: 0.11397460103034973
17
train loss item: 0.256307452917099
18
train loss item: 0.3276151120662689
19
train loss item: 0.2366153746843338
20
train loss item: 0.20498333871364594
21
train loss item: 0.14682617783546448
22
train loss item: 0.7813012003898621
23
train loss item: 0.7916003465652466
24
train loss item: 0.46265047788619995
25
train loss item: 0.19544389843940735
26
train loss item: 0.20523236691951752
27
train loss item: 0.309118390083313
28
train loss item: 0.11283208429813385
29
train loss item: 0.6170704364776611
30
train loss item: 1.980912685394287
31
train loss item: 0.4975181221961975
32
train loss item: 0.14167273044586182
33
train loss item: 0.36659279465675354
34
train loss item: 0.18282820284366608
35
train loss item: 2.2161786556243896
36
train loss item: 0.4625355005264282
37
train loss item: 0.3015948534011841
38
train loss item: 0.38867825269699097
39
train loss item: 0.32680320739746094
40
train loss item: 0.17136873304843903
41
train loss item: 0.2860068082809448
42
train loss item: 0.24474674463272095
43
train loss item: 0.18739767372608185
44
train loss item: 0.6836808323860168
45
train loss item: 0.14972612261772156
46
train loss item: 0.14085179567337036
47
train loss item: 0.28638720512390137
48
train loss item: 0.22808825969696045
49
train loss item: 0.17031149566173553
50
train loss item: 0.24725916981697083
51
train loss item: 0.7642329931259155
52
train loss item: 0.12020804733037949
53
train loss item: 0.16429074108600616
54
train loss item: 2.0815937519073486
55
train loss item: 0.20632435381412506
56
train loss item: 0.2897928059101105
57
train loss item: 0.26355689764022827
58
train loss item: 0.1738419085741043
59
train loss item: 0.15947511792182922
60
train loss item: 0.7601811289787292
61
train loss item: 1.9965178966522217
62
train loss item: 0.21180503070354462
63
train loss item: 0.2936038076877594
64
train loss item: 0.1739160269498825
65
train loss item: 0.47450223565101624
66
train loss item: 0.38649997115135193
67
train loss item: 0.20247827470302582
68
train loss item: 0.2653333842754364
69
train loss item: 0.3013145923614502
70
train loss item: 0.23653998970985413
71
train loss item: 0.15672455728054047
72
train loss item: 0.17805255949497223
73
train loss item: 0.2853601574897766
74
train loss item: 0.13319657742977142
75
train loss item: 0.13909412920475006
76
train loss item: 0.7882984280586243
77
train loss item: 1.1655837297439575
78
train loss item: 0.11897709220647812
79
train loss item: 0.2592858076095581
80
train loss item: 0.14475445449352264
81
train loss item: 0.18960043787956238
82
train loss item: 0.21343187987804413
83
train loss item: 0.5084632635116577
84
train loss item: 0.3481781780719757
85
train loss item: 0.5010179281234741
86
train loss item: 3.9784903526306152
87
train loss item: 0.171474426984787
88
train loss item: 0.32406073808670044
epoch train loss: 0.4484854040855772
testing phase
test loss item: 0.19145555794239044
test loss item: 0.1616939902305603
test loss item: 0.5356354117393494
test loss item: 0.23047120869159698
test loss item: 0.279893159866333
test loss item: 0.15931552648544312
test loss item: 1.2982368469238281
test loss item: 0.4457390606403351
test loss item: 0.2123824805021286
test loss item: 0.3822047710418701
test loss item: 0.7810697555541992
test loss item: 0.18156737089157104
test loss item: 0.1910475790500641
test loss item: 0.2924702763557434
test loss item: 0.20453579723834991
test loss item: 0.13571299612522125
test loss item: 0.2553565204143524
test loss item: 0.47115927934646606
test loss item: 0.5760476589202881
test loss item: 0.24022309482097626
test loss item: 0.7213467359542847
test loss item: 0.34148406982421875
test loss item: 0.3065594732761383
test loss item: 0.18263019621372223
test loss item: 0.23115526139736176
test loss item: 0.2266523689031601
test loss item: 0.30711597204208374
test loss item: 0.21237212419509888
test loss item: 0.33201470971107483
test loss item: 0.3471418619155884
test loss item: 0.6577966213226318
test loss item: 0.12511739134788513
test loss item: 0.16665545105934143
test loss item: 0.5721917748451233
test loss item: 0.43165528774261475
test loss item: 0.476563423871994
test loss item: 0.6882389783859253
test loss item: 1.3116554021835327
test loss item: 0.46655604243278503
test loss item: 0.2578834593296051
test loss item: 0.279598593711853
test loss item: 0.22316057980060577
test loss item: 0.36133965849876404
test loss item: 0.199278324842453
test loss item: 0.5797958374023438
test loss item: 0.35520631074905396
test loss item: 0.3136759400367737
test loss item: 0.22246350347995758
test loss item: 0.44607335329055786
test loss item: 0.6168009638786316
test loss item: 0.29391926527023315
test loss item: 0.17172834277153015
test loss item: 0.23577266931533813
test loss item: 0.18547993898391724
test loss item: 0.30657723546028137
test loss item: 0.8225662708282471
test loss item: 0.5180379152297974
test loss item: 0.24472540616989136
test loss item: 0.234177365899086
test loss item: 0.22603356838226318
test loss item: 0.45949414372444153
test loss item: 0.2127579152584076
test loss item: 0.19997698068618774
test loss item: 0.24364426732063293
test loss item: 0.7788432836532593
test loss item: 0.3036292791366577
test loss item: 0.27693477272987366
test loss item: 0.2519945204257965
test loss item: 0.5498671531677246
test loss item: 0.36562827229499817
test loss item: 0.12972578406333923
test loss item: 0.7424163222312927
test loss item: 0.2844293415546417
test loss item: 0.3285967707633972
test loss item: 0.16126631200313568
test loss item: 0.2182205319404602
test loss item: 0.18692132830619812
test loss item: 1.3755344152450562
test loss item: 0.4244348704814911
test loss item: 0.20462943613529205
test loss item: 0.12991972267627716
test loss item: 0.798606276512146
test loss item: 0.7346217632293701
test loss item: 0.906374454498291
test loss item: 0.22174930572509766
test loss item: 0.23525796830654144
test loss item: 0.13209111988544464
test loss item: 0.12013459205627441
test loss item: 0.2698327600955963
Epoch [37/100], Training Loss: 0.4485, Testing Loss: 0.3783
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Epoch 38/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4804050028324127
1
train loss item: 1.0623699426651
2
train loss item: 0.21732591092586517
3
train loss item: 0.4593963623046875
4
train loss item: 0.37213757634162903
5
train loss item: 0.3525116443634033
6
train loss item: 0.2202700823545456
7
train loss item: 0.7220376133918762
8
train loss item: 0.14666393399238586
9
train loss item: 0.23240190744400024
10
train loss item: 0.30777549743652344
11
train loss item: 0.2609027028083801
12
train loss item: 0.14964787662029266
13
train loss item: 0.4507302939891815
14
train loss item: 0.30873727798461914
15
train loss item: 0.5351933240890503
16
train loss item: 0.11151450872421265
17
train loss item: 0.2546055316925049
18
train loss item: 0.32489335536956787
19
train loss item: 0.2331644594669342
20
train loss item: 0.20088326930999756
21
train loss item: 0.1434088945388794
22
train loss item: 0.7673650979995728
23
train loss item: 0.7805519104003906
24
train loss item: 0.4548501670360565
25
train loss item: 0.19418177008628845
26
train loss item: 0.20309872925281525
27
train loss item: 0.3038264513015747
28
train loss item: 0.11054152250289917
29
train loss item: 0.6048926711082458
30
train loss item: 1.9604662656784058
31
train loss item: 0.4913672208786011
32
train loss item: 0.13886700570583344
33
train loss item: 0.36146461963653564
34
train loss item: 0.18121108412742615
35
train loss item: 2.204246997833252
36
train loss item: 0.4599543511867523
37
train loss item: 0.30097755789756775
38
train loss item: 0.3839413821697235
39
train loss item: 0.3215567469596863
40
train loss item: 0.16894330084323883
41
train loss item: 0.28126439452171326
42
train loss item: 0.244034543633461
43
train loss item: 0.1846083700656891
44
train loss item: 0.6760590672492981
45
train loss item: 0.1471935212612152
46
train loss item: 0.13838718831539154
47
train loss item: 0.281408429145813
48
train loss item: 0.2245478630065918
49
train loss item: 0.167275533080101
50
train loss item: 0.24392974376678467
51
train loss item: 0.7514023184776306
52
train loss item: 0.11827968806028366
53
train loss item: 0.16050496697425842
54
train loss item: 2.0689198970794678
55
train loss item: 0.20284146070480347
56
train loss item: 0.28553128242492676
57
train loss item: 0.2575661540031433
58
train loss item: 0.17026564478874207
59
train loss item: 0.1559741348028183
60
train loss item: 0.7479977011680603
61
train loss item: 1.9823815822601318
62
train loss item: 0.2071131318807602
63
train loss item: 0.2904028594493866
64
train loss item: 0.17236262559890747
65
train loss item: 0.47015613317489624
66
train loss item: 0.3846340477466583
67
train loss item: 0.20034122467041016
68
train loss item: 0.25882312655448914
69
train loss item: 0.2944088578224182
70
train loss item: 0.23358026146888733
71
train loss item: 0.1532505452632904
72
train loss item: 0.17515859007835388
73
train loss item: 0.2786168158054352
74
train loss item: 0.12967532873153687
75
train loss item: 0.1375589519739151
76
train loss item: 0.777980387210846
77
train loss item: 1.1517413854599
78
train loss item: 0.11761880666017532
79
train loss item: 0.2566870152950287
80
train loss item: 0.14329011738300323
81
train loss item: 0.18558591604232788
82
train loss item: 0.20868155360221863
83
train loss item: 0.4980524182319641
84
train loss item: 0.34760740399360657
85
train loss item: 0.4919546842575073
86
train loss item: 3.960721731185913
87
train loss item: 0.1680854856967926
88
train loss item: 0.32198119163513184
epoch train loss: 0.44321040340353934
testing phase
test loss item: 0.1908932477235794
test loss item: 0.15735936164855957
test loss item: 0.49675121903419495
test loss item: 0.2265319526195526
test loss item: 0.2714996337890625
test loss item: 0.16952870786190033
test loss item: 1.3025535345077515
test loss item: 0.4456169009208679
test loss item: 0.2059844434261322
test loss item: 0.36734911799430847
test loss item: 0.7208383679389954
test loss item: 0.17522284388542175
test loss item: 0.1908033788204193
test loss item: 0.29416555166244507
test loss item: 0.19886967539787292
test loss item: 0.13362111151218414
test loss item: 0.25466328859329224
test loss item: 0.44314277172088623
test loss item: 0.5656880140304565
test loss item: 0.24330618977546692
test loss item: 0.6764047145843506
test loss item: 0.3382970988750458
test loss item: 0.2848358452320099
test loss item: 0.18226616084575653
test loss item: 0.2245982587337494
test loss item: 0.22033549845218658
test loss item: 0.3064195215702057
test loss item: 0.21130119264125824
test loss item: 0.32387682795524597
test loss item: 0.33522918820381165
test loss item: 0.6162101626396179
test loss item: 0.12206709384918213
test loss item: 0.16529223322868347
test loss item: 0.542493999004364
test loss item: 0.40277448296546936
test loss item: 0.4474182724952698
test loss item: 0.6843073964118958
test loss item: 1.1751127243041992
test loss item: 0.4433610737323761
test loss item: 0.2628478705883026
test loss item: 0.2788058817386627
test loss item: 0.20408327877521515
test loss item: 0.3488241732120514
test loss item: 0.19474951922893524
test loss item: 0.5501954555511475
test loss item: 0.35502105951309204
test loss item: 0.29744914174079895
test loss item: 0.228469580411911
test loss item: 0.426090806722641
test loss item: 0.589190661907196
test loss item: 0.28065720200538635
test loss item: 0.16688065230846405
test loss item: 0.22868992388248444
test loss item: 0.17241206765174866
test loss item: 0.2908872961997986
test loss item: 0.7498539090156555
test loss item: 0.501298725605011
test loss item: 0.2383691668510437
test loss item: 0.22812028229236603
test loss item: 0.22144964337348938
test loss item: 0.4397715926170349
test loss item: 0.21274736523628235
test loss item: 0.20228981971740723
test loss item: 0.24402785301208496
test loss item: 0.7150534391403198
test loss item: 0.2963080406188965
test loss item: 0.2724527418613434
test loss item: 0.25047677755355835
test loss item: 0.5209253430366516
test loss item: 0.3675585389137268
test loss item: 0.12813618779182434
test loss item: 0.7485206127166748
test loss item: 0.28510555624961853
test loss item: 0.3340858519077301
test loss item: 0.15564754605293274
test loss item: 0.2029767781496048
test loss item: 0.18546214699745178
test loss item: 1.1953017711639404
test loss item: 0.42173269391059875
test loss item: 0.20752601325511932
test loss item: 0.12208721041679382
test loss item: 0.7572318315505981
test loss item: 0.7270928025245667
test loss item: 0.7914263010025024
test loss item: 0.21851889789104462
test loss item: 0.21559518575668335
test loss item: 0.1210956871509552
test loss item: 0.11948556452989578
test loss item: 0.1963866800069809
Epoch [38/100], Training Loss: 0.4432, Testing Loss: 0.3621
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 39/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4742979109287262
1
train loss item: 1.0481352806091309
2
train loss item: 0.2165054976940155
3
train loss item: 0.45619136095046997
4
train loss item: 0.3665368854999542
5
train loss item: 0.3479464650154114
6
train loss item: 0.2175174057483673
7
train loss item: 0.7106183171272278
8
train loss item: 0.14414434134960175
9
train loss item: 0.23237942159175873
10
train loss item: 0.30710339546203613
11
train loss item: 0.2550683319568634
12
train loss item: 0.14589253067970276
13
train loss item: 0.4506433606147766
14
train loss item: 0.30247172713279724
15
train loss item: 0.5288574695587158
16
train loss item: 0.10905549675226212
17
train loss item: 0.25097039341926575
18
train loss item: 0.32330191135406494
19
train loss item: 0.2321697473526001
20
train loss item: 0.19480694830417633
21
train loss item: 0.14067286252975464
22
train loss item: 0.7566101551055908
23
train loss item: 0.7689160704612732
24
train loss item: 0.44767916202545166
25
train loss item: 0.19478857517242432
26
train loss item: 0.20054864883422852
27
train loss item: 0.2974332273006439
28
train loss item: 0.10845838487148285
29
train loss item: 0.5948066711425781
30
train loss item: 1.9401506185531616
31
train loss item: 0.4931678771972656
32
train loss item: 0.13782189786434174
33
train loss item: 0.35410043597221375
34
train loss item: 0.177906796336174
35
train loss item: 2.190436601638794
36
train loss item: 0.4554363489151001
37
train loss item: 0.2961767911911011
38
train loss item: 0.38140013813972473
39
train loss item: 0.3165515959262848
40
train loss item: 0.16407868266105652
41
train loss item: 0.27559226751327515
42
train loss item: 0.2394707351922989
43
train loss item: 0.18233910202980042
44
train loss item: 0.6682969331741333
45
train loss item: 0.14673738181591034
46
train loss item: 0.1399545818567276
47
train loss item: 0.276570588350296
48
train loss item: 0.2222972810268402
49
train loss item: 0.1656951904296875
50
train loss item: 0.24018709361553192
51
train loss item: 0.742794930934906
52
train loss item: 0.11712012439966202
53
train loss item: 0.15840911865234375
54
train loss item: 2.0539493560791016
55
train loss item: 0.1986297070980072
56
train loss item: 0.2814476490020752
57
train loss item: 0.25298720598220825
58
train loss item: 0.1681387722492218
59
train loss item: 0.15546727180480957
60
train loss item: 0.7330440282821655
61
train loss item: 1.965793251991272
62
train loss item: 0.20478256046772003
63
train loss item: 0.2882041931152344
64
train loss item: 0.17034436762332916
65
train loss item: 0.4653727114200592
66
train loss item: 0.37583228945732117
67
train loss item: 0.1986621916294098
68
train loss item: 0.2530406713485718
69
train loss item: 0.2883640229701996
70
train loss item: 0.2306818813085556
71
train loss item: 0.15302349627017975
72
train loss item: 0.17318622767925262
73
train loss item: 0.2730863094329834
74
train loss item: 0.12722769379615784
75
train loss item: 0.13559751212596893
76
train loss item: 0.7663940787315369
77
train loss item: 1.1460652351379395
78
train loss item: 0.11497869342565536
79
train loss item: 0.2515256106853485
80
train loss item: 0.14193126559257507
81
train loss item: 0.18174485862255096
82
train loss item: 0.206318661570549
83
train loss item: 0.4924478232860565
84
train loss item: 0.34342366456985474
85
train loss item: 0.4895547330379486
86
train loss item: 3.940816640853882
87
train loss item: 0.16450119018554688
88
train loss item: 0.3212449550628662
epoch train loss: 0.4383711444025629
testing phase
test loss item: 0.20022690296173096
test loss item: 0.1879304051399231
test loss item: 0.5594234466552734
test loss item: 0.24001619219779968
test loss item: 0.3050588071346283
test loss item: 0.20918865501880646
test loss item: 1.2823517322540283
test loss item: 0.4327373206615448
test loss item: 0.22123779356479645
test loss item: 0.3882800042629242
test loss item: 0.8343712091445923
test loss item: 0.1902477890253067
test loss item: 0.19803020358085632
test loss item: 0.2907736599445343
test loss item: 0.23268981277942657
test loss item: 0.15306489169597626
test loss item: 0.25109508633613586
test loss item: 0.4859822392463684
test loss item: 0.5822510123252869
test loss item: 0.2367330640554428
test loss item: 0.7420032024383545
test loss item: 0.3427022695541382
test loss item: 0.3289983570575714
test loss item: 0.19150376319885254
test loss item: 0.23346737027168274
test loss item: 0.24050599336624146
test loss item: 0.3057677745819092
test loss item: 0.23467223346233368
test loss item: 0.34326377511024475
test loss item: 0.3484189212322235
test loss item: 0.6986414194107056
test loss item: 0.14552709460258484
test loss item: 0.18094828724861145
test loss item: 0.5901501774787903
test loss item: 0.4454990029335022
test loss item: 0.4979186952114105
test loss item: 0.6772946119308472
test loss item: 1.4241920709609985
test loss item: 0.4750264585018158
test loss item: 0.2768166661262512
test loss item: 0.27729520201683044
test loss item: 0.26241523027420044
test loss item: 0.3752896189689636
test loss item: 0.20086926221847534
test loss item: 0.5894644856452942
test loss item: 0.35225892066955566
test loss item: 0.3302389681339264
test loss item: 0.21596305072307587
test loss item: 0.4590071141719818
test loss item: 0.652124285697937
test loss item: 0.30532413721084595
test loss item: 0.17430995404720306
test loss item: 0.2376192957162857
test loss item: 0.19540798664093018
test loss item: 0.31568440794944763
test loss item: 0.8772408366203308
test loss item: 0.5312386751174927
test loss item: 0.27065205574035645
test loss item: 0.23888768255710602
test loss item: 0.23559284210205078
test loss item: 0.4733787178993225
test loss item: 0.21553584933280945
test loss item: 0.20348212122917175
test loss item: 0.24503418803215027
test loss item: 0.8319177627563477
test loss item: 0.3083130419254303
test loss item: 0.27660050988197327
test loss item: 0.2577780485153198
test loss item: 0.5736302733421326
test loss item: 0.376137375831604
test loss item: 0.15031489729881287
test loss item: 0.7245425581932068
test loss item: 0.2831534743309021
test loss item: 0.32208436727523804
test loss item: 0.17466385662555695
test loss item: 0.24232542514801025
test loss item: 0.19784203171730042
test loss item: 1.5023784637451172
test loss item: 0.42336416244506836
test loss item: 0.23980222642421722
test loss item: 0.15721429884433746
test loss item: 0.8491755723953247
test loss item: 0.737492024898529
test loss item: 0.9891247153282166
test loss item: 0.22601842880249023
test loss item: 0.25755205750465393
test loss item: 0.1666906327009201
test loss item: 0.12999796867370605
test loss item: 0.4048137664794922
Epoch [39/100], Training Loss: 0.4384, Testing Loss: 0.3960
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 40/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46895432472229004
1
train loss item: 1.0363181829452515
2
train loss item: 0.2127557247877121
3
train loss item: 0.44755950570106506
4
train loss item: 0.3616142272949219
5
train loss item: 0.34310969710350037
6
train loss item: 0.21431446075439453
7
train loss item: 0.7068236470222473
8
train loss item: 0.14206528663635254
9
train loss item: 0.22756613790988922
10
train loss item: 0.29713156819343567
11
train loss item: 0.2517092227935791
12
train loss item: 0.14524924755096436
13
train loss item: 0.4395621716976166
14
train loss item: 0.29666244983673096
15
train loss item: 0.517442524433136
16
train loss item: 0.10606782138347626
17
train loss item: 0.24686799943447113
18
train loss item: 0.3144192397594452
19
train loss item: 0.2276235967874527
20
train loss item: 0.19230978190898895
21
train loss item: 0.13835829496383667
22
train loss item: 0.7436214685440063
23
train loss item: 0.7578961849212646
24
train loss item: 0.4435204863548279
25
train loss item: 0.18839898705482483
26
train loss item: 0.19679734110832214
27
train loss item: 0.29519975185394287
28
train loss item: 0.1053897887468338
29
train loss item: 0.5829084515571594
30
train loss item: 1.9272236824035645
31
train loss item: 0.48049482703208923
32
train loss item: 0.1354561150074005
33
train loss item: 0.34607642889022827
34
train loss item: 0.17433221638202667
35
train loss item: 2.1821727752685547
36
train loss item: 0.4538213908672333
37
train loss item: 0.29364386200904846
38
train loss item: 0.3724689483642578
39
train loss item: 0.3114369809627533
40
train loss item: 0.16423319280147552
41
train loss item: 0.2712365388870239
42
train loss item: 0.23748406767845154
43
train loss item: 0.17966824769973755
44
train loss item: 0.6645315885543823
45
train loss item: 0.14375050365924835
46
train loss item: 0.13405095040798187
47
train loss item: 0.2749951481819153
48
train loss item: 0.2194613367319107
49
train loss item: 0.1631118357181549
50
train loss item: 0.23723189532756805
51
train loss item: 0.7295514941215515
52
train loss item: 0.11467581987380981
53
train loss item: 0.1552790105342865
54
train loss item: 2.046649932861328
55
train loss item: 0.19753852486610413
56
train loss item: 0.2766904830932617
57
train loss item: 0.24840407073497772
58
train loss item: 0.16683612763881683
59
train loss item: 0.15355916321277618
60
train loss item: 0.7230812907218933
61
train loss item: 1.955512523651123
62
train loss item: 0.19928501546382904
63
train loss item: 0.2861033082008362
64
train loss item: 0.16666661202907562
65
train loss item: 0.4555191695690155
66
train loss item: 0.37121301889419556
67
train loss item: 0.19743044674396515
68
train loss item: 0.2519890367984772
69
train loss item: 0.2823600769042969
70
train loss item: 0.22564175724983215
71
train loss item: 0.14818933606147766
72
train loss item: 0.17012427747249603
73
train loss item: 0.27220019698143005
74
train loss item: 0.1239122748374939
75
train loss item: 0.13336530327796936
76
train loss item: 0.7607352137565613
77
train loss item: 1.1348390579223633
78
train loss item: 0.11202245205640793
79
train loss item: 0.24937686324119568
80
train loss item: 0.14002250134944916
81
train loss item: 0.18009357154369354
82
train loss item: 0.20359282195568085
83
train loss item: 0.48368406295776367
84
train loss item: 0.3396027684211731
85
train loss item: 0.481054425239563
86
train loss item: 3.9282639026641846
87
train loss item: 0.16228778660297394
88
train loss item: 0.31303170323371887
epoch train loss: 0.43320770235208983
testing phase
test loss item: 0.18489065766334534
test loss item: 0.14723673462867737
test loss item: 0.4999640882015228
test loss item: 0.22282589972019196
test loss item: 0.2636684775352478
test loss item: 0.15573175251483917
test loss item: 1.3146038055419922
test loss item: 0.45633864402770996
test loss item: 0.19838722050189972
test loss item: 0.36054620146751404
test loss item: 0.7450958490371704
test loss item: 0.17354992032051086
test loss item: 0.18705925345420837
test loss item: 0.2839423716068268
test loss item: 0.1907949000597
test loss item: 0.12427400052547455
test loss item: 0.25226107239723206
test loss item: 0.4395243227481842
test loss item: 0.5704529881477356
test loss item: 0.23450666666030884
test loss item: 0.6770496368408203
test loss item: 0.3422047793865204
test loss item: 0.2838948667049408
test loss item: 0.17627276480197906
test loss item: 0.21970179677009583
test loss item: 0.22126786410808563
test loss item: 0.29718729853630066
test loss item: 0.20285217463970184
test loss item: 0.31398552656173706
test loss item: 0.32787632942199707
test loss item: 0.6415402889251709
test loss item: 0.1138429269194603
test loss item: 0.15793216228485107
test loss item: 0.5401902198791504
test loss item: 0.39974433183670044
test loss item: 0.45442846417427063
test loss item: 0.6857790946960449
test loss item: 1.2380892038345337
test loss item: 0.437839537858963
test loss item: 0.25611019134521484
test loss item: 0.27716055512428284
test loss item: 0.19979405403137207
test loss item: 0.34271684288978577
test loss item: 0.1944216638803482
test loss item: 0.5448217988014221
test loss item: 0.3500393331050873
test loss item: 0.2941700518131256
test loss item: 0.21634215116500854
test loss item: 0.4249376356601715
test loss item: 0.5950773358345032
test loss item: 0.2760685384273529
test loss item: 0.15865427255630493
test loss item: 0.22363720834255219
test loss item: 0.17132903635501862
test loss item: 0.28688570857048035
test loss item: 0.7673631310462952
test loss item: 0.5034161806106567
test loss item: 0.2444465011358261
test loss item: 0.22544856369495392
test loss item: 0.21592676639556885
test loss item: 0.42995673418045044
test loss item: 0.215901181101799
test loss item: 0.19763925671577454
test loss item: 0.2411341518163681
test loss item: 0.7462772130966187
test loss item: 0.2957020401954651
test loss item: 0.2700762152671814
test loss item: 0.2461812049150467
test loss item: 0.5213274359703064
test loss item: 0.36830195784568787
test loss item: 0.11933314055204391
test loss item: 0.7559981942176819
test loss item: 0.2703262269496918
test loss item: 0.32887303829193115
test loss item: 0.15159545838832855
test loss item: 0.19559204578399658
test loss item: 0.17950114607810974
test loss item: 1.2991260290145874
test loss item: 0.4107836186885834
test loss item: 0.19738978147506714
test loss item: 0.11883729696273804
test loss item: 0.7818861603736877
test loss item: 0.7299917340278625
test loss item: 0.8535646796226501
test loss item: 0.2114250808954239
test loss item: 0.2205171436071396
test loss item: 0.11857903003692627
test loss item: 0.11083322018384933
test loss item: 0.22736535966396332
Epoch [40/100], Training Loss: 0.4332, Testing Loss: 0.3631
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 41/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4626946747303009
1
train loss item: 1.0243228673934937
2
train loss item: 0.20985516905784607
3
train loss item: 0.4415126442909241
4
train loss item: 0.3558962047100067
5
train loss item: 0.33785319328308105
6
train loss item: 0.2118183970451355
7
train loss item: 0.6974173188209534
8
train loss item: 0.14013922214508057
9
train loss item: 0.22456054389476776
10
train loss item: 0.29385942220687866
11
train loss item: 0.24853581190109253
12
train loss item: 0.14354665577411652
13
train loss item: 0.4325934648513794
14
train loss item: 0.29056453704833984
15
train loss item: 0.5096210241317749
16
train loss item: 0.10410691052675247
17
train loss item: 0.24354730546474457
18
train loss item: 0.3108149468898773
19
train loss item: 0.22368468344211578
20
train loss item: 0.1893550455570221
21
train loss item: 0.13682492077350616
22
train loss item: 0.7325755953788757
23
train loss item: 0.7454346418380737
24
train loss item: 0.4380422830581665
25
train loss item: 0.18715590238571167
26
train loss item: 0.19301173090934753
27
train loss item: 0.28922876715660095
28
train loss item: 0.10341735929250717
29
train loss item: 0.5723134279251099
30
train loss item: 1.907177448272705
31
train loss item: 0.4753522574901581
32
train loss item: 0.13298657536506653
33
train loss item: 0.33852118253707886
34
train loss item: 0.17127197980880737
35
train loss item: 2.1701977252960205
36
train loss item: 0.44548627734184265
37
train loss item: 0.2871004343032837
38
train loss item: 0.3680839240550995
39
train loss item: 0.30597397685050964
40
train loss item: 0.16124999523162842
41
train loss item: 0.2664928436279297
42
train loss item: 0.2338831126689911
43
train loss item: 0.17741069197654724
44
train loss item: 0.6571555733680725
45
train loss item: 0.14124956727027893
46
train loss item: 0.13084889948368073
47
train loss item: 0.2697950601577759
48
train loss item: 0.2161751240491867
49
train loss item: 0.16107861697673798
50
train loss item: 0.23349478840827942
51
train loss item: 0.7227839827537537
52
train loss item: 0.11270033568143845
53
train loss item: 0.15215830504894257
54
train loss item: 2.0340070724487305
55
train loss item: 0.19524416327476501
56
train loss item: 0.27277958393096924
57
train loss item: 0.24244306981563568
58
train loss item: 0.16429460048675537
59
train loss item: 0.1498565971851349
60
train loss item: 0.7112656831741333
61
train loss item: 1.941347599029541
62
train loss item: 0.1979522705078125
63
train loss item: 0.2813683748245239
64
train loss item: 0.16420480608940125
65
train loss item: 0.4490278661251068
66
train loss item: 0.3630901575088501
67
train loss item: 0.19478219747543335
68
train loss item: 0.247928649187088
69
train loss item: 0.2804979681968689
70
train loss item: 0.22121340036392212
71
train loss item: 0.14700543880462646
72
train loss item: 0.16774439811706543
73
train loss item: 0.270209938287735
74
train loss item: 0.1215369924902916
75
train loss item: 0.1311858892440796
76
train loss item: 0.7481266856193542
77
train loss item: 1.1256815195083618
78
train loss item: 0.11001082509756088
79
train loss item: 0.24345187842845917
80
train loss item: 0.13698166608810425
81
train loss item: 0.17916609346866608
82
train loss item: 0.2002444565296173
83
train loss item: 0.4792572259902954
84
train loss item: 0.33540865778923035
85
train loss item: 0.4751255512237549
86
train loss item: 3.91092586517334
87
train loss item: 0.15920956432819366
88
train loss item: 0.3094976544380188
epoch train loss: 0.4280337944961666
testing phase
test loss item: 0.18592263758182526
test loss item: 0.15646177530288696
test loss item: 0.5200233459472656
test loss item: 0.22510284185409546
test loss item: 0.273378849029541
test loss item: 0.15740354359149933
test loss item: 1.2922000885009766
test loss item: 0.43568623065948486
test loss item: 0.2083500623703003
test loss item: 0.37021881341934204
test loss item: 0.7657344937324524
test loss item: 0.17760562896728516
test loss item: 0.19075559079647064
test loss item: 0.2814428508281708
test loss item: 0.20059621334075928
test loss item: 0.13270393013954163
test loss item: 0.24764537811279297
test loss item: 0.4527716040611267
test loss item: 0.5566579699516296
test loss item: 0.2327631264925003
test loss item: 0.6934033632278442
test loss item: 0.33675751090049744
test loss item: 0.2912631034851074
test loss item: 0.17676761746406555
test loss item: 0.22252145409584045
test loss item: 0.21976123750209808
test loss item: 0.29770758748054504
test loss item: 0.20760191977024078
test loss item: 0.3213467001914978
test loss item: 0.33522287011146545
test loss item: 0.6496772766113281
test loss item: 0.1210051029920578
test loss item: 0.1608782410621643
test loss item: 0.5537441968917847
test loss item: 0.4142841696739197
test loss item: 0.465925395488739
test loss item: 0.6772264838218689
test loss item: 1.2840094566345215
test loss item: 0.4471299350261688
test loss item: 0.251593679189682
test loss item: 0.273061066865921
test loss item: 0.19818972051143646
test loss item: 0.3518908619880676
test loss item: 0.19387921690940857
test loss item: 0.551164984703064
test loss item: 0.34278738498687744
test loss item: 0.2994978427886963
test loss item: 0.2139004021883011
test loss item: 0.43474170565605164
test loss item: 0.6022746562957764
test loss item: 0.28219759464263916
test loss item: 0.16429661214351654
test loss item: 0.22614686191082
test loss item: 0.1771637350320816
test loss item: 0.29395386576652527
test loss item: 0.7961950302124023
test loss item: 0.5099902153015137
test loss item: 0.24282127618789673
test loss item: 0.22669091820716858
test loss item: 0.22045888006687164
test loss item: 0.4470924735069275
test loss item: 0.21126201748847961
test loss item: 0.19375820457935333
test loss item: 0.23937924206256866
test loss item: 0.7632041573524475
test loss item: 0.2975599467754364
test loss item: 0.268659383058548
test loss item: 0.24526384472846985
test loss item: 0.5346429347991943
test loss item: 0.36396729946136475
test loss item: 0.12562750279903412
test loss item: 0.7333902716636658
test loss item: 0.27257269620895386
test loss item: 0.32059478759765625
test loss item: 0.15263795852661133
test loss item: 0.1990392506122589
test loss item: 0.18063871562480927
test loss item: 1.3568235635757446
test loss item: 0.4118312895298004
test loss item: 0.19814909994602203
test loss item: 0.11922033876180649
test loss item: 0.7882885932922363
test loss item: 0.7242458462715149
test loss item: 0.8869205117225647
test loss item: 0.21294961869716644
test loss item: 0.22147519886493683
test loss item: 0.11893503367900848
test loss item: 0.11637619882822037
test loss item: 0.19567342102527618
Epoch [41/100], Training Loss: 0.4280, Testing Loss: 0.3673
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 42/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4559524655342102
1
train loss item: 1.0116182565689087
2
train loss item: 0.20765230059623718
3
train loss item: 0.4355200231075287
4
train loss item: 0.35220491886138916
5
train loss item: 0.33364272117614746
6
train loss item: 0.2093811184167862
7
train loss item: 0.6902279257774353
8
train loss item: 0.13833901286125183
9
train loss item: 0.2235369235277176
10
train loss item: 0.29040050506591797
11
train loss item: 0.24668249487876892
12
train loss item: 0.14072708785533905
13
train loss item: 0.4267135262489319
14
train loss item: 0.28489118814468384
15
train loss item: 0.4998903274536133
16
train loss item: 0.10289876163005829
17
train loss item: 0.2434758096933365
18
train loss item: 0.3048444986343384
19
train loss item: 0.22166869044303894
20
train loss item: 0.18387824296951294
21
train loss item: 0.13409386575222015
22
train loss item: 0.7173938155174255
23
train loss item: 0.7367128729820251
24
train loss item: 0.43093767762184143
25
train loss item: 0.18306109309196472
26
train loss item: 0.19243068993091583
27
train loss item: 0.28458258509635925
28
train loss item: 0.1025342047214508
29
train loss item: 0.5608853101730347
30
train loss item: 1.8925840854644775
31
train loss item: 0.469182550907135
32
train loss item: 0.1323503702878952
33
train loss item: 0.3382343351840973
34
train loss item: 0.17003773152828217
35
train loss item: 2.160675525665283
36
train loss item: 0.4403766095638275
37
train loss item: 0.2855413556098938
38
train loss item: 0.3650992512702942
39
train loss item: 0.30265408754348755
40
train loss item: 0.1602717489004135
41
train loss item: 0.2627828121185303
42
train loss item: 0.23472189903259277
43
train loss item: 0.17626433074474335
44
train loss item: 0.6513401865959167
45
train loss item: 0.14056755602359772
46
train loss item: 0.13036680221557617
47
train loss item: 0.2658630609512329
48
train loss item: 0.21359951794147491
49
train loss item: 0.1578485369682312
50
train loss item: 0.23039031028747559
51
train loss item: 0.7114326357841492
52
train loss item: 0.10981222987174988
53
train loss item: 0.1489744633436203
54
train loss item: 2.0238640308380127
55
train loss item: 0.1918782740831375
56
train loss item: 0.26846444606781006
57
train loss item: 0.2385948896408081
58
train loss item: 0.1597236543893814
59
train loss item: 0.14880071580410004
60
train loss item: 0.6990835666656494
61
train loss item: 1.9300458431243896
62
train loss item: 0.1928826868534088
63
train loss item: 0.2790207862854004
64
train loss item: 0.1665256917476654
65
train loss item: 0.4439981281757355
66
train loss item: 0.35958147048950195
67
train loss item: 0.19232942163944244
68
train loss item: 0.24211840331554413
69
train loss item: 0.27883365750312805
70
train loss item: 0.2217087745666504
71
train loss item: 0.14301031827926636
72
train loss item: 0.16653762757778168
73
train loss item: 0.26428690552711487
74
train loss item: 0.11923377215862274
75
train loss item: 0.13114188611507416
76
train loss item: 0.7386126518249512
77
train loss item: 1.1114670038223267
78
train loss item: 0.10820340365171432
79
train loss item: 0.24113468825817108
80
train loss item: 0.1370302140712738
81
train loss item: 0.17499564588069916
82
train loss item: 0.19733554124832153
83
train loss item: 0.4697631597518921
84
train loss item: 0.33384445309638977
85
train loss item: 0.4677690267562866
86
train loss item: 3.896930456161499
87
train loss item: 0.15772759914398193
88
train loss item: 0.30649253726005554
epoch train loss: 0.42360362067316354
testing phase
test loss item: 0.20529566705226898
test loss item: 0.18397675454616547
test loss item: 0.5056021809577942
test loss item: 0.23559848964214325
test loss item: 0.3500553071498871
test loss item: 0.3492918014526367
test loss item: 1.3211373090744019
test loss item: 0.48692014813423157
test loss item: 0.20367605984210968
test loss item: 0.3545195758342743
test loss item: 0.738497793674469
test loss item: 0.17411629855632782
test loss item: 0.17812953889369965
test loss item: 0.27925705909729004
test loss item: 0.23280906677246094
test loss item: 0.1391240805387497
test loss item: 0.2534514367580414
test loss item: 0.4489572048187256
test loss item: 0.6092248558998108
test loss item: 0.23726868629455566
test loss item: 0.6954801678657532
test loss item: 0.34486955404281616
test loss item: 0.2948443293571472
test loss item: 0.18988506495952606
test loss item: 0.22352629899978638
test loss item: 0.24699696898460388
test loss item: 0.3039441406726837
test loss item: 0.2811749577522278
test loss item: 0.3310505151748657
test loss item: 0.32023924589157104
test loss item: 0.6509712338447571
test loss item: 0.12307190150022507
test loss item: 0.18394595384597778
test loss item: 0.5468814969062805
test loss item: 0.408314049243927
test loss item: 0.4521661698818207
test loss item: 0.6848746538162231
test loss item: 1.2404561042785645
test loss item: 0.43796300888061523
test loss item: 0.3609572947025299
test loss item: 0.27834808826446533
test loss item: 0.25445541739463806
test loss item: 0.34205400943756104
test loss item: 0.1916806697845459
test loss item: 0.5452688932418823
test loss item: 0.3582087457180023
test loss item: 0.2957534193992615
test loss item: 0.2252694070339203
test loss item: 0.42631417512893677
test loss item: 0.6106910705566406
test loss item: 0.2700144946575165
test loss item: 0.15771639347076416
test loss item: 0.2249181568622589
test loss item: 0.16664887964725494
test loss item: 0.2926003634929657
test loss item: 0.7802017331123352
test loss item: 0.5041962265968323
test loss item: 0.24421244859695435
test loss item: 0.2298087626695633
test loss item: 0.2117740511894226
test loss item: 0.4228348135948181
test loss item: 0.2256004363298416
test loss item: 0.21026788651943207
test loss item: 0.2351541668176651
test loss item: 0.7965389490127563
test loss item: 0.29088670015335083
test loss item: 0.2746393382549286
test loss item: 0.26172032952308655
test loss item: 0.523812472820282
test loss item: 0.3696943521499634
test loss item: 0.1530298888683319
test loss item: 0.7693588733673096
test loss item: 0.27738243341445923
test loss item: 0.33927351236343384
test loss item: 0.1881476789712906
test loss item: 0.23591943085193634
test loss item: 0.19776245951652527
test loss item: 1.3110442161560059
test loss item: 0.4090106189250946
test loss item: 0.34144532680511475
test loss item: 0.18953141570091248
test loss item: 0.8063337802886963
test loss item: 0.7280827164649963
test loss item: 0.844271719455719
test loss item: 0.2162247896194458
test loss item: 0.2649855315685272
test loss item: 0.20796874165534973
test loss item: 0.1239301785826683
test loss item: 0.498391717672348
Epoch [42/100], Training Loss: 0.4236, Testing Loss: 0.3835
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 43/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45311129093170166
1
train loss item: 1.001147985458374
2
train loss item: 0.20729762315750122
3
train loss item: 0.433893620967865
4
train loss item: 0.3477799594402313
5
train loss item: 0.3292338252067566
6
train loss item: 0.20741654932498932
7
train loss item: 0.685156524181366
8
train loss item: 0.13821157813072205
9
train loss item: 0.22762806713581085
10
train loss item: 0.28683990240097046
11
train loss item: 0.24072203040122986
12
train loss item: 0.14268483221530914
13
train loss item: 0.4153550863265991
14
train loss item: 0.2802288830280304
15
train loss item: 0.5020677447319031
16
train loss item: 0.10188407450914383
17
train loss item: 0.236074760556221
18
train loss item: 0.3044356405735016
19
train loss item: 0.2315339744091034
20
train loss item: 0.18862779438495636
21
train loss item: 0.1370110958814621
22
train loss item: 0.7099452614784241
23
train loss item: 0.7250020503997803
24
train loss item: 0.4357462525367737
25
train loss item: 0.18602049350738525
26
train loss item: 0.19916334748268127
27
train loss item: 0.28233763575553894
28
train loss item: 0.10065976530313492
29
train loss item: 0.5548508167266846
30
train loss item: 1.8750128746032715
31
train loss item: 0.4604586064815521
32
train loss item: 0.13296760618686676
33
train loss item: 0.32144349813461304
34
train loss item: 0.16422338783740997
35
train loss item: 2.150024175643921
36
train loss item: 0.4330739974975586
37
train loss item: 0.2777099013328552
38
train loss item: 0.36463412642478943
39
train loss item: 0.2981724739074707
40
train loss item: 0.16650083661079407
41
train loss item: 0.2592630386352539
42
train loss item: 0.2377023547887802
43
train loss item: 0.1751687228679657
44
train loss item: 0.6441261768341064
45
train loss item: 0.13660180568695068
46
train loss item: 0.1293841451406479
47
train loss item: 0.2690553069114685
48
train loss item: 0.21482284367084503
49
train loss item: 0.16371895372867584
50
train loss item: 0.2354334592819214
51
train loss item: 0.7115795612335205
52
train loss item: 0.10796964913606644
53
train loss item: 0.15095986425876617
54
train loss item: 2.01448130607605
55
train loss item: 0.19647003710269928
56
train loss item: 0.26320695877075195
57
train loss item: 0.24067921936511993
58
train loss item: 0.16712425649166107
59
train loss item: 0.1461603194475174
60
train loss item: 0.6928018927574158
61
train loss item: 1.91632878780365
62
train loss item: 0.19692620635032654
63
train loss item: 0.28714844584465027
64
train loss item: 0.1590958535671234
65
train loss item: 0.4358002841472626
66
train loss item: 0.35702988505363464
67
train loss item: 0.19481121003627777
68
train loss item: 0.24749381840229034
69
train loss item: 0.2818860709667206
70
train loss item: 0.2190530002117157
71
train loss item: 0.14456205070018768
72
train loss item: 0.1648496389389038
73
train loss item: 0.279060035943985
74
train loss item: 0.11845774203538895
75
train loss item: 0.12810955941677094
76
train loss item: 0.7300222516059875
77
train loss item: 1.113939642906189
78
train loss item: 0.10813625901937485
79
train loss item: 0.2426169216632843
80
train loss item: 0.13198408484458923
81
train loss item: 0.1780610829591751
82
train loss item: 0.19328030943870544
83
train loss item: 0.467965692281723
84
train loss item: 0.33355697989463806
85
train loss item: 0.4664662480354309
86
train loss item: 3.8816096782684326
87
train loss item: 0.15620659291744232
88
train loss item: 0.30863380432128906
epoch train loss: 0.4217538422580515
testing phase
test loss item: 0.2054622918367386
test loss item: 0.15820705890655518
test loss item: 0.5611168742179871
test loss item: 0.2352854460477829
test loss item: 0.27420616149902344
test loss item: 0.15338774025440216
test loss item: 1.3174456357955933
test loss item: 0.40278807282447815
test loss item: 0.22376097738742828
test loss item: 0.394273966550827
test loss item: 0.8624486327171326
test loss item: 0.18877074122428894
test loss item: 0.19511644542217255
test loss item: 0.27795732021331787
test loss item: 0.20323263108730316
test loss item: 0.13524571061134338
test loss item: 0.24092784523963928
test loss item: 0.47454768419265747
test loss item: 0.5593344569206238
test loss item: 0.23378422856330872
test loss item: 0.7106180191040039
test loss item: 0.33539527654647827
test loss item: 0.3153429627418518
test loss item: 0.17736758291721344
test loss item: 0.22474715113639832
test loss item: 0.232660174369812
test loss item: 0.3058202862739563
test loss item: 0.20774811506271362
test loss item: 0.3209700286388397
test loss item: 0.3539060354232788
test loss item: 0.7229856252670288
test loss item: 0.12967874109745026
test loss item: 0.162107452750206
test loss item: 0.5763111710548401
test loss item: 0.4358074367046356
test loss item: 0.5421254634857178
test loss item: 0.6739468574523926
test loss item: 1.468421220779419
test loss item: 0.4692903161048889
test loss item: 0.24796831607818604
test loss item: 0.2709648907184601
test loss item: 0.21554087102413177
test loss item: 0.35878050327301025
test loss item: 0.2024325728416443
test loss item: 0.5604758262634277
test loss item: 0.33523476123809814
test loss item: 0.3110063076019287
test loss item: 0.22756989300251007
test loss item: 0.45581743121147156
test loss item: 0.665855884552002
test loss item: 0.2954210937023163
test loss item: 0.17124299705028534
test loss item: 0.23072433471679688
test loss item: 0.20379282534122467
test loss item: 0.3071034550666809
test loss item: 0.8927258253097534
test loss item: 0.547046422958374
test loss item: 0.23362773656845093
test loss item: 0.22872358560562134
test loss item: 0.22670572996139526
test loss item: 0.4824327826499939
test loss item: 0.20365773141384125
test loss item: 0.21785962581634521
test loss item: 0.237993061542511
test loss item: 0.8254975080490112
test loss item: 0.3166118264198303
test loss item: 0.2694277763366699
test loss item: 0.23995475471019745
test loss item: 0.5536748766899109
test loss item: 0.39439234137535095
test loss item: 0.1247127428650856
test loss item: 0.7159069180488586
test loss item: 0.27500447630882263
test loss item: 0.3274679183959961
test loss item: 0.14766736328601837
test loss item: 0.21126733720302582
test loss item: 0.17998050153255463
test loss item: 1.5593082904815674
test loss item: 0.4143299460411072
test loss item: 0.21500246226787567
test loss item: 0.11494424194097519
test loss item: 0.8689091801643372
test loss item: 0.7480685710906982
test loss item: 1.0305100679397583
test loss item: 0.21779492497444153
test loss item: 0.22155018150806427
test loss item: 0.11188988387584686
test loss item: 0.11581668257713318
test loss item: 0.2524418830871582
Epoch [43/100], Training Loss: 0.4218, Testing Loss: 0.3870
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 44/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4508027136325836
1
train loss item: 0.999000072479248
2
train loss item: 0.20760709047317505
3
train loss item: 0.44866880774497986
4
train loss item: 0.35405367612838745
5
train loss item: 0.3342975676059723
6
train loss item: 0.20535613596439362
7
train loss item: 0.6804107427597046
8
train loss item: 0.1390565186738968
9
train loss item: 0.22676947712898254
10
train loss item: 0.2903115749359131
11
train loss item: 0.2557845711708069
12
train loss item: 0.1384337693452835
13
train loss item: 0.4405352473258972
14
train loss item: 0.2811514437198639
15
train loss item: 0.48061394691467285
16
train loss item: 0.09972620010375977
17
train loss item: 0.2406216263771057
18
train loss item: 0.3011449873447418
19
train loss item: 0.21707554161548615
20
train loss item: 0.1752866804599762
21
train loss item: 0.13467346131801605
22
train loss item: 0.6893659830093384
23
train loss item: 0.7270300388336182
24
train loss item: 0.420576810836792
25
train loss item: 0.190579354763031
26
train loss item: 0.19833138585090637
27
train loss item: 0.2814110815525055
28
train loss item: 0.09942542761564255
29
train loss item: 0.5471789240837097
30
train loss item: 1.8848909139633179
31
train loss item: 0.4684608280658722
32
train loss item: 0.1362355798482895
33
train loss item: 0.34774482250213623
34
train loss item: 0.16672316193580627
35
train loss item: 2.150082588195801
36
train loss item: 0.4712611436843872
37
train loss item: 0.29793882369995117
38
train loss item: 0.3791899085044861
39
train loss item: 0.30540940165519714
40
train loss item: 0.15869835019111633
41
train loss item: 0.26738524436950684
42
train loss item: 0.2547486126422882
43
train loss item: 0.17708943784236908
44
train loss item: 0.6451442241668701
45
train loss item: 0.1454087793827057
46
train loss item: 0.13329088687896729
47
train loss item: 0.2617611587047577
48
train loss item: 0.21117131412029266
49
train loss item: 0.16160805523395538
50
train loss item: 0.22495755553245544
51
train loss item: 0.700077474117279
52
train loss item: 0.10639651864767075
53
train loss item: 0.15166594088077545
54
train loss item: 2.009784698486328
55
train loss item: 0.18951526284217834
56
train loss item: 0.27120301127433777
57
train loss item: 0.23375171422958374
58
train loss item: 0.15636061131954193
59
train loss item: 0.14902792870998383
60
train loss item: 0.6906746625900269
61
train loss item: 1.9154324531555176
62
train loss item: 0.18822668492794037
63
train loss item: 0.27806276082992554
64
train loss item: 0.17079974710941315
65
train loss item: 0.43396463990211487
66
train loss item: 0.38289883732795715
67
train loss item: 0.19562971591949463
68
train loss item: 0.23092862963676453
69
train loss item: 0.2823529541492462
70
train loss item: 0.23359765112400055
71
train loss item: 0.13932682573795319
72
train loss item: 0.16934606432914734
73
train loss item: 0.2617255747318268
74
train loss item: 0.11653929203748703
75
train loss item: 0.1303904503583908
76
train loss item: 0.7422719597816467
77
train loss item: 1.0826629400253296
78
train loss item: 0.10565660148859024
79
train loss item: 0.24466143548488617
80
train loss item: 0.13733860850334167
81
train loss item: 0.18389885127544403
82
train loss item: 0.1997695416212082
83
train loss item: 0.45648741722106934
84
train loss item: 0.3676348030567169
85
train loss item: 0.4699791967868805
86
train loss item: 3.8786251544952393
87
train loss item: 0.15834176540374756
88
train loss item: 0.3049585819244385
epoch train loss: 0.42274661362171173
testing phase
test loss item: 0.1836363524198532
test loss item: 0.14450211822986603
test loss item: 0.4604107737541199
test loss item: 0.2209703028202057
test loss item: 0.26528477668762207
test loss item: 0.19411683082580566
test loss item: 1.3236154317855835
test loss item: 0.4537288248538971
test loss item: 0.1871921271085739
test loss item: 0.34408944845199585
test loss item: 0.6797719597816467
test loss item: 0.16197136044502258
test loss item: 0.1828709989786148
test loss item: 0.2703418731689453
test loss item: 0.18753281235694885
test loss item: 0.11495981365442276
test loss item: 0.2440415620803833
test loss item: 0.41257819533348083
test loss item: 0.5594576597213745
test loss item: 0.22794082760810852
test loss item: 0.634705126285553
test loss item: 0.3318285346031189
test loss item: 0.2590925693511963
test loss item: 0.17867816984653473
test loss item: 0.2086055725812912
test loss item: 0.21942636370658875
test loss item: 0.2845577001571655
test loss item: 0.21037665009498596
test loss item: 0.29963400959968567
test loss item: 0.31322386860847473
test loss item: 0.6069492697715759
test loss item: 0.1033162847161293
test loss item: 0.16368231177330017
test loss item: 0.5112670660018921
test loss item: 0.37092551589012146
test loss item: 0.4287048280239105
test loss item: 0.672953188419342
test loss item: 1.1140172481536865
test loss item: 0.41270911693573
test loss item: 0.27177152037620544
test loss item: 0.2705965042114258
test loss item: 0.1897912174463272
test loss item: 0.32934823632240295
test loss item: 0.18602395057678223
test loss item: 0.5108718276023865
test loss item: 0.33830612897872925
test loss item: 0.2696862518787384
test loss item: 0.20892013609409332
test loss item: 0.4009643495082855
test loss item: 0.5583469867706299
test loss item: 0.2607155442237854
test loss item: 0.1510164737701416
test loss item: 0.21628989279270172
test loss item: 0.15541638433933258
test loss item: 0.2728806138038635
test loss item: 0.6938107013702393
test loss item: 0.4863664507865906
test loss item: 0.22445055842399597
test loss item: 0.21663248538970947
test loss item: 0.20997236669063568
test loss item: 0.40603023767471313
test loss item: 0.20918729901313782
test loss item: 0.19807308912277222
test loss item: 0.23373019695281982
test loss item: 0.6841306686401367
test loss item: 0.2878303825855255
test loss item: 0.2641197144985199
test loss item: 0.23637397587299347
test loss item: 0.4910212457180023
test loss item: 0.3594421148300171
test loss item: 0.11530578881502151
test loss item: 0.752953052520752
test loss item: 0.2609165608882904
test loss item: 0.3258785307407379
test loss item: 0.1455969214439392
test loss item: 0.17381484806537628
test loss item: 0.17701908946037292
test loss item: 1.1521875858306885
test loss item: 0.3892776668071747
test loss item: 0.21867001056671143
test loss item: 0.11918896436691284
test loss item: 0.7453020811080933
test loss item: 0.7103500366210938
test loss item: 0.7603123784065247
test loss item: 0.20813298225402832
test loss item: 0.19951418042182922
test loss item: 0.1151813268661499
test loss item: 0.10830552130937576
test loss item: 0.21334697306156158
Epoch [44/100], Training Loss: 0.4227, Testing Loss: 0.3464
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Epoch 45/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4433554708957672
1
train loss item: 0.9805322885513306
2
train loss item: 0.20422665774822235
3
train loss item: 0.42859214544296265
4
train loss item: 0.34011927247047424
5
train loss item: 0.3234212100505829
6
train loss item: 0.2001689374446869
7
train loss item: 0.6661006212234497
8
train loss item: 0.13344456255435944
9
train loss item: 0.21797852218151093
10
train loss item: 0.28360453248023987
11
train loss item: 0.23753777146339417
12
train loss item: 0.13921822607517242
13
train loss item: 0.41433918476104736
14
train loss item: 0.27228736877441406
15
train loss item: 0.48904839158058167
16
train loss item: 0.09814827889204025
17
train loss item: 0.23166237771511078
18
train loss item: 0.2976832985877991
19
train loss item: 0.22746412456035614
20
train loss item: 0.18223527073860168
21
train loss item: 0.1337364763021469
22
train loss item: 0.6930748224258423
23
train loss item: 0.7083001732826233
24
train loss item: 0.4205113351345062
25
train loss item: 0.19229604303836823
26
train loss item: 0.18430458009243011
27
train loss item: 0.27190902829170227
28
train loss item: 0.09724793583154678
29
train loss item: 0.5372992753982544
30
train loss item: 1.8429311513900757
31
train loss item: 0.46743905544281006
32
train loss item: 0.12853176891803741
33
train loss item: 0.3250633180141449
34
train loss item: 0.16171878576278687
35
train loss item: 2.1297192573547363
36
train loss item: 0.42942553758621216
37
train loss item: 0.27866289019584656
38
train loss item: 0.3743879199028015
39
train loss item: 0.29087141156196594
40
train loss item: 0.15720605850219727
41
train loss item: 0.25099092721939087
42
train loss item: 0.23573057353496552
43
train loss item: 0.1685837060213089
44
train loss item: 0.6338744759559631
45
train loss item: 0.13853341341018677
46
train loss item: 0.13028086721897125
47
train loss item: 0.2620556354522705
48
train loss item: 0.20930081605911255
49
train loss item: 0.1567366123199463
50
train loss item: 0.22639314830303192
51
train loss item: 0.7024110555648804
52
train loss item: 0.10533380508422852
53
train loss item: 0.1473715454339981
54
train loss item: 1.9931588172912598
55
train loss item: 0.1885898858308792
56
train loss item: 0.2593041956424713
57
train loss item: 0.2288532257080078
58
train loss item: 0.15835419297218323
59
train loss item: 0.1449737548828125
60
train loss item: 0.6690506935119629
61
train loss item: 1.893715739250183
62
train loss item: 0.19871722161769867
63
train loss item: 0.2801804542541504
64
train loss item: 0.15542824566364288
65
train loss item: 0.42778870463371277
66
train loss item: 0.3524704873561859
67
train loss item: 0.18963143229484558
68
train loss item: 0.24440301954746246
69
train loss item: 0.2731773555278778
70
train loss item: 0.21326716244220734
71
train loss item: 0.1462680846452713
72
train loss item: 0.15885774791240692
73
train loss item: 0.2642097771167755
74
train loss item: 0.11535520106554031
75
train loss item: 0.12497320026159286
76
train loss item: 0.7143412232398987
77
train loss item: 1.0985004901885986
78
train loss item: 0.10427478700876236
79
train loss item: 0.23421894013881683
80
train loss item: 0.13082650303840637
81
train loss item: 0.1730320155620575
82
train loss item: 0.19080397486686707
83
train loss item: 0.4562312364578247
84
train loss item: 0.3314014971256256
85
train loss item: 0.46395352482795715
86
train loss item: 3.8517916202545166
87
train loss item: 0.15223060548305511
88
train loss item: 0.30253130197525024
epoch train loss: 0.4144749240426535
testing phase
test loss item: 0.18435214459896088
test loss item: 0.1525951623916626
test loss item: 0.564020574092865
test loss item: 0.2268933653831482
test loss item: 0.2850991487503052
test loss item: 0.1547057032585144
test loss item: 1.3486578464508057
test loss item: 0.4534853994846344
test loss item: 0.2075304538011551
test loss item: 0.3726080358028412
test loss item: 0.8511563539505005
test loss item: 0.18203216791152954
test loss item: 0.1842295229434967
test loss item: 0.26561424136161804
test loss item: 0.20345336198806763
test loss item: 0.1284901201725006
test loss item: 0.2450442612171173
test loss item: 0.4809413254261017
test loss item: 0.5665704607963562
test loss item: 0.228980153799057
test loss item: 0.7433526515960693
test loss item: 0.3468504548072815
test loss item: 0.32124048471450806
test loss item: 0.1700066775083542
test loss item: 0.22279398143291473
test loss item: 0.217926487326622
test loss item: 0.2908940315246582
test loss item: 0.21199247241020203
test loss item: 0.32620421051979065
test loss item: 0.3279138505458832
test loss item: 0.738210916519165
test loss item: 0.11907920986413956
test loss item: 0.15359711647033691
test loss item: 0.6027786731719971
test loss item: 0.4390472173690796
test loss item: 0.5034415125846863
test loss item: 0.6832410097122192
test loss item: 1.5047690868377686
test loss item: 0.46743243932724
test loss item: 0.24890413880348206
test loss item: 0.2726649045944214
test loss item: 0.21023084223270416
test loss item: 0.3660339415073395
test loss item: 0.19957685470581055
test loss item: 0.5691993832588196
test loss item: 0.34312641620635986
test loss item: 0.32214754819869995
test loss item: 0.20755204558372498
test loss item: 0.4569959342479706
test loss item: 0.6486563682556152
test loss item: 0.2840568423271179
test loss item: 0.1514490842819214
test loss item: 0.2307194322347641
test loss item: 0.1930341273546219
test loss item: 0.3051036596298218
test loss item: 0.906532347202301
test loss item: 0.5347332954406738
test loss item: 0.2478945404291153
test loss item: 0.22397057712078094
test loss item: 0.22396989166736603
test loss item: 0.45765432715415955
test loss item: 0.21544647216796875
test loss item: 0.1932203322649002
test loss item: 0.23324070870876312
test loss item: 0.8829811811447144
test loss item: 0.3082004189491272
test loss item: 0.27096202969551086
test loss item: 0.24399743974208832
test loss item: 0.5791592001914978
test loss item: 0.35947075486183167
test loss item: 0.12567031383514404
test loss item: 0.7588972449302673
test loss item: 0.27967604994773865
test loss item: 0.32249876856803894
test loss item: 0.15402589738368988
test loss item: 0.21671411395072937
test loss item: 0.17664065957069397
test loss item: 1.6428738832473755
test loss item: 0.4045431315898895
test loss item: 0.20097143948078156
test loss item: 0.1269548088312149
test loss item: 0.8710001707077026
test loss item: 0.7424576282501221
test loss item: 1.0700477361679077
test loss item: 0.21813035011291504
test loss item: 0.23785758018493652
test loss item: 0.12573085725307465
test loss item: 0.11011701822280884
test loss item: 0.253610759973526
Epoch [45/100], Training Loss: 0.4145, Testing Loss: 0.3888
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 46/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.43675464391708374
1
train loss item: 0.9668343663215637
2
train loss item: 0.2017124891281128
3
train loss item: 0.41915178298950195
4
train loss item: 0.3362285792827606
5
train loss item: 0.3159821331501007
6
train loss item: 0.19873911142349243
7
train loss item: 0.662796676158905
8
train loss item: 0.1329500377178192
9
train loss item: 0.21610382199287415
10
train loss item: 0.2748703956604004
11
train loss item: 0.23333558440208435
12
train loss item: 0.1398194283246994
13
train loss item: 0.40029293298721313
14
train loss item: 0.2673446834087372
15
train loss item: 0.49134448170661926
16
train loss item: 0.09687690436840057
17
train loss item: 0.23056349158287048
18
train loss item: 0.29100170731544495
19
train loss item: 0.23069988191127777
20
train loss item: 0.1861494779586792
21
train loss item: 0.13387376070022583
22
train loss item: 0.6890031695365906
23
train loss item: 0.6989412307739258
24
train loss item: 0.42031553387641907
25
train loss item: 0.1803704798221588
26
train loss item: 0.18305610120296478
27
train loss item: 0.26990583539009094
28
train loss item: 0.09592549502849579
29
train loss item: 0.5287996530532837
30
train loss item: 1.8321105241775513
31
train loss item: 0.4454497694969177
32
train loss item: 0.1257227659225464
33
train loss item: 0.31400564312934875
34
train loss item: 0.15944541990756989
35
train loss item: 2.1241095066070557
36
train loss item: 0.41968756914138794
37
train loss item: 0.2746429741382599
38
train loss item: 0.3617364466190338
39
train loss item: 0.2865319848060608
40
train loss item: 0.16047066450119019
41
train loss item: 0.24651633203029633
42
train loss item: 0.2353488802909851
43
train loss item: 0.16682571172714233
44
train loss item: 0.6293706893920898
45
train loss item: 0.13261738419532776
46
train loss item: 0.13050641119480133
47
train loss item: 0.2640030086040497
48
train loss item: 0.20642907917499542
49
train loss item: 0.15285693109035492
50
train loss item: 0.22703664004802704
51
train loss item: 0.6981111168861389
52
train loss item: 0.10469188541173935
53
train loss item: 0.14332151412963867
54
train loss item: 1.9874886274337769
55
train loss item: 0.19018076360225677
56
train loss item: 0.25148266553878784
57
train loss item: 0.2258961796760559
58
train loss item: 0.16052281856536865
59
train loss item: 0.13739900290966034
60
train loss item: 0.664413332939148
61
train loss item: 1.8864638805389404
62
train loss item: 0.19447200000286102
63
train loss item: 0.2820098400115967
64
train loss item: 0.15285493433475494
65
train loss item: 0.42509493231773376
66
train loss item: 0.3446696102619171
67
train loss item: 0.1911984533071518
68
train loss item: 0.24635949730873108
69
train loss item: 0.27526822686195374
70
train loss item: 0.21479560434818268
71
train loss item: 0.1409793645143509
72
train loss item: 0.15759244561195374
73
train loss item: 0.2633849084377289
74
train loss item: 0.11327559500932693
75
train loss item: 0.1240067407488823
76
train loss item: 0.7050366401672363
77
train loss item: 1.0916513204574585
78
train loss item: 0.103314608335495
79
train loss item: 0.23424296081066132
80
train loss item: 0.1275939643383026
81
train loss item: 0.17401023209095
82
train loss item: 0.18244746327400208
83
train loss item: 0.45169973373413086
84
train loss item: 0.3273647129535675
85
train loss item: 0.4509160816669464
86
train loss item: 3.842654228210449
87
train loss item: 0.15153715014457703
88
train loss item: 0.3021014332771301
epoch train loss: 0.4106255357017678
testing phase
test loss item: 0.18107375502586365
test loss item: 0.1540721356868744
test loss item: 0.519173264503479
test loss item: 0.22461484372615814
test loss item: 0.27486884593963623
test loss item: 0.1556464433670044
test loss item: 1.2668417692184448
test loss item: 0.41249826550483704
test loss item: 0.1987474411725998
test loss item: 0.3550775647163391
test loss item: 0.7925753593444824
test loss item: 0.17719987034797668
test loss item: 0.17660753428936005
test loss item: 0.26771119236946106
test loss item: 0.20103663206100464
test loss item: 0.1274862140417099
test loss item: 0.23856744170188904
test loss item: 0.4482528865337372
test loss item: 0.5359386801719666
test loss item: 0.22061188519001007
test loss item: 0.6895617842674255
test loss item: 0.3336702585220337
test loss item: 0.2916839122772217
test loss item: 0.1722472757101059
test loss item: 0.21447572112083435
test loss item: 0.2105327695608139
test loss item: 0.2846284806728363
test loss item: 0.20873166620731354
test loss item: 0.31756290793418884
test loss item: 0.3188270926475525
test loss item: 0.6740860342979431
test loss item: 0.11865191906690598
test loss item: 0.15819241106510162
test loss item: 0.5573310852050781
test loss item: 0.4081667959690094
test loss item: 0.4943484961986542
test loss item: 0.6495640873908997
test loss item: 1.3720479011535645
test loss item: 0.4380415976047516
test loss item: 0.24566683173179626
test loss item: 0.26772841811180115
test loss item: 0.1935712695121765
test loss item: 0.34362635016441345
test loss item: 0.19372954964637756
test loss item: 0.5341888666152954
test loss item: 0.3295273184776306
test loss item: 0.2970508635044098
test loss item: 0.20705826580524445
test loss item: 0.4262085556983948
test loss item: 0.6076478958129883
test loss item: 0.2657308280467987
test loss item: 0.15097318589687347
test loss item: 0.22161750495433807
test loss item: 0.18501396477222443
test loss item: 0.2874973714351654
test loss item: 0.8135930895805359
test loss item: 0.5126764178276062
test loss item: 0.2252805233001709
test loss item: 0.21613404154777527
test loss item: 0.2117176502943039
test loss item: 0.4356207251548767
test loss item: 0.20762664079666138
test loss item: 0.18757647275924683
test loss item: 0.22635021805763245
test loss item: 0.7787602543830872
test loss item: 0.3004133999347687
test loss item: 0.25962385535240173
test loss item: 0.2361677885055542
test loss item: 0.5393137335777283
test loss item: 0.3482367992401123
test loss item: 0.11948665976524353
test loss item: 0.7111383676528931
test loss item: 0.27432119846343994
test loss item: 0.31035834550857544
test loss item: 0.14494915306568146
test loss item: 0.19845575094223022
test loss item: 0.17686837911605835
test loss item: 1.479372262954712
test loss item: 0.3995864689350128
test loss item: 0.19627608358860016
test loss item: 0.11277671903371811
test loss item: 0.7963410019874573
test loss item: 0.7037158608436584
test loss item: 0.9583587050437927
test loss item: 0.20951426029205322
test loss item: 0.22441215813159943
test loss item: 0.11305507272481918
test loss item: 0.10949857532978058
test loss item: 0.18941359221935272
Epoch [46/100], Training Loss: 0.4106, Testing Loss: 0.3654
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 47/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4312313497066498
1
train loss item: 0.9542676210403442
2
train loss item: 0.1956409066915512
3
train loss item: 0.4087262749671936
4
train loss item: 0.3333628475666046
5
train loss item: 0.313831090927124
6
train loss item: 0.1945158690214157
7
train loss item: 0.6594948768615723
8
train loss item: 0.1296927034854889
9
train loss item: 0.21289023756980896
10
train loss item: 0.2736184895038605
11
train loss item: 0.2335505336523056
12
train loss item: 0.13636337220668793
13
train loss item: 0.400145560503006
14
train loss item: 0.26549169421195984
15
train loss item: 0.47071215510368347
16
train loss item: 0.09620894491672516
17
train loss item: 0.2296110987663269
18
train loss item: 0.28520262241363525
19
train loss item: 0.2210165560245514
20
train loss item: 0.1746400147676468
21
train loss item: 0.12793198227882385
22
train loss item: 0.6617608070373535
23
train loss item: 0.6955181956291199
24
train loss item: 0.41054609417915344
25
train loss item: 0.17420388758182526
26
train loss item: 0.18041794002056122
27
train loss item: 0.2684418559074402
28
train loss item: 0.09558908641338348
29
train loss item: 0.510471761226654
30
train loss item: 1.8285812139511108
31
train loss item: 0.4409473240375519
32
train loss item: 0.1265603005886078
33
train loss item: 0.3195056617259979
34
train loss item: 0.16003099083900452
35
train loss item: 2.11848783493042
36
train loss item: 0.4249756634235382
37
train loss item: 0.27524298429489136
38
train loss item: 0.3443814516067505
39
train loss item: 0.28342458605766296
40
train loss item: 0.15487146377563477
41
train loss item: 0.24473543465137482
42
train loss item: 0.23383089900016785
43
train loss item: 0.16526052355766296
44
train loss item: 0.6268099546432495
45
train loss item: 0.13704374432563782
46
train loss item: 0.12619803845882416
47
train loss item: 0.25393059849739075
48
train loss item: 0.20160284638404846
49
train loss item: 0.1506665050983429
50
train loss item: 0.21907390654087067
51
train loss item: 0.6695515513420105
52
train loss item: 0.10300295054912567
53
train loss item: 0.141402006149292
54
train loss item: 1.9817578792572021
55
train loss item: 0.18547439575195312
56
train loss item: 0.2498200684785843
57
train loss item: 0.22488129138946533
58
train loss item: 0.15310555696487427
59
train loss item: 0.13688549399375916
60
train loss item: 0.6512396931648254
61
train loss item: 1.8805532455444336
62
train loss item: 0.18691518902778625
63
train loss item: 0.2725347578525543
64
train loss item: 0.1555023193359375
65
train loss item: 0.4172990322113037
66
train loss item: 0.34409812092781067
67
train loss item: 0.18739905953407288
68
train loss item: 0.23117798566818237
69
train loss item: 0.2634241580963135
70
train loss item: 0.21079526841640472
71
train loss item: 0.13669495284557343
72
train loss item: 0.15467716753482819
73
train loss item: 0.25301575660705566
74
train loss item: 0.1111900731921196
75
train loss item: 0.12386419624090195
76
train loss item: 0.6981915831565857
77
train loss item: 1.0647550821304321
78
train loss item: 0.10157022625207901
79
train loss item: 0.2302102893590927
80
train loss item: 0.12897729873657227
81
train loss item: 0.16891589760780334
82
train loss item: 0.18274889886379242
83
train loss item: 0.43590399622917175
84
train loss item: 0.3282279372215271
85
train loss item: 0.4410227835178375
86
train loss item: 3.836176872253418
87
train loss item: 0.15124979615211487
88
train loss item: 0.2947269082069397
epoch train loss: 0.4052831246779206
testing phase
test loss item: 0.1794809252023697
test loss item: 0.13618916273117065
test loss item: 0.45240068435668945
test loss item: 0.21291397511959076
test loss item: 0.24505701661109924
test loss item: 0.1431158483028412
test loss item: 1.2282397747039795
test loss item: 0.40140417218208313
test loss item: 0.18306481838226318
test loss item: 0.33129432797431946
test loss item: 0.6737436652183533
test loss item: 0.15993747115135193
test loss item: 0.16802538931369781
test loss item: 0.27162760496139526
test loss item: 0.17838826775550842
test loss item: 0.11258415132761002
test loss item: 0.23432400822639465
test loss item: 0.40207144618034363
test loss item: 0.525082528591156
test loss item: 0.21563169360160828
test loss item: 0.6200540065765381
test loss item: 0.31987425684928894
test loss item: 0.2538616955280304
test loss item: 0.16306546330451965
test loss item: 0.20307379961013794
test loss item: 0.20374995470046997
test loss item: 0.27549368143081665
test loss item: 0.1885303407907486
test loss item: 0.2927826941013336
test loss item: 0.3041718602180481
test loss item: 0.5825455784797668
test loss item: 0.10408405214548111
test loss item: 0.14894631505012512
test loss item: 0.4981350898742676
test loss item: 0.3637843728065491
test loss item: 0.4316498637199402
test loss item: 0.6319020986557007
test loss item: 1.1153695583343506
test loss item: 0.39916229248046875
test loss item: 0.23757043480873108
test loss item: 0.2645280063152313
test loss item: 0.17447035014629364
test loss item: 0.3129444420337677
test loss item: 0.18238747119903564
test loss item: 0.4961116313934326
test loss item: 0.3191353380680084
test loss item: 0.2638927698135376
test loss item: 0.2076696902513504
test loss item: 0.3861613869667053
test loss item: 0.5451294779777527
test loss item: 0.2473945915699005
test loss item: 0.14762982726097107
test loss item: 0.21145294606685638
test loss item: 0.15584562718868256
test loss item: 0.26495322585105896
test loss item: 0.6846594214439392
test loss item: 0.46894609928131104
test loss item: 0.22188463807106018
test loss item: 0.20709234476089478
test loss item: 0.19695769250392914
test loss item: 0.3963586688041687
test loss item: 0.20088709890842438
test loss item: 0.18818405270576477
test loss item: 0.22061987221240997
test loss item: 0.6531289219856262
test loss item: 0.28334227204322815
test loss item: 0.24913541972637177
test loss item: 0.22760719060897827
test loss item: 0.48032209277153015
test loss item: 0.3419259190559387
test loss item: 0.10428141057491302
test loss item: 0.6945523619651794
test loss item: 0.264834463596344
test loss item: 0.3056674897670746
test loss item: 0.13780294358730316
test loss item: 0.17103311419487
test loss item: 0.16535939276218414
test loss item: 1.1552693843841553
test loss item: 0.38892561197280884
test loss item: 0.18687091767787933
test loss item: 0.10395687073469162
test loss item: 0.7042015194892883
test loss item: 0.6737312078475952
test loss item: 0.758329451084137
test loss item: 0.20031212270259857
test loss item: 0.2004392296075821
test loss item: 0.10430587083101273
test loss item: 0.10014749318361282
test loss item: 0.1831764131784439
Epoch [47/100], Training Loss: 0.4053, Testing Loss: 0.3325
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 48/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4283329248428345
1
train loss item: 0.9489777088165283
2
train loss item: 0.1943981945514679
3
train loss item: 0.405178427696228
4
train loss item: 0.329916387796402
5
train loss item: 0.310667484998703
6
train loss item: 0.19382697343826294
7
train loss item: 0.6523448824882507
8
train loss item: 0.12923942506313324
9
train loss item: 0.20870231091976166
10
train loss item: 0.27133750915527344
11
train loss item: 0.23587508499622345
12
train loss item: 0.1355450600385666
13
train loss item: 0.3987972140312195
14
train loss item: 0.26205477118492126
15
train loss item: 0.46073830127716064
16
train loss item: 0.09353455901145935
17
train loss item: 0.22805844247341156
18
train loss item: 0.2842887043952942
19
train loss item: 0.21217890083789825
20
train loss item: 0.17155912518501282
21
train loss item: 0.12685160338878632
22
train loss item: 0.6475264430046082
23
train loss item: 0.685725212097168
24
train loss item: 0.4037404954433441
25
train loss item: 0.17723916471004486
26
train loss item: 0.17808307707309723
27
train loss item: 0.2641656696796417
28
train loss item: 0.09279735386371613
29
train loss item: 0.506779134273529
30
train loss item: 1.8170616626739502
31
train loss item: 0.4499104619026184
32
train loss item: 0.1254044622182846
33
train loss item: 0.31252092123031616
34
train loss item: 0.15837836265563965
35
train loss item: 2.1088168621063232
36
train loss item: 0.4330344796180725
37
train loss item: 0.2712404131889343
38
train loss item: 0.348225474357605
39
train loss item: 0.27982357144355774
40
train loss item: 0.15174975991249084
41
train loss item: 0.24122828245162964
42
train loss item: 0.22913521528244019
43
train loss item: 0.1632281243801117
44
train loss item: 0.621906578540802
45
train loss item: 0.13265393674373627
46
train loss item: 0.12134295701980591
47
train loss item: 0.25087353587150574
48
train loss item: 0.19642367959022522
49
train loss item: 0.1494665890932083
50
train loss item: 0.21367162466049194
51
train loss item: 0.6560415625572205
52
train loss item: 0.1000455990433693
53
train loss item: 0.1399637758731842
54
train loss item: 1.9716992378234863
55
train loss item: 0.18097038567066193
56
train loss item: 0.2488071769475937
57
train loss item: 0.2210066020488739
58
train loss item: 0.14938804507255554
59
train loss item: 0.1372777223587036
60
train loss item: 0.6369401216506958
61
train loss item: 1.8679859638214111
62
train loss item: 0.18309946358203888
63
train loss item: 0.26656174659729004
64
train loss item: 0.15373753011226654
65
train loss item: 0.40992724895477295
66
train loss item: 0.34486374258995056
67
train loss item: 0.1806739866733551
68
train loss item: 0.22414550185203552
69
train loss item: 0.25889644026756287
70
train loss item: 0.2125861644744873
71
train loss item: 0.1369359791278839
72
train loss item: 0.15331099927425385
73
train loss item: 0.25072574615478516
74
train loss item: 0.11195817589759827
75
train loss item: 0.12267093360424042
76
train loss item: 0.6884108781814575
77
train loss item: 1.0525493621826172
78
train loss item: 0.09815213084220886
79
train loss item: 0.22511617839336395
80
train loss item: 0.12687253952026367
81
train loss item: 0.16598287224769592
82
train loss item: 0.18159694969654083
83
train loss item: 0.4275389313697815
84
train loss item: 0.33157625794410706
85
train loss item: 0.4358101785182953
86
train loss item: 3.824146032333374
87
train loss item: 0.1454268842935562
88
train loss item: 0.2896818220615387
epoch train loss: 0.4014341390032447
testing phase
test loss item: 0.17868639528751373
test loss item: 0.1320018470287323
test loss item: 0.4652763903141022
test loss item: 0.21189582347869873
test loss item: 0.24469715356826782
test loss item: 0.1397899091243744
test loss item: 1.306066632270813
test loss item: 0.44015610218048096
test loss item: 0.18439123034477234
test loss item: 0.33627986907958984
test loss item: 0.6870825290679932
test loss item: 0.15786930918693542
test loss item: 0.17166933417320251
test loss item: 0.2678317129611969
test loss item: 0.17424322664737701
test loss item: 0.10977406799793243
test loss item: 0.2356233149766922
test loss item: 0.40756911039352417
test loss item: 0.550695538520813
test loss item: 0.21866433322429657
test loss item: 0.6277130842208862
test loss item: 0.32772570848464966
test loss item: 0.2609020471572876
test loss item: 0.1606852412223816
test loss item: 0.20291942358016968
test loss item: 0.20482569932937622
test loss item: 0.27498963475227356
test loss item: 0.1866523176431656
test loss item: 0.29145774245262146
test loss item: 0.30469635128974915
test loss item: 0.6056983470916748
test loss item: 0.10087519139051437
test loss item: 0.14458850026130676
test loss item: 0.5055575370788574
test loss item: 0.3696368336677551
test loss item: 0.4327702820301056
test loss item: 0.6592415571212769
test loss item: 1.1427556276321411
test loss item: 0.4041202962398529
test loss item: 0.23945936560630798
test loss item: 0.26678699254989624
test loss item: 0.17770147323608398
test loss item: 0.31854817271232605
test loss item: 0.18360769748687744
test loss item: 0.498716801404953
test loss item: 0.3236137330532074
test loss item: 0.26874929666519165
test loss item: 0.20626898109912872
test loss item: 0.39780908823013306
test loss item: 0.5600215792655945
test loss item: 0.2496928572654724
test loss item: 0.14572905004024506
test loss item: 0.2129317820072174
test loss item: 0.15365682542324066
test loss item: 0.26732945442199707
test loss item: 0.6984928250312805
test loss item: 0.48039811849594116
test loss item: 0.2200399935245514
test loss item: 0.20756927132606506
test loss item: 0.20052218437194824
test loss item: 0.3998958468437195
test loss item: 0.20616072416305542
test loss item: 0.18858784437179565
test loss item: 0.2230132818222046
test loss item: 0.6774595975875854
test loss item: 0.2847445011138916
test loss item: 0.25146737694740295
test loss item: 0.23043261468410492
test loss item: 0.49105483293533325
test loss item: 0.35136690735816956
test loss item: 0.10628875344991684
test loss item: 0.7356058359146118
test loss item: 0.263247549533844
test loss item: 0.31155598163604736
test loss item: 0.1413649469614029
test loss item: 0.17546376585960388
test loss item: 0.1631416529417038
test loss item: 1.191375732421875
test loss item: 0.38935691118240356
test loss item: 0.18671536445617676
test loss item: 0.11260002851486206
test loss item: 0.7427542805671692
test loss item: 0.7000377178192139
test loss item: 0.7840399742126465
test loss item: 0.20098081231117249
test loss item: 0.20317526161670685
test loss item: 0.11485569924116135
test loss item: 0.09646130353212357
test loss item: 0.22575828433036804
Epoch [48/100], Training Loss: 0.4014, Testing Loss: 0.3399
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 49/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4220765233039856
1
train loss item: 0.9355813264846802
2
train loss item: 0.19298017024993896
3
train loss item: 0.40097707509994507
4
train loss item: 0.32511886954307556
5
train loss item: 0.30534595251083374
6
train loss item: 0.18994338810443878
7
train loss item: 0.6436801552772522
8
train loss item: 0.12716689705848694
9
train loss item: 0.2061363160610199
10
train loss item: 0.266826868057251
11
train loss item: 0.2298412173986435
12
train loss item: 0.13415555655956268
13
train loss item: 0.3933088481426239
14
train loss item: 0.25639215111732483
15
train loss item: 0.45540663599967957
16
train loss item: 0.09180286526679993
17
train loss item: 0.2227686643600464
18
train loss item: 0.27976176142692566
19
train loss item: 0.20815183222293854
20
train loss item: 0.1699548363685608
21
train loss item: 0.12430375814437866
22
train loss item: 0.6388735175132751
23
train loss item: 0.6752133369445801
24
train loss item: 0.40118804574012756
25
train loss item: 0.17597998678684235
26
train loss item: 0.17548274993896484
27
train loss item: 0.25849419832229614
28
train loss item: 0.09100925177335739
29
train loss item: 0.5018585920333862
30
train loss item: 1.7987533807754517
31
train loss item: 0.4447536766529083
32
train loss item: 0.12069875746965408
33
train loss item: 0.303305059671402
34
train loss item: 0.15410681068897247
35
train loss item: 2.0990500450134277
36
train loss item: 0.4202103912830353
37
train loss item: 0.2615150511264801
38
train loss item: 0.3417963981628418
39
train loss item: 0.2752580940723419
40
train loss item: 0.15025340020656586
41
train loss item: 0.23498345911502838
42
train loss item: 0.2261725217103958
43
train loss item: 0.16142548620700836
44
train loss item: 0.6166999936103821
45
train loss item: 0.12844645977020264
46
train loss item: 0.1187933087348938
47
train loss item: 0.24509458243846893
48
train loss item: 0.19597883522510529
49
train loss item: 0.14755932986736298
50
train loss item: 0.21252775192260742
51
train loss item: 0.652052640914917
52
train loss item: 0.09903742372989655
53
train loss item: 0.13775715231895447
54
train loss item: 1.96261727809906
55
train loss item: 0.1800282895565033
56
train loss item: 0.24331945180892944
57
train loss item: 0.21548010408878326
58
train loss item: 0.14861391484737396
59
train loss item: 0.1364143341779709
60
train loss item: 0.6267837882041931
61
train loss item: 1.8559647798538208
62
train loss item: 0.18325062096118927
63
train loss item: 0.26481765508651733
64
train loss item: 0.15049222111701965
65
train loss item: 0.4030205011367798
66
train loss item: 0.3318166136741638
67
train loss item: 0.17817296087741852
68
train loss item: 0.2260902225971222
69
train loss item: 0.2562108337879181
70
train loss item: 0.20561043918132782
71
train loss item: 0.13594552874565125
72
train loss item: 0.15073636174201965
73
train loss item: 0.24995671212673187
74
train loss item: 0.11077097803354263
75
train loss item: 0.12040915340185165
76
train loss item: 0.6809468865394592
77
train loss item: 1.0525760650634766
78
train loss item: 0.09653032571077347
79
train loss item: 0.2185211032629013
80
train loss item: 0.12275714427232742
81
train loss item: 0.16228660941123962
82
train loss item: 0.18033722043037415
83
train loss item: 0.420937180519104
84
train loss item: 0.32125362753868103
85
train loss item: 0.4326624572277069
86
train loss item: 3.8098621368408203
87
train loss item: 0.14348582923412323
88
train loss item: 0.28610697388648987
epoch train loss: 0.39675053552295386
testing phase
test loss item: 0.17556707561016083
test loss item: 0.13776463270187378
test loss item: 0.5184394717216492
test loss item: 0.2178906798362732
test loss item: 0.2585521936416626
test loss item: 0.14122074842453003
test loss item: 1.3574658632278442
test loss item: 0.45823413133621216
test loss item: 0.19620919227600098
test loss item: 0.35520121455192566
test loss item: 0.777979850769043
test loss item: 0.17070333659648895
test loss item: 0.18121129274368286
test loss item: 0.2654195725917816
test loss item: 0.1814490705728531
test loss item: 0.11787047237157822
test loss item: 0.23622697591781616
test loss item: 0.4362255334854126
test loss item: 0.5607587695121765
test loss item: 0.22519451379776
test loss item: 0.6705659031867981
test loss item: 0.33808591961860657
test loss item: 0.29173657298088074
test loss item: 0.16177695989608765
test loss item: 0.2094561755657196
test loss item: 0.2054525762796402
test loss item: 0.28049615025520325
test loss item: 0.19576722383499146
test loss item: 0.3015880882740021
test loss item: 0.3123635947704315
test loss item: 0.6742313504219055
test loss item: 0.10975182801485062
test loss item: 0.14407244324684143
test loss item: 0.5449613332748413
test loss item: 0.4004136621952057
test loss item: 0.48431381583213806
test loss item: 0.6781029105186462
test loss item: 1.3265280723571777
test loss item: 0.42975515127182007
test loss item: 0.24232876300811768
test loss item: 0.26791471242904663
test loss item: 0.19082461297512054
test loss item: 0.33931928873062134
test loss item: 0.19238367676734924
test loss item: 0.5223868489265442
test loss item: 0.32907089591026306
test loss item: 0.29701071977615356
test loss item: 0.20805038511753082
test loss item: 0.43068549036979675
test loss item: 0.6109421253204346
test loss item: 0.26204240322113037
test loss item: 0.14697925746440887
test loss item: 0.2187201827764511
test loss item: 0.17518837749958038
test loss item: 0.2836463451385498
test loss item: 0.7851628661155701
test loss item: 0.5120740532875061
test loss item: 0.22645607590675354
test loss item: 0.21189609169960022
test loss item: 0.21267098188400269
test loss item: 0.42598021030426025
test loss item: 0.2115902602672577
test loss item: 0.18615767359733582
test loss item: 0.2289493978023529
test loss item: 0.7569736838340759
test loss item: 0.29763227701187134
test loss item: 0.2568734288215637
test loss item: 0.23336075246334076
test loss item: 0.533995509147644
test loss item: 0.3614521622657776
test loss item: 0.11052537709474564
test loss item: 0.7569143772125244
test loss item: 0.27210596203804016
test loss item: 0.31443294882774353
test loss item: 0.1395730823278427
test loss item: 0.19191160798072815
test loss item: 0.1654694825410843
test loss item: 1.4254473447799683
test loss item: 0.4003446102142334
test loss item: 0.18793518841266632
test loss item: 0.10448718816041946
test loss item: 0.8275271654129028
test loss item: 0.7282240986824036
test loss item: 0.9409163594245911
test loss item: 0.20618805289268494
test loss item: 0.21123769879341125
test loss item: 0.10449876636266708
test loss item: 0.09987962990999222
test loss item: 0.1879379153251648
Epoch [49/100], Training Loss: 0.3968, Testing Loss: 0.3625
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 50/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41462400555610657
1
train loss item: 0.9227582216262817
2
train loss item: 0.19036881625652313
3
train loss item: 0.39408913254737854
4
train loss item: 0.3228859603404999
5
train loss item: 0.29992467164993286
6
train loss item: 0.18642836809158325
7
train loss item: 0.6361663341522217
8
train loss item: 0.12481171637773514
9
train loss item: 0.20558904111385345
10
train loss item: 0.26205286383628845
11
train loss item: 0.22795620560646057
12
train loss item: 0.13198326528072357
13
train loss item: 0.38583147525787354
14
train loss item: 0.2516941726207733
15
train loss item: 0.45190033316612244
16
train loss item: 0.08956870436668396
17
train loss item: 0.21904510259628296
18
train loss item: 0.2743333578109741
19
train loss item: 0.2059837281703949
20
train loss item: 0.16555869579315186
21
train loss item: 0.12124413251876831
22
train loss item: 0.632095456123352
23
train loss item: 0.6672000288963318
24
train loss item: 0.3918991982936859
25
train loss item: 0.16995972394943237
26
train loss item: 0.17532728612422943
27
train loss item: 0.2546178102493286
28
train loss item: 0.08918239176273346
29
train loss item: 0.49385949969291687
30
train loss item: 1.7859352827072144
31
train loss item: 0.4260386824607849
32
train loss item: 0.11824639141559601
33
train loss item: 0.2973405718803406
34
train loss item: 0.1502378135919571
35
train loss item: 2.093550205230713
36
train loss item: 0.4079265594482422
37
train loss item: 0.2579866647720337
38
train loss item: 0.3308252990245819
39
train loss item: 0.2717237174510956
40
train loss item: 0.14851360023021698
41
train loss item: 0.23263432085514069
42
train loss item: 0.22885100543498993
43
train loss item: 0.1594046652317047
44
train loss item: 0.6115933060646057
45
train loss item: 0.12656338512897491
46
train loss item: 0.12062037736177444
47
train loss item: 0.24188050627708435
48
train loss item: 0.19631612300872803
49
train loss item: 0.14537765085697174
50
train loss item: 0.21040955185890198
51
train loss item: 0.6511297225952148
52
train loss item: 0.09628652036190033
53
train loss item: 0.1344079077243805
54
train loss item: 1.9571655988693237
55
train loss item: 0.17951029539108276
56
train loss item: 0.2378753125667572
57
train loss item: 0.21366727352142334
58
train loss item: 0.14711961150169373
59
train loss item: 0.1341482698917389
60
train loss item: 0.6210787892341614
61
train loss item: 1.8472474813461304
62
train loss item: 0.17890223860740662
63
train loss item: 0.2662416696548462
64
train loss item: 0.14864109456539154
65
train loss item: 0.39641866087913513
66
train loss item: 0.3290063738822937
67
train loss item: 0.1778867095708847
68
train loss item: 0.220357745885849
69
train loss item: 0.25200292468070984
70
train loss item: 0.20157575607299805
71
train loss item: 0.13364998996257782
72
train loss item: 0.14897280931472778
73
train loss item: 0.24506667256355286
74
train loss item: 0.10682375729084015
75
train loss item: 0.11979491263628006
76
train loss item: 0.6734769940376282
77
train loss item: 1.0439165830612183
78
train loss item: 0.09461162984371185
79
train loss item: 0.21912994980812073
80
train loss item: 0.12149678170681
81
train loss item: 0.1617133915424347
82
train loss item: 0.17675986886024475
83
train loss item: 0.4167919456958771
84
train loss item: 0.3163435161113739
85
train loss item: 0.4218112826347351
86
train loss item: 3.8004283905029297
87
train loss item: 0.1420886516571045
88
train loss item: 0.281692773103714
epoch train loss: 0.3925410700815447
testing phase
test loss item: 0.17503084242343903
test loss item: 0.13731610774993896
test loss item: 0.5120452642440796
test loss item: 0.21868449449539185
test loss item: 0.25405722856521606
test loss item: 0.14140264689922333
test loss item: 1.3002502918243408
test loss item: 0.4409514367580414
test loss item: 0.19119593501091003
test loss item: 0.3470795452594757
test loss item: 0.7736783027648926
test loss item: 0.17530620098114014
test loss item: 0.17932771146297455
test loss item: 0.2637840807437897
test loss item: 0.17986661195755005
test loss item: 0.11969760805368423
test loss item: 0.23046521842479706
test loss item: 0.4274712800979614
test loss item: 0.5434810519218445
test loss item: 0.22076523303985596
test loss item: 0.6542259454727173
test loss item: 0.3314436972141266
test loss item: 0.2821477949619293
test loss item: 0.1600760668516159
test loss item: 0.206643745303154
test loss item: 0.20472751557826996
test loss item: 0.27734875679016113
test loss item: 0.19127719104290009
test loss item: 0.2957817316055298
test loss item: 0.3070039749145508
test loss item: 0.6618109941482544
test loss item: 0.11096028983592987
test loss item: 0.14330434799194336
test loss item: 0.5386523604393005
test loss item: 0.3933227062225342
test loss item: 0.4902515709400177
test loss item: 0.6557140946388245
test loss item: 1.326411247253418
test loss item: 0.4220796525478363
test loss item: 0.23788611590862274
test loss item: 0.2626205086708069
test loss item: 0.1859116107225418
test loss item: 0.3306116461753845
test loss item: 0.19265776872634888
test loss item: 0.5096880197525024
test loss item: 0.31914398074150085
test loss item: 0.28741979598999023
test loss item: 0.20461510121822357
test loss item: 0.42199522256851196
test loss item: 0.6021066904067993
test loss item: 0.2549581825733185
test loss item: 0.14659325778484344
test loss item: 0.21277748048305511
test loss item: 0.18393592536449432
test loss item: 0.27799391746520996
test loss item: 0.7847025990486145
test loss item: 0.5067967176437378
test loss item: 0.22875605523586273
test loss item: 0.2094140350818634
test loss item: 0.2074827253818512
test loss item: 0.4182963967323303
test loss item: 0.2074047178030014
test loss item: 0.1840832382440567
test loss item: 0.22527742385864258
test loss item: 0.7502838373184204
test loss item: 0.300258994102478
test loss item: 0.2505297064781189
test loss item: 0.22898919880390167
test loss item: 0.5277635455131531
test loss item: 0.3495892286300659
test loss item: 0.11006584018468857
test loss item: 0.7246252298355103
test loss item: 0.26925891637802124
test loss item: 0.30565470457077026
test loss item: 0.13658356666564941
test loss item: 0.18305177986621857
test loss item: 0.16338194906711578
test loss item: 1.4327956438064575
test loss item: 0.39463120698928833
test loss item: 0.18698179721832275
test loss item: 0.10229868441820145
test loss item: 0.8097543716430664
test loss item: 0.7068479061126709
test loss item: 0.9425249099731445
test loss item: 0.2021738737821579
test loss item: 0.20707190036773682
test loss item: 0.103066086769104
test loss item: 0.10187207162380219
test loss item: 0.18930386006832123
Epoch [50/100], Training Loss: 0.3925, Testing Loss: 0.3569
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 51/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4101209342479706
1
train loss item: 0.9116258025169373
2
train loss item: 0.187142014503479
3
train loss item: 0.3888017237186432
4
train loss item: 0.3208613395690918
5
train loss item: 0.2956834137439728
6
train loss item: 0.18306541442871094
7
train loss item: 0.6289957761764526
8
train loss item: 0.12312554568052292
9
train loss item: 0.20440183579921722
10
train loss item: 0.2598917484283447
11
train loss item: 0.22766181826591492
12
train loss item: 0.13071365654468536
13
train loss item: 0.3813821077346802
14
train loss item: 0.2474346160888672
15
train loss item: 0.4436322748661041
16
train loss item: 0.08818870037794113
17
train loss item: 0.21696826815605164
18
train loss item: 0.27067437767982483
19
train loss item: 0.20175868272781372
20
train loss item: 0.15913444757461548
21
train loss item: 0.1200684979557991
22
train loss item: 0.6184758543968201
23
train loss item: 0.6608281135559082
24
train loss item: 0.3864116370677948
25
train loss item: 0.16936686635017395
26
train loss item: 0.17478731274604797
27
train loss item: 0.25209492444992065
28
train loss item: 0.08808065950870514
29
train loss item: 0.4809345006942749
30
train loss item: 1.7744969129562378
31
train loss item: 0.4195879101753235
32
train loss item: 0.11818274110555649
33
train loss item: 0.29481908679008484
34
train loss item: 0.1488405168056488
35
train loss item: 2.0869686603546143
36
train loss item: 0.4026540517807007
37
train loss item: 0.25658369064331055
38
train loss item: 0.327720582485199
39
train loss item: 0.2683720886707306
40
train loss item: 0.14699576795101166
41
train loss item: 0.23046378791332245
42
train loss item: 0.22930186986923218
43
train loss item: 0.1575751155614853
44
train loss item: 0.6059440970420837
45
train loss item: 0.125704824924469
46
train loss item: 0.11957817524671555
47
train loss item: 0.2369450479745865
48
train loss item: 0.19313447177410126
49
train loss item: 0.1440756916999817
50
train loss item: 0.20277392864227295
51
train loss item: 0.6415130496025085
52
train loss item: 0.09510760754346848
53
train loss item: 0.13300815224647522
54
train loss item: 1.9499343633651733
55
train loss item: 0.17808738350868225
56
train loss item: 0.23508481681346893
57
train loss item: 0.21159076690673828
58
train loss item: 0.14557823538780212
59
train loss item: 0.13376176357269287
60
train loss item: 0.6104210019111633
61
train loss item: 1.837854027748108
62
train loss item: 0.17432264983654022
63
train loss item: 0.26290497183799744
64
train loss item: 0.14722156524658203
65
train loss item: 0.3904009759426117
66
train loss item: 0.32717281579971313
67
train loss item: 0.1768093854188919
68
train loss item: 0.21740268170833588
69
train loss item: 0.2514686584472656
70
train loss item: 0.20127883553504944
71
train loss item: 0.1312207728624344
72
train loss item: 0.14746616780757904
73
train loss item: 0.24093030393123627
74
train loss item: 0.10618657618761063
75
train loss item: 0.11988754570484161
76
train loss item: 0.6653161644935608
77
train loss item: 1.0278712511062622
78
train loss item: 0.09382618963718414
79
train loss item: 0.21757842600345612
80
train loss item: 0.12144937366247177
81
train loss item: 0.1620723456144333
82
train loss item: 0.17376595735549927
83
train loss item: 0.40900272130966187
84
train loss item: 0.31388989090919495
85
train loss item: 0.4179697632789612
86
train loss item: 3.7911455631256104
87
train loss item: 0.14115343987941742
88
train loss item: 0.2826141119003296
epoch train loss: 0.3888460916749547
testing phase
test loss item: 0.1884431391954422
test loss item: 0.13789542019367218
test loss item: 0.4598877429962158
test loss item: 0.21384932100772858
test loss item: 0.24413029849529266
test loss item: 0.15166300535202026
test loss item: 1.2343841791152954
test loss item: 0.41586029529571533
test loss item: 0.18015523254871368
test loss item: 0.32388371229171753
test loss item: 0.6911688446998596
test loss item: 0.16959232091903687
test loss item: 0.16940826177597046
test loss item: 0.25954732298851013
test loss item: 0.17615704238414764
test loss item: 0.1205567792057991
test loss item: 0.22537383437156677
test loss item: 0.39605605602264404
test loss item: 0.5294461250305176
test loss item: 0.21242092549800873
test loss item: 0.604046106338501
test loss item: 0.3196287751197815
test loss item: 0.25137969851493835
test loss item: 0.1603253036737442
test loss item: 0.20020216703414917
test loss item: 0.20754973590373993
test loss item: 0.27053552865982056
test loss item: 0.1859309822320938
test loss item: 0.285401314496994
test loss item: 0.29573479294776917
test loss item: 0.596411943435669
test loss item: 0.11045413464307785
test loss item: 0.14555464684963226
test loss item: 0.4969671666622162
test loss item: 0.3616073429584503
test loss item: 0.4604220390319824
test loss item: 0.6232699751853943
test loss item: 1.1694655418395996
test loss item: 0.3930791914463043
test loss item: 0.2364313304424286
test loss item: 0.25891992449760437
test loss item: 0.1849573254585266
test loss item: 0.30426594614982605
test loss item: 0.1846521943807602
test loss item: 0.47809937596321106
test loss item: 0.30841588973999023
test loss item: 0.254378080368042
test loss item: 0.19876247644424438
test loss item: 0.386502742767334
test loss item: 0.5513896346092224
test loss item: 0.24104438722133636
test loss item: 0.14694565534591675
test loss item: 0.20585477352142334
test loss item: 0.16991324722766876
test loss item: 0.2612391710281372
test loss item: 0.7078636884689331
test loss item: 0.47839629650115967
test loss item: 0.22247625887393951
test loss item: 0.20657847821712494
test loss item: 0.1950782835483551
test loss item: 0.3875196576118469
test loss item: 0.203392893075943
test loss item: 0.19361309707164764
test loss item: 0.21718142926692963
test loss item: 0.6780520677566528
test loss item: 0.2889455258846283
test loss item: 0.24253419041633606
test loss item: 0.2269628494977951
test loss item: 0.4851401150226593
test loss item: 0.3338320851325989
test loss item: 0.11649760603904724
test loss item: 0.6888754963874817
test loss item: 0.257230281829834
test loss item: 0.30320510268211365
test loss item: 0.1450476497411728
test loss item: 0.17281976342201233
test loss item: 0.16399109363555908
test loss item: 1.2454190254211426
test loss item: 0.3769014775753021
test loss item: 0.1996784508228302
test loss item: 0.13241858780384064
test loss item: 0.7316187024116516
test loss item: 0.6688759326934814
test loss item: 0.8126442432403564
test loss item: 0.19714634120464325
test loss item: 0.2052338868379593
test loss item: 0.1375371366739273
test loss item: 0.10478135198354721
test loss item: 0.3060964047908783
Epoch [51/100], Training Loss: 0.3888, Testing Loss: 0.3376
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 52/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4048912525177002
1
train loss item: 0.9012743234634399
2
train loss item: 0.18524488806724548
3
train loss item: 0.3828085660934448
4
train loss item: 0.3145099878311157
5
train loss item: 0.29262402653694153
6
train loss item: 0.18129941821098328
7
train loss item: 0.6201831698417664
8
train loss item: 0.12061476707458496
9
train loss item: 0.20004507899284363
10
train loss item: 0.25620344281196594
11
train loss item: 0.22392487525939941
12
train loss item: 0.12968207895755768
13
train loss item: 0.37374332547187805
14
train loss item: 0.24223408102989197
15
train loss item: 0.43290093541145325
16
train loss item: 0.0865752324461937
17
train loss item: 0.21378687024116516
18
train loss item: 0.26865774393081665
19
train loss item: 0.1982754021883011
20
train loss item: 0.15663357079029083
21
train loss item: 0.11873558163642883
22
train loss item: 0.6044942140579224
23
train loss item: 0.648135781288147
24
train loss item: 0.3822161853313446
25
train loss item: 0.16696804761886597
26
train loss item: 0.1692148596048355
27
train loss item: 0.24752038717269897
28
train loss item: 0.08624211698770523
29
train loss item: 0.47296541929244995
30
train loss item: 1.758968472480774
31
train loss item: 0.4175797998905182
32
train loss item: 0.11577305197715759
33
train loss item: 0.2843643128871918
34
train loss item: 0.14551515877246857
35
train loss item: 2.0756585597991943
36
train loss item: 0.39836230874061584
37
train loss item: 0.25421518087387085
38
train loss item: 0.3248364329338074
39
train loss item: 0.2639293670654297
40
train loss item: 0.1438128501176834
41
train loss item: 0.22446849942207336
42
train loss item: 0.22788460552692413
43
train loss item: 0.15530911087989807
44
train loss item: 0.5984396934509277
45
train loss item: 0.12377103418111801
46
train loss item: 0.11628314852714539
47
train loss item: 0.2354678064584732
48
train loss item: 0.19028697907924652
49
train loss item: 0.14262694120407104
50
train loss item: 0.1988171935081482
51
train loss item: 0.627578616142273
52
train loss item: 0.0931992307305336
53
train loss item: 0.13131439685821533
54
train loss item: 1.9390350580215454
55
train loss item: 0.17735257744789124
56
train loss item: 0.2317984402179718
57
train loss item: 0.21005962789058685
58
train loss item: 0.14472904801368713
59
train loss item: 0.13116224110126495
60
train loss item: 0.5999918580055237
61
train loss item: 1.8247977495193481
62
train loss item: 0.17165589332580566
63
train loss item: 0.26067352294921875
64
train loss item: 0.14381136000156403
65
train loss item: 0.38265788555145264
66
train loss item: 0.3178396224975586
67
train loss item: 0.1732046902179718
68
train loss item: 0.21197713911533356
69
train loss item: 0.24616901576519012
70
train loss item: 0.1988241970539093
71
train loss item: 0.129754438996315
72
train loss item: 0.14440646767616272
73
train loss item: 0.24089568853378296
74
train loss item: 0.10343177616596222
75
train loss item: 0.11726820468902588
76
train loss item: 0.6549057364463806
77
train loss item: 1.0151900053024292
78
train loss item: 0.09218814969062805
79
train loss item: 0.21327297389507294
80
train loss item: 0.11865837872028351
81
train loss item: 0.15848103165626526
82
train loss item: 0.1713232547044754
83
train loss item: 0.4010776877403259
84
train loss item: 0.3093336522579193
85
train loss item: 0.4136222302913666
86
train loss item: 3.776585578918457
87
train loss item: 0.1367870420217514
88
train loss item: 0.2727949619293213
epoch train loss: 0.38389646705616726
testing phase
test loss item: 0.18031924962997437
test loss item: 0.13421779870986938
test loss item: 0.455515056848526
test loss item: 0.21270500123500824
test loss item: 0.24193820357322693
test loss item: 0.1467331051826477
test loss item: 1.2881176471710205
test loss item: 0.4240347146987915
test loss item: 0.1797967106103897
test loss item: 0.3222144842147827
test loss item: 0.6881418824195862
test loss item: 0.16776849329471588
test loss item: 0.16421595215797424
test loss item: 0.25695106387138367
test loss item: 0.17288951575756073
test loss item: 0.11570283025503159
test loss item: 0.2282646894454956
test loss item: 0.3902980387210846
test loss item: 0.5388811230659485
test loss item: 0.21104060113430023
test loss item: 0.5962904691696167
test loss item: 0.32774677872657776
test loss item: 0.24349240958690643
test loss item: 0.15975694358348846
test loss item: 0.19729948043823242
test loss item: 0.20712901651859283
test loss item: 0.26855167746543884
test loss item: 0.18457752466201782
test loss item: 0.28593823313713074
test loss item: 0.2953849136829376
test loss item: 0.6033247113227844
test loss item: 0.10521458089351654
test loss item: 0.14330042898654938
test loss item: 0.4908186197280884
test loss item: 0.3565848171710968
test loss item: 0.4431813359260559
test loss item: 0.6359639167785645
test loss item: 1.1560736894607544
test loss item: 0.3899729549884796
test loss item: 0.23849724233150482
test loss item: 0.2641196846961975
test loss item: 0.18497009575366974
test loss item: 0.2998168468475342
test loss item: 0.18729251623153687
test loss item: 0.47148796916007996
test loss item: 0.3118826150894165
test loss item: 0.2500074803829193
test loss item: 0.19729016721248627
test loss item: 0.38515231013298035
test loss item: 0.5546208620071411
test loss item: 0.23850426077842712
test loss item: 0.14086739718914032
test loss item: 0.20723938941955566
test loss item: 0.16936370730400085
test loss item: 0.2570161819458008
test loss item: 0.6991493105888367
test loss item: 0.4721524715423584
test loss item: 0.21944452822208405
test loss item: 0.20493796467781067
test loss item: 0.1918182075023651
test loss item: 0.38268953561782837
test loss item: 0.20872986316680908
test loss item: 0.18809300661087036
test loss item: 0.21574854850769043
test loss item: 0.679057776927948
test loss item: 0.2886405289173126
test loss item: 0.24384506046772003
test loss item: 0.2262585610151291
test loss item: 0.47779619693756104
test loss item: 0.3407248556613922
test loss item: 0.10569296777248383
test loss item: 0.7160202264785767
test loss item: 0.2546858787536621
test loss item: 0.30484122037887573
test loss item: 0.13957519829273224
test loss item: 0.16229963302612305
test loss item: 0.16327731311321259
test loss item: 1.224661111831665
test loss item: 0.3754315972328186
test loss item: 0.19328294694423676
test loss item: 0.11229177564382553
test loss item: 0.7376507520675659
test loss item: 0.6814510226249695
test loss item: 0.7977826595306396
test loss item: 0.19583135843276978
test loss item: 0.21065184473991394
test loss item: 0.11693967133760452
test loss item: 0.09927106648683548
test loss item: 0.30530405044555664
Epoch [52/100], Training Loss: 0.3839, Testing Loss: 0.3360
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6894.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6894.00 MB
Epoch 53/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.40054163336753845
1
train loss item: 0.8936507701873779
2
train loss item: 0.1829952448606491
3
train loss item: 0.38047516345977783
4
train loss item: 0.3114071786403656
5
train loss item: 0.2904033660888672
6
train loss item: 0.17930933833122253
7
train loss item: 0.6131234169006348
8
train loss item: 0.11881936341524124
9
train loss item: 0.1972314864397049
10
train loss item: 0.2544337511062622
11
train loss item: 0.22359950840473175
12
train loss item: 0.12827447056770325
13
train loss item: 0.37100914120674133
14
train loss item: 0.23839004337787628
15
train loss item: 0.42596131563186646
16
train loss item: 0.08536189794540405
17
train loss item: 0.21182149648666382
18
train loss item: 0.266631156206131
19
train loss item: 0.19488690793514252
20
train loss item: 0.15419669449329376
21
train loss item: 0.11731447279453278
22
train loss item: 0.5930968523025513
23
train loss item: 0.6384019255638123
24
train loss item: 0.3789764940738678
25
train loss item: 0.16661915183067322
26
train loss item: 0.16714096069335938
27
train loss item: 0.24421177804470062
28
train loss item: 0.08500131964683533
29
train loss item: 0.46631506085395813
30
train loss item: 1.7477540969848633
31
train loss item: 0.41661176085472107
32
train loss item: 0.11536499112844467
33
train loss item: 0.28129202127456665
34
train loss item: 0.14484970271587372
35
train loss item: 2.067664623260498
36
train loss item: 0.3968762457370758
37
train loss item: 0.25411322712898254
38
train loss item: 0.32436826825141907
39
train loss item: 0.25990039110183716
40
train loss item: 0.14175273478031158
41
train loss item: 0.22070933878421783
42
train loss item: 0.2267206609249115
43
train loss item: 0.15338009595870972
44
train loss item: 0.5925169587135315
45
train loss item: 0.12242959439754486
46
train loss item: 0.11481227725744247
47
train loss item: 0.23286305367946625
48
train loss item: 0.18718387186527252
49
train loss item: 0.14107534289360046
50
train loss item: 0.19656488299369812
51
train loss item: 0.6189391016960144
52
train loss item: 0.09186539053916931
53
train loss item: 0.12979963421821594
54
train loss item: 1.931536316871643
55
train loss item: 0.17615653574466705
56
train loss item: 0.22839057445526123
57
train loss item: 0.20854385197162628
58
train loss item: 0.1412954330444336
59
train loss item: 0.13025948405265808
60
train loss item: 0.5939360857009888
61
train loss item: 1.8147070407867432
62
train loss item: 0.16929659247398376
63
train loss item: 0.25780826807022095
64
train loss item: 0.143265500664711
65
train loss item: 0.37709522247314453
66
train loss item: 0.31399214267730713
67
train loss item: 0.17135827243328094
68
train loss item: 0.20910459756851196
69
train loss item: 0.24515604972839355
70
train loss item: 0.19811785221099854
71
train loss item: 0.12838265299797058
72
train loss item: 0.1423649936914444
73
train loss item: 0.23906612396240234
74
train loss item: 0.10303234308958054
75
train loss item: 0.11636760085821152
76
train loss item: 0.6475634574890137
77
train loss item: 1.0047653913497925
78
train loss item: 0.09091169387102127
79
train loss item: 0.21175682544708252
80
train loss item: 0.117852583527565
81
train loss item: 0.15800689160823822
82
train loss item: 0.16827437281608582
83
train loss item: 0.39596471190452576
84
train loss item: 0.3060579299926758
85
train loss item: 0.4107654392719269
86
train loss item: 3.7661781311035156
87
train loss item: 0.13478273153305054
88
train loss item: 0.2692422568798065
epoch train loss: 0.38067826494741974
testing phase
test loss item: 0.17155084013938904
test loss item: 0.13250891864299774
test loss item: 0.4868445098400116
test loss item: 0.21320757269859314
test loss item: 0.24605637788772583
test loss item: 0.13829366862773895
test loss item: 1.3361175060272217
test loss item: 0.44371941685676575
test loss item: 0.1859990656375885
test loss item: 0.33418306708335876
test loss item: 0.7339840531349182
test loss item: 0.16775910556316376
test loss item: 0.16710789501667023
test loss item: 0.2536941170692444
test loss item: 0.17348606884479523
test loss item: 0.11441586166620255
test loss item: 0.22872675955295563
test loss item: 0.40602952241897583
test loss item: 0.5427917838096619
test loss item: 0.2138955146074295
test loss item: 0.6194667220115662
test loss item: 0.3342995345592499
test loss item: 0.2557772397994995
test loss item: 0.159656822681427
test loss item: 0.19925402104854584
test loss item: 0.20252709090709686
test loss item: 0.2704661786556244
test loss item: 0.1847141683101654
test loss item: 0.28823062777519226
test loss item: 0.3002519905567169
test loss item: 0.6452893614768982
test loss item: 0.10382208228111267
test loss item: 0.14120857417583466
test loss item: 0.5118873715400696
test loss item: 0.3727315664291382
test loss item: 0.4390193223953247
test loss item: 0.652671754360199
test loss item: 1.2511910200119019
test loss item: 0.4029547870159149
test loss item: 0.23800714313983917
test loss item: 0.2659306824207306
test loss item: 0.17418697476387024
test loss item: 0.313703715801239
test loss item: 0.19000764191150665
test loss item: 0.4818260967731476
test loss item: 0.3148437440395355
test loss item: 0.26222512125968933
test loss item: 0.19829872250556946
test loss item: 0.4054337739944458
test loss item: 0.5844371914863586
test loss item: 0.2442445307970047
test loss item: 0.139884814620018
test loss item: 0.21156185865402222
test loss item: 0.17455840110778809
test loss item: 0.2662889361381531
test loss item: 0.7465618848800659
test loss item: 0.4813188910484314
test loss item: 0.22169029712677002
test loss item: 0.20533739030361176
test loss item: 0.19717082381248474
test loss item: 0.3990294337272644
test loss item: 0.21191993355751038
test loss item: 0.1818966120481491
test loss item: 0.21586625277996063
test loss item: 0.7244512438774109
test loss item: 0.291536808013916
test loss item: 0.24645115435123444
test loss item: 0.22629821300506592
test loss item: 0.501226007938385
test loss item: 0.3475569784641266
test loss item: 0.10304468870162964
test loss item: 0.740545392036438
test loss item: 0.2580835223197937
test loss item: 0.3057614862918854
test loss item: 0.13386860489845276
test loss item: 0.16276712715625763
test loss item: 0.16317254304885864
test loss item: 1.3387728929519653
test loss item: 0.38189786672592163
test loss item: 0.18315188586711884
test loss item: 0.09751052409410477
test loss item: 0.7737135887145996
test loss item: 0.7020329236984253
test loss item: 0.8693516254425049
test loss item: 0.19806382060050964
test loss item: 0.20955166220664978
test loss item: 0.09622079879045486
test loss item: 0.0972425788640976
test loss item: 0.21509785950183868
Epoch [53/100], Training Loss: 0.3807, Testing Loss: 0.3452
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 54/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.39270341396331787
1
train loss item: 0.8797838091850281
2
train loss item: 0.18008005619049072
3
train loss item: 0.369395911693573
4
train loss item: 0.30776065587997437
5
train loss item: 0.28480541706085205
6
train loss item: 0.1767614632844925
7
train loss item: 0.6067764163017273
8
train loss item: 0.11684853583574295
9
train loss item: 0.1951589286327362
10
train loss item: 0.2490362823009491
11
train loss item: 0.22347505390644073
12
train loss item: 0.12602800130844116
13
train loss item: 0.36155691742897034
14
train loss item: 0.23516152799129486
15
train loss item: 0.4196142554283142
16
train loss item: 0.0840940922498703
17
train loss item: 0.2094212770462036
18
train loss item: 0.261007696390152
19
train loss item: 0.19232574105262756
20
train loss item: 0.15113615989685059
21
train loss item: 0.115623340010643
22
train loss item: 0.5819587707519531
23
train loss item: 0.6291010975837708
24
train loss item: 0.37389013171195984
25
train loss item: 0.1605096012353897
26
train loss item: 0.1661180704832077
27
train loss item: 0.2396855354309082
28
train loss item: 0.08410152047872543
29
train loss item: 0.4563325047492981
30
train loss item: 1.7354602813720703
31
train loss item: 0.404904305934906
32
train loss item: 0.11385546624660492
33
train loss item: 0.2762695550918579
34
train loss item: 0.14264975488185883
35
train loss item: 2.061427116394043
36
train loss item: 0.38463863730430603
37
train loss item: 0.2513740658760071
38
train loss item: 0.317004919052124
39
train loss item: 0.255415141582489
40
train loss item: 0.14101339876651764
41
train loss item: 0.21708612143993378
42
train loss item: 0.22641286253929138
43
train loss item: 0.15190176665782928
44
train loss item: 0.5872091054916382
45
train loss item: 0.1215742900967598
46
train loss item: 0.11456029862165451
47
train loss item: 0.22937290370464325
48
train loss item: 0.18512704968452454
49
train loss item: 0.1385866403579712
50
train loss item: 0.1946665346622467
51
train loss item: 0.6092216372489929
52
train loss item: 0.09106432646512985
53
train loss item: 0.12723498046398163
54
train loss item: 1.9254212379455566
55
train loss item: 0.172027587890625
56
train loss item: 0.2237967848777771
57
train loss item: 0.20488004386425018
58
train loss item: 0.13774831593036652
59
train loss item: 0.1286478489637375
60
train loss item: 0.5841115117073059
61
train loss item: 1.805521011352539
62
train loss item: 0.16717800498008728
63
train loss item: 0.25594520568847656
64
train loss item: 0.14392872154712677
65
train loss item: 0.3707197308540344
66
train loss item: 0.3077273964881897
67
train loss item: 0.16926206648349762
68
train loss item: 0.20650087296962738
69
train loss item: 0.2407614290714264
70
train loss item: 0.19470317661762238
71
train loss item: 0.1261998414993286
72
train loss item: 0.140258327126503
73
train loss item: 0.2335774153470993
74
train loss item: 0.10072970390319824
75
train loss item: 0.11630064249038696
76
train loss item: 0.639427125453949
77
train loss item: 0.9948196411132812
78
train loss item: 0.08950623869895935
79
train loss item: 0.2106299251317978
80
train loss item: 0.11775871366262436
81
train loss item: 0.15518517792224884
82
train loss item: 0.16638608276844025
83
train loss item: 0.3879965543746948
84
train loss item: 0.29501551389694214
85
train loss item: 0.4031367599964142
86
train loss item: 3.756589412689209
87
train loss item: 0.13269171118736267
88
train loss item: 0.2655046582221985
epoch train loss: 0.3761671655968334
testing phase
test loss item: 0.17015619575977325
test loss item: 0.12766949832439423
test loss item: 0.48284438252449036
test loss item: 0.21011844277381897
test loss item: 0.24175512790679932
test loss item: 0.13550329208374023
test loss item: 1.3519550561904907
test loss item: 0.46585482358932495
test loss item: 0.1823638379573822
test loss item: 0.32839059829711914
test loss item: 0.7295103073120117
test loss item: 0.16273966431617737
test loss item: 0.16434574127197266
test loss item: 0.25449949502944946
test loss item: 0.16851812601089478
test loss item: 0.11146175861358643
test loss item: 0.22692272067070007
test loss item: 0.39876043796539307
test loss item: 0.5499449372291565
test loss item: 0.21441549062728882
test loss item: 0.6085125803947449
test loss item: 0.3325643539428711
test loss item: 0.2599995732307434
test loss item: 0.15860208868980408
test loss item: 0.19637103378772736
test loss item: 0.20103628933429718
test loss item: 0.26912134885787964
test loss item: 0.18085739016532898
test loss item: 0.28089478611946106
test loss item: 0.29334327578544617
test loss item: 0.6470344066619873
test loss item: 0.0997641459107399
test loss item: 0.13889582455158234
test loss item: 0.5074104070663452
test loss item: 0.36626774072647095
test loss item: 0.43170303106307983
test loss item: 0.6587932109832764
test loss item: 1.2466048002243042
test loss item: 0.3961726427078247
test loss item: 0.23776043951511383
test loss item: 0.26502174139022827
test loss item: 0.17865756154060364
test loss item: 0.3090810775756836
test loss item: 0.1867065578699112
test loss item: 0.4732207655906677
test loss item: 0.3140110969543457
test loss item: 0.26512670516967773
test loss item: 0.20079125463962555
test loss item: 0.4031412601470947
test loss item: 0.5838250517845154
test loss item: 0.2376820147037506
test loss item: 0.13628704845905304
test loss item: 0.20793218910694122
test loss item: 0.16710038483142853
test loss item: 0.2627362012863159
test loss item: 0.7411259412765503
test loss item: 0.4829730689525604
test loss item: 0.21956868469715118
test loss item: 0.20283420383930206
test loss item: 0.193159282207489
test loss item: 0.3890654146671295
test loss item: 0.2125874012708664
test loss item: 0.18134386837482452
test loss item: 0.21418073773384094
test loss item: 0.7283242344856262
test loss item: 0.2873248755931854
test loss item: 0.244419664144516
test loss item: 0.224910706281662
test loss item: 0.50093013048172
test loss item: 0.35146594047546387
test loss item: 0.10060162842273712
test loss item: 0.7535589933395386
test loss item: 0.26039445400238037
test loss item: 0.3076806366443634
test loss item: 0.13160040974617004
test loss item: 0.16795547306537628
test loss item: 0.162294402718544
test loss item: 1.344231128692627
test loss item: 0.3816165626049042
test loss item: 0.18026703596115112
test loss item: 0.09657379984855652
test loss item: 0.7786786556243896
test loss item: 0.7046583890914917
test loss item: 0.8701515197753906
test loss item: 0.1966123878955841
test loss item: 0.20604780316352844
test loss item: 0.09373321384191513
test loss item: 0.09573619067668915
test loss item: 0.19384919106960297
Epoch [54/100], Training Loss: 0.3762, Testing Loss: 0.3436
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 55/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3882858157157898
1
train loss item: 0.8685075044631958
2
train loss item: 0.17759473621845245
3
train loss item: 0.36683523654937744
4
train loss item: 0.30451586842536926
5
train loss item: 0.2795744240283966
6
train loss item: 0.17295211553573608
7
train loss item: 0.5991297364234924
8
train loss item: 0.11573005467653275
9
train loss item: 0.19364753365516663
10
train loss item: 0.24505098164081573
11
train loss item: 0.22021012008190155
12
train loss item: 0.12561346590518951
13
train loss item: 0.35477402806282043
14
train loss item: 0.23078708350658417
15
train loss item: 0.41606593132019043
16
train loss item: 0.08277545124292374
17
train loss item: 0.20689450204372406
18
train loss item: 0.25825655460357666
19
train loss item: 0.19044853746891022
20
train loss item: 0.14934539794921875
21
train loss item: 0.11390180885791779
22
train loss item: 0.5724726915359497
23
train loss item: 0.6188606023788452
24
train loss item: 0.3687625825405121
25
train loss item: 0.16020886600017548
26
train loss item: 0.1645888239145279
27
train loss item: 0.23657546937465668
28
train loss item: 0.08261574059724808
29
train loss item: 0.44800087809562683
30
train loss item: 1.7210891246795654
31
train loss item: 0.4003276526927948
32
train loss item: 0.1108175590634346
33
train loss item: 0.27046284079551697
34
train loss item: 0.14099419116973877
35
train loss item: 2.0539584159851074
36
train loss item: 0.3722860813140869
37
train loss item: 0.24582622945308685
38
train loss item: 0.31043288111686707
39
train loss item: 0.2527369558811188
40
train loss item: 0.14002150297164917
41
train loss item: 0.2145838886499405
42
train loss item: 0.22761644423007965
43
train loss item: 0.1493135541677475
44
train loss item: 0.5818554759025574
45
train loss item: 0.11930423229932785
46
train loss item: 0.11346422135829926
47
train loss item: 0.22612306475639343
48
train loss item: 0.1827593594789505
49
train loss item: 0.13770240545272827
50
train loss item: 0.19170331954956055
51
train loss item: 0.6065330505371094
52
train loss item: 0.09030462056398392
53
train loss item: 0.12521012127399445
54
train loss item: 1.917839527130127
55
train loss item: 0.1697339415550232
56
train loss item: 0.22102972865104675
57
train loss item: 0.20128437876701355
58
train loss item: 0.13749554753303528
59
train loss item: 0.1253984421491623
60
train loss item: 0.5752365589141846
61
train loss item: 1.7945799827575684
62
train loss item: 0.16672900319099426
63
train loss item: 0.25567734241485596
64
train loss item: 0.14067338407039642
65
train loss item: 0.36501747369766235
66
train loss item: 0.3037396967411041
67
train loss item: 0.16811513900756836
68
train loss item: 0.20649273693561554
69
train loss item: 0.23791469633579254
70
train loss item: 0.19171085953712463
71
train loss item: 0.12639492750167847
72
train loss item: 0.13807155191898346
73
train loss item: 0.23097893595695496
74
train loss item: 0.09889334440231323
75
train loss item: 0.11444207280874252
76
train loss item: 0.6299622058868408
77
train loss item: 0.9864802360534668
78
train loss item: 0.08879651129245758
79
train loss item: 0.20863504707813263
80
train loss item: 0.1151096299290657
81
train loss item: 0.15332622826099396
82
train loss item: 0.16293710470199585
83
train loss item: 0.3814113736152649
84
train loss item: 0.28598958253860474
85
train loss item: 0.39622604846954346
86
train loss item: 3.7455546855926514
87
train loss item: 0.1318674087524414
88
train loss item: 0.26300209760665894
epoch train loss: 0.37230513671810705
testing phase
test loss item: 0.16949418187141418
test loss item: 0.1315966099500656
test loss item: 0.47029244899749756
test loss item: 0.20973551273345947
test loss item: 0.2416568398475647
test loss item: 0.14214390516281128
test loss item: 1.303813099861145
test loss item: 0.44244953989982605
test loss item: 0.181876078248024
test loss item: 0.3216952383518219
test loss item: 0.7141712307929993
test loss item: 0.16371528804302216
test loss item: 0.1621340811252594
test loss item: 0.2576383352279663
test loss item: 0.16984911262989044
test loss item: 0.11572562903165817
test loss item: 0.2212817370891571
test loss item: 0.38970890641212463
test loss item: 0.5329506397247314
test loss item: 0.21016745269298553
test loss item: 0.5876119136810303
test loss item: 0.32224294543266296
test loss item: 0.2556208372116089
test loss item: 0.1586287021636963
test loss item: 0.19284369051456451
test loss item: 0.19975517690181732
test loss item: 0.26621073484420776
test loss item: 0.18456892669200897
test loss item: 0.2780464291572571
test loss item: 0.289041131734848
test loss item: 0.6253389120101929
test loss item: 0.10431579500436783
test loss item: 0.14031091332435608
test loss item: 0.49680936336517334
test loss item: 0.3577607572078705
test loss item: 0.44048914313316345
test loss item: 0.6399704217910767
test loss item: 1.213397741317749
test loss item: 0.3877699375152588
test loss item: 0.2342079132795334
test loss item: 0.25913792848587036
test loss item: 0.1760081946849823
test loss item: 0.30018454790115356
test loss item: 0.18253402411937714
test loss item: 0.4625171720981598
test loss item: 0.3050498366355896
test loss item: 0.26065897941589355
test loss item: 0.20038339495658875
test loss item: 0.3925873339176178
test loss item: 0.572870135307312
test loss item: 0.23525263369083405
test loss item: 0.13727489113807678
test loss item: 0.2037459909915924
test loss item: 0.16455233097076416
test loss item: 0.25756824016571045
test loss item: 0.724068820476532
test loss item: 0.4816140830516815
test loss item: 0.2149244248867035
test loss item: 0.20179462432861328
test loss item: 0.1902162730693817
test loss item: 0.38196080923080444
test loss item: 0.20468875765800476
test loss item: 0.17818503081798553
test loss item: 0.21071329712867737
test loss item: 0.7067344188690186
test loss item: 0.2854582965373993
test loss item: 0.23986120522022247
test loss item: 0.22196827828884125
test loss item: 0.49154046177864075
test loss item: 0.34297457337379456
test loss item: 0.10422047972679138
test loss item: 0.7206328511238098
test loss item: 0.2581031024456024
test loss item: 0.29808399081230164
test loss item: 0.13195104897022247
test loss item: 0.1696607768535614
test loss item: 0.16411790251731873
test loss item: 1.306637167930603
test loss item: 0.377054363489151
test loss item: 0.18239983916282654
test loss item: 0.10025850683450699
test loss item: 0.759483277797699
test loss item: 0.6859279274940491
test loss item: 0.8501870632171631
test loss item: 0.19335849583148956
test loss item: 0.20533685386180878
test loss item: 0.09628915041685104
test loss item: 0.09760788828134537
test loss item: 0.1912853866815567
Epoch [55/100], Training Loss: 0.3723, Testing Loss: 0.3372
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 56/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.38209766149520874
1
train loss item: 0.8587613701820374
2
train loss item: 0.17709973454475403
3
train loss item: 0.35984715819358826
4
train loss item: 0.3012728691101074
5
train loss item: 0.2759001553058624
6
train loss item: 0.1704677790403366
7
train loss item: 0.5909256935119629
8
train loss item: 0.1146780252456665
9
train loss item: 0.19068577885627747
10
train loss item: 0.24121607840061188
11
train loss item: 0.2169170081615448
12
train loss item: 0.12701192498207092
13
train loss item: 0.3511955738067627
14
train loss item: 0.2255651205778122
15
train loss item: 0.41070812940597534
16
train loss item: 0.08171391487121582
17
train loss item: 0.20510423183441162
18
train loss item: 0.25439348816871643
19
train loss item: 0.1883424073457718
20
train loss item: 0.14858078956604004
21
train loss item: 0.1138252466917038
22
train loss item: 0.5608674883842468
23
train loss item: 0.6096602082252502
24
train loss item: 0.36559703946113586
25
train loss item: 0.15710847079753876
26
train loss item: 0.16337278485298157
27
train loss item: 0.23262713849544525
28
train loss item: 0.08124537020921707
29
train loss item: 0.43880653381347656
30
train loss item: 1.7084479331970215
31
train loss item: 0.3986121416091919
32
train loss item: 0.10920526087284088
33
train loss item: 0.26411551237106323
34
train loss item: 0.1398896425962448
35
train loss item: 2.0456957817077637
36
train loss item: 0.36586350202560425
37
train loss item: 0.24516306817531586
38
train loss item: 0.3061009645462036
39
train loss item: 0.2492671012878418
40
train loss item: 0.13795222342014313
41
train loss item: 0.21013471484184265
42
train loss item: 0.2254413217306137
43
train loss item: 0.14703215658664703
44
train loss item: 0.5754499435424805
45
train loss item: 0.11829430609941483
46
train loss item: 0.11142172664403915
47
train loss item: 0.22219684720039368
48
train loss item: 0.18064656853675842
49
train loss item: 0.136201411485672
50
train loss item: 0.1879614144563675
51
train loss item: 0.5944885611534119
52
train loss item: 0.08941638469696045
53
train loss item: 0.12316645681858063
54
train loss item: 1.9093470573425293
55
train loss item: 0.16934989392757416
56
train loss item: 0.2179163247346878
57
train loss item: 0.1997186690568924
58
train loss item: 0.13774871826171875
59
train loss item: 0.1235034316778183
60
train loss item: 0.5648530721664429
61
train loss item: 1.7840481996536255
62
train loss item: 0.16527880728244781
63
train loss item: 0.25337985157966614
64
train loss item: 0.13720642030239105
65
train loss item: 0.36044684052467346
66
train loss item: 0.29981327056884766
67
train loss item: 0.16717572510242462
68
train loss item: 0.20226596295833588
69
train loss item: 0.23478685319423676
70
train loss item: 0.18950580060482025
71
train loss item: 0.12827694416046143
72
train loss item: 0.13628503680229187
73
train loss item: 0.22976204752922058
74
train loss item: 0.09729544073343277
75
train loss item: 0.11194848269224167
76
train loss item: 0.6200831532478333
77
train loss item: 0.9750030040740967
78
train loss item: 0.08835847675800323
79
train loss item: 0.20616668462753296
80
train loss item: 0.11356854438781738
81
train loss item: 0.15077047049999237
82
train loss item: 0.15941625833511353
83
train loss item: 0.3744664788246155
84
train loss item: 0.28175508975982666
85
train loss item: 0.38956961035728455
86
train loss item: 3.7348015308380127
87
train loss item: 0.12984640896320343
88
train loss item: 0.2602043151855469
epoch train loss: 0.3684458763579304
testing phase
test loss item: 0.16906607151031494
test loss item: 0.13008630275726318
test loss item: 0.4762924611568451
test loss item: 0.20540182292461395
test loss item: 0.24311110377311707
test loss item: 0.1458132416009903
test loss item: 1.2438020706176758
test loss item: 0.42127466201782227
test loss item: 0.18288789689540863
test loss item: 0.32433435320854187
test loss item: 0.7051186561584473
test loss item: 0.15715396404266357
test loss item: 0.15976077318191528
test loss item: 0.24676407873630524
test loss item: 0.17128309607505798
test loss item: 0.11266814172267914
test loss item: 0.21819083392620087
test loss item: 0.40072062611579895
test loss item: 0.5236638784408569
test loss item: 0.20414666831493378
test loss item: 0.6002515554428101
test loss item: 0.31523382663726807
test loss item: 0.25301429629325867
test loss item: 0.15494853258132935
test loss item: 0.19212868809700012
test loss item: 0.1985207051038742
test loss item: 0.26254069805145264
test loss item: 0.18367737531661987
test loss item: 0.2782376706600189
test loss item: 0.2921018898487091
test loss item: 0.6160915493965149
test loss item: 0.10191459953784943
test loss item: 0.1388416588306427
test loss item: 0.5011400580406189
test loss item: 0.364667147397995
test loss item: 0.4266369342803955
test loss item: 0.6218582391738892
test loss item: 1.2078888416290283
test loss item: 0.3894788920879364
test loss item: 0.23287652432918549
test loss item: 0.2556178867816925
test loss item: 0.17643526196479797
test loss item: 0.30758145451545715
test loss item: 0.17788970470428467
test loss item: 0.4650968909263611
test loss item: 0.29800063371658325
test loss item: 0.2559700310230255
test loss item: 0.19483350217342377
test loss item: 0.39379915595054626
test loss item: 0.5674970746040344
test loss item: 0.23590777814388275
test loss item: 0.13870778679847717
test loss item: 0.20443366467952728
test loss item: 0.15537306666374207
test loss item: 0.2585158944129944
test loss item: 0.728630781173706
test loss item: 0.4720720946788788
test loss item: 0.20935198664665222
test loss item: 0.20094721019268036
test loss item: 0.18917055428028107
test loss item: 0.39475902915000916
test loss item: 0.20042212307453156
test loss item: 0.1749102920293808
test loss item: 0.20716580748558044
test loss item: 0.6995283961296082
test loss item: 0.27782976627349854
test loss item: 0.23668189346790314
test loss item: 0.21755151450634003
test loss item: 0.4886666238307953
test loss item: 0.3376352787017822
test loss item: 0.10036727041006088
test loss item: 0.6903515458106995
test loss item: 0.24856002628803253
test loss item: 0.28882333636283875
test loss item: 0.13193023204803467
test loss item: 0.1627865582704544
test loss item: 0.1596613973379135
test loss item: 1.2881834506988525
test loss item: 0.36779332160949707
test loss item: 0.18399187922477722
test loss item: 0.09922651201486588
test loss item: 0.7387147545814514
test loss item: 0.6689898371696472
test loss item: 0.8398041725158691
test loss item: 0.19053585827350616
test loss item: 0.2080601304769516
test loss item: 0.1023944616317749
test loss item: 0.09626166522502899
test loss item: 0.2595701515674591
Epoch [56/100], Training Loss: 0.3684, Testing Loss: 0.3339
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 57/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.37509942054748535
1
train loss item: 0.8475282788276672
2
train loss item: 0.17418624460697174
3
train loss item: 0.3533298373222351
4
train loss item: 0.29811781644821167
5
train loss item: 0.27139604091644287
6
train loss item: 0.16840757429599762
7
train loss item: 0.5852689146995544
8
train loss item: 0.11265264451503754
9
train loss item: 0.18820464611053467
10
train loss item: 0.2367292046546936
11
train loss item: 0.21622216701507568
12
train loss item: 0.1255713403224945
13
train loss item: 0.34535130858421326
14
train loss item: 0.22206799685955048
15
train loss item: 0.40163081884384155
16
train loss item: 0.08041407912969589
17
train loss item: 0.20287249982357025
18
train loss item: 0.24851317703723907
19
train loss item: 0.18494661152362823
20
train loss item: 0.1476757973432541
21
train loss item: 0.11164499074220657
22
train loss item: 0.5491894483566284
23
train loss item: 0.601640522480011
24
train loss item: 0.3609674870967865
25
train loss item: 0.154670849442482
26
train loss item: 0.1601121872663498
27
train loss item: 0.22993990778923035
28
train loss item: 0.07991909235715866
29
train loss item: 0.4324270486831665
30
train loss item: 1.6993812322616577
31
train loss item: 0.3920193016529083
32
train loss item: 0.10752788186073303
33
train loss item: 0.2601611018180847
34
train loss item: 0.13751459121704102
35
train loss item: 2.0395472049713135
36
train loss item: 0.3629472553730011
37
train loss item: 0.243001326918602
38
train loss item: 0.30252471566200256
39
train loss item: 0.24679774045944214
40
train loss item: 0.13669492304325104
41
train loss item: 0.2057507336139679
42
train loss item: 0.2239811271429062
43
train loss item: 0.1455305963754654
44
train loss item: 0.5715281367301941
45
train loss item: 0.11762167513370514
46
train loss item: 0.10855814814567566
47
train loss item: 0.21976995468139648
48
train loss item: 0.1770908385515213
49
train loss item: 0.13414020836353302
50
train loss item: 0.18457457423210144
51
train loss item: 0.5833024382591248
52
train loss item: 0.08839383721351624
53
train loss item: 0.12182842195034027
54
train loss item: 1.9032604694366455
55
train loss item: 0.16696342825889587
56
train loss item: 0.21391895413398743
57
train loss item: 0.1962386816740036
58
train loss item: 0.13365526497364044
59
train loss item: 0.12289956957101822
60
train loss item: 0.5552234649658203
61
train loss item: 1.7748056650161743
62
train loss item: 0.16374531388282776
63
train loss item: 0.2491498589515686
64
train loss item: 0.1363435536623001
65
train loss item: 0.3547702729701996
66
train loss item: 0.2940571904182434
67
train loss item: 0.16446951031684875
68
train loss item: 0.19863289594650269
69
train loss item: 0.23165620863437653
70
train loss item: 0.1883222907781601
71
train loss item: 0.12493083626031876
72
train loss item: 0.13425183296203613
73
train loss item: 0.226870596408844
74
train loss item: 0.09569808095693588
75
train loss item: 0.11058391630649567
76
train loss item: 0.611034631729126
77
train loss item: 0.9629496335983276
78
train loss item: 0.0869564414024353
79
train loss item: 0.2033035308122635
80
train loss item: 0.1118934378027916
81
train loss item: 0.14931009709835052
82
train loss item: 0.15769779682159424
83
train loss item: 0.3675181269645691
84
train loss item: 0.2764989733695984
85
train loss item: 0.38242802023887634
86
train loss item: 3.725703001022339
87
train loss item: 0.12884120643138885
88
train loss item: 0.2567466199398041
epoch train loss: 0.36447432913472144
testing phase
test loss item: 0.1676061600446701
test loss item: 0.12473444640636444
test loss item: 0.459290087223053
test loss item: 0.20576578378677368
test loss item: 0.23802588880062103
test loss item: 0.13509267568588257
test loss item: 1.2744505405426025
test loss item: 0.43460386991500854
test loss item: 0.17684012651443481
test loss item: 0.31737077236175537
test loss item: 0.6931511163711548
test loss item: 0.15598173439502716
test loss item: 0.15728828310966492
test loss item: 0.2435426115989685
test loss item: 0.16609396040439606
test loss item: 0.1048094853758812
test loss item: 0.2178831696510315
test loss item: 0.38955986499786377
test loss item: 0.5290930271148682
test loss item: 0.20214751362800598
test loss item: 0.5907858610153198
test loss item: 0.31937357783317566
test loss item: 0.25443732738494873
test loss item: 0.15161225199699402
test loss item: 0.18765927851200104
test loss item: 0.1999613642692566
test loss item: 0.25679320096969604
test loss item: 0.17890885472297668
test loss item: 0.27385714650154114
test loss item: 0.28759875893592834
test loss item: 0.6128830909729004
test loss item: 0.09372974187135696
test loss item: 0.13623417913913727
test loss item: 0.4905160665512085
test loss item: 0.35360875725746155
test loss item: 0.4275214672088623
test loss item: 0.6264132857322693
test loss item: 1.1824604272842407
test loss item: 0.3805854916572571
test loss item: 0.23023656010627747
test loss item: 0.257526159286499
test loss item: 0.17375005781650543
test loss item: 0.30499017238616943
test loss item: 0.17967486381530762
test loss item: 0.4571079909801483
test loss item: 0.2976706027984619
test loss item: 0.2576178014278412
test loss item: 0.19099590182304382
test loss item: 0.3838252127170563
test loss item: 0.5541021823883057
test loss item: 0.23091813921928406
test loss item: 0.13754071295261383
test loss item: 0.20292465388774872
test loss item: 0.1572790890932083
test loss item: 0.25267714262008667
test loss item: 0.7023398876190186
test loss item: 0.4698915481567383
test loss item: 0.21175269782543182
test loss item: 0.1997726559638977
test loss item: 0.18582314252853394
test loss item: 0.384947806596756
test loss item: 0.2023439109325409
test loss item: 0.17415964603424072
test loss item: 0.2064276486635208
test loss item: 0.6879211068153381
test loss item: 0.28048059344291687
test loss item: 0.23479516804218292
test loss item: 0.21702954173088074
test loss item: 0.48017042875289917
test loss item: 0.3368418216705322
test loss item: 0.0924416109919548
test loss item: 0.708534836769104
test loss item: 0.24411113560199738
test loss item: 0.2904816269874573
test loss item: 0.1281995177268982
test loss item: 0.16052451729774475
test loss item: 0.15460556745529175
test loss item: 1.2713379859924316
test loss item: 0.36244282126426697
test loss item: 0.17867472767829895
test loss item: 0.09243728220462799
test loss item: 0.7426252365112305
test loss item: 0.6727965474128723
test loss item: 0.831260621547699
test loss item: 0.19020409882068634
test loss item: 0.20911504328250885
test loss item: 0.09288139641284943
test loss item: 0.09099303185939789
test loss item: 0.2510335147380829
Epoch [57/100], Training Loss: 0.3645, Testing Loss: 0.3304
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 58/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3691079914569855
1
train loss item: 0.8372753858566284
2
train loss item: 0.17119140923023224
3
train loss item: 0.34833618998527527
4
train loss item: 0.2961040735244751
5
train loss item: 0.2657323479652405
6
train loss item: 0.16606126725673676
7
train loss item: 0.5790722370147705
8
train loss item: 0.11075243353843689
9
train loss item: 0.18623459339141846
10
train loss item: 0.23353448510169983
11
train loss item: 0.21506525576114655
12
train loss item: 0.12301088869571686
13
train loss item: 0.3394118547439575
14
train loss item: 0.21896179020404816
15
train loss item: 0.3937802016735077
16
train loss item: 0.07909588515758514
17
train loss item: 0.2009875774383545
18
train loss item: 0.2453031837940216
19
train loss item: 0.1818530112504959
20
train loss item: 0.1465013474225998
21
train loss item: 0.11008575558662415
22
train loss item: 0.5385220050811768
23
train loss item: 0.5921105742454529
24
train loss item: 0.3567279577255249
25
train loss item: 0.15215380489826202
26
train loss item: 0.1583910435438156
27
train loss item: 0.22641269862651825
28
train loss item: 0.07872563600540161
29
train loss item: 0.42604324221611023
30
train loss item: 1.6853851079940796
31
train loss item: 0.3865389823913574
32
train loss item: 0.10653843730688095
33
train loss item: 0.25470390915870667
34
train loss item: 0.13642042875289917
35
train loss item: 2.032191276550293
36
train loss item: 0.35450276732444763
37
train loss item: 0.24010610580444336
38
train loss item: 0.29654625058174133
39
train loss item: 0.24148550629615784
40
train loss item: 0.13515523076057434
41
train loss item: 0.20233233273029327
42
train loss item: 0.22242744266986847
43
train loss item: 0.14451269805431366
44
train loss item: 0.5667806267738342
45
train loss item: 0.11589634418487549
46
train loss item: 0.10770116746425629
47
train loss item: 0.2173748016357422
48
train loss item: 0.17459243535995483
49
train loss item: 0.13290953636169434
50
train loss item: 0.18084703385829926
51
train loss item: 0.5756739377975464
52
train loss item: 0.08661919832229614
53
train loss item: 0.12046260386705399
54
train loss item: 1.8958454132080078
55
train loss item: 0.16382430493831635
56
train loss item: 0.2104160636663437
57
train loss item: 0.1935870349407196
58
train loss item: 0.13117192685604095
59
train loss item: 0.12085025757551193
60
train loss item: 0.5463350415229797
61
train loss item: 1.7645903825759888
62
train loss item: 0.1596125215291977
63
train loss item: 0.2462518960237503
64
train loss item: 0.1356617510318756
65
train loss item: 0.34932541847229004
66
train loss item: 0.28776586055755615
67
train loss item: 0.1625729501247406
68
train loss item: 0.19604110717773438
69
train loss item: 0.22951973974704742
70
train loss item: 0.18649840354919434
71
train loss item: 0.12226185947656631
72
train loss item: 0.13184243440628052
73
train loss item: 0.22343167662620544
74
train loss item: 0.09443826228380203
75
train loss item: 0.11038337647914886
76
train loss item: 0.6036286950111389
77
train loss item: 0.9543876051902771
78
train loss item: 0.08484706282615662
79
train loss item: 0.2013978362083435
80
train loss item: 0.111623115837574
81
train loss item: 0.1475953906774521
82
train loss item: 0.15553048253059387
83
train loss item: 0.3603666424751282
84
train loss item: 0.2684457004070282
85
train loss item: 0.3769192397594452
86
train loss item: 3.7151169776916504
87
train loss item: 0.12731623649597168
88
train loss item: 0.2540513575077057
epoch train loss: 0.3605360035481078
testing phase
test loss item: 0.1671924591064453
test loss item: 0.131817027926445
test loss item: 0.4588053524494171
test loss item: 0.20898182690143585
test loss item: 0.24113969504833221
test loss item: 0.14275819063186646
test loss item: 1.264750361442566
test loss item: 0.44069939851760864
test loss item: 0.17829802632331848
test loss item: 0.31494659185409546
test loss item: 0.7087885141372681
test loss item: 0.16245123744010925
test loss item: 0.15999455749988556
test loss item: 0.24703221023082733
test loss item: 0.16877806186676025
test loss item: 0.11360754817724228
test loss item: 0.21619845926761627
test loss item: 0.3807929754257202
test loss item: 0.5315527319908142
test loss item: 0.205206498503685
test loss item: 0.5771816372871399
test loss item: 0.3194117844104767
test loss item: 0.24888913333415985
test loss item: 0.15418744087219238
test loss item: 0.18842023611068726
test loss item: 0.19780714809894562
test loss item: 0.25693249702453613
test loss item: 0.1812710016965866
test loss item: 0.2730989456176758
test loss item: 0.28081566095352173
test loss item: 0.6216359734535217
test loss item: 0.10010892152786255
test loss item: 0.13891838490962982
test loss item: 0.4891866445541382
test loss item: 0.34944620728492737
test loss item: 0.4400268793106079
test loss item: 0.6243278980255127
test loss item: 1.2113735675811768
test loss item: 0.3769044876098633
test loss item: 0.2297956645488739
test loss item: 0.25440603494644165
test loss item: 0.17517304420471191
test loss item: 0.30115991830825806
test loss item: 0.18143166601657867
test loss item: 0.4488041400909424
test loss item: 0.2987237274646759
test loss item: 0.2524294853210449
test loss item: 0.19342251121997833
test loss item: 0.3838093876838684
test loss item: 0.5590581297874451
test loss item: 0.2294599562883377
test loss item: 0.14008741080760956
test loss item: 0.20220792293548584
test loss item: 0.16743841767311096
test loss item: 0.2541517913341522
test loss item: 0.7068652510643005
test loss item: 0.47389498353004456
test loss item: 0.21107730269432068
test loss item: 0.19941911101341248
test loss item: 0.18851904571056366
test loss item: 0.37638017535209656
test loss item: 0.20349912345409393
test loss item: 0.17418085038661957
test loss item: 0.20596185326576233
test loss item: 0.6921437978744507
test loss item: 0.2852221429347992
test loss item: 0.23365676403045654
test loss item: 0.21824297308921814
test loss item: 0.486595094203949
test loss item: 0.34112846851348877
test loss item: 0.10162048041820526
test loss item: 0.7040298581123352
test loss item: 0.24722950160503387
test loss item: 0.2881528437137604
test loss item: 0.13440656661987305
test loss item: 0.16299937665462494
test loss item: 0.15938664972782135
test loss item: 1.3094115257263184
test loss item: 0.3644893169403076
test loss item: 0.18251295387744904
test loss item: 0.10155798494815826
test loss item: 0.7606093883514404
test loss item: 0.6707751750946045
test loss item: 0.8601580858230591
test loss item: 0.19117605686187744
test loss item: 0.2095317542552948
test loss item: 0.1062435433268547
test loss item: 0.0973895713686943
test loss item: 0.26674047112464905
Epoch [58/100], Training Loss: 0.3605, Testing Loss: 0.3333
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 59/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3636140823364258
1
train loss item: 0.8259609937667847
2
train loss item: 0.1690586507320404
3
train loss item: 0.3440847396850586
4
train loss item: 0.29236698150634766
5
train loss item: 0.2626653015613556
6
train loss item: 0.16347302496433258
7
train loss item: 0.5711256265640259
8
train loss item: 0.10909916460514069
9
train loss item: 0.18460345268249512
10
train loss item: 0.23031361401081085
11
train loss item: 0.2104162871837616
12
train loss item: 0.12151483446359634
13
train loss item: 0.3319782316684723
14
train loss item: 0.21311530470848083
15
train loss item: 0.3903263211250305
16
train loss item: 0.07804223150014877
17
train loss item: 0.19770017266273499
18
train loss item: 0.24317967891693115
19
train loss item: 0.18022951483726501
20
train loss item: 0.14450426399707794
21
train loss item: 0.10859636217355728
22
train loss item: 0.5280057787895203
23
train loss item: 0.5818377733230591
24
train loss item: 0.3525407910346985
25
train loss item: 0.14870448410511017
26
train loss item: 0.15748544037342072
27
train loss item: 0.22256071865558624
28
train loss item: 0.0777808129787445
29
train loss item: 0.4146669805049896
30
train loss item: 1.673952579498291
31
train loss item: 0.38030579686164856
32
train loss item: 0.10472578555345535
33
train loss item: 0.25104740262031555
34
train loss item: 0.1343889981508255
35
train loss item: 2.0250513553619385
36
train loss item: 0.34688836336135864
37
train loss item: 0.23803432285785675
38
train loss item: 0.2921425402164459
39
train loss item: 0.23705469071865082
40
train loss item: 0.1342979073524475
41
train loss item: 0.19961093366146088
42
train loss item: 0.2225317358970642
43
train loss item: 0.14214107394218445
44
train loss item: 0.5599271059036255
45
train loss item: 0.1145000010728836
46
train loss item: 0.1079317107796669
47
train loss item: 0.21508480608463287
48
train loss item: 0.17298997938632965
49
train loss item: 0.13118892908096313
50
train loss item: 0.17841799557209015
51
train loss item: 0.5687884092330933
52
train loss item: 0.08524375408887863
53
train loss item: 0.11786437779664993
54
train loss item: 1.8901004791259766
55
train loss item: 0.16279412806034088
56
train loss item: 0.20741406083106995
57
train loss item: 0.1935422718524933
58
train loss item: 0.129958376288414
59
train loss item: 0.11896273493766785
60
train loss item: 0.5374876260757446
61
train loss item: 1.7543635368347168
62
train loss item: 0.1570717692375183
63
train loss item: 0.24563442170619965
64
train loss item: 0.13312944769859314
65
train loss item: 0.3439297676086426
66
train loss item: 0.28487566113471985
67
train loss item: 0.1613125056028366
68
train loss item: 0.1946573704481125
69
train loss item: 0.2265176624059677
70
train loss item: 0.18403998017311096
71
train loss item: 0.11993202567100525
72
train loss item: 0.12977899610996246
73
train loss item: 0.22112520039081573
74
train loss item: 0.09315390884876251
75
train loss item: 0.10979948192834854
76
train loss item: 0.5957465767860413
77
train loss item: 0.9451090097427368
78
train loss item: 0.08325988799333572
79
train loss item: 0.2001599669456482
80
train loss item: 0.11001142114400864
81
train loss item: 0.1461874097585678
82
train loss item: 0.152002215385437
83
train loss item: 0.3551716208457947
84
train loss item: 0.2627224326133728
85
train loss item: 0.3716806471347809
86
train loss item: 3.705601215362549
87
train loss item: 0.12572243809700012
88
train loss item: 0.2503451108932495
epoch train loss: 0.3568198150128461
testing phase
test loss item: 0.16456665098667145
test loss item: 0.12175939232110977
test loss item: 0.4622493088245392
test loss item: 0.20970933139324188
test loss item: 0.23252752423286438
test loss item: 0.13201044499874115
test loss item: 1.2742893695831299
test loss item: 0.4453968405723572
test loss item: 0.1774049699306488
test loss item: 0.31667476892471313
test loss item: 0.7164965271949768
test loss item: 0.1598970592021942
test loss item: 0.15624456107616425
test loss item: 0.2413846254348755
test loss item: 0.16258187592029572
test loss item: 0.10571860522031784
test loss item: 0.21478506922721863
test loss item: 0.38338255882263184
test loss item: 0.5298299789428711
test loss item: 0.20101307332515717
test loss item: 0.5782080292701721
test loss item: 0.31976833939552307
test loss item: 0.24344760179519653
test loss item: 0.15231744945049286
test loss item: 0.18663723766803741
test loss item: 0.19707521796226501
test loss item: 0.25408056378364563
test loss item: 0.17466412484645844
test loss item: 0.26756009459495544
test loss item: 0.28094905614852905
test loss item: 0.6254639625549316
test loss item: 0.09460873901844025
test loss item: 0.13594205677509308
test loss item: 0.49131831526756287
test loss item: 0.3496321141719818
test loss item: 0.4473554790019989
test loss item: 0.6272100806236267
test loss item: 1.222849726676941
test loss item: 0.37969350814819336
test loss item: 0.22653692960739136
test loss item: 0.25387731194496155
test loss item: 0.16975897550582886
test loss item: 0.3032256066799164
test loss item: 0.18320536613464355
test loss item: 0.4493243396282196
test loss item: 0.29393571615219116
test loss item: 0.2482178509235382
test loss item: 0.18891966342926025
test loss item: 0.3872551918029785
test loss item: 0.5625743269920349
test loss item: 0.22891491651535034
test loss item: 0.13416825234889984
test loss item: 0.20147283375263214
test loss item: 0.16969820857048035
test loss item: 0.25503453612327576
test loss item: 0.7133609056472778
test loss item: 0.48046359419822693
test loss item: 0.2065778374671936
test loss item: 0.19793762266635895
test loss item: 0.1847071498632431
test loss item: 0.3791350722312927
test loss item: 0.2054368257522583
test loss item: 0.17475786805152893
test loss item: 0.20317494869232178
test loss item: 0.6960658431053162
test loss item: 0.2890762686729431
test loss item: 0.23264344036579132
test loss item: 0.21415045857429504
test loss item: 0.48406219482421875
test loss item: 0.34455302357673645
test loss item: 0.09379533678293228
test loss item: 0.704400897026062
test loss item: 0.2447649985551834
test loss item: 0.2864762544631958
test loss item: 0.12736281752586365
test loss item: 0.15335869789123535
test loss item: 0.15517558157444
test loss item: 1.3255614042282104
test loss item: 0.36026617884635925
test loss item: 0.1747116595506668
test loss item: 0.09239950776100159
test loss item: 0.7706503868103027
test loss item: 0.675285816192627
test loss item: 0.8731621503829956
test loss item: 0.18759362399578094
test loss item: 0.2037433683872223
test loss item: 0.09047253429889679
test loss item: 0.09113285690546036
test loss item: 0.2203134149312973
Epoch [59/100], Training Loss: 0.3568, Testing Loss: 0.3318
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 60/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3573865592479706
1
train loss item: 0.8141623139381409
2
train loss item: 0.1663622260093689
3
train loss item: 0.33876076340675354
4
train loss item: 0.2890617847442627
5
train loss item: 0.25798919796943665
6
train loss item: 0.16135075688362122
7
train loss item: 0.5646522641181946
8
train loss item: 0.1074187159538269
9
train loss item: 0.18248488008975983
10
train loss item: 0.22627775371074677
11
train loss item: 0.21148943901062012
12
train loss item: 0.12023470550775528
13
train loss item: 0.32771599292755127
14
train loss item: 0.21044383943080902
15
train loss item: 0.38457250595092773
16
train loss item: 0.07681908458471298
17
train loss item: 0.19559656083583832
18
train loss item: 0.23822589218616486
19
train loss item: 0.17958709597587585
20
train loss item: 0.14306750893592834
21
train loss item: 0.10739105939865112
22
train loss item: 0.5168766975402832
23
train loss item: 0.5733494162559509
24
train loss item: 0.3479207456111908
25
train loss item: 0.14646115899085999
26
train loss item: 0.15554668009281158
27
train loss item: 0.21947428584098816
28
train loss item: 0.07658395916223526
29
train loss item: 0.4054802358150482
30
train loss item: 1.6640679836273193
31
train loss item: 0.37291252613067627
32
train loss item: 0.10354315489530563
33
train loss item: 0.24552220106124878
34
train loss item: 0.13271261751651764
35
train loss item: 2.0185911655426025
36
train loss item: 0.3425700068473816
37
train loss item: 0.23666775226593018
38
train loss item: 0.2883976697921753
39
train loss item: 0.23453353345394135
40
train loss item: 0.13353565335273743
41
train loss item: 0.19622816145420074
42
train loss item: 0.22141623497009277
43
train loss item: 0.14009134471416473
44
train loss item: 0.5557060241699219
45
train loss item: 0.11363501846790314
46
train loss item: 0.1055619865655899
47
train loss item: 0.2124328911304474
48
train loss item: 0.16956573724746704
49
train loss item: 0.12997238337993622
50
train loss item: 0.17595365643501282
51
train loss item: 0.5561143755912781
52
train loss item: 0.08390629291534424
53
train loss item: 0.11680538952350616
54
train loss item: 1.8838741779327393
55
train loss item: 0.15987643599510193
56
train loss item: 0.2045392096042633
57
train loss item: 0.18976150453090668
58
train loss item: 0.12789098918437958
59
train loss item: 0.11800280958414078
60
train loss item: 0.5276676416397095
61
train loss item: 1.7460664510726929
62
train loss item: 0.1558895707130432
63
train loss item: 0.24463248252868652
64
train loss item: 0.13170476257801056
65
train loss item: 0.33929550647735596
66
train loss item: 0.28147000074386597
67
train loss item: 0.15924349427223206
68
train loss item: 0.19261492788791656
69
train loss item: 0.22456243634223938
70
train loss item: 0.18212150037288666
71
train loss item: 0.11816322803497314
72
train loss item: 0.12797881662845612
73
train loss item: 0.21808521449565887
74
train loss item: 0.09185971319675446
75
train loss item: 0.10847814381122589
76
train loss item: 0.5853163003921509
77
train loss item: 0.9332395195960999
78
train loss item: 0.08223617821931839
79
train loss item: 0.20012742280960083
80
train loss item: 0.10958947986364365
81
train loss item: 0.14469873905181885
82
train loss item: 0.15143294632434845
83
train loss item: 0.34658506512641907
84
train loss item: 0.2599606513977051
85
train loss item: 0.36573556065559387
86
train loss item: 3.696920156478882
87
train loss item: 0.12374597042798996
88
train loss item: 0.2476249486207962
epoch train loss: 0.35319303143560216
testing phase
test loss item: 0.16815683245658875
test loss item: 0.12347214668989182
test loss item: 0.45263180136680603
test loss item: 0.20801235735416412
test loss item: 0.23814737796783447
test loss item: 0.1613714098930359
test loss item: 1.30057954788208
test loss item: 0.45152747631073
test loss item: 0.1777479350566864
test loss item: 0.3136083483695984
test loss item: 0.6912686824798584
test loss item: 0.15712614357471466
test loss item: 0.15412957966327667
test loss item: 0.24094721674919128
test loss item: 0.16245515644550323
test loss item: 0.10586521774530411
test loss item: 0.21627432107925415
test loss item: 0.37866225838661194
test loss item: 0.5414190888404846
test loss item: 0.20226219296455383
test loss item: 0.5684500336647034
test loss item: 0.32300788164138794
test loss item: 0.23863883316516876
test loss item: 0.15593639016151428
test loss item: 0.186151921749115
test loss item: 0.1988806128501892
test loss item: 0.2554766535758972
test loss item: 0.18158778548240662
test loss item: 0.2683621346950531
test loss item: 0.2789781093597412
test loss item: 0.6246469616889954
test loss item: 0.09445890784263611
test loss item: 0.13776494562625885
test loss item: 0.48198211193084717
test loss item: 0.3434422016143799
test loss item: 0.4299297630786896
test loss item: 0.625171422958374
test loss item: 1.1834373474121094
test loss item: 0.374686062335968
test loss item: 0.24119403958320618
test loss item: 0.2572372257709503
test loss item: 0.18086859583854675
test loss item: 0.29685351252555847
test loss item: 0.18246516585350037
test loss item: 0.4434511065483093
test loss item: 0.2972690463066101
test loss item: 0.2434401959180832
test loss item: 0.19194640219211578
test loss item: 0.385727196931839
test loss item: 0.5564029216766357
test loss item: 0.22593526542186737
test loss item: 0.1334122121334076
test loss item: 0.20079538226127625
test loss item: 0.16205273568630219
test loss item: 0.24957600235939026
test loss item: 0.696896493434906
test loss item: 0.47205498814582825
test loss item: 0.20238623023033142
test loss item: 0.19818483293056488
test loss item: 0.1819208562374115
test loss item: 0.3757378160953522
test loss item: 0.20974420011043549
test loss item: 0.17855587601661682
test loss item: 0.20284488797187805
test loss item: 0.6893450617790222
test loss item: 0.28467410802841187
test loss item: 0.2342413365840912
test loss item: 0.2191253900527954
test loss item: 0.4766111671924591
test loss item: 0.3425765633583069
test loss item: 0.10146985203027725
test loss item: 0.7210046648979187
test loss item: 0.24571527540683746
test loss item: 0.29320791363716125
test loss item: 0.13683775067329407
test loss item: 0.1639888882637024
test loss item: 0.15920862555503845
test loss item: 1.2770975828170776
test loss item: 0.3556818962097168
test loss item: 0.19604404270648956
test loss item: 0.11086421459913254
test loss item: 0.76406329870224
test loss item: 0.6725556254386902
test loss item: 0.8396050333976746
test loss item: 0.18745426833629608
test loss item: 0.20680056512355804
test loss item: 0.11987766623497009
test loss item: 0.09043588489294052
test loss item: 0.3619977533817291
Epoch [60/100], Training Loss: 0.3532, Testing Loss: 0.3327
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 61/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.35068750381469727
1
train loss item: 0.8044242262840271
2
train loss item: 0.16578033566474915
3
train loss item: 0.33539092540740967
4
train loss item: 0.28607189655303955
5
train loss item: 0.25338804721832275
6
train loss item: 0.1613764613866806
7
train loss item: 0.5595030188560486
8
train loss item: 0.10595755279064178
9
train loss item: 0.18058304488658905
10
train loss item: 0.2227330058813095
11
train loss item: 0.20724596083164215
12
train loss item: 0.12032394111156464
13
train loss item: 0.3215581774711609
14
train loss item: 0.2062491774559021
15
train loss item: 0.38046225905418396
16
train loss item: 0.07559267431497574
17
train loss item: 0.1927708089351654
18
train loss item: 0.2361152619123459
19
train loss item: 0.17818693816661835
20
train loss item: 0.14219261705875397
21
train loss item: 0.10719103366136551
22
train loss item: 0.5074130892753601
23
train loss item: 0.5647087693214417
24
train loss item: 0.3490673899650574
25
train loss item: 0.14615587890148163
26
train loss item: 0.15418274700641632
27
train loss item: 0.21716493368148804
28
train loss item: 0.0750247985124588
29
train loss item: 0.3999638557434082
30
train loss item: 1.6541252136230469
31
train loss item: 0.36644014716148376
32
train loss item: 0.10273871570825577
33
train loss item: 0.24159838259220123
34
train loss item: 0.13132089376449585
35
train loss item: 2.0113728046417236
36
train loss item: 0.34017953276634216
37
train loss item: 0.23620370030403137
38
train loss item: 0.28651630878448486
39
train loss item: 0.23199112713336945
40
train loss item: 0.13381081819534302
41
train loss item: 0.19370071589946747
42
train loss item: 0.21967151761054993
43
train loss item: 0.13933631777763367
44
train loss item: 0.5512351393699646
45
train loss item: 0.11221624910831451
46
train loss item: 0.10546897351741791
47
train loss item: 0.21537037193775177
48
train loss item: 0.16953757405281067
49
train loss item: 0.12823958694934845
50
train loss item: 0.17498591542243958
51
train loss item: 0.5494863986968994
52
train loss item: 0.08335601538419724
53
train loss item: 0.1152999997138977
54
train loss item: 1.8774633407592773
55
train loss item: 0.16095128655433655
56
train loss item: 0.20192353427410126
57
train loss item: 0.18884004652500153
58
train loss item: 0.12888114154338837
59
train loss item: 0.11731945723295212
60
train loss item: 0.5196262001991272
61
train loss item: 1.73615562915802
62
train loss item: 0.15422818064689636
63
train loss item: 0.24405786395072937
64
train loss item: 0.12883298099040985
65
train loss item: 0.3359869420528412
66
train loss item: 0.277101069688797
67
train loss item: 0.15876826643943787
68
train loss item: 0.19294460117816925
69
train loss item: 0.2225458025932312
70
train loss item: 0.18234579265117645
71
train loss item: 0.11962930113077164
72
train loss item: 0.12620612978935242
73
train loss item: 0.21790869534015656
74
train loss item: 0.09035157412290573
75
train loss item: 0.10677359998226166
76
train loss item: 0.5772426128387451
77
train loss item: 0.9282943606376648
78
train loss item: 0.08154892176389694
79
train loss item: 0.1976703554391861
80
train loss item: 0.10578079521656036
81
train loss item: 0.14417870342731476
82
train loss item: 0.14821210503578186
83
train loss item: 0.34175339341163635
84
train loss item: 0.26034048199653625
85
train loss item: 0.3608904182910919
86
train loss item: 3.6877071857452393
87
train loss item: 0.12328213453292847
88
train loss item: 0.245085209608078
epoch train loss: 0.35047749287626717
testing phase
test loss item: 0.16562381386756897
test loss item: 0.11680550128221512
test loss item: 0.4303857386112213
test loss item: 0.208857923746109
test loss item: 0.22630196809768677
test loss item: 0.12711793184280396
test loss item: 1.2276649475097656
test loss item: 0.43432462215423584
test loss item: 0.17085693776607513
test loss item: 0.30139586329460144
test loss item: 0.6739224791526794
test loss item: 0.16012445092201233
test loss item: 0.1462232619524002
test loss item: 0.23699530959129333
test loss item: 0.15516658127307892
test loss item: 0.09728016704320908
test loss item: 0.21159662306308746
test loss item: 0.3646608591079712
test loss item: 0.5145984292030334
test loss item: 0.19115230441093445
test loss item: 0.5505018830299377
test loss item: 0.3163563311100006
test loss item: 0.23913297057151794
test loss item: 0.14926479756832123
test loss item: 0.18193672597408295
test loss item: 0.19494092464447021
test loss item: 0.24720153212547302
test loss item: 0.17472732067108154
test loss item: 0.2600233554840088
test loss item: 0.2732664942741394
test loss item: 0.5905335545539856
test loss item: 0.08628731220960617
test loss item: 0.1344347596168518
test loss item: 0.4637354016304016
test loss item: 0.32970595359802246
test loss item: 0.42869284749031067
test loss item: 0.6108856797218323
test loss item: 1.143560528755188
test loss item: 0.36341622471809387
test loss item: 0.22302283346652985
test loss item: 0.2537938356399536
test loss item: 0.16714254021644592
test loss item: 0.2789308428764343
test loss item: 0.18400192260742188
test loss item: 0.43592116236686707
test loss item: 0.28145831823349
test loss item: 0.24480071663856506
test loss item: 0.18430499732494354
test loss item: 0.3674662411212921
test loss item: 0.5377405881881714
test loss item: 0.21878917515277863
test loss item: 0.12877200543880463
test loss item: 0.19714727997779846
test loss item: 0.1724562793970108
test loss item: 0.2418166995048523
test loss item: 0.6709885001182556
test loss item: 0.45977941155433655
test loss item: 0.198977530002594
test loss item: 0.1950855404138565
test loss item: 0.17559532821178436
test loss item: 0.35854965448379517
test loss item: 0.2058018147945404
test loss item: 0.17258967459201813
test loss item: 0.2012273222208023
test loss item: 0.6621893644332886
test loss item: 0.28852152824401855
test loss item: 0.2259223759174347
test loss item: 0.21109215915203094
test loss item: 0.4559844732284546
test loss item: 0.32824578881263733
test loss item: 0.08442752808332443
test loss item: 0.6796109676361084
test loss item: 0.2349693477153778
test loss item: 0.2764069736003876
test loss item: 0.12306411564350128
test loss item: 0.15461045503616333
test loss item: 0.14962849020957947
test loss item: 1.2389346361160278
test loss item: 0.35245048999786377
test loss item: 0.17430737614631653
test loss item: 0.08766493201255798
test loss item: 0.7226267457008362
test loss item: 0.6501420736312866
test loss item: 0.8124997615814209
test loss item: 0.18343839049339294
test loss item: 0.2006589025259018
test loss item: 0.08392950147390366
test loss item: 0.08366747945547104
test loss item: 0.19125965237617493
Epoch [61/100], Training Loss: 0.3505, Testing Loss: 0.3181
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 62/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3544620871543884
1
train loss item: 0.7982871532440186
2
train loss item: 0.1629461944103241
3
train loss item: 0.34048107266426086
4
train loss item: 0.28364449739456177
5
train loss item: 0.2578451633453369
6
train loss item: 0.1588464379310608
7
train loss item: 0.5579918622970581
8
train loss item: 0.10458439588546753
9
train loss item: 0.1847524642944336
10
train loss item: 0.2233273684978485
11
train loss item: 0.21462808549404144
12
train loss item: 0.11809335649013519
13
train loss item: 0.32865801453590393
14
train loss item: 0.20708094537258148
15
train loss item: 0.3764926791191101
16
train loss item: 0.07510527223348618
17
train loss item: 0.19547848403453827
18
train loss item: 0.2384551614522934
19
train loss item: 0.18456831574440002
20
train loss item: 0.14248786866664886
21
train loss item: 0.10794594883918762
22
train loss item: 0.4982505440711975
23
train loss item: 0.5597878694534302
24
train loss item: 0.3572246730327606
25
train loss item: 0.1455177515745163
26
train loss item: 0.15524886548519135
27
train loss item: 0.21614804863929749
28
train loss item: 0.07515819370746613
29
train loss item: 0.39231815934181213
30
train loss item: 1.642013669013977
31
train loss item: 0.36267775297164917
32
train loss item: 0.10331911593675613
33
train loss item: 0.24230429530143738
34
train loss item: 0.13129624724388123
35
train loss item: 2.0062255859375
36
train loss item: 0.34170404076576233
37
train loss item: 0.23977813124656677
38
train loss item: 0.2895483076572418
39
train loss item: 0.23524782061576843
40
train loss item: 0.1327206790447235
41
train loss item: 0.19361436367034912
42
train loss item: 0.2272261381149292
43
train loss item: 0.13759008049964905
44
train loss item: 0.5481562614440918
45
train loss item: 0.11255287379026413
46
train loss item: 0.10562766343355179
47
train loss item: 0.22049693763256073
48
train loss item: 0.16567203402519226
49
train loss item: 0.1286284327507019
50
train loss item: 0.17444348335266113
51
train loss item: 0.5385042428970337
52
train loss item: 0.08200918138027191
53
train loss item: 0.11569823324680328
54
train loss item: 1.8701642751693726
55
train loss item: 0.15369994938373566
56
train loss item: 0.20485447347164154
57
train loss item: 0.18903017044067383
58
train loss item: 0.12333964556455612
59
train loss item: 0.11814671009778976
60
train loss item: 0.5132558941841125
61
train loss item: 1.7269607782363892
62
train loss item: 0.15596416592597961
63
train loss item: 0.24498791992664337
64
train loss item: 0.13117246329784393
65
train loss item: 0.3410325348377228
66
train loss item: 0.2786813974380493
67
train loss item: 0.15814746916294098
68
train loss item: 0.19945786893367767
69
train loss item: 0.229264497756958
70
train loss item: 0.18352799117565155
71
train loss item: 0.11576709896326065
72
train loss item: 0.12418121099472046
73
train loss item: 0.21977996826171875
74
train loss item: 0.09009154140949249
75
train loss item: 0.10775911808013916
76
train loss item: 0.5733253955841064
77
train loss item: 0.9128353595733643
78
train loss item: 0.07982143759727478
79
train loss item: 0.20413857698440552
80
train loss item: 0.10788135975599289
81
train loss item: 0.1459578275680542
82
train loss item: 0.14874625205993652
83
train loss item: 0.3380878269672394
84
train loss item: 0.267688512802124
85
train loss item: 0.3599972724914551
86
train loss item: 3.679713487625122
87
train loss item: 0.12270905822515488
88
train loss item: 0.2509010434150696
epoch train loss: 0.3501566635926118
testing phase
test loss item: 0.21002398431301117
test loss item: 0.1512531340122223
test loss item: 0.46836036443710327
test loss item: 0.213597372174263
test loss item: 0.29770755767822266
test loss item: 0.2887544631958008
test loss item: 1.2472608089447021
test loss item: 0.4849495589733124
test loss item: 0.18089130520820618
test loss item: 0.3154587745666504
test loss item: 0.6852529644966125
test loss item: 0.15258118510246277
test loss item: 0.15589676797389984
test loss item: 0.24299417436122894
test loss item: 0.19236065447330475
test loss item: 0.11302728205919266
test loss item: 0.2186618596315384
test loss item: 0.3871784210205078
test loss item: 0.645527720451355
test loss item: 0.2076738178730011
test loss item: 0.5787283182144165
test loss item: 0.324505090713501
test loss item: 0.26371389627456665
test loss item: 0.17665351927280426
test loss item: 0.1918374001979828
test loss item: 0.28295937180519104
test loss item: 0.2620429992675781
test loss item: 0.23601341247558594
test loss item: 0.2853216230869293
test loss item: 0.2771129906177521
test loss item: 0.6404769420623779
test loss item: 0.10007540136575699
test loss item: 0.163837730884552
test loss item: 0.48955607414245605
test loss item: 0.35143718123435974
test loss item: 0.4210624694824219
test loss item: 0.6152364611625671
test loss item: 1.2064558267593384
test loss item: 0.37458640336990356
test loss item: 0.3156282305717468
test loss item: 0.256414532661438
test loss item: 0.3823798596858978
test loss item: 0.29563280940055847
test loss item: 0.17939996719360352
test loss item: 0.4434635639190674
test loss item: 0.30244818329811096
test loss item: 0.24130605161190033
test loss item: 0.20116010308265686
test loss item: 0.3969002068042755
test loss item: 0.5807970762252808
test loss item: 0.22633376717567444
test loss item: 0.1375800222158432
test loss item: 0.20408473908901215
test loss item: 0.15280656516551971
test loss item: 0.2566702663898468
test loss item: 0.7240157127380371
test loss item: 0.4649527370929718
test loss item: 0.2051200419664383
test loss item: 0.20426909625530243
test loss item: 0.18535619974136353
test loss item: 0.37732112407684326
test loss item: 0.21707011759281158
test loss item: 0.21619835495948792
test loss item: 0.20222453773021698
test loss item: 0.7350583076477051
test loss item: 0.2743779718875885
test loss item: 0.23710061609745026
test loss item: 0.2319549322128296
test loss item: 0.4874614179134369
test loss item: 0.3398514688014984
test loss item: 0.1423206478357315
test loss item: 0.709483802318573
test loss item: 0.24970802664756775
test loss item: 0.31365662813186646
test loss item: 0.18697158992290497
test loss item: 0.22412163019180298
test loss item: 0.17985622584819794
test loss item: 1.2994316816329956
test loss item: 0.3588370978832245
test loss item: 0.3168649971485138
test loss item: 0.209340900182724
test loss item: 0.8308424353599548
test loss item: 0.6558691263198853
test loss item: 0.8422768115997314
test loss item: 0.1927206665277481
test loss item: 0.2703716456890106
test loss item: 0.2362106591463089
test loss item: 0.09472282975912094
test loss item: 0.8461596369743347
Epoch [62/100], Training Loss: 0.3502, Testing Loss: 0.3588
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 63/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.34982457756996155
1
train loss item: 0.7930111885070801
2
train loss item: 0.16519442200660706
3
train loss item: 0.35047924518585205
4
train loss item: 0.2816258370876312
5
train loss item: 0.2546643316745758
6
train loss item: 0.16587494313716888
7
train loss item: 0.590883195400238
8
train loss item: 0.10537879914045334
9
train loss item: 0.18614892661571503
10
train loss item: 0.22100870311260223
11
train loss item: 0.20720091462135315
12
train loss item: 0.11950531601905823
13
train loss item: 0.3233613967895508
14
train loss item: 0.20659968256950378
15
train loss item: 0.3963603973388672
16
train loss item: 0.07388931512832642
17
train loss item: 0.19019141793251038
18
train loss item: 0.24226762354373932
19
train loss item: 0.19752195477485657
20
train loss item: 0.1495535522699356
21
train loss item: 0.10777589678764343
22
train loss item: 0.5278698801994324
23
train loss item: 0.56743323802948
24
train loss item: 0.37465426325798035
25
train loss item: 0.1452638953924179
26
train loss item: 0.15273457765579224
27
train loss item: 0.222041517496109
28
train loss item: 0.07300708442926407
29
train loss item: 0.40264037251472473
30
train loss item: 1.6495281457901
31
train loss item: 0.36357730627059937
32
train loss item: 0.1109417974948883
33
train loss item: 0.2414715737104416
34
train loss item: 0.12868225574493408
35
train loss item: 2.000992774963379
36
train loss item: 0.3340590298175812
37
train loss item: 0.23576106131076813
38
train loss item: 0.2905222177505493
39
train loss item: 0.23911705613136292
40
train loss item: 0.1398981362581253
41
train loss item: 0.19908688962459564
42
train loss item: 0.22415725886821747
43
train loss item: 0.1399279236793518
44
train loss item: 0.553634762763977
45
train loss item: 0.11095119267702103
46
train loss item: 0.10919933766126633
47
train loss item: 0.23231779038906097
48
train loss item: 0.17644238471984863
49
train loss item: 0.12972499430179596
50
train loss item: 0.19212497770786285
51
train loss item: 0.5437735319137573
52
train loss item: 0.08345644921064377
53
train loss item: 0.11565587669610977
54
train loss item: 1.8961952924728394
55
train loss item: 0.1624649614095688
56
train loss item: 0.20688475668430328
57
train loss item: 0.1927875131368637
58
train loss item: 0.13094159960746765
59
train loss item: 0.11651978641748428
60
train loss item: 0.5329136252403259
61
train loss item: 1.7249807119369507
62
train loss item: 0.16121578216552734
63
train loss item: 0.2550235390663147
64
train loss item: 0.1265752762556076
65
train loss item: 0.3325102925300598
66
train loss item: 0.27984705567359924
67
train loss item: 0.1618012636899948
68
train loss item: 0.20875410735607147
69
train loss item: 0.22329959273338318
70
train loss item: 0.1859685331583023
71
train loss item: 0.11847496032714844
72
train loss item: 0.12521089613437653
73
train loss item: 0.22148451209068298
74
train loss item: 0.08802792429924011
75
train loss item: 0.10484068095684052
76
train loss item: 0.5861060619354248
77
train loss item: 0.9756081700325012
78
train loss item: 0.08041498810052872
79
train loss item: 0.20726731419563293
80
train loss item: 0.10399845987558365
81
train loss item: 0.1450534462928772
82
train loss item: 0.15048851072788239
83
train loss item: 0.3454855680465698
84
train loss item: 0.2594243586063385
85
train loss item: 0.3880784511566162
86
train loss item: 3.674112319946289
87
train loss item: 0.12416664510965347
88
train loss item: 0.24326395988464355
epoch train loss: 0.3542602484145861
testing phase
test loss item: 0.1636732816696167
test loss item: 0.1172177866101265
test loss item: 0.4405372440814972
test loss item: 0.21192441880702972
test loss item: 0.22587962448596954
test loss item: 0.12596818804740906
test loss item: 1.3690401315689087
test loss item: 0.4649038016796112
test loss item: 0.17628242075443268
test loss item: 0.3114030063152313
test loss item: 0.6892499923706055
test loss item: 0.15736281871795654
test loss item: 0.16263480484485626
test loss item: 0.24092167615890503
test loss item: 0.15748001635074615
test loss item: 0.10061077028512955
test loss item: 0.21411143243312836
test loss item: 0.36200764775276184
test loss item: 0.5341596007347107
test loss item: 0.2018156796693802
test loss item: 0.542306125164032
test loss item: 0.3237508237361908
test loss item: 0.24132877588272095
test loss item: 0.15947826206684113
test loss item: 0.17819111049175262
test loss item: 0.19976456463336945
test loss item: 0.2541450560092926
test loss item: 0.170371413230896
test loss item: 0.2641656994819641
test loss item: 0.279763400554657
test loss item: 0.6267708539962769
test loss item: 0.09108629822731018
test loss item: 0.13852649927139282
test loss item: 0.4642332196235657
test loss item: 0.32875698804855347
test loss item: 0.45536935329437256
test loss item: 0.6427826881408691
test loss item: 1.1555311679840088
test loss item: 0.36656659841537476
test loss item: 0.23479841649532318
test loss item: 0.2550806403160095
test loss item: 0.16731221973896027
test loss item: 0.27915313839912415
test loss item: 0.18464012444019318
test loss item: 0.43091660737991333
test loss item: 0.2921426594257355
test loss item: 0.24910412728786469
test loss item: 0.192792147397995
test loss item: 0.3722309470176697
test loss item: 0.5433030128479004
test loss item: 0.22829297184944153
test loss item: 0.13440895080566406
test loss item: 0.1994628757238388
test loss item: 0.16547927260398865
test loss item: 0.24142594635486603
test loss item: 0.6722301840782166
test loss item: 0.4841327965259552
test loss item: 0.19427993893623352
test loss item: 0.19918258488178253
test loss item: 0.18565376102924347
test loss item: 0.3624078333377838
test loss item: 0.20141330361366272
test loss item: 0.1796698123216629
test loss item: 0.20123356580734253
test loss item: 0.685730516910553
test loss item: 0.29330700635910034
test loss item: 0.23406031727790833
test loss item: 0.21268987655639648
test loss item: 0.46821272373199463
test loss item: 0.3490997552871704
test loss item: 0.09299122542142868
test loss item: 0.7438370585441589
test loss item: 0.23986946046352386
test loss item: 0.29322338104248047
test loss item: 0.12570779025554657
test loss item: 0.15885578095912933
test loss item: 0.1581718772649765
test loss item: 1.2704288959503174
test loss item: 0.35140788555145264
test loss item: 0.1724545657634735
test loss item: 0.09235193580389023
test loss item: 0.7749667763710022
test loss item: 0.6837902069091797
test loss item: 0.8460074067115784
test loss item: 0.18989937007427216
test loss item: 0.1947649121284485
test loss item: 0.08644641935825348
test loss item: 0.08393549919128418
test loss item: 0.16680726408958435
Epoch [63/100], Training Loss: 0.3543, Testing Loss: 0.3273
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 64/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.34910890460014343
1
train loss item: 0.7792761325836182
2
train loss item: 0.16847103834152222
3
train loss item: 0.35376277565956116
4
train loss item: 0.2782190442085266
5
train loss item: 0.25422969460487366
6
train loss item: 0.15442927181720734
7
train loss item: 0.5461351871490479
8
train loss item: 0.10112372040748596
9
train loss item: 0.18355411291122437
10
train loss item: 0.23020821809768677
11
train loss item: 0.21132032573223114
12
train loss item: 0.11688460409641266
13
train loss item: 0.3497667908668518
14
train loss item: 0.20154514908790588
15
train loss item: 0.3693464994430542
16
train loss item: 0.07580020278692245
17
train loss item: 0.1949937492609024
18
train loss item: 0.2303321659564972
19
train loss item: 0.1734095960855484
20
train loss item: 0.13798126578330994
21
train loss item: 0.11369537562131882
22
train loss item: 0.4827080965042114
23
train loss item: 0.5752013921737671
24
train loss item: 0.335737019777298
25
train loss item: 0.17898818850517273
26
train loss item: 0.1736311912536621
27
train loss item: 0.20763413608074188
28
train loss item: 0.07597624510526657
29
train loss item: 0.3797813951969147
30
train loss item: 1.6250008344650269
31
train loss item: 0.40252014994621277
32
train loss item: 0.10354965180158615
33
train loss item: 0.2511655390262604
34
train loss item: 0.14093856513500214
35
train loss item: 1.9941409826278687
36
train loss item: 0.3404674530029297
37
train loss item: 0.24159684777259827
38
train loss item: 0.5545824766159058
39
train loss item: 0.22674597799777985
40
train loss item: 0.13382557034492493
41
train loss item: 0.18583761155605316
42
train loss item: 0.22321805357933044
43
train loss item: 0.1361851543188095
44
train loss item: 0.5415989756584167
45
train loss item: 0.11339683830738068
46
train loss item: 0.10913661122322083
47
train loss item: 0.20504961907863617
48
train loss item: 0.16615475714206696
49
train loss item: 0.1305299550294876
50
train loss item: 0.16608846187591553
51
train loss item: 0.5290634036064148
52
train loss item: 0.08097299933433533
53
train loss item: 0.12028000503778458
54
train loss item: 1.858514428138733
55
train loss item: 0.15248700976371765
56
train loss item: 0.19969883561134338
57
train loss item: 0.1862650364637375
58
train loss item: 0.1209186539053917
59
train loss item: 0.11806975305080414
60
train loss item: 0.5017899870872498
61
train loss item: 1.717540979385376
62
train loss item: 0.16641759872436523
63
train loss item: 0.24044950306415558
64
train loss item: 0.1328156441450119
65
train loss item: 0.3322908580303192
66
train loss item: 0.2871668040752411
67
train loss item: 0.16856606304645538
68
train loss item: 0.22319544851779938
69
train loss item: 0.24256449937820435
70
train loss item: 0.2124776840209961
71
train loss item: 0.1148209497332573
72
train loss item: 0.12092941254377365
73
train loss item: 0.21428470313549042
74
train loss item: 0.09028664976358414
75
train loss item: 0.10947088152170181
76
train loss item: 0.5658270716667175
77
train loss item: 0.9030022025108337
78
train loss item: 0.07848889380693436
79
train loss item: 0.19745084643363953
80
train loss item: 0.10747702419757843
81
train loss item: 0.14929038286209106
82
train loss item: 0.15093721449375153
83
train loss item: 0.32804012298583984
84
train loss item: 0.265902578830719
85
train loss item: 0.35155317187309265
86
train loss item: 3.668242931365967
87
train loss item: 0.13215744495391846
88
train loss item: 0.27621525526046753
epoch train loss: 0.35270679223068646
testing phase
test loss item: 0.16505739092826843
test loss item: 0.12158101797103882
test loss item: 0.40983450412750244
test loss item: 0.2057548463344574
test loss item: 0.22744126617908478
test loss item: 0.14122651517391205
test loss item: 1.3060489892959595
test loss item: 0.42230215668678284
test loss item: 0.16650450229644775
test loss item: 0.29563459753990173
test loss item: 0.6353958249092102
test loss item: 0.15220066905021667
test loss item: 0.14924730360507965
test loss item: 0.23118722438812256
test loss item: 0.15591944754123688
test loss item: 0.09949461370706558
test loss item: 0.20303510129451752
test loss item: 0.35087987780570984
test loss item: 0.5030294060707092
test loss item: 0.18775826692581177
test loss item: 0.5354268550872803
test loss item: 0.3121199309825897
test loss item: 0.24921715259552002
test loss item: 0.14717432856559753
test loss item: 0.17329438030719757
test loss item: 0.18731629848480225
test loss item: 0.24013686180114746
test loss item: 0.17247845232486725
test loss item: 0.25104328989982605
test loss item: 0.26673203706741333
test loss item: 0.5814732909202576
test loss item: 0.08928065747022629
test loss item: 0.13103869557380676
test loss item: 0.4490993618965149
test loss item: 0.3150535821914673
test loss item: 0.4217575192451477
test loss item: 0.6028396487236023
test loss item: 1.0622227191925049
test loss item: 0.35081425309181213
test loss item: 0.2249922752380371
test loss item: 0.24847100675106049
test loss item: 0.1674364060163498
test loss item: 0.28071630001068115
test loss item: 0.17600378394126892
test loss item: 0.41437384486198425
test loss item: 0.27843353152275085
test loss item: 0.25064966082572937
test loss item: 0.18152441084384918
test loss item: 0.3538202941417694
test loss item: 0.5104063153266907
test loss item: 0.21584224700927734
test loss item: 0.1297951340675354
test loss item: 0.19365517795085907
test loss item: 0.15815117955207825
test loss item: 0.23820790648460388
test loss item: 0.6225793361663818
test loss item: 0.46066907048225403
test loss item: 0.23056775331497192
test loss item: 0.1876913160085678
test loss item: 0.1759139746427536
test loss item: 0.3498517870903015
test loss item: 0.19378282129764557
test loss item: 0.16460733115673065
test loss item: 0.19298137724399567
test loss item: 0.6355319023132324
test loss item: 0.28621983528137207
test loss item: 0.2254420965909958
test loss item: 0.20517870783805847
test loss item: 0.44254356622695923
test loss item: 0.33022600412368774
test loss item: 0.08869443833827972
test loss item: 0.7024685740470886
test loss item: 0.22057311236858368
test loss item: 0.27560362219810486
test loss item: 0.12408814579248428
test loss item: 0.15633732080459595
test loss item: 0.15037965774536133
test loss item: 1.1575922966003418
test loss item: 0.3301686942577362
test loss item: 0.18224972486495972
test loss item: 0.09206646680831909
test loss item: 0.7330992817878723
test loss item: 0.650102436542511
test loss item: 0.7740446329116821
test loss item: 0.17703187465667725
test loss item: 0.1937817931175232
test loss item: 0.08951260149478912
test loss item: 0.08588214218616486
test loss item: 0.17669281363487244
Epoch [64/100], Training Loss: 0.3527, Testing Loss: 0.3119
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Epoch 65/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.34555816650390625
1
train loss item: 0.777317225933075
2
train loss item: 0.16219602525234222
3
train loss item: 0.325980544090271
4
train loss item: 0.2820487320423126
5
train loss item: 0.24974468350410461
6
train loss item: 0.15810778737068176
7
train loss item: 0.5440272688865662
8
train loss item: 0.10234197974205017
9
train loss item: 0.17736245691776276
10
train loss item: 0.22088871896266937
11
train loss item: 0.20968954265117645
12
train loss item: 0.11927677690982819
13
train loss item: 0.3254247009754181
14
train loss item: 0.1982535868883133
15
train loss item: 0.37786319851875305
16
train loss item: 0.07414456456899643
17
train loss item: 0.18844188749790192
18
train loss item: 0.23177386820316315
19
train loss item: 0.1754450798034668
20
train loss item: 0.1463300883769989
21
train loss item: 0.10521650314331055
22
train loss item: 0.5004589557647705
23
train loss item: 0.5458616018295288
24
train loss item: 0.34105557203292847
25
train loss item: 0.16880886256694794
26
train loss item: 0.15355607867240906
27
train loss item: 0.2086600959300995
28
train loss item: 0.07312972843647003
29
train loss item: 0.4031926393508911
30
train loss item: 1.6145683526992798
31
train loss item: 0.36742985248565674
32
train loss item: 0.100038081407547
33
train loss item: 0.23030687868595123
34
train loss item: 0.13233783841133118
35
train loss item: 1.9918640851974487
36
train loss item: 0.34692829847335815
37
train loss item: 0.23972457647323608
38
train loss item: 0.4593648612499237
39
train loss item: 0.22801165282726288
40
train loss item: 0.1317678540945053
41
train loss item: 0.18604078888893127
42
train loss item: 0.22360610961914062
43
train loss item: 0.13444045186042786
44
train loss item: 0.5383065938949585
45
train loss item: 0.11135102808475494
46
train loss item: 0.10211854428052902
47
train loss item: 0.20742569863796234
48
train loss item: 0.16237276792526245
49
train loss item: 0.12594132125377655
50
train loss item: 0.16865693032741547
51
train loss item: 0.5428500771522522
52
train loss item: 0.08102154731750488
53
train loss item: 0.1155376136302948
54
train loss item: 1.8543087244033813
55
train loss item: 0.1538323163986206
56
train loss item: 0.19822587072849274
57
train loss item: 0.182445228099823
58
train loss item: 0.12639851868152618
59
train loss item: 0.11222349852323532
60
train loss item: 0.4984835088253021
61
train loss item: 1.704262614250183
62
train loss item: 0.15351232886314392
63
train loss item: 0.23951448500156403
64
train loss item: 0.12335451692342758
65
train loss item: 0.33019644021987915
66
train loss item: 0.29183509945869446
67
train loss item: 0.15860892832279205
68
train loss item: 0.1947147697210312
69
train loss item: 0.23064324259757996
70
train loss item: 0.17808401584625244
71
train loss item: 0.12084267288446426
72
train loss item: 0.12088977545499802
73
train loss item: 0.21249552071094513
74
train loss item: 0.08827684819698334
75
train loss item: 0.10445331037044525
76
train loss item: 0.557050883769989
77
train loss item: 0.9087773561477661
78
train loss item: 0.0792229101061821
79
train loss item: 0.19783584773540497
80
train loss item: 0.10506885498762131
81
train loss item: 0.14586851000785828
82
train loss item: 0.14212460815906525
83
train loss item: 0.33063414692878723
84
train loss item: 0.26984360814094543
85
train loss item: 0.3545346260070801
86
train loss item: 3.660810947418213
87
train loss item: 0.11938796937465668
88
train loss item: 0.2593909800052643
epoch train loss: 0.3476665416795216
testing phase
test loss item: 0.16606976091861725
test loss item: 0.14037537574768066
test loss item: 0.49716439843177795
test loss item: 0.21079866588115692
test loss item: 0.2538328468799591
test loss item: 0.15246091783046722
test loss item: 1.258732795715332
test loss item: 0.4286666214466095
test loss item: 0.19253291189670563
test loss item: 0.32987597584724426
test loss item: 0.7450568079948425
test loss item: 0.16418589651584625
test loss item: 0.15674465894699097
test loss item: 0.2297877073287964
test loss item: 0.1811923235654831
test loss item: 0.11841778457164764
test loss item: 0.20574438571929932
test loss item: 0.4099181294441223
test loss item: 0.5657610893249512
test loss item: 0.19207613170146942
test loss item: 0.6165623068809509
test loss item: 0.31687042117118835
test loss item: 0.2625825107097626
test loss item: 0.15508560836315155
test loss item: 0.1904986947774887
test loss item: 0.28126972913742065
test loss item: 0.2510954439640045
test loss item: 0.1913285255432129
test loss item: 0.27676424384117126
test loss item: 0.28572574257850647
test loss item: 0.6498708724975586
test loss item: 0.10878444463014603
test loss item: 0.14113977551460266
test loss item: 0.5226954817771912
test loss item: 0.37186193466186523
test loss item: 0.44599929451942444
test loss item: 0.6124008297920227
test loss item: 1.2819424867630005
test loss item: 0.39280542731285095
test loss item: 0.22412483394145966
test loss item: 0.24910223484039307
test loss item: 0.2407611757516861
test loss item: 0.3247954249382019
test loss item: 0.18206799030303955
test loss item: 0.4605272710323334
test loss item: 0.28206610679626465
test loss item: 0.2521342933177948
test loss item: 0.18069687485694885
test loss item: 0.4087139070034027
test loss item: 0.6285324692726135
test loss item: 0.23712584376335144
test loss item: 0.13240103423595428
test loss item: 0.2031051069498062
test loss item: 0.1776409149169922
test loss item: 0.2693038880825043
test loss item: 0.7764813899993896
test loss item: 0.4797595143318176
test loss item: 0.2096007764339447
test loss item: 0.1977759599685669
test loss item: 0.18857641518115997
test loss item: 0.41266411542892456
test loss item: 0.20222890377044678
test loss item: 0.16758400201797485
test loss item: 0.19351960718631744
test loss item: 0.7350214123725891
test loss item: 0.2899338901042938
test loss item: 0.23060517013072968
test loss item: 0.21126744151115417
test loss item: 0.5066255927085876
test loss item: 0.3474429249763489
test loss item: 0.11071779578924179
test loss item: 0.6839405298233032
test loss item: 0.24090451002120972
test loss item: 0.27434486150741577
test loss item: 0.13197124004364014
test loss item: 0.15183937549591064
test loss item: 0.16203604638576508
test loss item: 1.3830716609954834
test loss item: 0.3548729121685028
test loss item: 0.18602928519248962
test loss item: 0.10468444228172302
test loss item: 0.8122431635856628
test loss item: 0.6731679439544678
test loss item: 0.9207738637924194
test loss item: 0.18545548617839813
test loss item: 0.31264621019363403
test loss item: 0.09848301857709885
test loss item: 0.09758063405752182
test loss item: 0.5161182284355164
Epoch [65/100], Training Loss: 0.3477, Testing Loss: 0.3478
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 66/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.33738285303115845
1
train loss item: 0.7679140567779541
2
train loss item: 0.16017009317874908
3
train loss item: 0.3194320499897003
4
train loss item: 0.28637441992759705
5
train loss item: 0.24291715025901794
6
train loss item: 0.15526974201202393
7
train loss item: 0.5441563725471497
8
train loss item: 0.10023839771747589
9
train loss item: 0.17748351395130157
10
train loss item: 0.21217072010040283
11
train loss item: 0.20439673960208893
12
train loss item: 0.1172308623790741
13
train loss item: 0.31219711899757385
14
train loss item: 0.19758641719818115
15
train loss item: 0.3726625442504883
16
train loss item: 0.07157327979803085
17
train loss item: 0.18468646705150604
18
train loss item: 0.22382225096225739
19
train loss item: 0.17458327114582062
20
train loss item: 0.14353857934474945
21
train loss item: 0.10170024633407593
22
train loss item: 0.48657044768333435
23
train loss item: 0.534221887588501
24
train loss item: 0.33807528018951416
25
train loss item: 0.14683906733989716
26
train loss item: 0.14967018365859985
27
train loss item: 0.21111375093460083
28
train loss item: 0.07085318863391876
29
train loss item: 0.3914053738117218
30
train loss item: 1.6149015426635742
31
train loss item: 0.3474384844303131
32
train loss item: 0.09844208508729935
33
train loss item: 0.2355104684829712
34
train loss item: 0.1271687150001526
35
train loss item: 1.9896907806396484
36
train loss item: 0.3299826383590698
37
train loss item: 0.2348337471485138
38
train loss item: 0.31796878576278687
39
train loss item: 0.22892165184020996
40
train loss item: 0.13443757593631744
41
train loss item: 0.18687422573566437
42
train loss item: 0.22634609043598175
43
train loss item: 0.13457220792770386
44
train loss item: 0.5420151948928833
45
train loss item: 0.11078883707523346
46
train loss item: 0.10083257406949997
47
train loss item: 0.20840981602668762
48
train loss item: 0.16448459029197693
49
train loss item: 0.12457700818777084
50
train loss item: 0.1710045039653778
51
train loss item: 0.5316382050514221
52
train loss item: 0.07841639965772629
53
train loss item: 0.1128118634223938
54
train loss item: 1.8537060022354126
55
train loss item: 0.15633085370063782
56
train loss item: 0.19299425184726715
57
train loss item: 0.19003628194332123
58
train loss item: 0.12075059860944748
59
train loss item: 0.11632286757230759
60
train loss item: 0.5036337375640869
61
train loss item: 1.7041441202163696
62
train loss item: 0.14953407645225525
63
train loss item: 0.24158594012260437
64
train loss item: 0.1278582364320755
65
train loss item: 0.31860727071762085
66
train loss item: 0.2709237337112427
67
train loss item: 0.15883567929267883
68
train loss item: 0.1927785575389862
69
train loss item: 0.21864226460456848
70
train loss item: 0.17627356946468353
71
train loss item: 0.11590506136417389
72
train loss item: 0.12156061083078384
73
train loss item: 0.21047422289848328
74
train loss item: 0.084779292345047
75
train loss item: 0.10359828174114227
76
train loss item: 0.547423779964447
77
train loss item: 0.8980401754379272
78
train loss item: 0.07611197233200073
79
train loss item: 0.19955624639987946
80
train loss item: 0.10427545011043549
81
train loss item: 0.14244751632213593
82
train loss item: 0.14646482467651367
83
train loss item: 0.3232390582561493
84
train loss item: 0.25503748655319214
85
train loss item: 0.3470800220966339
86
train loss item: 3.65708065032959
87
train loss item: 0.12382002919912338
88
train loss item: 0.24606306850910187
epoch train loss: 0.34251932707730304
testing phase
test loss item: 0.1757788509130478
test loss item: 0.11798525601625443
test loss item: 0.44583603739738464
test loss item: 0.20643383264541626
test loss item: 0.22158753871917725
test loss item: 0.12586377561092377
test loss item: 1.1874128580093384
test loss item: 0.4670008420944214
test loss item: 0.16798849403858185
test loss item: 0.2991085350513458
test loss item: 0.6434248685836792
test loss item: 0.14828351140022278
test loss item: 0.15229029953479767
test loss item: 0.22816653549671173
test loss item: 0.15633632242679596
test loss item: 0.09864833205938339
test loss item: 0.21168670058250427
test loss item: 0.36791253089904785
test loss item: 0.6304285526275635
test loss item: 0.19011768698692322
test loss item: 0.5498324632644653
test loss item: 0.31971701979637146
test loss item: 0.24259664118289948
test loss item: 0.14777164161205292
test loss item: 0.18195287883281708
test loss item: 0.33077767491340637
test loss item: 0.24074529111385345
test loss item: 0.16168704628944397
test loss item: 0.2540731430053711
test loss item: 0.2666128873825073
test loss item: 0.5903094410896301
test loss item: 0.08697845786809921
test loss item: 0.1346244215965271
test loss item: 0.47401198744773865
test loss item: 0.3332110345363617
test loss item: 0.38845887780189514
test loss item: 0.6100549697875977
test loss item: 1.1252729892730713
test loss item: 0.3582386076450348
test loss item: 0.21730978786945343
test loss item: 0.25312480330467224
test loss item: 0.2854757606983185
test loss item: 0.2862774133682251
test loss item: 0.18360482156276703
test loss item: 0.416776567697525
test loss item: 0.28429266810417175
test loss item: 0.2293553650379181
test loss item: 0.1770140826702118
test loss item: 0.3815397322177887
test loss item: 0.6116702556610107
test loss item: 0.21295006573200226
test loss item: 0.1260409951210022
test loss item: 0.19520050287246704
test loss item: 0.16905517876148224
test loss item: 0.24134302139282227
test loss item: 0.6746702194213867
test loss item: 0.44279882311820984
test loss item: 0.18840792775154114
test loss item: 0.1918947696685791
test loss item: 0.1729670614004135
test loss item: 0.36045631766319275
test loss item: 0.2161804884672165
test loss item: 0.18538297712802887
test loss item: 0.19498221576213837
test loss item: 0.6627271771430969
test loss item: 0.2816014587879181
test loss item: 0.22966314852237701
test loss item: 0.20663262903690338
test loss item: 0.4616483449935913
test loss item: 0.3430126905441284
test loss item: 0.0877397358417511
test loss item: 0.6914383769035339
test loss item: 0.23159770667552948
test loss item: 0.2910011410713196
test loss item: 0.12376190721988678
test loss item: 0.14174695312976837
test loss item: 0.1476520597934723
test loss item: 1.2122849225997925
test loss item: 0.33884143829345703
test loss item: 0.17705795168876648
test loss item: 0.08938038349151611
test loss item: 0.7583944201469421
test loss item: 0.64349764585495
test loss item: 0.7945881485939026
test loss item: 0.17866000533103943
test loss item: 0.3615752160549164
test loss item: 0.0889715775847435
test loss item: 0.08692657202482224
test loss item: 0.7118088006973267
Epoch [66/100], Training Loss: 0.3425, Testing Loss: 0.3290
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 67/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.332134485244751
1
train loss item: 0.7615100741386414
2
train loss item: 0.15768180787563324
3
train loss item: 0.3171344995498657
4
train loss item: 0.2710762917995453
5
train loss item: 0.23942339420318604
6
train loss item: 0.15137003362178802
7
train loss item: 0.5348533391952515
8
train loss item: 0.09867042303085327
9
train loss item: 0.17428959906101227
10
train loss item: 0.2067616730928421
11
train loss item: 0.20232996344566345
12
train loss item: 0.1170317605137825
13
train loss item: 0.3075372278690338
14
train loss item: 0.19200143218040466
15
train loss item: 0.3586001396179199
16
train loss item: 0.07068169116973877
17
train loss item: 0.18261761963367462
18
train loss item: 0.22175121307373047
19
train loss item: 0.17463208734989166
20
train loss item: 0.14237987995147705
21
train loss item: 0.10066186636686325
22
train loss item: 0.4771256744861603
23
train loss item: 0.5260453224182129
24
train loss item: 0.3272863030433655
25
train loss item: 0.13850805163383484
26
train loss item: 0.14737971127033234
27
train loss item: 0.2025497853755951
28
train loss item: 0.06976272910833359
29
train loss item: 0.3778780400753021
30
train loss item: 1.5997995138168335
31
train loss item: 0.3510483503341675
32
train loss item: 0.09672746062278748
33
train loss item: 0.2247399091720581
34
train loss item: 0.12627652287483215
35
train loss item: 1.9784599542617798
36
train loss item: 0.31761568784713745
37
train loss item: 0.23286843299865723
38
train loss item: 0.3049188554286957
39
train loss item: 0.22198475897312164
40
train loss item: 0.12891489267349243
41
train loss item: 0.18110083043575287
42
train loss item: 0.22252681851387024
43
train loss item: 0.13175202906131744
44
train loss item: 0.5334861278533936
45
train loss item: 0.10903450846672058
46
train loss item: 0.09877264499664307
47
train loss item: 0.2054263949394226
48
train loss item: 0.16245126724243164
49
train loss item: 0.12322685122489929
50
train loss item: 0.1686367243528366
51
train loss item: 0.5265614986419678
52
train loss item: 0.07773993164300919
53
train loss item: 0.1108090728521347
54
train loss item: 1.845473051071167
55
train loss item: 0.15414384007453918
56
train loss item: 0.18780961632728577
57
train loss item: 0.18392179906368256
58
train loss item: 0.11974504590034485
59
train loss item: 0.1141778826713562
60
train loss item: 0.4855590760707855
61
train loss item: 1.690609097480774
62
train loss item: 0.14989545941352844
63
train loss item: 0.24310949444770813
64
train loss item: 0.12319401651620865
65
train loss item: 0.31377044320106506
66
train loss item: 0.26694256067276
67
train loss item: 0.15441566705703735
68
train loss item: 0.19237107038497925
69
train loss item: 0.21608984470367432
70
train loss item: 0.1744614839553833
71
train loss item: 0.11520200222730637
72
train loss item: 0.11872553080320358
73
train loss item: 0.208480104804039
74
train loss item: 0.08358027040958405
75
train loss item: 0.10277524590492249
76
train loss item: 0.537331759929657
77
train loss item: 0.8920345306396484
78
train loss item: 0.0765165388584137
79
train loss item: 0.196648508310318
80
train loss item: 0.10349627584218979
81
train loss item: 0.1397516429424286
82
train loss item: 0.14512059092521667
83
train loss item: 0.3199557363986969
84
train loss item: 0.2489817887544632
85
train loss item: 0.3334970772266388
86
train loss item: 3.645831823348999
87
train loss item: 0.12013109028339386
88
train loss item: 0.24317625164985657
epoch train loss: 0.3377918132235495
testing phase
test loss item: 0.15720781683921814
test loss item: 0.11661556363105774
test loss item: 0.41777336597442627
test loss item: 0.20167452096939087
test loss item: 0.21721979975700378
test loss item: 0.12591184675693512
test loss item: 1.26889967918396
test loss item: 0.4599572718143463
test loss item: 0.16482777893543243
test loss item: 0.2899540364742279
test loss item: 0.6513311266899109
test loss item: 0.15184010565280914
test loss item: 0.1503322571516037
test loss item: 0.22422190010547638
test loss item: 0.15160198509693146
test loss item: 0.09510879218578339
test loss item: 0.20616479218006134
test loss item: 0.3419284224510193
test loss item: 0.5335028171539307
test loss item: 0.18626078963279724
test loss item: 0.5117620825767517
test loss item: 0.3163785934448242
test loss item: 0.22553174197673798
test loss item: 0.14375966787338257
test loss item: 0.16985741257667542
test loss item: 0.2016320526599884
test loss item: 0.23468631505966187
test loss item: 0.16422832012176514
test loss item: 0.25207656621932983
test loss item: 0.2598486542701721
test loss item: 0.5919248461723328
test loss item: 0.08600129187107086
test loss item: 0.1299528330564499
test loss item: 0.4412915110588074
test loss item: 0.31141477823257446
test loss item: 0.4023531675338745
test loss item: 0.6204293370246887
test loss item: 1.1021978855133057
test loss item: 0.3429504632949829
test loss item: 0.21664761006832123
test loss item: 0.2490430772304535
test loss item: 0.17478607594966888
test loss item: 0.2642940580844879
test loss item: 0.17949315905570984
test loss item: 0.3968994617462158
test loss item: 0.27492791414260864
test loss item: 0.23290683329105377
test loss item: 0.17581476271152496
test loss item: 0.3632088601589203
test loss item: 0.5361372232437134
test loss item: 0.2105865329504013
test loss item: 0.11992695182561874
test loss item: 0.19349375367164612
test loss item: 0.16462574899196625
test loss item: 0.2293052077293396
test loss item: 0.6356402635574341
test loss item: 0.4521084129810333
test loss item: 0.18387946486473083
test loss item: 0.18488511443138123
test loss item: 0.1759403944015503
test loss item: 0.33730611205101013
test loss item: 0.2052716165781021
test loss item: 0.16456404328346252
test loss item: 0.1914806216955185
test loss item: 0.6396758556365967
test loss item: 0.2795045077800751
test loss item: 0.22260816395282745
test loss item: 0.2037860006093979
test loss item: 0.4410570561885834
test loss item: 0.34116557240486145
test loss item: 0.0864088237285614
test loss item: 0.7028598785400391
test loss item: 0.21677061915397644
test loss item: 0.27175164222717285
test loss item: 0.1223672404885292
test loss item: 0.15205521881580353
test loss item: 0.14571334421634674
test loss item: 1.194934606552124
test loss item: 0.3304554522037506
test loss item: 0.16788524389266968
test loss item: 0.08580368757247925
test loss item: 0.7292947769165039
test loss item: 0.6594681739807129
test loss item: 0.7959507703781128
test loss item: 0.17639806866645813
test loss item: 0.21975164115428925
test loss item: 0.08381444215774536
test loss item: 0.07970491796731949
test loss item: 0.27897563576698303
Epoch [67/100], Training Loss: 0.3378, Testing Loss: 0.3119
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7072.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7072.00 MB
Epoch 68/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.32906925678253174
1
train loss item: 0.7480152249336243
2
train loss item: 0.15667003393173218
3
train loss item: 0.31228554248809814
4
train loss item: 0.27067551016807556
5
train loss item: 0.23859088122844696
6
train loss item: 0.14886850118637085
7
train loss item: 0.5293357372283936
8
train loss item: 0.0966736301779747
9
train loss item: 0.1703442484140396
10
train loss item: 0.2077554315328598
11
train loss item: 0.20422446727752686
12
train loss item: 0.11721033602952957
13
train loss item: 0.3120853304862976
14
train loss item: 0.18868102133274078
15
train loss item: 0.35753244161605835
16
train loss item: 0.0707394927740097
17
train loss item: 0.18378432095050812
18
train loss item: 0.22492466866970062
19
train loss item: 0.16936402022838593
20
train loss item: 0.13996967673301697
21
train loss item: 0.10133477300405502
22
train loss item: 0.46069881319999695
23
train loss item: 0.5169216394424438
24
train loss item: 0.322062611579895
25
train loss item: 0.13944876194000244
26
train loss item: 0.14607180655002594
27
train loss item: 0.19755485653877258
28
train loss item: 0.06973055005073547
29
train loss item: 0.3635692894458771
30
train loss item: 1.5875903367996216
31
train loss item: 0.3452501595020294
32
train loss item: 0.098127081990242
33
train loss item: 0.22163991630077362
34
train loss item: 0.12586520612239838
35
train loss item: 1.970903992652893
36
train loss item: 0.31024226546287537
37
train loss item: 0.2357759177684784
38
train loss item: 0.2831275463104248
39
train loss item: 0.21870340406894684
40
train loss item: 0.12620043754577637
41
train loss item: 0.17680054903030396
42
train loss item: 0.22567573189735413
43
train loss item: 0.1291690319776535
44
train loss item: 0.5246849656105042
45
train loss item: 0.10848494619131088
46
train loss item: 0.09918900579214096
47
train loss item: 0.20004461705684662
48
train loss item: 0.15703034400939941
49
train loss item: 0.12213140726089478
50
train loss item: 0.16322535276412964
51
train loss item: 0.5085879564285278
52
train loss item: 0.0775214210152626
53
train loss item: 0.11085435748100281
54
train loss item: 1.8368927240371704
55
train loss item: 0.14972297847270966
56
train loss item: 0.18900878727436066
57
train loss item: 0.18025103211402893
58
train loss item: 0.11887513101100922
59
train loss item: 0.1107095330953598
60
train loss item: 0.47418656945228577
61
train loss item: 1.6796280145645142
62
train loss item: 0.1472078263759613
63
train loss item: 0.23709386587142944
64
train loss item: 0.1212574690580368
65
train loss item: 0.30956193804740906
66
train loss item: 0.2635612487792969
67
train loss item: 0.15396574139595032
68
train loss item: 0.18893848359584808
69
train loss item: 0.21260082721710205
70
train loss item: 0.17287299036979675
71
train loss item: 0.11325838416814804
72
train loss item: 0.11472050100564957
73
train loss item: 0.20552374422550201
74
train loss item: 0.0834033191204071
75
train loss item: 0.10237856954336166
76
train loss item: 0.5309672355651855
77
train loss item: 0.8791669607162476
78
train loss item: 0.07734120637178421
79
train loss item: 0.1941140741109848
80
train loss item: 0.10349348932504654
81
train loss item: 0.13810913264751434
82
train loss item: 0.13723811507225037
83
train loss item: 0.31257641315460205
84
train loss item: 0.24494338035583496
85
train loss item: 0.3351341187953949
86
train loss item: 3.635173797607422
87
train loss item: 0.1169738844037056
88
train loss item: 0.2398325353860855
epoch train loss: 0.33406407695807766
testing phase
test loss item: 0.15839755535125732
test loss item: 0.11983107030391693
test loss item: 0.42963239550590515
test loss item: 0.2032603621482849
test loss item: 0.22093626856803894
test loss item: 0.13215495645999908
test loss item: 1.304971694946289
test loss item: 0.44556838274002075
test loss item: 0.17146959900856018
test loss item: 0.29715895652770996
test loss item: 0.6780864000320435
test loss item: 0.15337365865707397
test loss item: 0.155235156416893
test loss item: 0.23404088616371155
test loss item: 0.15682554244995117
test loss item: 0.09764282405376434
test loss item: 0.20162154734134674
test loss item: 0.34738513827323914
test loss item: 0.5449695587158203
test loss item: 0.19187507033348083
test loss item: 0.518235981464386
test loss item: 0.31063902378082275
test loss item: 0.22524501383304596
test loss item: 0.1478687822818756
test loss item: 0.17156878113746643
test loss item: 0.24268709123134613
test loss item: 0.2375529557466507
test loss item: 0.167805477976799
test loss item: 0.253566175699234
test loss item: 0.26205524802207947
test loss item: 0.6167094707489014
test loss item: 0.08929059654474258
test loss item: 0.13384653627872467
test loss item: 0.44614288210868835
test loss item: 0.3173370063304901
test loss item: 0.4068068861961365
test loss item: 0.6191836595535278
test loss item: 1.1436221599578857
test loss item: 0.349007248878479
test loss item: 0.21895141899585724
test loss item: 0.24754002690315247
test loss item: 0.1951030045747757
test loss item: 0.2682936489582062
test loss item: 0.1788657307624817
test loss item: 0.4044094979763031
test loss item: 0.2700607180595398
test loss item: 0.22708870470523834
test loss item: 0.1856842190027237
test loss item: 0.36965838074684143
test loss item: 0.5661848187446594
test loss item: 0.2149171084165573
test loss item: 0.1266053467988968
test loss item: 0.19288218021392822
test loss item: 0.163772314786911
test loss item: 0.22984683513641357
test loss item: 0.6528403162956238
test loss item: 0.46010786294937134
test loss item: 0.18583522737026215
test loss item: 0.18584120273590088
test loss item: 0.17928145825862885
test loss item: 0.3523460328578949
test loss item: 0.19570013880729675
test loss item: 0.16731183230876923
test loss item: 0.1917707771062851
test loss item: 0.6500501036643982
test loss item: 0.28006115555763245
test loss item: 0.2196064442396164
test loss item: 0.20336048305034637
test loss item: 0.4486824572086334
test loss item: 0.34131723642349243
test loss item: 0.0910409688949585
test loss item: 0.7043269872665405
test loss item: 0.23216359317302704
test loss item: 0.27548179030418396
test loss item: 0.12299732118844986
test loss item: 0.14745600521564484
test loss item: 0.15065836906433105
test loss item: 1.236122965812683
test loss item: 0.34044793248176575
test loss item: 0.1693480908870697
test loss item: 0.08995986729860306
test loss item: 0.7700687050819397
test loss item: 0.6667978763580322
test loss item: 0.8304908871650696
test loss item: 0.18159054219722748
test loss item: 0.25635719299316406
test loss item: 0.08532516658306122
test loss item: 0.08233096450567245
test loss item: 0.3934362232685089
Epoch [68/100], Training Loss: 0.3341, Testing Loss: 0.3203
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7014.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7014.00 MB
Epoch 69/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3247818946838379
1
train loss item: 0.7349563837051392
2
train loss item: 0.15396152436733246
3
train loss item: 0.3055294454097748
4
train loss item: 0.2651544511318207
5
train loss item: 0.23482155799865723
6
train loss item: 0.14781439304351807
7
train loss item: 0.5245146155357361
8
train loss item: 0.09600311517715454
9
train loss item: 0.16826285421848297
10
train loss item: 0.20396989583969116
11
train loss item: 0.2069665640592575
12
train loss item: 0.11410191655158997
13
train loss item: 0.3045520782470703
14
train loss item: 0.18811042606830597
15
train loss item: 0.35068145394325256
16
train loss item: 0.06937836855649948
17
train loss item: 0.1859813928604126
18
train loss item: 0.2224002331495285
19
train loss item: 0.16369670629501343
20
train loss item: 0.13545402884483337
21
train loss item: 0.10084990411996841
22
train loss item: 0.45222383737564087
23
train loss item: 0.5125682950019836
24
train loss item: 0.3189485967159271
25
train loss item: 0.13812726736068726
26
train loss item: 0.14740626513957977
27
train loss item: 0.1952078491449356
28
train loss item: 0.06930837035179138
29
train loss item: 0.36040306091308594
30
train loss item: 1.5829414129257202
31
train loss item: 0.33576908707618713
32
train loss item: 0.10044479370117188
33
train loss item: 0.2186213880777359
34
train loss item: 0.1270599067211151
35
train loss item: 1.9668960571289062
36
train loss item: 0.3114319443702698
37
train loss item: 0.23465225100517273
38
train loss item: 0.27047571539878845
39
train loss item: 0.21657586097717285
40
train loss item: 0.12374324351549149
41
train loss item: 0.1745533049106598
42
train loss item: 0.22849711775779724
43
train loss item: 0.13043524324893951
44
train loss item: 0.5223909020423889
45
train loss item: 0.10953010618686676
46
train loss item: 0.10062165558338165
47
train loss item: 0.19598959386348724
48
train loss item: 0.15559040009975433
49
train loss item: 0.1213594526052475
50
train loss item: 0.15809859335422516
51
train loss item: 0.5063701272010803
52
train loss item: 0.07667270302772522
53
train loss item: 0.10953591018915176
54
train loss item: 1.8328334093093872
55
train loss item: 0.14530333876609802
56
train loss item: 0.18806208670139313
57
train loss item: 0.17811937630176544
58
train loss item: 0.1153368353843689
59
train loss item: 0.11271704733371735
60
train loss item: 0.46906983852386475
61
train loss item: 1.6750564575195312
62
train loss item: 0.14313162863254547
63
train loss item: 0.2336646020412445
64
train loss item: 0.12811513245105743
65
train loss item: 0.30578696727752686
66
train loss item: 0.26030609011650085
67
train loss item: 0.1539333164691925
68
train loss item: 0.1832580268383026
69
train loss item: 0.20836418867111206
70
train loss item: 0.1727607399225235
71
train loss item: 0.11078455299139023
72
train loss item: 0.11495097726583481
73
train loss item: 0.20060567557811737
74
train loss item: 0.08348668366670609
75
train loss item: 0.10433157533407211
76
train loss item: 0.523044764995575
77
train loss item: 0.872218668460846
78
train loss item: 0.07385004311800003
79
train loss item: 0.19459334015846252
80
train loss item: 0.10522472113370895
81
train loss item: 0.13806574046611786
82
train loss item: 0.1392878293991089
83
train loss item: 0.3071305751800537
84
train loss item: 0.23970147967338562
85
train loss item: 0.32607340812683105
86
train loss item: 3.6292386054992676
87
train loss item: 0.1145654246211052
88
train loss item: 0.23377129435539246
epoch train loss: 0.33136110066362984
testing phase
test loss item: 0.15639366209506989
test loss item: 0.1174047589302063
test loss item: 0.4331352710723877
test loss item: 0.19634142518043518
test loss item: 0.22146816551685333
test loss item: 0.13042648136615753
test loss item: 1.3127079010009766
test loss item: 0.46270817518234253
test loss item: 0.16930313408374786
test loss item: 0.2988511025905609
test loss item: 0.6561775207519531
test loss item: 0.14463649690151215
test loss item: 0.15644997358322144
test loss item: 0.2198859006166458
test loss item: 0.1550602912902832
test loss item: 0.10048113763332367
test loss item: 0.2009463906288147
test loss item: 0.3644673228263855
test loss item: 0.5384129285812378
test loss item: 0.1912478655576706
test loss item: 0.5533358454704285
test loss item: 0.3091937005519867
test loss item: 0.2282886654138565
test loss item: 0.14654558897018433
test loss item: 0.17313188314437866
test loss item: 0.22979393601417542
test loss item: 0.23383112251758575
test loss item: 0.16526749730110168
test loss item: 0.2507413923740387
test loss item: 0.2620633840560913
test loss item: 0.614830493927002
test loss item: 0.09029658138751984
test loss item: 0.1297762244939804
test loss item: 0.4548225998878479
test loss item: 0.32664430141448975
test loss item: 0.378691703081131
test loss item: 0.6224076151847839
test loss item: 1.123665690422058
test loss item: 0.35445791482925415
test loss item: 0.2187977135181427
test loss item: 0.24842646718025208
test loss item: 0.18769028782844543
test loss item: 0.2815035581588745
test loss item: 0.17359474301338196
test loss item: 0.4225102961063385
test loss item: 0.2732425630092621
test loss item: 0.22669506072998047
test loss item: 0.17721480131149292
test loss item: 0.3766820728778839
test loss item: 0.5536307692527771
test loss item: 0.22225408256053925
test loss item: 0.12388835847377777
test loss item: 0.19364941120147705
test loss item: 0.14481396973133087
test loss item: 0.23826342821121216
test loss item: 0.649693489074707
test loss item: 0.4509660303592682
test loss item: 0.20047587156295776
test loss item: 0.18890541791915894
test loss item: 0.1812659502029419
test loss item: 0.36110714077949524
test loss item: 0.20211276412010193
test loss item: 0.16558510065078735
test loss item: 0.19277848303318024
test loss item: 0.6516305804252625
test loss item: 0.26862749457359314
test loss item: 0.22059494256973267
test loss item: 0.20477160811424255
test loss item: 0.4513728618621826
test loss item: 0.33655741810798645
test loss item: 0.09500855207443237
test loss item: 0.7181310057640076
test loss item: 0.22965529561042786
test loss item: 0.27526023983955383
test loss item: 0.123116135597229
test loss item: 0.13603563606739044
test loss item: 0.14980719983577728
test loss item: 1.217890977859497
test loss item: 0.33230167627334595
test loss item: 0.16673502326011658
test loss item: 0.09248940646648407
test loss item: 0.7512985467910767
test loss item: 0.6672279238700867
test loss item: 0.8093463182449341
test loss item: 0.1803620606660843
test loss item: 0.22922329604625702
test loss item: 0.08872688561677933
test loss item: 0.08571165055036545
test loss item: 0.34888845682144165
Epoch [69/100], Training Loss: 0.3314, Testing Loss: 0.3187
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 70/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3174256384372711
1
train loss item: 0.7232402563095093
2
train loss item: 0.15314628183841705
3
train loss item: 0.30584537982940674
4
train loss item: 0.26355135440826416
5
train loss item: 0.22813871502876282
6
train loss item: 0.14605960249900818
7
train loss item: 0.5156961679458618
8
train loss item: 0.09328246116638184
9
train loss item: 0.16649480164051056
10
train loss item: 0.20132607221603394
11
train loss item: 0.19942672550678253
12
train loss item: 0.11492811888456345
13
train loss item: 0.29389020800590515
14
train loss item: 0.18431977927684784
15
train loss item: 0.347675085067749
16
train loss item: 0.0682031586766243
17
train loss item: 0.18136820197105408
18
train loss item: 0.21458281576633453
19
train loss item: 0.16345609724521637
20
train loss item: 0.13554443418979645
21
train loss item: 0.10059503465890884
22
train loss item: 0.4466630816459656
23
train loss item: 0.5027610659599304
24
train loss item: 0.32326504588127136
25
train loss item: 0.1335098147392273
26
train loss item: 0.14699694514274597
27
train loss item: 0.19291482865810394
28
train loss item: 0.06766457110643387
29
train loss item: 0.35180193185806274
30
train loss item: 1.5728569030761719
31
train loss item: 0.3279670178890228
32
train loss item: 0.09560004621744156
33
train loss item: 0.21405792236328125
34
train loss item: 0.12404406070709229
35
train loss item: 1.961144208908081
36
train loss item: 0.3058694005012512
37
train loss item: 0.22857975959777832
38
train loss item: 0.27205413579940796
39
train loss item: 0.21167047321796417
40
train loss item: 0.12436754256486893
41
train loss item: 0.1698472648859024
42
train loss item: 0.22208957374095917
43
train loss item: 0.13393434882164001
44
train loss item: 0.5198327898979187
45
train loss item: 0.10803462564945221
46
train loss item: 0.09778318554162979
47
train loss item: 0.19764792919158936
48
train loss item: 0.15279871225357056
49
train loss item: 0.11977185308933258
50
train loss item: 0.1555287390947342
51
train loss item: 0.49559882283210754
52
train loss item: 0.07585323601961136
53
train loss item: 0.10839574784040451
54
train loss item: 1.8270978927612305
55
train loss item: 0.14587365090847015
56
train loss item: 0.1809072047472
57
train loss item: 0.1756836324930191
58
train loss item: 0.12937074899673462
59
train loss item: 0.1088666245341301
60
train loss item: 0.4640245735645294
61
train loss item: 1.66669762134552
62
train loss item: 0.14384791254997253
63
train loss item: 0.23290590941905975
64
train loss item: 0.12060853093862534
65
train loss item: 0.3039090633392334
66
train loss item: 0.257398784160614
67
train loss item: 0.15067045390605927
68
train loss item: 0.18485774099826813
69
train loss item: 0.20930933952331543
70
train loss item: 0.16866856813430786
71
train loss item: 0.11089283972978592
72
train loss item: 0.11109543591737747
73
train loss item: 0.19953253865242004
74
train loss item: 0.08072863519191742
75
train loss item: 0.1010008230805397
76
train loss item: 0.514069676399231
77
train loss item: 0.8715712428092957
78
train loss item: 0.07387808710336685
79
train loss item: 0.18847762048244476
80
train loss item: 0.10051324218511581
81
train loss item: 0.13534095883369446
82
train loss item: 0.13689154386520386
83
train loss item: 0.3073659837245941
84
train loss item: 0.23618344962596893
85
train loss item: 0.3231630027294159
86
train loss item: 3.620087146759033
87
train loss item: 0.11439956724643707
88
train loss item: 0.23161324858665466
epoch train loss: 0.328164104162977
testing phase
test loss item: 0.15624022483825684
test loss item: 0.12692323327064514
test loss item: 0.435733437538147
test loss item: 0.20006735622882843
test loss item: 0.22559797763824463
test loss item: 0.13171765208244324
test loss item: 1.2425578832626343
test loss item: 0.4321018159389496
test loss item: 0.17291736602783203
test loss item: 0.3004617393016815
test loss item: 0.6555610299110413
test loss item: 0.14833644032478333
test loss item: 0.15755468606948853
test loss item: 0.2207833081483841
test loss item: 0.16162002086639404
test loss item: 0.11155513674020767
test loss item: 0.19884765148162842
test loss item: 0.36888980865478516
test loss item: 0.5255197286605835
test loss item: 0.19426488876342773
test loss item: 0.5474063158035278
test loss item: 0.30244943499565125
test loss item: 0.22660233080387115
test loss item: 0.1485387682914734
test loss item: 0.17477484047412872
test loss item: 0.2372972071170807
test loss item: 0.23641639947891235
test loss item: 0.16901054978370667
test loss item: 0.2557556629180908
test loss item: 0.26296064257621765
test loss item: 0.6008322834968567
test loss item: 0.10167773067951202
test loss item: 0.13376641273498535
test loss item: 0.4590732753276825
test loss item: 0.330808162689209
test loss item: 0.395832359790802
test loss item: 0.599704921245575
test loss item: 1.1179627180099487
test loss item: 0.3562476634979248
test loss item: 0.21445146203041077
test loss item: 0.24237875640392303
test loss item: 0.20180445909500122
test loss item: 0.2802360951900482
test loss item: 0.17283029854297638
test loss item: 0.4186181426048279
test loss item: 0.27085620164871216
test loss item: 0.22534078359603882
test loss item: 0.18622025847434998
test loss item: 0.37650343775749207
test loss item: 0.555973470211029
test loss item: 0.22452709078788757
test loss item: 0.12327194213867188
test loss item: 0.19214479625225067
test loss item: 0.1515510231256485
test loss item: 0.2397017627954483
test loss item: 0.6589398384094238
test loss item: 0.453148752450943
test loss item: 0.18443556129932404
test loss item: 0.19162635505199432
test loss item: 0.18205323815345764
test loss item: 0.36670437455177307
test loss item: 0.20097583532333374
test loss item: 0.16801609098911285
test loss item: 0.19042335450649261
test loss item: 0.6472377181053162
test loss item: 0.2718140780925751
test loss item: 0.22010120749473572
test loss item: 0.20252202451229095
test loss item: 0.4530799984931946
test loss item: 0.3272365629673004
test loss item: 0.10415416210889816
test loss item: 0.677073061466217
test loss item: 0.24933962523937225
test loss item: 0.2718723714351654
test loss item: 0.12456844747066498
test loss item: 0.13980314135551453
test loss item: 0.1518096625804901
test loss item: 1.2086580991744995
test loss item: 0.33473074436187744
test loss item: 0.16614598035812378
test loss item: 0.09572389721870422
test loss item: 0.7363744378089905
test loss item: 0.6443377137184143
test loss item: 0.8003018498420715
test loss item: 0.1779416799545288
test loss item: 0.24595390260219574
test loss item: 0.09037303179502487
test loss item: 0.09106750041246414
test loss item: 0.3881826400756836
Epoch [70/100], Training Loss: 0.3282, Testing Loss: 0.3182
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 71/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3125121593475342
1
train loss item: 0.7157750725746155
2
train loss item: 0.151899054646492
3
train loss item: 0.2961476445198059
4
train loss item: 0.2609381377696991
5
train loss item: 0.22736318409442902
6
train loss item: 0.1450244039297104
7
train loss item: 0.510143518447876
8
train loss item: 0.09216894954442978
9
train loss item: 0.16395783424377441
10
train loss item: 0.19794616103172302
11
train loss item: 0.19776049256324768
12
train loss item: 0.11240369081497192
13
train loss item: 0.28958597779273987
14
train loss item: 0.1811760514974594
15
train loss item: 0.3478970229625702
16
train loss item: 0.06718377768993378
17
train loss item: 0.1808752864599228
18
train loss item: 0.21142154932022095
19
train loss item: 0.16150632500648499
20
train loss item: 0.13267935812473297
21
train loss item: 0.09856156259775162
22
train loss item: 0.43366265296936035
23
train loss item: 0.49580901861190796
24
train loss item: 0.31320011615753174
25
train loss item: 0.13185714185237885
26
train loss item: 0.14526137709617615
27
train loss item: 0.19065310060977936
28
train loss item: 0.0670432299375534
29
train loss item: 0.3437758982181549
30
train loss item: 1.5654643774032593
31
train loss item: 0.3245522379875183
32
train loss item: 0.09559419006109238
33
train loss item: 0.21226222813129425
34
train loss item: 0.12276032567024231
35
train loss item: 1.9557899236679077
36
train loss item: 0.2992670238018036
37
train loss item: 0.22864677011966705
38
train loss item: 0.26640063524246216
39
train loss item: 0.2083882838487625
40
train loss item: 0.12377544492483139
41
train loss item: 0.1675066351890564
42
train loss item: 0.22197255492210388
43
train loss item: 0.12572328746318817
44
train loss item: 0.5163118243217468
45
train loss item: 0.10655786842107773
46
train loss item: 0.09630800783634186
47
train loss item: 0.19304165244102478
48
train loss item: 0.15167614817619324
49
train loss item: 0.11790134012699127
50
train loss item: 0.15321902930736542
51
train loss item: 0.48474323749542236
52
train loss item: 0.07495466619729996
53
train loss item: 0.10726495832204819
54
train loss item: 1.822044014930725
55
train loss item: 0.1454204022884369
56
train loss item: 0.17783686518669128
57
train loss item: 0.17659321427345276
58
train loss item: 0.11413918435573578
59
train loss item: 0.11050770431756973
60
train loss item: 0.45642438530921936
61
train loss item: 1.6584668159484863
62
train loss item: 0.14243574440479279
63
train loss item: 0.22994329035282135
64
train loss item: 0.1193738579750061
65
train loss item: 0.2995525002479553
66
train loss item: 0.2510315179824829
67
train loss item: 0.1475292295217514
68
train loss item: 0.17993806302547455
69
train loss item: 0.20409131050109863
70
train loss item: 0.16795814037322998
71
train loss item: 0.1096438392996788
72
train loss item: 0.11112689971923828
73
train loss item: 0.1964418590068817
74
train loss item: 0.08082639425992966
75
train loss item: 0.10065717250108719
76
train loss item: 0.5070593953132629
77
train loss item: 0.8584217429161072
78
train loss item: 0.0723501443862915
79
train loss item: 0.18616817891597748
80
train loss item: 0.10032570362091064
81
train loss item: 0.13343611359596252
82
train loss item: 0.1347535103559494
83
train loss item: 0.30224525928497314
84
train loss item: 0.2312554121017456
85
train loss item: 0.31561753153800964
86
train loss item: 3.6131114959716797
87
train loss item: 0.11201035231351852
88
train loss item: 0.22734446823596954
epoch train loss: 0.32463319231285137
testing phase
test loss item: 0.15672257542610168
test loss item: 0.11264460533857346
test loss item: 0.4195515215396881
test loss item: 0.1998296082019806
test loss item: 0.2147466391324997
test loss item: 0.12069368362426758
test loss item: 1.2571487426757812
test loss item: 0.4320377707481384
test loss item: 0.16463345289230347
test loss item: 0.2920648157596588
test loss item: 0.6411824226379395
test loss item: 0.14216341078281403
test loss item: 0.15083716809749603
test loss item: 0.22564807534217834
test loss item: 0.14920823276042938
test loss item: 0.09409196674823761
test loss item: 0.20123454928398132
test loss item: 0.35064026713371277
test loss item: 0.5156898498535156
test loss item: 0.19290272891521454
test loss item: 0.5171487331390381
test loss item: 0.3051839768886566
test loss item: 0.2208375632762909
test loss item: 0.14348235726356506
test loss item: 0.17085301876068115
test loss item: 0.21727490425109863
test loss item: 0.23438803851604462
test loss item: 0.15732616186141968
test loss item: 0.24837759137153625
test loss item: 0.2598937451839447
test loss item: 0.5861690640449524
test loss item: 0.0831446498632431
test loss item: 0.12884421646595
test loss item: 0.4432032108306885
test loss item: 0.314560204744339
test loss item: 0.4047107398509979
test loss item: 0.5981715321540833
test loss item: 1.075551986694336
test loss item: 0.34475022554397583
test loss item: 0.21346214413642883
test loss item: 0.24348251521587372
test loss item: 0.18834756314754486
test loss item: 0.26518380641937256
test loss item: 0.173681378364563
test loss item: 0.39943841099739075
test loss item: 0.27009448409080505
test loss item: 0.223270446062088
test loss item: 0.1877085268497467
test loss item: 0.3650646209716797
test loss item: 0.5369994044303894
test loss item: 0.2119850367307663
test loss item: 0.11745566874742508
test loss item: 0.19022628664970398
test loss item: 0.14783456921577454
test loss item: 0.2298748791217804
test loss item: 0.6361944079399109
test loss item: 0.46057334542274475
test loss item: 0.18040215969085693
test loss item: 0.18970981240272522
test loss item: 0.17360267043113708
test loss item: 0.35053080320358276
test loss item: 0.20349253714084625
test loss item: 0.16975590586662292
test loss item: 0.18741483986377716
test loss item: 0.6412809491157532
test loss item: 0.27513402700424194
test loss item: 0.22131280601024628
test loss item: 0.19852973520755768
test loss item: 0.4364190995693207
test loss item: 0.3274548053741455
test loss item: 0.0859309732913971
test loss item: 0.6807383298873901
test loss item: 0.24603170156478882
test loss item: 0.27570831775665283
test loss item: 0.12009448558092117
test loss item: 0.14057882130146027
test loss item: 0.1431591659784317
test loss item: 1.169657826423645
test loss item: 0.33235836029052734
test loss item: 0.1606423556804657
test loss item: 0.08572369068861008
test loss item: 0.7261713743209839
test loss item: 0.6420103311538696
test loss item: 0.7701008915901184
test loss item: 0.17526184022426605
test loss item: 0.22886255383491516
test loss item: 0.080846406519413
test loss item: 0.078257255256176
test loss item: 0.32923808693885803
Epoch [71/100], Training Loss: 0.3246, Testing Loss: 0.3098
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 72/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.30723124742507935
1
train loss item: 0.7084960341453552
2
train loss item: 0.15261797606945038
3
train loss item: 0.2906784415245056
4
train loss item: 0.2580609917640686
5
train loss item: 0.22245793044567108
6
train loss item: 0.14317120611667633
7
train loss item: 0.5030922293663025
8
train loss item: 0.09138237684965134
9
train loss item: 0.16220247745513916
10
train loss item: 0.19723285734653473
11
train loss item: 0.19782951474189758
12
train loss item: 0.11204805970191956
13
train loss item: 0.28832972049713135
14
train loss item: 0.17697106301784515
15
train loss item: 0.3426607847213745
16
train loss item: 0.0661747008562088
17
train loss item: 0.17794959247112274
18
train loss item: 0.21015629172325134
19
train loss item: 0.15929578244686127
20
train loss item: 0.13180196285247803
21
train loss item: 0.09815532714128494
22
train loss item: 0.4249217212200165
23
train loss item: 0.48921307921409607
24
train loss item: 0.31119784712791443
25
train loss item: 0.1312600076198578
26
train loss item: 0.1432119458913803
27
train loss item: 0.1869431883096695
28
train loss item: 0.06583580374717712
29
train loss item: 0.33808284997940063
30
train loss item: 1.5527901649475098
31
train loss item: 0.32194191217422485
32
train loss item: 0.09354394674301147
33
train loss item: 0.208255797624588
34
train loss item: 0.12282705307006836
35
train loss item: 1.9476767778396606
36
train loss item: 0.2942902743816376
37
train loss item: 0.22864459455013275
38
train loss item: 0.26152193546295166
39
train loss item: 0.20461829006671906
40
train loss item: 0.12233792245388031
41
train loss item: 0.1646159291267395
42
train loss item: 0.2191683053970337
43
train loss item: 0.1253773719072342
44
train loss item: 0.5089917778968811
45
train loss item: 0.10668206214904785
46
train loss item: 0.09525667876005173
47
train loss item: 0.1900506615638733
48
train loss item: 0.15002459287643433
49
train loss item: 0.11726132035255432
50
train loss item: 0.15101037919521332
51
train loss item: 0.47854161262512207
52
train loss item: 0.07463086396455765
53
train loss item: 0.10700825601816177
54
train loss item: 1.8142956495285034
55
train loss item: 0.14378483593463898
56
train loss item: 0.17581287026405334
57
train loss item: 0.1746862381696701
58
train loss item: 0.11252550035715103
59
train loss item: 0.10909359157085419
60
train loss item: 0.4464978873729706
61
train loss item: 1.6485116481781006
62
train loss item: 0.14109204709529877
63
train loss item: 0.2279903143644333
64
train loss item: 0.12002472579479218
65
train loss item: 0.2971670925617218
66
train loss item: 0.24668347835540771
67
train loss item: 0.14652617275714874
68
train loss item: 0.1782436966896057
69
train loss item: 0.2007177770137787
70
train loss item: 0.16671521961688995
71
train loss item: 0.11261529475450516
72
train loss item: 0.10939325392246246
73
train loss item: 0.19503836333751678
74
train loss item: 0.0793033167719841
75
train loss item: 0.09976906329393387
76
train loss item: 0.5017273426055908
77
train loss item: 0.8486083149909973
78
train loss item: 0.07210589945316315
79
train loss item: 0.18398451805114746
80
train loss item: 0.09842360019683838
81
train loss item: 0.13170184195041656
82
train loss item: 0.13136084377765656
83
train loss item: 0.2956940531730652
84
train loss item: 0.23005351424217224
85
train loss item: 0.3135890066623688
86
train loss item: 3.603558301925659
87
train loss item: 0.11050986498594284
88
train loss item: 0.2239663153886795
epoch train loss: 0.32165733649489586
testing phase
test loss item: 0.1554754078388214
test loss item: 0.11186781525611877
test loss item: 0.42843881249427795
test loss item: 0.1974005550146103
test loss item: 0.2184009552001953
test loss item: 0.11801106482744217
test loss item: 1.2904620170593262
test loss item: 0.4470445215702057
test loss item: 0.1650669425725937
test loss item: 0.2949211299419403
test loss item: 0.6655634045600891
test loss item: 0.14376837015151978
test loss item: 0.14846131205558777
test loss item: 0.2160390317440033
test loss item: 0.14949797093868256
test loss item: 0.09163808822631836
test loss item: 0.20364028215408325
test loss item: 0.35613512992858887
test loss item: 0.5222111940383911
test loss item: 0.18866746127605438
test loss item: 0.5276950001716614
test loss item: 0.31296059489250183
test loss item: 0.22749841213226318
test loss item: 0.14022986590862274
test loss item: 0.17156878113746643
test loss item: 0.20593391358852386
test loss item: 0.23286588490009308
test loss item: 0.15871207416057587
test loss item: 0.25208568572998047
test loss item: 0.2622375190258026
test loss item: 0.6098604202270508
test loss item: 0.08011306822299957
test loss item: 0.12525995075702667
test loss item: 0.4502902030944824
test loss item: 0.3209962546825409
test loss item: 0.4043803811073303
test loss item: 0.6089228391647339
test loss item: 1.117168664932251
test loss item: 0.35053136944770813
test loss item: 0.2146368771791458
test loss item: 0.24709412455558777
test loss item: 0.1796945035457611
test loss item: 0.26794686913490295
test loss item: 0.17649933695793152
test loss item: 0.40624961256980896
test loss item: 0.27565106749534607
test loss item: 0.22883006930351257
test loss item: 0.1780540496110916
test loss item: 0.37058696150779724
test loss item: 0.5469498634338379
test loss item: 0.21532608568668365
test loss item: 0.11663650721311569
test loss item: 0.19326815009117126
test loss item: 0.15220661461353302
test loss item: 0.23322468996047974
test loss item: 0.6574674844741821
test loss item: 0.46221768856048584
test loss item: 0.18145272135734558
test loss item: 0.18855328857898712
test loss item: 0.17410652339458466
test loss item: 0.3531245291233063
test loss item: 0.20819588005542755
test loss item: 0.16428345441818237
test loss item: 0.18701669573783875
test loss item: 0.6748656630516052
test loss item: 0.2738872766494751
test loss item: 0.2239343374967575
test loss item: 0.19929355382919312
test loss item: 0.44365328550338745
test loss item: 0.3309352397918701
test loss item: 0.08076640963554382
test loss item: 0.701911211013794
test loss item: 0.22895219922065735
test loss item: 0.27517589926719666
test loss item: 0.11907188594341278
test loss item: 0.14144828915596008
test loss item: 0.14034941792488098
test loss item: 1.2270702123641968
test loss item: 0.32700279355049133
test loss item: 0.16089852154254913
test loss item: 0.08243530243635178
test loss item: 0.7473128437995911
test loss item: 0.6543924808502197
test loss item: 0.80587238073349
test loss item: 0.17441700398921967
test loss item: 0.2311433106660843
test loss item: 0.0789385735988617
test loss item: 0.07535902410745621
test loss item: 0.31137460470199585
Epoch [72/100], Training Loss: 0.3217, Testing Loss: 0.3142
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 73/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3034196197986603
1
train loss item: 0.6971915364265442
2
train loss item: 0.14984145760536194
3
train loss item: 0.2897992432117462
4
train loss item: 0.25550577044487
5
train loss item: 0.21772897243499756
6
train loss item: 0.1415371149778366
7
train loss item: 0.4975467324256897
8
train loss item: 0.08989910036325455
9
train loss item: 0.1602534055709839
10
train loss item: 0.19504670798778534
11
train loss item: 0.1973152756690979
12
train loss item: 0.11160482466220856
13
train loss item: 0.28222987055778503
14
train loss item: 0.1751507967710495
15
train loss item: 0.33375123143196106
16
train loss item: 0.0650385171175003
17
train loss item: 0.1742566078901291
18
train loss item: 0.2087114453315735
19
train loss item: 0.15674176812171936
20
train loss item: 0.13092617690563202
21
train loss item: 0.09598565846681595
22
train loss item: 0.41806358098983765
23
train loss item: 0.4794337749481201
24
train loss item: 0.30615365505218506
25
train loss item: 0.12964195013046265
26
train loss item: 0.1405423879623413
27
train loss item: 0.18442727625370026
28
train loss item: 0.06439411640167236
29
train loss item: 0.3337777256965637
30
train loss item: 1.5417875051498413
31
train loss item: 0.31577321887016296
32
train loss item: 0.09123629331588745
33
train loss item: 0.20451276004314423
34
train loss item: 0.12052879482507706
35
train loss item: 1.94189453125
36
train loss item: 0.2906070649623871
37
train loss item: 0.22606289386749268
38
train loss item: 0.25640353560447693
39
train loss item: 0.20213575661182404
40
train loss item: 0.12174778431653976
41
train loss item: 0.16283738613128662
42
train loss item: 0.2169189304113388
43
train loss item: 0.12379904091358185
44
train loss item: 0.504894495010376
45
train loss item: 0.10400363802909851
46
train loss item: 0.09381522983312607
47
train loss item: 0.18745741248130798
48
train loss item: 0.1480940878391266
49
train loss item: 0.11593052744865417
50
train loss item: 0.14843444526195526
51
train loss item: 0.47394391894340515
52
train loss item: 0.07308764010667801
53
train loss item: 0.10480145364999771
54
train loss item: 1.80843985080719
55
train loss item: 0.14169684052467346
56
train loss item: 0.1730114221572876
57
train loss item: 0.1726374477148056
58
train loss item: 0.11204946041107178
59
train loss item: 0.1062459647655487
60
train loss item: 0.4387090504169464
61
train loss item: 1.6396979093551636
62
train loss item: 0.13820265233516693
63
train loss item: 0.22680509090423584
64
train loss item: 0.11771628260612488
65
train loss item: 0.29152682423591614
66
train loss item: 0.2430538535118103
67
train loss item: 0.14647315442562103
68
train loss item: 0.17740501463413239
69
train loss item: 0.19797223806381226
70
train loss item: 0.16445036232471466
71
train loss item: 0.11078526824712753
72
train loss item: 0.10761375725269318
73
train loss item: 0.19337572157382965
74
train loss item: 0.07767088711261749
75
train loss item: 0.09861968457698822
76
train loss item: 0.49350500106811523
77
train loss item: 0.8430883288383484
78
train loss item: 0.07067140191793442
79
train loss item: 0.18387268483638763
80
train loss item: 0.09679591655731201
81
train loss item: 0.13100668787956238
82
train loss item: 0.1292203813791275
83
train loss item: 0.29018068313598633
84
train loss item: 0.2253114879131317
85
train loss item: 0.3095163106918335
86
train loss item: 3.5946803092956543
87
train loss item: 0.10892943292856216
88
train loss item: 0.2210531383752823
epoch train loss: 0.3184114061714558
testing phase
test loss item: 0.15532457828521729
test loss item: 0.1213507279753685
test loss item: 0.4383758306503296
test loss item: 0.1986992359161377
test loss item: 0.22606761753559113
test loss item: 0.12547896802425385
test loss item: 1.2612106800079346
test loss item: 0.44300106167793274
test loss item: 0.1692405790090561
test loss item: 0.29730480909347534
test loss item: 0.6792586445808411
test loss item: 0.15160198509693146
test loss item: 0.15129606425762177
test loss item: 0.2145385444164276
test loss item: 0.1558327078819275
test loss item: 0.10110917687416077
test loss item: 0.20160095393657684
test loss item: 0.358541876077652
test loss item: 0.524997889995575
test loss item: 0.18847832083702087
test loss item: 0.5326780676841736
test loss item: 0.3133447468280792
test loss item: 0.23529177904129028
test loss item: 0.14261187613010406
test loss item: 0.17154298722743988
test loss item: 0.2194289267063141
test loss item: 0.23145154118537903
test loss item: 0.16602447628974915
test loss item: 0.25663483142852783
test loss item: 0.26057782769203186
test loss item: 0.6237992644309998
test loss item: 0.08853023499250412
test loss item: 0.12803888320922852
test loss item: 0.45527365803718567
test loss item: 0.32686200737953186
test loss item: 0.3916710615158081
test loss item: 0.6010380983352661
test loss item: 1.159113883972168
test loss item: 0.3533385097980499
test loss item: 0.21519072353839874
test loss item: 0.24443864822387695
test loss item: 0.18970203399658203
test loss item: 0.2711520493030548
test loss item: 0.1787867695093155
test loss item: 0.406014621257782
test loss item: 0.2770351469516754
test loss item: 0.23311935365200043
test loss item: 0.17591366171836853
test loss item: 0.37503018975257874
test loss item: 0.562130331993103
test loss item: 0.21952299773693085
test loss item: 0.1201835349202156
test loss item: 0.192959725856781
test loss item: 0.16510014235973358
test loss item: 0.23490707576274872
test loss item: 0.6727538704872131
test loss item: 0.4475690722465515
test loss item: 0.18292546272277832
test loss item: 0.18696393072605133
test loss item: 0.17746078968048096
test loss item: 0.3550119698047638
test loss item: 0.20565544068813324
test loss item: 0.164130300283432
test loss item: 0.18621927499771118
test loss item: 0.6858997941017151
test loss item: 0.27429842948913574
test loss item: 0.2227400541305542
test loss item: 0.19921104609966278
test loss item: 0.4536426365375519
test loss item: 0.3282206654548645
test loss item: 0.08875418454408646
test loss item: 0.6920749545097351
test loss item: 0.22446297109127045
test loss item: 0.27294981479644775
test loss item: 0.1212441548705101
test loss item: 0.14656980335712433
test loss item: 0.14370682835578918
test loss item: 1.2699570655822754
test loss item: 0.32767677307128906
test loss item: 0.16635870933532715
test loss item: 0.0857747495174408
test loss item: 0.7509640455245972
test loss item: 0.6452202796936035
test loss item: 0.8342883586883545
test loss item: 0.17500971257686615
test loss item: 0.2531379759311676
test loss item: 0.08459299057722092
test loss item: 0.08168866485357285
test loss item: 0.3604637384414673
Epoch [73/100], Training Loss: 0.3184, Testing Loss: 0.3185
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 74/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.29805776476860046
1
train loss item: 0.6870346665382385
2
train loss item: 0.14599518477916718
3
train loss item: 0.285642147064209
4
train loss item: 0.2519463300704956
5
train loss item: 0.21487729251384735
6
train loss item: 0.14083987474441528
7
train loss item: 0.49068567156791687
8
train loss item: 0.08833260834217072
9
train loss item: 0.1583947092294693
10
train loss item: 0.19066224992275238
11
train loss item: 0.19452546536922455
12
train loss item: 0.11049854010343552
13
train loss item: 0.2748880982398987
14
train loss item: 0.1727459728717804
15
train loss item: 0.3295729160308838
16
train loss item: 0.06469930708408356
17
train loss item: 0.17218303680419922
18
train loss item: 0.20468908548355103
19
train loss item: 0.1555958390235901
20
train loss item: 0.1299837827682495
21
train loss item: 0.09448621422052383
22
train loss item: 0.4106537401676178
23
train loss item: 0.4688485264778137
24
train loss item: 0.3036583960056305
25
train loss item: 0.12737953662872314
26
train loss item: 0.139711394906044
27
train loss item: 0.18118447065353394
28
train loss item: 0.06403717398643494
29
train loss item: 0.32653912901878357
30
train loss item: 1.5347532033920288
31
train loss item: 0.31080102920532227
32
train loss item: 0.09251168370246887
33
train loss item: 0.20204024016857147
34
train loss item: 0.1205449178814888
35
train loss item: 1.9375935792922974
36
train loss item: 0.2876293957233429
37
train loss item: 0.2257107049226761
38
train loss item: 0.25430846214294434
39
train loss item: 0.19904254376888275
40
train loss item: 0.12157964706420898
41
train loss item: 0.16019797325134277
42
train loss item: 0.21770943701267242
43
train loss item: 0.12311514467000961
44
train loss item: 0.501057505607605
45
train loss item: 0.10455647110939026
46
train loss item: 0.09405241161584854
47
train loss item: 0.1861562579870224
48
train loss item: 0.1473623365163803
49
train loss item: 0.11505739390850067
50
train loss item: 0.14645305275917053
51
train loss item: 0.46439895033836365
52
train loss item: 0.07270832359790802
53
train loss item: 0.1034468561410904
54
train loss item: 1.8047780990600586
55
train loss item: 0.13991107046604156
56
train loss item: 0.17003947496414185
57
train loss item: 0.17136013507843018
58
train loss item: 0.1106906458735466
59
train loss item: 0.10670212656259537
60
train loss item: 0.4313984811306
61
train loss item: 1.6323931217193604
62
train loss item: 0.1371394246816635
63
train loss item: 0.22478854656219482
64
train loss item: 0.1180720180273056
65
train loss item: 0.28703606128692627
66
train loss item: 0.24094966053962708
67
train loss item: 0.14644870162010193
68
train loss item: 0.1759978085756302
69
train loss item: 0.19647671282291412
70
train loss item: 0.16304655373096466
71
train loss item: 0.10656188428401947
72
train loss item: 0.10664856433868408
73
train loss item: 0.19122765958309174
74
train loss item: 0.0784110277891159
75
train loss item: 0.09863550215959549
76
train loss item: 0.48424383997917175
77
train loss item: 0.8357253670692444
78
train loss item: 0.06910095363855362
79
train loss item: 0.1839056760072708
80
train loss item: 0.09892063587903976
81
train loss item: 0.13076849281787872
82
train loss item: 0.12878398597240448
83
train loss item: 0.2866058945655823
84
train loss item: 0.22212058305740356
85
train loss item: 0.3047786355018616
86
train loss item: 3.5879054069519043
87
train loss item: 0.1076151579618454
88
train loss item: 0.21969205141067505
epoch train loss: 0.31573052369476706
testing phase
test loss item: 0.15472392737865448
test loss item: 0.11691523343324661
test loss item: 0.4109625518321991
test loss item: 0.19390982389450073
test loss item: 0.21422544121742249
test loss item: 0.12373197078704834
test loss item: 1.2143933773040771
test loss item: 0.4343649446964264
test loss item: 0.16348008811473846
test loss item: 0.2827351987361908
test loss item: 0.6221793293952942
test loss item: 0.14572912454605103
test loss item: 0.14848467707633972
test loss item: 0.2239283174276352
test loss item: 0.1478559821844101
test loss item: 0.09987799823284149
test loss item: 0.19961537420749664
test loss item: 0.33363077044487
test loss item: 0.5088421106338501
test loss item: 0.1891014128923416
test loss item: 0.4985320568084717
test loss item: 0.3054279685020447
test loss item: 0.22111420333385468
test loss item: 0.1460544764995575
test loss item: 0.1657089740037918
test loss item: 0.22598712146282196
test loss item: 0.22758343815803528
test loss item: 0.1592034101486206
test loss item: 0.2432752251625061
test loss item: 0.24779032170772552
test loss item: 0.5859512090682983
test loss item: 0.08640316873788834
test loss item: 0.13005749881267548
test loss item: 0.4271300733089447
test loss item: 0.3044784665107727
test loss item: 0.36244308948516846
test loss item: 0.5833941102027893
test loss item: 1.078712821006775
test loss item: 0.33006781339645386
test loss item: 0.21360260248184204
test loss item: 0.24197521805763245
test loss item: 0.18214823305606842
test loss item: 0.25739946961402893
test loss item: 0.17261289060115814
test loss item: 0.38007840514183044
test loss item: 0.27452418208122253
test loss item: 0.21942414343357086
test loss item: 0.17973844707012177
test loss item: 0.35748305916786194
test loss item: 0.5345996618270874
test loss item: 0.2057650238275528
test loss item: 0.11941739916801453
test loss item: 0.18585434556007385
test loss item: 0.1508265882730484
test loss item: 0.22117331624031067
test loss item: 0.6169172525405884
test loss item: 0.418782502412796
test loss item: 0.17576844990253448
test loss item: 0.18359404802322388
test loss item: 0.1699400097131729
test loss item: 0.33183199167251587
test loss item: 0.20215074717998505
test loss item: 0.16842085123062134
test loss item: 0.18440651893615723
test loss item: 0.6283424496650696
test loss item: 0.2633015215396881
test loss item: 0.218391552567482
test loss item: 0.19672584533691406
test loss item: 0.43024900555610657
test loss item: 0.3212147653102875
test loss item: 0.08740395307540894
test loss item: 0.6764237284660339
test loss item: 0.22497834265232086
test loss item: 0.2733248174190521
test loss item: 0.1205006092786789
test loss item: 0.13799361884593964
test loss item: 0.14574307203292847
test loss item: 1.1696395874023438
test loss item: 0.3214983642101288
test loss item: 0.16250057518482208
test loss item: 0.08666878193616867
test loss item: 0.6976354122161865
test loss item: 0.6195457577705383
test loss item: 0.7707738280296326
test loss item: 0.17323613166809082
test loss item: 0.23518036305904388
test loss item: 0.08513767272233963
test loss item: 0.08300627022981644
test loss item: 0.33581438660621643
Epoch [74/100], Training Loss: 0.3157, Testing Loss: 0.3042
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 75/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.29243749380111694
1
train loss item: 0.6776896119117737
2
train loss item: 0.14519959688186646
3
train loss item: 0.27874064445495605
4
train loss item: 0.2510708272457123
5
train loss item: 0.21298670768737793
6
train loss item: 0.13955137133598328
7
train loss item: 0.48316600918769836
8
train loss item: 0.08702639490365982
9
train loss item: 0.1567261815071106
10
train loss item: 0.18801698088645935
11
train loss item: 0.19085584580898285
12
train loss item: 0.11033476889133453
13
train loss item: 0.27340155839920044
14
train loss item: 0.1679793745279312
15
train loss item: 0.3278040289878845
16
train loss item: 0.06356684863567352
17
train loss item: 0.16958291828632355
18
train loss item: 0.20236091315746307
19
train loss item: 0.15300333499908447
20
train loss item: 0.12966376543045044
21
train loss item: 0.09436596930027008
22
train loss item: 0.4037315249443054
23
train loss item: 0.4608103632926941
24
train loss item: 0.2996929883956909
25
train loss item: 0.125374898314476
26
train loss item: 0.13812291622161865
27
train loss item: 0.17783044278621674
28
train loss item: 0.06278876215219498
29
train loss item: 0.32175883650779724
30
train loss item: 1.5233620405197144
31
train loss item: 0.30513817071914673
32
train loss item: 0.09052268415689468
33
train loss item: 0.19763225317001343
34
train loss item: 0.11763910204172134
35
train loss item: 1.9307301044464111
36
train loss item: 0.28263258934020996
37
train loss item: 0.22508810460567474
38
train loss item: 0.24965839087963104
39
train loss item: 0.19476360082626343
40
train loss item: 0.11848868429660797
41
train loss item: 0.157554030418396
42
train loss item: 0.21627406775951385
43
train loss item: 0.12089555710554123
44
train loss item: 0.4943388104438782
45
train loss item: 0.10326790809631348
46
train loss item: 0.09271062165498734
47
train loss item: 0.18382397294044495
48
train loss item: 0.14539282023906708
49
train loss item: 0.11413765698671341
50
train loss item: 0.14382441341876984
51
train loss item: 0.4585249125957489
52
train loss item: 0.0714179128408432
53
train loss item: 0.10112018138170242
54
train loss item: 1.7988779544830322
55
train loss item: 0.13797178864479065
56
train loss item: 0.1684301197528839
57
train loss item: 0.17041173577308655
58
train loss item: 0.11243512481451035
59
train loss item: 0.10470607876777649
60
train loss item: 0.42459890246391296
61
train loss item: 1.6229095458984375
62
train loss item: 0.1343768984079361
63
train loss item: 0.2224634885787964
64
train loss item: 0.11361030489206314
65
train loss item: 0.28358161449432373
66
train loss item: 0.23658369481563568
67
train loss item: 0.1436668336391449
68
train loss item: 0.17408309876918793
69
train loss item: 0.19488686323165894
70
train loss item: 0.16076479852199554
71
train loss item: 0.10586081445217133
72
train loss item: 0.10500689595937729
73
train loss item: 0.18804702162742615
74
train loss item: 0.07617019861936569
75
train loss item: 0.09689437597990036
76
train loss item: 0.4767756462097168
77
train loss item: 0.8268542885780334
78
train loss item: 0.06805411726236343
79
train loss item: 0.18001972138881683
80
train loss item: 0.0962812677025795
81
train loss item: 0.12918633222579956
82
train loss item: 0.12571494281291962
83
train loss item: 0.2808108329772949
84
train loss item: 0.22179125249385834
85
train loss item: 0.2994733452796936
86
train loss item: 3.5792086124420166
87
train loss item: 0.10606840997934341
88
train loss item: 0.21670474112033844
epoch train loss: 0.31244788913244614
testing phase
test loss item: 0.15270505845546722
test loss item: 0.11163926124572754
test loss item: 0.42348718643188477
test loss item: 0.19429410994052887
test loss item: 0.21390895545482635
test loss item: 0.12105091661214828
test loss item: 1.2000905275344849
test loss item: 0.43317776918411255
test loss item: 0.1658613681793213
test loss item: 0.2897549867630005
test loss item: 0.6338080167770386
test loss item: 0.14333270490169525
test loss item: 0.1466219574213028
test loss item: 0.21336686611175537
test loss item: 0.1471802443265915
test loss item: 0.0939410850405693
test loss item: 0.19866153597831726
test loss item: 0.3464159369468689
test loss item: 0.5113959908485413
test loss item: 0.18277966976165771
test loss item: 0.5162749886512756
test loss item: 0.3026045858860016
test loss item: 0.21951287984848022
test loss item: 0.1446877270936966
test loss item: 0.16727177798748016
test loss item: 0.2250184565782547
test loss item: 0.22620968520641327
test loss item: 0.15840741991996765
test loss item: 0.24051204323768616
test loss item: 0.2544945180416107
test loss item: 0.5862796902656555
test loss item: 0.08247647434473038
test loss item: 0.12827633321285248
test loss item: 0.4374121427536011
test loss item: 0.31487369537353516
test loss item: 0.3702748417854309
test loss item: 0.5844209790229797
test loss item: 1.101663589477539
test loss item: 0.3384859263896942
test loss item: 0.20988702774047852
test loss item: 0.24078288674354553
test loss item: 0.1811446249485016
test loss item: 0.26675647497177124
test loss item: 0.172825425863266
test loss item: 0.3904251754283905
test loss item: 0.26661768555641174
test loss item: 0.21678002178668976
test loss item: 0.1737985759973526
test loss item: 0.36420202255249023
test loss item: 0.5418399572372437
test loss item: 0.2126750946044922
test loss item: 0.11881262063980103
test loss item: 0.18889473378658295
test loss item: 0.151334747672081
test loss item: 0.22866787016391754
test loss item: 0.6362308263778687
test loss item: 0.427611380815506
test loss item: 0.17712940275669098
test loss item: 0.18487334251403809
test loss item: 0.1699676215648651
test loss item: 0.3444446921348572
test loss item: 0.2006147801876068
test loss item: 0.1654197871685028
test loss item: 0.18197274208068848
test loss item: 0.6406189799308777
test loss item: 0.26540958881378174
test loss item: 0.2180224508047104
test loss item: 0.19392472505569458
test loss item: 0.43407106399536133
test loss item: 0.32229897379875183
test loss item: 0.08210696280002594
test loss item: 0.6632204651832581
test loss item: 0.21898648142814636
test loss item: 0.26330727338790894
test loss item: 0.1196368932723999
test loss item: 0.131057009100914
test loss item: 0.1433878242969513
test loss item: 1.194689154624939
test loss item: 0.31832557916641235
test loss item: 0.16001653671264648
test loss item: 0.08424351364374161
test loss item: 0.7039690613746643
test loss item: 0.6225929260253906
test loss item: 0.7848801612854004
test loss item: 0.16964711248874664
test loss item: 0.24259327352046967
test loss item: 0.08125030249357224
test loss item: 0.07876826077699661
test loss item: 0.34986066818237305
Epoch [75/100], Training Loss: 0.3124, Testing Loss: 0.3059
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 76/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.28905609250068665
1
train loss item: 0.6683946251869202
2
train loss item: 0.14298774302005768
3
train loss item: 0.27463340759277344
4
train loss item: 0.24523882567882538
5
train loss item: 0.20861011743545532
6
train loss item: 0.13860803842544556
7
train loss item: 0.4778689742088318
8
train loss item: 0.08567865937948227
9
train loss item: 0.15485601127147675
10
train loss item: 0.18450585007667542
11
train loss item: 0.19038812816143036
12
train loss item: 0.11007609963417053
13
train loss item: 0.268177330493927
14
train loss item: 0.16601164638996124
15
train loss item: 0.32350796461105347
16
train loss item: 0.06298543512821198
17
train loss item: 0.16773121058940887
18
train loss item: 0.1990499645471573
19
train loss item: 0.15169565379619598
20
train loss item: 0.12932482361793518
21
train loss item: 0.09320981055498123
22
train loss item: 0.39692339301109314
23
train loss item: 0.45373931527137756
24
train loss item: 0.2969963252544403
25
train loss item: 0.12349364161491394
26
train loss item: 0.13737787306308746
27
train loss item: 0.1763157993555069
28
train loss item: 0.06197455897927284
29
train loss item: 0.3166012465953827
30
train loss item: 1.5157464742660522
31
train loss item: 0.30124762654304504
32
train loss item: 0.08930589258670807
33
train loss item: 0.19490784406661987
34
train loss item: 0.11627113819122314
35
train loss item: 1.925986886024475
36
train loss item: 0.2805953025817871
37
train loss item: 0.22395072877407074
38
train loss item: 0.24438025057315826
39
train loss item: 0.19216622412204742
40
train loss item: 0.11876949667930603
41
train loss item: 0.15572583675384521
42
train loss item: 0.21428655087947845
43
train loss item: 0.1193104088306427
44
train loss item: 0.49190786480903625
45
train loss item: 0.1020139530301094
46
train loss item: 0.09034871309995651
47
train loss item: 0.18300104141235352
48
train loss item: 0.14241933822631836
49
train loss item: 0.11221396923065186
50
train loss item: 0.1420362889766693
51
train loss item: 0.4520058035850525
52
train loss item: 0.07100187242031097
53
train loss item: 0.0997258797287941
54
train loss item: 1.7941538095474243
55
train loss item: 0.13657881319522858
56
train loss item: 0.166091650724411
57
train loss item: 0.1678892970085144
58
train loss item: 0.111084945499897
59
train loss item: 0.10334797203540802
60
train loss item: 0.4169749915599823
61
train loss item: 1.6158497333526611
62
train loss item: 0.1341191977262497
63
train loss item: 0.21928174793720245
64
train loss item: 0.11182109266519547
65
train loss item: 0.28003987669944763
66
train loss item: 0.23382750153541565
67
train loss item: 0.1409861147403717
68
train loss item: 0.1723479926586151
69
train loss item: 0.19310951232910156
70
train loss item: 0.16022369265556335
71
train loss item: 0.1045633926987648
72
train loss item: 0.10291067510843277
73
train loss item: 0.1859733909368515
74
train loss item: 0.07490085810422897
75
train loss item: 0.0956212505698204
76
train loss item: 0.46839872002601624
77
train loss item: 0.8168089985847473
78
train loss item: 0.06782088428735733
79
train loss item: 0.17755287885665894
80
train loss item: 0.09551014006137848
81
train loss item: 0.12704086303710938
82
train loss item: 0.12528811395168304
83
train loss item: 0.2759692668914795
84
train loss item: 0.21746286749839783
85
train loss item: 0.2952062487602234
86
train loss item: 3.5722155570983887
87
train loss item: 0.10500996559858322
88
train loss item: 0.21487262845039368
epoch train loss: 0.309620208912686
testing phase
test loss item: 0.15123330056667328
test loss item: 0.10897132009267807
test loss item: 0.4364590048789978
test loss item: 0.1944078803062439
test loss item: 0.216790571808815
test loss item: 0.11891700327396393
test loss item: 1.2482666969299316
test loss item: 0.4536544978618622
test loss item: 0.16876128315925598
test loss item: 0.29466894268989563
test loss item: 0.6606549620628357
test loss item: 0.14238305389881134
test loss item: 0.14755885303020477
test loss item: 0.21301501989364624
test loss item: 0.14711111783981323
test loss item: 0.09038637578487396
test loss item: 0.20198529958724976
test loss item: 0.3544921576976776
test loss item: 0.5146780014038086
test loss item: 0.1852952390909195
test loss item: 0.5258859992027283
test loss item: 0.30791470408439636
test loss item: 0.22064810991287231
test loss item: 0.1447930485010147
test loss item: 0.1683126837015152
test loss item: 0.2049381285905838
test loss item: 0.22868932783603668
test loss item: 0.15902183949947357
test loss item: 0.24227078258991241
test loss item: 0.25826144218444824
test loss item: 0.6085275411605835
test loss item: 0.0787457674741745
test loss item: 0.12725065648555756
test loss item: 0.4468584358692169
test loss item: 0.32344380021095276
test loss item: 0.383118599653244
test loss item: 0.6031116843223572
test loss item: 1.1422282457351685
test loss item: 0.3469077944755554
test loss item: 0.2110203206539154
test loss item: 0.24412764608860016
test loss item: 0.16342918574810028
test loss item: 0.270815908908844
test loss item: 0.1744392216205597
test loss item: 0.3959084153175354
test loss item: 0.27118387818336487
test loss item: 0.2167627513408661
test loss item: 0.17416635155677795
test loss item: 0.37391528487205505
test loss item: 0.5450688600540161
test loss item: 0.21568241715431213
test loss item: 0.11688094586133957
test loss item: 0.19137772917747498
test loss item: 0.15043692290782928
test loss item: 0.23275843262672424
test loss item: 0.6545352339744568
test loss item: 0.44578373432159424
test loss item: 0.1764121800661087
test loss item: 0.18627575039863586
test loss item: 0.1713520735502243
test loss item: 0.34983736276626587
test loss item: 0.20472706854343414
test loss item: 0.1644642949104309
test loss item: 0.18333590030670166
test loss item: 0.6660086512565613
test loss item: 0.26763278245925903
test loss item: 0.22385519742965698
test loss item: 0.19643853604793549
test loss item: 0.4447968900203705
test loss item: 0.33112430572509766
test loss item: 0.08027935028076172
test loss item: 0.6882745623588562
test loss item: 0.22067773342132568
test loss item: 0.26599833369255066
test loss item: 0.1203828826546669
test loss item: 0.12791220843791962
test loss item: 0.14349067211151123
test loss item: 1.2475218772888184
test loss item: 0.32338038086891174
test loss item: 0.15861806273460388
test loss item: 0.0832892432808876
test loss item: 0.7346318960189819
test loss item: 0.6423718929290771
test loss item: 0.8197505474090576
test loss item: 0.17119210958480835
test loss item: 0.22106310725212097
test loss item: 0.079320527613163
test loss item: 0.07588645815849304
test loss item: 0.2797083258628845
Epoch [76/100], Training Loss: 0.3096, Testing Loss: 0.3109
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 77/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.284848153591156
1
train loss item: 0.6588066220283508
2
train loss item: 0.14155243337154388
3
train loss item: 0.26811447739601135
4
train loss item: 0.24327422678470612
5
train loss item: 0.2063450664281845
6
train loss item: 0.13786090910434723
7
train loss item: 0.4717813730239868
8
train loss item: 0.08467959612607956
9
train loss item: 0.15249855816364288
10
train loss item: 0.18134565651416779
11
train loss item: 0.18678626418113708
12
train loss item: 0.10917256772518158
13
train loss item: 0.2643432021141052
14
train loss item: 0.1626819670200348
15
train loss item: 0.31637200713157654
16
train loss item: 0.062284134328365326
17
train loss item: 0.16535598039627075
18
train loss item: 0.19652150571346283
19
train loss item: 0.14916227757930756
20
train loss item: 0.12737953662872314
21
train loss item: 0.09238462895154953
22
train loss item: 0.39056453108787537
23
train loss item: 0.4457768499851227
24
train loss item: 0.29352328181266785
25
train loss item: 0.12142449617385864
26
train loss item: 0.13541847467422485
27
train loss item: 0.1739388108253479
28
train loss item: 0.06108652055263519
29
train loss item: 0.31137657165527344
30
train loss item: 1.5067260265350342
31
train loss item: 0.2958412170410156
32
train loss item: 0.08784092962741852
33
train loss item: 0.1902174949645996
34
train loss item: 0.11514369398355484
35
train loss item: 1.9208099842071533
36
train loss item: 0.27627089619636536
37
train loss item: 0.22081176936626434
38
train loss item: 0.24206659197807312
39
train loss item: 0.19001805782318115
40
train loss item: 0.11701555550098419
41
train loss item: 0.15387097001075745
42
train loss item: 0.21222315728664398
43
train loss item: 0.11848945915699005
44
train loss item: 0.48737427592277527
45
train loss item: 0.09966011345386505
46
train loss item: 0.08904779702425003
47
train loss item: 0.17940866947174072
48
train loss item: 0.14158843457698822
49
train loss item: 0.11059306561946869
50
train loss item: 0.13929060101509094
51
train loss item: 0.4465169310569763
52
train loss item: 0.07077069580554962
53
train loss item: 0.0986131802201271
54
train loss item: 1.7890106439590454
55
train loss item: 0.13637541234493256
56
train loss item: 0.1634385734796524
57
train loss item: 0.16721872985363007
58
train loss item: 0.11027783155441284
59
train loss item: 0.10218896716833115
60
train loss item: 0.41024282574653625
61
train loss item: 1.607873797416687
62
train loss item: 0.13285036385059357
63
train loss item: 0.21835395693778992
64
train loss item: 0.11053462326526642
65
train loss item: 0.2767321765422821
66
train loss item: 0.23109795153141022
67
train loss item: 0.13993041217327118
68
train loss item: 0.1711626946926117
69
train loss item: 0.19122552871704102
70
train loss item: 0.1584680825471878
71
train loss item: 0.10421561449766159
72
train loss item: 0.10147132724523544
73
train loss item: 0.1841726452112198
74
train loss item: 0.07377263158559799
75
train loss item: 0.09451338648796082
76
train loss item: 0.4611390233039856
77
train loss item: 0.8111531138420105
78
train loss item: 0.0674758180975914
79
train loss item: 0.17527234554290771
80
train loss item: 0.09254232794046402
81
train loss item: 0.12640418112277985
82
train loss item: 0.12252184003591537
83
train loss item: 0.27195313572883606
84
train loss item: 0.21505768597126007
85
train loss item: 0.2896173298358917
86
train loss item: 3.564167022705078
87
train loss item: 0.10396022349596024
88
train loss item: 0.21242709457874298
epoch train loss: 0.3066931412126241
testing phase
test loss item: 0.1507946252822876
test loss item: 0.11077005416154861
test loss item: 0.42718368768692017
test loss item: 0.19274502992630005
test loss item: 0.2157873660326004
test loss item: 0.11814209818840027
test loss item: 1.2588675022125244
test loss item: 0.45305919647216797
test loss item: 0.16779658198356628
test loss item: 0.2883669137954712
test loss item: 0.6521354913711548
test loss item: 0.14312155544757843
test loss item: 0.14793001115322113
test loss item: 0.22105926275253296
test loss item: 0.14756359159946442
test loss item: 0.09229490160942078
test loss item: 0.20117947459220886
test loss item: 0.3428649604320526
test loss item: 0.5140825510025024
test loss item: 0.1885819435119629
test loss item: 0.5029908418655396
test loss item: 0.30740708112716675
test loss item: 0.21596354246139526
test loss item: 0.14436635375022888
test loss item: 0.16498707234859467
test loss item: 0.20921948552131653
test loss item: 0.2281579077243805
test loss item: 0.15890298783779144
test loss item: 0.24207335710525513
test loss item: 0.2520129382610321
test loss item: 0.6090121269226074
test loss item: 0.08007118105888367
test loss item: 0.12714900076389313
test loss item: 0.4358215928077698
test loss item: 0.314386248588562
test loss item: 0.38009342551231384
test loss item: 0.6012008786201477
test loss item: 1.125003695487976
test loss item: 0.3383999764919281
test loss item: 0.2104261815547943
test loss item: 0.24356697499752045
test loss item: 0.1651700735092163
test loss item: 0.26171156764030457
test loss item: 0.17355534434318542
test loss item: 0.3805556297302246
test loss item: 0.27194634079933167
test loss item: 0.21261809766292572
test loss item: 0.1792343258857727
test loss item: 0.3674454092979431
test loss item: 0.5428174138069153
test loss item: 0.20931582152843475
test loss item: 0.11709816753864288
test loss item: 0.18824534118175507
test loss item: 0.15084221959114075
test loss item: 0.22669683396816254
test loss item: 0.6376056671142578
test loss item: 0.44035789370536804
test loss item: 0.1782684624195099
test loss item: 0.183030366897583
test loss item: 0.16960398852825165
test loss item: 0.3387933373451233
test loss item: 0.20265713334083557
test loss item: 0.1639399379491806
test loss item: 0.18339936435222626
test loss item: 0.6526522040367126
test loss item: 0.26489007472991943
test loss item: 0.2218102663755417
test loss item: 0.19769524037837982
test loss item: 0.4394374489784241
test loss item: 0.3304135501384735
test loss item: 0.0833171084523201
test loss item: 0.695091962814331
test loss item: 0.22740261256694794
test loss item: 0.26852717995643616
test loss item: 0.1206701323390007
test loss item: 0.1293785125017166
test loss item: 0.14439073204994202
test loss item: 1.2270121574401855
test loss item: 0.32708245515823364
test loss item: 0.15771658718585968
test loss item: 0.08395278453826904
test loss item: 0.7334567308425903
test loss item: 0.6369568109512329
test loss item: 0.8101691603660583
test loss item: 0.17172501981258392
test loss item: 0.22500137984752655
test loss item: 0.07968424260616302
test loss item: 0.07665219902992249
test loss item: 0.2853151559829712
Epoch [77/100], Training Loss: 0.3067, Testing Loss: 0.3085
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 78/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2805595397949219
1
train loss item: 0.6494004726409912
2
train loss item: 0.14003735780715942
3
train loss item: 0.26370641589164734
4
train loss item: 0.24053844809532166
5
train loss item: 0.20451878011226654
6
train loss item: 0.13686490058898926
7
train loss item: 0.466004341840744
8
train loss item: 0.08329258859157562
9
train loss item: 0.1510193794965744
10
train loss item: 0.17913225293159485
11
train loss item: 0.18440477550029755
12
train loss item: 0.10703819245100021
13
train loss item: 0.25940507650375366
14
train loss item: 0.15962137281894684
15
train loss item: 0.310698926448822
16
train loss item: 0.06101218983530998
17
train loss item: 0.1633153259754181
18
train loss item: 0.19391819834709167
19
train loss item: 0.14725683629512787
20
train loss item: 0.1253250688314438
21
train loss item: 0.0912511795759201
22
train loss item: 0.3836228549480438
23
train loss item: 0.4377511143684387
24
train loss item: 0.28909310698509216
25
train loss item: 0.11990077048540115
26
train loss item: 0.13394373655319214
27
train loss item: 0.17128947377204895
28
train loss item: 0.06012112647294998
29
train loss item: 0.3068080544471741
30
train loss item: 1.4979989528656006
31
train loss item: 0.2913426160812378
32
train loss item: 0.08716780692338943
33
train loss item: 0.1878029704093933
34
train loss item: 0.11377984285354614
35
train loss item: 1.915464997291565
36
train loss item: 0.2714666426181793
37
train loss item: 0.21930120885372162
38
train loss item: 0.2387593686580658
39
train loss item: 0.18756254017353058
40
train loss item: 0.11514055728912354
41
train loss item: 0.15242986381053925
42
train loss item: 0.2112116515636444
43
train loss item: 0.11780533194541931
44
train loss item: 0.48168787360191345
45
train loss item: 0.09950628131628036
46
train loss item: 0.0901704952120781
47
train loss item: 0.17739452421665192
48
train loss item: 0.1410197764635086
49
train loss item: 0.11002063751220703
50
train loss item: 0.137304425239563
51
train loss item: 0.441108763217926
52
train loss item: 0.0685407891869545
53
train loss item: 0.09741327911615372
54
train loss item: 1.7838717699050903
55
train loss item: 0.13499850034713745
56
train loss item: 0.1614575982093811
57
train loss item: 0.16622883081436157
58
train loss item: 0.10662248730659485
59
train loss item: 0.1016327515244484
60
train loss item: 0.40497466921806335
61
train loss item: 1.600204586982727
62
train loss item: 0.1305370032787323
63
train loss item: 0.2171633541584015
64
train loss item: 0.11232537031173706
65
train loss item: 0.27256911993026733
66
train loss item: 0.2281656414270401
67
train loss item: 0.13891810178756714
68
train loss item: 0.16993644833564758
69
train loss item: 0.18888892233371735
70
train loss item: 0.15663789212703705
71
train loss item: 0.10220297425985336
72
train loss item: 0.10050877183675766
73
train loss item: 0.1817675679922104
74
train loss item: 0.07336016744375229
75
train loss item: 0.09447220712900162
76
train loss item: 0.4540921151638031
77
train loss item: 0.8053858876228333
78
train loss item: 0.06522088497877121
79
train loss item: 0.1739937663078308
80
train loss item: 0.09203533828258514
81
train loss item: 0.12484616786241531
82
train loss item: 0.1216488853096962
83
train loss item: 0.2661897540092468
84
train loss item: 0.21357738971710205
85
train loss item: 0.28477752208709717
86
train loss item: 3.5569748878479004
87
train loss item: 0.1025700494647026
88
train loss item: 0.2097051441669464
epoch train loss: 0.3039406245427855
testing phase
test loss item: 0.14997471868991852
test loss item: 0.10636204481124878
test loss item: 0.40859758853912354
test loss item: 0.18977759778499603
test loss item: 0.2098991423845291
test loss item: 0.114742211997509
test loss item: 1.230255365371704
test loss item: 0.4412655532360077
test loss item: 0.1628689020872116
test loss item: 0.2812650799751282
test loss item: 0.6192237138748169
test loss item: 0.13971981406211853
test loss item: 0.14539149403572083
test loss item: 0.2111763209104538
test loss item: 0.14384466409683228
test loss item: 0.08792218565940857
test loss item: 0.1975303739309311
test loss item: 0.33300474286079407
test loss item: 0.509536623954773
test loss item: 0.18204441666603088
test loss item: 0.48865625262260437
test loss item: 0.3028494417667389
test loss item: 0.21140308678150177
test loss item: 0.1405094712972641
test loss item: 0.16039258241653442
test loss item: 0.216157466173172
test loss item: 0.22303858399391174
test loss item: 0.1553882211446762
test loss item: 0.23711271584033966
test loss item: 0.2472890168428421
test loss item: 0.5869675874710083
test loss item: 0.07732527703046799
test loss item: 0.1239398941397667
test loss item: 0.41942864656448364
test loss item: 0.3022746741771698
test loss item: 0.3663859963417053
test loss item: 0.5870668292045593
test loss item: 1.068613886833191
test loss item: 0.32730939984321594
test loss item: 0.20744433999061584
test loss item: 0.24062083661556244
test loss item: 0.174400195479393
test loss item: 0.2548167407512665
test loss item: 0.1711491346359253
test loss item: 0.37195536494255066
test loss item: 0.2640020549297333
test loss item: 0.20917561650276184
test loss item: 0.17376279830932617
test loss item: 0.35564789175987244
test loss item: 0.5308824181556702
test loss item: 0.20668096840381622
test loss item: 0.11687418073415756
test loss item: 0.18654903769493103
test loss item: 0.14740008115768433
test loss item: 0.22254237532615662
test loss item: 0.6061359643936157
test loss item: 0.4248823821544647
test loss item: 0.17316843569278717
test loss item: 0.18008244037628174
test loss item: 0.16717371344566345
test loss item: 0.3282776474952698
test loss item: 0.19926971197128296
test loss item: 0.16079117357730865
test loss item: 0.18063755333423615
test loss item: 0.6214150190353394
test loss item: 0.2608538269996643
test loss item: 0.21566464006900787
test loss item: 0.19384147226810455
test loss item: 0.42151546478271484
test loss item: 0.32280921936035156
test loss item: 0.07770848274230957
test loss item: 0.6805208325386047
test loss item: 0.21459175646305084
test loss item: 0.2614566683769226
test loss item: 0.1171192079782486
test loss item: 0.12581570446491241
test loss item: 0.140412375330925
test loss item: 1.1631304025650024
test loss item: 0.3132680654525757
test loss item: 0.1557369977235794
test loss item: 0.08037133514881134
test loss item: 0.7063811421394348
test loss item: 0.6196660399436951
test loss item: 0.7690870761871338
test loss item: 0.16799509525299072
test loss item: 0.24006891250610352
test loss item: 0.07594906538724899
test loss item: 0.07368482649326324
test loss item: 0.3276420831680298
Epoch [78/100], Training Loss: 0.3039, Testing Loss: 0.3001
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 79/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.27662691473960876
1
train loss item: 0.6405996084213257
2
train loss item: 0.1375945657491684
3
train loss item: 0.2610730230808258
4
train loss item: 0.23620252311229706
5
train loss item: 0.20088037848472595
6
train loss item: 0.13541097939014435
7
train loss item: 0.4615705907344818
8
train loss item: 0.082059845328331
9
train loss item: 0.14938849210739136
10
train loss item: 0.1766221970319748
11
train loss item: 0.18373502790927887
12
train loss item: 0.10596975684165955
13
train loss item: 0.2563284933567047
14
train loss item: 0.15713652968406677
15
train loss item: 0.3066484332084656
16
train loss item: 0.06036946550011635
17
train loss item: 0.16172005236148834
18
train loss item: 0.1909245401620865
19
train loss item: 0.14629459381103516
20
train loss item: 0.12463773787021637
21
train loss item: 0.09047628194093704
22
train loss item: 0.37704744935035706
23
train loss item: 0.43082109093666077
24
train loss item: 0.28639018535614014
25
train loss item: 0.11795177310705185
26
train loss item: 0.13324004411697388
27
train loss item: 0.16849441826343536
28
train loss item: 0.05943191051483154
29
train loss item: 0.3047754764556885
30
train loss item: 1.4887253046035767
31
train loss item: 0.28742533922195435
32
train loss item: 0.0866985097527504
33
train loss item: 0.184650257229805
34
train loss item: 0.11246229708194733
35
train loss item: 1.909904956817627
36
train loss item: 0.2696574628353119
37
train loss item: 0.21816670894622803
38
train loss item: 0.2352057546377182
39
train loss item: 0.18514344096183777
40
train loss item: 0.11408136785030365
41
train loss item: 0.14960797131061554
42
train loss item: 0.20969077944755554
43
train loss item: 0.1158297136425972
44
train loss item: 0.47726044058799744
45
train loss item: 0.09822794795036316
46
train loss item: 0.08807971328496933
47
train loss item: 0.17526941001415253
48
train loss item: 0.13833601772785187
49
train loss item: 0.10910824686288834
50
train loss item: 0.13567063212394714
51
train loss item: 0.4357568323612213
52
train loss item: 0.06781931221485138
53
train loss item: 0.09611788392066956
54
train loss item: 1.778282880783081
55
train loss item: 0.1326109617948532
56
train loss item: 0.15917406976222992
57
train loss item: 0.16264484822750092
58
train loss item: 0.10534369945526123
59
train loss item: 0.1010882705450058
60
train loss item: 0.3980928957462311
61
train loss item: 1.593045949935913
62
train loss item: 0.12961727380752563
63
train loss item: 0.21461646258831024
64
train loss item: 0.11071192473173141
65
train loss item: 0.2681489884853363
66
train loss item: 0.22519882023334503
67
train loss item: 0.1372285932302475
68
train loss item: 0.1678619086742401
69
train loss item: 0.18677948415279388
70
train loss item: 0.15485937893390656
71
train loss item: 0.10035335272550583
72
train loss item: 0.09884394705295563
73
train loss item: 0.1799669861793518
74
train loss item: 0.07255670428276062
75
train loss item: 0.09367785602807999
76
train loss item: 0.44685375690460205
77
train loss item: 0.7988181114196777
78
train loss item: 0.064175084233284
79
train loss item: 0.17268210649490356
80
train loss item: 0.09246533364057541
81
train loss item: 0.12296022474765778
82
train loss item: 0.11852384358644485
83
train loss item: 0.26097244024276733
84
train loss item: 0.21124258637428284
85
train loss item: 0.28247350454330444
86
train loss item: 3.5500950813293457
87
train loss item: 0.10138951987028122
88
train loss item: 0.20758792757987976
epoch train loss: 0.30123891526561103
testing phase
test loss item: 0.14936059713363647
test loss item: 0.10577473789453506
test loss item: 0.40892288088798523
test loss item: 0.1905360221862793
test loss item: 0.2095353752374649
test loss item: 0.1158619374036789
test loss item: 1.2208877801895142
test loss item: 0.4427993893623352
test loss item: 0.1625659018754959
test loss item: 0.2806258499622345
test loss item: 0.6236848831176758
test loss item: 0.14009146392345428
test loss item: 0.14605297148227692
test loss item: 0.20801812410354614
test loss item: 0.142490416765213
test loss item: 0.08755922317504883
test loss item: 0.19676567614078522
test loss item: 0.3322333097457886
test loss item: 0.5035386681556702
test loss item: 0.18140095472335815
test loss item: 0.4877234101295471
test loss item: 0.30292952060699463
test loss item: 0.21156851947307587
test loss item: 0.14140385389328003
test loss item: 0.15975947678089142
test loss item: 0.2053651660680771
test loss item: 0.22138357162475586
test loss item: 0.15603378415107727
test loss item: 0.23503945767879486
test loss item: 0.24615666270256042
test loss item: 0.5861202478408813
test loss item: 0.0765029564499855
test loss item: 0.12474367767572403
test loss item: 0.42001622915267944
test loss item: 0.3010087013244629
test loss item: 0.36819371581077576
test loss item: 0.5855626463890076
test loss item: 1.0747824907302856
test loss item: 0.32622280716896057
test loss item: 0.20784634351730347
test loss item: 0.23925268650054932
test loss item: 0.16730695962905884
test loss item: 0.2541090250015259
test loss item: 0.17040392756462097
test loss item: 0.3693745732307434
test loss item: 0.26322224736213684
test loss item: 0.20910301804542542
test loss item: 0.1723664104938507
test loss item: 0.3566574156284332
test loss item: 0.5244898200035095
test loss item: 0.2064865231513977
test loss item: 0.11658506095409393
test loss item: 0.18658821284770966
test loss item: 0.14702443778514862
test loss item: 0.2211376428604126
test loss item: 0.6096316576004028
test loss item: 0.4288245439529419
test loss item: 0.172292560338974
test loss item: 0.1814315915107727
test loss item: 0.16810233891010284
test loss item: 0.32536885142326355
test loss item: 0.20082919299602509
test loss item: 0.1606358140707016
test loss item: 0.1801990121603012
test loss item: 0.6276652812957764
test loss item: 0.26209557056427
test loss item: 0.21578489243984222
test loss item: 0.19341138005256653
test loss item: 0.42584970593452454
test loss item: 0.32150033116340637
test loss item: 0.07695823907852173
test loss item: 0.676082968711853
test loss item: 0.21052508056163788
test loss item: 0.2599872648715973
test loss item: 0.1174454465508461
test loss item: 0.12504027783870697
test loss item: 0.1411687433719635
test loss item: 1.1744678020477295
test loss item: 0.30922919511795044
test loss item: 0.15637408196926117
test loss item: 0.0814976692199707
test loss item: 0.7088061571121216
test loss item: 0.6181640625
test loss item: 0.7776714563369751
test loss item: 0.16906338930130005
test loss item: 0.2247745394706726
test loss item: 0.07655594497919083
test loss item: 0.07301689684391022
test loss item: 0.2983171045780182
Epoch [79/100], Training Loss: 0.3012, Testing Loss: 0.2993
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 80/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2716143727302551
1
train loss item: 0.6313186287879944
2
train loss item: 0.13626165688037872
3
train loss item: 0.25657010078430176
4
train loss item: 0.23371006548404694
5
train loss item: 0.19786013662815094
6
train loss item: 0.13396090269088745
7
train loss item: 0.454712450504303
8
train loss item: 0.08130719512701035
9
train loss item: 0.14788220822811127
10
train loss item: 0.17432674765586853
11
train loss item: 0.1799292415380478
12
train loss item: 0.10563241690397263
13
train loss item: 0.25161734223365784
14
train loss item: 0.1535995751619339
15
train loss item: 0.3017387390136719
16
train loss item: 0.05978932976722717
17
train loss item: 0.15992677211761475
18
train loss item: 0.18890655040740967
19
train loss item: 0.14396873116493225
20
train loss item: 0.12431943416595459
21
train loss item: 0.08964088559150696
22
train loss item: 0.3711259067058563
23
train loss item: 0.42261672019958496
24
train loss item: 0.2823059856891632
25
train loss item: 0.11596116423606873
26
train loss item: 0.13134628534317017
27
train loss item: 0.16574887931346893
28
train loss item: 0.05856860429048538
29
train loss item: 0.29908254742622375
30
train loss item: 1.479838252067566
31
train loss item: 0.2828179895877838
32
train loss item: 0.08574023097753525
33
train loss item: 0.18033306300640106
34
train loss item: 0.11161426454782486
35
train loss item: 1.9043196439743042
36
train loss item: 0.26395103335380554
37
train loss item: 0.21682025492191315
38
train loss item: 0.2321544587612152
39
train loss item: 0.1823645532131195
40
train loss item: 0.11289633065462112
41
train loss item: 0.1475316435098648
42
train loss item: 0.20829461514949799
43
train loss item: 0.11479800194501877
44
train loss item: 0.4726342260837555
45
train loss item: 0.0970531478524208
46
train loss item: 0.08718141913414001
47
train loss item: 0.17325206100940704
48
train loss item: 0.13715247809886932
49
train loss item: 0.10750504583120346
50
train loss item: 0.13358180224895477
51
train loss item: 0.4293138086795807
52
train loss item: 0.06695673614740372
53
train loss item: 0.09501994401216507
54
train loss item: 1.7730287313461304
55
train loss item: 0.13139277696609497
56
train loss item: 0.15670530498027802
57
train loss item: 0.16147372126579285
58
train loss item: 0.10724235326051712
59
train loss item: 0.09990685433149338
60
train loss item: 0.3904381990432739
61
train loss item: 1.585156798362732
62
train loss item: 0.12795408070087433
63
train loss item: 0.2140994817018509
64
train loss item: 0.10728464275598526
65
train loss item: 0.26526975631713867
66
train loss item: 0.22242461144924164
67
train loss item: 0.1360858678817749
68
train loss item: 0.16651985049247742
69
train loss item: 0.18451818823814392
70
train loss item: 0.15301428735256195
71
train loss item: 0.09976399689912796
72
train loss item: 0.0972125306725502
73
train loss item: 0.17761017382144928
74
train loss item: 0.07155976444482803
75
train loss item: 0.09255274385213852
76
train loss item: 0.43960103392601013
77
train loss item: 0.7919397950172424
78
train loss item: 0.06369839608669281
79
train loss item: 0.17165353894233704
80
train loss item: 0.09079331159591675
81
train loss item: 0.12180651724338531
82
train loss item: 0.11638280749320984
83
train loss item: 0.2561708092689514
84
train loss item: 0.20983931422233582
85
train loss item: 0.2775519788265228
86
train loss item: 3.5427000522613525
87
train loss item: 0.10023214668035507
88
train loss item: 0.20565663278102875
epoch train loss: 0.2984012992361958
testing phase
test loss item: 0.15161386132240295
test loss item: 0.10800541937351227
test loss item: 0.4269774854183197
test loss item: 0.19382283091545105
test loss item: 0.21129341423511505
test loss item: 0.11676712334156036
test loss item: 1.2004705667495728
test loss item: 0.4340370297431946
test loss item: 0.16639167070388794
test loss item: 0.2858123481273651
test loss item: 0.6571351289749146
test loss item: 0.1429659128189087
test loss item: 0.14667996764183044
test loss item: 0.2095014452934265
test loss item: 0.14445674419403076
test loss item: 0.08970983326435089
test loss item: 0.19398880004882812
test loss item: 0.3397866189479828
test loss item: 0.5230279564857483
test loss item: 0.18124957382678986
test loss item: 0.49743902683258057
test loss item: 0.29936569929122925
test loss item: 0.21737568080425262
test loss item: 0.14169038832187653
test loss item: 0.1620214581489563
test loss item: 0.23994924128055573
test loss item: 0.22197604179382324
test loss item: 0.1553245186805725
test loss item: 0.2347838282585144
test loss item: 0.2484605610370636
test loss item: 0.6013644933700562
test loss item: 0.07823751866817474
test loss item: 0.12659482657909393
test loss item: 0.4328061640262604
test loss item: 0.31028100848197937
test loss item: 0.38015708327293396
test loss item: 0.5804727077484131
test loss item: 1.1347320079803467
test loss item: 0.3339448571205139
test loss item: 0.20486325025558472
test loss item: 0.23591366410255432
test loss item: 0.20161210000514984
test loss item: 0.2593850791454315
test loss item: 0.1707647442817688
test loss item: 0.3730248510837555
test loss item: 0.25994324684143066
test loss item: 0.20916669070720673
test loss item: 0.173767551779747
test loss item: 0.36431774497032166
test loss item: 0.5590124130249023
test loss item: 0.20812122523784637
test loss item: 0.11725899577140808
test loss item: 0.18497854471206665
test loss item: 0.15462474524974823
test loss item: 0.22280076146125793
test loss item: 0.6443281173706055
test loss item: 0.43793344497680664
test loss item: 0.16931089758872986
test loss item: 0.18150898814201355
test loss item: 0.16775886714458466
test loss item: 0.3354663550853729
test loss item: 0.19789990782737732
test loss item: 0.16502679884433746
test loss item: 0.17832966148853302
test loss item: 0.6548250913619995
test loss item: 0.26564812660217285
test loss item: 0.21370406448841095
test loss item: 0.19111277163028717
test loss item: 0.4414304494857788
test loss item: 0.3206896185874939
test loss item: 0.07817459106445312
test loss item: 0.6593000292778015
test loss item: 0.21552489697933197
test loss item: 0.25971519947052
test loss item: 0.11757718771696091
test loss item: 0.1272129863500595
test loss item: 0.14142122864723206
test loss item: 1.241612434387207
test loss item: 0.3149832487106323
test loss item: 0.15770457684993744
test loss item: 0.08306491374969482
test loss item: 0.7448909282684326
test loss item: 0.6181628108024597
test loss item: 0.8262540698051453
test loss item: 0.16898153722286224
test loss item: 0.2764393091201782
test loss item: 0.07776939123868942
test loss item: 0.07408267259597778
test loss item: 0.42517268657684326
Epoch [80/100], Training Loss: 0.2984, Testing Loss: 0.3078
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 81/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.26700359582901
1
train loss item: 0.6217640042304993
2
train loss item: 0.13580429553985596
3
train loss item: 0.2569458782672882
4
train loss item: 0.23288308084011078
5
train loss item: 0.19514119625091553
6
train loss item: 0.133842334151268
7
train loss item: 0.45051878690719604
8
train loss item: 0.08051857352256775
9
train loss item: 0.14735063910484314
10
train loss item: 0.17305056750774384
11
train loss item: 0.1785302460193634
12
train loss item: 0.10400707274675369
13
train loss item: 0.24727359414100647
14
train loss item: 0.1519280970096588
15
train loss item: 0.30009227991104126
16
train loss item: 0.05901573970913887
17
train loss item: 0.15901534259319305
18
train loss item: 0.1863623410463333
19
train loss item: 0.14202842116355896
20
train loss item: 0.12345762550830841
21
train loss item: 0.08918542414903641
22
train loss item: 0.36620137095451355
23
train loss item: 0.4156610667705536
24
train loss item: 0.2803991734981537
25
train loss item: 0.11524750292301178
26
train loss item: 0.13024523854255676
27
train loss item: 0.16372641921043396
28
train loss item: 0.058059971779584885
29
train loss item: 0.29654979705810547
30
train loss item: 1.4735196828842163
31
train loss item: 0.27948588132858276
32
train loss item: 0.08562726527452469
33
train loss item: 0.17991860210895538
34
train loss item: 0.11052785813808441
35
train loss item: 1.9003150463104248
36
train loss item: 0.2622004747390747
37
train loss item: 0.21526890993118286
38
train loss item: 0.23151381313800812
39
train loss item: 0.18078139424324036
40
train loss item: 0.11261112242937088
41
train loss item: 0.14582233130931854
42
train loss item: 0.20674148201942444
43
train loss item: 0.11351615190505981
44
train loss item: 0.4705316126346588
45
train loss item: 0.09641759097576141
46
train loss item: 0.08573909103870392
47
train loss item: 0.1724465936422348
48
train loss item: 0.13551266491413116
49
train loss item: 0.10652418434619904
50
train loss item: 0.1315806359052658
51
train loss item: 0.42232316732406616
52
train loss item: 0.06606514006853104
53
train loss item: 0.0953437015414238
54
train loss item: 1.7691231966018677
55
train loss item: 0.13056330382823944
56
train loss item: 0.1543835997581482
57
train loss item: 0.15963402390480042
58
train loss item: 0.1023312360048294
59
train loss item: 0.09941937774419785
60
train loss item: 0.38472193479537964
61
train loss item: 1.5784766674041748
62
train loss item: 0.12716491520404816
63
train loss item: 0.2106844186782837
64
train loss item: 0.10978148877620697
65
train loss item: 0.26226428151130676
66
train loss item: 0.21956244111061096
67
train loss item: 0.1341329663991928
68
train loss item: 0.16543243825435638
69
train loss item: 0.18314893543720245
70
train loss item: 0.1521928757429123
71
train loss item: 0.09844096004962921
72
train loss item: 0.09739101678133011
73
train loss item: 0.17665106058120728
74
train loss item: 0.07081366330385208
75
train loss item: 0.09247422963380814
76
train loss item: 0.4314125180244446
77
train loss item: 0.7816232442855835
78
train loss item: 0.06237538903951645
79
train loss item: 0.17000028491020203
80
train loss item: 0.09049232304096222
81
train loss item: 0.1210940033197403
82
train loss item: 0.11590475589036942
83
train loss item: 0.25404810905456543
84
train loss item: 0.2072826772928238
85
train loss item: 0.27480819821357727
86
train loss item: 3.5371294021606445
87
train loss item: 0.10185913741588593
88
train loss item: 0.20340053737163544
epoch train loss: 0.29631869310743353
testing phase
test loss item: 0.14715619385242462
test loss item: 0.09873593598604202
test loss item: 0.39607828855514526
test loss item: 0.18568289279937744
test loss item: 0.19966886937618256
test loss item: 0.11208441108465195
test loss item: 1.226862907409668
test loss item: 0.45133453607559204
test loss item: 0.15501664578914642
test loss item: 0.2671656012535095
test loss item: 0.6042361259460449
test loss item: 0.13335876166820526
test loss item: 0.13998450338840485
test loss item: 0.21166855096817017
test loss item: 0.134579136967659
test loss item: 0.08217363804578781
test loss item: 0.19462750852108002
test loss item: 0.3151184618473053
test loss item: 0.4964435398578644
test loss item: 0.18058860301971436
test loss item: 0.4675458073616028
test loss item: 0.2990891635417938
test loss item: 0.20663300156593323
test loss item: 0.13957154750823975
test loss item: 0.15520881116390228
test loss item: 0.18743766844272614
test loss item: 0.21756644546985626
test loss item: 0.14562693238258362
test loss item: 0.22465455532073975
test loss item: 0.2350059151649475
test loss item: 0.5766559839248657
test loss item: 0.07153954356908798
test loss item: 0.12365413457155228
test loss item: 0.40303218364715576
test loss item: 0.2866203784942627
test loss item: 0.34556081891059875
test loss item: 0.5846360921859741
test loss item: 1.046604871749878
test loss item: 0.31241822242736816
test loss item: 0.20621776580810547
test loss item: 0.2393074929714203
test loss item: 0.1553642600774765
test loss item: 0.24067707359790802
test loss item: 0.16513650119304657
test loss item: 0.3524150550365448
test loss item: 0.26465147733688354
test loss item: 0.20302677154541016
test loss item: 0.17281119525432587
test loss item: 0.3463963568210602
test loss item: 0.5033591389656067
test loss item: 0.1920813024044037
test loss item: 0.11239347606897354
test loss item: 0.1793869137763977
test loss item: 0.1339922547340393
test loss item: 0.20888081192970276
test loss item: 0.5886164307594299
test loss item: 0.4231067895889282
test loss item: 0.1668476015329361
test loss item: 0.17795954644680023
test loss item: 0.15784351527690887
test loss item: 0.30580562353134155
test loss item: 0.20214159786701202
test loss item: 0.16108369827270508
test loss item: 0.1797088086605072
test loss item: 0.6187818646430969
test loss item: 0.2537941634654999
test loss item: 0.213704451918602
test loss item: 0.1920429915189743
test loss item: 0.4143456518650055
test loss item: 0.32087889313697815
test loss item: 0.0712466612458229
test loss item: 0.6841561198234558
test loss item: 0.20981034636497498
test loss item: 0.2630172371864319
test loss item: 0.11442116647958755
test loss item: 0.12419333308935165
test loss item: 0.1390833854675293
test loss item: 1.1452864408493042
test loss item: 0.3034045398235321
test loss item: 0.15057142078876495
test loss item: 0.0799897313117981
test loss item: 0.6993367671966553
test loss item: 0.6127122044563293
test loss item: 0.7580292820930481
test loss item: 0.16839605569839478
test loss item: 0.19235260784626007
test loss item: 0.0751853808760643
test loss item: 0.07086214423179626
test loss item: 0.22851131856441498
Epoch [81/100], Training Loss: 0.2963, Testing Loss: 0.2911
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 82/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.26325723528862
1
train loss item: 0.616362452507019
2
train loss item: 0.13558152318000793
3
train loss item: 0.2525823414325714
4
train loss item: 0.2322571873664856
5
train loss item: 0.19365116953849792
6
train loss item: 0.13256877660751343
7
train loss item: 0.4428132176399231
8
train loss item: 0.08195912837982178
9
train loss item: 0.14694367349147797
10
train loss item: 0.17125681042671204
11
train loss item: 0.1770876944065094
12
train loss item: 0.1048232838511467
13
train loss item: 0.24629251658916473
14
train loss item: 0.1485808789730072
15
train loss item: 0.29481562972068787
16
train loss item: 0.05914886295795441
17
train loss item: 0.15766145288944244
18
train loss item: 0.18532809615135193
19
train loss item: 0.14069628715515137
20
train loss item: 0.12237559258937836
21
train loss item: 0.08976543694734573
22
train loss item: 0.3613084852695465
23
train loss item: 0.40791329741477966
24
train loss item: 0.27778807282447815
25
train loss item: 0.11421897262334824
26
train loss item: 0.13147418200969696
27
train loss item: 0.16082806885242462
28
train loss item: 0.05757267400622368
29
train loss item: 0.29904279112815857
30
train loss item: 1.4630998373031616
31
train loss item: 0.2761836349964142
32
train loss item: 0.08475658297538757
33
train loss item: 0.17512762546539307
34
train loss item: 0.11085352301597595
35
train loss item: 1.8935946226119995
36
train loss item: 0.25686025619506836
37
train loss item: 0.2148536741733551
38
train loss item: 0.22814811766147614
39
train loss item: 0.1780575066804886
40
train loss item: 0.11230139434337616
41
train loss item: 0.14511162042617798
42
train loss item: 0.206654354929924
43
train loss item: 0.11477356404066086
44
train loss item: 0.46358853578567505
45
train loss item: 0.09611715376377106
46
train loss item: 0.08623982220888138
47
train loss item: 0.17053425312042236
48
train loss item: 0.13628742098808289
49
train loss item: 0.10606565326452255
50
train loss item: 0.1299557089805603
51
train loss item: 0.42467236518859863
52
train loss item: 0.06625525653362274
53
train loss item: 0.09564784914255142
54
train loss item: 1.7624101638793945
55
train loss item: 0.1298713982105255
56
train loss item: 0.15401902794837952
57
train loss item: 0.15925216674804688
58
train loss item: 0.10845702886581421
59
train loss item: 0.09905534982681274
60
train loss item: 0.3796215057373047
61
train loss item: 1.569007396697998
62
train loss item: 0.12634703516960144
63
train loss item: 0.2103699892759323
64
train loss item: 0.10531523823738098
65
train loss item: 0.26063087582588196
66
train loss item: 0.21820688247680664
67
train loss item: 0.13433627784252167
68
train loss item: 0.16387391090393066
69
train loss item: 0.1821272224187851
70
train loss item: 0.15074104070663452
71
train loss item: 0.10114285349845886
72
train loss item: 0.09723659604787827
73
train loss item: 0.17596347630023956
74
train loss item: 0.07031355053186417
75
train loss item: 0.09122126549482346
76
train loss item: 0.426234632730484
77
train loss item: 0.7779332399368286
78
train loss item: 0.06397262960672379
79
train loss item: 0.1678573340177536
80
train loss item: 0.08796803653240204
81
train loss item: 0.12029168754816055
82
train loss item: 0.11493944376707077
83
train loss item: 0.2498602569103241
84
train loss item: 0.20741663873195648
85
train loss item: 0.27486202120780945
86
train loss item: 3.528028964996338
87
train loss item: 0.10313663631677628
88
train loss item: 0.20259910821914673
epoch train loss: 0.29456535965371666
testing phase
test loss item: 0.1505325585603714
test loss item: 0.11253426969051361
test loss item: 0.437494695186615
test loss item: 0.1915254294872284
test loss item: 0.21379505097866058
test loss item: 0.11487128585577011
test loss item: 1.1852136850357056
test loss item: 0.4104902744293213
test loss item: 0.17033685743808746
test loss item: 0.29267531633377075
test loss item: 0.6552883982658386
test loss item: 0.1415712982416153
test loss item: 0.14961232244968414
test loss item: 0.20492583513259888
test loss item: 0.14979462325572968
test loss item: 0.09400355815887451
test loss item: 0.1892574280500412
test loss item: 0.3499114513397217
test loss item: 0.5091570019721985
test loss item: 0.17819339036941528
test loss item: 0.5078830122947693
test loss item: 0.2934756278991699
test loss item: 0.22281642258167267
test loss item: 0.13692830502986908
test loss item: 0.16253922879695892
test loss item: 0.22365374863147736
test loss item: 0.22389551997184753
test loss item: 0.1555761694908142
test loss item: 0.24011817574501038
test loss item: 0.255703330039978
test loss item: 0.6066737174987793
test loss item: 0.08380810171365738
test loss item: 0.12374838441610336
test loss item: 0.43737295269966125
test loss item: 0.31864288449287415
test loss item: 0.38747119903564453
test loss item: 0.568291187286377
test loss item: 1.13953697681427
test loss item: 0.3407171070575714
test loss item: 0.2001422494649887
test loss item: 0.23183229565620422
test loss item: 0.20596209168434143
test loss item: 0.2666417062282562
test loss item: 0.16981817781925201
test loss item: 0.38084039092063904
test loss item: 0.25239571928977966
test loss item: 0.21327140927314758
test loss item: 0.17265257239341736
test loss item: 0.36818280816078186
test loss item: 0.5600727200508118
test loss item: 0.22081507742404938
test loss item: 0.11990778148174286
test loss item: 0.18732000887393951
test loss item: 0.15966880321502686
test loss item: 0.23102641105651855
test loss item: 0.6596763730049133
test loss item: 0.42885878682136536
test loss item: 0.1671149730682373
test loss item: 0.1802721470594406
test loss item: 0.17287392914295197
test loss item: 0.35134804248809814
test loss item: 0.18990235030651093
test loss item: 0.16006654500961304
test loss item: 0.17622537910938263
test loss item: 0.6539965271949768
test loss item: 0.2621384859085083
test loss item: 0.21032962203025818
test loss item: 0.1889856457710266
test loss item: 0.44263380765914917
test loss item: 0.3171078860759735
test loss item: 0.08311750739812851
test loss item: 0.642252504825592
test loss item: 0.21477507054805756
test loss item: 0.25346559286117554
test loss item: 0.11670480668544769
test loss item: 0.13242116570472717
test loss item: 0.13874469697475433
test loss item: 1.2381556034088135
test loss item: 0.3113636374473572
test loss item: 0.1557808518409729
test loss item: 0.08161969482898712
test loss item: 0.7366265654563904
test loss item: 0.6095958948135376
test loss item: 0.8295906782150269
test loss item: 0.16497334837913513
test loss item: 0.28680849075317383
test loss item: 0.07718116044998169
test loss item: 0.0760948434472084
test loss item: 0.42899584770202637
Epoch [82/100], Training Loss: 0.2946, Testing Loss: 0.3080
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 83/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.26330363750457764
1
train loss item: 0.6094414591789246
2
train loss item: 0.13896282017230988
3
train loss item: 0.2694871127605438
4
train loss item: 0.2334042489528656
5
train loss item: 0.19360581040382385
6
train loss item: 0.1341634839773178
7
train loss item: 0.44012215733528137
8
train loss item: 0.0821034386754036
9
train loss item: 0.1494084894657135
10
train loss item: 0.17250901460647583
11
train loss item: 0.18236114084720612
12
train loss item: 0.10248049348592758
13
train loss item: 0.24346064031124115
14
train loss item: 0.15340864658355713
15
train loss item: 0.2945784628391266
16
train loss item: 0.05838657543063164
17
train loss item: 0.1585109382867813
18
train loss item: 0.18477998673915863
19
train loss item: 0.1407596617937088
20
train loss item: 0.12149931490421295
21
train loss item: 0.09112746268510818
22
train loss item: 0.3621066212654114
23
train loss item: 0.40249601006507874
24
train loss item: 0.2763095498085022
25
train loss item: 0.1151658147573471
26
train loss item: 0.13397327065467834
27
train loss item: 0.16113156080245972
28
train loss item: 0.05781438201665878
29
train loss item: 0.3091430366039276
30
train loss item: 1.4597866535186768
31
train loss item: 0.27492114901542664
32
train loss item: 0.08939063549041748
33
train loss item: 0.1798248142004013
34
train loss item: 0.10902917385101318
35
train loss item: 1.8909484148025513
36
train loss item: 0.26810553669929504
37
train loss item: 0.2171044647693634
38
train loss item: 0.24236296117305756
39
train loss item: 0.18353210389614105
40
train loss item: 0.11250541359186172
41
train loss item: 0.14504191279411316
42
train loss item: 0.2134978473186493
43
train loss item: 0.11872835457324982
44
train loss item: 0.4637659788131714
45
train loss item: 0.09812476485967636
46
train loss item: 0.08884518593549728
47
train loss item: 0.17130841314792633
48
train loss item: 0.13437104225158691
49
train loss item: 0.11000891774892807
50
train loss item: 0.12947207689285278
51
train loss item: 0.43164461851119995
52
train loss item: 0.06559471786022186
53
train loss item: 0.10055054724216461
54
train loss item: 1.7591867446899414
55
train loss item: 0.1314927041530609
56
train loss item: 0.15235571563243866
57
train loss item: 0.16150537133216858
58
train loss item: 0.10204857587814331
59
train loss item: 0.1014770045876503
60
train loss item: 0.3812876045703888
61
train loss item: 1.5655511617660522
62
train loss item: 0.12704907357692719
63
train loss item: 0.2072860449552536
64
train loss item: 0.11968869715929031
65
train loss item: 0.25907188653945923
66
train loss item: 0.2351246178150177
67
train loss item: 0.13681812584400177
68
train loss item: 0.16397203505039215
69
train loss item: 0.18486683070659637
70
train loss item: 0.1525709480047226
71
train loss item: 0.09786011278629303
72
train loss item: 0.10175597667694092
73
train loss item: 0.17795081436634064
74
train loss item: 0.07078796625137329
75
train loss item: 0.09467151015996933
76
train loss item: 0.4175216853618622
77
train loss item: 0.7669106125831604
78
train loss item: 0.06153244525194168
79
train loss item: 0.17049166560173035
80
train loss item: 0.09359101206064224
81
train loss item: 0.1212819516658783
82
train loss item: 0.1158950999379158
83
train loss item: 0.2509787082672119
84
train loss item: 0.2156318724155426
85
train loss item: 0.28418609499931335
86
train loss item: 3.523965358734131
87
train loss item: 0.10519050061702728
88
train loss item: 0.20319519937038422
epoch train loss: 0.29605868169933225
testing phase
test loss item: 0.15178930759429932
test loss item: 0.0979650467634201
test loss item: 0.3822537362575531
test loss item: 0.18704593181610107
test loss item: 0.19801446795463562
test loss item: 0.11658219248056412
test loss item: 1.2912687063217163
test loss item: 0.46983602643013
test loss item: 0.15348497033119202
test loss item: 0.2632431983947754
test loss item: 0.5738033652305603
test loss item: 0.13372375071048737
test loss item: 0.14810465276241302
test loss item: 0.23125770688056946
test loss item: 0.1322990357875824
test loss item: 0.0822363868355751
test loss item: 0.20186036825180054
test loss item: 0.30089071393013
test loss item: 0.5015875101089478
test loss item: 0.19626039266586304
test loss item: 0.44437840580940247
test loss item: 0.3092481195926666
test loss item: 0.20979087054729462
test loss item: 0.14437247812747955
test loss item: 0.15158139169216156
test loss item: 0.18333590030670166
test loss item: 0.2285982221364975
test loss item: 0.14679023623466492
test loss item: 0.22678224742412567
test loss item: 0.23554788529872894
test loss item: 0.5782940983772278
test loss item: 0.07050926983356476
test loss item: 0.12641452252864838
test loss item: 0.3899551331996918
test loss item: 0.2738165259361267
test loss item: 0.3494012951850891
test loss item: 0.5980634093284607
test loss item: 0.9947202205657959
test loss item: 0.3047977387905121
test loss item: 0.21763436496257782
test loss item: 0.24525916576385498
test loss item: 0.14922867715358734
test loss item: 0.23204877972602844
test loss item: 0.16867145895957947
test loss item: 0.3413023352622986
test loss item: 0.28074684739112854
test loss item: 0.2043270766735077
test loss item: 0.19119863212108612
test loss item: 0.34522897005081177
test loss item: 0.495552122592926
test loss item: 0.1936141699552536
test loss item: 0.11169445514678955
test loss item: 0.18088826537132263
test loss item: 0.13064438104629517
test loss item: 0.20199787616729736
test loss item: 0.5580294728279114
test loss item: 0.42374497652053833
test loss item: 0.18029172718524933
test loss item: 0.182750403881073
test loss item: 0.16208679974079132
test loss item: 0.2914924621582031
test loss item: 0.20918694138526917
test loss item: 0.16920821368694305
test loss item: 0.1867518126964569
test loss item: 0.6099088191986084
test loss item: 0.2555161714553833
test loss item: 0.2267654687166214
test loss item: 0.19924208521842957
test loss item: 0.40897250175476074
test loss item: 0.32874399423599243
test loss item: 0.0738072544336319
test loss item: 0.7247754335403442
test loss item: 0.22079694271087646
test loss item: 0.28088319301605225
test loss item: 0.11662652343511581
test loss item: 0.12675076723098755
test loss item: 0.1432533860206604
test loss item: 1.0946638584136963
test loss item: 0.30869320034980774
test loss item: 0.15416035056114197
test loss item: 0.08042459934949875
test loss item: 0.6916564106941223
test loss item: 0.6226851940155029
test loss item: 0.7260729670524597
test loss item: 0.1781284362077713
test loss item: 0.1802547425031662
test loss item: 0.07505559176206589
test loss item: 0.07021653652191162
test loss item: 0.17813222110271454
Epoch [83/100], Training Loss: 0.2961, Testing Loss: 0.2911
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7010.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7010.00 MB
Epoch 84/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2646787166595459
1
train loss item: 0.6118380427360535
2
train loss item: 0.14810870587825775
3
train loss item: 0.2681870758533478
4
train loss item: 0.23716163635253906
5
train loss item: 0.19875399768352509
6
train loss item: 0.14212676882743835
7
train loss item: 0.4340084195137024
8
train loss item: 0.08826509118080139
9
train loss item: 0.15729711949825287
10
train loss item: 0.1739521026611328
11
train loss item: 0.18209445476531982
12
train loss item: 0.10523664951324463
13
train loss item: 0.24096213281154633
14
train loss item: 0.14646495878696442
15
train loss item: 0.3098564147949219
16
train loss item: 0.058933842927217484
17
train loss item: 0.16193559765815735
18
train loss item: 0.19040925800800323
19
train loss item: 0.1520475447177887
20
train loss item: 0.12947581708431244
21
train loss item: 0.09514573961496353
22
train loss item: 0.3791678249835968
23
train loss item: 0.3977311849594116
24
train loss item: 0.28783977031707764
25
train loss item: 0.1186453327536583
26
train loss item: 0.13784249126911163
27
train loss item: 0.15951062738895416
28
train loss item: 0.0570228211581707
29
train loss item: 0.32378751039505005
30
train loss item: 1.4498882293701172
31
train loss item: 0.2745334804058075
32
train loss item: 0.08836695551872253
33
train loss item: 0.17312851548194885
34
train loss item: 0.11152897030115128
35
train loss item: 1.884027123451233
36
train loss item: 0.2565373182296753
37
train loss item: 0.22266851365566254
38
train loss item: 0.23595941066741943
39
train loss item: 0.17809359729290009
40
train loss item: 0.123079314827919
41
train loss item: 0.1478927880525589
42
train loss item: 0.2163548618555069
43
train loss item: 0.11721985787153244
44
train loss item: 0.45628926157951355
45
train loss item: 0.09736301004886627
46
train loss item: 0.10109405964612961
47
train loss item: 0.18625056743621826
48
train loss item: 0.14218537509441376
49
train loss item: 0.11666029691696167
50
train loss item: 0.13947565853595734
51
train loss item: 0.45382341742515564
52
train loss item: 0.06564857065677643
53
train loss item: 0.10071073472499847
54
train loss item: 1.7528133392333984
55
train loss item: 0.13693568110466003
56
train loss item: 0.15750247240066528
57
train loss item: 0.1676645278930664
58
train loss item: 0.1131138950586319
59
train loss item: 0.09724000096321106
60
train loss item: 0.37822529673576355
61
train loss item: 1.5544971227645874
62
train loss item: 0.13024365901947021
63
train loss item: 0.22566622495651245
64
train loss item: 0.10533556342124939
65
train loss item: 0.26978039741516113
66
train loss item: 0.2277688831090927
67
train loss item: 0.14385652542114258
68
train loss item: 0.17083626985549927
69
train loss item: 0.19243350625038147
70
train loss item: 0.1595170497894287
71
train loss item: 0.10792813450098038
72
train loss item: 0.10794524103403091
73
train loss item: 0.1855764091014862
74
train loss item: 0.06904404610395432
75
train loss item: 0.09143944829702377
76
train loss item: 0.4170074164867401
77
train loss item: 0.7814465761184692
78
train loss item: 0.06358139961957932
79
train loss item: 0.17632801830768585
80
train loss item: 0.09004607796669006
81
train loss item: 0.1254499852657318
82
train loss item: 0.11714472621679306
83
train loss item: 0.2528535723686218
84
train loss item: 0.22089624404907227
85
train loss item: 0.2924264669418335
86
train loss item: 3.514468193054199
87
train loss item: 0.11124508827924728
88
train loss item: 0.21487978100776672
epoch train loss: 0.2991056716843937
testing phase
test loss item: 0.15095968544483185
test loss item: 0.10799963772296906
test loss item: 0.45277777314186096
test loss item: 0.19669638574123383
test loss item: 0.21647904813289642
test loss item: 0.11523615568876266
test loss item: 1.2167608737945557
test loss item: 0.4173756241798401
test loss item: 0.1718796342611313
test loss item: 0.29610762000083923
test loss item: 0.6990603804588318
test loss item: 0.14946231245994568
test loss item: 0.1462850421667099
test loss item: 0.20482024550437927
test loss item: 0.14926867187023163
test loss item: 0.08822822570800781
test loss item: 0.19267162680625916
test loss item: 0.35407987236976624
test loss item: 0.5294379591941833
test loss item: 0.17851004004478455
test loss item: 0.5157923102378845
test loss item: 0.2999715805053711
test loss item: 0.22055970132350922
test loss item: 0.1359221190214157
test loss item: 0.1634708046913147
test loss item: 0.2450188398361206
test loss item: 0.22787697613239288
test loss item: 0.15596356987953186
test loss item: 0.2401355803012848
test loss item: 0.2624424695968628
test loss item: 0.6317528486251831
test loss item: 0.07833144068717957
test loss item: 0.12199757993221283
test loss item: 0.4481193721294403
test loss item: 0.325588196516037
test loss item: 0.42265716195106506
test loss item: 0.5782264471054077
test loss item: 1.2094427347183228
test loss item: 0.3513259291648865
test loss item: 0.2033970206975937
test loss item: 0.23548324406147003
test loss item: 0.216033473610878
test loss item: 0.2673589885234833
test loss item: 0.17758360505104065
test loss item: 0.38779446482658386
test loss item: 0.25422313809394836
test loss item: 0.2093678116798401
test loss item: 0.17343878746032715
test loss item: 0.373455673456192
test loss item: 0.5942222476005554
test loss item: 0.22093242406845093
test loss item: 0.1144736111164093
test loss item: 0.19016984105110168
test loss item: 0.17081202566623688
test loss item: 0.23347583413124084
test loss item: 0.6884388327598572
test loss item: 0.4557938873767853
test loss item: 0.16682246327400208
test loss item: 0.18200063705444336
test loss item: 0.17112523317337036
test loss item: 0.35116392374038696
test loss item: 0.19134192168712616
test loss item: 0.16010890901088715
test loss item: 0.1766834557056427
test loss item: 0.6899696588516235
test loss item: 0.2742537260055542
test loss item: 0.21679697930812836
test loss item: 0.18928322196006775
test loss item: 0.45662397146224976
test loss item: 0.31786322593688965
test loss item: 0.07605477422475815
test loss item: 0.6541343331336975
test loss item: 0.21773752570152283
test loss item: 0.2560020983219147
test loss item: 0.1152004599571228
test loss item: 0.12600697576999664
test loss item: 0.1377059817314148
test loss item: 1.3255536556243896
test loss item: 0.3192465305328369
test loss item: 0.15458540618419647
test loss item: 0.07984655350446701
test loss item: 0.7915483117103577
test loss item: 0.6261675953865051
test loss item: 0.8941754698753357
test loss item: 0.1666318029165268
test loss item: 0.3023340106010437
test loss item: 0.07290492951869965
test loss item: 0.07112131267786026
test loss item: 0.4841293394565582
Epoch [84/100], Training Loss: 0.2991, Testing Loss: 0.3174
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 85/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2557884454727173
1
train loss item: 0.6051125526428223
2
train loss item: 0.13198530673980713
3
train loss item: 0.25980013608932495
4
train loss item: 0.23849233984947205
5
train loss item: 0.18774640560150146
6
train loss item: 0.1301531195640564
7
train loss item: 0.439090371131897
8
train loss item: 0.07865070551633835
9
train loss item: 0.1453273892402649
10
train loss item: 0.1731826663017273
11
train loss item: 0.1776033490896225
12
train loss item: 0.10179370641708374
13
train loss item: 0.2480396330356598
14
train loss item: 0.14643652737140656
15
train loss item: 0.2874245345592499
16
train loss item: 0.05667826533317566
17
train loss item: 0.15434864163398743
18
train loss item: 0.17944453656673431
19
train loss item: 0.13977761566638947
20
train loss item: 0.12074708938598633
21
train loss item: 0.08704999834299088
22
train loss item: 0.34939369559288025
23
train loss item: 0.39987772703170776
24
train loss item: 0.26951006054878235
25
train loss item: 0.11625037342309952
26
train loss item: 0.12673591077327728
27
train loss item: 0.1587139517068863
28
train loss item: 0.055410221219062805
29
train loss item: 0.2948307991027832
30
train loss item: 1.4505468606948853
31
train loss item: 0.27223825454711914
32
train loss item: 0.08353838324546814
33
train loss item: 0.18606799840927124
34
train loss item: 0.10833080857992172
35
train loss item: 1.8836429119110107
36
train loss item: 0.25972893834114075
37
train loss item: 0.21249881386756897
38
train loss item: 0.23434510827064514
39
train loss item: 0.17485491931438446
40
train loss item: 0.11039122194051743
41
train loss item: 0.14318622648715973
42
train loss item: 0.20286640524864197
43
train loss item: 0.11260290443897247
44
train loss item: 0.4648382067680359
45
train loss item: 0.0953601822257042
46
train loss item: 0.08437202125787735
47
train loss item: 0.16730168461799622
48
train loss item: 0.13071393966674805
49
train loss item: 0.10368021577596664
50
train loss item: 0.1279996633529663
51
train loss item: 0.41706952452659607
52
train loss item: 0.06393234431743622
53
train loss item: 0.09415675699710846
54
train loss item: 1.753587245941162
55
train loss item: 0.12691444158554077
56
train loss item: 0.1493941992521286
57
train loss item: 0.15548419952392578
58
train loss item: 0.09965170174837112
59
train loss item: 0.09802396595478058
60
train loss item: 0.36467674374580383
61
train loss item: 1.5548322200775146
62
train loss item: 0.12439961731433868
63
train loss item: 0.20860661566257477
64
train loss item: 0.11229413747787476
65
train loss item: 0.25350332260131836
66
train loss item: 0.21590764820575714
67
train loss item: 0.132487490773201
68
train loss item: 0.16152897477149963
69
train loss item: 0.17910361289978027
70
train loss item: 0.15145394206047058
71
train loss item: 0.0966295674443245
72
train loss item: 0.09621705859899521
73
train loss item: 0.17133530974388123
74
train loss item: 0.06881777197122574
75
train loss item: 0.09091132879257202
76
train loss item: 0.4069065451622009
77
train loss item: 0.7632033824920654
78
train loss item: 0.059948842972517014
79
train loss item: 0.16735802590847015
80
train loss item: 0.08902908861637115
81
train loss item: 0.11809121072292328
82
train loss item: 0.11335154622793198
83
train loss item: 0.244993656873703
84
train loss item: 0.20487238466739655
85
train loss item: 0.26368287205696106
86
train loss item: 3.5129287242889404
87
train loss item: 0.10420028865337372
88
train loss item: 0.19812779128551483
epoch train loss: 0.2911473690542612
testing phase
test loss item: 0.14475643634796143
test loss item: 0.10070300847291946
test loss item: 0.4176830053329468
test loss item: 0.18418127298355103
test loss item: 0.20540152490139008
test loss item: 0.1077335998415947
test loss item: 1.1160579919815063
test loss item: 0.3972422480583191
test loss item: 0.16274088621139526
test loss item: 0.27778270840644836
test loss item: 0.6212734580039978
test loss item: 0.13303151726722717
test loss item: 0.14064082503318787
test loss item: 0.200361430644989
test loss item: 0.1432504802942276
test loss item: 0.08309555053710938
test loss item: 0.18663181364536285
test loss item: 0.33359402418136597
test loss item: 0.4703156054019928
test loss item: 0.1666698455810547
test loss item: 0.4977594316005707
test loss item: 0.2841641306877136
test loss item: 0.21389153599739075
test loss item: 0.13009437918663025
test loss item: 0.1571258008480072
test loss item: 0.19783402979373932
test loss item: 0.21451392769813538
test loss item: 0.14637812972068787
test loss item: 0.2298165261745453
test loss item: 0.2428249567747116
test loss item: 0.5760990977287292
test loss item: 0.07460933178663254
test loss item: 0.11728931218385696
test loss item: 0.4166826903820038
test loss item: 0.3029802143573761
test loss item: 0.36136743426322937
test loss item: 0.5443699359893799
test loss item: 1.0906788110733032
test loss item: 0.3251563608646393
test loss item: 0.1945825219154358
test loss item: 0.22690966725349426
test loss item: 0.17062687873840332
test loss item: 0.2548947334289551
test loss item: 0.1665651500225067
test loss item: 0.37555161118507385
test loss item: 0.24287888407707214
test loss item: 0.20363514125347137
test loss item: 0.16310054063796997
test loss item: 0.3544589877128601
test loss item: 0.5204060673713684
test loss item: 0.21220603585243225
test loss item: 0.11109291017055511
test loss item: 0.18375688791275024
test loss item: 0.14806753396987915
test loss item: 0.22243353724479675
test loss item: 0.613050103187561
test loss item: 0.4097728729248047
test loss item: 0.16590310633182526
test loss item: 0.1750049740076065
test loss item: 0.1637948453426361
test loss item: 0.32709822058677673
test loss item: 0.18614676594734192
test loss item: 0.15210238099098206
test loss item: 0.1700008511543274
test loss item: 0.6109880208969116
test loss item: 0.25359851121902466
test loss item: 0.2065557986497879
test loss item: 0.1808837652206421
test loss item: 0.4209962785243988
test loss item: 0.30031609535217285
test loss item: 0.07076254487037659
test loss item: 0.6126141548156738
test loss item: 0.19846698641777039
test loss item: 0.2383711040019989
test loss item: 0.11170350015163422
test loss item: 0.11885518580675125
test loss item: 0.13109757006168365
test loss item: 1.1903332471847534
test loss item: 0.2938220202922821
test loss item: 0.1468176394701004
test loss item: 0.07745786011219025
test loss item: 0.6978564262390137
test loss item: 0.5821660757064819
test loss item: 0.8018428087234497
test loss item: 0.1582711935043335
test loss item: 0.22654858231544495
test loss item: 0.07157333195209503
test loss item: 0.0691133439540863
test loss item: 0.31881183385849
Epoch [85/100], Training Loss: 0.2911, Testing Loss: 0.2912
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 86/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.25650760531425476
1
train loss item: 0.5917977094650269
2
train loss item: 0.13139210641384125
3
train loss item: 0.24626310169696808
4
train loss item: 0.22353620827198029
5
train loss item: 0.1863289773464203
6
train loss item: 0.12929578125476837
7
train loss item: 0.43330276012420654
8
train loss item: 0.07854631543159485
9
train loss item: 0.14249549806118011
10
train loss item: 0.1677861362695694
11
train loss item: 0.17835652828216553
12
train loss item: 0.10108740627765656
13
train loss item: 0.23941224813461304
14
train loss item: 0.14689964056015015
15
train loss item: 0.2856944501399994
16
train loss item: 0.05646375194191933
17
train loss item: 0.15401554107666016
18
train loss item: 0.1804518848657608
19
train loss item: 0.138745978474617
20
train loss item: 0.12054143100976944
21
train loss item: 0.08643057197332382
22
train loss item: 0.34535539150238037
23
train loss item: 0.3895597755908966
24
train loss item: 0.28800588846206665
25
train loss item: 0.1129094734787941
26
train loss item: 0.1282712072134018
27
train loss item: 0.1579132229089737
28
train loss item: 0.05485154688358307
29
train loss item: 0.2895514667034149
30
train loss item: 1.4464679956436157
31
train loss item: 0.2647153437137604
32
train loss item: 0.08367997407913208
33
train loss item: 0.1757359355688095
34
train loss item: 0.10676921159029007
35
train loss item: 1.8786695003509521
36
train loss item: 0.2614259719848633
37
train loss item: 0.21372203528881073
38
train loss item: 0.2274027019739151
39
train loss item: 0.1737738996744156
40
train loss item: 0.11051005125045776
41
train loss item: 0.14400210976600647
42
train loss item: 0.20163224637508392
43
train loss item: 0.11097106337547302
44
train loss item: 0.45779579877853394
45
train loss item: 0.09689754247665405
46
train loss item: 0.0871889516711235
47
train loss item: 0.16762690246105194
48
train loss item: 0.12854668498039246
49
train loss item: 0.1047702208161354
50
train loss item: 0.1285431981086731
51
train loss item: 0.4019921123981476
52
train loss item: 0.06367228925228119
53
train loss item: 0.09247736632823944
54
train loss item: 1.7475495338439941
55
train loss item: 0.12577146291732788
56
train loss item: 0.1519564390182495
57
train loss item: 0.15467490255832672
58
train loss item: 0.09880417585372925
59
train loss item: 0.09705924987792969
60
train loss item: 0.3606643080711365
61
train loss item: 1.5493435859680176
62
train loss item: 0.12409919500350952
63
train loss item: 0.20554977655410767
64
train loss item: 0.10988671332597733
65
train loss item: 0.2551705837249756
66
train loss item: 0.2124963253736496
67
train loss item: 0.12984874844551086
68
train loss item: 0.16049236059188843
69
train loss item: 0.1794148087501526
70
train loss item: 0.14979073405265808
71
train loss item: 0.09667424857616425
72
train loss item: 0.09512656927108765
73
train loss item: 0.17019526660442352
74
train loss item: 0.06749360263347626
75
train loss item: 0.0893266424536705
76
train loss item: 0.4024568200111389
77
train loss item: 0.7527547478675842
78
train loss item: 0.060071878135204315
79
train loss item: 0.1670076996088028
80
train loss item: 0.08973430842161179
81
train loss item: 0.11717181652784348
82
train loss item: 0.11531190574169159
83
train loss item: 0.24132536351680756
84
train loss item: 0.20318123698234558
85
train loss item: 0.2659479081630707
86
train loss item: 3.506488561630249
87
train loss item: 0.09895487129688263
88
train loss item: 0.1988765001296997
epoch train loss: 0.2890048490397716
testing phase
test loss item: 0.14960351586341858
test loss item: 0.09420574456453323
test loss item: 0.36459845304489136
test loss item: 0.18595552444458008
test loss item: 0.1932545155286789
test loss item: 0.1162458285689354
test loss item: 1.2880733013153076
test loss item: 0.4727773666381836
test loss item: 0.15133215487003326
test loss item: 0.25800621509552
test loss item: 0.5487317442893982
test loss item: 0.12852635979652405
test loss item: 0.1406863033771515
test loss item: 0.2125311642885208
test loss item: 0.1342315673828125
test loss item: 0.07931500673294067
test loss item: 0.2061253786087036
test loss item: 0.2942503094673157
test loss item: 0.5023327469825745
test loss item: 0.18783703446388245
test loss item: 0.4321826994419098
test loss item: 0.30774736404418945
test loss item: 0.19796794652938843
test loss item: 0.14195919036865234
test loss item: 0.14898887276649475
test loss item: 0.19068822264671326
test loss item: 0.22375115752220154
test loss item: 0.14517052471637726
test loss item: 0.2253463715314865
test loss item: 0.23365730047225952
test loss item: 0.5620331168174744
test loss item: 0.07171119004487991
test loss item: 0.1249770075082779
test loss item: 0.36979570984840393
test loss item: 0.2633151710033417
test loss item: 0.3375300168991089
test loss item: 0.592689573764801
test loss item: 0.9369416832923889
test loss item: 0.2953152656555176
test loss item: 0.21628232300281525
test loss item: 0.24259831011295319
test loss item: 0.15990279614925385
test loss item: 0.22084976732730865
test loss item: 0.1709623634815216
test loss item: 0.33451133966445923
test loss item: 0.27991706132888794
test loss item: 0.19989393651485443
test loss item: 0.18070478737354279
test loss item: 0.33425503969192505
test loss item: 0.48371174931526184
test loss item: 0.1900426149368286
test loss item: 0.10978217422962189
test loss item: 0.18180789053440094
test loss item: 0.13233435153961182
test loss item: 0.19682082533836365
test loss item: 0.5189151167869568
test loss item: 0.4179602563381195
test loss item: 0.17134860157966614
test loss item: 0.1860998272895813
test loss item: 0.15418362617492676
test loss item: 0.2841143310070038
test loss item: 0.20956917107105255
test loss item: 0.16952121257781982
test loss item: 0.17865972220897675
test loss item: 0.5764327645301819
test loss item: 0.2534358501434326
test loss item: 0.2250608205795288
test loss item: 0.19245880842208862
test loss item: 0.38531994819641113
test loss item: 0.3278519809246063
test loss item: 0.0681447982788086
test loss item: 0.722399115562439
test loss item: 0.209833562374115
test loss item: 0.27471214532852173
test loss item: 0.11695119738578796
test loss item: 0.12281142920255661
test loss item: 0.14045707881450653
test loss item: 1.0290440320968628
test loss item: 0.2878614664077759
test loss item: 0.15579167008399963
test loss item: 0.07820246368646622
test loss item: 0.686085045337677
test loss item: 0.6156839728355408
test loss item: 0.692994236946106
test loss item: 0.17219313979148865
test loss item: 0.18963094055652618
test loss item: 0.07160147279500961
test loss item: 0.06846845895051956
test loss item: 0.22817763686180115
Epoch [86/100], Training Loss: 0.2890, Testing Loss: 0.2846
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 87/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2519664764404297
1
train loss item: 0.5816293358802795
2
train loss item: 0.13553915917873383
3
train loss item: 0.2488228976726532
4
train loss item: 0.2398804873228073
5
train loss item: 0.18678854405879974
6
train loss item: 0.13449408113956451
7
train loss item: 0.42140161991119385
8
train loss item: 0.07902733981609344
9
train loss item: 0.146511048078537
10
train loss item: 0.16643734276294708
11
train loss item: 0.17459969222545624
12
train loss item: 0.10273370146751404
13
train loss item: 0.2340846210718155
14
train loss item: 0.14040899276733398
15
train loss item: 0.28801190853118896
16
train loss item: 0.0570925809442997
17
train loss item: 0.1521448940038681
18
train loss item: 0.17951148748397827
19
train loss item: 0.14418663084506989
20
train loss item: 0.12562033534049988
21
train loss item: 0.08822140842676163
22
train loss item: 0.34054020047187805
23
train loss item: 0.3838019073009491
24
train loss item: 0.2736068069934845
25
train loss item: 0.11511823534965515
26
train loss item: 0.12591876089572906
27
train loss item: 0.1525779664516449
28
train loss item: 0.055043064057826996
29
train loss item: 0.2824549973011017
30
train loss item: 1.4265031814575195
31
train loss item: 0.2708280384540558
32
train loss item: 0.08263351768255234
33
train loss item: 0.16832758486270905
34
train loss item: 0.10929536819458008
35
train loss item: 1.869882345199585
36
train loss item: 0.24911774694919586
37
train loss item: 0.213709756731987
38
train loss item: 0.23155421018600464
39
train loss item: 0.17126819491386414
40
train loss item: 0.11097171157598495
41
train loss item: 0.14051882922649384
42
train loss item: 0.20393481850624084
43
train loss item: 0.11087126284837723
44
train loss item: 0.4498250484466553
45
train loss item: 0.09379621595144272
46
train loss item: 0.08366251736879349
47
train loss item: 0.1748848855495453
48
train loss item: 0.13174624741077423
49
train loss item: 0.1053597554564476
50
train loss item: 0.13193723559379578
51
train loss item: 0.412149041891098
52
train loss item: 0.06378333270549774
53
train loss item: 0.09347888827323914
54
train loss item: 1.7388402223587036
55
train loss item: 0.12823601067066193
56
train loss item: 0.15088671445846558
57
train loss item: 0.1590132713317871
58
train loss item: 0.10548616945743561
59
train loss item: 0.09539232403039932
60
train loss item: 0.3544255197048187
61
train loss item: 1.5368520021438599
62
train loss item: 0.12673594057559967
63
train loss item: 0.21349471807479858
64
train loss item: 0.10092496871948242
65
train loss item: 0.2532343566417694
66
train loss item: 0.21291609108448029
67
train loss item: 0.13421031832695007
68
train loss item: 0.16565637290477753
69
train loss item: 0.17705214023590088
70
train loss item: 0.14965349435806274
71
train loss item: 0.10178326815366745
72
train loss item: 0.09507618844509125
73
train loss item: 0.17135293781757355
74
train loss item: 0.06805542856454849
75
train loss item: 0.08912965655326843
76
train loss item: 0.4004685580730438
77
train loss item: 0.7611311078071594
78
train loss item: 0.06138911098241806
79
train loss item: 0.16507236659526825
80
train loss item: 0.0855235755443573
81
train loss item: 0.12031863629817963
82
train loss item: 0.10920785367488861
83
train loss item: 0.23879067599773407
84
train loss item: 0.20859697461128235
85
train loss item: 0.2758347988128662
86
train loss item: 3.4969143867492676
87
train loss item: 0.09962735325098038
88
train loss item: 0.19927194714546204
epoch train loss: 0.2883008058402645
testing phase
test loss item: 0.14713901281356812
test loss item: 0.10216454416513443
test loss item: 0.4142264723777771
test loss item: 0.1826673448085785
test loss item: 0.20464184880256653
test loss item: 0.11316579580307007
test loss item: 1.270965337753296
test loss item: 0.44987866282463074
test loss item: 0.16258291900157928
test loss item: 0.27712562680244446
test loss item: 0.643765389919281
test loss item: 0.13278324902057648
test loss item: 0.14332148432731628
test loss item: 0.21105127036571503
test loss item: 0.13933785259723663
test loss item: 0.08351106941699982
test loss item: 0.19786973297595978
test loss item: 0.3211013078689575
test loss item: 0.49065059423446655
test loss item: 0.18651890754699707
test loss item: 0.46788790822029114
test loss item: 0.30081620812416077
test loss item: 0.2080245167016983
test loss item: 0.1380511075258255
test loss item: 0.15423820912837982
test loss item: 0.18043652176856995
test loss item: 0.22390694916248322
test loss item: 0.14956890046596527
test loss item: 0.23237475752830505
test loss item: 0.24320566654205322
test loss item: 0.6088206171989441
test loss item: 0.07181600481271744
test loss item: 0.12260913103818893
test loss item: 0.40655115246772766
test loss item: 0.2948343753814697
test loss item: 0.36762678623199463
test loss item: 0.5882894992828369
test loss item: 1.1040273904800415
test loss item: 0.3197000026702881
test loss item: 0.20793704688549042
test loss item: 0.23812466859817505
test loss item: 0.15555831789970398
test loss item: 0.2402259111404419
test loss item: 0.16643717885017395
test loss item: 0.3561623692512512
test loss item: 0.26834550499916077
test loss item: 0.20754806697368622
test loss item: 0.1764596402645111
test loss item: 0.3569490909576416
test loss item: 0.5185383558273315
test loss item: 0.20047251880168915
test loss item: 0.11258934438228607
test loss item: 0.18337766826152802
test loss item: 0.13644927740097046
test loss item: 0.2123405635356903
test loss item: 0.6114478707313538
test loss item: 0.43595898151397705
test loss item: 0.1823408454656601
test loss item: 0.18242578208446503
test loss item: 0.16151480376720428
test loss item: 0.31688392162323
test loss item: 0.19799107313156128
test loss item: 0.1632128357887268
test loss item: 0.17750492691993713
test loss item: 0.6423687934875488
test loss item: 0.25032946467399597
test loss item: 0.21825772523880005
test loss item: 0.19160182774066925
test loss item: 0.42747563123703003
test loss item: 0.32251131534576416
test loss item: 0.07297035306692123
test loss item: 0.6964004039764404
test loss item: 0.2204614281654358
test loss item: 0.2673981189727783
test loss item: 0.11714297533035278
test loss item: 0.13189317286014557
test loss item: 0.1389179825782776
test loss item: 1.2236839532852173
test loss item: 0.3075456917285919
test loss item: 0.1543368101119995
test loss item: 0.07795589417219162
test loss item: 0.7464476227760315
test loss item: 0.6237972974777222
test loss item: 0.8261972665786743
test loss item: 0.17125780880451202
test loss item: 0.1907464563846588
test loss item: 0.07262075692415237
test loss item: 0.06918526440858841
test loss item: 0.197179913520813
Epoch [87/100], Training Loss: 0.2883, Testing Loss: 0.2987
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 88/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.24552534520626068
1
train loss item: 0.5642684698104858
2
train loss item: 0.12973006069660187
3
train loss item: 0.23352128267288208
4
train loss item: 0.21994628012180328
5
train loss item: 0.18230509757995605
6
train loss item: 0.1288936585187912
7
train loss item: 0.41681161522865295
8
train loss item: 0.0735422670841217
9
train loss item: 0.13883894681930542
10
train loss item: 0.16070297360420227
11
train loss item: 0.17165352404117584
12
train loss item: 0.09978648275136948
13
train loss item: 0.2324604094028473
14
train loss item: 0.1394975483417511
15
train loss item: 0.27670052647590637
16
train loss item: 0.055206798017024994
17
train loss item: 0.14839056134223938
18
train loss item: 0.17471075057983398
19
train loss item: 0.13722948729991913
20
train loss item: 0.11833275854587555
21
train loss item: 0.08386348932981491
22
train loss item: 0.3324749171733856
23
train loss item: 0.37593454122543335
24
train loss item: 0.2706647515296936
25
train loss item: 0.10830515623092651
26
train loss item: 0.12256978452205658
27
train loss item: 0.14916957914829254
28
train loss item: 0.05363911762833595
29
train loss item: 0.27384501695632935
30
train loss item: 1.4217233657836914
31
train loss item: 0.2558511793613434
32
train loss item: 0.07922114431858063
33
train loss item: 0.1624353528022766
34
train loss item: 0.10545691102743149
35
train loss item: 1.8673549890518188
36
train loss item: 0.24386706948280334
37
train loss item: 0.20961938798427582
38
train loss item: 0.21757876873016357
39
train loss item: 0.1679030954837799
40
train loss item: 0.10659055411815643
41
train loss item: 0.13518935441970825
42
train loss item: 0.20133556425571442
43
train loss item: 0.10779417306184769
44
train loss item: 0.44584739208221436
45
train loss item: 0.09164712578058243
46
train loss item: 0.08128378540277481
47
train loss item: 0.16378074884414673
48
train loss item: 0.12805724143981934
49
train loss item: 0.10162237286567688
50
train loss item: 0.12490896880626678
51
train loss item: 0.39799925684928894
52
train loss item: 0.06226484850049019
53
train loss item: 0.08907649666070938
54
train loss item: 1.735915184020996
55
train loss item: 0.12408452481031418
56
train loss item: 0.14399340748786926
57
train loss item: 0.155046746134758
58
train loss item: 0.0971880704164505
59
train loss item: 0.09482723474502563
60
train loss item: 0.3473827838897705
61
train loss item: 1.5318244695663452
62
train loss item: 0.11951247602701187
63
train loss item: 0.2055159956216812
64
train loss item: 0.10262048244476318
65
train loss item: 0.24514496326446533
66
train loss item: 0.2052837610244751
67
train loss item: 0.12859219312667847
68
train loss item: 0.16007418930530548
69
train loss item: 0.1725250482559204
70
train loss item: 0.14379946887493134
71
train loss item: 0.09810563176870346
72
train loss item: 0.08985095471143723
73
train loss item: 0.16606123745441437
74
train loss item: 0.06501635164022446
75
train loss item: 0.08832600712776184
76
train loss item: 0.3906339108943939
77
train loss item: 0.7499236464500427
78
train loss item: 0.05844172090291977
79
train loss item: 0.1619260609149933
80
train loss item: 0.08273030072450638
81
train loss item: 0.11379020661115646
82
train loss item: 0.10865598171949387
83
train loss item: 0.23365052044391632
84
train loss item: 0.19916516542434692
85
train loss item: 0.26503220200538635
86
train loss item: 3.491926670074463
87
train loss item: 0.09428401291370392
88
train loss item: 0.1930333822965622
epoch train loss: 0.28259343042802276
testing phase
test loss item: 0.14199946820735931
test loss item: 0.10147733241319656
test loss item: 0.4346974790096283
test loss item: 0.17982055246829987
test loss item: 0.2067239135503769
test loss item: 0.10839436948299408
test loss item: 1.114396333694458
test loss item: 0.39757758378982544
test loss item: 0.1646859496831894
test loss item: 0.28081345558166504
test loss item: 0.655903160572052
test loss item: 0.1346193552017212
test loss item: 0.1386190950870514
test loss item: 0.1995614618062973
test loss item: 0.1384434849023819
test loss item: 0.08248117566108704
test loss item: 0.18208998441696167
test loss item: 0.33350828289985657
test loss item: 0.4580182731151581
test loss item: 0.16992712020874023
test loss item: 0.48993557691574097
test loss item: 0.28319185972213745
test loss item: 0.21495245397090912
test loss item: 0.12863068282604218
test loss item: 0.1549348384141922
test loss item: 0.1754748821258545
test loss item: 0.21401725709438324
test loss item: 0.1450057029724121
test loss item: 0.2252454161643982
test loss item: 0.24322111904621124
test loss item: 0.5920573472976685
test loss item: 0.07029596716165543
test loss item: 0.1157863438129425
test loss item: 0.42335984110832214
test loss item: 0.3096468150615692
test loss item: 0.3621756136417389
test loss item: 0.5420482158660889
test loss item: 1.1472699642181396
test loss item: 0.3254406750202179
test loss item: 0.19231462478637695
test loss item: 0.22440993785858154
test loss item: 0.16054801642894745
test loss item: 0.2520411014556885
test loss item: 0.16229963302612305
test loss item: 0.36341163516044617
test loss item: 0.2400633841753006
test loss item: 0.2053776979446411
test loss item: 0.16639520227909088
test loss item: 0.3596428632736206
test loss item: 0.5224378108978271
test loss item: 0.20253857970237732
test loss item: 0.11351215094327927
test loss item: 0.17979411780834198
test loss item: 0.14895257353782654
test loss item: 0.221247136592865
test loss item: 0.6468706727027893
test loss item: 0.41505324840545654
test loss item: 0.17317873239517212
test loss item: 0.17426170408725739
test loss item: 0.15961915254592896
test loss item: 0.3295711278915405
test loss item: 0.18489085137844086
test loss item: 0.14983700215816498
test loss item: 0.1700315624475479
test loss item: 0.6490613222122192
test loss item: 0.2491483837366104
test loss item: 0.20370082557201385
test loss item: 0.1799243688583374
test loss item: 0.4350973665714264
test loss item: 0.30384495854377747
test loss item: 0.06859994679689407
test loss item: 0.6075339317321777
test loss item: 0.202867329120636
test loss item: 0.2381889373064041
test loss item: 0.11137419193983078
test loss item: 0.12574782967567444
test loss item: 0.12928858399391174
test loss item: 1.2616788148880005
test loss item: 0.3020784854888916
test loss item: 0.14803840219974518
test loss item: 0.0751037746667862
test loss item: 0.7164512872695923
test loss item: 0.5813949704170227
test loss item: 0.8480377793312073
test loss item: 0.16012269258499146
test loss item: 0.2051396518945694
test loss item: 0.07054657489061356
test loss item: 0.0694853663444519
test loss item: 0.2294464260339737
Epoch [88/100], Training Loss: 0.2826, Testing Loss: 0.2930
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 89/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.24684402346611023
1
train loss item: 0.559484601020813
2
train loss item: 0.1274920105934143
3
train loss item: 0.23268786072731018
4
train loss item: 0.22800995409488678
5
train loss item: 0.18257346749305725
6
train loss item: 0.13029947876930237
7
train loss item: 0.4176097512245178
8
train loss item: 0.07661455124616623
9
train loss item: 0.14130058884620667
10
train loss item: 0.1627824604511261
11
train loss item: 0.17904885113239288
12
train loss item: 0.09836787730455399
13
train loss item: 0.23097969591617584
14
train loss item: 0.14332182705402374
15
train loss item: 0.2839832305908203
16
train loss item: 0.05451318621635437
17
train loss item: 0.1496397703886032
18
train loss item: 0.175892636179924
19
train loss item: 0.13854441046714783
20
train loss item: 0.12102136760950089
21
train loss item: 0.08644578605890274
22
train loss item: 0.3355827033519745
23
train loss item: 0.3697543740272522
24
train loss item: 0.2620982229709625
25
train loss item: 0.10841990262269974
26
train loss item: 0.12426982820034027
27
train loss item: 0.1534416228532791
28
train loss item: 0.05302297696471214
29
train loss item: 0.2773183584213257
30
train loss item: 1.4192066192626953
31
train loss item: 0.25524142384529114
32
train loss item: 0.08250868320465088
33
train loss item: 0.16273722052574158
34
train loss item: 0.10380742698907852
35
train loss item: 1.8643622398376465
36
train loss item: 0.2549479603767395
37
train loss item: 0.20987620949745178
38
train loss item: 0.21873146295547485
39
train loss item: 0.16945266723632812
40
train loss item: 0.10588125884532928
41
train loss item: 0.14033420383930206
42
train loss item: 0.2001677304506302
43
train loss item: 0.10959617048501968
44
train loss item: 0.4490317106246948
45
train loss item: 0.09262610971927643
46
train loss item: 0.08499962091445923
47
train loss item: 0.17193621397018433
48
train loss item: 0.12684904038906097
49
train loss item: 0.10229992121458054
50
train loss item: 0.1251562386751175
51
train loss item: 0.39118367433547974
52
train loss item: 0.06190168857574463
53
train loss item: 0.09072016924619675
54
train loss item: 1.7333191633224487
55
train loss item: 0.12548692524433136
56
train loss item: 0.14450934529304504
57
train loss item: 0.1526445746421814
58
train loss item: 0.09586578607559204
59
train loss item: 0.09593651443719864
60
train loss item: 0.34300896525382996
61
train loss item: 1.5291575193405151
62
train loss item: 0.12353639304637909
63
train loss item: 0.1991095095872879
64
train loss item: 0.10879893600940704
65
train loss item: 0.2457108050584793
66
train loss item: 0.20815950632095337
67
train loss item: 0.12834158539772034
68
train loss item: 0.15868178009986877
69
train loss item: 0.17448914051055908
70
train loss item: 0.1517624408006668
71
train loss item: 0.0944908857345581
72
train loss item: 0.0937516912817955
73
train loss item: 0.1684495061635971
74
train loss item: 0.06621464341878891
75
train loss item: 0.08858508616685867
76
train loss item: 0.38287264108657837
77
train loss item: 0.7357967495918274
78
train loss item: 0.057821255177259445
79
train loss item: 0.16666316986083984
80
train loss item: 0.08565191179513931
81
train loss item: 0.11827215552330017
82
train loss item: 0.11089631170034409
83
train loss item: 0.23600606620311737
84
train loss item: 0.2001318484544754
85
train loss item: 0.2511608600616455
86
train loss item: 3.4886016845703125
87
train loss item: 0.09716316312551498
88
train loss item: 0.19558756053447723
epoch train loss: 0.2831635631704598
testing phase
test loss item: 0.142891526222229
test loss item: 0.09789545089006424
test loss item: 0.3946024775505066
test loss item: 0.1771405041217804
test loss item: 0.19841831922531128
test loss item: 0.11026657372713089
test loss item: 1.1447875499725342
test loss item: 0.41851210594177246
test loss item: 0.15520328283309937
test loss item: 0.2613661289215088
test loss item: 0.5735752582550049
test loss item: 0.12909796833992004
test loss item: 0.13700199127197266
test loss item: 0.20269843935966492
test loss item: 0.1332160383462906
test loss item: 0.08055496215820312
test loss item: 0.1900932788848877
test loss item: 0.3060167729854584
test loss item: 0.46282273530960083
test loss item: 0.1708245873451233
test loss item: 0.45110177993774414
test loss item: 0.29004302620887756
test loss item: 0.2070649117231369
test loss item: 0.13062670826911926
test loss item: 0.14906279742717743
test loss item: 0.18023400008678436
test loss item: 0.20580698549747467
test loss item: 0.1400202363729477
test loss item: 0.21970118582248688
test loss item: 0.22872747480869293
test loss item: 0.5570994019508362
test loss item: 0.06961675733327866
test loss item: 0.11630526185035706
test loss item: 0.3911956548690796
test loss item: 0.28217995166778564
test loss item: 0.32611730694770813
test loss item: 0.5452766418457031
test loss item: 1.0150728225708008
test loss item: 0.299791157245636
test loss item: 0.1986534744501114
test loss item: 0.22876349091529846
test loss item: 0.16116291284561157
test loss item: 0.23535870015621185
test loss item: 0.16258402168750763
test loss item: 0.33510807156562805
test loss item: 0.25039196014404297
test loss item: 0.19824238121509552
test loss item: 0.15897320210933685
test loss item: 0.34231582283973694
test loss item: 0.48661887645721436
test loss item: 0.18919499218463898
test loss item: 0.1064467653632164
test loss item: 0.17603987455368042
test loss item: 0.13797780871391296
test loss item: 0.20582151412963867
test loss item: 0.5682108402252197
test loss item: 0.38963940739631653
test loss item: 0.16736693680286407
test loss item: 0.17326946556568146
test loss item: 0.15391604602336884
test loss item: 0.2965986132621765
test loss item: 0.19822461903095245
test loss item: 0.15516245365142822
test loss item: 0.1710129976272583
test loss item: 0.5890523791313171
test loss item: 0.24294200539588928
test loss item: 0.20885629951953888
test loss item: 0.18270441889762878
test loss item: 0.4039435386657715
test loss item: 0.3031221926212311
test loss item: 0.06817398220300674
test loss item: 0.640478789806366
test loss item: 0.19913268089294434
test loss item: 0.24801434576511383
test loss item: 0.11277743428945541
test loss item: 0.12042620778083801
test loss item: 0.12995384633541107
test loss item: 1.1250560283660889
test loss item: 0.2846592962741852
test loss item: 0.14759667217731476
test loss item: 0.07726024836301804
test loss item: 0.6596723794937134
test loss item: 0.5711055994033813
test loss item: 0.7509104013442993
test loss item: 0.1591879427433014
test loss item: 0.2006516307592392
test loss item: 0.07045888900756836
test loss item: 0.06646568328142166
test loss item: 0.23238961398601532
Epoch [89/100], Training Loss: 0.2832, Testing Loss: 0.2802
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 90/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.23985666036605835
1
train loss item: 0.5500050187110901
2
train loss item: 0.1260005384683609
3
train loss item: 0.22870098054409027
4
train loss item: 0.2116001397371292
5
train loss item: 0.17815665900707245
6
train loss item: 0.12519556283950806
7
train loss item: 0.4072246849536896
8
train loss item: 0.07232526689767838
9
train loss item: 0.13558369874954224
10
train loss item: 0.15571129322052002
11
train loss item: 0.1676979660987854
12
train loss item: 0.09877340495586395
13
train loss item: 0.22585375607013702
14
train loss item: 0.13710279762744904
15
train loss item: 0.27276286482810974
16
train loss item: 0.054670047014951706
17
train loss item: 0.14498543739318848
18
train loss item: 0.1701015830039978
19
train loss item: 0.13288789987564087
20
train loss item: 0.11621654033660889
21
train loss item: 0.08254313468933105
22
train loss item: 0.32414910197257996
23
train loss item: 0.3629765510559082
24
train loss item: 0.2603449523448944
25
train loss item: 0.10461536794900894
26
train loss item: 0.12009388208389282
27
train loss item: 0.1468273252248764
28
train loss item: 0.052485644817352295
29
train loss item: 0.26819780468940735
30
train loss item: 1.4072030782699585
31
train loss item: 0.2486090213060379
32
train loss item: 0.07797090709209442
33
train loss item: 0.16070117056369781
34
train loss item: 0.10263338685035706
35
train loss item: 1.857672095298767
36
train loss item: 0.24081137776374817
37
train loss item: 0.2063712626695633
38
train loss item: 0.21097712218761444
39
train loss item: 0.16454929113388062
40
train loss item: 0.1033363938331604
41
train loss item: 0.1331871896982193
42
train loss item: 0.19589483737945557
43
train loss item: 0.10571083426475525
44
train loss item: 0.44102323055267334
45
train loss item: 0.09016920626163483
46
train loss item: 0.07911772280931473
47
train loss item: 0.1591317057609558
48
train loss item: 0.12374884635210037
49
train loss item: 0.0988980159163475
50
train loss item: 0.12125985324382782
51
train loss item: 0.38797804713249207
52
train loss item: 0.06092549115419388
53
train loss item: 0.08757050335407257
54
train loss item: 1.7263200283050537
55
train loss item: 0.12134990841150284
56
train loss item: 0.1407093107700348
57
train loss item: 0.14896497130393982
58
train loss item: 0.09894858300685883
59
train loss item: 0.09262845665216446
60
train loss item: 0.33449336886405945
61
train loss item: 1.5199302434921265
62
train loss item: 0.11818341910839081
63
train loss item: 0.1966707557439804
64
train loss item: 0.09878655523061752
65
train loss item: 0.23952654004096985
66
train loss item: 0.1997080147266388
67
train loss item: 0.1264810413122177
68
train loss item: 0.15555499494075775
69
train loss item: 0.16899116337299347
70
train loss item: 0.14122126996517181
71
train loss item: 0.0938873365521431
72
train loss item: 0.08718141168355942
73
train loss item: 0.16199864447116852
74
train loss item: 0.06387989968061447
75
train loss item: 0.08624320477247238
76
train loss item: 0.37559473514556885
77
train loss item: 0.7350292801856995
78
train loss item: 0.057525962591171265
79
train loss item: 0.15746642649173737
80
train loss item: 0.08258344233036041
81
train loss item: 0.11206565797328949
82
train loss item: 0.10596206039190292
83
train loss item: 0.22832728922367096
84
train loss item: 0.1936807632446289
85
train loss item: 0.2452469915151596
86
train loss item: 3.4805948734283447
87
train loss item: 0.09259074181318283
88
train loss item: 0.19045637547969818
epoch train loss: 0.2777289986359269
testing phase
test loss item: 0.14671878516674042
test loss item: 0.09937156736850739
test loss item: 0.39108985662460327
test loss item: 0.1832074373960495
test loss item: 0.19716638326644897
test loss item: 0.11377518624067307
test loss item: 1.2645809650421143
test loss item: 0.45624321699142456
test loss item: 0.15765662491321564
test loss item: 0.2634657025337219
test loss item: 0.5717171430587769
test loss item: 0.13151006400585175
test loss item: 0.14367401599884033
test loss item: 0.21411354839801788
test loss item: 0.1353096067905426
test loss item: 0.08359638601541519
test loss item: 0.20174437761306763
test loss item: 0.30172988772392273
test loss item: 0.48815327882766724
test loss item: 0.18590377271175385
test loss item: 0.44013315439224243
test loss item: 0.30243733525276184
test loss item: 0.20553825795650482
test loss item: 0.1389651596546173
test loss item: 0.1498495191335678
test loss item: 0.18529266119003296
test loss item: 0.21455883979797363
test loss item: 0.14455942809581757
test loss item: 0.2248888611793518
test loss item: 0.23138535022735596
test loss item: 0.5708516836166382
test loss item: 0.07333982735872269
test loss item: 0.12315201759338379
test loss item: 0.3856394290924072
test loss item: 0.27755334973335266
test loss item: 0.33502766489982605
test loss item: 0.5827586054801941
test loss item: 0.9878963828086853
test loss item: 0.30221349000930786
test loss item: 0.20967508852481842
test loss item: 0.23675332963466644
test loss item: 0.16115565598011017
test loss item: 0.23037350177764893
test loss item: 0.16849632561206818
test loss item: 0.3325815796852112
test loss item: 0.2711322009563446
test loss item: 0.20175263285636902
test loss item: 0.17223724722862244
test loss item: 0.34491488337516785
test loss item: 0.49173951148986816
test loss item: 0.1886563003063202
test loss item: 0.10856848210096359
test loss item: 0.17915308475494385
test loss item: 0.13558903336524963
test loss item: 0.20152877271175385
test loss item: 0.5584230422973633
test loss item: 0.4137555658817291
test loss item: 0.165801540017128
test loss item: 0.180059015750885
test loss item: 0.15605111420154572
test loss item: 0.29281845688819885
test loss item: 0.20586520433425903
test loss item: 0.1662517488002777
test loss item: 0.17462369799613953
test loss item: 0.6000487804412842
test loss item: 0.2491239607334137
test loss item: 0.22039295732975006
test loss item: 0.18986837565898895
test loss item: 0.4012390077114105
test loss item: 0.3196506202220917
test loss item: 0.07346752285957336
test loss item: 0.7044149041175842
test loss item: 0.2146957665681839
test loss item: 0.27108481526374817
test loss item: 0.11886578798294067
test loss item: 0.12673456966876984
test loss item: 0.13806411623954773
test loss item: 1.081729769706726
test loss item: 0.2939596474170685
test loss item: 0.151667058467865
test loss item: 0.07874386012554169
test loss item: 0.6914122700691223
test loss item: 0.6100283861160278
test loss item: 0.7304980158805847
test loss item: 0.1675792932510376
test loss item: 0.1974608153104782
test loss item: 0.07169625163078308
test loss item: 0.06677863746881485
test loss item: 0.21749617159366608
Epoch [90/100], Training Loss: 0.2777, Testing Loss: 0.2870
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 91/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.23874615132808685
1
train loss item: 0.5462856292724609
2
train loss item: 0.12841783463954926
3
train loss item: 0.2307896763086319
4
train loss item: 0.20983552932739258
5
train loss item: 0.17848818004131317
6
train loss item: 0.12653794884681702
7
train loss item: 0.4018869698047638
8
train loss item: 0.07309645414352417
9
train loss item: 0.1363653838634491
10
train loss item: 0.1542479246854782
11
train loss item: 0.16647286713123322
12
train loss item: 0.0988052636384964
13
train loss item: 0.22355765104293823
14
train loss item: 0.13491111993789673
15
train loss item: 0.2667814791202545
16
train loss item: 0.054347001016139984
17
train loss item: 0.14453479647636414
18
train loss item: 0.1713128536939621
19
train loss item: 0.13360831141471863
20
train loss item: 0.11637486517429352
21
train loss item: 0.08365362882614136
22
train loss item: 0.3239499628543854
23
train loss item: 0.35773134231567383
24
train loss item: 0.26132887601852417
25
train loss item: 0.10552611947059631
26
train loss item: 0.12010279297828674
27
train loss item: 0.14489710330963135
28
train loss item: 0.052524417638778687
29
train loss item: 0.2647199332714081
30
train loss item: 1.3992570638656616
31
train loss item: 0.24860019981861115
32
train loss item: 0.07883406430482864
33
train loss item: 0.16055816411972046
34
train loss item: 0.10288022458553314
35
train loss item: 1.8521109819412231
36
train loss item: 0.23571357131004333
37
train loss item: 0.20735912024974823
38
train loss item: 0.2166992574930191
39
train loss item: 0.1634419560432434
40
train loss item: 0.10369854420423508
41
train loss item: 0.13285571336746216
42
train loss item: 0.20022132992744446
43
train loss item: 0.10854993760585785
44
train loss item: 0.43520453572273254
45
train loss item: 0.09005333483219147
46
train loss item: 0.08035986125469208
47
train loss item: 0.16900761425495148
48
train loss item: 0.1251867711544037
49
train loss item: 0.10016737133264542
50
train loss item: 0.12277191877365112
51
train loss item: 0.3898972272872925
52
train loss item: 0.06049158424139023
53
train loss item: 0.0874200090765953
54
train loss item: 1.721481204032898
55
train loss item: 0.12333429604768753
56
train loss item: 0.1408996433019638
57
train loss item: 0.15415669977664948
58
train loss item: 0.10314524173736572
59
train loss item: 0.09312856197357178
60
train loss item: 0.3333468437194824
61
train loss item: 1.5130581855773926
62
train loss item: 0.11725065112113953
63
train loss item: 0.20330575108528137
64
train loss item: 0.09893453121185303
65
train loss item: 0.23870041966438293
66
train loss item: 0.2002694010734558
67
train loss item: 0.12790566682815552
68
train loss item: 0.15740659832954407
69
train loss item: 0.16849008202552795
70
train loss item: 0.14252085983753204
71
train loss item: 0.09588577598333359
72
train loss item: 0.08933941274881363
73
train loss item: 0.1611487716436386
74
train loss item: 0.06374136358499527
75
train loss item: 0.08705659210681915
76
train loss item: 0.3720363676548004
77
train loss item: 0.7387496829032898
78
train loss item: 0.056812066584825516
79
train loss item: 0.15845303237438202
80
train loss item: 0.08157602697610855
81
train loss item: 0.1121901273727417
82
train loss item: 0.10547390580177307
83
train loss item: 0.22565039992332458
84
train loss item: 0.19742968678474426
85
train loss item: 0.2460816651582718
86
train loss item: 3.473844528198242
87
train loss item: 0.09165768325328827
88
train loss item: 0.1878606677055359
epoch train loss: 0.2775674249265301
testing phase
test loss item: 0.14311018586158752
test loss item: 0.10328571498394012
test loss item: 0.4278293550014496
test loss item: 0.18193428218364716
test loss item: 0.20367911458015442
test loss item: 0.11001814901828766
test loss item: 1.2179919481277466
test loss item: 0.4277642071247101
test loss item: 0.16729964315891266
test loss item: 0.2794446349143982
test loss item: 0.6350237727165222
test loss item: 0.13457010686397552
test loss item: 0.14362002909183502
test loss item: 0.20192404091358185
test loss item: 0.1412554532289505
test loss item: 0.0863410159945488
test loss item: 0.19166943430900574
test loss item: 0.326209157705307
test loss item: 0.47158944606781006
test loss item: 0.17711113393306732
test loss item: 0.47552454471588135
test loss item: 0.29046502709388733
test loss item: 0.21006615459918976
test loss item: 0.13529124855995178
test loss item: 0.15390221774578094
test loss item: 0.17920418083667755
test loss item: 0.21404294669628143
test loss item: 0.14734186232089996
test loss item: 0.22837497293949127
test loss item: 0.24071477353572845
test loss item: 0.5978052020072937
test loss item: 0.07662133127450943
test loss item: 0.12097815424203873
test loss item: 0.4127834141254425
test loss item: 0.3023303151130676
test loss item: 0.35675665736198425
test loss item: 0.5678699016571045
test loss item: 1.1036732196807861
test loss item: 0.3221602737903595
test loss item: 0.19950370490550995
test loss item: 0.22821083664894104
test loss item: 0.1591968536376953
test loss item: 0.24656474590301514
test loss item: 0.16521361470222473
test loss item: 0.35469648241996765
test loss item: 0.25579407811164856
test loss item: 0.20371942222118378
test loss item: 0.16485349833965302
test loss item: 0.3595694303512573
test loss item: 0.5156630873680115
test loss item: 0.19948609173297882
test loss item: 0.11026358604431152
test loss item: 0.1806875765323639
test loss item: 0.14128944277763367
test loss item: 0.2144753634929657
test loss item: 0.6259130239486694
test loss item: 0.42474162578582764
test loss item: 0.16165761649608612
test loss item: 0.17534735798835754
test loss item: 0.16047893464565277
test loss item: 0.32251331210136414
test loss item: 0.19023185968399048
test loss item: 0.15776501595973969
test loss item: 0.17006058990955353
test loss item: 0.6413756608963013
test loss item: 0.2480182647705078
test loss item: 0.21087558567523956
test loss item: 0.1842721551656723
test loss item: 0.4247475862503052
test loss item: 0.31088584661483765
test loss item: 0.07659084349870682
test loss item: 0.6664056777954102
test loss item: 0.21062198281288147
test loss item: 0.25537773966789246
test loss item: 0.1161770224571228
test loss item: 0.12650957703590393
test loss item: 0.13639630377292633
test loss item: 1.2092262506484985
test loss item: 0.3012813925743103
test loss item: 0.14729128777980804
test loss item: 0.07864342629909515
test loss item: 0.7283573150634766
test loss item: 0.606351912021637
test loss item: 0.8201408982276917
test loss item: 0.16217626631259918
test loss item: 0.20436860620975494
test loss item: 0.0724722295999527
test loss item: 0.06855270266532898
test loss item: 0.22486275434494019
Epoch [91/100], Training Loss: 0.2776, Testing Loss: 0.2947
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 92/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2353510856628418
1
train loss item: 0.5309207439422607
2
train loss item: 0.12277445197105408
3
train loss item: 0.21879862248897552
4
train loss item: 0.2057601660490036
5
train loss item: 0.1759326308965683
6
train loss item: 0.1237587109208107
7
train loss item: 0.40063440799713135
8
train loss item: 0.07024827599525452
9
train loss item: 0.1343725621700287
10
train loss item: 0.15245521068572998
11
train loss item: 0.16389232873916626
12
train loss item: 0.09587445110082626
13
train loss item: 0.21971823275089264
14
train loss item: 0.13480179011821747
15
train loss item: 0.26134052872657776
16
train loss item: 0.0529288649559021
17
train loss item: 0.14238479733467102
18
train loss item: 0.16648513078689575
19
train loss item: 0.13038204610347748
20
train loss item: 0.11319556087255478
21
train loss item: 0.08143987506628036
22
train loss item: 0.31800416111946106
23
train loss item: 0.3501049280166626
24
train loss item: 0.2551828920841217
25
train loss item: 0.10305885225534439
26
train loss item: 0.11829128861427307
27
train loss item: 0.14400817453861237
28
train loss item: 0.05198362097144127
29
train loss item: 0.2622278034687042
30
train loss item: 1.393965482711792
31
train loss item: 0.24357430636882782
32
train loss item: 0.07679959386587143
33
train loss item: 0.15395963191986084
34
train loss item: 0.10067465156316757
35
train loss item: 1.8492920398712158
36
train loss item: 0.23557904362678528
37
train loss item: 0.20463618636131287
38
train loss item: 0.2092343419790268
39
train loss item: 0.16103535890579224
40
train loss item: 0.10168429464101791
41
train loss item: 0.13147911429405212
42
train loss item: 0.1954827904701233
43
train loss item: 0.1043960452079773
44
train loss item: 0.4333385229110718
45
train loss item: 0.08959874510765076
46
train loss item: 0.07850782573223114
47
train loss item: 0.15945057570934296
48
train loss item: 0.12243965268135071
49
train loss item: 0.09764198958873749
50
train loss item: 0.11847908049821854
51
train loss item: 0.3802199959754944
52
train loss item: 0.059756193310022354
53
train loss item: 0.08639049530029297
54
train loss item: 1.7183743715286255
55
train loss item: 0.1202055960893631
56
train loss item: 0.1380499005317688
57
train loss item: 0.14888489246368408
58
train loss item: 0.09277753531932831
59
train loss item: 0.0930994525551796
60
train loss item: 0.32558491826057434
61
train loss item: 1.5083609819412231
62
train loss item: 0.11488685756921768
63
train loss item: 0.1925269514322281
64
train loss item: 0.10078009963035583
65
train loss item: 0.23455743491649628
66
train loss item: 0.19696255028247833
67
train loss item: 0.12338373064994812
68
train loss item: 0.1533229649066925
69
train loss item: 0.16732841730117798
70
train loss item: 0.13939274847507477
71
train loss item: 0.09200935065746307
72
train loss item: 0.08788440376520157
73
train loss item: 0.15981072187423706
74
train loss item: 0.06296965479850769
75
train loss item: 0.08639038354158401
76
train loss item: 0.3625730872154236
77
train loss item: 0.7278680205345154
78
train loss item: 0.055204905569553375
79
train loss item: 0.1542367935180664
80
train loss item: 0.08176665753126144
81
train loss item: 0.1097617819905281
82
train loss item: 0.105012908577919
83
train loss item: 0.22448857128620148
84
train loss item: 0.19253523647785187
85
train loss item: 0.24367596209049225
86
train loss item: 3.468646287918091
87
train loss item: 0.09142955392599106
88
train loss item: 0.18756675720214844
epoch train loss: 0.27400268086891494
testing phase
test loss item: 0.13786472380161285
test loss item: 0.09985974431037903
test loss item: 0.4215320944786072
test loss item: 0.17707835137844086
test loss item: 0.20157836377620697
test loss item: 0.10530507564544678
test loss item: 1.131252646446228
test loss item: 0.4108556807041168
test loss item: 0.16373072564601898
test loss item: 0.2747277319431305
test loss item: 0.6341434121131897
test loss item: 0.13493356108665466
test loss item: 0.13692748546600342
test loss item: 0.19527779519557953
test loss item: 0.13732929527759552
test loss item: 0.08186838775873184
test loss item: 0.18444283306598663
test loss item: 0.3233729600906372
test loss item: 0.4541056752204895
test loss item: 0.16489370167255402
test loss item: 0.4756408631801605
test loss item: 0.2798643112182617
test loss item: 0.2100658416748047
test loss item: 0.1266535520553589
test loss item: 0.1515808403491974
test loss item: 0.17051570117473602
test loss item: 0.20839132368564606
test loss item: 0.1435442566871643
test loss item: 0.2223198562860489
test loss item: 0.23885899782180786
test loss item: 0.5814316272735596
test loss item: 0.07236309349536896
test loss item: 0.11373644322156906
test loss item: 0.4068982005119324
test loss item: 0.2992195188999176
test loss item: 0.354164719581604
test loss item: 0.5438718199729919
test loss item: 1.1063740253448486
test loss item: 0.3164277672767639
test loss item: 0.18996579945087433
test loss item: 0.22180652618408203
test loss item: 0.148703932762146
test loss item: 0.24475371837615967
test loss item: 0.16157270967960358
test loss item: 0.35335296392440796
test loss item: 0.24219080805778503
test loss item: 0.19917018711566925
test loss item: 0.15809312462806702
test loss item: 0.35031336545944214
test loss item: 0.5034124255180359
test loss item: 0.19854477047920227
test loss item: 0.10941971838474274
test loss item: 0.1786608248949051
test loss item: 0.1438896656036377
test loss item: 0.21528582274913788
test loss item: 0.6179353594779968
test loss item: 0.4144051671028137
test loss item: 0.16168251633644104
test loss item: 0.1697099655866623
test loss item: 0.15634848177433014
test loss item: 0.3173735737800598
test loss item: 0.18357865512371063
test loss item: 0.1474551260471344
test loss item: 0.1667575091123581
test loss item: 0.6276355385780334
test loss item: 0.24452213943004608
test loss item: 0.2055380642414093
test loss item: 0.17848144471645355
test loss item: 0.41724148392677307
test loss item: 0.2985793352127075
test loss item: 0.06970550864934921
test loss item: 0.6228283643722534
test loss item: 0.19530507922172546
test loss item: 0.23444807529449463
test loss item: 0.11137273162603378
test loss item: 0.1191781535744667
test loss item: 0.12890954315662384
test loss item: 1.2211236953735352
test loss item: 0.29481688141822815
test loss item: 0.14254598319530487
test loss item: 0.0764952301979065
test loss item: 0.7125206589698792
test loss item: 0.5795748829841614
test loss item: 0.8243833184242249
test loss item: 0.1564771980047226
test loss item: 0.1989021599292755
test loss item: 0.07030750066041946
test loss item: 0.06601977348327637
test loss item: 0.207725390791893
Epoch [92/100], Training Loss: 0.2740, Testing Loss: 0.2871
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 93/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.23466144502162933
1
train loss item: 0.5259323716163635
2
train loss item: 0.12259777635335922
3
train loss item: 0.2173265963792801
4
train loss item: 0.20474469661712646
5
train loss item: 0.1738259643316269
6
train loss item: 0.12444635480642319
7
train loss item: 0.3952120840549469
8
train loss item: 0.07041828334331512
9
train loss item: 0.13370691239833832
10
train loss item: 0.15118318796157837
11
train loss item: 0.1663273721933365
12
train loss item: 0.09503437578678131
13
train loss item: 0.21911559998989105
14
train loss item: 0.13490216434001923
15
train loss item: 0.2617032825946808
16
train loss item: 0.05242210999131203
17
train loss item: 0.14238683879375458
18
train loss item: 0.16671256721019745
19
train loss item: 0.132512629032135
20
train loss item: 0.11370918154716492
21
train loss item: 0.08133843541145325
22
train loss item: 0.3144875466823578
23
train loss item: 0.34472760558128357
24
train loss item: 0.25176841020584106
25
train loss item: 0.10331064462661743
26
train loss item: 0.11743952333927155
27
train loss item: 0.14377224445343018
28
train loss item: 0.051113616675138474
29
train loss item: 0.2582329213619232
30
train loss item: 1.389603853225708
31
train loss item: 0.2412101775407791
32
train loss item: 0.07698678225278854
33
train loss item: 0.15292136371135712
34
train loss item: 0.10049737244844437
35
train loss item: 1.8455661535263062
36
train loss item: 0.2348044514656067
37
train loss item: 0.2048720121383667
38
train loss item: 0.2048116773366928
39
train loss item: 0.16095536947250366
40
train loss item: 0.10206439346075058
41
train loss item: 0.13209857046604156
42
train loss item: 0.19435837864875793
43
train loss item: 0.10387926548719406
44
train loss item: 0.43073999881744385
45
train loss item: 0.08906777203083038
46
train loss item: 0.07861042022705078
47
train loss item: 0.15663036704063416
48
train loss item: 0.12066883593797684
49
train loss item: 0.09974189847707748
50
train loss item: 0.12053877860307693
51
train loss item: 0.37303799390792847
52
train loss item: 0.05939701572060585
53
train loss item: 0.0862443670630455
54
train loss item: 1.71477472782135
55
train loss item: 0.11959809064865112
56
train loss item: 0.13796943426132202
57
train loss item: 0.14505146443843842
58
train loss item: 0.09233006834983826
59
train loss item: 0.09203583747148514
60
train loss item: 0.32020342350006104
61
train loss item: 1.5028055906295776
62
train loss item: 0.11647484451532364
63
train loss item: 0.187265545129776
64
train loss item: 0.1010303795337677
65
train loss item: 0.2348279505968094
66
train loss item: 0.1957433968782425
67
train loss item: 0.1233287900686264
68
train loss item: 0.15301138162612915
69
train loss item: 0.16656136512756348
70
train loss item: 0.13968780636787415
71
train loss item: 0.09081349521875381
72
train loss item: 0.08616942167282104
73
train loss item: 0.15956565737724304
74
train loss item: 0.06261558085680008
75
train loss item: 0.08541976660490036
76
train loss item: 0.3571462631225586
77
train loss item: 0.71648108959198
78
train loss item: 0.05490465089678764
79
train loss item: 0.1567816287279129
80
train loss item: 0.08289190381765366
81
train loss item: 0.11000814288854599
82
train loss item: 0.1042749360203743
83
train loss item: 0.2241915613412857
84
train loss item: 0.18949736654758453
85
train loss item: 0.24112695455551147
86
train loss item: 3.463881015777588
87
train loss item: 0.09048447757959366
88
train loss item: 0.18816323578357697
epoch train loss: 0.2727134523264478
testing phase
test loss item: 0.1407623440027237
test loss item: 0.09329263865947723
test loss item: 0.382305383682251
test loss item: 0.1748650074005127
test loss item: 0.19168688356876373
test loss item: 0.10500705987215042
test loss item: 1.1628687381744385
test loss item: 0.4411896765232086
test loss item: 0.15358363091945648
test loss item: 0.2554473280906677
test loss item: 0.5788232088088989
test loss item: 0.1290985643863678
test loss item: 0.13531355559825897
test loss item: 0.20501278340816498
test loss item: 0.12891626358032227
test loss item: 0.07510368525981903
test loss item: 0.19124864041805267
test loss item: 0.29151657223701477
test loss item: 0.47379133105278015
test loss item: 0.17153915762901306
test loss item: 0.4240734279155731
test loss item: 0.2887207269668579
test loss item: 0.19778676331043243
test loss item: 0.1271103471517563
test loss item: 0.14221465587615967
test loss item: 0.17549896240234375
test loss item: 0.20624803006649017
test loss item: 0.13665415346622467
test loss item: 0.2148183286190033
test loss item: 0.2249104529619217
test loss item: 0.5552149415016174
test loss item: 0.06765148788690567
test loss item: 0.11220741271972656
test loss item: 0.37411126494407654
test loss item: 0.2685081958770752
test loss item: 0.3316023051738739
test loss item: 0.555837094783783
test loss item: 1.000280499458313
test loss item: 0.2907135784626007
test loss item: 0.19680655002593994
test loss item: 0.2303244024515152
test loss item: 0.15717813372612
test loss item: 0.22608357667922974
test loss item: 0.16248533129692078
test loss item: 0.3182327449321747
test loss item: 0.25440362095832825
test loss item: 0.187198668718338
test loss item: 0.16130737960338593
test loss item: 0.33270904421806335
test loss item: 0.47890162467956543
test loss item: 0.18494153022766113
test loss item: 0.10546588897705078
test loss item: 0.17476099729537964
test loss item: 0.13669556379318237
test loss item: 0.19809238612651825
test loss item: 0.5486397743225098
test loss item: 0.4030452370643616
test loss item: 0.16250066459178925
test loss item: 0.1665986329317093
test loss item: 0.15093743801116943
test loss item: 0.286221981048584
test loss item: 0.19342072308063507
test loss item: 0.15058958530426025
test loss item: 0.17207574844360352
test loss item: 0.583526074886322
test loss item: 0.24239413440227509
test loss item: 0.21310551464557648
test loss item: 0.18489709496498108
test loss item: 0.39116108417510986
test loss item: 0.3099341094493866
test loss item: 0.06452886015176773
test loss item: 0.6581935882568359
test loss item: 0.19564950466156006
test loss item: 0.24565790593624115
test loss item: 0.11100710183382034
test loss item: 0.11433819681406021
test loss item: 0.12851175665855408
test loss item: 1.108341097831726
test loss item: 0.281981498003006
test loss item: 0.14105892181396484
test loss item: 0.07636265456676483
test loss item: 0.685032308101654
test loss item: 0.5769341588020325
test loss item: 0.7464184165000916
test loss item: 0.15913385152816772
test loss item: 0.19450394809246063
test loss item: 0.06830814480781555
test loss item: 0.0615089125931263
test loss item: 0.22915561497211456
Epoch [93/100], Training Loss: 0.2727, Testing Loss: 0.2774
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 94/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.22965314984321594
1
train loss item: 0.5194597244262695
2
train loss item: 0.12069330364465714
3
train loss item: 0.21375872194766998
4
train loss item: 0.2041599154472351
5
train loss item: 0.17244084179401398
6
train loss item: 0.12179334461688995
7
train loss item: 0.38809114694595337
8
train loss item: 0.07002506405115128
9
train loss item: 0.13093578815460205
10
train loss item: 0.1486915647983551
11
train loss item: 0.16072459518909454
12
train loss item: 0.09475388377904892
13
train loss item: 0.2132195085287094
14
train loss item: 0.13116222620010376
15
train loss item: 0.26431140303611755
16
train loss item: 0.05205806717276573
17
train loss item: 0.13942673802375793
18
train loss item: 0.16384561359882355
19
train loss item: 0.12791752815246582
20
train loss item: 0.11370699107646942
21
train loss item: 0.08021792024374008
22
train loss item: 0.3156638741493225
23
train loss item: 0.3380947709083557
24
train loss item: 0.2503589689731598
25
train loss item: 0.10088817030191422
26
train loss item: 0.1161811426281929
27
train loss item: 0.1397925764322281
28
train loss item: 0.05016482621431351
29
train loss item: 0.25764089822769165
30
train loss item: 1.3780784606933594
31
train loss item: 0.2363939732313156
32
train loss item: 0.07414977997541428
33
train loss item: 0.14824849367141724
34
train loss item: 0.09926798939704895
35
train loss item: 1.8387491703033447
36
train loss item: 0.22949379682540894
37
train loss item: 0.20219962298870087
38
train loss item: 0.20556659996509552
39
train loss item: 0.15878942608833313
40
train loss item: 0.10006167739629745
41
train loss item: 0.12813809514045715
42
train loss item: 0.19123901426792145
43
train loss item: 0.10199690610170364
44
train loss item: 0.42671599984169006
45
train loss item: 0.08786111325025558
46
train loss item: 0.07706554979085922
47
train loss item: 0.15423141419887543
48
train loss item: 0.11974252760410309
49
train loss item: 0.09537087380886078
50
train loss item: 0.11720006912946701
51
train loss item: 0.37180230021476746
52
train loss item: 0.05899989977478981
53
train loss item: 0.08448921889066696
54
train loss item: 1.7095016241073608
55
train loss item: 0.11845140904188156
56
train loss item: 0.1358136236667633
57
train loss item: 0.14396199584007263
58
train loss item: 0.0939255803823471
59
train loss item: 0.09004030376672745
60
train loss item: 0.3167293965816498
61
train loss item: 1.4948794841766357
62
train loss item: 0.11443861573934555
63
train loss item: 0.18804161250591278
64
train loss item: 0.09590985625982285
65
train loss item: 0.23173648118972778
66
train loss item: 0.193479984998703
67
train loss item: 0.12159544974565506
68
train loss item: 0.15181860327720642
69
train loss item: 0.1633678674697876
70
train loss item: 0.13742223381996155
71
train loss item: 0.09141501039266586
72
train loss item: 0.08508448302745819
73
train loss item: 0.15663670003414154
74
train loss item: 0.06096721813082695
75
train loss item: 0.0836818739771843
76
train loss item: 0.3526366055011749
77
train loss item: 0.7176125049591064
78
train loss item: 0.05444621667265892
79
train loss item: 0.15286892652511597
80
train loss item: 0.07918892800807953
81
train loss item: 0.10838136821985245
82
train loss item: 0.10185244679450989
83
train loss item: 0.2214815765619278
84
train loss item: 0.18856550753116608
85
train loss item: 0.23475906252861023
86
train loss item: 3.4560258388519287
87
train loss item: 0.08888784795999527
88
train loss item: 0.1838269829750061
epoch train loss: 0.2700574995761507
testing phase
test loss item: 0.14380712807178497
test loss item: 0.09625512361526489
test loss item: 0.3923380374908447
test loss item: 0.17663350701332092
test loss item: 0.19489213824272156
test loss item: 0.1081986203789711
test loss item: 1.1805198192596436
test loss item: 0.43132373690605164
test loss item: 0.15876182913780212
test loss item: 0.2609541714191437
test loss item: 0.587067186832428
test loss item: 0.12843972444534302
test loss item: 0.14117565751075745
test loss item: 0.2111833393573761
test loss item: 0.13329370319843292
test loss item: 0.07858622074127197
test loss item: 0.19241733849048615
test loss item: 0.298279345035553
test loss item: 0.4648992121219635
test loss item: 0.18308104574680328
test loss item: 0.42850813269615173
test loss item: 0.2909693717956543
test loss item: 0.19885173439979553
test loss item: 0.13651257753372192
test loss item: 0.1436537504196167
test loss item: 0.17572666704654694
test loss item: 0.21492117643356323
test loss item: 0.14136910438537598
test loss item: 0.2235664427280426
test loss item: 0.22622574865818024
test loss item: 0.5684828758239746
test loss item: 0.06976376473903656
test loss item: 0.11982931196689606
test loss item: 0.38042008876800537
test loss item: 0.27514874935150146
test loss item: 0.33747491240501404
test loss item: 0.5563517212867737
test loss item: 1.0183064937591553
test loss item: 0.2978377938270569
test loss item: 0.2039290964603424
test loss item: 0.2311214953660965
test loss item: 0.15480569005012512
test loss item: 0.23190288245677948
test loss item: 0.16241993010044098
test loss item: 0.32457244396209717
test loss item: 0.2608548700809479
test loss item: 0.19315290451049805
test loss item: 0.1728968769311905
test loss item: 0.34131136536598206
test loss item: 0.4851031005382538
test loss item: 0.1934313327074051
test loss item: 0.1062215268611908
test loss item: 0.17726966738700867
test loss item: 0.13344760239124298
test loss item: 0.20224058628082275
test loss item: 0.5626687407493591
test loss item: 0.4043881893157959
test loss item: 0.16148996353149414
test loss item: 0.17177031934261322
test loss item: 0.15786410868167877
test loss item: 0.29463204741477966
test loss item: 0.19307862222194672
test loss item: 0.15812818706035614
test loss item: 0.1741326004266739
test loss item: 0.5922614932060242
test loss item: 0.24083136022090912
test loss item: 0.21430222690105438
test loss item: 0.18765239417552948
test loss item: 0.3983694612979889
test loss item: 0.3104337453842163
test loss item: 0.06864911317825317
test loss item: 0.662936270236969
test loss item: 0.21228082478046417
test loss item: 0.25901445746421814
test loss item: 0.11226647347211838
test loss item: 0.12076979130506516
test loss item: 0.13580824434757233
test loss item: 1.1229130029678345
test loss item: 0.29346808791160583
test loss item: 0.1461271345615387
test loss item: 0.07568379491567612
test loss item: 0.6901415586471558
test loss item: 0.581012487411499
test loss item: 0.7592225670814514
test loss item: 0.1653767228126526
test loss item: 0.1867661476135254
test loss item: 0.06796550750732422
test loss item: 0.06263317912817001
test loss item: 0.20239782333374023
Epoch [94/100], Training Loss: 0.2701, Testing Loss: 0.2819
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 95/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.22717903554439545
1
train loss item: 0.5117413997650146
2
train loss item: 0.12004609405994415
3
train loss item: 0.20917558670043945
4
train loss item: 0.2000773549079895
5
train loss item: 0.17114225029945374
6
train loss item: 0.1212264820933342
7
train loss item: 0.38256412744522095
8
train loss item: 0.06883170455694199
9
train loss item: 0.13067246973514557
10
train loss item: 0.14749597012996674
11
train loss item: 0.15880833566188812
12
train loss item: 0.09360566735267639
13
train loss item: 0.2123953253030777
14
train loss item: 0.12955079972743988
15
train loss item: 0.25330400466918945
16
train loss item: 0.051349859684705734
17
train loss item: 0.13792908191680908
18
train loss item: 0.1625831127166748
19
train loss item: 0.1262214034795761
20
train loss item: 0.11122424900531769
21
train loss item: 0.07928720861673355
22
train loss item: 0.3050594627857208
23
train loss item: 0.33365461230278015
24
train loss item: 0.24656300246715546
25
train loss item: 0.10013435781002045
26
train loss item: 0.11471812427043915
27
train loss item: 0.13808690011501312
28
train loss item: 0.049850236624479294
29
train loss item: 0.25117260217666626
30
train loss item: 1.3714442253112793
31
train loss item: 0.2348160445690155
32
train loss item: 0.07407256960868835
33
train loss item: 0.14770224690437317
34
train loss item: 0.09841372817754745
35
train loss item: 1.8340071439743042
36
train loss item: 0.2269245684146881
37
train loss item: 0.20156636834144592
38
train loss item: 0.20159702003002167
39
train loss item: 0.15693238377571106
40
train loss item: 0.0987846851348877
41
train loss item: 0.12664420902729034
42
train loss item: 0.19173981249332428
43
train loss item: 0.10134260356426239
44
train loss item: 0.4228678345680237
45
train loss item: 0.08758053183555603
46
train loss item: 0.07851158827543259
47
train loss item: 0.15332633256912231
48
train loss item: 0.11982549726963043
49
train loss item: 0.09483658522367477
50
train loss item: 0.11598189175128937
51
train loss item: 0.3680292069911957
52
train loss item: 0.05821284279227257
53
train loss item: 0.08429057896137238
54
train loss item: 1.7041049003601074
55
train loss item: 0.117814801633358
56
train loss item: 0.13494184613227844
57
train loss item: 0.14434371888637543
58
train loss item: 0.09232538938522339
59
train loss item: 0.09011641144752502
60
train loss item: 0.3112962245941162
61
train loss item: 1.488994836807251
62
train loss item: 0.11253633350133896
63
train loss item: 0.18686272203922272
64
train loss item: 0.09599454700946808
65
train loss item: 0.22811923921108246
66
train loss item: 0.19054576754570007
67
train loss item: 0.12067312002182007
68
train loss item: 0.15031678974628448
69
train loss item: 0.16215896606445312
70
train loss item: 0.13602103292942047
71
train loss item: 0.09089598059654236
72
train loss item: 0.08502370119094849
73
train loss item: 0.15513959527015686
74
train loss item: 0.06055502966046333
75
train loss item: 0.08407428115606308
76
train loss item: 0.3483937680721283
77
train loss item: 0.7121176719665527
78
train loss item: 0.05357520282268524
79
train loss item: 0.15063944458961487
80
train loss item: 0.07886417955160141
81
train loss item: 0.10715097934007645
82
train loss item: 0.10190826654434204
83
train loss item: 0.21683412790298462
84
train loss item: 0.18852204084396362
85
train loss item: 0.23226328194141388
86
train loss item: 3.4510951042175293
87
train loss item: 0.08968519419431686
88
train loss item: 0.1808173507452011
epoch train loss: 0.26797554122932843
testing phase
test loss item: 0.14156003296375275
test loss item: 0.09636000543832779
test loss item: 0.41881459951400757
test loss item: 0.1765204221010208
test loss item: 0.19926269352436066
test loss item: 0.10500973463058472
test loss item: 1.1651540994644165
test loss item: 0.4194624722003937
test loss item: 0.1635747104883194
test loss item: 0.2728106379508972
test loss item: 0.6252332925796509
test loss item: 0.12709581851959229
test loss item: 0.14227119088172913
test loss item: 0.1974058449268341
test loss item: 0.1360696703195572
test loss item: 0.07906987518072128
test loss item: 0.18814703822135925
test loss item: 0.32050347328186035
test loss item: 0.4566750228404999
test loss item: 0.17805799841880798
test loss item: 0.4670846164226532
test loss item: 0.28627580404281616
test loss item: 0.20496919751167297
test loss item: 0.13627828657627106
test loss item: 0.14822490513324738
test loss item: 0.1718406230211258
test loss item: 0.21639485657215118
test loss item: 0.14332105219364166
test loss item: 0.22565458714962006
test loss item: 0.2340753823518753
test loss item: 0.5901496410369873
test loss item: 0.06986147910356522
test loss item: 0.12002734839916229
test loss item: 0.4022168517112732
test loss item: 0.29610300064086914
test loss item: 0.3568421006202698
test loss item: 0.551474392414093
test loss item: 1.0949054956436157
test loss item: 0.3158755600452423
test loss item: 0.19998487830162048
test loss item: 0.2264372855424881
test loss item: 0.1479800045490265
test loss item: 0.24487504363059998
test loss item: 0.16019472479820251
test loss item: 0.3509494662284851
test loss item: 0.25553587079048157
test loss item: 0.20040865242481232
test loss item: 0.16724959015846252
test loss item: 0.35550159215927124
test loss item: 0.50457763671875
test loss item: 0.20546947419643402
test loss item: 0.10673170536756516
test loss item: 0.1798211932182312
test loss item: 0.13417993485927582
test loss item: 0.21458108723163605
test loss item: 0.6107234954833984
test loss item: 0.41512349247932434
test loss item: 0.15601330995559692
test loss item: 0.17447662353515625
test loss item: 0.16173112392425537
test loss item: 0.313860148191452
test loss item: 0.18888559937477112
test loss item: 0.1546860635280609
test loss item: 0.17036862671375275
test loss item: 0.624747633934021
test loss item: 0.2405938357114792
test loss item: 0.21130812168121338
test loss item: 0.18343354761600494
test loss item: 0.4153822362422943
test loss item: 0.30784252285957336
test loss item: 0.06856498122215271
test loss item: 0.6469773054122925
test loss item: 0.20595984160900116
test loss item: 0.25147587060928345
test loss item: 0.11066779494285583
test loss item: 0.12056483328342438
test loss item: 0.13494746387004852
test loss item: 1.2077624797821045
test loss item: 0.29700055718421936
test loss item: 0.14539270102977753
test loss item: 0.0747363343834877
test loss item: 0.7148071527481079
test loss item: 0.5860688090324402
test loss item: 0.8181107044219971
test loss item: 0.16137047111988068
test loss item: 0.19005364179611206
test loss item: 0.06668343394994736
test loss item: 0.06222880259156227
test loss item: 0.19410084187984467
Epoch [95/100], Training Loss: 0.2680, Testing Loss: 0.2886
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 96/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.22487904131412506
1
train loss item: 0.5012373924255371
2
train loss item: 0.11788195371627808
3
train loss item: 0.2079184651374817
4
train loss item: 0.1989593803882599
5
train loss item: 0.168645441532135
6
train loss item: 0.12047768384218216
7
train loss item: 0.3793275058269501
8
train loss item: 0.06717963516712189
9
train loss item: 0.12840931117534637
10
train loss item: 0.14490489661693573
11
train loss item: 0.15731193125247955
12
train loss item: 0.09216336905956268
13
train loss item: 0.2093939334154129
14
train loss item: 0.12908516824245453
15
train loss item: 0.25349482893943787
16
train loss item: 0.05074034631252289
17
train loss item: 0.13674236834049225
18
train loss item: 0.16009272634983063
19
train loss item: 0.12505695223808289
20
train loss item: 0.1097111627459526
21
train loss item: 0.0779203325510025
22
train loss item: 0.3061443865299225
23
train loss item: 0.32830560207366943
24
train loss item: 0.24502046406269073
25
train loss item: 0.09892169386148453
26
train loss item: 0.113264299929142
27
train loss item: 0.13732224702835083
28
train loss item: 0.0493156835436821
29
train loss item: 0.25406867265701294
30
train loss item: 1.3651769161224365
31
train loss item: 0.22968211770057678
32
train loss item: 0.07396993786096573
33
train loss item: 0.14603914320468903
34
train loss item: 0.09746028482913971
35
train loss item: 1.8303780555725098
36
train loss item: 0.22882643342018127
37
train loss item: 0.20048801600933075
38
train loss item: 0.20074665546417236
39
train loss item: 0.15437506139278412
40
train loss item: 0.0981566309928894
41
train loss item: 0.1258944422006607
42
train loss item: 0.18955540657043457
43
train loss item: 0.10054177790880203
44
train loss item: 0.4192245602607727
45
train loss item: 0.08664777129888535
46
train loss item: 0.07523707300424576
47
train loss item: 0.15363624691963196
48
train loss item: 0.11793216317892075
49
train loss item: 0.0941854864358902
50
train loss item: 0.11392378062009811
51
train loss item: 0.3629174828529358
52
train loss item: 0.05763084441423416
53
train loss item: 0.08310311287641525
54
train loss item: 1.6996184587478638
55
train loss item: 0.11649677902460098
56
train loss item: 0.1319492757320404
57
train loss item: 0.1406080424785614
58
train loss item: 0.09009011834859848
59
train loss item: 0.08924409747123718
60
train loss item: 0.30552464723587036
61
train loss item: 1.4839136600494385
62
train loss item: 0.11143697798252106
63
train loss item: 0.17990605533123016
64
train loss item: 0.0964052677154541
65
train loss item: 0.22666171193122864
66
train loss item: 0.1910569667816162
67
train loss item: 0.11953854560852051
68
train loss item: 0.14912398159503937
69
train loss item: 0.1607145369052887
70
train loss item: 0.13475331664085388
71
train loss item: 0.08901559561491013
72
train loss item: 0.0833103135228157
73
train loss item: 0.1534319519996643
74
train loss item: 0.059583935886621475
75
train loss item: 0.08330068737268448
76
train loss item: 0.3409116566181183
77
train loss item: 0.7044768333435059
78
train loss item: 0.0529194101691246
79
train loss item: 0.1489461362361908
80
train loss item: 0.08040016889572144
81
train loss item: 0.10573715716600418
82
train loss item: 0.10062360018491745
83
train loss item: 0.21599546074867249
84
train loss item: 0.18684326112270355
85
train loss item: 0.2293875366449356
86
train loss item: 3.445554733276367
87
train loss item: 0.08590342849493027
88
train loss item: 0.17958015203475952
epoch train loss: 0.2659841655764017
testing phase
test loss item: 0.13949845731258392
test loss item: 0.09211847931146622
test loss item: 0.4085060656070709
test loss item: 0.17526517808437347
test loss item: 0.19366951286792755
test loss item: 0.10094799101352692
test loss item: 1.1825984716415405
test loss item: 0.4478156268596649
test loss item: 0.15755236148834229
test loss item: 0.2645927369594574
test loss item: 0.6239755749702454
test loss item: 0.12718524038791656
test loss item: 0.1361730992794037
test loss item: 0.19198006391525269
test loss item: 0.12987421452999115
test loss item: 0.07538030296564102
test loss item: 0.18835827708244324
test loss item: 0.30976584553718567
test loss item: 0.4774390757083893
test loss item: 0.17155323922634125
test loss item: 0.45596516132354736
test loss item: 0.28735119104385376
test loss item: 0.2035706788301468
test loss item: 0.1324964314699173
test loss item: 0.14550593495368958
test loss item: 0.17387358844280243
test loss item: 0.2104571908712387
test loss item: 0.13787733018398285
test loss item: 0.21548505127429962
test loss item: 0.2294664829969406
test loss item: 0.590061366558075
test loss item: 0.06582074612379074
test loss item: 0.11606001853942871
test loss item: 0.39308658242225647
test loss item: 0.2869788706302643
test loss item: 0.35650259256362915
test loss item: 0.56180739402771
test loss item: 1.0902479887008667
test loss item: 0.3073122799396515
test loss item: 0.19715741276741028
test loss item: 0.22781963646411896
test loss item: 0.1508622020483017
test loss item: 0.2356823980808258
test loss item: 0.1595958173274994
test loss item: 0.3403492271900177
test loss item: 0.25757572054862976
test loss item: 0.19568070769309998
test loss item: 0.15915019810199738
test loss item: 0.34773895144462585
test loss item: 0.5045994520187378
test loss item: 0.1917562335729599
test loss item: 0.10470013320446014
test loss item: 0.17470233142375946
test loss item: 0.13307282328605652
test loss item: 0.20557895302772522
test loss item: 0.5973984599113464
test loss item: 0.42327219247817993
test loss item: 0.15653051435947418
test loss item: 0.17102107405662537
test loss item: 0.15202702581882477
test loss item: 0.2996106445789337
test loss item: 0.19267630577087402
test loss item: 0.15190976858139038
test loss item: 0.16898910701274872
test loss item: 0.6236997246742249
test loss item: 0.24131612479686737
test loss item: 0.21161070466041565
test loss item: 0.18252462148666382
test loss item: 0.4086853861808777
test loss item: 0.31391799449920654
test loss item: 0.06286608427762985
test loss item: 0.6656537055969238
test loss item: 0.19388523697853088
test loss item: 0.2469472587108612
test loss item: 0.10828670859336853
test loss item: 0.11597486585378647
test loss item: 0.1318654865026474
test loss item: 1.210294485092163
test loss item: 0.2902207374572754
test loss item: 0.14122450351715088
test loss item: 0.074166439473629
test loss item: 0.7264983057975769
test loss item: 0.5924348831176758
test loss item: 0.8180762529373169
test loss item: 0.15695124864578247
test loss item: 0.19658128917217255
test loss item: 0.06517046689987183
test loss item: 0.05998340994119644
test loss item: 0.221433624625206
Epoch [96/100], Training Loss: 0.2660, Testing Loss: 0.2867
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 97/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.22301363945007324
1
train loss item: 0.4954352378845215
2
train loss item: 0.11638584733009338
3
train loss item: 0.20523332059383392
4
train loss item: 0.19622385501861572
5
train loss item: 0.16671961545944214
6
train loss item: 0.1192876547574997
7
train loss item: 0.3746507465839386
8
train loss item: 0.06708724051713943
9
train loss item: 0.12684603035449982
10
train loss item: 0.14376823604106903
11
train loss item: 0.156157448887825
12
train loss item: 0.09181922674179077
13
train loss item: 0.20729127526283264
14
train loss item: 0.12827225029468536
15
train loss item: 0.2484714835882187
16
train loss item: 0.05082770064473152
17
train loss item: 0.13554175198078156
18
train loss item: 0.15968374907970428
19
train loss item: 0.12453816086053848
20
train loss item: 0.10952512919902802
21
train loss item: 0.07750602811574936
22
train loss item: 0.29958415031433105
23
train loss item: 0.32257261872291565
24
train loss item: 0.24219278991222382
25
train loss item: 0.09818584471940994
26
train loss item: 0.1121894046664238
27
train loss item: 0.1354999840259552
28
train loss item: 0.04869676008820534
29
train loss item: 0.24668237566947937
30
train loss item: 1.3578312397003174
31
train loss item: 0.22930671274662018
32
train loss item: 0.07285668700933456
33
train loss item: 0.14400912821292877
34
train loss item: 0.0968947634100914
35
train loss item: 1.8265860080718994
36
train loss item: 0.22357922792434692
37
train loss item: 0.19972646236419678
38
train loss item: 0.19674989581108093
39
train loss item: 0.15266942977905273
40
train loss item: 0.098124660551548
41
train loss item: 0.1259792596101761
42
train loss item: 0.18818266689777374
43
train loss item: 0.09984327852725983
44
train loss item: 0.41705092787742615
45
train loss item: 0.08583039790391922
46
train loss item: 0.07411634176969528
47
train loss item: 0.150943785905838
48
train loss item: 0.11634636670351028
49
train loss item: 0.09365259855985641
50
train loss item: 0.11312969774007797
51
train loss item: 0.35899555683135986
52
train loss item: 0.057494599372148514
53
train loss item: 0.08273261785507202
54
train loss item: 1.6953212022781372
55
train loss item: 0.11616840958595276
56
train loss item: 0.1309385746717453
57
train loss item: 0.13940319418907166
58
train loss item: 0.09143621474504471
59
train loss item: 0.08804140239953995
60
train loss item: 0.30140891671180725
61
train loss item: 1.4772433042526245
62
train loss item: 0.11135774105787277
63
train loss item: 0.1777048110961914
64
train loss item: 0.09364867210388184
65
train loss item: 0.2234988808631897
66
train loss item: 0.18811416625976562
67
train loss item: 0.11886046826839447
68
train loss item: 0.14819307625293732
69
train loss item: 0.15890218317508698
70
train loss item: 0.13326913118362427
71
train loss item: 0.08870693296194077
72
train loss item: 0.08112895488739014
73
train loss item: 0.15196795761585236
74
train loss item: 0.05873040109872818
75
train loss item: 0.08214285224676132
76
train loss item: 0.33543476462364197
77
train loss item: 0.6998878121376038
78
train loss item: 0.05300787091255188
79
train loss item: 0.148929625749588
80
train loss item: 0.07881186902523041
81
train loss item: 0.1052415668964386
82
train loss item: 0.09941462427377701
83
train loss item: 0.21403534710407257
84
train loss item: 0.1844027191400528
85
train loss item: 0.22650711238384247
86
train loss item: 3.4390830993652344
87
train loss item: 0.087640181183815
88
train loss item: 0.17812497913837433
epoch train loss: 0.2640363021094478
testing phase
test loss item: 0.13987405598163605
test loss item: 0.09246524423360825
test loss item: 0.3867745101451874
test loss item: 0.17430442571640015
test loss item: 0.18944142758846283
test loss item: 0.10452556610107422
test loss item: 1.179944396018982
test loss item: 0.4426465332508087
test loss item: 0.15330399572849274
test loss item: 0.2529461681842804
test loss item: 0.5947864055633545
test loss item: 0.13191723823547363
test loss item: 0.13362626731395721
test loss item: 0.20367759466171265
test loss item: 0.12729088962078094
test loss item: 0.07557906955480576
test loss item: 0.18635033071041107
test loss item: 0.2866724133491516
test loss item: 0.4874817430973053
test loss item: 0.17278634011745453
test loss item: 0.41299498081207275
test loss item: 0.28329557180404663
test loss item: 0.1958344727754593
test loss item: 0.1321483999490738
test loss item: 0.1390223503112793
test loss item: 0.2136671096086502
test loss item: 0.20700839161872864
test loss item: 0.13643570244312286
test loss item: 0.20982591807842255
test loss item: 0.22060053050518036
test loss item: 0.5725717544555664
test loss item: 0.06598038226366043
test loss item: 0.11547069996595383
test loss item: 0.37244752049446106
test loss item: 0.26791998744010925
test loss item: 0.33780744671821594
test loss item: 0.5556690692901611
test loss item: 1.035920262336731
test loss item: 0.28963208198547363
test loss item: 0.196583554148674
test loss item: 0.227882981300354
test loss item: 0.177983358502388
test loss item: 0.2214907556772232
test loss item: 0.15879419445991516
test loss item: 0.3120995759963989
test loss item: 0.2557705342769623
test loss item: 0.1846703439950943
test loss item: 0.16092844307422638
test loss item: 0.33198413252830505
test loss item: 0.5084956288337708
test loss item: 0.1804492473602295
test loss item: 0.10508137941360474
test loss item: 0.16951972246170044
test loss item: 0.13274426758289337
test loss item: 0.1931523084640503
test loss item: 0.5602859258651733
test loss item: 0.4093582332134247
test loss item: 0.1571163833141327
test loss item: 0.1657438576221466
test loss item: 0.14668866991996765
test loss item: 0.28211721777915955
test loss item: 0.18638749420642853
test loss item: 0.1544213443994522
test loss item: 0.17121468484401703
test loss item: 0.5940987467765808
test loss item: 0.2392602115869522
test loss item: 0.20939426124095917
test loss item: 0.18396830558776855
test loss item: 0.39525657892227173
test loss item: 0.3114762306213379
test loss item: 0.06418414413928986
test loss item: 0.6635227203369141
test loss item: 0.19344940781593323
test loss item: 0.24867698550224304
test loss item: 0.1085493341088295
test loss item: 0.11466334015130997
test loss item: 0.13276934623718262
test loss item: 1.1475776433944702
test loss item: 0.28486496210098267
test loss item: 0.14065881073474884
test loss item: 0.07445964217185974
test loss item: 0.7114050388336182
test loss item: 0.5809606313705444
test loss item: 0.7733451724052429
test loss item: 0.15894827246665955
test loss item: 0.22576594352722168
test loss item: 0.06602724641561508
test loss item: 0.06056928634643555
test loss item: 0.3210398852825165
Epoch [97/100], Training Loss: 0.2640, Testing Loss: 0.2813
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 98/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.21892686188220978
1
train loss item: 0.4878288805484772
2
train loss item: 0.11563381552696228
3
train loss item: 0.20172306895256042
4
train loss item: 0.19459126889705658
5
train loss item: 0.1656307429075241
6
train loss item: 0.11835184693336487
7
train loss item: 0.3691371977329254
8
train loss item: 0.06628178060054779
9
train loss item: 0.12619665265083313
10
train loss item: 0.14182035624980927
11
train loss item: 0.15321451425552368
12
train loss item: 0.09054578840732574
13
train loss item: 0.20327721536159515
14
train loss item: 0.12546074390411377
15
train loss item: 0.2474564015865326
16
train loss item: 0.05021657794713974
17
train loss item: 0.13427117466926575
18
train loss item: 0.1573784351348877
19
train loss item: 0.1233988106250763
20
train loss item: 0.10834348946809769
21
train loss item: 0.07732193917036057
22
train loss item: 0.29403364658355713
23
train loss item: 0.3183932304382324
24
train loss item: 0.23951828479766846
25
train loss item: 0.09681098163127899
26
train loss item: 0.11116097867488861
27
train loss item: 0.13291750848293304
28
train loss item: 0.0483073890209198
29
train loss item: 0.24254490435123444
30
train loss item: 1.3503140211105347
31
train loss item: 0.2250349521636963
32
train loss item: 0.0711727887392044
33
train loss item: 0.14216823875904083
34
train loss item: 0.09606390446424484
35
train loss item: 1.8208657503128052
36
train loss item: 0.21859526634216309
37
train loss item: 0.19776690006256104
38
train loss item: 0.1944640725851059
39
train loss item: 0.1507868766784668
40
train loss item: 0.09661641716957092
41
train loss item: 0.12301886826753616
42
train loss item: 0.18628162145614624
43
train loss item: 0.09887829422950745
44
train loss item: 0.4104943871498108
45
train loss item: 0.08607873320579529
46
train loss item: 0.07412349432706833
47
train loss item: 0.1495591402053833
48
train loss item: 0.11556262522935867
49
train loss item: 0.0925530344247818
50
train loss item: 0.11291630566120148
51
train loss item: 0.3574340343475342
52
train loss item: 0.056883905082941055
53
train loss item: 0.08122259378433228
54
train loss item: 1.690595030784607
55
train loss item: 0.11481557041406631
56
train loss item: 0.12910610437393188
57
train loss item: 0.13820171356201172
58
train loss item: 0.08974394202232361
59
train loss item: 0.08736485987901688
60
train loss item: 0.29719918966293335
61
train loss item: 1.4708155393600464
62
train loss item: 0.10982105135917664
63
train loss item: 0.1763003170490265
64
train loss item: 0.09300132840871811
65
train loss item: 0.221821591258049
66
train loss item: 0.18510933220386505
67
train loss item: 0.1178571954369545
68
train loss item: 0.1468459665775299
69
train loss item: 0.157536119222641
70
train loss item: 0.1319182813167572
71
train loss item: 0.08888863027095795
72
train loss item: 0.08081194013357162
73
train loss item: 0.150394469499588
74
train loss item: 0.05817161500453949
75
train loss item: 0.08124100416898727
76
train loss item: 0.3327174186706543
77
train loss item: 0.6957474946975708
78
train loss item: 0.052028484642505646
79
train loss item: 0.14590157568454742
80
train loss item: 0.07665586471557617
81
train loss item: 0.10429392009973526
82
train loss item: 0.09883572161197662
83
train loss item: 0.21136833727359772
84
train loss item: 0.18349575996398926
85
train loss item: 0.22342157363891602
86
train loss item: 3.433063268661499
87
train loss item: 0.0853194072842598
88
train loss item: 0.1766633838415146
epoch train loss: 0.2618721765832285
testing phase
test loss item: 0.13858474791049957
test loss item: 0.09580802172422409
test loss item: 0.3988974392414093
test loss item: 0.1692337840795517
test loss item: 0.19355274736881256
test loss item: 0.10452095419168472
test loss item: 1.128919005393982
test loss item: 0.4078672528266907
test loss item: 0.158767968416214
test loss item: 0.2607228457927704
test loss item: 0.5956274271011353
test loss item: 0.12640132009983063
test loss item: 0.13751867413520813
test loss item: 0.19980791211128235
test loss item: 0.13113407790660858
test loss item: 0.07821720093488693
test loss item: 0.18182620406150818
test loss item: 0.29621613025665283
test loss item: 0.4528553783893585
test loss item: 0.17252221703529358
test loss item: 0.42439085245132446
test loss item: 0.27507010102272034
test loss item: 0.19489265978336334
test loss item: 0.1292956918478012
test loss item: 0.1407240629196167
test loss item: 0.18260817229747772
test loss item: 0.2082301527261734
test loss item: 0.13838838040828705
test loss item: 0.21531203389167786
test loss item: 0.22456367313861847
test loss item: 0.5683544874191284
test loss item: 0.06743592023849487
test loss item: 0.11380809545516968
test loss item: 0.3799102008342743
test loss item: 0.27616339921951294
test loss item: 0.331198126077652
test loss item: 0.5337041020393372
test loss item: 1.0468227863311768
test loss item: 0.2952105700969696
test loss item: 0.19242331385612488
test loss item: 0.22270771861076355
test loss item: 0.1616833508014679
test loss item: 0.23114649951457977
test loss item: 0.1541539877653122
test loss item: 0.32111671566963196
test loss item: 0.24741515517234802
test loss item: 0.1876312643289566
test loss item: 0.1617124378681183
test loss item: 0.33836159110069275
test loss item: 0.4935668408870697
test loss item: 0.19035857915878296
test loss item: 0.10681579262018204
test loss item: 0.17168746888637543
test loss item: 0.12690556049346924
test loss item: 0.20040106773376465
test loss item: 0.574861466884613
test loss item: 0.3949677646160126
test loss item: 0.1542321741580963
test loss item: 0.16456757485866547
test loss item: 0.1531420201063156
test loss item: 0.2956790328025818
test loss item: 0.1785636842250824
test loss item: 0.1495193988084793
test loss item: 0.16883879899978638
test loss item: 0.5925045013427734
test loss item: 0.23162221908569336
test loss item: 0.2037488967180252
test loss item: 0.18152637779712677
test loss item: 0.4028688669204712
test loss item: 0.29725584387779236
test loss item: 0.06774210184812546
test loss item: 0.6263110041618347
test loss item: 0.19354398548603058
test loss item: 0.24207967519760132
test loss item: 0.10897541791200638
test loss item: 0.11689472943544388
test loss item: 0.13060998916625977
test loss item: 1.1557050943374634
test loss item: 0.28463447093963623
test loss item: 0.14068353176116943
test loss item: 0.07372644543647766
test loss item: 0.6887207627296448
test loss item: 0.56242436170578
test loss item: 0.7795006632804871
test loss item: 0.1558430939912796
test loss item: 0.20196980237960815
test loss item: 0.0665338784456253
test loss item: 0.061960961669683456
test loss item: 0.25576967000961304
Epoch [98/100], Training Loss: 0.2619, Testing Loss: 0.2780
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Epoch 99/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.21716155111789703
1
train loss item: 0.47903114557266235
2
train loss item: 0.11412007361650467
3
train loss item: 0.1993587464094162
4
train loss item: 0.19165951013565063
5
train loss item: 0.1647839993238449
6
train loss item: 0.11755088716745377
7
train loss item: 0.3646189570426941
8
train loss item: 0.06524136662483215
9
train loss item: 0.125322163105011
10
train loss item: 0.1406647264957428
11
train loss item: 0.15269401669502258
12
train loss item: 0.08921749889850616
13
train loss item: 0.2019260674715042
14
train loss item: 0.12478415668010712
15
train loss item: 0.24343985319137573
16
train loss item: 0.04965567588806152
17
train loss item: 0.13318170607089996
18
train loss item: 0.15538345277309418
19
train loss item: 0.12200102210044861
20
train loss item: 0.10722370445728302
21
train loss item: 0.07655832171440125
22
train loss item: 0.29076725244522095
23
train loss item: 0.31425854563713074
24
train loss item: 0.23765215277671814
25
train loss item: 0.0956670269370079
26
train loss item: 0.10977815836668015
27
train loss item: 0.1316324770450592
28
train loss item: 0.048102736473083496
29
train loss item: 0.2426639050245285
30
train loss item: 1.3446626663208008
31
train loss item: 0.2224893420934677
32
train loss item: 0.07098360359668732
33
train loss item: 0.14126893877983093
34
train loss item: 0.09527021646499634
35
train loss item: 1.817030429840088
36
train loss item: 0.21762143075466156
37
train loss item: 0.19676490128040314
38
train loss item: 0.1931970864534378
39
train loss item: 0.1496182531118393
40
train loss item: 0.09526033699512482
41
train loss item: 0.12178517878055573
42
train loss item: 0.18534690141677856
43
train loss item: 0.09818842262029648
44
train loss item: 0.4100079834461212
45
train loss item: 0.08533300459384918
46
train loss item: 0.07318903505802155
47
train loss item: 0.14857117831707
48
train loss item: 0.11473267525434494
49
train loss item: 0.09160446375608444
50
train loss item: 0.11162461340427399
51
train loss item: 0.3535274267196655
52
train loss item: 0.05640525743365288
53
train loss item: 0.08135181665420532
54
train loss item: 1.6868805885314941
55
train loss item: 0.11381356418132782
56
train loss item: 0.1279233992099762
57
train loss item: 0.1372813880443573
58
train loss item: 0.08753535151481628
59
train loss item: 0.08720314502716064
60
train loss item: 0.29249247908592224
61
train loss item: 1.465559482574463
62
train loss item: 0.10900919139385223
63
train loss item: 0.17233161628246307
64
train loss item: 0.09373173117637634
65
train loss item: 0.21939656138420105
66
train loss item: 0.182531476020813
67
train loss item: 0.11683496087789536
68
train loss item: 0.14563114941120148
69
train loss item: 0.1564442217350006
70
train loss item: 0.1308213472366333
71
train loss item: 0.08794983476400375
72
train loss item: 0.08012308925390244
73
train loss item: 0.1492449939250946
74
train loss item: 0.05765312537550926
75
train loss item: 0.08110345155000687
76
train loss item: 0.32597073912620544
77
train loss item: 0.6893314719200134
78
train loss item: 0.051404062658548355
79
train loss item: 0.14517341554164886
80
train loss item: 0.07619041949510574
81
train loss item: 0.1031065583229065
82
train loss item: 0.09774519503116608
83
train loss item: 0.21012331545352936
84
train loss item: 0.18124651908874512
85
train loss item: 0.22161372005939484
86
train loss item: 3.428319215774536
87
train loss item: 0.08593910932540894
88
train loss item: 0.17493480443954468
epoch train loss: 0.2601632664628913
testing phase
test loss item: 0.13847757875919342
test loss item: 0.09399568289518356
test loss item: 0.4103275537490845
test loss item: 0.16869454085826874
test loss item: 0.19677646458148956
test loss item: 0.10133278369903564
test loss item: 1.131357192993164
test loss item: 0.41125890612602234
test loss item: 0.1601022481918335
test loss item: 0.2662769556045532
test loss item: 0.6058177947998047
test loss item: 0.12329099327325821
test loss item: 0.13714481890201569
test loss item: 0.19364033639431
test loss item: 0.13248513638973236
test loss item: 0.07549389451742172
test loss item: 0.18564748764038086
test loss item: 0.31006139516830444
test loss item: 0.4459734857082367
test loss item: 0.17075054347515106
test loss item: 0.45168694853782654
test loss item: 0.27868127822875977
test loss item: 0.20096638798713684
test loss item: 0.12785759568214417
test loss item: 0.14454908668994904
test loss item: 0.16759109497070312
test loss item: 0.20966967940330505
test loss item: 0.13878023624420166
test loss item: 0.2201870232820511
test loss item: 0.23064634203910828
test loss item: 0.5759299397468567
test loss item: 0.06543201208114624
test loss item: 0.11252949386835098
test loss item: 0.39084485173225403
test loss item: 0.28653380274772644
test loss item: 0.3390839695930481
test loss item: 0.5354477763175964
test loss item: 1.0681788921356201
test loss item: 0.3052290380001068
test loss item: 0.19312554597854614
test loss item: 0.22390161454677582
test loss item: 0.14582757651805878
test loss item: 0.23959703743457794
test loss item: 0.156439408659935
test loss item: 0.3380686640739441
test loss item: 0.24888156354427338
test loss item: 0.1936822235584259
test loss item: 0.1596195250749588
test loss item: 0.34574270248413086
test loss item: 0.4914041757583618
test loss item: 0.1979108303785324
test loss item: 0.10524464398622513
test loss item: 0.17725872993469238
test loss item: 0.12656234204769135
test loss item: 0.2096923142671585
test loss item: 0.5931992530822754
test loss item: 0.4006955921649933
test loss item: 0.15312445163726807
test loss item: 0.16740436851978302
test loss item: 0.1556272804737091
test loss item: 0.30440714955329895
test loss item: 0.18407875299453735
test loss item: 0.14677320420742035
test loss item: 0.16731740534305573
test loss item: 0.6099122166633606
test loss item: 0.23183861374855042
test loss item: 0.20740845799446106
test loss item: 0.18049617111682892
test loss item: 0.4096078872680664
test loss item: 0.2961866855621338
test loss item: 0.06378475576639175
test loss item: 0.6281270980834961
test loss item: 0.19314800202846527
test loss item: 0.24082471430301666
test loss item: 0.10850204527378082
test loss item: 0.11616726964712143
test loss item: 0.12863366305828094
test loss item: 1.1835578680038452
test loss item: 0.28452539443969727
test loss item: 0.13980761170387268
test loss item: 0.07192455232143402
test loss item: 0.6958555579185486
test loss item: 0.5669625401496887
test loss item: 0.799827516078949
test loss item: 0.15482112765312195
test loss item: 0.18899813294410706
test loss item: 0.06410237401723862
test loss item: 0.05997372418642044
test loss item: 0.20032285153865814
Epoch [99/100], Training Loss: 0.2602, Testing Loss: 0.2804
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 100/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2143816202878952
1
train loss item: 0.47110453248023987
2
train loss item: 0.11306455731391907
3
train loss item: 0.196996808052063
4
train loss item: 0.18814904987812042
5
train loss item: 0.16193637251853943
6
train loss item: 0.11683771014213562
7
train loss item: 0.3602910339832306
8
train loss item: 0.06467559933662415
9
train loss item: 0.12345673143863678
10
train loss item: 0.13878020644187927
11
train loss item: 0.15117870271205902
12
train loss item: 0.0882628932595253
13
train loss item: 0.1994033306837082
14
train loss item: 0.12361397594213486
15
train loss item: 0.23991277813911438
16
train loss item: 0.04924854263663292
17
train loss item: 0.13175621628761292
18
train loss item: 0.15435241162776947
19
train loss item: 0.12093151360750198
20
train loss item: 0.10675042867660522
21
train loss item: 0.07542061805725098
22
train loss item: 0.2869061529636383
23
train loss item: 0.3074171841144562
24
train loss item: 0.23561489582061768
25
train loss item: 0.09484609216451645
26
train loss item: 0.10851912945508957
27
train loss item: 0.1310984492301941
28
train loss item: 0.047385942190885544
29
train loss item: 0.23843622207641602
30
train loss item: 1.3385374546051025
31
train loss item: 0.21881259977817535
32
train loss item: 0.06999674439430237
33
train loss item: 0.13845883309841156
34
train loss item: 0.09438693523406982
35
train loss item: 1.8131860494613647
36
train loss item: 0.21608832478523254
37
train loss item: 0.1953859031200409
38
train loss item: 0.190939798951149
39
train loss item: 0.1474476009607315
40
train loss item: 0.09500889480113983
41
train loss item: 0.1210496574640274
42
train loss item: 0.18415577709674835
43
train loss item: 0.09730877727270126
44
train loss item: 0.4051973819732666
45
train loss item: 0.08410726487636566
46
train loss item: 0.07188300788402557
47
train loss item: 0.1468169093132019
48
train loss item: 0.11352591961622238
49
train loss item: 0.09078282862901688
50
train loss item: 0.11016333103179932
51
train loss item: 0.34770044684410095
52
train loss item: 0.055893588811159134
53
train loss item: 0.08018535375595093
54
train loss item: 1.6828186511993408
55
train loss item: 0.11298663914203644
56
train loss item: 0.12588456273078918
57
train loss item: 0.13623249530792236
58
train loss item: 0.08740946650505066
59
train loss item: 0.08604077994823456
60
train loss item: 0.287838339805603
61
train loss item: 1.4597795009613037
62
train loss item: 0.10833495855331421
63
train loss item: 0.16861578822135925
64
train loss item: 0.09182237833738327
65
train loss item: 0.2172357589006424
66
train loss item: 0.18083253502845764
67
train loss item: 0.1155419573187828
68
train loss item: 0.14476525783538818
69
train loss item: 0.15495234727859497
70
train loss item: 0.1296183466911316
71
train loss item: 0.08700919896364212
72
train loss item: 0.07883504778146744
73
train loss item: 0.14766763150691986
74
train loss item: 0.05677269399166107
75
train loss item: 0.07985038310289383
76
train loss item: 0.3190370798110962
77
train loss item: 0.6828907132148743
78
train loss item: 0.05092842876911163
79
train loss item: 0.1448885202407837
80
train loss item: 0.07641124725341797
81
train loss item: 0.10226897895336151
82
train loss item: 0.09650212526321411
83
train loss item: 0.2088795304298401
84
train loss item: 0.1792079359292984
85
train loss item: 0.21826410293579102
86
train loss item: 3.422391414642334
87
train loss item: 0.08345039188861847
88
train loss item: 0.17293375730514526
epoch train loss: 0.25805222506770925
testing phase
test loss item: 0.13934367895126343
test loss item: 0.09213528037071228
test loss item: 0.40101826190948486
test loss item: 0.17199750244617462
test loss item: 0.1944521814584732
test loss item: 0.10038300603628159
test loss item: 1.177424669265747
test loss item: 0.43792349100112915
test loss item: 0.15684060752391815
test loss item: 0.2588888704776764
test loss item: 0.6036500334739685
test loss item: 0.1245073452591896
test loss item: 0.13565769791603088
test loss item: 0.19589686393737793
test loss item: 0.13093633949756622
test loss item: 0.07357142865657806
test loss item: 0.190938338637352
test loss item: 0.30055782198905945
test loss item: 0.4639025330543518
test loss item: 0.17173250019550323
test loss item: 0.4383928179740906
test loss item: 0.28550148010253906
test loss item: 0.19904549419879913
test loss item: 0.12973126769065857
test loss item: 0.14354754984378815
test loss item: 0.16909708082675934
test loss item: 0.20746727287769318
test loss item: 0.13788287341594696
test loss item: 0.21820686757564545
test loss item: 0.2260761260986328
test loss item: 0.5796827673912048
test loss item: 0.06485618650913239
test loss item: 0.11416233330965042
test loss item: 0.38292866945266724
test loss item: 0.27839022874832153
test loss item: 0.34617355465888977
test loss item: 0.5509047508239746
test loss item: 1.0576177835464478
test loss item: 0.29967808723449707
test loss item: 0.19607162475585938
test loss item: 0.22796326875686646
test loss item: 0.1472211331129074
test loss item: 0.23065802454948425
test loss item: 0.16058023273944855
test loss item: 0.32560333609580994
test loss item: 0.25530025362968445
test loss item: 0.19111724197864532
test loss item: 0.15833351016044617
test loss item: 0.34126919507980347
test loss item: 0.48902928829193115
test loss item: 0.18729905784130096
test loss item: 0.10377281904220581
test loss item: 0.17625273764133453
test loss item: 0.12865124642848969
test loss item: 0.20164276659488678
test loss item: 0.5813782215118408
test loss item: 0.41383957862854004
test loss item: 0.15316142141819
test loss item: 0.1681959480047226
test loss item: 0.15090231597423553
test loss item: 0.29098889231681824
test loss item: 0.19180665910243988
test loss item: 0.15018397569656372
test loss item: 0.1679704189300537
test loss item: 0.6126581430435181
test loss item: 0.23652565479278564
test loss item: 0.21329368650913239
test loss item: 0.18258458375930786
test loss item: 0.404371976852417
test loss item: 0.3068116009235382
test loss item: 0.06118093058466911
test loss item: 0.6600722074508667
test loss item: 0.19313214719295502
test loss item: 0.24671140313148499
test loss item: 0.10927163809537888
test loss item: 0.11494308710098267
test loss item: 0.12999315559864044
test loss item: 1.1767727136611938
test loss item: 0.28536689281463623
test loss item: 0.14029531180858612
test loss item: 0.07261301577091217
test loss item: 0.7124224901199341
test loss item: 0.5799127817153931
test loss item: 0.7963881492614746
test loss item: 0.15724775195121765
test loss item: 0.1884259730577469
test loss item: 0.06324425339698792
test loss item: 0.05827270448207855
test loss item: 0.20349417626857758
Epoch [100/100], Training Loss: 0.2581, Testing Loss: 0.2814
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
loss item: 0.2453182190656662
loss item: 0.15328705310821533
loss item: 1.2308392524719238
loss item: 0.5977545976638794
loss item: 0.39674702286720276
loss item: 0.2593388259410858
loss item: 0.19161435961723328
loss item: 0.545939028263092
loss item: 0.16347838938236237
loss item: 0.1584496945142746
loss item: 0.6477686762809753
loss item: 0.0629982054233551
loss item: 0.6406314969062805
loss item: 0.15307967364788055
loss item: 0.22367852926254272
loss item: 0.1954662948846817
loss item: 0.24541401863098145
loss item: 0.4221293032169342
loss item: 0.6327328681945801
loss item: 0.2844759225845337
loss item: 0.24047093093395233
loss item: 0.15297643840312958
loss item: 0.19024641811847687
loss item: 0.17914697527885437
loss item: 0.19028960168361664
loss item: 0.49285170435905457
loss item: 0.7975700497627258
loss item: 0.13371947407722473
loss item: 0.10924848914146423
loss item: 0.2504715621471405
loss item: 0.7343336343765259
loss item: 1.1134437322616577
loss item: 0.11915180087089539
loss item: 0.4076569378376007
loss item: 0.13489270210266113
loss item: 0.11630802601575851
loss item: 0.2697647213935852
loss item: 0.16331180930137634
loss item: 0.30454644560813904
loss item: 0.5105013847351074
loss item: 0.7257773280143738
loss item: 0.16263262927532196
loss item: 0.14340105652809143
loss item: 0.05694473907351494
Val Loss: 0.3443
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 100 0.0001 2 360 done at Wed Nov 13 20:32:03 CET 2024
UNet6 with 1 100 0.0005 2 360 start at Wed Nov 13 20:32:03 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 1073.396240234375
test loss item: 1825.4366455078125
test loss item: 593.513916015625
test loss item: 3402.35400390625
test loss item: 1432.8350830078125
test loss item: 1101.7930908203125
test loss item: 4293.38525390625
test loss item: 2056.052001953125
test loss item: 983.393798828125
test loss item: 1080.54150390625
test loss item: 3268.616455078125
test loss item: 3387.968505859375
test loss item: 1415.2587890625
test loss item: 155.1746826171875
test loss item: 1560.358642578125
test loss item: 2054.7509765625
test loss item: 586.7355346679688
test loss item: 1424.037841796875
test loss item: 2285.005615234375
test loss item: 477.49407958984375
test loss item: 490.1462707519531
test loss item: 3241.994384765625
test loss item: 1987.736083984375
test loss item: 1667.1552734375
test loss item: 1189.39404296875
test loss item: 1011.9746704101562
test loss item: 1110.9444580078125
test loss item: 1439.2664794921875
test loss item: 1637.3873291015625
test loss item: 1456.5567626953125
test loss item: 2567.75830078125
test loss item: 2156.354248046875
test loss item: 1647.2252197265625
test loss item: 3415.092041015625
test loss item: 1677.3106689453125
test loss item: 10306.333984375
test loss item: 2520.37939453125
test loss item: 4596.36572265625
test loss item: 2994.80419921875
test loss item: 1459.9661865234375
test loss item: 1574.25341796875
test loss item: 2169.212646484375
test loss item: 314.3674011230469
test loss item: 3197.302978515625
test loss item: 481.6025695800781
test loss item: 1431.2628173828125
test loss item: 1962.573486328125
test loss item: 636.291015625
test loss item: 638.4937133789062
test loss item: 2052.255615234375
test loss item: 1341.2618408203125
test loss item: 1359.8218994140625
test loss item: 943.6686401367188
test loss item: 4905.68896484375
test loss item: 779.1927490234375
test loss item: 1749.71044921875
test loss item: 6549.90380859375
test loss item: 61.08621597290039
test loss item: 1279.8924560546875
test loss item: 1106.2103271484375
test loss item: 1298.221435546875
test loss item: 1257.730712890625
test loss item: 686.1917724609375
test loss item: 1438.11474609375
test loss item: 2255.193603515625
test loss item: 5237.1640625
test loss item: 1227.04248046875
test loss item: 1095.8515625
test loss item: 1473.5120849609375
test loss item: 2248.47998046875
test loss item: 1458.933349609375
test loss item: 2143.240234375
test loss item: 323.953369140625
test loss item: 1194.3221435546875
test loss item: 400.1552734375
test loss item: 1925.527099609375
test loss item: 1530.5855712890625
test loss item: 5113.45458984375
test loss item: 113.53984832763672
test loss item: 994.1921997070312
test loss item: 553.6729125976562
test loss item: 4730.39404296875
test loss item: 2573.75146484375
test loss item: 4917.96240234375
test loss item: 793.8377075195312
test loss item: 783.5877685546875
test loss item: 1389.701171875
test loss item: 1987.3375244140625
test loss item: 1082.837646484375
Epoch [1/100], Training Loss: 1.0161, Testing Loss: 1907.8066
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.9610803723335266
1
train loss item: 2.0869719982147217
2
train loss item: 0.8648231029510498
3
train loss item: 1.1216984987258911
4
train loss item: 1.9628078937530518
5
train loss item: 0.7860296368598938
6
train loss item: 0.9755358695983887
7
train loss item: 1.276835560798645
8
train loss item: 0.9419233202934265
9
train loss item: 0.636870801448822
10
train loss item: 0.7311280369758606
11
train loss item: 0.5714137554168701
12
train loss item: 0.6297969818115234
13
train loss item: 1.0564218759536743
14
train loss item: 0.7491157650947571
15
train loss item: 1.3152027130126953
16
train loss item: 0.7876008749008179
17
train loss item: 0.9731787443161011
18
train loss item: 0.8148528933525085
19
train loss item: 0.6499318480491638
20
train loss item: 0.7342736124992371
21
train loss item: 0.6737383008003235
22
train loss item: 1.9226921796798706
23
train loss item: 1.3755406141281128
24
train loss item: 1.0840805768966675
25
train loss item: 0.7472132444381714
26
train loss item: 0.7659173011779785
27
train loss item: 0.6883385181427002
28
train loss item: 0.7842848896980286
29
train loss item: 1.564386010169983
30
train loss item: 2.917602777481079
31
train loss item: 1.0476430654525757
32
train loss item: 0.5979970693588257
33
train loss item: 0.9200557470321655
34
train loss item: 1.2829920053482056
35
train loss item: 2.950822591781616
36
train loss item: 1.0549070835113525
37
train loss item: 0.6426941156387329
38
train loss item: 1.1503973007202148
39
train loss item: 0.7319750189781189
40
train loss item: 0.7444394826889038
41
train loss item: 0.6483772397041321
42
train loss item: 0.6060624122619629
43
train loss item: 0.6421911716461182
44
train loss item: 1.1402636766433716
45
train loss item: 0.7553742527961731
46
train loss item: 0.681804358959198
47
train loss item: 0.8301006555557251
48
train loss item: 0.6657137274742126
49
train loss item: 0.6807478070259094
50
train loss item: 0.6668230295181274
51
train loss item: 1.6286009550094604
52
train loss item: 0.7506836652755737
53
train loss item: 0.8124781847000122
54
train loss item: 2.7997705936431885
55
train loss item: 0.8023961782455444
56
train loss item: 0.6549271941184998
57
train loss item: 0.679426372051239
58
train loss item: 0.6117108464241028
59
train loss item: 0.6076603531837463
60
train loss item: 1.7864497900009155
61
train loss item: 2.7589123249053955
62
train loss item: 0.667665421962738
63
train loss item: 0.7758030891418457
64
train loss item: 0.612826406955719
65
train loss item: 1.279589056968689
66
train loss item: 0.7979201674461365
67
train loss item: 0.6886866688728333
68
train loss item: 0.8516250848770142
69
train loss item: 0.7631414532661438
70
train loss item: 0.7257243990898132
71
train loss item: 1.0015699863433838
72
train loss item: 0.9294403195381165
73
train loss item: 0.7485255002975464
74
train loss item: 1.0114132165908813
75
train loss item: 0.625966489315033
76
train loss item: 1.3848271369934082
77
train loss item: 2.0647308826446533
78
train loss item: 0.7570294141769409
79
train loss item: 0.6416780352592468
80
train loss item: 0.9463794827461243
81
train loss item: 0.6630517244338989
82
train loss item: 0.7165557146072388
83
train loss item: 1.3105486631393433
84
train loss item: 0.8187755346298218
85
train loss item: 1.1267739534378052
86
train loss item: 4.951118469238281
87
train loss item: 0.9303812384605408
88
train loss item: 0.774116575717926
epoch train loss: 1.0567589991548088
testing phase
test loss item: 1.6952979564666748
test loss item: 9.625849723815918
test loss item: 2.691225051879883
test loss item: 38.27228546142578
test loss item: 7.350315093994141
test loss item: 5.846074104309082
test loss item: 20.474124908447266
test loss item: 6.659194469451904
test loss item: 1.1748534440994263
test loss item: 4.6506266593933105
test loss item: 24.397600173950195
test loss item: 36.54059600830078
test loss item: 5.641790390014648
test loss item: 0.7489233613014221
test loss item: 7.349485397338867
test loss item: 12.024171829223633
test loss item: 1.9126787185668945
test loss item: 6.343292236328125
test loss item: 8.421590805053711
test loss item: 0.6090383529663086
test loss item: 2.897944688796997
test loss item: 37.776153564453125
test loss item: 18.683368682861328
test loss item: 7.812326431274414
test loss item: 5.44108772277832
test loss item: 5.987850189208984
test loss item: 1.3666883707046509
test loss item: 7.144177436828613
test loss item: 7.813586711883545
test loss item: 6.361095905303955
test loss item: 25.833454132080078
test loss item: 11.886795043945312
test loss item: 7.941087245941162
test loss item: 41.5970458984375
test loss item: 8.978658676147461
test loss item: 152.70481872558594
test loss item: 8.280072212219238
test loss item: 40.83656311035156
test loss item: 31.929595947265625
test loss item: 7.145925998687744
test loss item: 7.720831394195557
test loss item: 20.765243530273438
test loss item: 0.8431825041770935
test loss item: 36.8121223449707
test loss item: 2.0887584686279297
test loss item: 7.666717529296875
test loss item: 18.209367752075195
test loss item: 0.7529315948486328
test loss item: 1.4781244993209839
test loss item: 10.07898235321045
test loss item: 5.243545055389404
test loss item: 5.531370162963867
test loss item: 4.027170658111572
test loss item: 60.67716979980469
test loss item: 2.955077886581421
test loss item: 8.937223434448242
test loss item: 83.23029327392578
test loss item: 0.8209882378578186
test loss item: 5.119174003601074
test loss item: 4.177523136138916
test loss item: 6.436301231384277
test loss item: 6.872252464294434
test loss item: 2.8275954723358154
test loss item: 5.022403717041016
test loss item: 11.198412895202637
test loss item: 64.35678100585938
test loss item: 4.291144847869873
test loss item: 4.325949668884277
test loss item: 7.919835567474365
test loss item: 8.365128517150879
test loss item: 8.267951965332031
test loss item: 4.000560283660889
test loss item: 1.0867365598678589
test loss item: 3.7332310676574707
test loss item: 1.4995241165161133
test loss item: 17.838932037353516
test loss item: 7.238837718963623
test loss item: 57.285072326660156
test loss item: 0.9476891160011292
test loss item: 5.287164211273193
test loss item: 2.0927717685699463
test loss item: 34.28313446044922
test loss item: 10.352858543395996
test loss item: 49.220340728759766
test loss item: 3.2549819946289062
test loss item: 6.598217487335205
test loss item: 7.951676368713379
test loss item: 11.18775749206543
test loss item: 9.065872192382812
Epoch [2/100], Training Loss: 1.0568, Testing Loss: 14.5033
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7753306031227112
1
train loss item: 1.9373955726623535
2
train loss item: 0.48450934886932373
3
train loss item: 1.0331743955612183
4
train loss item: 0.9824836850166321
5
train loss item: 0.5950410962104797
6
train loss item: 0.5091562271118164
7
train loss item: 1.2250372171401978
8
train loss item: 0.4754185676574707
9
train loss item: 0.4638817310333252
10
train loss item: 0.6290343999862671
11
train loss item: 0.40699079632759094
12
train loss item: 0.35201478004455566
13
train loss item: 0.8948885798454285
14
train loss item: 0.551002025604248
15
train loss item: 1.0726706981658936
16
train loss item: 0.3707497715950012
17
train loss item: 0.5284109115600586
18
train loss item: 0.6259781718254089
19
train loss item: 0.4379565119743347
20
train loss item: 0.39260342717170715
21
train loss item: 0.44246700406074524
22
train loss item: 1.5754714012145996
23
train loss item: 1.3360466957092285
24
train loss item: 0.8429235816001892
25
train loss item: 0.5052021741867065
26
train loss item: 0.4471554458141327
27
train loss item: 0.5551421046257019
28
train loss item: 0.37232908606529236
29
train loss item: 1.3058303594589233
30
train loss item: 2.943434238433838
31
train loss item: 0.9255861043930054
32
train loss item: 0.366534948348999
33
train loss item: 0.7713114023208618
34
train loss item: 0.6291664838790894
35
train loss item: 2.941950559616089
36
train loss item: 0.8456735014915466
37
train loss item: 0.4106711149215698
38
train loss item: 0.9005528688430786
39
train loss item: 0.5786586999893188
40
train loss item: 0.419023334980011
41
train loss item: 0.532141387462616
42
train loss item: 0.4084606468677521
43
train loss item: 0.43716010451316833
44
train loss item: 1.0760644674301147
45
train loss item: 0.4653486907482147
46
train loss item: 0.47002318501472473
47
train loss item: 0.6124353408813477
48
train loss item: 0.5024266242980957
49
train loss item: 0.4876966178417206
50
train loss item: 0.42818504571914673
51
train loss item: 1.415174961090088
52
train loss item: 0.36160144209861755
53
train loss item: 0.4910452663898468
54
train loss item: 2.8157169818878174
55
train loss item: 0.49821850657463074
56
train loss item: 0.5213576555252075
57
train loss item: 0.4669608771800995
58
train loss item: 0.40954363346099854
59
train loss item: 0.374469131231308
60
train loss item: 1.521458625793457
61
train loss item: 2.801856756210327
62
train loss item: 0.4282427728176117
63
train loss item: 0.5508915781974792
64
train loss item: 0.4252351224422455
65
train loss item: 0.9064849615097046
66
train loss item: 0.6466435790061951
67
train loss item: 0.4837954044342041
68
train loss item: 0.5308824181556702
69
train loss item: 0.568732500076294
70
train loss item: 0.49967238306999207
71
train loss item: 0.48316025733947754
72
train loss item: 0.4887859523296356
73
train loss item: 0.5104274153709412
74
train loss item: 0.49377527832984924
75
train loss item: 0.36806562542915344
76
train loss item: 1.330392599105835
77
train loss item: 1.7725940942764282
78
train loss item: 0.3619401156902313
79
train loss item: 0.4328960180282593
80
train loss item: 0.46722978353500366
81
train loss item: 0.4052654504776001
82
train loss item: 0.5447877645492554
83
train loss item: 1.0891740322113037
84
train loss item: 0.6080710887908936
85
train loss item: 0.9767184853553772
86
train loss item: 4.9969964027404785
87
train loss item: 0.5371173024177551
88
train loss item: 0.5534860491752625
epoch train loss: 0.8136816855227009
testing phase
test loss item: 1.1898895502090454
test loss item: 3.227278470993042
test loss item: 1.703351616859436
test loss item: 6.817262649536133
test loss item: 2.866787910461426
test loss item: 2.747218608856201
test loss item: 5.039423942565918
test loss item: 2.2433838844299316
test loss item: 1.010989785194397
test loss item: 1.4505813121795654
test loss item: 6.24137020111084
test loss item: 6.7986884117126465
test loss item: 1.7276753187179565
test loss item: 0.6354014277458191
test loss item: 2.7934041023254395
test loss item: 3.9495513439178467
test loss item: 0.761549711227417
test loss item: 2.0514755249023438
test loss item: 2.8010435104370117
test loss item: 0.4654821455478668
test loss item: 2.1977763175964355
test loss item: 6.5736775398254395
test loss item: 6.604550361633301
test loss item: 2.591827630996704
test loss item: 2.015840768814087
test loss item: 2.14677357673645
test loss item: 1.139235496520996
test loss item: 2.7506701946258545
test loss item: 2.765331745147705
test loss item: 1.8219664096832275
test loss item: 6.111570358276367
test loss item: 3.866427421569824
test loss item: 2.6664106845855713
test loss item: 7.155632495880127
test loss item: 2.893854856491089
test loss item: 22.10896873474121
test loss item: 2.69307279586792
test loss item: 11.15649127960205
test loss item: 5.8358025550842285
test loss item: 2.7186625003814697
test loss item: 2.518120527267456
test loss item: 6.929379940032959
test loss item: 0.7523263692855835
test loss item: 6.4873456954956055
test loss item: 1.73220694065094
test loss item: 2.571293354034424
test loss item: 6.46089506149292
test loss item: 0.5021698474884033
test loss item: 1.1642178297042847
test loss item: 3.6170618534088135
test loss item: 1.5473241806030273
test loss item: 1.8063280582427979
test loss item: 1.7111142873764038
test loss item: 10.242157936096191
test loss item: 1.8909834623336792
test loss item: 3.651387929916382
test loss item: 12.682930946350098
test loss item: 0.6178389191627502
test loss item: 1.6577080488204956
test loss item: 1.847389817237854
test loss item: 2.2478511333465576
test loss item: 2.198476552963257
test loss item: 1.5555464029312134
test loss item: 1.6990206241607666
test loss item: 4.155920028686523
test loss item: 10.821247100830078
test loss item: 1.6911855936050415
test loss item: 1.5414832830429077
test loss item: 2.787243127822876
test loss item: 2.8590431213378906
test loss item: 2.7159781455993652
test loss item: 1.8706729412078857
test loss item: 0.8868982195854187
test loss item: 1.1505937576293945
test loss item: 0.7609840631484985
test loss item: 6.275387287139893
test loss item: 2.607560396194458
test loss item: 13.385534286499023
test loss item: 0.8619686961174011
test loss item: 2.345057249069214
test loss item: 1.5323015451431274
test loss item: 7.98535680770874
test loss item: 3.431525468826294
test loss item: 10.907723426818848
test loss item: 1.8699524402618408
test loss item: 1.7947497367858887
test loss item: 2.6904611587524414
test loss item: 3.8197081089019775
test loss item: 2.529606342315674
Epoch [3/100], Training Loss: 0.8137, Testing Loss: 3.6596
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6983966827392578
1
train loss item: 1.8895678520202637
2
train loss item: 0.4078570008277893
3
train loss item: 1.0575674772262573
4
train loss item: 1.0385847091674805
5
train loss item: 0.52247154712677
6
train loss item: 0.41971778869628906
7
train loss item: 1.2598832845687866
8
train loss item: 0.4240264296531677
9
train loss item: 0.4619661271572113
10
train loss item: 0.6555545926094055
11
train loss item: 0.3903302252292633
12
train loss item: 0.3221556842327118
13
train loss item: 0.8316524028778076
14
train loss item: 0.49575939774513245
15
train loss item: 0.9327904582023621
16
train loss item: 0.34123098850250244
17
train loss item: 0.456911563873291
18
train loss item: 0.5701507925987244
19
train loss item: 0.400150328874588
20
train loss item: 0.35642391443252563
21
train loss item: 0.37708383798599243
22
train loss item: 1.3951287269592285
23
train loss item: 1.353918194770813
24
train loss item: 0.7554471492767334
25
train loss item: 0.4307234287261963
26
train loss item: 0.38092318177223206
27
train loss item: 0.526859700679779
28
train loss item: 0.33884429931640625
29
train loss item: 1.1439898014068604
30
train loss item: 3.0326292514801025
31
train loss item: 0.9294781684875488
32
train loss item: 0.41547268629074097
33
train loss item: 0.787726879119873
34
train loss item: 0.42948347330093384
35
train loss item: 2.976135492324829
36
train loss item: 0.7441644072532654
37
train loss item: 0.3760562539100647
38
train loss item: 0.8047831654548645
39
train loss item: 0.5277100205421448
40
train loss item: 0.31911784410476685
41
train loss item: 0.5406798124313354
42
train loss item: 0.3650849461555481
43
train loss item: 0.4221801161766052
44
train loss item: 1.0753355026245117
45
train loss item: 0.40256625413894653
46
train loss item: 0.41455337405204773
47
train loss item: 0.5339937806129456
48
train loss item: 0.4749167859554291
49
train loss item: 0.42313259840011597
50
train loss item: 0.4188964366912842
51
train loss item: 1.32359778881073
52
train loss item: 0.3932873606681824
53
train loss item: 0.3888820707798004
54
train loss item: 2.866298198699951
55
train loss item: 0.4193289875984192
56
train loss item: 0.5133644342422485
57
train loss item: 0.4223174750804901
58
train loss item: 0.39009371399879456
59
train loss item: 0.41822704672813416
60
train loss item: 1.3682383298873901
61
train loss item: 2.8778650760650635
62
train loss item: 0.43743205070495605
63
train loss item: 0.4907551407814026
64
train loss item: 0.42146041989326477
65
train loss item: 0.7421570420265198
66
train loss item: 0.6023702025413513
67
train loss item: 0.42771679162979126
68
train loss item: 0.4219704866409302
69
train loss item: 0.50228351354599
70
train loss item: 0.43160462379455566
71
train loss item: 0.31944015622138977
72
train loss item: 0.47537699341773987
73
train loss item: 0.43796253204345703
74
train loss item: 0.42013832926750183
75
train loss item: 0.35526344180107117
76
train loss item: 1.3376119136810303
77
train loss item: 1.6430391073226929
78
train loss item: 0.35548120737075806
79
train loss item: 0.40230482816696167
80
train loss item: 0.3651096820831299
81
train loss item: 0.35108229517936707
82
train loss item: 0.4823961555957794
83
train loss item: 0.9637957215309143
84
train loss item: 0.5152562856674194
85
train loss item: 0.9517197608947754
86
train loss item: 5.090278625488281
87
train loss item: 0.4349687993526459
88
train loss item: 0.48934024572372437
epoch train loss: 0.7674155241987678
testing phase
test loss item: 0.28967922925949097
test loss item: 0.4661613702774048
test loss item: 1.0977962017059326
test loss item: 0.8411714434623718
test loss item: 0.6092407703399658
test loss item: 0.47013771533966064
test loss item: 2.278618812561035
test loss item: 0.6200326681137085
test loss item: 0.37713998556137085
test loss item: 0.6189283728599548
test loss item: 1.831299066543579
test loss item: 0.8438577055931091
test loss item: 0.34918975830078125
test loss item: 0.4146531820297241
test loss item: 0.4850887060165405
test loss item: 0.5186068415641785
test loss item: 0.36682209372520447
test loss item: 0.819593071937561
test loss item: 0.8401731848716736
test loss item: 0.3737275004386902
test loss item: 1.3717535734176636
test loss item: 0.8750786185264587
test loss item: 0.9892051219940186
test loss item: 0.41947486996650696
test loss item: 0.41661784052848816
test loss item: 0.44115975499153137
test loss item: 0.4562559425830841
test loss item: 0.5141705274581909
test loss item: 0.6226191520690918
test loss item: 0.5139089226722717
test loss item: 1.5652313232421875
test loss item: 0.5349465608596802
test loss item: 0.4094506502151489
test loss item: 1.2278848886489868
test loss item: 0.8185349106788635
test loss item: 2.2731616497039795
test loss item: 1.0341012477874756
test loss item: 3.327460765838623
test loss item: 1.0333184003829956
test loss item: 0.5245742797851562
test loss item: 0.4867233335971832
test loss item: 0.8754964470863342
test loss item: 0.5635008215904236
test loss item: 0.7994691133499146
test loss item: 1.0707730054855347
test loss item: 0.6088303327560425
test loss item: 0.9605841636657715
test loss item: 0.4078099727630615
test loss item: 0.7924291491508484
test loss item: 1.206511378288269
test loss item: 0.5406088829040527
test loss item: 0.3122153878211975
test loss item: 0.4157840311527252
test loss item: 1.1872050762176514
test loss item: 0.5935589671134949
test loss item: 1.7029435634613037
test loss item: 1.5778933763504028
test loss item: 0.4830836355686188
test loss item: 0.39540863037109375
test loss item: 0.40097305178642273
test loss item: 0.7240050435066223
test loss item: 0.3896774351596832
test loss item: 0.3439917266368866
test loss item: 0.3831360638141632
test loss item: 1.7959402799606323
test loss item: 1.275413155555725
test loss item: 0.4710361063480377
test loss item: 0.39208316802978516
test loss item: 1.0246944427490234
test loss item: 0.6592327952384949
test loss item: 0.39657318592071533
test loss item: 1.0477616786956787
test loss item: 0.5025136470794678
test loss item: 0.4581690728664398
test loss item: 0.2774539291858673
test loss item: 0.8348803520202637
test loss item: 0.4248865842819214
test loss item: 3.6898858547210693
test loss item: 0.700594425201416
test loss item: 0.45810234546661377
test loss item: 0.27888163924217224
test loss item: 2.071094274520874
test loss item: 1.2470712661743164
test loss item: 2.6188879013061523
test loss item: 0.39289888739585876
test loss item: 0.4359573423862457
test loss item: 0.3628467321395874
test loss item: 0.47481682896614075
test loss item: 0.4011151194572449
Epoch [4/100], Training Loss: 0.7674, Testing Loss: 0.8292
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6756762266159058
1
train loss item: 1.8227037191390991
2
train loss item: 0.37234199047088623
3
train loss item: 0.9910301566123962
4
train loss item: 0.918097198009491
5
train loss item: 0.512028694152832
6
train loss item: 0.4177883267402649
7
train loss item: 1.2159864902496338
8
train loss item: 0.3952226936817169
9
train loss item: 0.4213326573371887
10
train loss item: 0.5899624228477478
11
train loss item: 0.3660014867782593
12
train loss item: 0.28829464316368103
13
train loss item: 0.7883545160293579
14
train loss item: 0.4807130694389343
15
train loss item: 0.8995276093482971
16
train loss item: 0.2694915235042572
17
train loss item: 0.4307445287704468
18
train loss item: 0.5323776006698608
19
train loss item: 0.3909452557563782
20
train loss item: 0.3488242030143738
21
train loss item: 0.333306223154068
22
train loss item: 1.3327043056488037
23
train loss item: 1.2924134731292725
24
train loss item: 0.7219944000244141
25
train loss item: 0.3935707211494446
26
train loss item: 0.38187772035598755
27
train loss item: 0.4978334307670593
28
train loss item: 0.2726540267467499
29
train loss item: 1.0741456747055054
30
train loss item: 2.9715728759765625
31
train loss item: 0.8734990358352661
32
train loss item: 0.3875848054885864
33
train loss item: 0.7251477241516113
34
train loss item: 0.4227859377861023
35
train loss item: 2.9328434467315674
36
train loss item: 0.6845158934593201
37
train loss item: 0.37049177289009094
38
train loss item: 0.7201752066612244
39
train loss item: 0.4930780529975891
40
train loss item: 0.3014034926891327
41
train loss item: 0.49657267332077026
42
train loss item: 0.3604181408882141
43
train loss item: 0.3855047821998596
44
train loss item: 1.0297542810440063
45
train loss item: 0.3466341495513916
46
train loss item: 0.3548533022403717
47
train loss item: 0.49289366602897644
48
train loss item: 0.4337422847747803
49
train loss item: 0.35309314727783203
50
train loss item: 0.4112716615200043
51
train loss item: 1.267536997795105
52
train loss item: 0.3253319263458252
53
train loss item: 0.35252681374549866
54
train loss item: 2.8232924938201904
55
train loss item: 0.41496580839157104
56
train loss item: 0.478279173374176
57
train loss item: 0.4213694632053375
58
train loss item: 0.3638981580734253
59
train loss item: 0.36891600489616394
60
train loss item: 1.3064498901367188
61
train loss item: 2.8205347061157227
62
train loss item: 0.40030649304389954
63
train loss item: 0.47829553484916687
64
train loss item: 0.3820277452468872
65
train loss item: 0.7256078124046326
66
train loss item: 0.5505028963088989
67
train loss item: 0.4006686210632324
68
train loss item: 0.41346731781959534
69
train loss item: 0.4650878608226776
70
train loss item: 0.4030076265335083
71
train loss item: 0.2978228032588959
72
train loss item: 0.41744598746299744
73
train loss item: 0.4164917767047882
74
train loss item: 0.366365522146225
75
train loss item: 0.3059244155883789
76
train loss item: 1.2832101583480835
77
train loss item: 1.5993642807006836
78
train loss item: 0.2903710901737213
79
train loss item: 0.39616137742996216
80
train loss item: 0.3380153477191925
81
train loss item: 0.3419483006000519
82
train loss item: 0.4190782904624939
83
train loss item: 0.9058240056037903
84
train loss item: 0.4595102071762085
85
train loss item: 0.9038756489753723
86
train loss item: 5.041164875030518
87
train loss item: 0.3814472258090973
88
train loss item: 0.4677489101886749
epoch train loss: 0.727748594257269
testing phase
test loss item: 0.2521902620792389
test loss item: 0.2463563233613968
test loss item: 0.9279228448867798
test loss item: 0.4478243589401245
test loss item: 0.44093936681747437
test loss item: 0.26315709948539734
test loss item: 1.881082534790039
test loss item: 0.4942623972892761
test loss item: 0.3242061138153076
test loss item: 0.5410722494125366
test loss item: 1.3805214166641235
test loss item: 0.39780691266059875
test loss item: 0.25827130675315857
test loss item: 0.36585739254951477
test loss item: 0.3131088614463806
test loss item: 0.23211047053337097
test loss item: 0.3411058783531189
test loss item: 0.7314189672470093
test loss item: 0.7001429796218872
test loss item: 0.3340034782886505
test loss item: 1.2429800033569336
test loss item: 0.530864417552948
test loss item: 0.5760958194732666
test loss item: 0.263040691614151
test loss item: 0.32923972606658936
test loss item: 0.32115480303764343
test loss item: 0.41688182950019836
test loss item: 0.334978848695755
test loss item: 0.46883952617645264
test loss item: 0.4418793022632599
test loss item: 1.155320405960083
test loss item: 0.2260134518146515
test loss item: 0.25187963247299194
test loss item: 0.9095188975334167
test loss item: 0.6939302682876587
test loss item: 0.9157507419586182
test loss item: 0.9040374159812927
test loss item: 2.472788095474243
test loss item: 0.762606680393219
test loss item: 0.3699493110179901
test loss item: 0.37357962131500244
test loss item: 0.4297417402267456
test loss item: 0.5317898988723755
test loss item: 0.41653186082839966
test loss item: 0.9710813164710999
test loss item: 0.49325644969940186
test loss item: 0.5541343688964844
test loss item: 0.3550383150577545
test loss item: 0.7064530253410339
test loss item: 0.9429876208305359
test loss item: 0.4762984812259674
test loss item: 0.21357931196689606
test loss item: 0.34673020243644714
test loss item: 0.5554941892623901
test loss item: 0.4891375005245209
test loss item: 1.3449243307113647
test loss item: 0.8914442658424377
test loss item: 0.4740852415561676
test loss item: 0.33222848176956177
test loss item: 0.31106722354888916
test loss item: 0.6115779876708984
test loss item: 0.2753452956676483
test loss item: 0.27454936504364014
test loss item: 0.31695428490638733
test loss item: 1.3981748819351196
test loss item: 0.6524821519851685
test loss item: 0.3997931182384491
test loss item: 0.337953120470047
test loss item: 0.8603289127349854
test loss item: 0.45089611411094666
test loss item: 0.2130456268787384
test loss item: 0.9769094586372375
test loss item: 0.46808573603630066
test loss item: 0.42276740074157715
test loss item: 0.23896542191505432
test loss item: 0.415365070104599
test loss item: 0.2598615884780884
test loss item: 2.823284387588501
test loss item: 0.6321609616279602
test loss item: 0.305255651473999
test loss item: 0.179587721824646
test loss item: 1.5141198635101318
test loss item: 1.013110876083374
test loss item: 1.9094038009643555
test loss item: 0.32573437690734863
test loss item: 0.337069034576416
test loss item: 0.2178996503353119
test loss item: 0.21727725863456726
test loss item: 0.2600052058696747
Epoch [5/100], Training Loss: 0.7277, Testing Loss: 0.6065
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6452210545539856
1
train loss item: 1.7289482355117798
2
train loss item: 0.3383975028991699
3
train loss item: 0.8923723697662354
4
train loss item: 0.6983416676521301
5
train loss item: 0.48326975107192993
6
train loss item: 0.3885626196861267
7
train loss item: 1.1405962705612183
8
train loss item: 0.2940666973590851
9
train loss item: 0.37343961000442505
10
train loss item: 0.5261847972869873
11
train loss item: 0.33319157361984253
12
train loss item: 0.23672565817832947
13
train loss item: 0.7501187920570374
14
train loss item: 0.43800103664398193
15
train loss item: 0.8853161334991455
16
train loss item: 0.19598424434661865
17
train loss item: 0.40613195300102234
18
train loss item: 0.4862695336341858
19
train loss item: 0.35405290126800537
20
train loss item: 0.32285600900650024
21
train loss item: 0.29618796706199646
22
train loss item: 1.2978127002716064
23
train loss item: 1.2209099531173706
24
train loss item: 0.6966726779937744
25
train loss item: 0.36117926239967346
26
train loss item: 0.3067795932292938
27
train loss item: 0.4608197510242462
28
train loss item: 0.19701042771339417
29
train loss item: 1.0397021770477295
30
train loss item: 2.852604627609253
31
train loss item: 0.7977504730224609
32
train loss item: 0.2906121611595154
33
train loss item: 0.6504994630813599
34
train loss item: 0.3805777132511139
35
train loss item: 2.8484134674072266
36
train loss item: 0.6507179141044617
37
train loss item: 0.3445320129394531
38
train loss item: 0.646823525428772
39
train loss item: 0.45959651470184326
40
train loss item: 0.2655152678489685
41
train loss item: 0.4443369209766388
42
train loss item: 0.32348504662513733
43
train loss item: 0.31999507546424866
44
train loss item: 0.9792998433113098
45
train loss item: 0.276140958070755
46
train loss item: 0.2940624952316284
47
train loss item: 0.4554567039012909
48
train loss item: 0.3804987967014313
49
train loss item: 0.30832639336586
50
train loss item: 0.37832367420196533
51
train loss item: 1.2200555801391602
52
train loss item: 0.22142644226551056
53
train loss item: 0.324291855096817
54
train loss item: 2.7330944538116455
55
train loss item: 0.34025338292121887
56
train loss item: 0.43192732334136963
57
train loss item: 0.377086877822876
58
train loss item: 0.30416861176490784
59
train loss item: 0.280572772026062
60
train loss item: 1.261991024017334
61
train loss item: 2.713313579559326
62
train loss item: 0.33034905791282654
63
train loss item: 0.44636857509613037
64
train loss item: 0.30631592869758606
65
train loss item: 0.7223644852638245
66
train loss item: 0.5028720498085022
67
train loss item: 0.3599405884742737
68
train loss item: 0.3869301974773407
69
train loss item: 0.42883527278900146
70
train loss item: 0.3731733560562134
71
train loss item: 0.2536478638648987
72
train loss item: 0.3198274075984955
73
train loss item: 0.3933572471141815
74
train loss item: 0.25255000591278076
75
train loss item: 0.24613520503044128
76
train loss item: 1.2061687707901
77
train loss item: 1.568737268447876
78
train loss item: 0.20533603429794312
79
train loss item: 0.35739952325820923
80
train loss item: 0.2686823904514313
81
train loss item: 0.2959524691104889
82
train loss item: 0.36959120631217957
83
train loss item: 0.8659226298332214
84
train loss item: 0.4310261011123657
85
train loss item: 0.8453577160835266
86
train loss item: 4.91859245300293
87
train loss item: 0.33064746856689453
88
train loss item: 0.4398626685142517
epoch train loss: 0.6716496383541086
testing phase
test loss item: 0.2514267861843109
test loss item: 0.23578743636608124
test loss item: 0.8421409130096436
test loss item: 0.4452724754810333
test loss item: 0.42802539467811584
test loss item: 0.2799590229988098
test loss item: 1.7652606964111328
test loss item: 0.4751644730567932
test loss item: 0.3089240789413452
test loss item: 0.5173994302749634
test loss item: 1.2175014019012451
test loss item: 0.3869268298149109
test loss item: 0.2465045303106308
test loss item: 0.3696826100349426
test loss item: 0.30334359407424927
test loss item: 0.2102905660867691
test loss item: 0.33833515644073486
test loss item: 0.6976087093353271
test loss item: 0.6878243088722229
test loss item: 0.31682783365249634
test loss item: 1.168135643005371
test loss item: 0.5216313004493713
test loss item: 0.6039986610412598
test loss item: 0.2496688812971115
test loss item: 0.3211801052093506
test loss item: 0.2962656021118164
test loss item: 0.3963067829608917
test loss item: 0.32584360241889954
test loss item: 0.44714540243148804
test loss item: 0.4340917766094208
test loss item: 1.024134874343872
test loss item: 0.2076060175895691
test loss item: 0.24558763206005096
test loss item: 0.8633992671966553
test loss item: 0.6510388255119324
test loss item: 0.773166298866272
test loss item: 0.8732166290283203
test loss item: 2.1387643814086914
test loss item: 0.7205466628074646
test loss item: 0.37008607387542725
test loss item: 0.3637576699256897
test loss item: 0.4798930585384369
test loss item: 0.5318541526794434
test loss item: 0.4097404479980469
test loss item: 0.9212838411331177
test loss item: 0.48347416520118713
test loss item: 0.5823826193809509
test loss item: 0.2856253683567047
test loss item: 0.6546012759208679
test loss item: 0.8706822395324707
test loss item: 0.4544416666030884
test loss item: 0.2123052477836609
test loss item: 0.3372083604335785
test loss item: 0.5486108064651489
test loss item: 0.4659050703048706
test loss item: 1.2120914459228516
test loss item: 0.7781188488006592
test loss item: 0.4993182420730591
test loss item: 0.3311591148376465
test loss item: 0.30207526683807373
test loss item: 0.592872679233551
test loss item: 0.2670460343360901
test loss item: 0.26929771900177
test loss item: 0.3131084442138672
test loss item: 1.2296767234802246
test loss item: 0.6468898057937622
test loss item: 0.39008715748786926
test loss item: 0.3257649838924408
test loss item: 0.7924712896347046
test loss item: 0.4600687026977539
test loss item: 0.19059856235980988
test loss item: 0.9367020130157471
test loss item: 0.45986735820770264
test loss item: 0.41702017188072205
test loss item: 0.2349158227443695
test loss item: 0.4681587517261505
test loss item: 0.24304378032684326
test loss item: 2.377206802368164
test loss item: 0.5958420634269714
test loss item: 0.3123306632041931
test loss item: 0.16323167085647583
test loss item: 1.329064965248108
test loss item: 0.9638237953186035
test loss item: 1.6042238473892212
test loss item: 0.3282613754272461
test loss item: 0.3230404853820801
test loss item: 0.21498508751392365
test loss item: 0.21535086631774902
test loss item: 0.2492603063583374
Epoch [6/100], Training Loss: 0.6716, Testing Loss: 0.5685
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6208663582801819
1
train loss item: 1.6327667236328125
2
train loss item: 0.3193853795528412
3
train loss item: 0.8058030605316162
4
train loss item: 0.58958500623703
5
train loss item: 0.4652804136276245
6
train loss item: 0.35918864607810974
7
train loss item: 1.0811164379119873
8
train loss item: 0.25466981530189514
9
train loss item: 0.36075204610824585
10
train loss item: 0.4986518621444702
11
train loss item: 0.32432499527931213
12
train loss item: 0.21677842736244202
13
train loss item: 0.7221936583518982
14
train loss item: 0.4171341359615326
15
train loss item: 0.8644335269927979
16
train loss item: 0.18400153517723083
17
train loss item: 0.4137260317802429
18
train loss item: 0.4535277783870697
19
train loss item: 0.33846673369407654
20
train loss item: 0.29837724566459656
21
train loss item: 0.2901039123535156
22
train loss item: 1.2509926557540894
23
train loss item: 1.1673998832702637
24
train loss item: 0.6697906255722046
25
train loss item: 0.36520665884017944
26
train loss item: 0.28737688064575195
27
train loss item: 0.4359801411628723
28
train loss item: 0.18188732862472534
29
train loss item: 1.0065757036209106
30
train loss item: 2.7441580295562744
31
train loss item: 0.7459144592285156
32
train loss item: 0.21404866874217987
33
train loss item: 0.5948442220687866
34
train loss item: 0.3749246299266815
35
train loss item: 2.774412155151367
36
train loss item: 0.628724217414856
37
train loss item: 0.332899272441864
38
train loss item: 0.5903997421264648
39
train loss item: 0.4397202432155609
40
train loss item: 0.2694013714790344
41
train loss item: 0.41962361335754395
42
train loss item: 0.2992267906665802
43
train loss item: 0.28080520033836365
44
train loss item: 0.9428375959396362
45
train loss item: 0.24122819304466248
46
train loss item: 0.25512638688087463
47
train loss item: 0.44452837109565735
48
train loss item: 0.35549265146255493
49
train loss item: 0.3148382306098938
50
train loss item: 0.35431304574012756
51
train loss item: 1.1735419034957886
52
train loss item: 0.19849374890327454
53
train loss item: 0.3432384133338928
54
train loss item: 2.6534955501556396
55
train loss item: 0.2861960530281067
56
train loss item: 0.40684768557548523
57
train loss item: 0.33878329396247864
58
train loss item: 0.2608513832092285
59
train loss item: 0.23534061014652252
60
train loss item: 1.206522822380066
61
train loss item: 2.6270031929016113
62
train loss item: 0.3084268569946289
63
train loss item: 0.41363388299942017
64
train loss item: 0.24848933517932892
65
train loss item: 0.71045982837677
66
train loss item: 0.47698870301246643
67
train loss item: 0.3393414318561554
68
train loss item: 0.37059080600738525
69
train loss item: 0.41112020611763
70
train loss item: 0.3794271945953369
71
train loss item: 0.24603167176246643
72
train loss item: 0.28612029552459717
73
train loss item: 0.3883107304573059
74
train loss item: 0.24127180874347687
75
train loss item: 0.22147731482982635
76
train loss item: 1.142932653427124
77
train loss item: 1.5296545028686523
78
train loss item: 0.18140393495559692
79
train loss item: 0.32386544346809387
80
train loss item: 0.23611871898174286
81
train loss item: 0.2937258780002594
82
train loss item: 0.35281169414520264
83
train loss item: 0.8258532881736755
84
train loss item: 0.4186643064022064
85
train loss item: 0.8044732809066772
86
train loss item: 4.810916423797607
87
train loss item: 0.3477106988430023
88
train loss item: 0.413939893245697
epoch train loss: 0.6398638892039824
testing phase
test loss item: 0.25328224897384644
test loss item: 0.23399780690670013
test loss item: 0.7863457798957825
test loss item: 0.368974506855011
test loss item: 0.4158589541912079
test loss item: 0.28650444746017456
test loss item: 1.6987099647521973
test loss item: 0.4847869873046875
test loss item: 0.30651775002479553
test loss item: 0.5041671395301819
test loss item: 1.1632639169692993
test loss item: 0.2955278158187866
test loss item: 0.24966846406459808
test loss item: 0.37091028690338135
test loss item: 0.29675668478012085
test loss item: 0.19261586666107178
test loss item: 0.3354567885398865
test loss item: 0.658467710018158
test loss item: 0.7020514011383057
test loss item: 0.3365957736968994
test loss item: 1.0800809860229492
test loss item: 0.4553881585597992
test loss item: 0.5420660376548767
test loss item: 0.24936026334762573
test loss item: 0.3089473247528076
test loss item: 0.2937248945236206
test loss item: 0.4003644585609436
test loss item: 0.32294631004333496
test loss item: 0.43510717153549194
test loss item: 0.4349900484085083
test loss item: 0.980178952217102
test loss item: 0.1922481507062912
test loss item: 0.24669389426708221
test loss item: 0.7876656651496887
test loss item: 0.61049485206604
test loss item: 0.6336287260055542
test loss item: 0.8631623387336731
test loss item: 2.0098345279693604
test loss item: 0.6577877998352051
test loss item: 0.3688564598560333
test loss item: 0.3540785312652588
test loss item: 0.41334807872772217
test loss item: 0.5202460289001465
test loss item: 0.3289024531841278
test loss item: 0.8626096248626709
test loss item: 0.48132169246673584
test loss item: 0.5258878469467163
test loss item: 0.3278862535953522
test loss item: 0.6146120429039001
test loss item: 0.8574888110160828
test loss item: 0.4361375868320465
test loss item: 0.23381556570529938
test loss item: 0.32944661378860474
test loss item: 0.4002256691455841
test loss item: 0.44654610753059387
test loss item: 1.1548115015029907
test loss item: 0.6924795508384705
test loss item: 0.48410564661026
test loss item: 0.32444435358047485
test loss item: 0.2960008680820465
test loss item: 0.575468897819519
test loss item: 0.25710317492485046
test loss item: 0.27240630984306335
test loss item: 0.30408579111099243
test loss item: 1.13593590259552
test loss item: 0.5057934522628784
test loss item: 0.3816291093826294
test loss item: 0.3176214396953583
test loss item: 0.7442411184310913
test loss item: 0.5109080076217651
test loss item: 0.17674438655376434
test loss item: 0.9177349805831909
test loss item: 0.43562421202659607
test loss item: 0.4124358594417572
test loss item: 0.23801030218601227
test loss item: 0.4064955413341522
test loss item: 0.24171008169651031
test loss item: 2.1690943241119385
test loss item: 0.5672817230224609
test loss item: 0.3174498677253723
test loss item: 0.15501831471920013
test loss item: 1.2530807256698608
test loss item: 0.9615751504898071
test loss item: 1.4807672500610352
test loss item: 0.32790207862854004
test loss item: 0.32940152287483215
test loss item: 0.204376220703125
test loss item: 0.20055340230464935
test loss item: 0.25986024737358093
Epoch [7/100], Training Loss: 0.6399, Testing Loss: 0.5389
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6005350351333618
1
train loss item: 1.5514355897903442
2
train loss item: 0.3006862998008728
3
train loss item: 0.7503088712692261
4
train loss item: 0.5332026481628418
5
train loss item: 0.4506199359893799
6
train loss item: 0.33452343940734863
7
train loss item: 1.0390982627868652
8
train loss item: 0.2612323462963104
9
train loss item: 0.3621290922164917
10
train loss item: 0.4872727692127228
11
train loss item: 0.3368585407733917
12
train loss item: 0.2147115021944046
13
train loss item: 0.6922715306282043
14
train loss item: 0.4084062874317169
15
train loss item: 0.8324126601219177
16
train loss item: 0.18377695977687836
17
train loss item: 0.41638991236686707
18
train loss item: 0.4313204288482666
19
train loss item: 0.34050583839416504
20
train loss item: 0.28871989250183105
21
train loss item: 0.28100109100341797
22
train loss item: 1.196636438369751
23
train loss item: 1.130042552947998
24
train loss item: 0.64091956615448
25
train loss item: 0.3553757965564728
26
train loss item: 0.2989475131034851
27
train loss item: 0.41955286264419556
28
train loss item: 0.181097149848938
29
train loss item: 0.9636754989624023
30
train loss item: 2.667633295059204
31
train loss item: 0.7108197808265686
32
train loss item: 0.2119992971420288
33
train loss item: 0.5540957450866699
34
train loss item: 0.34873494505882263
35
train loss item: 2.722177743911743
36
train loss item: 0.6042764782905579
37
train loss item: 0.3363940119743347
38
train loss item: 0.5467432141304016
39
train loss item: 0.42083466053009033
40
train loss item: 0.26340165734291077
41
train loss item: 0.40876612067222595
42
train loss item: 0.29846152663230896
43
train loss item: 0.26552045345306396
44
train loss item: 0.9126308560371399
45
train loss item: 0.2240470051765442
46
train loss item: 0.23971202969551086
47
train loss item: 0.4315193295478821
48
train loss item: 0.3436274826526642
49
train loss item: 0.31174206733703613
50
train loss item: 0.3491704761981964
51
train loss item: 1.1253582239151
52
train loss item: 0.200222447514534
53
train loss item: 0.3259042203426361
54
train loss item: 2.599846601486206
55
train loss item: 0.26549211144447327
56
train loss item: 0.39387747645378113
57
train loss item: 0.3249340057373047
58
train loss item: 0.24916549026966095
59
train loss item: 0.22602930665016174
60
train loss item: 1.139011263847351
61
train loss item: 2.5696566104888916
62
train loss item: 0.31132686138153076
63
train loss item: 0.3979695439338684
64
train loss item: 0.2307855784893036
65
train loss item: 0.6810782551765442
66
train loss item: 0.46563515067100525
67
train loss item: 0.3277639150619507
68
train loss item: 0.36771178245544434
69
train loss item: 0.4009914994239807
70
train loss item: 0.3744887113571167
71
train loss item: 0.2382773756980896
72
train loss item: 0.2837296426296234
73
train loss item: 0.3862657845020294
74
train loss item: 0.24189673364162445
75
train loss item: 0.2092791646718979
76
train loss item: 1.0974056720733643
77
train loss item: 1.4893975257873535
78
train loss item: 0.18096472322940826
79
train loss item: 0.31747496128082275
80
train loss item: 0.22049176692962646
81
train loss item: 0.2882404923439026
82
train loss item: 0.3403073847293854
83
train loss item: 0.7820855975151062
84
train loss item: 0.40775540471076965
85
train loss item: 0.7709012627601624
86
train loss item: 4.7397589683532715
87
train loss item: 0.32996097207069397
88
train loss item: 0.3938354551792145
epoch train loss: 0.6196769936366028
testing phase
test loss item: 0.24664191901683807
test loss item: 0.21502646803855896
test loss item: 0.7236920595169067
test loss item: 0.3011724352836609
test loss item: 0.38219791650772095
test loss item: 0.26222193241119385
test loss item: 1.6663777828216553
test loss item: 0.513744592666626
test loss item: 0.289548397064209
test loss item: 0.46857959032058716
test loss item: 1.129069447517395
test loss item: 0.21964554488658905
test loss item: 0.2255939543247223
test loss item: 0.3554159700870514
test loss item: 0.271467924118042
test loss item: 0.16800333559513092
test loss item: 0.32425421476364136
test loss item: 0.5946148037910461
test loss item: 0.7147129774093628
test loss item: 0.3179295063018799
test loss item: 0.9588596820831299
test loss item: 0.40579938888549805
test loss item: 0.4308619797229767
test loss item: 0.23743177950382233
test loss item: 0.2908378839492798
test loss item: 0.28787317872047424
test loss item: 0.38961929082870483
test loss item: 0.2988411784172058
test loss item: 0.4112653136253357
test loss item: 0.4065406322479248
test loss item: 0.9504793286323547
test loss item: 0.14757773280143738
test loss item: 0.23262788355350494
test loss item: 0.7091859579086304
test loss item: 0.5548900961875916
test loss item: 0.5682107210159302
test loss item: 0.8592382073402405
test loss item: 1.9178292751312256
test loss item: 0.595458447933197
test loss item: 0.34999871253967285
test loss item: 0.34007593989372253
test loss item: 0.30612826347351074
test loss item: 0.4736967086791992
test loss item: 0.26281997561454773
test loss item: 0.7755277752876282
test loss item: 0.45211219787597656
test loss item: 0.42043375968933105
test loss item: 0.31317880749702454
test loss item: 0.5690016150474548
test loss item: 0.8462586998939514
test loss item: 0.3974609673023224
test loss item: 0.20326028764247894
test loss item: 0.3090575635433197
test loss item: 0.26142776012420654
test loss item: 0.40613386034965515
test loss item: 1.106000542640686
test loss item: 0.6547552347183228
test loss item: 0.4023006856441498
test loss item: 0.2969154417514801
test loss item: 0.27714264392852783
test loss item: 0.5277537107467651
test loss item: 0.24254511296749115
test loss item: 0.26397958397865295
test loss item: 0.2910301983356476
test loss item: 1.06386137008667
test loss item: 0.38496270775794983
test loss item: 0.35274308919906616
test loss item: 0.31125450134277344
test loss item: 0.6957356333732605
test loss item: 0.5307685136795044
test loss item: 0.1623942106962204
test loss item: 0.9160824418067932
test loss item: 0.3774813115596771
test loss item: 0.40231260657310486
test loss item: 0.22766444087028503
test loss item: 0.29774338006973267
test loss item: 0.2321077138185501
test loss item: 2.0338950157165527
test loss item: 0.5312429070472717
test loss item: 0.29751288890838623
test loss item: 0.15327829122543335
test loss item: 1.2095121145248413
test loss item: 0.9550616145133972
test loss item: 1.4018468856811523
test loss item: 0.30933329463005066
test loss item: 0.32419922947883606
test loss item: 0.19147741794586182
test loss item: 0.17540690302848816
test loss item: 0.2703246474266052
Epoch [8/100], Training Loss: 0.6197, Testing Loss: 0.5011
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5743954181671143
1
train loss item: 1.4916267395019531
2
train loss item: 0.27790725231170654
3
train loss item: 0.7140593528747559
4
train loss item: 0.49876686930656433
5
train loss item: 0.4275818169116974
6
train loss item: 0.306278258562088
7
train loss item: 1.003696322441101
8
train loss item: 0.233316108584404
9
train loss item: 0.34300264716148376
10
train loss item: 0.46609407663345337
11
train loss item: 0.33860132098197937
12
train loss item: 0.20459496974945068
13
train loss item: 0.6516890525817871
14
train loss item: 0.3909648656845093
15
train loss item: 0.7942982912063599
16
train loss item: 0.16891592741012573
17
train loss item: 0.3754238784313202
18
train loss item: 0.40834012627601624
19
train loss item: 0.3302743136882782
20
train loss item: 0.2852264940738678
21
train loss item: 0.23983778059482574
22
train loss item: 1.1512608528137207
23
train loss item: 1.099772572517395
24
train loss item: 0.6158661246299744
25
train loss item: 0.3123924434185028
26
train loss item: 0.27463477849960327
27
train loss item: 0.3966401219367981
28
train loss item: 0.16410569846630096
29
train loss item: 0.9174605011940002
30
train loss item: 2.614682674407959
31
train loss item: 0.6719673275947571
32
train loss item: 0.20240092277526855
33
train loss item: 0.5133413076400757
34
train loss item: 0.29952138662338257
35
train loss item: 2.682870626449585
36
train loss item: 0.5726163387298584
37
train loss item: 0.3360234200954437
38
train loss item: 0.5089361071586609
39
train loss item: 0.39433014392852783
40
train loss item: 0.22762982547283173
41
train loss item: 0.3863799273967743
42
train loss item: 0.2908063530921936
43
train loss item: 0.24107900261878967
44
train loss item: 0.877792239189148
45
train loss item: 0.20571935176849365
46
train loss item: 0.21620884537696838
47
train loss item: 0.4042266309261322
48
train loss item: 0.3132947087287903
49
train loss item: 0.2678401470184326
50
train loss item: 0.34227150678634644
51
train loss item: 1.0801708698272705
52
train loss item: 0.1831454187631607
53
train loss item: 0.2618120014667511
54
train loss item: 2.561413288116455
55
train loss item: 0.24399928748607635
56
train loss item: 0.3725316524505615
57
train loss item: 0.3198336064815521
58
train loss item: 0.2319193035364151
59
train loss item: 0.2155981808900833
60
train loss item: 1.0776489973068237
61
train loss item: 2.524946689605713
62
train loss item: 0.29267480969429016
63
train loss item: 0.39422693848609924
64
train loss item: 0.21531882882118225
65
train loss item: 0.6449991464614868
66
train loss item: 0.45068392157554626
67
train loss item: 0.3019859790802002
68
train loss item: 0.35489845275878906
69
train loss item: 0.38172784447669983
70
train loss item: 0.33799639344215393
71
train loss item: 0.21700140833854675
72
train loss item: 0.2585693299770355
73
train loss item: 0.36577698588371277
74
train loss item: 0.1993708610534668
75
train loss item: 0.19013698399066925
76
train loss item: 1.0623209476470947
77
train loss item: 1.4598063230514526
78
train loss item: 0.17003242671489716
79
train loss item: 0.31991639733314514
80
train loss item: 0.20348985493183136
81
train loss item: 0.25250622630119324
82
train loss item: 0.30849921703338623
83
train loss item: 0.7397314310073853
84
train loss item: 0.388505756855011
85
train loss item: 0.7360994815826416
86
train loss item: 4.689479351043701
87
train loss item: 0.26612716913223267
88
train loss item: 0.3776043951511383
epoch train loss: 0.5919041564960158
testing phase
test loss item: 0.2374350130558014
test loss item: 0.204989954829216
test loss item: 0.6638544797897339
test loss item: 0.2869490087032318
test loss item: 0.348295658826828
test loss item: 0.23729656636714935
test loss item: 1.6404938697814941
test loss item: 0.5504173040390015
test loss item: 0.27005258202552795
test loss item: 0.4351678192615509
test loss item: 1.0920649766921997
test loss item: 0.22052595019340515
test loss item: 0.21198345720767975
test loss item: 0.3387492597103119
test loss item: 0.24627642333507538
test loss item: 0.17498961091041565
test loss item: 0.3203371465206146
test loss item: 0.533289909362793
test loss item: 0.7220916748046875
test loss item: 0.29822301864624023
test loss item: 0.848271906375885
test loss item: 0.40806519985198975
test loss item: 0.3575718104839325
test loss item: 0.22678734362125397
test loss item: 0.27688032388687134
test loss item: 0.2795330882072449
test loss item: 0.3735771179199219
test loss item: 0.273692786693573
test loss item: 0.3873918056488037
test loss item: 0.3808150887489319
test loss item: 0.9183586835861206
test loss item: 0.13679702579975128
test loss item: 0.21988962590694427
test loss item: 0.6588415503501892
test loss item: 0.5039399862289429
test loss item: 0.5445810556411743
test loss item: 0.8568220734596252
test loss item: 1.8267126083374023
test loss item: 0.5543065071105957
test loss item: 0.33256134390830994
test loss item: 0.33095723390579224
test loss item: 0.26222553849220276
test loss item: 0.42625799775123596
test loss item: 0.25707700848579407
test loss item: 0.694802463054657
test loss item: 0.4406060576438904
test loss item: 0.35480761528015137
test loss item: 0.27570146322250366
test loss item: 0.5318006277084351
test loss item: 0.8268119692802429
test loss item: 0.35652580857276917
test loss item: 0.17673684656620026
test loss item: 0.28669947385787964
test loss item: 0.2484801858663559
test loss item: 0.3621397018432617
test loss item: 1.0510272979736328
test loss item: 0.6378564238548279
test loss item: 0.3073435425758362
test loss item: 0.2734279930591583
test loss item: 0.2589291036128998
test loss item: 0.4817594289779663
test loss item: 0.25409042835235596
test loss item: 0.25339192152023315
test loss item: 0.2826824486255646
test loss item: 0.9994363784790039
test loss item: 0.36520349979400635
test loss item: 0.33251869678497314
test loss item: 0.3075465261936188
test loss item: 0.6540760397911072
test loss item: 0.5299025177955627
test loss item: 0.16828753054141998
test loss item: 0.9232310056686401
test loss item: 0.3201812505722046
test loss item: 0.39648279547691345
test loss item: 0.22276689112186432
test loss item: 0.25015583634376526
test loss item: 0.22374768555164337
test loss item: 1.914823055267334
test loss item: 0.49858883023262024
test loss item: 0.2749374508857727
test loss item: 0.15843002498149872
test loss item: 1.171126365661621
test loss item: 0.9418053030967712
test loss item: 1.330901861190796
test loss item: 0.2835186719894409
test loss item: 0.31664368510246277
test loss item: 0.1920916885137558
test loss item: 0.17714186012744904
test loss item: 0.2690761387348175
Epoch [9/100], Training Loss: 0.5919, Testing Loss: 0.4748
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5508936643600464
1
train loss item: 1.4480639696121216
2
train loss item: 0.26590055227279663
3
train loss item: 0.6869901418685913
4
train loss item: 0.4862743318080902
5
train loss item: 0.41420409083366394
6
train loss item: 0.2989979684352875
7
train loss item: 0.9726355075836182
8
train loss item: 0.19978362321853638
9
train loss item: 0.3225676417350769
10
train loss item: 0.44241952896118164
11
train loss item: 0.33469992876052856
12
train loss item: 0.19037111103534698
13
train loss item: 0.6139525175094604
14
train loss item: 0.38179734349250793
15
train loss item: 0.7639994025230408
16
train loss item: 0.15268348157405853
17
train loss item: 0.325615793466568
18
train loss item: 0.391751229763031
19
train loss item: 0.32109349966049194
20
train loss item: 0.28855350613594055
21
train loss item: 0.1993803083896637
22
train loss item: 1.1175400018692017
23
train loss item: 1.0761607885360718
24
train loss item: 0.5969193577766418
25
train loss item: 0.263967901468277
26
train loss item: 0.24954138696193695
27
train loss item: 0.37520501017570496
28
train loss item: 0.14764048159122467
29
train loss item: 0.8792175650596619
30
train loss item: 2.5720536708831787
31
train loss item: 0.6389164924621582
32
train loss item: 0.18089191615581512
33
train loss item: 0.4808811545372009
34
train loss item: 0.25813862681388855
35
train loss item: 2.648876905441284
36
train loss item: 0.5435669422149658
37
train loss item: 0.3407854437828064
38
train loss item: 0.483424574136734
39
train loss item: 0.36770960688591003
40
train loss item: 0.20145295560359955
41
train loss item: 0.36625486612319946
42
train loss item: 0.28494200110435486
43
train loss item: 0.22571198642253876
44
train loss item: 0.8441744446754456
45
train loss item: 0.19139669835567474
46
train loss item: 0.20340484380722046
47
train loss item: 0.38348519802093506
48
train loss item: 0.28934791684150696
49
train loss item: 0.2280598133802414
50
train loss item: 0.34039679169654846
51
train loss item: 1.0428266525268555
52
train loss item: 0.16741597652435303
53
train loss item: 0.20739056169986725
54
train loss item: 2.5289976596832275
55
train loss item: 0.24627482891082764
56
train loss item: 0.35215142369270325
57
train loss item: 0.32916975021362305
58
train loss item: 0.21596363186836243
59
train loss item: 0.20892031490802765
60
train loss item: 1.0325493812561035
61
train loss item: 2.4843223094940186
62
train loss item: 0.27146753668785095
63
train loss item: 0.3972403407096863
64
train loss item: 0.20149779319763184
65
train loss item: 0.610788106918335
66
train loss item: 0.4359866678714752
67
train loss item: 0.27898016571998596
68
train loss item: 0.3364366590976715
69
train loss item: 0.3648364543914795
70
train loss item: 0.29800036549568176
71
train loss item: 0.19887591898441315
72
train loss item: 0.23473364114761353
73
train loss item: 0.3461650013923645
74
train loss item: 0.1583653837442398
75
train loss item: 0.17535030841827393
76
train loss item: 1.0354362726211548
77
train loss item: 1.438515543937683
78
train loss item: 0.15701203048229218
79
train loss item: 0.3261179029941559
80
train loss item: 0.19260744750499725
81
train loss item: 0.23409849405288696
82
train loss item: 0.28284701704978943
83
train loss item: 0.7068325281143188
84
train loss item: 0.371254563331604
85
train loss item: 0.7038127779960632
86
train loss item: 4.645908832550049
87
train loss item: 0.21204747259616852
88
train loss item: 0.370811402797699
epoch train loss: 0.5689292540041249
testing phase
test loss item: 0.2272849678993225
test loss item: 0.20338794589042664
test loss item: 0.6205271482467651
test loss item: 0.318146675825119
test loss item: 0.32119715213775635
test loss item: 0.21336260437965393
test loss item: 1.6092668771743774
test loss item: 0.5722198486328125
test loss item: 0.2576253414154053
test loss item: 0.42084845900535583
test loss item: 1.0494475364685059
test loss item: 0.2800818383693695
test loss item: 0.21884198486804962
test loss item: 0.3316322863101959
test loss item: 0.2283218502998352
test loss item: 0.19804970920085907
test loss item: 0.3212909400463104
test loss item: 0.4970603585243225
test loss item: 0.7177485227584839
test loss item: 0.2939162254333496
test loss item: 0.7877835631370544
test loss item: 0.44286710023880005
test loss item: 0.32607555389404297
test loss item: 0.21721217036247253
test loss item: 0.27033063769340515
test loss item: 0.26824086904525757
test loss item: 0.36257240176200867
test loss item: 0.2537863552570343
test loss item: 0.3705706000328064
test loss item: 0.37308165431022644
test loss item: 0.884648859500885
test loss item: 0.1620720624923706
test loss item: 0.20786456763744354
test loss item: 0.6470438241958618
test loss item: 0.47367697954177856
test loss item: 0.5441855192184448
test loss item: 0.8496650457382202
test loss item: 1.737194299697876
test loss item: 0.5440074801445007
test loss item: 0.3173810839653015
test loss item: 0.3282066285610199
test loss item: 0.25413253903388977
test loss item: 0.4016309976577759
test loss item: 0.2986319065093994
test loss item: 0.6502663493156433
test loss item: 0.44802579283714294
test loss item: 0.3331123888492584
test loss item: 0.2585006058216095
test loss item: 0.5106247663497925
test loss item: 0.8024330735206604
test loss item: 0.33572646975517273
test loss item: 0.1750064492225647
test loss item: 0.2707447111606598
test loss item: 0.3411376178264618
test loss item: 0.3334020674228668
test loss item: 0.9987852573394775
test loss item: 0.6283557415008545
test loss item: 0.2669852375984192
test loss item: 0.2625662386417389
test loss item: 0.25200918316841125
test loss item: 0.46164005994796753
test loss item: 0.2737477719783783
test loss item: 0.24352115392684937
test loss item: 0.2855801284313202
test loss item: 0.9383442997932434
test loss item: 0.43249285221099854
test loss item: 0.3271367847919464
test loss item: 0.30482470989227295
test loss item: 0.62424236536026
test loss item: 0.5150288343429565
test loss item: 0.18096166849136353
test loss item: 0.9252745509147644
test loss item: 0.29508453607559204
test loss item: 0.3944634795188904
test loss item: 0.21898196637630463
test loss item: 0.24053868651390076
test loss item: 0.2157016396522522
test loss item: 1.8007031679153442
test loss item: 0.4766644835472107
test loss item: 0.25504541397094727
test loss item: 0.15885761380195618
test loss item: 1.1276463270187378
test loss item: 0.9254928827285767
test loss item: 1.261329174041748
test loss item: 0.25902259349823
test loss item: 0.30183276534080505
test loss item: 0.19566300511360168
test loss item: 0.19488726556301117
test loss item: 0.2460114061832428
Epoch [10/100], Training Loss: 0.5689, Testing Loss: 0.4626
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 11/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5346777439117432
1
train loss item: 1.4106807708740234
2
train loss item: 0.2602550685405731
3
train loss item: 0.6625857353210449
4
train loss item: 0.4789712131023407
5
train loss item: 0.41144847869873047
6
train loss item: 0.2935319244861603
7
train loss item: 0.9448906779289246
8
train loss item: 0.19270770251750946
9
train loss item: 0.311654269695282
10
train loss item: 0.4252462685108185
11
train loss item: 0.3259658217430115
12
train loss item: 0.17791089415550232
13
train loss item: 0.5911469459533691
14
train loss item: 0.376517653465271
15
train loss item: 0.7431761026382446
16
train loss item: 0.14155052602291107
17
train loss item: 0.299151211977005
18
train loss item: 0.38288792967796326
19
train loss item: 0.31488484144210815
20
train loss item: 0.28488585352897644
21
train loss item: 0.17724648118019104
22
train loss item: 1.086606502532959
23
train loss item: 1.0569888353347778
24
train loss item: 0.5801804661750793
25
train loss item: 0.2464776486158371
26
train loss item: 0.24067924916744232
27
train loss item: 0.3559446930885315
28
train loss item: 0.14140085875988007
29
train loss item: 0.8501297831535339
30
train loss item: 2.528212070465088
31
train loss item: 0.6223792433738708
32
train loss item: 0.1644730567932129
33
train loss item: 0.4644816517829895
34
train loss item: 0.23012684285640717
35
train loss item: 2.6139113903045654
36
train loss item: 0.5235388875007629
37
train loss item: 0.3482149839401245
38
train loss item: 0.4761417806148529
39
train loss item: 0.3441483676433563
40
train loss item: 0.20465904474258423
41
train loss item: 0.3532889187335968
42
train loss item: 0.28311336040496826
43
train loss item: 0.22281910479068756
44
train loss item: 0.816307783126831
45
train loss item: 0.1832820177078247
46
train loss item: 0.19921737909317017
47
train loss item: 0.37884753942489624
48
train loss item: 0.2811490297317505
49
train loss item: 0.214413121342659
50
train loss item: 0.33820822834968567
51
train loss item: 1.0109350681304932
52
train loss item: 0.1659216284751892
53
train loss item: 0.19522225856781006
54
train loss item: 2.4947662353515625
55
train loss item: 0.2489798367023468
56
train loss item: 0.33846768736839294
57
train loss item: 0.3368053436279297
58
train loss item: 0.20802602171897888
59
train loss item: 0.20775139331817627
60
train loss item: 0.9988077282905579
61
train loss item: 2.4445865154266357
62
train loss item: 0.2618447244167328
63
train loss item: 0.39173707365989685
64
train loss item: 0.19773055613040924
65
train loss item: 0.5843738317489624
66
train loss item: 0.4263222813606262
67
train loss item: 0.2656988203525543
68
train loss item: 0.31875157356262207
69
train loss item: 0.35711610317230225
70
train loss item: 0.28431791067123413
71
train loss item: 0.1842103749513626
72
train loss item: 0.23466195166110992
73
train loss item: 0.3391789197921753
74
train loss item: 0.151005357503891
75
train loss item: 0.16772949695587158
76
train loss item: 1.0139271020889282
77
train loss item: 1.4143823385238647
78
train loss item: 0.14576494693756104
79
train loss item: 0.32379022240638733
80
train loss item: 0.18112219870090485
81
train loss item: 0.2577565312385559
82
train loss item: 0.2725377082824707
83
train loss item: 0.6811457872390747
84
train loss item: 0.36514076590538025
85
train loss item: 0.6760604977607727
86
train loss item: 4.599111557006836
87
train loss item: 0.20130428671836853
88
train loss item: 0.3710324764251709
epoch train loss: 0.5551611355851206
testing phase
test loss item: 0.20947614312171936
test loss item: 0.18972431123256683
test loss item: 0.5876334309577942
test loss item: 0.3333742618560791
test loss item: 0.29524311423301697
test loss item: 0.18569415807724
test loss item: 1.5645729303359985
test loss item: 0.5651399493217468
test loss item: 0.2481924146413803
test loss item: 0.41715648770332336
test loss item: 0.9941172003746033
test loss item: 0.3141297996044159
test loss item: 0.22663743793964386
test loss item: 0.32814428210258484
test loss item: 0.21050433814525604
test loss item: 0.19601358473300934
test loss item: 0.3133164942264557
test loss item: 0.4779893159866333
test loss item: 0.6971263289451599
test loss item: 0.2884930670261383
test loss item: 0.757662832736969
test loss item: 0.45840463042259216
test loss item: 0.30502331256866455
test loss item: 0.20271462202072144
test loss item: 0.2634202241897583
test loss item: 0.25667476654052734
test loss item: 0.3521999716758728
test loss item: 0.23391041159629822
test loss item: 0.3558630347251892
test loss item: 0.37490513920783997
test loss item: 0.8428052663803101
test loss item: 0.17162160575389862
test loss item: 0.18983030319213867
test loss item: 0.6378099918365479
test loss item: 0.45352181792259216
test loss item: 0.5366722345352173
test loss item: 0.830225944519043
test loss item: 1.6403459310531616
test loss item: 0.5397837162017822
test loss item: 0.30220744013786316
test loss item: 0.32448166608810425
test loss item: 0.23582734167575836
test loss item: 0.3812659680843353
test loss item: 0.320247620344162
test loss item: 0.626875102519989
test loss item: 0.44476884603500366
test loss item: 0.3164122998714447
test loss item: 0.25194767117500305
test loss item: 0.4957166016101837
test loss item: 0.7709066867828369
test loss item: 0.33045461773872375
test loss item: 0.18276014924049377
test loss item: 0.25967779755592346
test loss item: 0.3888281285762787
test loss item: 0.31967395544052124
test loss item: 0.9471473693847656
test loss item: 0.6097491979598999
test loss item: 0.2554856240749359
test loss item: 0.25365737080574036
test loss item: 0.25099119544029236
test loss item: 0.45561814308166504
test loss item: 0.27630436420440674
test loss item: 0.23038716614246368
test loss item: 0.2913392186164856
test loss item: 0.872759222984314
test loss item: 0.4710990786552429
test loss item: 0.3232811689376831
test loss item: 0.29708537459373474
test loss item: 0.5970025062561035
test loss item: 0.482783704996109
test loss item: 0.17296947538852692
test loss item: 0.9107962250709534
test loss item: 0.2838728427886963
test loss item: 0.3894382417201996
test loss item: 0.19814233481884003
test loss item: 0.2213549017906189
test loss item: 0.20242351293563843
test loss item: 1.6766092777252197
test loss item: 0.4572284519672394
test loss item: 0.23041820526123047
test loss item: 0.14315074682235718
test loss item: 1.0680073499679565
test loss item: 0.8982592225074768
test loss item: 1.179215669631958
test loss item: 0.24219155311584473
test loss item: 0.2732776403427124
test loss item: 0.17681685090065002
test loss item: 0.18661221861839294
test loss item: 0.21832279860973358
Epoch [11/100], Training Loss: 0.5552, Testing Loss: 0.4465
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 12/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5201162695884705
1
train loss item: 1.3715088367462158
2
train loss item: 0.24862895905971527
3
train loss item: 0.6377956867218018
4
train loss item: 0.4592893123626709
5
train loss item: 0.40052059292793274
6
train loss item: 0.27318274974823
7
train loss item: 0.9179098606109619
8
train loss item: 0.1908685564994812
9
train loss item: 0.2909826338291168
10
train loss item: 0.41053175926208496
11
train loss item: 0.3111651539802551
12
train loss item: 0.17082375288009644
13
train loss item: 0.5812366604804993
14
train loss item: 0.3585137724876404
15
train loss item: 0.717884361743927
16
train loss item: 0.13489140570163727
17
train loss item: 0.2911339998245239
18
train loss item: 0.3733762502670288
19
train loss item: 0.29454925656318665
20
train loss item: 0.26803988218307495
21
train loss item: 0.16406024992465973
22
train loss item: 1.052816390991211
23
train loss item: 1.036767840385437
24
train loss item: 0.5617807507514954
25
train loss item: 0.24803470075130463
26
train loss item: 0.23518501222133636
27
train loss item: 0.33571356534957886
28
train loss item: 0.13928160071372986
29
train loss item: 0.8208200931549072
30
train loss item: 2.4782602787017822
31
train loss item: 0.6179704666137695
32
train loss item: 0.1581811010837555
33
train loss item: 0.46273669600486755
34
train loss item: 0.20511645078659058
35
train loss item: 2.575108766555786
36
train loss item: 0.5085384845733643
37
train loss item: 0.34544920921325684
38
train loss item: 0.48043161630630493
39
train loss item: 0.32554391026496887
40
train loss item: 0.19924652576446533
41
train loss item: 0.3364950120449066
42
train loss item: 0.27233240008354187
43
train loss item: 0.21912337839603424
44
train loss item: 0.7923139929771423
45
train loss item: 0.17911586165428162
46
train loss item: 0.18517403304576874
47
train loss item: 0.37168338894844055
48
train loss item: 0.2697888910770416
49
train loss item: 0.20435592532157898
50
train loss item: 0.3225550651550293
51
train loss item: 0.9785789847373962
52
train loss item: 0.16445617377758026
53
train loss item: 0.196730375289917
54
train loss item: 2.454453229904175
55
train loss item: 0.23012444376945496
56
train loss item: 0.32424935698509216
57
train loss item: 0.3227161467075348
58
train loss item: 0.20272305607795715
59
train loss item: 0.19831804931163788
60
train loss item: 0.9684551358222961
61
train loss item: 2.4044084548950195
62
train loss item: 0.2546623945236206
63
train loss item: 0.3711026608943939
64
train loss item: 0.19975847005844116
65
train loss item: 0.5642712712287903
66
train loss item: 0.41902056336402893
67
train loss item: 0.2562393248081207
68
train loss item: 0.3040890395641327
69
train loss item: 0.3491828739643097
70
train loss item: 0.2784169912338257
71
train loss item: 0.17008984088897705
72
train loss item: 0.23669591546058655
73
train loss item: 0.3280535936355591
74
train loss item: 0.15113328397274017
75
train loss item: 0.16182070970535278
76
train loss item: 0.9919928908348083
77
train loss item: 1.3830137252807617
78
train loss item: 0.1382843554019928
79
train loss item: 0.30811187624931335
80
train loss item: 0.162911057472229
81
train loss item: 0.2637721598148346
82
train loss item: 0.2648991644382477
83
train loss item: 0.6558482646942139
84
train loss item: 0.3625625669956207
85
train loss item: 0.651979386806488
86
train loss item: 4.545409679412842
87
train loss item: 0.20324836671352386
88
train loss item: 0.3720775544643402
epoch train loss: 0.5406830647353376
testing phase
test loss item: 0.19487401843070984
test loss item: 0.16676440834999084
test loss item: 0.5578685402870178
test loss item: 0.31358450651168823
test loss item: 0.2730136215686798
test loss item: 0.16371256113052368
test loss item: 1.5120429992675781
test loss item: 0.5401291847229004
test loss item: 0.24053265154361725
test loss item: 0.41845372319221497
test loss item: 0.9268431067466736
test loss item: 0.2982148826122284
test loss item: 0.23069556057453156
test loss item: 0.32645612955093384
test loss item: 0.1954939365386963
test loss item: 0.16641740500926971
test loss item: 0.2999280095100403
test loss item: 0.4683588147163391
test loss item: 0.6697933673858643
test loss item: 0.281772643327713
test loss item: 0.7376391887664795
test loss item: 0.4405531883239746
test loss item: 0.2896375358104706
test loss item: 0.18882061541080475
test loss item: 0.25429901480674744
test loss item: 0.24992108345031738
test loss item: 0.34474489092826843
test loss item: 0.21719633042812347
test loss item: 0.34268665313720703
test loss item: 0.3868910074234009
test loss item: 0.7912535071372986
test loss item: 0.15182256698608398
test loss item: 0.1729832887649536
test loss item: 0.6131995320320129
test loss item: 0.4372357726097107
test loss item: 0.5165897011756897
test loss item: 0.8028428554534912
test loss item: 1.5291776657104492
test loss item: 0.5241377949714661
test loss item: 0.2902531027793884
test loss item: 0.31561169028282166
test loss item: 0.21444973349571228
test loss item: 0.365600049495697
test loss item: 0.3019711375236511
test loss item: 0.6118362545967102
test loss item: 0.4280623197555542
test loss item: 0.30107471346855164
test loss item: 0.2569841146469116
test loss item: 0.47893330454826355
test loss item: 0.7320478558540344
test loss item: 0.33322787284851074
test loss item: 0.20351335406303406
test loss item: 0.25374531745910645
test loss item: 0.36104893684387207
test loss item: 0.31660303473472595
test loss item: 0.891806423664093
test loss item: 0.5823186635971069
test loss item: 0.2644609212875366
test loss item: 0.2494506537914276
test loss item: 0.24930673837661743
test loss item: 0.46002328395843506
test loss item: 0.2631054222583771
test loss item: 0.21986135840415955
test loss item: 0.28894612193107605
test loss item: 0.8048508167266846
test loss item: 0.4466629922389984
test loss item: 0.3191763460636139
test loss item: 0.2844513952732086
test loss item: 0.5686696171760559
test loss item: 0.4458303153514862
test loss item: 0.14421552419662476
test loss item: 0.885934591293335
test loss item: 0.27836257219314575
test loss item: 0.38255974650382996
test loss item: 0.17332680523395538
test loss item: 0.19745030999183655
test loss item: 0.18937796354293823
test loss item: 1.5388202667236328
test loss item: 0.4413028955459595
test loss item: 0.2096356451511383
test loss item: 0.12049458175897598
test loss item: 0.9960830807685852
test loss item: 0.8626400232315063
test loss item: 1.081794023513794
test loss item: 0.23801839351654053
test loss item: 0.24572284519672394
test loss item: 0.14224837720394135
test loss item: 0.15340742468833923
test loss item: 0.2060813307762146
Epoch [12/100], Training Loss: 0.5407, Testing Loss: 0.4250
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 13/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5053532719612122
1
train loss item: 1.3293442726135254
2
train loss item: 0.24606667459011078
3
train loss item: 0.6140488982200623
4
train loss item: 0.4414489269256592
5
train loss item: 0.38087207078933716
6
train loss item: 0.2608255445957184
7
train loss item: 0.8915334939956665
8
train loss item: 0.1834997832775116
9
train loss item: 0.265426903963089
10
train loss item: 0.39800652861595154
11
train loss item: 0.3036733865737915
12
train loss item: 0.16942965984344482
13
train loss item: 0.5773353576660156
14
train loss item: 0.33576494455337524
15
train loss item: 0.6879717111587524
16
train loss item: 0.13066065311431885
17
train loss item: 0.2967621088027954
18
train loss item: 0.36347681283950806
19
train loss item: 0.2739619016647339
20
train loss item: 0.2545730471611023
21
train loss item: 0.1599932163953781
22
train loss item: 1.0220087766647339
23
train loss item: 1.0121419429779053
24
train loss item: 0.5455015301704407
25
train loss item: 0.24709172546863556
26
train loss item: 0.23420549929141998
27
train loss item: 0.3215292990207672
28
train loss item: 0.1346433013677597
29
train loss item: 0.7912208437919617
30
train loss item: 2.4223484992980957
31
train loss item: 0.6160619258880615
32
train loss item: 0.15822939574718475
33
train loss item: 0.46637341380119324
34
train loss item: 0.18843995034694672
35
train loss item: 2.533461809158325
36
train loss item: 0.4985262155532837
37
train loss item: 0.3425953984260559
38
train loss item: 0.4849840998649597
39
train loss item: 0.3137691915035248
40
train loss item: 0.18261206150054932
41
train loss item: 0.3204578757286072
42
train loss item: 0.2590152621269226
43
train loss item: 0.21518008410930634
44
train loss item: 0.7710758447647095
45
train loss item: 0.1764252781867981
46
train loss item: 0.17571984231472015
47
train loss item: 0.35621270537376404
48
train loss item: 0.2579304277896881
49
train loss item: 0.1979018747806549
50
train loss item: 0.3064740300178528
51
train loss item: 0.9463770389556885
52
train loss item: 0.1559796929359436
53
train loss item: 0.1945285052061081
54
train loss item: 2.4096899032592773
55
train loss item: 0.21304310858249664
56
train loss item: 0.3115324378013611
57
train loss item: 0.29829373955726624
58
train loss item: 0.19976036250591278
59
train loss item: 0.1819356381893158
60
train loss item: 0.940623939037323
61
train loss item: 2.363208770751953
62
train loss item: 0.252760648727417
63
train loss item: 0.3520413339138031
64
train loss item: 0.20218992233276367
65
train loss item: 0.5529670119285583
66
train loss item: 0.41593581438064575
67
train loss item: 0.2506016194820404
68
train loss item: 0.29676875472068787
69
train loss item: 0.33989080786705017
70
train loss item: 0.26567888259887695
71
train loss item: 0.166336327791214
72
train loss item: 0.22686180472373962
73
train loss item: 0.3131464719772339
74
train loss item: 0.14125844836235046
75
train loss item: 0.1557977944612503
76
train loss item: 0.9668840169906616
77
train loss item: 1.352170705795288
78
train loss item: 0.13490620255470276
79
train loss item: 0.296936959028244
80
train loss item: 0.15111462771892548
81
train loss item: 0.24082182347774506
82
train loss item: 0.26239532232284546
83
train loss item: 0.6328084468841553
84
train loss item: 0.3622977137565613
85
train loss item: 0.6305668950080872
86
train loss item: 4.485407829284668
87
train loss item: 0.19692546129226685
88
train loss item: 0.37589725852012634
epoch train loss: 0.5265001046858476
testing phase
test loss item: 0.19505299627780914
test loss item: 0.14854012429714203
test loss item: 0.5309597253799438
test loss item: 0.27444571256637573
test loss item: 0.26029953360557556
test loss item: 0.15551947057247162
test loss item: 1.4688917398452759
test loss item: 0.5128229260444641
test loss item: 0.23150527477264404
test loss item: 0.41690540313720703
test loss item: 0.8600106239318848
test loss item: 0.25075894594192505
test loss item: 0.22842292487621307
test loss item: 0.3284997344017029
test loss item: 0.18761727213859558
test loss item: 0.1316860467195511
test loss item: 0.29062607884407043
test loss item: 0.4639395773410797
test loss item: 0.6448777318000793
test loss item: 0.27665215730667114
test loss item: 0.7245231866836548
test loss item: 0.40679094195365906
test loss item: 0.2959994077682495
test loss item: 0.18017931282520294
test loss item: 0.2459794580936432
test loss item: 0.24548400938510895
test loss item: 0.3400025963783264
test loss item: 0.20935580134391785
test loss item: 0.33406862616539
test loss item: 0.3968541622161865
test loss item: 0.7408803105354309
test loss item: 0.12391898036003113
test loss item: 0.16275335848331451
test loss item: 0.582469642162323
test loss item: 0.4246782064437866
test loss item: 0.4913170039653778
test loss item: 0.7750113010406494
test loss item: 1.419425368309021
test loss item: 0.4999261498451233
test loss item: 0.2837224304676056
test loss item: 0.3067191541194916
test loss item: 0.21821564435958862
test loss item: 0.3613448143005371
test loss item: 0.2611400783061981
test loss item: 0.6024709343910217
test loss item: 0.41331323981285095
test loss item: 0.30791959166526794
test loss item: 0.2655867636203766
test loss item: 0.4591048061847687
test loss item: 0.6914046406745911
test loss item: 0.33335164189338684
test loss item: 0.22033901512622833
test loss item: 0.251816987991333
test loss item: 0.28554317355155945
test loss item: 0.31741243600845337
test loss item: 0.8377663493156433
test loss item: 0.555733859539032
test loss item: 0.3012143671512604
test loss item: 0.25077709555625916
test loss item: 0.24506285786628723
test loss item: 0.46640148758888245
test loss item: 0.24702951312065125
test loss item: 0.21814663708209991
test loss item: 0.2801499664783478
test loss item: 0.7487084865570068
test loss item: 0.384669691324234
test loss item: 0.3161320388317108
test loss item: 0.27386629581451416
test loss item: 0.5449265241622925
test loss item: 0.41715267300605774
test loss item: 0.11572400480508804
test loss item: 0.8639594316482544
test loss item: 0.28070706129074097
test loss item: 0.37934955954551697
test loss item: 0.1632365584373474
test loss item: 0.19716741144657135
test loss item: 0.18182246387004852
test loss item: 1.40938138961792
test loss item: 0.43528562784194946
test loss item: 0.20641028881072998
test loss item: 0.10679097473621368
test loss item: 0.9280533790588379
test loss item: 0.8264409899711609
test loss item: 0.9858759045600891
test loss item: 0.24384517967700958
test loss item: 0.23202846944332123
test loss item: 0.11449888348579407
test loss item: 0.11960478872060776
test loss item: 0.20023928582668304
Epoch [13/100], Training Loss: 0.5265, Testing Loss: 0.4058
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 14/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.49152871966362
1
train loss item: 1.2872766256332397
2
train loss item: 0.255955308675766
3
train loss item: 0.5890719890594482
4
train loss item: 0.4418350160121918
5
train loss item: 0.36348411440849304
6
train loss item: 0.26228320598602295
7
train loss item: 0.865871787071228
8
train loss item: 0.17656517028808594
9
train loss item: 0.2552987039089203
10
train loss item: 0.38741326332092285
11
train loss item: 0.30333438515663147
12
train loss item: 0.16985832154750824
13
train loss item: 0.5708497762680054
14
train loss item: 0.32071492075920105
15
train loss item: 0.6656275391578674
16
train loss item: 0.12766075134277344
17
train loss item: 0.29967162013053894
18
train loss item: 0.3567480742931366
19
train loss item: 0.2671735882759094
20
train loss item: 0.2562195062637329
21
train loss item: 0.15752263367176056
22
train loss item: 1.0029196739196777
23
train loss item: 0.9822925925254822
24
train loss item: 0.5370756387710571
25
train loss item: 0.24203656613826752
26
train loss item: 0.23312561213970184
27
train loss item: 0.3129969835281372
28
train loss item: 0.12803344428539276
29
train loss item: 0.7685827016830444
30
train loss item: 2.365861415863037
31
train loss item: 0.6077572703361511
32
train loss item: 0.15385545790195465
33
train loss item: 0.45995110273361206
34
train loss item: 0.18322336673736572
35
train loss item: 2.491635799407959
36
train loss item: 0.4922442138195038
37
train loss item: 0.3489290177822113
38
train loss item: 0.48161837458610535
39
train loss item: 0.30336734652519226
40
train loss item: 0.1750587671995163
41
train loss item: 0.3093925416469574
42
train loss item: 0.25330954790115356
43
train loss item: 0.21011973917484283
44
train loss item: 0.7504565715789795
45
train loss item: 0.17087247967720032
46
train loss item: 0.1744154840707779
47
train loss item: 0.343872994184494
48
train loss item: 0.2512780427932739
49
train loss item: 0.19502444565296173
50
train loss item: 0.30103838443756104
51
train loss item: 0.9189902544021606
52
train loss item: 0.1475543975830078
53
train loss item: 0.18869590759277344
54
train loss item: 2.3653404712677
55
train loss item: 0.2118685394525528
56
train loss item: 0.3017287850379944
57
train loss item: 0.2811538577079773
58
train loss item: 0.1973726749420166
59
train loss item: 0.1695534884929657
60
train loss item: 0.9162521958351135
61
train loss item: 2.3214099407196045
62
train loss item: 0.25991302728652954
63
train loss item: 0.34515973925590515
64
train loss item: 0.1961202770471573
65
train loss item: 0.5523598194122314
66
train loss item: 0.41468241810798645
67
train loss item: 0.2429104447364807
68
train loss item: 0.2972206473350525
69
train loss item: 0.33263951539993286
70
train loss item: 0.2558046281337738
71
train loss item: 0.1738659292459488
72
train loss item: 0.21162131428718567
73
train loss item: 0.3041399419307709
74
train loss item: 0.13468652963638306
75
train loss item: 0.14938059449195862
76
train loss item: 0.9392292499542236
77
train loss item: 1.3302559852600098
78
train loss item: 0.13300910592079163
79
train loss item: 0.29675909876823425
80
train loss item: 0.15299178659915924
81
train loss item: 0.21393729746341705
82
train loss item: 0.26196619868278503
83
train loss item: 0.6159602999687195
84
train loss item: 0.3663174510002136
85
train loss item: 0.6108761429786682
86
train loss item: 4.424276351928711
87
train loss item: 0.18770240247249603
88
train loss item: 0.3834528625011444
epoch train loss: 0.5158367434914193
testing phase
test loss item: 0.19725722074508667
test loss item: 0.13719405233860016
test loss item: 0.5118351578712463
test loss item: 0.24285322427749634
test loss item: 0.25512781739234924
test loss item: 0.15079821646213531
test loss item: 1.44297194480896
test loss item: 0.48363515734672546
test loss item: 0.22011421620845795
test loss item: 0.4078938663005829
test loss item: 0.8136628270149231
test loss item: 0.20781254768371582
test loss item: 0.217943474650383
test loss item: 0.3323858678340912
test loss item: 0.18277283012866974
test loss item: 0.10970078408718109
test loss item: 0.28575995564460754
test loss item: 0.4598122537136078
test loss item: 0.6219447255134583
test loss item: 0.27098557353019714
test loss item: 0.7161465287208557
test loss item: 0.3819137513637543
test loss item: 0.31265988945961
test loss item: 0.17403799295425415
test loss item: 0.2387729287147522
test loss item: 0.23943933844566345
test loss item: 0.33388152718544006
test loss item: 0.2060449868440628
test loss item: 0.32998692989349365
test loss item: 0.3912162482738495
test loss item: 0.7082080841064453
test loss item: 0.1064906045794487
test loss item: 0.15474259853363037
test loss item: 0.5612194538116455
test loss item: 0.41466382145881653
test loss item: 0.4685974419116974
test loss item: 0.7485137581825256
test loss item: 1.344523549079895
test loss item: 0.4797116219997406
test loss item: 0.280259370803833
test loss item: 0.30129897594451904
test loss item: 0.2296644151210785
test loss item: 0.36025458574295044
test loss item: 0.22775515913963318
test loss item: 0.5946293473243713
test loss item: 0.40626972913742065
test loss item: 0.3209633529186249
test loss item: 0.26237043738365173
test loss item: 0.4424408972263336
test loss item: 0.6608673334121704
test loss item: 0.3237851560115814
test loss item: 0.21518374979496002
test loss item: 0.24927349388599396
test loss item: 0.21711787581443787
test loss item: 0.3147410750389099
test loss item: 0.7995671629905701
test loss item: 0.5347685813903809
test loss item: 0.3223440945148468
test loss item: 0.2485910803079605
test loss item: 0.23912307620048523
test loss item: 0.4642432630062103
test loss item: 0.23550772666931152
test loss item: 0.21832796931266785
test loss item: 0.2723729908466339
test loss item: 0.7146522998809814
test loss item: 0.3336338996887207
test loss item: 0.3131745755672455
test loss item: 0.2686305344104767
test loss item: 0.5309615135192871
test loss item: 0.39606165885925293
test loss item: 0.10058379918336868
test loss item: 0.847646951675415
test loss item: 0.28259918093681335
test loss item: 0.38132715225219727
test loss item: 0.16050201654434204
test loss item: 0.20675773918628693
test loss item: 0.1772543042898178
test loss item: 1.325452208518982
test loss item: 0.43780988454818726
test loss item: 0.20987574756145477
test loss item: 0.09905147552490234
test loss item: 0.8810340166091919
test loss item: 0.7954299449920654
test loss item: 0.918520450592041
test loss item: 0.250367671251297
test loss item: 0.22677838802337646
test loss item: 0.09948474913835526
test loss item: 0.09934132546186447
test loss item: 0.19094383716583252
Epoch [14/100], Training Loss: 0.5158, Testing Loss: 0.3916
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 15/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47835320234298706
1
train loss item: 1.2498692274093628
2
train loss item: 0.25688058137893677
3
train loss item: 0.5633166432380676
4
train loss item: 0.4414224624633789
5
train loss item: 0.35124561190605164
6
train loss item: 0.26332563161849976
7
train loss item: 0.8409239053726196
8
train loss item: 0.16948102414608002
9
train loss item: 0.25645333528518677
10
train loss item: 0.3750241696834564
11
train loss item: 0.29804226756095886
12
train loss item: 0.1687658131122589
13
train loss item: 0.5571946501731873
14
train loss item: 0.30666226148605347
15
train loss item: 0.6535013318061829
16
train loss item: 0.12436453998088837
17
train loss item: 0.28802186250686646
18
train loss item: 0.35008788108825684
19
train loss item: 0.2650895416736603
20
train loss item: 0.26270440220832825
21
train loss item: 0.15119247138500214
22
train loss item: 0.9916755557060242
23
train loss item: 0.9517486691474915
24
train loss item: 0.5367067456245422
25
train loss item: 0.23601199686527252
26
train loss item: 0.22349131107330322
27
train loss item: 0.3006644546985626
28
train loss item: 0.12185530364513397
29
train loss item: 0.753485381603241
30
train loss item: 2.3171770572662354
31
train loss item: 0.5929251909255981
32
train loss item: 0.1474425494670868
33
train loss item: 0.44011256098747253
34
train loss item: 0.1772204339504242
35
train loss item: 2.4546010494232178
36
train loss item: 0.4842691123485565
37
train loss item: 0.3575940430164337
38
train loss item: 0.47563308477401733
39
train loss item: 0.28904008865356445
40
train loss item: 0.17937049269676208
41
train loss item: 0.2960847318172455
42
train loss item: 0.25066617131233215
43
train loss item: 0.20281004905700684
44
train loss item: 0.7288731932640076
45
train loss item: 0.16140985488891602
46
train loss item: 0.16340605914592743
47
train loss item: 0.34016820788383484
48
train loss item: 0.243598073720932
49
train loss item: 0.18491962552070618
50
train loss item: 0.300961971282959
51
train loss item: 0.8974137902259827
52
train loss item: 0.14168637990951538
53
train loss item: 0.1827872097492218
54
train loss item: 2.3277621269226074
55
train loss item: 0.21012872457504272
56
train loss item: 0.28924107551574707
57
train loss item: 0.2701060473918915
58
train loss item: 0.1955680400133133
59
train loss item: 0.16426126658916473
60
train loss item: 0.8934186697006226
61
train loss item: 2.282989978790283
62
train loss item: 0.2654604911804199
63
train loss item: 0.34444355964660645
64
train loss item: 0.18185386061668396
65
train loss item: 0.5558716654777527
66
train loss item: 0.4113875925540924
67
train loss item: 0.23125210404396057
68
train loss item: 0.30075880885124207
69
train loss item: 0.3263847827911377
70
train loss item: 0.25340354442596436
71
train loss item: 0.17898039519786835
72
train loss item: 0.20037205517292023
73
train loss item: 0.2999419569969177
74
train loss item: 0.14047932624816895
75
train loss item: 0.14419087767601013
76
train loss item: 0.9129742980003357
77
train loss item: 1.317050814628601
78
train loss item: 0.13130059838294983
79
train loss item: 0.2973787784576416
80
train loss item: 0.15615609288215637
81
train loss item: 0.20097237825393677
82
train loss item: 0.24996308982372284
83
train loss item: 0.6043196320533752
84
train loss item: 0.3708827495574951
85
train loss item: 0.5945149064064026
86
train loss item: 4.37116003036499
87
train loss item: 0.1843327134847641
88
train loss item: 0.39038729667663574
epoch train loss: 0.5061503769306654
testing phase
test loss item: 0.19177651405334473
test loss item: 0.13320690393447876
test loss item: 0.5060930252075195
test loss item: 0.2309299260377884
test loss item: 0.25520026683807373
test loss item: 0.1441093534231186
test loss item: 1.4247596263885498
test loss item: 0.44872790575027466
test loss item: 0.21371930837631226
test loss item: 0.39890730381011963
test loss item: 0.797954261302948
test loss item: 0.1905725747346878
test loss item: 0.2083340585231781
test loss item: 0.3375515639781952
test loss item: 0.18096515536308289
test loss item: 0.10392209142446518
test loss item: 0.28328919410705566
test loss item: 0.45672351121902466
test loss item: 0.5985924601554871
test loss item: 0.26995933055877686
test loss item: 0.709891676902771
test loss item: 0.37231194972991943
test loss item: 0.32173407077789307
test loss item: 0.1724214106798172
test loss item: 0.23393121361732483
test loss item: 0.2337387502193451
test loss item: 0.3292267918586731
test loss item: 0.20442689955234528
test loss item: 0.33041661977767944
test loss item: 0.37634900212287903
test loss item: 0.699207067489624
test loss item: 0.10111460834741592
test loss item: 0.15081144869327545
test loss item: 0.5542840361595154
test loss item: 0.40891847014427185
test loss item: 0.45499321818351746
test loss item: 0.7238370776176453
test loss item: 1.3228422403335571
test loss item: 0.47039783000946045
test loss item: 0.2788181006908417
test loss item: 0.2980211079120636
test loss item: 0.22545741498470306
test loss item: 0.3594639003276825
test loss item: 0.21514177322387695
test loss item: 0.5878111720085144
test loss item: 0.40318405628204346
test loss item: 0.32135912775993347
test loss item: 0.2544683516025543
test loss item: 0.4358992576599121
test loss item: 0.6491851806640625
test loss item: 0.3132479190826416
test loss item: 0.19610266387462616
test loss item: 0.2458324283361435
test loss item: 0.19092722237110138
test loss item: 0.3094936013221741
test loss item: 0.7861369848251343
test loss item: 0.5197607278823853
test loss item: 0.3094806671142578
test loss item: 0.2426033467054367
test loss item: 0.23612533509731293
test loss item: 0.4593222439289093
test loss item: 0.22894646227359772
test loss item: 0.2143322378396988
test loss item: 0.26951587200164795
test loss item: 0.6986029744148254
test loss item: 0.3141061067581177
test loss item: 0.3114025294780731
test loss item: 0.267607182264328
test loss item: 0.5278794765472412
test loss item: 0.37961700558662415
test loss item: 0.09955431520938873
test loss item: 0.8291621804237366
test loss item: 0.28711608052253723
test loss item: 0.38666728138923645
test loss item: 0.15835712850093842
test loss item: 0.20681022107601166
test loss item: 0.17702621221542358
test loss item: 1.3015788793563843
test loss item: 0.4446747601032257
test loss item: 0.2067803144454956
test loss item: 0.09495857357978821
test loss item: 0.8595606088638306
test loss item: 0.7738432288169861
test loss item: 0.8959629535675049
test loss item: 0.251783162355423
test loss item: 0.22475451231002808
test loss item: 0.09474386274814606
test loss item: 0.0919434130191803
test loss item: 0.1806633621454239
Epoch [15/100], Training Loss: 0.5062, Testing Loss: 0.3838
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 16/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.464773565530777
1
train loss item: 1.2196898460388184
2
train loss item: 0.2481204867362976
3
train loss item: 0.5436679720878601
4
train loss item: 0.4156726896762848
5
train loss item: 0.3412291705608368
6
train loss item: 0.26386362314224243
7
train loss item: 0.8190775513648987
8
train loss item: 0.15949735045433044
9
train loss item: 0.25497499108314514
10
train loss item: 0.36183494329452515
11
train loss item: 0.2878800630569458
12
train loss item: 0.1627093255519867
13
train loss item: 0.5400184988975525
14
train loss item: 0.2875291109085083
15
train loss item: 0.6400689482688904
16
train loss item: 0.11891990900039673
17
train loss item: 0.26867955923080444
18
train loss item: 0.34041619300842285
19
train loss item: 0.2630615532398224
20
train loss item: 0.2628956139087677
21
train loss item: 0.14635610580444336
22
train loss item: 0.973993718624115
23
train loss item: 0.9286383390426636
24
train loss item: 0.5369480848312378
25
train loss item: 0.22872407734394073
26
train loss item: 0.2110707014799118
27
train loss item: 0.28340551257133484
28
train loss item: 0.11611422151327133
29
train loss item: 0.7364981174468994
30
train loss item: 2.2786035537719727
31
train loss item: 0.5797721147537231
32
train loss item: 0.1477176696062088
33
train loss item: 0.4216180741786957
34
train loss item: 0.16465722024440765
35
train loss item: 2.425492763519287
36
train loss item: 0.4733029901981354
37
train loss item: 0.3650241792201996
38
train loss item: 0.47415292263031006
39
train loss item: 0.27226775884628296
40
train loss item: 0.18558090925216675
41
train loss item: 0.27926191687583923
42
train loss item: 0.24734976887702942
43
train loss item: 0.19614210724830627
44
train loss item: 0.7092707753181458
45
train loss item: 0.15330073237419128
46
train loss item: 0.1526465117931366
47
train loss item: 0.33892178535461426
48
train loss item: 0.23360513150691986
49
train loss item: 0.17176073789596558
50
train loss item: 0.30122533440589905
51
train loss item: 0.8789724707603455
52
train loss item: 0.13403373956680298
53
train loss item: 0.17667822539806366
54
train loss item: 2.300100564956665
55
train loss item: 0.20583517849445343
56
train loss item: 0.2746032774448395
57
train loss item: 0.26132825016975403
58
train loss item: 0.19335857033729553
59
train loss item: 0.1598283052444458
60
train loss item: 0.8709737062454224
61
train loss item: 2.251570701599121
62
train loss item: 0.2587108314037323
63
train loss item: 0.3440282642841339
64
train loss item: 0.1695864200592041
65
train loss item: 0.5520545244216919
66
train loss item: 0.40772855281829834
67
train loss item: 0.22132791578769684
68
train loss item: 0.29793524742126465
69
train loss item: 0.31982582807540894
70
train loss item: 0.25221070647239685
71
train loss item: 0.172990620136261
72
train loss item: 0.19297169148921967
73
train loss item: 0.2947462499141693
74
train loss item: 0.14189335703849792
75
train loss item: 0.13882076740264893
76
train loss item: 0.8927563428878784
77
train loss item: 1.3066387176513672
78
train loss item: 0.12756496667861938
79
train loss item: 0.2947693467140198
80
train loss item: 0.1510535478591919
81
train loss item: 0.19757451117038727
82
train loss item: 0.2310369461774826
83
train loss item: 0.5943210124969482
84
train loss item: 0.3741403818130493
85
train loss item: 0.5827512741088867
86
train loss item: 4.332095146179199
87
train loss item: 0.18268625438213348
88
train loss item: 0.39197009801864624
epoch train loss: 0.4958368237601237
testing phase
test loss item: 0.18397650122642517
test loss item: 0.13562947511672974
test loss item: 0.5139370560646057
test loss item: 0.2312324345111847
test loss item: 0.25812169909477234
test loss item: 0.13868825137615204
test loss item: 1.403923511505127
test loss item: 0.41844481229782104
test loss item: 0.21533256769180298
test loss item: 0.3957536518573761
test loss item: 0.8065636157989502
test loss item: 0.19244436919689178
test loss item: 0.2073315978050232
test loss item: 0.34080690145492554
test loss item: 0.182481586933136
test loss item: 0.10948388278484344
test loss item: 0.28269094228744507
test loss item: 0.4566081166267395
test loss item: 0.5795106291770935
test loss item: 0.27574893832206726
test loss item: 0.7063419818878174
test loss item: 0.3697092533111572
test loss item: 0.3251310884952545
test loss item: 0.17607340216636658
test loss item: 0.2328731268644333
test loss item: 0.22984686493873596
test loss item: 0.3278392553329468
test loss item: 0.20473146438598633
test loss item: 0.3328898251056671
test loss item: 0.3630716800689697
test loss item: 0.7057824730873108
test loss item: 0.10417871177196503
test loss item: 0.15299907326698303
test loss item: 0.5565313696861267
test loss item: 0.40885084867477417
test loss item: 0.4536132216453552
test loss item: 0.7046202421188354
test loss item: 1.3438667058944702
test loss item: 0.46917369961738586
test loss item: 0.27796366810798645
test loss item: 0.29531779885292053
test loss item: 0.21597209572792053
test loss item: 0.36147457361221313
test loss item: 0.21527034044265747
test loss item: 0.584181010723114
test loss item: 0.40012481808662415
test loss item: 0.3179818391799927
test loss item: 0.25194671750068665
test loss item: 0.43909841775894165
test loss item: 0.6531807780265808
test loss item: 0.30923470854759216
test loss item: 0.1787232607603073
test loss item: 0.2428516298532486
test loss item: 0.19375881552696228
test loss item: 0.30502021312713623
test loss item: 0.7932475209236145
test loss item: 0.5136035084724426
test loss item: 0.28138062357902527
test loss item: 0.23769061267375946
test loss item: 0.23789355158805847
test loss item: 0.45826148986816406
test loss item: 0.22572188079357147
test loss item: 0.2091565579175949
test loss item: 0.2707344591617584
test loss item: 0.6955534219741821
test loss item: 0.31250184774398804
test loss item: 0.3099532425403595
test loss item: 0.26804786920547485
test loss item: 0.5326263308525085
test loss item: 0.3717906177043915
test loss item: 0.1072002500295639
test loss item: 0.8062686920166016
test loss item: 0.3011566400527954
test loss item: 0.39108139276504517
test loss item: 0.15952658653259277
test loss item: 0.20715174078941345
test loss item: 0.18076983094215393
test loss item: 1.3238039016723633
test loss item: 0.4514056146144867
test loss item: 0.1995958536863327
test loss item: 0.09707459807395935
test loss item: 0.8583367466926575
test loss item: 0.7627687454223633
test loss item: 0.911523163318634
test loss item: 0.24670538306236267
test loss item: 0.22588354349136353
test loss item: 0.09888703376054764
test loss item: 0.0948033556342125
test loss item: 0.17294174432754517
Epoch [16/100], Training Loss: 0.4958, Testing Loss: 0.3826
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 17/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45122796297073364
1
train loss item: 1.1956967115402222
2
train loss item: 0.23951031267642975
3
train loss item: 0.5320448875427246
4
train loss item: 0.39336177706718445
5
train loss item: 0.3327711820602417
6
train loss item: 0.265445351600647
7
train loss item: 0.8026495575904846
8
train loss item: 0.14973831176757812
9
train loss item: 0.24897480010986328
10
train loss item: 0.35124948620796204
11
train loss item: 0.2792186141014099
12
train loss item: 0.15176494419574738
13
train loss item: 0.5249396562576294
14
train loss item: 0.26839056611061096
15
train loss item: 0.6223706603050232
16
train loss item: 0.11161541193723679
17
train loss item: 0.2534288763999939
18
train loss item: 0.32878249883651733
19
train loss item: 0.262153297662735
20
train loss item: 0.2554686665534973
21
train loss item: 0.14157521724700928
22
train loss item: 0.9473239779472351
23
train loss item: 0.9156344532966614
24
train loss item: 0.5309893488883972
25
train loss item: 0.21870490908622742
26
train loss item: 0.20479805767536163
27
train loss item: 0.2668428421020508
28
train loss item: 0.11010421067476273
29
train loss item: 0.7161588668823242
30
train loss item: 2.249130964279175
31
train loss item: 0.5715712904930115
32
train loss item: 0.14541202783584595
33
train loss item: 0.41627100110054016
34
train loss item: 0.15464098751544952
35
train loss item: 2.402010679244995
36
train loss item: 0.46226340532302856
37
train loss item: 0.37202492356300354
38
train loss item: 0.47440478205680847
39
train loss item: 0.2564306855201721
40
train loss item: 0.18679536879062653
41
train loss item: 0.26479387283325195
42
train loss item: 0.24579554796218872
43
train loss item: 0.1891847848892212
44
train loss item: 0.695274293422699
45
train loss item: 0.14999249577522278
46
train loss item: 0.15529337525367737
47
train loss item: 0.3347267806529999
48
train loss item: 0.22654132544994354
49
train loss item: 0.16314677894115448
50
train loss item: 0.2999195158481598
51
train loss item: 0.8616476655006409
52
train loss item: 0.1261640340089798
53
train loss item: 0.1714075803756714
54
train loss item: 2.27927827835083
55
train loss item: 0.20690032839775085
56
train loss item: 0.26236289739608765
57
train loss item: 0.2544708847999573
58
train loss item: 0.18498562276363373
59
train loss item: 0.15416096150875092
60
train loss item: 0.8502624034881592
61
train loss item: 2.2285356521606445
62
train loss item: 0.24060530960559845
63
train loss item: 0.34247860312461853
64
train loss item: 0.1632671058177948
65
train loss item: 0.5368908047676086
66
train loss item: 0.4043624997138977
67
train loss item: 0.21427148580551147
68
train loss item: 0.2858743369579315
69
train loss item: 0.31320497393608093
70
train loss item: 0.24749548733234406
71
train loss item: 0.1598307341337204
72
train loss item: 0.1887725293636322
73
train loss item: 0.2881968915462494
74
train loss item: 0.1311187744140625
75
train loss item: 0.13164761662483215
76
train loss item: 0.8797652721405029
77
train loss item: 1.295104742050171
78
train loss item: 0.11947903782129288
79
train loss item: 0.2909093499183655
80
train loss item: 0.13983331620693207
81
train loss item: 0.19541366398334503
82
train loss item: 0.21794867515563965
83
train loss item: 0.5833433866500854
84
train loss item: 0.3770499527454376
85
train loss item: 0.5739404559135437
86
train loss item: 4.302964210510254
87
train loss item: 0.1797940731048584
88
train loss item: 0.3863813281059265
epoch train loss: 0.48605259809266316
testing phase
test loss item: 0.1795479655265808
test loss item: 0.13809596002101898
test loss item: 0.5278609395027161
test loss item: 0.23533138632774353
test loss item: 0.2602735161781311
test loss item: 0.13624921441078186
test loss item: 1.3871464729309082
test loss item: 0.4086046516895294
test loss item: 0.21884764730930328
test loss item: 0.39607566595077515
test loss item: 0.8196797966957092
test loss item: 0.20172609388828278
test loss item: 0.2114972025156021
test loss item: 0.33692675828933716
test loss item: 0.1832006424665451
test loss item: 0.11691968142986298
test loss item: 0.28241488337516785
test loss item: 0.45856359601020813
test loss item: 0.5687587857246399
test loss item: 0.2807747423648834
test loss item: 0.7078200578689575
test loss item: 0.37008440494537354
test loss item: 0.32585692405700684
test loss item: 0.1791156530380249
test loss item: 0.23365706205368042
test loss item: 0.22641955316066742
test loss item: 0.3259553015232086
test loss item: 0.20516668260097504
test loss item: 0.3329736292362213
test loss item: 0.35421842336654663
test loss item: 0.713898777961731
test loss item: 0.11024224013090134
test loss item: 0.15585260093212128
test loss item: 0.5624617338180542
test loss item: 0.41229066252708435
test loss item: 0.45308616757392883
test loss item: 0.6949927806854248
test loss item: 1.3736852407455444
test loss item: 0.47143444418907166
test loss item: 0.27537375688552856
test loss item: 0.2925967276096344
test loss item: 0.2121889442205429
test loss item: 0.36497995257377625
test loss item: 0.21961109340190887
test loss item: 0.5847718119621277
test loss item: 0.3959158658981323
test loss item: 0.3185783326625824
test loss item: 0.25107866525650024
test loss item: 0.4466138780117035
test loss item: 0.6587359309196472
test loss item: 0.31022095680236816
test loss item: 0.16795580089092255
test loss item: 0.239997997879982
test loss item: 0.20686902105808258
test loss item: 0.30250322818756104
test loss item: 0.8045376539230347
test loss item: 0.5141324996948242
test loss item: 0.2602410316467285
test loss item: 0.23518268764019012
test loss item: 0.24124304950237274
test loss item: 0.4594094455242157
test loss item: 0.22532010078430176
test loss item: 0.2062033861875534
test loss item: 0.2732277810573578
test loss item: 0.7022639513015747
test loss item: 0.31774359941482544
test loss item: 0.3069411814212799
test loss item: 0.26703187823295593
test loss item: 0.5394853353500366
test loss item: 0.3659762740135193
test loss item: 0.11355007439851761
test loss item: 0.7899420857429504
test loss item: 0.317970871925354
test loss item: 0.39068344235420227
test loss item: 0.1621050089597702
test loss item: 0.21219678223133087
test loss item: 0.18271778523921967
test loss item: 1.3599411249160767
test loss item: 0.45254790782928467
test loss item: 0.1947246640920639
test loss item: 0.1001027300953865
test loss item: 0.8637527227401733
test loss item: 0.7588886022567749
test loss item: 0.9377596974372864
test loss item: 0.23732921481132507
test loss item: 0.2277631163597107
test loss item: 0.10412606596946716
test loss item: 0.10055729746818542
test loss item: 0.16884219646453857
Epoch [17/100], Training Loss: 0.4861, Testing Loss: 0.3843
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 18/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4390221834182739
1
train loss item: 1.1762453317642212
2
train loss item: 0.2345958799123764
3
train loss item: 0.5228735208511353
4
train loss item: 0.39249399304389954
5
train loss item: 0.32524147629737854
6
train loss item: 0.26304590702056885
7
train loss item: 0.789982259273529
8
train loss item: 0.14426620304584503
9
train loss item: 0.24288170039653778
10
train loss item: 0.34224626421928406
11
train loss item: 0.27271416783332825
12
train loss item: 0.14229124784469604
13
train loss item: 0.5123371481895447
14
train loss item: 0.2539372444152832
15
train loss item: 0.6071872711181641
16
train loss item: 0.10293794423341751
17
train loss item: 0.24624811112880707
18
train loss item: 0.3175336718559265
19
train loss item: 0.2606341540813446
20
train loss item: 0.2462848722934723
21
train loss item: 0.13717013597488403
22
train loss item: 0.9217588305473328
23
train loss item: 0.9074892401695251
24
train loss item: 0.520194947719574
25
train loss item: 0.2081928551197052
26
train loss item: 0.2028341144323349
27
train loss item: 0.2551409602165222
28
train loss item: 0.10253062099218369
29
train loss item: 0.6988943219184875
30
train loss item: 2.223565101623535
31
train loss item: 0.5653397440910339
32
train loss item: 0.1340428590774536
33
train loss item: 0.4202425181865692
34
train loss item: 0.15067636966705322
35
train loss item: 2.380751132965088
36
train loss item: 0.45251187682151794
37
train loss item: 0.3760129511356354
38
train loss item: 0.46846258640289307
39
train loss item: 0.24441485106945038
40
train loss item: 0.182725727558136
41
train loss item: 0.25552722811698914
42
train loss item: 0.24669769406318665
43
train loss item: 0.18372395634651184
44
train loss item: 0.685674250125885
45
train loss item: 0.1485981047153473
46
train loss item: 0.1583140641450882
47
train loss item: 0.3292545676231384
48
train loss item: 0.22390979528427124
49
train loss item: 0.15824958682060242
50
train loss item: 0.29572731256484985
51
train loss item: 0.8448977470397949
52
train loss item: 0.119322270154953
53
train loss item: 0.16920581459999084
54
train loss item: 2.2603232860565186
55
train loss item: 0.21063648164272308
56
train loss item: 0.2536093592643738
57
train loss item: 0.24745264649391174
58
train loss item: 0.1736958622932434
59
train loss item: 0.1497756391763687
60
train loss item: 0.8330999612808228
61
train loss item: 2.209712266921997
62
train loss item: 0.2195083051919937
63
train loss item: 0.33924436569213867
64
train loss item: 0.16354380548000336
65
train loss item: 0.519386887550354
66
train loss item: 0.39892205595970154
67
train loss item: 0.20854711532592773
68
train loss item: 0.27369093894958496
69
train loss item: 0.3070007562637329
70
train loss item: 0.24126222729682922
71
train loss item: 0.15029756724834442
72
train loss item: 0.19020900130271912
73
train loss item: 0.28319212794303894
74
train loss item: 0.11731366813182831
75
train loss item: 0.12652581930160522
76
train loss item: 0.870657205581665
77
train loss item: 1.28215754032135
78
train loss item: 0.10740377008914948
79
train loss item: 0.2854536473751068
80
train loss item: 0.1301664412021637
81
train loss item: 0.19290316104888916
82
train loss item: 0.21285326778888702
83
train loss item: 0.5707969069480896
84
train loss item: 0.37881115078926086
85
train loss item: 0.5651582479476929
86
train loss item: 4.27729606628418
87
train loss item: 0.18036888539791107
88
train loss item: 0.3754551112651825
epoch train loss: 0.4776796206329646
testing phase
test loss item: 0.17784236371517181
test loss item: 0.13719579577445984
test loss item: 0.5344434976577759
test loss item: 0.23780851066112518
test loss item: 0.2591812014579773
test loss item: 0.13410869240760803
test loss item: 1.3868991136550903
test loss item: 0.4274008870124817
test loss item: 0.21691125631332397
test loss item: 0.3936111629009247
test loss item: 0.8182723522186279
test loss item: 0.20795999467372894
test loss item: 0.21252231299877167
test loss item: 0.3253036141395569
test loss item: 0.1813238561153412
test loss item: 0.11994010210037231
test loss item: 0.2798326909542084
test loss item: 0.45905545353889465
test loss item: 0.5692559480667114
test loss item: 0.27734774351119995
test loss item: 0.7122097015380859
test loss item: 0.3716282546520233
test loss item: 0.3233214318752289
test loss item: 0.17886902391910553
test loss item: 0.23240648210048676
test loss item: 0.2219243049621582
test loss item: 0.31961506605148315
test loss item: 0.2036704421043396
test loss item: 0.328775018453598
test loss item: 0.3469342589378357
test loss item: 0.712917685508728
test loss item: 0.11414667218923569
test loss item: 0.15626105666160583
test loss item: 0.5651819109916687
test loss item: 0.41390299797058105
test loss item: 0.44177761673927307
test loss item: 0.6966418027877808
test loss item: 1.376810908317566
test loss item: 0.4715692698955536
test loss item: 0.2704315483570099
test loss item: 0.289482444524765
test loss item: 0.21186703443527222
test loss item: 0.3647605776786804
test loss item: 0.22189995646476746
test loss item: 0.5865240693092346
test loss item: 0.3901657164096832
test loss item: 0.32002902030944824
test loss item: 0.24481450021266937
test loss item: 0.4502909779548645
test loss item: 0.6533889770507812
test loss item: 0.3103247284889221
test loss item: 0.16060002148151398
test loss item: 0.23583301901817322
test loss item: 0.2171250879764557
test loss item: 0.3004455864429474
test loss item: 0.8017759323120117
test loss item: 0.5163893103599548
test loss item: 0.2517547309398651
test loss item: 0.23312222957611084
test loss item: 0.2411673218011856
test loss item: 0.4570590555667877
test loss item: 0.22643785178661346
test loss item: 0.20346564054489136
test loss item: 0.2725106477737427
test loss item: 0.7088509202003479
test loss item: 0.3224918842315674
test loss item: 0.3015829622745514
test loss item: 0.26261529326438904
test loss item: 0.5415278673171997
test loss item: 0.36118826270103455
test loss item: 0.11281903088092804
test loss item: 0.7920787334442139
test loss item: 0.3259459137916565
test loss item: 0.38400354981422424
test loss item: 0.16074202954769135
test loss item: 0.21558701992034912
test loss item: 0.18125511705875397
test loss item: 1.3737432956695557
test loss item: 0.4443398714065552
test loss item: 0.19168365001678467
test loss item: 0.09991158545017242
test loss item: 0.8633235096931458
test loss item: 0.7584540247917175
test loss item: 0.9453384876251221
test loss item: 0.22707831859588623
test loss item: 0.22610169649124146
test loss item: 0.10495729744434357
test loss item: 0.10309876501560211
test loss item: 0.16651590168476105
Epoch [18/100], Training Loss: 0.4777, Testing Loss: 0.3837
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 19/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.42831242084503174
1
train loss item: 1.158857822418213
2
train loss item: 0.23137085139751434
3
train loss item: 0.5086199641227722
4
train loss item: 0.3800085186958313
5
train loss item: 0.31677472591400146
6
train loss item: 0.2553494870662689
7
train loss item: 0.7767841219902039
8
train loss item: 0.14015249907970428
9
train loss item: 0.23645253479480743
10
train loss item: 0.3300974369049072
11
train loss item: 0.26648569107055664
12
train loss item: 0.13876734673976898
13
train loss item: 0.49888747930526733
14
train loss item: 0.24387311935424805
15
train loss item: 0.5980829000473022
16
train loss item: 0.09620486199855804
17
train loss item: 0.24299080669879913
18
train loss item: 0.30787965655326843
19
train loss item: 0.25727447867393494
20
train loss item: 0.2408812791109085
21
train loss item: 0.1358022689819336
22
train loss item: 0.9045893549919128
23
train loss item: 0.8955429792404175
24
train loss item: 0.509209156036377
25
train loss item: 0.1993635594844818
26
train loss item: 0.1985388845205307
27
train loss item: 0.24744723737239838
28
train loss item: 0.09581281989812851
29
train loss item: 0.6868520975112915
30
train loss item: 2.195094347000122
31
train loss item: 0.5546186566352844
32
train loss item: 0.12126616388559341
33
train loss item: 0.4214247167110443
34
train loss item: 0.14667800068855286
35
train loss item: 2.3589797019958496
36
train loss item: 0.4435369074344635
37
train loss item: 0.3741767704486847
38
train loss item: 0.45176512002944946
39
train loss item: 0.2365693897008896
40
train loss item: 0.1756288707256317
41
train loss item: 0.24806417524814606
42
train loss item: 0.24744853377342224
43
train loss item: 0.18094982206821442
44
train loss item: 0.6752335429191589
45
train loss item: 0.1448419839143753
46
train loss item: 0.1526726335287094
47
train loss item: 0.3251579701900482
48
train loss item: 0.22114652395248413
49
train loss item: 0.15436308085918427
50
train loss item: 0.28938359022140503
51
train loss item: 0.8276521563529968
52
train loss item: 0.11319451779127121
53
train loss item: 0.16655710339546204
54
train loss item: 2.2392354011535645
55
train loss item: 0.2112569808959961
56
train loss item: 0.24531029164791107
57
train loss item: 0.23938170075416565
58
train loss item: 0.16646426916122437
59
train loss item: 0.14496788382530212
60
train loss item: 0.8188905715942383
61
train loss item: 2.188100576400757
62
train loss item: 0.2036476582288742
63
train loss item: 0.33459895849227905
64
train loss item: 0.16624405980110168
65
train loss item: 0.5083129405975342
66
train loss item: 0.39019399881362915
67
train loss item: 0.20367051661014557
68
train loss item: 0.26813334226608276
69
train loss item: 0.30065158009529114
70
train loss item: 0.2359572798013687
71
train loss item: 0.15148890018463135
72
train loss item: 0.19067230820655823
73
train loss item: 0.27904272079467773
74
train loss item: 0.10790514200925827
75
train loss item: 0.1252787858247757
76
train loss item: 0.8594317436218262
77
train loss item: 1.268768548965454
78
train loss item: 0.09791858494281769
79
train loss item: 0.27724575996398926
80
train loss item: 0.12667015194892883
81
train loss item: 0.1893133819103241
82
train loss item: 0.21006657183170319
83
train loss item: 0.5580232739448547
84
train loss item: 0.37813442945480347
85
train loss item: 0.5519635677337646
86
train loss item: 4.248642444610596
87
train loss item: 0.18142352998256683
88
train loss item: 0.3634752929210663
epoch train loss: 0.46948487403687467
testing phase
test loss item: 0.17567424476146698
test loss item: 0.13234689831733704
test loss item: 0.5260275602340698
test loss item: 0.23524479568004608
test loss item: 0.2541215121746063
test loss item: 0.13008540868759155
test loss item: 1.40651535987854
test loss item: 0.4648256301879883
test loss item: 0.20809273421764374
test loss item: 0.38526061177253723
test loss item: 0.7997134923934937
test loss item: 0.20458465814590454
test loss item: 0.2051294445991516
test loss item: 0.3098473846912384
test loss item: 0.1767948716878891
test loss item: 0.11706046015024185
test loss item: 0.2728497385978699
test loss item: 0.4545838534832001
test loss item: 0.5817194581031799
test loss item: 0.26371583342552185
test loss item: 0.7117747664451599
test loss item: 0.3708411455154419
test loss item: 0.3142228424549103
test loss item: 0.17534688115119934
test loss item: 0.2263399064540863
test loss item: 0.21576523780822754
test loss item: 0.30867114663124084
test loss item: 0.199323832988739
test loss item: 0.3206564486026764
test loss item: 0.33893346786499023
test loss item: 0.7026623487472534
test loss item: 0.11390076577663422
test loss item: 0.15355509519577026
test loss item: 0.5590443015098572
test loss item: 0.4092102348804474
test loss item: 0.42755600810050964
test loss item: 0.70731520652771
test loss item: 1.3449952602386475
test loss item: 0.46519210934638977
test loss item: 0.2640156149864197
test loss item: 0.2856847941875458
test loss item: 0.20665568113327026
test loss item: 0.35753121972084045
test loss item: 0.2179039567708969
test loss item: 0.5836395025253296
test loss item: 0.3811851143836975
test loss item: 0.31512582302093506
test loss item: 0.2326991856098175
test loss item: 0.44452598690986633
test loss item: 0.6383587718009949
test loss item: 0.30513817071914673
test loss item: 0.1535254716873169
test loss item: 0.2296796590089798
test loss item: 0.21637646853923798
test loss item: 0.2965923547744751
test loss item: 0.7813876271247864
test loss item: 0.5197597742080688
test loss item: 0.2486822009086609
test loss item: 0.228756844997406
test loss item: 0.23441307246685028
test loss item: 0.4488750994205475
test loss item: 0.22552920877933502
test loss item: 0.19789934158325195
test loss item: 0.26449888944625854
test loss item: 0.7063475251197815
test loss item: 0.32112085819244385
test loss item: 0.2932533919811249
test loss item: 0.2543404996395111
test loss item: 0.5338736772537231
test loss item: 0.3696272075176239
test loss item: 0.10464522987604141
test loss item: 0.8106984496116638
test loss item: 0.3205980956554413
test loss item: 0.3718191981315613
test loss item: 0.15251225233078003
test loss item: 0.20950430631637573
test loss item: 0.1772269457578659
test loss item: 1.3491449356079102
test loss item: 0.4279221296310425
test loss item: 0.18738095462322235
test loss item: 0.09621494263410568
test loss item: 0.8560743927955627
test loss item: 0.7625376582145691
test loss item: 0.9255231618881226
test loss item: 0.21796472370624542
test loss item: 0.21840789914131165
test loss item: 0.10040266811847687
test loss item: 0.10089156031608582
test loss item: 0.16350829601287842
Epoch [19/100], Training Loss: 0.4695, Testing Loss: 0.3784
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 20/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4195750653743744
1
train loss item: 1.1398003101348877
2
train loss item: 0.22668564319610596
3
train loss item: 0.4893135726451874
4
train loss item: 0.35899728536605835
5
train loss item: 0.3078053891658783
6
train loss item: 0.24577835202217102
7
train loss item: 0.7604930400848389
8
train loss item: 0.13750331103801727
9
train loss item: 0.22881609201431274
10
train loss item: 0.31567302346229553
11
train loss item: 0.262103796005249
12
train loss item: 0.1378602832555771
13
train loss item: 0.4837961196899414
14
train loss item: 0.2362784445285797
15
train loss item: 0.593822717666626
16
train loss item: 0.09589242935180664
17
train loss item: 0.24241937696933746
18
train loss item: 0.3007984459400177
19
train loss item: 0.25287166237831116
20
train loss item: 0.23850961029529572
21
train loss item: 0.13613085448741913
22
train loss item: 0.8941177725791931
23
train loss item: 0.8762867450714111
24
train loss item: 0.5002288818359375
25
train loss item: 0.193057119846344
26
train loss item: 0.19066296517848969
27
train loss item: 0.2409401684999466
28
train loss item: 0.0949055477976799
29
train loss item: 0.6780020594596863
30
train loss item: 2.1617324352264404
31
train loss item: 0.5385870933532715
32
train loss item: 0.11407691985368729
33
train loss item: 0.4134261906147003
34
train loss item: 0.14441542327404022
35
train loss item: 2.3358311653137207
36
train loss item: 0.43693941831588745
37
train loss item: 0.36917948722839355
38
train loss item: 0.43242162466049194
39
train loss item: 0.23042257130146027
40
train loss item: 0.16814324259757996
41
train loss item: 0.24019788205623627
42
train loss item: 0.2469116747379303
43
train loss item: 0.17743052542209625
44
train loss item: 0.6611793041229248
45
train loss item: 0.1388126164674759
46
train loss item: 0.14318233728408813
47
train loss item: 0.3221062123775482
48
train loss item: 0.21499000489711761
49
train loss item: 0.15065324306488037
50
train loss item: 0.28265777230262756
51
train loss item: 0.8100708723068237
52
train loss item: 0.11142285168170929
53
train loss item: 0.16001297533512115
54
train loss item: 2.21523380279541
55
train loss item: 0.2062350958585739
56
train loss item: 0.2359377145767212
57
train loss item: 0.23165252804756165
58
train loss item: 0.16239018738269806
59
train loss item: 0.13785438239574432
60
train loss item: 0.8047785758972168
61
train loss item: 2.1608493328094482
62
train loss item: 0.1969069093465805
63
train loss item: 0.3297899663448334
64
train loss item: 0.16516204178333282
65
train loss item: 0.5041583180427551
66
train loss item: 0.3822867274284363
67
train loss item: 0.19891151785850525
68
train loss item: 0.2672577500343323
69
train loss item: 0.2948928475379944
70
train loss item: 0.23251618444919586
71
train loss item: 0.1586131453514099
72
train loss item: 0.1860387772321701
73
train loss item: 0.27406132221221924
74
train loss item: 0.10530591011047363
75
train loss item: 0.12344599515199661
76
train loss item: 0.8425178527832031
77
train loss item: 1.2550443410873413
78
train loss item: 0.09757880121469498
79
train loss item: 0.268226683139801
80
train loss item: 0.12739814817905426
81
train loss item: 0.1842372864484787
82
train loss item: 0.2055894136428833
83
train loss item: 0.5466077327728271
84
train loss item: 0.3777623474597931
85
train loss item: 0.5330870747566223
86
train loss item: 4.215088367462158
87
train loss item: 0.17734459042549133
88
train loss item: 0.3556234538555145
epoch train loss: 0.46117207926980563
testing phase
test loss item: 0.17185135185718536
test loss item: 0.12230392545461655
test loss item: 0.5072982907295227
test loss item: 0.22891902923583984
test loss item: 0.24510382115840912
test loss item: 0.12305336445569992
test loss item: 1.4333094358444214
test loss item: 0.48860663175582886
test loss item: 0.19665023684501648
test loss item: 0.37371426820755005
test loss item: 0.7726402282714844
test loss item: 0.1946025788784027
test loss item: 0.19060413539409637
test loss item: 0.2956204116344452
test loss item: 0.1682789921760559
test loss item: 0.10979831963777542
test loss item: 0.26289406418800354
test loss item: 0.44537076354026794
test loss item: 0.5899032950401306
test loss item: 0.2446053922176361
test loss item: 0.7011533975601196
test loss item: 0.36674994230270386
test loss item: 0.2977793216705322
test loss item: 0.1670476347208023
test loss item: 0.21676725149154663
test loss item: 0.20841073989868164
test loss item: 0.29620638489723206
test loss item: 0.19124044477939606
test loss item: 0.3097192645072937
test loss item: 0.3309396207332611
test loss item: 0.6885261535644531
test loss item: 0.1109333410859108
test loss item: 0.1453302502632141
test loss item: 0.5457643866539001
test loss item: 0.3987344205379486
test loss item: 0.41455402970314026
test loss item: 0.7145816683769226
test loss item: 1.2941831350326538
test loss item: 0.45374423265457153
test loss item: 0.25651559233665466
test loss item: 0.28220370411872864
test loss item: 0.19467271864414215
test loss item: 0.3459825813770294
test loss item: 0.21106088161468506
test loss item: 0.5729683041572571
test loss item: 0.36841100454330444
test loss item: 0.30158039927482605
test loss item: 0.2197207808494568
test loss item: 0.4307021498680115
test loss item: 0.6200262904167175
test loss item: 0.29493746161460876
test loss item: 0.14634865522384644
test loss item: 0.22325770556926727
test loss item: 0.20920200645923615
test loss item: 0.2906550168991089
test loss item: 0.7527592778205872
test loss item: 0.5172214508056641
test loss item: 0.24410055577754974
test loss item: 0.22114048898220062
test loss item: 0.2224608212709427
test loss item: 0.4382052719593048
test loss item: 0.22003532946109772
test loss item: 0.19039806723594666
test loss item: 0.25049614906311035
test loss item: 0.6925988793373108
test loss item: 0.31649526953697205
test loss item: 0.28245028853416443
test loss item: 0.24438099563121796
test loss item: 0.5175665020942688
test loss item: 0.37640729546546936
test loss item: 0.09176822006702423
test loss item: 0.8276894688606262
test loss item: 0.3061959445476532
test loss item: 0.3576662242412567
test loss item: 0.13971570134162903
test loss item: 0.19282203912734985
test loss item: 0.16926637291908264
test loss item: 1.2970921993255615
test loss item: 0.4086992144584656
test loss item: 0.1812957376241684
test loss item: 0.08898446708917618
test loss item: 0.8436911702156067
test loss item: 0.7663775086402893
test loss item: 0.8893364667892456
test loss item: 0.21045401692390442
test loss item: 0.20661412179470062
test loss item: 0.09105405956506729
test loss item: 0.0949273556470871
test loss item: 0.16055811941623688
Epoch [20/100], Training Loss: 0.4612, Testing Loss: 0.3685
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 21/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41321462392807007
1
train loss item: 1.1160110235214233
2
train loss item: 0.21920616924762726
3
train loss item: 0.47114884853363037
4
train loss item: 0.3498256206512451
5
train loss item: 0.30152034759521484
6
train loss item: 0.23370151221752167
7
train loss item: 0.7419186234474182
8
train loss item: 0.13521480560302734
9
train loss item: 0.22240377962589264
10
train loss item: 0.30617639422416687
11
train loss item: 0.26053059101104736
12
train loss item: 0.1341029703617096
13
train loss item: 0.4702145457267761
14
train loss item: 0.23030011355876923
15
train loss item: 0.5877775549888611
16
train loss item: 0.09382672607898712
17
train loss item: 0.24205757677555084
18
train loss item: 0.2958988845348358
19
train loss item: 0.24670028686523438
20
train loss item: 0.232448011636734
21
train loss item: 0.13554899394512177
22
train loss item: 0.8815147280693054
23
train loss item: 0.8534871935844421
24
train loss item: 0.4915226697921753
25
train loss item: 0.19092048704624176
26
train loss item: 0.18304476141929626
27
train loss item: 0.2346057891845703
28
train loss item: 0.09231150895357132
29
train loss item: 0.667817234992981
30
train loss item: 2.126589775085449
31
train loss item: 0.5231520533561707
32
train loss item: 0.11003059148788452
33
train loss item: 0.40045326948165894
34
train loss item: 0.14483220875263214
35
train loss item: 2.312039613723755
36
train loss item: 0.4339663088321686
37
train loss item: 0.3648843765258789
38
train loss item: 0.41980862617492676
39
train loss item: 0.22393901646137238
40
train loss item: 0.16219276189804077
41
train loss item: 0.23351821303367615
42
train loss item: 0.24579273164272308
43
train loss item: 0.1715836077928543
44
train loss item: 0.6456136703491211
45
train loss item: 0.13191844522953033
46
train loss item: 0.1342172920703888
47
train loss item: 0.31816479563713074
48
train loss item: 0.2062070220708847
49
train loss item: 0.14737747609615326
50
train loss item: 0.27449196577072144
51
train loss item: 0.7929558157920837
52
train loss item: 0.10830467939376831
53
train loss item: 0.15239207446575165
54
train loss item: 2.190098285675049
55
train loss item: 0.19526700675487518
56
train loss item: 0.22762833535671234
57
train loss item: 0.2256542146205902
58
train loss item: 0.15763278305530548
59
train loss item: 0.13085505366325378
60
train loss item: 0.787003755569458
61
train loss item: 2.130751609802246
62
train loss item: 0.1967449188232422
63
train loss item: 0.324666827917099
64
train loss item: 0.16046901047229767
65
train loss item: 0.49898990988731384
66
train loss item: 0.378413587808609
67
train loss item: 0.19449365139007568
68
train loss item: 0.26450303196907043
69
train loss item: 0.2904359698295593
70
train loss item: 0.23059362173080444
71
train loss item: 0.15892915427684784
72
train loss item: 0.17812228202819824
73
train loss item: 0.2684905230998993
74
train loss item: 0.10435669869184494
75
train loss item: 0.11736813187599182
76
train loss item: 0.8212052583694458
77
train loss item: 1.2395230531692505
78
train loss item: 0.0974445790052414
79
train loss item: 0.2604455053806305
80
train loss item: 0.12447504699230194
81
train loss item: 0.1799817532300949
82
train loss item: 0.19936510920524597
83
train loss item: 0.5354081988334656
84
train loss item: 0.37934884428977966
85
train loss item: 0.5130003690719604
86
train loss item: 4.179292678833008
87
train loss item: 0.16984470188617706
88
train loss item: 0.3529585003852844
epoch train loss: 0.4526197834965888
testing phase
test loss item: 0.1683543473482132
test loss item: 0.11138671636581421
test loss item: 0.48764941096305847
test loss item: 0.2234656810760498
test loss item: 0.23493874073028564
test loss item: 0.11500705778598785
test loss item: 1.4564363956451416
test loss item: 0.4881495535373688
test loss item: 0.18818451464176178
test loss item: 0.3631379306316376
test loss item: 0.746467649936676
test loss item: 0.18613071739673615
test loss item: 0.17612946033477783
test loss item: 0.28451353311538696
test loss item: 0.159291610121727
test loss item: 0.10349787771701813
test loss item: 0.2547919452190399
test loss item: 0.43430691957473755
test loss item: 0.5855939984321594
test loss item: 0.22906175255775452
test loss item: 0.6822614669799805
test loss item: 0.3622986674308777
test loss item: 0.2789960503578186
test loss item: 0.15751229226589203
test loss item: 0.20816725492477417
test loss item: 0.20164360105991364
test loss item: 0.28642308712005615
test loss item: 0.18171249330043793
test loss item: 0.2995700538158417
test loss item: 0.3245724141597748
test loss item: 0.6760112047195435
test loss item: 0.10948756337165833
test loss item: 0.1350424885749817
test loss item: 0.5312085747718811
test loss item: 0.3864729404449463
test loss item: 0.4010220170021057
test loss item: 0.7124961018562317
test loss item: 1.2431780099868774
test loss item: 0.4416263997554779
test loss item: 0.25006037950515747
test loss item: 0.2809758186340332
test loss item: 0.18189361691474915
test loss item: 0.3353811204433441
test loss item: 0.2073739767074585
test loss item: 0.5564429759979248
test loss item: 0.35612067580223083
test loss item: 0.28455665707588196
test loss item: 0.2122415453195572
test loss item: 0.4148690104484558
test loss item: 0.6030260920524597
test loss item: 0.28328579664230347
test loss item: 0.14138902723789215
test loss item: 0.21896755695343018
test loss item: 0.2043236643075943
test loss item: 0.28388163447380066
test loss item: 0.7257575988769531
test loss item: 0.5059292316436768
test loss item: 0.23574267327785492
test loss item: 0.21283607184886932
test loss item: 0.21066908538341522
test loss item: 0.42891329526901245
test loss item: 0.2128891795873642
test loss item: 0.18422015011310577
test loss item: 0.23725509643554688
test loss item: 0.6730254292488098
test loss item: 0.313850075006485
test loss item: 0.27231043577194214
test loss item: 0.2370278239250183
test loss item: 0.49850645661354065
test loss item: 0.3705465495586395
test loss item: 0.08142700046300888
test loss item: 0.8351743817329407
test loss item: 0.29068294167518616
test loss item: 0.3466785252094269
test loss item: 0.1293504387140274
test loss item: 0.17327894270420074
test loss item: 0.1605319231748581
test loss item: 1.2384921312332153
test loss item: 0.3917493522167206
test loss item: 0.1750228852033615
test loss item: 0.08214008063077927
test loss item: 0.8291839957237244
test loss item: 0.7663650512695312
test loss item: 0.8517988324165344
test loss item: 0.20484121143817902
test loss item: 0.1956903636455536
test loss item: 0.0816216766834259
test loss item: 0.08974015712738037
test loss item: 0.15953102707862854
Epoch [21/100], Training Loss: 0.4526, Testing Loss: 0.3577
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 22/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4084379971027374
1
train loss item: 1.0885963439941406
2
train loss item: 0.21065501868724823
3
train loss item: 0.45885950326919556
4
train loss item: 0.3491537272930145
5
train loss item: 0.29895588755607605
6
train loss item: 0.2200593799352646
7
train loss item: 0.7231674194335938
8
train loss item: 0.13260269165039062
9
train loss item: 0.21841222047805786
10
train loss item: 0.3038291335105896
11
train loss item: 0.2602561116218567
12
train loss item: 0.12903714179992676
13
train loss item: 0.4608546495437622
14
train loss item: 0.22577540576457977
15
train loss item: 0.576767086982727
16
train loss item: 0.08754955232143402
17
train loss item: 0.2384280264377594
18
train loss item: 0.29160642623901367
19
train loss item: 0.2387295514345169
20
train loss item: 0.22074756026268005
21
train loss item: 0.13436058163642883
22
train loss item: 0.8610367774963379
23
train loss item: 0.8319573402404785
24
train loss item: 0.48078206181526184
25
train loss item: 0.19281922280788422
26
train loss item: 0.17829224467277527
27
train loss item: 0.22854475677013397
28
train loss item: 0.0857657641172409
29
train loss item: 0.6545979976654053
30
train loss item: 2.093684196472168
31
train loss item: 0.5120112299919128
32
train loss item: 0.10828467458486557
33
train loss item: 0.3900138735771179
34
train loss item: 0.14429756999015808
35
train loss item: 2.2890048027038574
36
train loss item: 0.4328071177005768
37
train loss item: 0.3611743152141571
38
train loss item: 0.416242390871048
39
train loss item: 0.21736101806163788
40
train loss item: 0.15818752348423004
41
train loss item: 0.22902162373065948
42
train loss item: 0.24515429139137268
43
train loss item: 0.1664593517780304
44
train loss item: 0.6311704516410828
45
train loss item: 0.12698432803153992
46
train loss item: 0.12879739701747894
47
train loss item: 0.3134828209877014
48
train loss item: 0.19790177047252655
49
train loss item: 0.14615319669246674
50
train loss item: 0.26421767473220825
51
train loss item: 0.7771773934364319
52
train loss item: 0.1009734719991684
53
train loss item: 0.14773330092430115
54
train loss item: 2.1661529541015625
55
train loss item: 0.18287807703018188
56
train loss item: 0.22232314944267273
57
train loss item: 0.2217179834842682
58
train loss item: 0.15314076840877533
59
train loss item: 0.1286517232656479
60
train loss item: 0.7652727365493774
61
train loss item: 2.1021547317504883
62
train loss item: 0.19848720729351044
63
train loss item: 0.31911832094192505
64
train loss item: 0.1571030169725418
65
train loss item: 0.485993355512619
66
train loss item: 0.37620559334754944
67
train loss item: 0.19219601154327393
68
train loss item: 0.2563806176185608
69
train loss item: 0.28596562147140503
70
train loss item: 0.23009848594665527
71
train loss item: 0.14997752010822296
72
train loss item: 0.1705433428287506
73
train loss item: 0.26299747824668884
74
train loss item: 0.10392314940690994
75
train loss item: 0.11125772446393967
76
train loss item: 0.7996463179588318
77
train loss item: 1.2225054502487183
78
train loss item: 0.09262824803590775
79
train loss item: 0.25425010919570923
80
train loss item: 0.117293581366539
81
train loss item: 0.17841868102550507
82
train loss item: 0.19336755573749542
83
train loss item: 0.5235248804092407
84
train loss item: 0.38029834628105164
85
train loss item: 0.49675533175468445
86
train loss item: 4.145147323608398
87
train loss item: 0.16374778747558594
88
train loss item: 0.3514791429042816
epoch train loss: 0.444388041502974
testing phase
test loss item: 0.1665818840265274
test loss item: 0.10810831189155579
test loss item: 0.4732655882835388
test loss item: 0.22137634456157684
test loss item: 0.22848986089229584
test loss item: 0.11057984083890915
test loss item: 1.4856714010238647
test loss item: 0.4874964654445648
test loss item: 0.18478263914585114
test loss item: 0.355299174785614
test loss item: 0.7275916337966919
test loss item: 0.18282684683799744
test loss item: 0.16846780478954315
test loss item: 0.27548709511756897
test loss item: 0.15611690282821655
test loss item: 0.1022462323307991
test loss item: 0.2511349618434906
test loss item: 0.42433151602745056
test loss item: 0.5829241275787354
test loss item: 0.22206854820251465
test loss item: 0.6627812385559082
test loss item: 0.3614712357521057
test loss item: 0.2652568221092224
test loss item: 0.1536613255739212
test loss item: 0.20271030068397522
test loss item: 0.19734787940979004
test loss item: 0.2804885506629944
test loss item: 0.17560306191444397
test loss item: 0.2942805588245392
test loss item: 0.3194256126880646
test loss item: 0.6712396740913391
test loss item: 0.11104421317577362
test loss item: 0.1305411159992218
test loss item: 0.5195038318634033
test loss item: 0.37616968154907227
test loss item: 0.3926243782043457
test loss item: 0.7117723822593689
test loss item: 1.203660488128662
test loss item: 0.4316466748714447
test loss item: 0.24775099754333496
test loss item: 0.2816638946533203
test loss item: 0.17448750138282776
test loss item: 0.3280896842479706
test loss item: 0.20714016258716583
test loss item: 0.5396352410316467
test loss item: 0.35010406374931335
test loss item: 0.2712442874908447
test loss item: 0.2086474895477295
test loss item: 0.4035872220993042
test loss item: 0.5922157168388367
test loss item: 0.274128258228302
test loss item: 0.13853342831134796
test loss item: 0.21644823253154755
test loss item: 0.20265786349773407
test loss item: 0.2776835560798645
test loss item: 0.7057148814201355
test loss item: 0.49705350399017334
test loss item: 0.22629043459892273
test loss item: 0.20722664892673492
test loss item: 0.20367051661014557
test loss item: 0.4213297665119171
test loss item: 0.21007472276687622
test loss item: 0.1813265085220337
test loss item: 0.2303784191608429
test loss item: 0.6586197018623352
test loss item: 0.31288942694664
test loss item: 0.26653411984443665
test loss item: 0.23438875377178192
test loss item: 0.48322930932044983
test loss item: 0.3687703013420105
test loss item: 0.0795319527387619
test loss item: 0.8469159007072449
test loss item: 0.27964073419570923
test loss item: 0.34278202056884766
test loss item: 0.1250087171792984
test loss item: 0.1603263020515442
test loss item: 0.15744587779045105
test loss item: 1.190046787261963
test loss item: 0.3789369761943817
test loss item: 0.17024385929107666
test loss item: 0.07942250370979309
test loss item: 0.822006344795227
test loss item: 0.7691519260406494
test loss item: 0.8231832981109619
test loss item: 0.20100361108779907
test loss item: 0.18842852115631104
test loss item: 0.07707291841506958
test loss item: 0.08838310837745667
test loss item: 0.16050921380519867
Epoch [22/100], Training Loss: 0.4444, Testing Loss: 0.3510
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 23/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.40376827120780945
1
train loss item: 1.062140941619873
2
train loss item: 0.20400337874889374
3
train loss item: 0.45109957456588745
4
train loss item: 0.34872961044311523
5
train loss item: 0.2969723641872406
6
train loss item: 0.21020644903182983
7
train loss item: 0.7048766016960144
8
train loss item: 0.13067330420017242
9
train loss item: 0.21512359380722046
10
train loss item: 0.3016147315502167
11
train loss item: 0.2590349316596985
12
train loss item: 0.12570519745349884
13
train loss item: 0.45338496565818787
14
train loss item: 0.22084686160087585
15
train loss item: 0.5659624934196472
16
train loss item: 0.08420896530151367
17
train loss item: 0.23137785494327545
18
train loss item: 0.2867494225502014
19
train loss item: 0.2320692092180252
20
train loss item: 0.20848825573921204
21
train loss item: 0.13214194774627686
22
train loss item: 0.8375900387763977
23
train loss item: 0.8123602867126465
24
train loss item: 0.46942970156669617
25
train loss item: 0.1944604068994522
26
train loss item: 0.17359595000743866
27
train loss item: 0.2213786244392395
28
train loss item: 0.08266659080982208
29
train loss item: 0.6414069533348083
30
train loss item: 2.063993453979492
31
train loss item: 0.50169438123703
32
train loss item: 0.10905490070581436
33
train loss item: 0.38239017128944397
34
train loss item: 0.1431228518486023
35
train loss item: 2.2668895721435547
36
train loss item: 0.43033328652381897
37
train loss item: 0.3568166494369507
38
train loss item: 0.41642364859580994
39
train loss item: 0.21099352836608887
40
train loss item: 0.15532170236110687
41
train loss item: 0.223920077085495
42
train loss item: 0.2452395260334015
43
train loss item: 0.16322365403175354
44
train loss item: 0.6174566745758057
45
train loss item: 0.12609750032424927
46
train loss item: 0.12952183187007904
47
train loss item: 0.3104788362979889
48
train loss item: 0.19223105907440186
49
train loss item: 0.14565294981002808
50
train loss item: 0.2554675042629242
51
train loss item: 0.7635764479637146
52
train loss item: 0.09622703492641449
53
train loss item: 0.14531005918979645
54
train loss item: 2.143878221511841
55
train loss item: 0.17424549162387848
56
train loss item: 0.21829205751419067
57
train loss item: 0.21880540251731873
58
train loss item: 0.15003740787506104
59
train loss item: 0.1307956427335739
60
train loss item: 0.7441900372505188
61
train loss item: 2.0757088661193848
62
train loss item: 0.19905592501163483
63
train loss item: 0.31518182158470154
64
train loss item: 0.15536880493164062
65
train loss item: 0.468499094247818
66
train loss item: 0.3733043968677521
67
train loss item: 0.19100166857242584
68
train loss item: 0.24701565504074097
69
train loss item: 0.28033915162086487
70
train loss item: 0.23014940321445465
71
train loss item: 0.14040300250053406
72
train loss item: 0.16518999636173248
73
train loss item: 0.2585581839084625
74
train loss item: 0.10660948604345322
75
train loss item: 0.10945288091897964
76
train loss item: 0.7805383205413818
77
train loss item: 1.207337498664856
78
train loss item: 0.08880685269832611
79
train loss item: 0.24977435171604156
80
train loss item: 0.11309420317411423
81
train loss item: 0.17819876968860626
82
train loss item: 0.18801523745059967
83
train loss item: 0.5129887461662292
84
train loss item: 0.3789300322532654
85
train loss item: 0.4848366975784302
86
train loss item: 4.113205909729004
87
train loss item: 0.15986445546150208
88
train loss item: 0.34727561473846436
epoch train loss: 0.43721858504113187
testing phase
test loss item: 0.16485944390296936
test loss item: 0.11121440678834915
test loss item: 0.46774882078170776
test loss item: 0.2198721319437027
test loss item: 0.22749397158622742
test loss item: 0.11130204796791077
test loss item: 1.5146290063858032
test loss item: 0.49678152799606323
test loss item: 0.18466497957706451
test loss item: 0.3509098291397095
test loss item: 0.7174950838088989
test loss item: 0.18235716223716736
test loss item: 0.16922996938228607
test loss item: 0.2672101855278015
test loss item: 0.15753434598445892
test loss item: 0.10340014100074768
test loss item: 0.24951674044132233
test loss item: 0.41885530948638916
test loss item: 0.5861037969589233
test loss item: 0.22089806199073792
test loss item: 0.6527665853500366
test loss item: 0.36274588108062744
test loss item: 0.26506951451301575
test loss item: 0.15393446385860443
test loss item: 0.19947296380996704
test loss item: 0.19499388337135315
test loss item: 0.27563607692718506
test loss item: 0.17457278072834015
test loss item: 0.29313045740127563
test loss item: 0.3145681619644165
test loss item: 0.6723928451538086
test loss item: 0.1118890717625618
test loss item: 0.13052570819854736
test loss item: 0.513302743434906
test loss item: 0.37102431058883667
test loss item: 0.3893581032752991
test loss item: 0.7156177163124084
test loss item: 1.181361198425293
test loss item: 0.42516589164733887
test loss item: 0.247934490442276
test loss item: 0.2807757556438446
test loss item: 0.17947883903980255
test loss item: 0.32524701952934265
test loss item: 0.20595213770866394
test loss item: 0.5299283266067505
test loss item: 0.3493320643901825
test loss item: 0.27026116847991943
test loss item: 0.20172177255153656
test loss item: 0.40038949251174927
test loss item: 0.5879027247428894
test loss item: 0.2709377408027649
test loss item: 0.1349657028913498
test loss item: 0.21392227709293365
test loss item: 0.2000754326581955
test loss item: 0.27405795454978943
test loss item: 0.6953388452529907
test loss item: 0.4952228367328644
test loss item: 0.22128717601299286
test loss item: 0.2047731727361679
test loss item: 0.20323361456394196
test loss item: 0.4160365164279938
test loss item: 0.21168272197246552
test loss item: 0.1804129034280777
test loss item: 0.22998690605163574
test loss item: 0.6553042531013489
test loss item: 0.3101958930492401
test loss item: 0.264781653881073
test loss item: 0.23406803607940674
test loss item: 0.4759189188480377
test loss item: 0.3731215298175812
test loss item: 0.08226355165243149
test loss item: 0.8629872798919678
test loss item: 0.2743861973285675
test loss item: 0.343081533908844
test loss item: 0.12345661967992783
test loss item: 0.1641703099012375
test loss item: 0.1581793576478958
test loss item: 1.1631749868392944
test loss item: 0.3695690929889679
test loss item: 0.1678161919116974
test loss item: 0.07749377936124802
test loss item: 0.8230139017105103
test loss item: 0.7746945023536682
test loss item: 0.808958888053894
test loss item: 0.1976221799850464
test loss item: 0.18411295115947723
test loss item: 0.07482387125492096
test loss item: 0.08726535737514496
test loss item: 0.16023240983486176
Epoch [23/100], Training Loss: 0.4372, Testing Loss: 0.3490
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 24/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3976721465587616
1
train loss item: 1.0386806726455688
2
train loss item: 0.20031048357486725
3
train loss item: 0.442023903131485
4
train loss item: 0.3426744341850281
5
train loss item: 0.2920685410499573
6
train loss item: 0.2044340968132019
7
train loss item: 0.6869389414787292
8
train loss item: 0.12594009935855865
9
train loss item: 0.2107296735048294
10
train loss item: 0.2931913435459137
11
train loss item: 0.25464317202568054
12
train loss item: 0.12234722077846527
13
train loss item: 0.4434773027896881
14
train loss item: 0.21339969336986542
15
train loss item: 0.5568757653236389
16
train loss item: 0.08139926940202713
17
train loss item: 0.22237616777420044
18
train loss item: 0.2805638611316681
19
train loss item: 0.2286759316921234
20
train loss item: 0.1991667002439499
21
train loss item: 0.12717607617378235
22
train loss item: 0.8155070543289185
23
train loss item: 0.7932458519935608
24
train loss item: 0.45910218358039856
25
train loss item: 0.19188432395458221
26
train loss item: 0.16761350631713867
27
train loss item: 0.21228161454200745
28
train loss item: 0.0803312212228775
29
train loss item: 0.6271975636482239
30
train loss item: 2.0352768898010254
31
train loss item: 0.4882875382900238
32
train loss item: 0.10777182132005692
33
train loss item: 0.3733452260494232
34
train loss item: 0.14135529100894928
35
train loss item: 2.2448887825012207
36
train loss item: 0.42343419790267944
37
train loss item: 0.3519543409347534
38
train loss item: 0.41153284907341003
39
train loss item: 0.20433256030082703
40
train loss item: 0.15220412611961365
41
train loss item: 0.21559293568134308
42
train loss item: 0.24485652148723602
43
train loss item: 0.15965676307678223
44
train loss item: 0.6034321784973145
45
train loss item: 0.12551382184028625
46
train loss item: 0.13227352499961853
47
train loss item: 0.30876991152763367
48
train loss item: 0.1883644163608551
49
train loss item: 0.1417376697063446
50
train loss item: 0.25093093514442444
51
train loss item: 0.7494478821754456
52
train loss item: 0.09360270202159882
53
train loss item: 0.1423729807138443
54
train loss item: 2.122220277786255
55
train loss item: 0.16928113996982574
56
train loss item: 0.21243706345558167
57
train loss item: 0.21485596895217896
58
train loss item: 0.14663587510585785
59
train loss item: 0.13053593039512634
60
train loss item: 0.7254440784454346
61
train loss item: 2.049576759338379
62
train loss item: 0.19528646767139435
63
train loss item: 0.3128713071346283
64
train loss item: 0.1518225073814392
65
train loss item: 0.45297253131866455
66
train loss item: 0.36670762300491333
67
train loss item: 0.18727989494800568
68
train loss item: 0.241548553109169
69
train loss item: 0.2729836702346802
70
train loss item: 0.22798533737659454
71
train loss item: 0.13512730598449707
72
train loss item: 0.15907201170921326
73
train loss item: 0.2552359104156494
74
train loss item: 0.1066318228840828
75
train loss item: 0.10907100141048431
76
train loss item: 0.7640716433525085
77
train loss item: 1.1938982009887695
78
train loss item: 0.08499756455421448
79
train loss item: 0.2457408607006073
80
train loss item: 0.1124238520860672
81
train loss item: 0.17619957029819489
82
train loss item: 0.1824350655078888
83
train loss item: 0.5032336115837097
84
train loss item: 0.374822199344635
85
train loss item: 0.473758339881897
86
train loss item: 4.0815558433532715
87
train loss item: 0.15632420778274536
88
train loss item: 0.33806514739990234
epoch train loss: 0.42961768345551543
testing phase
test loss item: 0.1625601351261139
test loss item: 0.11396665126085281
test loss item: 0.4751851260662079
test loss item: 0.21691684424877167
test loss item: 0.23090948164463043
test loss item: 0.11596223711967468
test loss item: 1.501278281211853
test loss item: 0.49449971318244934
test loss item: 0.18801264464855194
test loss item: 0.3521493077278137
test loss item: 0.7187616229057312
test loss item: 0.18362009525299072
test loss item: 0.1768442541360855
test loss item: 0.2601955831050873
test loss item: 0.1594720333814621
test loss item: 0.10335230827331543
test loss item: 0.24672973155975342
test loss item: 0.42210233211517334
test loss item: 0.5820043683052063
test loss item: 0.22314591705799103
test loss item: 0.6602274775505066
test loss item: 0.35866305232048035
test loss item: 0.29006943106651306
test loss item: 0.15272098779678345
test loss item: 0.19917450845241547
test loss item: 0.19291256368160248
test loss item: 0.2717130482196808
test loss item: 0.1774541586637497
test loss item: 0.29293859004974365
test loss item: 0.31164178252220154
test loss item: 0.6698879599571228
test loss item: 0.1101638600230217
test loss item: 0.12958790361881256
test loss item: 0.5159222483634949
test loss item: 0.37446069717407227
test loss item: 0.3882204294204712
test loss item: 0.7106329202651978
test loss item: 1.185033917427063
test loss item: 0.4240156412124634
test loss item: 0.24583150446414948
test loss item: 0.2753528952598572
test loss item: 0.2122017741203308
test loss item: 0.3305802345275879
test loss item: 0.20217283070087433
test loss item: 0.5333994626998901
test loss item: 0.34638091921806335
test loss item: 0.29460808634757996
test loss item: 0.19457559287548065
test loss item: 0.40498462319374084
test loss item: 0.5875820517539978
test loss item: 0.2764683961868286
test loss item: 0.13245825469493866
test loss item: 0.21203090250492096
test loss item: 0.19616928696632385
test loss item: 0.2759071886539459
test loss item: 0.7004664540290833
test loss item: 0.493099570274353
test loss item: 0.22376810014247894
test loss item: 0.20439110696315765
test loss item: 0.2090391218662262
test loss item: 0.41760876774787903
test loss item: 0.21096068620681763
test loss item: 0.17867448925971985
test loss item: 0.2340589016675949
test loss item: 0.660805344581604
test loss item: 0.3054199516773224
test loss item: 0.26293426752090454
test loss item: 0.23286794126033783
test loss item: 0.4776689410209656
test loss item: 0.37132006883621216
test loss item: 0.0848844051361084
test loss item: 0.8552865982055664
test loss item: 0.27469494938850403
test loss item: 0.3385051190853119
test loss item: 0.1239561140537262
test loss item: 0.19994118809700012
test loss item: 0.15680870413780212
test loss item: 1.1682404279708862
test loss item: 0.36308956146240234
test loss item: 0.1681463122367859
test loss item: 0.0745738297700882
test loss item: 0.8210781812667847
test loss item: 0.7720504999160767
test loss item: 0.8146181106567383
test loss item: 0.19403965771198273
test loss item: 0.1834629327058792
test loss item: 0.07208779454231262
test loss item: 0.08399705588817596
test loss item: 0.15698635578155518
Epoch [24/100], Training Loss: 0.4296, Testing Loss: 0.3500
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 25/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3902583718299866
1
train loss item: 1.0165319442749023
2
train loss item: 0.19742515683174133
3
train loss item: 0.43054404854774475
4
train loss item: 0.33184367418289185
5
train loss item: 0.2835005223751068
6
train loss item: 0.20039477944374084
7
train loss item: 0.6706831455230713
8
train loss item: 0.11871139705181122
9
train loss item: 0.20554453134536743
10
train loss item: 0.2809920608997345
11
train loss item: 0.248797208070755
12
train loss item: 0.11959687620401382
13
train loss item: 0.43202435970306396
14
train loss item: 0.20499193668365479
15
train loss item: 0.5436276793479919
16
train loss item: 0.0769624337553978
17
train loss item: 0.21515947580337524
18
train loss item: 0.27290403842926025
19
train loss item: 0.22617888450622559
20
train loss item: 0.19445601105690002
21
train loss item: 0.1228906586766243
22
train loss item: 0.7897913455963135
23
train loss item: 0.7761570811271667
24
train loss item: 0.4486120939254761
25
train loss item: 0.18590395152568817
26
train loss item: 0.16223183274269104
27
train loss item: 0.20382177829742432
28
train loss item: 0.07611300051212311
29
train loss item: 0.6056474447250366
30
train loss item: 2.006225824356079
31
train loss item: 0.47431063652038574
32
train loss item: 0.10454030334949493
33
train loss item: 0.3648909032344818
34
train loss item: 0.13869871199131012
35
train loss item: 2.2230777740478516
36
train loss item: 0.4139723479747772
37
train loss item: 0.34924840927124023
38
train loss item: 0.3998027741909027
39
train loss item: 0.1977965235710144
40
train loss item: 0.14782129228115082
41
train loss item: 0.20690713822841644
42
train loss item: 0.2437760978937149
43
train loss item: 0.1565200537443161
44
train loss item: 0.5911412835121155
45
train loss item: 0.1229594498872757
46
train loss item: 0.1312558352947235
47
train loss item: 0.30405306816101074
48
train loss item: 0.18550512194633484
49
train loss item: 0.1360238790512085
50
train loss item: 0.2478359490633011
51
train loss item: 0.7313722372055054
52
train loss item: 0.09043450653553009
53
train loss item: 0.13930252194404602
54
train loss item: 2.100855827331543
55
train loss item: 0.16664615273475647
56
train loss item: 0.20527096092700958
57
train loss item: 0.2093914896249771
58
train loss item: 0.14309389889240265
59
train loss item: 0.12698045372962952
60
train loss item: 0.7057777643203735
61
train loss item: 2.024421215057373
62
train loss item: 0.1853543072938919
63
train loss item: 0.3094368577003479
64
train loss item: 0.14833547174930573
65
train loss item: 0.440658301115036
66
train loss item: 0.357058048248291
67
train loss item: 0.1814860850572586
68
train loss item: 0.23815034329891205
69
train loss item: 0.2642555236816406
70
train loss item: 0.2223915159702301
71
train loss item: 0.1323973834514618
72
train loss item: 0.15221932530403137
73
train loss item: 0.2515944838523865
74
train loss item: 0.1009744182229042
75
train loss item: 0.10874750465154648
76
train loss item: 0.7498637437820435
77
train loss item: 1.1777589321136475
78
train loss item: 0.07993277907371521
79
train loss item: 0.2414059340953827
80
train loss item: 0.11100710928440094
81
train loss item: 0.1705441176891327
82
train loss item: 0.17832942306995392
83
train loss item: 0.4908187985420227
84
train loss item: 0.3709242343902588
85
train loss item: 0.462660551071167
86
train loss item: 4.050101280212402
87
train loss item: 0.15391814708709717
88
train loss item: 0.3242780566215515
epoch train loss: 0.42108776185954555
testing phase
test loss item: 0.16011682152748108
test loss item: 0.11261594295501709
test loss item: 0.4933897852897644
test loss item: 0.21194490790367126
test loss item: 0.23606108129024506
test loss item: 0.12273454666137695
test loss item: 1.427880883216858
test loss item: 0.4643612802028656
test loss item: 0.19330355525016785
test loss item: 0.35697460174560547
test loss item: 0.731417179107666
test loss item: 0.1818525791168213
test loss item: 0.18271154165267944
test loss item: 0.2559642791748047
test loss item: 0.16010171175003052
test loss item: 0.09969040751457214
test loss item: 0.24039575457572937
test loss item: 0.4327731430530548
test loss item: 0.5623134970664978
test loss item: 0.22403833270072937
test loss item: 0.6831314563751221
test loss item: 0.3447764217853546
test loss item: 0.3451991081237793
test loss item: 0.14900946617126465
test loss item: 0.20026321709156036
test loss item: 0.1905100792646408
test loss item: 0.2692641019821167
test loss item: 0.1815820038318634
test loss item: 0.29160556197166443
test loss item: 0.3104008138179779
test loss item: 0.6593828201293945
test loss item: 0.10485173016786575
test loss item: 0.12710799276828766
test loss item: 0.5252296924591064
test loss item: 0.385076105594635
test loss item: 0.3871707320213318
test loss item: 0.688065767288208
test loss item: 1.2146506309509277
test loss item: 0.42672765254974365
test loss item: 0.24057769775390625
test loss item: 0.26559412479400635
test loss item: 0.27694904804229736
test loss item: 0.34081801772117615
test loss item: 0.19481322169303894
test loss item: 0.5480600595474243
test loss item: 0.33641713857650757
test loss item: 0.3493413031101227
test loss item: 0.19047966599464417
test loss item: 0.4124380052089691
test loss item: 0.5886915922164917
test loss item: 0.2861439287662506
test loss item: 0.13081584870815277
test loss item: 0.21093976497650146
test loss item: 0.1888154149055481
test loss item: 0.282595157623291
test loss item: 0.7213398814201355
test loss item: 0.4849461615085602
test loss item: 0.2302026003599167
test loss item: 0.2043219953775406
test loss item: 0.21460790932178497
test loss item: 0.42533376812934875
test loss item: 0.20330913364887238
test loss item: 0.17483282089233398
test loss item: 0.2360759973526001
test loss item: 0.6724326014518738
test loss item: 0.2980959713459015
test loss item: 0.2583908438682556
test loss item: 0.2281741052865982
test loss item: 0.48387113213539124
test loss item: 0.3579326868057251
test loss item: 0.08402455598115921
test loss item: 0.8092831373214722
test loss item: 0.2801523506641388
test loss item: 0.32556861639022827
test loss item: 0.12435448169708252
test loss item: 0.2666633725166321
test loss item: 0.15208686888217926
test loss item: 1.2036817073822021
test loss item: 0.36094698309898376
test loss item: 0.17064175009727478
test loss item: 0.07192754000425339
test loss item: 0.8105161190032959
test loss item: 0.7553820013999939
test loss item: 0.8385831117630005
test loss item: 0.19093641638755798
test loss item: 0.18477259576320648
test loss item: 0.0690803974866867
test loss item: 0.07900980114936829
test loss item: 0.15285401046276093
Epoch [25/100], Training Loss: 0.4211, Testing Loss: 0.3517
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 26/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3827531039714813
1
train loss item: 0.9949776530265808
2
train loss item: 0.19158175587654114
3
train loss item: 0.41973230242729187
4
train loss item: 0.321306973695755
5
train loss item: 0.27336934208869934
6
train loss item: 0.19455492496490479
7
train loss item: 0.6565683484077454
8
train loss item: 0.11387830972671509
9
train loss item: 0.19924773275852203
10
train loss item: 0.2702288329601288
11
train loss item: 0.2448059618473053
12
train loss item: 0.11911386251449585
13
train loss item: 0.42237919569015503
14
train loss item: 0.1993332803249359
15
train loss item: 0.5243560671806335
16
train loss item: 0.07610860466957092
17
train loss item: 0.20945313572883606
18
train loss item: 0.2645593285560608
19
train loss item: 0.22052912414073944
20
train loss item: 0.1902490109205246
21
train loss item: 0.1214357390999794
22
train loss item: 0.7581896781921387
23
train loss item: 0.7618152499198914
24
train loss item: 0.4374721646308899
25
train loss item: 0.1802915334701538
26
train loss item: 0.15911321341991425
27
train loss item: 0.19806675612926483
28
train loss item: 0.07518390566110611
29
train loss item: 0.5768498778343201
30
train loss item: 1.976835012435913
31
train loss item: 0.46366170048713684
32
train loss item: 0.10193236172199249
33
train loss item: 0.35989564657211304
34
train loss item: 0.1373639553785324
35
train loss item: 2.201671838760376
36
train loss item: 0.40799906849861145
37
train loss item: 0.35073330998420715
38
train loss item: 0.3914209008216858
39
train loss item: 0.19254285097122192
40
train loss item: 0.14253519475460052
41
train loss item: 0.201522096991539
42
train loss item: 0.2425239086151123
43
train loss item: 0.15350912511348724
44
train loss item: 0.5822046399116516
45
train loss item: 0.12081483006477356
46
train loss item: 0.1246773898601532
47
train loss item: 0.29417502880096436
48
train loss item: 0.182879239320755
49
train loss item: 0.13269172608852386
50
train loss item: 0.2408614605665207
51
train loss item: 0.7108153104782104
52
train loss item: 0.08972125500440598
53
train loss item: 0.13721010088920593
54
train loss item: 2.079338788986206
55
train loss item: 0.16582335531711578
56
train loss item: 0.19863471388816833
57
train loss item: 0.2046527862548828
58
train loss item: 0.13845771551132202
59
train loss item: 0.12312322109937668
60
train loss item: 0.6840918064117432
61
train loss item: 2.0005791187286377
62
train loss item: 0.17287184298038483
63
train loss item: 0.3036304712295532
64
train loss item: 0.1457594633102417
65
train loss item: 0.4303434491157532
66
train loss item: 0.3502189815044403
67
train loss item: 0.17634464800357819
68
train loss item: 0.23195941746234894
69
train loss item: 0.2558349668979645
70
train loss item: 0.21523064374923706
71
train loss item: 0.1306275874376297
72
train loss item: 0.14838407933712006
73
train loss item: 0.2459145188331604
74
train loss item: 0.09528826922178268
75
train loss item: 0.10870440304279327
76
train loss item: 0.7366687059402466
77
train loss item: 1.1570451259613037
78
train loss item: 0.07919079065322876
79
train loss item: 0.23793897032737732
80
train loss item: 0.10926752537488937
81
train loss item: 0.1633133888244629
82
train loss item: 0.17646124958992004
83
train loss item: 0.4757796823978424
84
train loss item: 0.3722054958343506
85
train loss item: 0.4538011848926544
86
train loss item: 4.0185065269470215
87
train loss item: 0.15331700444221497
88
train loss item: 0.3101872205734253
epoch train loss: 0.41288988811246463
testing phase
test loss item: 0.15812158584594727
test loss item: 0.10653965920209885
test loss item: 0.5057880878448486
test loss item: 0.20481735467910767
test loss item: 0.23779793083667755
test loss item: 0.1277974396944046
test loss item: 1.3513957262039185
test loss item: 0.4276379942893982
test loss item: 0.1938481330871582
test loss item: 0.3556923568248749
test loss item: 0.7405624985694885
test loss item: 0.17069308459758759
test loss item: 0.17728251218795776
test loss item: 0.2513964772224426
test loss item: 0.15731491148471832
test loss item: 0.09225349128246307
test loss item: 0.23326840996742249
test loss item: 0.4381411075592041
test loss item: 0.5396944284439087
test loss item: 0.22057467699050903
test loss item: 0.700065553188324
test loss item: 0.3288179636001587
test loss item: 0.39752212166786194
test loss item: 0.1456606686115265
test loss item: 0.1981518566608429
test loss item: 0.1884520798921585
test loss item: 0.2665579915046692
test loss item: 0.18263933062553406
test loss item: 0.2871858775615692
test loss item: 0.30581068992614746
test loss item: 0.6464084386825562
test loss item: 0.09528098255395889
test loss item: 0.1250590682029724
test loss item: 0.5284048318862915
test loss item: 0.39093437790870667
test loss item: 0.3823106288909912
test loss item: 0.6611130237579346
test loss item: 1.238196849822998
test loss item: 0.4245554506778717
test loss item: 0.23608052730560303
test loss item: 0.25655263662338257
test loss item: 0.33348777890205383
test loss item: 0.34247416257858276
test loss item: 0.18425504863262177
test loss item: 0.5567564368247986
test loss item: 0.3264157772064209
test loss item: 0.4012467563152313
test loss item: 0.18866802752017975
test loss item: 0.41344377398490906
test loss item: 0.5865963101387024
test loss item: 0.2856985330581665
test loss item: 0.1256904900074005
test loss item: 0.20826713740825653
test loss item: 0.17365342378616333
test loss item: 0.28536665439605713
test loss item: 0.7374351620674133
test loss item: 0.4745214283466339
test loss item: 0.2304149568080902
test loss item: 0.20276814699172974
test loss item: 0.21019306778907776
test loss item: 0.4256496727466583
test loss item: 0.1954789012670517
test loss item: 0.17178955674171448
test loss item: 0.22897985577583313
test loss item: 0.6840693354606628
test loss item: 0.2871844172477722
test loss item: 0.2540373206138611
test loss item: 0.22050032019615173
test loss item: 0.4845024347305298
test loss item: 0.34092456102371216
test loss item: 0.07814954966306686
test loss item: 0.7604207396507263
test loss item: 0.2862809896469116
test loss item: 0.3144381642341614
test loss item: 0.12179765105247498
test loss item: 0.3239273726940155
test loss item: 0.14745861291885376
test loss item: 1.2354847192764282
test loss item: 0.36106592416763306
test loss item: 0.17265020310878754
test loss item: 0.07040990889072418
test loss item: 0.7976619601249695
test loss item: 0.7339046001434326
test loss item: 0.8576908707618713
test loss item: 0.18867440521717072
test loss item: 0.18437236547470093
test loss item: 0.06674262136220932
test loss item: 0.07361135631799698
test loss item: 0.14921480417251587
Epoch [26/100], Training Loss: 0.4129, Testing Loss: 0.3501
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 27/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3759630620479584
1
train loss item: 0.9738597869873047
2
train loss item: 0.1848537176847458
3
train loss item: 0.40977755188941956
4
train loss item: 0.31363993883132935
5
train loss item: 0.26492446660995483
6
train loss item: 0.18789184093475342
7
train loss item: 0.6419533491134644
8
train loss item: 0.11201871931552887
9
train loss item: 0.19373197853565216
10
train loss item: 0.26186060905456543
11
train loss item: 0.242828831076622
12
train loss item: 0.11873973906040192
13
train loss item: 0.4130227267742157
14
train loss item: 0.19692394137382507
15
train loss item: 0.5085983872413635
16
train loss item: 0.07698380202054977
17
train loss item: 0.20383577048778534
18
train loss item: 0.258364200592041
19
train loss item: 0.21467988193035126
20
train loss item: 0.1857270449399948
21
train loss item: 0.11944826692342758
22
train loss item: 0.731713056564331
23
train loss item: 0.7448390126228333
24
train loss item: 0.4288330078125
25
train loss item: 0.1776617467403412
26
train loss item: 0.1580059677362442
27
train loss item: 0.19429489970207214
28
train loss item: 0.07591664046049118
29
train loss item: 0.5523719191551208
30
train loss item: 1.9453327655792236
31
train loss item: 0.4541932940483093
32
train loss item: 0.10074440389871597
33
train loss item: 0.3524392247200012
34
train loss item: 0.13825610280036926
35
train loss item: 2.178762197494507
36
train loss item: 0.4054015874862671
37
train loss item: 0.3530443608760834
38
train loss item: 0.38912051916122437
39
train loss item: 0.1886691302061081
40
train loss item: 0.13944678008556366
41
train loss item: 0.19853296875953674
42
train loss item: 0.24166788160800934
43
train loss item: 0.14852868020534515
44
train loss item: 0.5735654234886169
45
train loss item: 0.1196679174900055
46
train loss item: 0.11793030798435211
47
train loss item: 0.28483283519744873
48
train loss item: 0.17994631826877594
49
train loss item: 0.13163842260837555
50
train loss item: 0.23249351978302002
51
train loss item: 0.6929735541343689
52
train loss item: 0.09065715968608856
53
train loss item: 0.13469408452510834
54
train loss item: 2.0554893016815186
55
train loss item: 0.16488125920295715
56
train loss item: 0.1933138370513916
57
train loss item: 0.20295743644237518
58
train loss item: 0.13355091214179993
59
train loss item: 0.11855550110340118
60
train loss item: 0.6643123030662537
61
train loss item: 1.9735621213912964
62
train loss item: 0.16528856754302979
63
train loss item: 0.29838359355926514
64
train loss item: 0.1407061666250229
65
train loss item: 0.42230352759361267
66
train loss item: 0.3468182682991028
67
train loss item: 0.17188583314418793
68
train loss item: 0.22589467465877533
69
train loss item: 0.24983321130275726
70
train loss item: 0.21143832802772522
71
train loss item: 0.12807956337928772
72
train loss item: 0.14573684334754944
73
train loss item: 0.24059244990348816
74
train loss item: 0.09278210252523422
75
train loss item: 0.10601335763931274
76
train loss item: 0.7214694023132324
77
train loss item: 1.1378297805786133
78
train loss item: 0.08194003254175186
79
train loss item: 0.23653997480869293
80
train loss item: 0.10804370790719986
81
train loss item: 0.15933427214622498
82
train loss item: 0.17435896396636963
83
train loss item: 0.46440890431404114
84
train loss item: 0.37572723627090454
85
train loss item: 0.44558900594711304
86
train loss item: 3.9829914569854736
87
train loss item: 0.15109358727931976
88
train loss item: 0.30046385526657104
epoch train loss: 0.4057075578007805
testing phase
test loss item: 0.1579412966966629
test loss item: 0.09913254529237747
test loss item: 0.497882217168808
test loss item: 0.19892004132270813
test loss item: 0.23251070082187653
test loss item: 0.12757667899131775
test loss item: 1.351492166519165
test loss item: 0.42258501052856445
test loss item: 0.18766865134239197
test loss item: 0.3438052833080292
test loss item: 0.7300349473953247
test loss item: 0.1550530344247818
test loss item: 0.16372528672218323
test loss item: 0.2456575334072113
test loss item: 0.15149779617786407
test loss item: 0.08482217788696289
test loss item: 0.2328110933303833
test loss item: 0.4282001554965973
test loss item: 0.5335811972618103
test loss item: 0.21810927987098694
test loss item: 0.6900412440299988
test loss item: 0.3250683546066284
test loss item: 0.4082895517349243
test loss item: 0.1452452540397644
test loss item: 0.19342680275440216
test loss item: 0.1879216730594635
test loss item: 0.2631213665008545
test loss item: 0.17775864899158478
test loss item: 0.28021374344825745
test loss item: 0.29649269580841064
test loss item: 0.6387368440628052
test loss item: 0.08550094068050385
test loss item: 0.12456962466239929
test loss item: 0.5163851976394653
test loss item: 0.38185039162635803
test loss item: 0.37318259477615356
test loss item: 0.6512255668640137
test loss item: 1.2204080820083618
test loss item: 0.4122006297111511
test loss item: 0.23636028170585632
test loss item: 0.25612789392471313
test loss item: 0.34170591831207275
test loss item: 0.33028215169906616
test loss item: 0.1782854199409485
test loss item: 0.5442166328430176
test loss item: 0.32660970091819763
test loss item: 0.410830020904541
test loss item: 0.18959006667137146
test loss item: 0.40391331911087036
test loss item: 0.5788049101829529
test loss item: 0.26936691999435425
test loss item: 0.1185472160577774
test loss item: 0.20458976924419403
test loss item: 0.15607626736164093
test loss item: 0.27754732966423035
test loss item: 0.7272285223007202
test loss item: 0.46862921118736267
test loss item: 0.2206941843032837
test loss item: 0.20068348944187164
test loss item: 0.19628183543682098
test loss item: 0.41012337803840637
test loss item: 0.19812020659446716
test loss item: 0.17376366257667542
test loss item: 0.21765030920505524
test loss item: 0.68459153175354
test loss item: 0.2771220803260803
test loss item: 0.2543487548828125
test loss item: 0.21618568897247314
test loss item: 0.4735044538974762
test loss item: 0.33520960807800293
test loss item: 0.07135048508644104
test loss item: 0.7605789303779602
test loss item: 0.28776127099990845
test loss item: 0.31844964623451233
test loss item: 0.11964447051286697
test loss item: 0.3341839611530304
test loss item: 0.1465417742729187
test loss item: 1.2229459285736084
test loss item: 0.3594217002391815
test loss item: 0.17184190452098846
test loss item: 0.07043002545833588
test loss item: 0.7917110919952393
test loss item: 0.7238073945045471
test loss item: 0.8470420837402344
test loss item: 0.189043328166008
test loss item: 0.1825612485408783
test loss item: 0.06571143120527267
test loss item: 0.06950772553682327
test loss item: 0.1466042846441269
Epoch [27/100], Training Loss: 0.4057, Testing Loss: 0.3448
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 28/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36948341131210327
1
train loss item: 0.9518439769744873
2
train loss item: 0.18115510046482086
3
train loss item: 0.39623817801475525
4
train loss item: 0.3091404438018799
5
train loss item: 0.25868338346481323
6
train loss item: 0.18206210434436798
7
train loss item: 0.6243535280227661
8
train loss item: 0.10894926637411118
9
train loss item: 0.1901882141828537
10
train loss item: 0.25369879603385925
11
train loss item: 0.23858754336833954
12
train loss item: 0.11750951409339905
13
train loss item: 0.4007665812969208
14
train loss item: 0.19371236860752106
15
train loss item: 0.5037709474563599
16
train loss item: 0.07509560137987137
17
train loss item: 0.19744773209095
18
train loss item: 0.2536124587059021
19
train loss item: 0.2117348313331604
20
train loss item: 0.1838611364364624
21
train loss item: 0.1159980520606041
22
train loss item: 0.7186329364776611
23
train loss item: 0.7214509844779968
24
train loss item: 0.42322322726249695
25
train loss item: 0.17694950103759766
26
train loss item: 0.15668600797653198
27
train loss item: 0.18962202966213226
28
train loss item: 0.07386963069438934
29
train loss item: 0.5400457978248596
30
train loss item: 1.9106190204620361
31
train loss item: 0.4400694668292999
32
train loss item: 0.09926998615264893
33
train loss item: 0.33831101655960083
34
train loss item: 0.13829246163368225
35
train loss item: 2.1525752544403076
36
train loss item: 0.3978096842765808
37
train loss item: 0.3483668565750122
38
train loss item: 0.3765946924686432
39
train loss item: 0.18509402871131897
40
train loss item: 0.13934862613677979
41
train loss item: 0.1935291886329651
42
train loss item: 0.24009548127651215
43
train loss item: 0.1422889232635498
44
train loss item: 0.5620088577270508
45
train loss item: 0.11903344839811325
46
train loss item: 0.11484270542860031
47
train loss item: 0.2806154489517212
48
train loss item: 0.1753896027803421
49
train loss item: 0.1300680786371231
50
train loss item: 0.22710292041301727
51
train loss item: 0.6790835857391357
52
train loss item: 0.08827870339155197
53
train loss item: 0.1312868595123291
54
train loss item: 2.0286383628845215
55
train loss item: 0.1607722043991089
56
train loss item: 0.1884499341249466
57
train loss item: 0.2016187310218811
58
train loss item: 0.13103391230106354
59
train loss item: 0.11380496621131897
60
train loss item: 0.6491554379463196
61
train loss item: 1.9415034055709839
62
train loss item: 0.1625928431749344
63
train loss item: 0.2938997745513916
64
train loss item: 0.13335633277893066
65
train loss item: 0.41213491559028625
66
train loss item: 0.33722227811813354
67
train loss item: 0.16697648167610168
68
train loss item: 0.22284230589866638
69
train loss item: 0.2441776692867279
70
train loss item: 0.21019324660301208
71
train loss item: 0.12373854964971542
72
train loss item: 0.13906823098659515
73
train loss item: 0.23769031465053558
74
train loss item: 0.09253691881895065
75
train loss item: 0.10118456184864044
76
train loss item: 0.7023186683654785
77
train loss item: 1.1265289783477783
78
train loss item: 0.08310127258300781
79
train loss item: 0.2323153167963028
80
train loss item: 0.10646510124206543
81
train loss item: 0.15830890834331512
82
train loss item: 0.16962982714176178
83
train loss item: 0.4593903720378876
84
train loss item: 0.37029382586479187
85
train loss item: 0.4341821074485779
86
train loss item: 3.941990613937378
87
train loss item: 0.14602424204349518
88
train loss item: 0.2918192744255066
epoch train loss: 0.3982394165202473
testing phase
test loss item: 0.158411905169487
test loss item: 0.09589081257581711
test loss item: 0.4801222085952759
test loss item: 0.19654230773448944
test loss item: 0.22397328913211823
test loss item: 0.1221509650349617
test loss item: 1.421967625617981
test loss item: 0.44128453731536865
test loss item: 0.18251734972000122
test loss item: 0.3311576545238495
test loss item: 0.7095563411712646
test loss item: 0.14574158191680908
test loss item: 0.1527939885854721
test loss item: 0.24269439280033112
test loss item: 0.14750516414642334
test loss item: 0.08111949265003204
test loss item: 0.2361512929201126
test loss item: 0.412097305059433
test loss item: 0.5399823188781738
test loss item: 0.21881785988807678
test loss item: 0.6639974117279053
test loss item: 0.3317982256412506
test loss item: 0.37611424922943115
test loss item: 0.14643605053424835
test loss item: 0.18958640098571777
test loss item: 0.1881432682275772
test loss item: 0.2604847252368927
test loss item: 0.16942401230335236
test loss item: 0.2750012278556824
test loss item: 0.2886105179786682
test loss item: 0.6426942348480225
test loss item: 0.08028830587863922
test loss item: 0.12464289367198944
test loss item: 0.49907881021499634
test loss item: 0.3664165437221527
test loss item: 0.3659113943576813
test loss item: 0.658398449420929
test loss item: 1.1789571046829224
test loss item: 0.39805394411087036
test loss item: 0.23947101831436157
test loss item: 0.2624163329601288
test loss item: 0.3023020327091217
test loss item: 0.31631600856781006
test loss item: 0.17970748245716095
test loss item: 0.5204451084136963
test loss item: 0.33109572529792786
test loss item: 0.3756380081176758
test loss item: 0.19181594252586365
test loss item: 0.3921720087528229
test loss item: 0.5716593265533447
test loss item: 0.25064054131507874
test loss item: 0.11464614421129227
test loss item: 0.20268596708774567
test loss item: 0.14557787775993347
test loss item: 0.2660602331161499
test loss item: 0.7038061618804932
test loss item: 0.46670106053352356
test loss item: 0.20971561968326569
test loss item: 0.19900235533714294
test loss item: 0.1840735673904419
test loss item: 0.3924413323402405
test loss item: 0.20530015230178833
test loss item: 0.17804381251335144
test loss item: 0.21118906140327454
test loss item: 0.676408588886261
test loss item: 0.27216407656669617
test loss item: 0.2565867006778717
test loss item: 0.217351034283638
test loss item: 0.45807966589927673
test loss item: 0.3393275737762451
test loss item: 0.06830570846796036
test loss item: 0.8013750910758972
test loss item: 0.28416067361831665
test loss item: 0.3318674862384796
test loss item: 0.11875862628221512
test loss item: 0.2971118688583374
test loss item: 0.14828789234161377
test loss item: 1.1797305345535278
test loss item: 0.35604724287986755
test loss item: 0.16755424439907074
test loss item: 0.0701625719666481
test loss item: 0.7962074279785156
test loss item: 0.7307188510894775
test loss item: 0.82024747133255
test loss item: 0.1929699331521988
test loss item: 0.17928345501422882
test loss item: 0.06453977525234222
test loss item: 0.06652645766735077
test loss item: 0.14706987142562866
Epoch [28/100], Training Loss: 0.3982, Testing Loss: 0.3393
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Epoch 29/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36396703124046326
1
train loss item: 0.9299513101577759
2
train loss item: 0.17903149127960205
3
train loss item: 0.3845365643501282
4
train loss item: 0.30707958340644836
5
train loss item: 0.25441256165504456
6
train loss item: 0.1734430193901062
7
train loss item: 0.6061534881591797
8
train loss item: 0.10574167966842651
9
train loss item: 0.18803930282592773
10
train loss item: 0.24779240787029266
11
train loss item: 0.2331380993127823
12
train loss item: 0.11601851135492325
13
train loss item: 0.390057235956192
14
train loss item: 0.18885235488414764
15
train loss item: 0.5042876601219177
16
train loss item: 0.07123059034347534
17
train loss item: 0.19021707773208618
18
train loss item: 0.2488991916179657
19
train loss item: 0.20823734998703003
20
train loss item: 0.17824044823646545
21
train loss item: 0.11576198786497116
22
train loss item: 0.7114145755767822
23
train loss item: 0.6984643340110779
24
train loss item: 0.4172588586807251
25
train loss item: 0.17849716544151306
26
train loss item: 0.15392908453941345
27
train loss item: 0.18382737040519714
28
train loss item: 0.07008607685565948
29
train loss item: 0.5365066528320312
30
train loss item: 1.8784863948822021
31
train loss item: 0.4258383512496948
32
train loss item: 0.09830166399478912
33
train loss item: 0.3267984390258789
34
train loss item: 0.13727568089962006
35
train loss item: 2.12695050239563
36
train loss item: 0.3860328197479248
37
train loss item: 0.3377154767513275
38
train loss item: 0.3570399582386017
39
train loss item: 0.18249066174030304
40
train loss item: 0.1384250819683075
41
train loss item: 0.1874847561120987
42
train loss item: 0.2377070188522339
43
train loss item: 0.13840186595916748
44
train loss item: 0.5502680540084839
45
train loss item: 0.11989401280879974
46
train loss item: 0.11412867903709412
47
train loss item: 0.27886107563972473
48
train loss item: 0.16956448554992676
49
train loss item: 0.12873640656471252
50
train loss item: 0.22268472611904144
51
train loss item: 0.6684109568595886
52
train loss item: 0.08254241943359375
53
train loss item: 0.12914784252643585
54
train loss item: 2.0026683807373047
55
train loss item: 0.15381257236003876
56
train loss item: 0.18475618958473206
57
train loss item: 0.19760657846927643
58
train loss item: 0.1295420229434967
59
train loss item: 0.11269091069698334
60
train loss item: 0.6377166509628296
61
train loss item: 1.9112792015075684
62
train loss item: 0.16160593926906586
63
train loss item: 0.289157509803772
64
train loss item: 0.13025373220443726
65
train loss item: 0.39689916372299194
66
train loss item: 0.32361528277397156
67
train loss item: 0.16394908726215363
68
train loss item: 0.2193765789270401
69
train loss item: 0.23788678646087646
70
train loss item: 0.20816749334335327
71
train loss item: 0.11952811479568481
72
train loss item: 0.13306790590286255
73
train loss item: 0.23548077046871185
74
train loss item: 0.0933830738067627
75
train loss item: 0.09866904467344284
76
train loss item: 0.683235228061676
77
train loss item: 1.1205439567565918
78
train loss item: 0.08129697293043137
79
train loss item: 0.2250453680753708
80
train loss item: 0.10674901306629181
81
train loss item: 0.15757253766059875
82
train loss item: 0.16493114829063416
83
train loss item: 0.4555138349533081
84
train loss item: 0.35594868659973145
85
train loss item: 0.4250302314758301
86
train loss item: 3.902038097381592
87
train loss item: 0.14100338518619537
88
train loss item: 0.28079771995544434
epoch train loss: 0.39100089401341553
testing phase
test loss item: 0.15742716193199158
test loss item: 0.09877999126911163
test loss item: 0.46963435411453247
test loss item: 0.1949828565120697
test loss item: 0.21850521862506866
test loss item: 0.1162235215306282
test loss item: 1.4720579385757446
test loss item: 0.4508519172668457
test loss item: 0.1820020228624344
test loss item: 0.324518620967865
test loss item: 0.6967424750328064
test loss item: 0.1434505730867386
test loss item: 0.14829425513744354
test loss item: 0.23812733590602875
test loss item: 0.14768832921981812
test loss item: 0.0824161246418953
test loss item: 0.23286518454551697
test loss item: 0.4015164375305176
test loss item: 0.5416977405548096
test loss item: 0.21592167019844055
test loss item: 0.6446936130523682
test loss item: 0.3330584168434143
test loss item: 0.3311353623867035
test loss item: 0.1459837704896927
test loss item: 0.18618588149547577
test loss item: 0.18620087206363678
test loss item: 0.25631073117256165
test loss item: 0.16298796236515045
test loss item: 0.2714308202266693
test loss item: 0.2834770679473877
test loss item: 0.6481429934501648
test loss item: 0.08025062084197998
test loss item: 0.12411115318536758
test loss item: 0.4883978068828583
test loss item: 0.3569442927837372
test loss item: 0.3627239763736725
test loss item: 0.6625753045082092
test loss item: 1.1526988744735718
test loss item: 0.38875946402549744
test loss item: 0.23783662915229797
test loss item: 0.2636275291442871
test loss item: 0.24825118482112885
test loss item: 0.3096274137496948
test loss item: 0.1795320361852646
test loss item: 0.5025952458381653
test loss item: 0.32668203115463257
test loss item: 0.3264472484588623
test loss item: 0.18997476994991302
test loss item: 0.38513803482055664
test loss item: 0.5669942498207092
test loss item: 0.2406986504793167
test loss item: 0.11337385326623917
test loss item: 0.20043601095676422
test loss item: 0.14175978302955627
test loss item: 0.25896087288856506
test loss item: 0.691056489944458
test loss item: 0.46393340826034546
test loss item: 0.20243263244628906
test loss item: 0.195634126663208
test loss item: 0.1795215606689453
test loss item: 0.3837045729160309
test loss item: 0.20471280813217163
test loss item: 0.17792658507823944
test loss item: 0.2078799307346344
test loss item: 0.6683120131492615
test loss item: 0.26918721199035645
test loss item: 0.25304532051086426
test loss item: 0.21683739125728607
test loss item: 0.44857314229011536
test loss item: 0.3421669602394104
test loss item: 0.06994393467903137
test loss item: 0.8253742456436157
test loss item: 0.2767012119293213
test loss item: 0.3339441418647766
test loss item: 0.11647004634141922
test loss item: 0.24245207011699677
test loss item: 0.14852391183376312
test loss item: 1.149919867515564
test loss item: 0.3496854901313782
test loss item: 0.16215646266937256
test loss item: 0.06864850968122482
test loss item: 0.799997866153717
test loss item: 0.7378600835800171
test loss item: 0.8036370873451233
test loss item: 0.1939665526151657
test loss item: 0.17382176220417023
test loss item: 0.0630292147397995
test loss item: 0.06474515050649643
test loss item: 0.1497550755739212
Epoch [29/100], Training Loss: 0.3910, Testing Loss: 0.3340
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 30/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36008837819099426
1
train loss item: 0.9099957346916199
2
train loss item: 0.17467467486858368
3
train loss item: 0.37815168499946594
4
train loss item: 0.306513249874115
5
train loss item: 0.25191712379455566
6
train loss item: 0.1648682802915573
7
train loss item: 0.5907726287841797
8
train loss item: 0.10543826222419739
9
train loss item: 0.18472418189048767
10
train loss item: 0.2446848750114441
11
train loss item: 0.23076026141643524
12
train loss item: 0.11404277384281158
13
train loss item: 0.38433536887168884
14
train loss item: 0.185262992978096
15
train loss item: 0.50007563829422
16
train loss item: 0.06835374236106873
17
train loss item: 0.18613749742507935
18
train loss item: 0.24446545541286469
19
train loss item: 0.20140711963176727
20
train loss item: 0.16776926815509796
21
train loss item: 0.11754869669675827
22
train loss item: 0.6979308724403381
23
train loss item: 0.6814780831336975
24
train loss item: 0.40811678767204285
25
train loss item: 0.18147192895412445
26
train loss item: 0.15217405557632446
27
train loss item: 0.17905041575431824
28
train loss item: 0.06765105575323105
29
train loss item: 0.5310750603675842
30
train loss item: 1.851485252380371
31
train loss item: 0.41700127720832825
32
train loss item: 0.0988689735531807
33
train loss item: 0.32372671365737915
34
train loss item: 0.13849608600139618
35
train loss item: 2.105201005935669
36
train loss item: 0.37710192799568176
37
train loss item: 0.33046528697013855
38
train loss item: 0.34491318464279175
39
train loss item: 0.18100102245807648
40
train loss item: 0.13411009311676025
41
train loss item: 0.18362043797969818
42
train loss item: 0.2361692488193512
43
train loss item: 0.13653194904327393
44
train loss item: 0.5415369272232056
45
train loss item: 0.12163197249174118
46
train loss item: 0.11438319832086563
47
train loss item: 0.27500399947166443
48
train loss item: 0.16545987129211426
49
train loss item: 0.12814198434352875
50
train loss item: 0.21651174128055573
51
train loss item: 0.6577393412590027
52
train loss item: 0.07833270728588104
53
train loss item: 0.1280377209186554
54
train loss item: 1.9811880588531494
55
train loss item: 0.14831794798374176
56
train loss item: 0.18333110213279724
57
train loss item: 0.19261354207992554
58
train loss item: 0.12552359700202942
59
train loss item: 0.11478252708911896
60
train loss item: 0.6260163187980652
61
train loss item: 1.887596607208252
62
train loss item: 0.1613103151321411
63
train loss item: 0.2848016917705536
64
train loss item: 0.1321021020412445
65
train loss item: 0.3812258541584015
66
train loss item: 0.31388425827026367
67
train loss item: 0.16283918917179108
68
train loss item: 0.2121918946504593
69
train loss item: 0.23274873197078705
70
train loss item: 0.20544792711734772
71
train loss item: 0.11729186028242111
72
train loss item: 0.13128943741321564
73
train loss item: 0.2305876612663269
74
train loss item: 0.09289117902517319
75
train loss item: 0.09910248219966888
76
train loss item: 0.6672210097312927
77
train loss item: 1.1124283075332642
78
train loss item: 0.07756847143173218
79
train loss item: 0.22060926258563995
80
train loss item: 0.1090925931930542
81
train loss item: 0.15641328692436218
82
train loss item: 0.16372129321098328
83
train loss item: 0.44798651337623596
84
train loss item: 0.3421904444694519
85
train loss item: 0.41872718930244446
86
train loss item: 3.869475841522217
87
train loss item: 0.1374981850385666
88
train loss item: 0.2706317901611328
epoch train loss: 0.3850231072708462
testing phase
test loss item: 0.1551540046930313
test loss item: 0.10230019688606262
test loss item: 0.4654299020767212
test loss item: 0.19226303696632385
test loss item: 0.21417878568172455
test loss item: 0.10817451775074005
test loss item: 1.4398835897445679
test loss item: 0.44530898332595825
test loss item: 0.18067005276679993
test loss item: 0.31817787885665894
test loss item: 0.6882013082504272
test loss item: 0.1447303295135498
test loss item: 0.1488412767648697
test loss item: 0.22804704308509827
test loss item: 0.14696308970451355
test loss item: 0.0874854251742363
test loss item: 0.22381258010864258
test loss item: 0.39364421367645264
test loss item: 0.5333462953567505
test loss item: 0.2089872658252716
test loss item: 0.6350260376930237
test loss item: 0.32429951429367065
test loss item: 0.2955475151538849
test loss item: 0.1416979432106018
test loss item: 0.1827479898929596
test loss item: 0.18170875310897827
test loss item: 0.24819867312908173
test loss item: 0.15763436257839203
test loss item: 0.2645324766635895
test loss item: 0.27604761719703674
test loss item: 0.6353684067726135
test loss item: 0.08321069926023483
test loss item: 0.12134599685668945
test loss item: 0.48162248730659485
test loss item: 0.35158196091651917
test loss item: 0.35783833265304565
test loss item: 0.65196293592453
test loss item: 1.1401113271713257
test loss item: 0.3800547122955322
test loss item: 0.22545777261257172
test loss item: 0.25494492053985596
test loss item: 0.20527087152004242
test loss item: 0.3034067749977112
test loss item: 0.17429669201374054
test loss item: 0.49162763357162476
test loss item: 0.31528836488723755
test loss item: 0.28794071078300476
test loss item: 0.18276749551296234
test loss item: 0.3810241222381592
test loss item: 0.5572590231895447
test loss item: 0.23454780876636505
test loss item: 0.11099976301193237
test loss item: 0.19451841711997986
test loss item: 0.142521932721138
test loss item: 0.25317418575286865
test loss item: 0.685572624206543
test loss item: 0.45935389399528503
test loss item: 0.19665023684501648
test loss item: 0.19082149863243103
test loss item: 0.17827822268009186
test loss item: 0.3736754059791565
test loss item: 0.1998937577009201
test loss item: 0.1729270964860916
test loss item: 0.20422717928886414
test loss item: 0.6614121198654175
test loss item: 0.26616862416267395
test loss item: 0.244929239153862
test loss item: 0.21069267392158508
test loss item: 0.445546418428421
test loss item: 0.33655524253845215
test loss item: 0.07398944348096848
test loss item: 0.8037362694740295
test loss item: 0.2683549225330353
test loss item: 0.31795600056648254
test loss item: 0.11515507102012634
test loss item: 0.19522906839847565
test loss item: 0.14433801174163818
test loss item: 1.1410971879959106
test loss item: 0.3409542739391327
test loss item: 0.15561053156852722
test loss item: 0.06682460755109787
test loss item: 0.787033200263977
test loss item: 0.7255001664161682
test loss item: 0.79618901014328
test loss item: 0.187038853764534
test loss item: 0.17031998932361603
test loss item: 0.06230712682008743
test loss item: 0.06551758199930191
test loss item: 0.1484803706407547
Epoch [30/100], Training Loss: 0.3850, Testing Loss: 0.3263
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 31/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.35581958293914795
1
train loss item: 0.891343891620636
2
train loss item: 0.1698620617389679
3
train loss item: 0.3661664128303528
4
train loss item: 0.3022240698337555
5
train loss item: 0.2486688196659088
6
train loss item: 0.1599198579788208
7
train loss item: 0.5774073600769043
8
train loss item: 0.10332249850034714
9
train loss item: 0.17931170761585236
10
train loss item: 0.23925819993019104
11
train loss item: 0.22763606905937195
12
train loss item: 0.11243303120136261
13
train loss item: 0.3763556480407715
14
train loss item: 0.18132461607456207
15
train loss item: 0.4928445816040039
16
train loss item: 0.06678599864244461
17
train loss item: 0.1851262003183365
18
train loss item: 0.24049444496631622
19
train loss item: 0.19706317782402039
20
train loss item: 0.16078835725784302
21
train loss item: 0.1173899695277214
22
train loss item: 0.6820012331008911
23
train loss item: 0.6648526787757874
24
train loss item: 0.400030255317688
25
train loss item: 0.18330958485603333
26
train loss item: 0.151009663939476
27
train loss item: 0.1735178828239441
28
train loss item: 0.06622785329818726
29
train loss item: 0.5180395841598511
30
train loss item: 1.8224983215332031
31
train loss item: 0.40791085362434387
32
train loss item: 0.09774573892354965
33
train loss item: 0.3150283992290497
34
train loss item: 0.13989371061325073
35
train loss item: 2.0857300758361816
36
train loss item: 0.3708888590335846
37
train loss item: 0.33001983165740967
38
train loss item: 0.33420807123184204
39
train loss item: 0.1793205440044403
40
train loss item: 0.1300429105758667
41
train loss item: 0.17832760512828827
42
train loss item: 0.23492223024368286
43
train loss item: 0.13272173702716827
44
train loss item: 0.5323274731636047
45
train loss item: 0.12067990750074387
46
train loss item: 0.11382841318845749
47
train loss item: 0.26896634697914124
48
train loss item: 0.1617303341627121
49
train loss item: 0.1240302324295044
50
train loss item: 0.21226650476455688
51
train loss item: 0.6426953673362732
52
train loss item: 0.07464766502380371
53
train loss item: 0.12476904690265656
54
train loss item: 1.9624381065368652
55
train loss item: 0.14440515637397766
56
train loss item: 0.1814037263393402
57
train loss item: 0.18943911790847778
58
train loss item: 0.12142814695835114
59
train loss item: 0.11497987061738968
60
train loss item: 0.6120432615280151
61
train loss item: 1.8649555444717407
62
train loss item: 0.1577138453722
63
train loss item: 0.28133389353752136
64
train loss item: 0.13038668036460876
65
train loss item: 0.37344929575920105
66
train loss item: 0.3047603666782379
67
train loss item: 0.16096161305904388
68
train loss item: 0.20505836606025696
69
train loss item: 0.22977665066719055
70
train loss item: 0.20245057344436646
71
train loss item: 0.11678560823202133
72
train loss item: 0.12750768661499023
73
train loss item: 0.22395558655261993
74
train loss item: 0.09052874147891998
75
train loss item: 0.10003706067800522
76
train loss item: 0.6509976387023926
77
train loss item: 1.09981107711792
78
train loss item: 0.07372792810201645
79
train loss item: 0.21870861947536469
80
train loss item: 0.10980680584907532
81
train loss item: 0.15351277589797974
82
train loss item: 0.1603298783302307
83
train loss item: 0.4389322102069855
84
train loss item: 0.3358226418495178
85
train loss item: 0.40472856163978577
86
train loss item: 3.841003894805908
87
train loss item: 0.13289234042167664
88
train loss item: 0.2666851580142975
epoch train loss: 0.37874712250875625
testing phase
test loss item: 0.153206467628479
test loss item: 0.10256288945674896
test loss item: 0.47506511211395264
test loss item: 0.1894281804561615
test loss item: 0.21242068707942963
test loss item: 0.10384588688611984
test loss item: 1.3619939088821411
test loss item: 0.43151795864105225
test loss item: 0.18174462020397186
test loss item: 0.3165909945964813
test loss item: 0.6949393153190613
test loss item: 0.1468275487422943
test loss item: 0.15100187063217163
test loss item: 0.2172810286283493
test loss item: 0.14466871321201324
test loss item: 0.0928494930267334
test loss item: 0.2147434651851654
test loss item: 0.3933534622192383
test loss item: 0.5204607844352722
test loss item: 0.20295612514019012
test loss item: 0.6431121230125427
test loss item: 0.3128090500831604
test loss item: 0.28729161620140076
test loss item: 0.13551940023899078
test loss item: 0.1808464378118515
test loss item: 0.1770940124988556
test loss item: 0.24205142259597778
test loss item: 0.15479253232479095
test loss item: 0.25690770149230957
test loss item: 0.27082914113998413
test loss item: 0.6207100749015808
test loss item: 0.08542625606060028
test loss item: 0.11706940084695816
test loss item: 0.4825083315372467
test loss item: 0.3546087443828583
test loss item: 0.35439586639404297
test loss item: 0.6344297528266907
test loss item: 1.1601046323776245
test loss item: 0.37639734148979187
test loss item: 0.21055176854133606
test loss item: 0.24278970062732697
test loss item: 0.1933005452156067
test loss item: 0.30042997002601624
test loss item: 0.16849614679813385
test loss item: 0.49433135986328125
test loss item: 0.3048938810825348
test loss item: 0.27901598811149597
test loss item: 0.17785663902759552
test loss item: 0.38416656851768494
test loss item: 0.5537152290344238
test loss item: 0.23374506831169128
test loss item: 0.10951977223157883
test loss item: 0.18962711095809937
test loss item: 0.14603807032108307
test loss item: 0.25214090943336487
test loss item: 0.6982969641685486
test loss item: 0.4559730887413025
test loss item: 0.1953713297843933
test loss item: 0.18788298964500427
test loss item: 0.1782868206501007
test loss item: 0.3685702085494995
test loss item: 0.1969124674797058
test loss item: 0.16751423478126526
test loss item: 0.20005986094474792
test loss item: 0.6688111424446106
test loss item: 0.2643486559391022
test loss item: 0.23893624544143677
test loss item: 0.2018248736858368
test loss item: 0.4488385319709778
test loss item: 0.329662561416626
test loss item: 0.07671184092760086
test loss item: 0.7572774887084961
test loss item: 0.26504772901535034
test loss item: 0.2963417172431946
test loss item: 0.11531803011894226
test loss item: 0.17988277971744537
test loss item: 0.13788357377052307
test loss item: 1.1696058511734009
test loss item: 0.3353521227836609
test loss item: 0.15197846293449402
test loss item: 0.06677473336458206
test loss item: 0.7747514247894287
test loss item: 0.7075138688087463
test loss item: 0.8126716613769531
test loss item: 0.17772969603538513
test loss item: 0.17018209397792816
test loss item: 0.06381069123744965
test loss item: 0.06924330443143845
test loss item: 0.14522311091423035
Epoch [31/100], Training Loss: 0.3787, Testing Loss: 0.3221
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Epoch 32/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.34975549578666687
1
train loss item: 0.875616192817688
2
train loss item: 0.16408883035182953
3
train loss item: 0.3545040786266327
4
train loss item: 0.29196587204933167
5
train loss item: 0.24176084995269775
6
train loss item: 0.15596970915794373
7
train loss item: 0.5676847100257874
8
train loss item: 0.09901605546474457
9
train loss item: 0.17465578019618988
10
train loss item: 0.23229743540287018
11
train loss item: 0.2232014238834381
12
train loss item: 0.11136483401060104
13
train loss item: 0.366256982088089
14
train loss item: 0.17743760347366333
15
train loss item: 0.4825955331325531
16
train loss item: 0.065524160861969
17
train loss item: 0.1840483695268631
18
train loss item: 0.23537598550319672
19
train loss item: 0.19454292953014374
20
train loss item: 0.16001689434051514
21
train loss item: 0.11598911881446838
22
train loss item: 0.6627424955368042
23
train loss item: 0.6502511501312256
24
train loss item: 0.39291611313819885
25
train loss item: 0.1802951842546463
26
train loss item: 0.1489480584859848
27
train loss item: 0.1686268448829651
28
train loss item: 0.06459589302539825
29
train loss item: 0.5020390152931213
30
train loss item: 1.7963025569915771
31
train loss item: 0.39728108048439026
32
train loss item: 0.09345665574073792
33
train loss item: 0.30257448554039
34
train loss item: 0.1399896889925003
35
train loss item: 2.0692222118377686
36
train loss item: 0.3660784065723419
37
train loss item: 0.33150729537010193
38
train loss item: 0.32392632961273193
39
train loss item: 0.17682209610939026
40
train loss item: 0.12744687497615814
41
train loss item: 0.1744074672460556
42
train loss item: 0.23362022638320923
43
train loss item: 0.12840695679187775
44
train loss item: 0.5248198509216309
45
train loss item: 0.11697928607463837
46
train loss item: 0.10992727428674698
47
train loss item: 0.2614641785621643
48
train loss item: 0.15781505405902863
49
train loss item: 0.11908569186925888
50
train loss item: 0.20995491743087769
51
train loss item: 0.627007007598877
52
train loss item: 0.0714723989367485
53
train loss item: 0.12010955810546875
54
train loss item: 1.9468797445297241
55
train loss item: 0.141719788312912
56
train loss item: 0.1771720051765442
57
train loss item: 0.18824970722198486
58
train loss item: 0.11920499056577682
59
train loss item: 0.11128426343202591
60
train loss item: 0.5975191593170166
61
train loss item: 1.845123052597046
62
train loss item: 0.15090782940387726
63
train loss item: 0.27645111083984375
64
train loss item: 0.1255190521478653
65
train loss item: 0.3685789108276367
66
train loss item: 0.29626303911209106
67
train loss item: 0.15791283547878265
68
train loss item: 0.20049840211868286
69
train loss item: 0.22715598344802856
70
train loss item: 0.19873937964439392
71
train loss item: 0.11658621579408646
72
train loss item: 0.12213855236768723
73
train loss item: 0.2176358699798584
74
train loss item: 0.08743364363908768
75
train loss item: 0.09910128265619278
76
train loss item: 0.6359274983406067
77
train loss item: 1.0841448307037354
78
train loss item: 0.07093319296836853
79
train loss item: 0.21626408398151398
80
train loss item: 0.10662295669317245
81
train loss item: 0.14858520030975342
82
train loss item: 0.15534040331840515
83
train loss item: 0.42883598804473877
84
train loss item: 0.3357543349266052
85
train loss item: 0.39009031653404236
86
train loss item: 3.8172607421875
87
train loss item: 0.12800505757331848
88
train loss item: 0.2658863663673401
epoch train loss: 0.37224142630113644
testing phase
test loss item: 0.15323875844478607
test loss item: 0.10035955160856247
test loss item: 0.49352848529815674
test loss item: 0.18798960745334625
test loss item: 0.2141813337802887
test loss item: 0.10947215557098389
test loss item: 1.3424534797668457
test loss item: 0.4324125349521637
test loss item: 0.1863255351781845
test loss item: 0.3206346035003662
test loss item: 0.7143802642822266
test loss item: 0.14540939033031464
test loss item: 0.14955510199069977
test loss item: 0.21283702552318573
test loss item: 0.14348576962947845
test loss item: 0.09471281617879868
test loss item: 0.211500346660614
test loss item: 0.39886751770973206
test loss item: 0.516923189163208
test loss item: 0.199321910738945
test loss item: 0.660062313079834
test loss item: 0.3106221556663513
test loss item: 0.32474997639656067
test loss item: 0.13378241658210754
test loss item: 0.18032245337963104
test loss item: 0.17464874684810638
test loss item: 0.24122677743434906
test loss item: 0.15625858306884766
test loss item: 0.2528781592845917
test loss item: 0.27120527625083923
test loss item: 0.6298356056213379
test loss item: 0.08426038175821304
test loss item: 0.11606155335903168
test loss item: 0.4873458445072174
test loss item: 0.363029420375824
test loss item: 0.35615649819374084
test loss item: 0.630864143371582
test loss item: 1.201866865158081
test loss item: 0.37823575735092163
test loss item: 0.2071959227323532
test loss item: 0.23804037272930145
test loss item: 0.23094533383846283
test loss item: 0.30011364817619324
test loss item: 0.1671023815870285
test loss item: 0.5053424835205078
test loss item: 0.30208343267440796
test loss item: 0.3166098892688751
test loss item: 0.17637653648853302
test loss item: 0.3927362859249115
test loss item: 0.5631579160690308
test loss item: 0.23646719753742218
test loss item: 0.11040256172418594
test loss item: 0.18990947306156158
test loss item: 0.1465306133031845
test loss item: 0.2556195855140686
test loss item: 0.7231687903404236
test loss item: 0.45823776721954346
test loss item: 0.19947375357151031
test loss item: 0.18931233882904053
test loss item: 0.1760394275188446
test loss item: 0.3714344799518585
test loss item: 0.20061685144901276
test loss item: 0.1674104481935501
test loss item: 0.19445590674877167
test loss item: 0.6914861798286438
test loss item: 0.26316550374031067
test loss item: 0.2400534451007843
test loss item: 0.1952911615371704
test loss item: 0.45229363441467285
test loss item: 0.33283478021621704
test loss item: 0.0754055380821228
test loss item: 0.743071973323822
test loss item: 0.268481969833374
test loss item: 0.28916770219802856
test loss item: 0.11484939604997635
test loss item: 0.21494171023368835
test loss item: 0.13581232726573944
test loss item: 1.217036247253418
test loss item: 0.3363546133041382
test loss item: 0.15489649772644043
test loss item: 0.06981059908866882
test loss item: 0.7871994972229004
test loss item: 0.7111575603485107
test loss item: 0.8462141752243042
test loss item: 0.17358867824077606
test loss item: 0.17004768550395966
test loss item: 0.06733383238315582
test loss item: 0.07354792952537537
test loss item: 0.14535434544086456
Epoch [32/100], Training Loss: 0.3722, Testing Loss: 0.3266
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 33/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3426404297351837
1
train loss item: 0.858027458190918
2
train loss item: 0.15562686324119568
3
train loss item: 0.3501725494861603
4
train loss item: 0.28015026450157166
5
train loss item: 0.2321147620677948
6
train loss item: 0.15260611474514008
7
train loss item: 0.5619292259216309
8
train loss item: 0.09762120246887207
9
train loss item: 0.17231948673725128
10
train loss item: 0.2265610545873642
11
train loss item: 0.21866436302661896
12
train loss item: 0.11164287477731705
13
train loss item: 0.358353853225708
14
train loss item: 0.17648303508758545
15
train loss item: 0.4702357351779938
16
train loss item: 0.06670541316270828
17
train loss item: 0.1814376711845398
18
train loss item: 0.22814232110977173
19
train loss item: 0.18989060819149017
20
train loss item: 0.16193342208862305
21
train loss item: 0.11363209038972855
22
train loss item: 0.6411030292510986
23
train loss item: 0.6399697065353394
24
train loss item: 0.3824809789657593
25
train loss item: 0.17355412244796753
26
train loss item: 0.1461506336927414
27
train loss item: 0.16741743683815002
28
train loss item: 0.06528151780366898
29
train loss item: 0.4916771352291107
30
train loss item: 1.7785141468048096
31
train loss item: 0.3858044445514679
32
train loss item: 0.0906962975859642
33
train loss item: 0.29778775572776794
34
train loss item: 0.1386265903711319
35
train loss item: 2.055673599243164
36
train loss item: 0.3571496605873108
37
train loss item: 0.3273925185203552
38
train loss item: 0.3121792674064636
39
train loss item: 0.17453327775001526
40
train loss item: 0.12448319047689438
41
train loss item: 0.17497873306274414
42
train loss item: 0.23162102699279785
43
train loss item: 0.12641282379627228
44
train loss item: 0.5220466256141663
45
train loss item: 0.1142984926700592
46
train loss item: 0.10312344133853912
47
train loss item: 0.25403574109077454
48
train loss item: 0.15595859289169312
49
train loss item: 0.11704829335212708
50
train loss item: 0.20701484382152557
51
train loss item: 0.616921067237854
52
train loss item: 0.07298432290554047
53
train loss item: 0.1172715574502945
54
train loss item: 1.9344204664230347
55
train loss item: 0.14153777062892914
56
train loss item: 0.1725836545228958
57
train loss item: 0.18772713840007782
58
train loss item: 0.11775895208120346
59
train loss item: 0.10740736871957779
60
train loss item: 0.5851084589958191
61
train loss item: 1.8302611112594604
62
train loss item: 0.14819544553756714
63
train loss item: 0.2681569755077362
64
train loss item: 0.12233669310808182
65
train loss item: 0.35588371753692627
66
train loss item: 0.28470107913017273
67
train loss item: 0.15437552332878113
68
train loss item: 0.19778403639793396
69
train loss item: 0.2207731306552887
70
train loss item: 0.19339939951896667
71
train loss item: 0.11643264442682266
72
train loss item: 0.12064756453037262
73
train loss item: 0.21229378879070282
74
train loss item: 0.08625932037830353
75
train loss item: 0.09732986986637115
76
train loss item: 0.6236775517463684
77
train loss item: 1.0701496601104736
78
train loss item: 0.07188034802675247
79
train loss item: 0.21067290008068085
80
train loss item: 0.10165480524301529
81
train loss item: 0.1442003846168518
82
train loss item: 0.15458665788173676
83
train loss item: 0.4157487750053406
84
train loss item: 0.32391753792762756
85
train loss item: 0.3847866654396057
86
train loss item: 3.7982184886932373
87
train loss item: 0.12626513838768005
88
train loss item: 0.25764426589012146
epoch train loss: 0.36640290966194666
testing phase
test loss item: 0.1545284390449524
test loss item: 0.09413201361894608
test loss item: 0.4786944091320038
test loss item: 0.18735527992248535
test loss item: 0.20856201648712158
test loss item: 0.10889468342065811
test loss item: 1.3821282386779785
test loss item: 0.45921242237091064
test loss item: 0.18116417527198792
test loss item: 0.3120082914829254
test loss item: 0.6951850056648254
test loss item: 0.13989980518817902
test loss item: 0.1464347243309021
test loss item: 0.21102115511894226
test loss item: 0.13910135626792908
test loss item: 0.08365176618099213
test loss item: 0.21525569260120392
test loss item: 0.38550662994384766
test loss item: 0.5262369513511658
test loss item: 0.20063738524913788
test loss item: 0.6338560581207275
test loss item: 0.3180583715438843
test loss item: 0.36398187279701233
test loss item: 0.136243537068367
test loss item: 0.17644338309764862
test loss item: 0.17427131533622742
test loss item: 0.2386614978313446
test loss item: 0.15240038931369781
test loss item: 0.24684156477451324
test loss item: 0.2673267126083374
test loss item: 0.6303555369377136
test loss item: 0.07527227699756622
test loss item: 0.11818104237318039
test loss item: 0.4704900085926056
test loss item: 0.3499178886413574
test loss item: 0.3542155921459198
test loss item: 0.6403266787528992
test loss item: 1.1664060354232788
test loss item: 0.3662113845348358
test loss item: 0.20931297540664673
test loss item: 0.24002203345298767
test loss item: 0.271236777305603
test loss item: 0.28642067313194275
test loss item: 0.1693425178527832
test loss item: 0.48260217905044556
test loss item: 0.3077962100505829
test loss item: 0.3546024560928345
test loss item: 0.18006671965122223
test loss item: 0.3855378329753876
test loss item: 0.5543205738067627
test loss item: 0.22659990191459656
test loss item: 0.11247735470533371
test loss item: 0.1885252445936203
test loss item: 0.14260220527648926
test loss item: 0.24728690087795258
test loss item: 0.6993980407714844
test loss item: 0.46013182401657104
test loss item: 0.19908009469509125
test loss item: 0.1906932294368744
test loss item: 0.1679232120513916
test loss item: 0.35591164231300354
test loss item: 0.2101520597934723
test loss item: 0.1716100126504898
test loss item: 0.18833263218402863
test loss item: 0.6814841628074646
test loss item: 0.26087716221809387
test loss item: 0.24423885345458984
test loss item: 0.19308659434318542
test loss item: 0.4385673999786377
test loss item: 0.3405916690826416
test loss item: 0.0668068453669548
test loss item: 0.7689189910888672
test loss item: 0.2653021812438965
test loss item: 0.2958334982395172
test loss item: 0.11662044376134872
test loss item: 0.25501495599746704
test loss item: 0.13643303513526917
test loss item: 1.1822052001953125
test loss item: 0.33179235458374023
test loss item: 0.15513260662555695
test loss item: 0.06937593221664429
test loss item: 0.7884505987167358
test loss item: 0.7178369164466858
test loss item: 0.8237128257751465
test loss item: 0.17252026498317719
test loss item: 0.1697455495595932
test loss item: 0.06456825882196426
test loss item: 0.06557300686836243
test loss item: 0.14576181769371033
Epoch [33/100], Training Loss: 0.3664, Testing Loss: 0.3252
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 34/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.33590662479400635
1
train loss item: 0.8374078869819641
2
train loss item: 0.15205080807209015
3
train loss item: 0.34182435274124146
4
train loss item: 0.27322763204574585
5
train loss item: 0.224528506398201
6
train loss item: 0.15272019803524017
7
train loss item: 0.5517632365226746
8
train loss item: 0.09534606337547302
9
train loss item: 0.1680164933204651
10
train loss item: 0.220101460814476
11
train loss item: 0.2136014848947525
12
train loss item: 0.11176357418298721
13
train loss item: 0.34875696897506714
14
train loss item: 0.1731555461883545
15
train loss item: 0.4654533863067627
16
train loss item: 0.06705746799707413
17
train loss item: 0.17754779756069183
18
train loss item: 0.22312821447849274
19
train loss item: 0.18924690783023834
20
train loss item: 0.1658521145582199
21
train loss item: 0.1134079098701477
22
train loss item: 0.6295878291130066
23
train loss item: 0.6227755546569824
24
train loss item: 0.3753490149974823
25
train loss item: 0.17207059264183044
26
train loss item: 0.14245302975177765
27
train loss item: 0.1635332554578781
28
train loss item: 0.06535406410694122
29
train loss item: 0.486439973115921
30
train loss item: 1.7550586462020874
31
train loss item: 0.3730848729610443
32
train loss item: 0.08921293169260025
33
train loss item: 0.28579139709472656
34
train loss item: 0.13569559156894684
35
train loss item: 2.0396828651428223
36
train loss item: 0.34592702984809875
37
train loss item: 0.32117438316345215
38
train loss item: 0.301826149225235
39
train loss item: 0.17290478944778442
40
train loss item: 0.12317030876874924
41
train loss item: 0.17049981653690338
42
train loss item: 0.22905007004737854
43
train loss item: 0.12424298375844955
44
train loss item: 0.5146607160568237
45
train loss item: 0.11191211640834808
46
train loss item: 0.09899421781301498
47
train loss item: 0.2505311369895935
48
train loss item: 0.15198259055614471
49
train loss item: 0.11463199555873871
50
train loss item: 0.20763562619686127
51
train loss item: 0.6070075035095215
52
train loss item: 0.07463058084249496
53
train loss item: 0.11361511051654816
54
train loss item: 1.9189343452453613
55
train loss item: 0.13890409469604492
56
train loss item: 0.16887478530406952
57
train loss item: 0.1862139105796814
58
train loss item: 0.118387870490551
59
train loss item: 0.10473065823316574
60
train loss item: 0.5732138752937317
61
train loss item: 1.8093124628067017
62
train loss item: 0.14871051907539368
63
train loss item: 0.26273173093795776
64
train loss item: 0.1186419129371643
65
train loss item: 0.3457680940628052
66
train loss item: 0.2760654389858246
67
train loss item: 0.15239733457565308
68
train loss item: 0.20016346871852875
69
train loss item: 0.2156732678413391
70
train loss item: 0.18950025737285614
71
train loss item: 0.1158914789557457
72
train loss item: 0.11650648713111877
73
train loss item: 0.20846593379974365
74
train loss item: 0.08665566146373749
75
train loss item: 0.0955067053437233
76
train loss item: 0.6066464185714722
77
train loss item: 1.0605369806289673
78
train loss item: 0.07285688072443008
79
train loss item: 0.20545673370361328
80
train loss item: 0.09938279539346695
81
train loss item: 0.14267335832118988
82
train loss item: 0.15093940496444702
83
train loss item: 0.40659013390541077
84
train loss item: 0.3121577799320221
85
train loss item: 0.37429729104042053
86
train loss item: 3.774843692779541
87
train loss item: 0.12167198210954666
88
train loss item: 0.2522924840450287
epoch train loss: 0.3607185124681237
testing phase
test loss item: 0.1528262495994568
test loss item: 0.09489762037992477
test loss item: 0.4488641619682312
test loss item: 0.18472306430339813
test loss item: 0.20403806865215302
test loss item: 0.11100666224956512
test loss item: 1.3230291604995728
test loss item: 0.44219139218330383
test loss item: 0.17278322577476501
test loss item: 0.298997163772583
test loss item: 0.6530622243881226
test loss item: 0.13752484321594238
test loss item: 0.1426440179347992
test loss item: 0.20685803890228271
test loss item: 0.13742555677890778
test loss item: 0.08428662270307541
test loss item: 0.2085866779088974
test loss item: 0.36766111850738525
test loss item: 0.5100206136703491
test loss item: 0.19474583864212036
test loss item: 0.6047301888465881
test loss item: 0.3083125352859497
test loss item: 0.37735265493392944
test loss item: 0.1339777261018753
test loss item: 0.17038393020629883
test loss item: 0.1708214282989502
test loss item: 0.230666384100914
test loss item: 0.1498771458864212
test loss item: 0.23918776214122772
test loss item: 0.25949448347091675
test loss item: 0.5943195223808289
test loss item: 0.07423505187034607
test loss item: 0.117543064057827
test loss item: 0.4468349516391754
test loss item: 0.33130943775177
test loss item: 0.34379062056541443
test loss item: 0.6189899444580078
test loss item: 1.0904890298843384
test loss item: 0.34789979457855225
test loss item: 0.2036207616329193
test loss item: 0.23317179083824158
test loss item: 0.28114569187164307
test loss item: 0.27329394221305847
test loss item: 0.16453485190868378
test loss item: 0.46140772104263306
test loss item: 0.2985627353191376
test loss item: 0.3657686412334442
test loss item: 0.17775550484657288
test loss item: 0.3674429655075073
test loss item: 0.5238780379295349
test loss item: 0.21726107597351074
test loss item: 0.11295396834611893
test loss item: 0.18287576735019684
test loss item: 0.13846056163311005
test loss item: 0.23682066798210144
test loss item: 0.6540026068687439
test loss item: 0.44311216473579407
test loss item: 0.19595861434936523
test loss item: 0.18797600269317627
test loss item: 0.16241766512393951
test loss item: 0.34041351079940796
test loss item: 0.20530392229557037
test loss item: 0.16840247809886932
test loss item: 0.18200911581516266
test loss item: 0.6393295526504517
test loss item: 0.2566337287425995
test loss item: 0.23768314719200134
test loss item: 0.18710967898368835
test loss item: 0.4197882115840912
test loss item: 0.3271191716194153
test loss item: 0.06599955260753632
test loss item: 0.734795331954956
test loss item: 0.2595331072807312
test loss item: 0.2846408784389496
test loss item: 0.11498282849788666
test loss item: 0.2660808563232422
test loss item: 0.1340416967868805
test loss item: 1.1016829013824463
test loss item: 0.320340633392334
test loss item: 0.1534751057624817
test loss item: 0.06863118708133698
test loss item: 0.7455323338508606
test loss item: 0.6874257922172546
test loss item: 0.7664663195610046
test loss item: 0.16960270702838898
test loss item: 0.16542395949363708
test loss item: 0.06416980177164078
test loss item: 0.0660184696316719
test loss item: 0.14581826329231262
Epoch [34/100], Training Loss: 0.3607, Testing Loss: 0.3129
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 35/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.33066874742507935
1
train loss item: 0.8107200860977173
2
train loss item: 0.14809010922908783
3
train loss item: 0.3295169472694397
4
train loss item: 0.2711840271949768
5
train loss item: 0.22142185270786285
6
train loss item: 0.14906546473503113
7
train loss item: 0.5375996828079224
8
train loss item: 0.09271640330553055
9
train loss item: 0.16285517811775208
10
train loss item: 0.21697333455085754
11
train loss item: 0.21069404482841492
12
train loss item: 0.10976140946149826
13
train loss item: 0.3439144492149353
14
train loss item: 0.1688084453344345
15
train loss item: 0.44909170269966125
16
train loss item: 0.06406861543655396
17
train loss item: 0.1758379191160202
18
train loss item: 0.21928566694259644
19
train loss item: 0.18260683119297028
20
train loss item: 0.16032229363918304
21
train loss item: 0.11149248480796814
22
train loss item: 0.6063730716705322
23
train loss item: 0.603927493095398
24
train loss item: 0.36654114723205566
25
train loss item: 0.17109861969947815
26
train loss item: 0.14044979214668274
27
train loss item: 0.15796777606010437
28
train loss item: 0.06241660192608833
29
train loss item: 0.4661637544631958
30
train loss item: 1.723021388053894
31
train loss item: 0.3681129217147827
32
train loss item: 0.08713103830814362
33
train loss item: 0.27761077880859375
34
train loss item: 0.13369068503379822
35
train loss item: 2.021719217300415
36
train loss item: 0.34614184498786926
37
train loss item: 0.32423365116119385
38
train loss item: 0.3113100826740265
39
train loss item: 0.1705632507801056
40
train loss item: 0.11956072598695755
41
train loss item: 0.16340923309326172
42
train loss item: 0.22618253529071808
43
train loss item: 0.12126032263040543
44
train loss item: 0.5056318044662476
45
train loss item: 0.11115969717502594
46
train loss item: 0.09727463126182556
47
train loss item: 0.2441345453262329
48
train loss item: 0.14605571329593658
49
train loss item: 0.1122598871588707
50
train loss item: 0.20098601281642914
51
train loss item: 0.5898981094360352
52
train loss item: 0.07115551829338074
53
train loss item: 0.11165590584278107
54
train loss item: 1.900581955909729
55
train loss item: 0.13468733429908752
56
train loss item: 0.1665198653936386
57
train loss item: 0.18117763102054596
58
train loss item: 0.11515864729881287
59
train loss item: 0.10510633140802383
60
train loss item: 0.5507200956344604
61
train loss item: 1.7867366075515747
62
train loss item: 0.1472465693950653
63
train loss item: 0.2583164870738983
64
train loss item: 0.11693643033504486
65
train loss item: 0.3432590365409851
66
train loss item: 0.2762207090854645
67
train loss item: 0.14984910190105438
68
train loss item: 0.19419614970684052
69
train loss item: 0.21470539271831512
70
train loss item: 0.18657927215099335
71
train loss item: 0.11254438757896423
72
train loss item: 0.11277744174003601
73
train loss item: 0.20159374177455902
74
train loss item: 0.0849020779132843
75
train loss item: 0.09439544379711151
76
train loss item: 0.5863637328147888
77
train loss item: 1.0457547903060913
78
train loss item: 0.0691230446100235
79
train loss item: 0.20258072018623352
80
train loss item: 0.09912555664777756
81
train loss item: 0.1426667869091034
82
train loss item: 0.1473030000925064
83
train loss item: 0.3951930105686188
84
train loss item: 0.31459537148475647
85
train loss item: 0.35918107628822327
86
train loss item: 3.7494611740112305
87
train loss item: 0.11786843836307526
88
train loss item: 0.2514050602912903
epoch train loss: 0.35438905534951876
testing phase
test loss item: 0.15123793482780457
test loss item: 0.09958580136299133
test loss item: 0.4378755986690521
test loss item: 0.18357475101947784
test loss item: 0.20388305187225342
test loss item: 0.10972228646278381
test loss item: 1.2707526683807373
test loss item: 0.4275059401988983
test loss item: 0.17035402357578278
test loss item: 0.29463204741477966
test loss item: 0.6275166273117065
test loss item: 0.13796067237854004
test loss item: 0.1415136158466339
test loss item: 0.20764517784118652
test loss item: 0.140910342335701
test loss item: 0.08696786314249039
test loss item: 0.20324739813804626
test loss item: 0.36263391375541687
test loss item: 0.4951779246330261
test loss item: 0.19268430769443512
test loss item: 0.5973337292671204
test loss item: 0.3005857467651367
test loss item: 0.355457603931427
test loss item: 0.13455568253993988
test loss item: 0.1666683554649353
test loss item: 0.1696328967809677
test loss item: 0.22667977213859558
test loss item: 0.14833910763263702
test loss item: 0.23874840140342712
test loss item: 0.25549548864364624
test loss item: 0.5706912279129028
test loss item: 0.07588274776935577
test loss item: 0.11918431520462036
test loss item: 0.4373651146888733
test loss item: 0.32584649324417114
test loss item: 0.33702149987220764
test loss item: 0.6016400456428528
test loss item: 1.0491327047348022
test loss item: 0.340493381023407
test loss item: 0.19924019277095795
test loss item: 0.2275458574295044
test loss item: 0.2538001835346222
test loss item: 0.2701438069343567
test loss item: 0.1611781269311905
test loss item: 0.45529499650001526
test loss item: 0.2924981713294983
test loss item: 0.3427852988243103
test loss item: 0.17725887894630432
test loss item: 0.36104437708854675
test loss item: 0.5049528479576111
test loss item: 0.2171471267938614
test loss item: 0.11292929947376251
test loss item: 0.1806035190820694
test loss item: 0.1366642564535141
test loss item: 0.23482021689414978
test loss item: 0.6326469779014587
test loss item: 0.4310600161552429
test loss item: 0.19826042652130127
test loss item: 0.18740218877792358
test loss item: 0.1618705689907074
test loss item: 0.3370087146759033
test loss item: 0.2011197805404663
test loss item: 0.16702991724014282
test loss item: 0.1783832609653473
test loss item: 0.6192935705184937
test loss item: 0.2534993290901184
test loss item: 0.23438607156276703
test loss item: 0.18362313508987427
test loss item: 0.41252005100250244
test loss item: 0.3151088356971741
test loss item: 0.06895744800567627
test loss item: 0.7057729363441467
test loss item: 0.26192590594291687
test loss item: 0.2787714898586273
test loss item: 0.1143701896071434
test loss item: 0.2398989200592041
test loss item: 0.13470014929771423
test loss item: 1.0622432231903076
test loss item: 0.3173489272594452
test loss item: 0.15078935027122498
test loss item: 0.0685713142156601
test loss item: 0.7159262895584106
test loss item: 0.6635938286781311
test loss item: 0.7369622588157654
test loss item: 0.1703965812921524
test loss item: 0.16291286051273346
test loss item: 0.06400184333324432
test loss item: 0.06677607446908951
test loss item: 0.1442936658859253
Epoch [35/100], Training Loss: 0.3544, Testing Loss: 0.3052
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 36/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3243085443973541
1
train loss item: 0.7872336506843567
2
train loss item: 0.14277903735637665
3
train loss item: 0.3186275064945221
4
train loss item: 0.267133504152298
5
train loss item: 0.2183680534362793
6
train loss item: 0.1446818709373474
7
train loss item: 0.5259502530097961
8
train loss item: 0.09128732234239578
9
train loss item: 0.15877462923526764
10
train loss item: 0.21196340024471283
11
train loss item: 0.20752868056297302
12
train loss item: 0.10759969800710678
13
train loss item: 0.33922868967056274
14
train loss item: 0.1661268174648285
15
train loss item: 0.43319833278656006
16
train loss item: 0.06214189901947975
17
train loss item: 0.17365804314613342
18
train loss item: 0.21422143280506134
19
train loss item: 0.17741665244102478
20
train loss item: 0.1519201695919037
21
train loss item: 0.10841958224773407
22
train loss item: 0.583613395690918
23
train loss item: 0.5868464708328247
24
train loss item: 0.35776248574256897
25
train loss item: 0.16720670461654663
26
train loss item: 0.13941673934459686
27
train loss item: 0.15473583340644836
28
train loss item: 0.06075939163565636
29
train loss item: 0.4473252594470978
30
train loss item: 1.6953098773956299
31
train loss item: 0.3624233305454254
32
train loss item: 0.08827023208141327
33
train loss item: 0.27675777673721313
34
train loss item: 0.13131318986415863
35
train loss item: 2.0058186054229736
36
train loss item: 0.34313371777534485
37
train loss item: 0.3252716064453125
38
train loss item: 0.3157059848308563
39
train loss item: 0.16756442189216614
40
train loss item: 0.11590194702148438
41
train loss item: 0.15879280865192413
42
train loss item: 0.22504748404026031
43
train loss item: 0.11951153725385666
44
train loss item: 0.4991005063056946
45
train loss item: 0.11237680166959763
46
train loss item: 0.09790647029876709
47
train loss item: 0.23907704651355743
48
train loss item: 0.14345206320285797
49
train loss item: 0.11051435768604279
50
train loss item: 0.1950840801000595
51
train loss item: 0.5739850997924805
52
train loss item: 0.06827552616596222
53
train loss item: 0.11222407966852188
54
train loss item: 1.8847707509994507
55
train loss item: 0.13278523087501526
56
train loss item: 0.1642673909664154
57
train loss item: 0.17796112596988678
58
train loss item: 0.11044494807720184
59
train loss item: 0.10821406543254852
60
train loss item: 0.5313192009925842
61
train loss item: 1.7681400775909424
62
train loss item: 0.14626333117485046
63
train loss item: 0.25515052676200867
64
train loss item: 0.11754795908927917
65
train loss item: 0.33900001645088196
66
train loss item: 0.27350670099258423
67
train loss item: 0.146637424826622
68
train loss item: 0.1885526329278946
69
train loss item: 0.21323265135288239
70
train loss item: 0.18404394388198853
71
train loss item: 0.10883813351392746
72
train loss item: 0.11202172189950943
73
train loss item: 0.1963575780391693
74
train loss item: 0.0825352892279625
75
train loss item: 0.09462027996778488
76
train loss item: 0.5686143636703491
77
train loss item: 1.0334359407424927
78
train loss item: 0.06635415554046631
79
train loss item: 0.20022514462471008
80
train loss item: 0.10025636851787567
81
train loss item: 0.1428508758544922
82
train loss item: 0.14622001349925995
83
train loss item: 0.3855551481246948
84
train loss item: 0.3147094249725342
85
train loss item: 0.3472624719142914
86
train loss item: 3.7267966270446777
87
train loss item: 0.11870841681957245
88
train loss item: 0.24759338796138763
epoch train loss: 0.34885220137539874
testing phase
test loss item: 0.15077278017997742
test loss item: 0.10277894884347916
test loss item: 0.4449499845504761
test loss item: 0.18352647125720978
test loss item: 0.20870758593082428
test loss item: 0.11515969038009644
test loss item: 1.3306269645690918
test loss item: 0.4573891758918762
test loss item: 0.17190992832183838
test loss item: 0.2964268922805786
test loss item: 0.6253213882446289
test loss item: 0.1413262039422989
test loss item: 0.14358362555503845
test loss item: 0.21550053358078003
test loss item: 0.14443066716194153
test loss item: 0.09169269353151321
test loss item: 0.20803231000900269
test loss item: 0.3649837374687195
test loss item: 0.5065585970878601
test loss item: 0.20099294185638428
test loss item: 0.615388035774231
test loss item: 0.30970749258995056
test loss item: 0.3642163574695587
test loss item: 0.13782218098640442
test loss item: 0.167687326669693
test loss item: 0.1709345579147339
test loss item: 0.2288781702518463
test loss item: 0.15202179551124573
test loss item: 0.24333132803440094
test loss item: 0.2554917633533478
test loss item: 0.5883278250694275
test loss item: 0.0781286433339119
test loss item: 0.12033654749393463
test loss item: 0.43867677450180054
test loss item: 0.32998424768447876
test loss item: 0.33919772505760193
test loss item: 0.6181440949440002
test loss item: 1.0514901876449585
test loss item: 0.34328141808509827
test loss item: 0.20553767681121826
test loss item: 0.23256337642669678
test loss item: 0.2577728033065796
test loss item: 0.27005478739738464
test loss item: 0.1649497151374817
test loss item: 0.4703463912010193
test loss item: 0.3015666604042053
test loss item: 0.35056549310684204
test loss item: 0.18488499522209167
test loss item: 0.3681582808494568
test loss item: 0.5088317394256592
test loss item: 0.21937918663024902
test loss item: 0.11604597419500351
test loss item: 0.1830993890762329
test loss item: 0.1359415054321289
test loss item: 0.23649345338344574
test loss item: 0.6358318328857422
test loss item: 0.43945252895355225
test loss item: 0.2028937190771103
test loss item: 0.19139787554740906
test loss item: 0.1622217893600464
test loss item: 0.3371499478816986
test loss item: 0.20898057520389557
test loss item: 0.17049242556095123
test loss item: 0.17852506041526794
test loss item: 0.6371555328369141
test loss item: 0.25230881571769714
test loss item: 0.24017052352428436
test loss item: 0.18691964447498322
test loss item: 0.4161372184753418
test loss item: 0.3230283260345459
test loss item: 0.07295073568820953
test loss item: 0.744347870349884
test loss item: 0.2744247317314148
test loss item: 0.2925427556037903
test loss item: 0.11739177256822586
test loss item: 0.24116742610931396
test loss item: 0.14082127809524536
test loss item: 1.0772308111190796
test loss item: 0.3263867497444153
test loss item: 0.15287622809410095
test loss item: 0.07262985408306122
test loss item: 0.7338552474975586
test loss item: 0.6785850524902344
test loss item: 0.7465068101882935
test loss item: 0.17542971670627594
test loss item: 0.16546396911144257
test loss item: 0.06522472202777863
test loss item: 0.0698891133069992
test loss item: 0.13572874665260315
Epoch [36/100], Training Loss: 0.3489, Testing Loss: 0.3116
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 37/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3150191307067871
1
train loss item: 0.7713271975517273
2
train loss item: 0.13936136662960052
3
train loss item: 0.3078438937664032
4
train loss item: 0.25881075859069824
5
train loss item: 0.21096394956111908
6
train loss item: 0.1442086547613144
7
train loss item: 0.5177357196807861
8
train loss item: 0.0881112739443779
9
train loss item: 0.15503184497356415
10
train loss item: 0.20189324021339417
11
train loss item: 0.20144152641296387
12
train loss item: 0.10725505650043488
13
train loss item: 0.3285236656665802
14
train loss item: 0.16144555807113647
15
train loss item: 0.431652307510376
16
train loss item: 0.06115226447582245
17
train loss item: 0.16752414405345917
18
train loss item: 0.20694510638713837
19
train loss item: 0.18039460480213165
20
train loss item: 0.1513037234544754
21
train loss item: 0.10690497606992722
22
train loss item: 0.5738537907600403
23
train loss item: 0.567852258682251
24
train loss item: 0.3505617082118988
25
train loss item: 0.16093702614307404
26
train loss item: 0.1376381367444992
27
train loss item: 0.1524137407541275
28
train loss item: 0.05972866341471672
29
train loss item: 0.4437454342842102
30
train loss item: 1.67549729347229
31
train loss item: 0.3504559099674225
32
train loss item: 0.08816992491483688
33
train loss item: 0.26993489265441895
34
train loss item: 0.12696652114391327
35
train loss item: 1.9926530122756958
36
train loss item: 0.3271282911300659
37
train loss item: 0.3143216073513031
38
train loss item: 0.2964410185813904
39
train loss item: 0.16424204409122467
40
train loss item: 0.11673393845558167
41
train loss item: 0.15387284755706787
42
train loss item: 0.22485075891017914
43
train loss item: 0.1184118241071701
44
train loss item: 0.4925922453403473
45
train loss item: 0.11157014220952988
46
train loss item: 0.09786420315504074
47
train loss item: 0.2374209314584732
48
train loss item: 0.1424599438905716
49
train loss item: 0.1077265590429306
50
train loss item: 0.19825516641139984
51
train loss item: 0.5633688569068909
52
train loss item: 0.06746470928192139
53
train loss item: 0.11049607396125793
54
train loss item: 1.8725101947784424
55
train loss item: 0.13208715617656708
56
train loss item: 0.15945129096508026
57
train loss item: 0.1797691136598587
58
train loss item: 0.10958738625049591
59
train loss item: 0.10856284201145172
60
train loss item: 0.5220209956169128
61
train loss item: 1.7506842613220215
62
train loss item: 0.14487969875335693
63
train loss item: 0.2524704933166504
64
train loss item: 0.11581501364707947
65
train loss item: 0.32624682784080505
66
train loss item: 0.2622145712375641
67
train loss item: 0.1450122445821762
68
train loss item: 0.19174529612064362
69
train loss item: 0.20786239206790924
70
train loss item: 0.18049106001853943
71
train loss item: 0.10788016021251678
72
train loss item: 0.10916466265916824
73
train loss item: 0.19562433660030365
74
train loss item: 0.08029805123806
75
train loss item: 0.09407489001750946
76
train loss item: 0.5524857640266418
77
train loss item: 1.028936505317688
78
train loss item: 0.06562314927577972
79
train loss item: 0.19593733549118042
80
train loss item: 0.10108919441699982
81
train loss item: 0.14082355797290802
82
train loss item: 0.14173342287540436
83
train loss item: 0.38041701912879944
84
train loss item: 0.2971641421318054
85
train loss item: 0.3382379710674286
86
train loss item: 3.7065911293029785
87
train loss item: 0.11788730323314667
88
train loss item: 0.23844994604587555
epoch train loss: 0.3434192002070754
testing phase
test loss item: 0.1492895483970642
test loss item: 0.25436392426490784
test loss item: 0.46339479088783264
test loss item: 0.17921824753284454
test loss item: 0.3101233243942261
test loss item: 0.3208375573158264
test loss item: 1.224410057067871
test loss item: 0.41245850920677185
test loss item: 0.17473481595516205
test loss item: 0.2980949580669403
test loss item: 0.6452293395996094
test loss item: 0.20937499403953552
test loss item: 0.14058621227741241
test loss item: 0.2176695019006729
test loss item: 0.20263363420963287
test loss item: 0.40468642115592957
test loss item: 0.19769367575645447
test loss item: 0.36737361550331116
test loss item: 0.47725042700767517
test loss item: 0.19555236399173737
test loss item: 0.7949815392494202
test loss item: 0.2918326258659363
test loss item: 0.7530238628387451
test loss item: 0.1320730745792389
test loss item: 0.21682049334049225
test loss item: 0.16504204273223877
test loss item: 0.22746844589710236
test loss item: 0.2898913323879242
test loss item: 0.24042682349681854
test loss item: 0.2526146471500397
test loss item: 0.5782200694084167
test loss item: 0.37642502784729004
test loss item: 0.11570652574300766
test loss item: 0.4432356357574463
test loss item: 0.4059205651283264
test loss item: 0.3338751196861267
test loss item: 0.5846064686775208
test loss item: 1.1004835367202759
test loss item: 0.34424328804016113
test loss item: 0.28733018040657043
test loss item: 0.302565336227417
test loss item: 0.6302589178085327
test loss item: 0.2704653739929199
test loss item: 0.15764029324054718
test loss item: 0.6520358920097351
test loss item: 0.37399566173553467
test loss item: 0.7684550881385803
test loss item: 0.18294087052345276
test loss item: 0.371511310338974
test loss item: 0.5075993537902832
test loss item: 0.22162994742393494
test loss item: 0.1800520271062851
test loss item: 0.18145932257175446
test loss item: 0.1336704045534134
test loss item: 0.23965893685817719
test loss item: 0.6623510122299194
test loss item: 0.42750945687294006
test loss item: 0.20196156203746796
test loss item: 0.23465271294116974
test loss item: 0.16235759854316711
test loss item: 0.3692561388015747
test loss item: 0.29042911529541016
test loss item: 0.16346748173236847
test loss item: 0.17349371314048767
test loss item: 0.6839188933372498
test loss item: 0.24809134006500244
test loss item: 0.23258017003536224
test loss item: 0.17977450788021088
test loss item: 0.4759376347064972
test loss item: 0.3050714135169983
test loss item: 0.26662495732307434
test loss item: 0.693695068359375
test loss item: 0.3781660795211792
test loss item: 0.2751806080341339
test loss item: 0.11489831656217575
test loss item: 0.6488447785377502
test loss item: 0.20474253594875336
test loss item: 1.1403664350509644
test loss item: 0.33545786142349243
test loss item: 0.28591451048851013
test loss item: 0.18340377509593964
test loss item: 0.7220510244369507
test loss item: 0.6476811766624451
test loss item: 0.7834546566009521
test loss item: 0.17454110085964203
test loss item: 0.16424359381198883
test loss item: 0.26882919669151306
test loss item: 0.3970909118652344
test loss item: 0.1297251433134079
Epoch [37/100], Training Loss: 0.3434, Testing Loss: 0.3661
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Epoch 38/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3072455823421478
1
train loss item: 0.7492884993553162
2
train loss item: 0.13449014723300934
3
train loss item: 0.29828447103500366
4
train loss item: 0.2514066696166992
5
train loss item: 0.20385271310806274
6
train loss item: 0.1456468552350998
7
train loss item: 0.5100728273391724
8
train loss item: 0.08636137843132019
9
train loss item: 0.15427012741565704
10
train loss item: 0.19821274280548096
11
train loss item: 0.1981230080127716
12
train loss item: 0.10757672041654587
13
train loss item: 0.32642048597335815
14
train loss item: 0.1574462354183197
15
train loss item: 0.4093572497367859
16
train loss item: 0.06071850657463074
17
train loss item: 0.16707415878772736
18
train loss item: 0.20222075283527374
19
train loss item: 0.17290322482585907
20
train loss item: 0.1495373547077179
21
train loss item: 0.103474922478199
22
train loss item: 0.5391225814819336
23
train loss item: 0.5537811517715454
24
train loss item: 0.33990785479545593
25
train loss item: 0.15688197314739227
26
train loss item: 0.13625477254390717
27
train loss item: 0.14905525743961334
28
train loss item: 0.059030868113040924
29
train loss item: 0.41895416378974915
30
train loss item: 1.65471351146698
31
train loss item: 0.34262123703956604
32
train loss item: 0.08505133539438248
33
train loss item: 0.26390329003334045
34
train loss item: 0.12563693523406982
35
train loss item: 1.9809412956237793
36
train loss item: 0.33375465869903564
37
train loss item: 0.31733596324920654
38
train loss item: 0.3029254674911499
39
train loss item: 0.16152441501617432
40
train loss item: 0.11685354262590408
41
train loss item: 0.15220747888088226
42
train loss item: 0.22452622652053833
43
train loss item: 0.11616518348455429
44
train loss item: 0.48883023858070374
45
train loss item: 0.10893584042787552
46
train loss item: 0.09563025832176208
47
train loss item: 0.2291831225156784
48
train loss item: 0.14020982384681702
49
train loss item: 0.10623171925544739
50
train loss item: 0.18883715569972992
51
train loss item: 0.5478017926216125
52
train loss item: 0.06738685816526413
53
train loss item: 0.10732376575469971
54
train loss item: 1.8605035543441772
55
train loss item: 0.130886510014534
56
train loss item: 0.1554027646780014
57
train loss item: 0.1792803704738617
58
train loss item: 0.10707583278417587
59
train loss item: 0.10558867454528809
60
train loss item: 0.4976139962673187
61
train loss item: 1.7355588674545288
62
train loss item: 0.14067165553569794
63
train loss item: 0.2443222999572754
64
train loss item: 0.11357712000608444
65
train loss item: 0.32106441259384155
66
train loss item: 0.26042330265045166
67
train loss item: 0.14320357143878937
68
train loss item: 0.18229103088378906
69
train loss item: 0.20694366097450256
70
train loss item: 0.17701327800750732
71
train loss item: 0.10447122156620026
72
train loss item: 0.10679148137569427
73
train loss item: 0.19103209674358368
74
train loss item: 0.0778740867972374
75
train loss item: 0.09247299283742905
76
train loss item: 0.5372442007064819
77
train loss item: 1.0094300508499146
78
train loss item: 0.0649290606379509
79
train loss item: 0.19184677302837372
80
train loss item: 0.09988848865032196
81
train loss item: 0.1348540037870407
82
train loss item: 0.1379479020833969
83
train loss item: 0.3693709075450897
84
train loss item: 0.3056564927101135
85
train loss item: 0.3296683132648468
86
train loss item: 3.689917802810669
87
train loss item: 0.1152813509106636
88
train loss item: 0.23576992750167847
epoch train loss: 0.3377682295408142
testing phase
test loss item: 0.14820298552513123
test loss item: 0.12037253379821777
test loss item: 0.44349271059036255
test loss item: 0.17767664790153503
test loss item: 0.21139869093894958
test loss item: 0.14542856812477112
test loss item: 1.2652678489685059
test loss item: 0.4443299472332001
test loss item: 0.1656872034072876
test loss item: 0.28501269221305847
test loss item: 0.6272281408309937
test loss item: 0.15262183547019958
test loss item: 0.13985398411750793
test loss item: 0.2176322191953659
test loss item: 0.14874231815338135
test loss item: 0.1498081088066101
test loss item: 0.202626034617424
test loss item: 0.3448808789253235
test loss item: 0.49112558364868164
test loss item: 0.19948290288448334
test loss item: 0.6752399802207947
test loss item: 0.30032867193222046
test loss item: 0.3985329568386078
test loss item: 0.13261887431144714
test loss item: 0.17161749303340912
test loss item: 0.16553637385368347
test loss item: 0.22399131953716278
test loss item: 0.16376972198486328
test loss item: 0.23338168859481812
test loss item: 0.2452210634946823
test loss item: 0.5806736946105957
test loss item: 0.12665536999702454
test loss item: 0.1147783026099205
test loss item: 0.4220452904701233
test loss item: 0.32649096846580505
test loss item: 0.32985809445381165
test loss item: 0.5969563126564026
test loss item: 1.0658855438232422
test loss item: 0.33056697249412537
test loss item: 0.20621724426746368
test loss item: 0.2341340035200119
test loss item: 0.2934572994709015
test loss item: 0.2522587180137634
test loss item: 0.16037026047706604
test loss item: 0.5327392816543579
test loss item: 0.3019137382507324
test loss item: 0.3971705138683319
test loss item: 0.18676359951496124
test loss item: 0.36093568801879883
test loss item: 0.49860790371894836
test loss item: 0.20904973149299622
test loss item: 0.12866643071174622
test loss item: 0.17764732241630554
test loss item: 0.1296387016773224
test loss item: 0.22658777236938477
test loss item: 0.634139895439148
test loss item: 0.4319651424884796
test loss item: 0.1960790902376175
test loss item: 0.19506077468395233
test loss item: 0.15493075549602509
test loss item: 0.32321885228157043
test loss item: 0.21341075003147125
test loss item: 0.165493443608284
test loss item: 0.17251534759998322
test loss item: 0.6485308408737183
test loss item: 0.2458288073539734
test loss item: 0.23384889960289001
test loss item: 0.18153859674930573
test loss item: 0.4169009029865265
test loss item: 0.3128042221069336
test loss item: 0.1042013019323349
test loss item: 0.7149887084960938
test loss item: 0.2966989278793335
test loss item: 0.2852977216243744
test loss item: 0.11546068638563156
test loss item: 0.2886146306991577
test loss item: 0.15153685212135315
test loss item: 1.1150524616241455
test loss item: 0.33291876316070557
test loss item: 0.16195443272590637
test loss item: 0.10128891468048096
test loss item: 0.7260236740112305
test loss item: 0.6519736051559448
test loss item: 0.7649065852165222
test loss item: 0.173902228474617
test loss item: 0.1633950173854828
test loss item: 0.10131450742483139
test loss item: 0.1347496509552002
test loss item: 0.12684999406337738
Epoch [38/100], Training Loss: 0.3378, Testing Loss: 0.3148
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 39/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.30128103494644165
1
train loss item: 0.7308756709098816
2
train loss item: 0.13341152667999268
3
train loss item: 0.28715771436691284
4
train loss item: 0.24596205353736877
5
train loss item: 0.19718270003795624
6
train loss item: 0.1487606167793274
7
train loss item: 0.5005027651786804
8
train loss item: 0.08398354798555374
9
train loss item: 0.15196511149406433
10
train loss item: 0.19328242540359497
11
train loss item: 0.19403940439224243
12
train loss item: 0.10820239782333374
13
train loss item: 0.31709545850753784
14
train loss item: 0.15320046246051788
15
train loss item: 0.40595492720603943
16
train loss item: 0.06247060373425484
17
train loss item: 0.16320839524269104
18
train loss item: 0.19878964126110077
19
train loss item: 0.1744069755077362
20
train loss item: 0.15391306579113007
21
train loss item: 0.10274836421012878
22
train loss item: 0.5277628898620605
23
train loss item: 0.534328818321228
24
train loss item: 0.33173471689224243
25
train loss item: 0.15433308482170105
26
train loss item: 0.1367310732603073
27
train loss item: 0.14484496414661407
28
train loss item: 0.06034320965409279
29
train loss item: 0.41128039360046387
30
train loss item: 1.6341419219970703
31
train loss item: 0.33179163932800293
32
train loss item: 0.08196353167295456
33
train loss item: 0.24751579761505127
34
train loss item: 0.12250246107578278
35
train loss item: 1.9684420824050903
36
train loss item: 0.321098268032074
37
train loss item: 0.3064591884613037
38
train loss item: 0.2811461091041565
39
train loss item: 0.15978068113327026
40
train loss item: 0.1191115751862526
41
train loss item: 0.14705799520015717
42
train loss item: 0.2231370210647583
43
train loss item: 0.11414273828268051
44
train loss item: 0.4805774688720703
45
train loss item: 0.10553833097219467
46
train loss item: 0.09388317167758942
47
train loss item: 0.22696833312511444
48
train loss item: 0.13658367097377777
49
train loss item: 0.1045776829123497
50
train loss item: 0.19069170951843262
51
train loss item: 0.5370075106620789
52
train loss item: 0.07075267285108566
53
train loss item: 0.10445000231266022
54
train loss item: 1.8475717306137085
55
train loss item: 0.130484938621521
56
train loss item: 0.1531510055065155
57
train loss item: 0.18035906553268433
58
train loss item: 0.10830629616975784
59
train loss item: 0.10216687619686127
60
train loss item: 0.4849306046962738
61
train loss item: 1.715576410293579
62
train loss item: 0.13988934457302094
63
train loss item: 0.24029363691806793
64
train loss item: 0.10967454314231873
65
train loss item: 0.30901360511779785
66
train loss item: 0.2541826069355011
67
train loss item: 0.14175739884376526
68
train loss item: 0.18719139695167542
69
train loss item: 0.20241691172122955
70
train loss item: 0.17334601283073425
71
train loss item: 0.10541678965091705
72
train loss item: 0.1018703430891037
73
train loss item: 0.18862684071063995
74
train loss item: 0.07737068831920624
75
train loss item: 0.09093350172042847
76
train loss item: 0.5218312740325928
77
train loss item: 1.0003306865692139
78
train loss item: 0.06722540408372879
79
train loss item: 0.18811392784118652
80
train loss item: 0.09750385582447052
81
train loss item: 0.13402581214904785
82
train loss item: 0.13176849484443665
83
train loss item: 0.3631335198879242
84
train loss item: 0.29013070464134216
85
train loss item: 0.31923988461494446
86
train loss item: 3.670358180999756
87
train loss item: 0.11047512292861938
88
train loss item: 0.23029442131519318
epoch train loss: 0.33244985861054965
testing phase
test loss item: 0.14514383673667908
test loss item: 0.09418564289808273
test loss item: 0.45960092544555664
test loss item: 0.1749676913022995
test loss item: 0.20025686919689178
test loss item: 0.11591525375843048
test loss item: 1.2131507396697998
test loss item: 0.4228098392486572
test loss item: 0.16916978359222412
test loss item: 0.2898571193218231
test loss item: 0.6466336846351624
test loss item: 0.14370323717594147
test loss item: 0.13707639276981354
test loss item: 0.2076127827167511
test loss item: 0.1455477923154831
test loss item: 0.08396265655755997
test loss item: 0.19242142140865326
test loss item: 0.3490144908428192
test loss item: 0.4767245054244995
test loss item: 0.18686677515506744
test loss item: 0.6675256490707397
test loss item: 0.2884807884693146
test loss item: 0.32461196184158325
test loss item: 0.1290893703699112
test loss item: 0.16441023349761963
test loss item: 0.162069171667099
test loss item: 0.22047241032123566
test loss item: 0.1422981321811676
test loss item: 0.2313649207353592
test loss item: 0.24551373720169067
test loss item: 0.5840144753456116
test loss item: 0.06919505447149277
test loss item: 0.11305275559425354
test loss item: 0.4276299476623535
test loss item: 0.3269400894641876
test loss item: 0.3295937776565552
test loss item: 0.581851065158844
test loss item: 1.1069306135177612
test loss item: 0.3348299562931061
test loss item: 0.19293685257434845
test loss item: 0.2188640832901001
test loss item: 0.2247064858675003
test loss item: 0.25795045495033264
test loss item: 0.15536603331565857
test loss item: 0.520619809627533
test loss item: 0.2771711051464081
test loss item: 0.320032000541687
test loss item: 0.1738140732049942
test loss item: 0.36460238695144653
test loss item: 0.5011155009269714
test loss item: 0.22008094191551208
test loss item: 0.11824706941843033
test loss item: 0.17686660587787628
test loss item: 0.12748393416404724
test loss item: 0.23263129591941833
test loss item: 0.6582642197608948
test loss item: 0.42698100209236145
test loss item: 0.1987757384777069
test loss item: 0.18724390864372253
test loss item: 0.15691013634204865
test loss item: 0.32904332876205444
test loss item: 0.1906432807445526
test loss item: 0.15808899700641632
test loss item: 0.1692488044500351
test loss item: 0.6635674238204956
test loss item: 0.24267731606960297
test loss item: 0.2240489423274994
test loss item: 0.1761826127767563
test loss item: 0.4164046049118042
test loss item: 0.30576038360595703
test loss item: 0.06672659516334534
test loss item: 0.680079996585846
test loss item: 0.27770423889160156
test loss item: 0.2695668637752533
test loss item: 0.1095649003982544
test loss item: 0.21778330206871033
test loss item: 0.14070913195610046
test loss item: 1.1639082431793213
test loss item: 0.32834628224372864
test loss item: 0.14231549203395844
test loss item: 0.08839821815490723
test loss item: 0.7269492149353027
test loss item: 0.642464816570282
test loss item: 0.7966310381889343
test loss item: 0.1687142550945282
test loss item: 0.1563342660665512
test loss item: 0.06327849626541138
test loss item: 0.06548217684030533
test loss item: 0.13272704184055328
Epoch [39/100], Training Loss: 0.3324, Testing Loss: 0.3048
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 40/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.29731491208076477
1
train loss item: 0.7118470072746277
2
train loss item: 0.12843084335327148
3
train loss item: 0.2826836109161377
4
train loss item: 0.23673273622989655
5
train loss item: 0.1920153945684433
6
train loss item: 0.1405547559261322
7
train loss item: 0.4946407377719879
8
train loss item: 0.08426565676927567
9
train loss item: 0.14703848958015442
10
train loss item: 0.1905640959739685
11
train loss item: 0.1938164085149765
12
train loss item: 0.10566068440675735
13
train loss item: 0.31755149364471436
14
train loss item: 0.15321886539459229
15
train loss item: 0.39025694131851196
16
train loss item: 0.06192893162369728
17
train loss item: 0.16041633486747742
18
train loss item: 0.1941594034433365
19
train loss item: 0.16482365131378174
20
train loss item: 0.14422893524169922
21
train loss item: 0.09957929700613022
22
train loss item: 0.5001820921897888
23
train loss item: 0.5271964073181152
24
train loss item: 0.3144455552101135
25
train loss item: 0.1482538878917694
26
train loss item: 0.13387461006641388
27
train loss item: 0.14586639404296875
28
train loss item: 0.05984936282038689
29
train loss item: 0.3985375165939331
30
train loss item: 1.6201937198638916
31
train loss item: 0.3251870274543762
32
train loss item: 0.08314326405525208
33
train loss item: 0.2558494508266449
34
train loss item: 0.12246011942625046
35
train loss item: 1.957560658454895
36
train loss item: 0.31754258275032043
37
train loss item: 0.30294540524482727
38
train loss item: 0.27122706174850464
39
train loss item: 0.15730279684066772
40
train loss item: 0.11362923681735992
41
train loss item: 0.14728406071662903
42
train loss item: 0.2218112051486969
43
train loss item: 0.11387737095355988
44
train loss item: 0.4804222285747528
45
train loss item: 0.10675454884767532
46
train loss item: 0.09102115780115128
47
train loss item: 0.21959829330444336
48
train loss item: 0.13455058634281158
49
train loss item: 0.10505633801221848
50
train loss item: 0.17861251533031464
51
train loss item: 0.5301288962364197
52
train loss item: 0.07000745087862015
53
train loss item: 0.10516589134931564
54
train loss item: 1.8362979888916016
55
train loss item: 0.12984445691108704
56
train loss item: 0.1511567234992981
57
train loss item: 0.17320115864276886
58
train loss item: 0.10299264639616013
59
train loss item: 0.10274507105350494
60
train loss item: 0.4702906608581543
61
train loss item: 1.7051730155944824
62
train loss item: 0.13767236471176147
63
train loss item: 0.2337464541196823
64
train loss item: 0.11301672458648682
65
train loss item: 0.2918414771556854
66
train loss item: 0.2525123655796051
67
train loss item: 0.13827961683273315
68
train loss item: 0.18065327405929565
69
train loss item: 0.19662562012672424
70
train loss item: 0.1693613976240158
71
train loss item: 0.10408623516559601
72
train loss item: 0.10461835563182831
73
train loss item: 0.1816224455833435
74
train loss item: 0.07493680715560913
75
train loss item: 0.09045539796352386
76
train loss item: 0.5120915174484253
77
train loss item: 0.9843339920043945
78
train loss item: 0.06585226953029633
79
train loss item: 0.1858280599117279
80
train loss item: 0.09423403441905975
81
train loss item: 0.1304939240217209
82
train loss item: 0.13609090447425842
83
train loss item: 0.35351744294166565
84
train loss item: 0.2794383466243744
85
train loss item: 0.3121448755264282
86
train loss item: 3.6557271480560303
87
train loss item: 0.11292137205600739
88
train loss item: 0.2194371521472931
epoch train loss: 0.3273540244678433
testing phase
test loss item: 0.14315226674079895
test loss item: 0.09774580597877502
test loss item: 0.3964467942714691
test loss item: 0.17425255477428436
test loss item: 0.187197744846344
test loss item: 0.12412753701210022
test loss item: 1.2305258512496948
test loss item: 0.46067073941230774
test loss item: 0.1504550576210022
test loss item: 0.26051464676856995
test loss item: 0.5818253755569458
test loss item: 0.14945100247859955
test loss item: 0.13925215601921082
test loss item: 0.20114785432815552
test loss item: 0.14491009712219238
test loss item: 0.09158426523208618
test loss item: 0.19714035093784332
test loss item: 0.2998884618282318
test loss item: 0.493890643119812
test loss item: 0.19469797611236572
test loss item: 0.6121135354042053
test loss item: 0.2947227656841278
test loss item: 0.31808575987815857
test loss item: 0.1311698853969574
test loss item: 0.1593744307756424
test loss item: 0.1634618043899536
test loss item: 0.21273961663246155
test loss item: 0.13812397420406342
test loss item: 0.2209254950284958
test loss item: 0.22933654487133026
test loss item: 0.5533016324043274
test loss item: 0.07627234607934952
test loss item: 0.11492455750703812
test loss item: 0.3772003650665283
test loss item: 0.27979370951652527
test loss item: 0.32062408328056335
test loss item: 0.5907260775566101
test loss item: 0.9767550230026245
test loss item: 0.30008193850517273
test loss item: 0.19508178532123566
test loss item: 0.2206619828939438
test loss item: 0.22978267073631287
test loss item: 0.22105741500854492
test loss item: 0.1554536521434784
test loss item: 0.48746392130851746
test loss item: 0.2887928783893585
test loss item: 0.3174343407154083
test loss item: 0.18445539474487305
test loss item: 0.332518607378006
test loss item: 0.4646546542644501
test loss item: 0.1918943226337433
test loss item: 0.12654785811901093
test loss item: 0.16592258214950562
test loss item: 0.1252458691596985
test loss item: 0.20301152765750885
test loss item: 0.5708395838737488
test loss item: 0.4250446856021881
test loss item: 0.1813810169696808
test loss item: 0.1865205466747284
test loss item: 0.14708591997623444
test loss item: 0.2826811671257019
test loss item: 0.19974587857723236
test loss item: 0.1599472314119339
test loss item: 0.16942766308784485
test loss item: 0.6042556166648865
test loss item: 0.24001656472682953
test loss item: 0.22310136258602142
test loss item: 0.17808376252651215
test loss item: 0.38315412402153015
test loss item: 0.3141680359840393
test loss item: 0.07316194474697113
test loss item: 0.712048351764679
test loss item: 0.2597030997276306
test loss item: 0.2729496955871582
test loss item: 0.11406335979700089
test loss item: 0.22981137037277222
test loss item: 0.1490674614906311
test loss item: 1.0345951318740845
test loss item: 0.31045591831207275
test loss item: 0.14052778482437134
test loss item: 0.09632667154073715
test loss item: 0.6924263834953308
test loss item: 0.6295148134231567
test loss item: 0.705590009689331
test loss item: 0.16544897854328156
test loss item: 0.15591119229793549
test loss item: 0.06547727435827255
test loss item: 0.07129500061273575
test loss item: 0.1311514675617218
Epoch [40/100], Training Loss: 0.3274, Testing Loss: 0.2918
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 41/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.29460564255714417
1
train loss item: 0.6921922564506531
2
train loss item: 0.1326194852590561
3
train loss item: 0.2746736705303192
4
train loss item: 0.23768019676208496
5
train loss item: 0.1904798448085785
6
train loss item: 0.1468999981880188
7
train loss item: 0.4766315817832947
8
train loss item: 0.0811576172709465
9
train loss item: 0.14978726208209991
10
train loss item: 0.1947702318429947
11
train loss item: 0.19011062383651733
12
train loss item: 0.10449011623859406
13
train loss item: 0.30788904428482056
14
train loss item: 0.14480160176753998
15
train loss item: 0.39462265372276306
16
train loss item: 0.059653352946043015
17
train loss item: 0.15528441965579987
18
train loss item: 0.19600597023963928
19
train loss item: 0.1698867827653885
20
train loss item: 0.14886696636676788
21
train loss item: 0.10193562507629395
22
train loss item: 0.4949013292789459
23
train loss item: 0.5038707852363586
24
train loss item: 0.3165034055709839
25
train loss item: 0.15226157009601593
26
train loss item: 0.13018696010112762
27
train loss item: 0.13852190971374512
28
train loss item: 0.05774718523025513
29
train loss item: 0.3896079361438751
30
train loss item: 1.590536117553711
31
train loss item: 0.3285602629184723
32
train loss item: 0.08143698424100876
33
train loss item: 0.229917511343956
34
train loss item: 0.11902809143066406
35
train loss item: 1.9414215087890625
36
train loss item: 0.30981868505477905
37
train loss item: 0.29657259583473206
38
train loss item: 0.26595816016197205
39
train loss item: 0.1581520289182663
40
train loss item: 0.1170053780078888
41
train loss item: 0.13993994891643524
42
train loss item: 0.21932317316532135
43
train loss item: 0.1146586462855339
44
train loss item: 0.4646511971950531
45
train loss item: 0.1039787083864212
46
train loss item: 0.09455057978630066
47
train loss item: 0.2239580899477005
48
train loss item: 0.13088268041610718
49
train loss item: 0.10361415892839432
50
train loss item: 0.18559221923351288
51
train loss item: 0.5130325555801392
52
train loss item: 0.06697626411914825
53
train loss item: 0.10682285577058792
54
train loss item: 1.8189277648925781
55
train loss item: 0.12647128105163574
56
train loss item: 0.15584410727024078
57
train loss item: 0.1726486086845398
58
train loss item: 0.1086152046918869
59
train loss item: 0.10407926887273788
60
train loss item: 0.45183560252189636
61
train loss item: 1.6767009496688843
62
train loss item: 0.13608376681804657
63
train loss item: 0.2355668544769287
64
train loss item: 0.11366208642721176
65
train loss item: 0.28963062167167664
66
train loss item: 0.26031944155693054
67
train loss item: 0.1367366909980774
68
train loss item: 0.18319325149059296
69
train loss item: 0.19875577092170715
70
train loss item: 0.16999654471874237
71
train loss item: 0.1037236824631691
72
train loss item: 0.10026375949382782
73
train loss item: 0.18212437629699707
74
train loss item: 0.0741424709558487
75
train loss item: 0.0900731086730957
76
train loss item: 0.4956306219100952
77
train loss item: 0.972263753414154
78
train loss item: 0.0640883818268776
79
train loss item: 0.18553511798381805
80
train loss item: 0.09310030937194824
81
train loss item: 0.13163556158542633
82
train loss item: 0.1250627189874649
83
train loss item: 0.35020211338996887
84
train loss item: 0.267071932554245
85
train loss item: 0.2948114275932312
86
train loss item: 3.6308515071868896
87
train loss item: 0.10743565857410431
88
train loss item: 0.22437170147895813
epoch train loss: 0.3232189938007446
testing phase
test loss item: 0.14182274043560028
test loss item: 0.09968076646327972
test loss item: 0.5071308612823486
test loss item: 0.17290857434272766
test loss item: 0.2049953043460846
test loss item: 0.09907577931880951
test loss item: 1.1917147636413574
test loss item: 0.40244826674461365
test loss item: 0.18816158175468445
test loss item: 0.31232720613479614
test loss item: 0.7071393132209778
test loss item: 0.13205334544181824
test loss item: 0.13978971540927887
test loss item: 0.2092570960521698
test loss item: 0.14650508761405945
test loss item: 0.0825548842549324
test loss item: 0.18115682899951935
test loss item: 0.3668365776538849
test loss item: 0.4659067392349243
test loss item: 0.18078185617923737
test loss item: 0.6038188338279724
test loss item: 0.2756893038749695
test loss item: 0.2840849459171295
test loss item: 0.12671354413032532
test loss item: 0.15664757788181305
test loss item: 0.15993383526802063
test loss item: 0.22837987542152405
test loss item: 0.14047203958034515
test loss item: 0.24058622121810913
test loss item: 0.25902998447418213
test loss item: 0.6253488063812256
test loss item: 0.07423891872167587
test loss item: 0.11233929544687271
test loss item: 0.4485013484954834
test loss item: 0.3527575433254242
test loss item: 0.35082826018333435
test loss item: 0.5745764374732971
test loss item: 1.224621057510376
test loss item: 0.35574379563331604
test loss item: 0.18878348171710968
test loss item: 0.2123594880104065
test loss item: 0.17948532104492188
test loss item: 0.27355262637138367
test loss item: 0.15220260620117188
test loss item: 0.4564182162284851
test loss item: 0.26002511382102966
test loss item: 0.2679046392440796
test loss item: 0.1776682585477829
test loss item: 0.3850450813770294
test loss item: 0.5321166515350342
test loss item: 0.24744665622711182
test loss item: 0.1108146607875824
test loss item: 0.18191736936569214
test loss item: 0.1298092007637024
test loss item: 0.24956659972667694
test loss item: 0.7305948734283447
test loss item: 0.4336865246295929
test loss item: 0.20833852887153625
test loss item: 0.17928597331047058
test loss item: 0.16438399255275726
test loss item: 0.35419484972953796
test loss item: 0.17288170754909515
test loss item: 0.15007109940052032
test loss item: 0.16709387302398682
test loss item: 0.718860924243927
test loss item: 0.2402464598417282
test loss item: 0.2173927277326584
test loss item: 0.1737520396709442
test loss item: 0.43150100111961365
test loss item: 0.3205830454826355
test loss item: 0.073174387216568
test loss item: 0.6562685966491699
test loss item: 0.25847554206848145
test loss item: 0.2551650106906891
test loss item: 0.10768508911132812
test loss item: 0.18145497143268585
test loss item: 0.12678813934326172
test loss item: 1.2942278385162354
test loss item: 0.34220245480537415
test loss item: 0.1369820237159729
test loss item: 0.06689263135194778
test loss item: 0.7655474543571472
test loss item: 0.6574407815933228
test loss item: 0.887843132019043
test loss item: 0.16884516179561615
test loss item: 0.15227575600147247
test loss item: 0.06123371794819832
test loss item: 0.06123572215437889
test loss item: 0.14226579666137695
Epoch [41/100], Training Loss: 0.3232, Testing Loss: 0.3100
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 42/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2914732098579407
1
train loss item: 0.6780421733856201
2
train loss item: 0.1332525908946991
3
train loss item: 0.2845005393028259
4
train loss item: 0.24205875396728516
5
train loss item: 0.18601906299591064
6
train loss item: 0.13668158650398254
7
train loss item: 0.4821377694606781
8
train loss item: 0.09221529960632324
9
train loss item: 0.1521300971508026
10
train loss item: 0.19124145805835724
11
train loss item: 0.1962735801935196
12
train loss item: 0.10316714644432068
13
train loss item: 0.3174060881137848
14
train loss item: 0.150526762008667
15
train loss item: 0.3653918206691742
16
train loss item: 0.057129647582769394
17
train loss item: 0.1565060168504715
18
train loss item: 0.18848450481891632
19
train loss item: 0.1549341231584549
20
train loss item: 0.13739719986915588
21
train loss item: 0.102058544754982
22
train loss item: 0.46055421233177185
23
train loss item: 0.512895941734314
24
train loss item: 0.2928520143032074
25
train loss item: 0.1413041353225708
26
train loss item: 0.1321011334657669
27
train loss item: 0.15058843791484833
28
train loss item: 0.05566463991999626
29
train loss item: 0.3810102641582489
30
train loss item: 1.5954442024230957
31
train loss item: 0.3162873685359955
32
train loss item: 0.09472960233688354
33
train loss item: 0.2688150703907013
34
train loss item: 0.1217607706785202
35
train loss item: 1.9362479448318481
36
train loss item: 0.31086868047714233
37
train loss item: 0.2963245213031769
38
train loss item: 0.274221807718277
39
train loss item: 0.15812109410762787
40
train loss item: 0.11182483285665512
41
train loss item: 0.15307198464870453
42
train loss item: 0.22286400198936462
43
train loss item: 0.12266789376735687
44
train loss item: 0.47987499833106995
45
train loss item: 0.11086992919445038
46
train loss item: 0.09766466170549393
47
train loss item: 0.2133878767490387
48
train loss item: 0.13762076199054718
49
train loss item: 0.1099758967757225
50
train loss item: 0.16275881230831146
51
train loss item: 0.5236822962760925
52
train loss item: 0.06370751559734344
53
train loss item: 0.10921962559223175
54
train loss item: 1.8150197267532349
55
train loss item: 0.12774431705474854
56
train loss item: 0.15210236608982086
57
train loss item: 0.16342727839946747
58
train loss item: 0.10585780441761017
59
train loss item: 0.10839031636714935
60
train loss item: 0.444879412651062
61
train loss item: 1.6797940731048584
62
train loss item: 0.13670778274536133
63
train loss item: 0.22727154195308685
64
train loss item: 0.12701189517974854
65
train loss item: 0.26916155219078064
66
train loss item: 0.25853949785232544
67
train loss item: 0.13753212988376617
68
train loss item: 0.1695496290922165
69
train loss item: 0.1940833479166031
70
train loss item: 0.16758447885513306
71
train loss item: 0.10028457641601562
72
train loss item: 0.12127096205949783
73
train loss item: 0.17761322855949402
74
train loss item: 0.07265810668468475
75
train loss item: 0.09245197474956512
76
train loss item: 0.4919096529483795
77
train loss item: 0.9579448103904724
78
train loss item: 0.05992479994893074
79
train loss item: 0.18613912165164948
80
train loss item: 0.09474091976881027
81
train loss item: 0.12775005400180817
82
train loss item: 0.1432032436132431
83
train loss item: 0.345361590385437
84
train loss item: 0.26330840587615967
85
train loss item: 0.3085728585720062
86
train loss item: 3.627727508544922
87
train loss item: 0.1196451261639595
88
train loss item: 0.20768088102340698
epoch train loss: 0.32248152671067903
testing phase
test loss item: 0.14421626925468445
test loss item: 0.0933258980512619
test loss item: 0.35299980640411377
test loss item: 0.17258454859256744
test loss item: 0.18368753790855408
test loss item: 0.12847545742988586
test loss item: 1.2871882915496826
test loss item: 0.5018763542175293
test loss item: 0.14566822350025177
test loss item: 0.24592234194278717
test loss item: 0.5450900793075562
test loss item: 0.13695009052753448
test loss item: 0.14573301374912262
test loss item: 0.2231212705373764
test loss item: 0.12852363288402557
test loss item: 0.08137432485818863
test loss item: 0.20737063884735107
test loss item: 0.2613931894302368
test loss item: 0.5184500813484192
test loss item: 0.22036294639110565
test loss item: 0.4985964596271515
test loss item: 0.30132511258125305
test loss item: 0.5657480359077454
test loss item: 0.1344519853591919
test loss item: 0.1434999406337738
test loss item: 0.16680045425891876
test loss item: 0.2243533879518509
test loss item: 0.14859221875667572
test loss item: 0.21894952654838562
test loss item: 0.226405069231987
test loss item: 0.5456652045249939
test loss item: 0.06937616318464279
test loss item: 0.11642143130302429
test loss item: 0.33398035168647766
test loss item: 0.2403205782175064
test loss item: 0.33435001969337463
test loss item: 0.6087641716003418
test loss item: 0.8918948769569397
test loss item: 0.272204726934433
test loss item: 0.20780836045742035
test loss item: 0.22412937879562378
test loss item: 0.46257659792900085
test loss item: 0.1952279657125473
test loss item: 0.1563289612531662
test loss item: 0.40955787897109985
test loss item: 0.311322957277298
test loss item: 0.5728579163551331
test loss item: 0.2279941886663437
test loss item: 0.31057262420654297
test loss item: 0.45115187764167786
test loss item: 0.16996140778064728
test loss item: 0.13242074847221375
test loss item: 0.15993928909301758
test loss item: 0.12147405743598938
test loss item: 0.17861001193523407
test loss item: 0.5084993839263916
test loss item: 0.43455395102500916
test loss item: 0.17475460469722748
test loss item: 0.179756298661232
test loss item: 0.1377408802509308
test loss item: 0.24694745242595673
test loss item: 0.20925001800060272
test loss item: 0.16547344624996185
test loss item: 0.1709597408771515
test loss item: 0.5741932392120361
test loss item: 0.23615260422229767
test loss item: 0.23425427079200745
test loss item: 0.1839095652103424
test loss item: 0.3500116169452667
test loss item: 0.34071606397628784
test loss item: 0.07338297367095947
test loss item: 0.7607257962226868
test loss item: 0.25139477849006653
test loss item: 0.28792816400527954
test loss item: 0.12579160928726196
test loss item: 0.5125238299369812
test loss item: 0.14315739274024963
test loss item: 0.9456102252006531
test loss item: 0.3219427764415741
test loss item: 0.1547665148973465
test loss item: 0.07711734622716904
test loss item: 0.6888394951820374
test loss item: 0.6386013627052307
test loss item: 0.6495265960693359
test loss item: 0.17727309465408325
test loss item: 0.16305460035800934
test loss item: 0.06025794520974159
test loss item: 0.05971122533082962
test loss item: 0.13113661110401154
Epoch [42/100], Training Loss: 0.3225, Testing Loss: 0.2969
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 43/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2875077426433563
1
train loss item: 0.6571650505065918
2
train loss item: 0.15016411244869232
3
train loss item: 0.2812064588069916
4
train loss item: 0.23844687640666962
5
train loss item: 0.18756018579006195
6
train loss item: 0.16818836331367493
7
train loss item: 0.4559135437011719
8
train loss item: 0.08952081948518753
9
train loss item: 0.16577975451946259
10
train loss item: 0.20146866142749786
11
train loss item: 0.18811792135238647
12
train loss item: 0.10885303467512131
13
train loss item: 0.29735854268074036
14
train loss item: 0.1401243507862091
15
train loss item: 0.393344521522522
16
train loss item: 0.059619028121232986
17
train loss item: 0.15211601555347443
18
train loss item: 0.2006722092628479
19
train loss item: 0.17981590330600739
20
train loss item: 0.1657055914402008
21
train loss item: 0.11531136184930801
22
train loss item: 0.4702436029911041
23
train loss item: 0.47043418884277344
24
train loss item: 0.32124075293540955
25
train loss item: 0.1556675285100937
26
train loss item: 0.13096420466899872
27
train loss item: 0.1391524374485016
28
train loss item: 0.05760512501001358
29
train loss item: 0.377887487411499
30
train loss item: 1.5471245050430298
31
train loss item: 0.3363804221153259
32
train loss item: 0.09371441602706909
33
train loss item: 0.20716021955013275
34
train loss item: 0.11730694025754929
35
train loss item: 1.9154620170593262
36
train loss item: 0.30134260654449463
37
train loss item: 0.28621312975883484
38
train loss item: 0.2762732207775116
39
train loss item: 0.16497138142585754
40
train loss item: 0.13261090219020844
41
train loss item: 0.14361245930194855
42
train loss item: 0.21935595571994781
43
train loss item: 0.12806637585163116
44
train loss item: 0.4471481740474701
45
train loss item: 0.10088049620389938
46
train loss item: 0.11466560512781143
47
train loss item: 0.22690775990486145
48
train loss item: 0.1357746422290802
49
train loss item: 0.11367217451334
50
train loss item: 0.1963605433702469
51
train loss item: 0.49783217906951904
52
train loss item: 0.0659281387925148
53
train loss item: 0.11361335217952728
54
train loss item: 1.7918788194656372
55
train loss item: 0.1325843185186386
56
train loss item: 0.165823295712471
57
train loss item: 0.1834021508693695
58
train loss item: 0.1276315599679947
59
train loss item: 0.10630285739898682
60
train loss item: 0.4179880917072296
61
train loss item: 1.632429838180542
62
train loss item: 0.1363278031349182
63
train loss item: 0.2365376353263855
64
train loss item: 0.12435895949602127
65
train loss item: 0.283308744430542
66
train loss item: 0.27086934447288513
67
train loss item: 0.1445050835609436
68
train loss item: 0.18556222319602966
69
train loss item: 0.2028139978647232
70
train loss item: 0.17325107753276825
71
train loss item: 0.10602544248104095
72
train loss item: 0.1099180355668068
73
train loss item: 0.19108116626739502
74
train loss item: 0.07714693248271942
75
train loss item: 0.09307854622602463
76
train loss item: 0.46894216537475586
77
train loss item: 0.9492731094360352
78
train loss item: 0.06606461852788925
79
train loss item: 0.1842803657054901
80
train loss item: 0.0961228460073471
81
train loss item: 0.13893240690231323
82
train loss item: 0.12035363912582397
83
train loss item: 0.34645989537239075
84
train loss item: 0.26134124398231506
85
train loss item: 0.2874416410923004
86
train loss item: 3.5931661128997803
87
train loss item: 0.10896285623311996
88
train loss item: 0.2285914570093155
epoch train loss: 0.3217111379326729
testing phase
test loss item: 0.13991302251815796
test loss item: 0.09872910380363464
test loss item: 0.508592426776886
test loss item: 0.16923095285892487
test loss item: 0.22420427203178406
test loss item: 0.1453305035829544
test loss item: 1.087200403213501
test loss item: 0.3574219048023224
test loss item: 0.19014307856559753
test loss item: 0.31429168581962585
test loss item: 0.7091272473335266
test loss item: 0.1349833756685257
test loss item: 0.13967348635196686
test loss item: 0.20925864577293396
test loss item: 0.14973889291286469
test loss item: 0.08057789504528046
test loss item: 0.176701620221138
test loss item: 0.36711248755455017
test loss item: 0.43888482451438904
test loss item: 0.18081218004226685
test loss item: 0.61546790599823
test loss item: 0.2602003514766693
test loss item: 0.5249649286270142
test loss item: 0.12763531506061554
test loss item: 0.15567448735237122
test loss item: 0.1597781777381897
test loss item: 0.2287282794713974
test loss item: 0.17676469683647156
test loss item: 0.24138660728931427
test loss item: 0.2591570019721985
test loss item: 0.604103684425354
test loss item: 0.06979851424694061
test loss item: 0.11290677636861801
test loss item: 0.4441406726837158
test loss item: 0.35343030095100403
test loss item: 0.3454281985759735
test loss item: 0.5392863750457764
test loss item: 1.2287441492080688
test loss item: 0.3530876934528351
test loss item: 0.20161648094654083
test loss item: 0.2037070393562317
test loss item: 0.40880998969078064
test loss item: 0.2787610590457916
test loss item: 0.14587967097759247
test loss item: 0.47382691502571106
test loss item: 0.256817102432251
test loss item: 0.5240646004676819
test loss item: 0.1747770756483078
test loss item: 0.38363391160964966
test loss item: 0.5262749791145325
test loss item: 0.2545759081840515
test loss item: 0.11328256875276566
test loss item: 0.18040625751018524
test loss item: 0.12711600959300995
test loss item: 0.25197386741638184
test loss item: 0.7281577587127686
test loss item: 0.4206993281841278
test loss item: 0.2172790765762329
test loss item: 0.1817493438720703
test loss item: 0.16442716121673584
test loss item: 0.36023589968681335
test loss item: 0.16566750407218933
test loss item: 0.14721432328224182
test loss item: 0.16357871890068054
test loss item: 0.7162948250770569
test loss item: 0.2346952110528946
test loss item: 0.21783575415611267
test loss item: 0.1694687008857727
test loss item: 0.42708468437194824
test loss item: 0.3027045428752899
test loss item: 0.07104083150625229
test loss item: 0.5982764363288879
test loss item: 0.262861043214798
test loss item: 0.2435353845357895
test loss item: 0.10732964426279068
test loss item: 0.4521245062351227
test loss item: 0.13206462562084198
test loss item: 1.2991632223129272
test loss item: 0.34457340836524963
test loss item: 0.1698889136314392
test loss item: 0.07236197590827942
test loss item: 0.7438494563102722
test loss item: 0.6256190538406372
test loss item: 0.8891414403915405
test loss item: 0.17237044870853424
test loss item: 0.15150713920593262
test loss item: 0.0605458989739418
test loss item: 0.0604483000934124
test loss item: 0.14113973081111908
Epoch [43/100], Training Loss: 0.3217, Testing Loss: 0.3185
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 44/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.27937111258506775
1
train loss item: 0.6511348485946655
2
train loss item: 0.12912698090076447
3
train loss item: 0.27200907468795776
4
train loss item: 0.2303224354982376
5
train loss item: 0.1773754060268402
6
train loss item: 0.1312372386455536
7
train loss item: 0.4713507294654846
8
train loss item: 0.08852442353963852
9
train loss item: 0.1465653032064438
10
train loss item: 0.1829638034105301
11
train loss item: 0.18543162941932678
12
train loss item: 0.1009647324681282
13
train loss item: 0.3046916723251343
14
train loss item: 0.1478794813156128
15
train loss item: 0.35066303610801697
16
train loss item: 0.05707687512040138
17
train loss item: 0.14735889434814453
18
train loss item: 0.17983627319335938
19
train loss item: 0.1487768292427063
20
train loss item: 0.13360686600208282
21
train loss item: 0.0962163656949997
22
train loss item: 0.4243776202201843
23
train loss item: 0.48727095127105713
24
train loss item: 0.28344300389289856
25
train loss item: 0.13667555153369904
26
train loss item: 0.12355461716651917
27
train loss item: 0.1445259004831314
28
train loss item: 0.055301766842603683
29
train loss item: 0.3565095067024231
30
train loss item: 1.5597913265228271
31
train loss item: 0.299124151468277
32
train loss item: 0.0894969031214714
33
train loss item: 0.2599845230579376
34
train loss item: 0.11884518712759018
35
train loss item: 1.914777159690857
36
train loss item: 0.3035062253475189
37
train loss item: 0.28589507937431335
38
train loss item: 0.2624921202659607
39
train loss item: 0.15419253706932068
40
train loss item: 0.1108732521533966
41
train loss item: 0.1486789435148239
42
train loss item: 0.2173343449831009
43
train loss item: 0.11908046901226044
44
train loss item: 0.4725832939147949
45
train loss item: 0.1081445962190628
46
train loss item: 0.09377933293581009
47
train loss item: 0.20694786310195923
48
train loss item: 0.13528434932231903
49
train loss item: 0.10667753964662552
50
train loss item: 0.15657560527324677
51
train loss item: 0.5013091564178467
52
train loss item: 0.06491057574748993
53
train loss item: 0.1080591008067131
54
train loss item: 1.793347716331482
55
train loss item: 0.12556056678295135
56
train loss item: 0.1465727984905243
57
train loss item: 0.16104097664356232
58
train loss item: 0.10277104377746582
59
train loss item: 0.10398849099874496
60
train loss item: 0.41487932205200195
61
train loss item: 1.6497795581817627
62
train loss item: 0.1290358603000641
63
train loss item: 0.21873663365840912
64
train loss item: 0.12322704493999481
65
train loss item: 0.25473302602767944
66
train loss item: 0.2443290799856186
67
train loss item: 0.13154369592666626
68
train loss item: 0.16423329710960388
69
train loss item: 0.189127579331398
70
train loss item: 0.160774365067482
71
train loss item: 0.09896562993526459
72
train loss item: 0.11704239249229431
73
train loss item: 0.17304669320583344
74
train loss item: 0.06994572281837463
75
train loss item: 0.09084780514240265
76
train loss item: 0.46775099635124207
77
train loss item: 0.9302382469177246
78
train loss item: 0.060237400233745575
79
train loss item: 0.17879238724708557
80
train loss item: 0.09254349768161774
81
train loss item: 0.12511928379535675
82
train loss item: 0.1404389590024948
83
train loss item: 0.3356149196624756
84
train loss item: 0.27119141817092896
85
train loss item: 0.29586735367774963
86
train loss item: 3.5936553478240967
87
train loss item: 0.12074543535709381
88
train loss item: 0.19848395884037018
epoch train loss: 0.31344601202212025
testing phase
test loss item: 0.14505968987941742
test loss item: 0.08562308549880981
test loss item: 0.4313160181045532
test loss item: 0.1735883504152298
test loss item: 0.1843288242816925
test loss item: 0.09902630001306534
test loss item: 1.4486027956008911
test loss item: 0.5055508017539978
test loss item: 0.16254587471485138
test loss item: 0.2737300992012024
test loss item: 0.629892110824585
test loss item: 0.12988099455833435
test loss item: 0.13432292640209198
test loss item: 0.2118302285671234
test loss item: 0.12821272015571594
test loss item: 0.07092878967523575
test loss item: 0.20912720263004303
test loss item: 0.3089165687561035
test loss item: 0.5154576301574707
test loss item: 0.2051006704568863
test loss item: 0.5046395063400269
test loss item: 0.31061530113220215
test loss item: 0.3161543309688568
test loss item: 0.13758845627307892
test loss item: 0.14497992396354675
test loss item: 0.1729690134525299
test loss item: 0.22619332373142242
test loss item: 0.13407117128372192
test loss item: 0.23272188007831573
test loss item: 0.23728220164775848
test loss item: 0.6279286742210388
test loss item: 0.06014041230082512
test loss item: 0.116051584482193
test loss item: 0.3860400915145874
test loss item: 0.29324567317962646
test loss item: 0.32991495728492737
test loss item: 0.6263074278831482
test loss item: 1.0650602579116821
test loss item: 0.3172701299190521
test loss item: 0.21437858045101166
test loss item: 0.23976555466651917
test loss item: 0.214645653963089
test loss item: 0.23014605045318604
test loss item: 0.1677442491054535
test loss item: 0.3850071132183075
test loss item: 0.3044140338897705
test loss item: 0.2987616956233978
test loss item: 0.18545407056808472
test loss item: 0.3487074673175812
test loss item: 0.5003616213798523
test loss item: 0.20691585540771484
test loss item: 0.10548729449510574
test loss item: 0.17584358155727386
test loss item: 0.1236204132437706
test loss item: 0.21267180144786835
test loss item: 0.6123760342597961
test loss item: 0.4454309940338135
test loss item: 0.18991392850875854
test loss item: 0.17919501662254333
test loss item: 0.1436544954776764
test loss item: 0.29545116424560547
test loss item: 0.2053333967924118
test loss item: 0.16859500110149384
test loss item: 0.17336083948612213
test loss item: 0.6615858674049377
test loss item: 0.23877082765102386
test loss item: 0.23800107836723328
test loss item: 0.1911199986934662
test loss item: 0.38343295454978943
test loss item: 0.33726444840431213
test loss item: 0.06156463921070099
test loss item: 0.8247200846672058
test loss item: 0.25672268867492676
test loss item: 0.31081461906433105
test loss item: 0.11199429631233215
test loss item: 0.2274349331855774
test loss item: 0.13905979692935944
test loss item: 1.133938193321228
test loss item: 0.3351810574531555
test loss item: 0.14020013809204102
test loss item: 0.06487751007080078
test loss item: 0.7721099853515625
test loss item: 0.6858780980110168
test loss item: 0.7801957130432129
test loss item: 0.18559670448303223
test loss item: 0.15572093427181244
test loss item: 0.05738334730267525
test loss item: 0.054843612015247345
test loss item: 0.13997779786586761
Epoch [44/100], Training Loss: 0.3134, Testing Loss: 0.3046
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Epoch 45/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.27160370349884033
1
train loss item: 0.6307145953178406
2
train loss item: 0.11934813112020493
3
train loss item: 0.2567584812641144
4
train loss item: 0.21326595544815063
5
train loss item: 0.1719607710838318
6
train loss item: 0.13862185180187225
7
train loss item: 0.4585588574409485
8
train loss item: 0.0775088295340538
9
train loss item: 0.13645987212657928
10
train loss item: 0.16649873554706573
11
train loss item: 0.1733010709285736
12
train loss item: 0.10020598024129868
13
train loss item: 0.28322750329971313
14
train loss item: 0.13951684534549713
15
train loss item: 0.37425747513771057
16
train loss item: 0.05868377164006233
17
train loss item: 0.14000968635082245
18
train loss item: 0.17459414899349213
19
train loss item: 0.160791277885437
20
train loss item: 0.14213904738426208
21
train loss item: 0.09300757199525833
22
train loss item: 0.4389232099056244
23
train loss item: 0.45891422033309937
24
train loss item: 0.29274946451187134
25
train loss item: 0.13024300336837769
26
train loss item: 0.11857552826404572
27
train loss item: 0.12994365394115448
28
train loss item: 0.056428130716085434
29
train loss item: 0.36817115545272827
30
train loss item: 1.5363566875457764
31
train loss item: 0.2818077802658081
32
train loss item: 0.07524941116571426
33
train loss item: 0.22491280734539032
34
train loss item: 0.11403437703847885
35
train loss item: 1.9005494117736816
36
train loss item: 0.26925793290138245
37
train loss item: 0.26249319314956665
38
train loss item: 0.22796280682086945
39
train loss item: 0.1459542214870453
40
train loss item: 0.10999074578285217
41
train loss item: 0.13233934342861176
42
train loss item: 0.21429544687271118
43
train loss item: 0.10726113617420197
44
train loss item: 0.45252490043640137
45
train loss item: 0.10053014755249023
46
train loss item: 0.08384840935468674
47
train loss item: 0.21443234384059906
48
train loss item: 0.12542831897735596
49
train loss item: 0.09607534855604172
50
train loss item: 0.17615081369876862
51
train loss item: 0.4858299791812897
52
train loss item: 0.06703176349401474
53
train loss item: 0.09798957407474518
54
train loss item: 1.7792543172836304
55
train loss item: 0.12315601110458374
56
train loss item: 0.138154536485672
57
train loss item: 0.16811515390872955
58
train loss item: 0.0989140123128891
59
train loss item: 0.09932833909988403
60
train loss item: 0.41305169463157654
61
train loss item: 1.623187780380249
62
train loss item: 0.12374281138181686
63
train loss item: 0.22283127903938293
64
train loss item: 0.10519085824489594
65
train loss item: 0.24789142608642578
66
train loss item: 0.21649938821792603
67
train loss item: 0.1280393749475479
68
train loss item: 0.18065567314624786
69
train loss item: 0.17736831307411194
70
train loss item: 0.15850605070590973
71
train loss item: 0.09918785840272903
72
train loss item: 0.09590332210063934
73
train loss item: 0.17462529242038727
74
train loss item: 0.07163219153881073
75
train loss item: 0.08707079291343689
76
train loss item: 0.4494563639163971
77
train loss item: 0.9385029077529907
78
train loss item: 0.06242859736084938
79
train loss item: 0.17264042794704437
80
train loss item: 0.08671867847442627
81
train loss item: 0.1313512772321701
82
train loss item: 0.12058787047863007
83
train loss item: 0.32957446575164795
84
train loss item: 0.22351929545402527
85
train loss item: 0.2861103117465973
86
train loss item: 3.569725513458252
87
train loss item: 0.10623028874397278
88
train loss item: 0.19328200817108154
epoch train loss: 0.30539015634508615
testing phase
test loss item: 0.13778875768184662
test loss item: 0.08517139405012131
test loss item: 0.3449372351169586
test loss item: 0.15983064472675323
test loss item: 0.16766582429409027
test loss item: 0.09337286651134491
test loss item: 0.8863517045974731
test loss item: 0.3126492202281952
test loss item: 0.13788434863090515
test loss item: 0.2307872772216797
test loss item: 0.5251379013061523
test loss item: 0.12031500786542892
test loss item: 0.1269761472940445
test loss item: 0.19760483503341675
test loss item: 0.11600693315267563
test loss item: 0.07347079366445541
test loss item: 0.16876408457756042
test loss item: 0.25575533509254456
test loss item: 0.393053263425827
test loss item: 0.17681986093521118
test loss item: 0.404706746339798
test loss item: 0.23914192616939545
test loss item: 0.26713797450065613
test loss item: 0.11552190780639648
test loss item: 0.12682758271694183
test loss item: 0.15089038014411926
test loss item: 0.19611336290836334
test loss item: 0.12475383281707764
test loss item: 0.1990915983915329
test loss item: 0.20427629351615906
test loss item: 0.443298876285553
test loss item: 0.061497386544942856
test loss item: 0.10391607880592346
test loss item: 0.32381391525268555
test loss item: 0.23666207492351532
test loss item: 0.28763917088508606
test loss item: 0.45596832036972046
test loss item: 0.8814279437065125
test loss item: 0.25555220246315
test loss item: 0.16438648104667664
test loss item: 0.18880046904087067
test loss item: 0.18598179519176483
test loss item: 0.19216714799404144
test loss item: 0.13182897865772247
test loss item: 0.3140263855457306
test loss item: 0.24792078137397766
test loss item: 0.2573794424533844
test loss item: 0.18176187574863434
test loss item: 0.28440189361572266
test loss item: 0.39757412672042847
test loss item: 0.17037393152713776
test loss item: 0.10352165997028351
test loss item: 0.1467127650976181
test loss item: 0.11448505520820618
test loss item: 0.1768580824136734
test loss item: 0.4975561499595642
test loss item: 0.3582378625869751
test loss item: 0.16037176549434662
test loss item: 0.15660008788108826
test loss item: 0.13420015573501587
test loss item: 0.24565540254116058
test loss item: 0.1608191430568695
test loss item: 0.14337310194969177
test loss item: 0.1520927995443344
test loss item: 0.5016802549362183
test loss item: 0.222254678606987
test loss item: 0.19470526278018951
test loss item: 0.15927793085575104
test loss item: 0.3421911299228668
test loss item: 0.2495875358581543
test loss item: 0.06472823023796082
test loss item: 0.5061444640159607
test loss item: 0.22937171161174774
test loss item: 0.22397629916667938
test loss item: 0.10582201182842255
test loss item: 0.19766491651535034
test loss item: 0.11522120237350464
test loss item: 0.9359674453735352
test loss item: 0.29448187351226807
test loss item: 0.12991765141487122
test loss item: 0.06026579067111015
test loss item: 0.556963324546814
test loss item: 0.48397549986839294
test loss item: 0.6241158246994019
test loss item: 0.1571381837129593
test loss item: 0.14521880447864532
test loss item: 0.05541370064020157
test loss item: 0.054447803646326065
test loss item: 0.12634846568107605
Epoch [45/100], Training Loss: 0.3054, Testing Loss: 0.2449
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 46/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2710060775279999
1
train loss item: 0.6308771371841431
2
train loss item: 0.1265907883644104
3
train loss item: 0.30259275436401367
4
train loss item: 0.2341015785932541
5
train loss item: 0.18129859864711761
6
train loss item: 0.14443300664424896
7
train loss item: 0.43321844935417175
8
train loss item: 0.07724332064390182
9
train loss item: 0.1547679305076599
10
train loss item: 0.1894015371799469
11
train loss item: 0.18419921398162842
12
train loss item: 0.1015448197722435
13
train loss item: 0.29517051577568054
14
train loss item: 0.13450957834720612
15
train loss item: 0.3866656422615051
16
train loss item: 0.058474957942962646
17
train loss item: 0.15105347335338593
18
train loss item: 0.20099467039108276
19
train loss item: 0.15855063498020172
20
train loss item: 0.15033918619155884
21
train loss item: 0.10629400610923767
22
train loss item: 0.4119209349155426
23
train loss item: 0.4485265910625458
24
train loss item: 0.32482898235321045
25
train loss item: 0.1441745162010193
26
train loss item: 0.1225099265575409
27
train loss item: 0.12878181040287018
28
train loss item: 0.056257013231515884
29
train loss item: 0.34423986077308655
30
train loss item: 1.4906280040740967
31
train loss item: 0.34162867069244385
32
train loss item: 0.07962654531002045
33
train loss item: 0.20155324041843414
34
train loss item: 0.1213580071926117
35
train loss item: 1.8820313215255737
36
train loss item: 0.32288119196891785
37
train loss item: 0.3024158179759979
38
train loss item: 0.3472059667110443
39
train loss item: 0.15820658206939697
40
train loss item: 0.11657903343439102
41
train loss item: 0.13368584215641022
42
train loss item: 0.2187706083059311
43
train loss item: 0.11094469577074051
44
train loss item: 0.43528488278388977
45
train loss item: 0.0947827398777008
46
train loss item: 0.09407515823841095
47
train loss item: 0.22821944952011108
48
train loss item: 0.12215009331703186
49
train loss item: 0.10050035268068314
50
train loss item: 0.16817714273929596
51
train loss item: 0.45757386088371277
52
train loss item: 0.06575222313404083
53
train loss item: 0.10447856038808823
54
train loss item: 1.7579847574234009
55
train loss item: 0.1228175237774849
56
train loss item: 0.15389519929885864
57
train loss item: 0.17256729304790497
58
train loss item: 0.10914532095193863
59
train loss item: 0.10170398652553558
60
train loss item: 0.37194332480430603
61
train loss item: 1.5910546779632568
62
train loss item: 0.12754133343696594
63
train loss item: 0.234669491648674
64
train loss item: 0.10901283472776413
65
train loss item: 0.30381837487220764
66
train loss item: 0.278079628944397
67
train loss item: 0.13879002630710602
68
train loss item: 0.17302021384239197
69
train loss item: 0.21961958706378937
70
train loss item: 0.1730503886938095
71
train loss item: 0.09713486582040787
72
train loss item: 0.09527165442705154
73
train loss item: 0.1726524978876114
74
train loss item: 0.07439114898443222
75
train loss item: 0.08651863038539886
76
train loss item: 0.45053917169570923
77
train loss item: 0.8825734853744507
78
train loss item: 0.06296572834253311
79
train loss item: 0.18888349831104279
80
train loss item: 0.08964439481496811
81
train loss item: 0.13430847227573395
82
train loss item: 0.11047904193401337
83
train loss item: 0.3472267985343933
84
train loss item: 0.2956870198249817
85
train loss item: 0.26995620131492615
86
train loss item: 3.545527696609497
87
train loss item: 0.10020477324724197
88
train loss item: 0.24148264527320862
epoch train loss: 0.3116543729569805
testing phase
test loss item: 0.1443047821521759
test loss item: 0.08823363482952118
test loss item: 0.4555339813232422
test loss item: 0.1748000830411911
test loss item: 0.18906459212303162
test loss item: 0.1003519594669342
test loss item: 1.4246350526809692
test loss item: 0.4894191026687622
test loss item: 0.1757625937461853
test loss item: 0.29075923562049866
test loss item: 0.6495172381401062
test loss item: 0.13332007825374603
test loss item: 0.1348876804113388
test loss item: 0.21507148444652557
test loss item: 0.1337490975856781
test loss item: 0.07021372020244598
test loss item: 0.21026693284511566
test loss item: 0.32687458395957947
test loss item: 0.49937084317207336
test loss item: 0.20722778141498566
test loss item: 0.5267073512077332
test loss item: 0.309376060962677
test loss item: 0.26020511984825134
test loss item: 0.13923901319503784
test loss item: 0.14798618853092194
test loss item: 0.1759776771068573
test loss item: 0.23457585275173187
test loss item: 0.13475650548934937
test loss item: 0.24071739614009857
test loss item: 0.24789707362651825
test loss item: 0.6385256052017212
test loss item: 0.06048702448606491
test loss item: 0.11713629961013794
test loss item: 0.40150535106658936
test loss item: 0.31044816970825195
test loss item: 0.33728018403053284
test loss item: 0.6124383807182312
test loss item: 1.10469388961792
test loss item: 0.33220675587654114
test loss item: 0.21787136793136597
test loss item: 0.23910069465637207
test loss item: 0.1541016697883606
test loss item: 0.24886873364448547
test loss item: 0.17140944302082062
test loss item: 0.4047751724720001
test loss item: 0.303002268075943
test loss item: 0.2335931658744812
test loss item: 0.18204455077648163
test loss item: 0.3630904257297516
test loss item: 0.5148693919181824
test loss item: 0.22884449362754822
test loss item: 0.10451339185237885
test loss item: 0.18344241380691528
test loss item: 0.1296095997095108
test loss item: 0.22657139599323273
test loss item: 0.642345666885376
test loss item: 0.4396306872367859
test loss item: 0.2010185867547989
test loss item: 0.18388868868350983
test loss item: 0.15183939039707184
test loss item: 0.32311201095581055
test loss item: 0.20338568091392517
test loss item: 0.17105349898338318
test loss item: 0.17343328893184662
test loss item: 0.6741764545440674
test loss item: 0.2399243712425232
test loss item: 0.2405499368906021
test loss item: 0.19114655256271362
test loss item: 0.38983118534088135
test loss item: 0.3331086039543152
test loss item: 0.06372235715389252
test loss item: 0.808989942073822
test loss item: 0.25822991132736206
test loss item: 0.3194185793399811
test loss item: 0.11315758526325226
test loss item: 0.1509571522474289
test loss item: 0.1402348428964615
test loss item: 1.1686077117919922
test loss item: 0.3411215841770172
test loss item: 0.13897323608398438
test loss item: 0.06719864159822464
test loss item: 0.7745081186294556
test loss item: 0.6838756203651428
test loss item: 0.8071975708007812
test loss item: 0.19093695282936096
test loss item: 0.15703272819519043
test loss item: 0.05844882130622864
test loss item: 0.054510489106178284
test loss item: 0.14107386767864227
Epoch [46/100], Training Loss: 0.3117, Testing Loss: 0.3073
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 47/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.26596254110336304
1
train loss item: 0.623318612575531
2
train loss item: 0.11659690737724304
3
train loss item: 0.2702941298484802
4
train loss item: 0.2130649983882904
5
train loss item: 0.16555047035217285
6
train loss item: 0.1275652050971985
7
train loss item: 0.45919686555862427
8
train loss item: 0.0788513571023941
9
train loss item: 0.13485018908977509
10
train loss item: 0.16338904201984406
11
train loss item: 0.16801385581493378
12
train loss item: 0.09752526134252548
13
train loss item: 0.277618408203125
14
train loss item: 0.13894031941890717
15
train loss item: 0.3948877155780792
16
train loss item: 0.055478207767009735
17
train loss item: 0.13200560212135315
18
train loss item: 0.1675758957862854
19
train loss item: 0.15218167006969452
20
train loss item: 0.13344328105449677
21
train loss item: 0.08897152543067932
22
train loss item: 0.43666568398475647
23
train loss item: 0.4531168043613434
24
train loss item: 0.2906579077243805
25
train loss item: 0.12745581567287445
26
train loss item: 0.11511397361755371
27
train loss item: 0.13242323696613312
28
train loss item: 0.05311702564358711
29
train loss item: 0.3897864818572998
30
train loss item: 1.5269218683242798
31
train loss item: 0.26957106590270996
32
train loss item: 0.07750655710697174
33
train loss item: 0.24128790199756622
34
train loss item: 0.1134646013379097
35
train loss item: 1.883660078048706
36
train loss item: 0.26415008306503296
37
train loss item: 0.2511274218559265
38
train loss item: 0.22834061086177826
39
train loss item: 0.14309968054294586
40
train loss item: 0.10726620256900787
41
train loss item: 0.13522684574127197
42
train loss item: 0.21298229694366455
43
train loss item: 0.10857425630092621
44
train loss item: 0.45622870326042175
45
train loss item: 0.10222333669662476
46
train loss item: 0.08449140936136246
47
train loss item: 0.21581779420375824
48
train loss item: 0.12557914853096008
49
train loss item: 0.09658373892307281
50
train loss item: 0.16664695739746094
51
train loss item: 0.4822741746902466
52
train loss item: 0.060603924095630646
53
train loss item: 0.09946877509355545
54
train loss item: 1.766045331954956
55
train loss item: 0.12171212583780289
56
train loss item: 0.13514062762260437
57
train loss item: 0.1602625697851181
58
train loss item: 0.09595038741827011
59
train loss item: 0.09983548521995544
60
train loss item: 0.4217948913574219
61
train loss item: 1.6125202178955078
62
train loss item: 0.11979565769433975
63
train loss item: 0.2186577469110489
64
train loss item: 0.10959344357252121
65
train loss item: 0.23368105292320251
66
train loss item: 0.20684300363063812
67
train loss item: 0.12594152987003326
68
train loss item: 0.17847415804862976
69
train loss item: 0.1724480390548706
70
train loss item: 0.15696771442890167
71
train loss item: 0.09295695275068283
72
train loss item: 0.10224094241857529
73
train loss item: 0.17352139949798584
74
train loss item: 0.06781559437513351
75
train loss item: 0.0875970721244812
76
train loss item: 0.44125115871429443
77
train loss item: 0.9336727857589722
78
train loss item: 0.05792290344834328
79
train loss item: 0.16751456260681152
80
train loss item: 0.0874980017542839
81
train loss item: 0.12761878967285156
82
train loss item: 0.12444733083248138
83
train loss item: 0.3267720937728882
84
train loss item: 0.21766485273838043
85
train loss item: 0.2973974645137787
86
train loss item: 3.546293020248413
87
train loss item: 0.11162108182907104
88
train loss item: 0.18307580053806305
epoch train loss: 0.3029130585910229
testing phase
test loss item: 0.14117109775543213
test loss item: 0.08567888289690018
test loss item: 0.4582974910736084
test loss item: 0.16890786588191986
test loss item: 0.18884116411209106
test loss item: 0.09858101606369019
test loss item: 1.3588145971298218
test loss item: 0.4466123878955841
test loss item: 0.17277845740318298
test loss item: 0.2851623296737671
test loss item: 0.6637246012687683
test loss item: 0.12756246328353882
test loss item: 0.12961474061012268
test loss item: 0.2086292803287506
test loss item: 0.13178052008152008
test loss item: 0.06822910159826279
test loss item: 0.19464029371738434
test loss item: 0.32103675603866577
test loss item: 0.46885430812835693
test loss item: 0.19022499024868011
test loss item: 0.5177103281021118
test loss item: 0.2891598343849182
test loss item: 0.3075062334537506
test loss item: 0.1307017207145691
test loss item: 0.14520716667175293
test loss item: 0.16301566362380981
test loss item: 0.22414670884609222
test loss item: 0.13485237956047058
test loss item: 0.2342311590909958
test loss item: 0.24050551652908325
test loss item: 0.6311275362968445
test loss item: 0.05952993407845497
test loss item: 0.1103171706199646
test loss item: 0.39899924397468567
test loss item: 0.309228777885437
test loss item: 0.32546862959861755
test loss item: 0.5822626948356628
test loss item: 1.1399340629577637
test loss item: 0.3289673626422882
test loss item: 0.20800630748271942
test loss item: 0.22876501083374023
test loss item: 0.20165929198265076
test loss item: 0.2440049648284912
test loss item: 0.16165432333946228
test loss item: 0.39914682507514954
test loss item: 0.2759329080581665
test loss item: 0.2888875901699066
test loss item: 0.17091666162014008
test loss item: 0.35592347383499146
test loss item: 0.5086239576339722
test loss item: 0.2236924022436142
test loss item: 0.10094533860683441
test loss item: 0.17765119671821594
test loss item: 0.12455905973911285
test loss item: 0.22264763712882996
test loss item: 0.6535017490386963
test loss item: 0.42479828000068665
test loss item: 0.19143080711364746
test loss item: 0.17314234375953674
test loss item: 0.14939376711845398
test loss item: 0.31728795170783997
test loss item: 0.1817629486322403
test loss item: 0.15658776462078094
test loss item: 0.1669892817735672
test loss item: 0.670839786529541
test loss item: 0.23456968367099762
test loss item: 0.22080551087856293
test loss item: 0.18377584218978882
test loss item: 0.3953213691711426
test loss item: 0.31079524755477905
test loss item: 0.061450663954019547
test loss item: 0.7561794519424438
test loss item: 0.24924017488956451
test loss item: 0.29587724804878235
test loss item: 0.10620078444480896
test loss item: 0.2152351438999176
test loss item: 0.13268183171749115
test loss item: 1.2129747867584229
test loss item: 0.33739200234413147
test loss item: 0.13578695058822632
test loss item: 0.06365390121936798
test loss item: 0.764228105545044
test loss item: 0.6573858261108398
test loss item: 0.8291643261909485
test loss item: 0.17995451390743256
test loss item: 0.14975108206272125
test loss item: 0.05610547214746475
test loss item: 0.053837236016988754
test loss item: 0.13405092060565948
Epoch [47/100], Training Loss: 0.3029, Testing Loss: 0.3022
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 48/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.26255637407302856
1
train loss item: 0.5860418081283569
2
train loss item: 0.11267504841089249
3
train loss item: 0.24672332406044006
4
train loss item: 0.21131671965122223
5
train loss item: 0.16553954780101776
6
train loss item: 0.12315820157527924
7
train loss item: 0.4453328251838684
8
train loss item: 0.07874270528554916
9
train loss item: 0.12951970100402832
10
train loss item: 0.16430282592773438
11
train loss item: 0.17099617421627045
12
train loss item: 0.09699190407991409
13
train loss item: 0.27892324328422546
14
train loss item: 0.1358567178249359
15
train loss item: 0.3283962905406952
16
train loss item: 0.05456426739692688
17
train loss item: 0.13501772284507751
18
train loss item: 0.1628427803516388
19
train loss item: 0.13829956948757172
20
train loss item: 0.12881289422512054
21
train loss item: 0.08963440358638763
22
train loss item: 0.3744063675403595
23
train loss item: 0.4402915835380554
24
train loss item: 0.26854512095451355
25
train loss item: 0.12587092816829681
26
train loss item: 0.11392810195684433
27
train loss item: 0.13050411641597748
28
train loss item: 0.05237359553575516
29
train loss item: 0.3185473382472992
30
train loss item: 1.5015848875045776
31
train loss item: 0.26741698384284973
32
train loss item: 0.07778073847293854
33
train loss item: 0.2297583520412445
34
train loss item: 0.1176796555519104
35
train loss item: 1.871193289756775
36
train loss item: 0.2721557021141052
37
train loss item: 0.2665393650531769
38
train loss item: 0.21823087334632874
39
train loss item: 0.14075981080532074
40
train loss item: 0.10524314641952515
41
train loss item: 0.13175155222415924
42
train loss item: 0.20973272621631622
43
train loss item: 0.10645483434200287
44
train loss item: 0.4506939649581909
45
train loss item: 0.10080432146787643
46
train loss item: 0.08562695980072021
47
train loss item: 0.20161166787147522
48
train loss item: 0.12204792350530624
49
train loss item: 0.09562511742115021
50
train loss item: 0.14958418905735016
51
train loss item: 0.456142395734787
52
train loss item: 0.05945912376046181
53
train loss item: 0.09710194915533066
54
train loss item: 1.7518784999847412
55
train loss item: 0.1165534183382988
56
train loss item: 0.1334485411643982
57
train loss item: 0.15344898402690887
58
train loss item: 0.09411638975143433
59
train loss item: 0.10026031732559204
60
train loss item: 0.3733889162540436
61
train loss item: 1.593766450881958
62
train loss item: 0.11961236596107483
63
train loss item: 0.20661945641040802
64
train loss item: 0.10836231708526611
65
train loss item: 0.22683867812156677
66
train loss item: 0.21469904482364655
67
train loss item: 0.12437450885772705
68
train loss item: 0.15672381222248077
69
train loss item: 0.17020757496356964
70
train loss item: 0.15084801614284515
71
train loss item: 0.09132802486419678
72
train loss item: 0.09971168637275696
73
train loss item: 0.1608784943819046
74
train loss item: 0.06747155636548996
75
train loss item: 0.08650148659944534
76
train loss item: 0.4264192581176758
77
train loss item: 0.8907419443130493
78
train loss item: 0.05671035498380661
79
train loss item: 0.16426879167556763
80
train loss item: 0.08604046702384949
81
train loss item: 0.12022367864847183
82
train loss item: 0.12203939259052277
83
train loss item: 0.31343552470207214
84
train loss item: 0.23032787442207336
85
train loss item: 0.2719171345233917
86
train loss item: 3.530181407928467
87
train loss item: 0.10787233710289001
88
train loss item: 0.17961643636226654
epoch train loss: 0.2944553356743261
testing phase
test loss item: 0.14045533537864685
test loss item: 0.07969167083501816
test loss item: 0.3421028256416321
test loss item: 0.16169829666614532
test loss item: 0.16126997768878937
test loss item: 0.09039319306612015
test loss item: 1.1182993650436401
test loss item: 0.40795376896858215
test loss item: 0.13597728312015533
test loss item: 0.22535176575183868
test loss item: 0.5250861048698425
test loss item: 0.11922070384025574
test loss item: 0.12751826643943787
test loss item: 0.22305306792259216
test loss item: 0.11199362576007843
test loss item: 0.06745883077383041
test loss item: 0.18932877480983734
test loss item: 0.2416810691356659
test loss item: 0.43598291277885437
test loss item: 0.1971164345741272
test loss item: 0.3780534863471985
test loss item: 0.269228994846344
test loss item: 0.2605116665363312
test loss item: 0.12377780675888062
test loss item: 0.12665881216526031
test loss item: 0.15438121557235718
test loss item: 0.20606352388858795
test loss item: 0.11899854242801666
test loss item: 0.20396074652671814
test loss item: 0.2031489461660385
test loss item: 0.49754852056503296
test loss item: 0.0582113154232502
test loss item: 0.10650179535150528
test loss item: 0.3117138147354126
test loss item: 0.22590024769306183
test loss item: 0.29689621925354004
test loss item: 0.513114869594574
test loss item: 0.8766190409660339
test loss item: 0.2545728385448456
test loss item: 0.1862669140100479
test loss item: 0.2107774317264557
test loss item: 0.1797265261411667
test loss item: 0.17593398690223694
test loss item: 0.1472361981868744
test loss item: 0.29753556847572327
test loss item: 0.2755386233329773
test loss item: 0.24224810302257538
test loss item: 0.20350104570388794
test loss item: 0.28720536828041077
test loss item: 0.412991464138031
test loss item: 0.16047163307666779
test loss item: 0.10708795487880707
test loss item: 0.15284067392349243
test loss item: 0.11428344249725342
test loss item: 0.16780680418014526
test loss item: 0.4896180331707001
test loss item: 0.3819822669029236
test loss item: 0.16346625983715057
test loss item: 0.15919587016105652
test loss item: 0.1280657947063446
test loss item: 0.2277400940656662
test loss item: 0.18189264833927155
test loss item: 0.1537908911705017
test loss item: 0.15853703022003174
test loss item: 0.5254368782043457
test loss item: 0.22399166226387024
test loss item: 0.2102135419845581
test loss item: 0.17178381979465485
test loss item: 0.3352019190788269
test loss item: 0.29049158096313477
test loss item: 0.06015278026461601
test loss item: 0.6501917839050293
test loss item: 0.24161800742149353
test loss item: 0.27129051089286804
test loss item: 0.11072718352079391
test loss item: 0.1891053020954132
test loss item: 0.12468180805444717
test loss item: 0.9398764371871948
test loss item: 0.3139966130256653
test loss item: 0.12844450771808624
test loss item: 0.05897267162799835
test loss item: 0.6188031435012817
test loss item: 0.545121967792511
test loss item: 0.6309746503829956
test loss item: 0.16815467178821564
test loss item: 0.14850664138793945
test loss item: 0.054068438708782196
test loss item: 0.05264686420559883
test loss item: 0.12322574108839035
Epoch [48/100], Training Loss: 0.2945, Testing Loss: 0.2566
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 49/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2614434063434601
1
train loss item: 0.5748866200447083
2
train loss item: 0.1307828575372696
3
train loss item: 0.26969262957572937
4
train loss item: 0.2268410474061966
5
train loss item: 0.1700146347284317
6
train loss item: 0.1397911161184311
7
train loss item: 0.4137483537197113
8
train loss item: 0.0766064003109932
9
train loss item: 0.14508967101573944
10
train loss item: 0.17443639039993286
11
train loss item: 0.17684195935726166
12
train loss item: 0.10017324984073639
13
train loss item: 0.2761983275413513
14
train loss item: 0.12974587082862854
15
train loss item: 0.34948331117630005
16
train loss item: 0.05556061118841171
17
train loss item: 0.14307594299316406
18
train loss item: 0.1811458170413971
19
train loss item: 0.14872516691684723
20
train loss item: 0.14519259333610535
21
train loss item: 0.10621421039104462
22
train loss item: 0.38032060861587524
23
train loss item: 0.41178593039512634
24
train loss item: 0.3036016523838043
25
train loss item: 0.13057652115821838
26
train loss item: 0.11701589077711105
27
train loss item: 0.12569265067577362
28
train loss item: 0.05327896028757095
29
train loss item: 0.3060014545917511
30
train loss item: 1.44779634475708
31
train loss item: 0.30828163027763367
32
train loss item: 0.08468934148550034
33
train loss item: 0.18574853241443634
34
train loss item: 0.11453147232532501
35
train loss item: 1.8524196147918701
36
train loss item: 0.309276819229126
37
train loss item: 0.2902369499206543
38
train loss item: 0.29432496428489685
39
train loss item: 0.1536041647195816
40
train loss item: 0.1167166456580162
41
train loss item: 0.12616673111915588
42
train loss item: 0.20976662635803223
43
train loss item: 0.11082107573747635
44
train loss item: 0.42337387800216675
45
train loss item: 0.09391016513109207
46
train loss item: 0.09653943032026291
47
train loss item: 0.20823581516742706
48
train loss item: 0.11872967332601547
49
train loss item: 0.10053762793540955
50
train loss item: 0.1590600609779358
51
train loss item: 0.42685651779174805
52
train loss item: 0.06041775271296501
53
train loss item: 0.10092093050479889
54
train loss item: 1.7298095226287842
55
train loss item: 0.12114261835813522
56
train loss item: 0.14512109756469727
57
train loss item: 0.16523753106594086
58
train loss item: 0.11085696518421173
59
train loss item: 0.09958281368017197
60
train loss item: 0.3414343595504761
61
train loss item: 1.5530844926834106
62
train loss item: 0.12475647777318954
63
train loss item: 0.21845322847366333
64
train loss item: 0.10789045691490173
65
train loss item: 0.27613943815231323
66
train loss item: 0.2581610381603241
67
train loss item: 0.1350274235010147
68
train loss item: 0.15908312797546387
69
train loss item: 0.19701141119003296
70
train loss item: 0.1576315313577652
71
train loss item: 0.09768129140138626
72
train loss item: 0.09514768421649933
73
train loss item: 0.16321398317813873
74
train loss item: 0.07248678058385849
75
train loss item: 0.08506394177675247
76
train loss item: 0.4107306897640228
77
train loss item: 0.8503351807594299
78
train loss item: 0.05990554019808769
79
train loss item: 0.17386694252490997
80
train loss item: 0.09225619584321976
81
train loss item: 0.12423044443130493
82
train loss item: 0.10628725588321686
83
train loss item: 0.33355870842933655
84
train loss item: 0.27276861667633057
85
train loss item: 0.24634653329849243
86
train loss item: 3.502448797225952
87
train loss item: 0.09801317751407623
88
train loss item: 0.21959742903709412
epoch train loss: 0.2979920151528348
testing phase
test loss item: 0.1401263177394867
test loss item: 0.08237617462873459
test loss item: 0.43991005420684814
test loss item: 0.16484713554382324
test loss item: 0.18106989562511444
test loss item: 0.0931098684668541
test loss item: 1.207863450050354
test loss item: 0.42687034606933594
test loss item: 0.16382759809494019
test loss item: 0.27054134011268616
test loss item: 0.6274271607398987
test loss item: 0.1230987012386322
test loss item: 0.13186608254909515
test loss item: 0.21135933697223663
test loss item: 0.12664704024791718
test loss item: 0.06635387986898422
test loss item: 0.19618412852287292
test loss item: 0.3030669689178467
test loss item: 0.44677576422691345
test loss item: 0.19586125016212463
test loss item: 0.49240642786026
test loss item: 0.28145599365234375
test loss item: 0.283442884683609
test loss item: 0.12787781655788422
test loss item: 0.13971500098705292
test loss item: 0.1597282588481903
test loss item: 0.21862776577472687
test loss item: 0.12769390642642975
test loss item: 0.223779559135437
test loss item: 0.2283284068107605
test loss item: 0.5805611610412598
test loss item: 0.0587320514023304
test loss item: 0.10960221290588379
test loss item: 0.37898197770118713
test loss item: 0.2928200364112854
test loss item: 0.3087063431739807
test loss item: 0.5455390214920044
test loss item: 1.078029751777649
test loss item: 0.3090057373046875
test loss item: 0.19466020166873932
test loss item: 0.21725685894489288
test loss item: 0.18572668731212616
test loss item: 0.22666333615779877
test loss item: 0.15495449304580688
test loss item: 0.37738674879074097
test loss item: 0.28407755494117737
test loss item: 0.26270195841789246
test loss item: 0.18127217888832092
test loss item: 0.34580734372138977
test loss item: 0.4792596399784088
test loss item: 0.2097252905368805
test loss item: 0.0982394888997078
test loss item: 0.17074306309223175
test loss item: 0.11989077180624008
test loss item: 0.21023499965667725
test loss item: 0.6197115182876587
test loss item: 0.4078438878059387
test loss item: 0.183354452252388
test loss item: 0.17143578827381134
test loss item: 0.14500774443149567
test loss item: 0.2936303913593292
test loss item: 0.18874606490135193
test loss item: 0.15772917866706848
test loss item: 0.1629195660352707
test loss item: 0.6423487067222595
test loss item: 0.2279292494058609
test loss item: 0.22462095320224762
test loss item: 0.17546513676643372
test loss item: 0.3829655945301056
test loss item: 0.29664483666419983
test loss item: 0.06026535481214523
test loss item: 0.6919505596160889
test loss item: 0.2505207657814026
test loss item: 0.28493455052375793
test loss item: 0.10966301709413528
test loss item: 0.19660867750644684
test loss item: 0.12801335752010345
test loss item: 1.1565536260604858
test loss item: 0.3320825397968292
test loss item: 0.1312188357114792
test loss item: 0.06067706272006035
test loss item: 0.7126478552818298
test loss item: 0.6049109101295471
test loss item: 0.7854951620101929
test loss item: 0.17642749845981598
test loss item: 0.15066947042942047
test loss item: 0.05471862480044365
test loss item: 0.05319202318787575
test loss item: 0.12781110405921936
Epoch [49/100], Training Loss: 0.2980, Testing Loss: 0.2878
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 50/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2543582022190094
1
train loss item: 0.5545908212661743
2
train loss item: 0.10955299437046051
3
train loss item: 0.22640825808048248
4
train loss item: 0.19780661165714264
5
train loss item: 0.15869347751140594
6
train loss item: 0.12217338383197784
7
train loss item: 0.4268150329589844
8
train loss item: 0.07240710407495499
9
train loss item: 0.12513557076454163
10
train loss item: 0.15213543176651
11
train loss item: 0.16262520849704742
12
train loss item: 0.09578388929367065
13
train loss item: 0.2633261978626251
14
train loss item: 0.13158337771892548
15
train loss item: 0.30944252014160156
16
train loss item: 0.055180300027132034
17
train loss item: 0.12867695093154907
18
train loss item: 0.15859511494636536
19
train loss item: 0.13585174083709717
20
train loss item: 0.12653511762619019
21
train loss item: 0.08803465217351913
22
train loss item: 0.3479292690753937
23
train loss item: 0.4103226959705353
24
train loss item: 0.264344722032547
25
train loss item: 0.11999974399805069
26
train loss item: 0.10744741559028625
27
train loss item: 0.12436701357364655
28
train loss item: 0.05248703435063362
29
train loss item: 0.2820228636264801
30
train loss item: 1.4573827981948853
31
train loss item: 0.2521277368068695
32
train loss item: 0.07217410206794739
33
train loss item: 0.19798798859119415
34
train loss item: 0.10811935365200043
35
train loss item: 1.8502997159957886
36
train loss item: 0.2704867124557495
37
train loss item: 0.2629169225692749
38
train loss item: 0.20281100273132324
39
train loss item: 0.1364811360836029
40
train loss item: 0.10400406271219254
41
train loss item: 0.1243463084101677
42
train loss item: 0.2049705982208252
43
train loss item: 0.10042645037174225
44
train loss item: 0.43739306926727295
45
train loss item: 0.09603322297334671
46
train loss item: 0.08078629523515701
47
train loss item: 0.19648396968841553
48
train loss item: 0.11773742735385895
49
train loss item: 0.08982988446950912
50
train loss item: 0.1488250195980072
51
train loss item: 0.4249971807003021
52
train loss item: 0.0590892992913723
53
train loss item: 0.09117685258388519
54
train loss item: 1.7291574478149414
55
train loss item: 0.1149396225810051
56
train loss item: 0.12844356894493103
57
train loss item: 0.15036393702030182
58
train loss item: 0.09196402877569199
59
train loss item: 0.09631302207708359
60
train loss item: 0.33661434054374695
61
train loss item: 1.5573832988739014
62
train loss item: 0.11574150621891022
63
train loss item: 0.2013198882341385
64
train loss item: 0.0989859402179718
65
train loss item: 0.22643108665943146
66
train loss item: 0.20665216445922852
67
train loss item: 0.11997886747121811
68
train loss item: 0.15495005249977112
69
train loss item: 0.16760952770709991
70
train loss item: 0.14669586718082428
71
train loss item: 0.09441088885068893
72
train loss item: 0.0909019336104393
73
train loss item: 0.15560169517993927
74
train loss item: 0.06672410666942596
75
train loss item: 0.08330193161964417
76
train loss item: 0.40088149905204773
77
train loss item: 0.8530911803245544
78
train loss item: 0.057686448097229004
79
train loss item: 0.1580193191766739
80
train loss item: 0.0808577761054039
81
train loss item: 0.11639012396335602
82
train loss item: 0.11216536164283752
83
train loss item: 0.3111688494682312
84
train loss item: 0.2277008295059204
85
train loss item: 0.24363228678703308
86
train loss item: 3.497851610183716
87
train loss item: 0.10263408720493317
88
train loss item: 0.18008112907409668
epoch train loss: 0.284586124164
testing phase
test loss item: 0.14418043196201324
test loss item: 0.0832495242357254
test loss item: 0.4996222257614136
test loss item: 0.17048107087612152
test loss item: 0.19293420016765594
test loss item: 0.09750840812921524
test loss item: 1.4313709735870361
test loss item: 0.4973304867744446
test loss item: 0.1848689168691635
test loss item: 0.3018015921115875
test loss item: 0.709632933139801
test loss item: 0.12579840421676636
test loss item: 0.13787952065467834
test loss item: 0.2185819149017334
test loss item: 0.13518959283828735
test loss item: 0.06388838589191437
test loss item: 0.21100012958049774
test loss item: 0.3385659456253052
test loss item: 0.49904516339302063
test loss item: 0.207428976893425
test loss item: 0.5547248125076294
test loss item: 0.3078896403312683
test loss item: 0.29116612672805786
test loss item: 0.13635778427124023
test loss item: 0.1504412591457367
test loss item: 0.1693916767835617
test loss item: 0.23650728166103363
test loss item: 0.1345519870519638
test loss item: 0.24096882343292236
test loss item: 0.2506769001483917
test loss item: 0.6774555444717407
test loss item: 0.05743050575256348
test loss item: 0.11471690237522125
test loss item: 0.41889309883117676
test loss item: 0.3316023647785187
test loss item: 0.33756935596466064
test loss item: 0.6189147233963013
test loss item: 1.2234046459197998
test loss item: 0.3471178412437439
test loss item: 0.21296967566013336
test loss item: 0.2355564832687378
test loss item: 0.18264321982860565
test loss item: 0.25610432028770447
test loss item: 0.1680409163236618
test loss item: 0.425159215927124
test loss item: 0.3043653964996338
test loss item: 0.2669721245765686
test loss item: 0.1840992569923401
test loss item: 0.3853813111782074
test loss item: 0.5440201163291931
test loss item: 0.2394149750471115
test loss item: 0.10204225778579712
test loss item: 0.186364084482193
test loss item: 0.1235976442694664
test loss item: 0.2352684587240219
test loss item: 0.7060220837593079
test loss item: 0.4510469138622284
test loss item: 0.208262100815773
test loss item: 0.18433143198490143
test loss item: 0.1536969095468521
test loss item: 0.3304300010204315
test loss item: 0.2049921452999115
test loss item: 0.16811075806617737
test loss item: 0.17099694907665253
test loss item: 0.7368893027305603
test loss item: 0.23447564244270325
test loss item: 0.242780402302742
test loss item: 0.18706442415714264
test loss item: 0.41177210211753845
test loss item: 0.3374158442020416
test loss item: 0.05896207317709923
test loss item: 0.8105743527412415
test loss item: 0.26336804032325745
test loss item: 0.3148077130317688
test loss item: 0.11452954262495041
test loss item: 0.19048301875591278
test loss item: 0.13672581315040588
test loss item: 1.3112759590148926
test loss item: 0.3565398156642914
test loss item: 0.13730663061141968
test loss item: 0.06421488523483276
test loss item: 0.8228890895843506
test loss item: 0.6985432505607605
test loss item: 0.8995584845542908
test loss item: 0.187826007604599
test loss item: 0.15923835337162018
test loss item: 0.058328717947006226
test loss item: 0.054840900003910065
test loss item: 0.1452021300792694
Epoch [50/100], Training Loss: 0.2846, Testing Loss: 0.3193
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 51/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2574247419834137
1
train loss item: 0.5516186356544495
2
train loss item: 0.11372467875480652
3
train loss item: 0.24579691886901855
4
train loss item: 0.20350687205791473
5
train loss item: 0.15767426788806915
6
train loss item: 0.1192377582192421
7
train loss item: 0.439555287361145
8
train loss item: 0.07792923599481583
9
train loss item: 0.13494138419628143
10
train loss item: 0.16011810302734375
11
train loss item: 0.1589241325855255
12
train loss item: 0.09523797035217285
13
train loss item: 0.2649102509021759
14
train loss item: 0.1376587301492691
15
train loss item: 0.31437477469444275
16
train loss item: 0.055383723229169846
17
train loss item: 0.12401393055915833
18
train loss item: 0.16199809312820435
19
train loss item: 0.13926127552986145
20
train loss item: 0.12470480054616928
21
train loss item: 0.0841752141714096
22
train loss item: 0.34725436568260193
23
train loss item: 0.4181918203830719
24
train loss item: 0.264127641916275
25
train loss item: 0.1258290857076645
26
train loss item: 0.11101753264665604
27
train loss item: 0.13381725549697876
28
train loss item: 0.05256953835487366
29
train loss item: 0.301093190908432
30
train loss item: 1.467813491821289
31
train loss item: 0.24633429944515228
32
train loss item: 0.07475391030311584
33
train loss item: 0.225228413939476
34
train loss item: 0.10418490320444107
35
train loss item: 1.8471505641937256
36
train loss item: 0.25950706005096436
37
train loss item: 0.23989631235599518
38
train loss item: 0.22609935700893402
39
train loss item: 0.1390855759382248
40
train loss item: 0.10550893843173981
41
train loss item: 0.13856880366802216
42
train loss item: 0.20751629769802094
43
train loss item: 0.10725882649421692
44
train loss item: 0.4498963952064514
45
train loss item: 0.0996251106262207
46
train loss item: 0.08303102850914001
47
train loss item: 0.20200033485889435
48
train loss item: 0.1236618235707283
49
train loss item: 0.09400029480457306
50
train loss item: 0.1537676751613617
51
train loss item: 0.4388309717178345
52
train loss item: 0.05841877683997154
53
train loss item: 0.09794354438781738
54
train loss item: 1.7271559238433838
55
train loss item: 0.11877794563770294
56
train loss item: 0.135390505194664
57
train loss item: 0.14837335050106049
58
train loss item: 0.09295619279146194
59
train loss item: 0.09667263925075531
60
train loss item: 0.348747193813324
61
train loss item: 1.5586646795272827
62
train loss item: 0.11619636416435242
63
train loss item: 0.20368030667304993
64
train loss item: 0.10767380148172379
65
train loss item: 0.2136285901069641
66
train loss item: 0.2039341926574707
67
train loss item: 0.12107880413532257
68
train loss item: 0.1679171770811081
69
train loss item: 0.16396111249923706
70
train loss item: 0.14935536682605743
71
train loss item: 0.09293738752603531
72
train loss item: 0.10353734344244003
73
train loss item: 0.16478873789310455
74
train loss item: 0.0648605078458786
75
train loss item: 0.08548664301633835
76
train loss item: 0.4029187560081482
77
train loss item: 0.8693215250968933
78
train loss item: 0.057440850883722305
79
train loss item: 0.15745089948177338
80
train loss item: 0.08190442621707916
81
train loss item: 0.1207367554306984
82
train loss item: 0.12352504581212997
83
train loss item: 0.30629104375839233
84
train loss item: 0.20624414086341858
85
train loss item: 0.27239885926246643
86
train loss item: 3.492122173309326
87
train loss item: 0.11526814103126526
88
train loss item: 0.1717815399169922
epoch train loss: 0.2879700319569432
testing phase
test loss item: 0.1418927013874054
test loss item: 0.0782255157828331
test loss item: 0.3896690905094147
test loss item: 0.16373269259929657
test loss item: 0.16491569578647614
test loss item: 0.08954846858978271
test loss item: 1.2971382141113281
test loss item: 0.45781493186950684
test loss item: 0.1470886617898941
test loss item: 0.24039338529109955
test loss item: 0.5923153162002563
test loss item: 0.11706870794296265
test loss item: 0.12600481510162354
test loss item: 0.21183285117149353
test loss item: 0.11567236483097076
test loss item: 0.06401172280311584
test loss item: 0.19811806082725525
test loss item: 0.2576211094856262
test loss item: 0.46530431509017944
test loss item: 0.19399337470531464
test loss item: 0.4067160189151764
test loss item: 0.28728076815605164
test loss item: 0.2963947057723999
test loss item: 0.1281558871269226
test loss item: 0.1306796669960022
test loss item: 0.15703698992729187
test loss item: 0.20817428827285767
test loss item: 0.11963561177253723
test loss item: 0.21071287989616394
test loss item: 0.21056601405143738
test loss item: 0.5789443850517273
test loss item: 0.05671297013759613
test loss item: 0.10940542072057724
test loss item: 0.3347274363040924
test loss item: 0.2500464618206024
test loss item: 0.29548296332359314
test loss item: 0.564900279045105
test loss item: 0.9990442395210266
test loss item: 0.2773401737213135
test loss item: 0.19414126873016357
test loss item: 0.2204812914133072
test loss item: 0.21303260326385498
test loss item: 0.18762119114398956
test loss item: 0.15513558685779572
test loss item: 0.3153952658176422
test loss item: 0.2852642834186554
test loss item: 0.28213629126548767
test loss item: 0.1833030879497528
test loss item: 0.31403204798698425
test loss item: 0.45683786273002625
test loss item: 0.1748826652765274
test loss item: 0.09769780188798904
test loss item: 0.16201533377170563
test loss item: 0.11432673782110214
test loss item: 0.1809871941804886
test loss item: 0.5560073852539062
test loss item: 0.4043962359428406
test loss item: 0.16286012530326843
test loss item: 0.16381630301475525
test loss item: 0.13072800636291504
test loss item: 0.24676723778247833
test loss item: 0.1930685043334961
test loss item: 0.16017262637615204
test loss item: 0.15832851827144623
test loss item: 0.6003161668777466
test loss item: 0.22587382793426514
test loss item: 0.21780115365982056
test loss item: 0.17554005980491638
test loss item: 0.3514825105667114
test loss item: 0.3040090501308441
test loss item: 0.05844206362962723
test loss item: 0.7396905422210693
test loss item: 0.23648513853549957
test loss item: 0.2845124304294586
test loss item: 0.10976675897836685
test loss item: 0.23417744040489197
test loss item: 0.12811340391635895
test loss item: 1.0746246576309204
test loss item: 0.3167594373226166
test loss item: 0.13055214285850525
test loss item: 0.05940214544534683
test loss item: 0.7064738273620605
test loss item: 0.6135547161102295
test loss item: 0.7302178144454956
test loss item: 0.16755135357379913
test loss item: 0.15031756460666656
test loss item: 0.0543108806014061
test loss item: 0.053063564002513885
test loss item: 0.13070660829544067
Epoch [51/100], Training Loss: 0.2880, Testing Loss: 0.2775
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 52/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2496894747018814
1
train loss item: 0.5267484784126282
2
train loss item: 0.11130024492740631
3
train loss item: 0.22987648844718933
4
train loss item: 0.19811828434467316
5
train loss item: 0.15812914073467255
6
train loss item: 0.12472490221261978
7
train loss item: 0.403422474861145
8
train loss item: 0.06936758756637573
9
train loss item: 0.12289287894964218
10
train loss item: 0.15105833113193512
11
train loss item: 0.15915609896183014
12
train loss item: 0.09641464799642563
13
train loss item: 0.25615277886390686
14
train loss item: 0.1262226700782776
15
train loss item: 0.2981104850769043
16
train loss item: 0.05388364940881729
17
train loss item: 0.12588685750961304
18
train loss item: 0.15959537029266357
19
train loss item: 0.13471226394176483
20
train loss item: 0.12670542299747467
21
train loss item: 0.08987631648778915
22
train loss item: 0.323759526014328
23
train loss item: 0.3883622884750366
24
train loss item: 0.26112934947013855
25
train loss item: 0.11843860894441605
26
train loss item: 0.10717509686946869
27
train loss item: 0.11684850603342056
28
train loss item: 0.05134672671556473
29
train loss item: 0.26525163650512695
30
train loss item: 1.41648268699646
31
train loss item: 0.2604830861091614
32
train loss item: 0.0736440122127533
33
train loss item: 0.17713555693626404
34
train loss item: 0.10642104595899582
35
train loss item: 1.8286669254302979
36
train loss item: 0.26416873931884766
37
train loss item: 0.2525900900363922
38
train loss item: 0.2046118676662445
39
train loss item: 0.1374458372592926
40
train loss item: 0.10399477928876877
41
train loss item: 0.11770430952310562
42
train loss item: 0.2029818296432495
43
train loss item: 0.09829582273960114
44
train loss item: 0.41916900873184204
45
train loss item: 0.09200691431760788
46
train loss item: 0.08185411989688873
47
train loss item: 0.18938522040843964
48
train loss item: 0.11149200797080994
49
train loss item: 0.0892641544342041
50
train loss item: 0.14891314506530762
51
train loss item: 0.4019227623939514
52
train loss item: 0.0579451359808445
53
train loss item: 0.0891025960445404
54
train loss item: 1.7048280239105225
55
train loss item: 0.11153525859117508
56
train loss item: 0.12727776169776917
57
train loss item: 0.15226157009601593
58
train loss item: 0.09414874762296677
59
train loss item: 0.09575798362493515
60
train loss item: 0.3130500912666321
61
train loss item: 1.5246891975402832
62
train loss item: 0.11463751643896103
63
train loss item: 0.1947888433933258
64
train loss item: 0.09433922916650772
65
train loss item: 0.21795132756233215
66
train loss item: 0.20488950610160828
67
train loss item: 0.12272755056619644
68
train loss item: 0.14885000884532928
69
train loss item: 0.16694067418575287
70
train loss item: 0.14125487208366394
71
train loss item: 0.09260370582342148
72
train loss item: 0.08399463444948196
73
train loss item: 0.15083344280719757
74
train loss item: 0.06754247844219208
75
train loss item: 0.08083467930555344
76
train loss item: 0.38093429803848267
77
train loss item: 0.8287441730499268
78
train loss item: 0.05784498155117035
79
train loss item: 0.15239933133125305
80
train loss item: 0.08107918500900269
81
train loss item: 0.1141405925154686
82
train loss item: 0.10211996734142303
83
train loss item: 0.3075300455093384
84
train loss item: 0.21421562135219574
85
train loss item: 0.22733758389949799
86
train loss item: 3.4671528339385986
87
train loss item: 0.09458405524492264
88
train loss item: 0.17931443452835083
epoch train loss: 0.2780131735744771
testing phase
test loss item: 0.13862861692905426
test loss item: 0.08123745769262314
test loss item: 0.3610548973083496
test loss item: 0.16006731986999512
test loss item: 0.16078777611255646
test loss item: 0.08938682824373245
test loss item: 1.1606135368347168
test loss item: 0.41102203726768494
test loss item: 0.13925480842590332
test loss item: 0.2268071472644806
test loss item: 0.5479132533073425
test loss item: 0.11446884274482727
test loss item: 0.12264429032802582
test loss item: 0.20380502939224243
test loss item: 0.11461831629276276
test loss item: 0.06663263589143753
test loss item: 0.18635132908821106
test loss item: 0.2420225441455841
test loss item: 0.42984795570373535
test loss item: 0.18080691993236542
test loss item: 0.37941181659698486
test loss item: 0.2688639461994171
test loss item: 0.2387775480747223
test loss item: 0.12297851592302322
test loss item: 0.12457013875246048
test loss item: 0.15090042352676392
test loss item: 0.19567790627479553
test loss item: 0.1173747256398201
test loss item: 0.20015349984169006
test loss item: 0.20005342364311218
test loss item: 0.5261266231536865
test loss item: 0.05847948417067528
test loss item: 0.10731101781129837
test loss item: 0.3145134150981903
test loss item: 0.23300740122795105
test loss item: 0.2803725600242615
test loss item: 0.5183221697807312
test loss item: 0.9199826717376709
test loss item: 0.2585965692996979
test loss item: 0.17978931963443756
test loss item: 0.20642167329788208
test loss item: 0.16796834766864777
test loss item: 0.17632929980754852
test loss item: 0.1466745287179947
test loss item: 0.2953692078590393
test loss item: 0.2661248743534088
test loss item: 0.22544945776462555
test loss item: 0.17611467838287354
test loss item: 0.2944391965866089
test loss item: 0.4199751615524292
test loss item: 0.16620495915412903
test loss item: 0.09557131677865982
test loss item: 0.15468190610408783
test loss item: 0.11312285810709
test loss item: 0.17164810001850128
test loss item: 0.5130850076675415
test loss item: 0.37510162591934204
test loss item: 0.15860965847969055
test loss item: 0.15784414112567902
test loss item: 0.128244087100029
test loss item: 0.2332189381122589
test loss item: 0.18166787922382355
test loss item: 0.15364161133766174
test loss item: 0.14992007613182068
test loss item: 0.5481846332550049
test loss item: 0.22070863842964172
test loss item: 0.20436494052410126
test loss item: 0.1656399965286255
test loss item: 0.33438339829444885
test loss item: 0.27735042572021484
test loss item: 0.061446983367204666
test loss item: 0.6604968905448914
test loss item: 0.22576157748699188
test loss item: 0.25782617926597595
test loss item: 0.10763365775346756
test loss item: 0.17498981952667236
test loss item: 0.12207092344760895
test loss item: 0.9905900359153748
test loss item: 0.2970847189426422
test loss item: 0.12733112275600433
test loss item: 0.05905378609895706
test loss item: 0.6400576829910278
test loss item: 0.5593348741531372
test loss item: 0.6697720885276794
test loss item: 0.15734156966209412
test loss item: 0.14604203402996063
test loss item: 0.053490109741687775
test loss item: 0.052218299359083176
test loss item: 0.12782113254070282
Epoch [52/100], Training Loss: 0.2780, Testing Loss: 0.2573
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6894.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6894.00 MB
Epoch 53/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.24908538162708282
1
train loss item: 0.5216876864433289
2
train loss item: 0.11239500343799591
3
train loss item: 0.24127566814422607
4
train loss item: 0.204337939620018
5
train loss item: 0.1609330028295517
6
train loss item: 0.12333227694034576
7
train loss item: 0.38880980014801025
8
train loss item: 0.06894605606794357
9
train loss item: 0.12505677342414856
10
train loss item: 0.15499311685562134
11
train loss item: 0.15971513092517853
12
train loss item: 0.09617893397808075
13
train loss item: 0.2566680312156677
14
train loss item: 0.12511666119098663
15
train loss item: 0.3054586946964264
16
train loss item: 0.0531892403960228
17
train loss item: 0.13056547939777374
18
train loss item: 0.16423656046390533
19
train loss item: 0.13279610872268677
20
train loss item: 0.12600277364253998
21
train loss item: 0.09099042415618896
22
train loss item: 0.31816378235816956
23
train loss item: 0.38118797540664673
24
train loss item: 0.26536646485328674
25
train loss item: 0.11985165625810623
26
train loss item: 0.11061479896306992
27
train loss item: 0.11622489243745804
28
train loss item: 0.05094834789633751
29
train loss item: 0.2639126777648926
30
train loss item: 1.393825650215149
31
train loss item: 0.2749263048171997
32
train loss item: 0.07517408579587936
33
train loss item: 0.17391987144947052
34
train loss item: 0.10965916514396667
35
train loss item: 1.8173928260803223
36
train loss item: 0.2681959271430969
37
train loss item: 0.25763124227523804
38
train loss item: 0.21240222454071045
39
train loss item: 0.14108796417713165
40
train loss item: 0.1022433340549469
41
train loss item: 0.1166430190205574
42
train loss item: 0.20331768691539764
43
train loss item: 0.09897243231534958
44
train loss item: 0.4108453392982483
45
train loss item: 0.09093652665615082
46
train loss item: 0.08204527944326401
47
train loss item: 0.19003555178642273
48
train loss item: 0.1096424013376236
49
train loss item: 0.09080923348665237
50
train loss item: 0.14275677502155304
51
train loss item: 0.39227384328842163
52
train loss item: 0.0577753484249115
53
train loss item: 0.09070150554180145
54
train loss item: 1.6917939186096191
55
train loss item: 0.1094033420085907
56
train loss item: 0.13025246560573578
57
train loss item: 0.15164344012737274
58
train loss item: 0.09523787349462509
59
train loss item: 0.09641218930482864
60
train loss item: 0.3071451485157013
61
train loss item: 1.5098717212677002
62
train loss item: 0.11527061462402344
63
train loss item: 0.19224761426448822
64
train loss item: 0.09553058445453644
65
train loss item: 0.2265377938747406
66
train loss item: 0.21231892704963684
67
train loss item: 0.12363941967487335
68
train loss item: 0.14402276277542114
69
train loss item: 0.17470167577266693
70
train loss item: 0.1418716162443161
71
train loss item: 0.08960627019405365
72
train loss item: 0.08444971591234207
73
train loss item: 0.14752034842967987
74
train loss item: 0.06755828112363815
75
train loss item: 0.08076401054859161
76
train loss item: 0.37469953298568726
77
train loss item: 0.8113948106765747
78
train loss item: 0.056950341910123825
79
train loss item: 0.15268118679523468
80
train loss item: 0.08272404223680496
81
train loss item: 0.11242306977510452
82
train loss item: 0.10056335479021072
83
train loss item: 0.3108038306236267
84
train loss item: 0.2187916785478592
85
train loss item: 0.2329760640859604
86
train loss item: 3.4522645473480225
87
train loss item: 0.09257913380861282
88
train loss item: 0.18645869195461273
epoch train loss: 0.27746477413378406
testing phase
test loss item: 0.13874414563179016
test loss item: 0.0867534652352333
test loss item: 0.46066397428512573
test loss item: 0.16539013385772705
test loss item: 0.18623384833335876
test loss item: 0.09700054675340652
test loss item: 1.372098684310913
test loss item: 0.47821375727653503
test loss item: 0.17233461141586304
test loss item: 0.2815776467323303
test loss item: 0.6576237082481384
test loss item: 0.1220352053642273
test loss item: 0.13455498218536377
test loss item: 0.20905336737632751
test loss item: 0.13218653202056885
test loss item: 0.06750159710645676
test loss item: 0.20138521492481232
test loss item: 0.3138708472251892
test loss item: 0.47757428884506226
test loss item: 0.19657064974308014
test loss item: 0.5124328136444092
test loss item: 0.29508885741233826
test loss item: 0.2487209588289261
test loss item: 0.13211055099964142
test loss item: 0.14140789210796356
test loss item: 0.16421444714069366
test loss item: 0.22156395018100739
test loss item: 0.13209466636180878
test loss item: 0.22881095111370087
test loss item: 0.2371310442686081
test loss item: 0.6372969746589661
test loss item: 0.059442188590765
test loss item: 0.11267445236444473
test loss item: 0.3899204432964325
test loss item: 0.3062795400619507
test loss item: 0.3173923194408417
test loss item: 0.5927638411521912
test loss item: 1.1275447607040405
test loss item: 0.32398802042007446
test loss item: 0.19975732266902924
test loss item: 0.22427698969841003
test loss item: 0.1461178958415985
test loss item: 0.23736035823822021
test loss item: 0.16063329577445984
test loss item: 0.3939807116985321
test loss item: 0.2901062071323395
test loss item: 0.2236587554216385
test loss item: 0.17703764140605927
test loss item: 0.3610256612300873
test loss item: 0.5023821592330933
test loss item: 0.22543761134147644
test loss item: 0.10092852264642715
test loss item: 0.177730530500412
test loss item: 0.11996883898973465
test loss item: 0.22072173655033112
test loss item: 0.6468181014060974
test loss item: 0.4247812330722809
test loss item: 0.19720415771007538
test loss item: 0.1784537136554718
test loss item: 0.1482716202735901
test loss item: 0.3083781898021698
test loss item: 0.1986994445323944
test loss item: 0.16407270729541779
test loss item: 0.16250185668468475
test loss item: 0.683984100818634
test loss item: 0.22681692242622375
test loss item: 0.23142921924591064
test loss item: 0.178540900349617
test loss item: 0.3873749077320099
test loss item: 0.31368282437324524
test loss item: 0.06257186084985733
test loss item: 0.7725712060928345
test loss item: 0.2486676424741745
test loss item: 0.2932590842247009
test loss item: 0.11195878684520721
test loss item: 0.14354901015758514
test loss item: 0.1319149136543274
test loss item: 1.2178322076797485
test loss item: 0.33336445689201355
test loss item: 0.13404393196105957
test loss item: 0.06251255422830582
test loss item: 0.7687516808509827
test loss item: 0.6620905995368958
test loss item: 0.8333402872085571
test loss item: 0.1795521080493927
test loss item: 0.15453369915485382
test loss item: 0.05493541806936264
test loss item: 0.05246502533555031
test loss item: 0.13708674907684326
Epoch [53/100], Training Loss: 0.2775, Testing Loss: 0.3000
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 54/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.24790191650390625
1
train loss item: 0.511861264705658
2
train loss item: 0.10579019039869308
3
train loss item: 0.22610116004943848
4
train loss item: 0.1893731653690338
5
train loss item: 0.15327733755111694
6
train loss item: 0.11387644708156586
7
train loss item: 0.40752875804901123
8
train loss item: 0.07124465703964233
9
train loss item: 0.12286819517612457
10
train loss item: 0.14624439179897308
11
train loss item: 0.14740188419818878
12
train loss item: 0.09324958175420761
13
train loss item: 0.24765028059482574
14
train loss item: 0.12843561172485352
15
train loss item: 0.297238290309906
16
train loss item: 0.05229515582323074
17
train loss item: 0.1184702143073082
18
train loss item: 0.15222081542015076
19
train loss item: 0.12994423508644104
20
train loss item: 0.11741465330123901
21
train loss item: 0.08060885220766068
22
train loss item: 0.3145817518234253
23
train loss item: 0.383422315120697
24
train loss item: 0.2551197111606598
25
train loss item: 0.11522393673658371
26
train loss item: 0.1086449846625328
27
train loss item: 0.12337033450603485
28
train loss item: 0.049722108989953995
29
train loss item: 0.2732568085193634
30
train loss item: 1.4054046869277954
31
train loss item: 0.22748346626758575
32
train loss item: 0.07220771163702011
33
train loss item: 0.19892512261867523
34
train loss item: 0.10471451282501221
35
train loss item: 1.8155933618545532
36
train loss item: 0.24021463096141815
37
train loss item: 0.22784067690372467
38
train loss item: 0.20875895023345947
39
train loss item: 0.1329742968082428
40
train loss item: 0.09922058135271072
41
train loss item: 0.12595881521701813
42
train loss item: 0.2020362913608551
43
train loss item: 0.10029980540275574
44
train loss item: 0.427735835313797
45
train loss item: 0.09427591413259506
46
train loss item: 0.08136600255966187
47
train loss item: 0.19082869589328766
48
train loss item: 0.11492092162370682
49
train loss item: 0.08847866207361221
50
train loss item: 0.14325563609600067
51
train loss item: 0.40667036175727844
52
train loss item: 0.05656781420111656
53
train loss item: 0.08993925154209137
54
train loss item: 1.6907628774642944
55
train loss item: 0.11013873666524887
56
train loss item: 0.1277947872877121
57
train loss item: 0.1393996775150299
58
train loss item: 0.0885014459490776
59
train loss item: 0.09525061398744583
60
train loss item: 0.3270886540412903
61
train loss item: 1.5172653198242188
62
train loss item: 0.10893808305263519
63
train loss item: 0.19601169228553772
64
train loss item: 0.0999893918633461
65
train loss item: 0.2051910012960434
66
train loss item: 0.1881878674030304
67
train loss item: 0.11766576766967773
68
train loss item: 0.15351177752017975
69
train loss item: 0.1566314697265625
70
train loss item: 0.14129102230072021
71
train loss item: 0.08575605601072311
72
train loss item: 0.09280078113079071
73
train loss item: 0.15246811509132385
74
train loss item: 0.06315606087446213
75
train loss item: 0.0816769152879715
76
train loss item: 0.36503055691719055
77
train loss item: 0.8383849263191223
78
train loss item: 0.054366372525691986
79
train loss item: 0.14778876304626465
80
train loss item: 0.08282987773418427
81
train loss item: 0.11085239797830582
82
train loss item: 0.11421064287424088
83
train loss item: 0.2917059659957886
84
train loss item: 0.18441098928451538
85
train loss item: 0.2268107682466507
86
train loss item: 3.4486680030822754
87
train loss item: 0.10438530147075653
88
train loss item: 0.16596773266792297
epoch train loss: 0.2743247351452206
testing phase
test loss item: 0.13849684596061707
test loss item: 0.08227907866239548
test loss item: 0.4336831867694855
test loss item: 0.16267138719558716
test loss item: 0.17629748582839966
test loss item: 0.08976902067661285
test loss item: 1.3462423086166382
test loss item: 0.45539402961730957
test loss item: 0.16030558943748474
test loss item: 0.2611028254032135
test loss item: 0.6389552354812622
test loss item: 0.11967141181230545
test loss item: 0.1285713165998459
test loss item: 0.2087782770395279
test loss item: 0.12391450256109238
test loss item: 0.06628613919019699
test loss item: 0.1973213404417038
test loss item: 0.2887197732925415
test loss item: 0.46276894211769104
test loss item: 0.19329731166362762
test loss item: 0.4685423970222473
test loss item: 0.28830280900001526
test loss item: 0.23575228452682495
test loss item: 0.12944982945919037
test loss item: 0.13544203341007233
test loss item: 0.16027958691120148
test loss item: 0.21336740255355835
test loss item: 0.1251663863658905
test loss item: 0.21926036477088928
test loss item: 0.2228364199399948
test loss item: 0.6204690933227539
test loss item: 0.05842917785048485
test loss item: 0.11018076539039612
test loss item: 0.3674057722091675
test loss item: 0.2829127013683319
test loss item: 0.29916560649871826
test loss item: 0.5738039612770081
test loss item: 1.0920803546905518
test loss item: 0.30466026067733765
test loss item: 0.19414418935775757
test loss item: 0.22163960337638855
test loss item: 0.13975271582603455
test loss item: 0.21534956991672516
test loss item: 0.15696150064468384
test loss item: 0.3600761294364929
test loss item: 0.2838249206542969
test loss item: 0.2070196568965912
test loss item: 0.17750519514083862
test loss item: 0.3404245376586914
test loss item: 0.4821462333202362
test loss item: 0.20069390535354614
test loss item: 0.09652712196111679
test loss item: 0.1693071871995926
test loss item: 0.11579973250627518
test loss item: 0.20264311134815216
test loss item: 0.6129823923110962
test loss item: 0.4095490574836731
test loss item: 0.17648781836032867
test loss item: 0.17026586830615997
test loss item: 0.1381646990776062
test loss item: 0.2814028859138489
test loss item: 0.1931915283203125
test loss item: 0.16126832365989685
test loss item: 0.15957319736480713
test loss item: 0.6543011665344238
test loss item: 0.22373099625110626
test loss item: 0.22447258234024048
test loss item: 0.17619121074676514
test loss item: 0.3742343783378601
test loss item: 0.297406941652298
test loss item: 0.059886764734983444
test loss item: 0.7525693774223328
test loss item: 0.24136187136173248
test loss item: 0.2882479131221771
test loss item: 0.10892404615879059
test loss item: 0.13449357450008392
test loss item: 0.12952226400375366
test loss item: 1.1866074800491333
test loss item: 0.3288487195968628
test loss item: 0.1299654245376587
test loss item: 0.060731638222932816
test loss item: 0.7473883628845215
test loss item: 0.6372860670089722
test loss item: 0.8069269061088562
test loss item: 0.17656609416007996
test loss item: 0.15156754851341248
test loss item: 0.05330557003617287
test loss item: 0.051959674805402756
test loss item: 0.1335878223180771
Epoch [54/100], Training Loss: 0.2743, Testing Loss: 0.2881
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 55/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.24154113233089447
1
train loss item: 0.4885619282722473
2
train loss item: 0.10236810892820358
3
train loss item: 0.20965854823589325
4
train loss item: 0.18400752544403076
5
train loss item: 0.1509345918893814
6
train loss item: 0.115235835313797
7
train loss item: 0.3896683156490326
8
train loss item: 0.06746116280555725
9
train loss item: 0.11966361850500107
10
train loss item: 0.1411059945821762
11
train loss item: 0.14710171520709991
12
train loss item: 0.09353646636009216
13
train loss item: 0.23990322649478912
14
train loss item: 0.13421879708766937
15
train loss item: 0.2753596603870392
16
train loss item: 0.05201921612024307
17
train loss item: 0.11866556853055954
18
train loss item: 0.14992225170135498
19
train loss item: 0.1268315613269806
20
train loss item: 0.11715925484895706
21
train loss item: 0.08089377731084824
22
train loss item: 0.29835331439971924
23
train loss item: 0.36338770389556885
24
train loss item: 0.24712780117988586
25
train loss item: 0.11153826862573624
26
train loss item: 0.10348671674728394
27
train loss item: 0.11528869718313217
28
train loss item: 0.049209222197532654
29
train loss item: 0.24794095754623413
30
train loss item: 1.3784452676773071
31
train loss item: 0.22649966180324554
32
train loss item: 0.06990296393632889
33
train loss item: 0.1778363585472107
34
train loss item: 0.104643315076828
35
train loss item: 1.8046456575393677
36
train loss item: 0.2427392303943634
37
train loss item: 0.2297300398349762
38
train loss item: 0.19523341953754425
39
train loss item: 0.13097108900547028
40
train loss item: 0.09711379557847977
41
train loss item: 0.11760462075471878
42
train loss item: 0.20044773817062378
43
train loss item: 0.09601034224033356
44
train loss item: 0.4151133596897125
45
train loss item: 0.08952556550502777
46
train loss item: 0.07693435996770859
47
train loss item: 0.18026238679885864
48
train loss item: 0.1100592166185379
49
train loss item: 0.08540231734514236
50
train loss item: 0.13776487112045288
51
train loss item: 0.3893105387687683
52
train loss item: 0.05577092990279198
53
train loss item: 0.08494538813829422
54
train loss item: 1.6783759593963623
55
train loss item: 0.10709530115127563
56
train loss item: 0.1247330978512764
57
train loss item: 0.14070932567119598
58
train loss item: 0.087909035384655
59
train loss item: 0.09337516129016876
60
train loss item: 0.30368414521217346
61
train loss item: 1.4947543144226074
62
train loss item: 0.10806669294834137
63
train loss item: 0.19023269414901733
64
train loss item: 0.09358655661344528
65
train loss item: 0.20253954827785492
66
train loss item: 0.18574349582195282
67
train loss item: 0.11590763181447983
68
train loss item: 0.1468811184167862
69
train loss item: 0.15514571964740753
70
train loss item: 0.13582728803157806
71
train loss item: 0.08588957041501999
72
train loss item: 0.08446813374757767
73
train loss item: 0.14815469086170197
74
train loss item: 0.06374882906675339
75
train loss item: 0.07958614081144333
76
train loss item: 0.34787532687187195
77
train loss item: 0.8135145306587219
78
train loss item: 0.054760705679655075
79
train loss item: 0.14426444470882416
80
train loss item: 0.079749196767807
81
train loss item: 0.10837997496128082
82
train loss item: 0.10496771335601807
83
train loss item: 0.28939419984817505
84
train loss item: 0.18128237128257751
85
train loss item: 0.21101538836956024
86
train loss item: 3.4319746494293213
87
train loss item: 0.09595943987369537
88
train loss item: 0.1636401116847992
epoch train loss: 0.2677781559275777
testing phase
test loss item: 0.13891026377677917
test loss item: 0.0786280632019043
test loss item: 0.35037222504615784
test loss item: 0.1577211320400238
test loss item: 0.16152115166187286
test loss item: 0.09692046046257019
test loss item: 1.1377148628234863
test loss item: 0.37716495990753174
test loss item: 0.13478238880634308
test loss item: 0.21602465212345123
test loss item: 0.5423715710639954
test loss item: 0.1151849776506424
test loss item: 0.12069720029830933
test loss item: 0.21688397228717804
test loss item: 0.10968253761529922
test loss item: 0.06604836136102676
test loss item: 0.18544794619083405
test loss item: 0.22952498495578766
test loss item: 0.40707018971443176
test loss item: 0.1854630559682846
test loss item: 0.35705024003982544
test loss item: 0.2637242376804352
test loss item: 0.29549896717071533
test loss item: 0.1232641190290451
test loss item: 0.1212649792432785
test loss item: 0.1513500064611435
test loss item: 0.1951526701450348
test loss item: 0.12661431729793549
test loss item: 0.19560441374778748
test loss item: 0.1936022788286209
test loss item: 0.522972822189331
test loss item: 0.05836233124136925
test loss item: 0.10714524239301682
test loss item: 0.30329832434654236
test loss item: 0.22223947942256927
test loss item: 0.26547980308532715
test loss item: 0.494461327791214
test loss item: 0.9108155965805054
test loss item: 0.25003692507743835
test loss item: 0.18199139833450317
test loss item: 0.2053356170654297
test loss item: 0.21231387555599213
test loss item: 0.1664043366909027
test loss item: 0.1462274044752121
test loss item: 0.28091925382614136
test loss item: 0.2642657458782196
test loss item: 0.27922216057777405
test loss item: 0.18559986352920532
test loss item: 0.2838999330997467
test loss item: 0.4087890684604645
test loss item: 0.15456022322177887
test loss item: 0.09615671634674072
test loss item: 0.1513596922159195
test loss item: 0.11162440478801727
test loss item: 0.16351103782653809
test loss item: 0.4977116584777832
test loss item: 0.35670241713523865
test loss item: 0.15864776074886322
test loss item: 0.15586668252944946
test loss item: 0.1220981627702713
test loss item: 0.21985448896884918
test loss item: 0.17866668105125427
test loss item: 0.155278742313385
test loss item: 0.1498422771692276
test loss item: 0.5372182130813599
test loss item: 0.21691885590553284
test loss item: 0.20584167540073395
test loss item: 0.16417288780212402
test loss item: 0.3264414668083191
test loss item: 0.25578776001930237
test loss item: 0.05949584022164345
test loss item: 0.6371772885322571
test loss item: 0.23016007244586945
test loss item: 0.2626667320728302
test loss item: 0.10790617763996124
test loss item: 0.23753440380096436
test loss item: 0.12224940210580826
test loss item: 0.9924620985984802
test loss item: 0.30789634585380554
test loss item: 0.13666152954101562
test loss item: 0.06048029661178589
test loss item: 0.6278984546661377
test loss item: 0.5374115109443665
test loss item: 0.6678545475006104
test loss item: 0.16580143570899963
test loss item: 0.14680251479148865
test loss item: 0.05361555889248848
test loss item: 0.05215424671769142
test loss item: 0.12931428849697113
Epoch [55/100], Training Loss: 0.2678, Testing Loss: 0.2552
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.2155826836824417
loss item: 0.13883167505264282
loss item: 1.03340744972229
loss item: 0.527374804019928
loss item: 0.40480098128318787
loss item: 0.2644747793674469
loss item: 0.14449343085289001
loss item: 0.5123839974403381
loss item: 0.14860501885414124
loss item: 0.13599567115306854
loss item: 0.6209056377410889
loss item: 0.04451651871204376
loss item: 0.5667930841445923
loss item: 0.14419661462306976
loss item: 0.3006727695465088
loss item: 0.31163927912712097
loss item: 0.2278415858745575
loss item: 0.3651338815689087
loss item: 0.5449146032333374
loss item: 0.30351758003234863
loss item: 0.20303437113761902
loss item: 0.18049147725105286
loss item: 0.20827634632587433
loss item: 0.1709253489971161
loss item: 0.1733749955892563
loss item: 0.43429556488990784
loss item: 0.6937177777290344
loss item: 0.12198308855295181
loss item: 0.09070197492837906
loss item: 0.3436603844165802
loss item: 0.6844958066940308
loss item: 0.9704049229621887
loss item: 0.10260004550218582
loss item: 0.3520607352256775
loss item: 0.11944509297609329
loss item: 0.22695879638195038
loss item: 0.22097371518611908
loss item: 0.16009721159934998
loss item: 0.26859283447265625
loss item: 0.4519103765487671
loss item: 0.627554178237915
loss item: 0.34152835607528687
loss item: 0.13985180854797363
loss item: 0.05369539186358452
Val Loss: 0.3249
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 100 0.0005 2 360 done at Wed Nov 13 21:10:30 CET 2024
UNet6 with 1 100 0.001 2 360 start at Wed Nov 13 21:10:30 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 100, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: 11785081.0
test loss item: 18044648.0
test loss item: 7167461.0
test loss item: 29383746.0
test loss item: 15124092.0
test loss item: 11692700.0
test loss item: 39257308.0
test loss item: 21983670.0
test loss item: 10956118.0
test loss item: 11253177.0
test loss item: 30624698.0
test loss item: 29517882.0
test loss item: 14048648.0
test loss item: 1793891.75
test loss item: 16510353.0
test loss item: 18418314.0
test loss item: 6508121.5
test loss item: 13564400.0
test loss item: 23912850.0
test loss item: 6264794.0
test loss item: 5424060.0
test loss item: 27085740.0
test loss item: 20075276.0
test loss item: 17504854.0
test loss item: 11419959.0
test loss item: 10714604.0
test loss item: 12563931.0
test loss item: 15127241.0
test loss item: 17282536.0
test loss item: 14532781.0
test loss item: 23636338.0
test loss item: 19461510.0
test loss item: 17369196.0
test loss item: 28206086.0
test loss item: 15426254.0
test loss item: 75933592.0
test loss item: 24528266.0
test loss item: 42413388.0
test loss item: 26005210.0
test loss item: 15361826.0
test loss item: 14713672.0
test loss item: 21589830.0
test loss item: 4337666.0
test loss item: 27008148.0
test loss item: 5460098.0
test loss item: 13491585.0
test loss item: 19726744.0
test loss item: 7888513.5
test loss item: 7950283.0
test loss item: 21157566.0
test loss item: 12844620.0
test loss item: 13379003.0
test loss item: 9847971.0
test loss item: 40478308.0
test loss item: 9069851.0
test loss item: 18914676.0
test loss item: 51207676.0
test loss item: 790203.5
test loss item: 12065969.0
test loss item: 11776603.0
test loss item: 13123707.0
test loss item: 11832058.0
test loss item: 8010527.5
test loss item: 14818182.0
test loss item: 23189776.0
test loss item: 42727972.0
test loss item: 12784839.0
test loss item: 11372064.0
test loss item: 13868499.0
test loss item: 24966456.0
test loss item: 13975702.0
test loss item: 22125188.0
test loss item: 3733051.75
test loss item: 11549237.0
test loss item: 5526398.0
test loss item: 19573080.0
test loss item: 16077742.0
test loss item: 43605664.0
test loss item: 1412052.75
test loss item: 10582447.0
test loss item: 7402180.0
test loss item: 42150504.0
test loss item: 25959800.0
test loss item: 43047772.0
test loss item: 9130282.0
test loss item: 7604744.0
test loss item: 13163716.0
test loss item: 17791828.0
test loss item: 10392790.0
Epoch [1/100], Training Loss: 1.0161, Testing Loss: 18012155.5758
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.1627389192581177
1
train loss item: 2.1412336826324463
2
train loss item: 1.223680019378662
3
train loss item: 1.2127991914749146
4
train loss item: 3.0910515785217285
5
train loss item: 1.0142309665679932
6
train loss item: 1.4223579168319702
7
train loss item: 1.2893645763397217
8
train loss item: 1.440064787864685
9
train loss item: 0.8364047408103943
10
train loss item: 0.8886779546737671
11
train loss item: 0.7996166944503784
12
train loss item: 0.982550323009491
13
train loss item: 1.2329033613204956
14
train loss item: 0.9984112977981567
15
train loss item: 1.5051113367080688
16
train loss item: 1.2095601558685303
17
train loss item: 1.4161232709884644
18
train loss item: 1.012138843536377
19
train loss item: 0.9051920175552368
20
train loss item: 1.0893741846084595
21
train loss item: 1.0338590145111084
22
train loss item: 2.1671197414398193
23
train loss item: 1.3989713191986084
24
train loss item: 1.2572822570800781
25
train loss item: 1.0565353631973267
26
train loss item: 1.1701897382736206
27
train loss item: 0.8683547973632812
28
train loss item: 1.2076148986816406
29
train loss item: 1.7722322940826416
30
train loss item: 2.745358943939209
31
train loss item: 1.216265082359314
32
train loss item: 0.9440435171127319
33
train loss item: 1.1446332931518555
34
train loss item: 1.909136176109314
35
train loss item: 2.8699867725372314
36
train loss item: 1.219748854637146
37
train loss item: 0.8850826025009155
38
train loss item: 1.3808495998382568
39
train loss item: 0.911266565322876
40
train loss item: 1.1082417964935303
41
train loss item: 0.814866304397583
42
train loss item: 0.8350582718849182
43
train loss item: 0.9496601819992065
44
train loss item: 1.1882284879684448
45
train loss item: 1.1230639219284058
46
train loss item: 0.990526556968689
47
train loss item: 1.0901484489440918
48
train loss item: 0.9159326553344727
49
train loss item: 0.9682211875915527
50
train loss item: 0.9414951801300049
51
train loss item: 1.7621641159057617
52
train loss item: 1.1775217056274414
53
train loss item: 1.186757206916809
54
train loss item: 2.708171844482422
55
train loss item: 1.1227338314056396
56
train loss item: 0.8477191925048828
57
train loss item: 0.9238559007644653
58
train loss item: 0.9379908442497253
59
train loss item: 0.9621532559394836
60
train loss item: 1.9530788660049438
61
train loss item: 2.6338388919830322
62
train loss item: 0.9953965544700623
63
train loss item: 0.9847005605697632
64
train loss item: 0.9228894114494324
65
train loss item: 1.5504430532455444
66
train loss item: 0.9608433842658997
67
train loss item: 0.9519791007041931
68
train loss item: 1.1556516885757446
69
train loss item: 0.9736729264259338
70
train loss item: 1.0080184936523438
71
train loss item: 1.4687238931655884
72
train loss item: 1.419049620628357
73
train loss item: 0.9922592639923096
74
train loss item: 1.5344414710998535
75
train loss item: 0.9670674800872803
76
train loss item: 1.4292179346084595
77
train loss item: 2.2641994953155518
78
train loss item: 1.1958861351013184
79
train loss item: 0.8626599311828613
80
train loss item: 1.423616886138916
81
train loss item: 0.9546928405761719
82
train loss item: 0.9756700992584229
83
train loss item: 1.4691296815872192
84
train loss item: 1.007530927658081
85
train loss item: 1.1756672859191895
86
train loss item: 4.784779071807861
87
train loss item: 1.3828245401382446
88
train loss item: 0.9960072040557861
epoch train loss: 1.3143883622094485
testing phase
test loss item: 153.61972045898438
test loss item: 308.9806213378906
test loss item: 183.40676879882812
test loss item: 798.7156982421875
test loss item: 291.8871765136719
test loss item: 292.6216125488281
test loss item: 514.3078002929688
test loss item: 257.57354736328125
test loss item: 94.98118591308594
test loss item: 176.06163024902344
test loss item: 836.6275024414062
test loss item: 727.2073974609375
test loss item: 211.66830444335938
test loss item: 25.58147430419922
test loss item: 304.7413330078125
test loss item: 342.85205078125
test loss item: 102.54563903808594
test loss item: 221.5685577392578
test loss item: 326.33734130859375
test loss item: 61.57472610473633
test loss item: 197.2107391357422
test loss item: 768.4361572265625
test loss item: 412.4140319824219
test loss item: 277.70550537109375
test loss item: 242.00021362304688
test loss item: 215.24026489257812
test loss item: 124.50702667236328
test loss item: 281.31512451171875
test loss item: 278.3996887207031
test loss item: 232.18565368652344
test loss item: 913.3241577148438
test loss item: 322.2038879394531
test loss item: 285.8175354003906
test loss item: 885.0394287109375
test loss item: 284.91851806640625
test loss item: 3124.969482421875
test loss item: 242.1707000732422
test loss item: 1505.26123046875
test loss item: 653.8809204101562
test loss item: 278.1027526855469
test loss item: 238.0672149658203
test loss item: 470.8184814453125
test loss item: 106.63775634765625
test loss item: 764.1487426757812
test loss item: 171.2996368408203
test loss item: 221.57728576660156
test loss item: 394.1563720703125
test loss item: 76.13226318359375
test loss item: 136.9359588623047
test loss item: 377.9566345214844
test loss item: 169.89016723632812
test loss item: 250.63186645507812
test loss item: 187.15399169921875
test loss item: 1265.6878662109375
test loss item: 175.43740844726562
test loss item: 340.31024169921875
test loss item: 1724.4617919921875
test loss item: 28.963336944580078
test loss item: 216.02886962890625
test loss item: 187.63551330566406
test loss item: 270.0807800292969
test loss item: 193.7791748046875
test loss item: 189.17726135253906
test loss item: 176.4593963623047
test loss item: 385.3144226074219
test loss item: 1327.7686767578125
test loss item: 197.02804565429688
test loss item: 177.32077026367188
test loss item: 251.93359375
test loss item: 331.6430358886719
test loss item: 251.57339477539062
test loss item: 170.888916015625
test loss item: 142.28721618652344
test loss item: 162.67970275878906
test loss item: 112.36874389648438
test loss item: 391.0885314941406
test loss item: 294.4483337402344
test loss item: 1991.3853759765625
test loss item: 26.390583038330078
test loss item: 254.71168518066406
test loss item: 218.69187927246094
test loss item: 1090.5208740234375
test loss item: 376.3138427734375
test loss item: 1481.40771484375
test loss item: 188.2561492919922
test loss item: 189.47454833984375
test loss item: 268.1427001953125
test loss item: 354.2879943847656
test loss item: 306.29754638671875
Epoch [2/100], Training Loss: 1.3144, Testing Loss: 416.1080
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.7964559197425842
1
train loss item: 1.9164539575576782
2
train loss item: 0.4914293587207794
3
train loss item: 1.0187532901763916
4
train loss item: 1.1584614515304565
5
train loss item: 0.6224740743637085
6
train loss item: 0.5111649632453918
7
train loss item: 1.1942405700683594
8
train loss item: 0.4833643138408661
9
train loss item: 0.4539845883846283
10
train loss item: 0.6110211610794067
11
train loss item: 0.4189457595348358
12
train loss item: 0.3864139914512634
13
train loss item: 0.9050256609916687
14
train loss item: 0.5808258056640625
15
train loss item: 1.0991885662078857
16
train loss item: 0.3893755078315735
17
train loss item: 0.5358197093009949
18
train loss item: 0.6277730464935303
19
train loss item: 0.45866891741752625
20
train loss item: 0.44056186079978943
21
train loss item: 0.5438469648361206
22
train loss item: 1.5875545740127563
23
train loss item: 1.311381220817566
24
train loss item: 0.8389303088188171
25
train loss item: 0.5680174231529236
26
train loss item: 0.5187239646911621
27
train loss item: 0.5514217615127563
28
train loss item: 0.3835359215736389
29
train loss item: 1.335516333580017
30
train loss item: 2.904987096786499
31
train loss item: 0.9224701523780823
32
train loss item: 0.4165094196796417
33
train loss item: 0.8323606848716736
34
train loss item: 0.6988712549209595
35
train loss item: 2.8987181186676025
36
train loss item: 0.8292403221130371
37
train loss item: 0.42480412125587463
38
train loss item: 0.9086219668388367
39
train loss item: 0.5671680569648743
40
train loss item: 0.4864215850830078
41
train loss item: 0.5113524794578552
42
train loss item: 0.4147615432739258
43
train loss item: 0.503864586353302
44
train loss item: 1.0541573762893677
45
train loss item: 0.5304104685783386
46
train loss item: 0.5269127488136292
47
train loss item: 0.6658385396003723
48
train loss item: 0.5114231705665588
49
train loss item: 0.5182555317878723
50
train loss item: 0.43358439207077026
51
train loss item: 1.421248435974121
52
train loss item: 0.36023661494255066
53
train loss item: 0.5486335158348083
54
train loss item: 2.7745676040649414
55
train loss item: 0.532230794429779
56
train loss item: 0.5186665058135986
57
train loss item: 0.4975365102291107
58
train loss item: 0.48291459679603577
59
train loss item: 0.41723525524139404
60
train loss item: 1.522156000137329
61
train loss item: 2.795410394668579
62
train loss item: 0.44293272495269775
63
train loss item: 0.5582072138786316
64
train loss item: 0.5048189163208008
65
train loss item: 0.9101715683937073
66
train loss item: 0.6417673826217651
67
train loss item: 0.5198288559913635
68
train loss item: 0.5356034636497498
69
train loss item: 0.5900068879127502
70
train loss item: 0.5546663999557495
71
train loss item: 0.5127355456352234
72
train loss item: 0.5172411799430847
73
train loss item: 0.5207083821296692
74
train loss item: 0.48122572898864746
75
train loss item: 0.42484378814697266
76
train loss item: 1.3188378810882568
77
train loss item: 1.7620891332626343
78
train loss item: 0.36643823981285095
79
train loss item: 0.43722376227378845
80
train loss item: 0.5526209473609924
81
train loss item: 0.4490346312522888
82
train loss item: 0.5769686698913574
83
train loss item: 1.099683165550232
84
train loss item: 0.6078097820281982
85
train loss item: 0.9380335807800293
86
train loss item: 4.948439598083496
87
train loss item: 0.6036426424980164
88
train loss item: 0.5661624073982239
epoch train loss: 0.8327263288953332
testing phase
test loss item: 77.21778869628906
test loss item: 208.50421142578125
test loss item: 47.77352523803711
test loss item: 235.51731872558594
test loss item: 182.11798095703125
test loss item: 213.9215087890625
test loss item: 222.02711486816406
test loss item: 87.25261688232422
test loss item: 53.35943603515625
test loss item: 61.02340316772461
test loss item: 312.4098815917969
test loss item: 231.70742797851562
test loss item: 89.54730987548828
test loss item: 4.42367696762085
test loss item: 173.25010681152344
test loss item: 289.1364440917969
test loss item: 45.13939666748047
test loss item: 83.5167465209961
test loss item: 124.77787780761719
test loss item: 23.98427391052246
test loss item: 90.908203125
test loss item: 213.01943969726562
test loss item: 164.45269775390625
test loss item: 136.5330352783203
test loss item: 131.49227905273438
test loss item: 122.50988006591797
test loss item: 65.53367614746094
test loss item: 177.1501007080078
test loss item: 141.29454040527344
test loss item: 85.57294464111328
test loss item: 302.2391052246094
test loss item: 288.3783874511719
test loss item: 144.04776000976562
test loss item: 232.099853515625
test loss item: 176.452880859375
test loss item: 552.8222045898438
test loss item: 93.98589324951172
test loss item: 543.9161376953125
test loss item: 188.75015258789062
test loss item: 176.24600219726562
test loss item: 174.4817657470703
test loss item: 186.83718872070312
test loss item: 37.295745849609375
test loss item: 218.11570739746094
test loss item: 87.13880157470703
test loss item: 186.56300354003906
test loss item: 163.24313354492188
test loss item: 20.16522216796875
test loss item: 52.15702819824219
test loss item: 191.0410919189453
test loss item: 64.01798248291016
test loss item: 125.90208435058594
test loss item: 101.59657287597656
test loss item: 335.1656494140625
test loss item: 116.14768981933594
test loss item: 158.6660614013672
test loss item: 348.9639892578125
test loss item: 4.291358470916748
test loss item: 118.71106719970703
test loss item: 107.36035919189453
test loss item: 128.52496337890625
test loss item: 160.34283447265625
test loss item: 112.52493286132812
test loss item: 90.60031127929688
test loss item: 191.66241455078125
test loss item: 349.4522399902344
test loss item: 98.8329086303711
test loss item: 80.69192504882812
test loss item: 176.08963012695312
test loss item: 106.93560791015625
test loss item: 195.76907348632812
test loss item: 111.3395767211914
test loss item: 77.1908187866211
test loss item: 70.4561538696289
test loss item: 49.17377853393555
test loss item: 157.60121154785156
test loss item: 162.60433959960938
test loss item: 669.2105712890625
test loss item: 5.962140083312988
test loss item: 175.30136108398438
test loss item: 134.16542053222656
test loss item: 379.6590270996094
test loss item: 149.61219787597656
test loss item: 484.9559020996094
test loss item: 121.81741333007812
test loss item: 83.13935852050781
test loss item: 196.48019409179688
test loss item: 288.3746032714844
test loss item: 162.40072631835938
Epoch [3/100], Training Loss: 0.8327, Testing Loss: 165.8736
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.709123432636261
1
train loss item: 1.9657634496688843
2
train loss item: 0.5000889301300049
3
train loss item: 1.1529614925384521
4
train loss item: 1.2365509271621704
5
train loss item: 0.5506782531738281
6
train loss item: 0.5767817497253418
7
train loss item: 1.3263064622879028
8
train loss item: 0.6659162640571594
9
train loss item: 0.5278607606887817
10
train loss item: 0.6996232271194458
11
train loss item: 0.4170275032520294
12
train loss item: 0.432915598154068
13
train loss item: 0.8480802178382874
14
train loss item: 0.5367109179496765
15
train loss item: 0.9507414698600769
16
train loss item: 0.4766979515552521
17
train loss item: 0.5460578799247742
18
train loss item: 0.5886713266372681
19
train loss item: 0.4649198055267334
20
train loss item: 0.4338360130786896
21
train loss item: 0.45839133858680725
22
train loss item: 1.4093250036239624
23
train loss item: 1.3946943283081055
24
train loss item: 0.8080911040306091
25
train loss item: 0.431612104177475
26
train loss item: 0.5226308107376099
27
train loss item: 0.5555213689804077
28
train loss item: 0.49275803565979004
29
train loss item: 1.1389988660812378
30
train loss item: 3.1841647624969482
31
train loss item: 0.9783722162246704
32
train loss item: 0.5465304255485535
33
train loss item: 0.9233489036560059
34
train loss item: 0.5387077927589417
35
train loss item: 3.0640652179718018
36
train loss item: 0.7554970383644104
37
train loss item: 0.4328623116016388
38
train loss item: 0.8644354343414307
39
train loss item: 0.568266749382019
40
train loss item: 0.3991055488586426
41
train loss item: 0.5550557374954224
42
train loss item: 0.4180082380771637
43
train loss item: 0.5413540005683899
44
train loss item: 1.1137067079544067
45
train loss item: 0.5068544745445251
46
train loss item: 0.507759153842926
47
train loss item: 0.5719010233879089
48
train loss item: 0.514923095703125
49
train loss item: 0.4595623314380646
50
train loss item: 0.4906263053417206
51
train loss item: 1.3635722398757935
52
train loss item: 0.5539284348487854
53
train loss item: 0.46002376079559326
54
train loss item: 2.9592173099517822
55
train loss item: 0.5699785351753235
56
train loss item: 0.5645855069160461
57
train loss item: 0.498181015253067
58
train loss item: 0.5035938620567322
59
train loss item: 0.5185667872428894
60
train loss item: 1.367958664894104
61
train loss item: 3.005734443664551
62
train loss item: 0.48312562704086304
63
train loss item: 0.5321363210678101
64
train loss item: 0.5615054965019226
65
train loss item: 0.7630597949028015
66
train loss item: 0.6366426348686218
67
train loss item: 0.4929242730140686
68
train loss item: 0.4915876090526581
69
train loss item: 0.5484006404876709
70
train loss item: 0.464326947927475
71
train loss item: 0.46492263674736023
72
train loss item: 0.6935043931007385
73
train loss item: 0.47993430495262146
74
train loss item: 0.6734532713890076
75
train loss item: 0.48015597462654114
76
train loss item: 1.4055583477020264
77
train loss item: 1.6423330307006836
78
train loss item: 0.45913949608802795
79
train loss item: 0.44560879468917847
80
train loss item: 0.5420604348182678
81
train loss item: 0.41636255383491516
82
train loss item: 0.5060976147651672
83
train loss item: 0.9749600887298584
84
train loss item: 0.5251942873001099
85
train loss item: 1.0271364450454712
86
train loss item: 5.249999523162842
87
train loss item: 0.5360144972801208
88
train loss item: 0.5499196648597717
epoch train loss: 0.8445601048094503
testing phase
test loss item: 6.660935878753662
test loss item: 24.572599411010742
test loss item: 1.8816300630569458
test loss item: 15.636756896972656
test loss item: 20.379880905151367
test loss item: 24.810009002685547
test loss item: 8.808095932006836
test loss item: 4.127858638763428
test loss item: 4.2744622230529785
test loss item: 2.802062511444092
test loss item: 12.592875480651855
test loss item: 16.04220962524414
test loss item: 3.3028922080993652
test loss item: 0.3636178970336914
test loss item: 19.045166015625
test loss item: 36.084449768066406
test loss item: 1.4966766834259033
test loss item: 3.636437177658081
test loss item: 8.557174682617188
test loss item: 1.2040942907333374
test loss item: 8.61253547668457
test loss item: 11.08897590637207
test loss item: 9.043803215026855
test loss item: 13.963210105895996
test loss item: 11.813336372375488
test loss item: 10.755029678344727
test loss item: 4.903090953826904
test loss item: 19.74736976623535
test loss item: 14.714142799377441
test loss item: 3.869948625564575
test loss item: 13.102688789367676
test loss item: 36.08054733276367
test loss item: 15.000717163085938
test loss item: 11.8848876953125
test loss item: 20.135011672973633
test loss item: 27.186811447143555
test loss item: 2.567232847213745
test loss item: 20.833059310913086
test loss item: 9.151233673095703
test loss item: 19.78580093383789
test loss item: 20.000221252441406
test loss item: 11.983717918395996
test loss item: 2.0457167625427246
test loss item: 10.980056762695312
test loss item: 8.676756858825684
test loss item: 23.29848289489746
test loss item: 9.357924461364746
test loss item: 1.4813295602798462
test loss item: 0.7262448072433472
test loss item: 8.216689109802246
test loss item: 2.6947197914123535
test loss item: 12.094978332519531
test loss item: 7.204052448272705
test loss item: 17.732025146484375
test loss item: 9.657407760620117
test loss item: 4.905293941497803
test loss item: 16.52268409729004
test loss item: 0.49866342544555664
test loss item: 12.080366134643555
test loss item: 7.50446891784668
test loss item: 12.007767677307129
test loss item: 19.892839431762695
test loss item: 9.91112232208252
test loss item: 2.544482946395874
test loss item: 17.617774963378906
test loss item: 18.56720542907715
test loss item: 7.178098678588867
test loss item: 4.213913917541504
test loss item: 19.94830322265625
test loss item: 1.4496424198150635
test loss item: 24.0888614654541
test loss item: 12.18920612335205
test loss item: 8.134666442871094
test loss item: 5.30729866027832
test loss item: 4.271378517150879
test loss item: 8.73096752166748
test loss item: 17.73681640625
test loss item: 31.24643898010254
test loss item: 0.6571226119995117
test loss item: 19.971622467041016
test loss item: 15.365177154541016
test loss item: 18.052507400512695
test loss item: 3.682587146759033
test loss item: 21.838581085205078
test loss item: 10.503280639648438
test loss item: 7.6168646812438965
test loss item: 24.223745346069336
test loss item: 36.13582229614258
test loss item: 16.724477767944336
Epoch [4/100], Training Loss: 0.8446, Testing Loss: 12.2246
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.656474232673645
1
train loss item: 1.800570011138916
2
train loss item: 0.3560062646865845
3
train loss item: 0.9847120642662048
4
train loss item: 0.7940486073493958
5
train loss item: 0.5169562697410583
6
train loss item: 0.4104469120502472
7
train loss item: 1.1847126483917236
8
train loss item: 0.3739842176437378
9
train loss item: 0.40075042843818665
10
train loss item: 0.5523738861083984
11
train loss item: 0.3472879230976105
12
train loss item: 0.23801134526729584
13
train loss item: 0.7587170004844666
14
train loss item: 0.4528224468231201
15
train loss item: 0.9152129888534546
16
train loss item: 0.21535082161426544
17
train loss item: 0.40149834752082825
18
train loss item: 0.5005670785903931
19
train loss item: 0.37079182267189026
20
train loss item: 0.339496910572052
21
train loss item: 0.3335827589035034
22
train loss item: 1.3347214460372925
23
train loss item: 1.2491713762283325
24
train loss item: 0.7379628419876099
25
train loss item: 0.343426913022995
26
train loss item: 0.3759284019470215
27
train loss item: 0.4623745381832123
28
train loss item: 0.22934478521347046
29
train loss item: 1.0677324533462524
30
train loss item: 2.9919633865356445
31
train loss item: 0.8374354243278503
32
train loss item: 0.3214867413043976
33
train loss item: 0.7213915586471558
34
train loss item: 0.3950727581977844
35
train loss item: 2.934450387954712
36
train loss item: 0.6699051856994629
37
train loss item: 0.362498939037323
38
train loss item: 0.6967411041259766
39
train loss item: 0.4682409167289734
40
train loss item: 0.2849549651145935
41
train loss item: 0.45573320984840393
42
train loss item: 0.34396591782569885
43
train loss item: 0.3803582191467285
44
train loss item: 0.9998792409896851
45
train loss item: 0.2912740111351013
46
train loss item: 0.31111258268356323
47
train loss item: 0.48082560300827026
48
train loss item: 0.3996196687221527
49
train loss item: 0.3362523317337036
50
train loss item: 0.3792833089828491
51
train loss item: 1.28708815574646
52
train loss item: 0.26618140935897827
53
train loss item: 0.3198050260543823
54
train loss item: 2.8222036361694336
55
train loss item: 0.3625915050506592
56
train loss item: 0.4472717046737671
57
train loss item: 0.41129735112190247
58
train loss item: 0.3533138930797577
59
train loss item: 0.315391480922699
60
train loss item: 1.2785871028900146
61
train loss item: 2.816005229949951
62
train loss item: 0.3460095524787903
63
train loss item: 0.4680663049221039
64
train loss item: 0.36661478877067566
65
train loss item: 0.7488129734992981
66
train loss item: 0.5299195647239685
67
train loss item: 0.3824418783187866
68
train loss item: 0.397892028093338
69
train loss item: 0.46232062578201294
70
train loss item: 0.3831198215484619
71
train loss item: 0.28651097416877747
72
train loss item: 0.40339067578315735
73
train loss item: 0.4047895073890686
74
train loss item: 0.3277525305747986
75
train loss item: 0.26563137769699097
76
train loss item: 1.2581586837768555
77
train loss item: 1.5835521221160889
78
train loss item: 0.22450308501720428
79
train loss item: 0.36566492915153503
80
train loss item: 0.2943735122680664
81
train loss item: 0.33074724674224854
82
train loss item: 0.39640501141548157
83
train loss item: 0.8833985328674316
84
train loss item: 0.44848668575286865
85
train loss item: 0.9073538184165955
86
train loss item: 5.070106506347656
87
train loss item: 0.3438168466091156
88
train loss item: 0.4580044746398926
epoch train loss: 0.705450154589803
testing phase
test loss item: 3.071328639984131
test loss item: 13.616459846496582
test loss item: 0.766322910785675
test loss item: 8.478822708129883
test loss item: 11.728034019470215
test loss item: 14.323015213012695
test loss item: 5.163188934326172
test loss item: 2.049639940261841
test loss item: 1.9157134294509888
test loss item: 1.335042953491211
test loss item: 5.78125
test loss item: 8.631380081176758
test loss item: 1.5133655071258545
test loss item: 0.3845938444137573
test loss item: 10.16140365600586
test loss item: 20.250213623046875
test loss item: 0.39778637886047363
test loss item: 1.7710387706756592
test loss item: 4.0674519538879395
test loss item: 0.5138281583786011
test loss item: 4.286327838897705
test loss item: 6.113883972167969
test loss item: 5.429311275482178
test loss item: 7.5079264640808105
test loss item: 6.196392059326172
test loss item: 5.139895915985107
test loss item: 2.209871292114258
test loss item: 11.417559623718262
test loss item: 7.8815836906433105
test loss item: 1.7962192296981812
test loss item: 5.86696720123291
test loss item: 20.271381378173828
test loss item: 8.076258659362793
test loss item: 6.431876182556152
test loss item: 11.261919021606445
test loss item: 15.3003511428833
test loss item: 1.487786054611206
test loss item: 9.078228950500488
test loss item: 4.998075485229492
test loss item: 11.498032569885254
test loss item: 11.209548950195312
test loss item: 6.728250980377197
test loss item: 0.576207160949707
test loss item: 5.94780158996582
test loss item: 4.320725440979004
test loss item: 13.082039833068848
test loss item: 5.596370697021484
test loss item: 0.6087355613708496
test loss item: 0.5747856497764587
test loss item: 3.528599739074707
test loss item: 1.3609898090362549
test loss item: 6.32827615737915
test loss item: 3.4859979152679443
test loss item: 9.641182899475098
test loss item: 4.712542533874512
test loss item: 2.2052555084228516
test loss item: 9.41608715057373
test loss item: 0.5202631950378418
test loss item: 6.324753284454346
test loss item: 3.647731304168701
test loss item: 6.284181594848633
test loss item: 11.170061111450195
test loss item: 4.825756072998047
test loss item: 1.1522243022918701
test loss item: 10.386116027832031
test loss item: 10.110651969909668
test loss item: 3.515901565551758
test loss item: 1.9858249425888062
test loss item: 11.189913749694824
test loss item: 0.5962303280830383
test loss item: 13.457640647888184
test loss item: 6.479706764221191
test loss item: 4.081705093383789
test loss item: 2.5419602394104004
test loss item: 1.9210329055786133
test loss item: 5.3153157234191895
test loss item: 9.452017784118652
test loss item: 14.854684829711914
test loss item: 0.5530092716217041
test loss item: 11.683941841125488
test loss item: 8.03640365600586
test loss item: 9.62680435180664
test loss item: 1.615204930305481
test loss item: 10.97773551940918
test loss item: 5.195173263549805
test loss item: 3.451070547103882
test loss item: 13.525443077087402
test loss item: 20.28662109375
test loss item: 7.902615547180176
Epoch [5/100], Training Loss: 0.7055, Testing Loss: 6.5187
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6391021013259888
1
train loss item: 1.639237403869629
2
train loss item: 0.3429358899593353
3
train loss item: 0.8170899152755737
4
train loss item: 0.8759848475456238
5
train loss item: 0.5290408730506897
6
train loss item: 0.4101920425891876
7
train loss item: 1.0658186674118042
8
train loss item: 0.26959893107414246
9
train loss item: 0.3823898136615753
10
train loss item: 0.47453051805496216
11
train loss item: 0.3356063663959503
12
train loss item: 0.22082394361495972
13
train loss item: 0.715194582939148
14
train loss item: 0.45310723781585693
15
train loss item: 0.9170725345611572
16
train loss item: 0.21727128326892853
17
train loss item: 0.443759560585022
18
train loss item: 0.4572056829929352
19
train loss item: 0.35876598954200745
20
train loss item: 0.4018152952194214
21
train loss item: 0.35585108399391174
22
train loss item: 1.2967512607574463
23
train loss item: 1.1396089792251587
24
train loss item: 0.7108457684516907
25
train loss item: 0.37744468450546265
26
train loss item: 0.346173495054245
27
train loss item: 0.41993069648742676
28
train loss item: 0.21642859280109406
29
train loss item: 1.0451557636260986
30
train loss item: 2.7841145992279053
31
train loss item: 0.7351086139678955
32
train loss item: 0.25223472714424133
33
train loss item: 0.5859820246696472
34
train loss item: 0.44728970527648926
35
train loss item: 2.8024649620056152
36
train loss item: 0.6331271529197693
37
train loss item: 0.37587955594062805
38
train loss item: 0.5830286145210266
39
train loss item: 0.4266641438007355
40
train loss item: 0.30784645676612854
41
train loss item: 0.41317030787467957
42
train loss item: 0.326049268245697
43
train loss item: 0.32871609926223755
44
train loss item: 0.9131677746772766
45
train loss item: 0.25549009442329407
46
train loss item: 0.2909756600856781
47
train loss item: 0.49238601326942444
48
train loss item: 0.37482908368110657
49
train loss item: 0.3591698706150055
50
train loss item: 0.3830867111682892
51
train loss item: 1.2194278240203857
52
train loss item: 0.2368331104516983
53
train loss item: 0.3582583963871002
54
train loss item: 2.6812329292297363
55
train loss item: 0.29224202036857605
56
train loss item: 0.3967297673225403
57
train loss item: 0.35435381531715393
58
train loss item: 0.31150022149086
59
train loss item: 0.2473878562450409
60
train loss item: 1.221575140953064
61
train loss item: 2.634248971939087
62
train loss item: 0.31760451197624207
63
train loss item: 0.4348480999469757
64
train loss item: 0.26101043820381165
65
train loss item: 0.8097649812698364
66
train loss item: 0.4778249263763428
67
train loss item: 0.3611967861652374
68
train loss item: 0.4068447947502136
69
train loss item: 0.4374018609523773
70
train loss item: 0.4210388660430908
71
train loss item: 0.31726300716400146
72
train loss item: 0.2916499376296997
73
train loss item: 0.41536420583724976
74
train loss item: 0.28455474972724915
75
train loss item: 0.2291453778743744
76
train loss item: 1.1371147632598877
77
train loss item: 1.5442936420440674
78
train loss item: 0.2193654328584671
79
train loss item: 0.3264850974082947
80
train loss item: 0.2573302090167999
81
train loss item: 0.3570981025695801
82
train loss item: 0.3807446360588074
83
train loss item: 0.8334577679634094
84
train loss item: 0.4304877519607544
85
train loss item: 0.8020942807197571
86
train loss item: 4.863773822784424
87
train loss item: 0.3696031868457794
88
train loss item: 0.4246833622455597
epoch train loss: 0.666419661781761
testing phase
test loss item: 1.0577601194381714
test loss item: 6.423574447631836
test loss item: 0.738946795463562
test loss item: 2.736870765686035
test loss item: 5.11063814163208
test loss item: 6.373239994049072
test loss item: 1.9180032014846802
test loss item: 1.0632487535476685
test loss item: 0.5858234763145447
test loss item: 0.5959168672561646
test loss item: 1.1751071214675903
test loss item: 3.2047810554504395
test loss item: 0.4170583188533783
test loss item: 0.39405715465545654
test loss item: 4.659904479980469
test loss item: 9.764897346496582
test loss item: 0.33457109332084656
test loss item: 0.8795017004013062
test loss item: 1.8737934827804565
test loss item: 0.35690394043922424
test loss item: 1.9777753353118896
test loss item: 0.6255561709403992
test loss item: 0.9696524143218994
test loss item: 3.2449235916137695
test loss item: 2.9471442699432373
test loss item: 1.8828257322311401
test loss item: 0.7259348034858704
test loss item: 4.918213844299316
test loss item: 3.431366205215454
test loss item: 0.6244915127754211
test loss item: 1.2293422222137451
test loss item: 9.792121887207031
test loss item: 3.55519700050354
test loss item: 0.8820112943649292
test loss item: 5.4340081214904785
test loss item: 1.1870065927505493
test loss item: 1.0405278205871582
test loss item: 1.843719720840454
test loss item: 0.8246949911117554
test loss item: 5.018078327178955
test loss item: 5.40544319152832
test loss item: 1.7435706853866577
test loss item: 0.5188847184181213
test loss item: 0.5094870328903198
test loss item: 1.9160690307617188
test loss item: 6.3292365074157715
test loss item: 1.177905797958374
test loss item: 0.3521985709667206
test loss item: 0.6013098955154419
test loss item: 1.5166527032852173
test loss item: 0.6215004324913025
test loss item: 2.9691545963287354
test loss item: 1.2319600582122803
test loss item: 0.7340617179870605
test loss item: 1.6915589570999146
test loss item: 1.2955483198165894
test loss item: 1.024769902229309
test loss item: 0.5201119780540466
test loss item: 3.0063998699188232
test loss item: 1.3089962005615234
test loss item: 2.996319055557251
test loss item: 5.400940895080566
test loss item: 1.8506605625152588
test loss item: 0.33278852701187134
test loss item: 4.632922172546387
test loss item: 0.8337852358818054
test loss item: 1.226503849029541
test loss item: 0.7690749168395996
test loss item: 5.442905426025391
test loss item: 0.5375396013259888
test loss item: 6.468523979187012
test loss item: 3.2508678436279297
test loss item: 1.7632659673690796
test loss item: 1.058266520500183
test loss item: 0.8058069348335266
test loss item: 0.8926787376403809
test loss item: 4.29213809967041
test loss item: 2.0139477252960205
test loss item: 0.5588880181312561
test loss item: 5.070672988891602
test loss item: 3.805269241333008
test loss item: 2.045292854309082
test loss item: 1.0300495624542236
test loss item: 1.3429975509643555
test loss item: 1.942524790763855
test loss item: 1.3618927001953125
test loss item: 6.502540588378906
test loss item: 9.78781795501709
test loss item: 3.348339080810547
Epoch [6/100], Training Loss: 0.6664, Testing Loss: 2.4456
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.6200348138809204
1
train loss item: 1.5878140926361084
2
train loss item: 0.30962854623794556
3
train loss item: 0.7607928514480591
4
train loss item: 0.7289098501205444
5
train loss item: 0.49888530373573303
6
train loss item: 0.3654206395149231
7
train loss item: 1.041635513305664
8
train loss item: 0.27968597412109375
9
train loss item: 0.36295023560523987
10
train loss item: 0.4526933431625366
11
train loss item: 0.3411499857902527
12
train loss item: 0.21076549589633942
13
train loss item: 0.6858928203582764
14
train loss item: 0.4469723701477051
15
train loss item: 0.8926098942756653
16
train loss item: 0.20899783074855804
17
train loss item: 0.4274754524230957
18
train loss item: 0.44106000661849976
19
train loss item: 0.3483508229255676
20
train loss item: 0.36577534675598145
21
train loss item: 0.3057040274143219
22
train loss item: 1.2707300186157227
23
train loss item: 1.114900827407837
24
train loss item: 0.6722890138626099
25
train loss item: 0.38819509744644165
26
train loss item: 0.30865904688835144
27
train loss item: 0.39234593510627747
28
train loss item: 0.20561067759990692
29
train loss item: 1.014880895614624
30
train loss item: 2.728942632675171
31
train loss item: 0.6982608437538147
32
train loss item: 0.2306569516658783
33
train loss item: 0.5514926910400391
34
train loss item: 0.37383994460105896
35
train loss item: 2.764580249786377
36
train loss item: 0.6078891158103943
37
train loss item: 0.38241904973983765
38
train loss item: 0.5403754711151123
39
train loss item: 0.4061603844165802
40
train loss item: 0.31226757168769836
41
train loss item: 0.388174831867218
42
train loss item: 0.31501081585884094
43
train loss item: 0.2810392379760742
44
train loss item: 0.8784637451171875
45
train loss item: 0.23178768157958984
46
train loss item: 0.27487507462501526
47
train loss item: 0.4966577887535095
48
train loss item: 0.34777504205703735
49
train loss item: 0.3331131041049957
50
train loss item: 0.3854750692844391
51
train loss item: 1.177057147026062
52
train loss item: 0.24048033356666565
53
train loss item: 0.3451857268810272
54
train loss item: 2.6438279151916504
55
train loss item: 0.27836570143699646
56
train loss item: 0.37398797273635864
57
train loss item: 0.3433571755886078
58
train loss item: 0.2655278444290161
59
train loss item: 0.24475479125976562
60
train loss item: 1.183359980583191
61
train loss item: 2.592615842819214
62
train loss item: 0.29556283354759216
63
train loss item: 0.4284267723560333
64
train loss item: 0.23731876909732819
65
train loss item: 0.7699821591377258
66
train loss item: 0.46071115136146545
67
train loss item: 0.34364795684814453
68
train loss item: 0.40302079916000366
69
train loss item: 0.42139172554016113
70
train loss item: 0.42172276973724365
71
train loss item: 0.2839595675468445
72
train loss item: 0.2946137487888336
73
train loss item: 0.3977304697036743
74
train loss item: 0.2731129229068756
75
train loss item: 0.21266888082027435
76
train loss item: 1.1076081991195679
77
train loss item: 1.5221227407455444
78
train loss item: 0.20804841816425323
79
train loss item: 0.33172351121902466
80
train loss item: 0.21839678287506104
81
train loss item: 0.351632297039032
82
train loss item: 0.35612407326698303
83
train loss item: 0.7959581613540649
84
train loss item: 0.4223528504371643
85
train loss item: 0.7818775177001953
86
train loss item: 4.81502628326416
87
train loss item: 0.36651235818862915
88
train loss item: 0.4054528772830963
epoch train loss: 0.6426438320888562
testing phase
test loss item: 0.38802918791770935
test loss item: 2.638472557067871
test loss item: 0.8028857707977295
test loss item: 1.1304597854614258
test loss item: 1.9914606809616089
test loss item: 2.5254814624786377
test loss item: 1.858605980873108
test loss item: 0.7784498333930969
test loss item: 0.34693431854248047
test loss item: 0.5310851335525513
test loss item: 1.1863532066345215
test loss item: 1.3871040344238281
test loss item: 0.2529720664024353
test loss item: 0.3968346416950226
test loss item: 1.9261783361434937
test loss item: 4.072983264923096
test loss item: 0.3446253836154938
test loss item: 0.6820122599601746
test loss item: 1.0552799701690674
test loss item: 0.3478519916534424
test loss item: 1.216528058052063
test loss item: 0.4789900481700897
test loss item: 0.5273367762565613
test loss item: 1.2767524719238281
test loss item: 1.3058103322982788
test loss item: 0.6191486120223999
test loss item: 0.4469981789588928
test loss item: 1.8791481256484985
test loss item: 1.3761194944381714
test loss item: 0.4580228924751282
test loss item: 1.059882640838623
test loss item: 4.075713157653809
test loss item: 1.4277174472808838
test loss item: 0.7825371026992798
test loss item: 2.334413766860962
test loss item: 0.6355734467506409
test loss item: 1.0061211585998535
test loss item: 2.0283632278442383
test loss item: 0.6701406240463257
test loss item: 1.9582297801971436
test loss item: 2.2746853828430176
test loss item: 0.6762394905090332
test loss item: 0.5227820873260498
test loss item: 0.31175047159194946
test loss item: 1.036473035812378
test loss item: 2.680877923965454
test loss item: 0.5868505835533142
test loss item: 0.3146210312843323
test loss item: 0.6489301919937134
test loss item: 0.9907814860343933
test loss item: 0.48242461681365967
test loss item: 1.2903096675872803
test loss item: 0.4576944410800934
test loss item: 0.36245375871658325
test loss item: 0.6315300464630127
test loss item: 1.1982518434524536
test loss item: 0.7417598366737366
test loss item: 0.4651305675506592
test loss item: 1.3233507871627808
test loss item: 0.472339391708374
test loss item: 1.396726369857788
test loss item: 2.2687134742736816
test loss item: 0.6518427133560181
test loss item: 0.3054821193218231
test loss item: 2.079056739807129
test loss item: 0.4699942171573639
test loss item: 0.4806821346282959
test loss item: 0.4006553292274475
test loss item: 2.3732693195343018
test loss item: 0.6267842650413513
test loss item: 2.69112491607666
test loss item: 1.7159141302108765
test loss item: 0.7528160214424133
test loss item: 0.5421473383903503
test loss item: 0.37436091899871826
test loss item: 0.4037238657474518
test loss item: 1.767109990119934
test loss item: 2.100757360458374
test loss item: 0.5692365169525146
test loss item: 1.9615751504898071
test loss item: 1.6378083229064941
test loss item: 1.4287892580032349
test loss item: 1.0867952108383179
test loss item: 1.4523329734802246
test loss item: 0.6630635261535645
test loss item: 0.5294273495674133
test loss item: 2.728236436843872
test loss item: 4.107785224914551
test loss item: 1.2903923988342285
Epoch [7/100], Training Loss: 0.6426, Testing Loss: 1.1970
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5896019339561462
1
train loss item: 1.5669695138931274
2
train loss item: 0.275022953748703
3
train loss item: 0.7576500773429871
4
train loss item: 0.5000334978103638
5
train loss item: 0.4450802206993103
6
train loss item: 0.3177390992641449
7
train loss item: 1.042942762374878
8
train loss item: 0.21291495859622955
9
train loss item: 0.33961227536201477
10
train loss item: 0.44778215885162354
11
train loss item: 0.3426865339279175
12
train loss item: 0.16707101464271545
13
train loss item: 0.6555853486061096
14
train loss item: 0.40928974747657776
15
train loss item: 0.8271281719207764
16
train loss item: 0.15081429481506348
17
train loss item: 0.37051695585250854
18
train loss item: 0.42283838987350464
19
train loss item: 0.3267977833747864
20
train loss item: 0.29750242829322815
21
train loss item: 0.21111343801021576
22
train loss item: 1.2241815328598022
23
train loss item: 1.1238276958465576
24
train loss item: 0.641627311706543
25
train loss item: 0.31667542457580566
26
train loss item: 0.2559838593006134
27
train loss item: 0.3665471374988556
28
train loss item: 0.14347729086875916
29
train loss item: 0.9605110287666321
30
train loss item: 2.728264093399048
31
train loss item: 0.689106822013855
32
train loss item: 0.19447310268878937
33
train loss item: 0.5526072978973389
34
train loss item: 0.24949078261852264
35
train loss item: 2.7583937644958496
36
train loss item: 0.5777360200881958
37
train loss item: 0.37219157814979553
38
train loss item: 0.5280889868736267
39
train loss item: 0.3831784725189209
40
train loss item: 0.23187753558158875
41
train loss item: 0.36684951186180115
42
train loss item: 0.2955248951911926
43
train loss item: 0.23407746851444244
44
train loss item: 0.8678393363952637
45
train loss item: 0.20247985422611237
46
train loss item: 0.21737174689769745
47
train loss item: 0.4609992802143097
48
train loss item: 0.3071005642414093
49
train loss item: 0.2663955092430115
50
train loss item: 0.3653506636619568
51
train loss item: 1.1346079111099243
52
train loss item: 0.18458855152130127
53
train loss item: 0.2611144185066223
54
train loss item: 2.6432080268859863
55
train loss item: 0.24771153926849365
56
train loss item: 0.3527018129825592
57
train loss item: 0.32428672909736633
58
train loss item: 0.21555012464523315
59
train loss item: 0.22079895436763763
60
train loss item: 1.136268138885498
61
train loss item: 2.5963563919067383
62
train loss item: 0.25610390305519104
63
train loss item: 0.4248197674751282
64
train loss item: 0.2218853235244751
65
train loss item: 0.6889586448669434
66
train loss item: 0.454006165266037
67
train loss item: 0.312532901763916
68
train loss item: 0.36940839886665344
69
train loss item: 0.39950332045555115
70
train loss item: 0.3722383379936218
71
train loss item: 0.21259087324142456
72
train loss item: 0.2604232430458069
73
train loss item: 0.3665773868560791
74
train loss item: 0.15940728783607483
75
train loss item: 0.16761913895606995
76
train loss item: 1.1102919578552246
77
train loss item: 1.4903334379196167
78
train loss item: 0.1527608186006546
79
train loss item: 0.3363053500652313
80
train loss item: 0.16168056428432465
81
train loss item: 0.27716735005378723
82
train loss item: 0.3117416501045227
83
train loss item: 0.7503841519355774
84
train loss item: 0.40466344356536865
85
train loss item: 0.7871677279472351
86
train loss item: 4.825435638427734
87
train loss item: 0.2738678455352783
88
train loss item: 0.38576844334602356
epoch train loss: 0.6046040202124735
testing phase
test loss item: 0.27669718861579895
test loss item: 1.078012228012085
test loss item: 0.790270209312439
test loss item: 0.5125621557235718
test loss item: 0.828741192817688
test loss item: 1.023531436920166
test loss item: 1.7232950925827026
test loss item: 0.6646913886070251
test loss item: 0.34161749482154846
test loss item: 0.5123708844184875
test loss item: 1.2161338329315186
test loss item: 0.6336113810539246
test loss item: 0.2543029189109802
test loss item: 0.3861972391605377
test loss item: 0.8217871785163879
test loss item: 1.6871647834777832
test loss item: 0.3453383445739746
test loss item: 0.6084635257720947
test loss item: 0.8367019295692444
test loss item: 0.34448134899139404
test loss item: 1.0157572031021118
test loss item: 0.429059773683548
test loss item: 0.4130118787288666
test loss item: 0.5208942294120789
test loss item: 0.6360872983932495
test loss item: 0.319827139377594
test loss item: 0.43587473034858704
test loss item: 0.7399809956550598
test loss item: 0.6529534459114075
test loss item: 0.4373115003108978
test loss item: 1.0245121717453003
test loss item: 1.6786831617355347
test loss item: 0.5916963219642639
test loss item: 0.7244318127632141
test loss item: 1.0945817232131958
test loss item: 0.6026443839073181
test loss item: 0.947495698928833
test loss item: 2.0690126419067383
test loss item: 0.616271436214447
test loss item: 0.8064404726028442
test loss item: 0.9871841073036194
test loss item: 0.32112061977386475
test loss item: 0.4826173484325409
test loss item: 0.2536598742008209
test loss item: 0.8263952732086182
test loss item: 1.2001404762268066
test loss item: 0.42430728673934937
test loss item: 0.2958933711051941
test loss item: 0.6325905919075012
test loss item: 0.9359835386276245
test loss item: 0.434194952249527
test loss item: 0.6010643839836121
test loss item: 0.3198092579841614
test loss item: 0.23071736097335815
test loss item: 0.4273920953273773
test loss item: 1.1911685466766357
test loss item: 0.7058222889900208
test loss item: 0.37593692541122437
test loss item: 0.6416557431221008
test loss item: 0.3066354990005493
test loss item: 0.7921770215034485
test loss item: 0.9733605980873108
test loss item: 0.3140491247177124
test loss item: 0.30573657155036926
test loss item: 1.293429970741272
test loss item: 0.3530803620815277
test loss item: 0.3843154013156891
test loss item: 0.3349571228027344
test loss item: 1.1772863864898682
test loss item: 0.6224725842475891
test loss item: 1.1189714670181274
test loss item: 1.1690607070922852
test loss item: 0.45892128348350525
test loss item: 0.4404182732105255
test loss item: 0.2770061492919922
test loss item: 0.27615267038345337
test loss item: 0.7520979046821594
test loss item: 2.120776414871216
test loss item: 0.5603277087211609
test loss item: 0.7898563742637634
test loss item: 0.7412807941436768
test loss item: 1.2947156429290771
test loss item: 1.0514981746673584
test loss item: 1.4762682914733887
test loss item: 0.3255215585231781
test loss item: 0.3454250395298004
test loss item: 1.1538242101669312
test loss item: 1.7221826314926147
test loss item: 0.5338242650032043
Epoch [8/100], Training Loss: 0.6046, Testing Loss: 0.7348
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5521730184555054
1
train loss item: 1.5158112049102783
2
train loss item: 0.26129990816116333
3
train loss item: 0.7409176826477051
4
train loss item: 0.5277368426322937
5
train loss item: 0.4097363352775574
6
train loss item: 0.33950114250183105
7
train loss item: 1.021833062171936
8
train loss item: 0.2031938135623932
9
train loss item: 0.3324856162071228
10
train loss item: 0.43773865699768066
11
train loss item: 0.3439837694168091
12
train loss item: 0.14943818747997284
13
train loss item: 0.6185780167579651
14
train loss item: 0.3742477595806122
15
train loss item: 0.7508236169815063
16
train loss item: 0.12368039041757584
17
train loss item: 0.3453804552555084
18
train loss item: 0.3966441750526428
19
train loss item: 0.33292582631111145
20
train loss item: 0.2885774075984955
21
train loss item: 0.18596595525741577
22
train loss item: 1.1499179601669312
23
train loss item: 1.1138800382614136
24
train loss item: 0.6238185167312622
25
train loss item: 0.2585318982601166
26
train loss item: 0.24455298483371735
27
train loss item: 0.3443317711353302
28
train loss item: 0.11950286477804184
29
train loss item: 0.8864395618438721
30
train loss item: 2.6945712566375732
31
train loss item: 0.6759207844734192
32
train loss item: 0.16633105278015137
33
train loss item: 0.5380774140357971
34
train loss item: 0.2006891667842865
35
train loss item: 2.735907793045044
36
train loss item: 0.5469059348106384
37
train loss item: 0.3857266306877136
38
train loss item: 0.5134600400924683
39
train loss item: 0.35153988003730774
40
train loss item: 0.19509027898311615
41
train loss item: 0.3482166528701782
42
train loss item: 0.2848406434059143
43
train loss item: 0.222715362906456
44
train loss item: 0.8414042592048645
45
train loss item: 0.18940964341163635
46
train loss item: 0.18272116780281067
47
train loss item: 0.4206703007221222
48
train loss item: 0.28064823150634766
49
train loss item: 0.2205566018819809
50
train loss item: 0.35945838689804077
51
train loss item: 1.074734091758728
52
train loss item: 0.15915103256702423
53
train loss item: 0.21116513013839722
54
train loss item: 2.6221797466278076
55
train loss item: 0.2519567012786865
56
train loss item: 0.33411771059036255
57
train loss item: 0.3126453161239624
58
train loss item: 0.2049228399991989
59
train loss item: 0.20154765248298645
60
train loss item: 1.0695714950561523
61
train loss item: 2.571047306060791
62
train loss item: 0.242630735039711
63
train loss item: 0.4166107475757599
64
train loss item: 0.21152804791927338
65
train loss item: 0.6295230388641357
66
train loss item: 0.4487422704696655
67
train loss item: 0.2918448746204376
68
train loss item: 0.35290709137916565
69
train loss item: 0.38559573888778687
70
train loss item: 0.3261766731739044
71
train loss item: 0.19315367937088013
72
train loss item: 0.26301756501197815
73
train loss item: 0.3552144467830658
74
train loss item: 0.14239391684532166
75
train loss item: 0.14232061803340912
76
train loss item: 1.0946272611618042
77
train loss item: 1.4378310441970825
78
train loss item: 0.12322688847780228
79
train loss item: 0.33847975730895996
80
train loss item: 0.1513366550207138
81
train loss item: 0.2308666855096817
82
train loss item: 0.2768087685108185
83
train loss item: 0.6950972080230713
84
train loss item: 0.39441242814064026
85
train loss item: 0.7680115103721619
86
train loss item: 4.805697441101074
87
train loss item: 0.23141565918922424
88
train loss item: 0.3809422254562378
epoch train loss: 0.5808085609185561
testing phase
test loss item: 0.2425144761800766
test loss item: 0.36953434348106384
test loss item: 0.702391505241394
test loss item: 0.34074866771698
test loss item: 0.400704562664032
test loss item: 0.3693374693393707
test loss item: 1.6047214269638062
test loss item: 0.5535365343093872
test loss item: 0.30182215571403503
test loss item: 0.46622657775878906
test loss item: 1.1279726028442383
test loss item: 0.3436901271343231
test loss item: 0.23544204235076904
test loss item: 0.3783043622970581
test loss item: 0.3442925214767456
test loss item: 0.542753279209137
test loss item: 0.32524362206459045
test loss item: 0.5378843545913696
test loss item: 0.7295980453491211
test loss item: 0.3279336988925934
test loss item: 0.8701073527336121
test loss item: 0.42973145842552185
test loss item: 0.3533802330493927
test loss item: 0.27206864953041077
test loss item: 0.33238694071769714
test loss item: 0.2809692919254303
test loss item: 0.41088637709617615
test loss item: 0.32532185316085815
test loss item: 0.4373731017112732
test loss item: 0.40859487652778625
test loss item: 0.9381274580955505
test loss item: 0.5327112674713135
test loss item: 0.27522167563438416
test loss item: 0.6765502691268921
test loss item: 0.5851287841796875
test loss item: 0.5549617409706116
test loss item: 0.8618279099464417
test loss item: 1.9022084474563599
test loss item: 0.577060878276825
test loss item: 0.3913119435310364
test loss item: 0.43585675954818726
test loss item: 0.22795207798480988
test loss item: 0.4208841323852539
test loss item: 0.2824125587940216
test loss item: 0.7152206301689148
test loss item: 0.593702495098114
test loss item: 0.3602046072483063
test loss item: 0.2849975526332855
test loss item: 0.5645005702972412
test loss item: 0.8675161600112915
test loss item: 0.37631353735923767
test loss item: 0.27943697571754456
test loss item: 0.2813950777053833
test loss item: 0.3210108280181885
test loss item: 0.3667265772819519
test loss item: 1.0877907276153564
test loss item: 0.6461650133132935
test loss item: 0.30131110548973083
test loss item: 0.3410389721393585
test loss item: 0.2660478949546814
test loss item: 0.548910915851593
test loss item: 0.3940275013446808
test loss item: 0.2525935769081116
test loss item: 0.29551002383232117
test loss item: 1.0037236213684082
test loss item: 0.42028436064720154
test loss item: 0.35607388615608215
test loss item: 0.3170929253101349
test loss item: 0.7141545414924622
test loss item: 0.5385869741439819
test loss item: 0.38545799255371094
test loss item: 0.9516217112541199
test loss item: 0.37509268522262573
test loss item: 0.41593804955482483
test loss item: 0.24451640248298645
test loss item: 0.23969106376171112
test loss item: 0.32728010416030884
test loss item: 1.9312973022460938
test loss item: 0.53983074426651
test loss item: 0.3343436121940613
test loss item: 0.31489360332489014
test loss item: 1.160757303237915
test loss item: 0.9598540663719177
test loss item: 1.3406567573547363
test loss item: 0.26706889271736145
test loss item: 0.3095749318599701
test loss item: 0.4138340651988983
test loss item: 0.5705482959747314
test loss item: 0.2502743899822235
Epoch [9/100], Training Loss: 0.5808, Testing Loss: 0.5265
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5248295068740845
1
train loss item: 1.4347851276397705
2
train loss item: 0.26269465684890747
3
train loss item: 0.6879634857177734
4
train loss item: 0.5181117057800293
5
train loss item: 0.40478211641311646
6
train loss item: 0.34585192799568176
7
train loss item: 0.9721053838729858
8
train loss item: 0.19618552923202515
9
train loss item: 0.3178766071796417
10
train loss item: 0.41107049584388733
11
train loss item: 0.34449484944343567
12
train loss item: 0.1549699455499649
13
train loss item: 0.5770439505577087
14
train loss item: 0.36042091250419617
15
train loss item: 0.6927936673164368
16
train loss item: 0.12581202387809753
17
train loss item: 0.33480221033096313
18
train loss item: 0.37775835394859314
19
train loss item: 0.3432520627975464
20
train loss item: 0.29117265343666077
21
train loss item: 0.19779179990291595
22
train loss item: 1.0760868787765503
23
train loss item: 1.0659688711166382
24
train loss item: 0.6130269765853882
25
train loss item: 0.2518022954463959
26
train loss item: 0.2555457055568695
27
train loss item: 0.3360038101673126
28
train loss item: 0.12231921404600143
29
train loss item: 0.8174635767936707
30
train loss item: 2.6052162647247314
31
train loss item: 0.65252685546875
32
train loss item: 0.15413986146450043
33
train loss item: 0.4864993989467621
34
train loss item: 0.1958235204219818
35
train loss item: 2.676034927368164
36
train loss item: 0.5228974223136902
37
train loss item: 0.41367360949516296
38
train loss item: 0.4981403052806854
39
train loss item: 0.3173607289791107
40
train loss item: 0.20021800696849823
41
train loss item: 0.34083014726638794
42
train loss item: 0.2850470244884491
43
train loss item: 0.22232207655906677
44
train loss item: 0.7956061363220215
45
train loss item: 0.17727313935756683
46
train loss item: 0.16787058115005493
47
train loss item: 0.3959692418575287
48
train loss item: 0.28605350852012634
49
train loss item: 0.20475980639457703
50
train loss item: 0.3609507977962494
51
train loss item: 1.0067665576934814
52
train loss item: 0.14309647679328918
53
train loss item: 0.20007263123989105
54
train loss item: 2.5584263801574707
55
train loss item: 0.25631842017173767
56
train loss item: 0.32229509949684143
57
train loss item: 0.3171294033527374
58
train loss item: 0.21410219371318817
59
train loss item: 0.18576781451702118
60
train loss item: 0.9972485899925232
61
train loss item: 2.4980804920196533
62
train loss item: 0.2666541039943695
63
train loss item: 0.40292519330978394
64
train loss item: 0.19677278399467468
65
train loss item: 0.6114200949668884
66
train loss item: 0.44322845339775085
67
train loss item: 0.2765415608882904
68
train loss item: 0.3497740626335144
69
train loss item: 0.38033923506736755
70
train loss item: 0.306244820356369
71
train loss item: 0.20073193311691284
72
train loss item: 0.24088522791862488
73
train loss item: 0.3561534285545349
74
train loss item: 0.15549063682556152
75
train loss item: 0.13656459748744965
76
train loss item: 1.0451632738113403
77
train loss item: 1.381029725074768
78
train loss item: 0.12061396986246109
79
train loss item: 0.3366530239582062
80
train loss item: 0.15221266448497772
81
train loss item: 0.25103703141212463
82
train loss item: 0.26475560665130615
83
train loss item: 0.645088791847229
84
train loss item: 0.40388813614845276
85
train loss item: 0.7186697721481323
86
train loss item: 4.717405319213867
87
train loss item: 0.23205703496932983
88
train loss item: 0.3911639451980591
epoch train loss: 0.5624355971813202
testing phase
test loss item: 0.2081131637096405
test loss item: 0.19806954264640808
test loss item: 0.6187737584114075
test loss item: 0.29102036356925964
test loss item: 0.3126610219478607
test loss item: 0.23360416293144226
test loss item: 1.5366567373275757
test loss item: 0.4853909909725189
test loss item: 0.25515085458755493
test loss item: 0.43276315927505493
test loss item: 1.0078922510147095
test loss item: 0.26891931891441345
test loss item: 0.20621442794799805
test loss item: 0.38814207911491394
test loss item: 0.23014582693576813
test loss item: 0.24921511113643646
test loss item: 0.30595067143440247
test loss item: 0.4921885132789612
test loss item: 0.678895890712738
test loss item: 0.3117353618144989
test loss item: 0.7858961820602417
test loss item: 0.4013650417327881
test loss item: 0.32876113057136536
test loss item: 0.2192227840423584
test loss item: 0.2603682279586792
test loss item: 0.2653612792491913
test loss item: 0.38483360409736633
test loss item: 0.2579718232154846
test loss item: 0.3896220922470093
test loss item: 0.38963398337364197
test loss item: 0.841335117816925
test loss item: 0.24232544004917145
test loss item: 0.20090092718601227
test loss item: 0.6227375268936157
test loss item: 0.4732018709182739
test loss item: 0.5105975866317749
test loss item: 0.8095677495002747
test loss item: 1.6865805387496948
test loss item: 0.5346624255180359
test loss item: 0.3319074213504791
test loss item: 0.3417593240737915
test loss item: 0.21327297389507294
test loss item: 0.3805243968963623
test loss item: 0.257308691740036
test loss item: 0.6556626558303833
test loss item: 0.48515084385871887
test loss item: 0.32572200894355774
test loss item: 0.2810596525669098
test loss item: 0.5078450441360474
test loss item: 0.7859396934509277
test loss item: 0.34123775362968445
test loss item: 0.1956005096435547
test loss item: 0.2578631639480591
test loss item: 0.2832411825656891
test loss item: 0.33343762159347534
test loss item: 0.9689782857894897
test loss item: 0.5861067771911621
test loss item: 0.2726684808731079
test loss item: 0.27008822560310364
test loss item: 0.23985055088996887
test loss item: 0.49642473459243774
test loss item: 0.2686035931110382
test loss item: 0.2368537336587906
test loss item: 0.2876656651496887
test loss item: 0.8691298365592957
test loss item: 0.3944358229637146
test loss item: 0.33516502380371094
test loss item: 0.29448938369750977
test loss item: 0.6041241884231567
test loss item: 0.4642869532108307
test loss item: 0.19555698335170746
test loss item: 0.8942440748214722
test loss item: 0.35588082671165466
test loss item: 0.40990567207336426
test loss item: 0.19562625885009766
test loss item: 0.2032623142004013
test loss item: 0.23564766347408295
test loss item: 1.6846054792404175
test loss item: 0.530469536781311
test loss item: 0.2582375109195709
test loss item: 0.18780313432216644
test loss item: 1.0366326570510864
test loss item: 0.8946876525878906
test loss item: 1.1641852855682373
test loss item: 0.26294589042663574
test loss item: 0.2685449719429016
test loss item: 0.21074450016021729
test loss item: 0.2637544572353363
test loss item: 0.2127024233341217
Epoch [10/100], Training Loss: 0.5624, Testing Loss: 0.4534
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 11/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5123652815818787
1
train loss item: 1.3690329790115356
2
train loss item: 0.2587543725967407
3
train loss item: 0.6388407349586487
4
train loss item: 0.4794364273548126
5
train loss item: 0.40230169892311096
6
train loss item: 0.3063432276248932
7
train loss item: 0.9253485202789307
8
train loss item: 0.1698775589466095
9
train loss item: 0.29699382185935974
10
train loss item: 0.3921285569667816
11
train loss item: 0.3346822261810303
12
train loss item: 0.15546055138111115
13
train loss item: 0.5544769167900085
14
train loss item: 0.3434143662452698
15
train loss item: 0.665632426738739
16
train loss item: 0.12292711436748505
17
train loss item: 0.33275142312049866
18
train loss item: 0.3721317648887634
19
train loss item: 0.32170459628105164
20
train loss item: 0.2654482126235962
21
train loss item: 0.18887072801589966
22
train loss item: 1.0425933599472046
23
train loss item: 1.014412760734558
24
train loss item: 0.6060618162155151
25
train loss item: 0.2427358627319336
26
train loss item: 0.2619002163410187
27
train loss item: 0.33387356996536255
28
train loss item: 0.1177884042263031
29
train loss item: 0.7865092158317566
30
train loss item: 2.5142338275909424
31
train loss item: 0.6401506066322327
32
train loss item: 0.14229582250118256
33
train loss item: 0.44871923327445984
34
train loss item: 0.18134845793247223
35
train loss item: 2.605752944946289
36
train loss item: 0.5106983780860901
37
train loss item: 0.4169371724128723
38
train loss item: 0.4983259439468384
39
train loss item: 0.29724210500717163
40
train loss item: 0.18186558783054352
41
train loss item: 0.34056979417800903
42
train loss item: 0.28347963094711304
43
train loss item: 0.2138245552778244
44
train loss item: 0.7608292698860168
45
train loss item: 0.16045653820037842
46
train loss item: 0.15855467319488525
47
train loss item: 0.3789508640766144
48
train loss item: 0.2920096218585968
49
train loss item: 0.18761757016181946
50
train loss item: 0.34512341022491455
51
train loss item: 0.9653012752532959
52
train loss item: 0.13282956182956696
53
train loss item: 0.17233695089817047
54
train loss item: 2.485609531402588
55
train loss item: 0.2299855649471283
56
train loss item: 0.3220829665660858
57
train loss item: 0.31168878078460693
58
train loss item: 0.21063703298568726
59
train loss item: 0.17083708941936493
60
train loss item: 0.9536478519439697
61
train loss item: 2.421983242034912
62
train loss item: 0.2818709909915924
63
train loss item: 0.3823307156562805
64
train loss item: 0.1821526437997818
65
train loss item: 0.6125639081001282
66
train loss item: 0.44556501507759094
67
train loss item: 0.2590852379798889
68
train loss item: 0.33669736981391907
69
train loss item: 0.3727704882621765
70
train loss item: 0.28798699378967285
71
train loss item: 0.19407802820205688
72
train loss item: 0.21099300682544708
73
train loss item: 0.34841668605804443
74
train loss item: 0.13682745397090912
75
train loss item: 0.1344846934080124
76
train loss item: 0.995848536491394
77
train loss item: 1.3503124713897705
78
train loss item: 0.11501243710517883
79
train loss item: 0.3223038911819458
80
train loss item: 0.14304938912391663
81
train loss item: 0.24156230688095093
82
train loss item: 0.2551526129245758
83
train loss item: 0.6232026219367981
84
train loss item: 0.4182448983192444
85
train loss item: 0.6799301505088806
86
train loss item: 4.606853485107422
87
train loss item: 0.19625318050384521
88
train loss item: 0.4008730351924896
epoch train loss: 0.5425297395232018
testing phase
test loss item: 0.19794514775276184
test loss item: 0.13727989792823792
test loss item: 0.5824955701828003
test loss item: 0.24565717577934265
test loss item: 0.2766890823841095
test loss item: 0.19674904644489288
test loss item: 1.5255414247512817
test loss item: 0.4856317341327667
test loss item: 0.2419290542602539
test loss item: 0.43010398745536804
test loss item: 0.927722692489624
test loss item: 0.20845353603363037
test loss item: 0.20470735430717468
test loss item: 0.39188358187675476
test loss item: 0.19415342807769775
test loss item: 0.15477405488491058
test loss item: 0.3037641644477844
test loss item: 0.47775372862815857
test loss item: 0.6666301488876343
test loss item: 0.30997833609580994
test loss item: 0.7563616633415222
test loss item: 0.37597742676734924
test loss item: 0.3218543827533722
test loss item: 0.19484499096870422
test loss item: 0.24702894687652588
test loss item: 0.26067328453063965
test loss item: 0.38115978240966797
test loss item: 0.22841782867908478
test loss item: 0.36741846799850464
test loss item: 0.39820200204849243
test loss item: 0.7813946008682251
test loss item: 0.15045161545276642
test loss item: 0.17235122621059418
test loss item: 0.588207483291626
test loss item: 0.4425903558731079
test loss item: 0.4852491021156311
test loss item: 0.8026238083839417
test loss item: 1.5370969772338867
test loss item: 0.5096042156219482
test loss item: 0.32078078389167786
test loss item: 0.32812735438346863
test loss item: 0.1943158358335495
test loss item: 0.37316158413887024
test loss item: 0.21914419531822205
test loss item: 0.6338117718696594
test loss item: 0.4610394537448883
test loss item: 0.30429282784461975
test loss item: 0.2828768193721771
test loss item: 0.49123919010162354
test loss item: 0.7350594401359558
test loss item: 0.3414248824119568
test loss item: 0.1904596984386444
test loss item: 0.2528643012046814
test loss item: 0.18697766959667206
test loss item: 0.32308635115623474
test loss item: 0.8966279029846191
test loss item: 0.5601392984390259
test loss item: 0.2727746069431305
test loss item: 0.2575339674949646
test loss item: 0.23330329358577728
test loss item: 0.4978371560573578
test loss item: 0.24261894822120667
test loss item: 0.23091840744018555
test loss item: 0.2909444272518158
test loss item: 0.8121833801269531
test loss item: 0.3320457339286804
test loss item: 0.33232179284095764
test loss item: 0.28538721799850464
test loss item: 0.568239152431488
test loss item: 0.4262051284313202
test loss item: 0.12072684615850449
test loss item: 0.9033914804458618
test loss item: 0.33775410056114197
test loss item: 0.41770148277282715
test loss item: 0.165103480219841
test loss item: 0.17207741737365723
test loss item: 0.2058880776166916
test loss item: 1.5172098875045776
test loss item: 0.5208992958068848
test loss item: 0.2335033267736435
test loss item: 0.14125913381576538
test loss item: 0.9659310579299927
test loss item: 0.8722563982009888
test loss item: 1.0493652820587158
test loss item: 0.2743372619152069
test loss item: 0.24327261745929718
test loss item: 0.13569116592407227
test loss item: 0.16474072635173798
test loss item: 0.2128152847290039
Epoch [11/100], Training Loss: 0.5425, Testing Loss: 0.4235
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 12/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.49833446741104126
1
train loss item: 1.3303005695343018
2
train loss item: 0.2560933232307434
3
train loss item: 0.613364040851593
4
train loss item: 0.4811212122440338
5
train loss item: 0.3836899697780609
6
train loss item: 0.28870052099227905
7
train loss item: 0.8925052285194397
8
train loss item: 0.16548961400985718
9
train loss item: 0.28259313106536865
10
train loss item: 0.3832276165485382
11
train loss item: 0.3212198317050934
12
train loss item: 0.1501157134771347
13
train loss item: 0.5491105318069458
14
train loss item: 0.31813085079193115
15
train loss item: 0.6616432070732117
16
train loss item: 0.11579859256744385
17
train loss item: 0.34652334451675415
18
train loss item: 0.36322683095932007
19
train loss item: 0.2962478995323181
20
train loss item: 0.2460484504699707
21
train loss item: 0.18480484187602997
22
train loss item: 1.0452181100845337
23
train loss item: 0.982474684715271
24
train loss item: 0.6035612225532532
25
train loss item: 0.23105944693088531
26
train loss item: 0.2740562856197357
27
train loss item: 0.31047311425209045
28
train loss item: 0.10951151698827744
29
train loss item: 0.7886316776275635
30
train loss item: 2.4493248462677
31
train loss item: 0.6328853368759155
32
train loss item: 0.13431128859519958
33
train loss item: 0.4508541226387024
34
train loss item: 0.17933647334575653
35
train loss item: 2.552471399307251
36
train loss item: 0.49850860238075256
37
train loss item: 0.39929184317588806
38
train loss item: 0.4921709895133972
39
train loss item: 0.2778360843658447
40
train loss item: 0.1834898144006729
41
train loss item: 0.3223375380039215
42
train loss item: 0.27371522784233093
43
train loss item: 0.20807556807994843
44
train loss item: 0.7348858714103699
45
train loss item: 0.15259866416454315
46
train loss item: 0.15646333992481232
47
train loss item: 0.37769630551338196
48
train loss item: 0.27127382159233093
49
train loss item: 0.1918404996395111
50
train loss item: 0.32790616154670715
51
train loss item: 0.9545526504516602
52
train loss item: 0.1411316841840744
53
train loss item: 0.16509132087230682
54
train loss item: 2.431443691253662
55
train loss item: 0.23308050632476807
56
train loss item: 0.314472496509552
57
train loss item: 0.2873608469963074
58
train loss item: 0.20128005743026733
59
train loss item: 0.16452720761299133
60
train loss item: 0.9436159729957581
61
train loss item: 2.369905471801758
62
train loss item: 0.2746528685092926
63
train loss item: 0.37208062410354614
64
train loss item: 0.18369245529174805
65
train loss item: 0.616676390171051
66
train loss item: 0.4398670494556427
67
train loss item: 0.24639679491519928
68
train loss item: 0.3292655050754547
69
train loss item: 0.36260563135147095
70
train loss item: 0.27790337800979614
71
train loss item: 0.18805335462093353
72
train loss item: 0.20032456517219543
73
train loss item: 0.33717596530914307
74
train loss item: 0.1225651279091835
75
train loss item: 0.13611602783203125
76
train loss item: 0.9661290645599365
77
train loss item: 1.3510702848434448
78
train loss item: 0.10798705369234085
79
train loss item: 0.30883464217185974
80
train loss item: 0.1450108289718628
81
train loss item: 0.21019743382930756
82
train loss item: 0.2448732554912567
83
train loss item: 0.6275009512901306
84
train loss item: 0.41599172353744507
85
train loss item: 0.6639044880867004
86
train loss item: 4.523440361022949
87
train loss item: 0.17992562055587769
88
train loss item: 0.39909160137176514
epoch train loss: 0.5300937595494678
testing phase
test loss item: 0.19402894377708435
test loss item: 0.12997645139694214
test loss item: 0.5716665387153625
test loss item: 0.2355535328388214
test loss item: 0.26495909690856934
test loss item: 0.17668747901916504
test loss item: 1.561914324760437
test loss item: 0.5288452506065369
test loss item: 0.23863200843334198
test loss item: 0.4335874021053314
test loss item: 0.8879066109657288
test loss item: 0.19154739379882812
test loss item: 0.21475377678871155
test loss item: 0.38736048340797424
test loss item: 0.19043806195259094
test loss item: 0.13265955448150635
test loss item: 0.3064650297164917
test loss item: 0.47829216718673706
test loss item: 0.678716242313385
test loss item: 0.3115267753601074
test loss item: 0.7520469427108765
test loss item: 0.3791866600513458
test loss item: 0.32683923840522766
test loss item: 0.19209754467010498
test loss item: 0.24499477446079254
test loss item: 0.263814777135849
test loss item: 0.37740597128868103
test loss item: 0.2171468585729599
test loss item: 0.364374577999115
test loss item: 0.4065154790878296
test loss item: 0.7581112384796143
test loss item: 0.12987589836120605
test loss item: 0.1681361347436905
test loss item: 0.5809662342071533
test loss item: 0.4375457465648651
test loss item: 0.47698527574539185
test loss item: 0.8209900259971619
test loss item: 1.4584587812423706
test loss item: 0.5057045221328735
test loss item: 0.31676822900772095
test loss item: 0.3269329071044922
test loss item: 0.19196099042892456
test loss item: 0.3786719739437103
test loss item: 0.21137085556983948
test loss item: 0.6317558884620667
test loss item: 0.4611400067806244
test loss item: 0.3087984621524811
test loss item: 0.2781152129173279
test loss item: 0.4925488531589508
test loss item: 0.7120316624641418
test loss item: 0.3553679287433624
test loss item: 0.19787701964378357
test loss item: 0.2558552920818329
test loss item: 0.15849606692790985
test loss item: 0.32689622044563293
test loss item: 0.8602720499038696
test loss item: 0.5629755258560181
test loss item: 0.3034721910953522
test loss item: 0.264023095369339
test loss item: 0.24091608822345734
test loss item: 0.5048071146011353
test loss item: 0.24653829634189606
test loss item: 0.23300139605998993
test loss item: 0.2945421040058136
test loss item: 0.8010873794555664
test loss item: 0.3163521885871887
test loss item: 0.33945250511169434
test loss item: 0.28653743863105774
test loss item: 0.5619221329689026
test loss item: 0.4235648512840271
test loss item: 0.104702889919281
test loss item: 0.9428268074989319
test loss item: 0.3260344862937927
test loss item: 0.4277234375476837
test loss item: 0.15917161107063293
test loss item: 0.17136573791503906
test loss item: 0.20156735181808472
test loss item: 1.4381372928619385
test loss item: 0.5109464526176453
test loss item: 0.2185589224100113
test loss item: 0.12735329568386078
test loss item: 0.9460206627845764
test loss item: 0.8753387331962585
test loss item: 0.9969172477722168
test loss item: 0.28404948115348816
test loss item: 0.2374732792377472
test loss item: 0.11673001199960709
test loss item: 0.13860474526882172
test loss item: 0.20267628133296967
Epoch [12/100], Training Loss: 0.5301, Testing Loss: 0.4185
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 13/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4786674976348877
1
train loss item: 1.306564211845398
2
train loss item: 0.2593452036380768
3
train loss item: 0.5940048694610596
4
train loss item: 0.4690301716327667
5
train loss item: 0.3592414855957031
6
train loss item: 0.29148778319358826
7
train loss item: 0.8693650960922241
8
train loss item: 0.16644679009914398
9
train loss item: 0.27664247155189514
10
train loss item: 0.3708086907863617
11
train loss item: 0.3064700961112976
12
train loss item: 0.13919620215892792
13
train loss item: 0.5393052697181702
14
train loss item: 0.29985642433166504
15
train loss item: 0.6642366051673889
16
train loss item: 0.10277161002159119
17
train loss item: 0.34205830097198486
18
train loss item: 0.3516216576099396
19
train loss item: 0.2842755615711212
20
train loss item: 0.24562442302703857
21
train loss item: 0.1790558248758316
22
train loss item: 1.0557949542999268
23
train loss item: 0.9634101390838623
24
train loss item: 0.5988480448722839
25
train loss item: 0.23158645629882812
26
train loss item: 0.26235947012901306
27
train loss item: 0.2825986444950104
28
train loss item: 0.09702577441930771
29
train loss item: 0.7962101697921753
30
train loss item: 2.403266429901123
31
train loss item: 0.6159782409667969
32
train loss item: 0.13718228042125702
33
train loss item: 0.4562183618545532
34
train loss item: 0.17837455868721008
35
train loss item: 2.5141592025756836
36
train loss item: 0.47743090987205505
37
train loss item: 0.38704124093055725
38
train loss item: 0.46687981486320496
39
train loss item: 0.26068049669265747
40
train loss item: 0.19533351063728333
41
train loss item: 0.29962846636772156
42
train loss item: 0.26755768060684204
43
train loss item: 0.21004515886306763
44
train loss item: 0.7118398547172546
45
train loss item: 0.15221351385116577
46
train loss item: 0.15087191760540009
47
train loss item: 0.3878282606601715
48
train loss item: 0.2527364194393158
49
train loss item: 0.19694672524929047
50
train loss item: 0.32408490777015686
51
train loss item: 0.953069269657135
52
train loss item: 0.1383458971977234
53
train loss item: 0.17817257344722748
54
train loss item: 2.393482208251953
55
train loss item: 0.24967238306999207
56
train loss item: 0.2980732023715973
57
train loss item: 0.26725584268569946
58
train loss item: 0.19655953347682953
59
train loss item: 0.15426020324230194
60
train loss item: 0.9418643712997437
61
train loss item: 2.3346548080444336
62
train loss item: 0.2645653188228607
63
train loss item: 0.3736870288848877
64
train loss item: 0.188102126121521
65
train loss item: 0.6062149405479431
66
train loss item: 0.41576698422431946
67
train loss item: 0.23666006326675415
68
train loss item: 0.3286359906196594
69
train loss item: 0.35310056805610657
70
train loss item: 0.28158873319625854
71
train loss item: 0.18006756901741028
72
train loss item: 0.1965351700782776
73
train loss item: 0.32727479934692383
74
train loss item: 0.11710938066244125
75
train loss item: 0.1326652616262436
76
train loss item: 0.9498312473297119
77
train loss item: 1.3630610704421997
78
train loss item: 0.10020049661397934
79
train loss item: 0.3010464310646057
80
train loss item: 0.15024273097515106
81
train loss item: 0.2020156979560852
82
train loss item: 0.2451367974281311
83
train loss item: 0.6346476078033447
84
train loss item: 0.40016624331474304
85
train loss item: 0.6490973830223083
86
train loss item: 4.46697473526001
87
train loss item: 0.19056768715381622
88
train loss item: 0.3863535523414612
epoch train loss: 0.5210891433813599
testing phase
test loss item: 0.18804481625556946
test loss item: 0.1423303335905075
test loss item: 0.5690496563911438
test loss item: 0.2379433661699295
test loss item: 0.2730867862701416
test loss item: 0.17758096754550934
test loss item: 1.5522270202636719
test loss item: 0.5246695876121521
test loss item: 0.2316741645336151
test loss item: 0.4254428446292877
test loss item: 0.8760364651679993
test loss item: 0.19300857186317444
test loss item: 0.21112392842769623
test loss item: 0.3768777549266815
test loss item: 0.1990119218826294
test loss item: 0.13379627466201782
test loss item: 0.30370426177978516
test loss item: 0.4780329465866089
test loss item: 0.668286144733429
test loss item: 0.3047899007797241
test loss item: 0.7588523626327515
test loss item: 0.38098418712615967
test loss item: 0.32979515194892883
test loss item: 0.19478969275951385
test loss item: 0.24053972959518433
test loss item: 0.2586526870727539
test loss item: 0.36671388149261475
test loss item: 0.22325171530246735
test loss item: 0.3686828315258026
test loss item: 0.3937934935092926
test loss item: 0.7496753931045532
test loss item: 0.12829023599624634
test loss item: 0.17147250473499298
test loss item: 0.5824422836303711
test loss item: 0.43639376759529114
test loss item: 0.466123104095459
test loss item: 0.8121260404586792
test loss item: 1.4390348196029663
test loss item: 0.5045530200004578
test loss item: 0.3148980140686035
test loss item: 0.32291895151138306
test loss item: 0.188913494348526
test loss item: 0.3802575170993805
test loss item: 0.2117169201374054
test loss item: 0.6363735198974609
test loss item: 0.4571232795715332
test loss item: 0.31770333647727966
test loss item: 0.26377642154693604
test loss item: 0.49041101336479187
test loss item: 0.7012403607368469
test loss item: 0.35845887660980225
test loss item: 0.17967402935028076
test loss item: 0.25310760736465454
test loss item: 0.1696283221244812
test loss item: 0.3266962170600891
test loss item: 0.8507899641990662
test loss item: 0.5566427707672119
test loss item: 0.3271796703338623
test loss item: 0.2617373764514923
test loss item: 0.2425588071346283
test loss item: 0.4964700937271118
test loss item: 0.24568159878253937
test loss item: 0.22756697237491608
test loss item: 0.2908358871936798
test loss item: 0.7960110902786255
test loss item: 0.3182377219200134
test loss item: 0.33783552050590515
test loss item: 0.2866946756839752
test loss item: 0.5625922679901123
test loss item: 0.4143865704536438
test loss item: 0.11434603482484818
test loss item: 0.9343523383140564
test loss item: 0.3234015107154846
test loss item: 0.42400532960891724
test loss item: 0.16015402972698212
test loss item: 0.17711135745048523
test loss item: 0.20398257672786713
test loss item: 1.4251186847686768
test loss item: 0.5013182163238525
test loss item: 0.2179032415151596
test loss item: 0.12548500299453735
test loss item: 0.9340231418609619
test loss item: 0.8649967908859253
test loss item: 0.9850152134895325
test loss item: 0.2753259241580963
test loss item: 0.23799291253089905
test loss item: 0.11658994108438492
test loss item: 0.13374540209770203
test loss item: 0.18271268904209137
Epoch [13/100], Training Loss: 0.5211, Testing Loss: 0.4157
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 14/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45918893814086914
1
train loss item: 1.2836228609085083
2
train loss item: 0.24718473851680756
3
train loss item: 0.5751398205757141
4
train loss item: 0.4350069463253021
5
train loss item: 0.340617835521698
6
train loss item: 0.2778984308242798
7
train loss item: 0.8495064973831177
8
train loss item: 0.15068942308425903
9
train loss item: 0.26765573024749756
10
train loss item: 0.3568853437900543
11
train loss item: 0.2926076650619507
12
train loss item: 0.1295720487833023
13
train loss item: 0.5200155973434448
14
train loss item: 0.28133463859558105
15
train loss item: 0.6567124724388123
16
train loss item: 0.08386076241731644
17
train loss item: 0.3146308660507202
18
train loss item: 0.3389701843261719
19
train loss item: 0.2770211398601532
20
train loss item: 0.23831751942634583
21
train loss item: 0.15559813380241394
22
train loss item: 1.051973819732666
23
train loss item: 0.9507569074630737
24
train loss item: 0.5880767107009888
25
train loss item: 0.22062407433986664
26
train loss item: 0.22848767042160034
27
train loss item: 0.2579261362552643
28
train loss item: 0.08011943846940994
29
train loss item: 0.7864688634872437
30
train loss item: 2.3659658432006836
31
train loss item: 0.5947364568710327
32
train loss item: 0.13405022025108337
33
train loss item: 0.44532111287117004
34
train loss item: 0.16018417477607727
35
train loss item: 2.4837167263031006
36
train loss item: 0.455759733915329
37
train loss item: 0.3875757157802582
38
train loss item: 0.43993180990219116
39
train loss item: 0.24676679074764252
40
train loss item: 0.18080861866474152
41
train loss item: 0.27873095870018005
42
train loss item: 0.2656467854976654
43
train loss item: 0.20169487595558167
44
train loss item: 0.6918095350265503
45
train loss item: 0.14743517339229584
46
train loss item: 0.1314847618341446
47
train loss item: 0.3873908817768097
48
train loss item: 0.23951426148414612
49
train loss item: 0.18122458457946777
50
train loss item: 0.3198333978652954
51
train loss item: 0.9447899460792542
52
train loss item: 0.11235155910253525
53
train loss item: 0.16821321845054626
54
train loss item: 2.364572048187256
55
train loss item: 0.23277698457241058
56
train loss item: 0.27457478642463684
57
train loss item: 0.25539514422416687
58
train loss item: 0.18534299731254578
59
train loss item: 0.13547490537166595
60
train loss item: 0.9294266700744629
61
train loss item: 2.3073761463165283
62
train loss item: 0.2531006634235382
63
train loss item: 0.3757057189941406
64
train loss item: 0.17580829560756683
65
train loss item: 0.581342875957489
66
train loss item: 0.3944733738899231
67
train loss item: 0.2258872091770172
68
train loss item: 0.3214765787124634
69
train loss item: 0.34228289127349854
70
train loss item: 0.28111347556114197
71
train loss item: 0.16298039257526398
72
train loss item: 0.18661057949066162
73
train loss item: 0.3134826421737671
74
train loss item: 0.11139001697301865
75
train loss item: 0.12048851698637009
76
train loss item: 0.937389612197876
77
train loss item: 1.3656859397888184
78
train loss item: 0.08680517971515656
79
train loss item: 0.2964363992214203
80
train loss item: 0.14116209745407104
81
train loss item: 0.1960214227437973
82
train loss item: 0.2343258559703827
83
train loss item: 0.6318908333778381
84
train loss item: 0.39066505432128906
85
train loss item: 0.6263948082923889
86
train loss item: 4.426102161407471
87
train loss item: 0.17947471141815186
88
train loss item: 0.37466439604759216
epoch train loss: 0.506511345422
testing phase
test loss item: 0.18403910100460052
test loss item: 0.1484271138906479
test loss item: 0.5701863765716553
test loss item: 0.24897001683712006
test loss item: 0.27848100662231445
test loss item: 0.1742822825908661
test loss item: 1.4757965803146362
test loss item: 0.44975942373275757
test loss item: 0.22645466029644012
test loss item: 0.4127286672592163
test loss item: 0.88206547498703
test loss item: 0.20436426997184753
test loss item: 0.20179304480552673
test loss item: 0.3573664426803589
test loss item: 0.20414961874485016
test loss item: 0.12988753616809845
test loss item: 0.2969244122505188
test loss item: 0.47442519664764404
test loss item: 0.6231599450111389
test loss item: 0.29242977499961853
test loss item: 0.757746696472168
test loss item: 0.3791596591472626
test loss item: 0.31947770714759827
test loss item: 0.1971999853849411
test loss item: 0.23251688480377197
test loss item: 0.24981547892093658
test loss item: 0.35625919699668884
test loss item: 0.22673507034778595
test loss item: 0.36832934617996216
test loss item: 0.37557122111320496
test loss item: 0.7436042428016663
test loss item: 0.12787923216819763
test loss item: 0.17484985291957855
test loss item: 0.5861554741859436
test loss item: 0.43273088335990906
test loss item: 0.45266231894493103
test loss item: 0.7659470438957214
test loss item: 1.4581290483474731
test loss item: 0.5026366710662842
test loss item: 0.30709993839263916
test loss item: 0.31545770168304443
test loss item: 0.17831389605998993
test loss item: 0.3740222156047821
test loss item: 0.22089266777038574
test loss item: 0.6314566731452942
test loss item: 0.44052547216415405
test loss item: 0.31365883350372314
test loss item: 0.25001299381256104
test loss item: 0.48255693912506104
test loss item: 0.696151077747345
test loss item: 0.3472828269004822
test loss item: 0.1579674929380417
test loss item: 0.24657286703586578
test loss item: 0.20779360830783844
test loss item: 0.31942734122276306
test loss item: 0.8577413558959961
test loss item: 0.5329227447509766
test loss item: 0.31184685230255127
test loss item: 0.2519937753677368
test loss item: 0.23493418097496033
test loss item: 0.4806840121746063
test loss item: 0.23711423575878143
test loss item: 0.21710637211799622
test loss item: 0.27981117367744446
test loss item: 0.7836898565292358
test loss item: 0.3373579978942871
test loss item: 0.3313984274864197
test loss item: 0.28092923760414124
test loss item: 0.5596953630447388
test loss item: 0.38014841079711914
test loss item: 0.12071548402309418
test loss item: 0.8642764091491699
test loss item: 0.3216630220413208
test loss item: 0.4092830419540405
test loss item: 0.16097788512706757
test loss item: 0.17290709912776947
test loss item: 0.20411767065525055
test loss item: 1.449654459953308
test loss item: 0.48785632848739624
test loss item: 0.21455232799053192
test loss item: 0.1218404695391655
test loss item: 0.9157609343528748
test loss item: 0.8324825763702393
test loss item: 0.998673677444458
test loss item: 0.2549437880516052
test loss item: 0.24174168705940247
test loss item: 0.11200869083404541
test loss item: 0.12271092087030411
test loss item: 0.1679159551858902
Epoch [14/100], Training Loss: 0.5065, Testing Loss: 0.4077
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 15/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4473196864128113
1
train loss item: 1.2545645236968994
2
train loss item: 0.23177091777324677
3
train loss item: 0.5624193549156189
4
train loss item: 0.424691379070282
5
train loss item: 0.3347819447517395
6
train loss item: 0.27085772156715393
7
train loss item: 0.8302279114723206
8
train loss item: 0.13916990160942078
9
train loss item: 0.25638318061828613
10
train loss item: 0.35071414709091187
11
train loss item: 0.288695752620697
12
train loss item: 0.1342693418264389
13
train loss item: 0.5020378232002258
14
train loss item: 0.2645169794559479
15
train loss item: 0.6368269324302673
16
train loss item: 0.08203846961259842
17
train loss item: 0.28725168108940125
18
train loss item: 0.32819297909736633
19
train loss item: 0.2788366973400116
20
train loss item: 0.23073774576187134
21
train loss item: 0.14569173753261566
22
train loss item: 1.025895595550537
23
train loss item: 0.9427366256713867
24
train loss item: 0.5751320719718933
25
train loss item: 0.21013197302818298
26
train loss item: 0.20901177823543549
27
train loss item: 0.24010348320007324
28
train loss item: 0.07986767590045929
29
train loss item: 0.7582225203514099
30
train loss item: 2.3321657180786133
31
train loss item: 0.5823222994804382
32
train loss item: 0.12861527502536774
33
train loss item: 0.43305647373199463
34
train loss item: 0.16041173040866852
35
train loss item: 2.4564571380615234
36
train loss item: 0.44265469908714294
37
train loss item: 0.39927953481674194
38
train loss item: 0.42999494075775146
39
train loss item: 0.23655591905117035
40
train loss item: 0.1698177605867386
41
train loss item: 0.2623911499977112
42
train loss item: 0.26951298117637634
43
train loss item: 0.1929260939359665
44
train loss item: 0.6752143502235413
45
train loss item: 0.1441110521554947
46
train loss item: 0.12004120647907257
47
train loss item: 0.3768748342990875
48
train loss item: 0.22924314439296722
49
train loss item: 0.1682889759540558
50
train loss item: 0.30998730659484863
51
train loss item: 0.9278894066810608
52
train loss item: 0.08607835322618484
53
train loss item: 0.16218675673007965
54
train loss item: 2.339623212814331
55
train loss item: 0.21342617273330688
56
train loss item: 0.25609639286994934
57
train loss item: 0.2513728141784668
58
train loss item: 0.17796717584133148
59
train loss item: 0.12312137335538864
60
train loss item: 0.9030113816261292
61
train loss item: 2.2846107482910156
62
train loss item: 0.2413981854915619
63
train loss item: 0.3757813274860382
64
train loss item: 0.1670142263174057
65
train loss item: 0.5527905821800232
66
train loss item: 0.3910748064517975
67
train loss item: 0.22300347685813904
68
train loss item: 0.3093530535697937
69
train loss item: 0.3344486951828003
70
train loss item: 0.2776038646697998
71
train loss item: 0.15232990682125092
72
train loss item: 0.18191371858119965
73
train loss item: 0.3033839464187622
74
train loss item: 0.11650200933218002
75
train loss item: 0.11591681838035583
76
train loss item: 0.925003707408905
77
train loss item: 1.3535710573196411
78
train loss item: 0.08660639822483063
79
train loss item: 0.29773274064064026
80
train loss item: 0.13299815356731415
81
train loss item: 0.1978553980588913
82
train loss item: 0.21769419312477112
83
train loss item: 0.6207811832427979
84
train loss item: 0.3953973650932312
85
train loss item: 0.6042669415473938
86
train loss item: 4.391199588775635
87
train loss item: 0.17579367756843567
88
train loss item: 0.37479349970817566
epoch train loss: 0.4953327351406719
testing phase
test loss item: 0.17853711545467377
test loss item: 0.13444052636623383
test loss item: 0.5697702169418335
test loss item: 0.2520030438899994
test loss item: 0.2677278220653534
test loss item: 0.1573498696088791
test loss item: 1.4068697690963745
test loss item: 0.3864237368106842
test loss item: 0.2198103666305542
test loss item: 0.4021907150745392
test loss item: 0.8906673192977905
test loss item: 0.20743528008460999
test loss item: 0.19627448916435242
test loss item: 0.33814263343811035
test loss item: 0.19201108813285828
test loss item: 0.11809379607439041
test loss item: 0.29418686032295227
test loss item: 0.4661654233932495
test loss item: 0.5931261777877808
test loss item: 0.28369006514549255
test loss item: 0.7408790588378906
test loss item: 0.3769323229789734
test loss item: 0.3023996651172638
test loss item: 0.1882036030292511
test loss item: 0.22676250338554382
test loss item: 0.24161523580551147
test loss item: 0.3466092646121979
test loss item: 0.214641734957695
test loss item: 0.354861319065094
test loss item: 0.36400970816612244
test loss item: 0.7397197484970093
test loss item: 0.11989365518093109
test loss item: 0.165959894657135
test loss item: 0.5841007232666016
test loss item: 0.4245847463607788
test loss item: 0.4505523145198822
test loss item: 0.7281216382980347
test loss item: 1.4807225465774536
test loss item: 0.4944241940975189
test loss item: 0.29149535298347473
test loss item: 0.30952170491218567
test loss item: 0.17322693765163422
test loss item: 0.364952027797699
test loss item: 0.22793187201023102
test loss item: 0.6133552193641663
test loss item: 0.4229867458343506
test loss item: 0.30268433690071106
test loss item: 0.24498048424720764
test loss item: 0.4739578366279602
test loss item: 0.6972958445549011
test loss item: 0.32744812965393066
test loss item: 0.15191297233104706
test loss item: 0.24069449305534363
test loss item: 0.2282739281654358
test loss item: 0.3072853088378906
test loss item: 0.8615310192108154
test loss item: 0.5180269479751587
test loss item: 0.2751699686050415
test loss item: 0.24418886005878448
test loss item: 0.22347140312194824
test loss item: 0.4664039611816406
test loss item: 0.23384183645248413
test loss item: 0.21095602214336395
test loss item: 0.26857197284698486
test loss item: 0.770389199256897
test loss item: 0.34947317838668823
test loss item: 0.32759514451026917
test loss item: 0.2708784341812134
test loss item: 0.5517417192459106
test loss item: 0.37282830476760864
test loss item: 0.10830414295196533
test loss item: 0.8016299605369568
test loss item: 0.3200436532497406
test loss item: 0.3961401879787445
test loss item: 0.15985994040966034
test loss item: 0.16523043811321259
test loss item: 0.19311724603176117
test loss item: 1.4689228534698486
test loss item: 0.47464606165885925
test loss item: 0.2037181854248047
test loss item: 0.1073027104139328
test loss item: 0.9091289043426514
test loss item: 0.8094527125358582
test loss item: 1.0134133100509644
test loss item: 0.2367708384990692
test loss item: 0.24498538672924042
test loss item: 0.09863202273845673
test loss item: 0.108912892639637
test loss item: 0.1617375612258911
Epoch [15/100], Training Loss: 0.4953, Testing Loss: 0.3978
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 16/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.44363638758659363
1
train loss item: 1.2234601974487305
2
train loss item: 0.22555367648601532
3
train loss item: 0.5536231398582458
4
train loss item: 0.43453946709632874
5
train loss item: 0.33521780371665955
6
train loss item: 0.2770938277244568
7
train loss item: 0.811414361000061
8
train loss item: 0.1334514617919922
9
train loss item: 0.2529667317867279
10
train loss item: 0.3505399823188782
11
train loss item: 0.29183170199394226
12
train loss item: 0.14124226570129395
13
train loss item: 0.4888868033885956
14
train loss item: 0.2508033215999603
15
train loss item: 0.6191627383232117
16
train loss item: 0.0906086340546608
17
train loss item: 0.2813085913658142
18
train loss item: 0.3226020932197571
19
train loss item: 0.28445854783058167
20
train loss item: 0.23577052354812622
21
train loss item: 0.14903278648853302
22
train loss item: 0.9939418435096741
23
train loss item: 0.9329277276992798
24
train loss item: 0.5666717886924744
25
train loss item: 0.21135063469409943
26
train loss item: 0.2091846466064453
27
train loss item: 0.22952520847320557
28
train loss item: 0.08737614005804062
29
train loss item: 0.7311697006225586
30
train loss item: 2.3000144958496094
31
train loss item: 0.5764925479888916
32
train loss item: 0.11900613456964493
33
train loss item: 0.4224812686443329
34
train loss item: 0.1766267865896225
35
train loss item: 2.4299285411834717
36
train loss item: 0.43787986040115356
37
train loss item: 0.41199877858161926
38
train loss item: 0.4360898435115814
39
train loss item: 0.2280084639787674
40
train loss item: 0.17637883126735687
41
train loss item: 0.25334829092025757
42
train loss item: 0.2755627930164337
43
train loss item: 0.18846477568149567
44
train loss item: 0.6598522067070007
45
train loss item: 0.1388724446296692
46
train loss item: 0.11843431740999222
47
train loss item: 0.3666413426399231
48
train loss item: 0.22342102229595184
49
train loss item: 0.1629854440689087
50
train loss item: 0.3015003800392151
51
train loss item: 0.9115359783172607
52
train loss item: 0.08060355484485626
53
train loss item: 0.1653306484222412
54
train loss item: 2.3148772716522217
55
train loss item: 0.21199077367782593
56
train loss item: 0.24804428219795227
57
train loss item: 0.24865929782390594
58
train loss item: 0.1756119728088379
59
train loss item: 0.1199721246957779
60
train loss item: 0.8749993443489075
61
train loss item: 2.261009693145752
62
train loss item: 0.23137980699539185
63
train loss item: 0.3748140037059784
64
train loss item: 0.16676753759384155
65
train loss item: 0.5346808433532715
66
train loss item: 0.39652949571609497
67
train loss item: 0.22310957312583923
68
train loss item: 0.2993336021900177
69
train loss item: 0.3313390016555786
70
train loss item: 0.27671703696250916
71
train loss item: 0.15000081062316895
72
train loss item: 0.1783258616924286
73
train loss item: 0.3021039664745331
74
train loss item: 0.11340732127428055
75
train loss item: 0.11722344905138016
76
train loss item: 0.9093571901321411
77
train loss item: 1.3382073640823364
78
train loss item: 0.09201084822416306
79
train loss item: 0.3007946014404297
80
train loss item: 0.1251685470342636
81
train loss item: 0.20983749628067017
82
train loss item: 0.20607459545135498
83
train loss item: 0.6099333763122559
84
train loss item: 0.40495380759239197
85
train loss item: 0.5892690420150757
86
train loss item: 4.3553009033203125
87
train loss item: 0.18216992914676666
88
train loss item: 0.38468411564826965
epoch train loss: 0.48965697049090035
testing phase
test loss item: 0.177863210439682
test loss item: 0.11513277888298035
test loss item: 0.5607450008392334
test loss item: 0.23919978737831116
test loss item: 0.2510773539543152
test loss item: 0.1397779881954193
test loss item: 1.3836325407028198
test loss item: 0.3863307535648346
test loss item: 0.21176102757453918
test loss item: 0.3930239975452423
test loss item: 0.8737178444862366
test loss item: 0.18795377016067505
test loss item: 0.19378644227981567
test loss item: 0.32850325107574463
test loss item: 0.17425650358200073
test loss item: 0.10270952433347702
test loss item: 0.2965267598628998
test loss item: 0.4540393054485321
test loss item: 0.5884522199630737
test loss item: 0.2810806930065155
test loss item: 0.716772735118866
test loss item: 0.37130022048950195
test loss item: 0.28893139958381653
test loss item: 0.17913900315761566
test loss item: 0.2234487682580948
test loss item: 0.23452703654766083
test loss item: 0.33943045139312744
test loss item: 0.1973395049571991
test loss item: 0.33707141876220703
test loss item: 0.35732805728912354
test loss item: 0.7240968346595764
test loss item: 0.1020750105381012
test loss item: 0.1583695262670517
test loss item: 0.5699732899665833
test loss item: 0.41209763288497925
test loss item: 0.4289450943470001
test loss item: 0.7171913981437683
test loss item: 1.4568430185317993
test loss item: 0.47641119360923767
test loss item: 0.27903425693511963
test loss item: 0.306739866733551
test loss item: 0.1746993213891983
test loss item: 0.35656166076660156
test loss item: 0.21768426895141602
test loss item: 0.5909709930419922
test loss item: 0.4163654148578644
test loss item: 0.29362571239471436
test loss item: 0.2443181425333023
test loss item: 0.4657948613166809
test loss item: 0.6850652098655701
test loss item: 0.30679863691329956
test loss item: 0.1530485302209854
test loss item: 0.2348160296678543
test loss item: 0.19947722554206848
test loss item: 0.29313763976097107
test loss item: 0.8386333584785461
test loss item: 0.5103219151496887
test loss item: 0.2514640688896179
test loss item: 0.24175511300563812
test loss item: 0.2125520557165146
test loss item: 0.4546099901199341
test loss item: 0.23975451290607452
test loss item: 0.2119765430688858
test loss item: 0.26207199692726135
test loss item: 0.7510258555412292
test loss item: 0.33029869198799133
test loss item: 0.3278360962867737
test loss item: 0.26311710476875305
test loss item: 0.5394567251205444
test loss item: 0.36969849467277527
test loss item: 0.08649715781211853
test loss item: 0.7893864512443542
test loss item: 0.3191329836845398
test loss item: 0.392598956823349
test loss item: 0.1593049019575119
test loss item: 0.162811741232872
test loss item: 0.18177559971809387
test loss item: 1.440283179283142
test loss item: 0.46501684188842773
test loss item: 0.19423729181289673
test loss item: 0.09619645774364471
test loss item: 0.8971507549285889
test loss item: 0.7956821918487549
test loss item: 0.9926247596740723
test loss item: 0.2267395257949829
test loss item: 0.2425791621208191
test loss item: 0.09167207777500153
test loss item: 0.09832713007926941
test loss item: 0.16146206855773926
Epoch [16/100], Training Loss: 0.4897, Testing Loss: 0.3870
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 17/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4366638958454132
1
train loss item: 1.197843074798584
2
train loss item: 0.22529740631580353
3
train loss item: 0.5378106832504272
4
train loss item: 0.4147859811782837
5
train loss item: 0.3274303078651428
6
train loss item: 0.276743084192276
7
train loss item: 0.7924052476882935
8
train loss item: 0.1271401196718216
9
train loss item: 0.25129419565200806
10
train loss item: 0.34312763810157776
11
train loss item: 0.2877536118030548
12
train loss item: 0.13820745050907135
13
train loss item: 0.47471946477890015
14
train loss item: 0.23796935379505157
15
train loss item: 0.6125990748405457
16
train loss item: 0.0929488092660904
17
train loss item: 0.28415584564208984
18
train loss item: 0.3164084851741791
19
train loss item: 0.28231269121170044
20
train loss item: 0.2382020503282547
21
train loss item: 0.1419064998626709
22
train loss item: 0.9776265621185303
23
train loss item: 0.9134973883628845
24
train loss item: 0.5595595240592957
25
train loss item: 0.2022017240524292
26
train loss item: 0.20040956139564514
27
train loss item: 0.22136960923671722
28
train loss item: 0.08780965954065323
29
train loss item: 0.7189124822616577
30
train loss item: 2.2673070430755615
31
train loss item: 0.5644242167472839
32
train loss item: 0.1053696870803833
33
train loss item: 0.40957167744636536
34
train loss item: 0.16972008347511292
35
train loss item: 2.4028921127319336
36
train loss item: 0.4312320053577423
37
train loss item: 0.4122551679611206
38
train loss item: 0.43458861112594604
39
train loss item: 0.21883097290992737
40
train loss item: 0.1736224889755249
41
train loss item: 0.2469377964735031
42
train loss item: 0.27592623233795166
43
train loss item: 0.18278944492340088
44
train loss item: 0.643157958984375
45
train loss item: 0.12625068426132202
46
train loss item: 0.11387300491333008
47
train loss item: 0.35922548174858093
48
train loss item: 0.21840877830982208
49
train loss item: 0.15393823385238647
50
train loss item: 0.29477593302726746
51
train loss item: 0.8996672630310059
52
train loss item: 0.08921709656715393
53
train loss item: 0.15357822179794312
54
train loss item: 2.2879738807678223
55
train loss item: 0.20832034945487976
56
train loss item: 0.24086230993270874
57
train loss item: 0.2409176230430603
58
train loss item: 0.16954617202281952
59
train loss item: 0.11731193959712982
60
train loss item: 0.8574489951133728
61
train loss item: 2.231877088546753
62
train loss item: 0.2227070927619934
63
train loss item: 0.37179064750671387
64
train loss item: 0.16404283046722412
65
train loss item: 0.5260545611381531
66
train loss item: 0.3927144408226013
67
train loss item: 0.21522685885429382
68
train loss item: 0.2943854033946991
69
train loss item: 0.3261343538761139
70
train loss item: 0.2708817422389984
71
train loss item: 0.15071700513362885
72
train loss item: 0.16989636421203613
73
train loss item: 0.29978522658348083
74
train loss item: 0.09449274837970734
75
train loss item: 0.11463886499404907
76
train loss item: 0.8882274031639099
77
train loss item: 1.331472635269165
78
train loss item: 0.08973798155784607
79
train loss item: 0.29462501406669617
80
train loss item: 0.11124818027019501
81
train loss item: 0.20496860146522522
82
train loss item: 0.19806842505931854
83
train loss item: 0.6041463017463684
84
train loss item: 0.4050963521003723
85
train loss item: 0.5723462104797363
86
train loss item: 4.3153510093688965
87
train loss item: 0.16795450448989868
88
train loss item: 0.39054998755455017
epoch train loss: 0.480990907700544
testing phase
test loss item: 0.18238741159439087
test loss item: 0.11399554461240768
test loss item: 0.5481221675872803
test loss item: 0.22866380214691162
test loss item: 0.243124857544899
test loss item: 0.13355600833892822
test loss item: 1.4020297527313232
test loss item: 0.43318888545036316
test loss item: 0.20789426565170288
test loss item: 0.38710108399391174
test loss item: 0.842759370803833
test loss item: 0.16506949067115784
test loss item: 0.1887156367301941
test loss item: 0.3193768858909607
test loss item: 0.17256787419319153
test loss item: 0.09518064558506012
test loss item: 0.2963367700576782
test loss item: 0.44516146183013916
test loss item: 0.602202296257019
test loss item: 0.27561870217323303
test loss item: 0.6971915364265442
test loss item: 0.36614713072776794
test loss item: 0.27625375986099243
test loss item: 0.18212354183197021
test loss item: 0.2208559364080429
test loss item: 0.23073790967464447
test loss item: 0.3349018096923828
test loss item: 0.19016137719154358
test loss item: 0.3278796076774597
test loss item: 0.35277339816093445
test loss item: 0.7064369916915894
test loss item: 0.09010008722543716
test loss item: 0.16524194180965424
test loss item: 0.5547662377357483
test loss item: 0.4023861289024353
test loss item: 0.4052676558494568
test loss item: 0.7292435765266418
test loss item: 1.405637264251709
test loss item: 0.45998042821884155
test loss item: 0.2759688198566437
test loss item: 0.3050348162651062
test loss item: 0.17184005677700043
test loss item: 0.3529527187347412
test loss item: 0.20189829170703888
test loss item: 0.5732019543647766
test loss item: 0.41423144936561584
test loss item: 0.2840707302093506
test loss item: 0.23852665722370148
test loss item: 0.4596809148788452
test loss item: 0.6690424680709839
test loss item: 0.29571858048439026
test loss item: 0.15003472566604614
test loss item: 0.23059074580669403
test loss item: 0.15378065407276154
test loss item: 0.2845779061317444
test loss item: 0.8052603602409363
test loss item: 0.5140092968940735
test loss item: 0.2448589950799942
test loss item: 0.24136357009410858
test loss item: 0.20692594349384308
test loss item: 0.45023319125175476
test loss item: 0.24462652206420898
test loss item: 0.21348008513450623
test loss item: 0.2581883370876312
test loss item: 0.7340138554573059
test loss item: 0.3045552372932434
test loss item: 0.32558247447013855
test loss item: 0.25924816727638245
test loss item: 0.527254045009613
test loss item: 0.3692021071910858
test loss item: 0.07783879339694977
test loss item: 0.8170253038406372
test loss item: 0.3102131187915802
test loss item: 0.390521764755249
test loss item: 0.15644954144954681
test loss item: 0.1586257815361023
test loss item: 0.18273060023784637
test loss item: 1.383838176727295
test loss item: 0.4499775171279907
test loss item: 0.18965251743793488
test loss item: 0.10052447021007538
test loss item: 0.8849273920059204
test loss item: 0.7940348982810974
test loss item: 0.9512173533439636
test loss item: 0.22210444509983063
test loss item: 0.23399804532527924
test loss item: 0.09874849766492844
test loss item: 0.09870617091655731
test loss item: 0.17032888531684875
Epoch [17/100], Training Loss: 0.4810, Testing Loss: 0.3799
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 18/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4262981414794922
1
train loss item: 1.1776529550552368
2
train loss item: 0.22743920981884003
3
train loss item: 0.5183477401733398
4
train loss item: 0.3957895040512085
5
train loss item: 0.31403103470802307
6
train loss item: 0.262953519821167
7
train loss item: 0.7747655510902405
8
train loss item: 0.13089270889759064
9
train loss item: 0.2451736181974411
10
train loss item: 0.33031177520751953
11
train loss item: 0.27780812978744507
12
train loss item: 0.1306387037038803
13
train loss item: 0.46164533495903015
14
train loss item: 0.2301425337791443
15
train loss item: 0.6123236417770386
16
train loss item: 0.09576097130775452
17
train loss item: 0.2856474220752716
18
train loss item: 0.3092009723186493
19
train loss item: 0.27329301834106445
20
train loss item: 0.23181676864624023
21
train loss item: 0.13390418887138367
22
train loss item: 0.9727742671966553
23
train loss item: 0.8899762034416199
24
train loss item: 0.5489933490753174
25
train loss item: 0.19189727306365967
26
train loss item: 0.18529058992862701
27
train loss item: 0.21451787650585175
28
train loss item: 0.08972897380590439
29
train loss item: 0.7168521881103516
30
train loss item: 2.2351272106170654
31
train loss item: 0.5490198731422424
32
train loss item: 0.09685631841421127
33
train loss item: 0.403408020734787
34
train loss item: 0.16087408363819122
35
train loss item: 2.3763365745544434
36
train loss item: 0.42096149921417236
37
train loss item: 0.4036487936973572
38
train loss item: 0.42236897349357605
39
train loss item: 0.21224157512187958
40
train loss item: 0.17197953164577484
41
train loss item: 0.24126121401786804
42
train loss item: 0.27099063992500305
43
train loss item: 0.17738878726959229
44
train loss item: 0.6273206472396851
45
train loss item: 0.11679742485284805
46
train loss item: 0.10755547136068344
47
train loss item: 0.35630759596824646
48
train loss item: 0.21105434000492096
49
train loss item: 0.1471274346113205
50
train loss item: 0.28953617811203003
51
train loss item: 0.8902939558029175
52
train loss item: 0.09824545681476593
53
train loss item: 0.1461273729801178
54
train loss item: 2.260432004928589
55
train loss item: 0.19929270446300507
56
train loss item: 0.23348575830459595
57
train loss item: 0.2301606684923172
58
train loss item: 0.16005335748195648
59
train loss item: 0.11388082802295685
60
train loss item: 0.8489227890968323
61
train loss item: 2.201129198074341
62
train loss item: 0.21511805057525635
63
train loss item: 0.36784783005714417
64
train loss item: 0.16179658472537994
65
train loss item: 0.5209292769432068
66
train loss item: 0.3803030252456665
67
train loss item: 0.20467345416545868
68
train loss item: 0.2940838932991028
69
train loss item: 0.3174760043621063
70
train loss item: 0.2646987736225128
71
train loss item: 0.15597966313362122
72
train loss item: 0.16873344779014587
73
train loss item: 0.29317888617515564
74
train loss item: 0.0891968160867691
75
train loss item: 0.11274521052837372
76
train loss item: 0.8659021854400635
77
train loss item: 1.3304613828659058
78
train loss item: 0.08660560101270676
79
train loss item: 0.2819216549396515
80
train loss item: 0.10489638894796371
81
train loss item: 0.19271573424339294
82
train loss item: 0.19334614276885986
83
train loss item: 0.6004809737205505
84
train loss item: 0.3960920572280884
85
train loss item: 0.5515540838241577
86
train loss item: 4.274360179901123
87
train loss item: 0.1591634750366211
88
train loss item: 0.3880052864551544
epoch train loss: 0.4720036012403081
testing phase
test loss item: 0.18348433077335358
test loss item: 0.11510562151670456
test loss item: 0.5419729351997375
test loss item: 0.22665712237358093
test loss item: 0.23980066180229187
test loss item: 0.1293797343969345
test loss item: 1.4342507123947144
test loss item: 0.4809249937534332
test loss item: 0.2085464894771576
test loss item: 0.3866567015647888
test loss item: 0.8251644372940063
test loss item: 0.1554478257894516
test loss item: 0.17949530482292175
test loss item: 0.3037634789943695
test loss item: 0.17468437552452087
test loss item: 0.09083236008882523
test loss item: 0.2920038104057312
test loss item: 0.4433206021785736
test loss item: 0.6218668222427368
test loss item: 0.26290416717529297
test loss item: 0.6864579916000366
test loss item: 0.3642052412033081
test loss item: 0.26166555285453796
test loss item: 0.18257519602775574
test loss item: 0.21825212240219116
test loss item: 0.2265649437904358
test loss item: 0.3297727704048157
test loss item: 0.18748043477535248
test loss item: 0.3232249319553375
test loss item: 0.3504441976547241
test loss item: 0.7019555568695068
test loss item: 0.08420228213071823
test loss item: 0.1672554910182953
test loss item: 0.5485177040100098
test loss item: 0.3991730809211731
test loss item: 0.40678176283836365
test loss item: 0.748294472694397
test loss item: 1.37649405002594
test loss item: 0.4534584879875183
test loss item: 0.27293187379837036
test loss item: 0.30285653471946716
test loss item: 0.16441881656646729
test loss item: 0.3552872836589813
test loss item: 0.19664917886257172
test loss item: 0.5627227425575256
test loss item: 0.40645602345466614
test loss item: 0.2742393910884857
test loss item: 0.22596998512744904
test loss item: 0.45694252848625183
test loss item: 0.6654991507530212
test loss item: 0.2952052056789398
test loss item: 0.14104680716991425
test loss item: 0.23023276031017303
test loss item: 0.13874505460262299
test loss item: 0.28362956643104553
test loss item: 0.7875688076019287
test loss item: 0.5275540351867676
test loss item: 0.24544750154018402
test loss item: 0.23779217898845673
test loss item: 0.20549727976322174
test loss item: 0.45427918434143066
test loss item: 0.24179457128047943
test loss item: 0.20912206172943115
test loss item: 0.2532021701335907
test loss item: 0.7266286015510559
test loss item: 0.2982771098613739
test loss item: 0.3166309595108032
test loss item: 0.2560988962650299
test loss item: 0.5175477266311646
test loss item: 0.38463422656059265
test loss item: 0.07660068571567535
test loss item: 0.8480150103569031
test loss item: 0.2936350703239441
test loss item: 0.3820117712020874
test loss item: 0.1507181078195572
test loss item: 0.14905855059623718
test loss item: 0.18213635683059692
test loss item: 1.346431016921997
test loss item: 0.4284701645374298
test loss item: 0.18537011742591858
test loss item: 0.10206563770771027
test loss item: 0.8871627449989319
test loss item: 0.8057780861854553
test loss item: 0.9271189570426941
test loss item: 0.2159537971019745
test loss item: 0.22424805164337158
test loss item: 0.10247793793678284
test loss item: 0.09984402358531952
test loss item: 0.17993974685668945
Epoch [18/100], Training Loss: 0.4720, Testing Loss: 0.3768
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 19/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.42053520679473877
1
train loss item: 1.1597177982330322
2
train loss item: 0.22819824516773224
3
train loss item: 0.5061456561088562
4
train loss item: 0.3910525143146515
5
train loss item: 0.30629444122314453
6
train loss item: 0.24850471317768097
7
train loss item: 0.7605426907539368
8
train loss item: 0.13789153099060059
9
train loss item: 0.2382347285747528
10
train loss item: 0.32329806685447693
11
train loss item: 0.27076056599617004
12
train loss item: 0.12450102716684341
13
train loss item: 0.4545871317386627
14
train loss item: 0.22854416072368622
15
train loss item: 0.6111112833023071
16
train loss item: 0.09031890332698822
17
train loss item: 0.2871676981449127
18
train loss item: 0.3047541379928589
19
train loss item: 0.2636529505252838
20
train loss item: 0.2248612642288208
21
train loss item: 0.14158283174037933
22
train loss item: 0.9635106921195984
23
train loss item: 0.871817409992218
24
train loss item: 0.5351500511169434
25
train loss item: 0.19524738192558289
26
train loss item: 0.1800796538591385
27
train loss item: 0.21134576201438904
28
train loss item: 0.08475852012634277
29
train loss item: 0.7140378952026367
30
train loss item: 2.2067222595214844
31
train loss item: 0.5397144556045532
32
train loss item: 0.09930341690778732
33
train loss item: 0.4078303873538971
34
train loss item: 0.16798558831214905
35
train loss item: 2.352930784225464
36
train loss item: 0.414813756942749
37
train loss item: 0.3965860605239868
38
train loss item: 0.4137406647205353
39
train loss item: 0.21000978350639343
40
train loss item: 0.1795577108860016
41
train loss item: 0.2398437112569809
42
train loss item: 0.2658243179321289
43
train loss item: 0.17831212282180786
44
train loss item: 0.6160845756530762
45
train loss item: 0.11417913436889648
46
train loss item: 0.10610344260931015
47
train loss item: 0.3542323410511017
48
train loss item: 0.20489002764225006
49
train loss item: 0.15109537541866302
50
train loss item: 0.28608036041259766
51
train loss item: 0.8806806206703186
52
train loss item: 0.09407838433980942
53
train loss item: 0.15465781092643738
54
train loss item: 2.2359819412231445
55
train loss item: 0.19288288056850433
56
train loss item: 0.23091502487659454
57
train loss item: 0.22123248875141144
58
train loss item: 0.1564403623342514
59
train loss item: 0.11114335060119629
60
train loss item: 0.8411253690719604
61
train loss item: 2.174906015396118
62
train loss item: 0.21062704920768738
63
train loss item: 0.3633391559123993
64
train loss item: 0.16799022257328033
65
train loss item: 0.5154494643211365
66
train loss item: 0.3719746172428131
67
train loss item: 0.20122112333774567
68
train loss item: 0.2931426465511322
69
train loss item: 0.3091174364089966
70
train loss item: 0.2617826461791992
71
train loss item: 0.15526650846004486
72
train loss item: 0.172787144780159
73
train loss item: 0.2870462238788605
74
train loss item: 0.09384359419345856
75
train loss item: 0.11185240000486374
76
train loss item: 0.8474799394607544
77
train loss item: 1.3258366584777832
78
train loss item: 0.07973498851060867
79
train loss item: 0.2708095610141754
80
train loss item: 0.10327880084514618
81
train loss item: 0.19125685095787048
82
train loss item: 0.19442255795001984
83
train loss item: 0.594285786151886
84
train loss item: 0.3889940083026886
85
train loss item: 0.5348948836326599
86
train loss item: 4.238255977630615
87
train loss item: 0.17319731414318085
88
train loss item: 0.3827841281890869
epoch train loss: 0.46650293402457504
testing phase
test loss item: 0.1796455681324005
test loss item: 0.10374832898378372
test loss item: 0.541679859161377
test loss item: 0.2224833369255066
test loss item: 0.23402677476406097
test loss item: 0.11975046247243881
test loss item: 1.4531331062316895
test loss item: 0.5038288831710815
test loss item: 0.20977464318275452
test loss item: 0.38745802640914917
test loss item: 0.8212665915489197
test loss item: 0.15104606747627258
test loss item: 0.17191623151302338
test loss item: 0.2901327311992645
test loss item: 0.16748641431331635
test loss item: 0.08334480226039886
test loss item: 0.28896117210388184
test loss item: 0.44328126311302185
test loss item: 0.6309736371040344
test loss item: 0.2518691122531891
test loss item: 0.6790294051170349
test loss item: 0.3632264733314514
test loss item: 0.2506265938282013
test loss item: 0.17258775234222412
test loss item: 0.21607932448387146
test loss item: 0.21940480172634125
test loss item: 0.3238063156604767
test loss item: 0.18153886497020721
test loss item: 0.3169734477996826
test loss item: 0.3491976261138916
test loss item: 0.7044740915298462
test loss item: 0.07789845764636993
test loss item: 0.15528123080730438
test loss item: 0.546210527420044
test loss item: 0.3979688286781311
test loss item: 0.4128987789154053
test loss item: 0.7577526569366455
test loss item: 1.3739778995513916
test loss item: 0.45050546526908875
test loss item: 0.2648037374019623
test loss item: 0.30080801248550415
test loss item: 0.1587146520614624
test loss item: 0.3572981655597687
test loss item: 0.1979953944683075
test loss item: 0.555185079574585
test loss item: 0.39714571833610535
test loss item: 0.267363578081131
test loss item: 0.21641327440738678
test loss item: 0.45507586002349854
test loss item: 0.6680450439453125
test loss item: 0.2947753071784973
test loss item: 0.1333453208208084
test loss item: 0.23160165548324585
test loss item: 0.1428762972354889
test loss item: 0.2838182747364044
test loss item: 0.7832555174827576
test loss item: 0.5355265140533447
test loss item: 0.2432313859462738
test loss item: 0.23146764934062958
test loss item: 0.20379875600337982
test loss item: 0.4573417603969574
test loss item: 0.2370515614748001
test loss item: 0.20120738446712494
test loss item: 0.24815773963928223
test loss item: 0.7228171825408936
test loss item: 0.29937613010406494
test loss item: 0.30751505494117737
test loss item: 0.253542423248291
test loss item: 0.5094723701477051
test loss item: 0.3956661820411682
test loss item: 0.07332807034254074
test loss item: 0.8620200157165527
test loss item: 0.2808469533920288
test loss item: 0.37167903780937195
test loss item: 0.14801114797592163
test loss item: 0.14070846140384674
test loss item: 0.1730032116174698
test loss item: 1.336911916732788
test loss item: 0.41249388456344604
test loss item: 0.17959333956241608
test loss item: 0.09374852478504181
test loss item: 0.8953176140785217
test loss item: 0.8155618906021118
test loss item: 0.9239270091056824
test loss item: 0.20737913250923157
test loss item: 0.21958525478839874
test loss item: 0.09593568742275238
test loss item: 0.09451410174369812
test loss item: 0.18001437187194824
Epoch [19/100], Training Loss: 0.4665, Testing Loss: 0.3738
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 20/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4186345934867859
1
train loss item: 1.14072847366333
2
train loss item: 0.22305162250995636
3
train loss item: 0.49804890155792236
4
train loss item: 0.38286036252975464
5
train loss item: 0.3049800992012024
6
train loss item: 0.24090026319026947
7
train loss item: 0.7480016350746155
8
train loss item: 0.1365986317396164
9
train loss item: 0.23364688456058502
10
train loss item: 0.3198690116405487
11
train loss item: 0.2651454508304596
12
train loss item: 0.12351397424936295
13
train loss item: 0.44853460788726807
14
train loss item: 0.22549749910831451
15
train loss item: 0.6042059063911438
16
train loss item: 0.07724828273057938
17
train loss item: 0.28413689136505127
18
train loss item: 0.30238479375839233
19
train loss item: 0.25632598996162415
20
train loss item: 0.22084854543209076
21
train loss item: 0.14506244659423828
22
train loss item: 0.9424607157707214
23
train loss item: 0.8559910655021667
24
train loss item: 0.5218068957328796
25
train loss item: 0.194849893450737
26
train loss item: 0.18023507297039032
27
train loss item: 0.20797622203826904
28
train loss item: 0.07312483340501785
29
train loss item: 0.704007089138031
30
train loss item: 2.1808135509490967
31
train loss item: 0.5339425802230835
32
train loss item: 0.10330215096473694
33
train loss item: 0.4074437916278839
34
train loss item: 0.1725003570318222
35
train loss item: 2.3324530124664307
36
train loss item: 0.4123521149158478
37
train loss item: 0.39061862230300903
38
train loss item: 0.40906599164009094
39
train loss item: 0.2073066085577011
40
train loss item: 0.17681756615638733
41
train loss item: 0.23905211687088013
42
train loss item: 0.26270338892936707
43
train loss item: 0.17740729451179504
44
train loss item: 0.6071147918701172
45
train loss item: 0.11381304264068604
46
train loss item: 0.10771660506725311
47
train loss item: 0.3470659554004669
48
train loss item: 0.20009371638298035
49
train loss item: 0.15323320031166077
50
train loss item: 0.2829109728336334
51
train loss item: 0.8678979277610779
52
train loss item: 0.08056525886058807
53
train loss item: 0.15257522463798523
54
train loss item: 2.214986801147461
55
train loss item: 0.18609443306922913
56
train loss item: 0.2285756915807724
57
train loss item: 0.21740703284740448
58
train loss item: 0.15467624366283417
59
train loss item: 0.10771612077951431
60
train loss item: 0.8286632895469666
61
train loss item: 2.1508615016937256
62
train loss item: 0.20810087025165558
63
train loss item: 0.35649722814559937
64
train loss item: 0.16970032453536987
65
train loss item: 0.5061180591583252
66
train loss item: 0.3694486916065216
67
train loss item: 0.19986878335475922
68
train loss item: 0.28714361786842346
69
train loss item: 0.3021252453327179
70
train loss item: 0.25553786754608154
71
train loss item: 0.14888355135917664
72
train loss item: 0.17220531404018402
73
train loss item: 0.282903254032135
74
train loss item: 0.09262540191411972
75
train loss item: 0.10944978892803192
76
train loss item: 0.8313612937927246
77
train loss item: 1.3142672777175903
78
train loss item: 0.07139579206705093
79
train loss item: 0.2619238495826721
80
train loss item: 0.10329551249742508
81
train loss item: 0.1909336894750595
82
train loss item: 0.19223318994045258
83
train loss item: 0.5837317109107971
84
train loss item: 0.3853146731853485
85
train loss item: 0.52237868309021
86
train loss item: 4.207267761230469
87
train loss item: 0.17198409140110016
88
train loss item: 0.37978923320770264
epoch train loss: 0.46027986931332043
testing phase
test loss item: 0.17638766765594482
test loss item: 0.0940273255109787
test loss item: 0.5388562679290771
test loss item: 0.2234748899936676
test loss item: 0.22935692965984344
test loss item: 0.11344993114471436
test loss item: 1.4535800218582153
test loss item: 0.5060348510742188
test loss item: 0.2078380286693573
test loss item: 0.3824102580547333
test loss item: 0.8197760581970215
test loss item: 0.1570892035961151
test loss item: 0.1685282289981842
test loss item: 0.2803095281124115
test loss item: 0.16028301417827606
test loss item: 0.07765846699476242
test loss item: 0.28758683800697327
test loss item: 0.4384598731994629
test loss item: 0.629286527633667
test loss item: 0.24640630185604095
test loss item: 0.6677966713905334
test loss item: 0.36567485332489014
test loss item: 0.2447827160358429
test loss item: 0.1641080230474472
test loss item: 0.21379433572292328
test loss item: 0.21242733299732208
test loss item: 0.31710976362228394
test loss item: 0.17727747559547424
test loss item: 0.31169962882995605
test loss item: 0.3442082107067108
test loss item: 0.7043434381484985
test loss item: 0.07516776770353317
test loss item: 0.14390939474105835
test loss item: 0.5437762141227722
test loss item: 0.39322659373283386
test loss item: 0.4072454869747162
test loss item: 0.7550532817840576
test loss item: 1.3760794401168823
test loss item: 0.4458667039871216
test loss item: 0.25771966576576233
test loss item: 0.29783323407173157
test loss item: 0.15919135510921478
test loss item: 0.3522144556045532
test loss item: 0.2056010216474533
test loss item: 0.544457733631134
test loss item: 0.3909681439399719
test loss item: 0.26399046182632446
test loss item: 0.21014505624771118
test loss item: 0.44915199279785156
test loss item: 0.6670264601707458
test loss item: 0.28594326972961426
test loss item: 0.12953145802021027
test loss item: 0.23069459199905396
test loss item: 0.16773642599582672
test loss item: 0.2803969979286194
test loss item: 0.7787526249885559
test loss item: 0.5339746475219727
test loss item: 0.23363865911960602
test loss item: 0.22521740198135376
test loss item: 0.20066827535629272
test loss item: 0.4504713714122772
test loss item: 0.2344314157962799
test loss item: 0.19604410231113434
test loss item: 0.2445070445537567
test loss item: 0.7182873487472534
test loss item: 0.30990585684776306
test loss item: 0.3025413453578949
test loss item: 0.2517513930797577
test loss item: 0.5020843744277954
test loss item: 0.39718174934387207
test loss item: 0.0733160525560379
test loss item: 0.861126720905304
test loss item: 0.2758985161781311
test loss item: 0.3652048707008362
test loss item: 0.14916865527629852
test loss item: 0.14017851650714874
test loss item: 0.16602113842964172
test loss item: 1.3371585607528687
test loss item: 0.4050317108631134
test loss item: 0.176937535405159
test loss item: 0.08630380779504776
test loss item: 0.8992632031440735
test loss item: 0.8139707446098328
test loss item: 0.9248888492584229
test loss item: 0.19998522102832794
test loss item: 0.2190178781747818
test loss item: 0.08759597688913345
test loss item: 0.08628212660551071
test loss item: 0.17455610632896423
Epoch [20/100], Training Loss: 0.4603, Testing Loss: 0.3704
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 21/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41640374064445496
1
train loss item: 1.119391918182373
2
train loss item: 0.21440869569778442
3
train loss item: 0.48775598406791687
4
train loss item: 0.3719550669193268
5
train loss item: 0.3045963943004608
6
train loss item: 0.2375873327255249
7
train loss item: 0.7348705530166626
8
train loss item: 0.12609289586544037
9
train loss item: 0.23164218664169312
10
train loss item: 0.3127095699310303
11
train loss item: 0.25894322991371155
12
train loss item: 0.12733158469200134
13
train loss item: 0.4394032955169678
14
train loss item: 0.2166285663843155
15
train loss item: 0.5920383930206299
16
train loss item: 0.07065881043672562
17
train loss item: 0.27498817443847656
18
train loss item: 0.30056464672088623
19
train loss item: 0.2519527077674866
20
train loss item: 0.21859842538833618
21
train loss item: 0.13032877445220947
22
train loss item: 0.9152283668518066
23
train loss item: 0.8363592624664307
24
train loss item: 0.5120636224746704
25
train loss item: 0.18966348469257355
26
train loss item: 0.17588409781455994
27
train loss item: 0.20096588134765625
28
train loss item: 0.06780070811510086
29
train loss item: 0.6862668395042419
30
train loss item: 2.1548123359680176
31
train loss item: 0.5269570350646973
32
train loss item: 0.10596298426389694
33
train loss item: 0.3920802175998688
34
train loss item: 0.1646507829427719
35
train loss item: 2.312899351119995
36
train loss item: 0.41017064452171326
37
train loss item: 0.3832356631755829
38
train loss item: 0.4064844846725464
39
train loss item: 0.20255962014198303
40
train loss item: 0.16542890667915344
41
train loss item: 0.23442009091377258
42
train loss item: 0.2627905309200287
43
train loss item: 0.16837994754314423
44
train loss item: 0.5973713397979736
45
train loss item: 0.11351708322763443
46
train loss item: 0.10392486304044724
47
train loss item: 0.33713704347610474
48
train loss item: 0.1957883983850479
49
train loss item: 0.1453767567873001
50
train loss item: 0.2792120575904846
51
train loss item: 0.8515661954879761
52
train loss item: 0.06956356018781662
53
train loss item: 0.14045172929763794
54
train loss item: 2.1955366134643555
55
train loss item: 0.17828109860420227
56
train loss item: 0.22141538560390472
57
train loss item: 0.218672975897789
58
train loss item: 0.1482677310705185
59
train loss item: 0.10485632717609406
60
train loss item: 0.8110052347183228
61
train loss item: 2.125281572341919
62
train loss item: 0.20549090206623077
63
train loss item: 0.3482033312320709
64
train loss item: 0.15755510330200195
65
train loss item: 0.4946193993091583
66
train loss item: 0.36996790766716003
67
train loss item: 0.195303812623024
68
train loss item: 0.27865079045295715
69
train loss item: 0.2969950735569
70
train loss item: 0.24781212210655212
71
train loss item: 0.1449149250984192
72
train loss item: 0.16481146216392517
73
train loss item: 0.2803807258605957
74
train loss item: 0.09140443056821823
75
train loss item: 0.10661496967077255
76
train loss item: 0.8145416975021362
77
train loss item: 1.2978779077529907
78
train loss item: 0.07096793502569199
79
train loss item: 0.25466981530189514
80
train loss item: 0.10985112190246582
81
train loss item: 0.18901485204696655
82
train loss item: 0.18055026233196259
83
train loss item: 0.5704338550567627
84
train loss item: 0.383442223072052
85
train loss item: 0.5103241801261902
86
train loss item: 4.17891263961792
87
train loss item: 0.15461629629135132
88
train loss item: 0.3801606297492981
epoch train loss: 0.4520138218329194
testing phase
test loss item: 0.1750878393650055
test loss item: 0.0940389558672905
test loss item: 0.5341463088989258
test loss item: 0.23342886567115784
test loss item: 0.2266819179058075
test loss item: 0.11051688343286514
test loss item: 1.43315589427948
test loss item: 0.48335331678390503
test loss item: 0.20382845401763916
test loss item: 0.37451618909835815
test loss item: 0.8165093064308167
test loss item: 0.17438682913780212
test loss item: 0.1693757176399231
test loss item: 0.2731770873069763
test loss item: 0.15784607827663422
test loss item: 0.07544548809528351
test loss item: 0.28203532099723816
test loss item: 0.43146106600761414
test loss item: 0.6152457594871521
test loss item: 0.24437710642814636
test loss item: 0.6574458479881287
test loss item: 0.36871659755706787
test loss item: 0.24414674937725067
test loss item: 0.16092433035373688
test loss item: 0.20927020907402039
test loss item: 0.20822200179100037
test loss item: 0.31049689650535583
test loss item: 0.17456874251365662
test loss item: 0.30854225158691406
test loss item: 0.3368338644504547
test loss item: 0.6991448402404785
test loss item: 0.07632358372211456
test loss item: 0.13988447189331055
test loss item: 0.5441704988479614
test loss item: 0.3874330222606659
test loss item: 0.3944566249847412
test loss item: 0.739166259765625
test loss item: 1.3762325048446655
test loss item: 0.441924124956131
test loss item: 0.25273868441581726
test loss item: 0.2905353903770447
test loss item: 0.16726747155189514
test loss item: 0.34466493129730225
test loss item: 0.2161770910024643
test loss item: 0.5344182252883911
test loss item: 0.3838872015476227
test loss item: 0.2654845416545868
test loss item: 0.20875176787376404
test loss item: 0.4404197931289673
test loss item: 0.6601808667182922
test loss item: 0.2753627300262451
test loss item: 0.1288079470396042
test loss item: 0.22555068135261536
test loss item: 0.20747199654579163
test loss item: 0.2761628329753876
test loss item: 0.7730901837348938
test loss item: 0.5223067998886108
test loss item: 0.2260216623544693
test loss item: 0.2195744812488556
test loss item: 0.19945475459098816
test loss item: 0.43994325399398804
test loss item: 0.2277563512325287
test loss item: 0.19467602670192719
test loss item: 0.24292440712451935
test loss item: 0.7115687727928162
test loss item: 0.3319358825683594
test loss item: 0.298123300075531
test loss item: 0.24757352471351624
test loss item: 0.4970852732658386
test loss item: 0.3869020342826843
test loss item: 0.07339438050985336
test loss item: 0.8416044116020203
test loss item: 0.27713248133659363
test loss item: 0.36070623993873596
test loss item: 0.1473676562309265
test loss item: 0.14661496877670288
test loss item: 0.16301290690898895
test loss item: 1.340161919593811
test loss item: 0.40266719460487366
test loss item: 0.17666909098625183
test loss item: 0.08088276535272598
test loss item: 0.8942016363143921
test loss item: 0.8002728819847107
test loss item: 0.9255331754684448
test loss item: 0.19453150033950806
test loss item: 0.2173181176185608
test loss item: 0.0804792270064354
test loss item: 0.07678651809692383
test loss item: 0.17436207830905914
Epoch [21/100], Training Loss: 0.4520, Testing Loss: 0.3669
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 22/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41144654154777527
1
train loss item: 1.094984531402588
2
train loss item: 0.2121330201625824
3
train loss item: 0.47851625084877014
4
train loss item: 0.362591952085495
5
train loss item: 0.3016619384288788
6
train loss item: 0.24170048534870148
7
train loss item: 0.7217493653297424
8
train loss item: 0.11658535897731781
9
train loss item: 0.23130053281784058
10
train loss item: 0.3030007481575012
11
train loss item: 0.2530536353588104
12
train loss item: 0.12788181006908417
13
train loss item: 0.4315733015537262
14
train loss item: 0.20675233006477356
15
train loss item: 0.5740087032318115
16
train loss item: 0.06723037362098694
17
train loss item: 0.2672814428806305
18
train loss item: 0.296733558177948
19
train loss item: 0.24788926541805267
20
train loss item: 0.2169010192155838
21
train loss item: 0.11954618990421295
22
train loss item: 0.8821003437042236
23
train loss item: 0.8162115812301636
24
train loss item: 0.5027693510055542
25
train loss item: 0.19164541363716125
26
train loss item: 0.17384153604507446
27
train loss item: 0.1950889527797699
28
train loss item: 0.06470195949077606
29
train loss item: 0.6623509526252747
30
train loss item: 2.1286048889160156
31
train loss item: 0.5206362009048462
32
train loss item: 0.11222147941589355
33
train loss item: 0.37518903613090515
34
train loss item: 0.1522759050130844
35
train loss item: 2.293508291244507
36
train loss item: 0.40955638885498047
37
train loss item: 0.377056747674942
38
train loss item: 0.41084516048431396
39
train loss item: 0.19852013885974884
40
train loss item: 0.16488471627235413
41
train loss item: 0.22943717241287231
42
train loss item: 0.26447972655296326
43
train loss item: 0.16216230392456055
44
train loss item: 0.5891748666763306
45
train loss item: 0.11222483962774277
46
train loss item: 0.10673341155052185
47
train loss item: 0.32848474383354187
48
train loss item: 0.19527842104434967
49
train loss item: 0.13888679444789886
50
train loss item: 0.2725711464881897
51
train loss item: 0.8329513072967529
52
train loss item: 0.06434579938650131
53
train loss item: 0.13917198777198792
54
train loss item: 2.1768670082092285
55
train loss item: 0.17697839438915253
56
train loss item: 0.21474523842334747
57
train loss item: 0.22070923447608948
58
train loss item: 0.14543955028057098
59
train loss item: 0.10570409148931503
60
train loss item: 0.7885749936103821
61
train loss item: 2.1018354892730713
62
train loss item: 0.20023974776268005
63
train loss item: 0.3387199640274048
64
train loss item: 0.14757339656352997
65
train loss item: 0.48160815238952637
66
train loss item: 0.3718363642692566
67
train loss item: 0.19213774800300598
68
train loss item: 0.2697829306125641
69
train loss item: 0.2924641966819763
70
train loss item: 0.24292965233325958
71
train loss item: 0.14076396822929382
72
train loss item: 0.15681767463684082
73
train loss item: 0.27878326177597046
74
train loss item: 0.0913882628083229
75
train loss item: 0.1034194678068161
76
train loss item: 0.7981931567192078
77
train loss item: 1.2788671255111694
78
train loss item: 0.07204973697662354
79
train loss item: 0.24791033565998077
80
train loss item: 0.11600466817617416
81
train loss item: 0.19130583107471466
82
train loss item: 0.17084261775016785
83
train loss item: 0.5553798675537109
84
train loss item: 0.38318607211112976
85
train loss item: 0.49885618686676025
86
train loss item: 4.153322219848633
87
train loss item: 0.14908504486083984
88
train loss item: 0.3792281150817871
epoch train loss: 0.4447863335522373
testing phase
test loss item: 0.17490990459918976
test loss item: 0.09828004986047745
test loss item: 0.5347983837127686
test loss item: 0.23852965235710144
test loss item: 0.2252814918756485
test loss item: 0.10791128128767014
test loss item: 1.4027206897735596
test loss item: 0.4470648467540741
test loss item: 0.20181144773960114
test loss item: 0.37047430872917175
test loss item: 0.8132152557373047
test loss item: 0.18451017141342163
test loss item: 0.1713368445634842
test loss item: 0.2656124532222748
test loss item: 0.158780038356781
test loss item: 0.07503098994493484
test loss item: 0.2711729407310486
test loss item: 0.4298671782016754
test loss item: 0.5957632064819336
test loss item: 0.2409614771604538
test loss item: 0.6582663059234619
test loss item: 0.3637545108795166
test loss item: 0.2451055347919464
test loss item: 0.15900951623916626
test loss item: 0.20462173223495483
test loss item: 0.20567554235458374
test loss item: 0.30527201294898987
test loss item: 0.17064891755580902
test loss item: 0.30630630254745483
test loss item: 0.33004677295684814
test loss item: 0.692979097366333
test loss item: 0.07696942985057831
test loss item: 0.13968785107135773
test loss item: 0.5469610691070557
test loss item: 0.386927992105484
test loss item: 0.38511788845062256
test loss item: 0.7181383967399597
test loss item: 1.377922534942627
test loss item: 0.4400263726711273
test loss item: 0.24856245517730713
test loss item: 0.28056955337524414
test loss item: 0.1720297634601593
test loss item: 0.3434559106826782
test loss item: 0.2171040028333664
test loss item: 0.5324289798736572
test loss item: 0.37217986583709717
test loss item: 0.26722726225852966
test loss item: 0.2062830924987793
test loss item: 0.43519124388694763
test loss item: 0.6518807411193848
test loss item: 0.2729450464248657
test loss item: 0.12529495358467102
test loss item: 0.2185308337211609
test loss item: 0.22552520036697388
test loss item: 0.27506014704704285
test loss item: 0.7727529406547546
test loss item: 0.5072575211524963
test loss item: 0.22385947406291962
test loss item: 0.21484489738941193
test loss item: 0.2026137262582779
test loss item: 0.4369010627269745
test loss item: 0.2142941951751709
test loss item: 0.19290068745613098
test loss item: 0.24495618045330048
test loss item: 0.7087470293045044
test loss item: 0.34221214056015015
test loss item: 0.289747029542923
test loss item: 0.24146169424057007
test loss item: 0.4972084164619446
test loss item: 0.37062928080558777
test loss item: 0.0701814591884613
test loss item: 0.8113690614700317
test loss item: 0.2771163880825043
test loss item: 0.3552256226539612
test loss item: 0.13956347107887268
test loss item: 0.14867530763149261
test loss item: 0.15997396409511566
test loss item: 1.348995327949524
test loss item: 0.3979899287223816
test loss item: 0.17526116967201233
test loss item: 0.07795408368110657
test loss item: 0.8837649822235107
test loss item: 0.78306645154953
test loss item: 0.928276538848877
test loss item: 0.18933448195457458
test loss item: 0.21208912134170532
test loss item: 0.07742633670568466
test loss item: 0.06883101165294647
test loss item: 0.18475103378295898
Epoch [22/100], Training Loss: 0.4448, Testing Loss: 0.3631
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 23/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.40396958589553833
1
train loss item: 1.0697921514511108
2
train loss item: 0.2083192765712738
3
train loss item: 0.47421130537986755
4
train loss item: 0.35291537642478943
5
train loss item: 0.2936881184577942
6
train loss item: 0.23852969706058502
7
train loss item: 0.7101091146469116
8
train loss item: 0.1126876175403595
9
train loss item: 0.22881536185741425
10
train loss item: 0.29500579833984375
11
train loss item: 0.2478584498167038
12
train loss item: 0.12140058726072311
13
train loss item: 0.4295419156551361
14
train loss item: 0.1996072232723236
15
train loss item: 0.5521791577339172
16
train loss item: 0.062461525201797485
17
train loss item: 0.2606273591518402
18
train loss item: 0.28810158371925354
19
train loss item: 0.23911117017269135
20
train loss item: 0.20631492137908936
21
train loss item: 0.11996061354875565
22
train loss item: 0.8488545417785645
23
train loss item: 0.802066445350647
24
train loss item: 0.4885416626930237
25
train loss item: 0.19137711822986603
26
train loss item: 0.17298883199691772
27
train loss item: 0.1918407529592514
28
train loss item: 0.060359012335538864
29
train loss item: 0.638282835483551
30
train loss item: 2.1033506393432617
31
train loss item: 0.5156278610229492
32
train loss item: 0.11111721396446228
33
train loss item: 0.3714994788169861
34
train loss item: 0.140583798289299
35
train loss item: 2.2748570442199707
36
train loss item: 0.4125477373600006
37
train loss item: 0.3734102249145508
38
train loss item: 0.4223651885986328
39
train loss item: 0.1925494223833084
40
train loss item: 0.1637251079082489
41
train loss item: 0.2251165509223938
42
train loss item: 0.2615961730480194
43
train loss item: 0.15958504378795624
44
train loss item: 0.5849887132644653
45
train loss item: 0.11088026314973831
46
train loss item: 0.10747332125902176
47
train loss item: 0.3194408714771271
48
train loss item: 0.19341328740119934
49
train loss item: 0.13717733323574066
50
train loss item: 0.26113155484199524
51
train loss item: 0.8143702149391174
52
train loss item: 0.0634276419878006
53
train loss item: 0.14183209836483002
54
train loss item: 2.159266233444214
55
train loss item: 0.1742973029613495
56
train loss item: 0.21013231575489044
57
train loss item: 0.21578603982925415
58
train loss item: 0.14193402230739594
59
train loss item: 0.1086384654045105
60
train loss item: 0.7666960954666138
61
train loss item: 2.0855090618133545
62
train loss item: 0.18950140476226807
63
train loss item: 0.32789531350135803
64
train loss item: 0.1457996666431427
65
train loss item: 0.4689347743988037
66
train loss item: 0.3752027153968811
67
train loss item: 0.18887493014335632
68
train loss item: 0.26047632098197937
69
train loss item: 0.2853661775588989
70
train loss item: 0.23567864298820496
71
train loss item: 0.13013975322246552
72
train loss item: 0.1536162793636322
73
train loss item: 0.27455684542655945
74
train loss item: 0.09045331180095673
75
train loss item: 0.10077333450317383
76
train loss item: 0.7851982116699219
77
train loss item: 1.260197401046753
78
train loss item: 0.06623996794223785
79
train loss item: 0.2400447279214859
80
train loss item: 0.11045979708433151
81
train loss item: 0.1891849786043167
82
train loss item: 0.16870316863059998
83
train loss item: 0.5401811003684998
84
train loss item: 0.3849189877510071
85
train loss item: 0.4884636700153351
86
train loss item: 4.130306243896484
87
train loss item: 0.15096493065357208
88
train loss item: 0.3699875771999359
epoch train loss: 0.437595119846336
testing phase
test loss item: 0.17677919566631317
test loss item: 0.10886308550834656
test loss item: 0.5367026925086975
test loss item: 0.23387488722801208
test loss item: 0.23080217838287354
test loss item: 0.1176082044839859
test loss item: 1.389513373374939
test loss item: 0.43039652705192566
test loss item: 0.20097039639949799
test loss item: 0.3690469264984131
test loss item: 0.7986257672309875
test loss item: 0.1776563823223114
test loss item: 0.17236541211605072
test loss item: 0.2569037079811096
test loss item: 0.16653388738632202
test loss item: 0.07796615362167358
test loss item: 0.2628238797187805
test loss item: 0.4350190758705139
test loss item: 0.5825244188308716
test loss item: 0.23588629066944122
test loss item: 0.6736553311347961
test loss item: 0.3538987934589386
test loss item: 0.2468380481004715
test loss item: 0.1645895093679428
test loss item: 0.20357608795166016
test loss item: 0.20596732199192047
test loss item: 0.3016108274459839
test loss item: 0.1741466522216797
test loss item: 0.30727115273475647
test loss item: 0.32529494166374207
test loss item: 0.6840456128120422
test loss item: 0.07432079315185547
test loss item: 0.14823344349861145
test loss item: 0.5464152097702026
test loss item: 0.3914646506309509
test loss item: 0.3747623860836029
test loss item: 0.7063478231430054
test loss item: 1.3598662614822388
test loss item: 0.4379795491695404
test loss item: 0.2517440617084503
test loss item: 0.2749323546886444
test loss item: 0.16449078917503357
test loss item: 0.3466549515724182
test loss item: 0.20567110180854797
test loss item: 0.5408523678779602
test loss item: 0.3630850613117218
test loss item: 0.26625436544418335
test loss item: 0.19846510887145996
test loss item: 0.434152215719223
test loss item: 0.6381962895393372
test loss item: 0.278500497341156
test loss item: 0.12169289588928223
test loss item: 0.21480692923069
test loss item: 0.2083144187927246
test loss item: 0.27829793095588684
test loss item: 0.7671810984611511
test loss item: 0.4971947968006134
test loss item: 0.22920681536197662
test loss item: 0.2158188819885254
test loss item: 0.20693030953407288
test loss item: 0.43883100152015686
test loss item: 0.20577310025691986
test loss item: 0.1916610598564148
test loss item: 0.24762839078903198
test loss item: 0.7130694389343262
test loss item: 0.3291553556919098
test loss item: 0.2834886312484741
test loss item: 0.23849496245384216
test loss item: 0.49987849593162537
test loss item: 0.34787923097610474
test loss item: 0.07062672078609467
test loss item: 0.7982630729675293
test loss item: 0.27472397685050964
test loss item: 0.3532652258872986
test loss item: 0.13249137997627258
test loss item: 0.1418474167585373
test loss item: 0.16386139392852783
test loss item: 1.3466038703918457
test loss item: 0.38879725337028503
test loss item: 0.1771746575832367
test loss item: 0.0857318639755249
test loss item: 0.8691940903663635
test loss item: 0.7683973908424377
test loss item: 0.9194093942642212
test loss item: 0.1879858374595642
test loss item: 0.2064230591058731
test loss item: 0.08472379297018051
test loss item: 0.06912067532539368
test loss item: 0.19566494226455688
Epoch [23/100], Training Loss: 0.4376, Testing Loss: 0.3604
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 24/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.39592599868774414
1
train loss item: 1.046249270439148
2
train loss item: 0.19854527711868286
3
train loss item: 0.4648132920265198
4
train loss item: 0.3410126864910126
5
train loss item: 0.2823214530944824
6
train loss item: 0.2232942283153534
7
train loss item: 0.6995419859886169
8
train loss item: 0.11131785809993744
9
train loss item: 0.22316370904445648
10
train loss item: 0.2867104411125183
11
train loss item: 0.2446112185716629
12
train loss item: 0.11644453555345535
13
train loss item: 0.42839398980140686
14
train loss item: 0.19743861258029938
15
train loss item: 0.5357208847999573
16
train loss item: 0.0626877173781395
17
train loss item: 0.2532864809036255
18
train loss item: 0.2789056599140167
19
train loss item: 0.22790250182151794
20
train loss item: 0.19052277505397797
21
train loss item: 0.11667834222316742
22
train loss item: 0.8299567699432373
23
train loss item: 0.7885937094688416
24
train loss item: 0.47421520948410034
25
train loss item: 0.18140219151973724
26
train loss item: 0.1692994236946106
27
train loss item: 0.19143442809581757
28
train loss item: 0.06087560951709747
29
train loss item: 0.6190337538719177
30
train loss item: 2.0756936073303223
31
train loss item: 0.5063213109970093
32
train loss item: 0.10308672487735748
33
train loss item: 0.3732779920101166
34
train loss item: 0.13223038613796234
35
train loss item: 2.2556469440460205
36
train loss item: 0.4123340845108032
37
train loss item: 0.36971315741539
38
train loss item: 0.42000263929367065
39
train loss item: 0.1860656887292862
40
train loss item: 0.1514400988817215
41
train loss item: 0.22029532492160797
42
train loss item: 0.2535567879676819
43
train loss item: 0.15782108902931213
44
train loss item: 0.5814718008041382
45
train loss item: 0.11159379035234451
46
train loss item: 0.09927099198102951
47
train loss item: 0.3107220530509949
48
train loss item: 0.1885484755039215
49
train loss item: 0.13587546348571777
50
train loss item: 0.2504183053970337
51
train loss item: 0.7964437007904053
52
train loss item: 0.065742127597332
53
train loss item: 0.13660021126270294
54
train loss item: 2.1406054496765137
55
train loss item: 0.1699807345867157
56
train loss item: 0.20595525205135345
57
train loss item: 0.20658189058303833
58
train loss item: 0.13674895465373993
59
train loss item: 0.10943669825792313
60
train loss item: 0.7508423924446106
61
train loss item: 2.069103479385376
62
train loss item: 0.17900820076465607
63
train loss item: 0.31982919573783875
64
train loss item: 0.14558711647987366
65
train loss item: 0.4632696807384491
66
train loss item: 0.37578389048576355
67
train loss item: 0.18354974687099457
68
train loss item: 0.2572925388813019
69
train loss item: 0.2767814099788666
70
train loss item: 0.22405143082141876
71
train loss item: 0.11821425706148148
72
train loss item: 0.15307308733463287
73
train loss item: 0.26719939708709717
74
train loss item: 0.08870068937540054
75
train loss item: 0.10240151733160019
76
train loss item: 0.7733653783798218
77
train loss item: 1.2454347610473633
78
train loss item: 0.05957573652267456
79
train loss item: 0.2340283840894699
80
train loss item: 0.09980976581573486
81
train loss item: 0.17706675827503204
82
train loss item: 0.1710996776819229
83
train loss item: 0.527061939239502
84
train loss item: 0.38797491788864136
85
train loss item: 0.47443532943725586
86
train loss item: 4.1062822341918945
87
train loss item: 0.14662949740886688
88
train loss item: 0.3543721139431
epoch train loss: 0.42961355365729065
testing phase
test loss item: 0.17734253406524658
test loss item: 0.11772558093070984
test loss item: 0.5337733626365662
test loss item: 0.22367221117019653
test loss item: 0.23575545847415924
test loss item: 0.12422296404838562
test loss item: 1.4046651124954224
test loss item: 0.44038358330726624
test loss item: 0.19812636077404022
test loss item: 0.36696988344192505
test loss item: 0.7771496772766113
test loss item: 0.15942150354385376
test loss item: 0.1687149554491043
test loss item: 0.25228598713874817
test loss item: 0.17109858989715576
test loss item: 0.09059527516365051
test loss item: 0.2606584131717682
test loss item: 0.4417225122451782
test loss item: 0.5821595788002014
test loss item: 0.23123779892921448
test loss item: 0.6951053142547607
test loss item: 0.3468326926231384
test loss item: 0.2523978352546692
test loss item: 0.16992118954658508
test loss item: 0.2043106108903885
test loss item: 0.20687703788280487
test loss item: 0.29825159907341003
test loss item: 0.17834804952144623
test loss item: 0.30839213728904724
test loss item: 0.32259348034858704
test loss item: 0.6762375831604004
test loss item: 0.07840819656848907
test loss item: 0.15417279303073883
test loss item: 0.5412547588348389
test loss item: 0.3964274823665619
test loss item: 0.36961105465888977
test loss item: 0.7074423432350159
test loss item: 1.3248850107192993
test loss item: 0.434978723526001
test loss item: 0.2566364109516144
test loss item: 0.27647942304611206
test loss item: 0.15103614330291748
test loss item: 0.3488738238811493
test loss item: 0.19169053435325623
test loss item: 0.5547590851783752
test loss item: 0.3613303005695343
test loss item: 0.2673793137073517
test loss item: 0.19165655970573425
test loss item: 0.4328043758869171
test loss item: 0.6236802935600281
test loss item: 0.2854766249656677
test loss item: 0.1202666163444519
test loss item: 0.21568872034549713
test loss item: 0.17135345935821533
test loss item: 0.28350454568862915
test loss item: 0.754561722278595
test loss item: 0.494485467672348
test loss item: 0.24547035992145538
test loss item: 0.22019022703170776
test loss item: 0.20631170272827148
test loss item: 0.4394228458404541
test loss item: 0.20714180171489716
test loss item: 0.1910116970539093
test loss item: 0.24453970789909363
test loss item: 0.7182806730270386
test loss item: 0.3062303364276886
test loss item: 0.2822071611881256
test loss item: 0.2381887137889862
test loss item: 0.49985039234161377
test loss item: 0.34042128920555115
test loss item: 0.07595407217741013
test loss item: 0.8096973896026611
test loss item: 0.2763490080833435
test loss item: 0.3564966320991516
test loss item: 0.12904642522335052
test loss item: 0.1331547498703003
test loss item: 0.1687326729297638
test loss item: 1.3270128965377808
test loss item: 0.3821896016597748
test loss item: 0.17758941650390625
test loss item: 0.0924815684556961
test loss item: 0.8585107326507568
test loss item: 0.764039933681488
test loss item: 0.900074303150177
test loss item: 0.1903432011604309
test loss item: 0.20262673497200012
test loss item: 0.09372925013303757
test loss item: 0.08158332109451294
test loss item: 0.19136440753936768
Epoch [24/100], Training Loss: 0.4296, Testing Loss: 0.3591
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 25/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.38886937499046326
1
train loss item: 1.0258938074111938
2
train loss item: 0.18992914259433746
3
train loss item: 0.4450570344924927
4
train loss item: 0.33018043637275696
5
train loss item: 0.2723155617713928
6
train loss item: 0.2100948542356491
7
train loss item: 0.6879774928092957
8
train loss item: 0.10820861905813217
9
train loss item: 0.2165578454732895
10
train loss item: 0.27759453654289246
11
train loss item: 0.2419058382511139
12
train loss item: 0.11523307114839554
13
train loss item: 0.42281192541122437
14
train loss item: 0.19880786538124084
15
train loss item: 0.5361902713775635
16
train loss item: 0.06239146739244461
17
train loss item: 0.24785414338111877
18
train loss item: 0.2728177607059479
19
train loss item: 0.2181529402732849
20
train loss item: 0.18013903498649597
21
train loss item: 0.11029455810785294
22
train loss item: 0.8308714628219604
23
train loss item: 0.7692240476608276
24
train loss item: 0.46516314148902893
25
train loss item: 0.17210394144058228
26
train loss item: 0.16593371331691742
27
train loss item: 0.19156910479068756
28
train loss item: 0.05984686315059662
29
train loss item: 0.6064866185188293
30
train loss item: 2.044583797454834
31
train loss item: 0.49122241139411926
32
train loss item: 0.09685537964105606
33
train loss item: 0.3670729696750641
34
train loss item: 0.1285056173801422
35
train loss item: 2.2350456714630127
36
train loss item: 0.4112798273563385
37
train loss item: 0.3644225299358368
38
train loss item: 0.40765371918678284
39
train loss item: 0.1822328120470047
40
train loss item: 0.14332272112369537
41
train loss item: 0.21563832461833954
42
train loss item: 0.24513529241085052
43
train loss item: 0.15599988400936127
44
train loss item: 0.5741807222366333
45
train loss item: 0.1122502014040947
46
train loss item: 0.09547460079193115
47
train loss item: 0.30306655168533325
48
train loss item: 0.18451927602291107
49
train loss item: 0.13474076986312866
50
train loss item: 0.24320822954177856
51
train loss item: 0.7808226943016052
52
train loss item: 0.06551279872655869
53
train loss item: 0.12860722839832306
54
train loss item: 2.1197893619537354
55
train loss item: 0.1693536639213562
56
train loss item: 0.2017667293548584
57
train loss item: 0.1996225267648697
58
train loss item: 0.1350645273923874
59
train loss item: 0.10534755140542984
60
train loss item: 0.7405447959899902
61
train loss item: 2.0445973873138428
62
train loss item: 0.17452247440814972
63
train loss item: 0.31418490409851074
64
train loss item: 0.1432681381702423
65
train loss item: 0.4689277708530426
66
train loss item: 0.37651127576828003
67
train loss item: 0.17901751399040222
68
train loss item: 0.26005005836486816
69
train loss item: 0.269075870513916
70
train loss item: 0.21244744956493378
71
train loss item: 0.11154966801404953
72
train loss item: 0.14876346290111542
73
train loss item: 0.259390264749527
74
train loss item: 0.08286484330892563
75
train loss item: 0.10134658962488174
76
train loss item: 0.7582020163536072
77
train loss item: 1.2339563369750977
78
train loss item: 0.05809611827135086
79
train loss item: 0.22950749099254608
80
train loss item: 0.09507441520690918
81
train loss item: 0.16593270003795624
82
train loss item: 0.17467069625854492
83
train loss item: 0.5172245502471924
84
train loss item: 0.39591285586357117
85
train loss item: 0.4576246440410614
86
train loss item: 4.078161716461182
87
train loss item: 0.1422886699438095
88
train loss item: 0.34241369366645813
epoch train loss: 0.4224595869525095
testing phase
test loss item: 0.17349529266357422
test loss item: 0.11248848587274551
test loss item: 0.5350766777992249
test loss item: 0.2148132622241974
test loss item: 0.23277004063129425
test loss item: 0.11587153375148773
test loss item: 1.4230339527130127
test loss item: 0.4307827651500702
test loss item: 0.19923458993434906
test loss item: 0.36786985397338867
test loss item: 0.7695202231407166
test loss item: 0.14678098261356354
test loss item: 0.1612873673439026
test loss item: 0.250143438577652
test loss item: 0.16449667513370514
test loss item: 0.09973020106554031
test loss item: 0.2606044411659241
test loss item: 0.4468555450439453
test loss item: 0.5749044418334961
test loss item: 0.22874528169631958
test loss item: 0.7057313919067383
test loss item: 0.34304434061050415
test loss item: 0.25701719522476196
test loss item: 0.16406092047691345
test loss item: 0.20489230751991272
test loss item: 0.20452627539634705
test loss item: 0.2968865931034088
test loss item: 0.17405536770820618
test loss item: 0.30636143684387207
test loss item: 0.32224756479263306
test loss item: 0.6778993010520935
test loss item: 0.08616922795772552
test loss item: 0.14556802809238434
test loss item: 0.538801372051239
test loss item: 0.4002563953399658
test loss item: 0.36779674887657166
test loss item: 0.7032516598701477
test loss item: 1.3141257762908936
test loss item: 0.43412262201309204
test loss item: 0.25537198781967163
test loss item: 0.2811585068702698
test loss item: 0.14302073419094086
test loss item: 0.3523517847061157
test loss item: 0.1866900771856308
test loss item: 0.5617043375968933
test loss item: 0.3596738278865814
test loss item: 0.2686833441257477
test loss item: 0.19174475967884064
test loss item: 0.4317328631877899
test loss item: 0.620707094669342
test loss item: 0.28931090235710144
test loss item: 0.11788953840732574
test loss item: 0.21917767822742462
test loss item: 0.14701209962368011
test loss item: 0.28750231862068176
test loss item: 0.7526713013648987
test loss item: 0.4869268834590912
test loss item: 0.25518599152565
test loss item: 0.22035828232765198
test loss item: 0.20255574584007263
test loss item: 0.44313251972198486
test loss item: 0.20695772767066956
test loss item: 0.1876765936613083
test loss item: 0.23935918509960175
test loss item: 0.7181392908096313
test loss item: 0.2941373288631439
test loss item: 0.280244380235672
test loss item: 0.23870056867599487
test loss item: 0.4963534474372864
test loss item: 0.33291733264923096
test loss item: 0.07811785489320755
test loss item: 0.8162254691123962
test loss item: 0.27956968545913696
test loss item: 0.3606082797050476
test loss item: 0.12747733294963837
test loss item: 0.12769313156604767
test loss item: 0.16483142971992493
test loss item: 1.3172053098678589
test loss item: 0.38062483072280884
test loss item: 0.172181636095047
test loss item: 0.08969441056251526
test loss item: 0.8573231101036072
test loss item: 0.7646890878677368
test loss item: 0.8949189186096191
test loss item: 0.19128115475177765
test loss item: 0.2017155885696411
test loss item: 0.09374085813760757
test loss item: 0.09175210446119308
test loss item: 0.1791069507598877
Epoch [25/100], Training Loss: 0.4225, Testing Loss: 0.3575
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 26/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3834299147129059
1
train loss item: 1.0004634857177734
2
train loss item: 0.1824285089969635
3
train loss item: 0.4298737645149231
4
train loss item: 0.3287825286388397
5
train loss item: 0.2662425935268402
6
train loss item: 0.20374539494514465
7
train loss item: 0.6749088168144226
8
train loss item: 0.10561252385377884
9
train loss item: 0.20954491198062897
10
train loss item: 0.2723766267299652
11
train loss item: 0.23889575898647308
12
train loss item: 0.11617270112037659
13
train loss item: 0.41677433252334595
14
train loss item: 0.19821155071258545
15
train loss item: 0.5198978781700134
16
train loss item: 0.05977078527212143
17
train loss item: 0.23859506845474243
18
train loss item: 0.268422394990921
19
train loss item: 0.20820657908916473
20
train loss item: 0.16715015470981598
21
train loss item: 0.10907775908708572
22
train loss item: 0.8066458702087402
23
train loss item: 0.7490767240524292
24
train loss item: 0.45687609910964966
25
train loss item: 0.17203472554683685
26
train loss item: 0.16339270770549774
27
train loss item: 0.18860621750354767
28
train loss item: 0.05712735280394554
29
train loss item: 0.5908965468406677
30
train loss item: 2.0159859657287598
31
train loss item: 0.47989293932914734
32
train loss item: 0.09233138710260391
33
train loss item: 0.3563457131385803
34
train loss item: 0.12644866108894348
35
train loss item: 2.2155282497406006
36
train loss item: 0.4114159047603607
37
train loss item: 0.35601991415023804
38
train loss item: 0.4082103967666626
39
train loss item: 0.17956802248954773
40
train loss item: 0.14769352972507477
41
train loss item: 0.2130344659090042
42
train loss item: 0.23940736055374146
43
train loss item: 0.15271857380867004
44
train loss item: 0.5652453303337097
45
train loss item: 0.11185713112354279
46
train loss item: 0.09552948921918869
47
train loss item: 0.2940140664577484
48
train loss item: 0.18033920228481293
49
train loss item: 0.13493964076042175
50
train loss item: 0.23390258848667145
51
train loss item: 0.7646350860595703
52
train loss item: 0.06182662397623062
53
train loss item: 0.1263832300901413
54
train loss item: 2.0996713638305664
55
train loss item: 0.16649003326892853
56
train loss item: 0.19741041958332062
57
train loss item: 0.195948526263237
58
train loss item: 0.13554339110851288
59
train loss item: 0.10085165500640869
60
train loss item: 0.7239329218864441
61
train loss item: 2.0174789428710938
62
train loss item: 0.17274655401706696
63
train loss item: 0.30520573258399963
64
train loss item: 0.13981114327907562
65
train loss item: 0.4557555317878723
66
train loss item: 0.37318071722984314
67
train loss item: 0.17557330429553986
68
train loss item: 0.25395503640174866
69
train loss item: 0.260480135679245
70
train loss item: 0.2050056755542755
71
train loss item: 0.10878533124923706
72
train loss item: 0.14297285676002502
73
train loss item: 0.25316429138183594
74
train loss item: 0.0820441022515297
75
train loss item: 0.09777369350194931
76
train loss item: 0.7403085827827454
77
train loss item: 1.2196065187454224
78
train loss item: 0.05998248979449272
79
train loss item: 0.22377105057239532
80
train loss item: 0.09588827937841415
81
train loss item: 0.16312360763549805
82
train loss item: 0.1738204061985016
83
train loss item: 0.5039704442024231
84
train loss item: 0.3904474675655365
85
train loss item: 0.4452822208404541
86
train loss item: 4.049330234527588
87
train loss item: 0.14639021456241608
88
train loss item: 0.3351738452911377
epoch train loss: 0.4152515783403697
testing phase
test loss item: 0.16706183552742004
test loss item: 0.10474364459514618
test loss item: 0.5264284014701843
test loss item: 0.20981474220752716
test loss item: 0.22585438191890717
test loss item: 0.10553926229476929
test loss item: 1.4492994546890259
test loss item: 0.44383686780929565
test loss item: 0.19682592153549194
test loss item: 0.3613482415676117
test loss item: 0.7595275640487671
test loss item: 0.14365920424461365
test loss item: 0.16076424717903137
test loss item: 0.24418382346630096
test loss item: 0.15519030392169952
test loss item: 0.10406514257192612
test loss item: 0.2651386559009552
test loss item: 0.4366813600063324
test loss item: 0.5822161436080933
test loss item: 0.2355794906616211
test loss item: 0.6896794438362122
test loss item: 0.3484085500240326
test loss item: 0.2542603015899658
test loss item: 0.15925869345664978
test loss item: 0.20177629590034485
test loss item: 0.20534823834896088
test loss item: 0.29389166831970215
test loss item: 0.1687009185552597
test loss item: 0.30246561765670776
test loss item: 0.3173338770866394
test loss item: 0.6783021688461304
test loss item: 0.09288936853408813
test loss item: 0.13675861060619354
test loss item: 0.527286946773529
test loss item: 0.3913109004497528
test loss item: 0.370239794254303
test loss item: 0.7071390151977539
test loss item: 1.2921998500823975
test loss item: 0.42484766244888306
test loss item: 0.2545848786830902
test loss item: 0.28507351875305176
test loss item: 0.14306068420410156
test loss item: 0.3428124785423279
test loss item: 0.1869809627532959
test loss item: 0.5476696491241455
test loss item: 0.3681911528110504
test loss item: 0.2647040784358978
test loss item: 0.19567646086215973
test loss item: 0.4261045753955841
test loss item: 0.6188704967498779
test loss item: 0.27920034527778625
test loss item: 0.117276132106781
test loss item: 0.21755963563919067
test loss item: 0.13833926618099213
test loss item: 0.2807794511318207
test loss item: 0.7403576970100403
test loss item: 0.48599973320961
test loss item: 0.24512088298797607
test loss item: 0.2185487002134323
test loss item: 0.1967199295759201
test loss item: 0.43104180693626404
test loss item: 0.21667130291461945
test loss item: 0.19025760889053345
test loss item: 0.23873953521251678
test loss item: 0.7143338322639465
test loss item: 0.28932204842567444
test loss item: 0.28556713461875916
test loss item: 0.24115097522735596
test loss item: 0.48659810423851013
test loss item: 0.34691011905670166
test loss item: 0.08107932657003403
test loss item: 0.837066113948822
test loss item: 0.2780745029449463
test loss item: 0.37143006920814514
test loss item: 0.1309627890586853
test loss item: 0.12589313089847565
test loss item: 0.1620183289051056
test loss item: 1.2906494140625
test loss item: 0.37762686610221863
test loss item: 0.16722804307937622
test loss item: 0.08211123198270798
test loss item: 0.8609626889228821
test loss item: 0.7687721848487854
test loss item: 0.8815733194351196
test loss item: 0.19100254774093628
test loss item: 0.2044808715581894
test loss item: 0.08704204112291336
test loss item: 0.09434457123279572
test loss item: 0.17183338105678558
Epoch [26/100], Training Loss: 0.4153, Testing Loss: 0.3550
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 27/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3781145215034485
1
train loss item: 0.9745936989784241
2
train loss item: 0.17802870273590088
3
train loss item: 0.41014227271080017
4
train loss item: 0.3320058584213257
5
train loss item: 0.26273947954177856
6
train loss item: 0.20280437171459198
7
train loss item: 0.6585060358047485
8
train loss item: 0.10097531229257584
9
train loss item: 0.20537137985229492
10
train loss item: 0.2631172835826874
11
train loss item: 0.23214860260486603
12
train loss item: 0.11832115054130554
13
train loss item: 0.4032759368419647
14
train loss item: 0.19097557663917542
15
train loss item: 0.5037447810173035
16
train loss item: 0.058800384402275085
17
train loss item: 0.23030969500541687
18
train loss item: 0.2643621563911438
19
train loss item: 0.20597048103809357
20
train loss item: 0.1630466878414154
21
train loss item: 0.1054186001420021
22
train loss item: 0.780686616897583
23
train loss item: 0.7220965027809143
24
train loss item: 0.4555414021015167
25
train loss item: 0.17384564876556396
26
train loss item: 0.1641688346862793
27
train loss item: 0.18025483191013336
28
train loss item: 0.05656836926937103
29
train loss item: 0.5741254091262817
30
train loss item: 1.9851181507110596
31
train loss item: 0.46562665700912476
32
train loss item: 0.09582199901342392
33
train loss item: 0.3304656445980072
34
train loss item: 0.12366113066673279
35
train loss item: 2.1947178840637207
36
train loss item: 0.4060031771659851
37
train loss item: 0.3467629551887512
38
train loss item: 0.4104650914669037
39
train loss item: 0.1766795814037323
40
train loss item: 0.15373444557189941
41
train loss item: 0.20620755851268768
42
train loss item: 0.239867702126503
43
train loss item: 0.14567886292934418
44
train loss item: 0.5500105023384094
45
train loss item: 0.10937613248825073
46
train loss item: 0.09371267259120941
47
train loss item: 0.28799107670783997
48
train loss item: 0.17607372999191284
49
train loss item: 0.12754711508750916
50
train loss item: 0.22893431782722473
51
train loss item: 0.7463327050209045
52
train loss item: 0.059408560395240784
53
train loss item: 0.1248883530497551
54
train loss item: 2.0785858631134033
55
train loss item: 0.1583426594734192
56
train loss item: 0.18986505270004272
57
train loss item: 0.19634881615638733
58
train loss item: 0.1352008432149887
59
train loss item: 0.10303191095590591
60
train loss item: 0.7036382555961609
61
train loss item: 1.9841980934143066
62
train loss item: 0.17216742038726807
63
train loss item: 0.29711946845054626
64
train loss item: 0.12953603267669678
65
train loss item: 0.4419063329696655
66
train loss item: 0.3673344552516937
67
train loss item: 0.17266392707824707
68
train loss item: 0.2491813600063324
69
train loss item: 0.2562267482280731
70
train loss item: 0.20117713510990143
71
train loss item: 0.10936951637268066
72
train loss item: 0.13529963791370392
73
train loss item: 0.2490241825580597
74
train loss item: 0.08731929212808609
75
train loss item: 0.09609244018793106
76
train loss item: 0.7197718620300293
77
train loss item: 1.2042102813720703
78
train loss item: 0.061945103108882904
79
train loss item: 0.21893249452114105
80
train loss item: 0.09680674970149994
81
train loss item: 0.1620299071073532
82
train loss item: 0.16313302516937256
83
train loss item: 0.49234724044799805
84
train loss item: 0.3837014436721802
85
train loss item: 0.43232911825180054
86
train loss item: 4.017520427703857
87
train loss item: 0.1477072387933731
88
train loss item: 0.33708855509757996
epoch train loss: 0.4077112301346961
testing phase
test loss item: 0.16202881932258606
test loss item: 0.10578969866037369
test loss item: 0.5229548215866089
test loss item: 0.20726893842220306
test loss item: 0.22391244769096375
test loss item: 0.1049228310585022
test loss item: 1.4450774192810059
test loss item: 0.4546207785606384
test loss item: 0.19791951775550842
test loss item: 0.35712164640426636
test loss item: 0.7563952207565308
test loss item: 0.14512169361114502
test loss item: 0.1665724515914917
test loss item: 0.23974862694740295
test loss item: 0.1537291258573532
test loss item: 0.10770012438297272
test loss item: 0.26545029878616333
test loss item: 0.4254615306854248
test loss item: 0.5873845815658569
test loss item: 0.2425115704536438
test loss item: 0.6732279658317566
test loss item: 0.3508312702178955
test loss item: 0.2491646260023117
test loss item: 0.15978002548217773
test loss item: 0.1965475082397461
test loss item: 0.20766936242580414
test loss item: 0.2908892333507538
test loss item: 0.16938453912734985
test loss item: 0.3005494773387909
test loss item: 0.31268301606178284
test loss item: 0.6765511631965637
test loss item: 0.09910911321640015
test loss item: 0.13565848767757416
test loss item: 0.5171228051185608
test loss item: 0.3834567368030548
test loss item: 0.37628936767578125
test loss item: 0.7071845531463623
test loss item: 1.2823587656021118
test loss item: 0.4156250059604645
test loss item: 0.25358521938323975
test loss item: 0.28162893652915955
test loss item: 0.14771024882793427
test loss item: 0.3330110013484955
test loss item: 0.18408212065696716
test loss item: 0.5335948467254639
test loss item: 0.375237375497818
test loss item: 0.2605375051498413
test loss item: 0.19999352097511292
test loss item: 0.42451193928718567
test loss item: 0.618864893913269
test loss item: 0.2733795642852783
test loss item: 0.12023195624351501
test loss item: 0.2126869112253189
test loss item: 0.13740500807762146
test loss item: 0.2750604450702667
test loss item: 0.7354655265808105
test loss item: 0.48618271946907043
test loss item: 0.2347627878189087
test loss item: 0.2171846330165863
test loss item: 0.19506530463695526
test loss item: 0.41967013478279114
test loss item: 0.2243940532207489
test loss item: 0.194717675447464
test loss item: 0.23902209103107452
test loss item: 0.7139679789543152
test loss item: 0.285432368516922
test loss item: 0.2897331118583679
test loss item: 0.24059313535690308
test loss item: 0.47915032505989075
test loss item: 0.3606879413127899
test loss item: 0.0876617580652237
test loss item: 0.8410941362380981
test loss item: 0.275849312543869
test loss item: 0.3757280111312866
test loss item: 0.13507167994976044
test loss item: 0.1269107460975647
test loss item: 0.16301384568214417
test loss item: 1.2761468887329102
test loss item: 0.373247891664505
test loss item: 0.1670437455177307
test loss item: 0.07772549986839294
test loss item: 0.8617393374443054
test loss item: 0.7689619660377502
test loss item: 0.8776789307594299
test loss item: 0.18901024758815765
test loss item: 0.20615021884441376
test loss item: 0.08181220293045044
test loss item: 0.09436896443367004
test loss item: 0.17336539924144745
Epoch [27/100], Training Loss: 0.4077, Testing Loss: 0.3537
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 28/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.37319236993789673
1
train loss item: 0.9513962864875793
2
train loss item: 0.17568345367908478
3
train loss item: 0.3935128450393677
4
train loss item: 0.33313918113708496
5
train loss item: 0.26069191098213196
6
train loss item: 0.20027202367782593
7
train loss item: 0.6446107625961304
8
train loss item: 0.0984860211610794
9
train loss item: 0.20321163535118103
10
train loss item: 0.25363248586654663
11
train loss item: 0.22682559490203857
12
train loss item: 0.11622520536184311
13
train loss item: 0.39011135697364807
14
train loss item: 0.1844272017478943
15
train loss item: 0.49142691493034363
16
train loss item: 0.05698112025856972
17
train loss item: 0.22360292077064514
18
train loss item: 0.2603151202201843
19
train loss item: 0.20871655642986298
20
train loss item: 0.1593835949897766
21
train loss item: 0.10468020290136337
22
train loss item: 0.7547134160995483
23
train loss item: 0.6995294690132141
24
train loss item: 0.4518773853778839
25
train loss item: 0.17110104858875275
26
train loss item: 0.16586200892925262
27
train loss item: 0.17440079152584076
28
train loss item: 0.05499344319105148
29
train loss item: 0.555998682975769
30
train loss item: 1.9567835330963135
31
train loss item: 0.4532668888568878
32
train loss item: 0.09885438531637192
33
train loss item: 0.3103482723236084
34
train loss item: 0.12693755328655243
35
train loss item: 2.175245523452759
36
train loss item: 0.397121399641037
37
train loss item: 0.3431602716445923
38
train loss item: 0.40781959891319275
39
train loss item: 0.17354704439640045
40
train loss item: 0.14935359358787537
41
train loss item: 0.20021028816699982
42
train loss item: 0.24369437992572784
43
train loss item: 0.14064569771289825
44
train loss item: 0.5368865132331848
45
train loss item: 0.10925499349832535
46
train loss item: 0.09881015121936798
47
train loss item: 0.28121766448020935
48
train loss item: 0.17363087832927704
49
train loss item: 0.12131558358669281
50
train loss item: 0.22633494436740875
51
train loss item: 0.7275682687759399
52
train loss item: 0.059602100402116776
53
train loss item: 0.1191272884607315
54
train loss item: 2.0596365928649902
55
train loss item: 0.15290430188179016
56
train loss item: 0.1855964958667755
57
train loss item: 0.19802477955818176
58
train loss item: 0.13354481756687164
59
train loss item: 0.10948409140110016
60
train loss item: 0.6848163604736328
61
train loss item: 1.9569928646087646
62
train loss item: 0.16849389672279358
63
train loss item: 0.29132381081581116
64
train loss item: 0.1242615282535553
65
train loss item: 0.42833855748176575
66
train loss item: 0.3605160713195801
67
train loss item: 0.17049087584018707
68
train loss item: 0.24157170951366425
69
train loss item: 0.2547752559185028
70
train loss item: 0.19673946499824524
71
train loss item: 0.1090058758854866
72
train loss item: 0.13164681196212769
73
train loss item: 0.24615082144737244
74
train loss item: 0.0867420956492424
75
train loss item: 0.09509773552417755
76
train loss item: 0.7031105756759644
77
train loss item: 1.1878448724746704
78
train loss item: 0.06001052260398865
79
train loss item: 0.2176753729581833
80
train loss item: 0.09794982522726059
81
train loss item: 0.1563849300146103
82
train loss item: 0.15577411651611328
83
train loss item: 0.4838525354862213
84
train loss item: 0.38079479336738586
85
train loss item: 0.4192596971988678
86
train loss item: 3.988041877746582
87
train loss item: 0.1385253369808197
88
train loss item: 0.33736300468444824
epoch train loss: 0.40092674274457973
testing phase
test loss item: 0.15954962372779846
test loss item: 0.10695233196020126
test loss item: 0.5385382771492004
test loss item: 0.20724612474441528
test loss item: 0.22456559538841248
test loss item: 0.10484755039215088
test loss item: 1.408096194267273
test loss item: 0.4440157115459442
test loss item: 0.20662622153759003
test loss item: 0.3621954023838043
test loss item: 0.7757552266120911
test loss item: 0.15023022890090942
test loss item: 0.16719001531600952
test loss item: 0.24227240681648254
test loss item: 0.15569978952407837
test loss item: 0.10749746859073639
test loss item: 0.25757959485054016
test loss item: 0.427021861076355
test loss item: 0.5811343789100647
test loss item: 0.23739483952522278
test loss item: 0.6785872578620911
test loss item: 0.34531858563423157
test loss item: 0.24738089740276337
test loss item: 0.1576855480670929
test loss item: 0.1939302235841751
test loss item: 0.20589952170848846
test loss item: 0.2890823185443878
test loss item: 0.16928665339946747
test loss item: 0.29910582304000854
test loss item: 0.31102097034454346
test loss item: 0.6837547421455383
test loss item: 0.10020434111356735
test loss item: 0.13425345718860626
test loss item: 0.5207127928733826
test loss item: 0.38900288939476013
test loss item: 0.39011451601982117
test loss item: 0.6972867250442505
test loss item: 1.3183672428131104
test loss item: 0.41757580637931824
test loss item: 0.24826385080814362
test loss item: 0.27361705899238586
test loss item: 0.14947880804538727
test loss item: 0.3348844349384308
test loss item: 0.18246960639953613
test loss item: 0.5367892980575562
test loss item: 0.3656909763813019
test loss item: 0.2584502398967743
test loss item: 0.19613990187644958
test loss item: 0.4317852556705475
test loss item: 0.6290849447250366
test loss item: 0.28179097175598145
test loss item: 0.11810459941625595
test loss item: 0.21074967086315155
test loss item: 0.14824959635734558
test loss item: 0.2793571650981903
test loss item: 0.7596953511238098
test loss item: 0.4862399697303772
test loss item: 0.23582588136196136
test loss item: 0.21444249153137207
test loss item: 0.19715358316898346
test loss item: 0.4242735505104065
test loss item: 0.2191912829875946
test loss item: 0.19361086189746857
test loss item: 0.23650501668453217
test loss item: 0.7267951965332031
test loss item: 0.2870756685733795
test loss item: 0.2841465473175049
test loss item: 0.23544490337371826
test loss item: 0.47978949546813965
test loss item: 0.3705044686794281
test loss item: 0.08958370983600616
test loss item: 0.8155534267425537
test loss item: 0.2756984829902649
test loss item: 0.3676062524318695
test loss item: 0.1329350769519806
test loss item: 0.1255929172039032
test loss item: 0.1607404500246048
test loss item: 1.3089033365249634
test loss item: 0.371931254863739
test loss item: 0.16597218811511993
test loss item: 0.07705005258321762
test loss item: 0.867035984992981
test loss item: 0.7690133452415466
test loss item: 0.9062169790267944
test loss item: 0.18578708171844482
test loss item: 0.20208021998405457
test loss item: 0.08007366210222244
test loss item: 0.09312508255243301
test loss item: 0.17849627137184143
Epoch [28/100], Training Loss: 0.4009, Testing Loss: 0.3549
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Epoch 29/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36731091141700745
1
train loss item: 0.9326038360595703
2
train loss item: 0.16657394170761108
3
train loss item: 0.38922297954559326
4
train loss item: 0.32888805866241455
5
train loss item: 0.2551914155483246
6
train loss item: 0.191889688372612
7
train loss item: 0.6361575722694397
8
train loss item: 0.09772432595491409
9
train loss item: 0.19756467640399933
10
train loss item: 0.24754367768764496
11
train loss item: 0.22492238879203796
12
train loss item: 0.111416295170784
13
train loss item: 0.3830171227455139
14
train loss item: 0.18058301508426666
15
train loss item: 0.47754985094070435
16
train loss item: 0.05743652209639549
17
train loss item: 0.2182520031929016
18
train loss item: 0.252162367105484
19
train loss item: 0.20195643603801727
20
train loss item: 0.155581533908844
21
train loss item: 0.10243500769138336
22
train loss item: 0.724821925163269
23
train loss item: 0.6907150149345398
24
train loss item: 0.43658724427223206
25
train loss item: 0.1669609546661377
26
train loss item: 0.16278935968875885
27
train loss item: 0.17217662930488586
28
train loss item: 0.05523640289902687
29
train loss item: 0.5393355488777161
30
train loss item: 1.9386155605316162
31
train loss item: 0.4442041516304016
32
train loss item: 0.0891624167561531
33
train loss item: 0.31171441078186035
34
train loss item: 0.1348559558391571
35
train loss item: 2.1602768898010254
36
train loss item: 0.3919623792171478
37
train loss item: 0.3445332646369934
38
train loss item: 0.40128082036972046
39
train loss item: 0.16789725422859192
40
train loss item: 0.13648028671741486
41
train loss item: 0.19619609415531158
42
train loss item: 0.2418522983789444
43
train loss item: 0.13734017312526703
44
train loss item: 0.5322074890136719
45
train loss item: 0.11136447638273239
46
train loss item: 0.09575185924768448
47
train loss item: 0.2699089050292969
48
train loss item: 0.16807276010513306
49
train loss item: 0.12180550396442413
50
train loss item: 0.21723489463329315
51
train loss item: 0.7140358090400696
52
train loss item: 0.06092317774891853
53
train loss item: 0.11598239094018936
54
train loss item: 2.045841693878174
55
train loss item: 0.14991869032382965
56
train loss item: 0.18397480249404907
57
train loss item: 0.19231382012367249
58
train loss item: 0.12663820385932922
59
train loss item: 0.11112672835588455
60
train loss item: 0.6710049510002136
61
train loss item: 1.9441829919815063
62
train loss item: 0.1583530753850937
63
train loss item: 0.28325438499450684
64
train loss item: 0.12535248696804047
65
train loss item: 0.41242608428001404
66
train loss item: 0.35143041610717773
67
train loss item: 0.16504070162773132
68
train loss item: 0.22519898414611816
69
train loss item: 0.24693027138710022
70
train loss item: 0.19014707207679749
71
train loss item: 0.10420941561460495
72
train loss item: 0.13125568628311157
73
train loss item: 0.23988744616508484
74
train loss item: 0.0816107988357544
75
train loss item: 0.0947166457772255
76
train loss item: 0.6922959089279175
77
train loss item: 1.171653389930725
78
train loss item: 0.0568990632891655
79
train loss item: 0.21549324691295624
80
train loss item: 0.0971081480383873
81
train loss item: 0.14908196032047272
82
train loss item: 0.1555289328098297
83
train loss item: 0.47502610087394714
84
train loss item: 0.3788571059703827
85
train loss item: 0.40990152955055237
86
train loss item: 3.9656190872192383
87
train loss item: 0.13306763768196106
88
train loss item: 0.32202571630477905
epoch train loss: 0.39422066413452117
testing phase
test loss item: 0.1579446792602539
test loss item: 0.10418128967285156
test loss item: 0.5398536920547485
test loss item: 0.20805275440216064
test loss item: 0.2217545211315155
test loss item: 0.10361489653587341
test loss item: 1.4148725271224976
test loss item: 0.46739667654037476
test loss item: 0.203828826546669
test loss item: 0.3575412333011627
test loss item: 0.766609251499176
test loss item: 0.15332359075546265
test loss item: 0.1647683084011078
test loss item: 0.2418353110551834
test loss item: 0.1530706137418747
test loss item: 0.1050192266702652
test loss item: 0.2565382421016693
test loss item: 0.422744482755661
test loss item: 0.5808491706848145
test loss item: 0.23490431904792786
test loss item: 0.6819095611572266
test loss item: 0.3510882258415222
test loss item: 0.24761733412742615
test loss item: 0.15532462298870087
test loss item: 0.19193512201309204
test loss item: 0.20405979454517365
test loss item: 0.28491896390914917
test loss item: 0.16593670845031738
test loss item: 0.29442280530929565
test loss item: 0.3065919280052185
test loss item: 0.6816253066062927
test loss item: 0.09706751257181168
test loss item: 0.1321270614862442
test loss item: 0.5169655084609985
test loss item: 0.38758406043052673
test loss item: 0.37671220302581787
test loss item: 0.6993169188499451
test loss item: 1.3072901964187622
test loss item: 0.41508951783180237
test loss item: 0.2465222179889679
test loss item: 0.2724796533584595
test loss item: 0.14487537741661072
test loss item: 0.3276602625846863
test loss item: 0.18631473183631897
test loss item: 0.5370925068855286
test loss item: 0.365888774394989
test loss item: 0.25487977266311646
test loss item: 0.19145984947681427
test loss item: 0.43304893374443054
test loss item: 0.6226094365119934
test loss item: 0.28028354048728943
test loss item: 0.116971455514431
test loss item: 0.2087613344192505
test loss item: 0.15790465474128723
test loss item: 0.27792638540267944
test loss item: 0.7558697462081909
test loss item: 0.4875514805316925
test loss item: 0.23687385022640228
test loss item: 0.21382124722003937
test loss item: 0.19160878658294678
test loss item: 0.41552814841270447
test loss item: 0.22642533481121063
test loss item: 0.1933153122663498
test loss item: 0.2321266084909439
test loss item: 0.7409854531288147
test loss item: 0.29025739431381226
test loss item: 0.2853914201259613
test loss item: 0.23255093395709991
test loss item: 0.4764963984489441
test loss item: 0.35665401816368103
test loss item: 0.08599334210157394
test loss item: 0.8295713067054749
test loss item: 0.27605554461479187
test loss item: 0.3686487376689911
test loss item: 0.13092981278896332
test loss item: 0.12118697166442871
test loss item: 0.15865416824817657
test loss item: 1.3130627870559692
test loss item: 0.3711887300014496
test loss item: 0.16317342221736908
test loss item: 0.07567087560892105
test loss item: 0.8666024804115295
test loss item: 0.7659900784492493
test loss item: 0.9064193964004517
test loss item: 0.1851256787776947
test loss item: 0.19754387438297272
test loss item: 0.07942768186330795
test loss item: 0.091883085668087
test loss item: 0.17539553344249725
Epoch [29/100], Training Loss: 0.3942, Testing Loss: 0.3537
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 30/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36034882068634033
1
train loss item: 0.9165389537811279
2
train loss item: 0.16212913393974304
3
train loss item: 0.3744274973869324
4
train loss item: 0.3130091428756714
5
train loss item: 0.248446524143219
6
train loss item: 0.18612556159496307
7
train loss item: 0.6255545020103455
8
train loss item: 0.09409883618354797
9
train loss item: 0.19038733839988708
10
train loss item: 0.23761823773384094
11
train loss item: 0.22116287052631378
12
train loss item: 0.11277987062931061
13
train loss item: 0.36955970525741577
14
train loss item: 0.1778772920370102
15
train loss item: 0.47858625650405884
16
train loss item: 0.06159219145774841
17
train loss item: 0.217027485370636
18
train loss item: 0.24522764980793
19
train loss item: 0.19657155871391296
20
train loss item: 0.16066579520702362
21
train loss item: 0.10602546483278275
22
train loss item: 0.7226999998092651
23
train loss item: 0.6714286208152771
24
train loss item: 0.4304174482822418
25
train loss item: 0.16480466723442078
26
train loss item: 0.1629006564617157
27
train loss item: 0.16890357434749603
28
train loss item: 0.05815919116139412
29
train loss item: 0.5336197018623352
30
train loss item: 1.9152958393096924
31
train loss item: 0.4255421459674835
32
train loss item: 0.083079993724823
33
train loss item: 0.29986345767974854
34
train loss item: 0.12889668345451355
35
train loss item: 2.143216133117676
36
train loss item: 0.37815460562705994
37
train loss item: 0.3395789861679077
38
train loss item: 0.37376847863197327
39
train loss item: 0.16448438167572021
40
train loss item: 0.13398733735084534
41
train loss item: 0.19002923369407654
42
train loss item: 0.2364213913679123
43
train loss item: 0.1363367736339569
44
train loss item: 0.5230177044868469
45
train loss item: 0.10627797245979309
46
train loss item: 0.09270410239696503
47
train loss item: 0.26471951603889465
48
train loss item: 0.16188348829746246
49
train loss item: 0.11738987267017365
50
train loss item: 0.21337153017520905
51
train loss item: 0.7005702257156372
52
train loss item: 0.06203213706612587
53
train loss item: 0.11612393707036972
54
train loss item: 2.029327392578125
55
train loss item: 0.147736594080925
56
train loss item: 0.178969606757164
57
train loss item: 0.1864166110754013
58
train loss item: 0.12747155129909515
59
train loss item: 0.1056758463382721
60
train loss item: 0.6646850109100342
61
train loss item: 1.9242494106292725
62
train loss item: 0.15335237979888916
63
train loss item: 0.276747465133667
64
train loss item: 0.12285272032022476
65
train loss item: 0.40585383772850037
66
train loss item: 0.3404916822910309
67
train loss item: 0.16140148043632507
68
train loss item: 0.22818762063980103
69
train loss item: 0.24086980521678925
70
train loss item: 0.18654534220695496
71
train loss item: 0.10260745137929916
72
train loss item: 0.1263446807861328
73
train loss item: 0.23342420160770416
74
train loss item: 0.0732552632689476
75
train loss item: 0.09499715268611908
76
train loss item: 0.6758061647415161
77
train loss item: 1.1606523990631104
78
train loss item: 0.0563463531434536
79
train loss item: 0.2110053300857544
80
train loss item: 0.09137978404760361
81
train loss item: 0.14886662364006042
82
train loss item: 0.153006911277771
83
train loss item: 0.46816304326057434
84
train loss item: 0.37106817960739136
85
train loss item: 0.39635902643203735
86
train loss item: 3.94020938873291
87
train loss item: 0.13254742324352264
88
train loss item: 0.3126775324344635
epoch train loss: 0.38769653644622043
testing phase
test loss item: 0.15958838164806366
test loss item: 0.09568615257740021
test loss item: 0.5359131693840027
test loss item: 0.2069164663553238
test loss item: 0.2163820117712021
test loss item: 0.10130345076322556
test loss item: 1.4302409887313843
test loss item: 0.46399274468421936
test loss item: 0.20294611155986786
test loss item: 0.350835382938385
test loss item: 0.7611181735992432
test loss item: 0.14997516572475433
test loss item: 0.1535717099905014
test loss item: 0.23702551424503326
test loss item: 0.1477317065000534
test loss item: 0.09328988939523697
test loss item: 0.25258851051330566
test loss item: 0.4166177809238434
test loss item: 0.5738036036491394
test loss item: 0.22643321752548218
test loss item: 0.6720647215843201
test loss item: 0.34867915511131287
test loss item: 0.24650409817695618
test loss item: 0.15205924212932587
test loss item: 0.19089920818805695
test loss item: 0.19671140611171722
test loss item: 0.2820127308368683
test loss item: 0.1601807177066803
test loss item: 0.2889447808265686
test loss item: 0.30117473006248474
test loss item: 0.6835126876831055
test loss item: 0.08513476699590683
test loss item: 0.1286982148885727
test loss item: 0.509497344493866
test loss item: 0.3825622498989105
test loss item: 0.3696802854537964
test loss item: 0.6927178502082825
test loss item: 1.2985128164291382
test loss item: 0.4098707139492035
test loss item: 0.2465863972902298
test loss item: 0.2743084728717804
test loss item: 0.1409052163362503
test loss item: 0.3218647241592407
test loss item: 0.1893879771232605
test loss item: 0.5272014737129211
test loss item: 0.3511689007282257
test loss item: 0.24848544597625732
test loss item: 0.1853996366262436
test loss item: 0.4256036579608917
test loss item: 0.6177836656570435
test loss item: 0.2731699049472809
test loss item: 0.11167001724243164
test loss item: 0.2089666873216629
test loss item: 0.1570834219455719
test loss item: 0.2736608684062958
test loss item: 0.752018928527832
test loss item: 0.4835544228553772
test loss item: 0.22905902564525604
test loss item: 0.20810486376285553
test loss item: 0.18263834714889526
test loss item: 0.4089551270008087
test loss item: 0.21978788077831268
test loss item: 0.18684805929660797
test loss item: 0.2257116138935089
test loss item: 0.7417951822280884
test loss item: 0.28947243094444275
test loss item: 0.2794433534145355
test loss item: 0.23032262921333313
test loss item: 0.46699076890945435
test loss item: 0.3540603816509247
test loss item: 0.07497872412204742
test loss item: 0.8318762183189392
test loss item: 0.2731306850910187
test loss item: 0.3682158887386322
test loss item: 0.12609915435314178
test loss item: 0.11845017969608307
test loss item: 0.15607482194900513
test loss item: 1.3060187101364136
test loss item: 0.36890968680381775
test loss item: 0.16017332673072815
test loss item: 0.07706744968891144
test loss item: 0.8676353096961975
test loss item: 0.7636110782623291
test loss item: 0.9033622741699219
test loss item: 0.18409910798072815
test loss item: 0.18991832435131073
test loss item: 0.07854166626930237
test loss item: 0.08486909419298172
test loss item: 0.17228932678699493
Epoch [30/100], Training Loss: 0.3877, Testing Loss: 0.3494
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 31/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3546921908855438
1
train loss item: 0.896126925945282
2
train loss item: 0.15897049009799957
3
train loss item: 0.36870309710502625
4
train loss item: 0.2973933219909668
5
train loss item: 0.24376825988292694
6
train loss item: 0.18566302955150604
7
train loss item: 0.6135778427124023
8
train loss item: 0.094399094581604
9
train loss item: 0.18518780171871185
10
train loss item: 0.23505957424640656
11
train loss item: 0.22220715880393982
12
train loss item: 0.11778794229030609
13
train loss item: 0.363520085811615
14
train loss item: 0.1772768348455429
15
train loss item: 0.466782808303833
16
train loss item: 0.06670908629894257
17
train loss item: 0.2158176600933075
18
train loss item: 0.23909243941307068
19
train loss item: 0.18312184512615204
20
train loss item: 0.16337694227695465
21
train loss item: 0.10784459859132767
22
train loss item: 0.7034399509429932
23
train loss item: 0.6545329093933105
24
train loss item: 0.41609200835227966
25
train loss item: 0.16392020881175995
26
train loss item: 0.16424572467803955
27
train loss item: 0.1655566543340683
28
train loss item: 0.06310361623764038
29
train loss item: 0.5257018208503723
30
train loss item: 1.8968539237976074
31
train loss item: 0.41488170623779297
32
train loss item: 0.07911980897188187
33
train loss item: 0.2930485010147095
34
train loss item: 0.1246907040476799
35
train loss item: 2.1284828186035156
36
train loss item: 0.37170830368995667
37
train loss item: 0.3354067802429199
38
train loss item: 0.3624565601348877
39
train loss item: 0.16308371722698212
40
train loss item: 0.13480731844902039
41
train loss item: 0.187172994017601
42
train loss item: 0.22826792299747467
43
train loss item: 0.13695071637630463
44
train loss item: 0.5152370929718018
45
train loss item: 0.10173672437667847
46
train loss item: 0.09254762530326843
47
train loss item: 0.2572305202484131
48
train loss item: 0.15621502697467804
49
train loss item: 0.11645496636629105
50
train loss item: 0.20311672985553741
51
train loss item: 0.6915866732597351
52
train loss item: 0.06330353766679764
53
train loss item: 0.11579395830631256
54
train loss item: 2.014232873916626
55
train loss item: 0.14487719535827637
56
train loss item: 0.1749095916748047
57
train loss item: 0.1807064712047577
58
train loss item: 0.1305249035358429
59
train loss item: 0.09902993589639664
60
train loss item: 0.653200089931488
61
train loss item: 1.905738115310669
62
train loss item: 0.15068751573562622
63
train loss item: 0.2687053978443146
64
train loss item: 0.12230376154184341
65
train loss item: 0.39150679111480713
66
train loss item: 0.3323279917240143
67
train loss item: 0.1585986465215683
68
train loss item: 0.22123900055885315
69
train loss item: 0.2302902340888977
70
train loss item: 0.18249046802520752
71
train loss item: 0.10345446318387985
72
train loss item: 0.1217169463634491
73
train loss item: 0.2269679307937622
74
train loss item: 0.072913758456707
75
train loss item: 0.09677957743406296
76
train loss item: 0.6556273698806763
77
train loss item: 1.1503970623016357
78
train loss item: 0.05941585451364517
79
train loss item: 0.2076568454504013
80
train loss item: 0.08830193430185318
81
train loss item: 0.15037575364112854
82
train loss item: 0.15058250725269318
83
train loss item: 0.45691466331481934
84
train loss item: 0.36073338985443115
85
train loss item: 0.3871409296989441
86
train loss item: 3.917354106903076
87
train loss item: 0.1306036412715912
88
train loss item: 0.2994997501373291
epoch train loss: 0.38181609015786244
testing phase
test loss item: 0.1589951068162918
test loss item: 0.08943033218383789
test loss item: 0.5159515738487244
test loss item: 0.20370836555957794
test loss item: 0.20935118198394775
test loss item: 0.09877286851406097
test loss item: 1.4564995765686035
test loss item: 0.47205251455307007
test loss item: 0.1960570216178894
test loss item: 0.3368741273880005
test loss item: 0.7364901900291443
test loss item: 0.14515496790409088
test loss item: 0.1521638184785843
test loss item: 0.2347368746995926
test loss item: 0.14240244030952454
test loss item: 0.08363370597362518
test loss item: 0.25238037109375
test loss item: 0.39900684356689453
test loss item: 0.5729759931564331
test loss item: 0.2289174497127533
test loss item: 0.6418747901916504
test loss item: 0.3494563400745392
test loss item: 0.24422653019428253
test loss item: 0.151638925075531
test loss item: 0.18677493929862976
test loss item: 0.19320619106292725
test loss item: 0.27694767713546753
test loss item: 0.15506702661514282
test loss item: 0.28307831287384033
test loss item: 0.2938217520713806
test loss item: 0.6748611330986023
test loss item: 0.07749617099761963
test loss item: 0.1272023469209671
test loss item: 0.4898653030395508
test loss item: 0.36606284976005554
test loss item: 0.35735565423965454
test loss item: 0.6906023621559143
test loss item: 1.2513638734817505
test loss item: 0.3948250412940979
test loss item: 0.24806107580661774
test loss item: 0.2762397527694702
test loss item: 0.14455951750278473
test loss item: 0.3060198128223419
test loss item: 0.18903455138206482
test loss item: 0.5017740726470947
test loss item: 0.34861046075820923
test loss item: 0.24197015166282654
test loss item: 0.18837155401706696
test loss item: 0.4109719693660736
test loss item: 0.602017879486084
test loss item: 0.2557307779788971
test loss item: 0.11472872644662857
test loss item: 0.20534200966358185
test loss item: 0.14774666726589203
test loss item: 0.2611599862575531
test loss item: 0.7240301370620728
test loss item: 0.4789355397224426
test loss item: 0.21355588734149933
test loss item: 0.2038758546113968
test loss item: 0.1744157373905182
test loss item: 0.3883463144302368
test loss item: 0.22090835869312286
test loss item: 0.186385378241539
test loss item: 0.22394560277462006
test loss item: 0.7291982769966125
test loss item: 0.28332218527793884
test loss item: 0.2796873152256012
test loss item: 0.23054972290992737
test loss item: 0.4519118070602417
test loss item: 0.3523014783859253
test loss item: 0.06845647841691971
test loss item: 0.8469951748847961
test loss item: 0.26906251907348633
test loss item: 0.3733274042606354
test loss item: 0.1267527937889099
test loss item: 0.12117169797420502
test loss item: 0.15619437396526337
test loss item: 1.2614545822143555
test loss item: 0.3656933307647705
test loss item: 0.15834376215934753
test loss item: 0.07535476982593536
test loss item: 0.8589698076248169
test loss item: 0.7563163042068481
test loss item: 0.873477041721344
test loss item: 0.1865633726119995
test loss item: 0.18602512776851654
test loss item: 0.07400666922330856
test loss item: 0.07684695720672607
test loss item: 0.1715620458126068
Epoch [31/100], Training Loss: 0.3818, Testing Loss: 0.3425
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Epoch 32/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3507055938243866
1
train loss item: 0.8743043541908264
2
train loss item: 0.16103078424930573
3
train loss item: 0.35684671998023987
4
train loss item: 0.28867852687835693
5
train loss item: 0.2419794499874115
6
train loss item: 0.186737060546875
7
train loss item: 0.5968044400215149
8
train loss item: 0.09039497375488281
9
train loss item: 0.1832067221403122
10
train loss item: 0.22959484159946442
11
train loss item: 0.22259515523910522
12
train loss item: 0.11797892302274704
13
train loss item: 0.3561367392539978
14
train loss item: 0.17583777010440826
15
train loss item: 0.457342267036438
16
train loss item: 0.06477763503789902
17
train loss item: 0.21365641057491302
18
train loss item: 0.23457595705986023
19
train loss item: 0.17953039705753326
20
train loss item: 0.1628982126712799
21
train loss item: 0.11058435589075089
22
train loss item: 0.685893714427948
23
train loss item: 0.631270170211792
24
train loss item: 0.4080531597137451
25
train loss item: 0.16110429167747498
26
train loss item: 0.1675468236207962
27
train loss item: 0.16187350451946259
28
train loss item: 0.061748865991830826
29
train loss item: 0.5154974460601807
30
train loss item: 1.8733347654342651
31
train loss item: 0.4055803120136261
32
train loss item: 0.08253275603055954
33
train loss item: 0.27616119384765625
34
train loss item: 0.12566117942333221
35
train loss item: 2.112034320831299
36
train loss item: 0.3628869652748108
37
train loss item: 0.3330719470977783
38
train loss item: 0.35913369059562683
39
train loss item: 0.16267746686935425
40
train loss item: 0.1363837569952011
41
train loss item: 0.18392951786518097
42
train loss item: 0.22658376395702362
43
train loss item: 0.13594041764736176
44
train loss item: 0.5019979476928711
45
train loss item: 0.09823064506053925
46
train loss item: 0.09362642467021942
47
train loss item: 0.2523987889289856
48
train loss item: 0.15379564464092255
49
train loss item: 0.11340893059968948
50
train loss item: 0.19762618839740753
51
train loss item: 0.6805935502052307
52
train loss item: 0.06114182248711586
53
train loss item: 0.1126500740647316
54
train loss item: 1.9971702098846436
55
train loss item: 0.1405310183763504
56
train loss item: 0.170911967754364
57
train loss item: 0.1801055669784546
58
train loss item: 0.13253334164619446
59
train loss item: 0.09925836324691772
60
train loss item: 0.6374118328094482
61
train loss item: 1.8817487955093384
62
train loss item: 0.1480809897184372
63
train loss item: 0.2647440433502197
64
train loss item: 0.11965160071849823
65
train loss item: 0.38741376996040344
66
train loss item: 0.3284623324871063
67
train loss item: 0.15705999732017517
68
train loss item: 0.21637707948684692
69
train loss item: 0.22701714932918549
70
train loss item: 0.17934942245483398
71
train loss item: 0.1039939895272255
72
train loss item: 0.1152253970503807
73
train loss item: 0.22305509448051453
74
train loss item: 0.07447680085897446
75
train loss item: 0.09553761035203934
76
train loss item: 0.6332582831382751
77
train loss item: 1.1406121253967285
78
train loss item: 0.05858362838625908
79
train loss item: 0.20756329596042633
80
train loss item: 0.0851258635520935
81
train loss item: 0.14792051911354065
82
train loss item: 0.14484167098999023
83
train loss item: 0.4496632218360901
84
train loss item: 0.35231706500053406
85
train loss item: 0.3756643831729889
86
train loss item: 3.892944812774658
87
train loss item: 0.12457524985074997
88
train loss item: 0.2987433671951294
epoch train loss: 0.3762078336701634
testing phase
test loss item: 0.15547576546669006
test loss item: 0.0877688005566597
test loss item: 0.508309543132782
test loss item: 0.19899588823318481
test loss item: 0.20838132500648499
test loss item: 0.09859322011470795
test loss item: 1.4386816024780273
test loss item: 0.46153154969215393
test loss item: 0.19554974138736725
test loss item: 0.33178219199180603
test loss item: 0.7253214120864868
test loss item: 0.14070217311382294
test loss item: 0.15439178049564362
test loss item: 0.23639914393424988
test loss item: 0.14211240410804749
test loss item: 0.07511423528194427
test loss item: 0.24566195905208588
test loss item: 0.39073196053504944
test loss item: 0.563417911529541
test loss item: 0.22861425578594208
test loss item: 0.6272593140602112
test loss item: 0.34227144718170166
test loss item: 0.2424333244562149
test loss item: 0.15015625953674316
test loss item: 0.1809348165988922
test loss item: 0.19040526449680328
test loss item: 0.27281373739242554
test loss item: 0.15480630099773407
test loss item: 0.2802464962005615
test loss item: 0.28913435339927673
test loss item: 0.6667138934135437
test loss item: 0.07137203961610794
test loss item: 0.12553246319293976
test loss item: 0.4792788028717041
test loss item: 0.3590227961540222
test loss item: 0.35315006971359253
test loss item: 0.6793827414512634
test loss item: 1.230579137802124
test loss item: 0.38579756021499634
test loss item: 0.2441020905971527
test loss item: 0.2687848210334778
test loss item: 0.14878439903259277
test loss item: 0.2994081676006317
test loss item: 0.18177112936973572
test loss item: 0.48933178186416626
test loss item: 0.3425065577030182
test loss item: 0.23910585045814514
test loss item: 0.19050179421901703
test loss item: 0.40460875630378723
test loss item: 0.5935867428779602
test loss item: 0.2512356638908386
test loss item: 0.11635341495275497
test loss item: 0.20065654814243317
test loss item: 0.13805286586284637
test loss item: 0.25655922293663025
test loss item: 0.7151698470115662
test loss item: 0.47047701478004456
test loss item: 0.20848852396011353
test loss item: 0.200327530503273
test loss item: 0.17340229451656342
test loss item: 0.380028635263443
test loss item: 0.2157415896654129
test loss item: 0.1847938597202301
test loss item: 0.22036923468112946
test loss item: 0.7195348143577576
test loss item: 0.2751609981060028
test loss item: 0.27564167976379395
test loss item: 0.22621312737464905
test loss item: 0.4440070688724518
test loss item: 0.3474782109260559
test loss item: 0.0668732225894928
test loss item: 0.8325710296630859
test loss item: 0.26805540919303894
test loss item: 0.3678533732891083
test loss item: 0.1262376606464386
test loss item: 0.12315066158771515
test loss item: 0.15467581152915955
test loss item: 1.24014151096344
test loss item: 0.36294642090797424
test loss item: 0.15800228714942932
test loss item: 0.07208062708377838
test loss item: 0.8451789021492004
test loss item: 0.7451779246330261
test loss item: 0.8599172830581665
test loss item: 0.18560859560966492
test loss item: 0.18258695304393768
test loss item: 0.06733077764511108
test loss item: 0.06684844940900803
test loss item: 0.17613394558429718
Epoch [32/100], Training Loss: 0.3762, Testing Loss: 0.3370
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 33/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.34626248478889465
1
train loss item: 0.8533000349998474
2
train loss item: 0.15971466898918152
3
train loss item: 0.34951692819595337
4
train loss item: 0.2802634537220001
5
train loss item: 0.23752890527248383
6
train loss item: 0.18094182014465332
7
train loss item: 0.5832763910293579
8
train loss item: 0.08840049803256989
9
train loss item: 0.18004325032234192
10
train loss item: 0.223910853266716
11
train loss item: 0.22214773297309875
12
train loss item: 0.11146649718284607
13
train loss item: 0.35018542408943176
14
train loss item: 0.17377766966819763
15
train loss item: 0.44337770342826843
16
train loss item: 0.057646121829748154
17
train loss item: 0.2091720700263977
18
train loss item: 0.22935903072357178
19
train loss item: 0.17900846898555756
20
train loss item: 0.1568583846092224
21
train loss item: 0.106326624751091
22
train loss item: 0.6623676419258118
23
train loss item: 0.6151700019836426
24
train loss item: 0.3964803218841553
25
train loss item: 0.157808318734169
26
train loss item: 0.1638490855693817
27
train loss item: 0.16101078689098358
28
train loss item: 0.055549874901771545
29
train loss item: 0.49993807077407837
30
train loss item: 1.8521627187728882
31
train loss item: 0.399419903755188
32
train loss item: 0.08740422129631042
33
train loss item: 0.269759863615036
34
train loss item: 0.12840047478675842
35
train loss item: 2.096942901611328
36
train loss item: 0.35605955123901367
37
train loss item: 0.3335220515727997
38
train loss item: 0.35879892110824585
39
train loss item: 0.16002418100833893
40
train loss item: 0.1339409053325653
41
train loss item: 0.18264536559581757
42
train loss item: 0.22816739976406097
43
train loss item: 0.1338604986667633
44
train loss item: 0.49259960651397705
45
train loss item: 0.09963227808475494
46
train loss item: 0.09645040333271027
47
train loss item: 0.2458999902009964
48
train loss item: 0.15308301150798798
49
train loss item: 0.1130584329366684
50
train loss item: 0.1927465945482254
51
train loss item: 0.6690737009048462
52
train loss item: 0.05792322754859924
53
train loss item: 0.11310919374227524
54
train loss item: 1.9823542833328247
55
train loss item: 0.13774096965789795
56
train loss item: 0.17067861557006836
57
train loss item: 0.17991164326667786
58
train loss item: 0.12871196866035461
59
train loss item: 0.10483206063508987
60
train loss item: 0.6198706030845642
61
train loss item: 1.8637183904647827
62
train loss item: 0.1419769823551178
63
train loss item: 0.26247239112854004
64
train loss item: 0.12052682042121887
65
train loss item: 0.38259145617485046
66
train loss item: 0.3244319558143616
67
train loss item: 0.1523858606815338
68
train loss item: 0.20556855201721191
69
train loss item: 0.2246982455253601
70
train loss item: 0.1760922521352768
71
train loss item: 0.10168302804231644
72
train loss item: 0.11480052024126053
73
train loss item: 0.2183261513710022
74
train loss item: 0.07490433752536774
75
train loss item: 0.09246796369552612
76
train loss item: 0.6167716383934021
77
train loss item: 1.1291825771331787
78
train loss item: 0.05547009035944939
79
train loss item: 0.2085203379392624
80
train loss item: 0.0863901823759079
81
train loss item: 0.14131119847297668
82
train loss item: 0.14279773831367493
83
train loss item: 0.44476279616355896
84
train loss item: 0.34849080443382263
85
train loss item: 0.3634168803691864
86
train loss item: 3.8720996379852295
87
train loss item: 0.12292901426553726
88
train loss item: 0.296512633562088
epoch train loss: 0.3707724168394389
testing phase
test loss item: 0.1527113914489746
test loss item: 0.088907890021801
test loss item: 0.5159359574317932
test loss item: 0.19627124071121216
test loss item: 0.2123660147190094
test loss item: 0.10133246332406998
test loss item: 1.4013806581497192
test loss item: 0.45139750838279724
test loss item: 0.19992117583751678
test loss item: 0.33532750606536865
test loss item: 0.7307170629501343
test loss item: 0.13848429918289185
test loss item: 0.15513181686401367
test loss item: 0.23542453348636627
test loss item: 0.14516927301883698
test loss item: 0.0697479397058487
test loss item: 0.23910310864448547
test loss item: 0.39522451162338257
test loss item: 0.5532603859901428
test loss item: 0.2251872420310974
test loss item: 0.6364747881889343
test loss item: 0.3349919617176056
test loss item: 0.24177932739257812
test loss item: 0.14904828369617462
test loss item: 0.17847824096679688
test loss item: 0.18823155760765076
test loss item: 0.27177008986473083
test loss item: 0.15831288695335388
test loss item: 0.2799675166606903
test loss item: 0.2878277003765106
test loss item: 0.6665135025978088
test loss item: 0.06741994619369507
test loss item: 0.12517274916172028
test loss item: 0.48136621713638306
test loss item: 0.3644298017024994
test loss item: 0.35534989833831787
test loss item: 0.6683205962181091
test loss item: 1.2435554265975952
test loss item: 0.38675081729888916
test loss item: 0.2386394441127777
test loss item: 0.25938302278518677
test loss item: 0.1455826461315155
test loss item: 0.30315762758255005
test loss item: 0.17595286667346954
test loss item: 0.4949054718017578
test loss item: 0.33647847175598145
test loss item: 0.2385541945695877
test loss item: 0.1877657026052475
test loss item: 0.40853652358055115
test loss item: 0.5957701802253723
test loss item: 0.25861459970474243
test loss item: 0.11380226910114288
test loss item: 0.19961033761501312
test loss item: 0.1346873790025711
test loss item: 0.2613603174686432
test loss item: 0.7279863953590393
test loss item: 0.4650837481021881
test loss item: 0.21374844014644623
test loss item: 0.20032823085784912
test loss item: 0.1760864406824112
test loss item: 0.38476401567459106
test loss item: 0.21180251240730286
test loss item: 0.18245168030261993
test loss item: 0.21560265123844147
test loss item: 0.7247185111045837
test loss item: 0.2700730264186859
test loss item: 0.2709050476551056
test loss item: 0.21988238394260406
test loss item: 0.4447373151779175
test loss item: 0.3435249328613281
test loss item: 0.06641419231891632
test loss item: 0.8084352016448975
test loss item: 0.26938754320144653
test loss item: 0.3584893047809601
test loss item: 0.1253717839717865
test loss item: 0.11980468779802322
test loss item: 0.15287864208221436
test loss item: 1.2568140029907227
test loss item: 0.3593323230743408
test loss item: 0.1590147763490677
test loss item: 0.07039579749107361
test loss item: 0.8376748561859131
test loss item: 0.7385361194610596
test loss item: 0.8708856701850891
test loss item: 0.18253643810749054
test loss item: 0.18112392723560333
test loss item: 0.06324276328086853
test loss item: 0.059932418167591095
test loss item: 0.1772363930940628
Epoch [33/100], Training Loss: 0.3708, Testing Loss: 0.3359
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 34/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3383950889110565
1
train loss item: 0.8343450427055359
2
train loss item: 0.15381765365600586
3
train loss item: 0.3446573317050934
4
train loss item: 0.27250370383262634
5
train loss item: 0.2289656698703766
6
train loss item: 0.17241041362285614
7
train loss item: 0.5751549601554871
8
train loss item: 0.087681345641613
9
train loss item: 0.1751694679260254
10
train loss item: 0.21774768829345703
11
train loss item: 0.2177121639251709
12
train loss item: 0.10715611279010773
13
train loss item: 0.34255659580230713
14
train loss item: 0.16878877580165863
15
train loss item: 0.43378040194511414
16
train loss item: 0.05611984059214592
17
train loss item: 0.20362260937690735
18
train loss item: 0.22390824556350708
19
train loss item: 0.17748266458511353
20
train loss item: 0.15277200937271118
21
train loss item: 0.10112300515174866
22
train loss item: 0.6454415917396545
23
train loss item: 0.6025400161743164
24
train loss item: 0.3858150839805603
25
train loss item: 0.15188910067081451
26
train loss item: 0.15553520619869232
27
train loss item: 0.1577124297618866
28
train loss item: 0.053998805582523346
29
train loss item: 0.4889460802078247
30
train loss item: 1.8327432870864868
31
train loss item: 0.3901086151599884
32
train loss item: 0.08491440117359161
33
train loss item: 0.2677094638347626
34
train loss item: 0.12595345079898834
35
train loss item: 2.083374500274658
36
train loss item: 0.34902918338775635
37
train loss item: 0.329495370388031
38
train loss item: 0.3481232225894928
39
train loss item: 0.1556336134672165
40
train loss item: 0.12876877188682556
41
train loss item: 0.1784774363040924
42
train loss item: 0.22826138138771057
43
train loss item: 0.12961691617965698
44
train loss item: 0.4868956506252289
45
train loss item: 0.10107655823230743
46
train loss item: 0.09198474884033203
47
train loss item: 0.24077081680297852
48
train loss item: 0.14951135218143463
49
train loss item: 0.11243369430303574
50
train loss item: 0.18974041938781738
51
train loss item: 0.6584458351135254
52
train loss item: 0.05702345073223114
53
train loss item: 0.11470844596624374
54
train loss item: 1.9696425199508667
55
train loss item: 0.13561420142650604
56
train loss item: 0.16953054070472717
57
train loss item: 0.17598193883895874
58
train loss item: 0.12222738564014435
59
train loss item: 0.10630471259355545
60
train loss item: 0.6064860224723816
61
train loss item: 1.8480298519134521
62
train loss item: 0.1359308660030365
63
train loss item: 0.2584596872329712
64
train loss item: 0.118737131357193
65
train loss item: 0.37356916069984436
66
train loss item: 0.31861612200737
67
train loss item: 0.14738698303699493
68
train loss item: 0.1994030773639679
69
train loss item: 0.22007331252098083
70
train loss item: 0.17197497189044952
71
train loss item: 0.09859933704137802
72
train loss item: 0.11496730148792267
73
train loss item: 0.21323361992835999
74
train loss item: 0.07390347123146057
75
train loss item: 0.09197279065847397
76
train loss item: 0.604030191898346
77
train loss item: 1.1191284656524658
78
train loss item: 0.05522127449512482
79
train loss item: 0.20521047711372375
80
train loss item: 0.08517539501190186
81
train loss item: 0.13669823110103607
82
train loss item: 0.1412009298801422
83
train loss item: 0.4398149251937866
84
train loss item: 0.34270790219306946
85
train loss item: 0.35155126452445984
86
train loss item: 3.8529183864593506
87
train loss item: 0.12421610951423645
88
train loss item: 0.2892426550388336
epoch train loss: 0.36494731354746923
testing phase
test loss item: 0.15216317772865295
test loss item: 0.08776948601007462
test loss item: 0.5110057592391968
test loss item: 0.19602257013320923
test loss item: 0.21406076848506927
test loss item: 0.11031529307365417
test loss item: 1.3832545280456543
test loss item: 0.45708537101745605
test loss item: 0.19685132801532745
test loss item: 0.3319680392742157
test loss item: 0.7209712862968445
test loss item: 0.13608311116695404
test loss item: 0.15305429697036743
test loss item: 0.23432345688343048
test loss item: 0.14353404939174652
test loss item: 0.06692696362733841
test loss item: 0.2387249916791916
test loss item: 0.39326924085617065
test loss item: 0.5502296686172485
test loss item: 0.2244146317243576
test loss item: 0.6364955902099609
test loss item: 0.3348817825317383
test loss item: 0.2402740865945816
test loss item: 0.1491401046514511
test loss item: 0.17735610902309418
test loss item: 0.18772463500499725
test loss item: 0.2701932489871979
test loss item: 0.16194848716259003
test loss item: 0.2763209939002991
test loss item: 0.2850978672504425
test loss item: 0.6602169275283813
test loss item: 0.06508708745241165
test loss item: 0.12574778497219086
test loss item: 0.476567804813385
test loss item: 0.362455815076828
test loss item: 0.35398563742637634
test loss item: 0.6631960272789001
test loss item: 1.2278931140899658
test loss item: 0.38291096687316895
test loss item: 0.23828692734241486
test loss item: 0.255825400352478
test loss item: 0.13967646658420563
test loss item: 0.30021554231643677
test loss item: 0.1765270084142685
test loss item: 0.49330294132232666
test loss item: 0.33693861961364746
test loss item: 0.2370380163192749
test loss item: 0.18862491846084595
test loss item: 0.4053274989128113
test loss item: 0.5893410444259644
test loss item: 0.2573259472846985
test loss item: 0.11325602233409882
test loss item: 0.1999305635690689
test loss item: 0.13563023507595062
test loss item: 0.2614261209964752
test loss item: 0.7210845351219177
test loss item: 0.4613783061504364
test loss item: 0.21704009175300598
test loss item: 0.20196805894374847
test loss item: 0.1736232042312622
test loss item: 0.3806440234184265
test loss item: 0.2157360464334488
test loss item: 0.18238680064678192
test loss item: 0.21031536161899567
test loss item: 0.7245466113090515
test loss item: 0.26882851123809814
test loss item: 0.26947206258773804
test loss item: 0.21514928340911865
test loss item: 0.4394463002681732
test loss item: 0.3409419357776642
test loss item: 0.06355874240398407
test loss item: 0.8022014498710632
test loss item: 0.2697230279445648
test loss item: 0.35540181398391724
test loss item: 0.12611855566501617
test loss item: 0.11719762533903122
test loss item: 0.15153242647647858
test loss item: 1.249303936958313
test loss item: 0.3544187545776367
test loss item: 0.16349917650222778
test loss item: 0.07051374763250351
test loss item: 0.8266322612762451
test loss item: 0.7315372824668884
test loss item: 0.8633863925933838
test loss item: 0.1815275400876999
test loss item: 0.18187952041625977
test loss item: 0.06431009620428085
test loss item: 0.05938594043254852
test loss item: 0.1706535667181015
Epoch [34/100], Training Loss: 0.3649, Testing Loss: 0.3336
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 35/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3298273980617523
1
train loss item: 0.814149796962738
2
train loss item: 0.14900629222393036
3
train loss item: 0.3335427939891815
4
train loss item: 0.2620668411254883
5
train loss item: 0.2211177498102188
6
train loss item: 0.17141160368919373
7
train loss item: 0.5666597485542297
8
train loss item: 0.08720748126506805
9
train loss item: 0.17084971070289612
10
train loss item: 0.21136723458766937
11
train loss item: 0.21117793023586273
12
train loss item: 0.10948175191879272
13
train loss item: 0.33197352290153503
14
train loss item: 0.16196559369564056
15
train loss item: 0.43347597122192383
16
train loss item: 0.058587562292814255
17
train loss item: 0.20014546811580658
18
train loss item: 0.2203996628522873
19
train loss item: 0.17646950483322144
20
train loss item: 0.15355883538722992
21
train loss item: 0.10420887172222137
22
train loss item: 0.6387283205986023
23
train loss item: 0.5827214121818542
24
train loss item: 0.38253673911094666
25
train loss item: 0.1460699886083603
26
train loss item: 0.15001828968524933
27
train loss item: 0.14977669715881348
28
train loss item: 0.05526930093765259
29
train loss item: 0.4847725033760071
30
train loss item: 1.8085304498672485
31
train loss item: 0.3774227797985077
32
train loss item: 0.08013799786567688
33
train loss item: 0.25450602173805237
34
train loss item: 0.12124140560626984
35
train loss item: 2.0691964626312256
36
train loss item: 0.34107935428619385
37
train loss item: 0.32118940353393555
38
train loss item: 0.33282196521759033
39
train loss item: 0.15455229580402374
40
train loss item: 0.129623681306839
41
train loss item: 0.17069214582443237
42
train loss item: 0.22666575014591217
43
train loss item: 0.12602710723876953
44
train loss item: 0.47890669107437134
45
train loss item: 0.09633421897888184
46
train loss item: 0.08590978384017944
47
train loss item: 0.23955486714839935
48
train loss item: 0.14497509598731995
49
train loss item: 0.10890337824821472
50
train loss item: 0.18997302651405334
51
train loss item: 0.6472919583320618
52
train loss item: 0.057956211268901825
53
train loss item: 0.11113394796848297
54
train loss item: 1.9558383226394653
55
train loss item: 0.1345950812101364
56
train loss item: 0.16496042907238007
57
train loss item: 0.17427822947502136
58
train loss item: 0.12183928489685059
59
train loss item: 0.10126592963933945
60
train loss item: 0.594139814376831
61
train loss item: 1.8249027729034424
62
train loss item: 0.13529141247272491
63
train loss item: 0.25364115834236145
64
train loss item: 0.1131184920668602
65
train loss item: 0.3646323084831238
66
train loss item: 0.31736811995506287
67
train loss item: 0.14615054428577423
68
train loss item: 0.20298467576503754
69
train loss item: 0.2162708193063736
70
train loss item: 0.16845591366291046
71
train loss item: 0.0969633236527443
72
train loss item: 0.11025978624820709
73
train loss item: 0.21035195887088776
74
train loss item: 0.0692414939403534
75
train loss item: 0.09244202822446823
76
train loss item: 0.5878804922103882
77
train loss item: 1.1110576391220093
78
train loss item: 0.05700637400150299
79
train loss item: 0.1991046965122223
80
train loss item: 0.08133547008037567
81
train loss item: 0.13616377115249634
82
train loss item: 0.13722307980060577
83
train loss item: 0.43256470561027527
84
train loss item: 0.33235910534858704
85
train loss item: 0.3391326665878296
86
train loss item: 3.8305158615112305
87
train loss item: 0.12122160196304321
88
train loss item: 0.2859697639942169
epoch train loss: 0.3591426708473918
testing phase
test loss item: 0.15678448975086212
test loss item: 0.0870608240365982
test loss item: 0.49731943011283875
test loss item: 0.1980113536119461
test loss item: 0.2063576728105545
test loss item: 0.10774020105600357
test loss item: 1.352445125579834
test loss item: 0.43033942580223083
test loss item: 0.19278323650360107
test loss item: 0.32304203510284424
test loss item: 0.7048460841178894
test loss item: 0.13539953529834747
test loss item: 0.1445208489894867
test loss item: 0.23738698661327362
test loss item: 0.13838906586170197
test loss item: 0.07537975162267685
test loss item: 0.2373344600200653
test loss item: 0.38373664021492004
test loss item: 0.5332949757575989
test loss item: 0.21833060681819916
test loss item: 0.6167954206466675
test loss item: 0.3296626806259155
test loss item: 0.23685979843139648
test loss item: 0.1470762938261032
test loss item: 0.17761392891407013
test loss item: 0.1829821616411209
test loss item: 0.26711875200271606
test loss item: 0.1548624187707901
test loss item: 0.2682212293148041
test loss item: 0.27831387519836426
test loss item: 0.6466318368911743
test loss item: 0.07248890399932861
test loss item: 0.12489226460456848
test loss item: 0.4654492139816284
test loss item: 0.35358136892318726
test loss item: 0.3481150269508362
test loss item: 0.6432570219039917
test loss item: 1.197690725326538
test loss item: 0.3736379146575928
test loss item: 0.2346304953098297
test loss item: 0.2552511692047119
test loss item: 0.14271622896194458
test loss item: 0.29349464178085327
test loss item: 0.18123620748519897
test loss item: 0.4771691560745239
test loss item: 0.3262225091457367
test loss item: 0.23467838764190674
test loss item: 0.18704640865325928
test loss item: 0.39201292395591736
test loss item: 0.5753118991851807
test loss item: 0.24704882502555847
test loss item: 0.11019068211317062
test loss item: 0.1996602565050125
test loss item: 0.1425953507423401
test loss item: 0.25439488887786865
test loss item: 0.7048637270927429
test loss item: 0.4452451467514038
test loss item: 0.21103043854236603
test loss item: 0.1997675746679306
test loss item: 0.16669905185699463
test loss item: 0.37226924300193787
test loss item: 0.21093375980854034
test loss item: 0.18064071238040924
test loss item: 0.20379804074764252
test loss item: 0.7052172422409058
test loss item: 0.2718592584133148
test loss item: 0.26026293635368347
test loss item: 0.21034380793571472
test loss item: 0.4278489351272583
test loss item: 0.33190616965293884
test loss item: 0.06337041407823563
test loss item: 0.7755434513092041
test loss item: 0.2690909504890442
test loss item: 0.3506487309932709
test loss item: 0.12692399322986603
test loss item: 0.12248433381319046
test loss item: 0.14843161404132843
test loss item: 1.217677116394043
test loss item: 0.35075944662094116
test loss item: 0.16280272603034973
test loss item: 0.0739474669098854
test loss item: 0.8036185503005981
test loss item: 0.7128780484199524
test loss item: 0.8411875367164612
test loss item: 0.17872846126556396
test loss item: 0.18125374615192413
test loss item: 0.07326163351535797
test loss item: 0.07141396403312683
test loss item: 0.16865220665931702
Epoch [35/100], Training Loss: 0.3591, Testing Loss: 0.3269
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 36/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3251832127571106
1
train loss item: 0.7903741002082825
2
train loss item: 0.14440932869911194
3
train loss item: 0.32645756006240845
4
train loss item: 0.2593182921409607
5
train loss item: 0.2161182463169098
6
train loss item: 0.16744385659694672
7
train loss item: 0.5566900372505188
8
train loss item: 0.08994244784116745
9
train loss item: 0.16731856763362885
10
train loss item: 0.21062517166137695
11
train loss item: 0.20958806574344635
12
train loss item: 0.11194818466901779
13
train loss item: 0.3293660283088684
14
train loss item: 0.15913113951683044
15
train loss item: 0.4209864139556885
16
train loss item: 0.05919033661484718
17
train loss item: 0.1954764872789383
18
train loss item: 0.2167893946170807
19
train loss item: 0.1681901216506958
20
train loss item: 0.14731831848621368
21
train loss item: 0.10279685258865356
22
train loss item: 0.6162389516830444
23
train loss item: 0.5671816468238831
24
train loss item: 0.3721398413181305
25
train loss item: 0.1438080072402954
26
train loss item: 0.14513126015663147
27
train loss item: 0.1442333459854126
28
train loss item: 0.05592288821935654
29
train loss item: 0.47238561511039734
30
train loss item: 1.7862433195114136
31
train loss item: 0.3738720118999481
32
train loss item: 0.0777253657579422
33
train loss item: 0.24978512525558472
34
train loss item: 0.11940490454435349
35
train loss item: 2.0553455352783203
36
train loss item: 0.3411647379398346
37
train loss item: 0.3208501636981964
38
train loss item: 0.34092074632644653
39
train loss item: 0.15465092658996582
40
train loss item: 0.1281728446483612
41
train loss item: 0.16542871296405792
42
train loss item: 0.22319696843624115
43
train loss item: 0.12426222115755081
44
train loss item: 0.47295284271240234
45
train loss item: 0.09419755637645721
46
train loss item: 0.08289968967437744
47
train loss item: 0.23462055623531342
48
train loss item: 0.14135709404945374
49
train loss item: 0.10809817910194397
50
train loss item: 0.18315112590789795
51
train loss item: 0.6387620568275452
52
train loss item: 0.05894960090517998
53
train loss item: 0.10678399354219437
54
train loss item: 1.941724419593811
55
train loss item: 0.13349401950836182
56
train loss item: 0.15976902842521667
57
train loss item: 0.17256765067577362
58
train loss item: 0.12164018303155899
59
train loss item: 0.09768928587436676
60
train loss item: 0.5754099488258362
61
train loss item: 1.80460786819458
62
train loss item: 0.13376207649707794
63
train loss item: 0.24917608499526978
64
train loss item: 0.11111252754926682
65
train loss item: 0.35925620794296265
66
train loss item: 0.31343477964401245
67
train loss item: 0.1440948247909546
68
train loss item: 0.19392313063144684
69
train loss item: 0.21098920702934265
70
train loss item: 0.16730479896068573
71
train loss item: 0.09334440529346466
72
train loss item: 0.10761361569166183
73
train loss item: 0.20588088035583496
74
train loss item: 0.06877463310956955
75
train loss item: 0.09298314899206161
76
train loss item: 0.5712776780128479
77
train loss item: 1.1017460823059082
78
train loss item: 0.05854738503694534
79
train loss item: 0.19637133181095123
80
train loss item: 0.08170752972364426
81
train loss item: 0.1348559409379959
82
train loss item: 0.1336323469877243
83
train loss item: 0.42570704221725464
84
train loss item: 0.3318120241165161
85
train loss item: 0.3296058773994446
86
train loss item: 3.8089144229888916
87
train loss item: 0.11767804622650146
88
train loss item: 0.27780771255493164
epoch train loss: 0.3539631027686462
testing phase
test loss item: 0.15532925724983215
test loss item: 0.09700269252061844
test loss item: 0.46120545268058777
test loss item: 0.19740207493305206
test loss item: 0.1962636560201645
test loss item: 0.0992974266409874
test loss item: 1.3701497316360474
test loss item: 0.47833549976348877
test loss item: 0.17606034874916077
test loss item: 0.30371350049972534
test loss item: 0.655599057674408
test loss item: 0.1350429505109787
test loss item: 0.15522484481334686
test loss item: 0.24743802845478058
test loss item: 0.13620999455451965
test loss item: 0.10040219873189926
test loss item: 0.24487842619419098
test loss item: 0.36013317108154297
test loss item: 0.5558981895446777
test loss item: 0.23585377633571625
test loss item: 0.5819482803344727
test loss item: 0.3395289480686188
test loss item: 0.23577217757701874
test loss item: 0.14959895610809326
test loss item: 0.172538623213768
test loss item: 0.1847381442785263
test loss item: 0.26235273480415344
test loss item: 0.1456165760755539
test loss item: 0.26065942645072937
test loss item: 0.27100592851638794
test loss item: 0.6202352643013
test loss item: 0.09470558911561966
test loss item: 0.12778428196907043
test loss item: 0.43833252787590027
test loss item: 0.33123916387557983
test loss item: 0.3454935848712921
test loss item: 0.6571228504180908
test loss item: 1.1013721227645874
test loss item: 0.3521430790424347
test loss item: 0.231794074177742
test loss item: 0.2577522397041321
test loss item: 0.14784559607505798
test loss item: 0.26866596937179565
test loss item: 0.18221643567085266
test loss item: 0.44886377453804016
test loss item: 0.3494277596473694
test loss item: 0.2326635867357254
test loss item: 0.21403613686561584
test loss item: 0.37608417868614197
test loss item: 0.5471439957618713
test loss item: 0.2245432287454605
test loss item: 0.12519913911819458
test loss item: 0.19232535362243652
test loss item: 0.14061298966407776
test loss item: 0.23566268384456635
test loss item: 0.6481253504753113
test loss item: 0.4526870548725128
test loss item: 0.20145940780639648
test loss item: 0.2040105015039444
test loss item: 0.15889249742031097
test loss item: 0.33822867274284363
test loss item: 0.2314939796924591
test loss item: 0.1875973343849182
test loss item: 0.20395421981811523
test loss item: 0.6850835084915161
test loss item: 0.2688281536102295
test loss item: 0.26976415514945984
test loss item: 0.21051456034183502
test loss item: 0.4134162366390228
test loss item: 0.3528810739517212
test loss item: 0.07756959646940231
test loss item: 0.8088502883911133
test loss item: 0.27136319875717163
test loss item: 0.35767367482185364
test loss item: 0.1346837878227234
test loss item: 0.12910474836826324
test loss item: 0.15079165995121002
test loss item: 1.134121060371399
test loss item: 0.3507702052593231
test loss item: 0.15634572505950928
test loss item: 0.07006395608186722
test loss item: 0.7819668054580688
test loss item: 0.7037683725357056
test loss item: 0.7797707319259644
test loss item: 0.18304836750030518
test loss item: 0.1847793608903885
test loss item: 0.07833018153905869
test loss item: 0.09195581078529358
test loss item: 0.15940089523792267
Epoch [36/100], Training Loss: 0.3540, Testing Loss: 0.3218
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 37/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.31853240728378296
1
train loss item: 0.7759101986885071
2
train loss item: 0.14460746943950653
3
train loss item: 0.3082740902900696
4
train loss item: 0.25724032521247864
5
train loss item: 0.21054776012897491
6
train loss item: 0.16729924082756042
7
train loss item: 0.5404170751571655
8
train loss item: 0.08134938776493073
9
train loss item: 0.17049665749073029
10
train loss item: 0.20499953627586365
11
train loss item: 0.2012096643447876
12
train loss item: 0.10828914493322372
13
train loss item: 0.31745290756225586
14
train loss item: 0.1546761393547058
15
train loss item: 0.42846396565437317
16
train loss item: 0.054682645946741104
17
train loss item: 0.1923249512910843
18
train loss item: 0.21329966187477112
19
train loss item: 0.17714858055114746
20
train loss item: 0.1515328735113144
21
train loss item: 0.10654883831739426
22
train loss item: 0.6204910278320312
23
train loss item: 0.5384794473648071
24
train loss item: 0.37802162766456604
25
train loss item: 0.14013926684856415
26
train loss item: 0.14128199219703674
27
train loss item: 0.14140772819519043
28
train loss item: 0.052281949669122696
29
train loss item: 0.4685411751270294
30
train loss item: 1.7519031763076782
31
train loss item: 0.3606243431568146
32
train loss item: 0.0821257010102272
33
train loss item: 0.23014676570892334
34
train loss item: 0.11334031075239182
35
train loss item: 2.0378851890563965
36
train loss item: 0.3323673903942108
37
train loss item: 0.3174646198749542
38
train loss item: 0.3278200924396515
39
train loss item: 0.15508148074150085
40
train loss item: 0.12926220893859863
41
train loss item: 0.16185034811496735
42
train loss item: 0.2231961339712143
43
train loss item: 0.12897565960884094
44
train loss item: 0.45917975902557373
45
train loss item: 0.09220559149980545
46
train loss item: 0.08692110329866409
47
train loss item: 0.23611223697662354
48
train loss item: 0.14419549703598022
49
train loss item: 0.10517287999391556
50
train loss item: 0.18983212113380432
51
train loss item: 0.6237196326255798
52
train loss item: 0.0565321259200573
53
train loss item: 0.102313332259655
54
train loss item: 1.9230390787124634
55
train loss item: 0.13327327370643616
56
train loss item: 0.1590787172317505
57
train loss item: 0.17228570580482483
58
train loss item: 0.12771883606910706
59
train loss item: 0.09867846965789795
60
train loss item: 0.5647619366645813
61
train loss item: 1.7778197526931763
62
train loss item: 0.13052473962306976
63
train loss item: 0.24943037331104279
64
train loss item: 0.11434176564216614
65
train loss item: 0.36138680577278137
66
train loss item: 0.32147204875946045
67
train loss item: 0.14319844543933868
68
train loss item: 0.2014150172472
69
train loss item: 0.2152024358510971
70
train loss item: 0.16479898989200592
71
train loss item: 0.09050742536783218
72
train loss item: 0.10552563518285751
73
train loss item: 0.20765741169452667
74
train loss item: 0.0693422481417656
75
train loss item: 0.08782026171684265
76
train loss item: 0.5527299046516418
77
train loss item: 1.0942538976669312
78
train loss item: 0.05490008369088173
79
train loss item: 0.19073060154914856
80
train loss item: 0.08442263305187225
81
train loss item: 0.13310569524765015
82
train loss item: 0.1280740648508072
83
train loss item: 0.42413365840911865
84
train loss item: 0.32785627245903015
85
train loss item: 0.31618863344192505
86
train loss item: 3.7838268280029297
87
train loss item: 0.11415895819664001
88
train loss item: 0.28601354360580444
epoch train loss: 0.3497061751196893
testing phase
test loss item: 0.1603594571352005
test loss item: 0.09840667247772217
test loss item: 0.5096865296363831
test loss item: 0.19939157366752625
test loss item: 0.20823994278907776
test loss item: 0.10967382043600082
test loss item: 1.2775338888168335
test loss item: 0.39377379417419434
test loss item: 0.20201413333415985
test loss item: 0.32757753133773804
test loss item: 0.732940673828125
test loss item: 0.13579802215099335
test loss item: 0.1363840252161026
test loss item: 0.2528029978275299
test loss item: 0.1466100513935089
test loss item: 0.09656701236963272
test loss item: 0.22241392731666565
test loss item: 0.3908594250679016
test loss item: 0.530246913433075
test loss item: 0.20722608268260956
test loss item: 0.6177622675895691
test loss item: 0.30794546008110046
test loss item: 0.2395259439945221
test loss item: 0.14325487613677979
test loss item: 0.17691448330879211
test loss item: 0.1718587577342987
test loss item: 0.26645052433013916
test loss item: 0.15129339694976807
test loss item: 0.26542913913726807
test loss item: 0.2754586338996887
test loss item: 0.6530573964118958
test loss item: 0.09261424094438553
test loss item: 0.12545764446258545
test loss item: 0.4701501131057739
test loss item: 0.3635092079639435
test loss item: 0.38534700870513916
test loss item: 0.6219346523284912
test loss item: 1.2428812980651855
test loss item: 0.37555477023124695
test loss item: 0.22125640511512756
test loss item: 0.24544845521450043
test loss item: 0.15118207037448883
test loss item: 0.3006318509578705
test loss item: 0.17888997495174408
test loss item: 0.4757075905799866
test loss item: 0.2983418107032776
test loss item: 0.23525699973106384
test loss item: 0.19673261046409607
test loss item: 0.39202210307121277
test loss item: 0.5848957896232605
test loss item: 0.250019907951355
test loss item: 0.1078973188996315
test loss item: 0.20016151666641235
test loss item: 0.15179097652435303
test loss item: 0.2583702504634857
test loss item: 0.7383396625518799
test loss item: 0.44400081038475037
test loss item: 0.21133556962013245
test loss item: 0.19401027262210846
test loss item: 0.16726821660995483
test loss item: 0.3810400366783142
test loss item: 0.1887717992067337
test loss item: 0.1706097573041916
test loss item: 0.19229952991008759
test loss item: 0.7080491185188293
test loss item: 0.2736610174179077
test loss item: 0.23943737149238586
test loss item: 0.199905663728714
test loss item: 0.4311957061290741
test loss item: 0.3918567895889282
test loss item: 0.07746001332998276
test loss item: 0.7088039517402649
test loss item: 0.27585142850875854
test loss item: 0.32196661829948425
test loss item: 0.1284603774547577
test loss item: 0.1297592967748642
test loss item: 0.14465737342834473
test loss item: 1.2528570890426636
test loss item: 0.3576356768608093
test loss item: 0.1613636165857315
test loss item: 0.08020589500665665
test loss item: 0.8021414279937744
test loss item: 0.7093833088874817
test loss item: 0.8692834377288818
test loss item: 0.1775825321674347
test loss item: 0.178574338555336
test loss item: 0.08734216541051865
test loss item: 0.09564889967441559
test loss item: 0.17743265628814697
Epoch [37/100], Training Loss: 0.3497, Testing Loss: 0.3281
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Epoch 38/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.32128867506980896
1
train loss item: 0.7642226815223694
2
train loss item: 0.14421512186527252
3
train loss item: 0.3456166088581085
4
train loss item: 0.2711879014968872
5
train loss item: 0.20200665295124054
6
train loss item: 0.16498492658138275
7
train loss item: 0.5415709018707275
8
train loss item: 0.09512202441692352
9
train loss item: 0.16877542436122894
10
train loss item: 0.21372509002685547
11
train loss item: 0.21502764523029327
12
train loss item: 0.10598254203796387
13
train loss item: 0.33735135197639465
14
train loss item: 0.16312168538570404
15
train loss item: 0.40382689237594604
16
train loss item: 0.05342122167348862
17
train loss item: 0.1989677995443344
18
train loss item: 0.21204863488674164
19
train loss item: 0.15342824161052704
20
train loss item: 0.1475888043642044
21
train loss item: 0.11012931168079376
22
train loss item: 0.5866531729698181
23
train loss item: 0.5558226704597473
24
train loss item: 0.3488560914993286
25
train loss item: 0.1400025337934494
26
train loss item: 0.13945770263671875
27
train loss item: 0.1496468484401703
28
train loss item: 0.05334235355257988
29
train loss item: 0.4626542925834656
30
train loss item: 1.7543604373931885
31
train loss item: 0.3765052556991577
32
train loss item: 0.08801742643117905
33
train loss item: 0.2711355984210968
34
train loss item: 0.12264425307512283
35
train loss item: 2.030421257019043
36
train loss item: 0.36519742012023926
37
train loss item: 0.3334791958332062
38
train loss item: 0.396528035402298
39
train loss item: 0.14922408759593964
40
train loss item: 0.1184951663017273
41
train loss item: 0.17263710498809814
42
train loss item: 0.2163853943347931
43
train loss item: 0.12617555260658264
44
train loss item: 0.4719393253326416
45
train loss item: 0.10189493000507355
46
train loss item: 0.08617857843637466
47
train loss item: 0.22387424111366272
48
train loss item: 0.14278757572174072
49
train loss item: 0.11939633637666702
50
train loss item: 0.1707768589258194
51
train loss item: 0.6361883282661438
52
train loss item: 0.05368565022945404
53
train loss item: 0.11524996906518936
54
train loss item: 1.9160921573638916
55
train loss item: 0.13380923867225647
56
train loss item: 0.1585017889738083
57
train loss item: 0.16113066673278809
58
train loss item: 0.11815740913152695
59
train loss item: 0.10043773800134659
60
train loss item: 0.555637001991272
61
train loss item: 1.7869887351989746
62
train loss item: 0.12536074221134186
63
train loss item: 0.24671709537506104
64
train loss item: 0.12081481516361237
65
train loss item: 0.37328800559043884
66
train loss item: 0.3265360891819
67
train loss item: 0.14325301349163055
68
train loss item: 0.1737985461950302
69
train loss item: 0.20553043484687805
70
train loss item: 0.1726129800081253
71
train loss item: 0.08508612215518951
72
train loss item: 0.11445125192403793
73
train loss item: 0.19975163042545319
74
train loss item: 0.0761975422501564
75
train loss item: 0.0899711474776268
76
train loss item: 0.5502173900604248
77
train loss item: 1.0881900787353516
78
train loss item: 0.053852662444114685
79
train loss item: 0.19867341220378876
80
train loss item: 0.08808087557554245
81
train loss item: 0.12790842354297638
82
train loss item: 0.13743026554584503
83
train loss item: 0.4361586570739746
84
train loss item: 0.3634355068206787
85
train loss item: 0.32584574818611145
86
train loss item: 3.775428295135498
87
train loss item: 0.12769785523414612
88
train loss item: 0.2647109031677246
epoch train loss: 0.3520784046124206
testing phase
test loss item: 0.14915302395820618
test loss item: 0.08646722137928009
test loss item: 0.4616415798664093
test loss item: 0.19240093231201172
test loss item: 0.20416496694087982
test loss item: 0.11257903277873993
test loss item: 1.4361037015914917
test loss item: 0.5584259629249573
test loss item: 0.17436790466308594
test loss item: 0.30274954438209534
test loss item: 0.6667549014091492
test loss item: 0.13373316824436188
test loss item: 0.17118500173091888
test loss item: 0.2638084888458252
test loss item: 0.13603746891021729
test loss item: 0.06855539977550507
test loss item: 0.25095319747924805
test loss item: 0.35476019978523254
test loss item: 0.6074562072753906
test loss item: 0.260694682598114
test loss item: 0.5755850672721863
test loss item: 0.3513631224632263
test loss item: 0.23933570086956024
test loss item: 0.1485735923051834
test loss item: 0.16801127791404724
test loss item: 0.18803814053535461
test loss item: 0.26949411630630493
test loss item: 0.15454889833927155
test loss item: 0.25762975215911865
test loss item: 0.2752567231655121
test loss item: 0.6420837044715881
test loss item: 0.06262382864952087
test loss item: 0.12491489201784134
test loss item: 0.4324854612350464
test loss item: 0.3255636394023895
test loss item: 0.3756560981273651
test loss item: 0.7002341151237488
test loss item: 1.113625407218933
test loss item: 0.34551241993904114
test loss item: 0.230564147233963
test loss item: 0.2526778280735016
test loss item: 0.14175012707710266
test loss item: 0.26017001271247864
test loss item: 0.1789671927690506
test loss item: 0.43928855657577515
test loss item: 0.3736186623573303
test loss item: 0.22744432091712952
test loss item: 0.25410154461860657
test loss item: 0.3855750560760498
test loss item: 0.563489556312561
test loss item: 0.21674136817455292
test loss item: 0.14122265577316284
test loss item: 0.18937073647975922
test loss item: 0.135543093085289
test loss item: 0.23061244189739227
test loss item: 0.6529507637023926
test loss item: 0.4908272624015808
test loss item: 0.19754847884178162
test loss item: 0.20730376243591309
test loss item: 0.1588188260793686
test loss item: 0.3226826786994934
test loss item: 0.2481512427330017
test loss item: 0.18708913028240204
test loss item: 0.20529116690158844
test loss item: 0.7191216349601746
test loss item: 0.26269882917404175
test loss item: 0.28725001215934753
test loss item: 0.21237501502037048
test loss item: 0.41503098607063293
test loss item: 0.4185444712638855
test loss item: 0.06972561031579971
test loss item: 0.872800350189209
test loss item: 0.27597758173942566
test loss item: 0.3566339612007141
test loss item: 0.14412666857242584
test loss item: 0.12632189691066742
test loss item: 0.15113407373428345
test loss item: 1.1636559963226318
test loss item: 0.3620336949825287
test loss item: 0.1596328169107437
test loss item: 0.0750272274017334
test loss item: 0.8224195241928101
test loss item: 0.7383449673652649
test loss item: 0.8010193705558777
test loss item: 0.19344277679920197
test loss item: 0.19012446701526642
test loss item: 0.06623683869838715
test loss item: 0.05607597157359123
test loss item: 0.15407618880271912
Epoch [38/100], Training Loss: 0.3521, Testing Loss: 0.3295
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 39/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.30965808033943176
1
train loss item: 0.7634860873222351
2
train loss item: 0.15656068921089172
3
train loss item: 0.30765408277511597
4
train loss item: 0.2647102475166321
5
train loss item: 0.1977422684431076
6
train loss item: 0.18053685128688812
7
train loss item: 0.5235047340393066
8
train loss item: 0.090627521276474
9
train loss item: 0.1865069568157196
10
train loss item: 0.20440466701984406
11
train loss item: 0.20053929090499878
12
train loss item: 0.11114536970853806
13
train loss item: 0.30279475450515747
14
train loss item: 0.15125752985477448
15
train loss item: 0.4510619044303894
16
train loss item: 0.059785958379507065
17
train loss item: 0.19423030316829681
18
train loss item: 0.2158936709165573
19
train loss item: 0.19483114778995514
20
train loss item: 0.17338620126247406
21
train loss item: 0.12131136655807495
22
train loss item: 0.6372620463371277
23
train loss item: 0.5026381611824036
24
train loss item: 0.38247817754745483
25
train loss item: 0.13904696702957153
26
train loss item: 0.13969525694847107
27
train loss item: 0.14400964975357056
28
train loss item: 0.05648048594594002
29
train loss item: 0.4898286461830139
30
train loss item: 1.7108322381973267
31
train loss item: 0.3443913757801056
32
train loss item: 0.09874686598777771
33
train loss item: 0.20933178067207336
34
train loss item: 0.11215619742870331
35
train loss item: 2.013779878616333
36
train loss item: 0.3275381028652191
37
train loss item: 0.30990493297576904
38
train loss item: 0.31411996483802795
39
train loss item: 0.15928804874420166
40
train loss item: 0.14908266067504883
41
train loss item: 0.16368386149406433
42
train loss item: 0.2255515456199646
43
train loss item: 0.14061392843723297
44
train loss item: 0.4471530318260193
45
train loss item: 0.0858984962105751
46
train loss item: 0.10732158273458481
47
train loss item: 0.24082624912261963
48
train loss item: 0.1503465324640274
49
train loss item: 0.10990745574235916
50
train loss item: 0.20984980463981628
51
train loss item: 0.6159409284591675
52
train loss item: 0.06171542406082153
53
train loss item: 0.1019897311925888
54
train loss item: 1.8970364332199097
55
train loss item: 0.1402318924665451
56
train loss item: 0.1610555350780487
57
train loss item: 0.17511172592639923
58
train loss item: 0.1426289677619934
59
train loss item: 0.10237552970647812
60
train loss item: 0.5617437362670898
61
train loss item: 1.7422713041305542
62
train loss item: 0.13448400795459747
63
train loss item: 0.255330890417099
64
train loss item: 0.12398292869329453
65
train loss item: 0.35021403431892395
66
train loss item: 0.32755178213119507
67
train loss item: 0.14852769672870636
68
train loss item: 0.22244641184806824
69
train loss item: 0.2180393785238266
70
train loss item: 0.167030930519104
71
train loss item: 0.10182920843362808
72
train loss item: 0.12266027927398682
73
train loss item: 0.21976691484451294
74
train loss item: 0.06574784219264984
75
train loss item: 0.09040280431509018
76
train loss item: 0.5235229134559631
77
train loss item: 1.0879385471343994
78
train loss item: 0.06020462512969971
79
train loss item: 0.19145037233829498
80
train loss item: 0.0942697748541832
81
train loss item: 0.13229578733444214
82
train loss item: 0.12775972485542297
83
train loss item: 0.4294368326663971
84
train loss item: 0.31312644481658936
85
train loss item: 0.3081502616405487
86
train loss item: 3.746380090713501
87
train loss item: 0.11073994636535645
88
train loss item: 0.2907857298851013
epoch train loss: 0.3499951795413253
testing phase
test loss item: 0.1451290100812912
test loss item: 0.13774512708187103
test loss item: 0.5124046206474304
test loss item: 0.1856088936328888
test loss item: 0.20850218832492828
test loss item: 0.11157966405153275
test loss item: 1.2672604322433472
test loss item: 0.4160792827606201
test loss item: 0.19436216354370117
test loss item: 0.32504040002822876
test loss item: 0.7247404456138611
test loss item: 0.13499659299850464
test loss item: 0.14275667071342468
test loss item: 0.22782652080059052
test loss item: 0.15010343492031097
test loss item: 0.21888189017772675
test loss item: 0.2154800146818161
test loss item: 0.39196455478668213
test loss item: 0.5209213495254517
test loss item: 0.20011496543884277
test loss item: 0.6313165426254272
test loss item: 0.3010201156139374
test loss item: 0.23347467184066772
test loss item: 0.12940701842308044
test loss item: 0.1777089536190033
test loss item: 0.1712934821844101
test loss item: 0.2547639310359955
test loss item: 0.14955124258995056
test loss item: 0.2545807659626007
test loss item: 0.2727883756160736
test loss item: 0.641097903251648
test loss item: 0.19742469489574432
test loss item: 0.1110980287194252
test loss item: 0.46749448776245117
test loss item: 0.38519755005836487
test loss item: 0.3497520089149475
test loss item: 0.6238091588020325
test loss item: 1.2376008033752441
test loss item: 0.3701949715614319
test loss item: 0.2029360830783844
test loss item: 0.25461095571517944
test loss item: 0.13302181661128998
test loss item: 0.29702723026275635
test loss item: 0.16350199282169342
test loss item: 0.48043161630630493
test loss item: 0.3263876438140869
test loss item: 0.22621148824691772
test loss item: 0.18192969262599945
test loss item: 0.3971734046936035
test loss item: 0.5729785561561584
test loss item: 0.2530736029148102
test loss item: 0.11922837048768997
test loss item: 0.1940895915031433
test loss item: 0.1351548731327057
test loss item: 0.2599306106567383
test loss item: 0.7358071804046631
test loss item: 0.4412432909011841
test loss item: 0.21518929302692413
test loss item: 0.19929060339927673
test loss item: 0.1683931052684784
test loss item: 0.37641024589538574
test loss item: 0.22270013391971588
test loss item: 0.15516093373298645
test loss item: 0.18785417079925537
test loss item: 0.725675642490387
test loss item: 0.25978437066078186
test loss item: 0.24301640689373016
test loss item: 0.19226747751235962
test loss item: 0.44965338706970215
test loss item: 0.34585246443748474
test loss item: 0.15018165111541748
test loss item: 0.7215211987495422
test loss item: 0.2628304064273834
test loss item: 0.2933371365070343
test loss item: 0.12329508364200592
test loss item: 0.11074182391166687
test loss item: 0.14309872686862946
test loss item: 1.2773898839950562
test loss item: 0.3394862115383148
test loss item: 0.1468428075313568
test loss item: 0.10000559687614441
test loss item: 0.8001329302787781
test loss item: 0.6981924176216125
test loss item: 0.877837061882019
test loss item: 0.1712285578250885
test loss item: 0.1763291358947754
test loss item: 0.1663961112499237
test loss item: 0.23607636988162994
test loss item: 0.17635633051395416
Epoch [39/100], Training Loss: 0.3500, Testing Loss: 0.3312
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 40/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2982482314109802
1
train loss item: 0.7239372134208679
2
train loss item: 0.1401209831237793
3
train loss item: 0.3007007837295532
4
train loss item: 0.23931856453418732
5
train loss item: 0.19132040441036224
6
train loss item: 0.1473432183265686
7
train loss item: 0.5270059108734131
8
train loss item: 0.08846965432167053
9
train loss item: 0.15595920383930206
10
train loss item: 0.19460196793079376
11
train loss item: 0.1881813406944275
12
train loss item: 0.10427501797676086
13
train loss item: 0.30823323130607605
14
train loss item: 0.15909378230571747
15
train loss item: 0.3897123634815216
16
train loss item: 0.05104697868227959
17
train loss item: 0.17410048842430115
18
train loss item: 0.19825351238250732
19
train loss item: 0.15259729325771332
20
train loss item: 0.129755899310112
21
train loss item: 0.09529226273298264
22
train loss item: 0.5681819319725037
23
train loss item: 0.5178381204605103
24
train loss item: 0.33716586232185364
25
train loss item: 0.12856407463550568
26
train loss item: 0.12012312561273575
27
train loss item: 0.14268271625041962
28
train loss item: 0.048975273966789246
29
train loss item: 0.4400498867034912
30
train loss item: 1.7044435739517212
31
train loss item: 0.339254230260849
32
train loss item: 0.07770739495754242
33
train loss item: 0.2425675392150879
34
train loss item: 0.10498227179050446
35
train loss item: 2.0050342082977295
36
train loss item: 0.3257940113544464
37
train loss item: 0.3221166729927063
38
train loss item: 0.29812008142471313
39
train loss item: 0.14418698847293854
40
train loss item: 0.11761502176523209
41
train loss item: 0.1595078706741333
42
train loss item: 0.2091730386018753
43
train loss item: 0.11473667621612549
44
train loss item: 0.4596492052078247
45
train loss item: 0.09499073773622513
46
train loss item: 0.07893639802932739
47
train loss item: 0.21410591900348663
48
train loss item: 0.1344618946313858
49
train loss item: 0.10753978788852692
50
train loss item: 0.16967523097991943
51
train loss item: 0.603602409362793
52
train loss item: 0.05656896531581879
53
train loss item: 0.10999342799186707
54
train loss item: 1.8897303342819214
55
train loss item: 0.1321384161710739
56
train loss item: 0.14555910229682922
57
train loss item: 0.1590358316898346
58
train loss item: 0.1085808128118515
59
train loss item: 0.09761232137680054
60
train loss item: 0.52198326587677
61
train loss item: 1.7489556074142456
62
train loss item: 0.1254800260066986
63
train loss item: 0.2338494062423706
64
train loss item: 0.10800221562385559
65
train loss item: 0.34260374307632446
66
train loss item: 0.2777293026447296
67
train loss item: 0.1300889253616333
68
train loss item: 0.1736670583486557
69
train loss item: 0.1943116933107376
70
train loss item: 0.16051198542118073
71
train loss item: 0.09059859067201614
72
train loss item: 0.11022713780403137
73
train loss item: 0.1894536167383194
74
train loss item: 0.06505192071199417
75
train loss item: 0.08556248992681503
76
train loss item: 0.5165865421295166
77
train loss item: 1.0636472702026367
78
train loss item: 0.055261868983507156
79
train loss item: 0.17782731354236603
80
train loss item: 0.081822969019413
81
train loss item: 0.12587550282478333
82
train loss item: 0.1304500252008438
83
train loss item: 0.41235601902008057
84
train loss item: 0.32486793398857117
85
train loss item: 0.2931899130344391
86
train loss item: 3.7371463775634766
87
train loss item: 0.11791648715734482
88
train loss item: 0.25595003366470337
epoch train loss: 0.3352757855580094
testing phase
test loss item: 0.14904804527759552
test loss item: 0.11935976892709732
test loss item: 0.4976799190044403
test loss item: 0.18693400919437408
test loss item: 0.19974148273468018
test loss item: 0.1023295670747757
test loss item: 1.2145638465881348
test loss item: 0.38120612502098083
test loss item: 0.18510086834430695
test loss item: 0.3089335858821869
test loss item: 0.7227197885513306
test loss item: 0.12747886776924133
test loss item: 0.13626427948474884
test loss item: 0.22625239193439484
test loss item: 0.14069363474845886
test loss item: 0.1802218109369278
test loss item: 0.20880985260009766
test loss item: 0.37158823013305664
test loss item: 0.500920295715332
test loss item: 0.18944048881530762
test loss item: 0.598863959312439
test loss item: 0.28982898592948914
test loss item: 0.2236153483390808
test loss item: 0.1278945803642273
test loss item: 0.16974496841430664
test loss item: 0.16277191042900085
test loss item: 0.24521854519844055
test loss item: 0.14203700423240662
test loss item: 0.24379278719425201
test loss item: 0.26107388734817505
test loss item: 0.6283345818519592
test loss item: 0.16732200980186462
test loss item: 0.1120961531996727
test loss item: 0.4531470835208893
test loss item: 0.36335307359695435
test loss item: 0.3394835591316223
test loss item: 0.5964478254318237
test loss item: 1.2338485717773438
test loss item: 0.3560406267642975
test loss item: 0.19779051840305328
test loss item: 0.242959126830101
test loss item: 0.1354794204235077
test loss item: 0.2806641459465027
test loss item: 0.16360065340995789
test loss item: 0.4538344144821167
test loss item: 0.3006369173526764
test loss item: 0.21686378121376038
test loss item: 0.177031010389328
test loss item: 0.3798395097255707
test loss item: 0.555327296257019
test loss item: 0.2351374477148056
test loss item: 0.10964463651180267
test loss item: 0.18737541139125824
test loss item: 0.13878224790096283
test loss item: 0.2463424801826477
test loss item: 0.7241292595863342
test loss item: 0.42695069313049316
test loss item: 0.19970214366912842
test loss item: 0.18687361478805542
test loss item: 0.15887205302715302
test loss item: 0.3541843891143799
test loss item: 0.20166605710983276
test loss item: 0.15386049449443817
test loss item: 0.18116585910320282
test loss item: 0.711986780166626
test loss item: 0.2607548236846924
test loss item: 0.2294306457042694
test loss item: 0.1852346807718277
test loss item: 0.4366511404514313
test loss item: 0.33918172121047974
test loss item: 0.12285060435533524
test loss item: 0.6768360137939453
test loss item: 0.2553166449069977
test loss item: 0.28226056694984436
test loss item: 0.12002689391374588
test loss item: 0.11013028025627136
test loss item: 0.13396680355072021
test loss item: 1.283172607421875
test loss item: 0.3355106711387634
test loss item: 0.14555031061172485
test loss item: 0.08053307980298996
test loss item: 0.7838852405548096
test loss item: 0.6721252799034119
test loss item: 0.8758015632629395
test loss item: 0.16486035287380219
test loss item: 0.16888780891895294
test loss item: 0.13907809555530548
test loss item: 0.19605118036270142
test loss item: 0.1726393699645996
Epoch [40/100], Training Loss: 0.3353, Testing Loss: 0.3186
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 41/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.30010056495666504
1
train loss item: 0.6967504620552063
2
train loss item: 0.13826249539852142
3
train loss item: 0.29368001222610474
4
train loss item: 0.24442271888256073
5
train loss item: 0.18980394303798676
6
train loss item: 0.14545130729675293
7
train loss item: 0.5130791664123535
8
train loss item: 0.08892084658145905
9
train loss item: 0.15767914056777954
10
train loss item: 0.19798800349235535
11
train loss item: 0.1905413568019867
12
train loss item: 0.10119219124317169
13
train loss item: 0.30898556113243103
14
train loss item: 0.15433211624622345
15
train loss item: 0.3780190646648407
16
train loss item: 0.05081437528133392
17
train loss item: 0.17719581723213196
18
train loss item: 0.1957198679447174
19
train loss item: 0.1477782279253006
20
train loss item: 0.1301080584526062
21
train loss item: 0.0990852564573288
22
train loss item: 0.5408230423927307
23
train loss item: 0.5011926889419556
24
train loss item: 0.33250701427459717
25
train loss item: 0.12786418199539185
26
train loss item: 0.12048409134149551
27
train loss item: 0.13462084531784058
28
train loss item: 0.04935379698872566
29
train loss item: 0.41939663887023926
30
train loss item: 1.6810362339019775
31
train loss item: 0.3433757424354553
32
train loss item: 0.08258963376283646
33
train loss item: 0.23908908665180206
34
train loss item: 0.1067291870713234
35
train loss item: 1.9928748607635498
36
train loss item: 0.3341321647167206
37
train loss item: 0.32893291115760803
38
train loss item: 0.32395392656326294
39
train loss item: 0.1437259465456009
40
train loss item: 0.11419685930013657
41
train loss item: 0.15399089455604553
42
train loss item: 0.20690631866455078
43
train loss item: 0.1133057177066803
44
train loss item: 0.45002588629722595
45
train loss item: 0.09428960829973221
46
train loss item: 0.08019112050533295
47
train loss item: 0.20773564279079437
48
train loss item: 0.13002248108386993
49
train loss item: 0.10809038579463959
50
train loss item: 0.16388878226280212
51
train loss item: 0.5862196087837219
52
train loss item: 0.055976323783397675
53
train loss item: 0.10447043925523758
54
train loss item: 1.8766523599624634
55
train loss item: 0.1281154751777649
56
train loss item: 0.14655084908008575
57
train loss item: 0.15677814185619354
58
train loss item: 0.10513843595981598
59
train loss item: 0.09877435117959976
60
train loss item: 0.4902293384075165
61
train loss item: 1.727344274520874
62
train loss item: 0.12160791456699371
63
train loss item: 0.22942078113555908
64
train loss item: 0.10857842862606049
65
train loss item: 0.35055723786354065
66
train loss item: 0.28971949219703674
67
train loss item: 0.1279355138540268
68
train loss item: 0.16457892954349518
69
train loss item: 0.1981504112482071
70
train loss item: 0.1636638343334198
71
train loss item: 0.08975093811750412
72
train loss item: 0.10739175975322723
73
train loss item: 0.18596230447292328
74
train loss item: 0.06544170528650284
75
train loss item: 0.08588945865631104
76
train loss item: 0.49814388155937195
77
train loss item: 1.0471519231796265
78
train loss item: 0.053205456584692
79
train loss item: 0.17953908443450928
80
train loss item: 0.08379536122083664
81
train loss item: 0.12498293817043304
82
train loss item: 0.12689924240112305
83
train loss item: 0.39827480912208557
84
train loss item: 0.33596283197402954
85
train loss item: 0.28582239151000977
86
train loss item: 3.7171289920806885
87
train loss item: 0.11416143923997879
88
train loss item: 0.2641725242137909
epoch train loss: 0.3316783756017685
testing phase
test loss item: 0.1479879915714264
test loss item: 0.12353216856718063
test loss item: 0.4108967185020447
test loss item: 0.1864001452922821
test loss item: 0.18495716154575348
test loss item: 0.10751045495271683
test loss item: 1.3842010498046875
test loss item: 0.48030251264572144
test loss item: 0.15514132380485535
test loss item: 0.2691600024700165
test loss item: 0.6103112697601318
test loss item: 0.1290488839149475
test loss item: 0.15748576819896698
test loss item: 0.25391262769699097
test loss item: 0.12794652581214905
test loss item: 0.17667213082313538
test loss item: 0.2306896448135376
test loss item: 0.3070189356803894
test loss item: 0.5439194440841675
test loss item: 0.231119766831398
test loss item: 0.49424588680267334
test loss item: 0.3246420919895172
test loss item: 0.21611298620700836
test loss item: 0.14056815207004547
test loss item: 0.15503627061843872
test loss item: 0.1747955083847046
test loss item: 0.24224765598773956
test loss item: 0.14046910405158997
test loss item: 0.2351473569869995
test loss item: 0.2498456835746765
test loss item: 0.5959991216659546
test loss item: 0.17880208790302277
test loss item: 0.11903268843889236
test loss item: 0.38734549283981323
test loss item: 0.2977335453033447
test loss item: 0.3144422769546509
test loss item: 0.6424598097801208
test loss item: 1.0090677738189697
test loss item: 0.3082606792449951
test loss item: 0.21940398216247559
test loss item: 0.2581532895565033
test loss item: 0.1438240259885788
test loss item: 0.22607620060443878
test loss item: 0.16865691542625427
test loss item: 0.37627607583999634
test loss item: 0.34941011667251587
test loss item: 0.2070319950580597
test loss item: 0.22110208868980408
test loss item: 0.3417018949985504
test loss item: 0.5009777545928955
test loss item: 0.18835768103599548
test loss item: 0.13195377588272095
test loss item: 0.17423401772975922
test loss item: 0.12480589747428894
test loss item: 0.20252129435539246
test loss item: 0.583711564540863
test loss item: 0.4323972463607788
test loss item: 0.1789611428976059
test loss item: 0.1914949119091034
test loss item: 0.14631609618663788
test loss item: 0.2841508984565735
test loss item: 0.23800227046012878
test loss item: 0.1760421097278595
test loss item: 0.19174207746982574
test loss item: 0.6522553563117981
test loss item: 0.25454089045524597
test loss item: 0.2582540512084961
test loss item: 0.19911833107471466
test loss item: 0.39132142066955566
test loss item: 0.3416057229042053
test loss item: 0.12564674019813538
test loss item: 0.8100528717041016
test loss item: 0.2578522861003876
test loss item: 0.3306838274002075
test loss item: 0.1308416873216629
test loss item: 0.12206526845693588
test loss item: 0.14595723152160645
test loss item: 1.0675071477890015
test loss item: 0.33842357993125916
test loss item: 0.15049931406974792
test loss item: 0.07376621663570404
test loss item: 0.7556717395782471
test loss item: 0.675750195980072
test loss item: 0.7282548546791077
test loss item: 0.18023525178432465
test loss item: 0.17347539961338043
test loss item: 0.12211978435516357
test loss item: 0.17351806163787842
test loss item: 0.1587926745414734
Epoch [41/100], Training Loss: 0.3317, Testing Loss: 0.3070
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 42/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2970939576625824
1
train loss item: 0.6840699911117554
2
train loss item: 0.14077970385551453
3
train loss item: 0.27412718534469604
4
train loss item: 0.23405088484287262
5
train loss item: 0.18886716663837433
6
train loss item: 0.15591475367546082
7
train loss item: 0.4924458861351013
8
train loss item: 0.07841280102729797
9
train loss item: 0.17078445851802826
10
train loss item: 0.20558449625968933
11
train loss item: 0.18425177037715912
12
train loss item: 0.100670725107193
13
train loss item: 0.29359492659568787
14
train loss item: 0.1455351710319519
15
train loss item: 0.41088977456092834
16
train loss item: 0.05477677658200264
17
train loss item: 0.16658179461956024
18
train loss item: 0.20599238574504852
19
train loss item: 0.1770821362733841
20
train loss item: 0.1451549082994461
21
train loss item: 0.10453066974878311
22
train loss item: 0.5702921152114868
23
train loss item: 0.4561361074447632
24
train loss item: 0.35893020033836365
25
train loss item: 0.13887453079223633
26
train loss item: 0.12488681823015213
27
train loss item: 0.13374698162078857
28
train loss item: 0.05227265506982803
29
train loss item: 0.44172465801239014
30
train loss item: 1.6466304063796997
31
train loss item: 0.3418947160243988
32
train loss item: 0.07997827976942062
33
train loss item: 0.20777003467082977
34
train loss item: 0.10588766634464264
35
train loss item: 1.9790723323822021
36
train loss item: 0.3173328638076782
37
train loss item: 0.30166134238243103
38
train loss item: 0.3115418553352356
39
train loss item: 0.1637016385793686
40
train loss item: 0.1386234164237976
41
train loss item: 0.14948436617851257
42
train loss item: 0.2187497913837433
43
train loss item: 0.12975148856639862
44
train loss item: 0.42963117361068726
45
train loss item: 0.08290962129831314
46
train loss item: 0.0999348908662796
47
train loss item: 0.22731737792491913
48
train loss item: 0.13786673545837402
49
train loss item: 0.1037374883890152
50
train loss item: 0.19018256664276123
51
train loss item: 0.5714454650878906
52
train loss item: 0.05922483652830124
53
train loss item: 0.09809179604053497
54
train loss item: 1.8610634803771973
55
train loss item: 0.1299886256456375
56
train loss item: 0.16077551245689392
57
train loss item: 0.1713148057460785
58
train loss item: 0.1244269534945488
59
train loss item: 0.10089126229286194
60
train loss item: 0.48822981119155884
61
train loss item: 1.6878055334091187
62
train loss item: 0.12305853515863419
63
train loss item: 0.23719309270381927
64
train loss item: 0.11739864945411682
65
train loss item: 0.31439408659935
66
train loss item: 0.3110800087451935
67
train loss item: 0.13557206094264984
68
train loss item: 0.19486938416957855
69
train loss item: 0.21287626028060913
70
train loss item: 0.16004525125026703
71
train loss item: 0.09451992809772491
72
train loss item: 0.10874782502651215
73
train loss item: 0.20141549408435822
74
train loss item: 0.06392394751310349
75
train loss item: 0.08622521162033081
76
train loss item: 0.47302648425102234
77
train loss item: 1.049514651298523
78
train loss item: 0.054542168974876404
79
train loss item: 0.17709434032440186
80
train loss item: 0.09684653580188751
81
train loss item: 0.1338765025138855
82
train loss item: 0.11649027466773987
83
train loss item: 0.39603516459465027
84
train loss item: 0.29614537954330444
85
train loss item: 0.2870338261127472
86
train loss item: 3.6899609565734863
87
train loss item: 0.11336631327867508
88
train loss item: 0.28285127878189087
epoch train loss: 0.33183233862679995
testing phase
test loss item: 0.14403119683265686
test loss item: 0.11144993454217911
test loss item: 0.4645397961139679
test loss item: 0.18329903483390808
test loss item: 0.1936124563217163
test loss item: 0.09852902591228485
test loss item: 1.3376774787902832
test loss item: 0.40648192167282104
test loss item: 0.17091666162014008
test loss item: 0.2890479266643524
test loss item: 0.6644967794418335
test loss item: 0.12122195959091187
test loss item: 0.14012733101844788
test loss item: 0.22249791026115417
test loss item: 0.13695450127124786
test loss item: 0.16021740436553955
test loss item: 0.20846207439899445
test loss item: 0.34626516699790955
test loss item: 0.49992817640304565
test loss item: 0.1932923048734665
test loss item: 0.5659180283546448
test loss item: 0.29855984449386597
test loss item: 0.22056640684604645
test loss item: 0.13231828808784485
test loss item: 0.15667641162872314
test loss item: 0.16022971272468567
test loss item: 0.2326754331588745
test loss item: 0.13778485357761383
test loss item: 0.24094761908054352
test loss item: 0.24652855098247528
test loss item: 0.6216421127319336
test loss item: 0.1456882655620575
test loss item: 0.11347862333059311
test loss item: 0.4252859950065613
test loss item: 0.3374803364276886
test loss item: 0.3149845600128174
test loss item: 0.6083758473396301
test loss item: 1.1263697147369385
test loss item: 0.33838438987731934
test loss item: 0.20595982670783997
test loss item: 0.2438841611146927
test loss item: 0.12987357378005981
test loss item: 0.255825400352478
test loss item: 0.16092950105667114
test loss item: 0.42610254883766174
test loss item: 0.3000296950340271
test loss item: 0.21125075221061707
test loss item: 0.17783300578594208
test loss item: 0.36325785517692566
test loss item: 0.5163588523864746
test loss item: 0.2220897674560547
test loss item: 0.1055004671216011
test loss item: 0.17914246022701263
test loss item: 0.12311874330043793
test loss item: 0.22990012168884277
test loss item: 0.6637139916419983
test loss item: 0.4137219488620758
test loss item: 0.19215983152389526
test loss item: 0.18048684298992157
test loss item: 0.15464094281196594
test loss item: 0.3229213058948517
test loss item: 0.19907228648662567
test loss item: 0.15455280244350433
test loss item: 0.18200011551380157
test loss item: 0.6895775198936462
test loss item: 0.2523173689842224
test loss item: 0.22954429686069489
test loss item: 0.190097838640213
test loss item: 0.41790932416915894
test loss item: 0.31408435106277466
test loss item: 0.11308854818344116
test loss item: 0.739799439907074
test loss item: 0.25467368960380554
test loss item: 0.2991752326488495
test loss item: 0.11697258055210114
test loss item: 0.11104517430067062
test loss item: 0.1358010470867157
test loss item: 1.1923094987869263
test loss item: 0.32637548446655273
test loss item: 0.1394350230693817
test loss item: 0.06903275847434998
test loss item: 0.7662712931632996
test loss item: 0.6680843234062195
test loss item: 0.8100115656852722
test loss item: 0.1662968546152115
test loss item: 0.16193057596683502
test loss item: 0.12626002728939056
test loss item: 0.1766069531440735
test loss item: 0.15228278934955597
Epoch [42/100], Training Loss: 0.3318, Testing Loss: 0.3084
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 43/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2841572165489197
1
train loss item: 0.6652160882949829
2
train loss item: 0.132877379655838
3
train loss item: 0.26256924867630005
4
train loss item: 0.22993068397045135
5
train loss item: 0.17596593499183655
6
train loss item: 0.1377037912607193
7
train loss item: 0.4965456426143646
8
train loss item: 0.08150669932365417
9
train loss item: 0.1443021148443222
10
train loss item: 0.17885757982730865
11
train loss item: 0.1739797443151474
12
train loss item: 0.09739233553409576
13
train loss item: 0.29235053062438965
14
train loss item: 0.15199273824691772
15
train loss item: 0.3684234023094177
16
train loss item: 0.04908716306090355
17
train loss item: 0.15339644253253937
18
train loss item: 0.1837383359670639
19
train loss item: 0.14569631218910217
20
train loss item: 0.12047236412763596
21
train loss item: 0.08761085569858551
22
train loss item: 0.5213093757629395
23
train loss item: 0.4720732569694519
24
train loss item: 0.31642481684684753
25
train loss item: 0.11738325655460358
26
train loss item: 0.11023378372192383
27
train loss item: 0.13577498495578766
28
train loss item: 0.04828483238816261
29
train loss item: 0.4117593467235565
30
train loss item: 1.6453499794006348
31
train loss item: 0.31587693095207214
32
train loss item: 0.07746598869562149
33
train loss item: 0.22247414290905
34
train loss item: 0.09891963005065918
35
train loss item: 1.9707190990447998
36
train loss item: 0.29601001739501953
37
train loss item: 0.3046659827232361
38
train loss item: 0.26570144295692444
39
train loss item: 0.13769221305847168
40
train loss item: 0.11020252108573914
41
train loss item: 0.149169921875
42
train loss item: 0.206634059548378
43
train loss item: 0.10941284894943237
44
train loss item: 0.4398542046546936
45
train loss item: 0.09483890980482101
46
train loss item: 0.07940822094678879
47
train loss item: 0.21029512584209442
48
train loss item: 0.12938839197158813
49
train loss item: 0.09868994355201721
50
train loss item: 0.16229824721813202
51
train loss item: 0.5643665790557861
52
train loss item: 0.05400140583515167
53
train loss item: 0.10038663446903229
54
train loss item: 1.8543508052825928
55
train loss item: 0.12495563924312592
56
train loss item: 0.13944396376609802
57
train loss item: 0.1515597254037857
58
train loss item: 0.10130402445793152
59
train loss item: 0.0994950458407402
60
train loss item: 0.4783967435359955
61
train loss item: 1.700655221939087
62
train loss item: 0.11894319206476212
63
train loss item: 0.22127023339271545
64
train loss item: 0.10451805591583252
65
train loss item: 0.3041948676109314
66
train loss item: 0.25431063771247864
67
train loss item: 0.12435000389814377
68
train loss item: 0.1668744832277298
69
train loss item: 0.18423078954219818
70
train loss item: 0.15049052238464355
71
train loss item: 0.08222724497318268
72
train loss item: 0.10688597708940506
73
train loss item: 0.17855043709278107
74
train loss item: 0.06680744141340256
75
train loss item: 0.08259744197130203
76
train loss item: 0.4746394753456116
77
train loss item: 1.036952018737793
78
train loss item: 0.04977535456418991
79
train loss item: 0.1653509885072708
80
train loss item: 0.0880545824766159
81
train loss item: 0.11845102161169052
82
train loss item: 0.12241964787244797
83
train loss item: 0.3881853520870209
84
train loss item: 0.2928556203842163
85
train loss item: 0.27395662665367126
86
train loss item: 3.682673454284668
87
train loss item: 0.11217819899320602
88
train loss item: 0.23024490475654602
epoch train loss: 0.31935942072546886
testing phase
test loss item: 0.14349490404129028
test loss item: 0.16125071048736572
test loss item: 0.4963420331478119
test loss item: 0.18188026547431946
test loss item: 0.19732566177845
test loss item: 0.09520850330591202
test loss item: 1.2816880941390991
test loss item: 0.365455687046051
test loss item: 0.1726875603199005
test loss item: 0.29406484961509705
test loss item: 0.7039244174957275
test loss item: 0.12110991030931473
test loss item: 0.13374727964401245
test loss item: 0.2170499861240387
test loss item: 0.13847045600414276
test loss item: 0.2745446264743805
test loss item: 0.20237500965595245
test loss item: 0.36263781785964966
test loss item: 0.47083964943885803
test loss item: 0.179666668176651
test loss item: 0.6005370616912842
test loss item: 0.28685057163238525
test loss item: 0.22509899735450745
test loss item: 0.1255117654800415
test loss item: 0.1652952879667282
test loss item: 0.1549917608499527
test loss item: 0.2279457151889801
test loss item: 0.1358574777841568
test loss item: 0.23878781497478485
test loss item: 0.24653638899326324
test loss item: 0.6367098093032837
test loss item: 0.25640666484832764
test loss item: 0.10731273144483566
test loss item: 0.4463483989238739
test loss item: 0.3807532489299774
test loss item: 0.3121708929538727
test loss item: 0.5806823372840881
test loss item: 1.217399001121521
test loss item: 0.3536261320114136
test loss item: 0.1966213583946228
test loss item: 0.26811379194259644
test loss item: 0.12255163490772247
test loss item: 0.262274831533432
test loss item: 0.16190195083618164
test loss item: 0.4496390223503113
test loss item: 0.3147064745426178
test loss item: 0.21224570274353027
test loss item: 0.1691988855600357
test loss item: 0.37455764412879944
test loss item: 0.5241395831108093
test loss item: 0.22737273573875427
test loss item: 0.10699140280485153
test loss item: 0.18239451944828033
test loss item: 0.12977388501167297
test loss item: 0.23981241881847382
test loss item: 0.7128661870956421
test loss item: 0.41053497791290283
test loss item: 0.19553044438362122
test loss item: 0.17876401543617249
test loss item: 0.15145939588546753
test loss item: 0.3312973082065582
test loss item: 0.22355279326438904
test loss item: 0.145705908536911
test loss item: 0.17343682050704956
test loss item: 0.7297846078872681
test loss item: 0.25340911746025085
test loss item: 0.22143669426441193
test loss item: 0.18413467705249786
test loss item: 0.45869001746177673
test loss item: 0.2886793613433838
test loss item: 0.18211695551872253
test loss item: 0.6897475719451904
test loss item: 0.25685063004493713
test loss item: 0.28164365887641907
test loss item: 0.1161864846944809
test loss item: 0.10526343435049057
test loss item: 0.1317974328994751
test loss item: 1.3129404783248901
test loss item: 0.33516332507133484
test loss item: 0.1354902982711792
test loss item: 0.07483891397714615
test loss item: 0.778949499130249
test loss item: 0.6497569680213928
test loss item: 0.8803632259368896
test loss item: 0.16236181557178497
test loss item: 0.16328996419906616
test loss item: 0.2027275711297989
test loss item: 0.29929545521736145
test loss item: 0.14561422169208527
Epoch [43/100], Training Loss: 0.3194, Testing Loss: 0.3191
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 44/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2838755249977112
1
train loss item: 0.6464474201202393
2
train loss item: 0.13074199855327606
3
train loss item: 0.2555050849914551
4
train loss item: 0.21938635408878326
5
train loss item: 0.1753160059452057
6
train loss item: 0.135250985622406
7
train loss item: 0.4889727532863617
8
train loss item: 0.08390333503484726
9
train loss item: 0.14374634623527527
10
train loss item: 0.179001584649086
11
train loss item: 0.17834816873073578
12
train loss item: 0.10167042911052704
13
train loss item: 0.29578402638435364
14
train loss item: 0.15357814729213715
15
train loss item: 0.3499603569507599
16
train loss item: 0.050811804831027985
17
train loss item: 0.1543572098016739
18
train loss item: 0.18413040041923523
19
train loss item: 0.13617676496505737
20
train loss item: 0.12165698409080505
21
train loss item: 0.09182082116603851
22
train loss item: 0.4900146424770355
23
train loss item: 0.4653380215167999
24
train loss item: 0.3082018792629242
25
train loss item: 0.11844254285097122
26
train loss item: 0.11035803705453873
27
train loss item: 0.13838247954845428
28
train loss item: 0.04906770959496498
29
train loss item: 0.388467937707901
30
train loss item: 1.6267606019973755
31
train loss item: 0.31266945600509644
32
train loss item: 0.07872114330530167
33
train loss item: 0.21853387355804443
34
train loss item: 0.1040370985865593
35
train loss item: 1.9592770338058472
36
train loss item: 0.3053205907344818
37
train loss item: 0.31494173407554626
38
train loss item: 0.27930310368537903
39
train loss item: 0.13769973814487457
40
train loss item: 0.10966595262289047
41
train loss item: 0.15092535316944122
42
train loss item: 0.20176374912261963
43
train loss item: 0.10740599036216736
44
train loss item: 0.4389598071575165
45
train loss item: 0.0941937267780304
46
train loss item: 0.08155560493469238
47
train loss item: 0.20014049112796783
48
train loss item: 0.12702473998069763
49
train loss item: 0.09795506298542023
50
train loss item: 0.15047724545001984
51
train loss item: 0.5484699010848999
52
train loss item: 0.05468793958425522
53
train loss item: 0.09746850281953812
54
train loss item: 1.8426284790039062
55
train loss item: 0.12276964634656906
56
train loss item: 0.13964997231960297
57
train loss item: 0.14590278267860413
58
train loss item: 0.10097426176071167
59
train loss item: 0.09550776332616806
60
train loss item: 0.4612571895122528
61
train loss item: 1.6897683143615723
62
train loss item: 0.12046608328819275
63
train loss item: 0.21560215950012207
64
train loss item: 0.10244572162628174
65
train loss item: 0.3125342130661011
66
train loss item: 0.2587643265724182
67
train loss item: 0.12487106770277023
68
train loss item: 0.15718919038772583
69
train loss item: 0.1848064363002777
70
train loss item: 0.15241923928260803
71
train loss item: 0.08524637669324875
72
train loss item: 0.10496392101049423
73
train loss item: 0.17292994260787964
74
train loss item: 0.062461551278829575
75
train loss item: 0.08394426107406616
76
train loss item: 0.46607309579849243
77
train loss item: 1.0158203840255737
78
train loss item: 0.05399547517299652
79
train loss item: 0.1680840700864792
80
train loss item: 0.09087686240673065
81
train loss item: 0.11936239898204803
82
train loss item: 0.12314695119857788
83
train loss item: 0.37756311893463135
84
train loss item: 0.3104245364665985
85
train loss item: 0.26633545756340027
86
train loss item: 3.6665737628936768
87
train loss item: 0.10841759294271469
88
train loss item: 0.22613415122032166
epoch train loss: 0.3163661230983359
testing phase
test loss item: 0.14168138802051544
test loss item: 0.1130201518535614
test loss item: 0.42050448060035706
test loss item: 0.1807442605495453
test loss item: 0.18040673434734344
test loss item: 0.0924362763762474
test loss item: 1.38489830493927
test loss item: 0.44410240650177
test loss item: 0.15079373121261597
test loss item: 0.26256313920021057
test loss item: 0.6204739809036255
test loss item: 0.12142946571111679
test loss item: 0.14865288138389587
test loss item: 0.23296761512756348
test loss item: 0.123308926820755
test loss item: 0.17332151532173157
test loss item: 0.21747048199176788
test loss item: 0.30734655261039734
test loss item: 0.5122495889663696
test loss item: 0.2140006721019745
test loss item: 0.5048379302024841
test loss item: 0.3117969334125519
test loss item: 0.212342768907547
test loss item: 0.13437829911708832
test loss item: 0.15158849954605103
test loss item: 0.1645861566066742
test loss item: 0.22794628143310547
test loss item: 0.13133715093135834
test loss item: 0.22701522707939148
test loss item: 0.23894017934799194
test loss item: 0.6110222935676575
test loss item: 0.16884148120880127
test loss item: 0.11188727617263794
test loss item: 0.38877153396606445
test loss item: 0.3045618534088135
test loss item: 0.3079227805137634
test loss item: 0.6125527024269104
test loss item: 1.039182424545288
test loss item: 0.31136444211006165
test loss item: 0.20952805876731873
test loss item: 0.25298750400543213
test loss item: 0.12538625299930573
test loss item: 0.21771593391895294
test loss item: 0.16497141122817993
test loss item: 0.3781582713127136
test loss item: 0.32231405377388
test loss item: 0.19838395714759827
test loss item: 0.21194571256637573
test loss item: 0.3394857347011566
test loss item: 0.4860176742076874
test loss item: 0.18597477674484253
test loss item: 0.12663625180721283
test loss item: 0.17081588506698608
test loss item: 0.12138766795396805
test loss item: 0.2020566612482071
test loss item: 0.60196453332901
test loss item: 0.4165361523628235
test loss item: 0.17070677876472473
test loss item: 0.1801733374595642
test loss item: 0.13857673108577728
test loss item: 0.27435824275016785
test loss item: 0.22004903852939606
test loss item: 0.16171695291996002
test loss item: 0.17975756525993347
test loss item: 0.6651104092597961
test loss item: 0.2487950623035431
test loss item: 0.24335598945617676
test loss item: 0.19219255447387695
test loss item: 0.4013046324253082
test loss item: 0.33445462584495544
test loss item: 0.1191275492310524
test loss item: 0.7791240215301514
test loss item: 0.24940308928489685
test loss item: 0.31405186653137207
test loss item: 0.12337684631347656
test loss item: 0.10976888984441757
test loss item: 0.13904206454753876
test loss item: 1.1311230659484863
test loss item: 0.32844462990760803
test loss item: 0.13569757342338562
test loss item: 0.06656071543693542
test loss item: 0.7534205317497253
test loss item: 0.6561189293861389
test loss item: 0.7592033743858337
test loss item: 0.1725952923297882
test loss item: 0.16559264063835144
test loss item: 0.12862902879714966
test loss item: 0.1851935237646103
test loss item: 0.13445746898651123
Epoch [44/100], Training Loss: 0.3164, Testing Loss: 0.3011
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Epoch 45/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.280320942401886
1
train loss item: 0.6344465017318726
2
train loss item: 0.12560683488845825
3
train loss item: 0.2557273507118225
4
train loss item: 0.2283662110567093
5
train loss item: 0.1733921468257904
6
train loss item: 0.1466650366783142
7
train loss item: 0.46153658628463745
8
train loss item: 0.076289102435112
9
train loss item: 0.15276435017585754
10
train loss item: 0.1904037594795227
11
train loss item: 0.17332063615322113
12
train loss item: 0.10335220396518707
13
train loss item: 0.28179460763931274
14
train loss item: 0.1356854885816574
15
train loss item: 0.38482099771499634
16
train loss item: 0.05691526085138321
17
train loss item: 0.15583471953868866
18
train loss item: 0.1889074593782425
19
train loss item: 0.15614469349384308
20
train loss item: 0.13531890511512756
21
train loss item: 0.10345759987831116
22
train loss item: 0.5211396813392639
23
train loss item: 0.4230937063694
24
train loss item: 0.3378773033618927
25
train loss item: 0.1290997564792633
26
train loss item: 0.11565177142620087
27
train loss item: 0.1252264529466629
28
train loss item: 0.05387009680271149
29
train loss item: 0.4007302522659302
30
train loss item: 1.5924996137619019
31
train loss item: 0.3164600133895874
32
train loss item: 0.07142838090658188
33
train loss item: 0.18813760578632355
34
train loss item: 0.09854032099246979
35
train loss item: 1.9448384046554565
36
train loss item: 0.3017862141132355
37
train loss item: 0.2968669831752777
38
train loss item: 0.2981404662132263
39
train loss item: 0.15197357535362244
40
train loss item: 0.12188394367694855
41
train loss item: 0.1389354169368744
42
train loss item: 0.20582525432109833
43
train loss item: 0.11753933876752853
44
train loss item: 0.41552746295928955
45
train loss item: 0.07789132744073868
46
train loss item: 0.08235028386116028
47
train loss item: 0.2087232768535614
48
train loss item: 0.12492449581623077
49
train loss item: 0.0939767137169838
50
train loss item: 0.16817158460617065
51
train loss item: 0.5337843894958496
52
train loss item: 0.0616970919072628
53
train loss item: 0.08753462880849838
54
train loss item: 1.8263746500015259
55
train loss item: 0.12240468710660934
56
train loss item: 0.14585590362548828
57
train loss item: 0.15262798964977264
58
train loss item: 0.11475013196468353
59
train loss item: 0.09374290704727173
60
train loss item: 0.4528612792491913
61
train loss item: 1.6502883434295654
62
train loss item: 0.11801781505346298
63
train loss item: 0.21868261694908142
64
train loss item: 0.10607785731554031
65
train loss item: 0.3008333146572113
66
train loss item: 0.2950987219810486
67
train loss item: 0.13006141781806946
68
train loss item: 0.1790880560874939
69
train loss item: 0.1988694816827774
70
train loss item: 0.14709514379501343
71
train loss item: 0.09417320042848587
72
train loss item: 0.10134275257587433
73
train loss item: 0.1829734593629837
74
train loss item: 0.06144070252776146
75
train loss item: 0.08582804352045059
76
train loss item: 0.4399423897266388
77
train loss item: 1.007361650466919
78
train loss item: 0.060345765203237534
79
train loss item: 0.16393239796161652
80
train loss item: 0.09531566500663757
81
train loss item: 0.12479128688573837
82
train loss item: 0.10680794715881348
83
train loss item: 0.3784119188785553
84
train loss item: 0.3005591928958893
85
train loss item: 0.2722865343093872
86
train loss item: 3.639523506164551
87
train loss item: 0.10211380571126938
88
train loss item: 0.24600762128829956
epoch train loss: 0.31598972315701207
testing phase
test loss item: 0.14060236513614655
test loss item: 0.1584155559539795
test loss item: 0.4680326581001282
test loss item: 0.17697028815746307
test loss item: 0.1871068775653839
test loss item: 0.09320331364870071
test loss item: 1.3051509857177734
test loss item: 0.3799154758453369
test loss item: 0.17060846090316772
test loss item: 0.2841341197490692
test loss item: 0.671786904335022
test loss item: 0.11926942318677902
test loss item: 0.1305253952741623
test loss item: 0.21486641466617584
test loss item: 0.13255561888217926
test loss item: 0.2684074640274048
test loss item: 0.1963847130537033
test loss item: 0.3375645577907562
test loss item: 0.47600510716438293
test loss item: 0.18163050711154938
test loss item: 0.5456305146217346
test loss item: 0.2848675847053528
test loss item: 0.2123284786939621
test loss item: 0.12543992698192596
test loss item: 0.15354080498218536
test loss item: 0.15281236171722412
test loss item: 0.22348661720752716
test loss item: 0.13034284114837646
test loss item: 0.23004679381847382
test loss item: 0.23821905255317688
test loss item: 0.6241896152496338
test loss item: 0.25767338275909424
test loss item: 0.10671696066856384
test loss item: 0.41786888241767883
test loss item: 0.3563745319843292
test loss item: 0.3161660134792328
test loss item: 0.580597996711731
test loss item: 1.1459461450576782
test loss item: 0.33335137367248535
test loss item: 0.1973400115966797
test loss item: 0.26529568433761597
test loss item: 0.12443295866250992
test loss item: 0.2479579597711563
test loss item: 0.15494757890701294
test loss item: 0.4097308814525604
test loss item: 0.3135621249675751
test loss item: 0.20076002180576324
test loss item: 0.17197178304195404
test loss item: 0.35915103554725647
test loss item: 0.5114005208015442
test loss item: 0.21619723737239838
test loss item: 0.10217217355966568
test loss item: 0.1737305372953415
test loss item: 0.12018785625696182
test loss item: 0.22394850850105286
test loss item: 0.6700187921524048
test loss item: 0.4048919975757599
test loss item: 0.18375004827976227
test loss item: 0.1715458333492279
test loss item: 0.14714659750461578
test loss item: 0.31686973571777344
test loss item: 0.2169930785894394
test loss item: 0.1453433632850647
test loss item: 0.17120003700256348
test loss item: 0.6851881742477417
test loss item: 0.24540172517299652
test loss item: 0.21661093831062317
test loss item: 0.18170125782489777
test loss item: 0.4333137571811676
test loss item: 0.31112366914749146
test loss item: 0.1768980622291565
test loss item: 0.7027962803840637
test loss item: 0.245611310005188
test loss item: 0.2838757634162903
test loss item: 0.11113862693309784
test loss item: 0.1047772690653801
test loss item: 0.13130931556224823
test loss item: 1.2187769412994385
test loss item: 0.3200484812259674
test loss item: 0.13224004209041595
test loss item: 0.07092583924531937
test loss item: 0.76092529296875
test loss item: 0.6475539207458496
test loss item: 0.8250473141670227
test loss item: 0.1581198275089264
test loss item: 0.1547321081161499
test loss item: 0.1946103423833847
test loss item: 0.2887575328350067
test loss item: 0.14631116390228271
Epoch [45/100], Training Loss: 0.3160, Testing Loss: 0.3090
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 46/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2722688615322113
1
train loss item: 0.6132110953330994
2
train loss item: 0.12749704718589783
3
train loss item: 0.24587103724479675
4
train loss item: 0.20456679165363312
5
train loss item: 0.16574671864509583
6
train loss item: 0.12857882678508759
7
train loss item: 0.4652647376060486
8
train loss item: 0.07697811722755432
9
train loss item: 0.13540887832641602
10
train loss item: 0.1691674292087555
11
train loss item: 0.17280541360378265
12
train loss item: 0.09527197480201721
13
train loss item: 0.28786700963974
14
train loss item: 0.1404518038034439
15
train loss item: 0.33810943365097046
16
train loss item: 0.05041208863258362
17
train loss item: 0.14766354858875275
18
train loss item: 0.17659762501716614
19
train loss item: 0.13123396039009094
20
train loss item: 0.11355821043252945
21
train loss item: 0.09072082489728928
22
train loss item: 0.45362037420272827
23
train loss item: 0.43369919061660767
24
train loss item: 0.29478567838668823
25
train loss item: 0.11519522964954376
26
train loss item: 0.10710396617650986
27
train loss item: 0.1263185441493988
28
train loss item: 0.04932013899087906
29
train loss item: 0.3697023391723633
30
train loss item: 1.588441252708435
31
train loss item: 0.29966166615486145
32
train loss item: 0.077633336186409
33
train loss item: 0.21267879009246826
34
train loss item: 0.09350398182868958
35
train loss item: 1.935070276260376
36
train loss item: 0.2936999499797821
37
train loss item: 0.30260318517684937
38
train loss item: 0.268761545419693
39
train loss item: 0.13209939002990723
40
train loss item: 0.10164681077003479
41
train loss item: 0.1395217776298523
42
train loss item: 0.20100609958171844
43
train loss item: 0.1036718487739563
44
train loss item: 0.42590203881263733
45
train loss item: 0.08635302633047104
46
train loss item: 0.07846972346305847
47
train loss item: 0.1941814124584198
48
train loss item: 0.12059250473976135
49
train loss item: 0.09461827576160431
50
train loss item: 0.1453617811203003
51
train loss item: 0.5247414708137512
52
train loss item: 0.053628385066986084
53
train loss item: 0.09457956999540329
54
train loss item: 1.818589687347412
55
train loss item: 0.11881637573242188
56
train loss item: 0.1360638290643692
57
train loss item: 0.14394091069698334
58
train loss item: 0.09478134661912918
59
train loss item: 0.09502925723791122
60
train loss item: 0.43353453278541565
61
train loss item: 1.6575841903686523
62
train loss item: 0.11473861336708069
63
train loss item: 0.20719073712825775
64
train loss item: 0.10136374086141586
65
train loss item: 0.2950185537338257
66
train loss item: 0.24604684114456177
67
train loss item: 0.11928129196166992
68
train loss item: 0.14923061430454254
69
train loss item: 0.17930814623832703
70
train loss item: 0.1481611281633377
71
train loss item: 0.0821036547422409
72
train loss item: 0.0958985984325409
73
train loss item: 0.1656702607870102
74
train loss item: 0.06254405528306961
75
train loss item: 0.08295904844999313
76
train loss item: 0.4365626871585846
77
train loss item: 0.9877220988273621
78
train loss item: 0.04849084094166756
79
train loss item: 0.1616484373807907
80
train loss item: 0.07966458797454834
81
train loss item: 0.1142844557762146
82
train loss item: 0.11670158058404922
83
train loss item: 0.3652111887931824
84
train loss item: 0.2981816530227661
85
train loss item: 0.2571479082107544
86
train loss item: 3.628528118133545
87
train loss item: 0.10739822685718536
88
train loss item: 0.21015197038650513
epoch train loss: 0.3059210580135329
testing phase
test loss item: 0.14210771024227142
test loss item: 0.0773978903889656
test loss item: 0.48474618792533875
test loss item: 0.1795106828212738
test loss item: 0.18826377391815186
test loss item: 0.08889257162809372
test loss item: 1.367919921875
test loss item: 0.4212305247783661
test loss item: 0.17536887526512146
test loss item: 0.28954434394836426
test loss item: 0.6992212533950806
test loss item: 0.11893629282712936
test loss item: 0.13562531769275665
test loss item: 0.2253851741552353
test loss item: 0.12998314201831818
test loss item: 0.0594516396522522
test loss item: 0.21206064522266388
test loss item: 0.34098106622695923
test loss item: 0.49358227849006653
test loss item: 0.19820266962051392
test loss item: 0.5472999215126038
test loss item: 0.3043692111968994
test loss item: 0.21917134523391724
test loss item: 0.1310739815235138
test loss item: 0.1557786911725998
test loss item: 0.15818604826927185
test loss item: 0.23121081292629242
test loss item: 0.13088621199131012
test loss item: 0.23441295325756073
test loss item: 0.2457893192768097
test loss item: 0.6564440131187439
test loss item: 0.05474405735731125
test loss item: 0.11021162569522858
test loss item: 0.42464083433151245
test loss item: 0.3280390202999115
test loss item: 0.31881675124168396
test loss item: 0.6031691431999207
test loss item: 1.1975151300430298
test loss item: 0.33954039216041565
test loss item: 0.2041936218738556
test loss item: 0.2317497730255127
test loss item: 0.12932682037353516
test loss item: 0.24839332699775696
test loss item: 0.16506452858448029
test loss item: 0.41036900877952576
test loss item: 0.28812193870544434
test loss item: 0.20404571294784546
test loss item: 0.18290044367313385
test loss item: 0.37304580211639404
test loss item: 0.5358483791351318
test loss item: 0.21353909373283386
test loss item: 0.10624948889017105
test loss item: 0.17917929589748383
test loss item: 0.1258946806192398
test loss item: 0.2248774617910385
test loss item: 0.6927233338356018
test loss item: 0.42336827516555786
test loss item: 0.18532812595367432
test loss item: 0.17747090756893158
test loss item: 0.14314261078834534
test loss item: 0.31668564677238464
test loss item: 0.19064584374427795
test loss item: 0.1570233702659607
test loss item: 0.1730099320411682
test loss item: 0.715385913848877
test loss item: 0.2477995902299881
test loss item: 0.236299529671669
test loss item: 0.18736107647418976
test loss item: 0.41462016105651855
test loss item: 0.3211926519870758
test loss item: 0.05443470552563667
test loss item: 0.7499544024467468
test loss item: 0.2552223801612854
test loss item: 0.30535078048706055
test loss item: 0.12035250663757324
test loss item: 0.11062344163656235
test loss item: 0.13392318785190582
test loss item: 1.278544306755066
test loss item: 0.3353938162326813
test loss item: 0.13447150588035583
test loss item: 0.0627216249704361
test loss item: 0.8040801882743835
test loss item: 0.6745215654373169
test loss item: 0.8676618933677673
test loss item: 0.16694797575473785
test loss item: 0.16294027864933014
test loss item: 0.05712461471557617
test loss item: 0.05045156925916672
test loss item: 0.1426858752965927
Epoch [46/100], Training Loss: 0.3059, Testing Loss: 0.3067
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 47/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2635231018066406
1
train loss item: 0.6017780303955078
2
train loss item: 0.12381144613027573
3
train loss item: 0.2409008890390396
4
train loss item: 0.19697460532188416
5
train loss item: 0.16051864624023438
6
train loss item: 0.12721283733844757
7
train loss item: 0.45881420373916626
8
train loss item: 0.07372862100601196
9
train loss item: 0.13053520023822784
10
train loss item: 0.16142870485782623
11
train loss item: 0.1626463383436203
12
train loss item: 0.09534362703561783
13
train loss item: 0.27316024899482727
14
train loss item: 0.13720671832561493
15
train loss item: 0.34016451239585876
16
train loss item: 0.04824500158429146
17
train loss item: 0.13758805394172668
18
train loss item: 0.16838586330413818
19
train loss item: 0.1336280107498169
20
train loss item: 0.11387334018945694
21
train loss item: 0.08551009744405746
22
train loss item: 0.4497048556804657
23
train loss item: 0.41848844289779663
24
train loss item: 0.29229193925857544
25
train loss item: 0.1115775927901268
26
train loss item: 0.10246101021766663
27
train loss item: 0.12268849462270737
28
train loss item: 0.04722261056303978
29
train loss item: 0.3707925081253052
30
train loss item: 1.5712882280349731
31
train loss item: 0.28241634368896484
32
train loss item: 0.07437504827976227
33
train loss item: 0.20264190435409546
34
train loss item: 0.08996599912643433
35
train loss item: 1.9229164123535156
36
train loss item: 0.2764153480529785
37
train loss item: 0.2858258783817291
38
train loss item: 0.2350454181432724
39
train loss item: 0.13250742852687836
40
train loss item: 0.10130517929792404
41
train loss item: 0.13628597557544708
42
train loss item: 0.19897250831127167
43
train loss item: 0.1007649227976799
44
train loss item: 0.4207130968570709
45
train loss item: 0.08262114226818085
46
train loss item: 0.07354938238859177
47
train loss item: 0.19353774189949036
48
train loss item: 0.11862599849700928
49
train loss item: 0.09068611264228821
50
train loss item: 0.14819534122943878
51
train loss item: 0.5194830894470215
52
train loss item: 0.05243522301316261
53
train loss item: 0.09088640660047531
54
train loss item: 1.8064826726913452
55
train loss item: 0.11781495064496994
56
train loss item: 0.13046160340309143
57
train loss item: 0.14447008073329926
58
train loss item: 0.09466554969549179
59
train loss item: 0.09264466166496277
60
train loss item: 0.4300161600112915
61
train loss item: 1.6419949531555176
62
train loss item: 0.11179377883672714
63
train loss item: 0.20262078940868378
64
train loss item: 0.09786379337310791
65
train loss item: 0.27051231265068054
66
train loss item: 0.22973354160785675
67
train loss item: 0.11643800139427185
68
train loss item: 0.1516415923833847
69
train loss item: 0.1691957712173462
70
train loss item: 0.1398322731256485
71
train loss item: 0.08218193054199219
72
train loss item: 0.09376460313796997
73
train loss item: 0.16348424553871155
74
train loss item: 0.06226186454296112
75
train loss item: 0.07984350621700287
76
train loss item: 0.42461690306663513
77
train loss item: 0.9780316948890686
78
train loss item: 0.04881153255701065
79
train loss item: 0.15410980582237244
80
train loss item: 0.07706116884946823
81
train loss item: 0.11380942910909653
82
train loss item: 0.10993804782629013
83
train loss item: 0.36056163907051086
84
train loss item: 0.2735936939716339
85
train loss item: 0.2565290331840515
86
train loss item: 3.60850191116333
87
train loss item: 0.10334929078817368
88
train loss item: 0.19780287146568298
epoch train loss: 0.29986630719196933
testing phase
test loss item: 0.13761118054389954
test loss item: 0.0767645314335823
test loss item: 0.4281314015388489
test loss item: 0.17576929926872253
test loss item: 0.1780674159526825
test loss item: 0.09087008982896805
test loss item: 1.3777695894241333
test loss item: 0.4611016511917114
test loss item: 0.15811076760292053
test loss item: 0.2653726637363434
test loss item: 0.6307455897331238
test loss item: 0.11626037955284119
test loss item: 0.1447216123342514
test loss item: 0.22848351299762726
test loss item: 0.12062130123376846
test loss item: 0.059634018689394
test loss item: 0.2190985530614853
test loss item: 0.3025658428668976
test loss item: 0.5078169703483582
test loss item: 0.21419785916805267
test loss item: 0.4779876172542572
test loss item: 0.3137461245059967
test loss item: 0.20590829849243164
test loss item: 0.13345971703529358
test loss item: 0.14667756855487823
test loss item: 0.16209401190280914
test loss item: 0.2268969863653183
test loss item: 0.12992335855960846
test loss item: 0.22394594550132751
test loss item: 0.23968155682086945
test loss item: 0.6159660220146179
test loss item: 0.052957020699977875
test loss item: 0.11101782321929932
test loss item: 0.38101422786712646
test loss item: 0.28780364990234375
test loss item: 0.30244627594947815
test loss item: 0.6106442213058472
test loss item: 1.0616415739059448
test loss item: 0.3051539659500122
test loss item: 0.20536267757415771
test loss item: 0.23199345171451569
test loss item: 0.12322781980037689
test loss item: 0.21738702058792114
test loss item: 0.16334816813468933
test loss item: 0.3589875102043152
test loss item: 0.3092068135738373
test loss item: 0.19204917550086975
test loss item: 0.20406414568424225
test loss item: 0.34535250067710876
test loss item: 0.49997928738594055
test loss item: 0.18433372676372528
test loss item: 0.12091369181871414
test loss item: 0.17117825150489807
test loss item: 0.11823276430368423
test loss item: 0.19994255900382996
test loss item: 0.6062906384468079
test loss item: 0.41933926939964294
test loss item: 0.1701737493276596
test loss item: 0.17795495688915253
test loss item: 0.13460789620876312
test loss item: 0.27732735872268677
test loss item: 0.21074259281158447
test loss item: 0.16145436465740204
test loss item: 0.17423543334007263
test loss item: 0.6595802903175354
test loss item: 0.24148866534233093
test loss item: 0.24788732826709747
test loss item: 0.18852046132087708
test loss item: 0.38010188937187195
test loss item: 0.3228049576282501
test loss item: 0.05579368770122528
test loss item: 0.7809218168258667
test loss item: 0.24480047821998596
test loss item: 0.31072479486465454
test loss item: 0.12400200217962265
test loss item: 0.10971540957689285
test loss item: 0.13623546063899994
test loss item: 1.1391606330871582
test loss item: 0.32090646028518677
test loss item: 0.133332297205925
test loss item: 0.059551507234573364
test loss item: 0.7653457522392273
test loss item: 0.6593672633171082
test loss item: 0.7724378108978271
test loss item: 0.16895486414432526
test loss item: 0.1637003868818283
test loss item: 0.05352950841188431
test loss item: 0.04829822853207588
test loss item: 0.12305106967687607
Epoch [47/100], Training Loss: 0.2999, Testing Loss: 0.2929
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 48/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2643705904483795
1
train loss item: 0.5813817977905273
2
train loss item: 0.11601348221302032
3
train loss item: 0.23780015110969543
4
train loss item: 0.20500199496746063
5
train loss item: 0.16357971727848053
6
train loss item: 0.1375424861907959
7
train loss item: 0.43617475032806396
8
train loss item: 0.0691886618733406
9
train loss item: 0.13628189265727997
10
train loss item: 0.17213623225688934
11
train loss item: 0.16184315085411072
12
train loss item: 0.10235141962766647
13
train loss item: 0.2644193172454834
14
train loss item: 0.12860499322414398
15
train loss item: 0.3459022045135498
16
train loss item: 0.0498020201921463
17
train loss item: 0.14037936925888062
18
train loss item: 0.1769045889377594
19
train loss item: 0.14587169885635376
20
train loss item: 0.13304167985916138
21
train loss item: 0.09314243495464325
22
train loss item: 0.4522686004638672
23
train loss item: 0.3867381513118744
24
train loss item: 0.30907729268074036
25
train loss item: 0.12246639281511307
26
train loss item: 0.10570758581161499
27
train loss item: 0.1152888610959053
28
train loss item: 0.047192707657814026
29
train loss item: 0.3567081689834595
30
train loss item: 1.5334973335266113
31
train loss item: 0.28947362303733826
32
train loss item: 0.07122129946947098
33
train loss item: 0.17786167562007904
34
train loss item: 0.09506046772003174
35
train loss item: 1.9043045043945312
36
train loss item: 0.2758280634880066
37
train loss item: 0.2795505225658417
38
train loss item: 0.2454531341791153
39
train loss item: 0.14758971333503723
40
train loss item: 0.11039964854717255
41
train loss item: 0.12770302593708038
42
train loss item: 0.19920511543750763
43
train loss item: 0.1054188683629036
44
train loss item: 0.4016322195529938
45
train loss item: 0.07550094276666641
46
train loss item: 0.07485715299844742
47
train loss item: 0.19378869235515594
48
train loss item: 0.1170620322227478
49
train loss item: 0.08832915127277374
50
train loss item: 0.15712597966194153
51
train loss item: 0.4991189241409302
52
train loss item: 0.05620504915714264
53
train loss item: 0.0824318677186966
54
train loss item: 1.7854118347167969
55
train loss item: 0.11828292906284332
56
train loss item: 0.13164131343364716
57
train loss item: 0.14880706369876862
58
train loss item: 0.10535810142755508
59
train loss item: 0.08910513669252396
60
train loss item: 0.4086029529571533
61
train loss item: 1.6048117876052856
62
train loss item: 0.112505242228508
63
train loss item: 0.20395112037658691
64
train loss item: 0.09487727284431458
65
train loss item: 0.2665490508079529
66
train loss item: 0.2504511773586273
67
train loss item: 0.12422826141119003
68
train loss item: 0.16420750319957733
69
train loss item: 0.1796501725912094
70
train loss item: 0.13923676311969757
71
train loss item: 0.09149803966283798
72
train loss item: 0.09229335933923721
73
train loss item: 0.16909874975681305
74
train loss item: 0.061888083815574646
75
train loss item: 0.0805041715502739
76
train loss item: 0.40237393975257874
77
train loss item: 0.955787718296051
78
train loss item: 0.0579838901758194
79
train loss item: 0.15495987236499786
80
train loss item: 0.08815257251262665
81
train loss item: 0.12079140543937683
82
train loss item: 0.09798731654882431
83
train loss item: 0.35441258549690247
84
train loss item: 0.2618134319782257
85
train loss item: 0.2489439994096756
86
train loss item: 3.5783982276916504
87
train loss item: 0.09393726289272308
88
train loss item: 0.21993818879127502
epoch train loss: 0.29802518990937243
testing phase
test loss item: 0.13410361111164093
test loss item: 0.07399141788482666
test loss item: 0.46220263838768005
test loss item: 0.16867290437221527
test loss item: 0.18225008249282837
test loss item: 0.08692743629217148
test loss item: 1.202042579650879
test loss item: 0.36941248178482056
test loss item: 0.16842007637023926
test loss item: 0.2793913781642914
test loss item: 0.6568660736083984
test loss item: 0.1092393770813942
test loss item: 0.1281753033399582
test loss item: 0.20359311997890472
test loss item: 0.12514235079288483
test loss item: 0.056959591805934906
test loss item: 0.1925971508026123
test loss item: 0.33155637979507446
test loss item: 0.44722044467926025
test loss item: 0.17650552093982697
test loss item: 0.5306732654571533
test loss item: 0.27565276622772217
test loss item: 0.20686832070350647
test loss item: 0.11764063686132431
test loss item: 0.14674176275730133
test loss item: 0.1452249139547348
test loss item: 0.2148807942867279
test loss item: 0.1255297064781189
test loss item: 0.21949885785579681
test loss item: 0.23558205366134644
test loss item: 0.5939240455627441
test loss item: 0.051979295909404755
test loss item: 0.10073935985565186
test loss item: 0.4069022536277771
test loss item: 0.3164840042591095
test loss item: 0.30092987418174744
test loss item: 0.5492954254150391
test loss item: 1.126304268836975
test loss item: 0.3208398222923279
test loss item: 0.18197348713874817
test loss item: 0.21078936755657196
test loss item: 0.11260761320590973
test loss item: 0.24411961436271667
test loss item: 0.14886979758739471
test loss item: 0.3982129395008087
test loss item: 0.2599784731864929
test loss item: 0.1959439218044281
test loss item: 0.1631810963153839
test loss item: 0.35525232553482056
test loss item: 0.4958314001560211
test loss item: 0.21261698007583618
test loss item: 0.10017526149749756
test loss item: 0.1696649193763733
test loss item: 0.1155143529176712
test loss item: 0.21934469044208527
test loss item: 0.654370903968811
test loss item: 0.39124318957328796
test loss item: 0.18819156289100647
test loss item: 0.16826887428760529
test loss item: 0.14055103063583374
test loss item: 0.3112748861312866
test loss item: 0.17248989641666412
test loss item: 0.1394960731267929
test loss item: 0.1602894365787506
test loss item: 0.6646673679351807
test loss item: 0.23534055054187775
test loss item: 0.214419424533844
test loss item: 0.1707291156053543
test loss item: 0.39678481221199036
test loss item: 0.28121432662010193
test loss item: 0.050095681101083755
test loss item: 0.654010534286499
test loss item: 0.23907458782196045
test loss item: 0.26383325457572937
test loss item: 0.1104704812169075
test loss item: 0.10159286856651306
test loss item: 0.11934500932693481
test loss item: 1.2024409770965576
test loss item: 0.30429601669311523
test loss item: 0.12573325634002686
test loss item: 0.05940144136548042
test loss item: 0.731635570526123
test loss item: 0.6149546504020691
test loss item: 0.8111844658851624
test loss item: 0.149202361702919
test loss item: 0.15264064073562622
test loss item: 0.05562051013112068
test loss item: 0.049445509910583496
test loss item: 0.11874735355377197
Epoch [48/100], Training Loss: 0.2980, Testing Loss: 0.2846
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 49/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2589779794216156
1
train loss item: 0.5597927570343018
2
train loss item: 0.12002462148666382
3
train loss item: 0.22112689912319183
4
train loss item: 0.19634613394737244
5
train loss item: 0.15953703224658966
6
train loss item: 0.119439035654068
7
train loss item: 0.4308137893676758
8
train loss item: 0.07315809279680252
9
train loss item: 0.12828561663627625
10
train loss item: 0.1616942435503006
11
train loss item: 0.16185887157917023
12
train loss item: 0.09761666506528854
13
train loss item: 0.26947250962257385
14
train loss item: 0.1338849663734436
15
train loss item: 0.31007590889930725
16
train loss item: 0.04906375706195831
17
train loss item: 0.13870476186275482
18
train loss item: 0.16138410568237305
19
train loss item: 0.12213139981031418
20
train loss item: 0.11333594471216202
21
train loss item: 0.08733081817626953
22
train loss item: 0.4029127359390259
23
train loss item: 0.39285609126091003
24
train loss item: 0.2791655659675598
25
train loss item: 0.11401643604040146
26
train loss item: 0.10270906984806061
27
train loss item: 0.11836971342563629
28
train loss item: 0.04766367748379707
29
train loss item: 0.32224181294441223
30
train loss item: 1.51608407497406
31
train loss item: 0.2732846140861511
32
train loss item: 0.07320282608270645
33
train loss item: 0.1907016783952713
34
train loss item: 0.0943150520324707
35
train loss item: 1.8893862962722778
36
train loss item: 0.2859835922718048
37
train loss item: 0.29783564805984497
38
train loss item: 0.2523661255836487
39
train loss item: 0.1285403072834015
40
train loss item: 0.10184524953365326
41
train loss item: 0.13390454649925232
42
train loss item: 0.18790389597415924
43
train loss item: 0.09667221456766129
44
train loss item: 0.406055212020874
45
train loss item: 0.08247751742601395
46
train loss item: 0.07565861195325851
47
train loss item: 0.1785746067762375
48
train loss item: 0.11049048602581024
49
train loss item: 0.08981714397668839
50
train loss item: 0.13257552683353424
51
train loss item: 0.48910513520240784
52
train loss item: 0.05257585272192955
53
train loss item: 0.08720733225345612
54
train loss item: 1.7698912620544434
55
train loss item: 0.11038941890001297
56
train loss item: 0.12982413172721863
57
train loss item: 0.13394291698932648
58
train loss item: 0.09150682389736176
59
train loss item: 0.088524729013443
60
train loss item: 0.3902759552001953
61
train loss item: 1.6003559827804565
62
train loss item: 0.11124860495328903
63
train loss item: 0.19712433218955994
64
train loss item: 0.09375078231096268
65
train loss item: 0.2958027422428131
66
train loss item: 0.23037801682949066
67
train loss item: 0.1147226095199585
68
train loss item: 0.1450369656085968
69
train loss item: 0.17289935052394867
70
train loss item: 0.14230141043663025
71
train loss item: 0.07879491150379181
72
train loss item: 0.08976081758737564
73
train loss item: 0.15217572450637817
74
train loss item: 0.06058085709810257
75
train loss item: 0.08008599281311035
76
train loss item: 0.3951215445995331
77
train loss item: 0.9250423312187195
78
train loss item: 0.05220172181725502
79
train loss item: 0.15578190982341766
80
train loss item: 0.0772070586681366
81
train loss item: 0.11261026561260223
82
train loss item: 0.10685856640338898
83
train loss item: 0.34766462445259094
84
train loss item: 0.29009270668029785
85
train loss item: 0.22679220139980316
86
train loss item: 3.5598642826080322
87
train loss item: 0.09931134432554245
88
train loss item: 0.20330533385276794
epoch train loss: 0.29114362685365625
testing phase
test loss item: 0.14025895297527313
test loss item: 0.07394692301750183
test loss item: 0.4644780457019806
test loss item: 0.1762455850839615
test loss item: 0.1821426898241043
test loss item: 0.08867929130792618
test loss item: 1.4183310270309448
test loss item: 0.46253108978271484
test loss item: 0.16774091124534607
test loss item: 0.2798641324043274
test loss item: 0.6547395586967468
test loss item: 0.11677747219800949
test loss item: 0.1364341527223587
test loss item: 0.22183440625667572
test loss item: 0.12560760974884033
test loss item: 0.056456826627254486
test loss item: 0.21578752994537354
test loss item: 0.32964733242988586
test loss item: 0.49739474058151245
test loss item: 0.20578192174434662
test loss item: 0.5289731621742249
test loss item: 0.31396111845970154
test loss item: 0.2241407334804535
test loss item: 0.13345971703529358
test loss item: 0.14939287304878235
test loss item: 0.15780267119407654
test loss item: 0.226261168718338
test loss item: 0.1260911077260971
test loss item: 0.22977742552757263
test loss item: 0.23955711722373962
test loss item: 0.6460816264152527
test loss item: 0.05179525166749954
test loss item: 0.11103116720914841
test loss item: 0.4088687002658844
test loss item: 0.31451958417892456
test loss item: 0.30969199538230896
test loss item: 0.610819399356842
test loss item: 1.1185173988342285
test loss item: 0.327552855014801
test loss item: 0.20828430354595184
test loss item: 0.23249243199825287
test loss item: 0.12781120836734772
test loss item: 0.24044594168663025
test loss item: 0.16630776226520538
test loss item: 0.3955601453781128
test loss item: 0.29995232820510864
test loss item: 0.20638588070869446
test loss item: 0.18498337268829346
test loss item: 0.36694449186325073
test loss item: 0.5143745541572571
test loss item: 0.2079651802778244
test loss item: 0.10635398328304291
test loss item: 0.17574483156204224
test loss item: 0.1197294220328331
test loss item: 0.2162688672542572
test loss item: 0.6484984159469604
test loss item: 0.4202788472175598
test loss item: 0.19147229194641113
test loss item: 0.18034644424915314
test loss item: 0.13868992030620575
test loss item: 0.3063306212425232
test loss item: 0.20610807836055756
test loss item: 0.1626572459936142
test loss item: 0.16990207135677338
test loss item: 0.691939651966095
test loss item: 0.24127551913261414
test loss item: 0.24016156792640686
test loss item: 0.18530809879302979
test loss item: 0.3986642360687256
test loss item: 0.31617939472198486
test loss item: 0.04947374761104584
test loss item: 0.7909688353538513
test loss item: 0.257829874753952
test loss item: 0.3180476129055023
test loss item: 0.1183227002620697
test loss item: 0.11441318690776825
test loss item: 0.13436992466449738
test loss item: 1.2056008577346802
test loss item: 0.32442784309387207
test loss item: 0.13333874940872192
test loss item: 0.06145733594894409
test loss item: 0.7899267673492432
test loss item: 0.6748484373092651
test loss item: 0.8167106509208679
test loss item: 0.16801710426807404
test loss item: 0.161887526512146
test loss item: 0.056325387209653854
test loss item: 0.04937700182199478
test loss item: 0.12872374057769775
Epoch [49/100], Training Loss: 0.2911, Testing Loss: 0.3018
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 50/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.25509074330329895
1
train loss item: 0.5497947931289673
2
train loss item: 0.11859447509050369
3
train loss item: 0.21548153460025787
4
train loss item: 0.17933322489261627
5
train loss item: 0.1535261869430542
6
train loss item: 0.1167699471116066
7
train loss item: 0.4195615351200104
8
train loss item: 0.06753592193126678
9
train loss item: 0.12162649631500244
10
train loss item: 0.1541822999715805
11
train loss item: 0.15165318548679352
12
train loss item: 0.09262187778949738
13
train loss item: 0.26042747497558594
14
train loss item: 0.13106845319271088
15
train loss item: 0.3186790347099304
16
train loss item: 0.04886708781123161
17
train loss item: 0.12945911288261414
18
train loss item: 0.16126631200313568
19
train loss item: 0.1282186210155487
20
train loss item: 0.11462631076574326
21
train loss item: 0.08315841853618622
22
train loss item: 0.4068281352519989
23
train loss item: 0.3740187883377075
24
train loss item: 0.2657287120819092
25
train loss item: 0.10724541544914246
26
train loss item: 0.09918330609798431
27
train loss item: 0.11706411838531494
28
train loss item: 0.04769425839185715
29
train loss item: 0.3378004729747772
30
train loss item: 1.4999806880950928
31
train loss item: 0.2619248330593109
32
train loss item: 0.06822418421506882
33
train loss item: 0.18546928465366364
34
train loss item: 0.09014514833688736
35
train loss item: 1.876121997833252
36
train loss item: 0.24984827637672424
37
train loss item: 0.2640615403652191
38
train loss item: 0.20873931050300598
39
train loss item: 0.12661266326904297
40
train loss item: 0.09727589786052704
41
train loss item: 0.13165368139743805
42
train loss item: 0.1916748285293579
43
train loss item: 0.09590433537960052
44
train loss item: 0.39782068133354187
45
train loss item: 0.08162848651409149
46
train loss item: 0.07031160593032837
47
train loss item: 0.18656621873378754
48
train loss item: 0.1110033243894577
49
train loss item: 0.08741281181573868
50
train loss item: 0.14342285692691803
51
train loss item: 0.49283838272094727
52
train loss item: 0.05436735972762108
53
train loss item: 0.08728847652673721
54
train loss item: 1.7552835941314697
55
train loss item: 0.11227061599493027
56
train loss item: 0.1295294165611267
57
train loss item: 0.13807253539562225
58
train loss item: 0.09022006392478943
59
train loss item: 0.09017724543809891
60
train loss item: 0.40125802159309387
61
train loss item: 1.5791171789169312
62
train loss item: 0.1086881160736084
63
train loss item: 0.19105911254882812
64
train loss item: 0.09241856634616852
65
train loss item: 0.2387418895959854
66
train loss item: 0.21073774993419647
67
train loss item: 0.11364129185676575
68
train loss item: 0.15258082747459412
69
train loss item: 0.15700304508209229
70
train loss item: 0.1296100914478302
71
train loss item: 0.07767457515001297
72
train loss item: 0.0868377685546875
73
train loss item: 0.15267272293567657
74
train loss item: 0.06021806597709656
75
train loss item: 0.07849089801311493
76
train loss item: 0.3789374828338623
77
train loss item: 0.9328526854515076
78
train loss item: 0.049361452460289
79
train loss item: 0.14478935301303864
80
train loss item: 0.07703305035829544
81
train loss item: 0.11010865122079849
82
train loss item: 0.1034088060259819
83
train loss item: 0.34675514698028564
84
train loss item: 0.23201800882816315
85
train loss item: 0.23187926411628723
86
train loss item: 3.537924289703369
87
train loss item: 0.10010076314210892
88
train loss item: 0.18264585733413696
epoch train loss: 0.28496091385905664
testing phase
test loss item: 0.1336524933576584
test loss item: 0.07417997717857361
test loss item: 0.4220253825187683
test loss item: 0.16811707615852356
test loss item: 0.174449160695076
test loss item: 0.08591549098491669
test loss item: 1.3371573686599731
test loss item: 0.3975319266319275
test loss item: 0.1527324765920639
test loss item: 0.25504687428474426
test loss item: 0.6044148802757263
test loss item: 0.11200997233390808
test loss item: 0.13064438104629517
test loss item: 0.21619731187820435
test loss item: 0.11847378313541412
test loss item: 0.05768447369337082
test loss item: 0.1986546516418457
test loss item: 0.30017781257629395
test loss item: 0.45317402482032776
test loss item: 0.1915612518787384
test loss item: 0.4769885540008545
test loss item: 0.29025208950042725
test loss item: 0.2083912193775177
test loss item: 0.12583309412002563
test loss item: 0.13793015480041504
test loss item: 0.15081408619880676
test loss item: 0.2093888521194458
test loss item: 0.12417279928922653
test loss item: 0.2185927927494049
test loss item: 0.22165243327617645
test loss item: 0.5959373712539673
test loss item: 0.051291294395923615
test loss item: 0.10357247292995453
test loss item: 0.37699994444847107
test loss item: 0.28547200560569763
test loss item: 0.28140386939048767
test loss item: 0.5613752603530884
test loss item: 1.0259993076324463
test loss item: 0.2999812662601471
test loss item: 0.19582056999206543
test loss item: 0.22070220112800598
test loss item: 0.1194942444562912
test loss item: 0.21796241402626038
test loss item: 0.1541629284620285
test loss item: 0.3558605909347534
test loss item: 0.27454298734664917
test loss item: 0.19246533513069153
test loss item: 0.17676515877246857
test loss item: 0.3317584991455078
test loss item: 0.4671518802642822
test loss item: 0.18724367022514343
test loss item: 0.10316286981105804
test loss item: 0.1665051132440567
test loss item: 0.10996495187282562
test loss item: 0.20120297372341156
test loss item: 0.5918090343475342
test loss item: 0.38226521015167236
test loss item: 0.17162668704986572
test loss item: 0.16554901003837585
test loss item: 0.13621149957180023
test loss item: 0.2785598635673523
test loss item: 0.18240045011043549
test loss item: 0.15051287412643433
test loss item: 0.1631678342819214
test loss item: 0.6301547884941101
test loss item: 0.23220546543598175
test loss item: 0.2211591750383377
test loss item: 0.17805325984954834
test loss item: 0.37549132108688354
test loss item: 0.27583953738212585
test loss item: 0.05347574129700661
test loss item: 0.7285168170928955
test loss item: 0.24254199862480164
test loss item: 0.29282650351524353
test loss item: 0.11029297858476639
test loss item: 0.10877063870429993
test loss item: 0.12830635905265808
test loss item: 1.1108261346817017
test loss item: 0.30631211400032043
test loss item: 0.1284705400466919
test loss item: 0.057812005281448364
test loss item: 0.7238088250160217
test loss item: 0.6182176470756531
test loss item: 0.7456198334693909
test loss item: 0.16122405230998993
test loss item: 0.15228886902332306
test loss item: 0.05211561173200607
test loss item: 0.047204237431287766
test loss item: 0.1125587448477745
Epoch [50/100], Training Loss: 0.2850, Testing Loss: 0.2789
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 51/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.25653111934661865
1
train loss item: 0.5095511674880981
2
train loss item: 0.10830250382423401
3
train loss item: 0.21395118534564972
4
train loss item: 0.18993191421031952
5
train loss item: 0.15617600083351135
6
train loss item: 0.1204376146197319
7
train loss item: 0.39757242798805237
8
train loss item: 0.06461489200592041
9
train loss item: 0.12305991351604462
10
train loss item: 0.17261506617069244
11
train loss item: 0.15394334495067596
12
train loss item: 0.09536793828010559
13
train loss item: 0.26445427536964417
14
train loss item: 0.1235923022031784
15
train loss item: 0.29862385988235474
16
train loss item: 0.04800977185368538
17
train loss item: 0.12879367172718048
18
train loss item: 0.16208049654960632
19
train loss item: 0.12469159811735153
20
train loss item: 0.11305762827396393
21
train loss item: 0.08521926403045654
22
train loss item: 0.3677528202533722
23
train loss item: 0.35297447443008423
24
train loss item: 0.2693330645561218
25
train loss item: 0.11390786617994308
26
train loss item: 0.09957753121852875
27
train loss item: 0.10751485824584961
28
train loss item: 0.04620371013879776
29
train loss item: 0.29780513048171997
30
train loss item: 1.466845989227295
31
train loss item: 0.2831188440322876
32
train loss item: 0.06712997704744339
33
train loss item: 0.17716260254383087
34
train loss item: 0.0921354740858078
35
train loss item: 1.8610248565673828
36
train loss item: 0.2633951008319855
37
train loss item: 0.26649293303489685
38
train loss item: 0.24924029409885406
39
train loss item: 0.1390584409236908
40
train loss item: 0.10052312910556793
41
train loss item: 0.12004618346691132
42
train loss item: 0.18942765891551971
43
train loss item: 0.09693609923124313
44
train loss item: 0.38421186804771423
45
train loss item: 0.0747140496969223
46
train loss item: 0.07196158915758133
47
train loss item: 0.1776522696018219
48
train loss item: 0.1072167158126831
49
train loss item: 0.08579966425895691
50
train loss item: 0.13393141329288483
51
train loss item: 0.46201956272125244
52
train loss item: 0.05361684411764145
53
train loss item: 0.07867484539747238
54
train loss item: 1.738089680671692
55
train loss item: 0.10762094706296921
56
train loss item: 0.1298142522573471
57
train loss item: 0.13907355070114136
58
train loss item: 0.0938357561826706
59
train loss item: 0.08975166082382202
60
train loss item: 0.35318639874458313
61
train loss item: 1.5475850105285645
62
train loss item: 0.10689684003591537
63
train loss item: 0.18652227520942688
64
train loss item: 0.09007782489061356
65
train loss item: 0.25255316495895386
66
train loss item: 0.23198625445365906
67
train loss item: 0.11516929417848587
68
train loss item: 0.14015816152095795
69
train loss item: 0.16975177824497223
70
train loss item: 0.13031210005283356
71
train loss item: 0.07950954884290695
72
train loss item: 0.08768613636493683
73
train loss item: 0.14848896861076355
74
train loss item: 0.05954072251915932
75
train loss item: 0.07791204005479813
76
train loss item: 0.3610093891620636
77
train loss item: 0.9014225602149963
78
train loss item: 0.052862998098134995
79
train loss item: 0.14521941542625427
80
train loss item: 0.08065871149301529
81
train loss item: 0.11189881712198257
82
train loss item: 0.09176765382289886
83
train loss item: 0.3307904601097107
84
train loss item: 0.24655210971832275
85
train loss item: 0.22671474516391754
86
train loss item: 3.515022039413452
87
train loss item: 0.09037904441356659
88
train loss item: 0.1958257257938385
epoch train loss: 0.28082730173227494
testing phase
test loss item: 0.13346974551677704
test loss item: 0.072146475315094
test loss item: 0.47755277156829834
test loss item: 0.1664944291114807
test loss item: 0.18388667702674866
test loss item: 0.08293938636779785
test loss item: 1.2267042398452759
test loss item: 0.34045907855033875
test loss item: 0.1679847687482834
test loss item: 0.2774631083011627
test loss item: 0.6661936044692993
test loss item: 0.11019878089427948
test loss item: 0.1276387721300125
test loss item: 0.20869721472263336
test loss item: 0.12535706162452698
test loss item: 0.05582242086529732
test loss item: 0.1892881691455841
test loss item: 0.33672329783439636
test loss item: 0.4209153354167938
test loss item: 0.17747989296913147
test loss item: 0.5457995533943176
test loss item: 0.27092981338500977
test loss item: 0.22097860276699066
test loss item: 0.11963655054569244
test loss item: 0.1458975225687027
test loss item: 0.14563603699207306
test loss item: 0.21136285364627838
test loss item: 0.12504740059375763
test loss item: 0.22278179228305817
test loss item: 0.22926713526248932
test loss item: 0.6088660955429077
test loss item: 0.054147202521562576
test loss item: 0.10042108595371246
test loss item: 0.4156292974948883
test loss item: 0.32404011487960815
test loss item: 0.29567423462867737
test loss item: 0.5271525979042053
test loss item: 1.1531001329421997
test loss item: 0.3277236819267273
test loss item: 0.18387863039970398
test loss item: 0.2124028354883194
test loss item: 0.11741605401039124
test loss item: 0.2444552183151245
test loss item: 0.1517467498779297
test loss item: 0.4058963656425476
test loss item: 0.25229591131210327
test loss item: 0.20318026840686798
test loss item: 0.163603737950325
test loss item: 0.3598737120628357
test loss item: 0.49113523960113525
test loss item: 0.21599282324314117
test loss item: 0.09894656389951706
test loss item: 0.17420615255832672
test loss item: 0.1138320341706276
test loss item: 0.22619004547595978
test loss item: 0.6719252467155457
test loss item: 0.38083305954933167
test loss item: 0.1896202713251114
test loss item: 0.1664300411939621
test loss item: 0.14369122684001923
test loss item: 0.3120623826980591
test loss item: 0.166866734623909
test loss item: 0.14235468208789825
test loss item: 0.1572938859462738
test loss item: 0.6851233243942261
test loss item: 0.23130014538764954
test loss item: 0.21250997483730316
test loss item: 0.1695951670408249
test loss item: 0.4068918228149414
test loss item: 0.26608189940452576
test loss item: 0.049843430519104004
test loss item: 0.6488500237464905
test loss item: 0.25323498249053955
test loss item: 0.2708825469017029
test loss item: 0.10871054977178574
test loss item: 0.10786910355091095
test loss item: 0.12107155472040176
test loss item: 1.2506489753723145
test loss item: 0.3155803084373474
test loss item: 0.1261700689792633
test loss item: 0.05908159911632538
test loss item: 0.737949788570404
test loss item: 0.6026932001113892
test loss item: 0.8375131487846375
test loss item: 0.1564032882452011
test loss item: 0.15331438183784485
test loss item: 0.05488037317991257
test loss item: 0.05003442242741585
test loss item: 0.10992012172937393
Epoch [51/100], Training Loss: 0.2808, Testing Loss: 0.2868
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 52/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2502659559249878
1
train loss item: 0.5056082010269165
2
train loss item: 0.1128007024526596
3
train loss item: 0.2041000872850418
4
train loss item: 0.18268385529518127
5
train loss item: 0.1510818898677826
6
train loss item: 0.11680006980895996
7
train loss item: 0.4034743905067444
8
train loss item: 0.0696263313293457
9
train loss item: 0.12112890928983688
10
train loss item: 0.15318948030471802
11
train loss item: 0.15390783548355103
12
train loss item: 0.09345458447933197
13
train loss item: 0.25764384865760803
14
train loss item: 0.1284685581922531
15
train loss item: 0.28374800086021423
16
train loss item: 0.04715261608362198
17
train loss item: 0.12893059849739075
18
train loss item: 0.15237343311309814
19
train loss item: 0.11613111197948456
20
train loss item: 0.10947910696268082
21
train loss item: 0.08411289006471634
22
train loss item: 0.34310051798820496
23
train loss item: 0.3573450446128845
24
train loss item: 0.253339946269989
25
train loss item: 0.10474060475826263
26
train loss item: 0.1003514975309372
27
train loss item: 0.1112862229347229
28
train loss item: 0.04594704508781433
29
train loss item: 0.2934224307537079
30
train loss item: 1.4634335041046143
31
train loss item: 0.2562943696975708
32
train loss item: 0.07084979116916656
33
train loss item: 0.17536340653896332
34
train loss item: 0.0926913246512413
35
train loss item: 1.8541903495788574
36
train loss item: 0.2665858268737793
37
train loss item: 0.2704364061355591
38
train loss item: 0.25261473655700684
39
train loss item: 0.12390628457069397
40
train loss item: 0.09737156331539154
41
train loss item: 0.12497250735759735
42
train loss item: 0.18576261401176453
43
train loss item: 0.09350787848234177
44
train loss item: 0.39060112833976746
45
train loss item: 0.07938790321350098
46
train loss item: 0.07108493149280548
47
train loss item: 0.1699545979499817
48
train loss item: 0.10644788295030594
49
train loss item: 0.08437887579202652
50
train loss item: 0.12152762711048126
51
train loss item: 0.4632030427455902
52
train loss item: 0.05056536942720413
53
train loss item: 0.08433414995670319
54
train loss item: 1.732270359992981
55
train loss item: 0.10657049715518951
56
train loss item: 0.12265363335609436
57
train loss item: 0.1302517205476761
58
train loss item: 0.08775128424167633
59
train loss item: 0.08931669592857361
60
train loss item: 0.3550803065299988
61
train loss item: 1.5495814085006714
62
train loss item: 0.1084805577993393
63
train loss item: 0.1830662190914154
64
train loss item: 0.0894891768693924
65
train loss item: 0.2594403922557831
66
train loss item: 0.2212345004081726
67
train loss item: 0.11085284501314163
68
train loss item: 0.13245384395122528
69
train loss item: 0.1648993045091629
70
train loss item: 0.13364045321941376
71
train loss item: 0.07431761175394058
72
train loss item: 0.08769886940717697
73
train loss item: 0.14252549409866333
74
train loss item: 0.05945321545004845
75
train loss item: 0.0770367681980133
76
train loss item: 0.35901349782943726
77
train loss item: 0.8843976259231567
78
train loss item: 0.05197831988334656
79
train loss item: 0.14885643124580383
80
train loss item: 0.07457410544157028
81
train loss item: 0.10757230222225189
82
train loss item: 0.09736404567956924
83
train loss item: 0.33115747570991516
84
train loss item: 0.2548390328884125
85
train loss item: 0.21901220083236694
86
train loss item: 3.506427049636841
87
train loss item: 0.09858369827270508
88
train loss item: 0.1788361370563507
epoch train loss: 0.277706055284551
testing phase
test loss item: 0.13798284530639648
test loss item: 0.06885479390621185
test loss item: 0.4571155309677124
test loss item: 0.17588461935520172
test loss item: 0.17695356905460358
test loss item: 0.08446954190731049
test loss item: 1.5041028261184692
test loss item: 0.4981961250305176
test loss item: 0.15944062173366547
test loss item: 0.2693041265010834
test loss item: 0.6489351391792297
test loss item: 0.11916034668684006
test loss item: 0.14347562193870544
test loss item: 0.22145545482635498
test loss item: 0.12037969380617142
test loss item: 0.055331677198410034
test loss item: 0.22669647634029388
test loss item: 0.31626150012016296
test loss item: 0.5152842402458191
test loss item: 0.22312216460704803
test loss item: 0.5179598927497864
test loss item: 0.3279951810836792
test loss item: 0.22801554203033447
test loss item: 0.1390203833580017
test loss item: 0.14816825091838837
test loss item: 0.1623472273349762
test loss item: 0.22773738205432892
test loss item: 0.12255550920963287
test loss item: 0.2284095585346222
test loss item: 0.23527245223522186
test loss item: 0.6633802652359009
test loss item: 0.055136993527412415
test loss item: 0.113191619515419
test loss item: 0.3999612033367157
test loss item: 0.30412209033966064
test loss item: 0.30749228596687317
test loss item: 0.6287427544593811
test loss item: 1.100124716758728
test loss item: 0.3228585720062256
test loss item: 0.2152860164642334
test loss item: 0.24219688773155212
test loss item: 0.12908348441123962
test loss item: 0.22413673996925354
test loss item: 0.17444977164268494
test loss item: 0.3835168778896332
test loss item: 0.3225570023059845
test loss item: 0.20695912837982178
test loss item: 0.20276479423046112
test loss item: 0.36599335074424744
test loss item: 0.5107378959655762
test loss item: 0.19790953397750854
test loss item: 0.1144208088517189
test loss item: 0.17705310881137848
test loss item: 0.11893930286169052
test loss item: 0.20842941105365753
test loss item: 0.6367339491844177
test loss item: 0.431075781583786
test loss item: 0.18895523250102997
test loss item: 0.18409058451652527
test loss item: 0.13383185863494873
test loss item: 0.2835714519023895
test loss item: 0.22387489676475525
test loss item: 0.1698930412530899
test loss item: 0.17256172001361847
test loss item: 0.7069476246833801
test loss item: 0.2391260266304016
test loss item: 0.2530193030834198
test loss item: 0.19045662879943848
test loss item: 0.39608606696128845
test loss item: 0.33690524101257324
test loss item: 0.048372846096754074
test loss item: 0.8454439043998718
test loss item: 0.2619208097457886
test loss item: 0.3350016474723816
test loss item: 0.12401057034730911
test loss item: 0.11742516607046127
test loss item: 0.1398259997367859
test loss item: 1.2090914249420166
test loss item: 0.32570216059684753
test loss item: 0.13143248856067657
test loss item: 0.06130940839648247
test loss item: 0.8075563907623291
test loss item: 0.6895812749862671
test loss item: 0.8148351311683655
test loss item: 0.17143090069293976
test loss item: 0.16639356315135956
test loss item: 0.05651784688234329
test loss item: 0.05153290182352066
test loss item: 0.11647619307041168
Epoch [52/100], Training Loss: 0.2777, Testing Loss: 0.3053
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6894.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6894.00 MB
Epoch 53/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.24623043835163116
1
train loss item: 0.5045307874679565
2
train loss item: 0.11259589344263077
3
train loss item: 0.21261052787303925
4
train loss item: 0.164352685213089
5
train loss item: 0.14742602407932281
6
train loss item: 0.12231606990098953
7
train loss item: 0.39413589239120483
8
train loss item: 0.06402035057544708
9
train loss item: 0.12365998327732086
10
train loss item: 0.14652244746685028
11
train loss item: 0.1460852026939392
12
train loss item: 0.09067385643720627
13
train loss item: 0.23547987639904022
14
train loss item: 0.12353774905204773
15
train loss item: 0.32790184020996094
16
train loss item: 0.04742766544222832
17
train loss item: 0.12632091343402863
18
train loss item: 0.15955381095409393
19
train loss item: 0.13781104981899261
20
train loss item: 0.12661142647266388
21
train loss item: 0.08570802211761475
22
train loss item: 0.38808417320251465
23
train loss item: 0.33398541808128357
24
train loss item: 0.2672564387321472
25
train loss item: 0.09748191386461258
26
train loss item: 0.09667552262544632
27
train loss item: 0.11057446151971817
28
train loss item: 0.04529329389333725
29
train loss item: 0.3301555812358856
30
train loss item: 1.4430932998657227
31
train loss item: 0.23730787634849548
32
train loss item: 0.06509248912334442
33
train loss item: 0.15784646570682526
34
train loss item: 0.08640192449092865
35
train loss item: 1.8426791429519653
36
train loss item: 0.24174974858760834
37
train loss item: 0.23986484110355377
38
train loss item: 0.20588229596614838
39
train loss item: 0.12551651895046234
40
train loss item: 0.09967215359210968
41
train loss item: 0.12289994210004807
42
train loss item: 0.1936759501695633
43
train loss item: 0.09483528137207031
44
train loss item: 0.3823814392089844
45
train loss item: 0.0742589607834816
46
train loss item: 0.06760741770267487
47
train loss item: 0.19310542941093445
48
train loss item: 0.11010412126779556
49
train loss item: 0.08520618826150894
50
train loss item: 0.14949966967105865
51
train loss item: 0.47507262229919434
52
train loss item: 0.05259469896554947
53
train loss item: 0.08171641826629639
54
train loss item: 1.7197092771530151
55
train loss item: 0.11145162582397461
56
train loss item: 0.12522950768470764
57
train loss item: 0.13911287486553192
58
train loss item: 0.09380430728197098
59
train loss item: 0.08709478378295898
60
train loss item: 0.3820019066333771
61
train loss item: 1.5278340578079224
62
train loss item: 0.1099468469619751
63
train loss item: 0.19015763700008392
64
train loss item: 0.08718810975551605
65
train loss item: 0.2206439971923828
66
train loss item: 0.22052542865276337
67
train loss item: 0.11374640464782715
68
train loss item: 0.17195075750350952
69
train loss item: 0.1522883176803589
70
train loss item: 0.13054059445858002
71
train loss item: 0.08263395726680756
72
train loss item: 0.081985242664814
73
train loss item: 0.1531977504491806
74
train loss item: 0.05643315613269806
75
train loss item: 0.07605830579996109
76
train loss item: 0.34357842803001404
77
train loss item: 0.9046719074249268
78
train loss item: 0.05080505087971687
79
train loss item: 0.14455002546310425
80
train loss item: 0.07034891843795776
81
train loss item: 0.11311916261911392
82
train loss item: 0.09259632974863052
83
train loss item: 0.3369777500629425
84
train loss item: 0.21397076547145844
85
train loss item: 0.22377777099609375
86
train loss item: 3.4853808879852295
87
train loss item: 0.09614191949367523
88
train loss item: 0.1705673784017563
epoch train loss: 0.276664105107945
testing phase
test loss item: 0.12797191739082336
test loss item: 0.06908684223890305
test loss item: 0.4262658655643463
test loss item: 0.1610891968011856
test loss item: 0.1675393134355545
test loss item: 0.08031496405601501
test loss item: 1.091565489768982
test loss item: 0.29939740896224976
test loss item: 0.15205040574073792
test loss item: 0.25228166580200195
test loss item: 0.6199595332145691
test loss item: 0.10577301681041718
test loss item: 0.11701327562332153
test loss item: 0.1854124367237091
test loss item: 0.11531984061002731
test loss item: 0.05503412336111069
test loss item: 0.1756516396999359
test loss item: 0.2985636591911316
test loss item: 0.3949476480484009
test loss item: 0.15780113637447357
test loss item: 0.4749892055988312
test loss item: 0.24673610925674438
test loss item: 0.18859627842903137
test loss item: 0.11084495484828949
test loss item: 0.13738314807415009
test loss item: 0.13734610378742218
test loss item: 0.1955685019493103
test loss item: 0.11649926751852036
test loss item: 0.20260131359100342
test loss item: 0.21420574188232422
test loss item: 0.5431153178215027
test loss item: 0.05748744681477547
test loss item: 0.0957823172211647
test loss item: 0.3761799931526184
test loss item: 0.28766340017318726
test loss item: 0.27155253291130066
test loss item: 0.48773619532585144
test loss item: 1.0539593696594238
test loss item: 0.29525068402290344
test loss item: 0.16644257307052612
test loss item: 0.19898952543735504
test loss item: 0.10341298580169678
test loss item: 0.21984335780143738
test loss item: 0.14239107072353363
test loss item: 0.35528260469436646
test loss item: 0.23136761784553528
test loss item: 0.17780354619026184
test loss item: 0.14648905396461487
test loss item: 0.3221377432346344
test loss item: 0.44736531376838684
test loss item: 0.19432224333286285
test loss item: 0.09363354742527008
test loss item: 0.16313408315181732
test loss item: 0.11127764731645584
test loss item: 0.20400209724903107
test loss item: 0.6076528429985046
test loss item: 0.3507690131664276
test loss item: 0.1702439934015274
test loss item: 0.15319956839084625
test loss item: 0.13507862389087677
test loss item: 0.28204455971717834
test loss item: 0.15147672593593597
test loss item: 0.1278630495071411
test loss item: 0.14974874258041382
test loss item: 0.6126465201377869
test loss item: 0.22551076114177704
test loss item: 0.18999281525611877
test loss item: 0.1591784954071045
test loss item: 0.3735980689525604
test loss item: 0.24572241306304932
test loss item: 0.04934472218155861
test loss item: 0.5755218267440796
test loss item: 0.21463331580162048
test loss item: 0.23352964222431183
test loss item: 0.10381380468606949
test loss item: 0.09444374591112137
test loss item: 0.1122288703918457
test loss item: 1.137222170829773
test loss item: 0.27693572640419006
test loss item: 0.11723372340202332
test loss item: 0.06083482876420021
test loss item: 0.6669020056724548
test loss item: 0.5500010848045349
test loss item: 0.7573962211608887
test loss item: 0.13766874372959137
test loss item: 0.14361917972564697
test loss item: 0.058389559388160706
test loss item: 0.054159015417099
test loss item: 0.1060137078166008
Epoch [53/100], Training Loss: 0.2767, Testing Loss: 0.2608
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 54/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.24827790260314941
1
train loss item: 0.4683852791786194
2
train loss item: 0.10785318911075592
3
train loss item: 0.22069817781448364
4
train loss item: 0.1805332899093628
5
train loss item: 0.1528829038143158
6
train loss item: 0.11458734422922134
7
train loss item: 0.37140196561813354
8
train loss item: 0.06980369240045547
9
train loss item: 0.12506206333637238
10
train loss item: 0.16497565805912018
11
train loss item: 0.16100044548511505
12
train loss item: 0.08989559859037399
13
train loss item: 0.25778359174728394
14
train loss item: 0.12050484120845795
15
train loss item: 0.28470659255981445
16
train loss item: 0.04824044555425644
17
train loss item: 0.13803650438785553
18
train loss item: 0.15354931354522705
19
train loss item: 0.11394035071134567
20
train loss item: 0.11427861452102661
21
train loss item: 0.0888587161898613
22
train loss item: 0.3253355324268341
23
train loss item: 0.3407529294490814
24
train loss item: 0.24616318941116333
25
train loss item: 0.11114298552274704
26
train loss item: 0.10470763593912125
27
train loss item: 0.10313834249973297
28
train loss item: 0.04672197625041008
29
train loss item: 0.2735840380191803
30
train loss item: 1.412091851234436
31
train loss item: 0.26864001154899597
32
train loss item: 0.06804009526968002
33
train loss item: 0.17495745420455933
34
train loss item: 0.08959268778562546
35
train loss item: 1.8257561922073364
36
train loss item: 0.2878401577472687
37
train loss item: 0.2870776355266571
38
train loss item: 0.27792876958847046
39
train loss item: 0.12841357290744781
40
train loss item: 0.0953424796462059
41
train loss item: 0.11961156874895096
42
train loss item: 0.17985565960407257
43
train loss item: 0.09346023201942444
44
train loss item: 0.3752478063106537
45
train loss item: 0.07548409700393677
46
train loss item: 0.07096453756093979
47
train loss item: 0.1655871570110321
48
train loss item: 0.09968773275613785
49
train loss item: 0.08320805430412292
50
train loss item: 0.11976592242717743
51
train loss item: 0.4371506869792938
52
train loss item: 0.050941627472639084
53
train loss item: 0.07759501785039902
54
train loss item: 1.7008641958236694
55
train loss item: 0.09764356911182404
56
train loss item: 0.12662319839000702
57
train loss item: 0.12412805110216141
58
train loss item: 0.08730393648147583
59
train loss item: 0.08291163295507431
60
train loss item: 0.3148134648799896
61
train loss item: 1.5077478885650635
62
train loss item: 0.11096083372831345
63
train loss item: 0.1948338747024536
64
train loss item: 0.08642061054706573
65
train loss item: 0.2723239064216614
66
train loss item: 0.2342330515384674
67
train loss item: 0.11106830090284348
68
train loss item: 0.13816139101982117
69
train loss item: 0.17384940385818481
70
train loss item: 0.13844312727451324
71
train loss item: 0.07752401381731033
72
train loss item: 0.07985805720090866
73
train loss item: 0.1384148895740509
74
train loss item: 0.05694132298231125
75
train loss item: 0.07769076526165009
76
train loss item: 0.3423316478729248
77
train loss item: 0.8474288582801819
78
train loss item: 0.051805414259433746
79
train loss item: 0.16048237681388855
80
train loss item: 0.07328519225120544
81
train loss item: 0.10907545685768127
82
train loss item: 0.09257806837558746
83
train loss item: 0.32817432284355164
84
train loss item: 0.2777305245399475
85
train loss item: 0.20806333422660828
86
train loss item: 3.465693950653076
87
train loss item: 0.08856954425573349
88
train loss item: 0.179873988032341
epoch train loss: 0.27380782340684634
testing phase
test loss item: 0.13701483607292175
test loss item: 0.06748469918966293
test loss item: 0.437793105840683
test loss item: 0.1748352348804474
test loss item: 0.16804184019565582
test loss item: 0.08407188206911087
test loss item: 1.4622594118118286
test loss item: 0.48387259244918823
test loss item: 0.15809127688407898
test loss item: 0.26205432415008545
test loss item: 0.636305034160614
test loss item: 0.11909300833940506
test loss item: 0.13563823699951172
test loss item: 0.21505016088485718
test loss item: 0.11541636288166046
test loss item: 0.05553800240159035
test loss item: 0.22455176711082458
test loss item: 0.2973635494709015
test loss item: 0.504774272441864
test loss item: 0.21543684601783752
test loss item: 0.47158825397491455
test loss item: 0.322591096162796
test loss item: 0.21228188276290894
test loss item: 0.1358557790517807
test loss item: 0.1451549232006073
test loss item: 0.16097058355808258
test loss item: 0.22475793957710266
test loss item: 0.11852498352527618
test loss item: 0.2221379578113556
test loss item: 0.22972440719604492
test loss item: 0.6407098770141602
test loss item: 0.059341393411159515
test loss item: 0.11115516722202301
test loss item: 0.3808650076389313
test loss item: 0.2865716218948364
test loss item: 0.3005308210849762
test loss item: 0.615325927734375
test loss item: 1.0648093223571777
test loss item: 0.31081148982048035
test loss item: 0.211701437830925
test loss item: 0.24061992764472961
test loss item: 0.12391790002584457
test loss item: 0.21507665514945984
test loss item: 0.1752326339483261
test loss item: 0.352338969707489
test loss item: 0.31753361225128174
test loss item: 0.19336926937103271
test loss item: 0.18797631561756134
test loss item: 0.3535333573818207
test loss item: 0.5015864372253418
test loss item: 0.1908862143754959
test loss item: 0.10587391257286072
test loss item: 0.17735633254051208
test loss item: 0.12256906926631927
test loss item: 0.1991492360830307
test loss item: 0.6113647222518921
test loss item: 0.4175472557544708
test loss item: 0.1777525693178177
test loss item: 0.17800253629684448
test loss item: 0.1328917294740677
test loss item: 0.27519476413726807
test loss item: 0.220799520611763
test loss item: 0.1655910611152649
test loss item: 0.17036555707454681
test loss item: 0.672705352306366
test loss item: 0.23874792456626892
test loss item: 0.24565984308719635
test loss item: 0.1884017437696457
test loss item: 0.3763701915740967
test loss item: 0.32725465297698975
test loss item: 0.048483096063137054
test loss item: 0.8249304890632629
test loss item: 0.24539010226726532
test loss item: 0.3268406093120575
test loss item: 0.12277960777282715
test loss item: 0.11209937930107117
test loss item: 0.13707788288593292
test loss item: 1.1526646614074707
test loss item: 0.3102765381336212
test loss item: 0.1284651905298233
test loss item: 0.06258783489465714
test loss item: 0.7853078842163086
test loss item: 0.6744697690010071
test loss item: 0.7838046550750732
test loss item: 0.16518834233283997
test loss item: 0.16439145803451538
test loss item: 0.058343954384326935
test loss item: 0.05377887934446335
test loss item: 0.11808455735445023
Epoch [54/100], Training Loss: 0.2738, Testing Loss: 0.2956
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 55/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.23764900863170624
1
train loss item: 0.46138298511505127
2
train loss item: 0.10710857063531876
3
train loss item: 0.1996232122182846
4
train loss item: 0.16138535737991333
5
train loss item: 0.14277085661888123
6
train loss item: 0.11201232671737671
7
train loss item: 0.37268003821372986
8
train loss item: 0.06387237459421158
9
train loss item: 0.11269126087427139
10
train loss item: 0.14340652525424957
11
train loss item: 0.1404941827058792
12
train loss item: 0.08751873672008514
13
train loss item: 0.23248550295829773
14
train loss item: 0.11599857360124588
15
train loss item: 0.2974291741847992
16
train loss item: 0.04740222916007042
17
train loss item: 0.11973033845424652
18
train loss item: 0.15086306631565094
19
train loss item: 0.12706851959228516
20
train loss item: 0.11384014040231705
21
train loss item: 0.07758654654026031
22
train loss item: 0.34211039543151855
23
train loss item: 0.31911566853523254
24
train loss item: 0.24916896224021912
25
train loss item: 0.0994139164686203
26
train loss item: 0.09175948798656464
27
train loss item: 0.10524055361747742
28
train loss item: 0.045225899666547775
29
train loss item: 0.30192506313323975
30
train loss item: 1.405512809753418
31
train loss item: 0.23399263620376587
32
train loss item: 0.06097162514925003
33
train loss item: 0.1591775268316269
34
train loss item: 0.08252149820327759
35
train loss item: 1.8169625997543335
36
train loss item: 0.23162633180618286
37
train loss item: 0.23831604421138763
38
train loss item: 0.1935349404811859
39
train loss item: 0.12342137098312378
40
train loss item: 0.09651613235473633
41
train loss item: 0.1194106861948967
42
train loss item: 0.18896327912807465
43
train loss item: 0.09128504991531372
44
train loss item: 0.37206077575683594
45
train loss item: 0.07256350666284561
46
train loss item: 0.06552963703870773
47
train loss item: 0.1812390387058258
48
train loss item: 0.10448550432920456
49
train loss item: 0.07900408655405045
50
train loss item: 0.13710252940654755
51
train loss item: 0.4516026973724365
52
train loss item: 0.05268850177526474
53
train loss item: 0.0773082822561264
54
train loss item: 1.6930674314498901
55
train loss item: 0.10321309417486191
56
train loss item: 0.12006232142448425
57
train loss item: 0.1342545449733734
58
train loss item: 0.08949591219425201
59
train loss item: 0.08339020609855652
60
train loss item: 0.34212929010391235
61
train loss item: 1.4967715740203857
62
train loss item: 0.10805708169937134
63
train loss item: 0.18195287883281708
64
train loss item: 0.08474559336900711
65
train loss item: 0.200295552611351
66
train loss item: 0.1997186541557312
67
train loss item: 0.10857439041137695
68
train loss item: 0.1590423434972763
69
train loss item: 0.1460450291633606
70
train loss item: 0.124277763068676
71
train loss item: 0.07874888181686401
72
train loss item: 0.07841750234365463
73
train loss item: 0.14457419514656067
74
train loss item: 0.05531537905335426
75
train loss item: 0.0738355815410614
76
train loss item: 0.32520022988319397
77
train loss item: 0.8784888982772827
78
train loss item: 0.0512637160718441
79
train loss item: 0.13688479363918304
80
train loss item: 0.0699315145611763
81
train loss item: 0.10887214541435242
82
train loss item: 0.08771737664937973
83
train loss item: 0.3197847008705139
84
train loss item: 0.19736212491989136
85
train loss item: 0.21134378015995026
86
train loss item: 3.4494776725769043
87
train loss item: 0.09043572843074799
88
train loss item: 0.15896186232566833
epoch train loss: 0.26636478999692403
testing phase
test loss item: 0.1288151890039444
test loss item: 0.0704612135887146
test loss item: 0.4728143513202667
test loss item: 0.1652650088071823
test loss item: 0.17807239294052124
test loss item: 0.08188119530677795
test loss item: 1.3763657808303833
test loss item: 0.42157119512557983
test loss item: 0.1643526703119278
test loss item: 0.2719157338142395
test loss item: 0.6821156740188599
test loss item: 0.11170279234647751
test loss item: 0.1300184726715088
test loss item: 0.20077025890350342
test loss item: 0.12166737020015717
test loss item: 0.05606796219944954
test loss item: 0.20187605917453766
test loss item: 0.3191114366054535
test loss item: 0.46345755457878113
test loss item: 0.18843157589435577
test loss item: 0.5157068371772766
test loss item: 0.2934480309486389
test loss item: 0.21029268205165863
test loss item: 0.1227981299161911
test loss item: 0.1445719301700592
test loss item: 0.15245401859283447
test loss item: 0.21339689195156097
test loss item: 0.1223473995923996
test loss item: 0.22194808721542358
test loss item: 0.22756822407245636
test loss item: 0.6444503664970398
test loss item: 0.057750917971134186
test loss item: 0.1004151999950409
test loss item: 0.40537914633750916
test loss item: 0.31199783086776733
test loss item: 0.2955656945705414
test loss item: 0.5784159302711487
test loss item: 1.164586067199707
test loss item: 0.325509637594223
test loss item: 0.19399109482765198
test loss item: 0.22481191158294678
test loss item: 0.10832381993532181
test loss item: 0.22949595749378204
test loss item: 0.16054020822048187
test loss item: 0.3834189772605896
test loss item: 0.28002405166625977
test loss item: 0.18995346128940582
test loss item: 0.1640431433916092
test loss item: 0.36323991417884827
test loss item: 0.5057622194290161
test loss item: 0.20807403326034546
test loss item: 0.09767169505357742
test loss item: 0.17672021687030792
test loss item: 0.1143001839518547
test loss item: 0.21718713641166687
test loss item: 0.6700674891471863
test loss item: 0.4038224220275879
test loss item: 0.18175195157527924
test loss item: 0.1668989360332489
test loss item: 0.14255033433437347
test loss item: 0.29458630084991455
test loss item: 0.19064873456954956
test loss item: 0.1460821032524109
test loss item: 0.1625947654247284
test loss item: 0.7065351605415344
test loss item: 0.22963330149650574
test loss item: 0.22414836287498474
test loss item: 0.17842315137386322
test loss item: 0.40315213799476624
test loss item: 0.2943953573703766
test loss item: 0.05165063217282295
test loss item: 0.7519892454147339
test loss item: 0.2383125126361847
test loss item: 0.2892954647541046
test loss item: 0.11207155138254166
test loss item: 0.10001350939273834
test loss item: 0.12617847323417664
test loss item: 1.2723438739776611
test loss item: 0.30989113450050354
test loss item: 0.12122848629951477
test loss item: 0.057780921459198
test loss item: 0.7862966656684875
test loss item: 0.6495094895362854
test loss item: 0.855487048625946
test loss item: 0.1549079716205597
test loss item: 0.15557029843330383
test loss item: 0.053350403904914856
test loss item: 0.05012951418757439
test loss item: 0.10408065468072891
Epoch [55/100], Training Loss: 0.2664, Testing Loss: 0.2940
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 56/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2345239669084549
1
train loss item: 0.4354853630065918
2
train loss item: 0.10436747223138809
3
train loss item: 0.18270356953144073
4
train loss item: 0.1592944860458374
5
train loss item: 0.14285536110401154
6
train loss item: 0.10377343744039536
7
train loss item: 0.36469414830207825
8
train loss item: 0.06292440742254257
9
train loss item: 0.10669779032468796
10
train loss item: 0.13828188180923462
11
train loss item: 0.13857384026050568
12
train loss item: 0.08705656230449677
13
train loss item: 0.22965827584266663
14
train loss item: 0.11481993645429611
15
train loss item: 0.269363671541214
16
train loss item: 0.04542138800024986
17
train loss item: 0.11513198912143707
18
train loss item: 0.14000394940376282
19
train loss item: 0.11340032517910004
20
train loss item: 0.10243941843509674
21
train loss item: 0.07587368786334991
22
train loss item: 0.30879512429237366
23
train loss item: 0.31022006273269653
24
train loss item: 0.23168998956680298
25
train loss item: 0.09672494977712631
26
train loss item: 0.09150280058383942
27
train loss item: 0.10336848348379135
28
train loss item: 0.043948497623205185
29
train loss item: 0.2701335847377777
30
train loss item: 1.3846802711486816
31
train loss item: 0.22553810477256775
32
train loss item: 0.06291201710700989
33
train loss item: 0.15787653625011444
34
train loss item: 0.08423885703086853
35
train loss item: 1.8053399324417114
36
train loss item: 0.2335335910320282
37
train loss item: 0.24864524602890015
38
train loss item: 0.19166713953018188
39
train loss item: 0.11804793775081635
40
train loss item: 0.09363719820976257
41
train loss item: 0.11603263020515442
42
train loss item: 0.1828160285949707
43
train loss item: 0.08862443268299103
44
train loss item: 0.3695129156112671
45
train loss item: 0.07313065975904465
46
train loss item: 0.06559953093528748
47
train loss item: 0.16440129280090332
48
train loss item: 0.1013764888048172
49
train loss item: 0.07812641561031342
50
train loss item: 0.11943122744560242
51
train loss item: 0.43280133605003357
52
train loss item: 0.04917844384908676
53
train loss item: 0.07551161199808121
54
train loss item: 1.6816247701644897
55
train loss item: 0.09879953414201736
56
train loss item: 0.11662016808986664
57
train loss item: 0.12907637655735016
58
train loss item: 0.08513671159744263
59
train loss item: 0.08245065808296204
60
train loss item: 0.3139162063598633
61
train loss item: 1.4850534200668335
62
train loss item: 0.10542558133602142
63
train loss item: 0.17285728454589844
64
train loss item: 0.08448969572782516
65
train loss item: 0.2062007635831833
66
train loss item: 0.19087348878383636
67
train loss item: 0.10697782039642334
68
train loss item: 0.13439658284187317
69
train loss item: 0.1460423320531845
70
train loss item: 0.11907937377691269
71
train loss item: 0.0721951276063919
72
train loss item: 0.07860780507326126
73
train loss item: 0.13404032588005066
74
train loss item: 0.05537540093064308
75
train loss item: 0.07269936054944992
76
train loss item: 0.31302884221076965
77
train loss item: 0.8504127860069275
78
train loss item: 0.04936075583100319
79
train loss item: 0.130764439702034
80
train loss item: 0.06894323974847794
81
train loss item: 0.10493157804012299
82
train loss item: 0.08648496121168137
83
train loss item: 0.3157544434070587
84
train loss item: 0.20954006910324097
85
train loss item: 0.19812463223934174
86
train loss item: 3.434512138366699
87
train loss item: 0.09045199304819107
88
train loss item: 0.1525973677635193
epoch train loss: 0.2598116213686011
testing phase
test loss item: 0.12815868854522705
test loss item: 0.06917654722929001
test loss item: 0.44083788990974426
test loss item: 0.1623106151819229
test loss item: 0.1697758436203003
test loss item: 0.08207384496927261
test loss item: 1.2266125679016113
test loss item: 0.3548187017440796
test loss item: 0.14920076727867126
test loss item: 0.24777279794216156
test loss item: 0.6426663398742676
test loss item: 0.10796934366226196
test loss item: 0.12118600308895111
test loss item: 0.19056597352027893
test loss item: 0.11603851616382599
test loss item: 0.055912382900714874
test loss item: 0.1878296285867691
test loss item: 0.29408830404281616
test loss item: 0.41136443614959717
test loss item: 0.16870157420635223
test loss item: 0.4766993224620819
test loss item: 0.2679007649421692
test loss item: 0.19544674456119537
test loss item: 0.1152273416519165
test loss item: 0.1398075670003891
test loss item: 0.14088892936706543
test loss item: 0.1950589269399643
test loss item: 0.1174384355545044
test loss item: 0.20552004873752594
test loss item: 0.20988284051418304
test loss item: 0.5882303714752197
test loss item: 0.05913887172937393
test loss item: 0.09711085259914398
test loss item: 0.38108235597610474
test loss item: 0.2890617549419403
test loss item: 0.2668108344078064
test loss item: 0.5161468982696533
test loss item: 1.0998119115829468
test loss item: 0.3021216094493866
test loss item: 0.17852868139743805
test loss item: 0.21184830367565155
test loss item: 0.10540756583213806
test loss item: 0.20914164185523987
test loss item: 0.15474800765514374
test loss item: 0.35314199328422546
test loss item: 0.24815741181373596
test loss item: 0.17728331685066223
test loss item: 0.1511940360069275
test loss item: 0.3333253860473633
test loss item: 0.45921364426612854
test loss item: 0.18719789385795593
test loss item: 0.09476200491189957
test loss item: 0.1663426160812378
test loss item: 0.11770571023225784
test loss item: 0.1998940110206604
test loss item: 0.6272991299629211
test loss item: 0.3677297532558441
test loss item: 0.16481612622737885
test loss item: 0.15595394372940063
test loss item: 0.1319711059331894
test loss item: 0.2678218185901642
test loss item: 0.17154698073863983
test loss item: 0.1354479044675827
test loss item: 0.15154306590557098
test loss item: 0.657296895980835
test loss item: 0.22652125358581543
test loss item: 0.20235227048397064
test loss item: 0.16689230501651764
test loss item: 0.38568660616874695
test loss item: 0.24993346631526947
test loss item: 0.05050703510642052
test loss item: 0.6565693616867065
test loss item: 0.22312624752521515
test loss item: 0.2599601745605469
test loss item: 0.10896651446819305
test loss item: 0.09730182588100433
test loss item: 0.11788836121559143
test loss item: 1.2157230377197266
test loss item: 0.29224395751953125
test loss item: 0.11881611496210098
test loss item: 0.059198565781116486
test loss item: 0.717463493347168
test loss item: 0.579300582408905
test loss item: 0.8056495189666748
test loss item: 0.1414095163345337
test loss item: 0.14960183203220367
test loss item: 0.05554542317986488
test loss item: 0.051764607429504395
test loss item: 0.10354693979024887
Epoch [56/100], Training Loss: 0.2598, Testing Loss: 0.2720
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 57/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.23685139417648315
1
train loss item: 0.4113842844963074
2
train loss item: 0.0980345606803894
3
train loss item: 0.1897285133600235
4
train loss item: 0.16205880045890808
5
train loss item: 0.1468713879585266
6
train loss item: 0.10233119875192642
7
train loss item: 0.34575900435447693
8
train loss item: 0.06283595412969589
9
train loss item: 0.11135241389274597
10
train loss item: 0.15348589420318604
11
train loss item: 0.146427184343338
12
train loss item: 0.08770283311605453
13
train loss item: 0.23836438357830048
14
train loss item: 0.11231806129217148
15
train loss item: 0.26408347487449646
16
train loss item: 0.04584353417158127
17
train loss item: 0.1246446892619133
18
train loss item: 0.14394307136535645
19
train loss item: 0.10953361541032791
20
train loss item: 0.10545656085014343
21
train loss item: 0.0799853652715683
22
train loss item: 0.28877827525138855
23
train loss item: 0.2992655336856842
24
train loss item: 0.2289184033870697
25
train loss item: 0.10426531732082367
26
train loss item: 0.09550439566373825
27
train loss item: 0.09705939888954163
28
train loss item: 0.044132839888334274
29
train loss item: 0.24206677079200745
30
train loss item: 1.3525135517120361
31
train loss item: 0.2492537796497345
32
train loss item: 0.06306830048561096
33
train loss item: 0.14977377653121948
34
train loss item: 0.08828496187925339
35
train loss item: 1.790307641029358
36
train loss item: 0.2566717267036438
37
train loss item: 0.26844102144241333
38
train loss item: 0.24101080000400543
39
train loss item: 0.12203158438205719
40
train loss item: 0.09400300681591034
41
train loss item: 0.10846618562936783
42
train loss item: 0.17710177600383759
43
train loss item: 0.08864527940750122
44
train loss item: 0.36097392439842224
45
train loss item: 0.07074881345033646
46
train loss item: 0.06508217006921768
47
train loss item: 0.15703850984573364
48
train loss item: 0.09634670615196228
49
train loss item: 0.0798586830496788
50
train loss item: 0.1134490892291069
51
train loss item: 0.4059823453426361
52
train loss item: 0.04985969141125679
53
train loss item: 0.07318912446498871
54
train loss item: 1.6650519371032715
55
train loss item: 0.09338326752185822
56
train loss item: 0.11780352890491486
57
train loss item: 0.12500308454036713
58
train loss item: 0.08560174703598022
59
train loss item: 0.08137407898902893
60
train loss item: 0.27932101488113403
61
train loss item: 1.4611732959747314
62
train loss item: 0.10597524791955948
63
train loss item: 0.17901450395584106
64
train loss item: 0.08207448571920395
65
train loss item: 0.2464325875043869
66
train loss item: 0.20632906258106232
67
train loss item: 0.1067151352763176
68
train loss item: 0.12807069718837738
69
train loss item: 0.16532842814922333
70
train loss item: 0.12567225098609924
71
train loss item: 0.07167530059814453
72
train loss item: 0.0771147608757019
73
train loss item: 0.13033942878246307
74
train loss item: 0.05503298342227936
75
train loss item: 0.07329500466585159
76
train loss item: 0.30169034004211426
77
train loss item: 0.8173357844352722
78
train loss item: 0.05158300697803497
79
train loss item: 0.14079007506370544
80
train loss item: 0.06939274072647095
81
train loss item: 0.10655722767114639
82
train loss item: 0.08277182281017303
83
train loss item: 0.3129996359348297
84
train loss item: 0.24166852235794067
85
train loss item: 0.19481942057609558
86
train loss item: 3.4143126010894775
87
train loss item: 0.08496882021427155
88
train loss item: 0.16677026450634003
epoch train loss: 0.2589722658308704
testing phase
test loss item: 0.13484981656074524
test loss item: 0.06931369751691818
test loss item: 0.4598222076892853
test loss item: 0.17177361249923706
test loss item: 0.17305290699005127
test loss item: 0.08330891281366348
test loss item: 1.5580633878707886
test loss item: 0.5094124674797058
test loss item: 0.15716280043125153
test loss item: 0.2624916732311249
test loss item: 0.6613572239875793
test loss item: 0.11791753023862839
test loss item: 0.1330914944410324
test loss item: 0.21072672307491302
test loss item: 0.1194634959101677
test loss item: 0.05610477924346924
test loss item: 0.21985366940498352
test loss item: 0.3070620596408844
test loss item: 0.5069512128829956
test loss item: 0.20921191573143005
test loss item: 0.5030115246772766
test loss item: 0.3228258192539215
test loss item: 0.2231777161359787
test loss item: 0.13441504538059235
test loss item: 0.1463712602853775
test loss item: 0.15693849325180054
test loss item: 0.21888208389282227
test loss item: 0.1185745894908905
test loss item: 0.22382597625255585
test loss item: 0.2246907651424408
test loss item: 0.6798140406608582
test loss item: 0.05864853784441948
test loss item: 0.1081756055355072
test loss item: 0.3970884680747986
test loss item: 0.30007678270339966
test loss item: 0.2986428141593933
test loss item: 0.6319682598114014
test loss item: 1.1210733652114868
test loss item: 0.32401934266090393
test loss item: 0.21405436098575592
test loss item: 0.2442246973514557
test loss item: 0.11893421411514282
test loss item: 0.21937428414821625
test loss item: 0.17725053429603577
test loss item: 0.37250596284866333
test loss item: 0.30553993582725525
test loss item: 0.19576416909694672
test loss item: 0.1801677942276001
test loss item: 0.36234891414642334
test loss item: 0.5052910447120667
test loss item: 0.1975814402103424
test loss item: 0.1002083271741867
test loss item: 0.17862927913665771
test loss item: 0.12250211834907532
test loss item: 0.20589227974414825
test loss item: 0.6427105665206909
test loss item: 0.4279628098011017
test loss item: 0.18390469253063202
test loss item: 0.17515847086906433
test loss item: 0.1345292031764984
test loss item: 0.2790815234184265
test loss item: 0.21462130546569824
test loss item: 0.16099369525909424
test loss item: 0.1680782586336136
test loss item: 0.7157396674156189
test loss item: 0.2351263165473938
test loss item: 0.24157719314098358
test loss item: 0.18927910923957825
test loss item: 0.39472734928131104
test loss item: 0.3290546238422394
test loss item: 0.047587983310222626
test loss item: 0.8661317825317383
test loss item: 0.2523711621761322
test loss item: 0.3297775685787201
test loss item: 0.11814471334218979
test loss item: 0.1107039675116539
test loss item: 0.1370733678340912
test loss item: 1.242976427078247
test loss item: 0.3180406093597412
test loss item: 0.12463131546974182
test loss item: 0.06111498177051544
test loss item: 0.8220983743667603
test loss item: 0.6976720094680786
test loss item: 0.8362252712249756
test loss item: 0.16537810862064362
test loss item: 0.15967059135437012
test loss item: 0.0562395378947258
test loss item: 0.051219772547483444
test loss item: 0.11005055159330368
Epoch [57/100], Training Loss: 0.2590, Testing Loss: 0.3035
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 58/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2325887233018875
1
train loss item: 0.4133017957210541
2
train loss item: 0.10829947143793106
3
train loss item: 0.1913919299840927
4
train loss item: 0.15278160572052002
5
train loss item: 0.13843272626399994
6
train loss item: 0.10492175817489624
7
train loss item: 0.3523911237716675
8
train loss item: 0.06110185757279396
9
train loss item: 0.11221572011709213
10
train loss item: 0.1299794316291809
11
train loss item: 0.13393831253051758
12
train loss item: 0.08393502235412598
13
train loss item: 0.2213684469461441
14
train loss item: 0.11778853833675385
15
train loss item: 0.2920815646648407
16
train loss item: 0.04738139733672142
17
train loss item: 0.11282335221767426
18
train loss item: 0.14441272616386414
19
train loss item: 0.12112671881914139
20
train loss item: 0.10890696942806244
21
train loss item: 0.07422064989805222
22
train loss item: 0.3080734610557556
23
train loss item: 0.28586819767951965
24
train loss item: 0.2351289689540863
25
train loss item: 0.09308629482984543
26
train loss item: 0.08928369730710983
27
train loss item: 0.10678130388259888
28
train loss item: 0.04538172110915184
29
train loss item: 0.29188206791877747
30
train loss item: 1.352400541305542
31
train loss item: 0.21175551414489746
32
train loss item: 0.0590064562857151
33
train loss item: 0.15357309579849243
34
train loss item: 0.08158430457115173
35
train loss item: 1.7832611799240112
36
train loss item: 0.22199746966362
37
train loss item: 0.23291373252868652
38
train loss item: 0.1959010660648346
39
train loss item: 0.11671696603298187
40
train loss item: 0.09399067610502243
41
train loss item: 0.118836909532547
42
train loss item: 0.18456986546516418
43
train loss item: 0.08931156992912292
44
train loss item: 0.36256182193756104
45
train loss item: 0.07190655916929245
46
train loss item: 0.06302162259817123
47
train loss item: 0.18086913228034973
48
train loss item: 0.10357797890901566
49
train loss item: 0.0778799057006836
50
train loss item: 0.12988820672035217
51
train loss item: 0.4401957392692566
52
train loss item: 0.05246848613023758
53
train loss item: 0.07673435658216476
54
train loss item: 1.6586140394210815
55
train loss item: 0.100278340280056
56
train loss item: 0.11686444282531738
57
train loss item: 0.13147161900997162
58
train loss item: 0.08641413599252701
59
train loss item: 0.08354949206113815
60
train loss item: 0.3361261785030365
61
train loss item: 1.457688808441162
62
train loss item: 0.10686954110860825
63
train loss item: 0.18008415400981903
64
train loss item: 0.08352341502904892
65
train loss item: 0.18917681276798248
66
train loss item: 0.18655668199062347
67
train loss item: 0.11124182492494583
68
train loss item: 0.15976344048976898
69
train loss item: 0.13948823511600494
70
train loss item: 0.12184005975723267
71
train loss item: 0.07390880584716797
72
train loss item: 0.07979074865579605
73
train loss item: 0.1394127756357193
74
train loss item: 0.054726921021938324
75
train loss item: 0.07337099313735962
76
train loss item: 0.2899104356765747
77
train loss item: 0.8553192019462585
78
train loss item: 0.049341876059770584
79
train loss item: 0.13427338004112244
80
train loss item: 0.06499352306127548
81
train loss item: 0.10527573525905609
82
train loss item: 0.08738812804222107
83
train loss item: 0.30972597002983093
84
train loss item: 0.19094686210155487
85
train loss item: 0.20298068225383759
86
train loss item: 3.4015698432922363
87
train loss item: 0.09165098518133163
88
train loss item: 0.1490447223186493
epoch train loss: 0.2580784440794018
testing phase
test loss item: 0.12378988415002823
test loss item: 0.07222007215023041
test loss item: 0.43468350172042847
test loss item: 0.15735207498073578
test loss item: 0.16873414814472198
test loss item: 0.08144918084144592
test loss item: 1.302607536315918
test loss item: 0.35596761107444763
test loss item: 0.15065333247184753
test loss item: 0.24981647729873657
test loss item: 0.6397548913955688
test loss item: 0.10617189854383469
test loss item: 0.11697603017091751
test loss item: 0.1856783777475357
test loss item: 0.11666947603225708
test loss item: 0.055654846131801605
test loss item: 0.1780257672071457
test loss item: 0.2943814992904663
test loss item: 0.40913382172584534
test loss item: 0.16172181069850922
test loss item: 0.4709641635417938
test loss item: 0.2626841366291046
test loss item: 0.1929139941930771
test loss item: 0.11360093951225281
test loss item: 0.13655169308185577
test loss item: 0.14012692868709564
test loss item: 0.1935150921344757
test loss item: 0.1173643097281456
test loss item: 0.20698480308055878
test loss item: 0.21074987947940826
test loss item: 0.6039589643478394
test loss item: 0.05663878098130226
test loss item: 0.0934564471244812
test loss item: 0.3792371153831482
test loss item: 0.288016140460968
test loss item: 0.2707943916320801
test loss item: 0.5228427648544312
test loss item: 1.0898762941360474
test loss item: 0.30427828431129456
test loss item: 0.18061703443527222
test loss item: 0.21113209426403046
test loss item: 0.0975726917386055
test loss item: 0.21719104051589966
test loss item: 0.1506357491016388
test loss item: 0.35224196314811707
test loss item: 0.23392929136753082
test loss item: 0.17290429770946503
test loss item: 0.14701102674007416
test loss item: 0.3268931210041046
test loss item: 0.4585512578487396
test loss item: 0.19558680057525635
test loss item: 0.09171587228775024
test loss item: 0.16883635520935059
test loss item: 0.11147100478410721
test loss item: 0.2061503529548645
test loss item: 0.6219479441642761
test loss item: 0.3638983964920044
test loss item: 0.1702164113521576
test loss item: 0.15077191591262817
test loss item: 0.1395631581544876
test loss item: 0.2788846492767334
test loss item: 0.15755590796470642
test loss item: 0.12934917211532593
test loss item: 0.15057140588760376
test loss item: 0.642917275428772
test loss item: 0.220445916056633
test loss item: 0.1945558488368988
test loss item: 0.16625985503196716
test loss item: 0.3786817491054535
test loss item: 0.25583598017692566
test loss item: 0.04979538172483444
test loss item: 0.6827665567398071
test loss item: 0.216544970870018
test loss item: 0.2580905854701996
test loss item: 0.10143234580755234
test loss item: 0.09164169430732727
test loss item: 0.11772069334983826
test loss item: 1.1969019174575806
test loss item: 0.2838609516620636
test loss item: 0.11428201198577881
test loss item: 0.05679789558053017
test loss item: 0.7234913110733032
test loss item: 0.5965868830680847
test loss item: 0.7965628504753113
test loss item: 0.14520347118377686
test loss item: 0.14058279991149902
test loss item: 0.05324019864201546
test loss item: 0.04886395111680031
test loss item: 0.09651708602905273
Epoch [58/100], Training Loss: 0.2581, Testing Loss: 0.2711
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 59/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.22954107820987701
1
train loss item: 0.384685754776001
2
train loss item: 0.10001999884843826
3
train loss item: 0.18340568244457245
4
train loss item: 0.15522466599941254
5
train loss item: 0.13941466808319092
6
train loss item: 0.09769045561552048
7
train loss item: 0.33295950293540955
8
train loss item: 0.061796218156814575
9
train loss item: 0.10492577403783798
10
train loss item: 0.14585906267166138
11
train loss item: 0.1464807540178299
12
train loss item: 0.0834881067276001
13
train loss item: 0.23715846240520477
14
train loss item: 0.11256483197212219
15
train loss item: 0.24541917443275452
16
train loss item: 0.04531030356884003
17
train loss item: 0.11911924928426743
18
train loss item: 0.13767202198505402
19
train loss item: 0.10344915091991425
20
train loss item: 0.09962198138237
21
train loss item: 0.07861832529306412
22
train loss item: 0.2635194659233093
23
train loss item: 0.28878235816955566
24
train loss item: 0.2143266201019287
25
train loss item: 0.10250652581453323
26
train loss item: 0.09150031954050064
27
train loss item: 0.09485522657632828
28
train loss item: 0.04430354759097099
29
train loss item: 0.2322746217250824
30
train loss item: 1.3213741779327393
31
train loss item: 0.24188028275966644
32
train loss item: 0.06450241059064865
33
train loss item: 0.15693701803684235
34
train loss item: 0.08510664105415344
35
train loss item: 1.7666168212890625
36
train loss item: 0.2528630793094635
37
train loss item: 0.2597110867500305
38
train loss item: 0.2465943694114685
39
train loss item: 0.11787951737642288
40
train loss item: 0.08908966183662415
41
train loss item: 0.10931608825922012
42
train loss item: 0.17366579174995422
43
train loss item: 0.08626892417669296
44
train loss item: 0.35586804151535034
45
train loss item: 0.0711609423160553
46
train loss item: 0.06461789458990097
47
train loss item: 0.14914259314537048
48
train loss item: 0.09314747154712677
49
train loss item: 0.07698424905538559
50
train loss item: 0.10765969008207321
51
train loss item: 0.3947278559207916
52
train loss item: 0.048100002110004425
53
train loss item: 0.07198941707611084
54
train loss item: 1.6414653062820435
55
train loss item: 0.08940981328487396
56
train loss item: 0.11451263725757599
57
train loss item: 0.12031274288892746
58
train loss item: 0.08030866086483002
59
train loss item: 0.08043016493320465
60
train loss item: 0.26778560876846313
61
train loss item: 1.435518741607666
62
train loss item: 0.10120664536952972
63
train loss item: 0.1724633276462555
64
train loss item: 0.08163099735975266
65
train loss item: 0.23873892426490784
66
train loss item: 0.20267152786254883
67
train loss item: 0.10119623690843582
68
train loss item: 0.12176656723022461
69
train loss item: 0.15536898374557495
70
train loss item: 0.12128352373838425
71
train loss item: 0.07009030878543854
72
train loss item: 0.07416573166847229
73
train loss item: 0.12532363831996918
74
train loss item: 0.05541650950908661
75
train loss item: 0.07369660586118698
76
train loss item: 0.28596529364585876
77
train loss item: 0.8001495599746704
78
train loss item: 0.04904487356543541
79
train loss item: 0.13864532113075256
80
train loss item: 0.06762928515672684
81
train loss item: 0.09930633008480072
82
train loss item: 0.08464255928993225
83
train loss item: 0.3022679388523102
84
train loss item: 0.23026098310947418
85
train loss item: 0.19047321379184723
86
train loss item: 3.3818821907043457
87
train loss item: 0.08353552222251892
88
train loss item: 0.15416696667671204
epoch train loss: 0.2525216986456614
testing phase
test loss item: 0.1257922500371933
test loss item: 0.07110901921987534
test loss item: 0.42434048652648926
test loss item: 0.15907655656337738
test loss item: 0.1676844209432602
test loss item: 0.08262290805578232
test loss item: 1.3560417890548706
test loss item: 0.42887550592422485
test loss item: 0.14678338170051575
test loss item: 0.24589872360229492
test loss item: 0.6229826211929321
test loss item: 0.10913913697004318
test loss item: 0.13092057406902313
test loss item: 0.20080173015594482
test loss item: 0.11450518667697906
test loss item: 0.05585549399256706
test loss item: 0.20026551187038422
test loss item: 0.2850720286369324
test loss item: 0.4509260058403015
test loss item: 0.1968814730644226
test loss item: 0.4580269157886505
test loss item: 0.2894164025783539
test loss item: 0.20518368482589722
test loss item: 0.12437176704406738
test loss item: 0.13605867326259613
test loss item: 0.15016032755374908
test loss item: 0.20486396551132202
test loss item: 0.11891482770442963
test loss item: 0.21124444901943207
test loss item: 0.21284231543540955
test loss item: 0.608762264251709
test loss item: 0.05451269447803497
test loss item: 0.10151950269937515
test loss item: 0.36818087100982666
test loss item: 0.27773013710975647
test loss item: 0.2778531014919281
test loss item: 0.5585474371910095
test loss item: 1.0514922142028809
test loss item: 0.29802507162094116
test loss item: 0.19164259731769562
test loss item: 0.2191373109817505
test loss item: 0.11086444556713104
test loss item: 0.20461505651474
test loss item: 0.15714401006698608
test loss item: 0.34307345747947693
test loss item: 0.28297340869903564
test loss item: 0.18161162734031677
test loss item: 0.17457781732082367
test loss item: 0.3344159722328186
test loss item: 0.46532654762268066
test loss item: 0.1862168312072754
test loss item: 0.09979233145713806
test loss item: 0.16742126643657684
test loss item: 0.11057969927787781
test loss item: 0.19551627337932587
test loss item: 0.5985061526298523
test loss item: 0.38579389452934265
test loss item: 0.17200492322444916
test loss item: 0.16408859193325043
test loss item: 0.13444949686527252
test loss item: 0.26097527146339417
test loss item: 0.196792334318161
test loss item: 0.14847077429294586
test loss item: 0.15688583254814148
test loss item: 0.6460504531860352
test loss item: 0.21863460540771484
test loss item: 0.2262294590473175
test loss item: 0.17329853773117065
test loss item: 0.37168166041374207
test loss item: 0.2914193570613861
test loss item: 0.050019145011901855
test loss item: 0.7465209364891052
test loss item: 0.2356121987104416
test loss item: 0.29307377338409424
test loss item: 0.11279280483722687
test loss item: 0.1039012223482132
test loss item: 0.1269516944885254
test loss item: 1.1610406637191772
test loss item: 0.2963981032371521
test loss item: 0.11985965818166733
test loss item: 0.055662039667367935
test loss item: 0.7365651726722717
test loss item: 0.617840051651001
test loss item: 0.7751523852348328
test loss item: 0.15549077093601227
test loss item: 0.15291064977645874
test loss item: 0.05129145085811615
test loss item: 0.04667538404464722
test loss item: 0.09786946326494217
Epoch [59/100], Training Loss: 0.2525, Testing Loss: 0.2785
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 60/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2251429408788681
1
train loss item: 0.37310221791267395
2
train loss item: 0.0988001823425293
3
train loss item: 0.17690108716487885
4
train loss item: 0.15001195669174194
5
train loss item: 0.1373814344406128
6
train loss item: 0.10120892524719238
7
train loss item: 0.3344285190105438
8
train loss item: 0.05611557886004448
9
train loss item: 0.10698696225881577
10
train loss item: 0.13498647511005402
11
train loss item: 0.13200949132442474
12
train loss item: 0.08308326452970505
13
train loss item: 0.2139580100774765
14
train loss item: 0.10835196822881699
15
train loss item: 0.2561103105545044
16
train loss item: 0.045073509216308594
17
train loss item: 0.10690480470657349
18
train loss item: 0.1383657604455948
19
train loss item: 0.11127306520938873
20
train loss item: 0.10179979354143143
21
train loss item: 0.07304006814956665
22
train loss item: 0.27663180232048035
23
train loss item: 0.2682787775993347
24
train loss item: 0.22791439294815063
25
train loss item: 0.093174047768116
26
train loss item: 0.08656467497348785
27
train loss item: 0.09604998677968979
28
train loss item: 0.04327597841620445
29
train loss item: 0.23573142290115356
30
train loss item: 1.301615834236145
31
train loss item: 0.21939019858837128
32
train loss item: 0.06110566109418869
33
train loss item: 0.1384296715259552
34
train loss item: 0.08230303972959518
35
train loss item: 1.756426215171814
36
train loss item: 0.22848421335220337
37
train loss item: 0.2340129166841507
38
train loss item: 0.19159521162509918
39
train loss item: 0.11879408359527588
40
train loss item: 0.09299366921186447
41
train loss item: 0.10610702633857727
42
train loss item: 0.17793631553649902
43
train loss item: 0.08556672930717468
44
train loss item: 0.3539561629295349
45
train loss item: 0.06783432513475418
46
train loss item: 0.06600659340620041
47
train loss item: 0.15734434127807617
48
train loss item: 0.09791301190853119
49
train loss item: 0.07847480475902557
50
train loss item: 0.1150694191455841
51
train loss item: 0.3933102488517761
52
train loss item: 0.04941185936331749
53
train loss item: 0.07183391600847244
54
train loss item: 1.6319156885147095
55
train loss item: 0.09615607559680939
56
train loss item: 0.11101532727479935
57
train loss item: 0.13239063322544098
58
train loss item: 0.08384563028812408
59
train loss item: 0.08191339671611786
60
train loss item: 0.2706396281719208
61
train loss item: 1.4191079139709473
62
train loss item: 0.09778585284948349
63
train loss item: 0.1653720587491989
64
train loss item: 0.07966300845146179
65
train loss item: 0.19358444213867188
66
train loss item: 0.19213302433490753
67
train loss item: 0.10347957164049149
68
train loss item: 0.13404807448387146
69
train loss item: 0.14117005467414856
70
train loss item: 0.11316383630037308
71
train loss item: 0.07466847449541092
72
train loss item: 0.0733574703335762
73
train loss item: 0.1301221251487732
74
train loss item: 0.054329827427864075
75
train loss item: 0.07225318998098373
76
train loss item: 0.272403359413147
77
train loss item: 0.8043602705001831
78
train loss item: 0.04958389326930046
79
train loss item: 0.12403124570846558
80
train loss item: 0.06515712291002274
81
train loss item: 0.10332182049751282
82
train loss item: 0.0800909623503685
83
train loss item: 0.29825541377067566
84
train loss item: 0.20156963169574738
85
train loss item: 0.1888359636068344
86
train loss item: 3.3628718852996826
87
train loss item: 0.08225733041763306
88
train loss item: 0.14932528138160706
epoch train loss: 0.2480084535278631
testing phase
test loss item: 0.12950770556926727
test loss item: 0.07170617580413818
test loss item: 0.49957937002182007
test loss item: 0.1618693619966507
test loss item: 0.18143334984779358
test loss item: 0.08378959447145462
test loss item: 1.3877618312835693
test loss item: 0.423979252576828
test loss item: 0.17293505370616913
test loss item: 0.2839612364768982
test loss item: 0.7195964455604553
test loss item: 0.11035662889480591
test loss item: 0.1292407512664795
test loss item: 0.20854860544204712
test loss item: 0.12473822385072708
test loss item: 0.056112729012966156
test loss item: 0.20170816779136658
test loss item: 0.33490899205207825
test loss item: 0.4506992697715759
test loss item: 0.19258971512317657
test loss item: 0.5405405759811401
test loss item: 0.2883957326412201
test loss item: 0.22283318638801575
test loss item: 0.1235794872045517
test loss item: 0.15089908242225647
test loss item: 0.1494651734828949
test loss item: 0.2206718772649765
test loss item: 0.12246609479188919
test loss item: 0.22492358088493347
test loss item: 0.2336345762014389
test loss item: 0.672482430934906
test loss item: 0.05495627969503403
test loss item: 0.10188966244459152
test loss item: 0.42298424243927
test loss item: 0.32975906133651733
test loss item: 0.3054276704788208
test loss item: 0.5734308362007141
test loss item: 1.2373710870742798
test loss item: 0.3417346477508545
test loss item: 0.19262611865997314
test loss item: 0.22095000743865967
test loss item: 0.11060920357704163
test loss item: 0.24615293741226196
test loss item: 0.162190780043602
test loss item: 0.4062383472919464
test loss item: 0.27538222074508667
test loss item: 0.19620680809020996
test loss item: 0.16877561807632446
test loss item: 0.37737932801246643
test loss item: 0.5254551768302917
test loss item: 0.2229374498128891
test loss item: 0.09618707001209259
test loss item: 0.1817239373922348
test loss item: 0.11836712807416916
test loss item: 0.22815796732902527
test loss item: 0.7102126479148865
test loss item: 0.40823233127593994
test loss item: 0.19511078298091888
test loss item: 0.16988591849803925
test loss item: 0.14555415511131287
test loss item: 0.31475475430488586
test loss item: 0.1912877857685089
test loss item: 0.14641448855400085
test loss item: 0.15686045587062836
test loss item: 0.7321996092796326
test loss item: 0.22295081615447998
test loss item: 0.22758401930332184
test loss item: 0.17314237356185913
test loss item: 0.4132479727268219
test loss item: 0.2956990599632263
test loss item: 0.047592729330062866
test loss item: 0.7495969533920288
test loss item: 0.25165998935699463
test loss item: 0.2910129129886627
test loss item: 0.11562445759773254
test loss item: 0.10579948872327805
test loss item: 0.12555687129497528
test loss item: 1.350914716720581
test loss item: 0.3231842815876007
test loss item: 0.12149517238140106
test loss item: 0.0586911216378212
test loss item: 0.8090618848800659
test loss item: 0.6609313488006592
test loss item: 0.9097827672958374
test loss item: 0.16077838838100433
test loss item: 0.1593678891658783
test loss item: 0.055422697216272354
test loss item: 0.04925941675901413
test loss item: 0.09718966484069824
Epoch [60/100], Training Loss: 0.2480, Testing Loss: 0.3024
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 61/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2247646600008011
1
train loss item: 0.3771982192993164
2
train loss item: 0.1125817745923996
3
train loss item: 0.18906807899475098
4
train loss item: 0.16271717846393585
5
train loss item: 0.13414639234542847
6
train loss item: 0.09203989058732986
7
train loss item: 0.3450596332550049
8
train loss item: 0.06604253500699997
9
train loss item: 0.10814303904771805
10
train loss item: 0.12443304061889648
11
train loss item: 0.1293565034866333
12
train loss item: 0.08125907182693481
13
train loss item: 0.216053768992424
14
train loss item: 0.11447624862194061
15
train loss item: 0.24318882822990417
16
train loss item: 0.044293977320194244
17
train loss item: 0.10292349010705948
18
train loss item: 0.1324128359556198
19
train loss item: 0.10219010710716248
20
train loss item: 0.08995772153139114
21
train loss item: 0.07046518474817276
22
train loss item: 0.2610134780406952
23
train loss item: 0.2774468660354614
24
train loss item: 0.21039558947086334
25
train loss item: 0.09607450664043427
26
train loss item: 0.08482804894447327
27
train loss item: 0.10808294266462326
28
train loss item: 0.043925900012254715
29
train loss item: 0.25321418046951294
30
train loss item: 1.3077595233917236
31
train loss item: 0.1884000450372696
32
train loss item: 0.06297765672206879
33
train loss item: 0.1769300401210785
34
train loss item: 0.08162830024957657
35
train loss item: 1.7485491037368774
36
train loss item: 0.2176421731710434
37
train loss item: 0.2308182418346405
38
train loss item: 0.18717651069164276
39
train loss item: 0.11408688873052597
40
train loss item: 0.0898747518658638
41
train loss item: 0.12587127089500427
42
train loss item: 0.17455525696277618
43
train loss item: 0.08850814402103424
44
train loss item: 0.36564913392066956
45
train loss item: 0.07542695850133896
46
train loss item: 0.06498165428638458
47
train loss item: 0.15278564393520355
48
train loss item: 0.10181330889463425
49
train loss item: 0.07676846534013748
50
train loss item: 0.10747477412223816
51
train loss item: 0.41380101442337036
52
train loss item: 0.04678136855363846
53
train loss item: 0.07725688070058823
54
train loss item: 1.6260395050048828
55
train loss item: 0.09444398432970047
56
train loss item: 0.11613249778747559
57
train loss item: 0.12422369420528412
58
train loss item: 0.07899130135774612
59
train loss item: 0.07900815457105637
60
train loss item: 0.29507195949554443
61
train loss item: 1.4260787963867188
62
train loss item: 0.101761095225811
63
train loss item: 0.1618921458721161
64
train loss item: 0.08795082569122314
65
train loss item: 0.18724028766155243
66
train loss item: 0.18007689714431763
67
train loss item: 0.1057552620768547
68
train loss item: 0.1270398199558258
69
train loss item: 0.12987948954105377
70
train loss item: 0.11100273579359055
71
train loss item: 0.06747326254844666
72
train loss item: 0.08578699827194214
73
train loss item: 0.12707054615020752
74
train loss item: 0.05540783703327179
75
train loss item: 0.07244911789894104
76
train loss item: 0.27589577436447144
77
train loss item: 0.8039116263389587
78
train loss item: 0.04594198986887932
79
train loss item: 0.12373197078704834
80
train loss item: 0.06938206404447556
81
train loss item: 0.09200546145439148
82
train loss item: 0.09332432597875595
83
train loss item: 0.29503133893013
84
train loss item: 0.1912786215543747
85
train loss item: 0.1943211704492569
86
train loss item: 3.3542418479919434
87
train loss item: 0.09457511454820633
88
train loss item: 0.13559778034687042
epoch train loss: 0.24814928205830328
testing phase
test loss item: 0.12679754197597504
test loss item: 0.06866397708654404
test loss item: 0.351857453584671
test loss item: 0.15889325737953186
test loss item: 0.14817848801612854
test loss item: 0.08399160951375961
test loss item: 1.3256638050079346
test loss item: 0.40933218598365784
test loss item: 0.12864550948143005
test loss item: 0.2123243808746338
test loss item: 0.5514992475509644
test loss item: 0.10760989040136337
test loss item: 0.11882229149341583
test loss item: 0.20167675614356995
test loss item: 0.10151467472314835
test loss item: 0.05433519557118416
test loss item: 0.19576682150363922
test loss item: 0.2334730327129364
test loss item: 0.4356684386730194
test loss item: 0.18549668788909912
test loss item: 0.34756869077682495
test loss item: 0.2788192331790924
test loss item: 0.1778591126203537
test loss item: 0.12221268564462662
test loss item: 0.12903741002082825
test loss item: 0.1420900523662567
test loss item: 0.19119958579540253
test loss item: 0.11052890121936798
test loss item: 0.19266772270202637
test loss item: 0.19499985873699188
test loss item: 0.5563391447067261
test loss item: 0.05194932967424393
test loss item: 0.10191181302070618
test loss item: 0.3107371926307678
test loss item: 0.2260536104440689
test loss item: 0.2555713355541229
test loss item: 0.5377969741821289
test loss item: 0.9030575156211853
test loss item: 0.25781503319740295
test loss item: 0.1856481283903122
test loss item: 0.21432985365390778
test loss item: 0.10936325043439865
test loss item: 0.17056983709335327
test loss item: 0.15691974759101868
test loss item: 0.2680697441101074
test loss item: 0.2668141722679138
test loss item: 0.15895803272724152
test loss item: 0.16558797657489777
test loss item: 0.2849610149860382
test loss item: 0.4188028573989868
test loss item: 0.14810138940811157
test loss item: 0.09777293354272842
test loss item: 0.1578417271375656
test loss item: 0.11413238942623138
test loss item: 0.16129538416862488
test loss item: 0.4996896982192993
test loss item: 0.35708296298980713
test loss item: 0.1419224888086319
test loss item: 0.1538265198469162
test loss item: 0.11858891695737839
test loss item: 0.2171104997396469
test loss item: 0.1876317858695984
test loss item: 0.14403404295444489
test loss item: 0.14988599717617035
test loss item: 0.5494030714035034
test loss item: 0.2177392840385437
test loss item: 0.21021802723407745
test loss item: 0.16796350479125977
test loss item: 0.32019615173339844
test loss item: 0.27545133233070374
test loss item: 0.047539811581373215
test loss item: 0.726996660232544
test loss item: 0.20854967832565308
test loss item: 0.279212087392807
test loss item: 0.11210732161998749
test loss item: 0.10238127410411835
test loss item: 0.12404005229473114
test loss item: 0.9829009771347046
test loss item: 0.27039429545402527
test loss item: 0.11905229836702347
test loss item: 0.058281268924474716
test loss item: 0.6733902096748352
test loss item: 0.5854319334030151
test loss item: 0.6572006940841675
test loss item: 0.1485668569803238
test loss item: 0.14777213335037231
test loss item: 0.055018067359924316
test loss item: 0.048067424446344376
test loss item: 0.09551270306110382
Epoch [61/100], Training Loss: 0.2481, Testing Loss: 0.2530
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 62/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.230514794588089
1
train loss item: 0.3445321023464203
2
train loss item: 0.09471683949232101
3
train loss item: 0.20869013667106628
4
train loss item: 0.19299864768981934
5
train loss item: 0.1415669173002243
6
train loss item: 0.09356933832168579
7
train loss item: 0.3115238845348358
8
train loss item: 0.06268437206745148
9
train loss item: 0.11423667520284653
10
train loss item: 0.17292584478855133
11
train loss item: 0.1395801156759262
12
train loss item: 0.0833357572555542
13
train loss item: 0.24132223427295685
14
train loss item: 0.1072327047586441
15
train loss item: 0.23741669952869415
16
train loss item: 0.047094568610191345
17
train loss item: 0.10878441482782364
18
train loss item: 0.15750060975551605
19
train loss item: 0.10176222771406174
20
train loss item: 0.0934516191482544
21
train loss item: 0.07275334745645523
22
train loss item: 0.25717368721961975
23
train loss item: 0.26814159750938416
24
train loss item: 0.22364987432956696
25
train loss item: 0.11895758658647537
26
train loss item: 0.08791247010231018
27
train loss item: 0.10723498463630676
28
train loss item: 0.04530288279056549
29
train loss item: 0.2139611691236496
30
train loss item: 1.252404808998108
31
train loss item: 0.266419917345047
32
train loss item: 0.06108587607741356
33
train loss item: 0.1720229834318161
34
train loss item: 0.08379512280225754
35
train loss item: 1.727067470550537
36
train loss item: 0.2532038688659668
37
train loss item: 0.23600395023822784
38
train loss item: 0.23888300359249115
39
train loss item: 0.14669010043144226
40
train loss item: 0.09460633993148804
41
train loss item: 0.11079846322536469
42
train loss item: 0.1695767492055893
43
train loss item: 0.09611757099628448
44
train loss item: 0.3491336405277252
45
train loss item: 0.06714699417352676
46
train loss item: 0.06664824485778809
47
train loss item: 0.149989515542984
48
train loss item: 0.1003900021314621
49
train loss item: 0.08237753808498383
50
train loss item: 0.10619322210550308
51
train loss item: 0.3708004951477051
52
train loss item: 0.0530441552400589
53
train loss item: 0.08880864083766937
54
train loss item: 1.600229024887085
55
train loss item: 0.09112630039453506
56
train loss item: 0.1250622719526291
57
train loss item: 0.13289161026477814
58
train loss item: 0.08936819434165955
59
train loss item: 0.07929258793592453
60
train loss item: 0.23231585323810577
61
train loss item: 1.3741508722305298
62
train loss item: 0.10762732475996017
63
train loss item: 0.16638213396072388
64
train loss item: 0.08934561908245087
65
train loss item: 0.20875298976898193
66
train loss item: 0.21875634789466858
67
train loss item: 0.10570447146892548
68
train loss item: 0.1209263876080513
69
train loss item: 0.15647496283054352
70
train loss item: 0.11661867797374725
71
train loss item: 0.07309701293706894
72
train loss item: 0.09244021028280258
73
train loss item: 0.12485985457897186
74
train loss item: 0.055259037762880325
75
train loss item: 0.07236003130674362
76
train loss item: 0.26977232098579407
77
train loss item: 0.7706229090690613
78
train loss item: 0.052942775189876556
79
train loss item: 0.12843230366706848
80
train loss item: 0.07466968148946762
81
train loss item: 0.1013021320104599
82
train loss item: 0.08278296887874603
83
train loss item: 0.29422980546951294
84
train loss item: 0.21134623885154724
85
train loss item: 0.20540916919708252
86
train loss item: 3.3198840618133545
87
train loss item: 0.09196735173463821
88
train loss item: 0.163095623254776
epoch train loss: 0.24969927974966136
testing phase
test loss item: 0.12520748376846313
test loss item: 0.07497193664312363
test loss item: 0.5070469975471497
test loss item: 0.15787573158740997
test loss item: 0.18742439150810242
test loss item: 0.08678752183914185
test loss item: 1.4281378984451294
test loss item: 0.4411023259162903
test loss item: 0.1778450459241867
test loss item: 0.2919468283653259
test loss item: 0.7167234420776367
test loss item: 0.10837070643901825
test loss item: 0.13101208209991455
test loss item: 0.2066480964422226
test loss item: 0.12961749732494354
test loss item: 0.05700038745999336
test loss item: 0.19360418617725372
test loss item: 0.34713754057884216
test loss item: 0.45687055587768555
test loss item: 0.18761727213859558
test loss item: 0.5633192658424377
test loss item: 0.28524431586265564
test loss item: 0.22973929345607758
test loss item: 0.12191405147314072
test loss item: 0.14883118867874146
test loss item: 0.14675959944725037
test loss item: 0.21807043254375458
test loss item: 0.1267942637205124
test loss item: 0.2284923493862152
test loss item: 0.23473775386810303
test loss item: 0.6814998984336853
test loss item: 0.051531389355659485
test loss item: 0.10026951879262924
test loss item: 0.4303457736968994
test loss item: 0.3397218585014343
test loss item: 0.3125428557395935
test loss item: 0.5873917937278748
test loss item: 1.2335587739944458
test loss item: 0.3503504693508148
test loss item: 0.1928500533103943
test loss item: 0.2171584665775299
test loss item: 0.1041470319032669
test loss item: 0.2565954029560089
test loss item: 0.1565842628479004
test loss item: 0.42511895298957825
test loss item: 0.2687697112560272
test loss item: 0.19917826354503632
test loss item: 0.16282373666763306
test loss item: 0.3861018121242523
test loss item: 0.5281015038490295
test loss item: 0.23731520771980286
test loss item: 0.09277794510126114
test loss item: 0.18079395592212677
test loss item: 0.1128029003739357
test loss item: 0.2354222685098648
test loss item: 0.7143246531486511
test loss item: 0.41234859824180603
test loss item: 0.20971044898033142
test loss item: 0.16974541544914246
test loss item: 0.15154783427715302
test loss item: 0.3274780511856079
test loss item: 0.18542060256004333
test loss item: 0.14222216606140137
test loss item: 0.15641379356384277
test loss item: 0.7341738343238831
test loss item: 0.2169058471918106
test loss item: 0.22396771609783173
test loss item: 0.1716718226671219
test loss item: 0.41709104180336
test loss item: 0.30212658643722534
test loss item: 0.04976094514131546
test loss item: 0.7706145644187927
test loss item: 0.25463661551475525
test loss item: 0.28695738315582275
test loss item: 0.11034486442804337
test loss item: 0.10136212408542633
test loss item: 0.12446486204862595
test loss item: 1.3424761295318604
test loss item: 0.31988149881362915
test loss item: 0.1206565573811531
test loss item: 0.05745372548699379
test loss item: 0.8160586953163147
test loss item: 0.6758931875228882
test loss item: 0.9084660410881042
test loss item: 0.16162066161632538
test loss item: 0.15491265058517456
test loss item: 0.05327596887946129
test loss item: 0.04586934298276901
test loss item: 0.10069025307893753
Epoch [62/100], Training Loss: 0.2497, Testing Loss: 0.3051
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 63/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2252102643251419
1
train loss item: 0.3568485975265503
2
train loss item: 0.11670519411563873
3
train loss item: 0.19212724268436432
4
train loss item: 0.16791607439517975
5
train loss item: 0.13430358469486237
6
train loss item: 0.08693637698888779
7
train loss item: 0.33372026681900024
8
train loss item: 0.06863170862197876
9
train loss item: 0.1095537319779396
10
train loss item: 0.12401615083217621
11
train loss item: 0.1285693198442459
12
train loss item: 0.07797834277153015
13
train loss item: 0.21731717884540558
14
train loss item: 0.11484506726264954
15
train loss item: 0.23567889630794525
16
train loss item: 0.04651111736893654
17
train loss item: 0.10073352605104446
18
train loss item: 0.13147729635238647
19
train loss item: 0.09883727878332138
20
train loss item: 0.0846247673034668
21
train loss item: 0.07207360118627548
22
train loss item: 0.24335750937461853
23
train loss item: 0.2668555676937103
24
train loss item: 0.20258818566799164
25
train loss item: 0.10224609822034836
26
train loss item: 0.08727815747261047
27
train loss item: 0.11278578639030457
28
train loss item: 0.04672355577349663
29
train loss item: 0.25119465589523315
30
train loss item: 1.2772647142410278
31
train loss item: 0.18153510987758636
32
train loss item: 0.06519180536270142
33
train loss item: 0.18815098702907562
34
train loss item: 0.08326127380132675
35
train loss item: 1.724857211112976
36
train loss item: 0.21283738315105438
37
train loss item: 0.22389483451843262
38
train loss item: 0.19226782023906708
39
train loss item: 0.11407271772623062
40
train loss item: 0.08689242601394653
41
train loss item: 0.1309800148010254
42
train loss item: 0.1721314936876297
43
train loss item: 0.09104684740304947
44
train loss item: 0.3638205826282501
45
train loss item: 0.07802437245845795
46
train loss item: 0.06723663210868835
47
train loss item: 0.1491250842809677
48
train loss item: 0.10307803750038147
49
train loss item: 0.07827819138765335
50
train loss item: 0.10604405403137207
51
train loss item: 0.4112432897090912
52
train loss item: 0.046632904559373856
53
train loss item: 0.0811871737241745
54
train loss item: 1.6015390157699585
55
train loss item: 0.09249253571033478
56
train loss item: 0.1216239258646965
57
train loss item: 0.12135128676891327
58
train loss item: 0.07683321833610535
59
train loss item: 0.07892044633626938
60
train loss item: 0.29182615876197815
61
train loss item: 1.4019287824630737
62
train loss item: 0.10005304962396622
63
train loss item: 0.1600482314825058
64
train loss item: 0.09386717528104782
65
train loss item: 0.17919255793094635
66
train loss item: 0.17759716510772705
67
train loss item: 0.10712136328220367
68
train loss item: 0.12483810633420944
69
train loss item: 0.12625181674957275
70
train loss item: 0.10979500412940979
71
train loss item: 0.06704027950763702
72
train loss item: 0.09116846323013306
73
train loss item: 0.12463151663541794
74
train loss item: 0.05741921812295914
75
train loss item: 0.07485847920179367
76
train loss item: 0.26196879148483276
77
train loss item: 0.7882260680198669
78
train loss item: 0.04362141340970993
79
train loss item: 0.12434770166873932
80
train loss item: 0.07235150039196014
81
train loss item: 0.08672988414764404
82
train loss item: 0.09682688117027283
83
train loss item: 0.28505077958106995
84
train loss item: 0.18309542536735535
85
train loss item: 0.1919027864933014
86
train loss item: 3.3205301761627197
87
train loss item: 0.1005232185125351
88
train loss item: 0.13344497978687286
epoch train loss: 0.24534514006436542
testing phase
test loss item: 0.12281081080436707
test loss item: 0.07260020822286606
test loss item: 0.4494837522506714
test loss item: 0.1553671807050705
test loss item: 0.17297135293483734
test loss item: 0.08351520448923111
test loss item: 1.3952199220657349
test loss item: 0.429790198802948
test loss item: 0.14899858832359314
test loss item: 0.2493823915719986
test loss item: 0.6591706275939941
test loss item: 0.10534259676933289
test loss item: 0.12941332161426544
test loss item: 0.2047090083360672
test loss item: 0.11704058945178986
test loss item: 0.05652223899960518
test loss item: 0.19650904834270477
test loss item: 0.29777225852012634
test loss item: 0.44622185826301575
test loss item: 0.19275254011154175
test loss item: 0.4840514063835144
test loss item: 0.28249508142471313
test loss item: 0.2110559195280075
test loss item: 0.12288590520620346
test loss item: 0.1402692347764969
test loss item: 0.1453939527273178
test loss item: 0.2014339417219162
test loss item: 0.12099026888608932
test loss item: 0.21288533508777618
test loss item: 0.21196436882019043
test loss item: 0.6390065550804138
test loss item: 0.049690693616867065
test loss item: 0.1011669710278511
test loss item: 0.38371920585632324
test loss item: 0.29487308859825134
test loss item: 0.27789151668548584
test loss item: 0.5630690455436707
test loss item: 1.1292991638183594
test loss item: 0.31090593338012695
test loss item: 0.18676859140396118
test loss item: 0.21449601650238037
test loss item: 0.10809098929166794
test loss item: 0.20997965335845947
test loss item: 0.15598902106285095
test loss item: 0.3627301752567291
test loss item: 0.27258291840553284
test loss item: 0.18201468884944916
test loss item: 0.17286795377731323
test loss item: 0.3442991375923157
test loss item: 0.47762444615364075
test loss item: 0.18832330405712128
test loss item: 0.10152313858270645
test loss item: 0.16860567033290863
test loss item: 0.11057932674884796
test loss item: 0.20242145657539368
test loss item: 0.6377278566360474
test loss item: 0.39202404022216797
test loss item: 0.1715303361415863
test loss item: 0.16276060044765472
test loss item: 0.1319253295660019
test loss item: 0.2656712234020233
test loss item: 0.19193610548973083
test loss item: 0.14560499787330627
test loss item: 0.14977099001407623
test loss item: 0.6785821914672852
test loss item: 0.21249908208847046
test loss item: 0.22367607057094574
test loss item: 0.1692049652338028
test loss item: 0.38761788606643677
test loss item: 0.28631070256233215
test loss item: 0.0513552762567997
test loss item: 0.7549524903297424
test loss item: 0.2393122911453247
test loss item: 0.2856597900390625
test loss item: 0.11438349634408951
test loss item: 0.10291976481676102
test loss item: 0.1254437416791916
test loss item: 1.2550597190856934
test loss item: 0.3088253438472748
test loss item: 0.11993015557527542
test loss item: 0.05397558957338333
test loss item: 0.7675402164459229
test loss item: 0.6304888725280762
test loss item: 0.835318386554718
test loss item: 0.15845860540866852
test loss item: 0.15453511476516724
test loss item: 0.050729900598526
test loss item: 0.04429738223552704
test loss item: 0.09338806569576263
Epoch [63/100], Training Loss: 0.2453, Testing Loss: 0.2852
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 64/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2191929817199707
1
train loss item: 0.32133129239082336
2
train loss item: 0.0914226844906807
3
train loss item: 0.16738778352737427
4
train loss item: 0.1415078043937683
5
train loss item: 0.1361987143754959
6
train loss item: 0.09463662654161453
7
train loss item: 0.30452948808670044
8
train loss item: 0.05420137196779251
9
train loss item: 0.10218039900064468
10
train loss item: 0.12880000472068787
11
train loss item: 0.12821409106254578
12
train loss item: 0.08286932855844498
13
train loss item: 0.20633837580680847
14
train loss item: 0.10224547982215881
15
train loss item: 0.2315526157617569
16
train loss item: 0.04527030885219574
17
train loss item: 0.10182204842567444
18
train loss item: 0.13188500702381134
19
train loss item: 0.10437998920679092
20
train loss item: 0.09661801904439926
21
train loss item: 0.07061001658439636
22
train loss item: 0.24735771119594574
23
train loss item: 0.24160103499889374
24
train loss item: 0.21617335081100464
25
train loss item: 0.08712903410196304
26
train loss item: 0.0851995125412941
27
train loss item: 0.09084132313728333
28
train loss item: 0.043190885335206985
29
train loss item: 0.20916986465454102
30
train loss item: 1.2269656658172607
31
train loss item: 0.20430344343185425
32
train loss item: 0.05874175950884819
33
train loss item: 0.1251196712255478
34
train loss item: 0.0806463360786438
35
train loss item: 1.707092046737671
36
train loss item: 0.2201804369688034
37
train loss item: 0.21833312511444092
38
train loss item: 0.1829320341348648
39
train loss item: 0.11440815031528473
40
train loss item: 0.08893421292304993
41
train loss item: 0.10104398429393768
42
train loss item: 0.16963617503643036
43
train loss item: 0.08152540028095245
44
train loss item: 0.3393716812133789
45
train loss item: 0.06358737498521805
46
train loss item: 0.06072992831468582
47
train loss item: 0.14648863673210144
48
train loss item: 0.09172689914703369
49
train loss item: 0.07656189799308777
50
train loss item: 0.10876539349555969
51
train loss item: 0.3672102987766266
52
train loss item: 0.050565630197525024
53
train loss item: 0.06740763038396835
54
train loss item: 1.5808411836624146
55
train loss item: 0.08673806488513947
56
train loss item: 0.10648942738771439
57
train loss item: 0.1279512494802475
58
train loss item: 0.08027826249599457
59
train loss item: 0.07569411396980286
60
train loss item: 0.2372056543827057
61
train loss item: 1.359018087387085
62
train loss item: 0.09413375705480576
63
train loss item: 0.15808050334453583
64
train loss item: 0.07542858272790909
65
train loss item: 0.18501457571983337
66
train loss item: 0.19046276807785034
67
train loss item: 0.10013410449028015
68
train loss item: 0.1262456476688385
69
train loss item: 0.13829012215137482
70
train loss item: 0.10714296251535416
71
train loss item: 0.07358123362064362
72
train loss item: 0.07010497897863388
73
train loss item: 0.12102053314447403
74
train loss item: 0.053345937281847
75
train loss item: 0.06952478736639023
76
train loss item: 0.2391006052494049
77
train loss item: 0.7604283094406128
78
train loss item: 0.0517641045153141
79
train loss item: 0.11892867088317871
80
train loss item: 0.06362814456224442
81
train loss item: 0.09484706819057465
82
train loss item: 0.07488404214382172
83
train loss item: 0.28514617681503296
84
train loss item: 0.19020238518714905
85
train loss item: 0.17839154601097107
86
train loss item: 3.2914912700653076
87
train loss item: 0.07854009419679642
88
train loss item: 0.1419801115989685
epoch train loss: 0.2362044272797831
testing phase
test loss item: 0.12697699666023254
test loss item: 0.0702882781624794
test loss item: 0.4146401882171631
test loss item: 0.15762579441070557
test loss item: 0.15944413840770721
test loss item: 0.07958194613456726
test loss item: 1.3139903545379639
test loss item: 0.3669261634349823
test loss item: 0.14405079185962677
test loss item: 0.23403304815292358
test loss item: 0.6082688570022583
test loss item: 0.10632116347551346
test loss item: 0.11658541113138199
test loss item: 0.2010630965232849
test loss item: 0.11096242070198059
test loss item: 0.0563155859708786
test loss item: 0.18786509335041046
test loss item: 0.2762252986431122
test loss item: 0.40161681175231934
test loss item: 0.17503920197486877
test loss item: 0.435416579246521
test loss item: 0.2642959654331207
test loss item: 0.19767548143863678
test loss item: 0.11811080574989319
test loss item: 0.13736161589622498
test loss item: 0.1337357461452484
test loss item: 0.19195495545864105
test loss item: 0.11040344834327698
test loss item: 0.20175309479236603
test loss item: 0.1989971548318863
test loss item: 0.5899913907051086
test loss item: 0.050435785204172134
test loss item: 0.09922444075345993
test loss item: 0.3571036159992218
test loss item: 0.2715056836605072
test loss item: 0.2573609948158264
test loss item: 0.5168974995613098
test loss item: 1.0322898626327515
test loss item: 0.2915937900543213
test loss item: 0.178995743393898
test loss item: 0.209494486451149
test loss item: 0.11055350303649902
test loss item: 0.2024945318698883
test loss item: 0.15807338058948517
test loss item: 0.3299405872821808
test loss item: 0.24295595288276672
test loss item: 0.17314232885837555
test loss item: 0.1551353633403778
test loss item: 0.3158937394618988
test loss item: 0.43960607051849365
test loss item: 0.17796437442302704
test loss item: 0.09215211868286133
test loss item: 0.16477718949317932
test loss item: 0.12003850191831589
test loss item: 0.1879054456949234
test loss item: 0.5841532945632935
test loss item: 0.35206338763237
test loss item: 0.15983329713344574
test loss item: 0.1533658355474472
test loss item: 0.12589192390441895
test loss item: 0.25536030530929565
test loss item: 0.1711166501045227
test loss item: 0.13788045942783356
test loss item: 0.14320822060108185
test loss item: 0.6080470085144043
test loss item: 0.2167578786611557
test loss item: 0.2010594606399536
test loss item: 0.16230884194374084
test loss item: 0.3556390106678009
test loss item: 0.2504575848579407
test loss item: 0.04747384786605835
test loss item: 0.6914305686950684
test loss item: 0.2274724394083023
test loss item: 0.26961466670036316
test loss item: 0.11221279203891754
test loss item: 0.10545744746923447
test loss item: 0.11972489953041077
test loss item: 1.1307283639907837
test loss item: 0.28850963711738586
test loss item: 0.11658681929111481
test loss item: 0.05790744721889496
test loss item: 0.7021768093109131
test loss item: 0.5856077671051025
test loss item: 0.7550305128097534
test loss item: 0.14725154638290405
test loss item: 0.14884376525878906
test loss item: 0.05573325231671333
test loss item: 0.047955986112356186
test loss item: 0.09552992135286331
Epoch [64/100], Training Loss: 0.2362, Testing Loss: 0.2652
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Epoch 65/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.21686427295207977
1
train loss item: 0.3065861761569977
2
train loss item: 0.08973217010498047
3
train loss item: 0.1713283509016037
4
train loss item: 0.141904816031456
5
train loss item: 0.1302909255027771
6
train loss item: 0.08906792104244232
7
train loss item: 0.29106637835502625
8
train loss item: 0.05656159296631813
9
train loss item: 0.0946425050497055
10
train loss item: 0.13212406635284424
11
train loss item: 0.13149911165237427
12
train loss item: 0.082967109978199
13
train loss item: 0.2209155261516571
14
train loss item: 0.10397635400295258
15
train loss item: 0.21579694747924805
16
train loss item: 0.04406241327524185
17
train loss item: 0.10297372937202454
18
train loss item: 0.12717820703983307
19
train loss item: 0.09470196068286896
20
train loss item: 0.09290918707847595
21
train loss item: 0.07119332998991013
22
train loss item: 0.23192104697227478
23
train loss item: 0.24660128355026245
24
train loss item: 0.1980123519897461
25
train loss item: 0.09226002544164658
26
train loss item: 0.08652816712856293
27
train loss item: 0.08639858663082123
28
train loss item: 0.04295385256409645
29
train loss item: 0.2059222310781479
30
train loss item: 1.2104953527450562
31
train loss item: 0.21517302095890045
32
train loss item: 0.0612020418047905
33
train loss item: 0.1365126073360443
34
train loss item: 0.07997272163629532
35
train loss item: 1.69318687915802
36
train loss item: 0.23203939199447632
37
train loss item: 0.22182266414165497
38
train loss item: 0.20549799501895905
39
train loss item: 0.11229763180017471
40
train loss item: 0.0837957039475441
41
train loss item: 0.09924452751874924
42
train loss item: 0.16379785537719727
43
train loss item: 0.08133763819932938
44
train loss item: 0.3347910940647125
45
train loss item: 0.06592299789190292
46
train loss item: 0.060549959540367126
47
train loss item: 0.13868291676044464
48
train loss item: 0.08595016598701477
49
train loss item: 0.07233592122793198
50
train loss item: 0.09958900511264801
51
train loss item: 0.3579590320587158
52
train loss item: 0.0477236732840538
53
train loss item: 0.06587503105401993
54
train loss item: 1.56634521484375
55
train loss item: 0.08113039284944534
56
train loss item: 0.10345334559679031
57
train loss item: 0.11517333984375
58
train loss item: 0.07691624015569687
59
train loss item: 0.07295071333646774
60
train loss item: 0.22398172318935394
61
train loss item: 1.345902681350708
62
train loss item: 0.09380057454109192
63
train loss item: 0.1585083305835724
64
train loss item: 0.07588397711515427
65
train loss item: 0.19865159690380096
66
train loss item: 0.1880161464214325
67
train loss item: 0.09339255094528198
68
train loss item: 0.11632252484560013
69
train loss item: 0.14285166561603546
70
train loss item: 0.1083022952079773
71
train loss item: 0.06764431297779083
72
train loss item: 0.06884651631116867
73
train loss item: 0.1131989061832428
74
train loss item: 0.05394740775227547
75
train loss item: 0.06963535398244858
76
train loss item: 0.24002671241760254
77
train loss item: 0.7431679368019104
78
train loss item: 0.04960586503148079
79
train loss item: 0.1235145553946495
80
train loss item: 0.06382659822702408
81
train loss item: 0.08711784332990646
82
train loss item: 0.07580111175775528
83
train loss item: 0.28045549988746643
84
train loss item: 0.19243662059307098
85
train loss item: 0.17852242290973663
86
train loss item: 3.274545669555664
87
train loss item: 0.07714612782001495
88
train loss item: 0.13690033555030823
epoch train loss: 0.23351257905531464
testing phase
test loss item: 0.1274140328168869
test loss item: 0.0725252702832222
test loss item: 0.4725157916545868
test loss item: 0.1613224446773529
test loss item: 0.17609065771102905
test loss item: 0.082969069480896
test loss item: 1.584047794342041
test loss item: 0.5140764713287354
test loss item: 0.16305245459079742
test loss item: 0.2691613435745239
test loss item: 0.6696529388427734
test loss item: 0.11295421421527863
test loss item: 0.13617172837257385
test loss item: 0.21424779295921326
test loss item: 0.12204781919717789
test loss item: 0.05811038985848427
test loss item: 0.21452349424362183
test loss item: 0.31567588448524475
test loss item: 0.4987461566925049
test loss item: 0.2150355577468872
test loss item: 0.5119005441665649
test loss item: 0.3150183856487274
test loss item: 0.22889041900634766
test loss item: 0.13358275592327118
test loss item: 0.14405867457389832
test loss item: 0.1525932252407074
test loss item: 0.2190709412097931
test loss item: 0.12038931250572205
test loss item: 0.228395476937294
test loss item: 0.2229994237422943
test loss item: 0.6924846768379211
test loss item: 0.050007641315460205
test loss item: 0.10672856867313385
test loss item: 0.39927804470062256
test loss item: 0.3102303743362427
test loss item: 0.3007001280784607
test loss item: 0.6327320337295532
test loss item: 1.1420105695724487
test loss item: 0.33192014694213867
test loss item: 0.21042898297309875
test loss item: 0.23383797705173492
test loss item: 0.1172170341014862
test loss item: 0.2285429835319519
test loss item: 0.16994193196296692
test loss item: 0.38586872816085815
test loss item: 0.30685955286026
test loss item: 0.19671523571014404
test loss item: 0.18113107979297638
test loss item: 0.3720877766609192
test loss item: 0.51017826795578
test loss item: 0.20939257740974426
test loss item: 0.09725289046764374
test loss item: 0.17794157564640045
test loss item: 0.11466477066278458
test loss item: 0.21195439994335175
test loss item: 0.6531808972358704
test loss item: 0.42555657029151917
test loss item: 0.19142575562000275
test loss item: 0.174900084733963
test loss item: 0.13942481577396393
test loss item: 0.28932297229766846
test loss item: 0.2142120748758316
test loss item: 0.1608261615037918
test loss item: 0.1618192493915558
test loss item: 0.7138450741767883
test loss item: 0.21840916574001312
test loss item: 0.2453630119562149
test loss item: 0.1828579306602478
test loss item: 0.39260363578796387
test loss item: 0.3261044919490814
test loss item: 0.05035275220870972
test loss item: 0.8750828504562378
test loss item: 0.2579951882362366
test loss item: 0.3297140300273895
test loss item: 0.11791470646858215
test loss item: 0.11199358105659485
test loss item: 0.1358739584684372
test loss item: 1.256029725074768
test loss item: 0.32161834836006165
test loss item: 0.12303341180086136
test loss item: 0.056191641837358475
test loss item: 0.8276011943817139
test loss item: 0.703596830368042
test loss item: 0.8515476584434509
test loss item: 0.16953812539577484
test loss item: 0.1584850549697876
test loss item: 0.05205889418721199
test loss item: 0.04511115700006485
test loss item: 0.1000591516494751
Epoch [65/100], Training Loss: 0.2335, Testing Loss: 0.3054
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 66/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.21925769746303558
1
train loss item: 0.3156319558620453
2
train loss item: 0.10492981970310211
3
train loss item: 0.17729179561138153
4
train loss item: 0.1365494281053543
5
train loss item: 0.12643851339817047
6
train loss item: 0.09488464891910553
7
train loss item: 0.30201396346092224
8
train loss item: 0.056673936545848846
9
train loss item: 0.1128939688205719
10
train loss item: 0.11441688239574432
11
train loss item: 0.1192663386464119
12
train loss item: 0.07634744048118591
13
train loss item: 0.20179201662540436
14
train loss item: 0.10771849006414413
15
train loss item: 0.2642258405685425
16
train loss item: 0.045077696442604065
17
train loss item: 0.09907612204551697
18
train loss item: 0.13434579968452454
19
train loss item: 0.11370561271905899
20
train loss item: 0.10229160636663437
21
train loss item: 0.06500021368265152
22
train loss item: 0.23616044223308563
23
train loss item: 0.23125064373016357
24
train loss item: 0.21773383021354675
25
train loss item: 0.08957765996456146
26
train loss item: 0.08011078089475632
27
train loss item: 0.10003897547721863
28
train loss item: 0.043968647718429565
29
train loss item: 0.26002758741378784
30
train loss item: 1.2127375602722168
31
train loss item: 0.17426477372646332
32
train loss item: 0.055358003824949265
33
train loss item: 0.1512666940689087
34
train loss item: 0.07740604132413864
35
train loss item: 1.6855721473693848
36
train loss item: 0.20598991215229034
37
train loss item: 0.19914878904819489
38
train loss item: 0.19578908383846283
39
train loss item: 0.10633080452680588
40
train loss item: 0.08568108081817627
41
train loss item: 0.11576232314109802
42
train loss item: 0.17571860551834106
43
train loss item: 0.08385191857814789
44
train loss item: 0.3413722813129425
45
train loss item: 0.0687100738286972
46
train loss item: 0.06021406501531601
47
train loss item: 0.16538548469543457
48
train loss item: 0.10046583414077759
49
train loss item: 0.07161299139261246
50
train loss item: 0.12739986181259155
51
train loss item: 0.39924219250679016
52
train loss item: 0.04837988317012787
53
train loss item: 0.07243406772613525
54
train loss item: 1.560025691986084
55
train loss item: 0.09047963470220566
56
train loss item: 0.10658693313598633
57
train loss item: 0.12559352815151215
58
train loss item: 0.07774323970079422
59
train loss item: 0.0763404443860054
60
train loss item: 0.28157004714012146
61
train loss item: 1.3465291261672974
62
train loss item: 0.09413104504346848
63
train loss item: 0.1642693281173706
64
train loss item: 0.08071308583021164
65
train loss item: 0.16770631074905396
66
train loss item: 0.16908182203769684
67
train loss item: 0.10325803607702255
68
train loss item: 0.1547660529613495
69
train loss item: 0.12137547880411148
70
train loss item: 0.11713192611932755
71
train loss item: 0.07252300530672073
72
train loss item: 0.07669752836227417
73
train loss item: 0.12839120626449585
74
train loss item: 0.053671471774578094
75
train loss item: 0.0693272277712822
76
train loss item: 0.22893863916397095
77
train loss item: 0.7828343510627747
78
train loss item: 0.04402277618646622
79
train loss item: 0.12435149401426315
80
train loss item: 0.062044352293014526
81
train loss item: 0.0942625105381012
82
train loss item: 0.08373644202947617
83
train loss item: 0.26907879114151
84
train loss item: 0.1698339432477951
85
train loss item: 0.18293003737926483
86
train loss item: 3.260948896408081
87
train loss item: 0.08772608637809753
88
train loss item: 0.13454563915729523
epoch train loss: 0.23698830290624265
testing phase
test loss item: 0.11101208627223969
test loss item: 0.07387314736843109
test loss item: 0.42420274019241333
test loss item: 0.140377938747406
test loss item: 0.16683001816272736
test loss item: 0.07806558907032013
test loss item: 1.1218191385269165
test loss item: 0.2989361584186554
test loss item: 0.1420455276966095
test loss item: 0.2348756343126297
test loss item: 0.6159487366676331
test loss item: 0.0946606695652008
test loss item: 0.11495283991098404
test loss item: 0.1701013296842575
test loss item: 0.1142638549208641
test loss item: 0.05851642042398453
test loss item: 0.1555238664150238
test loss item: 0.283782958984375
test loss item: 0.35625433921813965
test loss item: 0.1478922963142395
test loss item: 0.45501723885536194
test loss item: 0.2237405627965927
test loss item: 0.1815059781074524
test loss item: 0.10205768048763275
test loss item: 0.12644925713539124
test loss item: 0.12640953063964844
test loss item: 0.17386497557163239
test loss item: 0.11610531806945801
test loss item: 0.19574841856956482
test loss item: 0.191196009516716
test loss item: 0.5496760606765747
test loss item: 0.04926968365907669
test loss item: 0.08724679052829742
test loss item: 0.36102551221847534
test loss item: 0.28185778856277466
test loss item: 0.24436578154563904
test loss item: 0.46359917521476746
test loss item: 1.0620694160461426
test loss item: 0.28902843594551086
test loss item: 0.15367363393306732
test loss item: 0.17896553874015808
test loss item: 0.08777885138988495
test loss item: 0.20333251357078552
test loss item: 0.12766872346401215
test loss item: 0.3432979881763458
test loss item: 0.212626650929451
test loss item: 0.16041775047779083
test loss item: 0.13031920790672302
test loss item: 0.31592440605163574
test loss item: 0.42210885882377625
test loss item: 0.18639256060123444
test loss item: 0.08380430936813354
test loss item: 0.15424641966819763
test loss item: 0.10033837705850601
test loss item: 0.19683922827243805
test loss item: 0.6014484167098999
test loss item: 0.3303834795951843
test loss item: 0.15877170860767365
test loss item: 0.13988207280635834
test loss item: 0.13474704325199127
test loss item: 0.2595095634460449
test loss item: 0.14218126237392426
test loss item: 0.11631587147712708
test loss item: 0.13471999764442444
test loss item: 0.6098377704620361
test loss item: 0.19686929881572723
test loss item: 0.17965056002140045
test loss item: 0.14552299678325653
test loss item: 0.36742690205574036
test loss item: 0.2099582701921463
test loss item: 0.05368690565228462
test loss item: 0.5759310722351074
test loss item: 0.2009762078523636
test loss item: 0.21499066054821014
test loss item: 0.0953473448753357
test loss item: 0.08408934623003006
test loss item: 0.10487893968820572
test loss item: 1.1739318370819092
test loss item: 0.2700456976890564
test loss item: 0.10800234228372574
test loss item: 0.050545088946819305
test loss item: 0.6604509949684143
test loss item: 0.5258119106292725
test loss item: 0.774840235710144
test loss item: 0.1333325207233429
test loss item: 0.13254065811634064
test loss item: 0.04880111292004585
test loss item: 0.043895334005355835
test loss item: 0.0860801711678505
Epoch [66/100], Training Loss: 0.2370, Testing Loss: 0.2506
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 67/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2175324559211731
1
train loss item: 0.3100908696651459
2
train loss item: 0.08591166883707047
3
train loss item: 0.19725669920444489
4
train loss item: 0.165580615401268
5
train loss item: 0.13687871396541595
6
train loss item: 0.0926111489534378
7
train loss item: 0.2742033004760742
8
train loss item: 0.05663706734776497
9
train loss item: 0.1035156324505806
10
train loss item: 0.1404939591884613
11
train loss item: 0.1382133662700653
12
train loss item: 0.08095455169677734
13
train loss item: 0.2206331491470337
14
train loss item: 0.10261024534702301
15
train loss item: 0.2476918250322342
16
train loss item: 0.04530898854136467
17
train loss item: 0.11556173115968704
18
train loss item: 0.13542801141738892
19
train loss item: 0.09760817140340805
20
train loss item: 0.09576290845870972
21
train loss item: 0.07487134635448456
22
train loss item: 0.26817771792411804
23
train loss item: 0.2410666048526764
24
train loss item: 0.2116132378578186
25
train loss item: 0.09610540419816971
26
train loss item: 0.09328754991292953
27
train loss item: 0.08550530672073364
28
train loss item: 0.0436287522315979
29
train loss item: 0.2220374196767807
30
train loss item: 1.1636662483215332
31
train loss item: 0.2278710901737213
32
train loss item: 0.05805063247680664
33
train loss item: 0.1299557238817215
34
train loss item: 0.0863456204533577
35
train loss item: 1.6662542819976807
36
train loss item: 0.2593662440776825
37
train loss item: 0.233933225274086
38
train loss item: 0.23327189683914185
39
train loss item: 0.11433467268943787
40
train loss item: 0.08146960288286209
41
train loss item: 0.09544733166694641
42
train loss item: 0.16050688922405243
43
train loss item: 0.08477640151977539
44
train loss item: 0.3274356722831726
45
train loss item: 0.06464755535125732
46
train loss item: 0.059940215200185776
47
train loss item: 0.15206021070480347
48
train loss item: 0.08491947501897812
49
train loss item: 0.07358027994632721
50
train loss item: 0.10081352293491364
51
train loss item: 0.3470514714717865
52
train loss item: 0.048044782131910324
53
train loss item: 0.06663178652524948
54
train loss item: 1.5376365184783936
55
train loss item: 0.07988794893026352
56
train loss item: 0.10911716520786285
57
train loss item: 0.11156228929758072
58
train loss item: 0.0788763165473938
59
train loss item: 0.07289740443229675
60
train loss item: 0.22213037312030792
61
train loss item: 1.3118958473205566
62
train loss item: 0.09944663941860199
63
train loss item: 0.18813824653625488
64
train loss item: 0.07641912996768951
65
train loss item: 0.25050145387649536
66
train loss item: 0.19486956298351288
67
train loss item: 0.09566321969032288
68
train loss item: 0.1330157369375229
69
train loss item: 0.1601899266242981
70
train loss item: 0.11451613903045654
71
train loss item: 0.06745896488428116
72
train loss item: 0.07059400528669357
73
train loss item: 0.1146208643913269
74
train loss item: 0.05215507373213768
75
train loss item: 0.07059212028980255
76
train loss item: 0.23872505128383636
77
train loss item: 0.7134365439414978
78
train loss item: 0.04916499927639961
79
train loss item: 0.14406663179397583
80
train loss item: 0.06457532197237015
81
train loss item: 0.09406690299510956
82
train loss item: 0.0736270472407341
83
train loss item: 0.29843828082084656
84
train loss item: 0.22786845266819
85
train loss item: 0.18722355365753174
86
train loss item: 3.235771656036377
87
train loss item: 0.0754716694355011
88
train loss item: 0.1479276418685913
epoch train loss: 0.23685058373748585
testing phase
test loss item: 0.12746912240982056
test loss item: 0.07074616849422455
test loss item: 0.4610983729362488
test loss item: 0.1604352593421936
test loss item: 0.17042359709739685
test loss item: 0.08055673539638519
test loss item: 1.4737648963928223
test loss item: 0.49179112911224365
test loss item: 0.15836332738399506
test loss item: 0.25897353887557983
test loss item: 0.6575953364372253
test loss item: 0.11064383387565613
test loss item: 0.13562120497226715
test loss item: 0.21431325376033783
test loss item: 0.11745477467775345
test loss item: 0.058423787355422974
test loss item: 0.21748225390911102
test loss item: 0.3028879165649414
test loss item: 0.4855252504348755
test loss item: 0.2188745141029358
test loss item: 0.48601099848747253
test loss item: 0.30848047137260437
test loss item: 0.22038085758686066
test loss item: 0.13172760605812073
test loss item: 0.14345595240592957
test loss item: 0.15190774202346802
test loss item: 0.21839329600334167
test loss item: 0.11638234555721283
test loss item: 0.22132658958435059
test loss item: 0.21882697939872742
test loss item: 0.6583800315856934
test loss item: 0.05011121928691864
test loss item: 0.10713870823383331
test loss item: 0.38347721099853516
test loss item: 0.2994135320186615
test loss item: 0.29778915643692017
test loss item: 0.6029021143913269
test loss item: 1.12169349193573
test loss item: 0.31829163432121277
test loss item: 0.20289379358291626
test loss item: 0.22816118597984314
test loss item: 0.11620862036943436
test loss item: 0.21416907012462616
test loss item: 0.17024943232536316
test loss item: 0.366609126329422
test loss item: 0.311203271150589
test loss item: 0.18972375988960266
test loss item: 0.18875396251678467
test loss item: 0.3629150092601776
test loss item: 0.49757516384124756
test loss item: 0.19348137080669403
test loss item: 0.10428287833929062
test loss item: 0.17667068541049957
test loss item: 0.11797517538070679
test loss item: 0.2027597576379776
test loss item: 0.6371924877166748
test loss item: 0.41461214423179626
test loss item: 0.1756799817085266
test loss item: 0.17481648921966553
test loss item: 0.1312619149684906
test loss item: 0.2709549367427826
test loss item: 0.22021017968654633
test loss item: 0.16071631014347076
test loss item: 0.15707480907440186
test loss item: 0.699315071105957
test loss item: 0.21702228486537933
test loss item: 0.2471025586128235
test loss item: 0.17786575853824615
test loss item: 0.3807082176208496
test loss item: 0.3242563307285309
test loss item: 0.04824650660157204
test loss item: 0.8233990669250488
test loss item: 0.25037479400634766
test loss item: 0.31988316774368286
test loss item: 0.12309755384922028
test loss item: 0.11126731336116791
test loss item: 0.13281090557575226
test loss item: 1.2348744869232178
test loss item: 0.3202178180217743
test loss item: 0.12147116661071777
test loss item: 0.056308481842279434
test loss item: 0.7941755056381226
test loss item: 0.6641839146614075
test loss item: 0.835747241973877
test loss item: 0.1680784821510315
test loss item: 0.1630273163318634
test loss item: 0.05419183522462845
test loss item: 0.04748755693435669
test loss item: 0.09222477674484253
Epoch [67/100], Training Loss: 0.2369, Testing Loss: 0.2969
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7072.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7072.00 MB
Epoch 68/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.21330446004867554
1
train loss item: 0.29384875297546387
2
train loss item: 0.09480278939008713
3
train loss item: 0.16861863434314728
4
train loss item: 0.1296340823173523
5
train loss item: 0.12292826920747757
6
train loss item: 0.09845756739377975
7
train loss item: 0.2882048189640045
8
train loss item: 0.053331632167100906
9
train loss item: 0.10567639023065567
10
train loss item: 0.11156141012907028
11
train loss item: 0.11319263279438019
12
train loss item: 0.08217723667621613
13
train loss item: 0.19013237953186035
14
train loss item: 0.1011677086353302
15
train loss item: 0.24424968659877777
16
train loss item: 0.043857142329216
17
train loss item: 0.09907514601945877
18
train loss item: 0.1309821605682373
19
train loss item: 0.10677793622016907
20
train loss item: 0.10163846611976624
21
train loss item: 0.06414160132408142
22
train loss item: 0.23071777820587158
23
train loss item: 0.21399058401584625
24
train loss item: 0.2179916948080063
25
train loss item: 0.08287250995635986
26
train loss item: 0.07891126722097397
27
train loss item: 0.09343117475509644
28
train loss item: 0.04152214154601097
29
train loss item: 0.2396850883960724
30
train loss item: 1.17244553565979
31
train loss item: 0.16911010444164276
32
train loss item: 0.05303482338786125
33
train loss item: 0.1292996108531952
34
train loss item: 0.07570821046829224
35
train loss item: 1.6602747440338135
36
train loss item: 0.19662371277809143
37
train loss item: 0.19014692306518555
38
train loss item: 0.1799475997686386
39
train loss item: 0.10689777135848999
40
train loss item: 0.08490945398807526
41
train loss item: 0.10730013996362686
42
train loss item: 0.1703312247991562
43
train loss item: 0.08157925307750702
44
train loss item: 0.3327445387840271
45
train loss item: 0.06300702691078186
46
train loss item: 0.0565757229924202
47
train loss item: 0.1520068347454071
48
train loss item: 0.09558185189962387
49
train loss item: 0.06898405402898788
50
train loss item: 0.11893312633037567
51
train loss item: 0.37264755368232727
52
train loss item: 0.04902394488453865
53
train loss item: 0.06645604968070984
54
train loss item: 1.5345871448516846
55
train loss item: 0.08600270003080368
56
train loss item: 0.0982440784573555
57
train loss item: 0.12208148092031479
58
train loss item: 0.08137001842260361
59
train loss item: 0.07193849980831146
60
train loss item: 0.25954893231391907
61
train loss item: 1.3143084049224854
62
train loss item: 0.09295758605003357
63
train loss item: 0.15139354765415192
64
train loss item: 0.07347118109464645
65
train loss item: 0.16526617109775543
66
train loss item: 0.16403314471244812
67
train loss item: 0.10065619647502899
68
train loss item: 0.14448094367980957
69
train loss item: 0.11876115202903748
70
train loss item: 0.11023375391960144
71
train loss item: 0.070960633456707
72
train loss item: 0.07051212340593338
73
train loss item: 0.12311679869890213
74
train loss item: 0.05035196244716644
75
train loss item: 0.06570468842983246
76
train loss item: 0.2154306322336197
77
train loss item: 0.7649715542793274
78
train loss item: 0.04818563163280487
79
train loss item: 0.11412432044744492
80
train loss item: 0.05877815559506416
81
train loss item: 0.09010016173124313
82
train loss item: 0.07474926859140396
83
train loss item: 0.2551748752593994
84
train loss item: 0.15923111140727997
85
train loss item: 0.17667824029922485
86
train loss item: 3.2229862213134766
87
train loss item: 0.08001808077096939
88
train loss item: 0.13238996267318726
epoch train loss: 0.22891294734364145
testing phase
test loss item: 0.12296673655509949
test loss item: 0.07160826027393341
test loss item: 0.4569091498851776
test loss item: 0.1544826775789261
test loss item: 0.16850174963474274
test loss item: 0.07908626645803452
test loss item: 1.4061980247497559
test loss item: 0.4102920889854431
test loss item: 0.1593465954065323
test loss item: 0.2574460804462433
test loss item: 0.6631160378456116
test loss item: 0.10454217344522476
test loss item: 0.11795302480459213
test loss item: 0.19747449457645416
test loss item: 0.11727721989154816
test loss item: 0.05672862380743027
test loss item: 0.19196926057338715
test loss item: 0.3027523159980774
test loss item: 0.4371703565120697
test loss item: 0.1812310665845871
test loss item: 0.4783242344856262
test loss item: 0.2771044373512268
test loss item: 0.20249180495738983
test loss item: 0.11973075568675995
test loss item: 0.13946469128131866
test loss item: 0.13914766907691956
test loss item: 0.20318534970283508
test loss item: 0.11369523406028748
test loss item: 0.2151821404695511
test loss item: 0.21099895238876343
test loss item: 0.6428709626197815
test loss item: 0.04857365041971207
test loss item: 0.09867451339960098
test loss item: 0.3831581473350525
test loss item: 0.29998302459716797
test loss item: 0.2812148928642273
test loss item: 0.5602347254753113
test loss item: 1.1331864595413208
test loss item: 0.31640538573265076
test loss item: 0.18858590722084045
test loss item: 0.21515204012393951
test loss item: 0.10579115897417068
test loss item: 0.22157709300518036
test loss item: 0.15817728638648987
test loss item: 0.36370357871055603
test loss item: 0.26131951808929443
test loss item: 0.1775948852300644
test loss item: 0.15458793938159943
test loss item: 0.3469673991203308
test loss item: 0.4843408465385437
test loss item: 0.19854669272899628
test loss item: 0.0867650955915451
test loss item: 0.17248769104480743
test loss item: 0.11350148171186447
test loss item: 0.20621155202388763
test loss item: 0.6441630721092224
test loss item: 0.3802427053451538
test loss item: 0.1694183051586151
test loss item: 0.15798993408679962
test loss item: 0.13450025022029877
test loss item: 0.28297147154808044
test loss item: 0.17935767769813538
test loss item: 0.1402537077665329
test loss item: 0.14953412115573883
test loss item: 0.6732825636863708
test loss item: 0.21276718378067017
test loss item: 0.21097496151924133
test loss item: 0.16875533759593964
test loss item: 0.37728220224380493
test loss item: 0.2830635905265808
test loss item: 0.049379974603652954
test loss item: 0.7546271085739136
test loss item: 0.2263578176498413
test loss item: 0.281389445066452
test loss item: 0.10810349136590958
test loss item: 0.10062235593795776
test loss item: 0.12188756465911865
test loss item: 1.2334387302398682
test loss item: 0.3026604950428009
test loss item: 0.11567967385053635
test loss item: 0.05571291968226433
test loss item: 0.7655909061431885
test loss item: 0.6349461078643799
test loss item: 0.8336799740791321
test loss item: 0.1537407487630844
test loss item: 0.14697575569152832
test loss item: 0.05327129364013672
test loss item: 0.0463101752102375
test loss item: 0.09409482777118683
Epoch [68/100], Training Loss: 0.2289, Testing Loss: 0.2834
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7014.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7014.00 MB
Epoch 69/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.20887796580791473
1
train loss item: 0.26940327882766724
2
train loss item: 0.09321999549865723
3
train loss item: 0.15818096697330475
4
train loss item: 0.1373140811920166
5
train loss item: 0.12447682023048401
6
train loss item: 0.08651793748140335
7
train loss item: 0.26899147033691406
8
train loss item: 0.05985386669635773
9
train loss item: 0.09185145050287247
10
train loss item: 0.11763737350702286
11
train loss item: 0.12466900795698166
12
train loss item: 0.07657988369464874
13
train loss item: 0.20637147128582
14
train loss item: 0.10251626372337341
15
train loss item: 0.20626118779182434
16
train loss item: 0.04409316927194595
17
train loss item: 0.09713642299175262
18
train loss item: 0.11673092097043991
19
train loss item: 0.09001822024583817
20
train loss item: 0.08371395617723465
21
train loss item: 0.07327775657176971
22
train loss item: 0.21508392691612244
23
train loss item: 0.22292475402355194
24
train loss item: 0.18821413815021515
25
train loss item: 0.09053412824869156
26
train loss item: 0.08413385599851608
27
train loss item: 0.08846879750490189
28
train loss item: 0.04425179213285446
29
train loss item: 0.215020552277565
30
train loss item: 1.149674892425537
31
train loss item: 0.18447767198085785
32
train loss item: 0.06454432755708694
33
train loss item: 0.14030075073242188
34
train loss item: 0.08110715448856354
35
train loss item: 1.6444673538208008
36
train loss item: 0.22012881934642792
37
train loss item: 0.20074127614498138
38
train loss item: 0.17821168899536133
39
train loss item: 0.10216386616230011
40
train loss item: 0.07794687896966934
41
train loss item: 0.10463118553161621
42
train loss item: 0.1613931506872177
43
train loss item: 0.08131445199251175
44
train loss item: 0.32651522755622864
45
train loss item: 0.0707075297832489
46
train loss item: 0.06409837305545807
47
train loss item: 0.1312856525182724
48
train loss item: 0.08715458959341049
49
train loss item: 0.07173687219619751
50
train loss item: 0.0971735492348671
51
train loss item: 0.35525500774383545
52
train loss item: 0.047049231827259064
53
train loss item: 0.0658722072839737
54
train loss item: 1.5178899765014648
55
train loss item: 0.08015838265419006
56
train loss item: 0.10507385432720184
57
train loss item: 0.10877636075019836
58
train loss item: 0.07322259992361069
59
train loss item: 0.07360394299030304
60
train loss item: 0.22643354535102844
61
train loss item: 1.2958372831344604
62
train loss item: 0.08843942731618881
63
train loss item: 0.14422409236431122
64
train loss item: 0.08003051578998566
65
train loss item: 0.17046932876110077
66
train loss item: 0.17356327176094055
67
train loss item: 0.09199395030736923
68
train loss item: 0.11202260106801987
69
train loss item: 0.12234175950288773
70
train loss item: 0.10149919986724854
71
train loss item: 0.06429678201675415
72
train loss item: 0.07135888189077377
73
train loss item: 0.1109820157289505
74
train loss item: 0.05434521660208702
75
train loss item: 0.06825442612171173
76
train loss item: 0.21319153904914856
77
train loss item: 0.7387908101081848
78
train loss item: 0.04339629411697388
79
train loss item: 0.11399231851100922
80
train loss item: 0.06649646162986755
81
train loss item: 0.08006250113248825
82
train loss item: 0.07629565894603729
83
train loss item: 0.2554014027118683
84
train loss item: 0.17404767870903015
85
train loss item: 0.16927538812160492
86
train loss item: 3.2031149864196777
87
train loss item: 0.0783771201968193
88
train loss item: 0.1223180890083313
epoch train loss: 0.22431297512369208
testing phase
test loss item: 0.11424741894006729
test loss item: 0.07891237735748291
test loss item: 0.39864617586135864
test loss item: 0.14589367806911469
test loss item: 0.1612744927406311
test loss item: 0.07948030531406403
test loss item: 1.3156182765960693
test loss item: 0.4024300277233124
test loss item: 0.13863641023635864
test loss item: 0.22682751715183258
test loss item: 0.5864438414573669
test loss item: 0.10175277292728424
test loss item: 0.12390033155679703
test loss item: 0.18502166867256165
test loss item: 0.11233104020357132
test loss item: 0.07743131369352341
test loss item: 0.1824827939271927
test loss item: 0.26488080620765686
test loss item: 0.42507195472717285
test loss item: 0.1817341148853302
test loss item: 0.4216373860836029
test loss item: 0.26685768365859985
test loss item: 0.186512291431427
test loss item: 0.11619120836257935
test loss item: 0.12491937726736069
test loss item: 0.13792107999324799
test loss item: 0.18654045462608337
test loss item: 0.11472529172897339
test loss item: 0.20292429625988007
test loss item: 0.19282004237174988
test loss item: 0.577078104019165
test loss item: 0.07009007036685944
test loss item: 0.09567315131425858
test loss item: 0.34012314677238464
test loss item: 0.26262545585632324
test loss item: 0.25751999020576477
test loss item: 0.5325060486793518
test loss item: 0.990047812461853
test loss item: 0.28012746572494507
test loss item: 0.1782543808221817
test loss item: 0.20442718267440796
test loss item: 0.10009261965751648
test loss item: 0.18821270763874054
test loss item: 0.1445264369249344
test loss item: 0.32055339217185974
test loss item: 0.2645374834537506
test loss item: 0.1634054332971573
test loss item: 0.15906164050102234
test loss item: 0.3134244680404663
test loss item: 0.43057340383529663
test loss item: 0.1726016104221344
test loss item: 0.0927470400929451
test loss item: 0.15652507543563843
test loss item: 0.10153677314519882
test loss item: 0.18222244083881378
test loss item: 0.5583204030990601
test loss item: 0.35651448369026184
test loss item: 0.15394723415374756
test loss item: 0.1516522914171219
test loss item: 0.12872090935707092
test loss item: 0.23954389989376068
test loss item: 0.18334653973579407
test loss item: 0.1371833086013794
test loss item: 0.1469893902540207
test loss item: 0.6037704944610596
test loss item: 0.20070570707321167
test loss item: 0.20817959308624268
test loss item: 0.1631162464618683
test loss item: 0.3473745584487915
test loss item: 0.26976388692855835
test loss item: 0.06571175158023834
test loss item: 0.718366801738739
test loss item: 0.20955310761928558
test loss item: 0.2677033543586731
test loss item: 0.10296522080898285
test loss item: 0.09392458945512772
test loss item: 0.11976364254951477
test loss item: 1.0903338193893433
test loss item: 0.27617117762565613
test loss item: 0.11226817220449448
test loss item: 0.05411510542035103
test loss item: 0.6929894089698792
test loss item: 0.5831541419029236
test loss item: 0.7298476099967957
test loss item: 0.14631612598896027
test loss item: 0.1395646631717682
test loss item: 0.05796436592936516
test loss item: 0.06461279094219208
test loss item: 0.09369951486587524
Epoch [69/100], Training Loss: 0.2243, Testing Loss: 0.2618
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 70/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.21033403277397156
1
train loss item: 0.2618832290172577
2
train loss item: 0.08769509941339493
3
train loss item: 0.18227018415927887
4
train loss item: 0.1573779284954071
5
train loss item: 0.13071008026599884
6
train loss item: 0.08841587603092194
7
train loss item: 0.2557638883590698
8
train loss item: 0.056463174521923065
9
train loss item: 0.10392305254936218
10
train loss item: 0.14869225025177002
11
train loss item: 0.12613092362880707
12
train loss item: 0.07890170812606812
13
train loss item: 0.2073841542005539
14
train loss item: 0.09826387465000153
15
train loss item: 0.20897600054740906
16
train loss item: 0.04712401330471039
17
train loss item: 0.09748020768165588
18
train loss item: 0.13777019083499908
19
train loss item: 0.09322528541088104
20
train loss item: 0.08837223052978516
21
train loss item: 0.0703289583325386
22
train loss item: 0.22646033763885498
23
train loss item: 0.22319148480892181
24
train loss item: 0.20482544600963593
25
train loss item: 0.09524589031934738
26
train loss item: 0.0838141143321991
27
train loss item: 0.09239466488361359
28
train loss item: 0.04443931207060814
29
train loss item: 0.1855519711971283
30
train loss item: 1.1066112518310547
31
train loss item: 0.22616957128047943
32
train loss item: 0.055739179253578186
33
train loss item: 0.1252831369638443
34
train loss item: 0.07528101652860641
35
train loss item: 1.6286181211471558
36
train loss item: 0.23400896787643433
37
train loss item: 0.203139990568161
38
train loss item: 0.19218093156814575
39
train loss item: 0.11790129542350769
40
train loss item: 0.08160170912742615
41
train loss item: 0.0988500565290451
42
train loss item: 0.16175024211406708
43
train loss item: 0.08665984123945236
44
train loss item: 0.3155546486377716
45
train loss item: 0.061723578721284866
46
train loss item: 0.06159805878996849
47
train loss item: 0.13530533015727997
48
train loss item: 0.08942069858312607
49
train loss item: 0.0786205381155014
50
train loss item: 0.100069560110569
51
train loss item: 0.33316728472709656
52
train loss item: 0.051752787083387375
53
train loss item: 0.07168598473072052
54
train loss item: 1.49973464012146
55
train loss item: 0.0819130465388298
56
train loss item: 0.11865803599357605
57
train loss item: 0.12085261195898056
58
train loss item: 0.08336073905229568
59
train loss item: 0.07360587269067764
60
train loss item: 0.19755691289901733
61
train loss item: 1.2592471837997437
62
train loss item: 0.09117672592401505
63
train loss item: 0.15050458908081055
64
train loss item: 0.0805678591132164
65
train loss item: 0.17294438183307648
66
train loss item: 0.19373752176761627
67
train loss item: 0.0941980630159378
68
train loss item: 0.11450681835412979
69
train loss item: 0.1357148438692093
70
train loss item: 0.09984074532985687
71
train loss item: 0.07085538655519485
72
train loss item: 0.07920282334089279
73
train loss item: 0.11150775104761124
74
train loss item: 0.05171261355280876
75
train loss item: 0.06831622123718262
76
train loss item: 0.21252934634685516
77
train loss item: 0.717639148235321
78
train loss item: 0.04963263124227524
79
train loss item: 0.11479756981134415
80
train loss item: 0.06551387161016464
81
train loss item: 0.09106575697660446
82
train loss item: 0.07577568292617798
83
train loss item: 0.26826685667037964
84
train loss item: 0.19037319719791412
85
train loss item: 0.18780270218849182
86
train loss item: 3.1770987510681152
87
train loss item: 0.07777609676122665
88
train loss item: 0.13373760879039764
epoch train loss: 0.22581829159949604
testing phase
test loss item: 0.11965204030275345
test loss item: 0.10765071213245392
test loss item: 0.5491332411766052
test loss item: 0.15097495913505554
test loss item: 0.19624356925487518
test loss item: 0.09237085282802582
test loss item: 1.3965870141983032
test loss item: 0.4186166822910309
test loss item: 0.18845300376415253
test loss item: 0.30491048097610474
test loss item: 0.7597982883453369
test loss item: 0.11269059777259827
test loss item: 0.13077646493911743
test loss item: 0.1990460455417633
test loss item: 0.1436598300933838
test loss item: 0.16150818765163422
test loss item: 0.18850070238113403
test loss item: 0.37159547209739685
test loss item: 0.43700939416885376
test loss item: 0.18312430381774902
test loss item: 0.6139559745788574
test loss item: 0.27688443660736084
test loss item: 0.23618507385253906
test loss item: 0.1188606321811676
test loss item: 0.15808933973312378
test loss item: 0.14230380952358246
test loss item: 0.21746067702770233
test loss item: 0.1288640946149826
test loss item: 0.23637264966964722
test loss item: 0.23560374975204468
test loss item: 0.70331209897995
test loss item: 0.15479058027267456
test loss item: 0.09834187477827072
test loss item: 0.4527432918548584
test loss item: 0.3779188394546509
test loss item: 0.3103671371936798
test loss item: 0.5736010074615479
test loss item: 1.3287835121154785
test loss item: 0.371586412191391
test loss item: 0.1878686547279358
test loss item: 0.22620809078216553
test loss item: 0.1009276807308197
test loss item: 0.27022454142570496
test loss item: 0.15427599847316742
test loss item: 0.4651596248149872
test loss item: 0.28154870867729187
test loss item: 0.2058095633983612
test loss item: 0.15350668132305145
test loss item: 0.40956827998161316
test loss item: 0.5456821322441101
test loss item: 0.25301361083984375
test loss item: 0.09806637465953827
test loss item: 0.18519680202007294
test loss item: 0.11054345965385437
test loss item: 0.25154629349708557
test loss item: 0.7691823840141296
test loss item: 0.41072988510131836
test loss item: 0.219635009765625
test loss item: 0.1771559715270996
test loss item: 0.1538863182067871
test loss item: 0.346119225025177
test loss item: 0.2026856392621994
test loss item: 0.1394471377134323
test loss item: 0.15174388885498047
test loss item: 0.7893882989883423
test loss item: 0.2071753740310669
test loss item: 0.22514425218105316
test loss item: 0.16618062555789948
test loss item: 0.44551143050193787
test loss item: 0.2860390245914459
test loss item: 0.11320029199123383
test loss item: 0.7494063973426819
test loss item: 0.25987207889556885
test loss item: 0.2801579535007477
test loss item: 0.10609270632266998
test loss item: 0.09864315390586853
test loss item: 0.1292281150817871
test loss item: 1.455285906791687
test loss item: 0.3354875147342682
test loss item: 0.11782822757959366
test loss item: 0.08083829283714294
test loss item: 0.8396192193031311
test loss item: 0.6700149178504944
test loss item: 0.9866687655448914
test loss item: 0.15965062379837036
test loss item: 0.15158772468566895
test loss item: 0.12165504693984985
test loss item: 0.17067447304725647
test loss item: 0.09624293446540833
Epoch [70/100], Training Loss: 0.2258, Testing Loss: 0.3198
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 71/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.21683369576931
1
train loss item: 0.2683984041213989
2
train loss item: 0.11158762872219086
3
train loss item: 0.1914099156856537
4
train loss item: 0.15921658277511597
5
train loss item: 0.12524628639221191
6
train loss item: 0.07901952415704727
7
train loss item: 0.2854655385017395
8
train loss item: 0.0674201250076294
9
train loss item: 0.11077161133289337
10
train loss item: 0.11968918889760971
11
train loss item: 0.11375986784696579
12
train loss item: 0.07518269121646881
13
train loss item: 0.20223478972911835
14
train loss item: 0.11224745213985443
15
train loss item: 0.2080257683992386
16
train loss item: 0.040997330099344254
17
train loss item: 0.08874162286520004
18
train loss item: 0.12629637122154236
19
train loss item: 0.08943504095077515
20
train loss item: 0.07985440641641617
21
train loss item: 0.06517992913722992
22
train loss item: 0.21389921009540558
23
train loss item: 0.21811163425445557
24
train loss item: 0.18874000012874603
25
train loss item: 0.10479388386011124
26
train loss item: 0.08105228841304779
27
train loss item: 0.11658535152673721
28
train loss item: 0.03952699154615402
29
train loss item: 0.2348189800977707
30
train loss item: 1.1388822793960571
31
train loss item: 0.1658412367105484
32
train loss item: 0.06577698886394501
33
train loss item: 0.1859634816646576
34
train loss item: 0.07890347391366959
35
train loss item: 1.6260688304901123
36
train loss item: 0.20976419746875763
37
train loss item: 0.19313736259937286
38
train loss item: 0.20310725271701813
39
train loss item: 0.11640463024377823
40
train loss item: 0.08403558284044266
41
train loss item: 0.13176071643829346
42
train loss item: 0.16178622841835022
43
train loss item: 0.08822233229875565
44
train loss item: 0.34842678904533386
45
train loss item: 0.07758079469203949
46
train loss item: 0.06650181114673615
47
train loss item: 0.13452117145061493
48
train loss item: 0.10255355387926102
49
train loss item: 0.07485102117061615
50
train loss item: 0.0967668741941452
51
train loss item: 0.37325406074523926
52
train loss item: 0.047093331813812256
53
train loss item: 0.08623656630516052
54
train loss item: 1.5012024641036987
55
train loss item: 0.08808325231075287
56
train loss item: 0.11625026911497116
57
train loss item: 0.11256254464387894
58
train loss item: 0.07565637677907944
59
train loss item: 0.07433544099330902
60
train loss item: 0.257220059633255
61
train loss item: 1.290650486946106
62
train loss item: 0.09767626225948334
63
train loss item: 0.14090688526630402
64
train loss item: 0.08900496363639832
65
train loss item: 0.15829439461231232
66
train loss item: 0.16785022616386414
67
train loss item: 0.10380499064922333
68
train loss item: 0.11890438944101334
69
train loss item: 0.11689356714487076
70
train loss item: 0.1041703149676323
71
train loss item: 0.06296911835670471
72
train loss item: 0.09562552720308304
73
train loss item: 0.11708255112171173
74
train loss item: 0.04912637546658516
75
train loss item: 0.06803150475025177
76
train loss item: 0.2141033560037613
77
train loss item: 0.7348300814628601
78
train loss item: 0.04321938008069992
79
train loss item: 0.11293523013591766
80
train loss item: 0.07465879619121552
81
train loss item: 0.08037158846855164
82
train loss item: 0.09581687301397324
83
train loss item: 0.25161483883857727
84
train loss item: 0.1628565937280655
85
train loss item: 0.18744923174381256
86
train loss item: 3.178636312484741
87
train loss item: 0.10234952718019485
88
train loss item: 0.12742234766483307
epoch train loss: 0.2288151550828741
testing phase
test loss item: 0.12098541855812073
test loss item: 0.06969909369945526
test loss item: 0.42215263843536377
test loss item: 0.1534760296344757
test loss item: 0.15967637300491333
test loss item: 0.07588358223438263
test loss item: 1.40485417842865
test loss item: 0.4370553493499756
test loss item: 0.14504669606685638
test loss item: 0.2377658635377884
test loss item: 0.6238706707954407
test loss item: 0.10253160446882248
test loss item: 0.12245511263608932
test loss item: 0.19392457604408264
test loss item: 0.11123073101043701
test loss item: 0.05667719617486
test loss item: 0.1987377256155014
test loss item: 0.2783454954624176
test loss item: 0.4457933306694031
test loss item: 0.18974730372428894
test loss item: 0.4435109794139862
test loss item: 0.28600212931632996
test loss item: 0.19450443983078003
test loss item: 0.12214568257331848
test loss item: 0.13617916405200958
test loss item: 0.13942459225654602
test loss item: 0.1971217542886734
test loss item: 0.10952897369861603
test loss item: 0.20786231756210327
test loss item: 0.20355024933815002
test loss item: 0.6227705478668213
test loss item: 0.04760220646858215
test loss item: 0.10067445784807205
test loss item: 0.3571949601173401
test loss item: 0.2756648361682892
test loss item: 0.2685016393661499
test loss item: 0.5623963475227356
test loss item: 1.058026909828186
test loss item: 0.29803088307380676
test loss item: 0.18836595118045807
test loss item: 0.21601539850234985
test loss item: 0.10935515910387039
test loss item: 0.19844135642051697
test loss item: 0.16146166622638702
test loss item: 0.33911165595054626
test loss item: 0.27417024970054626
test loss item: 0.1731264889240265
test loss item: 0.16379299759864807
test loss item: 0.3296239972114563
test loss item: 0.4611281156539917
test loss item: 0.1792881339788437
test loss item: 0.09570597857236862
test loss item: 0.1669028401374817
test loss item: 0.11419510096311569
test loss item: 0.18812011182308197
test loss item: 0.593251645565033
test loss item: 0.3785122334957123
test loss item: 0.16066712141036987
test loss item: 0.16122862696647644
test loss item: 0.12269752472639084
test loss item: 0.25216543674468994
test loss item: 0.19714953005313873
test loss item: 0.1462683379650116
test loss item: 0.14682359993457794
test loss item: 0.6428236365318298
test loss item: 0.20930027961730957
test loss item: 0.21988199651241302
test loss item: 0.1677291989326477
test loss item: 0.35556674003601074
test loss item: 0.2857147753238678
test loss item: 0.047833360731601715
test loss item: 0.7699768543243408
test loss item: 0.22164739668369293
test loss item: 0.2905006408691406
test loss item: 0.11124561727046967
test loss item: 0.10317107290029526
test loss item: 0.12360895425081253
test loss item: 1.1643346548080444
test loss item: 0.2929047644138336
test loss item: 0.1145111471414566
test loss item: 0.05466870963573456
test loss item: 0.7430689930915833
test loss item: 0.6239263415336609
test loss item: 0.7846086025238037
test loss item: 0.1510971486568451
test loss item: 0.1481640487909317
test loss item: 0.05394638702273369
test loss item: 0.047402456402778625
test loss item: 0.0903453379869461
Epoch [71/100], Training Loss: 0.2288, Testing Loss: 0.2755
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 72/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.20286300778388977
1
train loss item: 0.24118342995643616
2
train loss item: 0.0836973786354065
3
train loss item: 0.16415299475193024
4
train loss item: 0.122965969145298
5
train loss item: 0.1218615397810936
6
train loss item: 0.08285608142614365
7
train loss item: 0.2439473420381546
8
train loss item: 0.050552066415548325
9
train loss item: 0.09144949167966843
10
train loss item: 0.12562814354896545
11
train loss item: 0.11541279405355453
12
train loss item: 0.07898874580860138
13
train loss item: 0.19354982674121857
14
train loss item: 0.09450207650661469
15
train loss item: 0.1954295039176941
16
train loss item: 0.04265657067298889
17
train loss item: 0.08925072103738785
18
train loss item: 0.12430401891469955
19
train loss item: 0.0890493169426918
20
train loss item: 0.08534205704927444
21
train loss item: 0.06433593481779099
22
train loss item: 0.21084505319595337
23
train loss item: 0.21267493069171906
24
train loss item: 0.18845321238040924
25
train loss item: 0.0846245139837265
26
train loss item: 0.07761447876691818
27
train loss item: 0.08260485529899597
28
train loss item: 0.0404231995344162
29
train loss item: 0.17875410616397858
30
train loss item: 1.0725477933883667
31
train loss item: 0.19672685861587524
32
train loss item: 0.054241131991147995
33
train loss item: 0.11168757826089859
34
train loss item: 0.07315129041671753
35
train loss item: 1.6027988195419312
36
train loss item: 0.21761608123779297
37
train loss item: 0.19185879826545715
38
train loss item: 0.1727088987827301
39
train loss item: 0.1061534434556961
40
train loss item: 0.07683823257684708
41
train loss item: 0.09301337599754333
42
train loss item: 0.15756672620773315
43
train loss item: 0.07740113139152527
44
train loss item: 0.30782970786094666
45
train loss item: 0.06264355033636093
46
train loss item: 0.056004513055086136
47
train loss item: 0.1315804421901703
48
train loss item: 0.082562156021595
49
train loss item: 0.06932982057332993
50
train loss item: 0.0981161966919899
51
train loss item: 0.3288615942001343
52
train loss item: 0.04880470409989357
53
train loss item: 0.06338781118392944
54
train loss item: 1.4731978178024292
55
train loss item: 0.07601513713598251
56
train loss item: 0.10205817967653275
57
train loss item: 0.11238452792167664
58
train loss item: 0.07755978405475616
59
train loss item: 0.0690634697675705
60
train loss item: 0.1954883188009262
61
train loss item: 1.2302454710006714
62
train loss item: 0.08573073148727417
63
train loss item: 0.1395176649093628
64
train loss item: 0.06997412443161011
65
train loss item: 0.158169224858284
66
train loss item: 0.17670594155788422
67
train loss item: 0.08951587229967117
68
train loss item: 0.11815250664949417
69
train loss item: 0.12240415811538696
70
train loss item: 0.09684542566537857
71
train loss item: 0.0648602619767189
72
train loss item: 0.06510050594806671
73
train loss item: 0.105533167719841
74
train loss item: 0.049857135862112045
75
train loss item: 0.06408599764108658
76
train loss item: 0.19817546010017395
77
train loss item: 0.7133656144142151
78
train loss item: 0.04669314622879028
79
train loss item: 0.10570134967565536
80
train loss item: 0.05907681584358215
81
train loss item: 0.08338292688131332
82
train loss item: 0.06745783984661102
83
train loss item: 0.2581910192966461
84
train loss item: 0.17125017940998077
85
train loss item: 0.17327100038528442
86
train loss item: 3.1395339965820312
87
train loss item: 0.071563720703125
88
train loss item: 0.12460434436798096
epoch train loss: 0.21559704333711205
testing phase
test loss item: 0.11575716733932495
test loss item: 0.0701378583908081
test loss item: 0.3902434706687927
test loss item: 0.14581362903118134
test loss item: 0.15287533402442932
test loss item: 0.07300484925508499
test loss item: 1.3188120126724243
test loss item: 0.3882245421409607
test loss item: 0.14010627567768097
test loss item: 0.22653888165950775
test loss item: 0.578974723815918
test loss item: 0.09791887551546097
test loss item: 0.11257665604352951
test loss item: 0.18578574061393738
test loss item: 0.10734723508358002
test loss item: 0.05819731205701828
test loss item: 0.1795417219400406
test loss item: 0.2617674767971039
test loss item: 0.4078480899333954
test loss item: 0.17011448740959167
test loss item: 0.40714675188064575
test loss item: 0.26263439655303955
test loss item: 0.17935241758823395
test loss item: 0.11288554966449738
test loss item: 0.12585316598415375
test loss item: 0.13109643757343292
test loss item: 0.1838318258523941
test loss item: 0.10593545436859131
test loss item: 0.19961535930633545
test loss item: 0.1909654289484024
test loss item: 0.5776516795158386
test loss item: 0.04746799170970917
test loss item: 0.09299108386039734
test loss item: 0.3337956666946411
test loss item: 0.25739872455596924
test loss item: 0.2523505389690399
test loss item: 0.5223086476325989
test loss item: 0.972255527973175
test loss item: 0.28063395619392395
test loss item: 0.1769436001777649
test loss item: 0.2027691751718521
test loss item: 0.10307428240776062
test loss item: 0.1907069981098175
test loss item: 0.14882919192314148
test loss item: 0.3153391480445862
test loss item: 0.24555233120918274
test loss item: 0.1613273322582245
test loss item: 0.14497511088848114
test loss item: 0.30564653873443604
test loss item: 0.42863619327545166
test loss item: 0.175675168633461
test loss item: 0.0838421955704689
test loss item: 0.15916600823402405
test loss item: 0.10745776444673538
test loss item: 0.1808798611164093
test loss item: 0.5494995713233948
test loss item: 0.3446129858493805
test loss item: 0.15155023336410522
test loss item: 0.14751821756362915
test loss item: 0.12441524118185043
test loss item: 0.24612174928188324
test loss item: 0.1723516583442688
test loss item: 0.13412490487098694
test loss item: 0.14023253321647644
test loss item: 0.5801180005073547
test loss item: 0.2012118548154831
test loss item: 0.19754458963871002
test loss item: 0.15890350937843323
test loss item: 0.3316420912742615
test loss item: 0.2556142210960388
test loss item: 0.049520641565322876
test loss item: 0.7105534672737122
test loss item: 0.20640935003757477
test loss item: 0.26656171679496765
test loss item: 0.10033189505338669
test loss item: 0.09656599164009094
test loss item: 0.11542271822690964
test loss item: 1.055601716041565
test loss item: 0.27021729946136475
test loss item: 0.10894400626420975
test loss item: 0.05184027925133705
test loss item: 0.6832663416862488
test loss item: 0.5836207270622253
test loss item: 0.7146473526954651
test loss item: 0.1416441798210144
test loss item: 0.1355120837688446
test loss item: 0.050531066954135895
test loss item: 0.04592301696538925
test loss item: 0.08899535983800888
Epoch [72/100], Training Loss: 0.2156, Testing Loss: 0.2557
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 73/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.20498958230018616
1
train loss item: 0.24121160805225372
2
train loss item: 0.08247637748718262
3
train loss item: 0.16492362320423126
4
train loss item: 0.12387281656265259
5
train loss item: 0.1243382915854454
6
train loss item: 0.07989191263914108
7
train loss item: 0.2299443781375885
8
train loss item: 0.052079301327466965
9
train loss item: 0.08842206746339798
10
train loss item: 0.12438205629587173
11
train loss item: 0.11970965564250946
12
train loss item: 0.07296119630336761
13
train loss item: 0.2019270956516266
14
train loss item: 0.09308235347270966
15
train loss item: 0.1864781379699707
16
train loss item: 0.04103061184287071
17
train loss item: 0.09073420614004135
18
train loss item: 0.1203077882528305
19
train loss item: 0.08383471518754959
20
train loss item: 0.07916711270809174
21
train loss item: 0.06430938094854355
22
train loss item: 0.21031194925308228
23
train loss item: 0.21835316717624664
24
train loss item: 0.1783219575881958
25
train loss item: 0.08882448822259903
26
train loss item: 0.07902412116527557
27
train loss item: 0.08258897066116333
28
train loss item: 0.03993384912610054
29
train loss item: 0.17453643679618835
30
train loss item: 1.0519708395004272
31
train loss item: 0.19717516005039215
32
train loss item: 0.05672916769981384
33
train loss item: 0.12092737853527069
34
train loss item: 0.07486897706985474
35
train loss item: 1.5846236944198608
36
train loss item: 0.22063030302524567
37
train loss item: 0.19411544501781464
38
train loss item: 0.18078020215034485
39
train loss item: 0.10565498471260071
40
train loss item: 0.0725570023059845
41
train loss item: 0.09261444956064224
42
train loss item: 0.15642686188220978
43
train loss item: 0.07574422657489777
44
train loss item: 0.30300676822662354
45
train loss item: 0.06496790051460266
46
train loss item: 0.05910971015691757
47
train loss item: 0.1246415227651596
48
train loss item: 0.08143039047718048
49
train loss item: 0.06779737025499344
50
train loss item: 0.09055628627538681
51
train loss item: 0.32250070571899414
52
train loss item: 0.04520811140537262
53
train loss item: 0.06450539827346802
54
train loss item: 1.4544415473937988
55
train loss item: 0.07425332069396973
56
train loss item: 0.10190856456756592
57
train loss item: 0.11003853380680084
58
train loss item: 0.0705331489443779
59
train loss item: 0.07111244648694992
60
train loss item: 0.18750989437103271
61
train loss item: 1.21378493309021
62
train loss item: 0.08407570421695709
63
train loss item: 0.14091798663139343
64
train loss item: 0.07177217304706573
65
train loss item: 0.16830256581306458
66
train loss item: 0.17189869284629822
67
train loss item: 0.08698410540819168
68
train loss item: 0.10705304890871048
69
train loss item: 0.12614275515079498
70
train loss item: 0.09498319774866104
71
train loss item: 0.06225327029824257
72
train loss item: 0.0657883882522583
73
train loss item: 0.10079748928546906
74
train loss item: 0.051122140139341354
75
train loss item: 0.06451849639415741
76
train loss item: 0.20387069880962372
77
train loss item: 0.6959318518638611
78
train loss item: 0.04281501844525337
79
train loss item: 0.11142434924840927
80
train loss item: 0.061231374740600586
81
train loss item: 0.08048368990421295
82
train loss item: 0.06801507622003555
83
train loss item: 0.25459370017051697
84
train loss item: 0.1698211133480072
85
train loss item: 0.167373925447464
86
train loss item: 3.115769863128662
87
train loss item: 0.07171130925416946
88
train loss item: 0.12406355142593384
epoch train loss: 0.21345853922742136
testing phase
test loss item: 0.11703623086214066
test loss item: 0.1465976983308792
test loss item: 0.5110951662063599
test loss item: 0.14847755432128906
test loss item: 0.18560604751110077
test loss item: 0.12010210752487183
test loss item: 1.464431881904602
test loss item: 0.4674176871776581
test loss item: 0.17720183730125427
test loss item: 0.28729090094566345
test loss item: 0.7291566729545593
test loss item: 0.14283080399036407
test loss item: 0.12902593612670898
test loss item: 0.20306259393692017
test loss item: 0.1599961668252945
test loss item: 0.24417458474636078
test loss item: 0.19526568055152893
test loss item: 0.34124571084976196
test loss item: 0.46333277225494385
test loss item: 0.1927846372127533
test loss item: 0.5530213713645935
test loss item: 0.2900071144104004
test loss item: 0.22102589905261993
test loss item: 0.12120870500802994
test loss item: 0.17304570972919464
test loss item: 0.1485588103532791
test loss item: 0.21411481499671936
test loss item: 0.12463028728961945
test loss item: 0.2318567931652069
test loss item: 0.22711774706840515
test loss item: 0.7012817859649658
test loss item: 0.23544804751873016
test loss item: 0.09678219258785248
test loss item: 0.4213310480117798
test loss item: 0.3648616671562195
test loss item: 0.30652689933776855
test loss item: 0.5966289043426514
test loss item: 1.2620301246643066
test loss item: 0.35283058881759644
test loss item: 0.1944061815738678
test loss item: 0.2522211968898773
test loss item: 0.10584557056427002
test loss item: 0.24619996547698975
test loss item: 0.15728525817394257
test loss item: 0.42272883653640747
test loss item: 0.31735071539878845
test loss item: 0.19183139503002167
test loss item: 0.16045068204402924
test loss item: 0.38912951946258545
test loss item: 0.53521728515625
test loss item: 0.23063898086547852
test loss item: 0.12779773771762848
test loss item: 0.1827407032251358
test loss item: 0.1089111790060997
test loss item: 0.23345500230789185
test loss item: 0.7193322777748108
test loss item: 0.4181665778160095
test loss item: 0.19175709784030914
test loss item: 0.19151078164577484
test loss item: 0.1474684774875641
test loss item: 0.3300154507160187
test loss item: 0.2353500872850418
test loss item: 0.14590226113796234
test loss item: 0.15245665609836578
test loss item: 0.7519291639328003
test loss item: 0.2038758248090744
test loss item: 0.23192322254180908
test loss item: 0.17115262150764465
test loss item: 0.43335261940956116
test loss item: 0.30630794167518616
test loss item: 0.16465607285499573
test loss item: 0.807135820388794
test loss item: 0.2450629025697708
test loss item: 0.2968977391719818
test loss item: 0.1063840463757515
test loss item: 0.09858036786317825
test loss item: 0.15887902677059174
test loss item: 1.380662441253662
test loss item: 0.32741862535476685
test loss item: 0.116912342607975
test loss item: 0.13111266493797302
test loss item: 0.8371967077255249
test loss item: 0.682310938835144
test loss item: 0.9403693675994873
test loss item: 0.16461296379566193
test loss item: 0.15165230631828308
test loss item: 0.17322935163974762
test loss item: 0.25399187207221985
test loss item: 0.1034734696149826
Epoch [73/100], Training Loss: 0.2135, Testing Loss: 0.3224
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 74/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2071899175643921
1
train loss item: 0.24451281130313873
2
train loss item: 0.09648357331752777
3
train loss item: 0.18079476058483124
4
train loss item: 0.13634605705738068
5
train loss item: 0.1189010813832283
6
train loss item: 0.08317141979932785
7
train loss item: 0.25413551926612854
8
train loss item: 0.057931460440158844
9
train loss item: 0.10639918595552444
10
train loss item: 0.10742931813001633
11
train loss item: 0.10456424951553345
12
train loss item: 0.07191474735736847
13
train loss item: 0.18223480880260468
14
train loss item: 0.09832103550434113
15
train loss item: 0.21506017446517944
16
train loss item: 0.042016007006168365
17
train loss item: 0.08916004002094269
18
train loss item: 0.12457774579524994
19
train loss item: 0.09360044449567795
20
train loss item: 0.0888824462890625
21
train loss item: 0.06077159568667412
22
train loss item: 0.19979174435138702
23
train loss item: 0.19384580850601196
24
train loss item: 0.18859024345874786
25
train loss item: 0.08667508512735367
26
train loss item: 0.07482485473155975
27
train loss item: 0.10042917728424072
28
train loss item: 0.04012718051671982
29
train loss item: 0.22844068706035614
30
train loss item: 1.074291467666626
31
train loss item: 0.1512899398803711
32
train loss item: 0.05576048046350479
33
train loss item: 0.15107308328151703
34
train loss item: 0.07152827084064484
35
train loss item: 1.578049659729004
36
train loss item: 0.1921471804380417
37
train loss item: 0.17372719943523407
38
train loss item: 0.19081181287765503
39
train loss item: 0.10483691841363907
40
train loss item: 0.07522919774055481
41
train loss item: 0.11879997700452805
42
train loss item: 0.16223765909671783
43
train loss item: 0.07923992723226547
44
train loss item: 0.3267519474029541
45
train loss item: 0.06731536239385605
46
train loss item: 0.056144244968891144
47
train loss item: 0.13744086027145386
48
train loss item: 0.09548305720090866
49
train loss item: 0.066511370241642
50
train loss item: 0.10537742078304291
51
train loss item: 0.365183562040329
52
train loss item: 0.04569745063781738
53
train loss item: 0.07155392318964005
54
train loss item: 1.4507551193237305
55
train loss item: 0.08118098229169846
56
train loss item: 0.10153980553150177
57
train loss item: 0.11629842966794968
58
train loss item: 0.07191058248281479
59
train loss item: 0.07258270680904388
60
train loss item: 0.24674953520298004
61
train loss item: 1.2309207916259766
62
train loss item: 0.08845886588096619
63
train loss item: 0.13930673897266388
64
train loss item: 0.07674590498209
65
train loss item: 0.14993585646152496
66
train loss item: 0.15231740474700928
67
train loss item: 0.09646093845367432
68
train loss item: 0.13041265308856964
69
train loss item: 0.1093493327498436
70
train loss item: 0.10138027369976044
71
train loss item: 0.0635000616312027
72
train loss item: 0.0794014260172844
73
train loss item: 0.11508048325777054
74
train loss item: 0.048187244683504105
75
train loss item: 0.06465929001569748
76
train loss item: 0.19451136887073517
77
train loss item: 0.7307834625244141
78
train loss item: 0.042776186019182205
79
train loss item: 0.10800168663263321
80
train loss item: 0.060174282640218735
81
train loss item: 0.08217722177505493
82
train loss item: 0.0793241336941719
83
train loss item: 0.23402740061283112
84
train loss item: 0.1452474743127823
85
train loss item: 0.17614655196666718
86
train loss item: 3.10357928276062
87
train loss item: 0.08671633154153824
88
train loss item: 0.11727292835712433
epoch train loss: 0.21731997632913375
testing phase
test loss item: 0.1125212162733078
test loss item: 0.07071473449468613
test loss item: 0.4106152653694153
test loss item: 0.14288964867591858
test loss item: 0.15813550353050232
test loss item: 0.07462622970342636
test loss item: 1.257926106452942
test loss item: 0.37112465500831604
test loss item: 0.13868500292301178
test loss item: 0.2271854281425476
test loss item: 0.6206139326095581
test loss item: 0.09564641118049622
test loss item: 0.1097283661365509
test loss item: 0.18089747428894043
test loss item: 0.10836813598871231
test loss item: 0.06090922653675079
test loss item: 0.1733197569847107
test loss item: 0.26879507303237915
test loss item: 0.3964671194553375
test loss item: 0.16187816858291626
test loss item: 0.4250679314136505
test loss item: 0.2518030107021332
test loss item: 0.17559637129306793
test loss item: 0.10974270105361938
test loss item: 0.1299944519996643
test loss item: 0.12828126549720764
test loss item: 0.17968864738941193
test loss item: 0.10959654301404953
test loss item: 0.19551029801368713
test loss item: 0.19080235064029694
test loss item: 0.5873720049858093
test loss item: 0.052272263914346695
test loss item: 0.09221998602151871
test loss item: 0.3465607464313507
test loss item: 0.26993194222450256
test loss item: 0.2509326636791229
test loss item: 0.5056986808776855
test loss item: 1.0605542659759521
test loss item: 0.2879546582698822
test loss item: 0.16948427259922028
test loss item: 0.19691002368927002
test loss item: 0.09283013641834259
test loss item: 0.1896933615207672
test loss item: 0.14425621926784515
test loss item: 0.3270750641822815
test loss item: 0.23576800525188446
test loss item: 0.15439265966415405
test loss item: 0.14339295029640198
test loss item: 0.3110869824886322
test loss item: 0.43898800015449524
test loss item: 0.17112869024276733
test loss item: 0.08626653254032135
test loss item: 0.15803474187850952
test loss item: 0.10673285275697708
test loss item: 0.18437789380550385
test loss item: 0.5877410173416138
test loss item: 0.3506796360015869
test loss item: 0.14205026626586914
test loss item: 0.14413318037986755
test loss item: 0.120390884578228
test loss item: 0.24424785375595093
test loss item: 0.16742241382598877
test loss item: 0.12661316990852356
test loss item: 0.135665163397789
test loss item: 0.6154312491416931
test loss item: 0.19763238728046417
test loss item: 0.19266468286514282
test loss item: 0.15373310446739197
test loss item: 0.3527500033378601
test loss item: 0.25003206729888916
test loss item: 0.04975815489888191
test loss item: 0.6727312803268433
test loss item: 0.19484932720661163
test loss item: 0.24708330631256104
test loss item: 0.0981999933719635
test loss item: 0.08827278017997742
test loss item: 0.11266352981328964
test loss item: 1.1700360774993896
test loss item: 0.2800259292125702
test loss item: 0.10758596658706665
test loss item: 0.05448846146464348
test loss item: 0.6997681260108948
test loss item: 0.5682321786880493
test loss item: 0.7814034223556519
test loss item: 0.14015239477157593
test loss item: 0.13339167833328247
test loss item: 0.05532004311680794
test loss item: 0.05282769352197647
test loss item: 0.0849044993519783
Epoch [74/100], Training Loss: 0.2173, Testing Loss: 0.2581
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 75/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.2011813223361969
1
train loss item: 0.25146201252937317
2
train loss item: 0.07983648031949997
3
train loss item: 0.1639828085899353
4
train loss item: 0.14071619510650635
5
train loss item: 0.12841421365737915
6
train loss item: 0.08266305178403854
7
train loss item: 0.2290123552083969
8
train loss item: 0.0535614937543869
9
train loss item: 0.09276936203241348
10
train loss item: 0.12656551599502563
11
train loss item: 0.12370873242616653
12
train loss item: 0.07603679597377777
13
train loss item: 0.1916424185037613
14
train loss item: 0.0980292558670044
15
train loss item: 0.20383989810943604
16
train loss item: 0.0433536134660244
17
train loss item: 0.09775800257921219
18
train loss item: 0.12275109440088272
19
train loss item: 0.086983822286129
20
train loss item: 0.08435969799757004
21
train loss item: 0.06657557189464569
22
train loss item: 0.2325209379196167
23
train loss item: 0.21110014617443085
24
train loss item: 0.18537920713424683
25
train loss item: 0.09095412492752075
26
train loss item: 0.08321160823106766
27
train loss item: 0.0822339877486229
28
train loss item: 0.041355010122060776
29
train loss item: 0.18004503846168518
30
train loss item: 1.0049514770507812
31
train loss item: 0.18985615670681
32
train loss item: 0.05627348646521568
33
train loss item: 0.11333859711885452
34
train loss item: 0.07632984966039658
35
train loss item: 1.5527886152267456
36
train loss item: 0.22370029985904694
37
train loss item: 0.1941012293100357
38
train loss item: 0.16844671964645386
39
train loss item: 0.11009339988231659
40
train loss item: 0.0758700892329216
41
train loss item: 0.08887415379285812
42
train loss item: 0.1512281447649002
43
train loss item: 0.08018965274095535
44
train loss item: 0.30104848742485046
45
train loss item: 0.061237089335918427
46
train loss item: 0.058449383825063705
47
train loss item: 0.12944892048835754
48
train loss item: 0.08147358149290085
49
train loss item: 0.07005494832992554
50
train loss item: 0.09060992300510406
51
train loss item: 0.3076801300048828
52
train loss item: 0.04725499078631401
53
train loss item: 0.06674187630414963
54
train loss item: 1.4214767217636108
55
train loss item: 0.0777621641755104
56
train loss item: 0.10172828286886215
57
train loss item: 0.10999784618616104
58
train loss item: 0.07666225731372833
59
train loss item: 0.06817464530467987
60
train loss item: 0.1918691247701645
61
train loss item: 1.1788157224655151
62
train loss item: 0.08885166049003601
63
train loss item: 0.14744669198989868
64
train loss item: 0.07182945311069489
65
train loss item: 0.18525391817092896
66
train loss item: 0.17387980222702026
67
train loss item: 0.08918961882591248
68
train loss item: 0.11111786961555481
69
train loss item: 0.13950560986995697
70
train loss item: 0.09728815406560898
71
train loss item: 0.06385309249162674
72
train loss item: 0.0674782320857048
73
train loss item: 0.1040826141834259
74
train loss item: 0.048875320702791214
75
train loss item: 0.0651819184422493
76
train loss item: 0.2007783055305481
77
train loss item: 0.6771834492683411
78
train loss item: 0.04695401340723038
79
train loss item: 0.11819758266210556
80
train loss item: 0.06288925558328629
81
train loss item: 0.08636914938688278
82
train loss item: 0.0677274838089943
83
train loss item: 0.25894972681999207
84
train loss item: 0.17939043045043945
85
train loss item: 0.16411034762859344
86
train loss item: 3.0645158290863037
87
train loss item: 0.07267459481954575
88
train loss item: 0.13395269215106964
epoch train loss: 0.21310178156983986
testing phase
test loss item: 0.12236425280570984
test loss item: 0.07286326587200165
test loss item: 0.43075457215309143
test loss item: 0.1546829789876938
test loss item: 0.1642226278781891
test loss item: 0.08424622565507889
test loss item: 1.433854579925537
test loss item: 0.45239394903182983
test loss item: 0.15287208557128906
test loss item: 0.24768133461475372
test loss item: 0.6317281126976013
test loss item: 0.10685180127620697
test loss item: 0.11817524582147598
test loss item: 0.2018023431301117
test loss item: 0.11632337421178818
test loss item: 0.06386756896972656
test loss item: 0.20187726616859436
test loss item: 0.28856387734413147
test loss item: 0.45034727454185486
test loss item: 0.193634033203125
test loss item: 0.4571925401687622
test loss item: 0.29185473918914795
test loss item: 0.2005992978811264
test loss item: 0.12760473787784576
test loss item: 0.1395258605480194
test loss item: 0.14301137626171112
test loss item: 0.20445536077022552
test loss item: 0.11379750072956085
test loss item: 0.21389681100845337
test loss item: 0.20802654325962067
test loss item: 0.6380637288093567
test loss item: 0.056256286799907684
test loss item: 0.10585685074329376
test loss item: 0.36478862166404724
test loss item: 0.2849557101726532
test loss item: 0.2748733460903168
test loss item: 0.5729005336761475
test loss item: 1.0705292224884033
test loss item: 0.3098636865615845
test loss item: 0.19872555136680603
test loss item: 0.22208920121192932
test loss item: 0.10620555281639099
test loss item: 0.20911245048046112
test loss item: 0.16533246636390686
test loss item: 0.3533118963241577
test loss item: 0.2792620062828064
test loss item: 0.17419901490211487
test loss item: 0.1639878749847412
test loss item: 0.33843204379081726
test loss item: 0.4756796658039093
test loss item: 0.1894294023513794
test loss item: 0.09015824645757675
test loss item: 0.1716829538345337
test loss item: 0.11628566682338715
test loss item: 0.19511859118938446
test loss item: 0.603728175163269
test loss item: 0.3846818804740906
test loss item: 0.1639380156993866
test loss item: 0.1633037030696869
test loss item: 0.1242743581533432
test loss item: 0.26798614859580994
test loss item: 0.19916246831417084
test loss item: 0.14887456595897675
test loss item: 0.14906024932861328
test loss item: 0.6512382626533508
test loss item: 0.20830179750919342
test loss item: 0.22373513877391815
test loss item: 0.17154569923877716
test loss item: 0.3585219979286194
test loss item: 0.2911210358142853
test loss item: 0.05202087387442589
test loss item: 0.7913801074028015
test loss item: 0.22442367672920227
test loss item: 0.30062803626060486
test loss item: 0.11091074347496033
test loss item: 0.10174661129713058
test loss item: 0.1295514553785324
test loss item: 1.1689039468765259
test loss item: 0.30005234479904175
test loss item: 0.11723721772432327
test loss item: 0.06171754375100136
test loss item: 0.7577242255210876
test loss item: 0.639801561832428
test loss item: 0.7951448559761047
test loss item: 0.15932349860668182
test loss item: 0.14679355919361115
test loss item: 0.06169779971241951
test loss item: 0.05992106348276138
test loss item: 0.09237827360630035
Epoch [75/100], Training Loss: 0.2131, Testing Loss: 0.2820
no improvement in test loss for 9 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 76/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.19858615100383759
1
train loss item: 0.21948082745075226
2
train loss item: 0.08576159924268723
3
train loss item: 0.14809897541999817
4
train loss item: 0.116461843252182
5
train loss item: 0.11617583781480789
6
train loss item: 0.07517696171998978
7
train loss item: 0.22104617953300476
8
train loss item: 0.052768755704164505
9
train loss item: 0.08877906203269958
10
train loss item: 0.10074102878570557
11
train loss item: 0.10773473978042603
12
train loss item: 0.06963610649108887
13
train loss item: 0.17547547817230225
14
train loss item: 0.09454553574323654
15
train loss item: 0.195465549826622
16
train loss item: 0.04136384278535843
17
train loss item: 0.08291392028331757
18
train loss item: 0.11144446581602097
19
train loss item: 0.08731678873300552
20
train loss item: 0.07834590971469879
21
train loss item: 0.06001409515738487
22
train loss item: 0.18476499617099762
23
train loss item: 0.1871356964111328
24
train loss item: 0.17639409005641937
25
train loss item: 0.08116772025823593
26
train loss item: 0.07271760702133179
27
train loss item: 0.08685692399740219
28
train loss item: 0.04095757007598877
29
train loss item: 0.19602037966251373
30
train loss item: 1.0142052173614502
31
train loss item: 0.14972138404846191
32
train loss item: 0.05583151429891586
33
train loss item: 0.11776174604892731
34
train loss item: 0.07119469344615936
35
train loss item: 1.5435948371887207
36
train loss item: 0.18840476870536804
37
train loss item: 0.1767875850200653
38
train loss item: 0.15685151517391205
39
train loss item: 0.10093347728252411
40
train loss item: 0.07222896814346313
41
train loss item: 0.10459227859973907
42
train loss item: 0.15819011628627777
43
train loss item: 0.07478535920381546
44
train loss item: 0.3053596317768097
45
train loss item: 0.06519943475723267
46
train loss item: 0.0588981956243515
47
train loss item: 0.12652774155139923
48
train loss item: 0.08479830622673035
49
train loss item: 0.06551971286535263
50
train loss item: 0.09693639725446701
51
train loss item: 0.33701393008232117
52
train loss item: 0.04483870044350624
53
train loss item: 0.06325098127126694
54
train loss item: 1.4135074615478516
55
train loss item: 0.07528602331876755
56
train loss item: 0.09690827131271362
57
train loss item: 0.10940659046173096
58
train loss item: 0.0689786896109581
59
train loss item: 0.06951998919248581
60
train loss item: 0.21459360420703888
61
train loss item: 1.185989499092102
62
train loss item: 0.08103328943252563
63
train loss item: 0.13460735976696014
64
train loss item: 0.07235406339168549
65
train loss item: 0.14337162673473358
66
train loss item: 0.14535048604011536
67
train loss item: 0.08611294627189636
68
train loss item: 0.12012114375829697
69
train loss item: 0.10763165354728699
70
train loss item: 0.09444083273410797
71
train loss item: 0.06219303980469704
72
train loss item: 0.06587685644626617
73
train loss item: 0.10709508508443832
74
train loss item: 0.048982806503772736
75
train loss item: 0.06308026611804962
76
train loss item: 0.18186978995800018
77
train loss item: 0.7092273235321045
78
train loss item: 0.04062933847308159
79
train loss item: 0.10456837713718414
80
train loss item: 0.05876234173774719
81
train loss item: 0.07750902324914932
82
train loss item: 0.07079432904720306
83
train loss item: 0.22771500051021576
84
train loss item: 0.14192721247673035
85
train loss item: 0.15585678815841675
86
train loss item: 3.0524330139160156
87
train loss item: 0.07349766045808792
88
train loss item: 0.1097448319196701
epoch train loss: 0.20626687354753526
testing phase
test loss item: 0.11353381723165512
test loss item: 0.07247842848300934
test loss item: 0.4526914954185486
test loss item: 0.1457555890083313
test loss item: 0.1724364459514618
test loss item: 0.07718252390623093
test loss item: 1.3917266130447388
test loss item: 0.408296138048172
test loss item: 0.15734104812145233
test loss item: 0.257954865694046
test loss item: 0.661828875541687
test loss item: 0.10028928518295288
test loss item: 0.11680683493614197
test loss item: 0.1924004703760147
test loss item: 0.11773286759853363
test loss item: 0.05745561048388481
test loss item: 0.18631336092948914
test loss item: 0.3073626756668091
test loss item: 0.4243239760398865
test loss item: 0.17824068665504456
test loss item: 0.4950086772441864
test loss item: 0.2751457691192627
test loss item: 0.20246273279190063
test loss item: 0.11685895919799805
test loss item: 0.1383080929517746
test loss item: 0.13970333337783813
test loss item: 0.1987639218568802
test loss item: 0.118670254945755
test loss item: 0.21755032241344452
test loss item: 0.21018947660923004
test loss item: 0.6458510756492615
test loss item: 0.04792720451951027
test loss item: 0.09449704736471176
test loss item: 0.3843701481819153
test loss item: 0.30339673161506653
test loss item: 0.27172088623046875
test loss item: 0.5519833564758301
test loss item: 1.1351287364959717
test loss item: 0.3234274685382843
test loss item: 0.18721909821033478
test loss item: 0.2110690474510193
test loss item: 0.09630420058965683
test loss item: 0.22344081103801727
test loss item: 0.15400901436805725
test loss item: 0.38156944513320923
test loss item: 0.2581651508808136
test loss item: 0.1764865517616272
test loss item: 0.15048249065876007
test loss item: 0.34742045402526855
test loss item: 0.4829142391681671
test loss item: 0.20596107840538025
test loss item: 0.08414388447999954
test loss item: 0.17337316274642944
test loss item: 0.10864914208650589
test loss item: 0.2121524214744568
test loss item: 0.64239102602005
test loss item: 0.37383729219436646
test loss item: 0.17389526963233948
test loss item: 0.15660324692726135
test loss item: 0.13530868291854858
test loss item: 0.2857658267021179
test loss item: 0.1806163787841797
test loss item: 0.13728362321853638
test loss item: 0.14549796283245087
test loss item: 0.6699166297912598
test loss item: 0.20080024003982544
test loss item: 0.21258969604969025
test loss item: 0.16629213094711304
test loss item: 0.3775276243686676
test loss item: 0.26796165108680725
test loss item: 0.05026886984705925
test loss item: 0.7506574392318726
test loss item: 0.2221478521823883
test loss item: 0.2794416546821594
test loss item: 0.10214701294898987
test loss item: 0.0931384265422821
test loss item: 0.12047326564788818
test loss item: 1.2427067756652832
test loss item: 0.30160003900527954
test loss item: 0.11291301250457764
test loss item: 0.05118474364280701
test loss item: 0.7626622319221497
test loss item: 0.6284738779067993
test loss item: 0.8404873609542847
test loss item: 0.1566539853811264
test loss item: 0.1408974528312683
test loss item: 0.04914775490760803
test loss item: 0.04521133005619049
test loss item: 0.08599770069122314
Epoch [76/100], Training Loss: 0.2063, Testing Loss: 0.2818
no improvement in test loss for 10 epochs
Early stopping!
loss item: 0.2416893094778061
loss item: 0.13406190276145935
loss item: 1.2836509943008423
loss item: 0.677764892578125
loss item: 0.4090016484260559
loss item: 0.275158166885376
loss item: 0.1318291276693344
loss item: 0.5965867042541504
loss item: 0.1464289277791977
loss item: 0.12782442569732666
loss item: 0.7324057817459106
loss item: 0.03763395920395851
loss item: 0.6148883104324341
loss item: 0.14421263337135315
loss item: 0.2449694573879242
loss item: 0.19116152822971344
loss item: 0.24503985047340393
loss item: 0.48355111479759216
loss item: 0.6707779765129089
loss item: 0.2926985025405884
loss item: 0.2601560354232788
loss item: 0.15402595698833466
loss item: 0.1924733817577362
loss item: 0.17273660004138947
loss item: 0.17947068810462952
loss item: 0.4811829626560211
loss item: 0.8395956158638
loss item: 0.10100439190864563
loss item: 0.08991068601608276
loss item: 0.2608594000339508
loss item: 0.7951316833496094
loss item: 1.207578182220459
loss item: 0.124503493309021
loss item: 0.3645181953907013
loss item: 0.11488796770572662
loss item: 0.09492790699005127
loss item: 0.2789454460144043
loss item: 0.15818247199058533
loss item: 0.28994104266166687
loss item: 0.5204514861106873
loss item: 0.7563204765319824
loss item: 0.1942831128835678
loss item: 0.13330940902233124
loss item: 0.044446710497140884
Val Loss: 0.3520
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.001, epochs: 100, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 100 0.001 2 360 done at Wed Nov 13 22:03:15 CET 2024
UNet6 with 1 100 0.005 2 360 start at Wed Nov 13 22:03:15 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 100, batch size: 2
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.8683910369873047
1
train loss item: 2.382193088531494
2
train loss item: 0.593654990196228
3
train loss item: 1.3771746158599854
4
train loss item: 1.2764418125152588
5
train loss item: 0.6751511096954346
6
train loss item: 0.6763925552368164
7
train loss item: 1.5690721273422241
8
train loss item: 0.701848030090332
9
train loss item: 0.6682167649269104
10
train loss item: 0.8612480163574219
11
train loss item: 0.5461564660072327
12
train loss item: 0.5354071259498596
13
train loss item: 1.0284537076950073
14
train loss item: 0.5919447541236877
15
train loss item: 1.2881312370300293
16
train loss item: 0.524511456489563
17
train loss item: 0.7142107486724854
18
train loss item: 0.8246272802352905
19
train loss item: 0.6058518290519714
20
train loss item: 0.5170044302940369
21
train loss item: 0.5159300565719604
22
train loss item: 1.8495265245437622
23
train loss item: 1.6034530401229858
24
train loss item: 1.0550181865692139
25
train loss item: 0.6501007080078125
26
train loss item: 0.5941882133483887
27
train loss item: 0.6885870099067688
28
train loss item: 0.5295187830924988
29
train loss item: 1.4970941543579102
30
train loss item: 3.5986649990081787
31
train loss item: 1.2484612464904785
32
train loss item: 0.604256272315979
33
train loss item: 1.060405969619751
34
train loss item: 0.7382200360298157
35
train loss item: 3.335528612136841
36
train loss item: 0.9933324456214905
37
train loss item: 0.5563225746154785
38
train loss item: 1.1918492317199707
39
train loss item: 0.702652096748352
40
train loss item: 0.5388055443763733
41
train loss item: 0.6974869966506958
42
train loss item: 0.5633171796798706
43
train loss item: 0.6188725233078003
44
train loss item: 1.2913734912872314
45
train loss item: 0.5275934338569641
46
train loss item: 0.5292625427246094
47
train loss item: 0.8105137348175049
48
train loss item: 0.6565680503845215
49
train loss item: 0.5315561890602112
50
train loss item: 0.5768018364906311
51
train loss item: 1.6511173248291016
52
train loss item: 0.6113849878311157
53
train loss item: 0.6123525500297546
54
train loss item: 3.223827362060547
55
train loss item: 0.5809991955757141
56
train loss item: 0.6737948656082153
57
train loss item: 0.5509033203125
58
train loss item: 0.5713635087013245
59
train loss item: 0.659683108329773
60
train loss item: 1.7614445686340332
61
train loss item: 3.2216427326202393
62
train loss item: 0.6776043176651001
63
train loss item: 0.768122136592865
64
train loss item: 0.6229637861251831
65
train loss item: 1.091357946395874
66
train loss item: 0.8247737884521484
67
train loss item: 0.5938141942024231
68
train loss item: 0.8308650255203247
69
train loss item: 0.7554875016212463
70
train loss item: 0.6575753688812256
71
train loss item: 0.556104302406311
72
train loss item: 0.7488033175468445
73
train loss item: 0.6496177911758423
74
train loss item: 0.6939395666122437
75
train loss item: 0.5787387490272522
76
train loss item: 1.59280264377594
77
train loss item: 1.9825881719589233
78
train loss item: 0.5867175459861755
79
train loss item: 0.6535068154335022
80
train loss item: 0.5794782042503357
81
train loss item: 0.5776485204696655
82
train loss item: 0.6216252446174622
83
train loss item: 1.309710144996643
84
train loss item: 0.8079427480697632
85
train loss item: 1.287370204925537
86
train loss item: 5.631964206695557
87
train loss item: 0.6982468962669373
88
train loss item: 0.7556139826774597
epoch train loss: 1.0161218147599296
testing phase
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
test loss item: inf
Epoch [1/100], Training Loss: 1.0161, Testing Loss: inf
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 2/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.7337050437927246
1
train loss item: 2.7631168365478516
2
train loss item: 2.234610080718994
3
train loss item: 1.7419995069503784
4
train loss item: 6.1393723487854
5
train loss item: 1.5922759771347046
6
train loss item: 2.5647833347320557
7
train loss item: 1.6451680660247803
8
train loss item: 2.7176425457000732
9
train loss item: 1.492957592010498
10
train loss item: 1.491503357887268
11
train loss item: 1.5420777797698975
12
train loss item: 2.0083630084991455
13
train loss item: 1.8392164707183838
14
train loss item: 1.5706486701965332
15
train loss item: 2.232177257537842
16
train loss item: 2.496960163116455
17
train loss item: 2.4780821800231934
18
train loss item: 1.7222905158996582
19
train loss item: 1.6870818138122559
20
train loss item: 2.118736743927002
21
train loss item: 1.9805856943130493
22
train loss item: 3.185164213180542
23
train loss item: 1.762037992477417
24
train loss item: 1.825776219367981
25
train loss item: 1.7809085845947266
26
train loss item: 2.1128554344177246
27
train loss item: 1.5286165475845337
28
train loss item: 2.4832184314727783
29
train loss item: 2.54193377494812
30
train loss item: 2.50256085395813
31
train loss item: 2.065317153930664
32
train loss item: 2.0945029258728027
33
train loss item: 2.0646257400512695
34
train loss item: 3.4447174072265625
35
train loss item: 2.5013861656188965
36
train loss item: 1.735538363456726
37
train loss item: 1.645919919013977
38
train loss item: 2.2714486122131348
39
train loss item: 1.5122597217559814
40
train loss item: 1.890000820159912
41
train loss item: 1.462815284729004
42
train loss item: 1.4945224523544312
43
train loss item: 1.9924899339675903
44
train loss item: 1.6032381057739258
45
train loss item: 2.0889079570770264
46
train loss item: 1.7946295738220215
47
train loss item: 1.7839832305908203
48
train loss item: 1.6914453506469727
49
train loss item: 1.68925940990448
50
train loss item: 1.7840021848678589
51
train loss item: 2.236063241958618
52
train loss item: 2.3508286476135254
53
train loss item: 2.0815937519073486
54
train loss item: 2.320829391479492
55
train loss item: 1.8811920881271362
56
train loss item: 1.426205039024353
57
train loss item: 1.5302560329437256
58
train loss item: 1.9881020784378052
59
train loss item: 1.9739981889724731
60
train loss item: 2.6819868087768555
61
train loss item: 2.499228000640869
62
train loss item: 1.9953643083572388
63
train loss item: 1.7958790063858032
64
train loss item: 1.933268427848816
65
train loss item: 2.480179786682129
66
train loss item: 1.5023800134658813
67
train loss item: 1.7364012002944946
68
train loss item: 2.1607017517089844
69
train loss item: 1.6429253816604614
70
train loss item: 1.7046711444854736
71
train loss item: 2.773634195327759
72
train loss item: 2.7464749813079834
73
train loss item: 1.6722614765167236
74
train loss item: 2.9682271480560303
75
train loss item: 2.0106396675109863
76
train loss item: 1.8273371458053589
77
train loss item: 2.8965399265289307
78
train loss item: 2.4373278617858887
79
train loss item: 1.687382698059082
80
train loss item: 2.7743425369262695
81
train loss item: 1.6321439743041992
82
train loss item: 1.7260106801986694
83
train loss item: 2.1647098064422607
84
train loss item: 1.6363555192947388
85
train loss item: 1.46220862865448
86
train loss item: 4.096249580383301
87
train loss item: 2.4520556926727295
88
train loss item: 1.618540644645691
epoch train loss: 2.096988020318278
testing phase
test loss item: 64194280.0
test loss item: 77386600.0
test loss item: 37743548.0
test loss item: 117831720.0
test loss item: 73759496.0
test loss item: 67275080.0
test loss item: 52555964.0
test loss item: 53374168.0
test loss item: 50467592.0
test loss item: 28725310.0
test loss item: 94413592.0
test loss item: 114410088.0
test loss item: 36495640.0
test loss item: 6842875.0
test loss item: 71036792.0
test loss item: 80053312.0
test loss item: 27741210.0
test loss item: 42308932.0
test loss item: 52854640.0
test loss item: 24911878.0
test loss item: 38965384.0
test loss item: 105730408.0
test loss item: 51431464.0
test loss item: 73480056.0
test loss item: 38004784.0
test loss item: 45211844.0
test loss item: 54816716.0
test loss item: 72896384.0
test loss item: 73055392.0
test loss item: 30115762.0
test loss item: 81421744.0
test loss item: 82135216.0
test loss item: 73996600.0
test loss item: 114721768.0
test loss item: 57867968.0
test loss item: 192525392.0
test loss item: 46320204.0
test loss item: 148446352.0
test loss item: 97882680.0
test loss item: 71978528.0
test loss item: 53809276.0
test loss item: 53083764.0
test loss item: 23070896.0
test loss item: 106121736.0
test loss item: 38328132.0
test loss item: 56201788.0
test loss item: 42574956.0
test loss item: 27949896.0
test loss item: 28571482.0
test loss item: 56177952.0
test loss item: 39451744.0
test loss item: 33010762.0
test loss item: 34112568.0
test loss item: 165836064.0
test loss item: 32265634.0
test loss item: 80623072.0
test loss item: 126303920.0
test loss item: 6837115.5
test loss item: 39919224.0
test loss item: 37874236.0
test loss item: 33307098.0
test loss item: 47217752.0
test loss item: 44385896.0
test loss item: 41790576.0
test loss item: 105819848.0
test loss item: 169617760.0
test loss item: 31910236.0
test loss item: 48406540.0
test loss item: 60020248.0
test loss item: 45935168.0
test loss item: 70496864.0
test loss item: 38118292.0
test loss item: 34978408.0
test loss item: 47180848.0
test loss item: 41174452.0
test loss item: 51311912.0
test loss item: 69519968.0
test loss item: 192651280.0
test loss item: 6877895.5
test loss item: 67829576.0
test loss item: 57674132.0
test loss item: 135990032.0
test loss item: 47934808.0
test loss item: 185032400.0
test loss item: 32694296.0
test loss item: 40738712.0
test loss item: 69086096.0
test loss item: 78784400.0
test loss item: 69556800.0
Epoch [2/100], Training Loss: 2.0970, Testing Loss: 64871391.8427
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 3/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.183565616607666
1
train loss item: 1.9414341449737549
2
train loss item: 0.5925023555755615
3
train loss item: 1.1334564685821533
4
train loss item: 0.8947123289108276
5
train loss item: 0.9950372576713562
6
train loss item: 0.4728458821773529
7
train loss item: 1.4358906745910645
8
train loss item: 0.6126320362091064
9
train loss item: 0.6711855530738831
10
train loss item: 0.7577145099639893
11
train loss item: 0.8863354921340942
12
train loss item: 0.5569525957107544
13
train loss item: 1.0617115497589111
14
train loss item: 0.927487313747406
15
train loss item: 1.350458025932312
16
train loss item: 0.4471089839935303
17
train loss item: 0.5849692225456238
18
train loss item: 1.0702556371688843
19
train loss item: 0.743766188621521
20
train loss item: 0.5721824169158936
21
train loss item: 0.5679368376731873
22
train loss item: 1.8540056943893433
23
train loss item: 1.3585312366485596
24
train loss item: 0.8896396160125732
25
train loss item: 0.892193615436554
26
train loss item: 0.49351125955581665
27
train loss item: 0.989745020866394
28
train loss item: 0.46215173602104187
29
train loss item: 1.5552799701690674
30
train loss item: 2.726870059967041
31
train loss item: 1.151024580001831
32
train loss item: 0.7188815474510193
33
train loss item: 0.8409228324890137
34
train loss item: 0.6987011432647705
35
train loss item: 2.5515308380126953
36
train loss item: 1.1870825290679932
37
train loss item: 0.9118356704711914
38
train loss item: 1.00033438205719
39
train loss item: 0.9232012629508972
40
train loss item: 0.6649325489997864
41
train loss item: 0.9523438215255737
42
train loss item: 0.8555437922477722
43
train loss item: 0.6985820531845093
44
train loss item: 1.3676202297210693
45
train loss item: 0.5383530855178833
46
train loss item: 0.5667073130607605
47
train loss item: 0.974998414516449
48
train loss item: 0.8386710286140442
49
train loss item: 0.7001276612281799
50
train loss item: 0.75501549243927
51
train loss item: 1.569324016571045
52
train loss item: 0.6918904781341553
53
train loss item: 0.7456850409507751
54
train loss item: 2.4733364582061768
55
train loss item: 0.5959522128105164
56
train loss item: 0.9113231301307678
57
train loss item: 0.9146339893341064
58
train loss item: 0.6802918910980225
59
train loss item: 0.6703583002090454
60
train loss item: 1.7469711303710938
61
train loss item: 2.7646543979644775
62
train loss item: 0.8055040836334229
63
train loss item: 1.0253621339797974
64
train loss item: 0.6980629563331604
65
train loss item: 1.037177562713623
66
train loss item: 1.0598479509353638
67
train loss item: 0.7360441088676453
68
train loss item: 0.8391050100326538
69
train loss item: 0.7724520564079285
70
train loss item: 0.8917180895805359
71
train loss item: 0.5594335794448853
72
train loss item: 0.6747870445251465
73
train loss item: 0.7655966281890869
74
train loss item: 0.5394884347915649
75
train loss item: 0.5603901743888855
76
train loss item: 1.4299347400665283
77
train loss item: 1.9654195308685303
78
train loss item: 0.6301231980323792
79
train loss item: 0.9600579142570496
80
train loss item: 0.5262104868888855
81
train loss item: 0.7917017936706543
82
train loss item: 0.8507077097892761
83
train loss item: 1.376380443572998
84
train loss item: 1.0350337028503418
85
train loss item: 1.1629035472869873
86
train loss item: 4.447148323059082
87
train loss item: 0.8393546342849731
88
train loss item: 0.6154994964599609
epoch train loss: 1.021779167518187
testing phase
test loss item: 5521997.0
test loss item: 7138301.5
test loss item: 1392644.75
test loss item: 6179405.0
test loss item: 7189193.5
test loss item: 5434376.5
test loss item: 1869010.375
test loss item: 3627687.0
test loss item: 1355536.375
test loss item: 912160.5625
test loss item: 1723799.0
test loss item: 1830857.5
test loss item: 902500.75
test loss item: 2388472.75
test loss item: 8060358.5
test loss item: 2156714.25
test loss item: 1182667.0
test loss item: 3038765.25
test loss item: 4258468.5
test loss item: 4641197.5
test loss item: 5902174.5
test loss item: 973868.5
test loss item: 5363483.5
test loss item: 7947057.5
test loss item: 1475143.25
test loss item: 5812022.5
test loss item: 4786960.5
test loss item: 6819634.5
test loss item: 8102120.0
test loss item: 1242680.125
test loss item: 3931957.75
test loss item: 2135361.25
test loss item: 8305707.0
test loss item: 1627812.875
test loss item: 2823427.5
test loss item: 5473075.5
test loss item: 2050324.625
test loss item: 1824358.5
test loss item: 2303926.0
test loss item: 6839018.5
test loss item: 1211332.5
test loss item: 4378224.0
test loss item: 1720441.625
test loss item: 957279.3125
test loss item: 5909265.0
test loss item: 5766713.5
test loss item: 3475168.0
test loss item: 7323373.5
test loss item: 320534.03125
test loss item: 4742660.5
test loss item: 2703536.5
test loss item: 1828224.375
test loss item: 3397204.5
test loss item: 1506293.0
test loss item: 4624255.0
test loss item: 4243142.5
test loss item: 2237267.5
test loss item: 2392109.25
test loss item: 3163123.0
test loss item: 3440907.0
test loss item: 1807716.875
test loss item: 1218867.625
test loss item: 6611212.0
test loss item: 303618.21875
test loss item: 4985085.5
test loss item: 1553572.875
test loss item: 3415601.25
test loss item: 3451090.25
test loss item: 1360947.375
test loss item: 637669.125
test loss item: 4361056.5
test loss item: 2325683.0
test loss item: 5529577.5
test loss item: 5857173.0
test loss item: 3813475.25
test loss item: 3666666.25
test loss item: 7401176.0
test loss item: 3399414.5
test loss item: 2390457.75
test loss item: 7059022.0
test loss item: 5227428.5
test loss item: 4832469.0
test loss item: 4552043.5
test loss item: 3629586.5
test loss item: 4753256.5
test loss item: 4514552.5
test loss item: 4661881.5
test loss item: 2165708.5
test loss item: 8545681.0
Epoch [3/100], Training Loss: 1.0218, Testing Loss: 3774348.0098
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 4/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 1.1574124097824097
1
train loss item: 1.9939154386520386
2
train loss item: 0.6851544976234436
3
train loss item: 1.221824049949646
4
train loss item: 0.9709842205047607
5
train loss item: 1.1037614345550537
6
train loss item: 0.5823261141777039
7
train loss item: 1.5786597728729248
8
train loss item: 0.5369793176651001
9
train loss item: 0.6179637312889099
10
train loss item: 0.8371385931968689
11
train loss item: 1.0428433418273926
12
train loss item: 0.3738707900047302
13
train loss item: 0.9614976048469543
14
train loss item: 1.130540370941162
15
train loss item: 1.1000782251358032
16
train loss item: 0.34165799617767334
17
train loss item: 0.6350982785224915
18
train loss item: 1.0526798963546753
19
train loss item: 0.6815463304519653
20
train loss item: 0.5234748721122742
21
train loss item: 0.5844346284866333
22
train loss item: 1.6897159814834595
23
train loss item: 1.4940884113311768
24
train loss item: 0.8623356819152832
25
train loss item: 0.6053005456924438
26
train loss item: 0.5238592028617859
27
train loss item: 1.083116888999939
28
train loss item: 0.31862208247184753
29
train loss item: 1.4278826713562012
30
train loss item: 3.1265909671783447
31
train loss item: 1.3633322715759277
32
train loss item: 1.3678544759750366
33
train loss item: 1.0854909420013428
34
train loss item: 0.5634687542915344
35
train loss item: 3.0801820755004883
36
train loss item: 1.333024501800537
37
train loss item: 1.1170320510864258
38
train loss item: 1.0321985483169556
39
train loss item: 1.071929693222046
40
train loss item: 0.4916936457157135
41
train loss item: 1.0832405090332031
42
train loss item: 1.0191025733947754
43
train loss item: 1.3422534465789795
44
train loss item: 1.4352326393127441
45
train loss item: 0.6774218082427979
46
train loss item: 0.647018551826477
47
train loss item: 1.0861091613769531
48
train loss item: 1.0953893661499023
49
train loss item: 0.7269027233123779
50
train loss item: 0.6388546228408813
51
train loss item: 1.8398010730743408
52
train loss item: 0.5272270441055298
53
train loss item: 0.582594633102417
54
train loss item: 2.9758660793304443
55
train loss item: 0.6146993041038513
56
train loss item: 1.096402883529663
57
train loss item: 1.1103590726852417
58
train loss item: 1.3151277303695679
59
train loss item: 0.43090537190437317
60
train loss item: 1.528467059135437
61
train loss item: 2.9844484329223633
62
train loss item: 0.78636234998703
63
train loss item: 1.1165361404418945
64
train loss item: 1.370872974395752
65
train loss item: 0.8983699679374695
66
train loss item: 1.2378227710723877
67
train loss item: 0.6051691174507141
68
train loss item: 0.621517539024353
69
train loss item: 0.7023487687110901
70
train loss item: 1.0926916599273682
71
train loss item: 0.5507144927978516
72
train loss item: 0.6393551826477051
73
train loss item: 0.6313296556472778
74
train loss item: 0.23827973008155823
75
train loss item: 0.4085358679294586
76
train loss item: 1.4518320560455322
77
train loss item: 1.9775038957595825
78
train loss item: 0.5889081358909607
79
train loss item: 1.0293633937835693
80
train loss item: 0.6876837015151978
81
train loss item: 0.6747007369995117
82
train loss item: 1.0069897174835205
83
train loss item: 1.1776341199874878
84
train loss item: 1.2533090114593506
85
train loss item: 1.1214240789413452
86
train loss item: 5.2202043533325195
87
train loss item: 0.5375616550445557
88
train loss item: 0.6052843332290649
epoch train loss: 1.082486413502961
testing phase
test loss item: 1373.18505859375
test loss item: 189.09327697753906
test loss item: 369.2943115234375
test loss item: 424.96807861328125
test loss item: 211.4586181640625
test loss item: 251.73577880859375
test loss item: 80.72917938232422
test loss item: 185.982421875
test loss item: 16.79558563232422
test loss item: 15.428732872009277
test loss item: 129.42709350585938
test loss item: 507.9722595214844
test loss item: 16.074125289916992
test loss item: 565.6630249023438
test loss item: 267.7524108886719
test loss item: 109.59881591796875
test loss item: 377.2904357910156
test loss item: 384.050537109375
test loss item: 1343.378173828125
test loss item: 489.7862243652344
test loss item: 747.7205200195312
test loss item: 389.63543701171875
test loss item: 1376.2557373046875
test loss item: 52.161598205566406
test loss item: 137.7389373779297
test loss item: 835.73779296875
test loss item: 429.1953125
test loss item: 155.943115234375
test loss item: 225.03160095214844
test loss item: 14.522889137268066
test loss item: 194.5797576904297
test loss item: 109.61671447753906
test loss item: 142.3399200439453
test loss item: 504.4494323730469
test loss item: 290.06817626953125
test loss item: 411.9919128417969
test loss item: 180.49609375
test loss item: 205.38253784179688
test loss item: 422.0642395019531
test loss item: 141.83587646484375
test loss item: 62.18326950073242
test loss item: 1230.7574462890625
test loss item: 493.3901672363281
test loss item: 380.1335754394531
test loss item: 749.6412353515625
test loss item: 534.6477661132812
test loss item: 442.6421813964844
test loss item: 679.5367431640625
test loss item: 16.549957275390625
test loss item: 935.044921875
test loss item: 260.8851013183594
test loss item: 137.5486602783203
test loss item: 16.860403060913086
test loss item: 577.7509765625
test loss item: 162.39450073242188
test loss item: 197.6161651611328
test loss item: 16.391542434692383
test loss item: 566.707275390625
test loss item: 385.5350646972656
test loss item: 33.282684326171875
test loss item: 137.3617706298828
test loss item: 61.86630630493164
test loss item: 1411.269287109375
test loss item: 17.444717407226562
test loss item: 323.91796875
test loss item: 578.991943359375
test loss item: 13.818497657775879
test loss item: 159.61163330078125
test loss item: 62.07839584350586
test loss item: 15.281039237976074
test loss item: 156.96530151367188
test loss item: 159.56690979003906
test loss item: 723.7645874023438
test loss item: 1383.801513671875
test loss item: 447.0059814453125
test loss item: 189.57083129882812
test loss item: 152.9215850830078
test loss item: 574.351318359375
test loss item: 566.7460327148438
test loss item: 1428.2054443359375
test loss item: 298.8756408691406
test loss item: 1321.682861328125
test loss item: 406.78167724609375
test loss item: 557.9059448242188
test loss item: 182.75282287597656
test loss item: 1297.17919921875
test loss item: 248.6237335205078
test loss item: 109.65879821777344
test loss item: 2724.205810546875
Epoch [4/100], Training Loss: 1.0825, Testing Loss: 425.4847
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 5/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.669301450252533
1
train loss item: 2.005352735519409
2
train loss item: 0.5108360052108765
3
train loss item: 1.1352429389953613
4
train loss item: 0.5807209610939026
5
train loss item: 0.5794386267662048
6
train loss item: 0.4949324131011963
7
train loss item: 1.2751185894012451
8
train loss item: 0.4077865183353424
9
train loss item: 0.4953464865684509
10
train loss item: 0.6323778629302979
11
train loss item: 0.5133861899375916
12
train loss item: 0.4307023584842682
13
train loss item: 0.8104681968688965
14
train loss item: 0.5151399374008179
15
train loss item: 1.1922504901885986
16
train loss item: 0.3449742794036865
17
train loss item: 0.4205591678619385
18
train loss item: 0.6573119163513184
19
train loss item: 0.5358530282974243
20
train loss item: 0.43036356568336487
21
train loss item: 0.32258933782577515
22
train loss item: 1.8101774454116821
23
train loss item: 1.3432197570800781
24
train loss item: 0.8852701187133789
25
train loss item: 0.5495965480804443
26
train loss item: 0.27381429076194763
27
train loss item: 0.5837677121162415
28
train loss item: 0.3634118139743805
29
train loss item: 1.435518503189087
30
train loss item: 3.0796546936035156
31
train loss item: 0.9577363133430481
32
train loss item: 0.3649596869945526
33
train loss item: 0.8014232516288757
34
train loss item: 0.5286387205123901
35
train loss item: 2.885377883911133
36
train loss item: 0.8664788603782654
37
train loss item: 0.6632768511772156
38
train loss item: 0.9014606475830078
39
train loss item: 0.5859564542770386
40
train loss item: 0.29297399520874023
41
train loss item: 0.6027674078941345
42
train loss item: 0.5684018731117249
43
train loss item: 0.46087899804115295
44
train loss item: 1.0571134090423584
45
train loss item: 0.38469836115837097
46
train loss item: 0.35067543387413025
47
train loss item: 0.6974745988845825
48
train loss item: 0.43393397331237793
49
train loss item: 0.42840883135795593
50
train loss item: 0.6397272348403931
51
train loss item: 1.568054437637329
52
train loss item: 0.3257361352443695
53
train loss item: 0.4465019106864929
54
train loss item: 2.7694408893585205
55
train loss item: 0.3426324129104614
56
train loss item: 0.5977542996406555
57
train loss item: 0.5584379434585571
58
train loss item: 0.42660972476005554
59
train loss item: 0.25844404101371765
60
train loss item: 1.5652803182601929
61
train loss item: 2.8502142429351807
62
train loss item: 0.37750303745269775
63
train loss item: 0.7479260563850403
64
train loss item: 0.43345701694488525
65
train loss item: 0.9394662976264954
66
train loss item: 0.7468425035476685
67
train loss item: 0.5197861194610596
68
train loss item: 0.6439663767814636
69
train loss item: 0.6162663102149963
70
train loss item: 0.5631812810897827
71
train loss item: 0.297536700963974
72
train loss item: 0.49422869086265564
73
train loss item: 0.5071637630462646
74
train loss item: 0.2347545325756073
75
train loss item: 0.40762895345687866
76
train loss item: 1.3740973472595215
77
train loss item: 1.972565770149231
78
train loss item: 0.21327145397663116
79
train loss item: 0.5899575352668762
80
train loss item: 0.22748957574367523
81
train loss item: 0.49369609355926514
82
train loss item: 0.4424087107181549
83
train loss item: 1.1738381385803223
84
train loss item: 0.7521194219589233
85
train loss item: 1.0730184316635132
86
train loss item: 5.010405540466309
87
train loss item: 0.49739310145378113
88
train loss item: 0.5490522980690002
epoch train loss: 0.824325552147426
testing phase
test loss item: 193.53456115722656
test loss item: 194.09320068359375
test loss item: 500.2169494628906
test loss item: 796.852294921875
test loss item: 200.2329864501953
test loss item: 282.4388732910156
test loss item: 182.24461364746094
test loss item: 167.66429138183594
test loss item: 175.3987274169922
test loss item: 125.48291015625
test loss item: 166.9290313720703
test loss item: 1128.321533203125
test loss item: 540.4620361328125
test loss item: 671.693359375
test loss item: 91.36542510986328
test loss item: 351.97174072265625
test loss item: 744.7156372070312
test loss item: 115.01734924316406
test loss item: 117.93062591552734
test loss item: 702.40380859375
test loss item: 807.5352783203125
test loss item: 785.1324462890625
test loss item: 805.044677734375
test loss item: 185.39340209960938
test loss item: 727.920654296875
test loss item: 587.4926147460938
test loss item: 386.82562255859375
test loss item: 253.26596069335938
test loss item: 243.0707244873047
test loss item: 120.10271453857422
test loss item: 117.62374114990234
test loss item: 479.881591796875
test loss item: 136.21083068847656
test loss item: 851.7933349609375
test loss item: 206.7367706298828
test loss item: 366.36102294921875
test loss item: 197.50408935546875
test loss item: 180.21047973632812
test loss item: 863.2252197265625
test loss item: 258.83917236328125
test loss item: 819.5640869140625
test loss item: 834.2333984375
test loss item: 600.8545532226562
test loss item: 1004.1815795898438
test loss item: 850.4442138671875
test loss item: 550.06591796875
test loss item: 984.0051879882812
test loss item: 644.6589965820312
test loss item: 122.55614471435547
test loss item: 316.7966613769531
test loss item: 298.982421875
test loss item: 98.64193725585938
test loss item: 646.3541870117188
test loss item: 1156.1309814453125
test loss item: 481.9346923828125
test loss item: 62.12835693359375
test loss item: 107.43003845214844
test loss item: 709.7845458984375
test loss item: 138.30068969726562
test loss item: 647.699462890625
test loss item: 84.52913665771484
test loss item: 196.31517028808594
test loss item: 283.86846923828125
test loss item: 769.9132080078125
test loss item: 147.8094024658203
test loss item: 1123.41015625
test loss item: 321.3728942871094
test loss item: 724.9478149414062
test loss item: 506.3523254394531
test loss item: 117.76371002197266
test loss item: 237.07940673828125
test loss item: 155.59878540039062
test loss item: 837.0817260742188
test loss item: 144.57643127441406
test loss item: 566.4548950195312
test loss item: 749.6746826171875
test loss item: 171.1521453857422
test loss item: 165.53244018554688
test loss item: 674.7103271484375
test loss item: 219.24473571777344
test loss item: 87.8331298828125
test loss item: 153.9138946533203
test loss item: 353.70050048828125
test loss item: 146.09156799316406
test loss item: 431.7414245605469
test loss item: 616.6219482421875
test loss item: 184.28746032714844
test loss item: 273.68548583984375
test loss item: 121.00711822509766
Epoch [5/100], Training Loss: 0.8243, Testing Loss: 423.0355
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 6/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5946231484413147
1
train loss item: 1.9838461875915527
2
train loss item: 0.4009765386581421
3
train loss item: 1.0213115215301514
4
train loss item: 0.5309916734695435
5
train loss item: 0.46336641907691956
6
train loss item: 0.49030694365501404
7
train loss item: 1.1470869779586792
8
train loss item: 0.22655262053012848
9
train loss item: 0.4409114420413971
10
train loss item: 0.5291445851325989
11
train loss item: 0.4629054069519043
12
train loss item: 0.21491840481758118
13
train loss item: 0.6903838515281677
14
train loss item: 0.34871047735214233
15
train loss item: 1.2579970359802246
16
train loss item: 0.18816684186458588
17
train loss item: 0.48879173398017883
18
train loss item: 0.5870199799537659
19
train loss item: 0.5372936129570007
20
train loss item: 0.5211512446403503
21
train loss item: 0.3438786268234253
22
train loss item: 1.8720426559448242
23
train loss item: 1.2079607248306274
24
train loss item: 1.0332306623458862
25
train loss item: 0.3122381269931793
26
train loss item: 0.33172041177749634
27
train loss item: 0.4114626348018646
28
train loss item: 0.1851843148469925
29
train loss item: 1.4455047845840454
30
train loss item: 3.020362615585327
31
train loss item: 0.7786102294921875
32
train loss item: 0.2127753496170044
33
train loss item: 0.6196749806404114
34
train loss item: 0.3363945782184601
35
train loss item: 2.888387441635132
36
train loss item: 0.8179313540458679
37
train loss item: 0.6105154752731323
38
train loss item: 0.8980810642242432
39
train loss item: 0.4164239168167114
40
train loss item: 0.2508063018321991
41
train loss item: 0.42121002078056335
42
train loss item: 0.4569108188152313
43
train loss item: 0.3071165382862091
44
train loss item: 0.8957749009132385
45
train loss item: 0.19424252212047577
46
train loss item: 0.196355938911438
47
train loss item: 0.6809849739074707
48
train loss item: 0.3670964539051056
49
train loss item: 0.2346074879169464
50
train loss item: 0.579245924949646
51
train loss item: 1.5370079278945923
52
train loss item: 0.17673788964748383
53
train loss item: 0.27674761414527893
54
train loss item: 2.758492946624756
55
train loss item: 0.320963978767395
56
train loss item: 0.41256362199783325
57
train loss item: 0.40809956192970276
58
train loss item: 0.30322903394699097
59
train loss item: 0.19452440738677979
60
train loss item: 1.5820327997207642
61
train loss item: 2.6933252811431885
62
train loss item: 0.3721502125263214
63
train loss item: 0.7603291869163513
64
train loss item: 0.27402302622795105
65
train loss item: 1.0804136991500854
66
train loss item: 0.6739026308059692
67
train loss item: 0.426050066947937
68
train loss item: 0.7082470655441284
69
train loss item: 0.5692058205604553
70
train loss item: 0.5310481190681458
71
train loss item: 0.3975130021572113
72
train loss item: 0.30706295371055603
73
train loss item: 0.4843127429485321
74
train loss item: 0.19775870442390442
75
train loss item: 0.19237980246543884
76
train loss item: 1.2383753061294556
77
train loss item: 2.0013647079467773
78
train loss item: 0.1941377818584442
79
train loss item: 0.5912503004074097
80
train loss item: 0.2922463119029999
81
train loss item: 0.34221401810646057
82
train loss item: 0.3371834456920624
83
train loss item: 1.2277854681015015
84
train loss item: 0.7257451415061951
85
train loss item: 1.0315133333206177
86
train loss item: 4.955499649047852
87
train loss item: 0.2893543243408203
88
train loss item: 0.651634156703949
epoch train loss: 0.7524675788839211
testing phase
test loss item: 259.4425964355469
test loss item: 197.48121643066406
test loss item: 98.00985717773438
test loss item: 242.9959716796875
test loss item: 217.9160919189453
test loss item: 236.30177307128906
test loss item: 110.36363220214844
test loss item: 105.30272674560547
test loss item: 154.68600463867188
test loss item: 21.73921775817871
test loss item: 150.54066467285156
test loss item: 202.464599609375
test loss item: 30.069561004638672
test loss item: 283.8904724121094
test loss item: 154.61566162109375
test loss item: 236.31361389160156
test loss item: 111.42536926269531
test loss item: 126.01750183105469
test loss item: 346.5968933105469
test loss item: 106.1366958618164
test loss item: 336.512451171875
test loss item: 215.23597717285156
test loss item: 264.268310546875
test loss item: 120.32202911376953
test loss item: 103.47590637207031
test loss item: 403.9365539550781
test loss item: 214.18618774414062
test loss item: 201.45753479003906
test loss item: 159.6568145751953
test loss item: 14.346186637878418
test loss item: 109.02555084228516
test loss item: 224.5221710205078
test loss item: 139.29971313476562
test loss item: 219.76678466796875
test loss item: 177.98626708984375
test loss item: 89.12076568603516
test loss item: 76.31513977050781
test loss item: 196.98184204101562
test loss item: 185.42982482910156
test loss item: 193.0317840576172
test loss item: 139.58351135253906
test loss item: 392.52044677734375
test loss item: 117.28933715820312
test loss item: 191.39463806152344
test loss item: 317.12896728515625
test loss item: 196.3995361328125
test loss item: 307.9481506347656
test loss item: 153.33250427246094
test loss item: 20.645612716674805
test loss item: 406.4595947265625
test loss item: 147.2521514892578
test loss item: 50.480201721191406
test loss item: 172.25845336914062
test loss item: 311.2869873046875
test loss item: 222.57345581054688
test loss item: 146.69578552246094
test loss item: 168.74209594726562
test loss item: 293.5848693847656
test loss item: 121.58904266357422
test loss item: 146.02207946777344
test loss item: 49.03114318847656
test loss item: 133.844970703125
test loss item: 235.93679809570312
test loss item: 16.317113876342773
test loss item: 204.7295379638672
test loss item: 307.411865234375
test loss item: 128.5391845703125
test loss item: 100.72631072998047
test loss item: 147.0782928466797
test loss item: 12.050564765930176
test loss item: 182.52389526367188
test loss item: 119.85138702392578
test loss item: 329.3778991699219
test loss item: 195.74880981445312
test loss item: 145.92115783691406
test loss item: 221.43455505371094
test loss item: 112.62158203125
test loss item: 306.4727783203125
test loss item: 285.5953369140625
test loss item: 283.4070739746094
test loss item: 134.18812561035156
test loss item: 377.9163818359375
test loss item: 89.43124389648438
test loss item: 234.63430786132812
test loss item: 204.50035095214844
test loss item: 337.8183898925781
test loss item: 206.04635620117188
test loss item: 241.4140625
test loss item: 693.698486328125
Epoch [6/100], Training Loss: 0.7525, Testing Loss: 192.1196
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 7/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5607684850692749
1
train loss item: 1.926676630973816
2
train loss item: 0.35329684615135193
3
train loss item: 0.9597423076629639
4
train loss item: 0.5227727890014648
5
train loss item: 0.4508007764816284
6
train loss item: 0.4522921144962311
7
train loss item: 1.1024432182312012
8
train loss item: 0.22012585401535034
9
train loss item: 0.42723026871681213
10
train loss item: 0.49717867374420166
11
train loss item: 0.44841837882995605
12
train loss item: 0.14018264412879944
13
train loss item: 0.6654989719390869
14
train loss item: 0.32522228360176086
15
train loss item: 1.2281792163848877
16
train loss item: 0.13173611462116241
17
train loss item: 0.49172964692115784
18
train loss item: 0.5584751963615417
19
train loss item: 0.521047830581665
20
train loss item: 0.43972429633140564
21
train loss item: 0.2496684342622757
22
train loss item: 1.8391066789627075
23
train loss item: 1.164626121520996
24
train loss item: 0.976655125617981
25
train loss item: 0.24660524725914001
26
train loss item: 0.31871646642684937
27
train loss item: 0.37081149220466614
28
train loss item: 0.13135786354541779
29
train loss item: 1.4184701442718506
30
train loss item: 2.9813385009765625
31
train loss item: 0.7355334162712097
32
train loss item: 0.15874671936035156
33
train loss item: 0.5760723948478699
34
train loss item: 0.21040666103363037
35
train loss item: 2.8834216594696045
36
train loss item: 0.7677138447761536
37
train loss item: 0.6080870628356934
38
train loss item: 0.8013278245925903
39
train loss item: 0.37254300713539124
40
train loss item: 0.23103411495685577
41
train loss item: 0.3911621570587158
42
train loss item: 0.45177802443504333
43
train loss item: 0.2848416268825531
44
train loss item: 0.8446726202964783
45
train loss item: 0.17955805361270905
46
train loss item: 0.16463777422904968
47
train loss item: 0.6861543655395508
48
train loss item: 0.3559110760688782
49
train loss item: 0.21588771045207977
50
train loss item: 0.5786092877388
51
train loss item: 1.5088756084442139
52
train loss item: 0.1717795431613922
53
train loss item: 0.2368287891149521
54
train loss item: 2.7597692012786865
55
train loss item: 0.3183665871620178
56
train loss item: 0.3858959674835205
57
train loss item: 0.3778788149356842
58
train loss item: 0.272002637386322
59
train loss item: 0.22650496661663055
60
train loss item: 1.547382116317749
61
train loss item: 2.6094629764556885
62
train loss item: 0.3693045973777771
63
train loss item: 0.7556576132774353
64
train loss item: 0.24688805639743805
65
train loss item: 1.0776557922363281
66
train loss item: 0.6160284876823425
67
train loss item: 0.38643935322761536
68
train loss item: 0.708397626876831
69
train loss item: 0.5711262822151184
70
train loss item: 0.52189701795578
71
train loss item: 0.2561063766479492
72
train loss item: 0.28796645998954773
73
train loss item: 0.4740075170993805
74
train loss item: 0.17208364605903625
75
train loss item: 0.13727766275405884
76
train loss item: 1.197191596031189
77
train loss item: 1.9920690059661865
78
train loss item: 0.15299877524375916
79
train loss item: 0.5737409591674805
80
train loss item: 0.232942134141922
81
train loss item: 0.3285616636276245
82
train loss item: 0.317914217710495
83
train loss item: 1.215092420578003
84
train loss item: 0.6785671710968018
85
train loss item: 0.9451348781585693
86
train loss item: 4.934544563293457
87
train loss item: 0.2432193160057068
88
train loss item: 0.6013710498809814
epoch train loss: 0.7194149378645286
testing phase
test loss item: 29.274192810058594
test loss item: 18.11981201171875
test loss item: 2.0763919353485107
test loss item: 24.61143684387207
test loss item: 9.505044937133789
test loss item: 11.72424602508545
test loss item: 37.65914535522461
test loss item: 24.45854377746582
test loss item: 2.2086033821105957
test loss item: 3.9273390769958496
test loss item: 7.500892639160156
test loss item: 23.5261287689209
test loss item: 1.2914135456085205
test loss item: 43.845394134521484
test loss item: 11.692344665527344
test loss item: 28.7581787109375
test loss item: 1.8204401731491089
test loss item: 7.640153884887695
test loss item: 66.68626403808594
test loss item: 8.350934982299805
test loss item: 36.640594482421875
test loss item: 23.66779899597168
test loss item: 29.469741821289062
test loss item: 0.3994464874267578
test loss item: 7.319428443908691
test loss item: 50.59745407104492
test loss item: 6.379464626312256
test loss item: 5.975285053253174
test loss item: 14.872284889221191
test loss item: 0.8930281400680542
test loss item: 19.07354736328125
test loss item: 28.844356536865234
test loss item: 5.080907344818115
test loss item: 23.792264938354492
test loss item: 16.936445236206055
test loss item: 11.555089950561523
test loss item: 16.25121307373047
test loss item: 7.270370960235596
test loss item: 17.114681243896484
test loss item: 5.939759731292725
test loss item: 15.971391677856445
test loss item: 65.05948638916016
test loss item: 1.3123375177383423
test loss item: 17.224197387695312
test loss item: 30.896617889404297
test loss item: 21.392221450805664
test loss item: 28.908695220947266
test loss item: 12.208977699279785
test loss item: 2.3289201259613037
test loss item: 63.68441390991211
test loss item: 12.502114295959473
test loss item: 7.260521411895752
test loss item: 5.443305969238281
test loss item: 34.251869201660156
test loss item: 16.423215866088867
test loss item: 10.495035171508789
test loss item: 9.772098541259766
test loss item: 44.502464294433594
test loss item: 9.17160415649414
test loss item: 7.139128684997559
test loss item: 7.255197525024414
test loss item: 16.110315322875977
test loss item: 32.270599365234375
test loss item: 1.2586299180984497
test loss item: 24.13844108581543
test loss item: 34.62247848510742
test loss item: 4.717680931091309
test loss item: 8.049653053283691
test loss item: 15.92336654663086
test loss item: 15.266972541809082
test loss item: 20.055017471313477
test loss item: 37.78230667114258
test loss item: 35.220863342285156
test loss item: 28.76255226135254
test loss item: 9.375167846679688
test loss item: 17.704700469970703
test loss item: 7.635445594787598
test loss item: 13.802908897399902
test loss item: 44.19063949584961
test loss item: 31.40974998474121
test loss item: 14.445944786071777
test loss item: 68.6751480102539
test loss item: 17.49645233154297
test loss item: 8.602810859680176
test loss item: 17.964109420776367
test loss item: 63.051387786865234
test loss item: 22.31927490234375
test loss item: 28.763574600219727
test loss item: 130.95974731445312
Epoch [7/100], Training Loss: 0.7194, Testing Loss: 21.1970
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 8/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5261905789375305
1
train loss item: 1.8815093040466309
2
train loss item: 0.334087073802948
3
train loss item: 0.9091936945915222
4
train loss item: 0.4989086091518402
5
train loss item: 0.4167511463165283
6
train loss item: 0.3841474652290344
7
train loss item: 1.0699670314788818
8
train loss item: 0.2012716680765152
9
train loss item: 0.4094078838825226
10
train loss item: 0.4812868535518646
11
train loss item: 0.39548611640930176
12
train loss item: 0.12942124903202057
13
train loss item: 0.6368029713630676
14
train loss item: 0.3064843416213989
15
train loss item: 1.1815521717071533
16
train loss item: 0.09724964946508408
17
train loss item: 0.44703564047813416
18
train loss item: 0.5159271955490112
19
train loss item: 0.49059054255485535
20
train loss item: 0.3897812068462372
21
train loss item: 0.18639805912971497
22
train loss item: 1.785454273223877
23
train loss item: 1.1471267938613892
24
train loss item: 0.9325661063194275
25
train loss item: 0.22641023993492126
26
train loss item: 0.28639379143714905
27
train loss item: 0.34490838646888733
28
train loss item: 0.10615800321102142
29
train loss item: 1.3872405290603638
30
train loss item: 2.936075210571289
31
train loss item: 0.7216778993606567
32
train loss item: 0.16264352202415466
33
train loss item: 0.5739965438842773
34
train loss item: 0.14100129902362823
35
train loss item: 2.854309558868408
36
train loss item: 0.7120509743690491
37
train loss item: 0.5632851123809814
38
train loss item: 0.7622356414794922
39
train loss item: 0.33171844482421875
40
train loss item: 0.20960944890975952
41
train loss item: 0.3644246459007263
42
train loss item: 0.44512781500816345
43
train loss item: 0.2813429534435272
44
train loss item: 0.8206536173820496
45
train loss item: 0.19917233288288116
46
train loss item: 0.1626848727464676
47
train loss item: 0.6730755567550659
48
train loss item: 0.34580668807029724
49
train loss item: 0.20838603377342224
50
train loss item: 0.5450286269187927
51
train loss item: 1.4723633527755737
52
train loss item: 0.139985591173172
53
train loss item: 0.234366312623024
54
train loss item: 2.7319583892822266
55
train loss item: 0.3082907497882843
56
train loss item: 0.35070547461509705
57
train loss item: 0.3520001769065857
58
train loss item: 0.2554933428764343
59
train loss item: 0.20562435686588287
60
train loss item: 1.4962228536605835
61
train loss item: 2.585383653640747
62
train loss item: 0.34352433681488037
63
train loss item: 0.7016330361366272
64
train loss item: 0.25515466928482056
65
train loss item: 1.0155506134033203
66
train loss item: 0.5526156425476074
67
train loss item: 0.3439730703830719
68
train loss item: 0.6679310202598572
69
train loss item: 0.5637957453727722
70
train loss item: 0.4863538444042206
71
train loss item: 0.19932766258716583
72
train loss item: 0.27003246545791626
73
train loss item: 0.45723822712898254
74
train loss item: 0.10960523784160614
75
train loss item: 0.15374159812927246
76
train loss item: 1.1738535165786743
77
train loss item: 1.948042631149292
78
train loss item: 0.11716045439243317
79
train loss item: 0.5077100396156311
80
train loss item: 0.2175857126712799
81
train loss item: 0.31501054763793945
82
train loss item: 0.3138841986656189
83
train loss item: 1.1815367937088013
84
train loss item: 0.6088192462921143
85
train loss item: 0.9161341786384583
86
train loss item: 4.904420852661133
87
train loss item: 0.24947614967823029
88
train loss item: 0.556178092956543
epoch train loss: 0.6896932495946295
testing phase
test loss item: 4.63518762588501
test loss item: 2.1027517318725586
test loss item: 0.7715105414390564
test loss item: 3.2854652404785156
test loss item: 0.871174156665802
test loss item: 1.1470516920089722
test loss item: 7.60451078414917
test loss item: 4.816933631896973
test loss item: 0.3729412853717804
test loss item: 0.581008791923523
test loss item: 1.8923897743225098
test loss item: 3.3355493545532227
test loss item: 0.33144113421440125
test loss item: 7.105724334716797
test loss item: 1.2771002054214478
test loss item: 3.533783197402954
test loss item: 0.5164166688919067
test loss item: 1.4024797677993774
test loss item: 12.181984901428223
test loss item: 1.2082899808883667
test loss item: 5.020742416381836
test loss item: 3.227065324783325
test loss item: 3.9059512615203857
test loss item: 0.35053542256355286
test loss item: 1.0909963846206665
test loss item: 6.682380199432373
test loss item: 0.9084561467170715
test loss item: 0.3776666522026062
test loss item: 2.3321919441223145
test loss item: 0.5854926109313965
test loss item: 3.3928000926971436
test loss item: 3.5741097927093506
test loss item: 0.2939557433128357
test loss item: 3.6733920574188232
test loss item: 2.0331075191497803
test loss item: 1.8788388967514038
test loss item: 3.895296096801758
test loss item: 2.3921728134155273
test loss item: 2.5861284732818604
test loss item: 0.5398607850074768
test loss item: 2.0434210300445557
test loss item: 11.679802894592285
test loss item: 0.5923910140991211
test loss item: 2.567781925201416
test loss item: 3.651742458343506
test loss item: 2.8042993545532227
test loss item: 3.9158105850219727
test loss item: 1.5276432037353516
test loss item: 0.6792353987693787
test loss item: 9.021409034729004
test loss item: 1.9367659091949463
test loss item: 1.0425670146942139
test loss item: 0.44172191619873047
test loss item: 4.61857271194458
test loss item: 1.959934949874878
test loss item: 1.6902002096176147
test loss item: 2.039147138595581
test loss item: 7.037417888641357
test loss item: 1.3253735303878784
test loss item: 0.3171890676021576
test loss item: 1.2351149320602417
test loss item: 2.0091359615325928
test loss item: 4.917812824249268
test loss item: 0.4455571472644806
test loss item: 4.4553632736206055
test loss item: 4.774406433105469
test loss item: 0.593117356300354
test loss item: 0.7088049650192261
test loss item: 2.0743777751922607
test loss item: 3.3786120414733887
test loss item: 2.3479678630828857
test loss item: 6.815426349639893
test loss item: 4.534915924072266
test loss item: 4.2713623046875
test loss item: 0.8313164114952087
test loss item: 1.850317358970642
test loss item: 1.119567632675171
test loss item: 3.253239631652832
test loss item: 7.22829532623291
test loss item: 4.937180042266846
test loss item: 1.4998416900634766
test loss item: 12.178506851196289
test loss item: 3.491798162460327
test loss item: 1.7110826969146729
test loss item: 2.3581387996673584
test loss item: 11.997305870056152
test loss item: 2.555058479309082
test loss item: 3.54068660736084
test loss item: 23.527124404907227
Epoch [8/100], Training Loss: 0.6897, Testing Loss: 3.2949
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 9/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5008963346481323
1
train loss item: 1.8419960737228394
2
train loss item: 0.3138033449649811
3
train loss item: 0.8873890042304993
4
train loss item: 0.48258864879608154
5
train loss item: 0.3933088183403015
6
train loss item: 0.34448128938674927
7
train loss item: 1.0430988073349
8
train loss item: 0.18540768325328827
9
train loss item: 0.39656123518943787
10
train loss item: 0.4756363034248352
11
train loss item: 0.3732050955295563
12
train loss item: 0.13575555384159088
13
train loss item: 0.6071041226387024
14
train loss item: 0.28867244720458984
15
train loss item: 1.1371397972106934
16
train loss item: 0.09883623570203781
17
train loss item: 0.41871851682662964
18
train loss item: 0.4848158657550812
19
train loss item: 0.46221861243247986
20
train loss item: 0.34901806712150574
21
train loss item: 0.1561325043439865
22
train loss item: 1.7367268800735474
23
train loss item: 1.1337069272994995
24
train loss item: 0.9032079577445984
25
train loss item: 0.21852272748947144
26
train loss item: 0.2605217397212982
27
train loss item: 0.3265835642814636
28
train loss item: 0.1122811883687973
29
train loss item: 1.3580979108810425
30
train loss item: 2.8994977474212646
31
train loss item: 0.7155803442001343
32
train loss item: 0.15995773673057556
33
train loss item: 0.5629039406776428
34
train loss item: 0.12080159038305283
35
train loss item: 2.821160078048706
36
train loss item: 0.6810175776481628
37
train loss item: 0.5172445178031921
38
train loss item: 0.739145815372467
39
train loss item: 0.30303478240966797
40
train loss item: 0.1969151496887207
41
train loss item: 0.34709519147872925
42
train loss item: 0.43765461444854736
43
train loss item: 0.2768155336380005
44
train loss item: 0.8001705408096313
45
train loss item: 0.21291320025920868
46
train loss item: 0.16017858684062958
47
train loss item: 0.6510107517242432
48
train loss item: 0.3269619643688202
49
train loss item: 0.2089914083480835
50
train loss item: 0.5107414126396179
51
train loss item: 1.442151427268982
52
train loss item: 0.12398794293403625
53
train loss item: 0.23294231295585632
54
train loss item: 2.6995949745178223
55
train loss item: 0.2830786406993866
56
train loss item: 0.32815852761268616
57
train loss item: 0.3377278447151184
58
train loss item: 0.24372504651546478
59
train loss item: 0.18293406069278717
60
train loss item: 1.4498142004013062
61
train loss item: 2.569556951522827
62
train loss item: 0.3226715624332428
63
train loss item: 0.6704931259155273
64
train loss item: 0.2584972083568573
65
train loss item: 0.963245153427124
66
train loss item: 0.5296632051467896
67
train loss item: 0.30656328797340393
68
train loss item: 0.6247704029083252
69
train loss item: 0.551176130771637
70
train loss item: 0.45001107454299927
71
train loss item: 0.16778093576431274
72
train loss item: 0.2517733573913574
73
train loss item: 0.44302549958229065
74
train loss item: 0.11352110654115677
75
train loss item: 0.16641172766685486
76
train loss item: 1.1519765853881836
77
train loss item: 1.913063883781433
78
train loss item: 0.09683462977409363
79
train loss item: 0.46963682770729065
80
train loss item: 0.21475310623645782
81
train loss item: 0.30135852098464966
82
train loss item: 0.2928648293018341
83
train loss item: 1.1569172143936157
84
train loss item: 0.5808102488517761
85
train loss item: 0.896532416343689
86
train loss item: 4.857174873352051
87
train loss item: 0.24816307425498962
88
train loss item: 0.5205845832824707
epoch train loss: 0.6684289016248135
testing phase
test loss item: 1.4153518676757812
test loss item: 0.44596067070961
test loss item: 0.7096584439277649
test loss item: 0.8713239431381226
test loss item: 0.4049721658229828
test loss item: 0.2884518802165985
test loss item: 4.305753231048584
test loss item: 2.0241801738739014
test loss item: 0.2922353148460388
test loss item: 0.5569289326667786
test loss item: 1.2614082098007202
test loss item: 0.9174288511276245
test loss item: 0.26209720969200134
test loss item: 2.5092172622680664
test loss item: 0.3736642003059387
test loss item: 0.7584423422813416
test loss item: 0.468794584274292
test loss item: 0.7025678753852844
test loss item: 4.19722318649292
test loss item: 0.5826073288917542
test loss item: 1.8096455335617065
test loss item: 0.9725279211997986
test loss item: 1.0761992931365967
test loss item: 0.2653380036354065
test loss item: 0.3908248245716095
test loss item: 1.7765145301818848
test loss item: 0.5413155555725098
test loss item: 0.25266095995903015
test loss item: 0.9483507871627808
test loss item: 0.541612446308136
test loss item: 1.738486647605896
test loss item: 0.7786040902137756
test loss item: 0.20718039572238922
test loss item: 1.270975947380066
test loss item: 0.6771445870399475
test loss item: 0.8130353093147278
test loss item: 1.9397577047348022
test loss item: 1.7553690671920776
test loss item: 1.015175700187683
test loss item: 0.44454675912857056
test loss item: 0.6423308253288269
test loss item: 3.7596938610076904
test loss item: 0.5170904397964478
test loss item: 0.8140709400177002
test loss item: 1.2103809118270874
test loss item: 0.992234468460083
test loss item: 1.166764259338379
test loss item: 0.5234195590019226
test loss item: 0.6148073673248291
test loss item: 2.6734230518341064
test loss item: 0.7506895661354065
test loss item: 0.31902915239334106
test loss item: 0.3587283790111542
test loss item: 1.164077639579773
test loss item: 0.7384427785873413
test loss item: 1.0962868928909302
test loss item: 1.1048141717910767
test loss item: 2.3757102489471436
test loss item: 0.4272812604904175
test loss item: 0.2812708914279938
test loss item: 0.6969679594039917
test loss item: 0.551501989364624
test loss item: 1.4734255075454712
test loss item: 0.3533891439437866
test loss item: 2.0861339569091797
test loss item: 1.2734113931655884
test loss item: 0.45461103320121765
test loss item: 0.3936781883239746
test loss item: 0.777823269367218
test loss item: 1.2484816312789917
test loss item: 0.5056605339050293
test loss item: 3.052482843399048
test loss item: 1.330296516418457
test loss item: 1.3492133617401123
test loss item: 0.25860998034477234
test loss item: 0.3479948043823242
test loss item: 0.3698863089084625
test loss item: 2.322598457336426
test loss item: 2.6085593700408936
test loss item: 1.5879076719284058
test loss item: 0.32893168926239014
test loss item: 4.282411575317383
test loss item: 1.838644027709961
test loss item: 1.1728688478469849
test loss item: 0.8391405344009399
test loss item: 3.8644988536834717
test loss item: 0.5252659320831299
test loss item: 0.7721226811408997
test loss item: 7.7544097900390625
Epoch [9/100], Training Loss: 0.6684, Testing Loss: 1.2193
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 10/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4861049950122833
1
train loss item: 1.8051923513412476
2
train loss item: 0.2861803472042084
3
train loss item: 0.8643131256103516
4
train loss item: 0.5868417024612427
5
train loss item: 0.3822873830795288
6
train loss item: 0.3291281759738922
7
train loss item: 1.028601884841919
8
train loss item: 0.1698111891746521
9
train loss item: 0.3847709000110626
10
train loss item: 0.46388959884643555
11
train loss item: 0.3588963747024536
12
train loss item: 0.13874585926532745
13
train loss item: 0.5792500972747803
14
train loss item: 0.2724764049053192
15
train loss item: 1.099242091178894
16
train loss item: 0.09844200313091278
17
train loss item: 0.4011560380458832
18
train loss item: 0.46965551376342773
19
train loss item: 0.4365765452384949
20
train loss item: 0.31845444440841675
21
train loss item: 0.15102438628673553
22
train loss item: 1.692840576171875
23
train loss item: 1.1167936325073242
24
train loss item: 0.8853734135627747
25
train loss item: 0.21264301240444183
26
train loss item: 0.25218862295150757
27
train loss item: 0.30269455909729004
28
train loss item: 0.11220008134841919
29
train loss item: 1.3295471668243408
30
train loss item: 2.863866090774536
31
train loss item: 0.7051288485527039
32
train loss item: 0.15445028245449066
33
train loss item: 0.5357793569564819
34
train loss item: 0.11926575005054474
35
train loss item: 2.7927937507629395
36
train loss item: 0.6644423604011536
37
train loss item: 0.4872170686721802
38
train loss item: 0.7159695029258728
39
train loss item: 0.2851826846599579
40
train loss item: 0.1877748817205429
41
train loss item: 0.33279281854629517
42
train loss item: 0.42753782868385315
43
train loss item: 0.26479968428611755
44
train loss item: 0.7764772772789001
45
train loss item: 0.20859244465827942
46
train loss item: 0.15129093825817108
47
train loss item: 0.6262611746788025
48
train loss item: 0.30695733428001404
49
train loss item: 0.20828574895858765
50
train loss item: 0.4846822917461395
51
train loss item: 1.4159177541732788
52
train loss item: 0.10128758102655411
53
train loss item: 0.21540242433547974
54
train loss item: 2.671515703201294
55
train loss item: 0.2612287104129791
56
train loss item: 0.31787508726119995
57
train loss item: 0.32589322328567505
58
train loss item: 0.23145456612110138
59
train loss item: 0.1629592329263687
60
train loss item: 1.4126642942428589
61
train loss item: 2.5493128299713135
62
train loss item: 0.3154025971889496
63
train loss item: 0.6442998051643372
64
train loss item: 0.2483440637588501
65
train loss item: 0.9285319447517395
66
train loss item: 0.5207637548446655
67
train loss item: 0.2803442180156708
68
train loss item: 0.583650529384613
69
train loss item: 0.5340844988822937
70
train loss item: 0.42642077803611755
71
train loss item: 0.15523545444011688
72
train loss item: 0.22986148297786713
73
train loss item: 0.42720916867256165
74
train loss item: 0.1061815470457077
75
train loss item: 0.16099706292152405
76
train loss item: 1.1286393404006958
77
train loss item: 1.8817641735076904
78
train loss item: 0.0764949843287468
79
train loss item: 0.44626671075820923
80
train loss item: 0.1987297534942627
81
train loss item: 0.29250290989875793
82
train loss item: 0.2622082531452179
83
train loss item: 1.1321706771850586
84
train loss item: 0.5733901858329773
85
train loss item: 0.8783671259880066
86
train loss item: 4.820127010345459
87
train loss item: 0.22807303071022034
88
train loss item: 0.5077831149101257
epoch train loss: 0.6513283840391073
testing phase
test loss item: 0.6465536952018738
test loss item: 0.15147216618061066
test loss item: 0.6569714546203613
test loss item: 0.4261235296726227
test loss item: 0.33469659090042114
test loss item: 0.17306481301784515
test loss item: 3.624080181121826
test loss item: 1.3876558542251587
test loss item: 0.27391454577445984
test loss item: 0.5130000114440918
test loss item: 1.0992029905319214
test loss item: 0.3982168138027191
test loss item: 0.22609767317771912
test loss item: 1.505800485610962
test loss item: 0.22916166484355927
test loss item: 0.17892315983772278
test loss item: 0.4298320412635803
test loss item: 0.5839790105819702
test loss item: 2.2093262672424316
test loss item: 0.49219775199890137
test loss item: 1.5037990808486938
test loss item: 0.6411082744598389
test loss item: 0.528318464756012
test loss item: 0.2596774399280548
test loss item: 0.29709339141845703
test loss item: 0.6996183395385742
test loss item: 0.4996281564235687
test loss item: 0.2432260662317276
test loss item: 0.6783341765403748
test loss item: 0.4740464389324188
test loss item: 1.442176103591919
test loss item: 0.186695396900177
test loss item: 0.20655272901058197
test loss item: 1.0002830028533936
test loss item: 0.5206847190856934
test loss item: 0.6467905044555664
test loss item: 1.528018832206726
test loss item: 1.6357954740524292
test loss item: 0.728415846824646
test loss item: 0.43624648451805115
test loss item: 0.4752655327320099
test loss item: 1.7267876863479614
test loss item: 0.44573211669921875
test loss item: 0.45294708013534546
test loss item: 0.916002631187439
test loss item: 0.7522977590560913
test loss item: 0.7022454142570496
test loss item: 0.4010801613330841
test loss item: 0.5803750157356262
test loss item: 1.4209924936294556
test loss item: 0.5600839853286743
test loss item: 0.1880124807357788
test loss item: 0.34564533829689026
test loss item: 0.4713963568210602
test loss item: 0.5622454881668091
test loss item: 1.03703773021698
test loss item: 0.8961556553840637
test loss item: 1.403232455253601
test loss item: 0.3310844600200653
test loss item: 0.26813390851020813
test loss item: 0.5823677182197571
test loss item: 0.3510696291923523
test loss item: 0.6955950856208801
test loss item: 0.34125328063964844
test loss item: 1.57272469997406
test loss item: 0.5974783897399902
test loss item: 0.4340667426586151
test loss item: 0.3796912133693695
test loss item: 0.6275675296783447
test loss item: 0.8200361132621765
test loss item: 0.133931502699852
test loss item: 2.2748100757598877
test loss item: 0.8419560194015503
test loss item: 0.78729248046875
test loss item: 0.22615092992782593
test loss item: 0.23503464460372925
test loss item: 0.27432429790496826
test loss item: 1.7714563608169556
test loss item: 1.597555160522461
test loss item: 0.781466543674469
test loss item: 0.1398228108882904
test loss item: 2.413733720779419
test loss item: 1.5491507053375244
test loss item: 1.1321934461593628
test loss item: 0.5704789161682129
test loss item: 1.7952923774719238
test loss item: 0.14093667268753052
test loss item: 0.18416984379291534
test loss item: 3.650686025619507
Epoch [10/100], Training Loss: 0.6513, Testing Loss: 0.7925
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 11/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47880256175994873
1
train loss item: 1.7698723077774048
2
train loss item: 0.2748635709285736
3
train loss item: 0.8396556973457336
4
train loss item: 0.8638654947280884
5
train loss item: 0.38379397988319397
6
train loss item: 0.3207000494003296
7
train loss item: 1.0131804943084717
8
train loss item: 0.15946650505065918
9
train loss item: 0.3763669729232788
10
train loss item: 0.4552488923072815
11
train loss item: 0.3571434020996094
12
train loss item: 0.13109199702739716
13
train loss item: 0.5618051886558533
14
train loss item: 0.27132245898246765
15
train loss item: 1.065374493598938
16
train loss item: 0.08973803371191025
17
train loss item: 0.38557854294776917
18
train loss item: 0.4622604548931122
19
train loss item: 0.4142487049102783
20
train loss item: 0.29838308691978455
21
train loss item: 0.16383737325668335
22
train loss item: 1.6406463384628296
23
train loss item: 1.1020007133483887
24
train loss item: 0.8733376264572144
25
train loss item: 0.21081377565860748
26
train loss item: 0.2648095488548279
27
train loss item: 0.28732118010520935
28
train loss item: 0.09622316062450409
29
train loss item: 1.2989521026611328
30
train loss item: 2.8345329761505127
31
train loss item: 0.695460319519043
32
train loss item: 0.15607501566410065
33
train loss item: 0.5120772123336792
34
train loss item: 0.12558221817016602
35
train loss item: 2.7670841217041016
36
train loss item: 0.6485993266105652
37
train loss item: 0.47543662786483765
38
train loss item: 0.692664384841919
39
train loss item: 0.2800928056240082
40
train loss item: 0.1881055384874344
41
train loss item: 0.3297402858734131
42
train loss item: 0.41965410113334656
43
train loss item: 0.26091262698173523
44
train loss item: 0.7567780017852783
45
train loss item: 0.19810399413108826
46
train loss item: 0.14541266858577728
47
train loss item: 0.6041041612625122
48
train loss item: 0.29756489396095276
49
train loss item: 0.20887179672718048
50
train loss item: 0.4607560932636261
51
train loss item: 1.3884148597717285
52
train loss item: 0.08343155682086945
53
train loss item: 0.1994096040725708
54
train loss item: 2.6443004608154297
55
train loss item: 0.2485935539007187
56
train loss item: 0.32177475094795227
57
train loss item: 0.32242146134376526
58
train loss item: 0.23139061033725739
59
train loss item: 0.1460118442773819
60
train loss item: 1.3835688829421997
61
train loss item: 2.528242826461792
62
train loss item: 0.31875312328338623
63
train loss item: 0.6244175434112549
64
train loss item: 0.2413223385810852
65
train loss item: 0.8971490859985352
66
train loss item: 0.513041615486145
67
train loss item: 0.27983558177948
68
train loss item: 0.5457920432090759
69
train loss item: 0.5197794437408447
70
train loss item: 0.41119346022605896
71
train loss item: 0.15316027402877808
72
train loss item: 0.22377552092075348
73
train loss item: 0.416474848985672
74
train loss item: 0.09228436648845673
75
train loss item: 0.13887563347816467
76
train loss item: 1.1096526384353638
77
train loss item: 1.8529149293899536
78
train loss item: 0.07270421087741852
79
train loss item: 0.43265974521636963
80
train loss item: 0.17963330447673798
81
train loss item: 0.29014694690704346
82
train loss item: 0.24315577745437622
83
train loss item: 1.104414701461792
84
train loss item: 0.5705301761627197
85
train loss item: 0.8594452142715454
86
train loss item: 4.789554119110107
87
train loss item: 0.21253737807273865
88
train loss item: 0.5167037844657898
epoch train loss: 0.6413009224480457
testing phase
test loss item: 0.4205678701400757
test loss item: 0.11946181952953339
test loss item: 0.645322859287262
test loss item: 0.3283005654811859
test loss item: 0.2967665493488312
test loss item: 0.15626901388168335
test loss item: 3.301083564758301
test loss item: 1.1462585926055908
test loss item: 0.2621173858642578
test loss item: 0.49216851592063904
test loss item: 1.0321385860443115
test loss item: 0.2805926501750946
test loss item: 0.2129136323928833
test loss item: 1.2618756294250488
test loss item: 0.20633843541145325
test loss item: 0.07536020129919052
test loss item: 0.42091062664985657
test loss item: 0.5635349154472351
test loss item: 1.6612327098846436
test loss item: 0.44647926092147827
test loss item: 1.618263602256775
test loss item: 0.5793203711509705
test loss item: 0.41905856132507324
test loss item: 0.2538583278656006
test loss item: 0.28772255778312683
test loss item: 0.442613422870636
test loss item: 0.48352107405662537
test loss item: 0.23409892618656158
test loss item: 0.599484920501709
test loss item: 0.4502743184566498
test loss item: 1.3300952911376953
test loss item: 0.07584112137556076
test loss item: 0.2041272073984146
test loss item: 1.0012903213500977
test loss item: 0.5038327574729919
test loss item: 0.6063831448554993
test loss item: 1.3806700706481934
test loss item: 1.6196837425231934
test loss item: 0.6600843071937561
test loss item: 0.422985315322876
test loss item: 0.4572887122631073
test loss item: 1.1270439624786377
test loss item: 0.4234200716018677
test loss item: 0.36552566289901733
test loss item: 0.9149624109268188
test loss item: 0.6810210943222046
test loss item: 0.599886953830719
test loss item: 0.3576340973377228
test loss item: 0.565489649772644
test loss item: 1.1572086811065674
test loss item: 0.5739619731903076
test loss item: 0.16299821436405182
test loss item: 0.33877432346343994
test loss item: 0.2998683452606201
test loss item: 0.5938148498535156
test loss item: 1.0214797258377075
test loss item: 0.8099382519721985
test loss item: 1.2968326807022095
test loss item: 0.3142494857311249
test loss item: 0.25952523946762085
test loss item: 0.5487867593765259
test loss item: 0.325582355260849
test loss item: 0.47073042392730713
test loss item: 0.33265846967697144
test loss item: 1.3787603378295898
test loss item: 0.4439701735973358
test loss item: 0.41791799664497375
test loss item: 0.3693528175354004
test loss item: 0.6055952310562134
test loss item: 0.7163074612617493
test loss item: 0.07108129560947418
test loss item: 1.9711494445800781
test loss item: 0.8450144529342651
test loss item: 0.6541281342506409
test loss item: 0.2204584926366806
test loss item: 0.23115818202495575
test loss item: 0.25846216082572937
test loss item: 1.5975009202957153
test loss item: 1.3226642608642578
test loss item: 0.5440574884414673
test loss item: 0.11123376339673996
test loss item: 1.8780162334442139
test loss item: 1.4417592287063599
test loss item: 1.1113187074661255
test loss item: 0.4669135808944702
test loss item: 1.2693816423416138
test loss item: 0.09006297588348389
test loss item: 0.07715752720832825
test loss item: 2.450878143310547
Epoch [11/100], Training Loss: 0.6413, Testing Loss: 0.6859
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 12/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47094079852104187
1
train loss item: 1.7383192777633667
2
train loss item: 0.27455633878707886
3
train loss item: 0.8162466287612915
4
train loss item: 0.7688180804252625
5
train loss item: 0.3888839781284332
6
train loss item: 0.31486067175865173
7
train loss item: 0.9978872537612915
8
train loss item: 0.15468265116214752
9
train loss item: 0.36157578229904175
10
train loss item: 0.4486105144023895
11
train loss item: 0.3611766993999481
12
train loss item: 0.12029904872179031
13
train loss item: 0.5566061735153198
14
train loss item: 0.27717235684394836
15
train loss item: 1.0248780250549316
16
train loss item: 0.0869559496641159
17
train loss item: 0.37068355083465576
18
train loss item: 0.4494868814945221
19
train loss item: 0.3924252688884735
20
train loss item: 0.28655582666397095
21
train loss item: 0.16706091165542603
22
train loss item: 1.6123361587524414
23
train loss item: 1.096030831336975
24
train loss item: 0.8407382965087891
25
train loss item: 0.2084980607032776
26
train loss item: 0.25063854455947876
27
train loss item: 0.28336092829704285
28
train loss item: 0.08616667985916138
29
train loss item: 1.2593430280685425
30
train loss item: 2.801752805709839
31
train loss item: 0.6885546445846558
32
train loss item: 0.1504344791173935
33
train loss item: 0.5065780878067017
34
train loss item: 0.12792833149433136
35
train loss item: 2.7497451305389404
36
train loss item: 0.6291542649269104
37
train loss item: 0.4788488447666168
38
train loss item: 0.6655318737030029
39
train loss item: 0.2774782180786133
40
train loss item: 0.18409600853919983
41
train loss item: 0.3304053843021393
42
train loss item: 0.4141924977302551
43
train loss item: 0.25594362616539
44
train loss item: 0.7456105947494507
45
train loss item: 0.19578750431537628
46
train loss item: 0.14800381660461426
47
train loss item: 0.5810253620147705
48
train loss item: 0.2907106876373291
49
train loss item: 0.2088581770658493
50
train loss item: 0.4380030333995819
51
train loss item: 1.3579853773117065
52
train loss item: 0.085069939494133
53
train loss item: 0.1875554323196411
54
train loss item: 2.6246144771575928
55
train loss item: 0.2440977245569229
56
train loss item: 0.32630813121795654
57
train loss item: 0.3248763680458069
58
train loss item: 0.2290232926607132
59
train loss item: 0.13516949117183685
60
train loss item: 1.3611289262771606
61
train loss item: 2.51208758354187
62
train loss item: 0.3195035457611084
63
train loss item: 0.6054546236991882
64
train loss item: 0.2324831783771515
65
train loss item: 0.853663980960846
66
train loss item: 0.5016343593597412
67
train loss item: 0.272278755903244
68
train loss item: 0.5110476613044739
69
train loss item: 0.49989181756973267
70
train loss item: 0.3948966860771179
71
train loss item: 0.1501179039478302
72
train loss item: 0.21799947321414948
73
train loss item: 0.40251171588897705
74
train loss item: 0.08062136173248291
75
train loss item: 0.11757057160139084
76
train loss item: 1.099491000175476
77
train loss item: 1.8209456205368042
78
train loss item: 0.08480589836835861
79
train loss item: 0.41757574677467346
80
train loss item: 0.16966544091701508
81
train loss item: 0.28263506293296814
82
train loss item: 0.23931613564491272
83
train loss item: 1.0710368156433105
84
train loss item: 0.5601944923400879
85
train loss item: 0.8385640382766724
86
train loss item: 4.77608585357666
87
train loss item: 0.19847732782363892
88
train loss item: 0.5090752840042114
epoch train loss: 0.6286505580450712
testing phase
test loss item: 0.39493870735168457
test loss item: 0.10988331586122513
test loss item: 0.6487072706222534
test loss item: 0.3210059404373169
test loss item: 0.2879922091960907
test loss item: 0.1510932892560959
test loss item: 3.051313638687134
test loss item: 0.9560933709144592
test loss item: 0.2612771689891815
test loss item: 0.4925437271595001
test loss item: 1.0210219621658325
test loss item: 0.2738308012485504
test loss item: 0.21126769483089447
test loss item: 1.507859468460083
test loss item: 0.2019781917333603
test loss item: 0.07592138648033142
test loss item: 0.41293463110923767
test loss item: 0.5651660561561584
test loss item: 1.5734111070632935
test loss item: 0.3869779407978058
test loss item: 1.6983110904693604
test loss item: 0.5571568012237549
test loss item: 0.38428640365600586
test loss item: 0.24570995569229126
test loss item: 0.28909561038017273
test loss item: 0.3845244348049164
test loss item: 0.44637563824653625
test loss item: 0.23049476742744446
test loss item: 0.6361116766929626
test loss item: 0.44838544726371765
test loss item: 1.1484291553497314
test loss item: 0.08254929631948471
test loss item: 0.1978992521762848
test loss item: 0.9313223361968994
test loss item: 0.5087602138519287
test loss item: 0.5567909479141235
test loss item: 1.236987829208374
test loss item: 1.621719479560852
test loss item: 0.6536835432052612
test loss item: 0.40604642033576965
test loss item: 0.44780775904655457
test loss item: 1.080437421798706
test loss item: 0.4253149926662445
test loss item: 0.35490214824676514
test loss item: 0.9640694260597229
test loss item: 0.6081406474113464
test loss item: 0.6286302208900452
test loss item: 0.3159903883934021
test loss item: 0.5668401718139648
test loss item: 0.9701012372970581
test loss item: 0.6518033742904663
test loss item: 0.15931442379951477
test loss item: 0.3352523148059845
test loss item: 0.29218077659606934
test loss item: 0.6713932156562805
test loss item: 1.0027741193771362
test loss item: 0.7147861123085022
test loss item: 1.6098246574401855
test loss item: 0.31086117029190063
test loss item: 0.2543102204799652
test loss item: 0.5466068983078003
test loss item: 0.31437355279922485
test loss item: 0.43698254227638245
test loss item: 0.3228181004524231
test loss item: 1.182982325553894
test loss item: 0.42984476685523987
test loss item: 0.4042126536369324
test loss item: 0.35886624455451965
test loss item: 0.6058881878852844
test loss item: 0.5833759307861328
test loss item: 0.06761837750673294
test loss item: 1.7766047716140747
test loss item: 0.9698097109794617
test loss item: 0.607168972492218
test loss item: 0.2180759459733963
test loss item: 0.22456541657447815
test loss item: 0.24822691082954407
test loss item: 1.5965267419815063
test loss item: 1.5427311658859253
test loss item: 0.5423285961151123
test loss item: 0.11202066391706467
test loss item: 1.7499266862869263
test loss item: 1.2886139154434204
test loss item: 1.1073274612426758
test loss item: 0.4865458309650421
test loss item: 1.288103461265564
test loss item: 0.09813551604747772
test loss item: 0.08666641265153885
test loss item: 2.496262788772583
Epoch [12/100], Training Loss: 0.6287, Testing Loss: 0.6700
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 13/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4653775691986084
1
train loss item: 1.6991956233978271
2
train loss item: 0.2767004072666168
3
train loss item: 0.7929020524024963
4
train loss item: 0.5450616478919983
5
train loss item: 0.3920633792877197
6
train loss item: 0.3103664219379425
7
train loss item: 0.9840892553329468
8
train loss item: 0.15234021842479706
9
train loss item: 0.34072259068489075
10
train loss item: 0.44235965609550476
11
train loss item: 0.36258554458618164
12
train loss item: 0.11888422071933746
13
train loss item: 0.5560132265090942
14
train loss item: 0.2833858132362366
15
train loss item: 0.9744027256965637
16
train loss item: 0.09058521687984467
17
train loss item: 0.35889166593551636
18
train loss item: 0.4318784773349762
19
train loss item: 0.3708280920982361
20
train loss item: 0.2777349352836609
21
train loss item: 0.1592184603214264
22
train loss item: 1.5531402826309204
23
train loss item: 1.0954101085662842
24
train loss item: 0.7937746047973633
25
train loss item: 0.20087680220603943
26
train loss item: 0.22710704803466797
27
train loss item: 0.28428560495376587
28
train loss item: 0.08641105890274048
29
train loss item: 1.2100507020950317
30
train loss item: 2.766017436981201
31
train loss item: 0.6840894222259521
32
train loss item: 0.12384791672229767
33
train loss item: 0.5119659900665283
34
train loss item: 0.12131699174642563
35
train loss item: 2.7302470207214355
36
train loss item: 0.6089964509010315
37
train loss item: 0.4863284230232239
38
train loss item: 0.6293615698814392
39
train loss item: 0.2738727927207947
40
train loss item: 0.17653533816337585
41
train loss item: 0.3265036940574646
42
train loss item: 0.40686100721359253
43
train loss item: 0.24198272824287415
44
train loss item: 0.7395463585853577
45
train loss item: 0.1940280795097351
46
train loss item: 0.14757734537124634
47
train loss item: 0.5566232204437256
48
train loss item: 0.2825188636779785
49
train loss item: 0.20574912428855896
50
train loss item: 0.41665124893188477
51
train loss item: 1.325804352760315
52
train loss item: 0.09274286776781082
53
train loss item: 0.18124885857105255
54
train loss item: 2.6035258769989014
55
train loss item: 0.23937535285949707
56
train loss item: 0.3260173797607422
57
train loss item: 0.3194534480571747
58
train loss item: 0.2169296145439148
59
train loss item: 0.12709835171699524
60
train loss item: 1.3397070169448853
61
train loss item: 2.501042604446411
62
train loss item: 0.3141319453716278
63
train loss item: 0.5846328735351562
64
train loss item: 0.2153371125459671
65
train loss item: 0.8064279556274414
66
train loss item: 0.486355721950531
67
train loss item: 0.2560179531574249
68
train loss item: 0.4770757555961609
69
train loss item: 0.4730130434036255
70
train loss item: 0.3739515542984009
71
train loss item: 0.1427018791437149
72
train loss item: 0.2123609185218811
73
train loss item: 0.3856925666332245
74
train loss item: 0.07215413451194763
75
train loss item: 0.10460011661052704
76
train loss item: 1.0960248708724976
77
train loss item: 1.785562515258789
78
train loss item: 0.09736332297325134
79
train loss item: 0.39815428853034973
80
train loss item: 0.15826988220214844
81
train loss item: 0.26758894324302673
82
train loss item: 0.24032984673976898
83
train loss item: 1.0311726331710815
84
train loss item: 0.5445387363433838
85
train loss item: 0.8135591745376587
86
train loss item: 4.74826717376709
87
train loss item: 0.1845472902059555
88
train loss item: 0.48056960105895996
epoch train loss: 0.612254067083423
testing phase
test loss item: 0.34739235043525696
test loss item: 0.10503038018941879
test loss item: 0.659711480140686
test loss item: 0.32348430156707764
test loss item: 0.28747785091400146
test loss item: 0.1478041708469391
test loss item: 2.7548272609710693
test loss item: 0.8150598406791687
test loss item: 0.26224491000175476
test loss item: 0.49989888072013855
test loss item: 1.0485020875930786
test loss item: 0.27238503098487854
test loss item: 0.21597601473331451
test loss item: 1.4922653436660767
test loss item: 0.20025621354579926
test loss item: 0.08027024567127228
test loss item: 0.4011165499687195
test loss item: 0.5756645202636719
test loss item: 1.4206962585449219
test loss item: 0.3674444854259491
test loss item: 1.5634958744049072
test loss item: 0.5391802191734314
test loss item: 0.35582733154296875
test loss item: 0.2327078878879547
test loss item: 0.28859013319015503
test loss item: 0.32584547996520996
test loss item: 0.43588149547576904
test loss item: 0.23016852140426636
test loss item: 0.6281235814094543
test loss item: 0.4530644118785858
test loss item: 1.1092860698699951
test loss item: 0.08586975187063217
test loss item: 0.19049324095249176
test loss item: 0.8084245324134827
test loss item: 0.5213995575904846
test loss item: 0.550311803817749
test loss item: 1.1551424264907837
test loss item: 1.632997751235962
test loss item: 0.6603198051452637
test loss item: 0.38478317856788635
test loss item: 0.4330407679080963
test loss item: 0.8676664233207703
test loss item: 0.4263591170310974
test loss item: 0.34835273027420044
test loss item: 0.953911304473877
test loss item: 0.5678756833076477
test loss item: 0.5815979838371277
test loss item: 0.3010970950126648
test loss item: 0.5773335695266724
test loss item: 0.9009358882904053
test loss item: 0.6465846300125122
test loss item: 0.16251297295093536
test loss item: 0.33046960830688477
test loss item: 0.30951982736587524
test loss item: 0.6540035009384155
test loss item: 1.006831407546997
test loss item: 0.7074677348136902
test loss item: 1.590842366218567
test loss item: 0.30888083577156067
test loss item: 0.25447967648506165
test loss item: 0.5481722950935364
test loss item: 0.30690598487854004
test loss item: 0.3754459023475647
test loss item: 0.3147597908973694
test loss item: 1.0137717723846436
test loss item: 0.4394529461860657
test loss item: 0.3968612253665924
test loss item: 0.34783172607421875
test loss item: 0.6136714816093445
test loss item: 0.6024249792098999
test loss item: 0.06967026740312576
test loss item: 1.5387619733810425
test loss item: 0.9329805374145508
test loss item: 0.5579429268836975
test loss item: 0.21612338721752167
test loss item: 0.21379461884498596
test loss item: 0.23382259905338287
test loss item: 1.6137551069259644
test loss item: 1.5280348062515259
test loss item: 0.4812176525592804
test loss item: 0.11387604475021362
test loss item: 1.600174069404602
test loss item: 1.261572003364563
test loss item: 1.1166815757751465
test loss item: 0.477364718914032
test loss item: 1.1158367395401
test loss item: 0.10663972795009613
test loss item: 0.0947813168168068
test loss item: 2.179331064224243
Epoch [13/100], Training Loss: 0.6123, Testing Loss: 0.6379
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 14/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46337440609931946
1
train loss item: 1.6636788845062256
2
train loss item: 0.2877391576766968
3
train loss item: 0.7679114937782288
4
train loss item: 0.5641341805458069
5
train loss item: 0.39510685205459595
6
train loss item: 0.31181299686431885
7
train loss item: 0.9736213684082031
8
train loss item: 0.1554025113582611
9
train loss item: 0.3269082307815552
10
train loss item: 0.434547483921051
11
train loss item: 0.36677226424217224
12
train loss item: 0.12498635798692703
13
train loss item: 0.5578727722167969
14
train loss item: 0.286415159702301
15
train loss item: 0.9311413764953613
16
train loss item: 0.09579605609178543
17
train loss item: 0.3563084900379181
18
train loss item: 0.4185711741447449
19
train loss item: 0.35659119486808777
20
train loss item: 0.2766818106174469
21
train loss item: 0.1606214940547943
22
train loss item: 1.4884966611862183
23
train loss item: 1.0927784442901611
24
train loss item: 0.7567883729934692
25
train loss item: 0.19348573684692383
26
train loss item: 0.2271917313337326
27
train loss item: 0.28654909133911133
28
train loss item: 0.0897597074508667
29
train loss item: 1.1620821952819824
30
train loss item: 2.731220006942749
31
train loss item: 0.6781851649284363
32
train loss item: 0.10251927375793457
33
train loss item: 0.516555905342102
34
train loss item: 0.12370705604553223
35
train loss item: 2.7098450660705566
36
train loss item: 0.5973879098892212
37
train loss item: 0.4899696707725525
38
train loss item: 0.6019194722175598
39
train loss item: 0.2719094455242157
40
train loss item: 0.17602872848510742
41
train loss item: 0.3224095404148102
42
train loss item: 0.4027976989746094
43
train loss item: 0.2307867407798767
44
train loss item: 0.7342685461044312
45
train loss item: 0.1866464465856552
46
train loss item: 0.1464252769947052
47
train loss item: 0.5351840853691101
48
train loss item: 0.27964895963668823
49
train loss item: 0.20507504045963287
50
train loss item: 0.405370831489563
51
train loss item: 1.2941930294036865
52
train loss item: 0.10186681896448135
53
train loss item: 0.1820446401834488
54
train loss item: 2.5812389850616455
55
train loss item: 0.23812727630138397
56
train loss item: 0.324186235666275
57
train loss item: 0.318546324968338
58
train loss item: 0.20790624618530273
59
train loss item: 0.12204328924417496
60
train loss item: 1.307517170906067
61
train loss item: 2.488013505935669
62
train loss item: 0.3088012933731079
63
train loss item: 0.5665850043296814
64
train loss item: 0.20002378523349762
65
train loss item: 0.7741435766220093
66
train loss item: 0.4865225553512573
67
train loss item: 0.24952363967895508
68
train loss item: 0.44797348976135254
69
train loss item: 0.4531756341457367
70
train loss item: 0.35888078808784485
71
train loss item: 0.13696204125881195
72
train loss item: 0.2177838534116745
73
train loss item: 0.37534019351005554
74
train loss item: 0.06578528136014938
75
train loss item: 0.10253192484378815
76
train loss item: 1.0947905778884888
77
train loss item: 1.7496130466461182
78
train loss item: 0.10474231094121933
79
train loss item: 0.38540270924568176
80
train loss item: 0.14152365922927856
81
train loss item: 0.25205495953559875
82
train loss item: 0.24322381615638733
83
train loss item: 0.9939858913421631
84
train loss item: 0.5350879430770874
85
train loss item: 0.7914992570877075
86
train loss item: 4.715451717376709
87
train loss item: 0.18286778032779694
88
train loss item: 0.45632854104042053
epoch train loss: 0.6019918799735187
testing phase
test loss item: 0.27382349967956543
test loss item: 0.10970687121152878
test loss item: 0.673638105392456
test loss item: 0.30280300974845886
test loss item: 0.2947285771369934
test loss item: 0.1426885724067688
test loss item: 2.628673791885376
test loss item: 0.7862502336502075
test loss item: 0.26435744762420654
test loss item: 0.5062341690063477
test loss item: 1.0482728481292725
test loss item: 0.22335121035575867
test loss item: 0.22012142837047577
test loss item: 1.198886513710022
test loss item: 0.2022228240966797
test loss item: 0.08383843302726746
test loss item: 0.38613155484199524
test loss item: 0.5869778394699097
test loss item: 1.157399296760559
test loss item: 0.35017940402030945
test loss item: 1.2315505743026733
test loss item: 0.5054593682289124
test loss item: 0.33329737186431885
test loss item: 0.22322827577590942
test loss item: 0.285268098115921
test loss item: 0.28050610423088074
test loss item: 0.4245698153972626
test loss item: 0.2323366105556488
test loss item: 0.5733597874641418
test loss item: 0.4539468288421631
test loss item: 1.0738685131072998
test loss item: 0.08888615667819977
test loss item: 0.18731580674648285
test loss item: 0.6952001452445984
test loss item: 0.5338625907897949
test loss item: 0.5536512136459351
test loss item: 1.1283351182937622
test loss item: 1.6550347805023193
test loss item: 0.6612187623977661
test loss item: 0.3634587228298187
test loss item: 0.4151546359062195
test loss item: 0.5455780625343323
test loss item: 0.43067386746406555
test loss item: 0.32048577070236206
test loss item: 0.8530557751655579
test loss item: 0.5516111254692078
test loss item: 0.46718987822532654
test loss item: 0.29102054238319397
test loss item: 0.5841556191444397
test loss item: 0.862114429473877
test loss item: 0.5540733337402344
test loss item: 0.16483794152736664
test loss item: 0.32294225692749023
test loss item: 0.2643316388130188
test loss item: 0.5397099256515503
test loss item: 1.0200539827346802
test loss item: 0.701271116733551
test loss item: 1.2200310230255127
test loss item: 0.3043910562992096
test loss item: 0.25528913736343384
test loss item: 0.5560805797576904
test loss item: 0.29558777809143066
test loss item: 0.293182909488678
test loss item: 0.30781471729278564
test loss item: 1.0135616064071655
test loss item: 0.4115482568740845
test loss item: 0.3875446021556854
test loss item: 0.336248517036438
test loss item: 0.6254360675811768
test loss item: 0.6478581428527832
test loss item: 0.07187813520431519
test loss item: 1.4726136922836304
test loss item: 0.7101463079452515
test loss item: 0.5039674639701843
test loss item: 0.21139110624790192
test loss item: 0.19685088098049164
test loss item: 0.22327405214309692
test loss item: 1.640952706336975
test loss item: 1.266340970993042
test loss item: 0.35719063878059387
test loss item: 0.112299345433712
test loss item: 1.3725968599319458
test loss item: 1.2355495691299438
test loss item: 1.1322309970855713
test loss item: 0.4334522485733032
test loss item: 0.7615363001823425
test loss item: 0.10964728891849518
test loss item: 0.10046902298927307
test loss item: 1.452043890953064
Epoch [14/100], Training Loss: 0.6020, Testing Loss: 0.5824
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 15/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4671632647514343
1
train loss item: 1.6363542079925537
2
train loss item: 0.294514924287796
3
train loss item: 0.7445893883705139
4
train loss item: 0.6161081790924072
5
train loss item: 0.39956575632095337
6
train loss item: 0.3231945037841797
7
train loss item: 0.965021550655365
8
train loss item: 0.16085736453533173
9
train loss item: 0.32382696866989136
10
train loss item: 0.4299605190753937
11
train loss item: 0.3760101795196533
12
train loss item: 0.12984272837638855
13
train loss item: 0.5603998899459839
14
train loss item: 0.28711453080177307
15
train loss item: 0.9007739424705505
16
train loss item: 0.09588437527418137
17
train loss item: 0.3671416938304901
18
train loss item: 0.41169360280036926
19
train loss item: 0.353965699672699
20
train loss item: 0.2886165380477905
21
train loss item: 0.18350285291671753
22
train loss item: 1.4397776126861572
23
train loss item: 1.0860620737075806
24
train loss item: 0.7380911111831665
25
train loss item: 0.1909811943769455
26
train loss item: 0.24864600598812103
27
train loss item: 0.2861214876174927
28
train loss item: 0.08995570242404938
29
train loss item: 1.1189498901367188
30
train loss item: 2.699876308441162
31
train loss item: 0.6723579168319702
32
train loss item: 0.10043226182460785
33
train loss item: 0.515288233757019
34
train loss item: 0.13910908997058868
35
train loss item: 2.6931495666503906
36
train loss item: 0.5833277702331543
37
train loss item: 0.5047433376312256
38
train loss item: 0.5811029672622681
39
train loss item: 0.26984548568725586
40
train loss item: 0.17939510941505432
41
train loss item: 0.32017990946769714
42
train loss item: 0.4064119756221771
43
train loss item: 0.22461596131324768
44
train loss item: 0.7289320826530457
45
train loss item: 0.17203806340694427
46
train loss item: 0.141169011592865
47
train loss item: 0.5156086087226868
48
train loss item: 0.2802336513996124
49
train loss item: 0.2058941125869751
50
train loss item: 0.40659669041633606
51
train loss item: 1.2635612487792969
52
train loss item: 0.10468022525310516
53
train loss item: 0.18026794493198395
54
train loss item: 2.563450336456299
55
train loss item: 0.24000194668769836
56
train loss item: 0.3248046934604645
57
train loss item: 0.323066383600235
58
train loss item: 0.20487678050994873
59
train loss item: 0.11820376664400101
60
train loss item: 1.2744256258010864
61
train loss item: 2.4724087715148926
62
train loss item: 0.3051838278770447
63
train loss item: 0.5543348789215088
64
train loss item: 0.1902787685394287
65
train loss item: 0.7699298858642578
66
train loss item: 0.4863245189189911
67
train loss item: 0.2595745623111725
68
train loss item: 0.4281807839870453
69
train loss item: 0.4448907971382141
70
train loss item: 0.3552982807159424
71
train loss item: 0.13765911757946014
72
train loss item: 0.2214297652244568
73
train loss item: 0.37323781847953796
74
train loss item: 0.06210971623659134
75
train loss item: 0.10431613773107529
76
train loss item: 1.0915470123291016
77
train loss item: 1.7168787717819214
78
train loss item: 0.10588204860687256
79
train loss item: 0.3818494975566864
80
train loss item: 0.1245567798614502
81
train loss item: 0.24525146186351776
82
train loss item: 0.24159380793571472
83
train loss item: 0.9596534967422485
84
train loss item: 0.5202537775039673
85
train loss item: 0.7717361450195312
86
train loss item: 4.693483352661133
87
train loss item: 0.1844433844089508
88
train loss item: 0.45420071482658386
epoch train loss: 0.5967283448141613
testing phase
test loss item: 0.2937057316303253
test loss item: 0.2050788253545761
test loss item: 0.685018002986908
test loss item: 0.3928086757659912
test loss item: 0.3155716359615326
test loss item: 0.13687077164649963
test loss item: 2.507080554962158
test loss item: 0.738501787185669
test loss item: 0.29370635747909546
test loss item: 0.5078092813491821
test loss item: 1.0533883571624756
test loss item: 0.2517540752887726
test loss item: 0.21918271481990814
test loss item: 1.5527437925338745
test loss item: 0.20426127314567566
test loss item: 0.08379261195659637
test loss item: 0.37122687697410583
test loss item: 0.5958406925201416
test loss item: 1.1863040924072266
test loss item: 0.34012290835380554
test loss item: 1.0726346969604492
test loss item: 0.5076042413711548
test loss item: 0.3292783200740814
test loss item: 0.34421828389167786
test loss item: 0.28283631801605225
test loss item: 0.2683730125427246
test loss item: 0.41785988211631775
test loss item: 0.23286794126033783
test loss item: 0.6640123724937439
test loss item: 0.4486837685108185
test loss item: 1.0433646440505981
test loss item: 0.08869513124227524
test loss item: 0.32391512393951416
test loss item: 0.718652069568634
test loss item: 0.5422134399414062
test loss item: 0.5569838285446167
test loss item: 1.0932296514511108
test loss item: 1.6826751232147217
test loss item: 0.6833974123001099
test loss item: 0.34694594144821167
test loss item: 0.3997476398944855
test loss item: 0.5091981887817383
test loss item: 0.434465229511261
test loss item: 0.3482458293437958
test loss item: 0.8334608674049377
test loss item: 0.5360052585601807
test loss item: 0.46824780106544495
test loss item: 0.28632837533950806
test loss item: 0.5869936943054199
test loss item: 0.852077305316925
test loss item: 0.5746470093727112
test loss item: 0.16402553021907806
test loss item: 0.3149334490299225
test loss item: 0.3605082631111145
test loss item: 0.5547536611557007
test loss item: 1.0367257595062256
test loss item: 0.7036380171775818
test loss item: 1.5047889947891235
test loss item: 0.29673290252685547
test loss item: 0.25394558906555176
test loss item: 0.5610641241073608
test loss item: 0.2779533863067627
test loss item: 0.2980986535549164
test loss item: 0.3036331236362457
test loss item: 1.013183355331421
test loss item: 0.4851837456226349
test loss item: 0.3775193989276886
test loss item: 0.3275214731693268
test loss item: 0.6345304250717163
test loss item: 0.7025851607322693
test loss item: 0.0717175230383873
test loss item: 1.4025776386260986
test loss item: 0.7158656120300293
test loss item: 0.47913873195648193
test loss item: 0.20340465009212494
test loss item: 0.1828548014163971
test loss item: 0.32862553000450134
test loss item: 1.6755143404006958
test loss item: 1.6407166719436646
test loss item: 0.39458009600639343
test loss item: 0.10870867967605591
test loss item: 1.35980224609375
test loss item: 1.2113233804702759
test loss item: 1.1497231721878052
test loss item: 0.543754518032074
test loss item: 0.7322296500205994
test loss item: 0.10573327541351318
test loss item: 0.10061360895633698
test loss item: 1.5927914381027222
Epoch [15/100], Training Loss: 0.5967, Testing Loss: 0.6021
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 16/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47178319096565247
1
train loss item: 1.6106553077697754
2
train loss item: 0.2905922830104828
3
train loss item: 0.7255096435546875
4
train loss item: 0.6254229545593262
5
train loss item: 0.40398213267326355
6
train loss item: 0.3342418372631073
7
train loss item: 0.9593371748924255
8
train loss item: 0.1638084352016449
9
train loss item: 0.32680365443229675
10
train loss item: 0.4297567903995514
11
train loss item: 0.3839309513568878
12
train loss item: 0.12910236418247223
13
train loss item: 0.5610338449478149
14
train loss item: 0.281326562166214
15
train loss item: 0.8745598793029785
16
train loss item: 0.08972012251615524
17
train loss item: 0.3785754144191742
18
train loss item: 0.40734976530075073
19
train loss item: 0.3562255799770355
20
train loss item: 0.2987995743751526
21
train loss item: 0.21018843352794647
22
train loss item: 1.3919627666473389
23
train loss item: 1.0779942274093628
24
train loss item: 0.7292196154594421
25
train loss item: 0.1908639669418335
26
train loss item: 0.2722064256668091
27
train loss item: 0.28335312008857727
28
train loss item: 0.08379834145307541
29
train loss item: 1.0776660442352295
30
train loss item: 2.676081895828247
31
train loss item: 0.6687386631965637
32
train loss item: 0.10419218242168427
33
train loss item: 0.5105835199356079
34
train loss item: 0.15415824949741364
35
train loss item: 2.6781365871429443
36
train loss item: 0.5637863874435425
37
train loss item: 0.5200514793395996
38
train loss item: 0.5621607899665833
39
train loss item: 0.2670113146305084
40
train loss item: 0.18295301496982574
41
train loss item: 0.31820085644721985
42
train loss item: 0.41251692175865173
43
train loss item: 0.22080929577350616
44
train loss item: 0.7256225943565369
45
train loss item: 0.15349480509757996
46
train loss item: 0.13965286314487457
47
train loss item: 0.49897271394729614
48
train loss item: 0.2791667580604553
49
train loss item: 0.2009335160255432
50
train loss item: 0.4117847979068756
51
train loss item: 1.2361608743667603
52
train loss item: 0.10014623403549194
53
train loss item: 0.17495793104171753
54
train loss item: 2.5482490062713623
55
train loss item: 0.24288977682590485
56
train loss item: 0.3269749581813812
57
train loss item: 0.32928532361984253
58
train loss item: 0.20363271236419678
59
train loss item: 0.11332597583532333
60
train loss item: 1.2394236326217651
61
train loss item: 2.4584274291992188
62
train loss item: 0.29960963129997253
63
train loss item: 0.5431960821151733
64
train loss item: 0.18512922525405884
65
train loss item: 0.7711639404296875
66
train loss item: 0.4807363450527191
67
train loss item: 0.2726135551929474
68
train loss item: 0.41561293601989746
69
train loss item: 0.4456692039966583
70
train loss item: 0.3555145561695099
71
train loss item: 0.14358972012996674
72
train loss item: 0.2191215604543686
73
train loss item: 0.374493271112442
74
train loss item: 0.06017114967107773
75
train loss item: 0.10456345975399017
76
train loss item: 1.0871490240097046
77
train loss item: 1.686781883239746
78
train loss item: 0.09912825375795364
79
train loss item: 0.3802109956741333
80
train loss item: 0.11510106921195984
81
train loss item: 0.24307720363140106
82
train loss item: 0.23767946660518646
83
train loss item: 0.9270601868629456
84
train loss item: 0.5043560862541199
85
train loss item: 0.757418692111969
86
train loss item: 4.672129154205322
87
train loss item: 0.184274822473526
88
train loss item: 0.46314653754234314
epoch train loss: 0.5918084435750929
testing phase
test loss item: 0.5236892700195312
test loss item: 0.40198272466659546
test loss item: 0.6920490264892578
test loss item: 0.6881552934646606
test loss item: 0.3704150915145874
test loss item: 0.13516037166118622
test loss item: 2.396550416946411
test loss item: 0.664077639579773
test loss item: 0.5536640286445618
test loss item: 0.5047097206115723
test loss item: 1.1247332096099854
test loss item: 0.46700742840766907
test loss item: 0.2124261111021042
test loss item: 2.1270132064819336
test loss item: 0.20503678917884827
test loss item: 0.08484891057014465
test loss item: 0.3586787283420563
test loss item: 0.5967658162117004
test loss item: 1.21761953830719
test loss item: 0.33205631375312805
test loss item: 1.0707261562347412
test loss item: 0.6328165531158447
test loss item: 0.3449479937553406
test loss item: 0.6298605799674988
test loss item: 0.2802462875843048
test loss item: 0.2643652856349945
test loss item: 0.4283195734024048
test loss item: 0.27629953622817993
test loss item: 0.8077201843261719
test loss item: 0.44108325242996216
test loss item: 1.018245816230774
test loss item: 0.09086402505636215
test loss item: 0.6215677857398987
test loss item: 0.8440428972244263
test loss item: 0.545583963394165
test loss item: 0.5358047485351562
test loss item: 1.047266960144043
test loss item: 1.7075612545013428
test loss item: 0.7830570936203003
test loss item: 0.33698275685310364
test loss item: 0.3884979784488678
test loss item: 0.46617773175239563
test loss item: 0.4358076751232147
test loss item: 0.5179856419563293
test loss item: 0.8800713419914246
test loss item: 0.5176689624786377
test loss item: 0.508940577507019
test loss item: 0.28306975960731506
test loss item: 0.5830430388450623
test loss item: 0.846513569355011
test loss item: 0.6831695437431335
test loss item: 0.15840516984462738
test loss item: 0.3074721395969391
test loss item: 0.7154531478881836
test loss item: 0.6723880767822266
test loss item: 1.0531034469604492
test loss item: 0.8452835083007812
test loss item: 2.077418565750122
test loss item: 0.2882629632949829
test loss item: 0.25122421979904175
test loss item: 0.5667965412139893
test loss item: 0.2532656192779541
test loss item: 0.3871164619922638
test loss item: 0.30088695883750916
test loss item: 1.0058485269546509
test loss item: 0.7958754301071167
test loss item: 0.36683958768844604
test loss item: 0.32204174995422363
test loss item: 0.6397978663444519
test loss item: 0.6515925526618958
test loss item: 0.07423264533281326
test loss item: 1.3272583484649658
test loss item: 0.9272853136062622
test loss item: 0.5042009353637695
test loss item: 0.210954949259758
test loss item: 0.20487675070762634
test loss item: 0.5989401936531067
test loss item: 1.7601640224456787
test loss item: 2.214028835296631
test loss item: 0.5121932625770569
test loss item: 0.10923033207654953
test loss item: 1.3622411489486694
test loss item: 1.160287857055664
test loss item: 1.1639991998672485
test loss item: 0.694328784942627
test loss item: 0.6750561594963074
test loss item: 0.14667709171772003
test loss item: 0.10110187530517578
test loss item: 1.8132339715957642
Epoch [16/100], Training Loss: 0.5918, Testing Loss: 0.6707
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 17/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4741816222667694
1
train loss item: 1.5831904411315918
2
train loss item: 0.278838574886322
3
train loss item: 0.7122685313224792
4
train loss item: 0.5877336263656616
5
train loss item: 0.40719231963157654
6
train loss item: 0.3373106122016907
7
train loss item: 0.9563984274864197
8
train loss item: 0.1620555967092514
9
train loss item: 0.328779011964798
10
train loss item: 0.43246516585350037
11
train loss item: 0.3864893317222595
12
train loss item: 0.12289568781852722
13
train loss item: 0.5590303540229797
14
train loss item: 0.28060591220855713
15
train loss item: 0.8471096158027649
16
train loss item: 0.07900825887918472
17
train loss item: 0.3786787688732147
18
train loss item: 0.4039078652858734
19
train loss item: 0.3564578890800476
20
train loss item: 0.29809170961380005
21
train loss item: 0.2256886512041092
22
train loss item: 1.3441338539123535
23
train loss item: 1.0737004280090332
24
train loss item: 0.7216583490371704
25
train loss item: 0.19144952297210693
26
train loss item: 0.2843727767467499
27
train loss item: 0.2809247076511383
28
train loss item: 0.07260557264089584
29
train loss item: 1.0386797189712524
30
train loss item: 2.656083106994629
31
train loss item: 0.6709092855453491
32
train loss item: 0.10496176034212112
33
train loss item: 0.5068352818489075
34
train loss item: 0.161063089966774
35
train loss item: 2.664412021636963
36
train loss item: 0.5446515083312988
37
train loss item: 0.5309215784072876
38
train loss item: 0.5452092289924622
39
train loss item: 0.26543790102005005
40
train loss item: 0.18857350945472717
41
train loss item: 0.31625694036483765
42
train loss item: 0.4135817289352417
43
train loss item: 0.21812543272972107
44
train loss item: 0.7262997031211853
45
train loss item: 0.13815976679325104
46
train loss item: 0.14156079292297363
47
train loss item: 0.4850063621997833
48
train loss item: 0.2747229039669037
49
train loss item: 0.18941114842891693
50
train loss item: 0.4087645709514618
51
train loss item: 1.2115269899368286
52
train loss item: 0.09220170229673386
53
train loss item: 0.16933731734752655
54
train loss item: 2.5336241722106934
55
train loss item: 0.24377493560314178
56
train loss item: 0.33357539772987366
57
train loss item: 0.33281370997428894
58
train loss item: 0.2011183202266693
59
train loss item: 0.11087584495544434
60
train loss item: 1.2051295042037964
61
train loss item: 2.450059175491333
62
train loss item: 0.2912934422492981
63
train loss item: 0.5302965044975281
64
train loss item: 0.18289758265018463
65
train loss item: 0.758758544921875
66
train loss item: 0.4696449041366577
67
train loss item: 0.27928802371025085
68
train loss item: 0.40240466594696045
69
train loss item: 0.4478578567504883
70
train loss item: 0.35304343700408936
71
train loss item: 0.14890560507774353
72
train loss item: 0.21429337561130524
73
train loss item: 0.37934601306915283
74
train loss item: 0.05936463549733162
75
train loss item: 0.10332164913415909
76
train loss item: 1.0816720724105835
77
train loss item: 1.657785415649414
78
train loss item: 0.08514221757650375
79
train loss item: 0.37528321146965027
80
train loss item: 0.11313781142234802
81
train loss item: 0.2393043339252472
82
train loss item: 0.2319851517677307
83
train loss item: 0.8985320329666138
84
train loss item: 0.4926140308380127
85
train loss item: 0.7505854368209839
86
train loss item: 4.653926849365234
87
train loss item: 0.1838158369064331
88
train loss item: 0.46791353821754456
epoch train loss: 0.5853179974920963
testing phase
test loss item: 0.778448224067688
test loss item: 0.45115724205970764
test loss item: 0.696083664894104
test loss item: 0.9102843403816223
test loss item: 0.37663888931274414
test loss item: 0.1392698884010315
test loss item: 2.3118319511413574
test loss item: 0.6728098392486572
test loss item: 0.8505887389183044
test loss item: 0.5015709400177002
test loss item: 1.2733540534973145
test loss item: 0.733497679233551
test loss item: 0.20503486692905426
test loss item: 2.1018781661987305
test loss item: 0.2055562138557434
test loss item: 0.08378063142299652
test loss item: 0.34956875443458557
test loss item: 0.5923557877540588
test loss item: 1.0549850463867188
test loss item: 0.32722851634025574
test loss item: 1.1041219234466553
test loss item: 0.8051728010177612
test loss item: 0.36097201704978943
test loss item: 0.7180910110473633
test loss item: 0.2772563695907593
test loss item: 0.2628060579299927
test loss item: 0.5338261723518372
test loss item: 0.3493165075778961
test loss item: 0.7936413288116455
test loss item: 0.43482163548469543
test loss item: 1.033223032951355
test loss item: 0.09009508043527603
test loss item: 0.7133759260177612
test loss item: 1.1185729503631592
test loss item: 0.5457256436347961
test loss item: 0.5206199884414673
test loss item: 1.0039705038070679
test loss item: 1.7317662239074707
test loss item: 0.9283127784729004
test loss item: 0.33260247111320496
test loss item: 0.38167905807495117
test loss item: 0.31040364503860474
test loss item: 0.43555715680122375
test loss item: 0.7186704874038696
test loss item: 0.9281030893325806
test loss item: 0.5034196376800537
test loss item: 0.5416565537452698
test loss item: 0.2862633168697357
test loss item: 0.5783008933067322
test loss item: 0.8424529433250427
test loss item: 0.6725457906723022
test loss item: 0.15154412388801575
test loss item: 0.30192604660987854
test loss item: 1.0612187385559082
test loss item: 0.6599470376968384
test loss item: 1.0705195665359497
test loss item: 1.058255910873413
test loss item: 2.0336363315582275
test loss item: 0.2810119688510895
test loss item: 0.2493419647216797
test loss item: 0.5653489828109741
test loss item: 0.23149126768112183
test loss item: 0.4094878137111664
test loss item: 0.3005349338054657
test loss item: 0.9971536993980408
test loss item: 1.1245999336242676
test loss item: 0.35930490493774414
test loss item: 0.334946870803833
test loss item: 0.6442634463310242
test loss item: 0.47860923409461975
test loss item: 0.07600229233503342
test loss item: 1.2646701335906982
test loss item: 0.9631553888320923
test loss item: 0.5216453075408936
test loss item: 0.40884730219841003
test loss item: 0.4691760241985321
test loss item: 0.6909782290458679
test loss item: 1.879669427871704
test loss item: 2.1873714923858643
test loss item: 0.4959357976913452
test loss item: 0.12093138694763184
test loss item: 1.2729016542434692
test loss item: 1.1063077449798584
test loss item: 1.179098129272461
test loss item: 0.6908490061759949
test loss item: 0.41248032450675964
test loss item: 0.48618730902671814
test loss item: 0.09941166639328003
test loss item: 1.4256088733673096
Epoch [17/100], Training Loss: 0.5853, Testing Loss: 0.7027
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 18/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4768312871456146
1
train loss item: 1.5584571361541748
2
train loss item: 0.27231377363204956
3
train loss item: 0.7046030759811401
4
train loss item: 0.5275874733924866
5
train loss item: 0.40858718752861023
6
train loss item: 0.3298797607421875
7
train loss item: 0.9554533958435059
8
train loss item: 0.1575060486793518
9
train loss item: 0.3289421796798706
10
train loss item: 0.4364463686943054
11
train loss item: 0.38396361470222473
12
train loss item: 0.11500533670186996
13
train loss item: 0.5555550456047058
14
train loss item: 0.276787132024765
15
train loss item: 0.8212077617645264
16
train loss item: 0.06680203229188919
17
train loss item: 0.37070736289024353
18
train loss item: 0.4016857445240021
19
train loss item: 0.35322725772857666
20
train loss item: 0.289168119430542
21
train loss item: 0.22728081047534943
22
train loss item: 1.302729606628418
23
train loss item: 1.0732463598251343
24
train loss item: 0.7210332155227661
25
train loss item: 0.18810659646987915
26
train loss item: 0.28082412481307983
27
train loss item: 0.2800900340080261
28
train loss item: 0.059930045157670975
29
train loss item: 1.0075794458389282
30
train loss item: 2.6427321434020996
31
train loss item: 0.6775880455970764
32
train loss item: 0.10244054347276688
33
train loss item: 0.5054564476013184
34
train loss item: 0.1596183329820633
35
train loss item: 2.65579891204834
36
train loss item: 0.5325554013252258
37
train loss item: 0.5372017025947571
38
train loss item: 0.5362136960029602
39
train loss item: 0.26618364453315735
40
train loss item: 0.19260847568511963
41
train loss item: 0.3168686032295227
42
train loss item: 0.4076680541038513
43
train loss item: 0.2171536684036255
44
train loss item: 0.7306571006774902
45
train loss item: 0.1317499727010727
46
train loss item: 0.1452709287405014
47
train loss item: 0.47395479679107666
48
train loss item: 0.2703343629837036
49
train loss item: 0.1784634292125702
50
train loss item: 0.40231242775917053
51
train loss item: 1.1896438598632812
52
train loss item: 0.08419718593358994
53
train loss item: 0.16717574000358582
54
train loss item: 2.523463010787964
55
train loss item: 0.24287880957126617
56
train loss item: 0.34256717562675476
57
train loss item: 0.3315661549568176
58
train loss item: 0.19713470339775085
59
train loss item: 0.11450671404600143
60
train loss item: 1.1771377325057983
61
train loss item: 2.447265148162842
62
train loss item: 0.2835659086704254
63
train loss item: 0.5172621011734009
64
train loss item: 0.1846424639225006
65
train loss item: 0.7466301918029785
66
train loss item: 0.4606435000896454
67
train loss item: 0.27768397331237793
68
train loss item: 0.3894059360027313
69
train loss item: 0.4474147856235504
70
train loss item: 0.3477148413658142
71
train loss item: 0.15128056704998016
72
train loss item: 0.2124711573123932
73
train loss item: 0.3796289265155792
74
train loss item: 0.06160629540681839
75
train loss item: 0.10370463877916336
76
train loss item: 1.077339768409729
77
train loss item: 1.6301170587539673
78
train loss item: 0.06980431824922562
79
train loss item: 0.3687571883201599
80
train loss item: 0.11449875682592392
81
train loss item: 0.23322255909442902
82
train loss item: 0.22726097702980042
83
train loss item: 0.8752715587615967
84
train loss item: 0.4830400347709656
85
train loss item: 0.750203013420105
86
train loss item: 4.644121170043945
87
train loss item: 0.18549089133739471
88
train loss item: 0.46429798007011414
epoch train loss: 0.5788649979853229
testing phase
test loss item: 0.6705775260925293
test loss item: 0.30422496795654297
test loss item: 0.6966654062271118
test loss item: 0.7728142738342285
test loss item: 0.3289653956890106
test loss item: 0.14786195755004883
test loss item: 2.2664482593536377
test loss item: 0.649376630783081
test loss item: 0.7394468784332275
test loss item: 0.4991703927516937
test loss item: 1.2354031801223755
test loss item: 0.6812174916267395
test loss item: 0.20223310589790344
test loss item: 1.3099993467330933
test loss item: 0.20583952963352203
test loss item: 0.08055263757705688
test loss item: 0.3446890413761139
test loss item: 0.5869736671447754
test loss item: 0.8404855132102966
test loss item: 0.33118271827697754
test loss item: 1.0321807861328125
test loss item: 0.7357768416404724
test loss item: 0.36082035303115845
test loss item: 0.504401683807373
test loss item: 0.2741978168487549
test loss item: 0.2639910578727722
test loss item: 0.5461609959602356
test loss item: 0.31813594698905945
test loss item: 0.5891938805580139
test loss item: 0.43152081966400146
test loss item: 1.0347167253494263
test loss item: 0.08652359992265701
test loss item: 0.49769309163093567
test loss item: 1.0869114398956299
test loss item: 0.5432525277137756
test loss item: 0.520534098148346
test loss item: 0.9812160134315491
test loss item: 1.7445318698883057
test loss item: 0.8860728740692139
test loss item: 0.3339292109012604
test loss item: 0.37862324714660645
test loss item: 0.2126161903142929
test loss item: 0.44114625453948975
test loss item: 0.6541360020637512
test loss item: 0.8656798005104065
test loss item: 0.5004228949546814
test loss item: 0.4615764021873474
test loss item: 0.3017268776893616
test loss item: 0.5752807855606079
test loss item: 0.8413575291633606
test loss item: 0.512520968914032
test loss item: 0.1482972800731659
test loss item: 0.2983468174934387
test loss item: 0.9465591311454773
test loss item: 0.4831976592540741
test loss item: 1.0795255899429321
test loss item: 0.9447394013404846
test loss item: 1.2234464883804321
test loss item: 0.27743595838546753
test loss item: 0.24894697964191437
test loss item: 0.5640102624893188
test loss item: 0.22131359577178955
test loss item: 0.31922006607055664
test loss item: 0.3029499650001526
test loss item: 0.9934269785881042
test loss item: 1.014504075050354
test loss item: 0.35709816217422485
test loss item: 0.34152767062187195
test loss item: 0.6466010808944702
test loss item: 0.46954500675201416
test loss item: 0.0740082859992981
test loss item: 1.2349761724472046
test loss item: 0.6777136325836182
test loss item: 0.48497676849365234
test loss item: 0.41339996457099915
test loss item: 0.47615915536880493
test loss item: 0.4918529689311981
test loss item: 1.8445993661880493
test loss item: 1.4040696620941162
test loss item: 0.33785396814346313
test loss item: 0.13830842077732086
test loss item: 1.1787488460540771
test loss item: 1.090083360671997
test loss item: 1.1875786781311035
test loss item: 0.4882241189479828
test loss item: 0.27988705039024353
test loss item: 0.4988635778427124
test loss item: 0.09480553865432739
test loss item: 0.694891631603241
Epoch [18/100], Training Loss: 0.5789, Testing Loss: 0.6223
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 19/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.482753187417984
1
train loss item: 1.5394679307937622
2
train loss item: 0.2771599590778351
3
train loss item: 0.7006429433822632
4
train loss item: 0.47966432571411133
5
train loss item: 0.4081529378890991
6
train loss item: 0.3199339210987091
7
train loss item: 0.9552167654037476
8
train loss item: 0.15332067012786865
9
train loss item: 0.33051690459251404
10
train loss item: 0.4395042359828949
11
train loss item: 0.3766477406024933
12
train loss item: 0.11107536405324936
13
train loss item: 0.5527011752128601
14
train loss item: 0.27088862657546997
15
train loss item: 0.8012568950653076
16
train loss item: 0.05905230715870857
17
train loss item: 0.36274632811546326
18
train loss item: 0.4022640585899353
19
train loss item: 0.3475485146045685
20
train loss item: 0.2798481285572052
21
train loss item: 0.21885396540164948
22
train loss item: 1.2748079299926758
23
train loss item: 1.0743286609649658
24
train loss item: 0.7282713651657104
25
train loss item: 0.18607604503631592
26
train loss item: 0.2704872786998749
27
train loss item: 0.27981138229370117
28
train loss item: 0.05229675769805908
29
train loss item: 0.9894734621047974
30
train loss item: 2.6336565017700195
31
train loss item: 0.6844327449798584
32
train loss item: 0.10295959562063217
33
train loss item: 0.5050162672996521
34
train loss item: 0.1520448625087738
35
train loss item: 2.6518242359161377
36
train loss item: 0.5305816531181335
37
train loss item: 0.5385941863059998
38
train loss item: 0.539892315864563
39
train loss item: 0.26929771900177
40
train loss item: 0.19277054071426392
41
train loss item: 0.3216620981693268
42
train loss item: 0.3950452208518982
43
train loss item: 0.2185748964548111
44
train loss item: 0.7369364500045776
45
train loss item: 0.13415385782718658
46
train loss item: 0.14834457635879517
47
train loss item: 0.4668557345867157
48
train loss item: 0.27021101117134094
49
train loss item: 0.17433661222457886
50
train loss item: 0.39669135212898254
51
train loss item: 1.1713874340057373
52
train loss item: 0.07673970609903336
53
train loss item: 0.16934806108474731
54
train loss item: 2.5170178413391113
55
train loss item: 0.24282026290893555
56
train loss item: 0.3508146107196808
57
train loss item: 0.3254255950450897
58
train loss item: 0.19379931688308716
59
train loss item: 0.11736885458230972
60
train loss item: 1.1577776670455933
61
train loss item: 2.4455618858337402
62
train loss item: 0.2781938314437866
63
train loss item: 0.5047089457511902
64
train loss item: 0.19007325172424316
65
train loss item: 0.7500156760215759
66
train loss item: 0.45646926760673523
67
train loss item: 0.2709132134914398
68
train loss item: 0.3800494372844696
69
train loss item: 0.44504135847091675
70
train loss item: 0.342147558927536
71
train loss item: 0.150846928358078
72
train loss item: 0.21330279111862183
73
train loss item: 0.378251850605011
74
train loss item: 0.06635107845067978
75
train loss item: 0.10878245532512665
76
train loss item: 1.0728076696395874
77
train loss item: 1.6067345142364502
78
train loss item: 0.059995137155056
79
train loss item: 0.36090973019599915
80
train loss item: 0.11605889350175858
81
train loss item: 0.22719699144363403
82
train loss item: 0.22602635622024536
83
train loss item: 0.8588120341300964
84
train loss item: 0.47507426142692566
85
train loss item: 0.753808856010437
86
train loss item: 4.637316703796387
87
train loss item: 0.1898706704378128
88
train loss item: 0.4604547917842865
epoch train loss: 0.574572221239966
testing phase
test loss item: 0.343805193901062
test loss item: 0.149579256772995
test loss item: 0.6946437358856201
test loss item: 0.42766761779785156
test loss item: 0.30688101053237915
test loss item: 0.15658310055732727
test loss item: 2.2577173709869385
test loss item: 0.5508029460906982
test loss item: 0.40217044949531555
test loss item: 0.4974578320980072
test loss item: 1.1030362844467163
test loss item: 0.39405664801597595
test loss item: 0.2054988443851471
test loss item: 0.5396341681480408
test loss item: 0.20579111576080322
test loss item: 0.07606495171785355
test loss item: 0.343936562538147
test loss item: 0.5827085971832275
test loss item: 0.7765547037124634
test loss item: 0.34184566140174866
test loss item: 0.96269690990448
test loss item: 0.5101994872093201
test loss item: 0.3631771206855774
test loss item: 0.2654804587364197
test loss item: 0.27165287733078003
test loss item: 0.26819702982902527
test loss item: 0.451542466878891
test loss item: 0.2543186545372009
test loss item: 0.44131094217300415
test loss item: 0.4308575689792633
test loss item: 1.0015003681182861
test loss item: 0.08084855228662491
test loss item: 0.24616938829421997
test loss item: 0.8074705004692078
test loss item: 0.5398759841918945
test loss item: 0.5249394178390503
test loss item: 0.9786133170127869
test loss item: 1.7417374849319458
test loss item: 0.7141444087028503
test loss item: 0.3386189937591553
test loss item: 0.3782244622707367
test loss item: 0.2203417718410492
test loss item: 0.44182029366493225
test loss item: 0.3925826847553253
test loss item: 0.8067881464958191
test loss item: 0.5052306652069092
test loss item: 0.3711021840572357
test loss item: 0.3168467879295349
test loss item: 0.5734863877296448
test loss item: 0.840575098991394
test loss item: 0.4259977340698242
test loss item: 0.14999382197856903
test loss item: 0.2965923249721527
test loss item: 0.48418736457824707
test loss item: 0.3879862427711487
test loss item: 1.070515751838684
test loss item: 0.6894058585166931
test loss item: 0.46822065114974976
test loss item: 0.278480589389801
test loss item: 0.2502273619174957
test loss item: 0.5614140629768372
test loss item: 0.22003574669361115
test loss item: 0.2543838620185852
test loss item: 0.3077516257762909
test loss item: 0.9950470924377441
test loss item: 0.5786739587783813
test loss item: 0.35993924736976624
test loss item: 0.3231230080127716
test loss item: 0.6481091976165771
test loss item: 0.4785112738609314
test loss item: 0.0714411735534668
test loss item: 1.2334593534469604
test loss item: 0.47377535700798035
test loss item: 0.46635347604751587
test loss item: 0.23656606674194336
test loss item: 0.2647184729576111
test loss item: 0.26614055037498474
test loss item: 1.7469197511672974
test loss item: 0.6795587539672852
test loss item: 0.24476845562458038
test loss item: 0.10844258964061737
test loss item: 1.1539764404296875
test loss item: 1.0848748683929443
test loss item: 1.1865828037261963
test loss item: 0.3140411674976349
test loss item: 0.27417147159576416
test loss item: 0.2169419527053833
test loss item: 0.0885683074593544
test loss item: 0.25415223836898804
Epoch [19/100], Training Loss: 0.5746, Testing Loss: 0.5168
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 20/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.48939967155456543
1
train loss item: 1.5246821641921997
2
train loss item: 0.28371766209602356
3
train loss item: 0.6976882219314575
4
train loss item: 0.4569762647151947
5
train loss item: 0.4059332311153412
6
train loss item: 0.31324103474617004
7
train loss item: 0.9552748203277588
8
train loss item: 0.15135686099529266
9
train loss item: 0.3347167372703552
10
train loss item: 0.43986427783966064
11
train loss item: 0.36285242438316345
12
train loss item: 0.11211765557527542
13
train loss item: 0.5481806993484497
14
train loss item: 0.2648284137248993
15
train loss item: 0.7839811444282532
16
train loss item: 0.05749807506799698
17
train loss item: 0.35715100169181824
18
train loss item: 0.40432998538017273
19
train loss item: 0.34015366435050964
20
train loss item: 0.2717386782169342
21
train loss item: 0.20293676853179932
22
train loss item: 1.2567894458770752
23
train loss item: 1.07242751121521
24
train loss item: 0.7353664040565491
25
train loss item: 0.18500030040740967
26
train loss item: 0.2553699016571045
27
train loss item: 0.27930372953414917
28
train loss item: 0.05166681110858917
29
train loss item: 0.9775183200836182
30
train loss item: 2.6259427070617676
31
train loss item: 0.6860136985778809
32
train loss item: 0.10700583457946777
33
train loss item: 0.503474235534668
34
train loss item: 0.14132538437843323
35
train loss item: 2.6507503986358643
36
train loss item: 0.5348930954933167
37
train loss item: 0.5339813828468323
38
train loss item: 0.5432106256484985
39
train loss item: 0.2734401822090149
40
train loss item: 0.19074232876300812
41
train loss item: 0.32787230610847473
42
train loss item: 0.3768487572669983
43
train loss item: 0.2211753875017166
44
train loss item: 0.7423034310340881
45
train loss item: 0.13620978593826294
46
train loss item: 0.1495346873998642
47
train loss item: 0.4636385142803192
48
train loss item: 0.27307650446891785
49
train loss item: 0.1733849197626114
50
train loss item: 0.3915206789970398
51
train loss item: 1.1554447412490845
52
train loss item: 0.07041579484939575
53
train loss item: 0.17332781851291656
54
train loss item: 2.5141193866729736
55
train loss item: 0.24515558779239655
56
train loss item: 0.3564786911010742
57
train loss item: 0.3150367736816406
58
train loss item: 0.19204361736774445
59
train loss item: 0.12071958184242249
60
train loss item: 1.1451561450958252
61
train loss item: 2.4419827461242676
62
train loss item: 0.27532657980918884
63
train loss item: 0.49108755588531494
64
train loss item: 0.19546331465244293
65
train loss item: 0.7579318284988403
66
train loss item: 0.45438194274902344
67
train loss item: 0.26148200035095215
68
train loss item: 0.37761834263801575
69
train loss item: 0.4424722194671631
70
train loss item: 0.3365217447280884
71
train loss item: 0.14776726067066193
72
train loss item: 0.21375560760498047
73
train loss item: 0.3767361044883728
74
train loss item: 0.07071921229362488
75
train loss item: 0.1166478618979454
76
train loss item: 1.067589282989502
77
train loss item: 1.5847749710083008
78
train loss item: 0.05725032091140747
79
train loss item: 0.3502150774002075
80
train loss item: 0.11638422310352325
81
train loss item: 0.22318468987941742
82
train loss item: 0.2269350290298462
83
train loss item: 0.8460553884506226
84
train loss item: 0.46761849522590637
85
train loss item: 0.758484423160553
86
train loss item: 4.631710529327393
87
train loss item: 0.19475005567073822
88
train loss item: 0.4580650329589844
epoch train loss: 0.5713395135623686
testing phase
test loss item: 0.391771137714386
test loss item: 0.15524700284004211
test loss item: 0.692388653755188
test loss item: 0.5024934411048889
test loss item: 0.3109913170337677
test loss item: 0.1610231101512909
test loss item: 2.2666537761688232
test loss item: 0.560066282749176
test loss item: 0.47303250432014465
test loss item: 0.49715456366539
test loss item: 1.1227302551269531
test loss item: 0.5597252249717712
test loss item: 0.2129753679037094
test loss item: 0.4334922134876251
test loss item: 0.20529022812843323
test loss item: 0.07178797572851181
test loss item: 0.34668517112731934
test loss item: 0.5810911059379578
test loss item: 0.7782292366027832
test loss item: 0.3535667955875397
test loss item: 0.957983136177063
test loss item: 0.5966699123382568
test loss item: 0.3722187578678131
test loss item: 0.2631656527519226
test loss item: 0.27011552453041077
test loss item: 0.27440109848976135
test loss item: 0.4658481776714325
test loss item: 0.26057004928588867
test loss item: 0.425971120595932
test loss item: 0.4321559965610504
test loss item: 1.0001474618911743
test loss item: 0.07477760314941406
test loss item: 0.24650520086288452
test loss item: 0.9242777228355408
test loss item: 0.537639319896698
test loss item: 0.518890917301178
test loss item: 0.983187735080719
test loss item: 1.726510763168335
test loss item: 0.734376072883606
test loss item: 0.34415149688720703
test loss item: 0.3787110149860382
test loss item: 0.22546584904193878
test loss item: 0.45135512948036194
test loss item: 0.4639163315296173
test loss item: 0.8124517202377319
test loss item: 0.5140026807785034
test loss item: 0.381468802690506
test loss item: 0.32614657282829285
test loss item: 0.5737559795379639
test loss item: 0.8371501564979553
test loss item: 0.42484772205352783
test loss item: 0.15356256067752838
test loss item: 0.2965649962425232
test loss item: 0.648077130317688
test loss item: 0.38450518250465393
test loss item: 1.0617027282714844
test loss item: 0.7258303761482239
test loss item: 0.38633325695991516
test loss item: 0.2832624018192291
test loss item: 0.25359123945236206
test loss item: 0.5591334104537964
test loss item: 0.22574105858802795
test loss item: 0.26529213786125183
test loss item: 0.3133350908756256
test loss item: 0.99847811460495
test loss item: 0.6969916224479675
test loss item: 0.36736443638801575
test loss item: 0.324733167886734
test loss item: 0.6547371745109558
test loss item: 0.4740505814552307
test loss item: 0.06913955509662628
test loss item: 1.2437704801559448
test loss item: 0.47956445813179016
test loss item: 0.48185497522354126
test loss item: 0.24080362915992737
test loss item: 0.26864397525787354
test loss item: 0.26534804701805115
test loss item: 1.746785044670105
test loss item: 0.5834906101226807
test loss item: 0.25244206190109253
test loss item: 0.10414069890975952
test loss item: 1.1510558128356934
test loss item: 1.082732081413269
test loss item: 1.1779106855392456
test loss item: 0.2968882620334625
test loss item: 0.2771972417831421
test loss item: 0.21119000017642975
test loss item: 0.08218269050121307
test loss item: 0.22806097567081451
Epoch [20/100], Training Loss: 0.5713, Testing Loss: 0.5257
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 21/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4939647614955902
1
train loss item: 1.512141227722168
2
train loss item: 0.2856897711753845
3
train loss item: 0.6924282312393188
4
train loss item: 0.4494308531284332
5
train loss item: 0.40217283368110657
6
train loss item: 0.311532586812973
7
train loss item: 0.9558128118515015
8
train loss item: 0.15155771374702454
9
train loss item: 0.33960291743278503
10
train loss item: 0.43553563952445984
11
train loss item: 0.34316325187683105
12
train loss item: 0.11408211290836334
13
train loss item: 0.5416112542152405
14
train loss item: 0.2609574496746063
15
train loss item: 0.7667596340179443
16
train loss item: 0.05731065571308136
17
train loss item: 0.35561561584472656
18
train loss item: 0.40712299942970276
19
train loss item: 0.3329003155231476
20
train loss item: 0.2645132839679718
21
train loss item: 0.18152950704097748
22
train loss item: 1.2402105331420898
23
train loss item: 1.0659898519515991
24
train loss item: 0.7373067736625671
25
train loss item: 0.18499115109443665
26
train loss item: 0.23979324102401733
27
train loss item: 0.2789268493652344
28
train loss item: 0.052636630833148956
29
train loss item: 0.9631258249282837
30
train loss item: 2.6163806915283203
31
train loss item: 0.6796251535415649
32
train loss item: 0.11066696047782898
33
train loss item: 0.5014747977256775
34
train loss item: 0.13049840927124023
35
train loss item: 2.6498847007751465
36
train loss item: 0.5400064587593079
37
train loss item: 0.5246185660362244
38
train loss item: 0.5348193049430847
39
train loss item: 0.27764979004859924
40
train loss item: 0.1864052563905716
41
train loss item: 0.3318631947040558
42
train loss item: 0.35722237825393677
43
train loss item: 0.22341403365135193
44
train loss item: 0.7456300854682922
45
train loss item: 0.1389000117778778
46
train loss item: 0.1478511542081833
47
train loss item: 0.4627317786216736
48
train loss item: 0.2757631540298462
49
train loss item: 0.1714070439338684
50
train loss item: 0.38696253299713135
51
train loss item: 1.1415691375732422
52
train loss item: 0.06771393865346909
53
train loss item: 0.1769731342792511
54
train loss item: 2.511569023132324
55
train loss item: 0.2496914267539978
56
train loss item: 0.3595021367073059
57
train loss item: 0.30174699425697327
58
train loss item: 0.19154369831085205
59
train loss item: 0.12229151278734207
60
train loss item: 1.1347445249557495
61
train loss item: 2.435509204864502
62
train loss item: 0.2732947766780853
63
train loss item: 0.4765929579734802
64
train loss item: 0.19782565534114838
65
train loss item: 0.7560012936592102
66
train loss item: 0.4526321291923523
67
train loss item: 0.2519223988056183
68
train loss item: 0.3812035024166107
69
train loss item: 0.43940961360931396
70
train loss item: 0.3316360414028168
71
train loss item: 0.14310322701931
72
train loss item: 0.2141856551170349
73
train loss item: 0.37522828578948975
74
train loss item: 0.07159517705440521
75
train loss item: 0.12276998907327652
76
train loss item: 1.0625088214874268
77
train loss item: 1.56325364112854
78
train loss item: 0.05735132470726967
79
train loss item: 0.337118536233902
80
train loss item: 0.11663361638784409
81
train loss item: 0.22104349732398987
82
train loss item: 0.22815042734146118
83
train loss item: 0.8344643115997314
84
train loss item: 0.4594496488571167
85
train loss item: 0.7596615552902222
86
train loss item: 4.623538970947266
87
train loss item: 0.19801947474479675
88
train loss item: 0.4540916681289673
epoch train loss: 0.567502614278137
testing phase
test loss item: 0.4520205557346344
test loss item: 0.13105788826942444
test loss item: 0.6939586400985718
test loss item: 0.5844814777374268
test loss item: 0.3053952157497406
test loss item: 0.1600944697856903
test loss item: 2.2715070247650146
test loss item: 0.5648982524871826
test loss item: 0.5478432178497314
test loss item: 0.5003023147583008
test loss item: 1.1490176916122437
test loss item: 0.6773325800895691
test loss item: 0.22111298143863678
test loss item: 0.4490189850330353
test loss item: 0.20506872236728668
test loss item: 0.06932321935892105
test loss item: 0.35036569833755493
test loss item: 0.5840477347373962
test loss item: 0.7819253206253052
test loss item: 0.36145663261413574
test loss item: 0.9588027596473694
test loss item: 0.6755943298339844
test loss item: 0.38269224762916565
test loss item: 0.24474363029003143
test loss item: 0.2700205147266388
test loss item: 0.27998554706573486
test loss item: 0.47909364104270935
test loss item: 0.25571882724761963
test loss item: 0.42994871735572815
test loss item: 0.4354156255722046
test loss item: 0.9937969446182251
test loss item: 0.06991493701934814
test loss item: 0.2248678356409073
test loss item: 1.052412986755371
test loss item: 0.5392690896987915
test loss item: 0.5133099555969238
test loss item: 0.9902231097221375
test loss item: 1.7151955366134644
test loss item: 0.77956622838974
test loss item: 0.34720492362976074
test loss item: 0.3783659040927887
test loss item: 0.22284038364887238
test loss item: 0.46022748947143555
test loss item: 0.5419220328330994
test loss item: 0.8131000995635986
test loss item: 0.5257501006126404
test loss item: 0.3838260769844055
test loss item: 0.3261807858943939
test loss item: 0.578473687171936
test loss item: 0.8364759087562561
test loss item: 0.4263831377029419
test loss item: 0.15666180849075317
test loss item: 0.29851317405700684
test loss item: 0.7933008670806885
test loss item: 0.3791581988334656
test loss item: 1.0555247068405151
test loss item: 0.7731379866600037
test loss item: 0.36760270595550537
test loss item: 0.2893446981906891
test loss item: 0.2592960596084595
test loss item: 0.5598635673522949
test loss item: 0.23626452684402466
test loss item: 0.2853245437145233
test loss item: 0.31758230924606323
test loss item: 1.003798484802246
test loss item: 0.8272594809532166
test loss item: 0.37556472420692444
test loss item: 0.3228091895580292
test loss item: 0.6639189720153809
test loss item: 0.46756690740585327
test loss item: 0.06742113083600998
test loss item: 1.2530372142791748
test loss item: 0.44679883122444153
test loss item: 0.49689313769340515
test loss item: 0.21397799253463745
test loss item: 0.2396727055311203
test loss item: 0.24813491106033325
test loss item: 1.7533155679702759
test loss item: 0.5992151498794556
test loss item: 0.26775455474853516
test loss item: 0.10234475135803223
test loss item: 1.1472097635269165
test loss item: 1.08455228805542
test loss item: 1.172318458557129
test loss item: 0.3006960153579712
test loss item: 0.2797783613204956
test loss item: 0.15873245894908905
test loss item: 0.07785319536924362
test loss item: 0.21201948821544647
Epoch [21/100], Training Loss: 0.5675, Testing Loss: 0.5365
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 22/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4980311691761017
1
train loss item: 1.5016156435012817
2
train loss item: 0.28388532996177673
3
train loss item: 0.6884694695472717
4
train loss item: 0.44686955213546753
5
train loss item: 0.3974917232990265
6
train loss item: 0.31402599811553955
7
train loss item: 0.9560467600822449
8
train loss item: 0.15312817692756653
9
train loss item: 0.3410256803035736
10
train loss item: 0.429959774017334
11
train loss item: 0.32586243748664856
12
train loss item: 0.11447371542453766
13
train loss item: 0.537125289440155
14
train loss item: 0.2609211206436157
15
train loss item: 0.7556833624839783
16
train loss item: 0.05580736696720123
17
train loss item: 0.3592541217803955
18
train loss item: 0.41026633977890015
19
train loss item: 0.3276149332523346
20
train loss item: 0.2614450454711914
21
train loss item: 0.1628720909357071
22
train loss item: 1.2249171733856201
23
train loss item: 1.0594755411148071
24
train loss item: 0.7334761619567871
25
train loss item: 0.1860567331314087
26
train loss item: 0.22927390038967133
27
train loss item: 0.2790462076663971
28
train loss item: 0.05203265696763992
29
train loss item: 0.948707640171051
30
train loss item: 2.6067309379577637
31
train loss item: 0.6717613339424133
32
train loss item: 0.11129100620746613
33
train loss item: 0.5015873312950134
34
train loss item: 0.12086405605077744
35
train loss item: 2.646437644958496
36
train loss item: 0.5460311770439148
37
train loss item: 0.5146533250808716
38
train loss item: 0.5233686566352844
39
train loss item: 0.2809610664844513
40
train loss item: 0.18077170848846436
41
train loss item: 0.33253705501556396
42
train loss item: 0.3418886065483093
43
train loss item: 0.22480878233909607
44
train loss item: 0.7479206323623657
45
train loss item: 0.14376170933246613
46
train loss item: 0.14438238739967346
47
train loss item: 0.4616328477859497
48
train loss item: 0.2770470976829529
49
train loss item: 0.1708378791809082
50
train loss item: 0.3841199576854706
51
train loss item: 1.1281607151031494
52
train loss item: 0.06891083717346191
53
train loss item: 0.1799413412809372
54
train loss item: 2.506694793701172
55
train loss item: 0.25474870204925537
56
train loss item: 0.3604440987110138
57
train loss item: 0.2881815433502197
58
train loss item: 0.19149823486804962
59
train loss item: 0.12084826081991196
60
train loss item: 1.125378966331482
61
train loss item: 2.4286155700683594
62
train loss item: 0.2711167335510254
63
train loss item: 0.4638775587081909
64
train loss item: 0.1975826472043991
65
train loss item: 0.7458823919296265
66
train loss item: 0.45359599590301514
67
train loss item: 0.24617885053157806
68
train loss item: 0.3883344531059265
69
train loss item: 0.43652164936065674
70
train loss item: 0.327992707490921
71
train loss item: 0.1390150636434555
72
train loss item: 0.21555444598197937
73
train loss item: 0.37287595868110657
74
train loss item: 0.06963831186294556
75
train loss item: 0.1248607188463211
76
train loss item: 1.0586010217666626
77
train loss item: 1.5485886335372925
78
train loss item: 0.05786275863647461
79
train loss item: 0.32603201270103455
80
train loss item: 0.11961778998374939
81
train loss item: 0.21912504732608795
82
train loss item: 0.2304716259241104
83
train loss item: 0.8234267234802246
84
train loss item: 0.45496633648872375
85
train loss item: 0.7561872005462646
86
train loss item: 4.612399101257324
87
train loss item: 0.1992795467376709
88
train loss item: 0.44788044691085815
epoch train loss: 0.5639229787701971
testing phase
test loss item: 0.4624606668949127
test loss item: 0.10648034512996674
test loss item: 0.7008268237113953
test loss item: 0.5502788424491882
test loss item: 0.3030354082584381
test loss item: 0.156355619430542
test loss item: 2.2587625980377197
test loss item: 0.5665462017059326
test loss item: 0.5476011633872986
test loss item: 0.5069231390953064
test loss item: 1.1521486043930054
test loss item: 0.6432160139083862
test loss item: 0.22700393199920654
test loss item: 0.44332170486450195
test loss item: 0.20627371966838837
test loss item: 0.06987614184617996
test loss item: 0.35191085934638977
test loss item: 0.5915235877037048
test loss item: 0.7842848300933838
test loss item: 0.36259639263153076
test loss item: 0.9639335870742798
test loss item: 0.6538915038108826
test loss item: 0.3986186385154724
test loss item: 0.21703886985778809
test loss item: 0.2714855372905731
test loss item: 0.28328844904899597
test loss item: 0.4786279797554016
test loss item: 0.24563731253147125
test loss item: 0.432320237159729
test loss item: 0.4398992657661438
test loss item: 0.9911603927612305
test loss item: 0.06806592643260956
test loss item: 0.18747130036354065
test loss item: 1.1122212409973145
test loss item: 0.5456960797309875
test loss item: 0.5139905214309692
test loss item: 0.9943363666534424
test loss item: 1.718544363975525
test loss item: 0.7685448527336121
test loss item: 0.3468904495239258
test loss item: 0.37671875953674316
test loss item: 0.21774739027023315
test loss item: 0.4930110275745392
test loss item: 0.5145771503448486
test loss item: 0.8170994520187378
test loss item: 0.5323832035064697
test loss item: 0.3755050599575043
test loss item: 0.3215354382991791
test loss item: 0.586215615272522
test loss item: 0.8404274582862854
test loss item: 0.43621647357940674
test loss item: 0.15906023979187012
test loss item: 0.3023934066295624
test loss item: 0.746951162815094
test loss item: 0.38614389300346375
test loss item: 1.0610077381134033
test loss item: 0.7701499462127686
test loss item: 0.38117310404777527
test loss item: 0.29442596435546875
test loss item: 0.2664894163608551
test loss item: 0.5648738741874695
test loss item: 0.24399596452713013
test loss item: 0.30769866704940796
test loss item: 0.3194271922111511
test loss item: 1.009702444076538
test loss item: 0.784938633441925
test loss item: 0.37999722361564636
test loss item: 0.3221990764141083
test loss item: 0.6855090856552124
test loss item: 0.46509021520614624
test loss item: 0.06657300889492035
test loss item: 1.2505019903182983
test loss item: 0.42763635516166687
test loss item: 0.5072425603866577
test loss item: 0.18938571214675903
test loss item: 0.20644332468509674
test loss item: 0.21974895894527435
test loss item: 1.7551076412200928
test loss item: 0.591159462928772
test loss item: 0.28817442059516907
test loss item: 0.10338117927312851
test loss item: 1.1441020965576172
test loss item: 1.0864917039871216
test loss item: 1.176656723022461
test loss item: 0.2958366274833679
test loss item: 0.2817167341709137
test loss item: 0.0991017296910286
test loss item: 0.07821116596460342
test loss item: 0.2024534046649933
Epoch [22/100], Training Loss: 0.5639, Testing Loss: 0.5343
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 23/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5025433897972107
1
train loss item: 1.4895392656326294
2
train loss item: 0.2792688012123108
3
train loss item: 0.6837813258171082
4
train loss item: 0.44642385840415955
5
train loss item: 0.3925798237323761
6
train loss item: 0.316100537776947
7
train loss item: 0.9538612961769104
8
train loss item: 0.15507997572422028
9
train loss item: 0.3365848958492279
10
train loss item: 0.42684558033943176
11
train loss item: 0.3192255198955536
12
train loss item: 0.11380600184202194
13
train loss item: 0.5368900895118713
14
train loss item: 0.2642548084259033
15
train loss item: 0.7500891089439392
16
train loss item: 0.054296039044857025
17
train loss item: 0.36350002884864807
18
train loss item: 0.41208288073539734
19
train loss item: 0.3238029479980469
20
train loss item: 0.2613484859466553
21
train loss item: 0.15294422209262848
22
train loss item: 1.2138088941574097
23
train loss item: 1.0552259683609009
24
train loss item: 0.7233902812004089
25
train loss item: 0.18802997469902039
26
train loss item: 0.22360406816005707
27
train loss item: 0.2796221077442169
28
train loss item: 0.050927743315696716
29
train loss item: 0.9332760572433472
30
train loss item: 2.5911200046539307
31
train loss item: 0.6684035062789917
32
train loss item: 0.10913759469985962
33
train loss item: 0.5047118663787842
34
train loss item: 0.11367769539356232
35
train loss item: 2.638807773590088
36
train loss item: 0.550945520401001
37
train loss item: 0.508276104927063
38
train loss item: 0.5199576616287231
39
train loss item: 0.282545268535614
40
train loss item: 0.17452472448349
41
train loss item: 0.33015725016593933
42
train loss item: 0.3329906463623047
43
train loss item: 0.22522395849227905
44
train loss item: 0.7495964169502258
45
train loss item: 0.14995554089546204
46
train loss item: 0.141484335064888
47
train loss item: 0.458052396774292
48
train loss item: 0.27677279710769653
49
train loss item: 0.1736694723367691
50
train loss item: 0.3814779818058014
51
train loss item: 1.1117877960205078
52
train loss item: 0.07173114269971848
53
train loss item: 0.1825849562883377
54
train loss item: 2.4986135959625244
55
train loss item: 0.2589278817176819
56
train loss item: 0.3598337471485138
57
train loss item: 0.277994304895401
58
train loss item: 0.19128799438476562
59
train loss item: 0.11751332134008408
60
train loss item: 1.1118957996368408
61
train loss item: 2.41892147064209
62
train loss item: 0.2689664661884308
63
train loss item: 0.45509764552116394
64
train loss item: 0.19682975113391876
65
train loss item: 0.7358296513557434
66
train loss item: 0.4584414064884186
67
train loss item: 0.24474094808101654
68
train loss item: 0.39291033148765564
69
train loss item: 0.43308064341545105
70
train loss item: 0.32475972175598145
71
train loss item: 0.13667315244674683
72
train loss item: 0.21780051290988922
73
train loss item: 0.3687688708305359
74
train loss item: 0.06563475728034973
75
train loss item: 0.1236976608633995
76
train loss item: 1.0552749633789062
77
train loss item: 1.5318145751953125
78
train loss item: 0.059605538845062256
79
train loss item: 0.31977713108062744
80
train loss item: 0.1268244832754135
81
train loss item: 0.21656116843223572
82
train loss item: 0.23432625830173492
83
train loss item: 0.8106464147567749
84
train loss item: 0.45711275935173035
85
train loss item: 0.7488872408866882
86
train loss item: 4.59924840927124
87
train loss item: 0.19935233891010284
88
train loss item: 0.4421118497848511
epoch train loss: 0.5607875186238396
testing phase
test loss item: 0.43088212609291077
test loss item: 0.1018301472067833
test loss item: 0.7087657451629639
test loss item: 0.48783206939697266
test loss item: 0.3032066822052002
test loss item: 0.15311981737613678
test loss item: 2.2229528427124023
test loss item: 0.5595898628234863
test loss item: 0.5015149116516113
test loss item: 0.5134168863296509
test loss item: 1.1356523036956787
test loss item: 0.5667547583580017
test loss item: 0.22958478331565857
test loss item: 0.43810173869132996
test loss item: 0.2081134170293808
test loss item: 0.07240061461925507
test loss item: 0.3508926331996918
test loss item: 0.5996566414833069
test loss item: 0.7783116102218628
test loss item: 0.358143150806427
test loss item: 0.9751555323600769
test loss item: 0.6029917597770691
test loss item: 0.4043584167957306
test loss item: 0.21050530672073364
test loss item: 0.2734123468399048
test loss item: 0.2841208875179291
test loss item: 0.4649636745452881
test loss item: 0.23838096857070923
test loss item: 0.43366214632987976
test loss item: 0.44393637776374817
test loss item: 0.9882838129997253
test loss item: 0.06869453191757202
test loss item: 0.17776769399642944
test loss item: 1.1296557188034058
test loss item: 0.5532603859901428
test loss item: 0.5161473155021667
test loss item: 0.989274263381958
test loss item: 1.7283300161361694
test loss item: 0.7426361441612244
test loss item: 0.34414127469062805
test loss item: 0.37381622195243835
test loss item: 0.2139088213443756
test loss item: 0.5297205448150635
test loss item: 0.4589562714099884
test loss item: 0.827484667301178
test loss item: 0.5313152074813843
test loss item: 0.37369731068611145
test loss item: 0.3147023916244507
test loss item: 0.5921560525894165
test loss item: 0.8437741994857788
test loss item: 0.44754427671432495
test loss item: 0.1606222689151764
test loss item: 0.30646151304244995
test loss item: 0.6466403603553772
test loss item: 0.3954705595970154
test loss item: 1.0719540119171143
test loss item: 0.737325131893158
test loss item: 0.3929901123046875
test loss item: 0.29728949069976807
test loss item: 0.27265116572380066
test loss item: 0.5712624788284302
test loss item: 0.24507635831832886
test loss item: 0.31497448682785034
test loss item: 0.3187965452671051
test loss item: 1.01181960105896
test loss item: 0.6950752139091492
test loss item: 0.3796563446521759
test loss item: 0.31994879245758057
test loss item: 0.7047215104103088
test loss item: 0.4597194790840149
test loss item: 0.0671868771314621
test loss item: 1.2308385372161865
test loss item: 0.4235553443431854
test loss item: 0.5051237940788269
test loss item: 0.1887146532535553
test loss item: 0.20481246709823608
test loss item: 0.21092002093791962
test loss item: 1.7537840604782104
test loss item: 0.5833038091659546
test loss item: 0.2960876226425171
test loss item: 0.10368035733699799
test loss item: 1.1358956098556519
test loss item: 1.0824956893920898
test loss item: 1.1841439008712769
test loss item: 0.28890278935432434
test loss item: 0.28207406401634216
test loss item: 0.1014472246170044
test loss item: 0.08162405341863632
test loss item: 0.19296391308307648
Epoch [23/100], Training Loss: 0.5608, Testing Loss: 0.5283
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 24/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5069891214370728
1
train loss item: 1.472987174987793
2
train loss item: 0.2736656963825226
3
train loss item: 0.6814820170402527
4
train loss item: 0.4499583840370178
5
train loss item: 0.3893507421016693
6
train loss item: 0.3155139684677124
7
train loss item: 0.9481762051582336
8
train loss item: 0.15669190883636475
9
train loss item: 0.32850053906440735
10
train loss item: 0.42644819617271423
11
train loss item: 0.3213672637939453
12
train loss item: 0.1127266138792038
13
train loss item: 0.5386587977409363
14
train loss item: 0.26889681816101074
15
train loss item: 0.7335904240608215
16
train loss item: 0.05350017547607422
17
train loss item: 0.3641468286514282
18
train loss item: 0.41165825724601746
19
train loss item: 0.3210561275482178
20
train loss item: 0.26019755005836487
21
train loss item: 0.1512884944677353
22
train loss item: 1.193786382675171
23
train loss item: 1.0526574850082397
24
train loss item: 0.7078704833984375
25
train loss item: 0.1908891499042511
26
train loss item: 0.22073636949062347
27
train loss item: 0.28028690814971924
28
train loss item: 0.050270311534404755
29
train loss item: 0.9115948677062988
30
train loss item: 2.571614980697632
31
train loss item: 0.6706039905548096
32
train loss item: 0.10624058544635773
33
train loss item: 0.5086815357208252
34
train loss item: 0.10981351882219315
35
train loss item: 2.6269619464874268
36
train loss item: 0.5533453226089478
37
train loss item: 0.5086363554000854
38
train loss item: 0.5256958603858948
39
train loss item: 0.28234240412712097
40
train loss item: 0.16958700120449066
41
train loss item: 0.3267822861671448
42
train loss item: 0.3293718993663788
43
train loss item: 0.2243979126214981
44
train loss item: 0.7504889369010925
45
train loss item: 0.15662389993667603
46
train loss item: 0.14044632017612457
47
train loss item: 0.45141977071762085
48
train loss item: 0.2755424976348877
49
train loss item: 0.17854037880897522
50
train loss item: 0.37828147411346436
51
train loss item: 1.0898030996322632
52
train loss item: 0.07423965632915497
53
train loss item: 0.18487226963043213
54
train loss item: 2.4871203899383545
55
train loss item: 0.26148703694343567
56
train loss item: 0.35827144980430603
57
train loss item: 0.27388888597488403
58
train loss item: 0.19057033956050873
59
train loss item: 0.1138700619339943
60
train loss item: 1.0923963785171509
61
train loss item: 2.4096574783325195
62
train loss item: 0.26633119583129883
63
train loss item: 0.44996097683906555
64
train loss item: 0.19627809524536133
65
train loss item: 0.7300354838371277
66
train loss item: 0.4654296934604645
67
train loss item: 0.24470533430576324
68
train loss item: 0.39019596576690674
69
train loss item: 0.4288589358329773
70
train loss item: 0.3223215639591217
71
train loss item: 0.13600070774555206
72
train loss item: 0.21940618753433228
73
train loss item: 0.36403852701187134
74
train loss item: 0.06184074282646179
75
train loss item: 0.12079679220914841
76
train loss item: 1.0512524843215942
77
train loss item: 1.5109940767288208
78
train loss item: 0.06297626346349716
79
train loss item: 0.31823524832725525
80
train loss item: 0.13503442704677582
81
train loss item: 0.2140217423439026
82
train loss item: 0.2386140525341034
83
train loss item: 0.7945712804794312
84
train loss item: 0.4637037217617035
85
train loss item: 0.7386285066604614
86
train loss item: 4.584137916564941
87
train loss item: 0.19880858063697815
88
train loss item: 0.43747857213020325
epoch train loss: 0.5575415310397577
testing phase
test loss item: 0.399794340133667
test loss item: 0.10290473699569702
test loss item: 0.7134826183319092
test loss item: 0.42236387729644775
test loss item: 0.30349770188331604
test loss item: 0.15162606537342072
test loss item: 2.1721320152282715
test loss item: 0.5411580204963684
test loss item: 0.4524209201335907
test loss item: 0.5165863037109375
test loss item: 1.1159400939941406
test loss item: 0.48116400837898254
test loss item: 0.22936657071113586
test loss item: 0.4335981011390686
test loss item: 0.20948737859725952
test loss item: 0.0749421939253807
test loss item: 0.34931644797325134
test loss item: 0.6045266389846802
test loss item: 0.7665690183639526
test loss item: 0.351969450712204
test loss item: 0.9829308390617371
test loss item: 0.5480042695999146
test loss item: 0.3990035057067871
test loss item: 0.20964646339416504
test loss item: 0.27478933334350586
test loss item: 0.28326302766799927
test loss item: 0.45905324816703796
test loss item: 0.2373386025428772
test loss item: 0.43350037932395935
test loss item: 0.4460921287536621
test loss item: 0.9802089929580688
test loss item: 0.07015100866556168
test loss item: 0.17769594490528107
test loss item: 1.1297619342803955
test loss item: 0.5579448342323303
test loss item: 0.5152299404144287
test loss item: 0.9767887592315674
test loss item: 1.7344236373901367
test loss item: 0.7158021926879883
test loss item: 0.34054356813430786
test loss item: 0.37036946415901184
test loss item: 0.21272197365760803
test loss item: 0.6053506135940552
test loss item: 0.39992499351501465
test loss item: 0.8343489170074463
test loss item: 0.5270500779151917
test loss item: 0.3755948543548584
test loss item: 0.3080311119556427
test loss item: 0.5936556458473206
test loss item: 0.8426950573921204
test loss item: 0.4538775384426117
test loss item: 0.16094912588596344
test loss item: 0.30909252166748047
test loss item: 0.5351572036743164
test loss item: 0.4010604918003082
test loss item: 1.0802440643310547
test loss item: 0.7024268507957458
test loss item: 0.3985937833786011
test loss item: 0.29829418659210205
test loss item: 0.2757585346698761
test loss item: 0.5746611952781677
test loss item: 0.2426249384880066
test loss item: 0.30869996547698975
test loss item: 0.3164166212081909
test loss item: 1.0096838474273682
test loss item: 0.5985195636749268
test loss item: 0.376931369304657
test loss item: 0.31697678565979004
test loss item: 0.7348189353942871
test loss item: 0.44977498054504395
test loss item: 0.0690079852938652
test loss item: 1.2008929252624512
test loss item: 0.42129752039909363
test loss item: 0.4945860207080841
test loss item: 0.18889473378658295
test loss item: 0.20465300977230072
test loss item: 0.20899447798728943
test loss item: 1.7508671283721924
test loss item: 0.5765234231948853
test loss item: 0.2908296585083008
test loss item: 0.10588743537664413
test loss item: 1.1215146780014038
test loss item: 1.0717685222625732
test loss item: 1.1872882843017578
test loss item: 0.28144371509552
test loss item: 0.2820064425468445
test loss item: 0.1038476750254631
test loss item: 0.08523834496736526
test loss item: 0.18760983645915985
Epoch [24/100], Training Loss: 0.5575, Testing Loss: 0.5204
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 25/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.510908305644989
1
train loss item: 1.4538071155548096
2
train loss item: 0.26882582902908325
3
train loss item: 0.6761133074760437
4
train loss item: 0.4602917730808258
5
train loss item: 0.388760507106781
6
train loss item: 0.31285834312438965
7
train loss item: 0.9411873817443848
8
train loss item: 0.15710850059986115
9
train loss item: 0.32163694500923157
10
train loss item: 0.427827388048172
11
train loss item: 0.32860180735588074
12
train loss item: 0.11113499104976654
13
train loss item: 0.5398615598678589
14
train loss item: 0.2724302411079407
15
train loss item: 0.7198497653007507
16
train loss item: 0.05369811877608299
17
train loss item: 0.36168143153190613
18
train loss item: 0.4112855792045593
19
train loss item: 0.3203185796737671
20
train loss item: 0.25911465287208557
21
train loss item: 0.1559973657131195
22
train loss item: 1.1683529615402222
23
train loss item: 1.0505894422531128
24
train loss item: 0.6918585896492004
25
train loss item: 0.19331547617912292
26
train loss item: 0.2198781967163086
27
train loss item: 0.28048813343048096
28
train loss item: 0.05038018152117729
29
train loss item: 0.8860724568367004
30
train loss item: 2.5501387119293213
31
train loss item: 0.6769306659698486
32
train loss item: 0.10323582589626312
33
train loss item: 0.5094811916351318
34
train loss item: 0.11049783229827881
35
train loss item: 2.612727165222168
36
train loss item: 0.5545278787612915
37
train loss item: 0.517039954662323
38
train loss item: 0.5391358733177185
39
train loss item: 0.28237655758857727
40
train loss item: 0.16637484729290009
41
train loss item: 0.32525646686553955
42
train loss item: 0.3291586637496948
43
train loss item: 0.2223048359155655
44
train loss item: 0.749719500541687
45
train loss item: 0.16071482002735138
46
train loss item: 0.1410825252532959
47
train loss item: 0.4428146779537201
48
train loss item: 0.27360108494758606
49
train loss item: 0.18271349370479584
50
train loss item: 0.37622570991516113
51
train loss item: 1.0666922330856323
52
train loss item: 0.07578190416097641
53
train loss item: 0.1852126568555832
54
train loss item: 2.473775863647461
55
train loss item: 0.26127442717552185
56
train loss item: 0.3579990863800049
57
train loss item: 0.27532583475112915
58
train loss item: 0.18946987390518188
59
train loss item: 0.11158444732427597
60
train loss item: 1.0742933750152588
61
train loss item: 2.4003870487213135
62
train loss item: 0.264935165643692
63
train loss item: 0.44748654961586
64
train loss item: 0.1946765035390854
65
train loss item: 0.7304058074951172
66
train loss item: 0.4757687747478485
67
train loss item: 0.2441769540309906
68
train loss item: 0.38334786891937256
69
train loss item: 0.42567235231399536
70
train loss item: 0.320269376039505
71
train loss item: 0.13583946228027344
72
train loss item: 0.21943554282188416
73
train loss item: 0.361219584941864
74
train loss item: 0.05864781513810158
75
train loss item: 0.11589445173740387
76
train loss item: 1.0459860563278198
77
train loss item: 1.4884114265441895
78
train loss item: 0.06686241179704666
79
train loss item: 0.3207663595676422
80
train loss item: 0.13958582282066345
81
train loss item: 0.21193836629390717
82
train loss item: 0.24113690853118896
83
train loss item: 0.7762879729270935
84
train loss item: 0.4737851321697235
85
train loss item: 0.7278509140014648
86
train loss item: 4.566713809967041
87
train loss item: 0.1963045448064804
88
train loss item: 0.43592941761016846
epoch train loss: 0.5546227563381865
testing phase
test loss item: 0.34138548374176025
test loss item: 0.10362237691879272
test loss item: 0.7100619077682495
test loss item: 0.3580130636692047
test loss item: 0.30184629559516907
test loss item: 0.1508852243423462
test loss item: 2.11971378326416
test loss item: 0.5230593681335449
test loss item: 0.384980708360672
test loss item: 0.5130731463432312
test loss item: 1.0863734483718872
test loss item: 0.39203134179115295
test loss item: 0.22658802568912506
test loss item: 0.42887797951698303
test loss item: 0.2091759443283081
test loss item: 0.07780370861291885
test loss item: 0.348895788192749
test loss item: 0.6019103527069092
test loss item: 0.7548049688339233
test loss item: 0.3465043604373932
test loss item: 0.9799205660820007
test loss item: 0.49520379304885864
test loss item: 0.38417848944664
test loss item: 0.20892967283725739
test loss item: 0.27502530813217163
test loss item: 0.28095993399620056
test loss item: 0.4433934986591339
test loss item: 0.23574364185333252
test loss item: 0.4310056269168854
test loss item: 0.4437244236469269
test loss item: 0.9662551283836365
test loss item: 0.07294796407222748
test loss item: 0.1784401535987854
test loss item: 1.0345457792282104
test loss item: 0.5560032725334167
test loss item: 0.5075026154518127
test loss item: 0.9615284204483032
test loss item: 1.7274532318115234
test loss item: 0.6877362728118896
test loss item: 0.3369050621986389
test loss item: 0.36749330163002014
test loss item: 0.21409347653388977
test loss item: 0.6018284559249878
test loss item: 0.3428039252758026
test loss item: 0.8319681286811829
test loss item: 0.5237234830856323
test loss item: 0.375085711479187
test loss item: 0.3023216128349304
test loss item: 0.5883527398109436
test loss item: 0.8346801400184631
test loss item: 0.4506151080131531
test loss item: 0.15940028429031372
test loss item: 0.3085867166519165
test loss item: 0.41688111424446106
test loss item: 0.39967745542526245
test loss item: 1.076531171798706
test loss item: 0.6590911746025085
test loss item: 0.3968522250652313
test loss item: 0.29732850193977356
test loss item: 0.27371424436569214
test loss item: 0.5692604184150696
test loss item: 0.2414083480834961
test loss item: 0.2930068373680115
test loss item: 0.31290650367736816
test loss item: 1.0014917850494385
test loss item: 0.5021211504936218
test loss item: 0.37358012795448303
test loss item: 0.31417107582092285
test loss item: 0.7254956364631653
test loss item: 0.4377981424331665
test loss item: 0.07218365371227264
test loss item: 1.1715697050094604
test loss item: 0.4172004461288452
test loss item: 0.4803619980812073
test loss item: 0.1903037428855896
test loss item: 0.2058383971452713
test loss item: 0.2077062577009201
test loss item: 1.735943078994751
test loss item: 0.5696591138839722
test loss item: 0.2752660810947418
test loss item: 0.10916607081890106
test loss item: 1.1026628017425537
test loss item: 1.055243968963623
test loss item: 1.1797423362731934
test loss item: 0.273514986038208
test loss item: 0.28200191259384155
test loss item: 0.10745050013065338
test loss item: 0.08942808955907822
test loss item: 0.18711458146572113
Epoch [25/100], Training Loss: 0.5546, Testing Loss: 0.5066
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 26/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5135985016822815
1
train loss item: 1.4353488683700562
2
train loss item: 0.2654285430908203
3
train loss item: 0.6686073541641235
4
train loss item: 0.47430726885795593
5
train loss item: 0.3896835446357727
6
train loss item: 0.31092751026153564
7
train loss item: 0.9336065649986267
8
train loss item: 0.15615059435367584
9
train loss item: 0.3187076151371002
10
train loss item: 0.42868611216545105
11
train loss item: 0.3366226553916931
12
train loss item: 0.1093873530626297
13
train loss item: 0.5384936928749084
14
train loss item: 0.27244964241981506
15
train loss item: 0.7073487043380737
16
train loss item: 0.054566409438848495
17
train loss item: 0.3590944707393646
18
train loss item: 0.412616491317749
19
train loss item: 0.321601539850235
20
train loss item: 0.2604770064353943
21
train loss item: 0.1609206199645996
22
train loss item: 1.1485322713851929
23
train loss item: 1.0461331605911255
24
train loss item: 0.6814826130867004
25
train loss item: 0.19368652999401093
26
train loss item: 0.22034141421318054
27
train loss item: 0.27985668182373047
28
train loss item: 0.05089616775512695
29
train loss item: 0.8617539405822754
30
train loss item: 2.5281503200531006
31
train loss item: 0.6836369037628174
32
train loss item: 0.10042034089565277
33
train loss item: 0.5045998692512512
34
train loss item: 0.11800019443035126
35
train loss item: 2.5970587730407715
36
train loss item: 0.5557015538215637
37
train loss item: 0.5294389128684998
38
train loss item: 0.5553178787231445
39
train loss item: 0.28309935331344604
40
train loss item: 0.1641288697719574
41
train loss item: 0.3247651755809784
42
train loss item: 0.33110180497169495
43
train loss item: 0.21924415230751038
44
train loss item: 0.7455812692642212
45
train loss item: 0.1604742407798767
46
train loss item: 0.14061975479125977
47
train loss item: 0.43483105301856995
48
train loss item: 0.27141353487968445
49
train loss item: 0.1833670735359192
50
train loss item: 0.37648317217826843
51
train loss item: 1.044715404510498
52
train loss item: 0.07509313523769379
53
train loss item: 0.18240191042423248
54
train loss item: 2.459392786026001
55
train loss item: 0.25851553678512573
56
train loss item: 0.3601689040660858
57
train loss item: 0.2779959738254547
58
train loss item: 0.18831102550029755
59
train loss item: 0.10872793942689896
60
train loss item: 1.056222915649414
61
train loss item: 2.389415740966797
62
train loss item: 0.2643803656101227
63
train loss item: 0.4480155110359192
64
train loss item: 0.1908109486103058
65
train loss item: 0.7377299070358276
66
train loss item: 0.4868484139442444
67
train loss item: 0.2425035834312439
68
train loss item: 0.3771652579307556
69
train loss item: 0.4259255826473236
70
train loss item: 0.3188125193119049
71
train loss item: 0.13574278354644775
72
train loss item: 0.21713963150978088
73
train loss item: 0.36122196912765503
74
train loss item: 0.056019142270088196
75
train loss item: 0.10941101610660553
76
train loss item: 1.0390759706497192
77
train loss item: 1.46739661693573
78
train loss item: 0.0701322928071022
79
train loss item: 0.3268003761768341
80
train loss item: 0.13842131197452545
81
train loss item: 0.21104112267494202
82
train loss item: 0.24008610844612122
83
train loss item: 0.7584925889968872
84
train loss item: 0.48385143280029297
85
train loss item: 0.718193531036377
86
train loss item: 4.548459529876709
87
train loss item: 0.19126245379447937
88
train loss item: 0.4388958811759949
epoch train loss: 0.5519499456865734
testing phase
test loss item: 0.2720414698123932
test loss item: 0.10089975595474243
test loss item: 0.702284038066864
test loss item: 0.306037575006485
test loss item: 0.2993154525756836
test loss item: 0.14912296831607819
test loss item: 2.080472707748413
test loss item: 0.5145322680473328
test loss item: 0.31937113404273987
test loss item: 0.5059956312179565
test loss item: 1.056520700454712
test loss item: 0.3090948760509491
test loss item: 0.22329770028591156
test loss item: 0.4248116910457611
test loss item: 0.20662100613117218
test loss item: 0.07442167401313782
test loss item: 0.3509506583213806
test loss item: 0.5955469608306885
test loss item: 0.74853515625
test loss item: 0.34517306089401245
test loss item: 0.9687163233757019
test loss item: 0.45495232939720154
test loss item: 0.36713266372680664
test loss item: 0.2078072875738144
test loss item: 0.27424073219299316
test loss item: 0.2789526879787445
test loss item: 0.4260675311088562
test loss item: 0.23425443470478058
test loss item: 0.4273700714111328
test loss item: 0.4398106336593628
test loss item: 0.9506693482398987
test loss item: 0.07080015540122986
test loss item: 0.1779305338859558
test loss item: 0.8780891299247742
test loss item: 0.5499762296676636
test loss item: 0.4978022575378418
test loss item: 0.9497600793838501
test loss item: 1.7108519077301025
test loss item: 0.6644770503044128
test loss item: 0.3338136076927185
test loss item: 0.3657970130443573
test loss item: 0.21813635528087616
test loss item: 0.5048087239265442
test loss item: 0.2978277802467346
test loss item: 0.8217728137969971
test loss item: 0.5248779654502869
test loss item: 0.3736446499824524
test loss item: 0.30066874623298645
test loss item: 0.5802901387214661
test loss item: 0.8246901035308838
test loss item: 0.4404069483280182
test loss item: 0.15656021237373352
test loss item: 0.30601271986961365
test loss item: 0.30716025829315186
test loss item: 0.39366620779037476
test loss item: 1.06565523147583
test loss item: 0.6235416531562805
test loss item: 0.3897787630558014
test loss item: 0.295704185962677
test loss item: 0.26803866028785706
test loss item: 0.5596581101417542
test loss item: 0.2437378615140915
test loss item: 0.2749289274215698
test loss item: 0.3096455931663513
test loss item: 0.990653395652771
test loss item: 0.42269888520240784
test loss item: 0.3724163770675659
test loss item: 0.3122694790363312
test loss item: 0.6776674389839172
test loss item: 0.42952078580856323
test loss item: 0.07031752169132233
test loss item: 1.1523845195770264
test loss item: 0.4138551652431488
test loss item: 0.46858689188957214
test loss item: 0.19242577254772186
test loss item: 0.20730803906917572
test loss item: 0.20561693608760834
test loss item: 1.7127189636230469
test loss item: 0.5649290084838867
test loss item: 0.25564661622047424
test loss item: 0.10763359814882278
test loss item: 1.0859296321868896
test loss item: 1.0397934913635254
test loss item: 1.1648622751235962
test loss item: 0.2673115134239197
test loss item: 0.28379446268081665
test loss item: 0.10412988811731339
test loss item: 0.08496686816215515
test loss item: 0.19143234193325043
Epoch [26/100], Training Loss: 0.5519, Testing Loss: 0.4907
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 27/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5124244689941406
1
train loss item: 1.4207640886306763
2
train loss item: 0.2630388140678406
3
train loss item: 0.6603029370307922
4
train loss item: 0.483570396900177
5
train loss item: 0.3892080783843994
6
train loss item: 0.3108215928077698
7
train loss item: 0.9262811541557312
8
train loss item: 0.15404154360294342
9
train loss item: 0.3181103467941284
10
train loss item: 0.42734768986701965
11
train loss item: 0.34018704295158386
12
train loss item: 0.1078023687005043
13
train loss item: 0.5337966084480286
14
train loss item: 0.26854050159454346
15
train loss item: 0.7001413106918335
16
train loss item: 0.055045321583747864
17
train loss item: 0.35796311497688293
18
train loss item: 0.41464391350746155
19
train loss item: 0.32293540239334106
20
train loss item: 0.2629636228084564
21
train loss item: 0.1598563939332962
22
train loss item: 1.1382725238800049
23
train loss item: 1.0386184453964233
24
train loss item: 0.6795700192451477
25
train loss item: 0.1912243813276291
26
train loss item: 0.21970747411251068
27
train loss item: 0.2777409851551056
28
train loss item: 0.050895966589450836
29
train loss item: 0.8441814184188843
30
train loss item: 2.507871627807617
31
train loss item: 0.6854121685028076
32
train loss item: 0.09832413494586945
33
train loss item: 0.49600228667259216
34
train loss item: 0.1328418254852295
35
train loss item: 2.581582546234131
36
train loss item: 0.5556140542030334
37
train loss item: 0.5392529964447021
38
train loss item: 0.5667382478713989
39
train loss item: 0.2832481563091278
40
train loss item: 0.16297608613967896
41
train loss item: 0.322945237159729
42
train loss item: 0.33354029059410095
43
train loss item: 0.21597422659397125
44
train loss item: 0.7385210394859314
45
train loss item: 0.15649689733982086
46
train loss item: 0.13770882785320282
47
train loss item: 0.4291979670524597
48
train loss item: 0.26950955390930176
49
train loss item: 0.18002767860889435
50
train loss item: 0.37724533677101135
51
train loss item: 1.027608036994934
52
train loss item: 0.0720425546169281
53
train loss item: 0.17746736109256744
54
train loss item: 2.4451332092285156
55
train loss item: 0.2550651431083679
56
train loss item: 0.36229249835014343
57
train loss item: 0.27798590064048767
58
train loss item: 0.18703097105026245
59
train loss item: 0.1048634946346283
60
train loss item: 1.0387858152389526
61
train loss item: 2.374141216278076
62
train loss item: 0.2635475993156433
63
train loss item: 0.4504494071006775
64
train loss item: 0.18568523228168488
65
train loss item: 0.7454497218132019
66
train loss item: 0.4935740828514099
67
train loss item: 0.23936901986598969
68
train loss item: 0.3738133907318115
69
train loss item: 0.42838922142982483
70
train loss item: 0.3168858587741852
71
train loss item: 0.13593968749046326
72
train loss item: 0.21298567950725555
73
train loss item: 0.3621470034122467
74
train loss item: 0.054736025631427765
75
train loss item: 0.10294482111930847
76
train loss item: 1.0316238403320312
77
train loss item: 1.4524980783462524
78
train loss item: 0.07154962420463562
79
train loss item: 0.3327304720878601
80
train loss item: 0.1337602138519287
81
train loss item: 0.21110697090625763
82
train loss item: 0.2356177568435669
83
train loss item: 0.7456235289573669
84
train loss item: 0.4897085130214691
85
train loss item: 0.7114600539207458
86
train loss item: 4.530601978302002
87
train loss item: 0.18541114032268524
88
train loss item: 0.4437439739704132
epoch train loss: 0.5490426765231604
testing phase
test loss item: 0.2279251366853714
test loss item: 0.09817498922348022
test loss item: 0.694449782371521
test loss item: 0.27552512288093567
test loss item: 0.29685840010643005
test loss item: 0.14800028502941132
test loss item: 2.062439441680908
test loss item: 0.5167209506034851
test loss item: 0.2790856659412384
test loss item: 0.49877816438674927
test loss item: 1.037927508354187
test loss item: 0.2399081438779831
test loss item: 0.2206868976354599
test loss item: 0.42270582914352417
test loss item: 0.20363283157348633
test loss item: 0.0710630714893341
test loss item: 0.3548815846443176
test loss item: 0.5880479216575623
test loss item: 0.7488152980804443
test loss item: 0.3484600782394409
test loss item: 0.9535231590270996
test loss item: 0.43208834528923035
test loss item: 0.3523828387260437
test loss item: 0.20826567709445953
test loss item: 0.2733401656150818
test loss item: 0.2781636118888855
test loss item: 0.41978612542152405
test loss item: 0.23296986520290375
test loss item: 0.42433488368988037
test loss item: 0.43617159128189087
test loss item: 0.9403409957885742
test loss item: 0.06878289580345154
test loss item: 0.17833779752254486
test loss item: 0.7583848237991333
test loss item: 0.5429887175559998
test loss item: 0.4910443127155304
test loss item: 0.9444524049758911
test loss item: 1.6967277526855469
test loss item: 0.6497567892074585
test loss item: 0.33261850476264954
test loss item: 0.3659171164035797
test loss item: 0.2238679975271225
test loss item: 0.440824031829834
test loss item: 0.2719900608062744
test loss item: 0.8081209063529968
test loss item: 0.5303004384040833
test loss item: 0.3720043897628784
test loss item: 0.3036477267742157
test loss item: 0.572812020778656
test loss item: 0.8178346753120422
test loss item: 0.42622655630111694
test loss item: 0.15487496554851532
test loss item: 0.30282846093177795
test loss item: 0.22250419855117798
test loss item: 0.38519370555877686
test loss item: 1.0540318489074707
test loss item: 0.6067968010902405
test loss item: 0.3791729509830475
test loss item: 0.29500246047973633
test loss item: 0.2609254717826843
test loss item: 0.5495963096618652
test loss item: 0.2499013990163803
test loss item: 0.2620150148868561
test loss item: 0.30759692192077637
test loss item: 0.9829292297363281
test loss item: 0.3736351430416107
test loss item: 0.3740551173686981
test loss item: 0.3119608163833618
test loss item: 0.6459168791770935
test loss item: 0.42749112844467163
test loss item: 0.06901013106107712
test loss item: 1.1464972496032715
test loss item: 0.41175609827041626
test loss item: 0.4639817476272583
test loss item: 0.19545800983905792
test loss item: 0.20995379984378815
test loss item: 0.205173522233963
test loss item: 1.6952179670333862
test loss item: 0.5640373229980469
test loss item: 0.24014273285865784
test loss item: 0.1053803488612175
test loss item: 1.0777007341384888
test loss item: 1.0300509929656982
test loss item: 1.1523715257644653
test loss item: 0.26428547501564026
test loss item: 0.2867499589920044
test loss item: 0.10015963762998581
test loss item: 0.08052060008049011
test loss item: 0.1973714977502823
Epoch [27/100], Training Loss: 0.5490, Testing Loss: 0.4800
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 28/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5051310658454895
1
train loss item: 1.410439372062683
2
train loss item: 0.2608356177806854
3
train loss item: 0.6529178619384766
4
train loss item: 0.4816891551017761
5
train loss item: 0.38614532351493835
6
train loss item: 0.31233322620391846
7
train loss item: 0.9197772741317749
8
train loss item: 0.15196137130260468
9
train loss item: 0.31741851568222046
10
train loss item: 0.4246583580970764
11
train loss item: 0.3376149833202362
12
train loss item: 0.1065310686826706
13
train loss item: 0.5274086594581604
14
train loss item: 0.2627201974391937
15
train loss item: 0.6959718465805054
16
train loss item: 0.054259173572063446
17
train loss item: 0.3582419157028198
18
train loss item: 0.4151594042778015
19
train loss item: 0.32298576831817627
20
train loss item: 0.26416200399398804
21
train loss item: 0.15129713714122772
22
train loss item: 1.1341325044631958
23
train loss item: 1.0302324295043945
24
train loss item: 0.6842151284217834
25
train loss item: 0.18673743307590485
26
train loss item: 0.2178790420293808
27
train loss item: 0.27508050203323364
28
train loss item: 0.04975968599319458
29
train loss item: 0.8356858491897583
30
train loss item: 2.491602659225464
31
train loss item: 0.6808386445045471
32
train loss item: 0.0974678248167038
33
train loss item: 0.48858511447906494
34
train loss item: 0.12441544234752655
35
train loss item: 2.5689308643341064
36
train loss item: 0.5534789562225342
37
train loss item: 0.5417615175247192
38
train loss item: 0.5693347454071045
39
train loss item: 0.28019312024116516
40
train loss item: 0.1631840318441391
41
train loss item: 0.31772327423095703
42
train loss item: 0.33572033047676086
43
train loss item: 0.21350902318954468
44
train loss item: 0.7301788330078125
45
train loss item: 0.15005925297737122
46
train loss item: 0.1334981471300125
47
train loss item: 0.426568865776062
48
train loss item: 0.268245130777359
49
train loss item: 0.17487883567810059
50
train loss item: 0.37647825479507446
51
train loss item: 1.017350673675537
52
train loss item: 0.06860186159610748
53
train loss item: 0.17288663983345032
54
train loss item: 2.433666467666626
55
train loss item: 0.2531728148460388
56
train loss item: 0.3608998954296112
57
train loss item: 0.2753833532333374
58
train loss item: 0.18580643832683563
59
train loss item: 0.10097905248403549
60
train loss item: 1.0240665674209595
61
train loss item: 2.360218048095703
62
train loss item: 0.261089563369751
63
train loss item: 0.4532482922077179
64
train loss item: 0.18154823780059814
65
train loss item: 0.7443352937698364
66
train loss item: 0.49422070384025574
67
train loss item: 0.23536503314971924
68
train loss item: 0.37198102474212646
69
train loss item: 0.42935141921043396
70
train loss item: 0.31713712215423584
71
train loss item: 0.1345798671245575
72
train loss item: 0.2094005048274994
73
train loss item: 0.36211228370666504
74
train loss item: 0.055672649294137955
75
train loss item: 0.09831811487674713
76
train loss item: 1.0260785818099976
77
train loss item: 1.4447141885757446
78
train loss item: 0.07015899568796158
79
train loss item: 0.33522990345954895
80
train loss item: 0.12731534242630005
81
train loss item: 0.21155717968940735
82
train loss item: 0.2299957275390625
83
train loss item: 0.7406117916107178
84
train loss item: 0.49044767022132874
85
train loss item: 0.7088740468025208
86
train loss item: 4.514196872711182
87
train loss item: 0.1811068207025528
88
train loss item: 0.4464043080806732
epoch train loss: 0.5454844729870223
testing phase
test loss item: 0.21559493243694305
test loss item: 0.09602852910757065
test loss item: 0.693695604801178
test loss item: 0.2686383128166199
test loss item: 0.2968144416809082
test loss item: 0.14693039655685425
test loss item: 2.0655736923217773
test loss item: 0.5238122940063477
test loss item: 0.26647478342056274
test loss item: 0.4964387118816376
test loss item: 1.0347517728805542
test loss item: 0.20537959039211273
test loss item: 0.2196090668439865
test loss item: 0.42416509985923767
test loss item: 0.20203377306461334
test loss item: 0.06643074750900269
test loss item: 0.35967305302619934
test loss item: 0.5856037735939026
test loss item: 0.7533619999885559
test loss item: 0.3563506007194519
test loss item: 0.9440110921859741
test loss item: 0.4274887442588806
test loss item: 0.3488982021808624
test loss item: 0.20978331565856934
test loss item: 0.2731524705886841
test loss item: 0.27923935651779175
test loss item: 0.422645628452301
test loss item: 0.2321058064699173
test loss item: 0.4242662787437439
test loss item: 0.4355952739715576
test loss item: 0.9404839873313904
test loss item: 0.06517168879508972
test loss item: 0.1790885329246521
test loss item: 0.7045953869819641
test loss item: 0.5406240820884705
test loss item: 0.49201130867004395
test loss item: 0.9459540843963623
test loss item: 1.6975160837173462
test loss item: 0.6464982032775879
test loss item: 0.3334414064884186
test loss item: 0.3675326704978943
test loss item: 0.2303498238325119
test loss item: 0.42869681119918823
test loss item: 0.26717397570610046
test loss item: 0.7982434630393982
test loss item: 0.5386258959770203
test loss item: 0.3728468418121338
test loss item: 0.31117022037506104
test loss item: 0.5712604522705078
test loss item: 0.8198198676109314
test loss item: 0.4153698980808258
test loss item: 0.1546057164669037
test loss item: 0.30122673511505127
test loss item: 0.1892787516117096
test loss item: 0.37980949878692627
test loss item: 1.05237877368927
test loss item: 0.6052302718162537
test loss item: 0.36957964301109314
test loss item: 0.2962040305137634
test loss item: 0.2555968761444092
test loss item: 0.5460312962532043
test loss item: 0.25714001059532166
test loss item: 0.26121869683265686
test loss item: 0.307461678981781
test loss item: 0.9836947917938232
test loss item: 0.36044761538505554
test loss item: 0.3791934549808502
test loss item: 0.3132188022136688
test loss item: 0.6352689862251282
test loss item: 0.43239545822143555
test loss item: 0.06628203392028809
test loss item: 1.1515370607376099
test loss item: 0.41412153840065
test loss item: 0.469331830739975
test loss item: 0.19840100407600403
test loss item: 0.2129029929637909
test loss item: 0.20619294047355652
test loss item: 1.6934586763381958
test loss item: 0.5690406560897827
test loss item: 0.23649750649929047
test loss item: 0.10004120320081711
test loss item: 1.0826138257980347
test loss item: 1.0298142433166504
test loss item: 1.1524568796157837
test loss item: 0.266273558139801
test loss item: 0.29012224078178406
test loss item: 0.09251603484153748
test loss item: 0.07281137257814407
test loss item: 0.20355799794197083
Epoch [28/100], Training Loss: 0.5455, Testing Loss: 0.4779
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6934.00 MB
Epoch 29/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.493114709854126
1
train loss item: 1.402592420578003
2
train loss item: 0.2600298225879669
3
train loss item: 0.6481642127037048
4
train loss item: 0.4716619849205017
5
train loss item: 0.3821987509727478
6
train loss item: 0.3148873448371887
7
train loss item: 0.9142255783081055
8
train loss item: 0.1507245898246765
9
train loss item: 0.31676408648490906
10
train loss item: 0.4232165813446045
11
train loss item: 0.3314163386821747
12
train loss item: 0.10539418458938599
13
train loss item: 0.5220233201980591
14
train loss item: 0.25760942697525024
15
train loss item: 0.7009552717208862
16
train loss item: 0.05208964645862579
17
train loss item: 0.3592614531517029
18
train loss item: 0.4134014844894409
19
train loss item: 0.32245051860809326
20
train loss item: 0.2637919485569
21
train loss item: 0.13928145170211792
22
train loss item: 1.128479242324829
23
train loss item: 1.02458655834198
24
train loss item: 0.6914876699447632
25
train loss item: 0.1818680763244629
26
train loss item: 0.21597640216350555
27
train loss item: 0.2732059955596924
28
train loss item: 0.04770491272211075
29
train loss item: 0.8348551392555237
30
train loss item: 2.478257179260254
31
train loss item: 0.6732803583145142
32
train loss item: 0.09741642326116562
33
train loss item: 0.48625877499580383
34
train loss item: 0.10893762856721878
35
train loss item: 2.557591676712036
36
train loss item: 0.5495901107788086
37
train loss item: 0.5362539887428284
38
train loss item: 0.5653735995292664
39
train loss item: 0.27349570393562317
40
train loss item: 0.16475950181484222
41
train loss item: 0.3100234270095825
42
train loss item: 0.3383437395095825
43
train loss item: 0.2121400684118271
44
train loss item: 0.7227582931518555
45
train loss item: 0.1431918889284134
46
train loss item: 0.12969261407852173
47
train loss item: 0.4263726472854614
48
train loss item: 0.26756131649017334
49
train loss item: 0.1705806702375412
50
train loss item: 0.3746771812438965
51
train loss item: 1.0139511823654175
52
train loss item: 0.06217498704791069
53
train loss item: 0.16979937255382538
54
train loss item: 2.4229838848114014
55
train loss item: 0.2536340057849884
56
train loss item: 0.3545627295970917
57
train loss item: 0.27268481254577637
58
train loss item: 0.18489930033683777
59
train loss item: 0.09865497797727585
60
train loss item: 1.0191375017166138
61
train loss item: 2.3495349884033203
62
train loss item: 0.2570396661758423
63
train loss item: 0.4552990198135376
64
train loss item: 0.17974954843521118
65
train loss item: 0.7330703139305115
66
train loss item: 0.49033045768737793
67
train loss item: 0.2311704009771347
68
train loss item: 0.370891809463501
69
train loss item: 0.42717987298965454
70
train loss item: 0.31670066714286804
71
train loss item: 0.13323341310024261
72
train loss item: 0.20826523005962372
73
train loss item: 0.36135125160217285
74
train loss item: 0.05970589444041252
75
train loss item: 0.09666302800178528
76
train loss item: 1.0236343145370483
77
train loss item: 1.4424474239349365
78
train loss item: 0.06608676165342331
79
train loss item: 0.33388009667396545
80
train loss item: 0.12270621955394745
81
train loss item: 0.2120986133813858
82
train loss item: 0.2253817468881607
83
train loss item: 0.7420154213905334
84
train loss item: 0.48684123158454895
85
train loss item: 0.7103362679481506
86
train loss item: 4.497814178466797
87
train loss item: 0.17919541895389557
88
train loss item: 0.44604170322418213
epoch train loss: 0.542035096984231
testing phase
test loss item: 0.21437563002109528
test loss item: 0.0956152155995369
test loss item: 0.6989486813545227
test loss item: 0.26936671137809753
test loss item: 0.2980992794036865
test loss item: 0.145578533411026
test loss item: 2.0819015502929688
test loss item: 0.5309363603591919
test loss item: 0.26605498790740967
test loss item: 0.49775105714797974
test loss item: 1.041966199874878
test loss item: 0.19478698074817657
test loss item: 0.2190995216369629
test loss item: 0.4272240996360779
test loss item: 0.20173972845077515
test loss item: 0.06378965824842453
test loss item: 0.36363810300827026
test loss item: 0.5876384377479553
test loss item: 0.7590888738632202
test loss item: 0.36551499366760254
test loss item: 0.9398382902145386
test loss item: 0.42985406517982483
test loss item: 0.3521195352077484
test loss item: 0.21189150214195251
test loss item: 0.2733619809150696
test loss item: 0.2809024751186371
test loss item: 0.42837652564048767
test loss item: 0.23201218247413635
test loss item: 0.4262009263038635
test loss item: 0.43711328506469727
test loss item: 0.9488676190376282
test loss item: 0.06257646530866623
test loss item: 0.1800474375486374
test loss item: 0.6901973485946655
test loss item: 0.5426207184791565
test loss item: 0.49769672751426697
test loss item: 0.9510160684585571
test loss item: 1.7131109237670898
test loss item: 0.6481816172599792
test loss item: 0.335711807012558
test loss item: 0.36992520093917847
test loss item: 0.23595918715000153
test loss item: 0.4228821098804474
test loss item: 0.26881757378578186
test loss item: 0.792317271232605
test loss item: 0.5467207431793213
test loss item: 0.374489963054657
test loss item: 0.31936028599739075
test loss item: 0.5739417672157288
test loss item: 0.8283711671829224
test loss item: 0.4081282615661621
test loss item: 0.154836967587471
test loss item: 0.30069446563720703
test loss item: 0.1831844449043274
test loss item: 0.3770875930786133
test loss item: 1.0600895881652832
test loss item: 0.6097639203071594
test loss item: 0.36008140444755554
test loss item: 0.29806604981422424
test loss item: 0.2522852122783661
test loss item: 0.5479974150657654
test loss item: 0.262611985206604
test loss item: 0.26504284143447876
test loss item: 0.30879589915275574
test loss item: 0.9919099807739258
test loss item: 0.3597911596298218
test loss item: 0.38536202907562256
test loss item: 0.31538230180740356
test loss item: 0.6362854242324829
test loss item: 0.44072338938713074
test loss item: 0.06438462436199188
test loss item: 1.162174940109253
test loss item: 0.4179673492908478
test loss item: 0.4789661765098572
test loss item: 0.20018084347248077
test loss item: 0.2153882086277008
test loss item: 0.20814363658428192
test loss item: 1.706592321395874
test loss item: 0.5773895978927612
test loss item: 0.2373054325580597
test loss item: 0.09459483623504639
test loss item: 1.0977264642715454
test loss item: 1.035956859588623
test loss item: 1.1649881601333618
test loss item: 0.27180078625679016
test loss item: 0.2918470799922943
test loss item: 0.08457370102405548
test loss item: 0.06552089005708694
test loss item: 0.20870116353034973
Epoch [29/100], Training Loss: 0.5420, Testing Loss: 0.4802
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 30/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.48140138387680054
1
train loss item: 1.394365906715393
2
train loss item: 0.2608802318572998
3
train loss item: 0.646105945110321
4
train loss item: 0.46055516600608826
5
train loss item: 0.3792787790298462
6
train loss item: 0.31658121943473816
7
train loss item: 0.9083985686302185
8
train loss item: 0.1501954346895218
9
train loss item: 0.31728678941726685
10
train loss item: 0.4239759147167206
11
train loss item: 0.3271031081676483
12
train loss item: 0.10440293699502945
13
train loss item: 0.5190014243125916
14
train loss item: 0.25452759861946106
15
train loss item: 0.7036194205284119
16
train loss item: 0.049627635627985
17
train loss item: 0.3597053587436676
18
train loss item: 0.41072797775268555
19
train loss item: 0.3225748538970947
20
train loss item: 0.26240912079811096
21
train loss item: 0.12983514368534088
22
train loss item: 1.1191301345825195
23
train loss item: 1.0219244956970215
24
train loss item: 0.6987088322639465
25
train loss item: 0.1786428987979889
26
train loss item: 0.21502326428890228
27
train loss item: 0.27248382568359375
28
train loss item: 0.04567847028374672
29
train loss item: 0.8363722562789917
30
train loss item: 2.4656076431274414
31
train loss item: 0.6681861281394958
32
train loss item: 0.09811682999134064
33
train loss item: 0.4870814085006714
34
train loss item: 0.10427086800336838
35
train loss item: 2.546294689178467
36
train loss item: 0.5459383130073547
37
train loss item: 0.5298298001289368
38
train loss item: 0.5613007545471191
39
train loss item: 0.2662945091724396
40
train loss item: 0.16668732464313507
41
train loss item: 0.30439549684524536
42
train loss item: 0.34253907203674316
43
train loss item: 0.2116313874721527
44
train loss item: 0.7169264554977417
45
train loss item: 0.1373472958803177
46
train loss item: 0.1269601434469223
47
train loss item: 0.42695748805999756
48
train loss item: 0.2670772075653076
49
train loss item: 0.16803006827831268
50
train loss item: 0.37322133779525757
51
train loss item: 1.0126595497131348
52
train loss item: 0.056179627776145935
53
train loss item: 0.1679827868938446
54
train loss item: 2.411921977996826
55
train loss item: 0.25430160760879517
56
train loss item: 0.34674322605133057
57
train loss item: 0.2718164026737213
58
train loss item: 0.1844327300786972
59
train loss item: 0.09769383817911148
60
train loss item: 1.0176807641983032
61
train loss item: 2.340857982635498
62
train loss item: 0.25304168462753296
63
train loss item: 0.45747849345207214
64
train loss item: 0.1799045205116272
65
train loss item: 0.7182745933532715
66
train loss item: 0.48645010590553284
67
train loss item: 0.22800104320049286
68
train loss item: 0.37042102217674255
69
train loss item: 0.42436715960502625
70
train loss item: 0.3161582946777344
71
train loss item: 0.13304102420806885
72
train loss item: 0.2089664340019226
73
train loss item: 0.36124908924102783
74
train loss item: 0.06513895839452744
75
train loss item: 0.09682455658912659
76
train loss item: 1.0226938724517822
77
train loss item: 1.4414563179016113
78
train loss item: 0.06064603850245476
79
train loss item: 0.3323899805545807
80
train loss item: 0.1216789111495018
81
train loss item: 0.2124580293893814
82
train loss item: 0.22232086956501007
83
train loss item: 0.7450476884841919
84
train loss item: 0.48387402296066284
85
train loss item: 0.7135350108146667
86
train loss item: 4.481125354766846
87
train loss item: 0.17852528393268585
88
train loss item: 0.443602979183197
epoch train loss: 0.5393950578788024
testing phase
test loss item: 0.21458233892917633
test loss item: 0.09519270807504654
test loss item: 0.7029592990875244
test loss item: 0.26961588859558105
test loss item: 0.2975931167602539
test loss item: 0.14263948798179626
test loss item: 2.0966808795928955
test loss item: 0.5349147319793701
test loss item: 0.26760637760162354
test loss item: 0.4974810779094696
test loss item: 1.0494948625564575
test loss item: 0.19261159002780914
test loss item: 0.21709692478179932
test loss item: 0.42917466163635254
test loss item: 0.20119516551494598
test loss item: 0.06338607519865036
test loss item: 0.3649810254573822
test loss item: 0.5869598984718323
test loss item: 0.7629746198654175
test loss item: 0.37077200412750244
test loss item: 0.9346367716789246
test loss item: 0.4315280318260193
test loss item: 0.354732871055603
test loss item: 0.2132631540298462
test loss item: 0.2731773555278778
test loss item: 0.2814317047595978
test loss item: 0.4314231872558594
test loss item: 0.23008958995342255
test loss item: 0.42685917019844055
test loss item: 0.4367329180240631
test loss item: 0.9563589096069336
test loss item: 0.06275998055934906
test loss item: 0.1806470900774002
test loss item: 0.6893620491027832
test loss item: 0.5435235500335693
test loss item: 0.4995153546333313
test loss item: 0.9542566537857056
test loss item: 1.7287118434906006
test loss item: 0.6475858092308044
test loss item: 0.3372046947479248
test loss item: 0.3716749846935272
test loss item: 0.2396564781665802
test loss item: 0.4223353862762451
test loss item: 0.2694278359413147
test loss item: 0.7860485911369324
test loss item: 0.5503448247909546
test loss item: 0.37365350127220154
test loss item: 0.3235552906990051
test loss item: 0.5745202302932739
test loss item: 0.834966778755188
test loss item: 0.4001131057739258
test loss item: 0.15414413809776306
test loss item: 0.2993636429309845
test loss item: 0.18147651851177216
test loss item: 0.3738549053668976
test loss item: 1.0664687156677246
test loss item: 0.6138145327568054
test loss item: 0.3496915102005005
test loss item: 0.29791027307510376
test loss item: 0.24890336394309998
test loss item: 0.5475035905838013
test loss item: 0.2643861174583435
test loss item: 0.2676909565925598
test loss item: 0.31016236543655396
test loss item: 0.99992436170578
test loss item: 0.3594213128089905
test loss item: 0.38846418261528015
test loss item: 0.31705111265182495
test loss item: 0.6367272734642029
test loss item: 0.4468174874782562
test loss item: 0.06402111053466797
test loss item: 1.1709040403366089
test loss item: 0.41886967420578003
test loss item: 0.48637619614601135
test loss item: 0.19963660836219788
test loss item: 0.21646708250045776
test loss item: 0.2100326269865036
test loss item: 1.721067190170288
test loss item: 0.5842068195343018
test loss item: 0.23681846261024475
test loss item: 0.09160158783197403
test loss item: 1.1116564273834229
test loss item: 1.040302038192749
test loss item: 1.1772689819335938
test loss item: 0.2769281268119812
test loss item: 0.29061490297317505
test loss item: 0.08027181774377823
test loss item: 0.0635930523276329
test loss item: 0.21292218565940857
Epoch [30/100], Training Loss: 0.5394, Testing Loss: 0.4820
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 31/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.473084956407547
1
train loss item: 1.3841134309768677
2
train loss item: 0.262138694524765
3
train loss item: 0.6444418430328369
4
train loss item: 0.452515184879303
5
train loss item: 0.37708398699760437
6
train loss item: 0.3156689703464508
7
train loss item: 0.9009659290313721
8
train loss item: 0.14971406757831573
9
train loss item: 0.3179338872432709
10
train loss item: 0.42517387866973877
11
train loss item: 0.3269282281398773
12
train loss item: 0.10354238003492355
13
train loss item: 0.5171881318092346
14
train loss item: 0.2532999515533447
15
train loss item: 0.7036271691322327
16
train loss item: 0.0479503870010376
17
train loss item: 0.3586445152759552
18
train loss item: 0.4075218141078949
19
train loss item: 0.322686105966568
20
train loss item: 0.2597551643848419
21
train loss item: 0.12552598118782043
22
train loss item: 1.1081733703613281
23
train loss item: 1.0195459127426147
24
train loss item: 0.7041078805923462
25
train loss item: 0.17538899183273315
26
train loss item: 0.21522702276706696
27
train loss item: 0.27222657203674316
28
train loss item: 0.0443873256444931
29
train loss item: 0.8351550698280334
30
train loss item: 2.451545000076294
31
train loss item: 0.6663832664489746
32
train loss item: 0.09863147884607315
33
train loss item: 0.4869725704193115
34
train loss item: 0.10460633039474487
35
train loss item: 2.534149408340454
36
train loss item: 0.5436293482780457
37
train loss item: 0.527703583240509
38
train loss item: 0.5613130331039429
39
train loss item: 0.2607058882713318
40
train loss item: 0.16823743283748627
41
train loss item: 0.3024367690086365
42
train loss item: 0.34667906165122986
43
train loss item: 0.21141280233860016
44
train loss item: 0.7118057012557983
45
train loss item: 0.1316583752632141
46
train loss item: 0.1252806931734085
47
train loss item: 0.4264168441295624
48
train loss item: 0.2659975588321686
49
train loss item: 0.16738346219062805
50
train loss item: 0.3720982074737549
51
train loss item: 1.0088914632797241
52
train loss item: 0.05246932432055473
53
train loss item: 0.16543981432914734
54
train loss item: 2.399846315383911
55
train loss item: 0.25290238857269287
56
train loss item: 0.3411601781845093
57
train loss item: 0.27243825793266296
58
train loss item: 0.18401511013507843
59
train loss item: 0.09776109457015991
60
train loss item: 1.0141880512237549
61
train loss item: 2.331458330154419
62
train loss item: 0.24987578392028809
63
train loss item: 0.45988988876342773
64
train loss item: 0.18079639971256256
65
train loss item: 0.7081605792045593
66
train loss item: 0.4850202798843384
67
train loss item: 0.22534213960170746
68
train loss item: 0.369285523891449
69
train loss item: 0.42223063111305237
70
train loss item: 0.31543222069740295
71
train loss item: 0.13283780217170715
72
train loss item: 0.20999231934547424
73
train loss item: 0.36122557520866394
74
train loss item: 0.06879421323537827
75
train loss item: 0.09733469784259796
76
train loss item: 1.0207431316375732
77
train loss item: 1.4367210865020752
78
train loss item: 0.055735453963279724
79
train loss item: 0.33269062638282776
80
train loss item: 0.1206846609711647
81
train loss item: 0.21227651834487915
82
train loss item: 0.2205650508403778
83
train loss item: 0.7444208860397339
84
train loss item: 0.4844137132167816
85
train loss item: 0.7154751420021057
86
train loss item: 4.46336555480957
87
train loss item: 0.17749546468257904
88
train loss item: 0.44037240743637085
epoch train loss: 0.5370844011142683
testing phase
test loss item: 0.21431168913841248
test loss item: 0.09336135536432266
test loss item: 0.702540397644043
test loss item: 0.26833781599998474
test loss item: 0.2955052852630615
test loss item: 0.13833074271678925
test loss item: 2.100023031234741
test loss item: 0.5346800088882446
test loss item: 0.2671829164028168
test loss item: 0.4942513108253479
test loss item: 1.0506784915924072
test loss item: 0.19276493787765503
test loss item: 0.21348829567432404
test loss item: 0.42840734124183655
test loss item: 0.19975848495960236
test loss item: 0.06330371648073196
test loss item: 0.36316928267478943
test loss item: 0.5824891924858093
test loss item: 0.7633745670318604
test loss item: 0.3703726828098297
test loss item: 0.9281437993049622
test loss item: 0.4304454028606415
test loss item: 0.35495975613594055
test loss item: 0.2130555957555771
test loss item: 0.2721286714076996
test loss item: 0.2805531919002533
test loss item: 0.4301909804344177
test loss item: 0.22657404839992523
test loss item: 0.42507636547088623
test loss item: 0.433743953704834
test loss item: 0.9568033218383789
test loss item: 0.06418489664793015
test loss item: 0.18015506863594055
test loss item: 0.6864255666732788
test loss item: 0.5419472455978394
test loss item: 0.49485763907432556
test loss item: 0.9531940817832947
test loss item: 1.7330015897750854
test loss item: 0.643851101398468
test loss item: 0.3366169035434723
test loss item: 0.371652752161026
test loss item: 0.24067501723766327
test loss item: 0.4178526699542999
test loss item: 0.2677713632583618
test loss item: 0.7789734601974487
test loss item: 0.5489409565925598
test loss item: 0.3703864514827728
test loss item: 0.3226291835308075
test loss item: 0.5713004469871521
test loss item: 0.8350487947463989
test loss item: 0.3912317454814911
test loss item: 0.1521374136209488
test loss item: 0.2965772747993469
test loss item: 0.17969736456871033
test loss item: 0.3698291778564453
test loss item: 1.0657423734664917
test loss item: 0.6144306063652039
test loss item: 0.33975735306739807
test loss item: 0.29532650113105774
test loss item: 0.2452072948217392
test loss item: 0.5427204966545105
test loss item: 0.2622554898262024
test loss item: 0.267796128988266
test loss item: 0.310647189617157
test loss item: 1.0022104978561401
test loss item: 0.3578818142414093
test loss item: 0.3873912990093231
test loss item: 0.3173640966415405
test loss item: 0.6355539560317993
test loss item: 0.44748836755752563
test loss item: 0.06363826990127563
test loss item: 1.1731090545654297
test loss item: 0.41584476828575134
test loss item: 0.4882935881614685
test loss item: 0.19651934504508972
test loss item: 0.21538233757019043
test loss item: 0.21014656126499176
test loss item: 1.7257407903671265
test loss item: 0.5866717100143433
test loss item: 0.23439152538776398
test loss item: 0.08984105288982391
test loss item: 1.116381049156189
test loss item: 1.0389589071273804
test loss item: 1.1800956726074219
test loss item: 0.27920594811439514
test loss item: 0.2869729697704315
test loss item: 0.07831859588623047
test loss item: 0.0646689161658287
test loss item: 0.21636337041854858
Epoch [31/100], Training Loss: 0.5371, Testing Loss: 0.4808
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6830.00 MB
Epoch 32/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46875104308128357
1
train loss item: 1.371289610862732
2
train loss item: 0.26266786456108093
3
train loss item: 0.6404750943183899
4
train loss item: 0.4490983188152313
5
train loss item: 0.37516501545906067
6
train loss item: 0.31217527389526367
7
train loss item: 0.8914986848831177
8
train loss item: 0.1488368660211563
9
train loss item: 0.31684455275535583
10
train loss item: 0.42491090297698975
11
train loss item: 0.3293740451335907
12
train loss item: 0.10330966860055923
13
train loss item: 0.5154709815979004
14
train loss item: 0.2529878318309784
15
train loss item: 0.6991344690322876
16
train loss item: 0.04757179319858551
17
train loss item: 0.3561277985572815
18
train loss item: 0.4046730101108551
19
train loss item: 0.32186803221702576
20
train loss item: 0.2558565139770508
21
train loss item: 0.1270337849855423
22
train loss item: 1.094765067100525
23
train loss item: 1.014751672744751
24
train loss item: 0.7054380178451538
25
train loss item: 0.17341560125350952
26
train loss item: 0.21691453456878662
27
train loss item: 0.27114883065223694
28
train loss item: 0.0442025363445282
29
train loss item: 0.8270798921585083
30
train loss item: 2.4343159198760986
31
train loss item: 0.6668242812156677
32
train loss item: 0.09865584224462509
33
train loss item: 0.4829770624637604
34
train loss item: 0.10618381947278976
35
train loss item: 2.520704984664917
36
train loss item: 0.5436233878135681
37
train loss item: 0.5303105711936951
38
train loss item: 0.5670133829116821
39
train loss item: 0.2574058175086975
40
train loss item: 0.16911624372005463
41
train loss item: 0.30199989676475525
42
train loss item: 0.34905490279197693
43
train loss item: 0.21139736473560333
44
train loss item: 0.7058507204055786
45
train loss item: 0.1261667013168335
46
train loss item: 0.1242603287100792
47
train loss item: 0.42356958985328674
48
train loss item: 0.26384299993515015
49
train loss item: 0.1682833582162857
50
train loss item: 0.37030163407325745
51
train loss item: 1.0001493692398071
52
train loss item: 0.05131842568516731
53
train loss item: 0.16285210847854614
54
train loss item: 2.386328935623169
55
train loss item: 0.24879416823387146
56
train loss item: 0.33970755338668823
57
train loss item: 0.27289631962776184
58
train loss item: 0.18385282158851624
59
train loss item: 0.09795371443033218
60
train loss item: 1.0049068927764893
61
train loss item: 2.318666934967041
62
train loss item: 0.24780024588108063
63
train loss item: 0.4613262116909027
64
train loss item: 0.18170210719108582
65
train loss item: 0.705316424369812
66
train loss item: 0.48727571964263916
67
train loss item: 0.22336408495903015
68
train loss item: 0.3664405643939972
69
train loss item: 0.4212172329425812
70
train loss item: 0.31368207931518555
71
train loss item: 0.13161051273345947
72
train loss item: 0.21001778542995453
73
train loss item: 0.3601881265640259
74
train loss item: 0.06893251836299896
75
train loss item: 0.09745637327432632
76
train loss item: 1.0156919956207275
77
train loss item: 1.4258241653442383
78
train loss item: 0.052718259394168854
79
train loss item: 0.3340289890766144
80
train loss item: 0.11893969029188156
81
train loss item: 0.2113940566778183
82
train loss item: 0.21948625147342682
83
train loss item: 0.7371718287467957
84
train loss item: 0.4907810688018799
85
train loss item: 0.7129371166229248
86
train loss item: 4.444091320037842
87
train loss item: 0.17599371075630188
88
train loss item: 0.43731528520584106
epoch train loss: 0.534436259418726
testing phase
test loss item: 0.21322408318519592
test loss item: 0.09056093543767929
test loss item: 0.6980222463607788
test loss item: 0.26643508672714233
test loss item: 0.2924511432647705
test loss item: 0.1337374895811081
test loss item: 2.0897672176361084
test loss item: 0.5324380993843079
test loss item: 0.26398733258247375
test loss item: 0.4892127513885498
test loss item: 1.0441844463348389
test loss item: 0.1930304765701294
test loss item: 0.20950473845005035
test loss item: 0.4241456687450409
test loss item: 0.1975497603416443
test loss item: 0.06321871280670166
test loss item: 0.3595794439315796
test loss item: 0.5768218040466309
test loss item: 0.7609959840774536
test loss item: 0.3659694194793701
test loss item: 0.9213863015174866
test loss item: 0.4272571802139282
test loss item: 0.3522065579891205
test loss item: 0.21094752848148346
test loss item: 0.27046817541122437
test loss item: 0.2786099314689636
test loss item: 0.4259400963783264
test loss item: 0.22308558225631714
test loss item: 0.42111754417419434
test loss item: 0.42998841404914856
test loss item: 0.9488487839698792
test loss item: 0.06549810618162155
test loss item: 0.1782560497522354
test loss item: 0.6815588474273682
test loss item: 0.5390059947967529
test loss item: 0.48673081398010254
test loss item: 0.9485250115394592
test loss item: 1.7233667373657227
test loss item: 0.63861083984375
test loss item: 0.33404141664505005
test loss item: 0.3697167932987213
test loss item: 0.23867011070251465
test loss item: 0.41299739480018616
test loss item: 0.2648250162601471
test loss item: 0.7711830735206604
test loss item: 0.5452760457992554
test loss item: 0.36533522605895996
test loss item: 0.31777507066726685
test loss item: 0.5656611323356628
test loss item: 0.8289831876754761
test loss item: 0.3827969431877136
test loss item: 0.14944221079349518
test loss item: 0.2927356958389282
test loss item: 0.1784561574459076
test loss item: 0.3654463589191437
test loss item: 1.0582911968231201
test loss item: 0.611945390701294
test loss item: 0.3312739431858063
test loss item: 0.2913554310798645
test loss item: 0.24143187701702118
test loss item: 0.5363078713417053
test loss item: 0.2581363320350647
test loss item: 0.2656671404838562
test loss item: 0.30992209911346436
test loss item: 0.9976875185966492
test loss item: 0.3561897575855255
test loss item: 0.38361313939094543
test loss item: 0.3162411153316498
test loss item: 0.6328487396240234
test loss item: 0.44318878650665283
test loss item: 0.0628235936164856
test loss item: 1.1685736179351807
test loss item: 0.40882548689842224
test loss item: 0.4844459891319275
test loss item: 0.1921301931142807
test loss item: 0.21212118864059448
test loss item: 0.2083870768547058
test loss item: 1.7165883779525757
test loss item: 0.5835737586021423
test loss item: 0.2308838665485382
test loss item: 0.08866384625434875
test loss item: 1.110513687133789
test loss item: 1.0325345993041992
test loss item: 1.1714292764663696
test loss item: 0.27756941318511963
test loss item: 0.2821944057941437
test loss item: 0.07738424092531204
test loss item: 0.06598050892353058
test loss item: 0.21819821000099182
Epoch [32/100], Training Loss: 0.5344, Testing Loss: 0.4769
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 33/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46680909395217896
1
train loss item: 1.3576240539550781
2
train loss item: 0.2623305022716522
3
train loss item: 0.6341454982757568
4
train loss item: 0.4501779079437256
5
train loss item: 0.3735646605491638
6
train loss item: 0.3080396056175232
7
train loss item: 0.8807194232940674
8
train loss item: 0.14797347784042358
9
train loss item: 0.3137100636959076
10
train loss item: 0.4220535159111023
11
train loss item: 0.3310345709323883
12
train loss item: 0.10437484830617905
13
train loss item: 0.5138350129127502
14
train loss item: 0.2530885934829712
15
train loss item: 0.6914716362953186
16
train loss item: 0.04863834008574486
17
train loss item: 0.35342642664909363
18
train loss item: 0.40189817547798157
19
train loss item: 0.3203124403953552
20
train loss item: 0.2520489990711212
21
train loss item: 0.1330597996711731
22
train loss item: 1.0803883075714111
23
train loss item: 1.0074158906936646
24
train loss item: 0.7021379470825195
25
train loss item: 0.1723640114068985
26
train loss item: 0.22040331363677979
27
train loss item: 0.26881882548332214
28
train loss item: 0.04523034393787384
29
train loss item: 0.8131545782089233
30
train loss item: 2.41428804397583
31
train loss item: 0.6680176258087158
32
train loss item: 0.09813179820775986
33
train loss item: 0.47652775049209595
34
train loss item: 0.11190389841794968
35
train loss item: 2.506554126739502
36
train loss item: 0.545390784740448
37
train loss item: 0.5347265601158142
38
train loss item: 0.5760960578918457
39
train loss item: 0.25581440329551697
40
train loss item: 0.16928593814373016
41
train loss item: 0.30050569772720337
42
train loss item: 0.34920734167099
43
train loss item: 0.21210849285125732
44
train loss item: 0.6988185048103333
45
train loss item: 0.12194468080997467
46
train loss item: 0.12343920022249222
47
train loss item: 0.41942745447158813
48
train loss item: 0.26111069321632385
49
train loss item: 0.1704501062631607
50
train loss item: 0.3679521679878235
51
train loss item: 0.9882592558860779
52
train loss item: 0.0528588704764843
53
train loss item: 0.16157133877277374
54
train loss item: 2.3719325065612793
55
train loss item: 0.24336741864681244
56
train loss item: 0.34076404571533203
57
train loss item: 0.27229809761047363
58
train loss item: 0.18480443954467773
59
train loss item: 0.09764841943979263
60
train loss item: 0.9907062649726868
61
train loss item: 2.3029799461364746
62
train loss item: 0.24668088555335999
63
train loss item: 0.46083927154541016
64
train loss item: 0.18259301781654358
65
train loss item: 0.7081428170204163
66
train loss item: 0.4910017251968384
67
train loss item: 0.223114013671875
68
train loss item: 0.36313915252685547
69
train loss item: 0.4212265610694885
70
train loss item: 0.3112548589706421
71
train loss item: 0.13014677166938782
72
train loss item: 0.20900613069534302
73
train loss item: 0.3582913875579834
74
train loss item: 0.06609977781772614
75
train loss item: 0.09726172685623169
76
train loss item: 1.008003830909729
77
train loss item: 1.410060167312622
78
train loss item: 0.05297960713505745
79
train loss item: 0.3342128098011017
80
train loss item: 0.11780177801847458
81
train loss item: 0.21042349934577942
82
train loss item: 0.2191656529903412
83
train loss item: 0.7243845462799072
84
train loss item: 0.49935001134872437
85
train loss item: 0.7057446241378784
86
train loss item: 4.423738956451416
87
train loss item: 0.17566169798374176
88
train loss item: 0.43617576360702515
epoch train loss: 0.5315240768485525
testing phase
test loss item: 0.2121126800775528
test loss item: 0.08773484826087952
test loss item: 0.6942959427833557
test loss item: 0.2640652358531952
test loss item: 0.2900402247905731
test loss item: 0.13015949726104736
test loss item: 2.07247257232666
test loss item: 0.5336565375328064
test loss item: 0.26075419783592224
test loss item: 0.4856571853160858
test loss item: 1.035740852355957
test loss item: 0.19392763078212738
test loss item: 0.20681430399417877
test loss item: 0.4173305332660675
test loss item: 0.19554629921913147
test loss item: 0.0628867819905281
test loss item: 0.3564499616622925
test loss item: 0.5744712948799133
test loss item: 0.759372353553772
test loss item: 0.36074337363243103
test loss item: 0.9195004105567932
test loss item: 0.4242754280567169
test loss item: 0.34931525588035583
test loss item: 0.20801469683647156
test loss item: 0.26925674080848694
test loss item: 0.2766006588935852
test loss item: 0.4212419092655182
test loss item: 0.22111815214157104
test loss item: 0.41693541407585144
test loss item: 0.42752018570899963
test loss item: 0.9375218749046326
test loss item: 0.06610026955604553
test loss item: 0.17584221065044403
test loss item: 0.6816200017929077
test loss item: 0.5387147665023804
test loss item: 0.48069244623184204
test loss item: 0.9442917108535767
test loss item: 1.7102316617965698
test loss item: 0.6344912648200989
test loss item: 0.33072179555892944
test loss item: 0.3668084442615509
test loss item: 0.2344134896993637
test loss item: 0.4098605811595917
test loss item: 0.2614176869392395
test loss item: 0.7663179636001587
test loss item: 0.5426968932151794
test loss item: 0.36074119806289673
test loss item: 0.31156685948371887
test loss item: 0.5621086955070496
test loss item: 0.8227744698524475
test loss item: 0.3773632347583771
test loss item: 0.14719517529010773
test loss item: 0.2893458604812622
test loss item: 0.17776454985141754
test loss item: 0.3627459704875946
test loss item: 1.0522595643997192
test loss item: 0.6101230978965759
test loss item: 0.3273577392101288
test loss item: 0.2880443334579468
test loss item: 0.23851065337657928
test loss item: 0.5318987369537354
test loss item: 0.25521740317344666
test loss item: 0.26315441727638245
test loss item: 0.308397114276886
test loss item: 0.9921493530273438
test loss item: 0.35432112216949463
test loss item: 0.3800372779369354
test loss item: 0.31437864899635315
test loss item: 0.6313114166259766
test loss item: 0.4391718804836273
test loss item: 0.061286114156246185
test loss item: 1.1616588830947876
test loss item: 0.40029558539390564
test loss item: 0.47771143913269043
test loss item: 0.18845272064208984
test loss item: 0.20774520933628082
test loss item: 0.20576530694961548
test loss item: 1.7026242017745972
test loss item: 0.5768478512763977
test loss item: 0.22791720926761627
test loss item: 0.08736211061477661
test loss item: 1.1013727188110352
test loss item: 1.025728702545166
test loss item: 1.160254955291748
test loss item: 0.2729704678058624
test loss item: 0.2786133885383606
test loss item: 0.07637952268123627
test loss item: 0.06578245759010315
test loss item: 0.2173609584569931
Epoch [33/100], Training Loss: 0.5315, Testing Loss: 0.4731
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 34/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46555644273757935
1
train loss item: 1.3461148738861084
2
train loss item: 0.26093849539756775
3
train loss item: 0.6278906464576721
4
train loss item: 0.45113593339920044
5
train loss item: 0.3725840151309967
6
train loss item: 0.3055669367313385
7
train loss item: 0.8704041242599487
8
train loss item: 0.14786186814308167
9
train loss item: 0.3099324703216553
10
train loss item: 0.416943222284317
11
train loss item: 0.32899904251098633
12
train loss item: 0.1062963679432869
13
train loss item: 0.5124423503875732
14
train loss item: 0.25382518768310547
15
train loss item: 0.6844896674156189
16
train loss item: 0.05039737746119499
17
train loss item: 0.3519582450389862
18
train loss item: 0.3984069228172302
19
train loss item: 0.31857141852378845
20
train loss item: 0.25087204575538635
21
train loss item: 0.1389053612947464
22
train loss item: 1.067869782447815
23
train loss item: 0.9993776082992554
24
train loss item: 0.695021390914917
25
train loss item: 0.1713784784078598
26
train loss item: 0.22374968230724335
27
train loss item: 0.26683691143989563
28
train loss item: 0.04682835936546326
29
train loss item: 0.7985316514968872
30
train loss item: 2.3941078186035156
31
train loss item: 0.6667744517326355
32
train loss item: 0.09648626297712326
33
train loss item: 0.47201797366142273
34
train loss item: 0.11737147718667984
35
train loss item: 2.492886543273926
36
train loss item: 0.546667754650116
37
train loss item: 0.5337917804718018
38
train loss item: 0.5805773735046387
39
train loss item: 0.2542440891265869
40
train loss item: 0.16793225705623627
41
train loss item: 0.29725924134254456
42
train loss item: 0.34737950563430786
43
train loss item: 0.21249228715896606
44
train loss item: 0.692136287689209
45
train loss item: 0.11924678832292557
46
train loss item: 0.1223892793059349
47
train loss item: 0.41615307331085205
48
train loss item: 0.25895068049430847
49
train loss item: 0.17318442463874817
50
train loss item: 0.3657841682434082
51
train loss item: 0.9775030016899109
52
train loss item: 0.05626699700951576
53
train loss item: 0.160780131816864
54
train loss item: 2.3577349185943604
55
train loss item: 0.2391819804906845
56
train loss item: 0.3402162790298462
57
train loss item: 0.2704581022262573
58
train loss item: 0.1862265020608902
59
train loss item: 0.0973379835486412
60
train loss item: 0.9763846397399902
61
train loss item: 2.2873473167419434
62
train loss item: 0.24612480401992798
63
train loss item: 0.45819732546806335
64
train loss item: 0.18277451395988464
65
train loss item: 0.7145614624023438
66
train loss item: 0.4920523166656494
67
train loss item: 0.2241639643907547
68
train loss item: 0.3620467483997345
69
train loss item: 0.421249657869339
70
train loss item: 0.3090074360370636
71
train loss item: 0.12929284572601318
72
train loss item: 0.2074398398399353
73
train loss item: 0.35620734095573425
74
train loss item: 0.062333159148693085
75
train loss item: 0.09737809747457504
76
train loss item: 1.0003572702407837
77
train loss item: 1.3936809301376343
78
train loss item: 0.05595863610506058
79
train loss item: 0.3312074840068817
80
train loss item: 0.11619656533002853
81
train loss item: 0.20975524187088013
82
train loss item: 0.21949650347232819
83
train loss item: 0.7111291289329529
84
train loss item: 0.5022298693656921
85
train loss item: 0.6972664594650269
86
train loss item: 4.403139114379883
87
train loss item: 0.17557752132415771
88
train loss item: 0.4372000992298126
epoch train loss: 0.5284604785147677
testing phase
test loss item: 0.2135738581418991
test loss item: 0.08602975308895111
test loss item: 0.6993212699890137
test loss item: 0.26289549469947815
test loss item: 0.2903444766998291
test loss item: 0.12897561490535736
test loss item: 2.060167074203491
test loss item: 0.541650116443634
test loss item: 0.26124367117881775
test loss item: 0.4887375235557556
test loss item: 1.0351508855819702
test loss item: 0.1996924877166748
test loss item: 0.20744790136814117
test loss item: 0.4095540940761566
test loss item: 0.1949087381362915
test loss item: 0.061074160039424896
test loss item: 0.3565589487552643
test loss item: 0.5846208333969116
test loss item: 0.7619704604148865
test loss item: 0.35951605439186096
test loss item: 0.9303681254386902
test loss item: 0.4248899817466736
test loss item: 0.35288316011428833
test loss item: 0.20531639456748962
test loss item: 0.27030667662620544
test loss item: 0.2755753993988037
test loss item: 0.4206170439720154
test loss item: 0.2229664921760559
test loss item: 0.41547733545303345
test loss item: 0.43025943636894226
test loss item: 0.9323461055755615
test loss item: 0.06305443495512009
test loss item: 0.1733192652463913
test loss item: 0.6898053884506226
test loss item: 0.5462710857391357
test loss item: 0.48515212535858154
test loss item: 0.9457820653915405
test loss item: 1.7109050750732422
test loss item: 0.6378495693206787
test loss item: 0.3289725184440613
test loss item: 0.36456185579299927
test loss item: 0.22936472296714783
test loss item: 0.41549158096313477
test loss item: 0.2603921890258789
test loss item: 0.769135057926178
test loss item: 0.5450847148895264
test loss item: 0.36010435223579407
test loss item: 0.308362752199173
test loss item: 0.5672712922096252
test loss item: 0.8250425457954407
test loss item: 0.3789769113063812
test loss item: 0.1466452032327652
test loss item: 0.2889263331890106
test loss item: 0.1825673133134842
test loss item: 0.3647565245628357
test loss item: 1.0590828657150269
test loss item: 0.613541305065155
test loss item: 0.3282800316810608
test loss item: 0.2877277135848999
test loss item: 0.2381104826927185
test loss item: 0.537801206111908
test loss item: 0.25559067726135254
test loss item: 0.26378536224365234
test loss item: 0.306956022977829
test loss item: 0.9937819242477417
test loss item: 0.3546923100948334
test loss item: 0.38033726811408997
test loss item: 0.31301599740982056
test loss item: 0.6356155276298523
test loss item: 0.4430946409702301
test loss item: 0.05952470004558563
test loss item: 1.1583211421966553
test loss item: 0.39438700675964355
test loss item: 0.47327256202697754
test loss item: 0.1881854385137558
test loss item: 0.2040715217590332
test loss item: 0.2034207284450531
test loss item: 1.7000830173492432
test loss item: 0.5707409381866455
test loss item: 0.22918882966041565
test loss item: 0.08561751246452332
test loss item: 1.10053551197052
test loss item: 1.0262519121170044
test loss item: 1.1601979732513428
test loss item: 0.26808977127075195
test loss item: 0.2787185311317444
test loss item: 0.07455826550722122
test loss item: 0.06195615604519844
test loss item: 0.21289333701133728
Epoch [34/100], Training Loss: 0.5285, Testing Loss: 0.4734
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 35/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46597394347190857
1
train loss item: 1.3388044834136963
2
train loss item: 0.25807690620422363
3
train loss item: 0.6249806880950928
4
train loss item: 0.4456847310066223
5
train loss item: 0.3713756799697876
6
train loss item: 0.3052600622177124
7
train loss item: 0.8631782531738281
8
train loss item: 0.14820124208927155
9
train loss item: 0.3071218729019165
10
train loss item: 0.41178303956985474
11
train loss item: 0.32227376103401184
12
train loss item: 0.10709524899721146
13
train loss item: 0.5109976530075073
14
train loss item: 0.25603172183036804
15
train loss item: 0.6817131042480469
16
train loss item: 0.05057249963283539
17
train loss item: 0.35218068957328796
18
train loss item: 0.3934715986251831
19
train loss item: 0.3169139623641968
20
train loss item: 0.2536817491054535
21
train loss item: 0.1369817554950714
22
train loss item: 1.0598398447036743
23
train loss item: 0.9923452734947205
24
train loss item: 0.687374472618103
25
train loss item: 0.17162741720676422
26
train loss item: 0.22321948409080505
27
train loss item: 0.2669871151447296
28
train loss item: 0.047015056014060974
29
train loss item: 0.7906100749969482
30
train loss item: 2.37687087059021
31
train loss item: 0.6606408953666687
32
train loss item: 0.09468928724527359
33
train loss item: 0.47299718856811523
34
train loss item: 0.11488327383995056
35
train loss item: 2.480698823928833
36
train loss item: 0.545962393283844
37
train loss item: 0.5216296911239624
38
train loss item: 0.5764504671096802
39
train loss item: 0.2510504424571991
40
train loss item: 0.16371212899684906
41
train loss item: 0.29362449049949646
42
train loss item: 0.3426751494407654
43
train loss item: 0.21079155802726746
44
train loss item: 0.6890969276428223
45
train loss item: 0.11753960698843002
46
train loss item: 0.12126723676919937
47
train loss item: 0.41429445147514343
48
train loss item: 0.25861823558807373
49
train loss item: 0.17526070773601532
50
train loss item: 0.36454784870147705
51
train loss item: 0.9715594053268433
52
train loss item: 0.05905195325613022
53
train loss item: 0.15963409841060638
54
train loss item: 2.3447983264923096
55
train loss item: 0.23835508525371552
56
train loss item: 0.3326733112335205
57
train loss item: 0.26807984709739685
58
train loss item: 0.18558837473392487
59
train loss item: 0.09734433144330978
60
train loss item: 0.9677563309669495
61
train loss item: 2.274996280670166
62
train loss item: 0.2462247759103775
63
train loss item: 0.4533918797969818
64
train loss item: 0.18100093305110931
65
train loss item: 0.7183769941329956
66
train loss item: 0.48749861121177673
67
train loss item: 0.22377122938632965
68
train loss item: 0.3641466200351715
69
train loss item: 0.4193195402622223
70
train loss item: 0.3069128096103668
71
train loss item: 0.12803003191947937
72
train loss item: 0.20576119422912598
73
train loss item: 0.35417526960372925
74
train loss item: 0.05944427102804184
75
train loss item: 0.09694977849721909
76
train loss item: 0.9959499835968018
77
train loss item: 1.3816370964050293
78
train loss item: 0.05813152715563774
79
train loss item: 0.32386109232902527
80
train loss item: 0.11165192723274231
81
train loss item: 0.20897479355335236
82
train loss item: 0.22002984583377838
83
train loss item: 0.7044963836669922
84
train loss item: 0.4953834116458893
85
train loss item: 0.6916280388832092
86
train loss item: 4.383851528167725
87
train loss item: 0.17291715741157532
88
train loss item: 0.43739548325538635
epoch train loss: 0.5251620742963271
testing phase
test loss item: 0.21527057886123657
test loss item: 0.0855872705578804
test loss item: 0.707159698009491
test loss item: 0.26246023178100586
test loss item: 0.29108306765556335
test loss item: 0.12860535085201263
test loss item: 2.0581822395324707
test loss item: 0.5523665547370911
test loss item: 0.2622254490852356
test loss item: 0.49178218841552734
test loss item: 1.040955662727356
test loss item: 0.1997842639684677
test loss item: 0.20805323123931885
test loss item: 0.40302762389183044
test loss item: 0.1950339674949646
test loss item: 0.061663467437028885
test loss item: 0.3565795421600342
test loss item: 0.5907928347587585
test loss item: 0.7661576867103577
test loss item: 0.35805991291999817
test loss item: 0.9411194324493408
test loss item: 0.42626291513442993
test loss item: 0.3539638817310333
test loss item: 0.20481768250465393
test loss item: 0.2710685729980469
test loss item: 0.2751956284046173
test loss item: 0.42010441422462463
test loss item: 0.2238040417432785
test loss item: 0.41506344079971313
test loss item: 0.43235769867897034
test loss item: 0.9355181455612183
test loss item: 0.06280957162380219
test loss item: 0.17310045659542084
test loss item: 0.6933038830757141
test loss item: 0.5533448457717896
test loss item: 0.49037298560142517
test loss item: 0.9499889612197876
test loss item: 1.7229634523391724
test loss item: 0.6413147449493408
test loss item: 0.3282091021537781
test loss item: 0.36336201429367065
test loss item: 0.2240249365568161
test loss item: 0.4190147817134857
test loss item: 0.2596273124217987
test loss item: 0.7765637636184692
test loss item: 0.5471388697624207
test loss item: 0.35960060358047485
test loss item: 0.3042542040348053
test loss item: 0.5724186897277832
test loss item: 0.8297107815742493
test loss item: 0.3831971287727356
test loss item: 0.1461508721113205
test loss item: 0.2893275022506714
test loss item: 0.18309620022773743
test loss item: 0.36789461970329285
test loss item: 1.071425199508667
test loss item: 0.6188662648200989
test loss item: 0.33289676904678345
test loss item: 0.2885749042034149
test loss item: 0.23884418606758118
test loss item: 0.5415264964103699
test loss item: 0.2578224837779999
test loss item: 0.26485198736190796
test loss item: 0.3063426911830902
test loss item: 1.0070042610168457
test loss item: 0.35402822494506836
test loss item: 0.38080573081970215
test loss item: 0.3120076060295105
test loss item: 0.6403165459632874
test loss item: 0.4475812613964081
test loss item: 0.05969718098640442
test loss item: 1.1601101160049438
test loss item: 0.3901323974132538
test loss item: 0.4716534912586212
test loss item: 0.18739335238933563
test loss item: 0.2005314826965332
test loss item: 0.20262271165847778
test loss item: 1.715500831604004
test loss item: 0.5667243003845215
test loss item: 0.23104576766490936
test loss item: 0.08650179207324982
test loss item: 1.1058765649795532
test loss item: 1.0304852724075317
test loss item: 1.1718921661376953
test loss item: 0.2645270824432373
test loss item: 0.2782149910926819
test loss item: 0.07762686908245087
test loss item: 0.0654597356915474
test loss item: 0.20738033950328827
Epoch [35/100], Training Loss: 0.5252, Testing Loss: 0.4754
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 36/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4670104384422302
1
train loss item: 1.3340102434158325
2
train loss item: 0.2552347481250763
3
train loss item: 0.6235569715499878
4
train loss item: 0.43865102529525757
5
train loss item: 0.3704874813556671
6
train loss item: 0.306098610162735
7
train loss item: 0.858638346195221
8
train loss item: 0.14895620942115784
9
train loss item: 0.3055882453918457
10
train loss item: 0.4079172909259796
11
train loss item: 0.31496402621269226
12
train loss item: 0.10669046640396118
13
train loss item: 0.5105096101760864
14
train loss item: 0.2583344876766205
15
train loss item: 0.6813209056854248
16
train loss item: 0.04982461780309677
17
train loss item: 0.3532407581806183
18
train loss item: 0.38834118843078613
19
train loss item: 0.31596052646636963
20
train loss item: 0.2585130035877228
21
train loss item: 0.13197065889835358
22
train loss item: 1.0535850524902344
23
train loss item: 0.9879844784736633
24
train loss item: 0.6823132634162903
25
train loss item: 0.17214149236679077
26
train loss item: 0.22107002139091492
27
train loss item: 0.269107848405838
28
train loss item: 0.04607902839779854
29
train loss item: 0.7868509292602539
30
train loss item: 2.3624939918518066
31
train loss item: 0.6527245044708252
32
train loss item: 0.09260858595371246
33
train loss item: 0.475447416305542
34
train loss item: 0.10924854129552841
35
train loss item: 2.470440626144409
36
train loss item: 0.5432591438293457
37
train loss item: 0.5045233964920044
38
train loss item: 0.5711463093757629
39
train loss item: 0.2481335550546646
40
train loss item: 0.15923050045967102
41
train loss item: 0.291416198015213
42
train loss item: 0.33721426129341125
43
train loss item: 0.20810247957706451
44
train loss item: 0.6891940236091614
45
train loss item: 0.11636020243167877
46
train loss item: 0.12064026296138763
47
train loss item: 0.4134993553161621
48
train loss item: 0.25970426201820374
49
train loss item: 0.17621691524982452
50
train loss item: 0.36374351382255554
51
train loss item: 0.9693316221237183
52
train loss item: 0.06020338833332062
53
train loss item: 0.15840911865234375
54
train loss item: 2.3339755535125732
55
train loss item: 0.23873023688793182
56
train loss item: 0.32312071323394775
57
train loss item: 0.2662785053253174
58
train loss item: 0.1839803159236908
59
train loss item: 0.09689724445343018
60
train loss item: 0.9645538330078125
61
train loss item: 2.266578435897827
62
train loss item: 0.24652199447155
63
train loss item: 0.4484213888645172
64
train loss item: 0.17786066234111786
65
train loss item: 0.7184419631958008
66
train loss item: 0.48024851083755493
67
train loss item: 0.22284796833992004
68
train loss item: 0.3676844537258148
69
train loss item: 0.41660869121551514
70
train loss item: 0.3048064112663269
71
train loss item: 0.12663479149341583
72
train loss item: 0.20519204437732697
73
train loss item: 0.35276034474372864
74
train loss item: 0.056919973343610764
75
train loss item: 0.09503403306007385
76
train loss item: 0.9949825406074524
77
train loss item: 1.3721328973770142
78
train loss item: 0.05941995605826378
79
train loss item: 0.3159898519515991
80
train loss item: 0.10805921256542206
81
train loss item: 0.2083161473274231
82
train loss item: 0.22112135589122772
83
train loss item: 0.7021482586860657
84
train loss item: 0.4833115041255951
85
train loss item: 0.6892872452735901
86
train loss item: 4.366738319396973
87
train loss item: 0.1691499650478363
88
train loss item: 0.435453861951828
epoch train loss: 0.5222298127463024
testing phase
test loss item: 0.2147471159696579
test loss item: 0.08639627695083618
test loss item: 0.7128705382347107
test loss item: 0.2614278495311737
test loss item: 0.2920358180999756
test loss item: 0.12980374693870544
test loss item: 2.056966543197632
test loss item: 0.5527920126914978
test loss item: 0.2626112401485443
test loss item: 0.4921233057975769
test loss item: 1.0470572710037231
test loss item: 0.19459272921085358
test loss item: 0.20723651349544525
test loss item: 0.3992040455341339
test loss item: 0.1954074501991272
test loss item: 0.0638885423541069
test loss item: 0.35608428716659546
test loss item: 0.5913576483726501
test loss item: 0.7651968598365784
test loss item: 0.3555019199848175
test loss item: 0.9473943710327148
test loss item: 0.42585813999176025
test loss item: 0.35200658440589905
test loss item: 0.20567724108695984
test loss item: 0.2716846168041229
test loss item: 0.2749846279621124
test loss item: 0.41844239830970764
test loss item: 0.22424571216106415
test loss item: 0.4153877794742584
test loss item: 0.43175196647644043
test loss item: 0.9400811791419983
test loss item: 0.0646032989025116
test loss item: 0.17408840358257294
test loss item: 0.6958996057510376
test loss item: 0.5564098358154297
test loss item: 0.49159273505210876
test loss item: 0.9499384760856628
test loss item: 1.735824704170227
test loss item: 0.6420255303382874
test loss item: 0.32863906025886536
test loss item: 0.363017737865448
test loss item: 0.22056032717227936
test loss item: 0.41795769333839417
test loss item: 0.2585895359516144
test loss item: 0.7820171117782593
test loss item: 0.546261191368103
test loss item: 0.3588547110557556
test loss item: 0.2991984188556671
test loss item: 0.5742630362510681
test loss item: 0.8314672112464905
test loss item: 0.38512641191482544
test loss item: 0.1450389325618744
test loss item: 0.2897384464740753
test loss item: 0.17845918238162994
test loss item: 0.36989229917526245
test loss item: 1.0810052156448364
test loss item: 0.6199844479560852
test loss item: 0.3363475799560547
test loss item: 0.28843754529953003
test loss item: 0.23906098306179047
test loss item: 0.5402076244354248
test loss item: 0.2582288682460785
test loss item: 0.2638740539550781
test loss item: 0.30615895986557007
test loss item: 1.0195530652999878
test loss item: 0.3513789772987366
test loss item: 0.37984371185302734
test loss item: 0.31173115968704224
test loss item: 0.6430706977844238
test loss item: 0.4457709491252899
test loss item: 0.06197585165500641
test loss item: 1.1587945222854614
test loss item: 0.3877587914466858
test loss item: 0.47104594111442566
test loss item: 0.18626265227794647
test loss item: 0.19853436946868896
test loss item: 0.20310524106025696
test loss item: 1.734510064125061
test loss item: 0.565481960773468
test loss item: 0.2310221642255783
test loss item: 0.08832559734582901
test loss item: 1.1104259490966797
test loss item: 1.031696081161499
test loss item: 1.1848286390304565
test loss item: 0.26242828369140625
test loss item: 0.27705544233322144
test loss item: 0.08197923004627228
test loss item: 0.07094967365264893
test loss item: 0.2033858746290207
Epoch [36/100], Training Loss: 0.5222, Testing Loss: 0.4764
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 37/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4684250056743622
1
train loss item: 1.3239905834197998
2
train loss item: 0.25373515486717224
3
train loss item: 0.6179819703102112
4
train loss item: 0.43556657433509827
5
train loss item: 0.37051692605018616
6
train loss item: 0.3066895008087158
7
train loss item: 0.8535974025726318
8
train loss item: 0.14939723908901215
9
train loss item: 0.3044009804725647
10
train loss item: 0.40558797121047974
11
train loss item: 0.3097904324531555
12
train loss item: 0.10581528395414352
13
train loss item: 0.5091315507888794
14
train loss item: 0.2584748864173889
15
train loss item: 0.6768943071365356
16
train loss item: 0.04962433502078056
17
train loss item: 0.35363978147506714
18
train loss item: 0.3861408233642578
19
train loss item: 0.3158210515975952
20
train loss item: 0.2612403631210327
21
train loss item: 0.12936672568321228
22
train loss item: 1.0451226234436035
23
train loss item: 0.9822224378585815
24
train loss item: 0.6785905957221985
25
train loss item: 0.17084570229053497
26
train loss item: 0.21948909759521484
27
train loss item: 0.2694540023803711
28
train loss item: 0.045496273785829544
29
train loss item: 0.7776012420654297
30
train loss item: 2.345094680786133
31
train loss item: 0.6490197777748108
32
train loss item: 0.09122143685817719
33
train loss item: 0.47200098633766174
34
train loss item: 0.10678794234991074
35
train loss item: 2.4581212997436523
36
train loss item: 0.5415804386138916
37
train loss item: 0.4934827983379364
38
train loss item: 0.5699388980865479
39
train loss item: 0.2480938881635666
40
train loss item: 0.15680567920207977
41
train loss item: 0.29042091965675354
42
train loss item: 0.33302658796310425
43
train loss item: 0.20624719560146332
44
train loss item: 0.687552273273468
45
train loss item: 0.1170143187046051
46
train loss item: 0.12128177285194397
47
train loss item: 0.4127374589443207
48
train loss item: 0.25973638892173767
49
train loss item: 0.17631086707115173
50
train loss item: 0.36279022693634033
51
train loss item: 0.962473452091217
52
train loss item: 0.06033795326948166
53
train loss item: 0.1577092409133911
54
train loss item: 2.3222482204437256
55
train loss item: 0.23808233439922333
56
train loss item: 0.319137841463089
57
train loss item: 0.26427239179611206
58
train loss item: 0.18298812210559845
59
train loss item: 0.09598059207201004
60
train loss item: 0.9568381309509277
61
train loss item: 2.252469301223755
62
train loss item: 0.2463388293981552
63
train loss item: 0.44478142261505127
64
train loss item: 0.17476314306259155
65
train loss item: 0.7175611853599548
66
train loss item: 0.4756612181663513
67
train loss item: 0.22244039177894592
68
train loss item: 0.36923110485076904
69
train loss item: 0.4159410893917084
70
train loss item: 0.3035539984703064
71
train loss item: 0.1262698918581009
72
train loss item: 0.2048627883195877
73
train loss item: 0.3518209755420685
74
train loss item: 0.05487941950559616
75
train loss item: 0.09260989725589752
76
train loss item: 0.9914841651916504
77
train loss item: 1.3602080345153809
78
train loss item: 0.06050850823521614
79
train loss item: 0.31104743480682373
80
train loss item: 0.10851190239191055
81
train loss item: 0.20794300734996796
82
train loss item: 0.22124195098876953
83
train loss item: 0.6961494088172913
84
train loss item: 0.4759843349456787
85
train loss item: 0.6853296160697937
86
train loss item: 4.347936630249023
87
train loss item: 0.16629177331924438
88
train loss item: 0.43260863423347473
epoch train loss: 0.5192406179613611
testing phase
test loss item: 0.21284744143486023
test loss item: 0.08691522479057312
test loss item: 0.7109091877937317
test loss item: 0.26117193698883057
test loss item: 0.2917864918708801
test loss item: 0.13209721446037292
test loss item: 2.048264741897583
test loss item: 0.5398992896080017
test loss item: 0.26125332713127136
test loss item: 0.4879131615161896
test loss item: 1.045328140258789
test loss item: 0.18987122178077698
test loss item: 0.2049601674079895
test loss item: 0.39747753739356995
test loss item: 0.1950371265411377
test loss item: 0.06645134836435318
test loss item: 0.3553137481212616
test loss item: 0.5844355225563049
test loss item: 0.757698118686676
test loss item: 0.3528825044631958
test loss item: 0.9431663751602173
test loss item: 0.42408376932144165
test loss item: 0.347912460565567
test loss item: 0.20651774108409882
test loss item: 0.2714081108570099
test loss item: 0.27493032813072205
test loss item: 0.4154827892780304
test loss item: 0.22371578216552734
test loss item: 0.4149433672428131
test loss item: 0.42793118953704834
test loss item: 0.9382807612419128
test loss item: 0.06590664386749268
test loss item: 0.17491574585437775
test loss item: 0.6942754983901978
test loss item: 0.5525220036506653
test loss item: 0.48580312728881836
test loss item: 0.9427017569541931
test loss item: 1.7326760292053223
test loss item: 0.6383700966835022
test loss item: 0.3295460641384125
test loss item: 0.3629973828792572
test loss item: 0.22041501104831696
test loss item: 0.41251593828201294
test loss item: 0.2584384083747864
test loss item: 0.779159426689148
test loss item: 0.5433213710784912
test loss item: 0.3570161759853363
test loss item: 0.29484832286834717
test loss item: 0.569692850112915
test loss item: 0.8256514072418213
test loss item: 0.382158488035202
test loss item: 0.14325293898582458
test loss item: 0.28908559679985046
test loss item: 0.17469555139541626
test loss item: 0.36809104681015015
test loss item: 1.0782630443572998
test loss item: 0.6138072609901428
test loss item: 0.3354228138923645
test loss item: 0.2868805527687073
test loss item: 0.23766979575157166
test loss item: 0.5324896574020386
test loss item: 0.25613492727279663
test loss item: 0.2622840404510498
test loss item: 0.3060467541217804
test loss item: 1.020646095275879
test loss item: 0.3501289486885071
test loss item: 0.37749776244163513
test loss item: 0.3119744062423706
test loss item: 0.6406533718109131
test loss item: 0.43718865513801575
test loss item: 0.06576953828334808
test loss item: 1.1508166790008545
test loss item: 0.38551065325737
test loss item: 0.47141456604003906
test loss item: 0.1852373480796814
test loss item: 0.19817373156547546
test loss item: 0.20367205142974854
test loss item: 1.736236810684204
test loss item: 0.5644840598106384
test loss item: 0.23048262298107147
test loss item: 0.09020163118839264
test loss item: 1.1056010723114014
test loss item: 1.0259286165237427
test loss item: 1.183725118637085
test loss item: 0.2612740099430084
test loss item: 0.27588558197021484
test loss item: 0.08572111278772354
test loss item: 0.07623422145843506
test loss item: 0.20476721227169037
Epoch [37/100], Training Loss: 0.5192, Testing Loss: 0.4744
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6850.00 MB
Epoch 38/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46964165568351746
1
train loss item: 1.3091051578521729
2
train loss item: 0.2534249722957611
3
train loss item: 0.6096603870391846
4
train loss item: 0.43487274646759033
5
train loss item: 0.3710400462150574
6
train loss item: 0.30636489391326904
7
train loss item: 0.8477939367294312
8
train loss item: 0.14888592064380646
9
train loss item: 0.3036239445209503
10
train loss item: 0.40482407808303833
11
train loss item: 0.3051079511642456
12
train loss item: 0.10441970825195312
13
train loss item: 0.5071349143981934
14
train loss item: 0.25692132115364075
15
train loss item: 0.6690755486488342
16
train loss item: 0.04897527024149895
17
train loss item: 0.35281994938850403
18
train loss item: 0.38648080825805664
19
train loss item: 0.3159807622432709
20
train loss item: 0.2602846920490265
21
train loss item: 0.12767094373703003
22
train loss item: 1.0343273878097534
23
train loss item: 0.9755727052688599
24
train loss item: 0.674744725227356
25
train loss item: 0.1677771508693695
26
train loss item: 0.21834947168827057
27
train loss item: 0.2677011489868164
28
train loss item: 0.044594306498765945
29
train loss item: 0.7649485468864441
30
train loss item: 2.325730562210083
31
train loss item: 0.6504552960395813
32
train loss item: 0.09020183980464935
33
train loss item: 0.4640016257762909
34
train loss item: 0.10463449358940125
35
train loss item: 2.4445111751556396
36
train loss item: 0.5401342511177063
37
train loss item: 0.48749834299087524
38
train loss item: 0.5791316628456116
39
train loss item: 0.2508031129837036
40
train loss item: 0.15606866776943207
41
train loss item: 0.29029107093811035
42
train loss item: 0.3290957808494568
43
train loss item: 0.20541994273662567
44
train loss item: 0.6842055320739746
45
train loss item: 0.11783341318368912
46
train loss item: 0.12250062078237534
47
train loss item: 0.4115506708621979
48
train loss item: 0.2585923671722412
49
train loss item: 0.17565041780471802
50
train loss item: 0.3613637685775757
51
train loss item: 0.9516581892967224
52
train loss item: 0.0593094639480114
53
train loss item: 0.15648092329502106
54
train loss item: 2.309464693069458
55
train loss item: 0.2368292212486267
56
train loss item: 0.3198651075363159
57
train loss item: 0.2616579234600067
58
train loss item: 0.18223504722118378
59
train loss item: 0.09470558166503906
60
train loss item: 0.9450834393501282
61
train loss item: 2.2333407402038574
62
train loss item: 0.24511811137199402
63
train loss item: 0.44170457124710083
64
train loss item: 0.172620952129364
65
train loss item: 0.7144718170166016
66
train loss item: 0.4722590744495392
67
train loss item: 0.22122111916542053
68
train loss item: 0.3676265776157379
69
train loss item: 0.41685304045677185
70
train loss item: 0.3022112548351288
71
train loss item: 0.1259772628545761
72
train loss item: 0.2042127102613449
73
train loss item: 0.351432204246521
74
train loss item: 0.053680650889873505
75
train loss item: 0.09098752588033676
76
train loss item: 0.9841054677963257
77
train loss item: 1.3462917804718018
78
train loss item: 0.059715386480093
79
train loss item: 0.3076864182949066
80
train loss item: 0.10938900709152222
81
train loss item: 0.20744267106056213
82
train loss item: 0.2203546166419983
83
train loss item: 0.6864747405052185
84
train loss item: 0.47181203961372375
85
train loss item: 0.6796913146972656
86
train loss item: 4.327578544616699
87
train loss item: 0.16494950652122498
88
train loss item: 0.428585022687912
epoch train loss: 0.5159200380524892
testing phase
test loss item: 0.20906858146190643
test loss item: 0.08636034280061722
test loss item: 0.7060216069221497
test loss item: 0.2606455981731415
test loss item: 0.29071104526519775
test loss item: 0.13384082913398743
test loss item: 2.0408987998962402
test loss item: 0.5253251791000366
test loss item: 0.2581460475921631
test loss item: 0.48255977034568787
test loss item: 1.0396184921264648
test loss item: 0.18521949648857117
test loss item: 0.2027716487646103
test loss item: 0.3973841369152069
test loss item: 0.19403795897960663
test loss item: 0.06676995009183884
test loss item: 0.35528767108917236
test loss item: 0.5761723518371582
test loss item: 0.7503476738929749
test loss item: 0.3527543544769287
test loss item: 0.9342373013496399
test loss item: 0.42273059487342834
test loss item: 0.34357950091362
test loss item: 0.2069571167230606
test loss item: 0.2704358398914337
test loss item: 0.2753957211971283
test loss item: 0.4134843945503235
test loss item: 0.2225978970527649
test loss item: 0.4144030809402466
test loss item: 0.42400285601615906
test loss item: 0.9343225955963135
test loss item: 0.06403307616710663
test loss item: 0.17490920424461365
test loss item: 0.6906628012657166
test loss item: 0.5465537309646606
test loss item: 0.47874873876571655
test loss item: 0.9349891543388367
test loss item: 1.7216452360153198
test loss item: 0.6332330107688904
test loss item: 0.33098164200782776
test loss item: 0.3633998930454254
test loss item: 0.2229050248861313
test loss item: 0.4074230194091797
test loss item: 0.2586485743522644
test loss item: 0.771185040473938
test loss item: 0.5420390367507935
test loss item: 0.35498541593551636
test loss item: 0.29376715421676636
test loss item: 0.563641369342804
test loss item: 0.8182204961776733
test loss item: 0.3762635290622711
test loss item: 0.1415531486272812
test loss item: 0.28776484727859497
test loss item: 0.17113333940505981
test loss item: 0.36392128467559814
test loss item: 1.0707741975784302
test loss item: 0.6062119603157043
test loss item: 0.33063754439353943
test loss item: 0.2851269841194153
test loss item: 0.23522262275218964
test loss item: 0.524200439453125
test loss item: 0.25430750846862793
test loss item: 0.2607307732105255
test loss item: 0.30633142590522766
test loss item: 1.0171010494232178
test loss item: 0.3485623300075531
test loss item: 0.3763355016708374
test loss item: 0.31284868717193604
test loss item: 0.6364971995353699
test loss item: 0.43023818731307983
test loss item: 0.06898185610771179
test loss item: 1.1439709663391113
test loss item: 0.3837806284427643
test loss item: 0.473797470331192
test loss item: 0.18459446728229523
test loss item: 0.19885021448135376
test loss item: 0.20408232510089874
test loss item: 1.7272297143936157
test loss item: 0.5642828941345215
test loss item: 0.22904185950756073
test loss item: 0.09020189195871353
test loss item: 1.0987669229507446
test loss item: 1.019544005393982
test loss item: 1.175374150276184
test loss item: 0.2616749107837677
test loss item: 0.27486544847488403
test loss item: 0.08632821589708328
test loss item: 0.07821046561002731
test loss item: 0.20943380892276764
Epoch [38/100], Training Loss: 0.5159, Testing Loss: 0.4714
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 39/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4700948894023895
1
train loss item: 1.2936890125274658
2
train loss item: 0.25370413064956665
3
train loss item: 0.6024110317230225
4
train loss item: 0.4349433183670044
5
train loss item: 0.37175253033638
6
train loss item: 0.30549871921539307
7
train loss item: 0.8426723480224609
8
train loss item: 0.14794208109378815
9
train loss item: 0.30384448170661926
10
train loss item: 0.4055205285549164
11
train loss item: 0.29930081963539124
12
train loss item: 0.10267692059278488
13
train loss item: 0.5058469772338867
14
train loss item: 0.2550974488258362
15
train loss item: 0.6612449884414673
16
train loss item: 0.047490544617176056
17
train loss item: 0.3514496386051178
18
train loss item: 0.38694843649864197
19
train loss item: 0.31637611985206604
20
train loss item: 0.25670963525772095
21
train loss item: 0.1264924854040146
22
train loss item: 1.0217889547348022
23
train loss item: 0.9700987339019775
24
train loss item: 0.6711823344230652
25
train loss item: 0.16584645211696625
26
train loss item: 0.21746036410331726
27
train loss item: 0.2669369578361511
28
train loss item: 0.04323798045516014
29
train loss item: 0.7529692053794861
30
train loss item: 2.3064446449279785
31
train loss item: 0.654204249382019
32
train loss item: 0.08924397081136703
33
train loss item: 0.4568347930908203
34
train loss item: 0.10267944633960724
35
train loss item: 2.431328296661377
36
train loss item: 0.5371590256690979
37
train loss item: 0.4821884334087372
38
train loss item: 0.5894729495048523
39
train loss item: 0.254160612821579
40
train loss item: 0.15614311397075653
41
train loss item: 0.2909766435623169
42
train loss item: 0.3245261311531067
43
train loss item: 0.20507410168647766
44
train loss item: 0.6812314391136169
45
train loss item: 0.11765817552804947
46
train loss item: 0.12331853061914444
47
train loss item: 0.4103619456291199
48
train loss item: 0.25822189450263977
49
train loss item: 0.17433485388755798
50
train loss item: 0.3601796627044678
51
train loss item: 0.9416354298591614
52
train loss item: 0.05772602558135986
53
train loss item: 0.15486861765384674
54
train loss item: 2.2967138290405273
55
train loss item: 0.23569828271865845
56
train loss item: 0.3211267292499542
57
train loss item: 0.25914233922958374
58
train loss item: 0.18150396645069122
59
train loss item: 0.09466661512851715
60
train loss item: 0.9348835945129395
61
train loss item: 2.214961528778076
62
train loss item: 0.24293622374534607
63
train loss item: 0.43816468119621277
64
train loss item: 0.17175300419330597
65
train loss item: 0.709136962890625
66
train loss item: 0.4685196578502655
67
train loss item: 0.21921633183956146
68
train loss item: 0.36436375975608826
69
train loss item: 0.41767922043800354
70
train loss item: 0.2999153435230255
71
train loss item: 0.12569336593151093
72
train loss item: 0.20429541170597076
73
train loss item: 0.3516596853733063
74
train loss item: 0.05347011238336563
75
train loss item: 0.09073896706104279
76
train loss item: 0.9777178168296814
77
train loss item: 1.3327494859695435
78
train loss item: 0.05739814043045044
79
train loss item: 0.30405646562576294
80
train loss item: 0.10940693318843842
81
train loss item: 0.207048699259758
82
train loss item: 0.21970809996128082
83
train loss item: 0.6755462884902954
84
train loss item: 0.4672408699989319
85
train loss item: 0.6752967238426208
86
train loss item: 4.306973934173584
87
train loss item: 0.1645989716053009
88
train loss item: 0.42469683289527893
epoch train loss: 0.5126952801443888
testing phase
test loss item: 0.20583869516849518
test loss item: 0.08526328206062317
test loss item: 0.7040218710899353
test loss item: 0.2599204182624817
test loss item: 0.2895691692829132
test loss item: 0.13398048281669617
test loss item: 2.040675163269043
test loss item: 0.5205041170120239
test loss item: 0.2557171583175659
test loss item: 0.47882041335105896
test loss item: 1.0351930856704712
test loss item: 0.18248909711837769
test loss item: 0.2017439752817154
test loss item: 0.3987741768360138
test loss item: 0.19303591549396515
test loss item: 0.0643138512969017
test loss item: 0.35653936862945557
test loss item: 0.5712814927101135
test loss item: 0.7485951781272888
test loss item: 0.35578128695487976
test loss item: 0.9274695515632629
test loss item: 0.4238216280937195
test loss item: 0.3418251872062683
test loss item: 0.2073514312505722
test loss item: 0.2692885398864746
test loss item: 0.276403546333313
test loss item: 0.4134809374809265
test loss item: 0.22149249911308289
test loss item: 0.4145171046257019
test loss item: 0.4218568503856659
test loss item: 0.9321480393409729
test loss item: 0.06001242995262146
test loss item: 0.17471161484718323
test loss item: 0.6879988312721252
test loss item: 0.5432141423225403
test loss item: 0.4754943251609802
test loss item: 0.9321283102035522
test loss item: 1.7136545181274414
test loss item: 0.6289551854133606
test loss item: 0.3327518701553345
test loss item: 0.3642144203186035
test loss item: 0.22623808681964874
test loss item: 0.40329962968826294
test loss item: 0.2589079737663269
test loss item: 0.7639895081520081
test loss item: 0.5446703433990479
test loss item: 0.3540230989456177
test loss item: 0.2959345579147339
test loss item: 0.5608134865760803
test loss item: 0.8141809105873108
test loss item: 0.3702410161495209
test loss item: 0.14086610078811646
test loss item: 0.28615128993988037
test loss item: 0.169041708111763
test loss item: 0.35989633202552795
test loss item: 1.0674023628234863
test loss item: 0.6033121347427368
test loss item: 0.3254157602787018
test loss item: 0.2846735417842865
test loss item: 0.23235519230365753
test loss item: 0.5188779830932617
test loss item: 0.2557990550994873
test loss item: 0.2612980604171753
test loss item: 0.30717071890830994
test loss item: 1.0177464485168457
test loss item: 0.34680086374282837
test loss item: 0.37804561853408813
test loss item: 0.31412047147750854
test loss item: 0.6345252394676208
test loss item: 0.42995232343673706
test loss item: 0.07004132121801376
test loss item: 1.1440234184265137
test loss item: 0.38406264781951904
test loss item: 0.4789230525493622
test loss item: 0.18419049680233002
test loss item: 0.20000313222408295
test loss item: 0.20464226603507996
test loss item: 1.7198894023895264
test loss item: 0.5660215616226196
test loss item: 0.22809918224811554
test loss item: 0.08796707540750504
test loss item: 1.0970722436904907
test loss item: 1.0171170234680176
test loss item: 1.1697564125061035
test loss item: 0.2638169527053833
test loss item: 0.27362871170043945
test loss item: 0.083448126912117
test loss item: 0.07591749727725983
test loss item: 0.2137334942817688
Epoch [39/100], Training Loss: 0.5127, Testing Loss: 0.4700
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 40/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4700167179107666
1
train loss item: 1.2798293828964233
2
train loss item: 0.2538650929927826
3
train loss item: 0.5959044694900513
4
train loss item: 0.4345550239086151
5
train loss item: 0.37251970171928406
6
train loss item: 0.3053044378757477
7
train loss item: 0.8373734354972839
8
train loss item: 0.14737439155578613
9
train loss item: 0.3045518696308136
10
train loss item: 0.405845582485199
11
train loss item: 0.2929307222366333
12
train loss item: 0.10086767375469208
13
train loss item: 0.5050116777420044
14
train loss item: 0.25437110662460327
15
train loss item: 0.6562674641609192
16
train loss item: 0.04589886963367462
17
train loss item: 0.3507324755191803
18
train loss item: 0.38860663771629333
19
train loss item: 0.31702920794487
20
train loss item: 0.25371241569519043
21
train loss item: 0.12436641752719879
22
train loss item: 1.0122162103652954
23
train loss item: 0.9634298086166382
24
train loss item: 0.6675650477409363
25
train loss item: 0.16371077299118042
26
train loss item: 0.21589195728302002
27
train loss item: 0.2669592499732971
28
train loss item: 0.04220573231577873
29
train loss item: 0.7442746162414551
30
train loss item: 2.287405252456665
31
train loss item: 0.6568980813026428
32
train loss item: 0.08957210928201675
33
train loss item: 0.4515770971775055
34
train loss item: 0.1026921272277832
35
train loss item: 2.418034791946411
36
train loss item: 0.5325314998626709
37
train loss item: 0.47471871972084045
38
train loss item: 0.5976244211196899
39
train loss item: 0.25709396600723267
40
train loss item: 0.15637318789958954
41
train loss item: 0.29158052802085876
42
train loss item: 0.32021185755729675
43
train loss item: 0.20502303540706635
44
train loss item: 0.6775383949279785
45
train loss item: 0.11778508871793747
46
train loss item: 0.12295147031545639
47
train loss item: 0.4093969166278839
48
train loss item: 0.2583518922328949
49
train loss item: 0.17216582596302032
50
train loss item: 0.3597145974636078
51
train loss item: 0.9337173700332642
52
train loss item: 0.056219130754470825
53
train loss item: 0.1538103073835373
54
train loss item: 2.2835428714752197
55
train loss item: 0.23546937108039856
56
train loss item: 0.32181432843208313
57
train loss item: 0.2569742500782013
58
train loss item: 0.18085332214832306
59
train loss item: 0.09480313956737518
60
train loss item: 0.9263434410095215
61
train loss item: 2.196211814880371
62
train loss item: 0.24094203114509583
63
train loss item: 0.43454650044441223
64
train loss item: 0.1719423234462738
65
train loss item: 0.705099880695343
66
train loss item: 0.4628463387489319
67
train loss item: 0.2171049565076828
68
train loss item: 0.36274588108062744
69
train loss item: 0.41824018955230713
70
train loss item: 0.2980848550796509
71
train loss item: 0.12564128637313843
72
train loss item: 0.20500506460666656
73
train loss item: 0.35206544399261475
74
train loss item: 0.05471450462937355
75
train loss item: 0.09221062809228897
76
train loss item: 0.9703794717788696
77
train loss item: 1.3202407360076904
78
train loss item: 0.05411933735013008
79
train loss item: 0.29995208978652954
80
train loss item: 0.10992622375488281
81
train loss item: 0.20640800893306732
82
train loss item: 0.21919706463813782
83
train loss item: 0.6659218072891235
84
train loss item: 0.4602939486503601
85
train loss item: 0.6708110570907593
86
train loss item: 4.286009311676025
87
train loss item: 0.16468746960163116
88
train loss item: 0.4230748116970062
epoch train loss: 0.509712355064877
testing phase
test loss item: 0.20296534895896912
test loss item: 0.08400304615497589
test loss item: 0.7033016681671143
test loss item: 0.25690802931785583
test loss item: 0.28753411769866943
test loss item: 0.13127575814723969
test loss item: 2.0474648475646973
test loss item: 0.5265036225318909
test loss item: 0.2525961101055145
test loss item: 0.47597014904022217
test loss item: 1.0329467058181763
test loss item: 0.18090207874774933
test loss item: 0.20194460451602936
test loss item: 0.3998733460903168
test loss item: 0.1921265870332718
test loss item: 0.061118438839912415
test loss item: 0.35812968015670776
test loss item: 0.5681566596031189
test loss item: 0.7512774467468262
test loss item: 0.3601855933666229
test loss item: 0.9220811724662781
test loss item: 0.4266602694988251
test loss item: 0.34121057391166687
test loss item: 0.20737482607364655
test loss item: 0.26747941970825195
test loss item: 0.27735263109207153
test loss item: 0.41418105363845825
test loss item: 0.2197936475276947
test loss item: 0.414612740278244
test loss item: 0.4211573004722595
test loss item: 0.9319425821304321
test loss item: 0.05615263432264328
test loss item: 0.17393450438976288
test loss item: 0.6838772296905518
test loss item: 0.540799617767334
test loss item: 0.4740307033061981
test loss item: 0.9336240887641907
test loss item: 1.7115105390548706
test loss item: 0.62331223487854
test loss item: 0.33397141098976135
test loss item: 0.364892840385437
test loss item: 0.22720761597156525
test loss item: 0.3995937407016754
test loss item: 0.2568412721157074
test loss item: 0.7579978108406067
test loss item: 0.550453245639801
test loss item: 0.3531217873096466
test loss item: 0.298700749874115
test loss item: 0.559918224811554
test loss item: 0.8120140433311462
test loss item: 0.3650417625904083
test loss item: 0.14111578464508057
test loss item: 0.2839122414588928
test loss item: 0.16501069068908691
test loss item: 0.35634100437164307
test loss item: 1.0660666227340698
test loss item: 0.604747474193573
test loss item: 0.3219175338745117
test loss item: 0.2852244973182678
test loss item: 0.22979916632175446
test loss item: 0.5156018137931824
test loss item: 0.2604045271873474
test loss item: 0.2627823054790497
test loss item: 0.3084757626056671
test loss item: 1.0250626802444458
test loss item: 0.3425524830818176
test loss item: 0.38160085678100586
test loss item: 0.3153335154056549
test loss item: 0.6345266103744507
test loss item: 0.43204379081726074
test loss item: 0.06949819624423981
test loss item: 1.151291012763977
test loss item: 0.3841465413570404
test loss item: 0.48460325598716736
test loss item: 0.18305081129074097
test loss item: 0.19997641444206238
test loss item: 0.2049768716096878
test loss item: 1.7220710515975952
test loss item: 0.5672341585159302
test loss item: 0.2263094037771225
test loss item: 0.08406151831150055
test loss item: 1.1006735563278198
test loss item: 1.0178579092025757
test loss item: 1.1706922054290771
test loss item: 0.26643460988998413
test loss item: 0.27156201004981995
test loss item: 0.07822326570749283
test loss item: 0.07105349749326706
test loss item: 0.21218305826187134
Epoch [40/100], Training Loss: 0.5097, Testing Loss: 0.4696
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 41/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4685818552970886
1
train loss item: 1.2684019804000854
2
train loss item: 0.2535218894481659
3
train loss item: 0.5894598960876465
4
train loss item: 0.4334017336368561
5
train loss item: 0.37252944707870483
6
train loss item: 0.3060610592365265
7
train loss item: 0.832069456577301
8
train loss item: 0.14790815114974976
9
train loss item: 0.3052666485309601
10
train loss item: 0.4038861393928528
11
train loss item: 0.28542986512184143
12
train loss item: 0.1000458151102066
13
train loss item: 0.5041652917861938
14
train loss item: 0.25540003180503845
15
train loss item: 0.6531948447227478
16
train loss item: 0.046129871159791946
17
train loss item: 0.3507423400878906
18
train loss item: 0.3897722661495209
19
train loss item: 0.3173462152481079
20
train loss item: 0.2529836595058441
21
train loss item: 0.12142349034547806
22
train loss item: 1.0052458047866821
23
train loss item: 0.9556427001953125
24
train loss item: 0.6646100878715515
25
train loss item: 0.1617927849292755
26
train loss item: 0.21404027938842773
27
train loss item: 0.26875555515289307
28
train loss item: 0.04286797717213631
29
train loss item: 0.7370572090148926
30
train loss item: 2.26763653755188
31
train loss item: 0.6532837152481079
32
train loss item: 0.0911637470126152
33
train loss item: 0.44843751192092896
34
train loss item: 0.10348515957593918
35
train loss item: 2.4051074981689453
36
train loss item: 0.5260107517242432
37
train loss item: 0.4620884656906128
38
train loss item: 0.5953261256217957
39
train loss item: 0.2568894922733307
40
train loss item: 0.15623995661735535
41
train loss item: 0.2919022738933563
42
train loss item: 0.3156359791755676
43
train loss item: 0.20450372993946075
44
train loss item: 0.6739248037338257
45
train loss item: 0.11776859313249588
46
train loss item: 0.121237613260746
47
train loss item: 0.4085645079612732
48
train loss item: 0.25915297865867615
49
train loss item: 0.16899622976779938
50
train loss item: 0.3596705496311188
51
train loss item: 0.9285956025123596
52
train loss item: 0.0547046922147274
53
train loss item: 0.15425869822502136
54
train loss item: 2.270012855529785
55
train loss item: 0.23598824441432953
56
train loss item: 0.3187084197998047
57
train loss item: 0.2554701864719391
58
train loss item: 0.18028613924980164
59
train loss item: 0.09443864971399307
60
train loss item: 0.9219655990600586
61
train loss item: 2.177603006362915
62
train loss item: 0.23951111733913422
63
train loss item: 0.43039169907569885
64
train loss item: 0.17180438339710236
65
train loss item: 0.7021515369415283
66
train loss item: 0.45409879088401794
67
train loss item: 0.21505945920944214
68
train loss item: 0.3644271194934845
69
train loss item: 0.41675201058387756
70
train loss item: 0.29643648862838745
71
train loss item: 0.12511484324932098
72
train loss item: 0.20711180567741394
73
train loss item: 0.3517634868621826
74
train loss item: 0.05628253519535065
75
train loss item: 0.09413894265890121
76
train loss item: 0.9651755690574646
77
train loss item: 1.3104630708694458
78
train loss item: 0.05184314399957657
79
train loss item: 0.2945060133934021
80
train loss item: 0.10968128591775894
81
train loss item: 0.205134779214859
82
train loss item: 0.2188979983329773
83
train loss item: 0.6593502759933472
84
train loss item: 0.4480409324169159
85
train loss item: 0.6668189167976379
86
train loss item: 4.26458215713501
87
train loss item: 0.16347776353359222
88
train loss item: 0.4206535220146179
epoch train loss: 0.5066344079592925
testing phase
test loss item: 0.2003091722726822
test loss item: 0.08287666738033295
test loss item: 0.7078964710235596
test loss item: 0.24959425628185272
test loss item: 0.28626611828804016
test loss item: 0.12689000368118286
test loss item: 2.0528838634490967
test loss item: 0.5351472496986389
test loss item: 0.2510303854942322
test loss item: 0.474826842546463
test loss item: 1.0352792739868164
test loss item: 0.17898660898208618
test loss item: 0.20204585790634155
test loss item: 0.39971303939819336
test loss item: 0.19195277988910675
test loss item: 0.059437938034534454
test loss item: 0.3586858808994293
test loss item: 0.5678653120994568
test loss item: 0.7544671297073364
test loss item: 0.36286741495132446
test loss item: 0.9219375252723694
test loss item: 0.42780596017837524
test loss item: 0.3413364887237549
test loss item: 0.2066008299589157
test loss item: 0.2660781741142273
test loss item: 0.27758657932281494
test loss item: 0.4146100878715515
test loss item: 0.21800537407398224
test loss item: 0.4143311679363251
test loss item: 0.42117735743522644
test loss item: 0.9335861802101135
test loss item: 0.05481678992509842
test loss item: 0.17330870032310486
test loss item: 0.6810069680213928
test loss item: 0.5418632626533508
test loss item: 0.47374996542930603
test loss item: 0.9359610080718994
test loss item: 1.7211822271347046
test loss item: 0.6158208847045898
test loss item: 0.33383697271347046
test loss item: 0.36473366618156433
test loss item: 0.22484557330608368
test loss item: 0.3981783390045166
test loss item: 0.2496890425682068
test loss item: 0.7556474804878235
test loss item: 0.5552099347114563
test loss item: 0.3519878089427948
test loss item: 0.2997351288795471
test loss item: 0.5619308948516846
test loss item: 0.8126808404922485
test loss item: 0.36184149980545044
test loss item: 0.14128725230693817
test loss item: 0.2818398177623749
test loss item: 0.15478092432022095
test loss item: 0.35502859950065613
test loss item: 1.0715292692184448
test loss item: 0.6085888147354126
test loss item: 0.32080498337745667
test loss item: 0.2855512499809265
test loss item: 0.22802527248859406
test loss item: 0.5148013234138489
test loss item: 0.26423710584640503
test loss item: 0.2630142271518707
test loss item: 0.3092501759529114
test loss item: 1.0402553081512451
test loss item: 0.33347687125205994
test loss item: 0.3843431770801544
test loss item: 0.31567999720573425
test loss item: 0.63886958360672
test loss item: 0.4331718683242798
test loss item: 0.06808402389287949
test loss item: 1.1586220264434814
test loss item: 0.38330262899398804
test loss item: 0.48714467883110046
test loss item: 0.18109259009361267
test loss item: 0.19813412427902222
test loss item: 0.20510144531726837
test loss item: 1.739518165588379
test loss item: 0.5681176781654358
test loss item: 0.22345969080924988
test loss item: 0.08040405064821243
test loss item: 1.1084409952163696
test loss item: 1.0194693803787231
test loss item: 1.1816169023513794
test loss item: 0.26817256212234497
test loss item: 0.2692805826663971
test loss item: 0.0734630674123764
test loss item: 0.0675647109746933
test loss item: 0.2078360915184021
Epoch [41/100], Training Loss: 0.5066, Testing Loss: 0.4699
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 42/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46771395206451416
1
train loss item: 1.2583909034729004
2
train loss item: 0.25268980860710144
3
train loss item: 0.5826579332351685
4
train loss item: 0.4318195581436157
5
train loss item: 0.3728638291358948
6
train loss item: 0.30441394448280334
7
train loss item: 0.8259637951850891
8
train loss item: 0.14888933300971985
9
train loss item: 0.30528831481933594
10
train loss item: 0.4000932574272156
11
train loss item: 0.279295414686203
12
train loss item: 0.09998194128274918
13
train loss item: 0.5036956071853638
14
train loss item: 0.25757721066474915
15
train loss item: 0.6501902937889099
16
train loss item: 0.046862438321113586
17
train loss item: 0.35083651542663574
18
train loss item: 0.3904995620250702
19
train loss item: 0.3169418275356293
20
train loss item: 0.2530732750892639
21
train loss item: 0.12006815522909164
22
train loss item: 0.9987584352493286
23
train loss item: 0.9485964179039001
24
train loss item: 0.6614689230918884
25
train loss item: 0.16026750206947327
26
train loss item: 0.21296997368335724
27
train loss item: 0.2712514400482178
28
train loss item: 0.04361259564757347
29
train loss item: 0.7295438051223755
30
train loss item: 2.246706485748291
31
train loss item: 0.6453221440315247
32
train loss item: 0.09123730659484863
33
train loss item: 0.44664645195007324
34
train loss item: 0.10500810295343399
35
train loss item: 2.391288995742798
36
train loss item: 0.5200411081314087
37
train loss item: 0.450287401676178
38
train loss item: 0.5852744579315186
39
train loss item: 0.25438040494918823
40
train loss item: 0.15564464032649994
41
train loss item: 0.291987806558609
42
train loss item: 0.3122340738773346
43
train loss item: 0.2035742998123169
44
train loss item: 0.6708610653877258
45
train loss item: 0.11701027303934097
46
train loss item: 0.11910822242498398
47
train loss item: 0.40721505880355835
48
train loss item: 0.25999516248703003
49
train loss item: 0.16649211943149567
50
train loss item: 0.3597375750541687
51
train loss item: 0.9236632585525513
52
train loss item: 0.05391259863972664
53
train loss item: 0.15591484308242798
54
train loss item: 2.2552342414855957
55
train loss item: 0.2365981936454773
56
train loss item: 0.31326234340667725
57
train loss item: 0.254655659198761
58
train loss item: 0.1796521544456482
59
train loss item: 0.09375806897878647
60
train loss item: 0.9194812178611755
61
train loss item: 2.158449172973633
62
train loss item: 0.23881873488426208
63
train loss item: 0.426435649394989
64
train loss item: 0.17112573981285095
65
train loss item: 0.701531171798706
66
train loss item: 0.44605380296707153
67
train loss item: 0.21427223086357117
68
train loss item: 0.3673746883869171
69
train loss item: 0.4140612483024597
70
train loss item: 0.29550161957740784
71
train loss item: 0.12362860888242722
72
train loss item: 0.2098391056060791
73
train loss item: 0.3507384955883026
74
train loss item: 0.05540821701288223
75
train loss item: 0.09498558938503265
76
train loss item: 0.9602823257446289
77
train loss item: 1.3007171154022217
78
train loss item: 0.05148730427026749
79
train loss item: 0.28965872526168823
80
train loss item: 0.10813496261835098
81
train loss item: 0.20420695841312408
82
train loss item: 0.21885180473327637
83
train loss item: 0.6530282497406006
84
train loss item: 0.4357723891735077
85
train loss item: 0.6626946926116943
86
train loss item: 4.242317199707031
87
train loss item: 0.16104815900325775
88
train loss item: 0.4171653985977173
epoch train loss: 0.5034387759613187
testing phase
test loss item: 0.1984301209449768
test loss item: 0.08191976696252823
test loss item: 0.7136807441711426
test loss item: 0.24189738929271698
test loss item: 0.2854061424732208
test loss item: 0.12238694727420807
test loss item: 2.0458407402038574
test loss item: 0.5362072587013245
test loss item: 0.24972033500671387
test loss item: 0.47332435846328735
test loss item: 1.0379265546798706
test loss item: 0.17488309741020203
test loss item: 0.20005005598068237
test loss item: 0.3982866108417511
test loss item: 0.19142572581768036
test loss item: 0.05944991111755371
test loss item: 0.3565974235534668
test loss item: 0.5671892166137695
test loss item: 0.7537935376167297
test loss item: 0.361264169216156
test loss item: 0.9229166507720947
test loss item: 0.42531466484069824
test loss item: 0.3405247926712036
test loss item: 0.20512862503528595
test loss item: 0.2650032639503479
test loss item: 0.27622389793395996
test loss item: 0.4132007360458374
test loss item: 0.21587418019771576
test loss item: 0.4124774932861328
test loss item: 0.42009639739990234
test loss item: 0.9323174953460693
test loss item: 0.05467879772186279
test loss item: 0.17276088893413544
test loss item: 0.6797747611999512
test loss item: 0.5437784790992737
test loss item: 0.47278451919555664
test loss item: 0.933876097202301
test loss item: 1.7331236600875854
test loss item: 0.6070814728736877
test loss item: 0.3315907120704651
test loss item: 0.3630903959274292
test loss item: 0.2205168753862381
test loss item: 0.3975783884525299
test loss item: 0.24051569402217865
test loss item: 0.7544800639152527
test loss item: 0.5544238686561584
test loss item: 0.3501390814781189
test loss item: 0.29778987169265747
test loss item: 0.5628941059112549
test loss item: 0.8122650980949402
test loss item: 0.359623521566391
test loss item: 0.14033131301403046
test loss item: 0.27984723448753357
test loss item: 0.14620646834373474
test loss item: 0.35498154163360596
test loss item: 1.0785071849822998
test loss item: 0.6104963421821594
test loss item: 0.32062390446662903
test loss item: 0.2841804325580597
test loss item: 0.2265109121799469
test loss item: 0.5141608715057373
test loss item: 0.26309314370155334
test loss item: 0.26073887944221497
test loss item: 0.3085022568702698
test loss item: 1.0534062385559082
test loss item: 0.32543447613716125
test loss item: 0.3829978108406067
test loss item: 0.3143827021121979
test loss item: 0.6444736123085022
test loss item: 0.43121519684791565
test loss item: 0.06525427848100662
test loss item: 1.1570547819137573
test loss item: 0.3807779550552368
test loss item: 0.48407748341560364
test loss item: 0.17792633175849915
test loss item: 0.1949668526649475
test loss item: 0.20424234867095947
test loss item: 1.758618950843811
test loss item: 0.5678464770317078
test loss item: 0.22019843757152557
test loss item: 0.07795129716396332
test loss item: 1.1124588251113892
test loss item: 1.0172721147537231
test loss item: 1.1927168369293213
test loss item: 0.2682204842567444
test loss item: 0.2665046155452728
test loss item: 0.07143804430961609
test loss item: 0.06816250830888748
test loss item: 0.20432662963867188
Epoch [42/100], Training Loss: 0.5034, Testing Loss: 0.4691
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 43/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4691305160522461
1
train loss item: 1.246895432472229
2
train loss item: 0.2512916326522827
3
train loss item: 0.5757781267166138
4
train loss item: 0.43023255467414856
5
train loss item: 0.37407347559928894
6
train loss item: 0.30293965339660645
7
train loss item: 0.8174657821655273
8
train loss item: 0.1492953598499298
9
train loss item: 0.3033727705478668
10
train loss item: 0.39625129103660583
11
train loss item: 0.27832359075546265
12
train loss item: 0.10031004250049591
13
train loss item: 0.5043044686317444
14
train loss item: 0.2598329186439514
15
train loss item: 0.645091712474823
16
train loss item: 0.04746482893824577
17
train loss item: 0.35015857219696045
18
train loss item: 0.3904980719089508
19
train loss item: 0.31495770812034607
20
train loss item: 0.2507011294364929
21
train loss item: 0.12519554793834686
22
train loss item: 0.9896277189254761
23
train loss item: 0.9405713677406311
24
train loss item: 0.6558198928833008
25
train loss item: 0.16020551323890686
26
train loss item: 0.21382836997509003
27
train loss item: 0.27401113510131836
28
train loss item: 0.04378435015678406
29
train loss item: 0.7185810804367065
30
train loss item: 2.2245352268218994
31
train loss item: 0.6407901644706726
32
train loss item: 0.09034708142280579
33
train loss item: 0.44341301918029785
34
train loss item: 0.10806582868099213
35
train loss item: 2.3751015663146973
36
train loss item: 0.5137121677398682
37
train loss item: 0.44553321599960327
38
train loss item: 0.5770227313041687
39
train loss item: 0.2512744963169098
40
train loss item: 0.15470780432224274
41
train loss item: 0.2918287217617035
42
train loss item: 0.3115270733833313
43
train loss item: 0.20205284655094147
44
train loss item: 0.6653721928596497
45
train loss item: 0.1150084137916565
46
train loss item: 0.11798311024904251
47
train loss item: 0.40413588285446167
48
train loss item: 0.2598514258861542
49
train loss item: 0.1668233424425125
50
train loss item: 0.35861101746559143
51
train loss item: 0.9174148440361023
52
train loss item: 0.0547344945371151
53
train loss item: 0.15721778571605682
54
train loss item: 2.239077568054199
55
train loss item: 0.23560898005962372
56
train loss item: 0.3067246377468109
57
train loss item: 0.2541903257369995
58
train loss item: 0.1787777692079544
59
train loss item: 0.09294869750738144
60
train loss item: 0.9130287766456604
61
train loss item: 2.137361764907837
62
train loss item: 0.23845097422599792
63
train loss item: 0.42413103580474854
64
train loss item: 0.16941767930984497
65
train loss item: 0.7068749666213989
66
train loss item: 0.44095513224601746
67
train loss item: 0.2149859368801117
68
train loss item: 0.36731448769569397
69
train loss item: 0.41250136494636536
70
train loss item: 0.2942037284374237
71
train loss item: 0.12220993638038635
72
train loss item: 0.21143580973148346
73
train loss item: 0.34867286682128906
74
train loss item: 0.051877956837415695
75
train loss item: 0.0937943384051323
76
train loss item: 0.9524059891700745
77
train loss item: 1.2878743410110474
78
train loss item: 0.05435744673013687
79
train loss item: 0.2884502112865448
80
train loss item: 0.10687660425901413
81
train loss item: 0.20387287437915802
82
train loss item: 0.21854494512081146
83
train loss item: 0.6418945789337158
84
train loss item: 0.4310108721256256
85
train loss item: 0.6560578942298889
86
train loss item: 4.218190670013428
87
train loss item: 0.15772518515586853
88
train loss item: 0.4152505695819855
epoch train loss: 0.5001586065784599
testing phase
test loss item: 0.19765156507492065
test loss item: 0.08095419406890869
test loss item: 0.7201941609382629
test loss item: 0.23926211893558502
test loss item: 0.2838517725467682
test loss item: 0.11872007697820663
test loss item: 2.022857904434204
test loss item: 0.5277148485183716
test loss item: 0.2476413995027542
test loss item: 0.46977895498275757
test loss item: 1.0389816761016846
test loss item: 0.17275704443454742
test loss item: 0.1954997479915619
test loss item: 0.3952849209308624
test loss item: 0.18976590037345886
test loss item: 0.06193684786558151
test loss item: 0.3521605134010315
test loss item: 0.5638343691825867
test loss item: 0.7479708790779114
test loss item: 0.35551878809928894
test loss item: 0.9192724227905273
test loss item: 0.419240802526474
test loss item: 0.3380213677883148
test loss item: 0.20291750133037567
test loss item: 0.2637912333011627
test loss item: 0.2729140818119049
test loss item: 0.40989598631858826
test loss item: 0.21278434991836548
test loss item: 0.4081026017665863
test loss item: 0.41713541746139526
test loss item: 0.9257698655128479
test loss item: 0.05663098767399788
test loss item: 0.17144764959812164
test loss item: 0.6807737946510315
test loss item: 0.5450807809829712
test loss item: 0.46846047043800354
test loss item: 0.9255411624908447
test loss item: 1.7442224025726318
test loss item: 0.6019042134284973
test loss item: 0.32745984196662903
test loss item: 0.3600962162017822
test loss item: 0.21600571274757385
test loss item: 0.3955669105052948
test loss item: 0.23628488183021545
test loss item: 0.7485525608062744
test loss item: 0.5483259558677673
test loss item: 0.34587326645851135
test loss item: 0.293155699968338
test loss item: 0.5608388185501099
test loss item: 0.8089407086372375
test loss item: 0.3544246256351471
test loss item: 0.13846783339977264
test loss item: 0.2770487368106842
test loss item: 0.14410141110420227
test loss item: 0.3536544144153595
test loss item: 1.0880059003829956
test loss item: 0.6093559265136719
test loss item: 0.3173208236694336
test loss item: 0.2803634703159332
test loss item: 0.22368347644805908
test loss item: 0.51153165102005
test loss item: 0.25735199451446533
test loss item: 0.25644317269325256
test loss item: 0.3062286674976349
test loss item: 1.0651780366897583
test loss item: 0.32284173369407654
test loss item: 0.37751495838165283
test loss item: 0.3115818500518799
test loss item: 0.6501971483230591
test loss item: 0.42580413818359375
test loss item: 0.062325332313776016
test loss item: 1.1444849967956543
test loss item: 0.37453627586364746
test loss item: 0.4762285351753235
test loss item: 0.17377816140651703
test loss item: 0.1913461536169052
test loss item: 0.20187677443027496
test loss item: 1.774082899093628
test loss item: 0.5653688907623291
test loss item: 0.21671533584594727
test loss item: 0.07683545351028442
test loss item: 1.1103144884109497
test loss item: 1.0096344947814941
test loss item: 1.2006677389144897
test loss item: 0.2658092975616455
test loss item: 0.2619960308074951
test loss item: 0.072971411049366
test loss item: 0.0733463242650032
test loss item: 0.2011096328496933
Epoch [43/100], Training Loss: 0.5002, Testing Loss: 0.4667
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 44/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.47272634506225586
1
train loss item: 1.2327717542648315
2
train loss item: 0.2505003809928894
3
train loss item: 0.5730944871902466
4
train loss item: 0.42750924825668335
5
train loss item: 0.37440016865730286
6
train loss item: 0.3024067282676697
7
train loss item: 0.8077921271324158
8
train loss item: 0.1486770212650299
9
train loss item: 0.3003508448600769
10
train loss item: 0.3944476842880249
11
train loss item: 0.27742093801498413
12
train loss item: 0.10075182467699051
13
train loss item: 0.5030669569969177
14
train loss item: 0.2614830434322357
15
train loss item: 0.640933096408844
16
train loss item: 0.047955095767974854
17
train loss item: 0.3495689332485199
18
train loss item: 0.39344266057014465
19
train loss item: 0.3130221366882324
20
train loss item: 0.24907462298870087
21
train loss item: 0.13019737601280212
22
train loss item: 0.9802741408348083
23
train loss item: 0.9328736066818237
24
train loss item: 0.6515891551971436
25
train loss item: 0.15863770246505737
26
train loss item: 0.21410124003887177
27
train loss item: 0.2699393928050995
28
train loss item: 0.044024091213941574
29
train loss item: 0.710545003414154
30
train loss item: 2.1981706619262695
31
train loss item: 0.6416637897491455
32
train loss item: 0.08814191073179245
33
train loss item: 0.437385618686676
34
train loss item: 0.10724098235368729
35
train loss item: 2.35603928565979
36
train loss item: 0.5158904194831848
37
train loss item: 0.44347894191741943
38
train loss item: 0.5705984234809875
39
train loss item: 0.25036710500717163
40
train loss item: 0.15337780117988586
41
train loss item: 0.2914668321609497
42
train loss item: 0.3106965124607086
43
train loss item: 0.20071379840373993
44
train loss item: 0.6593020558357239
45
train loss item: 0.11372848600149155
46
train loss item: 0.11741414666175842
47
train loss item: 0.400515615940094
48
train loss item: 0.2580333948135376
49
train loss item: 0.16891038417816162
50
train loss item: 0.3572656810283661
51
train loss item: 0.9076199531555176
52
train loss item: 0.055355727672576904
53
train loss item: 0.15489928424358368
54
train loss item: 2.2200212478637695
55
train loss item: 0.23566947877407074
56
train loss item: 0.30616533756256104
57
train loss item: 0.25352567434310913
58
train loss item: 0.17808403074741364
59
train loss item: 0.09167911857366562
60
train loss item: 0.9042400121688843
61
train loss item: 2.1142680644989014
62
train loss item: 0.2382943034172058
63
train loss item: 0.42047929763793945
64
train loss item: 0.1674659103155136
65
train loss item: 0.7086629271507263
66
train loss item: 0.4433802664279938
67
train loss item: 0.21549902856349945
68
train loss item: 0.3657822906970978
69
train loss item: 0.41079646348953247
70
train loss item: 0.2925335764884949
71
train loss item: 0.12229131907224655
72
train loss item: 0.2082216441631317
73
train loss item: 0.3467786908149719
74
train loss item: 0.050303854048252106
75
train loss item: 0.09231898933649063
76
train loss item: 0.9428414702415466
77
train loss item: 1.2712321281433105
78
train loss item: 0.0564771331846714
79
train loss item: 0.28537383675575256
80
train loss item: 0.10473556816577911
81
train loss item: 0.20270003378391266
82
train loss item: 0.21870499849319458
83
train loss item: 0.6298121809959412
84
train loss item: 0.43120068311691284
85
train loss item: 0.6495764255523682
86
train loss item: 4.190769672393799
87
train loss item: 0.1553170382976532
88
train loss item: 0.41238775849342346
epoch train loss: 0.4967353379123666
testing phase
test loss item: 0.19708333909511566
test loss item: 0.0812860056757927
test loss item: 0.7080780863761902
test loss item: 0.2386007308959961
test loss item: 0.2816148102283478
test loss item: 0.1176907941699028
test loss item: 2.0084240436553955
test loss item: 0.5228936076164246
test loss item: 0.24475234746932983
test loss item: 0.46616771817207336
test loss item: 1.0269029140472412
test loss item: 0.172255277633667
test loss item: 0.1923651099205017
test loss item: 0.39548176527023315
test loss item: 0.18840190768241882
test loss item: 0.06401564925909042
test loss item: 0.3495815694332123
test loss item: 0.5599138140678406
test loss item: 0.7443708777427673
test loss item: 0.35250040888786316
test loss item: 0.913658857345581
test loss item: 0.41598185896873474
test loss item: 0.3370767831802368
test loss item: 0.20203503966331482
test loss item: 0.2625514566898346
test loss item: 0.2712072730064392
test loss item: 0.40802204608917236
test loss item: 0.21117061376571655
test loss item: 0.40622398257255554
test loss item: 0.415357768535614
test loss item: 0.9150943160057068
test loss item: 0.05961593613028526
test loss item: 0.1706557273864746
test loss item: 0.6741898059844971
test loss item: 0.5383574962615967
test loss item: 0.46447044610977173
test loss item: 0.920345664024353
test loss item: 1.7211288213729858
test loss item: 0.5966964364051819
test loss item: 0.32543954253196716
test loss item: 0.3589192032814026
test loss item: 0.21370632946491241
test loss item: 0.3954979181289673
test loss item: 0.23483987152576447
test loss item: 0.7465180158615112
test loss item: 0.5447196364402771
test loss item: 0.34524500370025635
test loss item: 0.2910654544830322
test loss item: 0.5530267953872681
test loss item: 0.8007068634033203
test loss item: 0.3541421890258789
test loss item: 0.13756446540355682
test loss item: 0.27590975165367126
test loss item: 0.14395229518413544
test loss item: 0.35280805826187134
test loss item: 1.070564866065979
test loss item: 0.604973316192627
test loss item: 0.31841906905174255
test loss item: 0.27888527512550354
test loss item: 0.22326412796974182
test loss item: 0.5102659463882446
test loss item: 0.25377464294433594
test loss item: 0.25403907895088196
test loss item: 0.3049432933330536
test loss item: 1.0468353033065796
test loss item: 0.3220280408859253
test loss item: 0.37360069155693054
test loss item: 0.31014102697372437
test loss item: 0.6434294581413269
test loss item: 0.42351070046424866
test loss item: 0.06125630810856819
test loss item: 1.1375813484191895
test loss item: 0.37308844923973083
test loss item: 0.4721193313598633
test loss item: 0.1714283972978592
test loss item: 0.18969035148620605
test loss item: 0.20045703649520874
test loss item: 1.748388409614563
test loss item: 0.5612123012542725
test loss item: 0.21540947258472443
test loss item: 0.0773865133523941
test loss item: 1.0981907844543457
test loss item: 1.0037693977355957
test loss item: 1.1808502674102783
test loss item: 0.2656867206096649
test loss item: 0.25942882895469666
test loss item: 0.07511278241872787
test loss item: 0.07707928121089935
test loss item: 0.1991569846868515
Epoch [44/100], Training Loss: 0.4967, Testing Loss: 0.4629
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7032.00 MB
Epoch 45/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4718796908855438
1
train loss item: 1.2195123434066772
2
train loss item: 0.25013238191604614
3
train loss item: 0.5725029706954956
4
train loss item: 0.4271085262298584
5
train loss item: 0.37363171577453613
6
train loss item: 0.3016493022441864
7
train loss item: 0.7987880110740662
8
train loss item: 0.14818938076496124
9
train loss item: 0.29869508743286133
10
train loss item: 0.39382416009902954
11
train loss item: 0.2767864465713501
12
train loss item: 0.10110104829072952
13
train loss item: 0.501650333404541
14
train loss item: 0.26189371943473816
15
train loss item: 0.6378042697906494
16
train loss item: 0.04832640290260315
17
train loss item: 0.3487798273563385
18
train loss item: 0.39193224906921387
19
train loss item: 0.3118794560432434
20
train loss item: 0.24775414168834686
21
train loss item: 0.13446369767189026
22
train loss item: 0.968078076839447
23
train loss item: 0.9273216724395752
24
train loss item: 0.6476789116859436
25
train loss item: 0.1585022360086441
26
train loss item: 0.2143116295337677
27
train loss item: 0.26784998178482056
28
train loss item: 0.044524211436510086
29
train loss item: 0.7057270407676697
30
train loss item: 2.174098253250122
31
train loss item: 0.6415513157844543
32
train loss item: 0.08470084518194199
33
train loss item: 0.4344119131565094
34
train loss item: 0.10403143614530563
35
train loss item: 2.337467670440674
36
train loss item: 0.5175031423568726
37
train loss item: 0.44176217913627625
38
train loss item: 0.563278317451477
39
train loss item: 0.24832426011562347
40
train loss item: 0.152273491024971
41
train loss item: 0.29012513160705566
42
train loss item: 0.30963465571403503
43
train loss item: 0.19989457726478577
44
train loss item: 0.6548500061035156
45
train loss item: 0.11317142844200134
46
train loss item: 0.11797843873500824
47
train loss item: 0.3975088596343994
48
train loss item: 0.2572801411151886
49
train loss item: 0.17240726947784424
50
train loss item: 0.35608088970184326
51
train loss item: 0.8998625874519348
52
train loss item: 0.055104609578847885
53
train loss item: 0.15319299697875977
54
train loss item: 2.2007224559783936
55
train loss item: 0.23629938066005707
56
train loss item: 0.3028741180896759
57
train loss item: 0.25284045934677124
58
train loss item: 0.17725001275539398
59
train loss item: 0.09045781195163727
60
train loss item: 0.8986892104148865
61
train loss item: 2.094268321990967
62
train loss item: 0.2380245327949524
63
train loss item: 0.4179441034793854
64
train loss item: 0.1663718968629837
65
train loss item: 0.705994725227356
66
train loss item: 0.44607362151145935
67
train loss item: 0.21575625240802765
68
train loss item: 0.362784743309021
69
train loss item: 0.40706002712249756
70
train loss item: 0.29018792510032654
71
train loss item: 0.12278474867343903
72
train loss item: 0.20634494721889496
73
train loss item: 0.34552302956581116
74
train loss item: 0.05185488238930702
75
train loss item: 0.0913466140627861
76
train loss item: 0.9367955327033997
77
train loss item: 1.258081316947937
78
train loss item: 0.056786537170410156
79
train loss item: 0.282942533493042
80
train loss item: 0.10267665237188339
81
train loss item: 0.20155544579029083
82
train loss item: 0.21989040076732635
83
train loss item: 0.6193221211433411
84
train loss item: 0.4329354465007782
85
train loss item: 0.6465681791305542
86
train loss item: 4.162266254425049
87
train loss item: 0.15368540585041046
88
train loss item: 0.40554752945899963
epoch train loss: 0.4935874215253953
testing phase
test loss item: 0.19679975509643555
test loss item: 0.08232532441616058
test loss item: 0.7029528021812439
test loss item: 0.23848973214626312
test loss item: 0.28184816241264343
test loss item: 0.11833199858665466
test loss item: 2.00370192527771
test loss item: 0.5250093340873718
test loss item: 0.24459823966026306
test loss item: 0.4660102128982544
test loss item: 1.0193778276443481
test loss item: 0.17286069691181183
test loss item: 0.19142872095108032
test loss item: 0.3973659873008728
test loss item: 0.18853822350502014
test loss item: 0.06417582929134369
test loss item: 0.3493238091468811
test loss item: 0.5598498582839966
test loss item: 0.7445108294487
test loss item: 0.35255271196365356
test loss item: 0.9137069582939148
test loss item: 0.4158448874950409
test loss item: 0.3386942148208618
test loss item: 0.20146623253822327
test loss item: 0.2623694837093353
test loss item: 0.27111396193504333
test loss item: 0.4078945517539978
test loss item: 0.21105113625526428
test loss item: 0.4067818820476532
test loss item: 0.4154042899608612
test loss item: 0.910142719745636
test loss item: 0.0604831762611866
test loss item: 0.16970312595367432
test loss item: 0.6717827916145325
test loss item: 0.5356078147888184
test loss item: 0.4633064568042755
test loss item: 0.9199026226997375
test loss item: 1.706896424293518
test loss item: 0.5954522490501404
test loss item: 0.3250262439250946
test loss item: 0.3588646650314331
test loss item: 0.21404904127120972
test loss item: 0.3972634971141815
test loss item: 0.234880730509758
test loss item: 0.7480599880218506
test loss item: 0.5448257327079773
test loss item: 0.34669119119644165
test loss item: 0.2911860942840576
test loss item: 0.5509041547775269
test loss item: 0.7978113889694214
test loss item: 0.3558984100818634
test loss item: 0.13728214800357819
test loss item: 0.27623075246810913
test loss item: 0.1444881111383438
test loss item: 0.3537697494029999
test loss item: 1.0613884925842285
test loss item: 0.6040752530097961
test loss item: 0.32045671343803406
test loss item: 0.2791614830493927
test loss item: 0.22393165528774261
test loss item: 0.5117170810699463
test loss item: 0.25397759675979614
test loss item: 0.25391915440559387
test loss item: 0.30459097027778625
test loss item: 1.036898136138916
test loss item: 0.32177111506462097
test loss item: 0.37326371669769287
test loss item: 0.31009888648986816
test loss item: 0.6400892734527588
test loss item: 0.4242230951786041
test loss item: 0.061949774622917175
test loss item: 1.1371488571166992
test loss item: 0.37477821111679077
test loss item: 0.4718678593635559
test loss item: 0.17116138339042664
test loss item: 0.1895100325345993
test loss item: 0.1998853236436844
test loss item: 1.7305138111114502
test loss item: 0.5604622960090637
test loss item: 0.21570035815238953
test loss item: 0.0772576853632927
test loss item: 1.0918861627578735
test loss item: 1.0025017261505127
test loss item: 1.1684496402740479
test loss item: 0.26676633954048157
test loss item: 0.2589873671531677
test loss item: 0.07427257299423218
test loss item: 0.07559093832969666
test loss item: 0.2010461688041687
Epoch [45/100], Training Loss: 0.4936, Testing Loss: 0.4618
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 46/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4687288701534271
1
train loss item: 1.2055350542068481
2
train loss item: 0.24944308400154114
3
train loss item: 0.5673647522926331
4
train loss item: 0.42780858278274536
5
train loss item: 0.3740580677986145
6
train loss item: 0.30094707012176514
7
train loss item: 0.7880194783210754
8
train loss item: 0.1475200206041336
9
train loss item: 0.29716166853904724
10
train loss item: 0.3918231427669525
11
train loss item: 0.27915194630622864
12
train loss item: 0.10086245834827423
13
train loss item: 0.5009718537330627
14
train loss item: 0.26046574115753174
15
train loss item: 0.6346084475517273
16
train loss item: 0.047370314598083496
17
train loss item: 0.3477634787559509
18
train loss item: 0.3891860246658325
19
train loss item: 0.3112041652202606
20
train loss item: 0.246529683470726
21
train loss item: 0.13726671040058136
22
train loss item: 0.9570786952972412
23
train loss item: 0.9189397692680359
24
train loss item: 0.6421659588813782
25
train loss item: 0.15861199796199799
26
train loss item: 0.2149987369775772
27
train loss item: 0.2682851552963257
28
train loss item: 0.043875034898519516
29
train loss item: 0.6992231607437134
30
train loss item: 2.148082971572876
31
train loss item: 0.6404109001159668
32
train loss item: 0.08415209501981735
33
train loss item: 0.4311634600162506
34
train loss item: 0.10317611694335938
35
train loss item: 2.3177149295806885
36
train loss item: 0.5106973648071289
37
train loss item: 0.44114136695861816
38
train loss item: 0.558200478553772
39
train loss item: 0.2455863356590271
40
train loss item: 0.15137118101119995
41
train loss item: 0.28737354278564453
42
train loss item: 0.3105703890323639
43
train loss item: 0.19928574562072754
44
train loss item: 0.6455002427101135
45
train loss item: 0.1131339892745018
46
train loss item: 0.11947331577539444
47
train loss item: 0.39567282795906067
48
train loss item: 0.2565566301345825
49
train loss item: 0.17441774904727936
50
train loss item: 0.3553985357284546
51
train loss item: 0.8950431942939758
52
train loss item: 0.054593998938798904
53
train loss item: 0.15195296704769135
54
train loss item: 2.180893898010254
55
train loss item: 0.23540358245372772
56
train loss item: 0.2956124544143677
57
train loss item: 0.25177818536758423
58
train loss item: 0.17683270573616028
59
train loss item: 0.09030827134847641
60
train loss item: 0.888590931892395
61
train loss item: 2.0726912021636963
62
train loss item: 0.23750066757202148
63
train loss item: 0.4187433123588562
64
train loss item: 0.16563530266284943
65
train loss item: 0.7080637216567993
66
train loss item: 0.44624778628349304
67
train loss item: 0.21536579728126526
68
train loss item: 0.358732670545578
69
train loss item: 0.40553227066993713
70
train loss item: 0.28895655274391174
71
train loss item: 0.12301631271839142
72
train loss item: 0.20570442080497742
73
train loss item: 0.34449291229248047
74
train loss item: 0.052569326013326645
75
train loss item: 0.0910186842083931
76
train loss item: 0.9273656010627747
77
train loss item: 1.2459454536437988
78
train loss item: 0.05637865513563156
79
train loss item: 0.28513631224632263
80
train loss item: 0.10310754179954529
81
train loss item: 0.20091289281845093
82
train loss item: 0.21915818750858307
83
train loss item: 0.6072995066642761
84
train loss item: 0.4384004473686218
85
train loss item: 0.6410716772079468
86
train loss item: 4.133400917053223
87
train loss item: 0.15274886786937714
88
train loss item: 0.4023192524909973
epoch train loss: 0.49027613186266983
testing phase
test loss item: 0.19594009220600128
test loss item: 0.0823981910943985
test loss item: 0.7103433012962341
test loss item: 0.23750317096710205
test loss item: 0.2814655601978302
test loss item: 0.11969821900129318
test loss item: 1.9965039491653442
test loss item: 0.5347847938537598
test loss item: 0.24302762746810913
test loss item: 0.46305152773857117
test loss item: 1.0177838802337646
test loss item: 0.17256750166416168
test loss item: 0.19093115627765656
test loss item: 0.39583197236061096
test loss item: 0.1876010149717331
test loss item: 0.06121794506907463
test loss item: 0.3502163589000702
test loss item: 0.5552420020103455
test loss item: 0.7475582361221313
test loss item: 0.3528546988964081
test loss item: 0.9068976044654846
test loss item: 0.4169101119041443
test loss item: 0.33611851930618286
test loss item: 0.20029513537883759
test loss item: 0.2615576386451721
test loss item: 0.27078136801719666
test loss item: 0.4065217077732086
test loss item: 0.21052874624729156
test loss item: 0.4049827456474304
test loss item: 0.4133577346801758
test loss item: 0.9059094190597534
test loss item: 0.0577191486954689
test loss item: 0.16808806359767914
test loss item: 0.6731069087982178
test loss item: 0.5349531769752502
test loss item: 0.46079087257385254
test loss item: 0.9198322892189026
test loss item: 1.7123229503631592
test loss item: 0.5916075706481934
test loss item: 0.3243753910064697
test loss item: 0.35784798860549927
test loss item: 0.21468880772590637
test loss item: 0.39343294501304626
test loss item: 0.23429875075817108
test loss item: 0.7396087646484375
test loss item: 0.5473803877830505
test loss item: 0.3440685272216797
test loss item: 0.2902967035770416
test loss item: 0.5511226058006287
test loss item: 0.7959136366844177
test loss item: 0.3494861125946045
test loss item: 0.13674578070640564
test loss item: 0.27423882484436035
test loss item: 0.14425405859947205
test loss item: 0.3510740399360657
test loss item: 1.0720618963241577
test loss item: 0.6081225275993347
test loss item: 0.3164486587047577
test loss item: 0.2778276801109314
test loss item: 0.22147837281227112
test loss item: 0.5073699951171875
test loss item: 0.25692516565322876
test loss item: 0.2549595534801483
test loss item: 0.30393195152282715
test loss item: 1.0550612211227417
test loss item: 0.3206143379211426
test loss item: 0.37381842732429504
test loss item: 0.3100450038909912
test loss item: 0.6452895998954773
test loss item: 0.42621898651123047
test loss item: 0.06275381147861481
test loss item: 1.138588786125183
test loss item: 0.371065229177475
test loss item: 0.47176632285118103
test loss item: 0.17191560566425323
test loss item: 0.18936340510845184
test loss item: 0.19861428439617157
test loss item: 1.7398126125335693
test loss item: 0.5591884255409241
test loss item: 0.2170584797859192
test loss item: 0.07673425227403641
test loss item: 1.0916500091552734
test loss item: 1.0003342628479004
test loss item: 1.172747015953064
test loss item: 0.26459041237831116
test loss item: 0.2580336034297943
test loss item: 0.07138453423976898
test loss item: 0.0709555372595787
test loss item: 0.20224809646606445
Epoch [46/100], Training Loss: 0.4903, Testing Loss: 0.4615
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 47/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4672273099422455
1
train loss item: 1.1956051588058472
2
train loss item: 0.2492455244064331
3
train loss item: 0.56120765209198
4
train loss item: 0.43336498737335205
5
train loss item: 0.3738784193992615
6
train loss item: 0.3009825646877289
7
train loss item: 0.7797484993934631
8
train loss item: 0.14653021097183228
9
train loss item: 0.2955852448940277
10
train loss item: 0.38899528980255127
11
train loss item: 0.27699926495552063
12
train loss item: 0.09967690706253052
13
train loss item: 0.4969537854194641
14
train loss item: 0.2571108341217041
15
train loss item: 0.6361027956008911
16
train loss item: 0.0453120619058609
17
train loss item: 0.34754690527915955
18
train loss item: 0.3920731842517853
19
train loss item: 0.3118186891078949
20
train loss item: 0.24785882234573364
21
train loss item: 0.13062341511249542
22
train loss item: 0.9549892544746399
23
train loss item: 0.9077890515327454
24
train loss item: 0.6421476602554321
25
train loss item: 0.15794463455677032
26
train loss item: 0.21288205683231354
27
train loss item: 0.26292353868484497
28
train loss item: 0.04218762367963791
29
train loss item: 0.6964930295944214
30
train loss item: 2.122305393218994
31
train loss item: 0.6399907469749451
32
train loss item: 0.08300639688968658
33
train loss item: 0.425065279006958
34
train loss item: 0.10232684761285782
35
train loss item: 2.2979865074157715
36
train loss item: 0.5079294443130493
37
train loss item: 0.43600618839263916
38
train loss item: 0.5573211312294006
39
train loss item: 0.24678193032741547
40
train loss item: 0.15062154829502106
41
train loss item: 0.28322723507881165
42
train loss item: 0.3082979917526245
43
train loss item: 0.1990594118833542
44
train loss item: 0.6351656317710876
45
train loss item: 0.11374352127313614
46
train loss item: 0.11792807281017303
47
train loss item: 0.39553260803222656
48
train loss item: 0.2550923824310303
49
train loss item: 0.1701563447713852
50
train loss item: 0.3563287854194641
51
train loss item: 0.8852853178977966
52
train loss item: 0.052634358406066895
53
train loss item: 0.14907962083816528
54
train loss item: 2.1612823009490967
55
train loss item: 0.2355145663022995
56
train loss item: 0.29610639810562134
57
train loss item: 0.25087130069732666
58
train loss item: 0.176677405834198
59
train loss item: 0.09009170532226562
60
train loss item: 0.8813557624816895
61
train loss item: 2.0468854904174805
62
train loss item: 0.23712508380413055
63
train loss item: 0.4183101952075958
64
train loss item: 0.16483096778392792
65
train loss item: 0.7038793563842773
66
train loss item: 0.4431801736354828
67
train loss item: 0.2128978669643402
68
train loss item: 0.35878416895866394
69
train loss item: 0.4057019352912903
70
train loss item: 0.2889362573623657
71
train loss item: 0.12201301753520966
72
train loss item: 0.20301441848278046
73
train loss item: 0.3447284698486328
74
train loss item: 0.05227426812052727
75
train loss item: 0.09177519381046295
76
train loss item: 0.9176745414733887
77
train loss item: 1.2339493036270142
78
train loss item: 0.05263993516564369
79
train loss item: 0.2844146490097046
80
train loss item: 0.10389262437820435
81
train loss item: 0.20170331001281738
82
train loss item: 0.21643605828285217
83
train loss item: 0.5987602472305298
84
train loss item: 0.43422436714172363
85
train loss item: 0.636337161064148
86
train loss item: 4.102947235107422
87
train loss item: 0.15331843495368958
88
train loss item: 0.40163707733154297
epoch train loss: 0.48681852045688734
testing phase
test loss item: 0.19558635354042053
test loss item: 0.08364515006542206
test loss item: 0.7052639126777649
test loss item: 0.23714080452919006
test loss item: 0.2809465229511261
test loss item: 0.12216335535049438
test loss item: 1.997435212135315
test loss item: 0.544975221157074
test loss item: 0.24235279858112335
test loss item: 0.4620019197463989
test loss item: 1.0064254999160767
test loss item: 0.17273356020450592
test loss item: 0.1916360706090927
test loss item: 0.3955671787261963
test loss item: 0.18735376000404358
test loss item: 0.057992760092020035
test loss item: 0.35183021426200867
test loss item: 0.553308367729187
test loss item: 0.7513638138771057
test loss item: 0.3544745147228241
test loss item: 0.902320384979248
test loss item: 0.4196060299873352
test loss item: 0.33483174443244934
test loss item: 0.20069091022014618
test loss item: 0.26094403862953186
test loss item: 0.2715030610561371
test loss item: 0.4066515266895294
test loss item: 0.21114951372146606
test loss item: 0.405265748500824
test loss item: 0.4131529629230499
test loss item: 0.8997066617012024
test loss item: 0.05496782436966896
test loss item: 0.16826921701431274
test loss item: 0.6710172891616821
test loss item: 0.5315507054328918
test loss item: 0.461855947971344
test loss item: 0.9225171804428101
test loss item: 1.690194010734558
test loss item: 0.5887743830680847
test loss item: 0.3253874182701111
test loss item: 0.35768699645996094
test loss item: 0.21543428301811218
test loss item: 0.3928873836994171
test loss item: 0.23456570506095886
test loss item: 0.7361775636672974
test loss item: 0.550614595413208
test loss item: 0.34420591592788696
test loss item: 0.2905653119087219
test loss item: 0.5492674112319946
test loss item: 0.7915993928909302
test loss item: 0.3482850193977356
test loss item: 0.13698789477348328
test loss item: 0.27362728118896484
test loss item: 0.1443498581647873
test loss item: 0.34983474016189575
test loss item: 1.0641539096832275
test loss item: 0.6081359386444092
test loss item: 0.31617769598960876
test loss item: 0.27828019857406616
test loss item: 0.22148534655570984
test loss item: 0.5068950057029724
test loss item: 0.26045313477516174
test loss item: 0.25677546858787537
test loss item: 0.30374518036842346
test loss item: 1.0483472347259521
test loss item: 0.3199799656867981
test loss item: 0.37509405612945557
test loss item: 0.3106756806373596
test loss item: 0.6415154337882996
test loss item: 0.4305894374847412
test loss item: 0.06457741558551788
test loss item: 1.1441287994384766
test loss item: 0.3706924021244049
test loss item: 0.47395065426826477
test loss item: 0.17348410189151764
test loss item: 0.1901940405368805
test loss item: 0.19943416118621826
test loss item: 1.7123767137527466
test loss item: 0.5565137267112732
test loss item: 0.21888966858386993
test loss item: 0.07778698951005936
test loss item: 1.0834165811538696
test loss item: 1.0009247064590454
test loss item: 1.1548964977264404
test loss item: 0.26378798484802246
test loss item: 0.25849461555480957
test loss item: 0.06881629675626755
test loss item: 0.06493175029754639
test loss item: 0.20099681615829468
Epoch [47/100], Training Loss: 0.4868, Testing Loss: 0.4604
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 48/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4622245728969574
1
train loss item: 1.1871285438537598
2
train loss item: 0.24836885929107666
3
train loss item: 0.5559802651405334
4
train loss item: 0.43568548560142517
5
train loss item: 0.37283089756965637
6
train loss item: 0.30098235607147217
7
train loss item: 0.7711357474327087
8
train loss item: 0.1466183364391327
9
train loss item: 0.2959379255771637
10
train loss item: 0.38637733459472656
11
train loss item: 0.27514421939849854
12
train loss item: 0.09892831742763519
13
train loss item: 0.4948233664035797
14
train loss item: 0.2541767656803131
15
train loss item: 0.6370018720626831
16
train loss item: 0.04429866001009941
17
train loss item: 0.34735849499702454
18
train loss item: 0.39068853855133057
19
train loss item: 0.3130788207054138
20
train loss item: 0.24951809644699097
21
train loss item: 0.12395315617322922
22
train loss item: 0.9502680897712708
23
train loss item: 0.8990392088890076
24
train loss item: 0.6403329968452454
25
train loss item: 0.1568906158208847
26
train loss item: 0.21038749814033508
27
train loss item: 0.264105886220932
28
train loss item: 0.04151373729109764
29
train loss item: 0.6954116821289062
30
train loss item: 2.097189426422119
31
train loss item: 0.6359408497810364
32
train loss item: 0.08304199576377869
33
train loss item: 0.423702210187912
34
train loss item: 0.10026692599058151
35
train loss item: 2.277872323989868
36
train loss item: 0.5033901929855347
37
train loss item: 0.42906448245048523
38
train loss item: 0.5451372265815735
39
train loss item: 0.2448999583721161
40
train loss item: 0.14961281418800354
41
train loss item: 0.2805575728416443
42
train loss item: 0.3082001209259033
43
train loss item: 0.19921723008155823
44
train loss item: 0.6267650127410889
45
train loss item: 0.11368586868047714
46
train loss item: 0.11695387959480286
47
train loss item: 0.3955698013305664
48
train loss item: 0.2554015815258026
49
train loss item: 0.1657707393169403
50
train loss item: 0.357342928647995
51
train loss item: 0.8795899748802185
52
train loss item: 0.05180812254548073
53
train loss item: 0.14912278950214386
54
train loss item: 2.141547918319702
55
train loss item: 0.23610658943653107
56
train loss item: 0.2922010123729706
57
train loss item: 0.25017547607421875
58
train loss item: 0.1766449362039566
59
train loss item: 0.09240859001874924
60
train loss item: 0.878178060054779
61
train loss item: 2.023674726486206
62
train loss item: 0.2366795539855957
63
train loss item: 0.4182511270046234
64
train loss item: 0.1652013659477234
65
train loss item: 0.6970722079277039
66
train loss item: 0.44023796916007996
67
train loss item: 0.2105235606431961
68
train loss item: 0.3596034646034241
69
train loss item: 0.4037575423717499
70
train loss item: 0.28908923268318176
71
train loss item: 0.11959458142518997
72
train loss item: 0.20390480756759644
73
train loss item: 0.34496283531188965
74
train loss item: 0.052433110773563385
75
train loss item: 0.0931171104311943
76
train loss item: 0.9116978049278259
77
train loss item: 1.2256947755813599
78
train loss item: 0.04961960017681122
79
train loss item: 0.2843311131000519
80
train loss item: 0.1034519374370575
81
train loss item: 0.20205436646938324
82
train loss item: 0.21499037742614746
83
train loss item: 0.5925068259239197
84
train loss item: 0.43192580342292786
85
train loss item: 0.634312093257904
86
train loss item: 4.07211971282959
87
train loss item: 0.15366196632385254
88
train loss item: 0.3978637754917145
epoch train loss: 0.48359427312284375
testing phase
test loss item: 0.19573120772838593
test loss item: 0.08378124982118607
test loss item: 0.7133553624153137
test loss item: 0.23734579980373383
test loss item: 0.28119462728500366
test loss item: 0.12224731594324112
test loss item: 1.993927001953125
test loss item: 0.5441047549247742
test loss item: 0.24486976861953735
test loss item: 0.4639187157154083
test loss item: 1.0069231986999512
test loss item: 0.17294533550739288
test loss item: 0.1914655864238739
test loss item: 0.39449751377105713
test loss item: 0.18723779916763306
test loss item: 0.058747339993715286
test loss item: 0.3519185185432434
test loss item: 0.5560876727104187
test loss item: 0.7499551773071289
test loss item: 0.3540157973766327
test loss item: 0.905386209487915
test loss item: 0.4201525151729584
test loss item: 0.33456316590309143
test loss item: 0.20142200589179993
test loss item: 0.2615266740322113
test loss item: 0.27113795280456543
test loss item: 0.40700799226760864
test loss item: 0.21083693206310272
test loss item: 0.4053054749965668
test loss item: 0.4138084352016449
test loss item: 0.8997203707695007
test loss item: 0.05433649569749832
test loss item: 0.16919547319412231
test loss item: 0.6765860915184021
test loss item: 0.5354191660881042
test loss item: 0.4634862244129181
test loss item: 0.9219100475311279
test loss item: 1.6938294172286987
test loss item: 0.5900932550430298
test loss item: 0.325742244720459
test loss item: 0.35749855637550354
test loss item: 0.21534806489944458
test loss item: 0.39525511860847473
test loss item: 0.23479683697223663
test loss item: 0.7364215850830078
test loss item: 0.5503198504447937
test loss item: 0.34432220458984375
test loss item: 0.2896273136138916
test loss item: 0.5524348020553589
test loss item: 0.7925235033035278
test loss item: 0.34855878353118896
test loss item: 0.13695867359638214
test loss item: 0.2738190293312073
test loss item: 0.14521029591560364
test loss item: 0.3515283763408661
test loss item: 1.0753440856933594
test loss item: 0.6073596477508545
test loss item: 0.31562167406082153
test loss item: 0.27794528007507324
test loss item: 0.22179588675498962
test loss item: 0.5104418396949768
test loss item: 0.26062703132629395
test loss item: 0.2572716474533081
test loss item: 0.30324211716651917
test loss item: 1.0557382106781006
test loss item: 0.31999436020851135
test loss item: 0.37460246682167053
test loss item: 0.3103266954421997
test loss item: 0.6453907489776611
test loss item: 0.43130263686180115
test loss item: 0.06444240361452103
test loss item: 1.1425952911376953
test loss item: 0.3704281449317932
test loss item: 0.47438347339630127
test loss item: 0.17340219020843506
test loss item: 0.190439373254776
test loss item: 0.2001425176858902
test loss item: 1.712638020515442
test loss item: 0.5562788248062134
test loss item: 0.21949777007102966
test loss item: 0.07768099009990692
test loss item: 1.0819454193115234
test loss item: 1.0023152828216553
test loss item: 1.1566411256790161
test loss item: 0.26225534081459045
test loss item: 0.2582552433013916
test loss item: 0.06879835575819016
test loss item: 0.06393922120332718
test loss item: 0.19921010732650757
Epoch [48/100], Training Loss: 0.4836, Testing Loss: 0.4610
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 49/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4588276147842407
1
train loss item: 1.1748186349868774
2
train loss item: 0.24712704122066498
3
train loss item: 0.5529473423957825
4
train loss item: 0.43658411502838135
5
train loss item: 0.3719191551208496
6
train loss item: 0.3002637028694153
7
train loss item: 0.7604627013206482
8
train loss item: 0.1461268663406372
9
train loss item: 0.29571470618247986
10
train loss item: 0.38546451926231384
11
train loss item: 0.2755163013935089
12
train loss item: 0.0985996276140213
13
train loss item: 0.49387702345848083
14
train loss item: 0.25211483240127563
15
train loss item: 0.6339821815490723
16
train loss item: 0.044012416154146194
17
train loss item: 0.34666264057159424
18
train loss item: 0.38990697264671326
19
train loss item: 0.3132942020893097
20
train loss item: 0.24964474141597748
21
train loss item: 0.12060649693012238
22
train loss item: 0.9414970874786377
23
train loss item: 0.8916018605232239
24
train loss item: 0.6358116865158081
25
train loss item: 0.1560547947883606
26
train loss item: 0.20883062481880188
27
train loss item: 0.2644055485725403
28
train loss item: 0.04098721966147423
29
train loss item: 0.6904619336128235
30
train loss item: 2.0701746940612793
31
train loss item: 0.6360701322555542
32
train loss item: 0.08241701126098633
33
train loss item: 0.42185235023498535
34
train loss item: 0.09869679808616638
35
train loss item: 2.2556450366973877
36
train loss item: 0.5036366581916809
37
train loss item: 0.4284709393978119
38
train loss item: 0.5347872376441956
39
train loss item: 0.24354679882526398
40
train loss item: 0.14851224422454834
41
train loss item: 0.2796953618526459
42
train loss item: 0.30701982975006104
43
train loss item: 0.19870024919509888
44
train loss item: 0.6189091205596924
45
train loss item: 0.11227542906999588
46
train loss item: 0.11624899506568909
47
train loss item: 0.39369499683380127
48
train loss item: 0.2551048994064331
49
train loss item: 0.16381235420703888
50
train loss item: 0.3570229709148407
51
train loss item: 0.87014240026474
52
train loss item: 0.05204182118177414
53
train loss item: 0.14879658818244934
54
train loss item: 2.1197283267974854
55
train loss item: 0.23598456382751465
56
train loss item: 0.29160118103027344
57
train loss item: 0.24958465993404388
58
train loss item: 0.176234170794487
59
train loss item: 0.09586335718631744
60
train loss item: 0.8694173097610474
61
train loss item: 1.9991346597671509
62
train loss item: 0.2360377162694931
63
train loss item: 0.4168757200241089
64
train loss item: 0.16477996110916138
65
train loss item: 0.6921850442886353
66
train loss item: 0.4434233009815216
67
train loss item: 0.20902296900749207
68
train loss item: 0.35941290855407715
69
train loss item: 0.4014348089694977
70
train loss item: 0.28817737102508545
71
train loss item: 0.11811135709285736
72
train loss item: 0.20328621566295624
73
train loss item: 0.34457242488861084
74
train loss item: 0.051041293889284134
75
train loss item: 0.09249144047498703
76
train loss item: 0.9038493633270264
77
train loss item: 1.2119494676589966
78
train loss item: 0.04890196770429611
79
train loss item: 0.28344616293907166
80
train loss item: 0.10182671993970871
81
train loss item: 0.202037051320076
82
train loss item: 0.2141246646642685
83
train loss item: 0.5840066075325012
84
train loss item: 0.43494999408721924
85
train loss item: 0.6312738060951233
86
train loss item: 4.040257930755615
87
train loss item: 0.15376964211463928
88
train loss item: 0.39468440413475037
epoch train loss: 0.4802121129514796
testing phase
test loss item: 0.19643981754779816
test loss item: 0.08344275504350662
test loss item: 0.7091019153594971
test loss item: 0.2381289303302765
test loss item: 0.2783309519290924
test loss item: 0.12090550363063812
test loss item: 1.9824100732803345
test loss item: 0.5376021265983582
test loss item: 0.24469666182994843
test loss item: 0.46250954270362854
test loss item: 0.99749356508255
test loss item: 0.17328955233097076
test loss item: 0.1900477409362793
test loss item: 0.3927290439605713
test loss item: 0.18499641120433807
test loss item: 0.0622134655714035
test loss item: 0.35123226046562195
test loss item: 0.5550811290740967
test loss item: 0.7455233931541443
test loss item: 0.3521445691585541
test loss item: 0.9017556309700012
test loss item: 0.4191364347934723
test loss item: 0.3326699435710907
test loss item: 0.20218470692634583
test loss item: 0.261384516954422
test loss item: 0.2700839340686798
test loss item: 0.4062519967556
test loss item: 0.20863303542137146
test loss item: 0.40324240922927856
test loss item: 0.41325807571411133
test loss item: 0.892153263092041
test loss item: 0.056116607040166855
test loss item: 0.17058901488780975
test loss item: 0.6758986115455627
test loss item: 0.5331442952156067
test loss item: 0.4620983898639679
test loss item: 0.9172253012657166
test loss item: 1.6748067140579224
test loss item: 0.5875871181488037
test loss item: 0.32524433732032776
test loss item: 0.3570108413696289
test loss item: 0.21488146483898163
test loss item: 0.3959386348724365
test loss item: 0.23526671528816223
test loss item: 0.7333142757415771
test loss item: 0.5478450059890747
test loss item: 0.34341999888420105
test loss item: 0.28813332319259644
test loss item: 0.5491170883178711
test loss item: 0.7871363759040833
test loss item: 0.34706857800483704
test loss item: 0.13690637052059174
test loss item: 0.2729908227920532
test loss item: 0.14660339057445526
test loss item: 0.3503502905368805
test loss item: 1.069325566291809
test loss item: 0.6019219160079956
test loss item: 0.3137062191963196
test loss item: 0.2770080864429474
test loss item: 0.2208290547132492
test loss item: 0.5113689303398132
test loss item: 0.2593781650066376
test loss item: 0.25708678364753723
test loss item: 0.30244123935699463
test loss item: 1.0445226430892944
test loss item: 0.32053446769714355
test loss item: 0.37199363112449646
test loss item: 0.3090452253818512
test loss item: 0.6416252255439758
test loss item: 0.42960330843925476
test loss item: 0.06260041892528534
test loss item: 1.1355540752410889
test loss item: 0.3687214255332947
test loss item: 0.47339335083961487
test loss item: 0.17236793041229248
test loss item: 0.19050216674804688
test loss item: 0.20027366280555725
test loss item: 1.6868282556533813
test loss item: 0.5531566739082336
test loss item: 0.21903708577156067
test loss item: 0.07800444215536118
test loss item: 1.0702588558197021
test loss item: 0.9990216493606567
test loss item: 1.1401008367538452
test loss item: 0.2598932683467865
test loss item: 0.2572850286960602
test loss item: 0.07197552174329758
test loss item: 0.06887893378734589
test loss item: 0.19585570693016052
Epoch [49/100], Training Loss: 0.4802, Testing Loss: 0.4586
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 50/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45822107791900635
1
train loss item: 1.157315731048584
2
train loss item: 0.24627915024757385
3
train loss item: 0.5534001588821411
4
train loss item: 0.43761560320854187
5
train loss item: 0.3704790771007538
6
train loss item: 0.2994113564491272
7
train loss item: 0.749790608882904
8
train loss item: 0.1446761041879654
9
train loss item: 0.2943773567676544
10
train loss item: 0.3854338228702545
11
train loss item: 0.27643412351608276
12
train loss item: 0.09895520657300949
13
train loss item: 0.49206042289733887
14
train loss item: 0.2505815029144287
15
train loss item: 0.6298236846923828
16
train loss item: 0.04477976635098457
17
train loss item: 0.34587788581848145
18
train loss item: 0.39114806056022644
19
train loss item: 0.3128107786178589
20
train loss item: 0.2494928389787674
21
train loss item: 0.11824355274438858
22
train loss item: 0.932783305644989
23
train loss item: 0.8830408453941345
24
train loss item: 0.6322814226150513
25
train loss item: 0.15738454461097717
26
train loss item: 0.20747436583042145
27
train loss item: 0.25949108600616455
28
train loss item: 0.04097926244139671
29
train loss item: 0.6833733916282654
30
train loss item: 2.042390823364258
31
train loss item: 0.640704870223999
32
train loss item: 0.08074234426021576
33
train loss item: 0.4189673066139221
34
train loss item: 0.09715317189693451
35
train loss item: 2.23299241065979
36
train loss item: 0.5105676054954529
37
train loss item: 0.43162834644317627
38
train loss item: 0.5310907363891602
39
train loss item: 0.24424302577972412
40
train loss item: 0.14768308401107788
41
train loss item: 0.27981919050216675
42
train loss item: 0.30559778213500977
43
train loss item: 0.1978556364774704
44
train loss item: 0.6126071810722351
45
train loss item: 0.10922174155712128
46
train loss item: 0.11511782556772232
47
train loss item: 0.39040040969848633
48
train loss item: 0.2535397410392761
49
train loss item: 0.16343800723552704
50
train loss item: 0.3558403253555298
51
train loss item: 0.8573405742645264
52
train loss item: 0.05236642435193062
53
train loss item: 0.14551544189453125
54
train loss item: 2.0969736576080322
55
train loss item: 0.23533689975738525
56
train loss item: 0.29691359400749207
57
train loss item: 0.24893321096897125
58
train loss item: 0.1757732331752777
59
train loss item: 0.09445879608392715
60
train loss item: 0.8576052188873291
61
train loss item: 1.9734265804290771
62
train loss item: 0.2355227768421173
63
train loss item: 0.41370105743408203
64
train loss item: 0.1635967493057251
65
train loss item: 0.6883822679519653
66
train loss item: 0.45122966170310974
67
train loss item: 0.2076379954814911
68
train loss item: 0.35899588465690613
69
train loss item: 0.3991992175579071
70
train loss item: 0.28674817085266113
71
train loss item: 0.11831069737672806
72
train loss item: 0.19986623525619507
73
train loss item: 0.3439919352531433
74
train loss item: 0.047327395528554916
75
train loss item: 0.09037323296070099
76
train loss item: 0.8948491215705872
77
train loss item: 1.1927473545074463
78
train loss item: 0.05042709410190582
79
train loss item: 0.28066208958625793
80
train loss item: 0.09898878633975983
81
train loss item: 0.20152506232261658
82
train loss item: 0.21345210075378418
83
train loss item: 0.5752015709877014
84
train loss item: 0.4378719925880432
85
train loss item: 0.6275674700737
86
train loss item: 4.0080885887146
87
train loss item: 0.15327180922031403
88
train loss item: 0.3932173550128937
epoch train loss: 0.4767754490623313
testing phase
test loss item: 0.19817475974559784
test loss item: 0.08439958840608597
test loss item: 0.7162110209465027
test loss item: 0.23968954384326935
test loss item: 0.28177300095558167
test loss item: 0.12260885536670685
test loss item: 1.9754588603973389
test loss item: 0.5359905958175659
test loss item: 0.25106531381607056
test loss item: 0.4702002704143524
test loss item: 0.9929602742195129
test loss item: 0.17468573153018951
test loss item: 0.19117222726345062
test loss item: 0.39380064606666565
test loss item: 0.1869855523109436
test loss item: 0.06736637651920319
test loss item: 0.3523674011230469
test loss item: 0.5692597031593323
test loss item: 0.744677722454071
test loss item: 0.3532862961292267
test loss item: 0.922767698764801
test loss item: 0.4198714792728424
test loss item: 0.34052136540412903
test loss item: 0.2040863186120987
test loss item: 0.2646273970603943
test loss item: 0.2708680331707001
test loss item: 0.4092969000339508
test loss item: 0.2107795923948288
test loss item: 0.40575289726257324
test loss item: 0.4177018105983734
test loss item: 0.8894621729850769
test loss item: 0.06070800870656967
test loss item: 0.173090398311615
test loss item: 0.6867395043373108
test loss item: 0.5430349111557007
test loss item: 0.4667726159095764
test loss item: 0.9181634783744812
test loss item: 1.663649559020996
test loss item: 0.5955311059951782
test loss item: 0.32610753178596497
test loss item: 0.35770681500434875
test loss item: 0.21600353717803955
test loss item: 0.4062972664833069
test loss item: 0.23694376647472382
test loss item: 0.7471621632575989
test loss item: 0.5484790802001953
test loss item: 0.3480468690395355
test loss item: 0.2889062464237213
test loss item: 0.557843804359436
test loss item: 0.7910370230674744
test loss item: 0.35429033637046814
test loss item: 0.1377655416727066
test loss item: 0.27562808990478516
test loss item: 0.1488664448261261
test loss item: 0.35695379972457886
test loss item: 1.073257565498352
test loss item: 0.6009395718574524
test loss item: 0.3181440234184265
test loss item: 0.2796781361103058
test loss item: 0.22277353703975677
test loss item: 0.524603545665741
test loss item: 0.2611807882785797
test loss item: 0.2587733566761017
test loss item: 0.30261582136154175
test loss item: 1.0366787910461426
test loss item: 0.32165172696113586
test loss item: 0.3745185136795044
test loss item: 0.30898135900497437
test loss item: 0.6433897018432617
test loss item: 0.43233150243759155
test loss item: 0.06355488300323486
test loss item: 1.1316440105438232
test loss item: 0.3752817213535309
test loss item: 0.47489967942237854
test loss item: 0.17363454401493073
test loss item: 0.19184066355228424
test loss item: 0.20172154903411865
test loss item: 1.6632000207901
test loss item: 0.5551758408546448
test loss item: 0.22079713642597198
test loss item: 0.08000001311302185
test loss item: 1.0646127462387085
test loss item: 1.0027824640274048
test loss item: 1.1290721893310547
test loss item: 0.26098424196243286
test loss item: 0.26016929745674133
test loss item: 0.0751400962471962
test loss item: 0.07278726994991302
test loss item: 0.19678431749343872
Epoch [50/100], Training Loss: 0.4768, Testing Loss: 0.4609
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 51/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.45240432024002075
1
train loss item: 1.1461039781570435
2
train loss item: 0.24508775770664215
3
train loss item: 0.5470765233039856
4
train loss item: 0.4289611279964447
5
train loss item: 0.36821821331977844
6
train loss item: 0.29794299602508545
7
train loss item: 0.7362442016601562
8
train loss item: 0.145176962018013
9
train loss item: 0.2976544499397278
10
train loss item: 0.3859213590621948
11
train loss item: 0.27869924902915955
12
train loss item: 0.09972286224365234
13
train loss item: 0.49323245882987976
14
train loss item: 0.25121572613716125
15
train loss item: 0.6254058480262756
16
train loss item: 0.04753421992063522
17
train loss item: 0.3447977900505066
18
train loss item: 0.3825571537017822
19
train loss item: 0.3118770718574524
20
train loss item: 0.2479136735200882
21
train loss item: 0.1176568791270256
22
train loss item: 0.9282165169715881
23
train loss item: 0.8762015104293823
24
train loss item: 0.6260861754417419
25
train loss item: 0.15566043555736542
26
train loss item: 0.20721253752708435
27
train loss item: 0.27257272601127625
28
train loss item: 0.04325908422470093
29
train loss item: 0.6812708973884583
30
train loss item: 2.0203351974487305
31
train loss item: 0.6291275024414062
32
train loss item: 0.08220894634723663
33
train loss item: 0.4220477044582367
34
train loss item: 0.09607544541358948
35
train loss item: 2.2124545574188232
36
train loss item: 0.5001871585845947
37
train loss item: 0.4245286285877228
38
train loss item: 0.5119003653526306
39
train loss item: 0.23523108661174774
40
train loss item: 0.1470237523317337
41
train loss item: 0.28207141160964966
42
train loss item: 0.30561956763267517
43
train loss item: 0.1977475881576538
44
train loss item: 0.6051362752914429
45
train loss item: 0.10629594326019287
46
train loss item: 0.11566844582557678
47
train loss item: 0.3877854645252228
48
train loss item: 0.2563568353652954
49
train loss item: 0.16409152746200562
50
train loss item: 0.35397985577583313
51
train loss item: 0.8670194149017334
52
train loss item: 0.05392451211810112
53
train loss item: 0.1526278257369995
54
train loss item: 2.076366662979126
55
train loss item: 0.23423801362514496
56
train loss item: 0.28270548582077026
57
train loss item: 0.2498490810394287
58
train loss item: 0.175596222281456
59
train loss item: 0.09230924397706985
60
train loss item: 0.8505279421806335
61
train loss item: 1.9574285745620728
62
train loss item: 0.2367900162935257
63
train loss item: 0.4128890037536621
64
train loss item: 0.16485446691513062
65
train loss item: 0.6876299977302551
66
train loss item: 0.44844797253608704
67
train loss item: 0.2067234069108963
68
train loss item: 0.3586726486682892
69
train loss item: 0.3964131772518158
70
train loss item: 0.286128431558609
71
train loss item: 0.11938691139221191
72
train loss item: 0.20527943968772888
73
train loss item: 0.3427225649356842
74
train loss item: 0.04555411636829376
75
train loss item: 0.08930317312479019
76
train loss item: 0.8897849321365356
77
train loss item: 1.1916844844818115
78
train loss item: 0.054909005761146545
79
train loss item: 0.2827281951904297
80
train loss item: 0.09659592807292938
81
train loss item: 0.20126906037330627
82
train loss item: 0.21330751478672028
83
train loss item: 0.5733138918876648
84
train loss item: 0.4409409463405609
85
train loss item: 0.6279612183570862
86
train loss item: 3.978508949279785
87
train loss item: 0.15071703493595123
88
train loss item: 0.38882339000701904
epoch train loss: 0.47395158228412104
testing phase
test loss item: 0.19775377213954926
test loss item: 0.08093229681253433
test loss item: 0.6943098306655884
test loss item: 0.23827089369297028
test loss item: 0.2715848982334137
test loss item: 0.121330127120018
test loss item: 1.9625242948532104
test loss item: 0.5416207313537598
test loss item: 0.23526088893413544
test loss item: 0.45075416564941406
test loss item: 0.9761915802955627
test loss item: 0.17413249611854553
test loss item: 0.1893654763698578
test loss item: 0.387546569108963
test loss item: 0.17983879148960114
test loss item: 0.06128114089369774
test loss item: 0.35369759798049927
test loss item: 0.5425778031349182
test loss item: 0.7433254718780518
test loss item: 0.35180404782295227
test loss item: 0.880534291267395
test loss item: 0.42117711901664734
test loss item: 0.3273526728153229
test loss item: 0.20108957588672638
test loss item: 0.2595468759536743
test loss item: 0.2704106867313385
test loss item: 0.40284156799316406
test loss item: 0.2043863832950592
test loss item: 0.3973325192928314
test loss item: 0.4084317684173584
test loss item: 0.8733994960784912
test loss item: 0.061143212020397186
test loss item: 0.1697385609149933
test loss item: 0.6661685705184937
test loss item: 0.5183340311050415
test loss item: 0.44989678263664246
test loss item: 0.9098924398422241
test loss item: 1.637547492980957
test loss item: 0.5740677714347839
test loss item: 0.3255041539669037
test loss item: 0.35705095529556274
test loss item: 0.2154589742422104
test loss item: 0.3874076008796692
test loss item: 0.23690062761306763
test loss item: 0.7167298197746277
test loss item: 0.5493507385253906
test loss item: 0.3394378423690796
test loss item: 0.2857009172439575
test loss item: 0.5362381935119629
test loss item: 0.7694011330604553
test loss item: 0.3353448510169983
test loss item: 0.13856494426727295
test loss item: 0.26867565512657166
test loss item: 0.14828552305698395
test loss item: 0.3410954773426056
test loss item: 1.0495737791061401
test loss item: 0.59682697057724
test loss item: 0.30718180537223816
test loss item: 0.27663758397102356
test loss item: 0.21508784592151642
test loss item: 0.49940919876098633
test loss item: 0.26467257738113403
test loss item: 0.259214848279953
test loss item: 0.30223017930984497
test loss item: 1.0376311540603638
test loss item: 0.3206358850002289
test loss item: 0.3714953064918518
test loss item: 0.3083227276802063
test loss item: 0.634291410446167
test loss item: 0.4245617687702179
test loss item: 0.05982625484466553
test loss item: 1.1306464672088623
test loss item: 0.3631724417209625
test loss item: 0.4756000339984894
test loss item: 0.17370475828647614
test loss item: 0.19118165969848633
test loss item: 0.19856540858745575
test loss item: 1.6564099788665771
test loss item: 0.54616779088974
test loss item: 0.21877312660217285
test loss item: 0.08092653751373291
test loss item: 1.051518201828003
test loss item: 0.9879257082939148
test loss item: 1.1138075590133667
test loss item: 0.2562714219093323
test loss item: 0.25698670744895935
test loss item: 0.07480895519256592
test loss item: 0.07122115790843964
test loss item: 0.19630250334739685
Epoch [51/100], Training Loss: 0.4740, Testing Loss: 0.4529
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 52/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46362778544425964
1
train loss item: 1.1365718841552734
2
train loss item: 0.2458571195602417
3
train loss item: 0.5487134456634521
4
train loss item: 0.44690048694610596
5
train loss item: 0.36727994680404663
6
train loss item: 0.2998141050338745
7
train loss item: 0.7376767992973328
8
train loss item: 0.14326989650726318
9
train loss item: 0.29380208253860474
10
train loss item: 0.3876037001609802
11
train loss item: 0.273276686668396
12
train loss item: 0.09958706796169281
13
train loss item: 0.48181694746017456
14
train loss item: 0.24587151408195496
15
train loss item: 0.6282562017440796
16
train loss item: 0.048308514058589935
17
train loss item: 0.3455103933811188
18
train loss item: 0.40280869603157043
19
train loss item: 0.31354770064353943
20
train loss item: 0.2539214789867401
21
train loss item: 0.10720918327569962
22
train loss item: 0.9283947944641113
23
train loss item: 0.8640092015266418
24
train loss item: 0.6326905488967896
25
train loss item: 0.16987144947052002
26
train loss item: 0.2049490511417389
27
train loss item: 0.2468651831150055
28
train loss item: 0.04401058703660965
29
train loss item: 0.6726227402687073
30
train loss item: 1.989040493965149
31
train loss item: 0.6515005826950073
32
train loss item: 0.07808874547481537
33
train loss item: 0.4122730791568756
34
train loss item: 0.09468691796064377
35
train loss item: 2.1945457458496094
36
train loss item: 0.5167586207389832
37
train loss item: 0.41911715269088745
38
train loss item: 0.5378267168998718
39
train loss item: 0.24875356256961823
40
train loss item: 0.14811429381370544
41
train loss item: 0.2805882394313812
42
train loss item: 0.30177056789398193
43
train loss item: 0.19843579828739166
44
train loss item: 0.6003998517990112
45
train loss item: 0.10493025183677673
46
train loss item: 0.11149135231971741
47
train loss item: 0.38669806718826294
48
train loss item: 0.2499624341726303
49
train loss item: 0.1566845327615738
50
train loss item: 0.3555077612400055
51
train loss item: 0.8430156707763672
52
train loss item: 0.05278881639242172
53
train loss item: 0.14102596044540405
54
train loss item: 2.05735445022583
55
train loss item: 0.235145702958107
56
train loss item: 0.30643507838249207
57
train loss item: 0.24731187522411346
58
train loss item: 0.1769685000181198
59
train loss item: 0.09150292724370956
60
train loss item: 0.8369954228401184
61
train loss item: 1.9219310283660889
62
train loss item: 0.2362002730369568
63
train loss item: 0.4074924886226654
64
train loss item: 0.1629415899515152
65
train loss item: 0.6816681027412415
66
train loss item: 0.4512002468109131
67
train loss item: 0.20441941916942596
68
train loss item: 0.3633947968482971
69
train loss item: 0.4008595645427704
70
train loss item: 0.2880314290523529
71
train loss item: 0.12009032815694809
72
train loss item: 0.19257692992687225
73
train loss item: 0.3439190983772278
74
train loss item: 0.045291755348443985
75
train loss item: 0.08878126740455627
76
train loss item: 0.8759021759033203
77
train loss item: 1.1671385765075684
78
train loss item: 0.05282684788107872
79
train loss item: 0.2759723663330078
80
train loss item: 0.09637203067541122
81
train loss item: 0.20150458812713623
82
train loss item: 0.20857617259025574
83
train loss item: 0.5635836720466614
84
train loss item: 0.42198851704597473
85
train loss item: 0.6197956800460815
86
train loss item: 3.9471607208251953
87
train loss item: 0.1554618626832962
88
train loss item: 0.39806684851646423
epoch train loss: 0.47138778363051037
testing phase
test loss item: 0.1984228938817978
test loss item: 0.08317391574382782
test loss item: 0.7061349153518677
test loss item: 0.23964029550552368
test loss item: 0.28277701139450073
test loss item: 0.12493158131837845
test loss item: 1.960941195487976
test loss item: 0.5296341776847839
test loss item: 0.2523469030857086
test loss item: 0.47318795323371887
test loss item: 0.983944296836853
test loss item: 0.17607255280017853
test loss item: 0.19268766045570374
test loss item: 0.3950800895690918
test loss item: 0.18792885541915894
test loss item: 0.06071656569838524
test loss item: 0.3533405363559723
test loss item: 0.5757254958152771
test loss item: 0.7397209405899048
test loss item: 0.35454803705215454
test loss item: 0.9312471151351929
test loss item: 0.420024037361145
test loss item: 0.34765729308128357
test loss item: 0.2022312879562378
test loss item: 0.2653238773345947
test loss item: 0.27198326587677
test loss item: 0.41120675206184387
test loss item: 0.21213233470916748
test loss item: 0.40828412771224976
test loss item: 0.4199948012828827
test loss item: 0.8844849467277527
test loss item: 0.061757877469062805
test loss item: 0.17039546370506287
test loss item: 0.6838212013244629
test loss item: 0.5389810800552368
test loss item: 0.4694634974002838
test loss item: 0.9145206212997437
test loss item: 1.6412910223007202
test loss item: 0.5961459279060364
test loss item: 0.3272053599357605
test loss item: 0.35767340660095215
test loss item: 0.21536001563072205
test loss item: 0.4142913818359375
test loss item: 0.23828767240047455
test loss item: 0.7568170428276062
test loss item: 0.5472635626792908
test loss item: 0.35325971245765686
test loss item: 0.28968560695648193
test loss item: 0.5569010376930237
test loss item: 0.7875515222549438
test loss item: 0.3628537058830261
test loss item: 0.13896867632865906
test loss item: 0.27733904123306274
test loss item: 0.1510351002216339
test loss item: 0.36026567220687866
test loss item: 1.052833080291748
test loss item: 0.5952758193016052
test loss item: 0.32389771938323975
test loss item: 0.2826986312866211
test loss item: 0.22557032108306885
test loss item: 0.5329960584640503
test loss item: 0.26159217953681946
test loss item: 0.2601734399795532
test loss item: 0.3029734194278717
test loss item: 1.0126798152923584
test loss item: 0.3222964107990265
test loss item: 0.3760805130004883
test loss item: 0.3090534806251526
test loss item: 0.634916365146637
test loss item: 0.4324555993080139
test loss item: 0.059546779841184616
test loss item: 1.122931718826294
test loss item: 0.38225358724594116
test loss item: 0.4780265688896179
test loss item: 0.17532049119472504
test loss item: 0.19254471361637115
test loss item: 0.1997254341840744
test loss item: 1.6361140012741089
test loss item: 0.5546385645866394
test loss item: 0.22142665088176727
test loss item: 0.07805640250444412
test loss item: 1.0543913841247559
test loss item: 1.001897931098938
test loss item: 1.1109095811843872
test loss item: 0.26360657811164856
test loss item: 0.26247432827949524
test loss item: 0.07078340649604797
test loss item: 0.06705337762832642
test loss item: 0.1883193701505661
Epoch [52/100], Training Loss: 0.4714, Testing Loss: 0.4596
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6894.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6894.00 MB
Epoch 53/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.44359055161476135
1
train loss item: 1.1279988288879395
2
train loss item: 0.2467605024576187
3
train loss item: 0.5467900633811951
4
train loss item: 0.4225093126296997
5
train loss item: 0.36046165227890015
6
train loss item: 0.2969449758529663
7
train loss item: 0.7204471826553345
8
train loss item: 0.14476920664310455
9
train loss item: 0.29345273971557617
10
train loss item: 0.38094472885131836
11
train loss item: 0.26953306794166565
12
train loss item: 0.09768292307853699
13
train loss item: 0.4854026436805725
14
train loss item: 0.24918442964553833
15
train loss item: 0.6225844621658325
16
train loss item: 0.044092919677495956
17
train loss item: 0.34264734387397766
18
train loss item: 0.37637418508529663
19
train loss item: 0.3123059570789337
20
train loss item: 0.24816137552261353
21
train loss item: 0.10735401511192322
22
train loss item: 0.9121192693710327
23
train loss item: 0.8650614619255066
24
train loss item: 0.6232023239135742
25
train loss item: 0.15255111455917358
26
train loss item: 0.20409083366394043
27
train loss item: 0.2592240869998932
28
train loss item: 0.04035739600658417
29
train loss item: 0.6770321130752563
30
train loss item: 1.970534324645996
31
train loss item: 0.6186909079551697
32
train loss item: 0.07920704782009125
33
train loss item: 0.4235934615135193
34
train loss item: 0.09186483174562454
35
train loss item: 2.1726572513580322
36
train loss item: 0.49112531542778015
37
train loss item: 0.4060598909854889
38
train loss item: 0.49495500326156616
39
train loss item: 0.2302713692188263
40
train loss item: 0.14641673862934113
41
train loss item: 0.27918577194213867
42
train loss item: 0.3007975220680237
43
train loss item: 0.19778919219970703
44
train loss item: 0.6009253263473511
45
train loss item: 0.1082349345088005
46
train loss item: 0.11410962045192719
47
train loss item: 0.38313135504722595
48
train loss item: 0.2538287937641144
49
train loss item: 0.16010579466819763
50
train loss item: 0.35264694690704346
51
train loss item: 0.8602558970451355
52
train loss item: 0.0498959943652153
53
train loss item: 0.14745914936065674
54
train loss item: 2.035884380340576
55
train loss item: 0.23855175077915192
56
train loss item: 0.2741214632987976
57
train loss item: 0.24821016192436218
58
train loss item: 0.17398510873317719
59
train loss item: 0.09295058250427246
60
train loss item: 0.8449271321296692
61
train loss item: 1.919731855392456
62
train loss item: 0.2314956784248352
63
train loss item: 0.4048704504966736
64
train loss item: 0.16676843166351318
65
train loss item: 0.6722009778022766
66
train loss item: 0.4320410490036011
67
train loss item: 0.20438767969608307
68
train loss item: 0.3578002154827118
69
train loss item: 0.39020058512687683
70
train loss item: 0.2820010483264923
71
train loss item: 0.1165311187505722
72
train loss item: 0.2020910531282425
73
train loss item: 0.342303067445755
74
train loss item: 0.04557790234684944
75
train loss item: 0.09071384370326996
76
train loss item: 0.8824191093444824
77
train loss item: 1.1730961799621582
78
train loss item: 0.047714732587337494
79
train loss item: 0.27233320474624634
80
train loss item: 0.0935300886631012
81
train loss item: 0.19885118305683136
82
train loss item: 0.21352694928646088
83
train loss item: 0.5618532299995422
84
train loss item: 0.4157567024230957
85
train loss item: 0.6256508231163025
86
train loss item: 3.916536569595337
87
train loss item: 0.1512296050786972
88
train loss item: 0.3815925121307373
epoch train loss: 0.46639112960756496
testing phase
test loss item: 0.19706687331199646
test loss item: 0.08383991569280624
test loss item: 0.7458649277687073
test loss item: 0.23901472985744476
test loss item: 0.28873252868652344
test loss item: 0.12457628548145294
test loss item: 1.948169231414795
test loss item: 0.5193571448326111
test loss item: 0.25786489248275757
test loss item: 0.4777907729148865
test loss item: 1.028929352760315
test loss item: 0.17626602947711945
test loss item: 0.19371497631072998
test loss item: 0.39371830224990845
test loss item: 0.19119518995285034
test loss item: 0.05872279405593872
test loss item: 0.3525266647338867
test loss item: 0.5852674245834351
test loss item: 0.7324863076210022
test loss item: 0.35316938161849976
test loss item: 0.9487364888191223
test loss item: 0.4173630177974701
test loss item: 0.35232892632484436
test loss item: 0.20015285909175873
test loss item: 0.2676926553249359
test loss item: 0.27143049240112305
test loss item: 0.41075214743614197
test loss item: 0.21408000588417053
test loss item: 0.4101528823375702
test loss item: 0.4204839766025543
test loss item: 0.9088230729103088
test loss item: 0.06184468790888786
test loss item: 0.1679747849702835
test loss item: 0.7009491324424744
test loss item: 0.5536984801292419
test loss item: 0.4674804210662842
test loss item: 0.9091713428497314
test loss item: 1.7467162609100342
test loss item: 0.6044988036155701
test loss item: 0.326261043548584
test loss item: 0.3565080761909485
test loss item: 0.21477115154266357
test loss item: 0.4171316623687744
test loss item: 0.237466499209404
test loss item: 0.7657837867736816
test loss item: 0.5443574786186218
test loss item: 0.3546576201915741
test loss item: 0.287687212228775
test loss item: 0.5711431503295898
test loss item: 0.8036746978759766
test loss item: 0.36494407057762146
test loss item: 0.13911205530166626
test loss item: 0.278352826833725
test loss item: 0.15160128474235535
test loss item: 0.3669705390930176
test loss item: 1.1108895540237427
test loss item: 0.604952335357666
test loss item: 0.3238256871700287
test loss item: 0.282469779253006
test loss item: 0.2263191193342209
test loss item: 0.5372880101203918
test loss item: 0.25923123955726624
test loss item: 0.2598607838153839
test loss item: 0.30281615257263184
test loss item: 1.0818661451339722
test loss item: 0.3221067786216736
test loss item: 0.376897394657135
test loss item: 0.3091243803501129
test loss item: 0.6627137660980225
test loss item: 0.4242866337299347
test loss item: 0.06175585836172104
test loss item: 1.1111029386520386
test loss item: 0.3850969076156616
test loss item: 0.47697684168815613
test loss item: 0.17627599835395813
test loss item: 0.19180597364902496
test loss item: 0.1982632577419281
test loss item: 1.7739131450653076
test loss item: 0.5650947093963623
test loss item: 0.2223205417394638
test loss item: 0.07712900638580322
test loss item: 1.089117407798767
test loss item: 1.0030643939971924
test loss item: 1.1966191530227661
test loss item: 0.2647206783294678
test loss item: 0.26232096552848816
test loss item: 0.06693524122238159
test loss item: 0.06068183481693268
test loss item: 0.1881508082151413
Epoch [53/100], Training Loss: 0.4664, Testing Loss: 0.4676
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 54/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4581849277019501
1
train loss item: 1.1096473932266235
2
train loss item: 0.24382293224334717
3
train loss item: 0.5405688285827637
4
train loss item: 0.42805802822113037
5
train loss item: 0.366781085729599
6
train loss item: 0.29393085837364197
7
train loss item: 0.7080001831054688
8
train loss item: 0.1423344910144806
9
train loss item: 0.2859823703765869
10
train loss item: 0.382019966840744
11
train loss item: 0.2745766341686249
12
train loss item: 0.0970713272690773
13
train loss item: 0.4852718412876129
14
train loss item: 0.24559280276298523
15
train loss item: 0.6087359189987183
16
train loss item: 0.04362120479345322
17
train loss item: 0.339189738035202
18
train loss item: 0.3948321044445038
19
train loss item: 0.306250661611557
20
train loss item: 0.24298782646656036
21
train loss item: 0.11068099737167358
22
train loss item: 0.897867739200592
23
train loss item: 0.8553138971328735
24
train loss item: 0.6150448322296143
25
train loss item: 0.15990829467773438
26
train loss item: 0.2039032280445099
27
train loss item: 0.2433074712753296
28
train loss item: 0.0403292179107666
29
train loss item: 0.6468623280525208
30
train loss item: 1.9390428066253662
31
train loss item: 0.6492241024971008
32
train loss item: 0.07986016571521759
33
train loss item: 0.4103972911834717
34
train loss item: 0.09417036920785904
35
train loss item: 2.1466469764709473
36
train loss item: 0.4967520236968994
37
train loss item: 0.41936612129211426
38
train loss item: 0.5297451019287109
39
train loss item: 0.23549291491508484
40
train loss item: 0.1459725797176361
41
train loss item: 0.2775936424732208
42
train loss item: 0.29864922165870667
43
train loss item: 0.19589588046073914
44
train loss item: 0.5866566896438599
45
train loss item: 0.10671421885490417
46
train loss item: 0.11481200903654099
47
train loss item: 0.3786872625350952
48
train loss item: 0.24687333405017853
49
train loss item: 0.15657760202884674
50
train loss item: 0.3486137390136719
51
train loss item: 0.8345710039138794
52
train loss item: 0.04986926540732384
53
train loss item: 0.140509232878685
54
train loss item: 2.0099284648895264
55
train loss item: 0.2328762710094452
56
train loss item: 0.28770798444747925
57
train loss item: 0.2473754584789276
58
train loss item: 0.17340151965618134
59
train loss item: 0.09403754770755768
60
train loss item: 0.805805504322052
61
train loss item: 1.8803261518478394
62
train loss item: 0.2293204516172409
63
train loss item: 0.4016272723674774
64
train loss item: 0.1632595807313919
65
train loss item: 0.6904283165931702
66
train loss item: 0.4346389174461365
67
train loss item: 0.20439977943897247
68
train loss item: 0.34454095363616943
69
train loss item: 0.3947405219078064
70
train loss item: 0.2806042730808258
71
train loss item: 0.11601612716913223
72
train loss item: 0.1935814470052719
73
train loss item: 0.33791452646255493
74
train loss item: 0.04475857689976692
75
train loss item: 0.08992374688386917
76
train loss item: 0.8575085401535034
77
train loss item: 1.1311845779418945
78
train loss item: 0.046548809856176376
79
train loss item: 0.2737220823764801
80
train loss item: 0.09597033262252808
81
train loss item: 0.19681577384471893
82
train loss item: 0.20719607174396515
83
train loss item: 0.5432516932487488
84
train loss item: 0.42377689480781555
85
train loss item: 0.6085262298583984
86
train loss item: 3.88509464263916
87
train loss item: 0.15009570121765137
88
train loss item: 0.3942819833755493
epoch train loss: 0.4620737012768729
testing phase
test loss item: 0.19639970362186432
test loss item: 0.0839603915810585
test loss item: 0.7285930514335632
test loss item: 0.2372771054506302
test loss item: 0.282776415348053
test loss item: 0.12304115295410156
test loss item: 1.9225009679794312
test loss item: 0.5199165940284729
test loss item: 0.25344035029411316
test loss item: 0.4678744077682495
test loss item: 1.0123414993286133
test loss item: 0.17522700130939484
test loss item: 0.19219166040420532
test loss item: 0.3876524865627289
test loss item: 0.1867355853319168
test loss item: 0.05830278992652893
test loss item: 0.3510633409023285
test loss item: 0.5707730650901794
test loss item: 0.729137122631073
test loss item: 0.3503175377845764
test loss item: 0.9236630797386169
test loss item: 0.4148583710193634
test loss item: 0.34305495023727417
test loss item: 0.19872252643108368
test loss item: 0.26429635286331177
test loss item: 0.26956892013549805
test loss item: 0.40660834312438965
test loss item: 0.2100340723991394
test loss item: 0.40333133935928345
test loss item: 0.41538918018341064
test loss item: 0.8921843767166138
test loss item: 0.0631428211927414
test loss item: 0.16720125079154968
test loss item: 0.6897830963134766
test loss item: 0.540590763092041
test loss item: 0.4596140682697296
test loss item: 0.9005401134490967
test loss item: 1.714685082435608
test loss item: 0.5913938879966736
test loss item: 0.3227415680885315
test loss item: 0.3535081148147583
test loss item: 0.21201850473880768
test loss item: 0.4072839021682739
test loss item: 0.23514947295188904
test loss item: 0.7462256550788879
test loss item: 0.5416231155395508
test loss item: 0.3467339277267456
test loss item: 0.2848971486091614
test loss item: 0.5591477751731873
test loss item: 0.7921551465988159
test loss item: 0.3527257740497589
test loss item: 0.14017026126384735
test loss item: 0.27340859174728394
test loss item: 0.15010467171669006
test loss item: 0.3569888770580292
test loss item: 1.0851222276687622
test loss item: 0.5999696254730225
test loss item: 0.31238600611686707
test loss item: 0.27886831760406494
test loss item: 0.22164815664291382
test loss item: 0.5246984958648682
test loss item: 0.26011499762535095
test loss item: 0.2582649886608124
test loss item: 0.30164915323257446
test loss item: 1.0595448017120361
test loss item: 0.31966108083724976
test loss item: 0.3742924630641937
test loss item: 0.30698296427726746
test loss item: 0.651178240776062
test loss item: 0.4212423861026764
test loss item: 0.06032082810997963
test loss item: 1.1011306047439575
test loss item: 0.37421414256095886
test loss item: 0.47298136353492737
test loss item: 0.17514774203300476
test loss item: 0.18911077082157135
test loss item: 0.19658242166042328
test loss item: 1.738701343536377
test loss item: 0.5576561689376831
test loss item: 0.21947968006134033
test loss item: 0.07649601995944977
test loss item: 1.074052333831787
test loss item: 0.9909888505935669
test loss item: 1.1706981658935547
test loss item: 0.26085376739501953
test loss item: 0.2601076066493988
test loss item: 0.06663937866687775
test loss item: 0.05888032540678978
test loss item: 0.18739815056324005
Epoch [54/100], Training Loss: 0.4621, Testing Loss: 0.4605
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6832.00 MB
Epoch 55/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.44318944215774536
1
train loss item: 1.1065788269042969
2
train loss item: 0.24446503818035126
3
train loss item: 0.5364211797714233
4
train loss item: 0.41909414529800415
5
train loss item: 0.35672956705093384
6
train loss item: 0.2940899729728699
7
train loss item: 0.700818657875061
8
train loss item: 0.14430104196071625
9
train loss item: 0.2862485647201538
10
train loss item: 0.37580910325050354
11
train loss item: 0.2644948661327362
12
train loss item: 0.09662282466888428
13
train loss item: 0.481120228767395
14
train loss item: 0.2449660450220108
15
train loss item: 0.6085758805274963
16
train loss item: 0.0427979938685894
17
train loss item: 0.33863621950149536
18
train loss item: 0.3736175298690796
19
train loss item: 0.3071564733982086
20
train loss item: 0.24630150198936462
21
train loss item: 0.10394788533449173
22
train loss item: 0.8935660123825073
23
train loss item: 0.8469837307929993
24
train loss item: 0.6170965433120728
25
train loss item: 0.1516667902469635
26
train loss item: 0.20291750133037567
27
train loss item: 0.24715930223464966
28
train loss item: 0.039855170994997025
29
train loss item: 0.6497469544410706
30
train loss item: 1.9172568321228027
31
train loss item: 0.6180099248886108
32
train loss item: 0.0776611715555191
33
train loss item: 0.41251710057258606
34
train loss item: 0.09107714146375656
35
train loss item: 2.1317427158355713
36
train loss item: 0.4863540828227997
37
train loss item: 0.39804625511169434
38
train loss item: 0.4910854995250702
39
train loss item: 0.2271411418914795
40
train loss item: 0.14598198235034943
41
train loss item: 0.2728807032108307
42
train loss item: 0.29424190521240234
43
train loss item: 0.1948787420988083
44
train loss item: 0.587975800037384
45
train loss item: 0.10700053721666336
46
train loss item: 0.11216376721858978
47
train loss item: 0.3770723342895508
48
train loss item: 0.24998436868190765
49
train loss item: 0.15460658073425293
50
train loss item: 0.34823986887931824
51
train loss item: 0.835360050201416
52
train loss item: 0.04939531534910202
53
train loss item: 0.14312401413917542
54
train loss item: 1.9931509494781494
55
train loss item: 0.2355547994375229
56
train loss item: 0.2709583044052124
57
train loss item: 0.24551410973072052
58
train loss item: 0.17160627245903015
59
train loss item: 0.09594714641571045
60
train loss item: 0.8237321972846985
61
train loss item: 1.865221619606018
62
train loss item: 0.2276001274585724
63
train loss item: 0.39677876234054565
64
train loss item: 0.1631678342819214
65
train loss item: 0.6706604361534119
66
train loss item: 0.41990339756011963
67
train loss item: 0.2031649351119995
68
train loss item: 0.3484184443950653
69
train loss item: 0.3878403306007385
70
train loss item: 0.27706122398376465
71
train loss item: 0.11467224359512329
72
train loss item: 0.19955827295780182
73
train loss item: 0.3378950357437134
74
train loss item: 0.044847697019577026
75
train loss item: 0.09003159403800964
76
train loss item: 0.8656125068664551
77
train loss item: 1.1354591846466064
78
train loss item: 0.04514032229781151
79
train loss item: 0.2672160565853119
80
train loss item: 0.09419534355401993
81
train loss item: 0.1935705840587616
82
train loss item: 0.2085522711277008
83
train loss item: 0.5422966480255127
84
train loss item: 0.4020845592021942
85
train loss item: 0.6144664287567139
86
train loss item: 3.8544833660125732
87
train loss item: 0.14859192073345184
88
train loss item: 0.3811356723308563
epoch train loss: 0.45758273515306164
testing phase
test loss item: 0.1956922560930252
test loss item: 0.08430065959692001
test loss item: 0.7421560883522034
test loss item: 0.23779328167438507
test loss item: 0.2885509431362152
test loss item: 0.12297441065311432
test loss item: 1.9500049352645874
test loss item: 0.5365322828292847
test loss item: 0.2581924498081207
test loss item: 0.4709993600845337
test loss item: 1.0247145891189575
test loss item: 0.17632636427879333
test loss item: 0.19289980828762054
test loss item: 0.38648760318756104
test loss item: 0.190132275223732
test loss item: 0.0588783323764801
test loss item: 0.35248124599456787
test loss item: 0.5741510391235352
test loss item: 0.7355782985687256
test loss item: 0.3507416248321533
test loss item: 0.9399284720420837
test loss item: 0.4207076132297516
test loss item: 0.3502063751220703
test loss item: 0.2002805918455124
test loss item: 0.2660590410232544
test loss item: 0.2711438536643982
test loss item: 0.4064894914627075
test loss item: 0.2104278951883316
test loss item: 0.40711709856987
test loss item: 0.41427305340766907
test loss item: 0.9083341956138611
test loss item: 0.06301943212747574
test loss item: 0.16756568849086761
test loss item: 0.6950962543487549
test loss item: 0.5458903908729553
test loss item: 0.45953166484832764
test loss item: 0.910252034664154
test loss item: 1.7409987449645996
test loss item: 0.5975074172019958
test loss item: 0.32533055543899536
test loss item: 0.3556630611419678
test loss item: 0.20889277756214142
test loss item: 0.4060259759426117
test loss item: 0.23699477314949036
test loss item: 0.7565770745277405
test loss item: 0.5425660014152527
test loss item: 0.34831735491752625
test loss item: 0.28394532203674316
test loss item: 0.5686653852462769
test loss item: 0.8010671734809875
test loss item: 0.35499346256256104
test loss item: 0.14022524654865265
test loss item: 0.2762293517589569
test loss item: 0.1507250815629959
test loss item: 0.3606139123439789
test loss item: 1.0898269414901733
test loss item: 0.6075465083122253
test loss item: 0.31326088309288025
test loss item: 0.27986791729927063
test loss item: 0.22283099591732025
test loss item: 0.524247944355011
test loss item: 0.26578712463378906
test loss item: 0.25910696387290955
test loss item: 0.3031542897224426
test loss item: 1.0750943422317505
test loss item: 0.32032933831214905
test loss item: 0.378633588552475
test loss item: 0.309145450592041
test loss item: 0.6569768190383911
test loss item: 0.42598897218704224
test loss item: 0.06163512542843819
test loss item: 1.117817997932434
test loss item: 0.3767092227935791
test loss item: 0.4791242480278015
test loss item: 0.1753670871257782
test loss item: 0.18703614175319672
test loss item: 0.19875788688659668
test loss item: 1.7729992866516113
test loss item: 0.5636112689971924
test loss item: 0.21821071207523346
test loss item: 0.0769529715180397
test loss item: 1.0947623252868652
test loss item: 1.0005359649658203
test loss item: 1.1919686794281006
test loss item: 0.264270156621933
test loss item: 0.2612389028072357
test loss item: 0.06683375686407089
test loss item: 0.058646850287914276
test loss item: 0.1820901781320572
Epoch [55/100], Training Loss: 0.4576, Testing Loss: 0.4652
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 56/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.44686901569366455
1
train loss item: 1.1005135774612427
2
train loss item: 0.2419130951166153
3
train loss item: 0.5283464789390564
4
train loss item: 0.4162736237049103
5
train loss item: 0.357494980096817
6
train loss item: 0.2918504476547241
7
train loss item: 0.6880975365638733
8
train loss item: 0.14215222001075745
9
train loss item: 0.2833549678325653
10
train loss item: 0.372300922870636
11
train loss item: 0.2658868432044983
12
train loss item: 0.09636856615543365
13
train loss item: 0.4788137674331665
14
train loss item: 0.24384930729866028
15
train loss item: 0.6013399958610535
16
train loss item: 0.044261716306209564
17
train loss item: 0.3365716338157654
18
train loss item: 0.37716102600097656
19
train loss item: 0.30386579036712646
20
train loss item: 0.2459956854581833
21
train loss item: 0.10369463264942169
22
train loss item: 0.8886302709579468
23
train loss item: 0.8377737998962402
24
train loss item: 0.612741231918335
25
train loss item: 0.1508479118347168
26
train loss item: 0.20247527956962585
27
train loss item: 0.2439924031496048
28
train loss item: 0.04124755784869194
29
train loss item: 0.6323215365409851
30
train loss item: 1.894329309463501
31
train loss item: 0.6201045513153076
32
train loss item: 0.07715941965579987
33
train loss item: 0.40565377473831177
34
train loss item: 0.09302486479282379
35
train loss item: 2.109828472137451
36
train loss item: 0.4812328517436981
37
train loss item: 0.39293986558914185
38
train loss item: 0.47933268547058105
39
train loss item: 0.2260715812444687
40
train loss item: 0.14606072008609772
41
train loss item: 0.2720176577568054
42
train loss item: 0.29246366024017334
43
train loss item: 0.19295364618301392
44
train loss item: 0.573517918586731
45
train loss item: 0.10350397229194641
46
train loss item: 0.11167925596237183
47
train loss item: 0.37361380457878113
48
train loss item: 0.24745425581932068
49
train loss item: 0.1534317582845688
50
train loss item: 0.3453930616378784
51
train loss item: 0.822898268699646
52
train loss item: 0.04908337816596031
53
train loss item: 0.142471045255661
54
train loss item: 1.9713417291641235
55
train loss item: 0.23029682040214539
56
train loss item: 0.271847128868103
57
train loss item: 0.24510540068149567
58
train loss item: 0.17037858068943024
59
train loss item: 0.09431759268045425
60
train loss item: 0.8035786747932434
61
train loss item: 1.8372882604599
62
train loss item: 0.22586005926132202
63
train loss item: 0.39321088790893555
64
train loss item: 0.16062137484550476
65
train loss item: 0.6741582751274109
66
train loss item: 0.41813573241233826
67
train loss item: 0.20101414620876312
68
train loss item: 0.3451530635356903
69
train loss item: 0.3890766501426697
70
train loss item: 0.2755037844181061
71
train loss item: 0.1168546974658966
72
train loss item: 0.1948813647031784
73
train loss item: 0.3352563679218292
74
train loss item: 0.043349284678697586
75
train loss item: 0.08822421729564667
76
train loss item: 0.8483617305755615
77
train loss item: 1.1147494316101074
78
train loss item: 0.04721779003739357
79
train loss item: 0.26708459854125977
80
train loss item: 0.09520569443702698
81
train loss item: 0.19158436357975006
82
train loss item: 0.20391139388084412
83
train loss item: 0.5318710803985596
84
train loss item: 0.39857640862464905
85
train loss item: 0.6036765575408936
86
train loss item: 3.825929880142212
87
train loss item: 0.1470741182565689
88
train loss item: 0.38384491205215454
epoch train loss: 0.45312098489048774
testing phase
test loss item: 0.19524019956588745
test loss item: 0.08185619860887527
test loss item: 0.7217850089073181
test loss item: 0.23654738068580627
test loss item: 0.2777358889579773
test loss item: 0.11969129741191864
test loss item: 1.9391058683395386
test loss item: 0.5338386297225952
test loss item: 0.2499157339334488
test loss item: 0.45818576216697693
test loss item: 1.0076537132263184
test loss item: 0.17557686567306519
test loss item: 0.18820028007030487
test loss item: 0.3789576590061188
test loss item: 0.18280921876430511
test loss item: 0.06028077378869057
test loss item: 0.35047447681427
test loss item: 0.5577656626701355
test loss item: 0.7302722334861755
test loss item: 0.34662577509880066
test loss item: 0.9066777229309082
test loss item: 0.41789522767066956
test loss item: 0.337286114692688
test loss item: 0.19900543987751007
test loss item: 0.2624858021736145
test loss item: 0.2672644555568695
test loss item: 0.4014914631843567
test loss item: 0.20494014024734497
test loss item: 0.39799177646636963
test loss item: 0.4081573784351349
test loss item: 0.8939671516418457
test loss item: 0.06291497498750687
test loss item: 0.16640229523181915
test loss item: 0.6824378967285156
test loss item: 0.5295150876045227
test loss item: 0.4517956078052521
test loss item: 0.9015166759490967
test loss item: 1.707030177116394
test loss item: 0.5821459889411926
test loss item: 0.3245069682598114
test loss item: 0.35426831245422363
test loss item: 0.20519502460956573
test loss item: 0.3974676728248596
test loss item: 0.2357669472694397
test loss item: 0.7301104068756104
test loss item: 0.5374906659126282
test loss item: 0.3374083638191223
test loss item: 0.27965325117111206
test loss item: 0.5508288741111755
test loss item: 0.7865779995918274
test loss item: 0.3391795754432678
test loss item: 0.13745926320552826
test loss item: 0.27012407779693604
test loss item: 0.15037383139133453
test loss item: 0.3484838008880615
test loss item: 1.0701826810836792
test loss item: 0.6007118225097656
test loss item: 0.29736000299453735
test loss item: 0.2736964523792267
test loss item: 0.2170325517654419
test loss item: 0.5124630331993103
test loss item: 0.2622590661048889
test loss item: 0.2564551532268524
test loss item: 0.30211228132247925
test loss item: 1.0564643144607544
test loss item: 0.31891584396362305
test loss item: 0.3727060854434967
test loss item: 0.30715590715408325
test loss item: 0.6449535489082336
test loss item: 0.42451414465904236
test loss item: 0.05802706256508827
test loss item: 1.1122339963912964
test loss item: 0.36385640501976013
test loss item: 0.4777379333972931
test loss item: 0.1711868941783905
test loss item: 0.18395830690860748
test loss item: 0.19722715020179749
test loss item: 1.7346020936965942
test loss item: 0.5540947318077087
test loss item: 0.21512708067893982
test loss item: 0.07782376557588577
test loss item: 1.080810546875
test loss item: 0.9921930432319641
test loss item: 1.1652491092681885
test loss item: 0.2591462731361389
test loss item: 0.2545529901981354
test loss item: 0.06876595318317413
test loss item: 0.06268193572759628
test loss item: 0.1790052205324173
Epoch [56/100], Training Loss: 0.4531, Testing Loss: 0.4571
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 57/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4438818097114563
1
train loss item: 1.0887967348098755
2
train loss item: 0.24093161523342133
3
train loss item: 0.5265243053436279
4
train loss item: 0.4134555757045746
5
train loss item: 0.3537602424621582
6
train loss item: 0.28973591327667236
7
train loss item: 0.6792950630187988
8
train loss item: 0.14005617797374725
9
train loss item: 0.2830771803855896
10
train loss item: 0.3718836009502411
11
train loss item: 0.2586039900779724
12
train loss item: 0.09599453955888748
13
train loss item: 0.47491028904914856
14
train loss item: 0.2419709712266922
15
train loss item: 0.5951260924339294
16
train loss item: 0.04498331993818283
17
train loss item: 0.3351381719112396
18
train loss item: 0.37680187821388245
19
train loss item: 0.3029747009277344
20
train loss item: 0.24519887566566467
21
train loss item: 0.10197759419679642
22
train loss item: 0.8720130324363708
23
train loss item: 0.8330179452896118
24
train loss item: 0.6067183017730713
25
train loss item: 0.14945141971111298
26
train loss item: 0.2011401653289795
27
train loss item: 0.23821260035037994
28
train loss item: 0.041928645223379135
29
train loss item: 0.6256808638572693
30
train loss item: 1.8675085306167603
31
train loss item: 0.6149592399597168
32
train loss item: 0.07740391790866852
33
train loss item: 0.4020928144454956
34
train loss item: 0.09192634373903275
35
train loss item: 2.0882034301757812
36
train loss item: 0.4768005609512329
37
train loss item: 0.3772222399711609
38
train loss item: 0.47102630138397217
39
train loss item: 0.22432412207126617
40
train loss item: 0.1459200233221054
41
train loss item: 0.27119582891464233
42
train loss item: 0.2894662022590637
43
train loss item: 0.19205120205879211
44
train loss item: 0.5683839917182922
45
train loss item: 0.10248539596796036
46
train loss item: 0.11097770184278488
47
train loss item: 0.36918798089027405
48
train loss item: 0.24537843465805054
49
train loss item: 0.15376053750514984
50
train loss item: 0.3427870273590088
51
train loss item: 0.811334490776062
52
train loss item: 0.047969866544008255
53
train loss item: 0.1412348449230194
54
train loss item: 1.947769284248352
55
train loss item: 0.22822214663028717
56
train loss item: 0.27147600054740906
57
train loss item: 0.2427469789981842
58
train loss item: 0.16913676261901855
59
train loss item: 0.09319202601909637
60
train loss item: 0.7988731265068054
61
train loss item: 1.8127552270889282
62
train loss item: 0.2237948328256607
63
train loss item: 0.387532114982605
64
train loss item: 0.1600705236196518
65
train loss item: 0.6551471948623657
66
train loss item: 0.4132102131843567
67
train loss item: 0.19970473647117615
68
train loss item: 0.3451315760612488
69
train loss item: 0.3845925033092499
70
train loss item: 0.27222740650177
71
train loss item: 0.11693598330020905
72
train loss item: 0.1908556967973709
73
train loss item: 0.33508890867233276
74
train loss item: 0.0434613935649395
75
train loss item: 0.08851263672113419
76
train loss item: 0.841107964515686
77
train loss item: 1.1002534627914429
78
train loss item: 0.04741942510008812
79
train loss item: 0.2612115442752838
80
train loss item: 0.09537375718355179
81
train loss item: 0.18949154019355774
82
train loss item: 0.20183759927749634
83
train loss item: 0.5230410695075989
84
train loss item: 0.3828437030315399
85
train loss item: 0.5997876524925232
86
train loss item: 3.791917324066162
87
train loss item: 0.14623898267745972
88
train loss item: 0.3766942620277405
epoch train loss: 0.4482527888390455
testing phase
test loss item: 0.19527405500411987
test loss item: 0.08301651477813721
test loss item: 0.7116894125938416
test loss item: 0.23817625641822815
test loss item: 0.2762433588504791
test loss item: 0.12179123610258102
test loss item: 1.9516395330429077
test loss item: 0.5402005314826965
test loss item: 0.25131452083587646
test loss item: 0.45911794900894165
test loss item: 1.0001283884048462
test loss item: 0.17614473402500153
test loss item: 0.1880498081445694
test loss item: 0.37828704714775085
test loss item: 0.1826612800359726
test loss item: 0.05974489822983742
test loss item: 0.3523808717727661
test loss item: 0.5597451329231262
test loss item: 0.7318581938743591
test loss item: 0.3473678231239319
test loss item: 0.906453549861908
test loss item: 0.4205254912376404
test loss item: 0.33887723088264465
test loss item: 0.20065325498580933
test loss item: 0.2634832262992859
test loss item: 0.2672693133354187
test loss item: 0.40201517939567566
test loss item: 0.2057957649230957
test loss item: 0.3984575867652893
test loss item: 0.40879562497138977
test loss item: 0.8954285979270935
test loss item: 0.0602545365691185
test loss item: 0.16777877509593964
test loss item: 0.6813647150993347
test loss item: 0.5268663167953491
test loss item: 0.4564996361732483
test loss item: 0.9044895172119141
test loss item: 1.6851599216461182
test loss item: 0.5819598436355591
test loss item: 0.3281823992729187
test loss item: 0.3559236526489258
test loss item: 0.20559625327587128
test loss item: 0.40186476707458496
test loss item: 0.2384987324476242
test loss item: 0.731010913848877
test loss item: 0.5367240905761719
test loss item: 0.3384370803833008
test loss item: 0.28023090958595276
test loss item: 0.5485405921936035
test loss item: 0.7864914536476135
test loss item: 0.34079429507255554
test loss item: 0.13691556453704834
test loss item: 0.27135324478149414
test loss item: 0.1537288874387741
test loss item: 0.34863337874412537
test loss item: 1.0555933713912964
test loss item: 0.6000166535377502
test loss item: 0.2953888773918152
test loss item: 0.27398186922073364
test loss item: 0.21809491515159607
test loss item: 0.5166150331497192
test loss item: 0.2625461518764496
test loss item: 0.257665753364563
test loss item: 0.30212506651878357
test loss item: 1.0373973846435547
test loss item: 0.32065850496292114
test loss item: 0.37342146039009094
test loss item: 0.30781498551368713
test loss item: 0.6368258595466614
test loss item: 0.4317657947540283
test loss item: 0.05815264955163002
test loss item: 1.1192200183868408
test loss item: 0.3664841949939728
test loss item: 0.48365727066993713
test loss item: 0.1717275083065033
test loss item: 0.18491120636463165
test loss item: 0.19882263243198395
test loss item: 1.7033228874206543
test loss item: 0.5533878803253174
test loss item: 0.2159302979707718
test loss item: 0.0791693851351738
test loss item: 1.0798020362854004
test loss item: 0.9976711869239807
test loss item: 1.148381233215332
test loss item: 0.26053449511528015
test loss item: 0.2546749711036682
test loss item: 0.06922683119773865
test loss item: 0.062155019491910934
test loss item: 0.1791328340768814
Epoch [57/100], Training Loss: 0.4483, Testing Loss: 0.4568
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 58/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.44001299142837524
1
train loss item: 1.0772098302841187
2
train loss item: 0.23974460363388062
3
train loss item: 0.5270050764083862
4
train loss item: 0.4109187424182892
5
train loss item: 0.3485221862792969
6
train loss item: 0.28633633255958557
7
train loss item: 0.6684998869895935
8
train loss item: 0.1386367529630661
9
train loss item: 0.2815357446670532
10
train loss item: 0.3708885908126831
11
train loss item: 0.25507423281669617
12
train loss item: 0.09555079787969589
13
train loss item: 0.47541677951812744
14
train loss item: 0.2414698451757431
15
train loss item: 0.5852376222610474
16
train loss item: 0.04379350692033768
17
train loss item: 0.3323310613632202
18
train loss item: 0.3726051151752472
19
train loss item: 0.2990677058696747
20
train loss item: 0.24196289479732513
21
train loss item: 0.10182896256446838
22
train loss item: 0.8521127104759216
23
train loss item: 0.8307023644447327
24
train loss item: 0.5995486974716187
25
train loss item: 0.14893047511577606
26
train loss item: 0.19939091801643372
27
train loss item: 0.2346339374780655
28
train loss item: 0.0407625287771225
29
train loss item: 0.6155321598052979
30
train loss item: 1.8417540788650513
31
train loss item: 0.6072666645050049
32
train loss item: 0.07972927391529083
33
train loss item: 0.4035583734512329
34
train loss item: 0.09128390997648239
35
train loss item: 2.0660929679870605
36
train loss item: 0.475405752658844
37
train loss item: 0.36866241693496704
38
train loss item: 0.4656376242637634
39
train loss item: 0.22130225598812103
40
train loss item: 0.14495687186717987
41
train loss item: 0.2704629600048065
42
train loss item: 0.2865421175956726
43
train loss item: 0.19158263504505157
44
train loss item: 0.5639021992683411
45
train loss item: 0.10260605812072754
46
train loss item: 0.1116359755396843
47
train loss item: 0.3629855215549469
48
train loss item: 0.24400745332241058
49
train loss item: 0.15388405323028564
50
train loss item: 0.3382885456085205
51
train loss item: 0.8007329702377319
52
train loss item: 0.046603940427303314
53
train loss item: 0.14145398139953613
54
train loss item: 1.9239106178283691
55
train loss item: 0.22656768560409546
56
train loss item: 0.26861727237701416
57
train loss item: 0.24148570001125336
58
train loss item: 0.1678100973367691
59
train loss item: 0.0921117439866066
60
train loss item: 0.7913806438446045
61
train loss item: 1.7910782098770142
62
train loss item: 0.22012196481227875
63
train loss item: 0.3815497159957886
64
train loss item: 0.16115230321884155
65
train loss item: 0.6429188251495361
66
train loss item: 0.41251179575920105
67
train loss item: 0.19826894998550415
68
train loss item: 0.33982768654823303
69
train loss item: 0.3775721490383148
70
train loss item: 0.26714253425598145
71
train loss item: 0.11489956825971603
72
train loss item: 0.18995903432369232
73
train loss item: 0.33330008387565613
74
train loss item: 0.04343221336603165
75
train loss item: 0.08968770503997803
76
train loss item: 0.8356032967567444
77
train loss item: 1.0768102407455444
78
train loss item: 0.04575669765472412
79
train loss item: 0.2566321790218353
80
train loss item: 0.09515378624200821
81
train loss item: 0.18718181550502777
82
train loss item: 0.20098288357257843
83
train loss item: 0.5125114917755127
84
train loss item: 0.37825143337249756
85
train loss item: 0.5974166989326477
86
train loss item: 3.758740186691284
87
train loss item: 0.1471472829580307
88
train loss item: 0.3704409599304199
epoch train loss: 0.44352288887407004
testing phase
test loss item: 0.19521944224834442
test loss item: 0.08453968167304993
test loss item: 0.7110673189163208
test loss item: 0.23832595348358154
test loss item: 0.27779847383499146
test loss item: 0.12321002781391144
test loss item: 1.9436297416687012
test loss item: 0.5445082187652588
test loss item: 0.25122499465942383
test loss item: 0.4598222076892853
test loss item: 0.9943366050720215
test loss item: 0.17461305856704712
test loss item: 0.19022426009178162
test loss item: 0.375868022441864
test loss item: 0.18385542929172516
test loss item: 0.05851079151034355
test loss item: 0.3534005284309387
test loss item: 0.5635436773300171
test loss item: 0.7286943793296814
test loss item: 0.34576553106307983
test loss item: 0.9163162708282471
test loss item: 0.4217260181903839
test loss item: 0.34291166067123413
test loss item: 0.20076243579387665
test loss item: 0.26473328471183777
test loss item: 0.26789146661758423
test loss item: 0.3999125063419342
test loss item: 0.2069730907678604
test loss item: 0.3985264003276825
test loss item: 0.4081103503704071
test loss item: 0.8929719924926758
test loss item: 0.05607519671320915
test loss item: 0.16798165440559387
test loss item: 0.6847419738769531
test loss item: 0.52842116355896
test loss item: 0.4526427388191223
test loss item: 0.9021415114402771
test loss item: 1.6768853664398193
test loss item: 0.5830086469650269
test loss item: 0.3278777003288269
test loss item: 0.3548029959201813
test loss item: 0.20660047233104706
test loss item: 0.4043656587600708
test loss item: 0.23903675377368927
test loss item: 0.7374075055122375
test loss item: 0.53487628698349
test loss item: 0.3410762846469879
test loss item: 0.27797767519950867
test loss item: 0.5501733422279358
test loss item: 0.7836746573448181
test loss item: 0.3426428735256195
test loss item: 0.13878212869167328
test loss item: 0.2722937762737274
test loss item: 0.1554526388645172
test loss item: 0.35117512941360474
test loss item: 1.0491726398468018
test loss item: 0.598822295665741
test loss item: 0.2971481382846832
test loss item: 0.27481767535209656
test loss item: 0.21933412551879883
test loss item: 0.5178089141845703
test loss item: 0.264507919549942
test loss item: 0.2589048147201538
test loss item: 0.3005743622779846
test loss item: 1.0346258878707886
test loss item: 0.3206515312194824
test loss item: 0.37486883997917175
test loss item: 0.3069538474082947
test loss item: 0.6366866827011108
test loss item: 0.42694738507270813
test loss item: 0.05696093291044235
test loss item: 1.1169655323028564
test loss item: 0.3702167272567749
test loss item: 0.4851912558078766
test loss item: 0.1734960675239563
test loss item: 0.18594658374786377
test loss item: 0.19891120493412018
test loss item: 1.69961678981781
test loss item: 0.5530273914337158
test loss item: 0.21626634895801544
test loss item: 0.07875978201627731
test loss item: 1.0769891738891602
test loss item: 0.9952171444892883
test loss item: 1.1437121629714966
test loss item: 0.2605683505535126
test loss item: 0.2566162049770355
test loss item: 0.06818954646587372
test loss item: 0.058804042637348175
test loss item: 0.17959800362586975
Epoch [58/100], Training Loss: 0.4435, Testing Loss: 0.4567
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 59/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4434393048286438
1
train loss item: 1.0655969381332397
2
train loss item: 0.23812370002269745
3
train loss item: 0.5214772820472717
4
train loss item: 0.40950098633766174
5
train loss item: 0.3486398756504059
6
train loss item: 0.2832225263118744
7
train loss item: 0.6571112871170044
8
train loss item: 0.13805769383907318
9
train loss item: 0.27801039814949036
10
train loss item: 0.3668329417705536
11
train loss item: 0.25557419657707214
12
train loss item: 0.09420743584632874
13
train loss item: 0.47320398688316345
14
train loss item: 0.24039462208747864
15
train loss item: 0.5727184414863586
16
train loss item: 0.042104341089725494
17
train loss item: 0.3283292055130005
18
train loss item: 0.3754773437976837
19
train loss item: 0.2927052080631256
20
train loss item: 0.2415163815021515
21
train loss item: 0.09738051146268845
22
train loss item: 0.8389396667480469
23
train loss item: 0.827079176902771
24
train loss item: 0.5857895016670227
25
train loss item: 0.14868509769439697
26
train loss item: 0.19756530225276947
27
train loss item: 0.22952769696712494
28
train loss item: 0.03935324773192406
29
train loss item: 0.5948386788368225
30
train loss item: 1.814447045326233
31
train loss item: 0.6065351963043213
32
train loss item: 0.07958835363388062
33
train loss item: 0.3983764350414276
34
train loss item: 0.09120989590883255
35
train loss item: 2.0425620079040527
36
train loss item: 0.4722084403038025
37
train loss item: 0.3671625554561615
38
train loss item: 0.4613613784313202
39
train loss item: 0.2191838175058365
40
train loss item: 0.14479582011699677
41
train loss item: 0.2683696448802948
42
train loss item: 0.28425806760787964
43
train loss item: 0.1908385455608368
44
train loss item: 0.5540552139282227
45
train loss item: 0.10237500071525574
46
train loss item: 0.11213576793670654
47
train loss item: 0.35807302594184875
48
train loss item: 0.24161022901535034
49
train loss item: 0.1506548970937729
50
train loss item: 0.3342042863368988
51
train loss item: 0.7849971652030945
52
train loss item: 0.0470283143222332
53
train loss item: 0.13975727558135986
54
train loss item: 1.8998124599456787
55
train loss item: 0.22405581176280975
56
train loss item: 0.2681232988834381
57
train loss item: 0.24125906825065613
58
train loss item: 0.1671440154314041
59
train loss item: 0.09320167452096939
60
train loss item: 0.769646406173706
61
train loss item: 1.7630183696746826
62
train loss item: 0.21577328443527222
63
train loss item: 0.375530481338501
64
train loss item: 0.16073642671108246
65
train loss item: 0.6405626535415649
66
train loss item: 0.410340815782547
67
train loss item: 0.19621697068214417
68
train loss item: 0.3332880437374115
69
train loss item: 0.37241920828819275
70
train loss item: 0.2638627290725708
71
train loss item: 0.11245711892843246
72
train loss item: 0.18799977004528046
73
train loss item: 0.32942745089530945
74
train loss item: 0.0443895049393177
75
train loss item: 0.09029849618673325
76
train loss item: 0.8226873874664307
77
train loss item: 1.0431214570999146
78
train loss item: 0.044686757028102875
79
train loss item: 0.2538641095161438
80
train loss item: 0.09649297595024109
81
train loss item: 0.18472601473331451
82
train loss item: 0.19819609820842743
83
train loss item: 0.505835771560669
84
train loss item: 0.3776995837688446
85
train loss item: 0.5879963040351868
86
train loss item: 3.7273614406585693
87
train loss item: 0.146694153547287
88
train loss item: 0.3708512485027313
epoch train loss: 0.43832549122109843
testing phase
test loss item: 0.19741666316986084
test loss item: 0.08745905756950378
test loss item: 0.72963947057724
test loss item: 0.23859600722789764
test loss item: 0.2812310755252838
test loss item: 0.12629146873950958
test loss item: 1.935505986213684
test loss item: 0.5545278787612915
test loss item: 0.25749099254608154
test loss item: 0.46756264567375183
test loss item: 1.01010262966156
test loss item: 0.17349156737327576
test loss item: 0.1937147080898285
test loss item: 0.3744836449623108
test loss item: 0.1861712634563446
test loss item: 0.060915324836969376
test loss item: 0.35548490285873413
test loss item: 0.5767545700073242
test loss item: 0.7290400266647339
test loss item: 0.3471162021160126
test loss item: 0.9356250762939453
test loss item: 0.4239208698272705
test loss item: 0.3489786684513092
test loss item: 0.20130674540996552
test loss item: 0.2678283154964447
test loss item: 0.26815471053123474
test loss item: 0.4024258255958557
test loss item: 0.2099774032831192
test loss item: 0.3992922604084015
test loss item: 0.4127945899963379
test loss item: 0.9039129614830017
test loss item: 0.057626545429229736
test loss item: 0.16895996034145355
test loss item: 0.6982076168060303
test loss item: 0.5399754047393799
test loss item: 0.45867645740509033
test loss item: 0.903254508972168
test loss item: 1.7138478755950928
test loss item: 0.5896574854850769
test loss item: 0.32836055755615234
test loss item: 0.3541198670864105
test loss item: 0.20620578527450562
test loss item: 0.4155673086643219
test loss item: 0.23929713666439056
test loss item: 0.7497056722640991
test loss item: 0.5362188816070557
test loss item: 0.3446800708770752
test loss item: 0.27895286679267883
test loss item: 0.5617952346801758
test loss item: 0.7974808216094971
test loss item: 0.34913259744644165
test loss item: 0.14174959063529968
test loss item: 0.2748453915119171
test loss item: 0.15691249072551727
test loss item: 0.35919487476348877
test loss item: 1.0742664337158203
test loss item: 0.6077738404273987
test loss item: 0.30257901549339294
test loss item: 0.2775997519493103
test loss item: 0.22186315059661865
test loss item: 0.5295189619064331
test loss item: 0.26901254057884216
test loss item: 0.25999152660369873
test loss item: 0.2992512583732605
test loss item: 1.0570998191833496
test loss item: 0.32015445828437805
test loss item: 0.37944918870925903
test loss item: 0.3056366741657257
test loss item: 0.6462888121604919
test loss item: 0.4317488670349121
test loss item: 0.056095775216817856
test loss item: 1.1145501136779785
test loss item: 0.3765045702457428
test loss item: 0.48855212330818176
test loss item: 0.17479369044303894
test loss item: 0.18678507208824158
test loss item: 0.19907671213150024
test loss item: 1.7402637004852295
test loss item: 0.5571326017379761
test loss item: 0.21738480031490326
test loss item: 0.08052482455968857
test loss item: 1.0927586555480957
test loss item: 1.0027107000350952
test loss item: 1.1729918718338013
test loss item: 0.2612902522087097
test loss item: 0.2588083744049072
test loss item: 0.07123644649982452
test loss item: 0.06196128576993942
test loss item: 0.17582131922245026
Epoch [59/100], Training Loss: 0.4383, Testing Loss: 0.4624
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 60/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4311041533946991
1
train loss item: 1.0671440362930298
2
train loss item: 0.23850391805171967
3
train loss item: 0.5224335193634033
4
train loss item: 0.40731555223464966
5
train loss item: 0.3389081656932831
6
train loss item: 0.2837068438529968
7
train loss item: 0.6507202386856079
8
train loss item: 0.13897374272346497
9
train loss item: 0.28264275193214417
10
train loss item: 0.3616800308227539
11
train loss item: 0.2467731386423111
12
train loss item: 0.09354394674301147
13
train loss item: 0.47216731309890747
14
train loss item: 0.24064509570598602
15
train loss item: 0.5752842426300049
16
train loss item: 0.041395336389541626
17
train loss item: 0.3276873826980591
18
train loss item: 0.3488241136074066
19
train loss item: 0.29541367292404175
20
train loss item: 0.24966078996658325
21
train loss item: 0.0916675329208374
22
train loss item: 0.8343600630760193
23
train loss item: 0.814729630947113
24
train loss item: 0.5875251293182373
25
train loss item: 0.1465107947587967
26
train loss item: 0.1965753138065338
27
train loss item: 0.2353506088256836
28
train loss item: 0.03889463096857071
29
train loss item: 0.6031103730201721
30
train loss item: 1.7869164943695068
31
train loss item: 0.5685481429100037
32
train loss item: 0.07821212708950043
33
train loss item: 0.405193030834198
34
train loss item: 0.08598954975605011
35
train loss item: 2.0181732177734375
36
train loss item: 0.46795064210891724
37
train loss item: 0.34828662872314453
38
train loss item: 0.43199673295021057
39
train loss item: 0.21731308102607727
40
train loss item: 0.14498652517795563
41
train loss item: 0.2637370824813843
42
train loss item: 0.27972573041915894
43
train loss item: 0.19076590240001678
44
train loss item: 0.5604774951934814
45
train loss item: 0.10321017354726791
46
train loss item: 0.10775545239448547
47
train loss item: 0.35513433814048767
48
train loss item: 0.24633757770061493
49
train loss item: 0.14763982594013214
50
train loss item: 0.33587852120399475
51
train loss item: 0.7853876948356628
52
train loss item: 0.04624204337596893
53
train loss item: 0.1460087150335312
54
train loss item: 1.876767873764038
55
train loss item: 0.22874827682971954
56
train loss item: 0.25047752261161804
57
train loss item: 0.24170194566249847
58
train loss item: 0.16635385155677795
59
train loss item: 0.09446002542972565
60
train loss item: 0.7941848635673523
61
train loss item: 1.7432289123535156
62
train loss item: 0.21401028335094452
63
train loss item: 0.372679740190506
64
train loss item: 0.1626776158809662
65
train loss item: 0.6159220337867737
66
train loss item: 0.39947640895843506
67
train loss item: 0.19716253876686096
68
train loss item: 0.34188520908355713
69
train loss item: 0.36250436305999756
70
train loss item: 0.2592688500881195
71
train loss item: 0.10995623469352722
72
train loss item: 0.19267351925373077
73
train loss item: 0.3326072692871094
74
train loss item: 0.046077657490968704
75
train loss item: 0.09084130823612213
76
train loss item: 0.837020754814148
77
train loss item: 1.0438233613967896
78
train loss item: 0.04383591189980507
79
train loss item: 0.2507419288158417
80
train loss item: 0.09230758249759674
81
train loss item: 0.18450325727462769
82
train loss item: 0.2004183530807495
83
train loss item: 0.4962199628353119
84
train loss item: 0.3637945055961609
85
train loss item: 0.6069676876068115
86
train loss item: 3.687898874282837
87
train loss item: 0.1550120860338211
88
train loss item: 0.3797726035118103
epoch train loss: 0.4350685613711229
testing phase
test loss item: 0.19621188938617706
test loss item: 0.08545415103435516
test loss item: 0.6951782703399658
test loss item: 0.23574817180633545
test loss item: 0.2770799994468689
test loss item: 0.12269213050603867
test loss item: 1.8828761577606201
test loss item: 0.5192078948020935
test loss item: 0.2444906085729599
test loss item: 0.45038196444511414
test loss item: 0.976900041103363
test loss item: 0.1700289398431778
test loss item: 0.18816307187080383
test loss item: 0.3679772615432739
test loss item: 0.18361683189868927
test loss item: 0.06192544102668762
test loss item: 0.34439435601234436
test loss item: 0.5561760067939758
test loss item: 0.7067572474479675
test loss item: 0.33037081360816956
test loss item: 0.9162031412124634
test loss item: 0.40900325775146484
test loss item: 0.34280845522880554
test loss item: 0.19516611099243164
test loss item: 0.26351356506347656
test loss item: 0.26390817761421204
test loss item: 0.3884319067001343
test loss item: 0.20596802234649658
test loss item: 0.3920886814594269
test loss item: 0.39868712425231934
test loss item: 0.8740566372871399
test loss item: 0.056428633630275726
test loss item: 0.16310925781726837
test loss item: 0.6827892661094666
test loss item: 0.5196855068206787
test loss item: 0.439165860414505
test loss item: 0.8759363889694214
test loss item: 1.6519219875335693
test loss item: 0.5747589468955994
test loss item: 0.3173268437385559
test loss item: 0.34690412878990173
test loss item: 0.20378854870796204
test loss item: 0.40700215101242065
test loss item: 0.23465493321418762
test loss item: 0.7392681241035461
test loss item: 0.5124586820602417
test loss item: 0.3401876986026764
test loss item: 0.2686867117881775
test loss item: 0.5371835827827454
test loss item: 0.7631603479385376
test loss item: 0.3420599699020386
test loss item: 0.13937659561634064
test loss item: 0.2694186568260193
test loss item: 0.15603074431419373
test loss item: 0.34936749935150146
test loss item: 1.02211594581604
test loss item: 0.5866027474403381
test loss item: 0.3014839291572571
test loss item: 0.26945796608924866
test loss item: 0.21949300169944763
test loss item: 0.5067379474639893
test loss item: 0.25248581171035767
test loss item: 0.2525068521499634
test loss item: 0.29339122772216797
test loss item: 1.0122684240341187
test loss item: 0.3188050389289856
test loss item: 0.3612368404865265
test loss item: 0.3008504807949066
test loss item: 0.6331876516342163
test loss item: 0.40618452429771423
test loss item: 0.059462856501340866
test loss item: 1.0738624334335327
test loss item: 0.36810198426246643
test loss item: 0.47082188725471497
test loss item: 0.17088399827480316
test loss item: 0.1838962584733963
test loss item: 0.19405613839626312
test loss item: 1.6907824277877808
test loss item: 0.543934166431427
test loss item: 0.21388711035251617
test loss item: 0.08307094126939774
test loss item: 1.0510485172271729
test loss item: 0.9686455726623535
test loss item: 1.1249552965164185
test loss item: 0.2544039785861969
test loss item: 0.25484025478363037
test loss item: 0.0742080956697464
test loss item: 0.06078594923019409
test loss item: 0.18774710595607758
Epoch [60/100], Training Loss: 0.4351, Testing Loss: 0.4483
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 61/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46947625279426575
1
train loss item: 1.0571112632751465
2
train loss item: 0.2402033805847168
3
train loss item: 0.5802181363105774
4
train loss item: 0.43182119727134705
5
train loss item: 0.3568986654281616
6
train loss item: 0.28038179874420166
7
train loss item: 0.6502905488014221
8
train loss item: 0.13485805690288544
9
train loss item: 0.2867514193058014
10
train loss item: 0.38371026515960693
11
train loss item: 0.2761479616165161
12
train loss item: 0.09686099737882614
13
train loss item: 0.4811747968196869
14
train loss item: 0.24208897352218628
15
train loss item: 0.599967896938324
16
train loss item: 0.04961072653532028
17
train loss item: 0.31854209303855896
18
train loss item: 0.39945271611213684
19
train loss item: 0.28429165482521057
20
train loss item: 0.23753109574317932
21
train loss item: 0.09896209090948105
22
train loss item: 0.8725780248641968
23
train loss item: 0.8303081393241882
24
train loss item: 0.6110442876815796
25
train loss item: 0.16124604642391205
26
train loss item: 0.19773417711257935
27
train loss item: 0.22496889531612396
28
train loss item: 0.046788983047008514
29
train loss item: 0.5958369970321655
30
train loss item: 1.7603356838226318
31
train loss item: 0.6624635457992554
32
train loss item: 0.08517570048570633
33
train loss item: 0.4094223976135254
34
train loss item: 0.09441377967596054
35
train loss item: 2.0053563117980957
36
train loss item: 0.48447632789611816
37
train loss item: 0.3883010447025299
38
train loss item: 0.5159429311752319
39
train loss item: 0.22583989799022675
40
train loss item: 0.15039922297000885
41
train loss item: 0.2934390604496002
42
train loss item: 0.28582656383514404
43
train loss item: 0.19617673754692078
44
train loss item: 0.5533153414726257
45
train loss item: 0.0992564931511879
46
train loss item: 0.11928414553403854
47
train loss item: 0.36279749870300293
48
train loss item: 0.23466642200946808
49
train loss item: 0.15568193793296814
50
train loss item: 0.3362424373626709
51
train loss item: 0.7692946195602417
52
train loss item: 0.04877917096018791
53
train loss item: 0.13358531892299652
54
train loss item: 1.8588298559188843
55
train loss item: 0.21476398408412933
56
train loss item: 0.2863902747631073
57
train loss item: 0.2479206919670105
58
train loss item: 0.17245112359523773
59
train loss item: 0.09229511767625809
60
train loss item: 0.7399283051490784
61
train loss item: 1.7142584323883057
62
train loss item: 0.2120591551065445
63
train loss item: 0.3746032118797302
64
train loss item: 0.16405709087848663
65
train loss item: 0.7056272625923157
66
train loss item: 0.4225155711174011
67
train loss item: 0.19524899125099182
68
train loss item: 0.3133695721626282
69
train loss item: 0.3967880606651306
70
train loss item: 0.2797872722148895
71
train loss item: 0.11348367482423782
72
train loss item: 0.1780773103237152
73
train loss item: 0.3262173533439636
74
train loss item: 0.04707901179790497
75
train loss item: 0.08562047779560089
76
train loss item: 0.802551805973053
77
train loss item: 0.9927537441253662
78
train loss item: 0.05188967287540436
79
train loss item: 0.26169049739837646
80
train loss item: 0.1089814230799675
81
train loss item: 0.18141721189022064
82
train loss item: 0.19480082392692566
83
train loss item: 0.5166898369789124
84
train loss item: 0.39627406001091003
85
train loss item: 0.5761298537254333
86
train loss item: 3.673313617706299
87
train loss item: 0.150236576795578
88
train loss item: 0.4208488464355469
epoch train loss: 0.44198067306300226
testing phase
test loss item: 0.21743138134479523
test loss item: 0.13438273966312408
test loss item: 0.8110395669937134
test loss item: 0.26730939745903015
test loss item: 0.31932535767555237
test loss item: 0.19191910326480865
test loss item: 1.9567691087722778
test loss item: 0.5591580867767334
test loss item: 0.3071744441986084
test loss item: 0.5132215023040771
test loss item: 1.1140360832214355
test loss item: 0.19012829661369324
test loss item: 0.19717851281166077
test loss item: 0.38837578892707825
test loss item: 0.22056040167808533
test loss item: 0.09385911375284195
test loss item: 0.3649727702140808
test loss item: 0.6291357278823853
test loss item: 0.7355402112007141
test loss item: 0.36357322335243225
test loss item: 0.986120343208313
test loss item: 0.4349101185798645
test loss item: 0.3715238869190216
test loss item: 0.23820340633392334
test loss item: 0.2820116877555847
test loss item: 0.27787306904792786
test loss item: 0.44067203998565674
test loss item: 0.2490285038948059
test loss item: 0.42461785674095154
test loss item: 0.4438380002975464
test loss item: 0.9851967096328735
test loss item: 0.09483566880226135
test loss item: 0.20865894854068756
test loss item: 0.7610569596290588
test loss item: 0.5891903042793274
test loss item: 0.5195533633232117
test loss item: 0.9148244857788086
test loss item: 1.9112070798873901
test loss item: 0.6329739689826965
test loss item: 0.36473944783210754
test loss item: 0.3651098310947418
test loss item: 0.22185243666172028
test loss item: 0.46896517276763916
test loss item: 0.2598210275173187
test loss item: 0.7856271862983704
test loss item: 0.5435358285903931
test loss item: 0.3577556610107422
test loss item: 0.2943211495876312
test loss item: 0.6115872859954834
test loss item: 0.8951350450515747
test loss item: 0.38292521238327026
test loss item: 0.14733819663524628
test loss item: 0.29465416073799133
test loss item: 0.1794595867395401
test loss item: 0.38886743783950806
test loss item: 1.1906670331954956
test loss item: 0.6466441750526428
test loss item: 0.31237316131591797
test loss item: 0.2945334315299988
test loss item: 0.23428086936473846
test loss item: 0.5994387269020081
test loss item: 0.27934321761131287
test loss item: 0.26907557249069214
test loss item: 0.30313360691070557
test loss item: 1.1254959106445312
test loss item: 0.33555474877357483
test loss item: 0.39674249291419983
test loss item: 0.31285226345062256
test loss item: 0.677804172039032
test loss item: 0.4789464473724365
test loss item: 0.08887393772602081
test loss item: 1.1127263307571411
test loss item: 0.3994377851486206
test loss item: 0.5195107460021973
test loss item: 0.19237416982650757
test loss item: 0.20061948895454407
test loss item: 0.23102104663848877
test loss item: 1.9007481336593628
test loss item: 0.587444007396698
test loss item: 0.252750962972641
test loss item: 0.12091219425201416
test loss item: 1.187058925628662
test loss item: 1.0589206218719482
test loss item: 1.3089436292648315
test loss item: 0.27651330828666687
test loss item: 0.2845858335494995
test loss item: 0.11370119452476501
test loss item: 0.10405676811933517
test loss item: 0.2107774168252945
Epoch [61/100], Training Loss: 0.4420, Testing Loss: 0.5001
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 62/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.43762943148612976
1
train loss item: 1.2629541158676147
2
train loss item: 0.25416100025177
3
train loss item: 0.7114754915237427
4
train loss item: 0.440878689289093
5
train loss item: 0.34060224890708923
6
train loss item: 0.2863239645957947
7
train loss item: 0.7225645184516907
8
train loss item: 0.14860625565052032
9
train loss item: 0.3464451730251312
10
train loss item: 0.42602187395095825
11
train loss item: 0.24511295557022095
12
train loss item: 0.09477811306715012
13
train loss item: 0.5424177646636963
14
train loss item: 0.2643372714519501
15
train loss item: 0.6663793325424194
16
train loss item: 0.042662911117076874
17
train loss item: 0.33303049206733704
18
train loss item: 0.3744358420372009
19
train loss item: 0.31773683428764343
20
train loss item: 0.25480416417121887
21
train loss item: 0.10126551985740662
22
train loss item: 0.9454026818275452
23
train loss item: 0.8923195600509644
24
train loss item: 0.6520834565162659
25
train loss item: 0.16794973611831665
26
train loss item: 0.19905367493629456
27
train loss item: 0.28714656829833984
28
train loss item: 0.03960490971803665
29
train loss item: 0.7639569044113159
30
train loss item: 1.9229509830474854
31
train loss item: 0.6118307709693909
32
train loss item: 0.0873723104596138
33
train loss item: 0.5370368957519531
34
train loss item: 0.07809814065694809
35
train loss item: 2.0362706184387207
36
train loss item: 0.5444796085357666
37
train loss item: 0.32703399658203125
38
train loss item: 0.5402023792266846
39
train loss item: 0.2498713731765747
40
train loss item: 0.15411369502544403
41
train loss item: 0.3249351978302002
42
train loss item: 0.2894253432750702
43
train loss item: 0.2147340625524521
44
train loss item: 0.6675928235054016
45
train loss item: 0.114776112139225
46
train loss item: 0.11028230935335159
47
train loss item: 0.3727846145629883
48
train loss item: 0.27756255865097046
49
train loss item: 0.16842032968997955
50
train loss item: 0.34861594438552856
51
train loss item: 0.9358659982681274
52
train loss item: 0.047372762113809586
53
train loss item: 0.18122275173664093
54
train loss item: 1.891385555267334
55
train loss item: 0.24495375156402588
56
train loss item: 0.2812469005584717
57
train loss item: 0.2642907500267029
58
train loss item: 0.17725445330142975
59
train loss item: 0.09430643171072006
60
train loss item: 1.0189791917800903
61
train loss item: 1.9075959920883179
62
train loss item: 0.22246761620044708
63
train loss item: 0.3947589099407196
64
train loss item: 0.19885268807411194
65
train loss item: 0.6108111143112183
66
train loss item: 0.45523959398269653
67
train loss item: 0.22102922201156616
68
train loss item: 0.3638977110385895
69
train loss item: 0.39267390966415405
70
train loss item: 0.27603602409362793
71
train loss item: 0.10729597508907318
72
train loss item: 0.2263726443052292
73
train loss item: 0.36816173791885376
74
train loss item: 0.051263369619846344
75
train loss item: 0.09295893460512161
76
train loss item: 0.9503946304321289
77
train loss item: 1.1788793802261353
78
train loss item: 0.04410140588879585
79
train loss item: 0.26599496603012085
80
train loss item: 0.10094653069972992
81
train loss item: 0.19610334932804108
82
train loss item: 0.2300146073102951
83
train loss item: 0.6152040958404541
84
train loss item: 0.410908043384552
85
train loss item: 0.7234066724777222
86
train loss item: 3.698587656021118
87
train loss item: 0.20579838752746582
88
train loss item: 0.393343061208725
epoch train loss: 0.47843267751878565
testing phase
test loss item: 0.2035723626613617
test loss item: 0.08895966410636902
test loss item: 0.7845551371574402
test loss item: 0.24640120565891266
test loss item: 0.2967325448989868
test loss item: 0.12468273937702179
test loss item: 2.0038087368011475
test loss item: 0.543170690536499
test loss item: 0.2904709577560425
test loss item: 0.5073347687721252
test loss item: 1.10568106174469
test loss item: 0.17980965971946716
test loss item: 0.19803974032402039
test loss item: 0.39522096514701843
test loss item: 0.1984485685825348
test loss item: 0.06443986296653748
test loss item: 0.36073294281959534
test loss item: 0.619972288608551
test loss item: 0.7310264110565186
test loss item: 0.359101802110672
test loss item: 0.9910745024681091
test loss item: 0.4297594130039215
test loss item: 0.3749520480632782
test loss item: 0.2080775499343872
test loss item: 0.27719464898109436
test loss item: 0.2732853293418884
test loss item: 0.426382839679718
test loss item: 0.21835541725158691
test loss item: 0.4182310998439789
test loss item: 0.43695327639579773
test loss item: 0.9919059872627258
test loss item: 0.06600436568260193
test loss item: 0.17424727976322174
test loss item: 0.7319639921188354
test loss item: 0.5778191685676575
test loss item: 0.5037882328033447
test loss item: 0.9206433892250061
test loss item: 1.888330101966858
test loss item: 0.6256596446037292
test loss item: 0.33843421936035156
test loss item: 0.3635011911392212
test loss item: 0.21650882065296173
test loss item: 0.4584592282772064
test loss item: 0.24968920648097992
test loss item: 0.7993520498275757
test loss item: 0.5340200662612915
test loss item: 0.3656490445137024
test loss item: 0.2926100790500641
test loss item: 0.603655993938446
test loss item: 0.8713144659996033
test loss item: 0.3912253677845001
test loss item: 0.14229820668697357
test loss item: 0.2933374345302582
test loss item: 0.16600677371025085
test loss item: 0.38732436299324036
test loss item: 1.152522087097168
test loss item: 0.6363782286643982
test loss item: 0.3235272169113159
test loss item: 0.2912880778312683
test loss item: 0.2359226793050766
test loss item: 0.5840764045715332
test loss item: 0.26769936084747314
test loss item: 0.2661406099796295
test loss item: 0.30254244804382324
test loss item: 1.1035476922988892
test loss item: 0.32881155610084534
test loss item: 0.3910571336746216
test loss item: 0.3096499443054199
test loss item: 0.665432870388031
test loss item: 0.45970508456230164
test loss item: 0.05658797547221184
test loss item: 1.1262435913085938
test loss item: 0.409066379070282
test loss item: 0.5101354122161865
test loss item: 0.18142078816890717
test loss item: 0.19582904875278473
test loss item: 0.20631539821624756
test loss item: 1.9136801958084106
test loss item: 0.5904037952423096
test loss item: 0.22147169709205627
test loss item: 0.0799965113401413
test loss item: 1.189133882522583
test loss item: 1.0524463653564453
test loss item: 1.3077349662780762
test loss item: 0.28042420744895935
test loss item: 0.2688271701335907
test loss item: 0.07309436798095703
test loss item: 0.06977415829896927
test loss item: 0.1800287663936615
Epoch [62/100], Training Loss: 0.4784, Testing Loss: 0.4892
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 63/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4330747425556183
1
train loss item: 1.1306490898132324
2
train loss item: 0.23923951387405396
3
train loss item: 0.5905305743217468
4
train loss item: 0.40816500782966614
5
train loss item: 0.3374692499637604
6
train loss item: 0.276081919670105
7
train loss item: 0.6758185625076294
8
train loss item: 0.13494007289409637
9
train loss item: 0.2894289195537567
10
train loss item: 0.37439966201782227
11
train loss item: 0.24389508366584778
12
train loss item: 0.09570975601673126
13
train loss item: 0.48734185099601746
14
train loss item: 0.25002342462539673
15
train loss item: 0.5928167104721069
16
train loss item: 0.042211443185806274
17
train loss item: 0.3200855851173401
18
train loss item: 0.33867958188056946
19
train loss item: 0.2895371913909912
20
train loss item: 0.22732199728488922
21
train loss item: 0.10136398673057556
22
train loss item: 0.8540405035018921
23
train loss item: 0.8320549726486206
24
train loss item: 0.6084743738174438
25
train loss item: 0.15237948298454285
26
train loss item: 0.1936194896697998
27
train loss item: 0.23457342386245728
28
train loss item: 0.03903637081384659
29
train loss item: 0.6604142189025879
30
train loss item: 1.8240129947662354
31
train loss item: 0.5743762850761414
32
train loss item: 0.08563106507062912
33
train loss item: 0.4404674172401428
34
train loss item: 0.08249139040708542
35
train loss item: 2.016469955444336
36
train loss item: 0.4821205735206604
37
train loss item: 0.3440301716327667
38
train loss item: 0.4382707178592682
39
train loss item: 0.2155119627714157
40
train loss item: 0.14348937571048737
41
train loss item: 0.27668336033821106
42
train loss item: 0.2804998457431793
43
train loss item: 0.1899213045835495
44
train loss item: 0.5894805788993835
45
train loss item: 0.10474234819412231
46
train loss item: 0.10622571408748627
47
train loss item: 0.348363995552063
48
train loss item: 0.24468275904655457
49
train loss item: 0.15630626678466797
50
train loss item: 0.32848086953163147
51
train loss item: 0.8416940569877625
52
train loss item: 0.046241290867328644
53
train loss item: 0.14166507124900818
54
train loss item: 1.8725066184997559
55
train loss item: 0.2301722764968872
56
train loss item: 0.2506335377693176
57
train loss item: 0.24623622000217438
58
train loss item: 0.16298843920230865
59
train loss item: 0.09218287467956543
60
train loss item: 0.9052479267120361
61
train loss item: 1.7958612442016602
62
train loss item: 0.2091611921787262
63
train loss item: 0.3709338903427124
64
train loss item: 0.16704513132572174
65
train loss item: 0.6023451685905457
66
train loss item: 0.40967321395874023
67
train loss item: 0.19574034214019775
68
train loss item: 0.316120445728302
69
train loss item: 0.3618505895137787
70
train loss item: 0.2548103332519531
71
train loss item: 0.10604868084192276
72
train loss item: 0.18784652650356293
73
train loss item: 0.33752018213272095
74
train loss item: 0.04935578629374504
75
train loss item: 0.08818888664245605
76
train loss item: 0.8725860118865967
77
train loss item: 1.0943721532821655
78
train loss item: 0.04594618082046509
79
train loss item: 0.24688827991485596
80
train loss item: 0.09282184392213821
81
train loss item: 0.18381966650485992
82
train loss item: 0.20570366084575653
83
train loss item: 0.5382823348045349
84
train loss item: 0.3760871887207031
85
train loss item: 0.6338327527046204
86
train loss item: 3.637050151824951
87
train loss item: 0.1560191959142685
88
train loss item: 0.36193785071372986
epoch train loss: 0.4428432911550731
testing phase
test loss item: 0.1972709745168686
test loss item: 0.09306050091981888
test loss item: 0.5656216144561768
test loss item: 0.2334243357181549
test loss item: 0.26167213916778564
test loss item: 0.1408265084028244
test loss item: 1.7614554166793823
test loss item: 0.4467504322528839
test loss item: 0.2129696011543274
test loss item: 0.41277074813842773
test loss item: 0.8526144623756409
test loss item: 0.1671953946352005
test loss item: 0.18274089694023132
test loss item: 0.366109699010849
test loss item: 0.1719641089439392
test loss item: 0.0694609209895134
test loss item: 0.333453506231308
test loss item: 0.5080909132957458
test loss item: 0.6695305705070496
test loss item: 0.32473260164260864
test loss item: 0.822420060634613
test loss item: 0.3833894729614258
test loss item: 0.3201175332069397
test loss item: 0.19039054214954376
test loss item: 0.24812667071819305
test loss item: 0.2607826888561249
test loss item: 0.3780438303947449
test loss item: 0.2083759307861328
test loss item: 0.37436643242836
test loss item: 0.3837093710899353
test loss item: 0.767801821231842
test loss item: 0.058793965727090836
test loss item: 0.1620541512966156
test loss item: 0.6047065854072571
test loss item: 0.4566999077796936
test loss item: 0.41120293736457825
test loss item: 0.8220608830451965
test loss item: 1.3768285512924194
test loss item: 0.5247454643249512
test loss item: 0.30913615226745605
test loss item: 0.3376041650772095
test loss item: 0.2090577930212021
test loss item: 0.37200048565864563
test loss item: 0.22499874234199524
test loss item: 0.6824119091033936
test loss item: 0.49365735054016113
test loss item: 0.3288987874984741
test loss item: 0.2741660475730896
test loss item: 0.4643497169017792
test loss item: 0.6809847354888916
test loss item: 0.31826895475387573
test loss item: 0.1426631361246109
test loss item: 0.2540469765663147
test loss item: 0.15086844563484192
test loss item: 0.31691932678222656
test loss item: 0.8538669347763062
test loss item: 0.5324047207832336
test loss item: 0.2821584641933441
test loss item: 0.2614361345767975
test loss item: 0.21039068698883057
test loss item: 0.4711248576641083
test loss item: 0.23106279969215393
test loss item: 0.24886254966259003
test loss item: 0.2883283197879791
test loss item: 0.8256064653396606
test loss item: 0.3145446479320526
test loss item: 0.34298545122146606
test loss item: 0.2949426472187042
test loss item: 0.553632915019989
test loss item: 0.37237897515296936
test loss item: 0.07469919323921204
test loss item: 1.0001487731933594
test loss item: 0.3562597334384918
test loss item: 0.45111212134361267
test loss item: 0.17369544506072998
test loss item: 0.18963806331157684
test loss item: 0.18920797109603882
test loss item: 1.3748042583465576
test loss item: 0.5154402852058411
test loss item: 0.22189053893089294
test loss item: 0.0885867178440094
test loss item: 0.9130061268806458
test loss item: 0.8999131917953491
test loss item: 0.9063400030136108
test loss item: 0.2510213851928711
test loss item: 0.2461278736591339
test loss item: 0.08293463289737701
test loss item: 0.0667593702673912
test loss item: 0.19780156016349792
Epoch [63/100], Training Loss: 0.4428, Testing Loss: 0.4109
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 64/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.5543935894966125
1
train loss item: 1.0767059326171875
2
train loss item: 0.2547597289085388
3
train loss item: 0.6062829494476318
4
train loss item: 0.5628294348716736
5
train loss item: 0.39284849166870117
6
train loss item: 0.2832288146018982
7
train loss item: 0.7142967581748962
8
train loss item: 0.15543094277381897
9
train loss item: 0.3758552670478821
10
train loss item: 0.5055818557739258
11
train loss item: 0.30431967973709106
12
train loss item: 0.10227621346712112
13
train loss item: 0.4897497892379761
14
train loss item: 0.25709494948387146
15
train loss item: 0.57496577501297
16
train loss item: 0.052555836737155914
17
train loss item: 0.3293631970882416
18
train loss item: 0.4764297306537628
19
train loss item: 0.2925669252872467
20
train loss item: 0.2269013226032257
21
train loss item: 0.13001975417137146
22
train loss item: 0.8767194151878357
23
train loss item: 0.8207511305809021
24
train loss item: 0.5947820544242859
25
train loss item: 0.2855987846851349
26
train loss item: 0.2275356948375702
27
train loss item: 0.289933443069458
28
train loss item: 0.05070078372955322
29
train loss item: 0.5952544808387756
30
train loss item: 1.6805607080459595
31
train loss item: 0.7512903809547424
32
train loss item: 0.11407861858606339
33
train loss item: 0.4515658915042877
34
train loss item: 0.11548203974962234
35
train loss item: 1.9707895517349243
36
train loss item: 0.5964656472206116
37
train loss item: 0.4342387914657593
38
train loss item: 0.7772002816200256
39
train loss item: 0.30439820885658264
40
train loss item: 0.17266777157783508
41
train loss item: 0.39799371361732483
42
train loss item: 0.30778995156288147
43
train loss item: 0.24655090272426605
44
train loss item: 0.5980584025382996
45
train loss item: 0.11394031345844269
46
train loss item: 0.14675401151180267
47
train loss item: 0.38840794563293457
48
train loss item: 0.2583615183830261
49
train loss item: 0.18513761460781097
50
train loss item: 0.3478788137435913
51
train loss item: 0.7804255485534668
52
train loss item: 0.04965776950120926
53
train loss item: 0.18519338965415955
54
train loss item: 1.8234596252441406
55
train loss item: 0.2125391811132431
56
train loss item: 0.39848119020462036
57
train loss item: 0.2595355808734894
58
train loss item: 0.21306398510932922
59
train loss item: 0.11775518953800201
60
train loss item: 0.7319130897521973
61
train loss item: 1.6427111625671387
62
train loss item: 0.2645470201969147
63
train loss item: 0.4035972058773041
64
train loss item: 0.21674661338329315
65
train loss item: 0.708690345287323
66
train loss item: 0.571096658706665
67
train loss item: 0.24214468896389008
68
train loss item: 0.3085483908653259
69
train loss item: 0.4167368412017822
70
train loss item: 0.3167453110218048
71
train loss item: 0.11474092304706573
72
train loss item: 0.2311515063047409
73
train loss item: 0.34718698263168335
74
train loss item: 0.05329599604010582
75
train loss item: 0.1034863293170929
76
train loss item: 0.8028373718261719
77
train loss item: 0.9697873592376709
78
train loss item: 0.055706094950437546
79
train loss item: 0.32149752974510193
80
train loss item: 0.1329275369644165
81
train loss item: 0.2008688598871231
82
train loss item: 0.2208319902420044
83
train loss item: 0.49796295166015625
84
train loss item: 0.4723336100578308
85
train loss item: 0.6074143648147583
86
train loss item: 3.55165696144104
87
train loss item: 0.20318129658699036
88
train loss item: 0.44384634494781494
epoch train loss: 0.4720634449733777
testing phase
test loss item: 0.230049729347229
test loss item: 0.1228494867682457
test loss item: 0.5642425417900085
test loss item: 0.23830251395702362
test loss item: 0.25253698229789734
test loss item: 0.13434180617332458
test loss item: 1.6814521551132202
test loss item: 0.4223059415817261
test loss item: 0.23759791254997253
test loss item: 0.4168599247932434
test loss item: 0.8487857580184937
test loss item: 0.16709904372692108
test loss item: 0.17634457349777222
test loss item: 0.3604046404361725
test loss item: 0.17653270065784454
test loss item: 0.19738242030143738
test loss item: 0.3277699947357178
test loss item: 0.5124151110649109
test loss item: 0.6495113372802734
test loss item: 0.3146689832210541
test loss item: 0.8162898421287537
test loss item: 0.37247249484062195
test loss item: 0.3124818205833435
test loss item: 0.19828085601329803
test loss item: 0.25126364827156067
test loss item: 0.2521097958087921
test loss item: 0.3895319402217865
test loss item: 0.20560841262340546
test loss item: 0.3703461289405823
test loss item: 0.38437193632125854
test loss item: 0.7469701170921326
test loss item: 0.2104692906141281
test loss item: 0.17305250465869904
test loss item: 0.6142332553863525
test loss item: 0.46826791763305664
test loss item: 0.4200851619243622
test loss item: 0.8008130788803101
test loss item: 1.3563741445541382
test loss item: 0.5202050805091858
test loss item: 0.3063277006149292
test loss item: 0.3470407724380493
test loss item: 0.19485130906105042
test loss item: 0.39371806383132935
test loss item: 0.22349248826503754
test loss item: 0.6776490211486816
test loss item: 0.48828455805778503
test loss item: 0.32171139121055603
test loss item: 0.2630305886268616
test loss item: 0.46229422092437744
test loss item: 0.6792442202568054
test loss item: 0.32430127263069153
test loss item: 0.13815248012542725
test loss item: 0.2547467350959778
test loss item: 0.1593930572271347
test loss item: 0.3190491497516632
test loss item: 0.8452785611152649
test loss item: 0.5325417518615723
test loss item: 0.2791176736354828
test loss item: 0.25959512591362
test loss item: 0.21213872730731964
test loss item: 0.4864307641983032
test loss item: 0.22457467019557953
test loss item: 0.24154792726039886
test loss item: 0.28328976035118103
test loss item: 0.792386531829834
test loss item: 0.31740400195121765
test loss item: 0.3327934741973877
test loss item: 0.28586649894714355
test loss item: 0.5451645255088806
test loss item: 0.3786652684211731
test loss item: 0.08228547871112823
test loss item: 0.9528453350067139
test loss item: 0.34717410802841187
test loss item: 0.43889230489730835
test loss item: 0.21270595490932465
test loss item: 0.18167142570018768
test loss item: 0.19425413012504578
test loss item: 1.3289146423339844
test loss item: 0.5032526850700378
test loss item: 0.21298857033252716
test loss item: 0.09595869481563568
test loss item: 0.8856706619262695
test loss item: 0.8897538781166077
test loss item: 0.8836512565612793
test loss item: 0.2440982460975647
test loss item: 0.2729083001613617
test loss item: 0.1747501641511917
test loss item: 0.22500969469547272
test loss item: 0.15835396945476532
Epoch [64/100], Training Loss: 0.4721, Testing Loss: 0.4129
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Epoch 65/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4591841995716095
1
train loss item: 1.0524436235427856
2
train loss item: 0.23332253098487854
3
train loss item: 0.5289834141731262
4
train loss item: 0.40936312079429626
5
train loss item: 0.35129955410957336
6
train loss item: 0.27089282870292664
7
train loss item: 0.6504649519920349
8
train loss item: 0.13059163093566895
9
train loss item: 0.26999178528785706
10
train loss item: 0.37177205085754395
11
train loss item: 0.27307772636413574
12
train loss item: 0.09906262159347534
13
train loss item: 0.46471038460731506
14
train loss item: 0.25007182359695435
15
train loss item: 0.5424841046333313
16
train loss item: 0.04892196133732796
17
train loss item: 0.316714346408844
18
train loss item: 0.35844123363494873
19
train loss item: 0.273593008518219
20
train loss item: 0.2177037000656128
21
train loss item: 0.10461721569299698
22
train loss item: 0.8023473620414734
23
train loss item: 0.7988103032112122
24
train loss item: 0.5644170641899109
25
train loss item: 0.17446096241474152
26
train loss item: 0.20194216072559357
27
train loss item: 0.22146593034267426
28
train loss item: 0.04529647156596184
29
train loss item: 0.568536102771759
30
train loss item: 1.6890411376953125
31
train loss item: 0.6117671728134155
32
train loss item: 0.07883911579847336
33
train loss item: 0.40412282943725586
34
train loss item: 0.09684961289167404
35
train loss item: 1.9479942321777344
36
train loss item: 0.5004307627677917
37
train loss item: 0.4043887257575989
38
train loss item: 0.5153185129165649
39
train loss item: 0.21998800337314606
40
train loss item: 0.1438143104314804
41
train loss item: 0.268781453371048
42
train loss item: 0.28180569410324097
43
train loss item: 0.18707382678985596
44
train loss item: 0.5461810827255249
45
train loss item: 0.10305668413639069
46
train loss item: 0.11002939194440842
47
train loss item: 0.34556135535240173
48
train loss item: 0.231357604265213
49
train loss item: 0.1474207639694214
50
train loss item: 0.32366445660591125
51
train loss item: 0.7591855525970459
52
train loss item: 0.04876658692955971
53
train loss item: 0.13461828231811523
54
train loss item: 1.807032823562622
55
train loss item: 0.2160426676273346
56
train loss item: 0.27618759870529175
57
train loss item: 0.2414766401052475
58
train loss item: 0.16599135100841522
59
train loss item: 0.08682820945978165
60
train loss item: 0.7860437631607056
61
train loss item: 1.676796555519104
62
train loss item: 0.21318934857845306
63
train loss item: 0.3759304881095886
64
train loss item: 0.15659074485301971
65
train loss item: 0.6378471851348877
66
train loss item: 0.46201151609420776
67
train loss item: 0.19459234178066254
68
train loss item: 0.2957227826118469
69
train loss item: 0.35356342792510986
70
train loss item: 0.2642689049243927
71
train loss item: 0.10791122168302536
72
train loss item: 0.17565563321113586
73
train loss item: 0.317755788564682
74
train loss item: 0.047544628381729126
75
train loss item: 0.08392401784658432
76
train loss item: 0.8170366287231445
77
train loss item: 0.9794151186943054
78
train loss item: 0.050939079374074936
79
train loss item: 0.2711698114871979
80
train loss item: 0.09538789093494415
81
train loss item: 0.18105344474315643
82
train loss item: 0.19795703887939453
83
train loss item: 0.47242894768714905
84
train loss item: 0.4170650839805603
85
train loss item: 0.5803015232086182
86
train loss item: 3.535217046737671
87
train loss item: 0.14251220226287842
88
train loss item: 0.36669883131980896
epoch train loss: 0.4292711417159338
testing phase
test loss item: 0.21199658513069153
test loss item: 0.11672899127006531
test loss item: 0.7587108016014099
test loss item: 0.24596147239208221
test loss item: 0.29774928092956543
test loss item: 0.14218834042549133
test loss item: 1.940988302230835
test loss item: 0.572349488735199
test loss item: 0.29715922474861145
test loss item: 0.508136510848999
test loss item: 1.0409221649169922
test loss item: 0.1766960173845291
test loss item: 0.1993391066789627
test loss item: 0.38844072818756104
test loss item: 0.2021392285823822
test loss item: 0.12499736249446869
test loss item: 0.36048367619514465
test loss item: 0.6230822801589966
test loss item: 0.7325621247291565
test loss item: 0.3570652902126312
test loss item: 0.9939256906509399
test loss item: 0.43054455518722534
test loss item: 0.37665581703186035
test loss item: 0.21308961510658264
test loss item: 0.27568167448043823
test loss item: 0.27214106917381287
test loss item: 0.42673248052597046
test loss item: 0.2260131537914276
test loss item: 0.4168098568916321
test loss item: 0.4375428557395935
test loss item: 0.9401859045028687
test loss item: 0.14557519555091858
test loss item: 0.1816590130329132
test loss item: 0.7227891087532043
test loss item: 0.5777459740638733
test loss item: 0.5025699138641357
test loss item: 0.9162923097610474
test loss item: 1.753172755241394
test loss item: 0.6174570918083191
test loss item: 0.3394487202167511
test loss item: 0.3614765405654907
test loss item: 0.20187003910541534
test loss item: 0.4659687876701355
test loss item: 0.2453741431236267
test loss item: 0.8022133708000183
test loss item: 0.5392637848854065
test loss item: 0.3634367883205414
test loss item: 0.28908753395080566
test loss item: 0.5992692112922668
test loss item: 0.8485970497131348
test loss item: 0.3976261615753174
test loss item: 0.14430831372737885
test loss item: 0.2924644649028778
test loss item: 0.1626746952533722
test loss item: 0.3885868191719055
test loss item: 1.0895406007766724
test loss item: 0.630478024482727
test loss item: 0.32948067784309387
test loss item: 0.2931729257106781
test loss item: 0.23890599608421326
test loss item: 0.5907518863677979
test loss item: 0.28107285499572754
test loss item: 0.2641567885875702
test loss item: 0.29819953441619873
test loss item: 1.040427565574646
test loss item: 0.32436978816986084
test loss item: 0.39336708188056946
test loss item: 0.3039666712284088
test loss item: 0.6405870914459229
test loss item: 0.4637046754360199
test loss item: 0.07379980385303497
test loss item: 1.1142796277999878
test loss item: 0.40643221139907837
test loss item: 0.5072488188743591
test loss item: 0.18117795884609222
test loss item: 0.18825271725654602
test loss item: 0.21157631278038025
test loss item: 1.7462655305862427
test loss item: 0.572567880153656
test loss item: 0.22431424260139465
test loss item: 0.0930921733379364
test loss item: 1.128891944885254
test loss item: 1.040342926979065
test loss item: 1.2017195224761963
test loss item: 0.27937883138656616
test loss item: 0.26884332299232483
test loss item: 0.15316519141197205
test loss item: 0.17204873263835907
test loss item: 0.16403359174728394
Epoch [65/100], Training Loss: 0.4293, Testing Loss: 0.4840
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 66/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4253978729248047
1
train loss item: 1.1069589853286743
2
train loss item: 0.25000935792922974
3
train loss item: 0.5937516093254089
4
train loss item: 0.4310269355773926
5
train loss item: 0.33796238899230957
6
train loss item: 0.2771150469779968
7
train loss item: 0.6613641381263733
8
train loss item: 0.14447811245918274
9
train loss item: 0.3169833719730377
10
train loss item: 0.385441392660141
11
train loss item: 0.2492939680814743
12
train loss item: 0.09447536617517471
13
train loss item: 0.5086332559585571
14
train loss item: 0.2609768211841583
15
train loss item: 0.5965891480445862
16
train loss item: 0.04419957473874092
17
train loss item: 0.3218420743942261
18
train loss item: 0.35181766748428345
19
train loss item: 0.2913458049297333
20
train loss item: 0.24834735691547394
21
train loss item: 0.08823992311954498
22
train loss item: 0.8477306365966797
23
train loss item: 0.8309739232063293
24
train loss item: 0.5913744568824768
25
train loss item: 0.16004911065101624
26
train loss item: 0.19154423475265503
27
train loss item: 0.2726360857486725
28
train loss item: 0.039837516844272614
29
train loss item: 0.6680379509925842
30
train loss item: 1.761734962463379
31
train loss item: 0.5704803466796875
32
train loss item: 0.07500489056110382
33
train loss item: 0.4900747835636139
34
train loss item: 0.07585732638835907
35
train loss item: 1.9466418027877808
36
train loss item: 0.47082391381263733
37
train loss item: 0.3408844470977783
38
train loss item: 0.42290791869163513
39
train loss item: 0.2351624220609665
40
train loss item: 0.15197281539440155
41
train loss item: 0.2959819734096527
42
train loss item: 0.2756817042827606
43
train loss item: 0.2046777307987213
44
train loss item: 0.6211646795272827
45
train loss item: 0.11330189555883408
46
train loss item: 0.10552941262722015
47
train loss item: 0.34968292713165283
48
train loss item: 0.2670276463031769
49
train loss item: 0.15650397539138794
50
train loss item: 0.3317272663116455
51
train loss item: 0.7964777946472168
52
train loss item: 0.04930625110864639
53
train loss item: 0.17099398374557495
54
train loss item: 1.801721453666687
55
train loss item: 0.2357545793056488
56
train loss item: 0.2605375349521637
57
train loss item: 0.2579617202281952
58
train loss item: 0.17147207260131836
59
train loss item: 0.08803948760032654
60
train loss item: 0.9249159097671509
61
train loss item: 1.7826882600784302
62
train loss item: 0.21252499520778656
63
train loss item: 0.3740469515323639
64
train loss item: 0.1878535896539688
65
train loss item: 0.5792903900146484
66
train loss item: 0.4114387333393097
67
train loss item: 0.20834733545780182
68
train loss item: 0.3316122591495514
69
train loss item: 0.36034277081489563
70
train loss item: 0.2529636323451996
71
train loss item: 0.10299434512853622
72
train loss item: 0.21632035076618195
73
train loss item: 0.34766995906829834
74
train loss item: 0.04780145362019539
75
train loss item: 0.08733458817005157
76
train loss item: 0.8923472166061401
77
train loss item: 1.0566740036010742
78
train loss item: 0.04629230499267578
79
train loss item: 0.2576771378517151
80
train loss item: 0.0991370677947998
81
train loss item: 0.18514108657836914
82
train loss item: 0.2262226641178131
83
train loss item: 0.5174856781959534
84
train loss item: 0.36607810854911804
85
train loss item: 0.6491386294364929
86
train loss item: 3.541811466217041
87
train loss item: 0.188455268740654
88
train loss item: 0.3529084026813507
epoch train loss: 0.4437195322151934
testing phase
test loss item: 0.19317112863063812
test loss item: 0.0909322202205658
test loss item: 0.801857590675354
test loss item: 0.23783250153064728
test loss item: 0.30412694811820984
test loss item: 0.12082671374082565
test loss item: 2.0539863109588623
test loss item: 0.6130960583686829
test loss item: 0.2966667115688324
test loss item: 0.5167150497436523
test loss item: 1.090946078300476
test loss item: 0.1733749955892563
test loss item: 0.20025959610939026
test loss item: 0.3862527310848236
test loss item: 0.20010508596897125
test loss item: 0.06298968195915222
test loss item: 0.36001458764076233
test loss item: 0.6355708241462708
test loss item: 0.7519251704216003
test loss item: 0.356176495552063
test loss item: 1.027880311012268
test loss item: 0.4451817572116852
test loss item: 0.38491129875183105
test loss item: 0.20207229256629944
test loss item: 0.27595606446266174
test loss item: 0.27091217041015625
test loss item: 0.42025026679039
test loss item: 0.2203153669834137
test loss item: 0.421580970287323
test loss item: 0.43687567114830017
test loss item: 1.002737283706665
test loss item: 0.05716964602470398
test loss item: 0.16259804368019104
test loss item: 0.7462930679321289
test loss item: 0.5929533243179321
test loss item: 0.5055677890777588
test loss item: 0.9473907947540283
test loss item: 1.863500714302063
test loss item: 0.6364352703094482
test loss item: 0.3411658704280853
test loss item: 0.36052119731903076
test loss item: 0.19580011069774628
test loss item: 0.4673517942428589
test loss item: 0.24429717659950256
test loss item: 0.822688639163971
test loss item: 0.537692666053772
test loss item: 0.36533546447753906
test loss item: 0.28333672881126404
test loss item: 0.6250184774398804
test loss item: 0.8792180418968201
test loss item: 0.40388110280036926
test loss item: 0.13584621250629425
test loss item: 0.2942216992378235
test loss item: 0.15405897796154022
test loss item: 0.39717477560043335
test loss item: 1.1485874652862549
test loss item: 0.6519035696983337
test loss item: 0.33295533061027527
test loss item: 0.28880494832992554
test loss item: 0.24156253039836884
test loss item: 0.5938494205474854
test loss item: 0.2822040021419525
test loss item: 0.2615330219268799
test loss item: 0.3005254566669464
test loss item: 1.1199716329574585
test loss item: 0.31990453600883484
test loss item: 0.3979785144329071
test loss item: 0.3098549246788025
test loss item: 0.67220139503479
test loss item: 0.4729483425617218
test loss item: 0.06089017167687416
test loss item: 1.175227403640747
test loss item: 0.410563588142395
test loss item: 0.5230293273925781
test loss item: 0.1743640899658203
test loss item: 0.18076521158218384
test loss item: 0.20396926999092102
test loss item: 1.8931639194488525
test loss item: 0.5885764956474304
test loss item: 0.21596869826316833
test loss item: 0.0782506987452507
test loss item: 1.2028841972351074
test loss item: 1.076128363609314
test loss item: 1.298488736152649
test loss item: 0.28027236461639404
test loss item: 0.265866756439209
test loss item: 0.07041928917169571
test loss item: 0.0625692754983902
test loss item: 0.17522141337394714
Epoch [66/100], Training Loss: 0.4437, Testing Loss: 0.4933
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 67/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.42442944645881653
1
train loss item: 1.0478540658950806
2
train loss item: 0.24460238218307495
3
train loss item: 0.5555142760276794
4
train loss item: 0.4225686490535736
5
train loss item: 0.32854801416397095
6
train loss item: 0.27368417382240295
7
train loss item: 0.6277154088020325
8
train loss item: 0.1392499953508377
9
train loss item: 0.30735817551612854
10
train loss item: 0.36532437801361084
11
train loss item: 0.23609739542007446
12
train loss item: 0.09279045462608337
13
train loss item: 0.4775756597518921
14
train loss item: 0.24251268804073334
15
train loss item: 0.5703929662704468
16
train loss item: 0.04217486456036568
17
train loss item: 0.31930482387542725
18
train loss item: 0.3375222086906433
19
train loss item: 0.29009145498275757
20
train loss item: 0.24829095602035522
21
train loss item: 0.08937669545412064
22
train loss item: 0.8016502261161804
23
train loss item: 0.7966696619987488
24
train loss item: 0.5691761374473572
25
train loss item: 0.15525847673416138
26
train loss item: 0.18833768367767334
27
train loss item: 0.2568846344947815
28
train loss item: 0.0387127660214901
29
train loss item: 0.620371401309967
30
train loss item: 1.6734955310821533
31
train loss item: 0.5555139183998108
32
train loss item: 0.07728741317987442
33
train loss item: 0.4607444405555725
34
train loss item: 0.07715006917715073
35
train loss item: 1.906510353088379
36
train loss item: 0.4594918191432953
37
train loss item: 0.3276088833808899
38
train loss item: 0.4041644334793091
39
train loss item: 0.2241487056016922
40
train loss item: 0.1499728113412857
41
train loss item: 0.2781159281730652
42
train loss item: 0.2736414968967438
43
train loss item: 0.19757884740829468
44
train loss item: 0.5793359875679016
45
train loss item: 0.11031445115804672
46
train loss item: 0.10272423177957535
47
train loss item: 0.3472404181957245
48
train loss item: 0.2566939890384674
49
train loss item: 0.14939557015895844
50
train loss item: 0.33219635486602783
51
train loss item: 0.7484771609306335
52
train loss item: 0.047180552035570145
53
train loss item: 0.16408488154411316
54
train loss item: 1.758566975593567
55
train loss item: 0.22738920152187347
56
train loss item: 0.24718549847602844
57
train loss item: 0.25071412324905396
58
train loss item: 0.16836051642894745
59
train loss item: 0.09282410144805908
60
train loss item: 0.8576645255088806
61
train loss item: 1.6879380941390991
62
train loss item: 0.2087659239768982
63
train loss item: 0.36596012115478516
64
train loss item: 0.17677409946918488
65
train loss item: 0.5714254379272461
66
train loss item: 0.3907460868358612
67
train loss item: 0.19950033724308014
68
train loss item: 0.32498741149902344
69
train loss item: 0.34754401445388794
70
train loss item: 0.24630680680274963
71
train loss item: 0.10224585235118866
72
train loss item: 0.20492997765541077
73
train loss item: 0.3403470814228058
74
train loss item: 0.05175158753991127
75
train loss item: 0.08685634285211563
76
train loss item: 0.8497530221939087
77
train loss item: 1.0015476942062378
78
train loss item: 0.041482504457235336
79
train loss item: 0.25433817505836487
80
train loss item: 0.09560064971446991
81
train loss item: 0.18076731264591217
82
train loss item: 0.21286018192768097
83
train loss item: 0.4734064042568207
84
train loss item: 0.3539033830165863
85
train loss item: 0.6146994233131409
86
train loss item: 3.483095645904541
87
train loss item: 0.17955011129379272
88
train loss item: 0.3396967947483063
epoch train loss: 0.4269954358342658
testing phase
test loss item: 0.19103951752185822
test loss item: 0.09636048972606659
test loss item: 0.6606853008270264
test loss item: 0.2250763177871704
test loss item: 0.28178444504737854
test loss item: 0.15046396851539612
test loss item: 1.8817166090011597
test loss item: 0.520280659198761
test loss item: 0.23975497484207153
test loss item: 0.4388982653617859
test loss item: 0.9419214725494385
test loss item: 0.15992043912410736
test loss item: 0.17613203823566437
test loss item: 0.35133978724479675
test loss item: 0.1863785982131958
test loss item: 0.06341962516307831
test loss item: 0.32627731561660767
test loss item: 0.5424949526786804
test loss item: 0.687812864780426
test loss item: 0.31119415163993835
test loss item: 0.8827590942382812
test loss item: 0.3971313536167145
test loss item: 0.3284703493118286
test loss item: 0.18794198334217072
test loss item: 0.251375287771225
test loss item: 0.2522304356098175
test loss item: 0.3736979067325592
test loss item: 0.21993322670459747
test loss item: 0.38561850786209106
test loss item: 0.38616108894348145
test loss item: 0.8679638504981995
test loss item: 0.06282801926136017
test loss item: 0.15374574065208435
test loss item: 0.6587319374084473
test loss item: 0.5025249123573303
test loss item: 0.4316628575325012
test loss item: 0.8602967858314514
test loss item: 1.5740140676498413
test loss item: 0.5581316947937012
test loss item: 0.3231062889099121
test loss item: 0.3352309465408325
test loss item: 0.18293288350105286
test loss item: 0.3968808948993683
test loss item: 0.21737349033355713
test loss item: 0.7162506580352783
test loss item: 0.48249152302742004
test loss item: 0.3202812075614929
test loss item: 0.24725359678268433
test loss item: 0.5193575024604797
test loss item: 0.7522023916244507
test loss item: 0.33845973014831543
test loss item: 0.12005504220724106
test loss item: 0.2580634653568268
test loss item: 0.13882099092006683
test loss item: 0.33861270546913147
test loss item: 0.9726559519767761
test loss item: 0.5745699405670166
test loss item: 0.28147268295288086
test loss item: 0.24973350763320923
test loss item: 0.21946504712104797
test loss item: 0.5036740303039551
test loss item: 0.23070582747459412
test loss item: 0.23529034852981567
test loss item: 0.2844390571117401
test loss item: 0.95305335521698
test loss item: 0.3044479489326477
test loss item: 0.3422785699367523
test loss item: 0.2955915033817291
test loss item: 0.6031680703163147
test loss item: 0.4002714157104492
test loss item: 0.08141440153121948
test loss item: 1.0651657581329346
test loss item: 0.3487623333930969
test loss item: 0.4684127867221832
test loss item: 0.15720908343791962
test loss item: 0.16773878037929535
test loss item: 0.19256490468978882
test loss item: 1.5996464490890503
test loss item: 0.5264162421226501
test loss item: 0.22305899858474731
test loss item: 0.09445897489786148
test loss item: 1.0341061353683472
test loss item: 0.9611735343933105
test loss item: 1.0720340013504028
test loss item: 0.24716494977474213
test loss item: 0.23699098825454712
test loss item: 0.08270727843046188
test loss item: 0.05909198895096779
test loss item: 0.19984912872314453
Epoch [67/100], Training Loss: 0.4270, Testing Loss: 0.4351
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7072.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7072.00 MB
Epoch 68/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.490293949842453
1
train loss item: 1.08610999584198
2
train loss item: 0.22972813248634338
3
train loss item: 0.5469501614570618
4
train loss item: 0.40198975801467896
5
train loss item: 0.357533723115921
6
train loss item: 0.2617349326610565
7
train loss item: 0.6370911002159119
8
train loss item: 0.1297738403081894
9
train loss item: 0.2735535204410553
10
train loss item: 0.38173672556877136
11
train loss item: 0.2581224739551544
12
train loss item: 0.09429182857275009
13
train loss item: 0.4759073555469513
14
train loss item: 0.23598405718803406
15
train loss item: 0.5710952877998352
16
train loss item: 0.04551352560520172
17
train loss item: 0.3031807243824005
18
train loss item: 0.39139923453330994
19
train loss item: 0.2682148516178131
20
train loss item: 0.2171638458967209
21
train loss item: 0.0924014076590538
22
train loss item: 0.873019278049469
23
train loss item: 0.8024997115135193
24
train loss item: 0.5834203362464905
25
train loss item: 0.16104881465435028
26
train loss item: 0.19403526186943054
27
train loss item: 0.2143927812576294
28
train loss item: 0.04227970540523529
29
train loss item: 0.5629315972328186
30
train loss item: 1.6217515468597412
31
train loss item: 0.650383710861206
32
train loss item: 0.08763586729764938
33
train loss item: 0.38286536931991577
34
train loss item: 0.09199501574039459
35
train loss item: 1.880458116531372
36
train loss item: 0.5425537824630737
37
train loss item: 0.4093876779079437
38
train loss item: 0.676438570022583
39
train loss item: 0.21805492043495178
40
train loss item: 0.146231546998024
41
train loss item: 0.2756666839122772
42
train loss item: 0.285770446062088
43
train loss item: 0.18199032545089722
44
train loss item: 0.5204704403877258
45
train loss item: 0.10512135177850723
46
train loss item: 0.11158883571624756
47
train loss item: 0.34514060616493225
48
train loss item: 0.22766372561454773
49
train loss item: 0.1512710601091385
50
train loss item: 0.3206503391265869
51
train loss item: 0.7618759274482727
52
train loss item: 0.048426587134599686
53
train loss item: 0.13465449213981628
54
train loss item: 1.7255884408950806
55
train loss item: 0.20348189771175385
56
train loss item: 0.2934577167034149
57
train loss item: 0.248119056224823
58
train loss item: 0.15980477631092072
59
train loss item: 0.10112529247999191
60
train loss item: 0.7449052333831787
61
train loss item: 1.5872642993927002
62
train loss item: 0.20141920447349548
63
train loss item: 0.3756278157234192
64
train loss item: 0.15314508974552155
65
train loss item: 0.6911832094192505
66
train loss item: 0.4905409514904022
67
train loss item: 0.19069156050682068
68
train loss item: 0.27316972613334656
69
train loss item: 0.3782457411289215
70
train loss item: 0.274299681186676
71
train loss item: 0.10239066928625107
72
train loss item: 0.17258962988853455
73
train loss item: 0.3149707019329071
74
train loss item: 0.05118725076317787
75
train loss item: 0.08577144891023636
76
train loss item: 0.7812681794166565
77
train loss item: 0.9168297648429871
78
train loss item: 0.046191878616809845
79
train loss item: 0.27565792202949524
80
train loss item: 0.10419607907533646
81
train loss item: 0.17000798881053925
82
train loss item: 0.1931837499141693
83
train loss item: 0.4927627742290497
84
train loss item: 0.47929930686950684
85
train loss item: 0.5595727562904358
86
train loss item: 3.4602811336517334
87
train loss item: 0.13933773338794708
88
train loss item: 0.42008987069129944
epoch train loss: 0.429428128044257
testing phase
test loss item: 0.19555415213108063
test loss item: 0.087410569190979
test loss item: 0.6088640093803406
test loss item: 0.23416613042354584
test loss item: 0.2562708556652069
test loss item: 0.14068259298801422
test loss item: 1.826755404472351
test loss item: 0.5180990695953369
test loss item: 0.22126470506191254
test loss item: 0.408517986536026
test loss item: 0.8860098123550415
test loss item: 0.16650496423244476
test loss item: 0.16484014689922333
test loss item: 0.336271196603775
test loss item: 0.17288218438625336
test loss item: 0.0662948489189148
test loss item: 0.3282693922519684
test loss item: 0.49934864044189453
test loss item: 0.6760663986206055
test loss item: 0.3037169277667999
test loss item: 0.8077729940414429
test loss item: 0.3946692943572998
test loss item: 0.30260708928108215
test loss item: 0.18489772081375122
test loss item: 0.2458554208278656
test loss item: 0.2444411814212799
test loss item: 0.3692657947540283
test loss item: 0.2028632014989853
test loss item: 0.36509984731674194
test loss item: 0.37087613344192505
test loss item: 0.8204643130302429
test loss item: 0.06741141527891159
test loss item: 0.1529538631439209
test loss item: 0.6636640429496765
test loss item: 0.4626908302307129
test loss item: 0.415223628282547
test loss item: 0.835022509098053
test loss item: 1.4572032690048218
test loss item: 0.5314028859138489
test loss item: 0.3154011368751526
test loss item: 0.3298959732055664
test loss item: 0.17691104114055634
test loss item: 0.40665727853775024
test loss item: 0.22958938777446747
test loss item: 0.6583544015884399
test loss item: 0.47390416264533997
test loss item: 0.29782429337501526
test loss item: 0.24034899473190308
test loss item: 0.4771418571472168
test loss item: 0.7179961204528809
test loss item: 0.30215781927108765
test loss item: 0.11762803792953491
test loss item: 0.2492915391921997
test loss item: 0.1542663425207138
test loss item: 0.31073108315467834
test loss item: 0.9031054377555847
test loss item: 0.5537193417549133
test loss item: 0.25342535972595215
test loss item: 0.23850442469120026
test loss item: 0.203994482755661
test loss item: 0.4706907272338867
test loss item: 0.23236586153507233
test loss item: 0.2321571260690689
test loss item: 0.2791287302970886
test loss item: 0.8789049386978149
test loss item: 0.31361138820648193
test loss item: 0.3315346837043762
test loss item: 0.28902149200439453
test loss item: 0.5740106105804443
test loss item: 0.399409681558609
test loss item: 0.07507870346307755
test loss item: 1.0406471490859985
test loss item: 0.32153913378715515
test loss item: 0.46471381187438965
test loss item: 0.16292499005794525
test loss item: 0.16234543919563293
test loss item: 0.18859516084194183
test loss item: 1.4540249109268188
test loss item: 0.5035074949264526
test loss item: 0.21478299796581268
test loss item: 0.09723896533250809
test loss item: 0.9814387559890747
test loss item: 0.935097873210907
test loss item: 0.9765748381614685
test loss item: 0.23569931089878082
test loss item: 0.257107138633728
test loss item: 0.0910935178399086
test loss item: 0.07019974291324615
test loss item: 0.19673115015029907
Epoch [68/100], Training Loss: 0.4294, Testing Loss: 0.4161
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7014.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7014.00 MB
Epoch 69/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.46432000398635864
1
train loss item: 1.0318961143493652
2
train loss item: 0.2285982370376587
3
train loss item: 0.5071033835411072
4
train loss item: 0.39852577447891235
5
train loss item: 0.3381434381008148
6
train loss item: 0.2591225206851959
7
train loss item: 0.6253588199615479
8
train loss item: 0.12955521047115326
9
train loss item: 0.26947295665740967
10
train loss item: 0.36197152733802795
11
train loss item: 0.2420070469379425
12
train loss item: 0.09615439176559448
13
train loss item: 0.4574262201786041
14
train loss item: 0.23202624917030334
15
train loss item: 0.5248661041259766
16
train loss item: 0.0490875318646431
17
train loss item: 0.3005651533603668
18
train loss item: 0.35662612318992615
19
train loss item: 0.2685837149620056
20
train loss item: 0.22153514623641968
21
train loss item: 0.09203078597784042
22
train loss item: 0.7616365551948547
23
train loss item: 0.7819221615791321
24
train loss item: 0.5534272193908691
25
train loss item: 0.15422475337982178
26
train loss item: 0.1902470886707306
27
train loss item: 0.21566058695316315
28
train loss item: 0.045147646218538284
29
train loss item: 0.5295472741127014
30
train loss item: 1.5881752967834473
31
train loss item: 0.6051057577133179
32
train loss item: 0.08262203633785248
33
train loss item: 0.38419631123542786
34
train loss item: 0.08801516145467758
35
train loss item: 1.8587749004364014
36
train loss item: 0.46978652477264404
37
train loss item: 0.35260000824928284
38
train loss item: 0.5181655883789062
39
train loss item: 0.2087298333644867
40
train loss item: 0.14730636775493622
41
train loss item: 0.26516252756118774
42
train loss item: 0.27510127425193787
43
train loss item: 0.17875626683235168
44
train loss item: 0.514962375164032
45
train loss item: 0.10159101337194443
46
train loss item: 0.10665766149759293
47
train loss item: 0.3313373923301697
48
train loss item: 0.22770096361637115
49
train loss item: 0.1485595554113388
50
train loss item: 0.3147994875907898
51
train loss item: 0.7156775593757629
52
train loss item: 0.047144848853349686
53
train loss item: 0.13506607711315155
54
train loss item: 1.7062431573867798
55
train loss item: 0.20258063077926636
56
train loss item: 0.26328396797180176
57
train loss item: 0.24620173871517181
58
train loss item: 0.15759651362895966
59
train loss item: 0.09459734708070755
60
train loss item: 0.7611235976219177
61
train loss item: 1.562635898590088
62
train loss item: 0.19869454205036163
63
train loss item: 0.3541938364505768
64
train loss item: 0.1490560919046402
65
train loss item: 0.6200811862945557
66
train loss item: 0.41098442673683167
67
train loss item: 0.18603113293647766
68
train loss item: 0.27639779448509216
69
train loss item: 0.353691041469574
70
train loss item: 0.24636158347129822
71
train loss item: 0.1018928736448288
72
train loss item: 0.17120422422885895
73
train loss item: 0.3165183365345001
74
train loss item: 0.05136846750974655
75
train loss item: 0.08199790865182877
76
train loss item: 0.7784357666969299
77
train loss item: 0.9177582263946533
78
train loss item: 0.05097990855574608
79
train loss item: 0.2553238570690155
80
train loss item: 0.10548428446054459
81
train loss item: 0.1719881147146225
82
train loss item: 0.19219325482845306
83
train loss item: 0.4553174078464508
84
train loss item: 0.37105703353881836
85
train loss item: 0.5521253943443298
86
train loss item: 3.421567916870117
87
train loss item: 0.13860686123371124
88
train loss item: 0.3761122524738312
epoch train loss: 0.41182551805055545
testing phase
test loss item: 0.19574646651744843
test loss item: 0.08133120834827423
test loss item: 0.7134867906570435
test loss item: 0.24826207756996155
test loss item: 0.2613755166530609
test loss item: 0.11153754591941833
test loss item: 1.9829397201538086
test loss item: 0.5991608500480652
test loss item: 0.25369712710380554
test loss item: 0.44747108221054077
test loss item: 1.0069113969802856
test loss item: 0.1738833487033844
test loss item: 0.17794302105903625
test loss item: 0.34858238697052
test loss item: 0.17561888694763184
test loss item: 0.07403148710727692
test loss item: 0.3490813374519348
test loss item: 0.5405771136283875
test loss item: 0.7217051982879639
test loss item: 0.325238972902298
test loss item: 0.8720483183860779
test loss item: 0.4280931055545807
test loss item: 0.32423797249794006
test loss item: 0.1917111575603485
test loss item: 0.2589111626148224
test loss item: 0.25002342462539673
test loss item: 0.3908751904964447
test loss item: 0.19381405413150787
test loss item: 0.3771393895149231
test loss item: 0.39397016167640686
test loss item: 0.9355558156967163
test loss item: 0.07792755216360092
test loss item: 0.155403733253479
test loss item: 0.7059053778648376
test loss item: 0.5132067203521729
test loss item: 0.45783478021621704
test loss item: 0.8968136310577393
test loss item: 1.698518991470337
test loss item: 0.5791118144989014
test loss item: 0.3207813799381256
test loss item: 0.342666357755661
test loss item: 0.18506763875484467
test loss item: 0.42791104316711426
test loss item: 0.2536618709564209
test loss item: 0.6998114585876465
test loss item: 0.5005179047584534
test loss item: 0.312405526638031
test loss item: 0.25672784447669983
test loss item: 0.5444961190223694
test loss item: 0.8169471025466919
test loss item: 0.3253882825374603
test loss item: 0.12581537663936615
test loss item: 0.2671278715133667
test loss item: 0.16907361149787903
test loss item: 0.33646175265312195
test loss item: 1.038938045501709
test loss item: 0.6147499680519104
test loss item: 0.26671236753463745
test loss item: 0.25442153215408325
test loss item: 0.2108788788318634
test loss item: 0.5096333622932434
test loss item: 0.2660660445690155
test loss item: 0.24344268441200256
test loss item: 0.28525909781455994
test loss item: 1.0170797109603882
test loss item: 0.3294724225997925
test loss item: 0.3618400990962982
test loss item: 0.29516837000846863
test loss item: 0.621602475643158
test loss item: 0.45264941453933716
test loss item: 0.06595689058303833
test loss item: 1.1292407512664795
test loss item: 0.344341903924942
test loss item: 0.49459895491600037
test loss item: 0.17914412915706635
test loss item: 0.16613933444023132
test loss item: 0.19479569792747498
test loss item: 1.7120978832244873
test loss item: 0.5420352816581726
test loss item: 0.201279416680336
test loss item: 0.08835909515619278
test loss item: 1.1264309883117676
test loss item: 1.019582748413086
test loss item: 1.1701301336288452
test loss item: 0.24929828941822052
test loss item: 0.27061957120895386
test loss item: 0.08920498192310333
test loss item: 0.08381658792495728
test loss item: 0.17239592969417572
Epoch [69/100], Training Loss: 0.4118, Testing Loss: 0.4544
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 70/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.43019920587539673
1
train loss item: 1.020589828491211
2
train loss item: 0.2328881323337555
3
train loss item: 0.5396941304206848
4
train loss item: 0.4078090786933899
5
train loss item: 0.3185277283191681
6
train loss item: 0.26307782530784607
7
train loss item: 0.6200516223907471
8
train loss item: 0.13379232585430145
9
train loss item: 0.2979586720466614
10
train loss item: 0.35496002435684204
11
train loss item: 0.23100852966308594
12
train loss item: 0.09456358850002289
13
train loss item: 0.4597933888435364
14
train loss item: 0.23642869293689728
15
train loss item: 0.5674230456352234
16
train loss item: 0.04838719591498375
17
train loss item: 0.3055129945278168
18
train loss item: 0.33222585916519165
19
train loss item: 0.28136712312698364
20
train loss item: 0.23382088541984558
21
train loss item: 0.09097941964864731
22
train loss item: 0.7978339195251465
23
train loss item: 0.7701913714408875
24
train loss item: 0.5542991757392883
25
train loss item: 0.15673163533210754
26
train loss item: 0.18677011132240295
27
train loss item: 0.2439100295305252
28
train loss item: 0.04409009590744972
29
train loss item: 0.6140920519828796
30
train loss item: 1.5940954685211182
31
train loss item: 0.544463574886322
32
train loss item: 0.07322502881288528
33
train loss item: 0.4353124499320984
34
train loss item: 0.07787185162305832
35
train loss item: 1.8508402109146118
36
train loss item: 0.4650769531726837
37
train loss item: 0.3065265715122223
38
train loss item: 0.4023868441581726
39
train loss item: 0.2139044851064682
40
train loss item: 0.14705736935138702
41
train loss item: 0.2735726833343506
42
train loss item: 0.27056461572647095
43
train loss item: 0.18555890023708344
44
train loss item: 0.5507858991622925
45
train loss item: 0.1021864041686058
46
train loss item: 0.09985527396202087
47
train loss item: 0.3445880711078644
48
train loss item: 0.24094916880130768
49
train loss item: 0.14513280987739563
50
train loss item: 0.3174496293067932
51
train loss item: 0.768592119216919
52
train loss item: 0.047909803688526154
53
train loss item: 0.15033002197742462
54
train loss item: 1.6918518543243408
55
train loss item: 0.2105151265859604
56
train loss item: 0.2488209307193756
57
train loss item: 0.24526095390319824
58
train loss item: 0.15874551236629486
59
train loss item: 0.08562204986810684
60
train loss item: 0.8789111375808716
61
train loss item: 1.5905903577804565
62
train loss item: 0.20022152364253998
63
train loss item: 0.3583555817604065
64
train loss item: 0.16225565969944
65
train loss item: 0.5606878399848938
66
train loss item: 0.37745749950408936
67
train loss item: 0.1887042224407196
68
train loss item: 0.3095807135105133
69
train loss item: 0.3384370803833008
70
train loss item: 0.2398463636636734
71
train loss item: 0.09836140275001526
72
train loss item: 0.18944968283176422
73
train loss item: 0.3311920762062073
74
train loss item: 0.04703518748283386
75
train loss item: 0.08334522694349289
76
train loss item: 0.8156613111495972
77
train loss item: 0.9827994704246521
78
train loss item: 0.05184568464756012
79
train loss item: 0.2504062056541443
80
train loss item: 0.09417689591646194
81
train loss item: 0.17755848169326782
82
train loss item: 0.1969383805990219
83
train loss item: 0.49660563468933105
84
train loss item: 0.34068283438682556
85
train loss item: 0.5855335593223572
86
train loss item: 3.39028000831604
87
train loss item: 0.16206195950508118
88
train loss item: 0.333505779504776
epoch train loss: 0.41517436052306317
testing phase
test loss item: 0.21690885722637177
test loss item: 0.09665122628211975
test loss item: 0.7531278133392334
test loss item: 0.2256866842508316
test loss item: 0.2720731198787689
test loss item: 0.10984835028648376
test loss item: 1.9383481740951538
test loss item: 0.5751979351043701
test loss item: 0.2681428790092468
test loss item: 0.4586401581764221
test loss item: 1.0531551837921143
test loss item: 0.16195523738861084
test loss item: 0.18312141299247742
test loss item: 0.34522318840026855
test loss item: 0.17901664972305298
test loss item: 0.11418730765581131
test loss item: 0.34681349992752075
test loss item: 0.5580540895462036
test loss item: 0.7090118527412415
test loss item: 0.3154579699039459
test loss item: 0.9076910614967346
test loss item: 0.40784579515457153
test loss item: 0.3297405540943146
test loss item: 0.18183653056621552
test loss item: 0.26364725828170776
test loss item: 0.24782989919185638
test loss item: 0.3954176604747772
test loss item: 0.20347587764263153
test loss item: 0.37584468722343445
test loss item: 0.39746153354644775
test loss item: 0.9532343745231628
test loss item: 0.15214696526527405
test loss item: 0.14791615307331085
test loss item: 0.7009478211402893
test loss item: 0.5381650328636169
test loss item: 0.45981764793395996
test loss item: 0.8865227103233337
test loss item: 1.7950831651687622
test loss item: 0.5784459114074707
test loss item: 0.30851536989212036
test loss item: 0.337516725063324
test loss item: 0.18322867155075073
test loss item: 0.4305809736251831
test loss item: 0.2386307269334793
test loss item: 0.725066065788269
test loss item: 0.48989999294281006
test loss item: 0.31782329082489014
test loss item: 0.2541653513908386
test loss item: 0.5622687339782715
test loss item: 0.8256838321685791
test loss item: 0.338279128074646
test loss item: 0.12687848508358002
test loss item: 0.27103573083877563
test loss item: 0.14326918125152588
test loss item: 0.34894153475761414
test loss item: 1.0891193151474
test loss item: 0.6268656253814697
test loss item: 0.2759142816066742
test loss item: 0.25308820605278015
test loss item: 0.21618300676345825
test loss item: 0.5206042528152466
test loss item: 0.25578948855400085
test loss item: 0.23969759047031403
test loss item: 0.2794906198978424
test loss item: 1.0651755332946777
test loss item: 0.30434200167655945
test loss item: 0.3564422130584717
test loss item: 0.28701645135879517
test loss item: 0.642126202583313
test loss item: 0.4412851631641388
test loss item: 0.07566486299037933
test loss item: 1.0893206596374512
test loss item: 0.34842947125434875
test loss item: 0.4676259756088257
test loss item: 0.2364465594291687
test loss item: 0.1633850336074829
test loss item: 0.18606169521808624
test loss item: 1.8394156694412231
test loss item: 0.5488638281822205
test loss item: 0.20575042068958282
test loss item: 0.07662233710289001
test loss item: 1.1505181789398193
test loss item: 1.0147658586502075
test loss item: 1.2481508255004883
test loss item: 0.24330087006092072
test loss item: 0.3042723834514618
test loss item: 0.1352033019065857
test loss item: 0.14750516414642334
test loss item: 0.16876807808876038
Epoch [70/100], Training Loss: 0.4152, Testing Loss: 0.4630
no improvement in test loss for 7 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6952.00 MB
Epoch 71/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.43152573704719543
1
train loss item: 1.0046466588974
2
train loss item: 0.22904282808303833
3
train loss item: 0.5133486986160278
4
train loss item: 0.39816346764564514
5
train loss item: 0.32301536202430725
6
train loss item: 0.2577429711818695
7
train loss item: 0.6064390540122986
8
train loss item: 0.13062815368175507
9
train loss item: 0.2806317210197449
10
train loss item: 0.34949642419815063
11
train loss item: 0.24176986515522003
12
train loss item: 0.09297570586204529
13
train loss item: 0.4604048728942871
14
train loss item: 0.24121913313865662
15
train loss item: 0.5350074768066406
16
train loss item: 0.04779022932052612
17
train loss item: 0.2967109680175781
18
train loss item: 0.3288370668888092
19
train loss item: 0.2653713524341583
20
train loss item: 0.21789033710956573
21
train loss item: 0.08998226374387741
22
train loss item: 0.779922604560852
23
train loss item: 0.7629094123840332
24
train loss item: 0.5420894622802734
25
train loss item: 0.15746447443962097
26
train loss item: 0.18887276947498322
27
train loss item: 0.23904702067375183
28
train loss item: 0.044010989367961884
29
train loss item: 0.5718269944190979
30
train loss item: 1.5575478076934814
31
train loss item: 0.5450366139411926
32
train loss item: 0.07742705941200256
33
train loss item: 0.4208660125732422
34
train loss item: 0.08630861341953278
35
train loss item: 1.8292796611785889
36
train loss item: 0.4531088173389435
37
train loss item: 0.3270765542984009
38
train loss item: 0.39192765951156616
39
train loss item: 0.21018844842910767
40
train loss item: 0.1411322057247162
41
train loss item: 0.2704985439777374
42
train loss item: 0.26354387402534485
43
train loss item: 0.1825680136680603
44
train loss item: 0.5407952070236206
45
train loss item: 0.09957097470760345
46
train loss item: 0.10075578093528748
47
train loss item: 0.3248912990093231
48
train loss item: 0.2346130609512329
49
train loss item: 0.14195634424686432
50
train loss item: 0.30776524543762207
51
train loss item: 0.7435755729675293
52
train loss item: 0.04887009412050247
53
train loss item: 0.14584602415561676
54
train loss item: 1.6696903705596924
55
train loss item: 0.20606514811515808
56
train loss item: 0.2520696818828583
57
train loss item: 0.2404175102710724
58
train loss item: 0.15545935928821564
59
train loss item: 0.08462021499872208
60
train loss item: 0.8325631022453308
61
train loss item: 1.5566959381103516
62
train loss item: 0.19554346799850464
63
train loss item: 0.34383174777030945
64
train loss item: 0.16232416033744812
65
train loss item: 0.5837711691856384
66
train loss item: 0.370266318321228
67
train loss item: 0.18258512020111084
68
train loss item: 0.28774604201316833
69
train loss item: 0.3340793251991272
70
train loss item: 0.23764564096927643
71
train loss item: 0.09866590797901154
72
train loss item: 0.18245792388916016
73
train loss item: 0.31742599606513977
74
train loss item: 0.048286452889442444
75
train loss item: 0.08476505428552628
76
train loss item: 0.8032943606376648
77
train loss item: 0.96160888671875
78
train loss item: 0.052111439406871796
79
train loss item: 0.23855935037136078
80
train loss item: 0.08997449278831482
81
train loss item: 0.16936703026294708
82
train loss item: 0.19471760094165802
83
train loss item: 0.46908071637153625
84
train loss item: 0.33726003766059875
85
train loss item: 0.570690929889679
86
train loss item: 3.3574752807617188
87
train loss item: 0.1581171154975891
88
train loss item: 0.33885592222213745
epoch train loss: 0.40721373460935745
testing phase
test loss item: 0.22501294314861298
test loss item: 0.12120357900857925
test loss item: 0.66396164894104
test loss item: 0.2109445482492447
test loss item: 0.2643480598926544
test loss item: 0.13555413484573364
test loss item: 1.7060843706130981
test loss item: 0.4705740809440613
test loss item: 0.24106258153915405
test loss item: 0.4160478115081787
test loss item: 0.9459561705589294
test loss item: 0.14698979258537292
test loss item: 0.17332011461257935
test loss item: 0.3267618417739868
test loss item: 0.1736384481191635
test loss item: 0.14017926156520844
test loss item: 0.32879531383514404
test loss item: 0.5113115906715393
test loss item: 0.6489348411560059
test loss item: 0.2865975797176361
test loss item: 0.8365936279296875
test loss item: 0.3606390357017517
test loss item: 0.30108320713043213
test loss item: 0.17035768926143646
test loss item: 0.25194889307022095
test loss item: 0.23998895287513733
test loss item: 0.372893750667572
test loss item: 0.2105991393327713
test loss item: 0.3528238534927368
test loss item: 0.37299513816833496
test loss item: 0.829616129398346
test loss item: 0.18942758440971375
test loss item: 0.1446446031332016
test loss item: 0.6446398496627808
test loss item: 0.48980027437210083
test loss item: 0.4144509434700012
test loss item: 0.8024958968162537
test loss item: 1.5844039916992188
test loss item: 0.5239893198013306
test loss item: 0.28839555382728577
test loss item: 0.31911224126815796
test loss item: 0.1770990639925003
test loss item: 0.4124692678451538
test loss item: 0.2152969241142273
test loss item: 0.6758350133895874
test loss item: 0.4564659297466278
test loss item: 0.300254762172699
test loss item: 0.24008014798164368
test loss item: 0.494281530380249
test loss item: 0.7307978272438049
test loss item: 0.308561235666275
test loss item: 0.12735484540462494
test loss item: 0.25225475430488586
test loss item: 0.12428410351276398
test loss item: 0.32008081674575806
test loss item: 0.9679269790649414
test loss item: 0.5677118897438049
test loss item: 0.25870800018310547
test loss item: 0.2364315539598465
test loss item: 0.20547473430633545
test loss item: 0.4754454493522644
test loss item: 0.224722221493721
test loss item: 0.22580938041210175
test loss item: 0.266014039516449
test loss item: 0.9377424716949463
test loss item: 0.2863646447658539
test loss item: 0.3223293721675873
test loss item: 0.2723452150821686
test loss item: 0.5953596830368042
test loss item: 0.3814724087715149
test loss item: 0.09977666288614273
test loss item: 0.9499707818031311
test loss item: 0.32009074091911316
test loss item: 0.41209664940834045
test loss item: 0.2665775418281555
test loss item: 0.1613861322402954
test loss item: 0.17516903579235077
test loss item: 1.6232889890670776
test loss item: 0.5053654313087463
test loss item: 0.21575970947742462
test loss item: 0.08870735764503479
test loss item: 1.0008074045181274
test loss item: 0.912945568561554
test loss item: 1.0820965766906738
test loss item: 0.2213730812072754
test loss item: 0.31908145546913147
test loss item: 0.15471062064170837
test loss item: 0.1598854959011078
test loss item: 0.20138463377952576
Epoch [71/100], Training Loss: 0.4072, Testing Loss: 0.4244
no improvement in test loss for 8 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6890.00 MB
Epoch 72/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4664987325668335
1
train loss item: 1.0085656642913818
2
train loss item: 0.22941790521144867
3
train loss item: 0.49742698669433594
4
train loss item: 0.4244299530982971
5
train loss item: 0.33995938301086426
6
train loss item: 0.26211971044540405
7
train loss item: 0.6047791838645935
8
train loss item: 0.12931324541568756
9
train loss item: 0.2551756501197815
10
train loss item: 0.3636617958545685
11
train loss item: 0.2770739793777466
12
train loss item: 0.09407021105289459
13
train loss item: 0.4533284306526184
14
train loss item: 0.2411680519580841
15
train loss item: 0.5179477334022522
16
train loss item: 0.047111161053180695
17
train loss item: 0.3010261654853821
18
train loss item: 0.35319432616233826
19
train loss item: 0.26844316720962524
20
train loss item: 0.21199432015419006
21
train loss item: 0.10638076066970825
22
train loss item: 0.7529274821281433
23
train loss item: 0.7705788016319275
24
train loss item: 0.5528275966644287
25
train loss item: 0.16379189491271973
26
train loss item: 0.20567668974399567
27
train loss item: 0.21434850990772247
28
train loss item: 0.04361237958073616
29
train loss item: 0.5150151252746582
30
train loss item: 1.5035187005996704
31
train loss item: 0.6105234026908875
32
train loss item: 0.09018858522176743
33
train loss item: 0.37375256419181824
34
train loss item: 0.1043989434838295
35
train loss item: 1.7937086820602417
36
train loss item: 0.4717302918434143
37
train loss item: 0.39377474784851074
38
train loss item: 0.4600547254085541
39
train loss item: 0.2076500803232193
40
train loss item: 0.14600399136543274
41
train loss item: 0.27245551347732544
42
train loss item: 0.27733901143074036
43
train loss item: 0.1865420639514923
44
train loss item: 0.5018750429153442
45
train loss item: 0.10123410820960999
46
train loss item: 0.11203061044216156
47
train loss item: 0.3356913924217224
48
train loss item: 0.22226475179195404
49
train loss item: 0.14612457156181335
50
train loss item: 0.3258296847343445
51
train loss item: 0.6952115297317505
52
train loss item: 0.051157720386981964
53
train loss item: 0.13235725462436676
54
train loss item: 1.633230447769165
55
train loss item: 0.19938205182552338
56
train loss item: 0.26572659611701965
57
train loss item: 0.23886804282665253
58
train loss item: 0.16678749024868011
59
train loss item: 0.09067234396934509
60
train loss item: 0.7399932146072388
61
train loss item: 1.485419511795044
62
train loss item: 0.20252907276153564
63
train loss item: 0.35706764459609985
64
train loss item: 0.1586635708808899
65
train loss item: 0.6822625994682312
66
train loss item: 0.4216276705265045
67
train loss item: 0.19056013226509094
68
train loss item: 0.2784392237663269
69
train loss item: 0.36242586374282837
70
train loss item: 0.2663511037826538
71
train loss item: 0.10302593559026718
72
train loss item: 0.16764409840106964
73
train loss item: 0.3069889545440674
74
train loss item: 0.0478832833468914
75
train loss item: 0.08709407597780228
76
train loss item: 0.7596136927604675
77
train loss item: 0.8787556290626526
78
train loss item: 0.050828900188207626
79
train loss item: 0.26177799701690674
80
train loss item: 0.10471277683973312
81
train loss item: 0.17577992379665375
82
train loss item: 0.19417516887187958
83
train loss item: 0.4329019784927368
84
train loss item: 0.38751816749572754
85
train loss item: 0.5420902967453003
86
train loss item: 3.3194735050201416
87
train loss item: 0.1401916742324829
88
train loss item: 0.38962322473526
epoch train loss: 0.40761088575707394
testing phase
test loss item: 0.22225125133991241
test loss item: 0.13861484825611115
test loss item: 0.6128343343734741
test loss item: 0.21449284255504608
test loss item: 0.24494199454784393
test loss item: 0.12552642822265625
test loss item: 1.6506973505020142
test loss item: 0.43002018332481384
test loss item: 0.237857848405838
test loss item: 0.39459338784217834
test loss item: 0.8947491645812988
test loss item: 0.14995159208774567
test loss item: 0.1649283468723297
test loss item: 0.33026257157325745
test loss item: 0.1794523447751999
test loss item: 0.14362064003944397
test loss item: 0.3284090757369995
test loss item: 0.4838219881057739
test loss item: 0.6288544535636902
test loss item: 0.2875458300113678
test loss item: 0.7880762219429016
test loss item: 0.35757189989089966
test loss item: 0.2963244616985321
test loss item: 0.1712864637374878
test loss item: 0.24595630168914795
test loss item: 0.23588493466377258
test loss item: 0.3684256970882416
test loss item: 0.1963329315185547
test loss item: 0.3534294664859772
test loss item: 0.36281606554985046
test loss item: 0.7810227274894714
test loss item: 0.19875478744506836
test loss item: 0.14585542678833008
test loss item: 0.6347573399543762
test loss item: 0.45842891931533813
test loss item: 0.40366074442863464
test loss item: 0.7737512588500977
test loss item: 1.4667253494262695
test loss item: 0.4984430968761444
test loss item: 0.28454288840293884
test loss item: 0.3224135637283325
test loss item: 0.18347595632076263
test loss item: 0.42375004291534424
test loss item: 0.21346835792064667
test loss item: 0.6414260268211365
test loss item: 0.4544079601764679
test loss item: 0.2972446084022522
test loss item: 0.24282854795455933
test loss item: 0.4590349495410919
test loss item: 0.691903829574585
test loss item: 0.28943997621536255
test loss item: 0.12546361982822418
test loss item: 0.24271374940872192
test loss item: 0.13138926029205322
test loss item: 0.3027195930480957
test loss item: 0.9039263129234314
test loss item: 0.5398029685020447
test loss item: 0.2496679127216339
test loss item: 0.23468823730945587
test loss item: 0.19580015540122986
test loss item: 0.45467108488082886
test loss item: 0.22378598153591156
test loss item: 0.22441455721855164
test loss item: 0.265625536441803
test loss item: 0.8685751557350159
test loss item: 0.29109248518943787
test loss item: 0.3174636960029602
test loss item: 0.2704973518848419
test loss item: 0.5675410032272339
test loss item: 0.37871477007865906
test loss item: 0.09206424653530121
test loss item: 0.9192891716957092
test loss item: 0.31972795724868774
test loss item: 0.4158996641635895
test loss item: 0.2580173909664154
test loss item: 0.16830986738204956
test loss item: 0.17324291169643402
test loss item: 1.4813463687896729
test loss item: 0.49595189094543457
test loss item: 0.20389977097511292
test loss item: 0.0875818133354187
test loss item: 0.94135981798172
test loss item: 0.8835762143135071
test loss item: 0.988007128238678
test loss item: 0.2219158262014389
test loss item: 0.31663551926612854
test loss item: 0.1362832635641098
test loss item: 0.13909298181533813
test loss item: 0.18383799493312836
Epoch [72/100], Training Loss: 0.4076, Testing Loss: 0.4081
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 73/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4509487748146057
1
train loss item: 0.9908939599990845
2
train loss item: 0.22464708983898163
3
train loss item: 0.49276474118232727
4
train loss item: 0.4112361967563629
5
train loss item: 0.32721197605133057
6
train loss item: 0.2556643784046173
7
train loss item: 0.6001755595207214
8
train loss item: 0.12640610337257385
9
train loss item: 0.25744640827178955
10
train loss item: 0.3586602509021759
11
train loss item: 0.2540746033191681
12
train loss item: 0.09411536902189255
13
train loss item: 0.4411882162094116
14
train loss item: 0.22666889429092407
15
train loss item: 0.5056747794151306
16
train loss item: 0.0453321672976017
17
train loss item: 0.2946634590625763
18
train loss item: 0.3426401615142822
19
train loss item: 0.2617163360118866
20
train loss item: 0.20704446732997894
21
train loss item: 0.09112858772277832
22
train loss item: 0.7442660331726074
23
train loss item: 0.7677201628684998
24
train loss item: 0.5400667786598206
25
train loss item: 0.15584611892700195
26
train loss item: 0.19250142574310303
27
train loss item: 0.20712758600711823
28
train loss item: 0.040959008038043976
29
train loss item: 0.5123386979103088
30
train loss item: 1.4808874130249023
31
train loss item: 0.5944141745567322
32
train loss item: 0.08063976466655731
33
train loss item: 0.37229517102241516
34
train loss item: 0.08577430248260498
35
train loss item: 1.7689582109451294
36
train loss item: 0.4535502791404724
37
train loss item: 0.3635176122188568
38
train loss item: 0.4309200942516327
39
train loss item: 0.20337843894958496
40
train loss item: 0.14199687540531158
41
train loss item: 0.2664056420326233
42
train loss item: 0.267914354801178
43
train loss item: 0.1788843423128128
44
train loss item: 0.4981183111667633
45
train loss item: 0.09383375942707062
46
train loss item: 0.1048298180103302
47
train loss item: 0.32632386684417725
48
train loss item: 0.2202852964401245
49
train loss item: 0.139102503657341
50
train loss item: 0.31100142002105713
51
train loss item: 0.6920472979545593
52
train loss item: 0.046116285026073456
53
train loss item: 0.12813898921012878
54
train loss item: 1.6118052005767822
55
train loss item: 0.20083916187286377
56
train loss item: 0.2534613311290741
57
train loss item: 0.23277147114276886
58
train loss item: 0.15773439407348633
59
train loss item: 0.08949846029281616
60
train loss item: 0.7297426462173462
61
train loss item: 1.4781036376953125
62
train loss item: 0.19523662328720093
63
train loss item: 0.3433699309825897
64
train loss item: 0.15260127186775208
65
train loss item: 0.6177082061767578
66
train loss item: 0.4105948805809021
67
train loss item: 0.18066416680812836
68
train loss item: 0.27509504556655884
69
train loss item: 0.34913063049316406
70
train loss item: 0.2501211166381836
71
train loss item: 0.09544648975133896
72
train loss item: 0.1641513556241989
73
train loss item: 0.3073655962944031
74
train loss item: 0.04605871066451073
75
train loss item: 0.08062779158353806
76
train loss item: 0.753381609916687
77
train loss item: 0.8787327408790588
78
train loss item: 0.0486416295170784
79
train loss item: 0.24223534762859344
80
train loss item: 0.09942388534545898
81
train loss item: 0.17335152626037598
82
train loss item: 0.18635009229183197
83
train loss item: 0.42760175466537476
84
train loss item: 0.3621702790260315
85
train loss item: 0.5386623740196228
86
train loss item: 3.2843685150146484
87
train loss item: 0.13736076653003693
88
train loss item: 0.3594662547111511
epoch train loss: 0.3975768248351772
testing phase
test loss item: 0.24257522821426392
test loss item: 0.16470710933208466
test loss item: 0.661058247089386
test loss item: 0.2301705926656723
test loss item: 0.24664857983589172
test loss item: 0.11663252860307693
test loss item: 1.8615422248840332
test loss item: 0.5327903628349304
test loss item: 0.2628978192806244
test loss item: 0.41357922554016113
test loss item: 0.9506299495697021
test loss item: 0.16579507291316986
test loss item: 0.17923134565353394
test loss item: 0.3572938144207001
test loss item: 0.1805676817893982
test loss item: 0.17715758085250854
test loss item: 0.35355934500694275
test loss item: 0.49988168478012085
test loss item: 0.6870437860488892
test loss item: 0.33083224296569824
test loss item: 0.8153037428855896
test loss item: 0.41019850969314575
test loss item: 0.3309384286403656
test loss item: 0.1943298727273941
test loss item: 0.25030192732810974
test loss item: 0.25119778513908386
test loss item: 0.39541783928871155
test loss item: 0.19322079420089722
test loss item: 0.37015432119369507
test loss item: 0.37820449471473694
test loss item: 0.8655890822410583
test loss item: 0.2658901512622833
test loss item: 0.1631346195936203
test loss item: 0.6456167697906494
test loss item: 0.4794009029865265
test loss item: 0.434359073638916
test loss item: 0.8427168130874634
test loss item: 1.567391037940979
test loss item: 0.5194174647331238
test loss item: 0.31332558393478394
test loss item: 0.36173659563064575
test loss item: 0.2146434783935547
test loss item: 0.4043703079223633
test loss item: 0.2364514023065567
test loss item: 0.6587541103363037
test loss item: 0.5160635709762573
test loss item: 0.31923791766166687
test loss item: 0.27593058347702026
test loss item: 0.4997079372406006
test loss item: 0.7498265504837036
test loss item: 0.29790198802948
test loss item: 0.13657619059085846
test loss item: 0.25621727108955383
test loss item: 0.15131762623786926
test loss item: 0.31282883882522583
test loss item: 0.9622998237609863
test loss item: 0.5893803238868713
test loss item: 0.26358652114868164
test loss item: 0.2573241591453552
test loss item: 0.19735360145568848
test loss item: 0.4672797620296478
test loss item: 0.2823319733142853
test loss item: 0.25740015506744385
test loss item: 0.28222715854644775
test loss item: 0.9631862044334412
test loss item: 0.3068631887435913
test loss item: 0.36063721776008606
test loss item: 0.2892456650733948
test loss item: 0.5848613381385803
test loss item: 0.43490031361579895
test loss item: 0.10508594661951065
test loss item: 1.056666374206543
test loss item: 0.3564028739929199
test loss item: 0.4865832030773163
test loss item: 0.29726356267929077
test loss item: 0.18726065754890442
test loss item: 0.19464537501335144
test loss item: 1.5960745811462402
test loss item: 0.5366837978363037
test loss item: 0.212039515376091
test loss item: 0.08792239427566528
test loss item: 1.0501267910003662
test loss item: 0.9595261216163635
test loss item: 1.0799866914749146
test loss item: 0.24943409860134125
test loss item: 0.35849466919898987
test loss item: 0.15161055326461792
test loss item: 0.16264374554157257
test loss item: 0.18965545296669006
Epoch [73/100], Training Loss: 0.3976, Testing Loss: 0.4439
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6930.00 MB
Epoch 74/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41847679018974304
1
train loss item: 0.978347659111023
2
train loss item: 0.23022662103176117
3
train loss item: 0.5060500502586365
4
train loss item: 0.3909134566783905
5
train loss item: 0.31245023012161255
6
train loss item: 0.2712550461292267
7
train loss item: 0.5887727737426758
8
train loss item: 0.12774881720542908
9
train loss item: 0.28866055607795715
10
train loss item: 0.3484248220920563
11
train loss item: 0.23487155139446259
12
train loss item: 0.09326166659593582
13
train loss item: 0.4371715486049652
14
train loss item: 0.22235259413719177
15
train loss item: 0.5480186343193054
16
train loss item: 0.044345639646053314
17
train loss item: 0.31017670035362244
18
train loss item: 0.32348161935806274
19
train loss item: 0.2840631902217865
20
train loss item: 0.23280636966228485
21
train loss item: 0.08408249169588089
22
train loss item: 0.7815131545066833
23
train loss item: 0.7502744197845459
24
train loss item: 0.5551159381866455
25
train loss item: 0.14031672477722168
26
train loss item: 0.18907439708709717
27
train loss item: 0.22042003273963928
28
train loss item: 0.03931145742535591
29
train loss item: 0.5648859739303589
30
train loss item: 1.4792219400405884
31
train loss item: 0.5404644012451172
32
train loss item: 0.07403746992349625
33
train loss item: 0.3922503888607025
34
train loss item: 0.07236336916685104
35
train loss item: 1.754595398902893
36
train loss item: 0.44439080357551575
37
train loss item: 0.3147852122783661
38
train loss item: 0.4057900607585907
39
train loss item: 0.2032528966665268
40
train loss item: 0.14497049152851105
41
train loss item: 0.26176100969314575
42
train loss item: 0.2716367840766907
43
train loss item: 0.1781754344701767
44
train loss item: 0.5065404176712036
45
train loss item: 0.09730911999940872
46
train loss item: 0.09679493308067322
47
train loss item: 0.3309871554374695
48
train loss item: 0.23387788236141205
49
train loss item: 0.13665111362934113
50
train loss item: 0.3109009265899658
51
train loss item: 0.7102736830711365
52
train loss item: 0.0459367036819458
53
train loss item: 0.13460147380828857
54
train loss item: 1.594076156616211
55
train loss item: 0.21724803745746613
56
train loss item: 0.23774322867393494
57
train loss item: 0.24397830665111542
58
train loss item: 0.15649060904979706
59
train loss item: 0.0871698185801506
60
train loss item: 0.7920222282409668
61
train loss item: 1.4883997440338135
62
train loss item: 0.1973818689584732
63
train loss item: 0.35258936882019043
64
train loss item: 0.15248233079910278
65
train loss item: 0.5513712167739868
66
train loss item: 0.3886752128601074
67
train loss item: 0.18186984956264496
68
train loss item: 0.32481148838996887
69
train loss item: 0.33087533712387085
70
train loss item: 0.23987066745758057
71
train loss item: 0.10013365745544434
72
train loss item: 0.17231963574886322
73
train loss item: 0.3306821286678314
74
train loss item: 0.045679084956645966
75
train loss item: 0.07978619635105133
76
train loss item: 0.7684051394462585
77
train loss item: 0.9329310655593872
78
train loss item: 0.04442420229315758
79
train loss item: 0.24314036965370178
80
train loss item: 0.09577562659978867
81
train loss item: 0.18129491806030273
82
train loss item: 0.18466147780418396
83
train loss item: 0.4361734688282013
84
train loss item: 0.34155842661857605
85
train loss item: 0.5581908822059631
86
train loss item: 3.257413864135742
87
train loss item: 0.14344221353530884
88
train loss item: 0.33613309264183044
epoch train loss: 0.398288100204441
testing phase
test loss item: 0.19224154949188232
test loss item: 0.08277180045843124
test loss item: 0.6726565361022949
test loss item: 0.2298571765422821
test loss item: 0.25275981426239014
test loss item: 0.11864092946052551
test loss item: 1.957566499710083
test loss item: 0.5887282490730286
test loss item: 0.2260778248310089
test loss item: 0.42046570777893066
test loss item: 0.9471784830093384
test loss item: 0.16421441733837128
test loss item: 0.18707704544067383
test loss item: 0.3616422712802887
test loss item: 0.16858504712581635
test loss item: 0.07061503827571869
test loss item: 0.3530552089214325
test loss item: 0.5092547535896301
test loss item: 0.7133581638336182
test loss item: 0.34137022495269775
test loss item: 0.8417770862579346
test loss item: 0.4280919134616852
test loss item: 0.33366021513938904
test loss item: 0.19462811946868896
test loss item: 0.24670283496379852
test loss item: 0.25577452778816223
test loss item: 0.38314515352249146
test loss item: 0.1915278136730194
test loss item: 0.36832842230796814
test loss item: 0.3820766806602478
test loss item: 0.8900940418243408
test loss item: 0.07133445888757706
test loss item: 0.1597311943769455
test loss item: 0.6376349925994873
test loss item: 0.48052138090133667
test loss item: 0.4299581050872803
test loss item: 0.87706059217453
test loss item: 1.5871838331222534
test loss item: 0.5294616222381592
test loss item: 0.317376047372818
test loss item: 0.346601665019989
test loss item: 0.20479288697242737
test loss item: 0.3734689950942993
test loss item: 0.23347432911396027
test loss item: 0.6765404939651489
test loss item: 0.520177960395813
test loss item: 0.3267490267753601
test loss item: 0.28180065751075745
test loss item: 0.5182724595069885
test loss item: 0.7560527920722961
test loss item: 0.3055521845817566
test loss item: 0.13813181221485138
test loss item: 0.2546352446079254
test loss item: 0.15062221884727478
test loss item: 0.31966495513916016
test loss item: 0.9760670065879822
test loss item: 0.5936359167098999
test loss item: 0.2781832218170166
test loss item: 0.263378769159317
test loss item: 0.20030981302261353
test loss item: 0.46901315450668335
test loss item: 0.2847156524658203
test loss item: 0.2560313940048218
test loss item: 0.2857358157634735
test loss item: 1.0147441625595093
test loss item: 0.3081057667732239
test loss item: 0.3744073510169983
test loss item: 0.29428938031196594
test loss item: 0.5960012674331665
test loss item: 0.436407208442688
test loss item: 0.06267000734806061
test loss item: 1.1237238645553589
test loss item: 0.3660052418708801
test loss item: 0.4973871111869812
test loss item: 0.17304041981697083
test loss item: 0.18732845783233643
test loss item: 0.1948627531528473
test loss item: 1.6418286561965942
test loss item: 0.5464726090431213
test loss item: 0.20794905722141266
test loss item: 0.08125821501016617
test loss item: 1.0841699838638306
test loss item: 0.9837676882743835
test loss item: 1.1087990999221802
test loss item: 0.2544703781604767
test loss item: 0.24831931293010712
test loss item: 0.08249498158693314
test loss item: 0.07834521681070328
test loss item: 0.18198038637638092
Epoch [74/100], Training Loss: 0.3983, Testing Loss: 0.4416
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6970.00 MB
Epoch 75/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4142400920391083
1
train loss item: 0.9708531498908997
2
train loss item: 0.22996489703655243
3
train loss item: 0.485262006521225
4
train loss item: 0.3881114721298218
5
train loss item: 0.31080713868141174
6
train loss item: 0.27250203490257263
7
train loss item: 0.586168110370636
8
train loss item: 0.1269824504852295
9
train loss item: 0.2802131474018097
10
train loss item: 0.3395044803619385
11
train loss item: 0.22926871478557587
12
train loss item: 0.09223642945289612
13
train loss item: 0.4332774877548218
14
train loss item: 0.2201215624809265
15
train loss item: 0.5273351669311523
16
train loss item: 0.04456255957484245
17
train loss item: 0.31141677498817444
18
train loss item: 0.325717568397522
19
train loss item: 0.28184381127357483
20
train loss item: 0.23948055505752563
21
train loss item: 0.08451742678880692
22
train loss item: 0.7484480142593384
23
train loss item: 0.7423944473266602
24
train loss item: 0.5478972792625427
25
train loss item: 0.1398155242204666
26
train loss item: 0.18580274283885956
27
train loss item: 0.2159217745065689
28
train loss item: 0.040402963757514954
29
train loss item: 0.532691478729248
30
train loss item: 1.4379204511642456
31
train loss item: 0.5431947708129883
32
train loss item: 0.07293584942817688
33
train loss item: 0.38237035274505615
34
train loss item: 0.07021379470825195
35
train loss item: 1.7220802307128906
36
train loss item: 0.431845486164093
37
train loss item: 0.31056472659111023
38
train loss item: 0.3898049294948578
39
train loss item: 0.20046396553516388
40
train loss item: 0.14423750340938568
41
train loss item: 0.25175559520721436
42
train loss item: 0.2708922326564789
43
train loss item: 0.17653058469295502
44
train loss item: 0.49013957381248474
45
train loss item: 0.0999809205532074
46
train loss item: 0.09767274558544159
47
train loss item: 0.3271206319332123
48
train loss item: 0.23216775059700012
49
train loss item: 0.13502554595470428
50
train loss item: 0.31265515089035034
51
train loss item: 0.6862674951553345
52
train loss item: 0.0459381602704525
53
train loss item: 0.13383354246616364
54
train loss item: 1.5605610609054565
55
train loss item: 0.21896536648273468
56
train loss item: 0.23388172686100006
57
train loss item: 0.24192842841148376
58
train loss item: 0.15563754737377167
59
train loss item: 0.0837697759270668
60
train loss item: 0.7532035708427429
61
train loss item: 1.4334660768508911
62
train loss item: 0.199374720454216
63
train loss item: 0.3486465513706207
64
train loss item: 0.1494041383266449
65
train loss item: 0.5507261753082275
66
train loss item: 0.3766764998435974
67
train loss item: 0.18153393268585205
68
train loss item: 0.3156846761703491
69
train loss item: 0.3276779055595398
70
train loss item: 0.23632694780826569
71
train loss item: 0.10090108215808868
72
train loss item: 0.17065240442752838
73
train loss item: 0.3280673921108246
74
train loss item: 0.04841895401477814
75
train loss item: 0.07986028492450714
76
train loss item: 0.7528719902038574
77
train loss item: 0.8853380084037781
78
train loss item: 0.04362552985548973
79
train loss item: 0.24177053570747375
80
train loss item: 0.09761872887611389
81
train loss item: 0.17894569039344788
82
train loss item: 0.18437115848064423
83
train loss item: 0.4350942373275757
84
train loss item: 0.33102473616600037
85
train loss item: 0.5471308827400208
86
train loss item: 3.216848850250244
87
train loss item: 0.14168621599674225
88
train loss item: 0.3341367542743683
epoch train loss: 0.3910022673061055
testing phase
test loss item: 0.18967881798744202
test loss item: 0.08448765426874161
test loss item: 0.627027690410614
test loss item: 0.21736972033977509
test loss item: 0.245625838637352
test loss item: 0.11607101559638977
test loss item: 1.8035508394241333
test loss item: 0.5163077116012573
test loss item: 0.20578455924987793
test loss item: 0.39853256940841675
test loss item: 0.8821006417274475
test loss item: 0.14984314143657684
test loss item: 0.1742400825023651
test loss item: 0.338222473859787
test loss item: 0.16297173500061035
test loss item: 0.09070392698049545
test loss item: 0.3221617043018341
test loss item: 0.48979702591896057
test loss item: 0.6666895151138306
test loss item: 0.3039233088493347
test loss item: 0.8185965418815613
test loss item: 0.3833138942718506
test loss item: 0.30971625447273254
test loss item: 0.17909575998783112
test loss item: 0.2358785718679428
test loss item: 0.23786434531211853
test loss item: 0.35919588804244995
test loss item: 0.18855097889900208
test loss item: 0.3480267822742462
test loss item: 0.36306729912757874
test loss item: 0.8140696883201599
test loss item: 0.11868611723184586
test loss item: 0.1497143805027008
test loss item: 0.6128450036048889
test loss item: 0.4599277973175049
test loss item: 0.4027790129184723
test loss item: 0.8199814558029175
test loss item: 1.4718748331069946
test loss item: 0.5046262741088867
test loss item: 0.2908395230770111
test loss item: 0.3259536921977997
test loss item: 0.1864805519580841
test loss item: 0.35977840423583984
test loss item: 0.20911872386932373
test loss item: 0.6591621041297913
test loss item: 0.47630131244659424
test loss item: 0.30892857909202576
test loss item: 0.25362786650657654
test loss item: 0.4794551134109497
test loss item: 0.6981234550476074
test loss item: 0.2949943542480469
test loss item: 0.12763988971710205
test loss item: 0.23821181058883667
test loss item: 0.13568216562271118
test loss item: 0.30845773220062256
test loss item: 0.9219472408294678
test loss item: 0.5547834634780884
test loss item: 0.2721385359764099
test loss item: 0.24150213599205017
test loss item: 0.19712887704372406
test loss item: 0.4505577087402344
test loss item: 0.24228283762931824
test loss item: 0.230515718460083
test loss item: 0.2716147303581238
test loss item: 0.9475434422492981
test loss item: 0.2945576012134552
test loss item: 0.33415210247039795
test loss item: 0.27729344367980957
test loss item: 0.5768606066703796
test loss item: 0.3892412781715393
test loss item: 0.07210767269134521
test loss item: 1.0240790843963623
test loss item: 0.33599936962127686
test loss item: 0.437656968832016
test loss item: 0.1743711233139038
test loss item: 0.1715884953737259
test loss item: 0.17992772161960602
test loss item: 1.527803659439087
test loss item: 0.5097652673721313
test loss item: 0.20203253626823425
test loss item: 0.08396536111831665
test loss item: 0.9869142770767212
test loss item: 0.9162243604660034
test loss item: 1.0156182050704956
test loss item: 0.2277153879404068
test loss item: 0.23544234037399292
test loss item: 0.09414403140544891
test loss item: 0.09163008630275726
test loss item: 0.17909672856330872
Epoch [75/100], Training Loss: 0.3910, Testing Loss: 0.4133
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 76/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.44154220819473267
1
train loss item: 1.0115281343460083
2
train loss item: 0.22219794988632202
3
train loss item: 0.48989391326904297
4
train loss item: 0.4059833884239197
5
train loss item: 0.32527706027030945
6
train loss item: 0.2535886764526367
7
train loss item: 0.5902674794197083
8
train loss item: 0.12336868792772293
9
train loss item: 0.2524244785308838
10
train loss item: 0.349216103553772
11
train loss item: 0.24450291693210602
12
train loss item: 0.09122727811336517
13
train loss item: 0.4492003321647644
14
train loss item: 0.2233387976884842
15
train loss item: 0.4988103210926056
16
train loss item: 0.04466808959841728
17
train loss item: 0.29215970635414124
18
train loss item: 0.34917089343070984
19
train loss item: 0.25516369938850403
20
train loss item: 0.21441039443016052
21
train loss item: 0.08454947918653488
22
train loss item: 0.7610509991645813
23
train loss item: 0.7722998261451721
24
train loss item: 0.5478578805923462
25
train loss item: 0.1494908183813095
26
train loss item: 0.18274037539958954
27
train loss item: 0.20542213320732117
28
train loss item: 0.040882524102926254
29
train loss item: 0.5050618648529053
30
train loss item: 1.4188355207443237
31
train loss item: 0.5950512886047363
32
train loss item: 0.07442250102758408
33
train loss item: 0.36736491322517395
34
train loss item: 0.0744229182600975
35
train loss item: 1.6953333616256714
36
train loss item: 0.45779353380203247
37
train loss item: 0.354696124792099
38
train loss item: 0.42732757329940796
39
train loss item: 0.20142818987369537
40
train loss item: 0.13787059485912323
41
train loss item: 0.2553236186504364
42
train loss item: 0.27336323261260986
43
train loss item: 0.1738327294588089
44
train loss item: 0.48218366503715515
45
train loss item: 0.10010845959186554
46
train loss item: 0.10232575982809067
47
train loss item: 0.31828573346138
48
train loss item: 0.21802373230457306
49
train loss item: 0.13745974004268646
50
train loss item: 0.3038255274295807
51
train loss item: 0.7182714939117432
52
train loss item: 0.0439816489815712
53
train loss item: 0.13019083440303802
54
train loss item: 1.5394006967544556
55
train loss item: 0.20567545294761658
56
train loss item: 0.2599693238735199
57
train loss item: 0.2336794137954712
58
train loss item: 0.15192320942878723
59
train loss item: 0.08478102833032608
60
train loss item: 0.697537899017334
61
train loss item: 1.3903158903121948
62
train loss item: 0.19362403452396393
63
train loss item: 0.3457067608833313
64
train loss item: 0.15045835077762604
65
train loss item: 0.6086248159408569
66
train loss item: 0.41074317693710327
67
train loss item: 0.17630918323993683
68
train loss item: 0.27130094170570374
69
train loss item: 0.34298962354660034
70
train loss item: 0.2436092346906662
71
train loss item: 0.09592968970537186
72
train loss item: 0.1621474176645279
73
train loss item: 0.3037060797214508
74
train loss item: 0.04524209722876549
75
train loss item: 0.07630286365747452
76
train loss item: 0.7402975559234619
77
train loss item: 0.8422170281410217
78
train loss item: 0.04645872116088867
79
train loss item: 0.23864275217056274
80
train loss item: 0.0974823608994484
81
train loss item: 0.16555479168891907
82
train loss item: 0.18309342861175537
83
train loss item: 0.551399827003479
84
train loss item: 0.3904520273208618
85
train loss item: 0.5332055687904358
86
train loss item: 3.1900553703308105
87
train loss item: 0.1347532421350479
88
train loss item: 0.35877591371536255
epoch train loss: 0.39215039189779355
testing phase
test loss item: 0.1986755132675171
test loss item: 0.10285228490829468
test loss item: 0.6484320163726807
test loss item: 0.22060856223106384
test loss item: 0.24180780351161957
test loss item: 0.10851908475160599
test loss item: 1.7483539581298828
test loss item: 0.45827165246009827
test loss item: 0.21809525787830353
test loss item: 0.3995404839515686
test loss item: 0.899486780166626
test loss item: 0.15380539000034332
test loss item: 0.1652204990386963
test loss item: 0.3325333297252655
test loss item: 0.16589801013469696
test loss item: 0.11686629801988602
test loss item: 0.31149885058403015
test loss item: 0.49362847208976746
test loss item: 0.6314685344696045
test loss item: 0.28462734818458557
test loss item: 0.8240348100662231
test loss item: 0.36462512612342834
test loss item: 0.30751171708106995
test loss item: 0.1829102337360382
test loss item: 0.2370041161775589
test loss item: 0.22841191291809082
test loss item: 0.35553842782974243
test loss item: 0.18248063325881958
test loss item: 0.3431273400783539
test loss item: 0.35813331604003906
test loss item: 0.81083744764328
test loss item: 0.1597476601600647
test loss item: 0.15583951771259308
test loss item: 0.6235763430595398
test loss item: 0.46968764066696167
test loss item: 0.39446356892585754
test loss item: 0.7892053127288818
test loss item: 1.5109295845031738
test loss item: 0.5080307126045227
test loss item: 0.28329184651374817
test loss item: 0.3236484229564667
test loss item: 0.18687614798545837
test loss item: 0.3661135733127594
test loss item: 0.20852597057819366
test loss item: 0.6598199605941772
test loss item: 0.45262962579727173
test loss item: 0.30389833450317383
test loss item: 0.23683521151542664
test loss item: 0.4791380763053894
test loss item: 0.6957355737686157
test loss item: 0.2970038056373596
test loss item: 0.12098873406648636
test loss item: 0.23785853385925293
test loss item: 0.138639435172081
test loss item: 0.3121137320995331
test loss item: 0.9427859783172607
test loss item: 0.5407682061195374
test loss item: 0.26676684617996216
test loss item: 0.23278574645519257
test loss item: 0.19720026850700378
test loss item: 0.45945417881011963
test loss item: 0.21862298250198364
test loss item: 0.21960535645484924
test loss item: 0.26686352491378784
test loss item: 0.9494320750236511
test loss item: 0.29432201385498047
test loss item: 0.3158663511276245
test loss item: 0.27083489298820496
test loss item: 0.5826098918914795
test loss item: 0.36967551708221436
test loss item: 0.08299801498651505
test loss item: 0.9717531800270081
test loss item: 0.3300267159938812
test loss item: 0.4204016923904419
test loss item: 0.198025181889534
test loss item: 0.16821308434009552
test loss item: 0.18275851011276245
test loss item: 1.5585215091705322
test loss item: 0.5082128643989563
test loss item: 0.19345344603061676
test loss item: 0.09604564309120178
test loss item: 0.9799603819847107
test loss item: 0.900887668132782
test loss item: 1.0393849611282349
test loss item: 0.22129294276237488
test loss item: 0.25680673122406006
test loss item: 0.11623278260231018
test loss item: 0.12224579602479935
test loss item: 0.1729980856180191
Epoch [76/100], Training Loss: 0.3922, Testing Loss: 0.4119
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 77/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41811230778694153
1
train loss item: 0.9686247110366821
2
train loss item: 0.22378912568092346
3
train loss item: 0.47189196944236755
4
train loss item: 0.3875345289707184
5
train loss item: 0.3167163133621216
6
train loss item: 0.2510886788368225
7
train loss item: 0.5617086291313171
8
train loss item: 0.12495924532413483
9
train loss item: 0.25441205501556396
10
train loss item: 0.33664464950561523
11
train loss item: 0.23547539114952087
12
train loss item: 0.09090482443571091
13
train loss item: 0.4504542946815491
14
train loss item: 0.23178015649318695
15
train loss item: 0.48296090960502625
16
train loss item: 0.04141584411263466
17
train loss item: 0.2902539074420929
18
train loss item: 0.3329504728317261
19
train loss item: 0.25289952754974365
20
train loss item: 0.20812317728996277
21
train loss item: 0.08598152548074722
22
train loss item: 0.7257426977157593
23
train loss item: 0.7471774816513062
24
train loss item: 0.5174697637557983
25
train loss item: 0.14704275131225586
26
train loss item: 0.18099643290042877
27
train loss item: 0.2140030413866043
28
train loss item: 0.037648674100637436
29
train loss item: 0.5031493902206421
30
train loss item: 1.4093400239944458
31
train loss item: 0.5546651482582092
32
train loss item: 0.07525286078453064
33
train loss item: 0.37806975841522217
34
train loss item: 0.076972097158432
35
train loss item: 1.6752883195877075
36
train loss item: 0.4432620704174042
37
train loss item: 0.33329054713249207
38
train loss item: 0.42283132672309875
39
train loss item: 0.19981245696544647
40
train loss item: 0.13647112250328064
41
train loss item: 0.2600165903568268
42
train loss item: 0.26531660556793213
43
train loss item: 0.17318882048130035
44
train loss item: 0.48311567306518555
45
train loss item: 0.10061132907867432
46
train loss item: 0.10019625723361969
47
train loss item: 0.30660897493362427
48
train loss item: 0.22155563533306122
49
train loss item: 0.1402529925107956
50
train loss item: 0.296889066696167
51
train loss item: 0.6791366338729858
52
train loss item: 0.04463544115424156
53
train loss item: 0.13365325331687927
54
train loss item: 1.515397071838379
55
train loss item: 0.20666009187698364
56
train loss item: 0.24876020848751068
57
train loss item: 0.2358514666557312
58
train loss item: 0.14971788227558136
59
train loss item: 0.08005310595035553
60
train loss item: 0.7184659242630005
61
train loss item: 1.397537112236023
62
train loss item: 0.19427691400051117
63
train loss item: 0.3308551609516144
64
train loss item: 0.1509896218776703
65
train loss item: 0.5717357993125916
66
train loss item: 0.37755057215690613
67
train loss item: 0.1754312515258789
68
train loss item: 0.2645013630390167
69
train loss item: 0.32034561038017273
70
train loss item: 0.2339549958705902
71
train loss item: 0.09624198079109192
72
train loss item: 0.16700197756290436
73
train loss item: 0.3024839758872986
74
train loss item: 0.043821197003126144
75
train loss item: 0.07727985084056854
76
train loss item: 0.7382702827453613
77
train loss item: 0.8365458250045776
78
train loss item: 0.048239752650260925
79
train loss item: 0.2282608449459076
80
train loss item: 0.09387320280075073
81
train loss item: 0.1656952053308487
82
train loss item: 0.18599756062030792
83
train loss item: 0.4557473063468933
84
train loss item: 0.3494115173816681
85
train loss item: 0.5333371758460999
86
train loss item: 3.156095027923584
87
train loss item: 0.13903486728668213
88
train loss item: 0.33159294724464417
epoch train loss: 0.38340854083888987
testing phase
test loss item: 0.18615703284740448
test loss item: 0.07868123054504395
test loss item: 0.6686625480651855
test loss item: 0.22301767766475677
test loss item: 0.2507006525993347
test loss item: 0.11815813928842545
test loss item: 1.9294105768203735
test loss item: 0.5580213665962219
test loss item: 0.22212181985378265
test loss item: 0.4109829068183899
test loss item: 0.9269204139709473
test loss item: 0.1603284776210785
test loss item: 0.1803966611623764
test loss item: 0.3477560877799988
test loss item: 0.16671141982078552
test loss item: 0.06150126829743385
test loss item: 0.3331841230392456
test loss item: 0.5009616017341614
test loss item: 0.6828880310058594
test loss item: 0.31917813420295715
test loss item: 0.834373414516449
test loss item: 0.40765830874443054
test loss item: 0.32651135325431824
test loss item: 0.18703031539916992
test loss item: 0.23840925097465515
test loss item: 0.24716182053089142
test loss item: 0.36755916476249695
test loss item: 0.1902279108762741
test loss item: 0.3571372330188751
test loss item: 0.36947816610336304
test loss item: 0.8761294484138489
test loss item: 0.06459878385066986
test loss item: 0.15364308655261993
test loss item: 0.6345332264900208
test loss item: 0.4742774963378906
test loss item: 0.412320077419281
test loss item: 0.8485881686210632
test loss item: 1.566695213317871
test loss item: 0.5205402374267578
test loss item: 0.3063560128211975
test loss item: 0.33364561200141907
test loss item: 0.19730323553085327
test loss item: 0.3699738383293152
test loss item: 0.22124458849430084
test loss item: 0.6667687892913818
test loss item: 0.48906993865966797
test loss item: 0.31611356139183044
test loss item: 0.26560860872268677
test loss item: 0.504525363445282
test loss item: 0.7393928170204163
test loss item: 0.2989620268344879
test loss item: 0.13235460221767426
test loss item: 0.2444101721048355
test loss item: 0.13942532241344452
test loss item: 0.3165309727191925
test loss item: 0.9653303027153015
test loss item: 0.5772554874420166
test loss item: 0.27088016271591187
test loss item: 0.24950478971004486
test loss item: 0.1983460932970047
test loss item: 0.4631466567516327
test loss item: 0.2585320472717285
test loss item: 0.24106408655643463
test loss item: 0.27650272846221924
test loss item: 1.0034371614456177
test loss item: 0.2975864112377167
test loss item: 0.3525742292404175
test loss item: 0.28465166687965393
test loss item: 0.5900011658668518
test loss item: 0.4074540138244629
test loss item: 0.06174667179584503
test loss item: 1.0907762050628662
test loss item: 0.35257425904273987
test loss item: 0.4723406732082367
test loss item: 0.1658240109682083
test loss item: 0.17854583263397217
test loss item: 0.1884266436100006
test loss item: 1.6275944709777832
test loss item: 0.532940149307251
test loss item: 0.20214562118053436
test loss item: 0.08201108127832413
test loss item: 1.0598397254943848
test loss item: 0.9597588777542114
test loss item: 1.0936557054519653
test loss item: 0.24421674013137817
test loss item: 0.25269174575805664
test loss item: 0.07759992778301239
test loss item: 0.06871579587459564
test loss item: 0.18729816377162933
Epoch [77/100], Training Loss: 0.3834, Testing Loss: 0.4301
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 78/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.40894052386283875
1
train loss item: 0.9640550017356873
2
train loss item: 0.2213185578584671
3
train loss item: 0.4758685529232025
4
train loss item: 0.3873055577278137
5
train loss item: 0.3059707283973694
6
train loss item: 0.25757384300231934
7
train loss item: 0.5680521130561829
8
train loss item: 0.12235807627439499
9
train loss item: 0.2684917151927948
10
train loss item: 0.333276629447937
11
train loss item: 0.22290633618831635
12
train loss item: 0.08740104734897614
13
train loss item: 0.431723028421402
14
train loss item: 0.22167430818080902
15
train loss item: 0.5230873227119446
16
train loss item: 0.04047195613384247
17
train loss item: 0.29557618498802185
18
train loss item: 0.3248308002948761
19
train loss item: 0.27197760343551636
20
train loss item: 0.2258559614419937
21
train loss item: 0.0819525271654129
22
train loss item: 0.7264847159385681
23
train loss item: 0.7264552712440491
24
train loss item: 0.5444334149360657
25
train loss item: 0.14132869243621826
26
train loss item: 0.178551584482193
27
train loss item: 0.21109837293624878
28
train loss item: 0.036996111273765564
29
train loss item: 0.541298508644104
30
train loss item: 1.4005374908447266
31
train loss item: 0.5351034998893738
32
train loss item: 0.07269196957349777
33
train loss item: 0.3741132318973541
34
train loss item: 0.0741504430770874
35
train loss item: 1.6777292490005493
36
train loss item: 0.44246938824653625
37
train loss item: 0.2951701581478119
38
train loss item: 0.3927243947982788
39
train loss item: 0.19986668229103088
40
train loss item: 0.13986167311668396
41
train loss item: 0.2511155605316162
42
train loss item: 0.26602649688720703
43
train loss item: 0.17156051099300385
44
train loss item: 0.4846978485584259
45
train loss item: 0.09609867632389069
46
train loss item: 0.09518792480230331
47
train loss item: 0.32625624537467957
48
train loss item: 0.22474990785121918
49
train loss item: 0.13335692882537842
50
train loss item: 0.30807116627693176
51
train loss item: 0.7088893055915833
52
train loss item: 0.04442224279046059
53
train loss item: 0.13022218644618988
54
train loss item: 1.5099678039550781
55
train loss item: 0.20880748331546783
56
train loss item: 0.23405063152313232
57
train loss item: 0.23345959186553955
58
train loss item: 0.14941395819187164
59
train loss item: 0.08186023682355881
60
train loss item: 0.7720038294792175
61
train loss item: 1.3801772594451904
62
train loss item: 0.19207195937633514
63
train loss item: 0.3432588279247284
64
train loss item: 0.1477101892232895
65
train loss item: 0.5331449508666992
66
train loss item: 0.36296939849853516
67
train loss item: 0.17693524062633514
68
train loss item: 0.2932203710079193
69
train loss item: 0.3209089934825897
70
train loss item: 0.23533658683300018
71
train loss item: 0.09606964886188507
72
train loss item: 0.16477322578430176
73
train loss item: 0.31523609161376953
74
train loss item: 0.04508048668503761
75
train loss item: 0.07768405228853226
76
train loss item: 0.7416368722915649
77
train loss item: 0.8908105492591858
78
train loss item: 0.04530079662799835
79
train loss item: 0.24138200283050537
80
train loss item: 0.08766571432352066
81
train loss item: 0.17369325459003448
82
train loss item: 0.1800415813922882
83
train loss item: 0.4207499325275421
84
train loss item: 0.3187713921070099
85
train loss item: 0.5505725145339966
86
train loss item: 3.1287410259246826
87
train loss item: 0.1371336728334427
88
train loss item: 0.33068910241127014
epoch train loss: 0.38330019617013716
testing phase
test loss item: 0.1831684559583664
test loss item: 0.08392525464296341
test loss item: 0.6355377435684204
test loss item: 0.2184855341911316
test loss item: 0.25357991456985474
test loss item: 0.13785451650619507
test loss item: 1.8876551389694214
test loss item: 0.5233765244483948
test loss item: 0.21340082585811615
test loss item: 0.4004374146461487
test loss item: 0.8942365646362305
test loss item: 0.15506145358085632
test loss item: 0.1763571798801422
test loss item: 0.3423234820365906
test loss item: 0.1652057021856308
test loss item: 0.05363718420267105
test loss item: 0.3217785656452179
test loss item: 0.48712432384490967
test loss item: 0.6607667803764343
test loss item: 0.3075352907180786
test loss item: 0.8059849739074707
test loss item: 0.3931932747364044
test loss item: 0.31631726026535034
test loss item: 0.1832505166530609
test loss item: 0.23233242332935333
test loss item: 0.2423468381166458
test loss item: 0.3584354817867279
test loss item: 0.19962178170681
test loss item: 0.3518133759498596
test loss item: 0.3620065152645111
test loss item: 0.8478133082389832
test loss item: 0.047967661172151566
test loss item: 0.15122577548027039
test loss item: 0.6140416264533997
test loss item: 0.45678582787513733
test loss item: 0.40158379077911377
test loss item: 0.8251515626907349
test loss item: 1.50307297706604
test loss item: 0.5051660537719727
test loss item: 0.3050435185432434
test loss item: 0.32537347078323364
test loss item: 0.19267569482326508
test loss item: 0.3621664345264435
test loss item: 0.21154968440532684
test loss item: 0.6483050584793091
test loss item: 0.470120370388031
test loss item: 0.30863380432128906
test loss item: 0.2585597634315491
test loss item: 0.4820918142795563
test loss item: 0.7103474736213684
test loss item: 0.29183971881866455
test loss item: 0.1293739527463913
test loss item: 0.23850756883621216
test loss item: 0.13283489644527435
test loss item: 0.30835387110710144
test loss item: 0.9241533279418945
test loss item: 0.5560919046401978
test loss item: 0.26002538204193115
test loss item: 0.24172808229923248
test loss item: 0.19820263981819153
test loss item: 0.454677939414978
test loss item: 0.2411850243806839
test loss item: 0.2344694584608078
test loss item: 0.2717117965221405
test loss item: 0.9517139196395874
test loss item: 0.29204535484313965
test loss item: 0.338420033454895
test loss item: 0.281155526638031
test loss item: 0.5700819492340088
test loss item: 0.3865087628364563
test loss item: 0.06760010868310928
test loss item: 1.0550549030303955
test loss item: 0.34234729409217834
test loss item: 0.4569614827632904
test loss item: 0.15786978602409363
test loss item: 0.1769098937511444
test loss item: 0.18523858487606049
test loss item: 1.5523836612701416
test loss item: 0.5179831385612488
test loss item: 0.2111787050962448
test loss item: 0.08331665396690369
test loss item: 1.0155612230300903
test loss item: 0.9334236979484558
test loss item: 1.0397518873214722
test loss item: 0.23879796266555786
test loss item: 0.2462076097726822
test loss item: 0.07334065437316895
test loss item: 0.05272287875413895
test loss item: 0.18480481207370758
Epoch [78/100], Training Loss: 0.3833, Testing Loss: 0.4165
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 79/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4182049632072449
1
train loss item: 0.957081139087677
2
train loss item: 0.21627485752105713
3
train loss item: 0.4705677628517151
4
train loss item: 0.41172322630882263
5
train loss item: 0.3104020655155182
6
train loss item: 0.2512257695198059
7
train loss item: 0.5744447112083435
8
train loss item: 0.12164755165576935
9
train loss item: 0.25394177436828613
10
train loss item: 0.3360990881919861
11
train loss item: 0.2235085666179657
12
train loss item: 0.08722695708274841
13
train loss item: 0.42388707399368286
14
train loss item: 0.21438159048557281
15
train loss item: 0.48966196179389954
16
train loss item: 0.04255521297454834
17
train loss item: 0.2864205539226532
18
train loss item: 0.32611197233200073
19
train loss item: 0.26011455059051514
20
train loss item: 0.21344773471355438
21
train loss item: 0.08190367370843887
22
train loss item: 0.7052907347679138
23
train loss item: 0.7330152988433838
24
train loss item: 0.5363244414329529
25
train loss item: 0.14724892377853394
26
train loss item: 0.18339481949806213
27
train loss item: 0.20144806802272797
28
train loss item: 0.039687544107437134
29
train loss item: 0.49989190697669983
30
train loss item: 1.3697822093963623
31
train loss item: 0.5634932518005371
32
train loss item: 0.07963267713785172
33
train loss item: 0.3608144223690033
34
train loss item: 0.0814475417137146
35
train loss item: 1.6566683053970337
36
train loss item: 0.4306304156780243
37
train loss item: 0.30489516258239746
38
train loss item: 0.4093724191188812
39
train loss item: 0.19878411293029785
40
train loss item: 0.13988041877746582
41
train loss item: 0.24512863159179688
42
train loss item: 0.2596123218536377
43
train loss item: 0.173555389046669
44
train loss item: 0.4783896803855896
45
train loss item: 0.09273575246334076
46
train loss item: 0.10133785754442215
47
train loss item: 0.31586408615112305
48
train loss item: 0.2163715362548828
49
train loss item: 0.13317522406578064
50
train loss item: 0.30218660831451416
51
train loss item: 0.678351879119873
52
train loss item: 0.04450388625264168
53
train loss item: 0.1251877397298813
54
train loss item: 1.4879951477050781
55
train loss item: 0.19882139563560486
56
train loss item: 0.23786881566047668
57
train loss item: 0.22415144741535187
58
train loss item: 0.15147031843662262
59
train loss item: 0.08811867237091064
60
train loss item: 0.7249894738197327
61
train loss item: 1.34474515914917
62
train loss item: 0.18474335968494415
63
train loss item: 0.3313232958316803
64
train loss item: 0.15045565366744995
65
train loss item: 0.5467208623886108
66
train loss item: 0.35616734623908997
67
train loss item: 0.17316502332687378
68
train loss item: 0.2686663568019867
69
train loss item: 0.31872180104255676
70
train loss item: 0.23390528559684753
71
train loss item: 0.0930570662021637
72
train loss item: 0.15848249197006226
73
train loss item: 0.30307793617248535
74
train loss item: 0.04502490162849426
75
train loss item: 0.07859233021736145
76
train loss item: 0.725963830947876
77
train loss item: 0.8569827675819397
78
train loss item: 0.04689865931868553
79
train loss item: 0.23244443535804749
80
train loss item: 0.09263023734092712
81
train loss item: 0.16659289598464966
82
train loss item: 0.17740267515182495
83
train loss item: 0.4095487594604492
84
train loss item: 0.3121863007545471
85
train loss item: 0.5336642861366272
86
train loss item: 3.0961544513702393
87
train loss item: 0.13167229294776917
88
train loss item: 0.3380030691623688
epoch train loss: 0.377520728395896
testing phase
test loss item: 0.181541308760643
test loss item: 0.07575731724500656
test loss item: 0.6262851357460022
test loss item: 0.21140210330486298
test loss item: 0.23625986278057098
test loss item: 0.10688576102256775
test loss item: 1.6922155618667603
test loss item: 0.4121474325656891
test loss item: 0.213642880320549
test loss item: 0.39495325088500977
test loss item: 0.8915585875511169
test loss item: 0.14659534394741058
test loss item: 0.16058456897735596
test loss item: 0.3307090699672699
test loss item: 0.15779440104961395
test loss item: 0.06691854447126389
test loss item: 0.29599031805992126
test loss item: 0.48171359300613403
test loss item: 0.602014422416687
test loss item: 0.2734324038028717
test loss item: 0.7905271649360657
test loss item: 0.3488556742668152
test loss item: 0.2968161106109619
test loss item: 0.17008602619171143
test loss item: 0.22934751212596893
test loss item: 0.221871480345726
test loss item: 0.34449097514152527
test loss item: 0.18131713569164276
test loss item: 0.33455124497413635
test loss item: 0.3531264066696167
test loss item: 0.7991106510162354
test loss item: 0.07153328508138657
test loss item: 0.1425221562385559
test loss item: 0.6071926951408386
test loss item: 0.4525933563709259
test loss item: 0.39651209115982056
test loss item: 0.7582079768180847
test loss item: 1.4992116689682007
test loss item: 0.49237513542175293
test loss item: 0.2752934694290161
test loss item: 0.30579009652137756
test loss item: 0.1803799271583557
test loss item: 0.36349353194236755
test loss item: 0.19547870755195618
test loss item: 0.6368857026100159
test loss item: 0.42341628670692444
test loss item: 0.2964843511581421
test loss item: 0.23432861268520355
test loss item: 0.46317818760871887
test loss item: 0.6855785846710205
test loss item: 0.28926315903663635
test loss item: 0.11851046234369278
test loss item: 0.23073464632034302
test loss item: 0.13173039257526398
test loss item: 0.3050842583179474
test loss item: 0.9209280014038086
test loss item: 0.5222538113594055
test loss item: 0.24551056325435638
test loss item: 0.22454985976219177
test loss item: 0.1955982893705368
test loss item: 0.45915794372558594
test loss item: 0.19704996049404144
test loss item: 0.21166518330574036
test loss item: 0.2590790092945099
test loss item: 0.9022505283355713
test loss item: 0.28728315234184265
test loss item: 0.30282992124557495
test loss item: 0.2629452049732208
test loss item: 0.5587871074676514
test loss item: 0.358907550573349
test loss item: 0.0617956817150116
test loss item: 0.9188676476478577
test loss item: 0.32416024804115295
test loss item: 0.40524691343307495
test loss item: 0.1429138481616974
test loss item: 0.1674710065126419
test loss item: 0.1711331456899643
test loss item: 1.5262902975082397
test loss item: 0.499114990234375
test loss item: 0.18939176201820374
test loss item: 0.08297998458147049
test loss item: 0.9510343670845032
test loss item: 0.8778297305107117
test loss item: 1.021899700164795
test loss item: 0.21826787292957306
test loss item: 0.22339661419391632
test loss item: 0.08193885535001755
test loss item: 0.07801038771867752
test loss item: 0.15607750415802002
Epoch [79/100], Training Loss: 0.3775, Testing Loss: 0.3954
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6852.00 MB
Epoch 80/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.41940397024154663
1
train loss item: 0.9506564140319824
2
train loss item: 0.21797488629817963
3
train loss item: 0.4799535870552063
4
train loss item: 0.4052664041519165
5
train loss item: 0.3170177936553955
6
train loss item: 0.2604873478412628
7
train loss item: 0.5571318864822388
8
train loss item: 0.12616679072380066
9
train loss item: 0.24834682047367096
10
train loss item: 0.33794498443603516
11
train loss item: 0.23828114569187164
12
train loss item: 0.09292320907115936
13
train loss item: 0.44107183814048767
14
train loss item: 0.22312809526920319
15
train loss item: 0.4904187023639679
16
train loss item: 0.04356537014245987
17
train loss item: 0.2968396246433258
18
train loss item: 0.3355923295021057
19
train loss item: 0.2532585561275482
20
train loss item: 0.2183363139629364
21
train loss item: 0.09927354753017426
22
train loss item: 0.7163619995117188
23
train loss item: 0.7389646172523499
24
train loss item: 0.5151215195655823
25
train loss item: 0.1467878669500351
26
train loss item: 0.20069751143455505
27
train loss item: 0.19944213330745697
28
train loss item: 0.04088829457759857
29
train loss item: 0.4952118396759033
30
train loss item: 1.3617427349090576
31
train loss item: 0.5729528665542603
32
train loss item: 0.07802634686231613
33
train loss item: 0.3607570230960846
34
train loss item: 0.10626626759767532
35
train loss item: 1.6231956481933594
36
train loss item: 0.44018012285232544
37
train loss item: 0.34361085295677185
38
train loss item: 0.43614351749420166
39
train loss item: 0.1975136250257492
40
train loss item: 0.13715820014476776
41
train loss item: 0.25308695435523987
42
train loss item: 0.2585846185684204
43
train loss item: 0.17778851091861725
44
train loss item: 0.4745872914791107
45
train loss item: 0.09189154207706451
46
train loss item: 0.09969677031040192
47
train loss item: 0.30634933710098267
48
train loss item: 0.2134648561477661
49
train loss item: 0.1396014541387558
50
train loss item: 0.3000524342060089
51
train loss item: 0.6539232730865479
52
train loss item: 0.04441540688276291
53
train loss item: 0.124216727912426
54
train loss item: 1.4579546451568604
55
train loss item: 0.19314521551132202
56
train loss item: 0.2454204112291336
57
train loss item: 0.2215142399072647
58
train loss item: 0.1571730673313141
59
train loss item: 0.08313265442848206
60
train loss item: 0.6952266097068787
61
train loss item: 1.3399971723556519
62
train loss item: 0.19040584564208984
63
train loss item: 0.32691115140914917
64
train loss item: 0.14764484763145447
65
train loss item: 0.5992516875267029
66
train loss item: 0.372407466173172
67
train loss item: 0.17948800325393677
68
train loss item: 0.25249001383781433
69
train loss item: 0.3196060061454773
70
train loss item: 0.2398735135793686
71
train loss item: 0.09865210950374603
72
train loss item: 0.15851721167564392
73
train loss item: 0.29352131485939026
74
train loss item: 0.04892861470580101
75
train loss item: 0.08139865100383759
76
train loss item: 0.7195718288421631
77
train loss item: 0.8022152781486511
78
train loss item: 0.05026474595069885
79
train loss item: 0.23059479892253876
80
train loss item: 0.09300577640533447
81
train loss item: 0.16263189911842346
82
train loss item: 0.17987245321273804
83
train loss item: 0.4157083332538605
84
train loss item: 0.35079512000083923
85
train loss item: 0.5252994894981384
86
train loss item: 3.0680627822875977
87
train loss item: 0.12658779323101044
88
train loss item: 0.3461219370365143
epoch train loss: 0.3783720727130938
testing phase
test loss item: 0.18679825961589813
test loss item: 0.07461342960596085
test loss item: 0.625580370426178
test loss item: 0.2178661823272705
test loss item: 0.23758740723133087
test loss item: 0.11593151092529297
test loss item: 1.776272177696228
test loss item: 0.5131046772003174
test loss item: 0.21329627931118011
test loss item: 0.39753612875938416
test loss item: 0.8803777098655701
test loss item: 0.1525222808122635
test loss item: 0.17664141952991486
test loss item: 0.34419456124305725
test loss item: 0.15773163735866547
test loss item: 0.06828811764717102
test loss item: 0.32251569628715515
test loss item: 0.48006582260131836
test loss item: 0.6458810567855835
test loss item: 0.3049846589565277
test loss item: 0.7863702178001404
test loss item: 0.38555073738098145
test loss item: 0.3095872402191162
test loss item: 0.18014846742153168
test loss item: 0.23255738615989685
test loss item: 0.23737552762031555
test loss item: 0.3565863072872162
test loss item: 0.18454255163669586
test loss item: 0.3392826020717621
test loss item: 0.36260178685188293
test loss item: 0.8141927719116211
test loss item: 0.07481273263692856
test loss item: 0.15063175559043884
test loss item: 0.6040210723876953
test loss item: 0.4490049183368683
test loss item: 0.40126076340675354
test loss item: 0.7994418740272522
test loss item: 1.481896996498108
test loss item: 0.49101313948631287
test loss item: 0.2898663580417633
test loss item: 0.31961506605148315
test loss item: 0.1994277834892273
test loss item: 0.3596271872520447
test loss item: 0.2108009308576584
test loss item: 0.6336046457290649
test loss item: 0.46665337681770325
test loss item: 0.30637720227241516
test loss item: 0.2633536458015442
test loss item: 0.47580403089523315
test loss item: 0.6967593431472778
test loss item: 0.28386688232421875
test loss item: 0.13751843571662903
test loss item: 0.23613935708999634
test loss item: 0.14077141880989075
test loss item: 0.301618367433548
test loss item: 0.9052850604057312
test loss item: 0.5494415163993835
test loss item: 0.24948807060718536
test loss item: 0.24364688992500305
test loss item: 0.1915261447429657
test loss item: 0.45291441679000854
test loss item: 0.24825897812843323
test loss item: 0.2356911599636078
test loss item: 0.2661920487880707
test loss item: 0.9221330881118774
test loss item: 0.29291629791259766
test loss item: 0.3382304608821869
test loss item: 0.27172061800956726
test loss item: 0.5541974902153015
test loss item: 0.38549143075942993
test loss item: 0.06131916493177414
test loss item: 0.9995100498199463
test loss item: 0.341249018907547
test loss item: 0.44423428177833557
test loss item: 0.16136011481285095
test loss item: 0.1807071566581726
test loss item: 0.17978093028068542
test loss item: 1.519255518913269
test loss item: 0.5120490789413452
test loss item: 0.19971083104610443
test loss item: 0.08151815086603165
test loss item: 0.9811384677886963
test loss item: 0.9069733023643494
test loss item: 1.0191212892532349
test loss item: 0.23260536789894104
test loss item: 0.23520174622535706
test loss item: 0.08137670159339905
test loss item: 0.07584621757268906
test loss item: 0.17238430678844452
Epoch [80/100], Training Loss: 0.3784, Testing Loss: 0.4084
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 81/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.39974600076675415
1
train loss item: 0.9441879987716675
2
train loss item: 0.2148243933916092
3
train loss item: 0.4640164077281952
4
train loss item: 0.3776923418045044
5
train loss item: 0.304922491312027
6
train loss item: 0.2491040676832199
7
train loss item: 0.5547640323638916
8
train loss item: 0.12187795341014862
9
train loss item: 0.2540988624095917
10
train loss item: 0.32783597707748413
11
train loss item: 0.22299814224243164
12
train loss item: 0.08717571943998337
13
train loss item: 0.42320823669433594
14
train loss item: 0.21590816974639893
15
train loss item: 0.48232918977737427
16
train loss item: 0.038976483047008514
17
train loss item: 0.2849425971508026
18
train loss item: 0.31702813506126404
19
train loss item: 0.25549668073654175
20
train loss item: 0.21613381803035736
21
train loss item: 0.07781881839036942
22
train loss item: 0.69926518201828
23
train loss item: 0.7164023518562317
24
train loss item: 0.5274673104286194
25
train loss item: 0.13595667481422424
26
train loss item: 0.17753806710243225
27
train loss item: 0.20030087232589722
28
train loss item: 0.03516465798020363
29
train loss item: 0.49608832597732544
30
train loss item: 1.339924931526184
31
train loss item: 0.535119891166687
32
train loss item: 0.07159058004617691
33
train loss item: 0.36791616678237915
34
train loss item: 0.07678733021020889
35
train loss item: 1.6077567338943481
36
train loss item: 0.4252225458621979
37
train loss item: 0.3061434030532837
38
train loss item: 0.37177565693855286
39
train loss item: 0.19453935325145721
40
train loss item: 0.1346805989742279
41
train loss item: 0.2474205493927002
42
train loss item: 0.2551521062850952
43
train loss item: 0.16557849943637848
44
train loss item: 0.47092267870903015
45
train loss item: 0.09222088754177094
46
train loss item: 0.09382683038711548
47
train loss item: 0.30822715163230896
48
train loss item: 0.2172231823205948
49
train loss item: 0.13058079779148102
50
train loss item: 0.300327330827713
51
train loss item: 0.6559686064720154
52
train loss item: 0.04261196404695511
53
train loss item: 0.12311223149299622
54
train loss item: 1.4412071704864502
55
train loss item: 0.1990184485912323
56
train loss item: 0.22663603723049164
57
train loss item: 0.22248664498329163
58
train loss item: 0.14347288012504578
59
train loss item: 0.08468461781740189
60
train loss item: 0.727803647518158
61
train loss item: 1.3129210472106934
62
train loss item: 0.18463130295276642
63
train loss item: 0.3273833394050598
64
train loss item: 0.14301472902297974
65
train loss item: 0.5361629724502563
66
train loss item: 0.352103590965271
67
train loss item: 0.16943231225013733
68
train loss item: 0.2681920528411865
69
train loss item: 0.3116874396800995
70
train loss item: 0.23063169419765472
71
train loss item: 0.09317466616630554
72
train loss item: 0.16170302033424377
73
train loss item: 0.300823837518692
74
train loss item: 0.045033954083919525
75
train loss item: 0.07534918934106827
76
train loss item: 0.7225348353385925
77
train loss item: 0.828123927116394
78
train loss item: 0.046397864818573
79
train loss item: 0.22950197756290436
80
train loss item: 0.08042877167463303
81
train loss item: 0.16543732583522797
82
train loss item: 0.1735558658838272
83
train loss item: 0.3942091464996338
84
train loss item: 0.31411272287368774
85
train loss item: 0.5351888537406921
86
train loss item: 3.031796932220459
87
train loss item: 0.1315021812915802
88
train loss item: 0.33066171407699585
epoch train loss: 0.3696506368728836
testing phase
test loss item: 0.1853531450033188
test loss item: 0.07396051287651062
test loss item: 0.6211372017860413
test loss item: 0.21794827282428741
test loss item: 0.2437003254890442
test loss item: 0.12483266741037369
test loss item: 1.8709065914154053
test loss item: 0.5818047523498535
test loss item: 0.21433526277542114
test loss item: 0.40287676453590393
test loss item: 0.8685643672943115
test loss item: 0.15291453897953033
test loss item: 0.1830592155456543
test loss item: 0.34723740816116333
test loss item: 0.15904411673545837
test loss item: 0.05432393401861191
test loss item: 0.3321767747402191
test loss item: 0.48459920287132263
test loss item: 0.6853083372116089
test loss item: 0.3164386749267578
test loss item: 0.796672523021698
test loss item: 0.40650472044944763
test loss item: 0.3161081373691559
test loss item: 0.18295986950397491
test loss item: 0.23210395872592926
test loss item: 0.24281780421733856
test loss item: 0.36144110560417175
test loss item: 0.1908082664012909
test loss item: 0.3463589549064636
test loss item: 0.3666539490222931
test loss item: 0.8318849802017212
test loss item: 0.05072076618671417
test loss item: 0.15068607032299042
test loss item: 0.604535698890686
test loss item: 0.44932153820991516
test loss item: 0.4140339493751526
test loss item: 0.8412961959838867
test loss item: 1.4557033777236938
test loss item: 0.49548086524009705
test loss item: 0.3008623421192169
test loss item: 0.32609662413597107
test loss item: 0.1967199295759201
test loss item: 0.3634442090988159
test loss item: 0.21503472328186035
test loss item: 0.6417050957679749
test loss item: 0.48668840527534485
test loss item: 0.31065794825553894
test loss item: 0.269416868686676
test loss item: 0.4865855574607849
test loss item: 0.7030341625213623
test loss item: 0.29076239466667175
test loss item: 0.13759738206863403
test loss item: 0.24003645777702332
test loss item: 0.13752098381519318
test loss item: 0.304697722196579
test loss item: 0.8919227123260498
test loss item: 0.5694062113761902
test loss item: 0.25824934244155884
test loss item: 0.2496662735939026
test loss item: 0.19602616131305695
test loss item: 0.45604270696640015
test loss item: 0.26752135157585144
test loss item: 0.24173791706562042
test loss item: 0.2705407440662384
test loss item: 0.9295452833175659
test loss item: 0.29334011673927307
test loss item: 0.35180017352104187
test loss item: 0.27855241298675537
test loss item: 0.5519651174545288
test loss item: 0.4152460992336273
test loss item: 0.06043105199933052
test loss item: 1.0686898231506348
test loss item: 0.34711652994155884
test loss item: 0.46212905645370483
test loss item: 0.1646801233291626
test loss item: 0.1801433116197586
test loss item: 0.18341673910617828
test loss item: 1.4974029064178467
test loss item: 0.5119708180427551
test loss item: 0.20522122085094452
test loss item: 0.07879729568958282
test loss item: 1.0021790266036987
test loss item: 0.9379011392593384
test loss item: 1.0072382688522339
test loss item: 0.23740606009960175
test loss item: 0.23525464534759521
test loss item: 0.07132992893457413
test loss item: 0.05474928393959999
test loss item: 0.17626769840717316
Epoch [81/100], Training Loss: 0.3697, Testing Loss: 0.4154
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6950.00 MB
Epoch 82/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3990146815776825
1
train loss item: 0.9535481929779053
2
train loss item: 0.21570754051208496
3
train loss item: 0.46717214584350586
4
train loss item: 0.3715716600418091
5
train loss item: 0.3012871742248535
6
train loss item: 0.25548848509788513
7
train loss item: 0.5599743127822876
8
train loss item: 0.12188771367073059
9
train loss item: 0.257644385099411
10
train loss item: 0.3253868818283081
11
train loss item: 0.22262811660766602
12
train loss item: 0.08855653554201126
13
train loss item: 0.4132666289806366
14
train loss item: 0.21176503598690033
15
train loss item: 0.4933900833129883
16
train loss item: 0.03929682821035385
17
train loss item: 0.29110896587371826
18
train loss item: 0.31890708208084106
19
train loss item: 0.2608802020549774
20
train loss item: 0.23180226981639862
21
train loss item: 0.07914964109659195
22
train loss item: 0.7076427936553955
23
train loss item: 0.7103786468505859
24
train loss item: 0.5361104011535645
25
train loss item: 0.1339804232120514
26
train loss item: 0.17700457572937012
27
train loss item: 0.19791315495967865
28
train loss item: 0.03519345074892044
29
train loss item: 0.4950140416622162
30
train loss item: 1.3083370923995972
31
train loss item: 0.5347810983657837
32
train loss item: 0.07457177340984344
33
train loss item: 0.36190348863601685
34
train loss item: 0.07507509738206863
35
train loss item: 1.5819814205169678
36
train loss item: 0.4170236885547638
37
train loss item: 0.30323484539985657
38
train loss item: 0.37577614188194275
39
train loss item: 0.1938350945711136
40
train loss item: 0.13745270669460297
41
train loss item: 0.24741682410240173
42
train loss item: 0.25645455718040466
43
train loss item: 0.1652345061302185
44
train loss item: 0.46665236353874207
45
train loss item: 0.09166301786899567
46
train loss item: 0.09455011785030365
47
train loss item: 0.31363528966903687
48
train loss item: 0.21835945546627045
49
train loss item: 0.12863142788410187
50
train loss item: 0.3071264624595642
51
train loss item: 0.6498604416847229
52
train loss item: 0.04300623759627342
53
train loss item: 0.12214106321334839
54
train loss item: 1.418832778930664
55
train loss item: 0.20190547406673431
56
train loss item: 0.22381946444511414
57
train loss item: 0.2217169553041458
58
train loss item: 0.14525555074214935
59
train loss item: 0.08739610761404037
60
train loss item: 0.7175484895706177
61
train loss item: 1.2796040773391724
62
train loss item: 0.18460077047348022
63
train loss item: 0.33023664355278015
64
train loss item: 0.14189356565475464
65
train loss item: 0.5296610593795776
66
train loss item: 0.3551214933395386
67
train loss item: 0.17140507698059082
68
train loss item: 0.2852371037006378
69
train loss item: 0.31419631838798523
70
train loss item: 0.23344667255878448
71
train loss item: 0.09572338312864304
72
train loss item: 0.16076168417930603
73
train loss item: 0.3067360818386078
74
train loss item: 0.042819544672966
75
train loss item: 0.0751623660326004
76
train loss item: 0.7164883017539978
77
train loss item: 0.816858172416687
78
train loss item: 0.0444791279733181
79
train loss item: 0.23498931527137756
80
train loss item: 0.08049202710390091
81
train loss item: 0.16916446387767792
82
train loss item: 0.1718083620071411
83
train loss item: 0.40273886919021606
84
train loss item: 0.3049168586730957
85
train loss item: 0.5301874876022339
86
train loss item: 2.998621702194214
87
train loss item: 0.1299089938402176
88
train loss item: 0.33559736609458923
epoch train loss: 0.3685472806015711
testing phase
test loss item: 0.18376637995243073
test loss item: 0.07299529761075974
test loss item: 0.6178024411201477
test loss item: 0.2116432934999466
test loss item: 0.23711419105529785
test loss item: 0.11000491678714752
test loss item: 1.7391328811645508
test loss item: 0.47434669733047485
test loss item: 0.21527710556983948
test loss item: 0.3999249339103699
test loss item: 0.8675771355628967
test loss item: 0.14641541242599487
test loss item: 0.1667090207338333
test loss item: 0.33512794971466064
test loss item: 0.15772384405136108
test loss item: 0.059600986540317535
test loss item: 0.30690065026283264
test loss item: 0.4864710867404938
test loss item: 0.6255460381507874
test loss item: 0.2805994153022766
test loss item: 0.7984941601753235
test loss item: 0.36751267313957214
test loss item: 0.3031216561794281
test loss item: 0.1708555370569229
test loss item: 0.22960038483142853
test loss item: 0.22488990426063538
test loss item: 0.3467177748680115
test loss item: 0.18179689347743988
test loss item: 0.33764636516571045
test loss item: 0.35707440972328186
test loss item: 0.7988914847373962
test loss item: 0.05778703838586807
test loss item: 0.14162319898605347
test loss item: 0.6046298742294312
test loss item: 0.4520535469055176
test loss item: 0.3974299430847168
test loss item: 0.7840185165405273
test loss item: 1.4617938995361328
test loss item: 0.492523729801178
test loss item: 0.28151267766952515
test loss item: 0.311056524515152
test loss item: 0.18222811818122864
test loss item: 0.36807429790496826
test loss item: 0.2018166184425354
test loss item: 0.6424528956413269
test loss item: 0.44026413559913635
test loss item: 0.3015068471431732
test loss item: 0.23773743212223053
test loss item: 0.47189539670944214
test loss item: 0.6757054328918457
test loss item: 0.29498469829559326
test loss item: 0.12089355289936066
test loss item: 0.2357831746339798
test loss item: 0.13382798433303833
test loss item: 0.3075547516345978
test loss item: 0.8925920128822327
test loss item: 0.5295402407646179
test loss item: 0.25164738297462463
test loss item: 0.2316494882106781
test loss item: 0.19859741628170013
test loss item: 0.464566171169281
test loss item: 0.2207898497581482
test loss item: 0.21878403425216675
test loss item: 0.26156386733055115
test loss item: 0.8948549032211304
test loss item: 0.28957992792129517
test loss item: 0.3158932328224182
test loss item: 0.26625731587409973
test loss item: 0.5495744943618774
test loss item: 0.3663819134235382
test loss item: 0.05780818313360214
test loss item: 0.9630186557769775
test loss item: 0.33168867230415344
test loss item: 0.4182523488998413
test loss item: 0.14796142280101776
test loss item: 0.16934973001480103
test loss item: 0.17178742587566376
test loss item: 1.5033174753189087
test loss item: 0.4967772662639618
test loss item: 0.19212254881858826
test loss item: 0.08118299394845963
test loss item: 0.9531347751617432
test loss item: 0.8907120823860168
test loss item: 1.0043106079101562
test loss item: 0.2196117341518402
test loss item: 0.21895401179790497
test loss item: 0.07741425931453705
test loss item: 0.06589203327894211
test loss item: 0.16562655568122864
Epoch [82/100], Training Loss: 0.3685, Testing Loss: 0.3988
no improvement in test loss for 3 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 83/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.4015927314758301
1
train loss item: 0.9441513419151306
2
train loss item: 0.21252280473709106
3
train loss item: 0.4610403776168823
4
train loss item: 0.37787243723869324
5
train loss item: 0.3089720904827118
6
train loss item: 0.2447948455810547
7
train loss item: 0.5475164651870728
8
train loss item: 0.12068472057580948
9
train loss item: 0.24218951165676117
10
train loss item: 0.3288722038269043
11
train loss item: 0.23110128939151764
12
train loss item: 0.08945687115192413
13
train loss item: 0.42514628171920776
14
train loss item: 0.21719211339950562
15
train loss item: 0.46820399165153503
16
train loss item: 0.04111657291650772
17
train loss item: 0.28139805793762207
18
train loss item: 0.3258431553840637
19
train loss item: 0.243627667427063
20
train loss item: 0.20548255741596222
21
train loss item: 0.08011841028928757
22
train loss item: 0.6917354464530945
23
train loss item: 0.7190804481506348
24
train loss item: 0.5060792565345764
25
train loss item: 0.13504579663276672
26
train loss item: 0.17968182265758514
27
train loss item: 0.19639332592487335
28
train loss item: 0.03804267197847366
29
train loss item: 0.4754679501056671
30
train loss item: 1.2926044464111328
31
train loss item: 0.5475149154663086
32
train loss item: 0.0723688080906868
33
train loss item: 0.36139264702796936
34
train loss item: 0.08270108699798584
35
train loss item: 1.551247477531433
36
train loss item: 0.4265878200531006
37
train loss item: 0.3431878387928009
38
train loss item: 0.3732020854949951
39
train loss item: 0.19096434116363525
40
train loss item: 0.1320074498653412
41
train loss item: 0.24995727837085724
42
train loss item: 0.2498248815536499
43
train loss item: 0.16616007685661316
44
train loss item: 0.45993146300315857
45
train loss item: 0.0868668481707573
46
train loss item: 0.09327957779169083
47
train loss item: 0.2946764826774597
48
train loss item: 0.21048575639724731
49
train loss item: 0.13314984738826752
50
train loss item: 0.2922186553478241
51
train loss item: 0.6591668725013733
52
train loss item: 0.044594429433345795
53
train loss item: 0.12040990591049194
54
train loss item: 1.3924449682235718
55
train loss item: 0.19358333945274353
56
train loss item: 0.23317798972129822
57
train loss item: 0.22096030414104462
58
train loss item: 0.1448693573474884
59
train loss item: 0.0854831114411354
60
train loss item: 0.6596543788909912
61
train loss item: 1.268310785293579
62
train loss item: 0.1832013577222824
63
train loss item: 0.32226207852363586
64
train loss item: 0.14431679248809814
65
train loss item: 0.5597460865974426
66
train loss item: 0.3682452142238617
67
train loss item: 0.1697443276643753
68
train loss item: 0.24727879464626312
69
train loss item: 0.310043066740036
70
train loss item: 0.22428029775619507
71
train loss item: 0.09210345149040222
72
train loss item: 0.15786927938461304
73
train loss item: 0.2893001437187195
74
train loss item: 0.040673088282346725
75
train loss item: 0.07369986176490784
76
train loss item: 0.7041811943054199
77
train loss item: 0.7741094827651978
78
train loss item: 0.04487171769142151
79
train loss item: 0.22199930250644684
80
train loss item: 0.08679035305976868
81
train loss item: 0.1616279035806656
82
train loss item: 0.17248867452144623
83
train loss item: 0.44573307037353516
84
train loss item: 0.3361716568470001
85
train loss item: 0.5133119225502014
86
train loss item: 2.97472882270813
87
train loss item: 0.13039806485176086
88
train loss item: 0.3271762430667877
epoch train loss: 0.3646040527422107
testing phase
test loss item: 0.18790912628173828
test loss item: 0.087051622569561
test loss item: 0.6045730113983154
test loss item: 0.21560339629650116
test loss item: 0.23679393529891968
test loss item: 0.12031589448451996
test loss item: 1.7631500959396362
test loss item: 0.5098586082458496
test loss item: 0.20850418508052826
test loss item: 0.3913654685020447
test loss item: 0.8565289974212646
test loss item: 0.15010571479797363
test loss item: 0.16819529235363007
test loss item: 0.33864784240722656
test loss item: 0.15684080123901367
test loss item: 0.09081366658210754
test loss item: 0.3165905475616455
test loss item: 0.4763842821121216
test loss item: 0.63973468542099
test loss item: 0.28921371698379517
test loss item: 0.7845849394798279
test loss item: 0.3802590072154999
test loss item: 0.30505675077438354
test loss item: 0.17609189450740814
test loss item: 0.22954005002975464
test loss item: 0.2311633974313736
test loss item: 0.3475056290626526
test loss item: 0.1840314269065857
test loss item: 0.33613845705986023
test loss item: 0.354021281003952
test loss item: 0.8005884289741516
test loss item: 0.09817727655172348
test loss item: 0.1467021405696869
test loss item: 0.5947415232658386
test loss item: 0.4442627429962158
test loss item: 0.3917698860168457
test loss item: 0.7939824461936951
test loss item: 1.4445388317108154
test loss item: 0.48464739322662354
test loss item: 0.2892305552959442
test loss item: 0.3189970850944519
test loss item: 0.18971037864685059
test loss item: 0.35756635665893555
test loss item: 0.20913299918174744
test loss item: 0.6307458877563477
test loss item: 0.45562535524368286
test loss item: 0.30106186866760254
test loss item: 0.24434223771095276
test loss item: 0.4663294851779938
test loss item: 0.6711243987083435
test loss item: 0.2819939851760864
test loss item: 0.12511888146400452
test loss item: 0.23526814579963684
test loss item: 0.1400650143623352
test loss item: 0.2996263802051544
test loss item: 0.8716801404953003
test loss item: 0.5355939865112305
test loss item: 0.246180921792984
test loss item: 0.23605455458164215
test loss item: 0.19217751920223236
test loss item: 0.45052972435951233
test loss item: 0.2418915033340454
test loss item: 0.2286468893289566
test loss item: 0.263482928276062
test loss item: 0.8924081921577454
test loss item: 0.29280978441238403
test loss item: 0.32576873898506165
test loss item: 0.269561767578125
test loss item: 0.5431400537490845
test loss item: 0.37311017513275146
test loss item: 0.07307159155607224
test loss item: 0.9890763759613037
test loss item: 0.3343625068664551
test loss item: 0.43293172121047974
test loss item: 0.15499909222126007
test loss item: 0.17418254911899567
test loss item: 0.1763744056224823
test loss item: 1.503389596939087
test loss item: 0.5004962682723999
test loss item: 0.19985619187355042
test loss item: 0.08560517430305481
test loss item: 0.9609074592590332
test loss item: 0.8920553922653198
test loss item: 0.999472975730896
test loss item: 0.2238677740097046
test loss item: 0.2251392900943756
test loss item: 0.09776470810174942
test loss item: 0.09160562604665756
test loss item: 0.17989501357078552
Epoch [83/100], Training Loss: 0.3646, Testing Loss: 0.4024
no improvement in test loss for 4 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7010.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7010.00 MB
Epoch 84/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3950752019882202
1
train loss item: 0.928676426410675
2
train loss item: 0.21118633449077606
3
train loss item: 0.45019274950027466
4
train loss item: 0.36720263957977295
5
train loss item: 0.30272963643074036
6
train loss item: 0.2444259375333786
7
train loss item: 0.5409639477729797
8
train loss item: 0.11947951465845108
9
train loss item: 0.24346229434013367
10
train loss item: 0.32225605845451355
11
train loss item: 0.2226252555847168
12
train loss item: 0.08811686187982559
13
train loss item: 0.41757604479789734
14
train loss item: 0.2125418335199356
15
train loss item: 0.4609752595424652
16
train loss item: 0.03970354422926903
17
train loss item: 0.2812584638595581
18
train loss item: 0.31619057059288025
19
train loss item: 0.24379366636276245
20
train loss item: 0.2092488557100296
21
train loss item: 0.07756896317005157
22
train loss item: 0.6747146844863892
23
train loss item: 0.7025176882743835
24
train loss item: 0.5083138346672058
25
train loss item: 0.13226769864559174
26
train loss item: 0.17515186965465546
27
train loss item: 0.19671323895454407
28
train loss item: 0.03666231036186218
29
train loss item: 0.4660022258758545
30
train loss item: 1.2704604864120483
31
train loss item: 0.5304447412490845
32
train loss item: 0.07058694213628769
33
train loss item: 0.35928425192832947
34
train loss item: 0.07744661718606949
35
train loss item: 1.5308119058609009
36
train loss item: 0.4098043143749237
37
train loss item: 0.3151117265224457
38
train loss item: 0.361544668674469
39
train loss item: 0.1910495012998581
40
train loss item: 0.13215947151184082
41
train loss item: 0.24557076394557953
42
train loss item: 0.248208150267601
43
train loss item: 0.1634926050901413
44
train loss item: 0.4559151232242584
45
train loss item: 0.08834300935268402
46
train loss item: 0.0927516520023346
47
train loss item: 0.29535260796546936
48
train loss item: 0.21151697635650635
49
train loss item: 0.13119931519031525
50
train loss item: 0.2913461923599243
51
train loss item: 0.6371134519577026
52
train loss item: 0.0440235361456871
53
train loss item: 0.1214933693408966
54
train loss item: 1.3727883100509644
55
train loss item: 0.19479826092720032
56
train loss item: 0.22598233819007874
57
train loss item: 0.22166258096694946
58
train loss item: 0.14193065464496613
59
train loss item: 0.0855182558298111
60
train loss item: 0.6658646464347839
61
train loss item: 1.2485594749450684
62
train loss item: 0.18153350055217743
63
train loss item: 0.3164099454879761
64
train loss item: 0.14247949421405792
65
train loss item: 0.5320221781730652
66
train loss item: 0.34979572892189026
67
train loss item: 0.16791462898254395
68
train loss item: 0.2546776533126831
69
train loss item: 0.30384746193885803
70
train loss item: 0.2201412171125412
71
train loss item: 0.09247775375843048
72
train loss item: 0.15707573294639587
73
train loss item: 0.29118651151657104
74
train loss item: 0.04094397649168968
75
train loss item: 0.07314246892929077
76
train loss item: 0.7000585794448853
77
train loss item: 0.7719666361808777
78
train loss item: 0.04231896996498108
79
train loss item: 0.22117583453655243
80
train loss item: 0.08922737836837769
81
train loss item: 0.16323970258235931
82
train loss item: 0.17087936401367188
83
train loss item: 0.41209572553634644
84
train loss item: 0.3086238205432892
85
train loss item: 0.513184666633606
86
train loss item: 2.9425995349884033
87
train loss item: 0.13178429007530212
88
train loss item: 0.31731289625167847
epoch train loss: 0.3587398333161065
testing phase
test loss item: 0.18570443987846375
test loss item: 0.0822959616780281
test loss item: 0.598300576210022
test loss item: 0.21881714463233948
test loss item: 0.24129927158355713
test loss item: 0.12872619926929474
test loss item: 1.8951504230499268
test loss item: 0.6020638942718506
test loss item: 0.20560669898986816
test loss item: 0.39149758219718933
test loss item: 0.8553348779678345
test loss item: 0.1535264253616333
test loss item: 0.17689143121242523
test loss item: 0.341817170381546
test loss item: 0.15828336775302887
test loss item: 0.07124984264373779
test loss item: 0.33183425664901733
test loss item: 0.47413596510887146
test loss item: 0.6918220520019531
test loss item: 0.30995678901672363
test loss item: 0.7864298820495605
test loss item: 0.41010820865631104
test loss item: 0.312122642993927
test loss item: 0.18478737771511078
test loss item: 0.22962701320648193
test loss item: 0.2412283718585968
test loss item: 0.3544495403766632
test loss item: 0.19005723297595978
test loss item: 0.34150320291519165
test loss item: 0.35768041014671326
test loss item: 0.8368315696716309
test loss item: 0.07036495208740234
test loss item: 0.15244226157665253
test loss item: 0.5914109945297241
test loss item: 0.43993061780929565
test loss item: 0.4078317880630493
test loss item: 0.8463613986968994
test loss item: 1.4357191324234009
test loss item: 0.4855268597602844
test loss item: 0.3046683967113495
test loss item: 0.32900404930114746
test loss item: 0.18985804915428162
test loss item: 0.35316386818885803
test loss item: 0.21777445077896118
test loss item: 0.630632758140564
test loss item: 0.4839858412742615
test loss item: 0.3029961884021759
test loss item: 0.26241856813430786
test loss item: 0.4749176800251007
test loss item: 0.6898123621940613
test loss item: 0.2780464291572571
test loss item: 0.13309745490550995
test loss item: 0.23820890486240387
test loss item: 0.1396009474992752
test loss item: 0.29758042097091675
test loss item: 0.8621076941490173
test loss item: 0.5674107074737549
test loss item: 0.24943041801452637
test loss item: 0.24629724025726318
test loss item: 0.19062325358390808
test loss item: 0.44206780195236206
test loss item: 0.2707047164440155
test loss item: 0.24064861238002777
test loss item: 0.26946336030960083
test loss item: 0.9130565524101257
test loss item: 0.2942711412906647
test loss item: 0.34807345271110535
test loss item: 0.27869006991386414
test loss item: 0.5406558513641357
test loss item: 0.42310523986816406
test loss item: 0.06800135225057602
test loss item: 1.0829825401306152
test loss item: 0.3395079970359802
test loss item: 0.46202352643013
test loss item: 0.16216807067394257
test loss item: 0.17442408204078674
test loss item: 0.18530724942684174
test loss item: 1.511361837387085
test loss item: 0.5059377551078796
test loss item: 0.20485813915729523
test loss item: 0.08593069016933441
test loss item: 1.0067145824432373
test loss item: 0.9350455403327942
test loss item: 1.006544828414917
test loss item: 0.2346959412097931
test loss item: 0.22993463277816772
test loss item: 0.08542197942733765
test loss item: 0.07230380922555923
test loss item: 0.18009187281131744
Epoch [84/100], Training Loss: 0.3587, Testing Loss: 0.4133
no improvement in test loss for 5 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 85/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3903687000274658
1
train loss item: 0.9324461221694946
2
train loss item: 0.21060313284397125
3
train loss item: 0.45293426513671875
4
train loss item: 0.36164143681526184
5
train loss item: 0.2953943908214569
6
train loss item: 0.2489793598651886
7
train loss item: 0.5353513956069946
8
train loss item: 0.11863569915294647
9
train loss item: 0.25134092569351196
10
train loss item: 0.317220002412796
11
train loss item: 0.21667373180389404
12
train loss item: 0.08630648255348206
13
train loss item: 0.407303124666214
14
train loss item: 0.20564435422420502
15
train loss item: 0.4799339175224304
16
train loss item: 0.037916067987680435
17
train loss item: 0.2866189181804657
18
train loss item: 0.31403249502182007
19
train loss item: 0.25126200914382935
20
train loss item: 0.22519659996032715
21
train loss item: 0.07795067876577377
22
train loss item: 0.6801078915596008
23
train loss item: 0.683198094367981
24
train loss item: 0.5273508429527283
25
train loss item: 0.13055187463760376
26
train loss item: 0.1743299514055252
27
train loss item: 0.1947358250617981
28
train loss item: 0.03444051742553711
29
train loss item: 0.4772360920906067
30
train loss item: 1.2456251382827759
31
train loss item: 0.5185544490814209
32
train loss item: 0.07163849472999573
33
train loss item: 0.3520753085613251
34
train loss item: 0.07031655311584473
35
train loss item: 1.5120586156845093
36
train loss item: 0.40906256437301636
37
train loss item: 0.2812234163284302
38
train loss item: 0.36451056599617004
39
train loss item: 0.19116178154945374
40
train loss item: 0.13493473827838898
41
train loss item: 0.246700257062912
42
train loss item: 0.2510068118572235
43
train loss item: 0.16227968037128448
44
train loss item: 0.4535278379917145
45
train loss item: 0.0869329422712326
46
train loss item: 0.09332398325204849
47
train loss item: 0.30598604679107666
48
train loss item: 0.21284659206867218
49
train loss item: 0.12764273583889008
50
train loss item: 0.29938805103302
51
train loss item: 0.6364936232566833
52
train loss item: 0.041696250438690186
53
train loss item: 0.12122107297182083
54
train loss item: 1.3522076606750488
55
train loss item: 0.19647851586341858
56
train loss item: 0.21718654036521912
57
train loss item: 0.21873214840888977
58
train loss item: 0.14227646589279175
59
train loss item: 0.08597733080387115
60
train loss item: 0.7002403736114502
61
train loss item: 1.2160687446594238
62
train loss item: 0.18182319402694702
63
train loss item: 0.32156211137771606
64
train loss item: 0.13970482349395752
65
train loss item: 0.5161293148994446
66
train loss item: 0.34120604395866394
67
train loss item: 0.168115496635437
68
train loss item: 0.27910301089286804
69
train loss item: 0.3069797158241272
70
train loss item: 0.22496959567070007
71
train loss item: 0.09250067919492722
72
train loss item: 0.15486663579940796
73
train loss item: 0.299464613199234
74
train loss item: 0.04100291058421135
75
train loss item: 0.07339342683553696
76
train loss item: 0.6995919942855835
77
train loss item: 0.7858063578605652
78
train loss item: 0.04010976850986481
79
train loss item: 0.23205392062664032
80
train loss item: 0.08328957110643387
81
train loss item: 0.16729450225830078
82
train loss item: 0.16876310110092163
83
train loss item: 0.3884276747703552
84
train loss item: 0.29487499594688416
85
train loss item: 0.5174105763435364
86
train loss item: 2.906285524368286
87
train loss item: 0.1298515647649765
88
train loss item: 0.3229553997516632
epoch train loss: 0.3573327720834968
testing phase
test loss item: 0.1794021725654602
test loss item: 0.07524396479129791
test loss item: 0.610480785369873
test loss item: 0.21029679477214813
test loss item: 0.23669680953025818
test loss item: 0.10662899166345596
test loss item: 1.7822718620300293
test loss item: 0.5020732283592224
test loss item: 0.21145111322402954
test loss item: 0.394122451543808
test loss item: 0.8697859048843384
test loss item: 0.14608903229236603
test loss item: 0.1633605808019638
test loss item: 0.3276090621948242
test loss item: 0.1581220179796219
test loss item: 0.0619354248046875
test loss item: 0.30500197410583496
test loss item: 0.4836040735244751
test loss item: 0.6329758763313293
test loss item: 0.2773347496986389
test loss item: 0.8016431927680969
test loss item: 0.37145334482192993
test loss item: 0.3030109703540802
test loss item: 0.1726180464029312
test loss item: 0.22717313468456268
test loss item: 0.2249220758676529
test loss item: 0.3409642279148102
test loss item: 0.1800348311662674
test loss item: 0.33386170864105225
test loss item: 0.35128891468048096
test loss item: 0.8149637579917908
test loss item: 0.06068354845046997
test loss item: 0.1426316350698471
test loss item: 0.6004796028137207
test loss item: 0.45107048749923706
test loss item: 0.38914936780929565
test loss item: 0.7936025857925415
test loss item: 1.4742062091827393
test loss item: 0.48843616247177124
test loss item: 0.28247353434562683
test loss item: 0.31176280975341797
test loss item: 0.17215174436569214
test loss item: 0.36273393034935
test loss item: 0.20119498670101166
test loss item: 0.6401627063751221
test loss item: 0.43979746103286743
test loss item: 0.29429635405540466
test loss item: 0.2321896106004715
test loss item: 0.4693087637424469
test loss item: 0.6701057553291321
test loss item: 0.2857211232185364
test loss item: 0.11808372288942337
test loss item: 0.23343177139759064
test loss item: 0.1307864487171173
test loss item: 0.3052196204662323
test loss item: 0.8764289021492004
test loss item: 0.533822238445282
test loss item: 0.24526455998420715
test loss item: 0.22972270846366882
test loss item: 0.19419044256210327
test loss item: 0.4559512436389923
test loss item: 0.22413931787014008
test loss item: 0.21611787378787994
test loss item: 0.26040396094322205
test loss item: 0.8924209475517273
test loss item: 0.2869234085083008
test loss item: 0.31668218970298767
test loss item: 0.26589229702949524
test loss item: 0.5466132760047913
test loss item: 0.36945840716362
test loss item: 0.06010648235678673
test loss item: 0.9857075810432434
test loss item: 0.32501962780952454
test loss item: 0.41862255334854126
test loss item: 0.14364884793758392
test loss item: 0.15980090200901031
test loss item: 0.17378416657447815
test loss item: 1.5537846088409424
test loss item: 0.49592500925064087
test loss item: 0.18609699606895447
test loss item: 0.08487251400947571
test loss item: 0.9758939146995544
test loss item: 0.8942960500717163
test loss item: 1.0289065837860107
test loss item: 0.2201370894908905
test loss item: 0.21308211982250214
test loss item: 0.08063735067844391
test loss item: 0.07006817311048508
test loss item: 0.1643231213092804
Epoch [85/100], Training Loss: 0.3573, Testing Loss: 0.3995
no improvement in test loss for 6 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6932.00 MB
Epoch 86/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.38857609033584595
1
train loss item: 0.9139195084571838
2
train loss item: 0.20745080709457397
3
train loss item: 0.44003814458847046
4
train loss item: 0.35843056440353394
5
train loss item: 0.3015325367450714
6
train loss item: 0.24098263680934906
7
train loss item: 0.5151562690734863
8
train loss item: 0.11812260001897812
9
train loss item: 0.23744799196720123
10
train loss item: 0.31650808453559875
11
train loss item: 0.22257627546787262
12
train loss item: 0.08837329596281052
13
train loss item: 0.41734060645103455
14
train loss item: 0.2135225385427475
15
train loss item: 0.45090579986572266
16
train loss item: 0.04073004052042961
17
train loss item: 0.2778347432613373
18
train loss item: 0.313708633184433
19
train loss item: 0.23556536436080933
20
train loss item: 0.19750425219535828
21
train loss item: 0.08070807158946991
22
train loss item: 0.67339026927948
23
train loss item: 0.6848437786102295
24
train loss item: 0.49899962544441223
25
train loss item: 0.13218684494495392
26
train loss item: 0.1831526905298233
27
train loss item: 0.19286911189556122
28
train loss item: 0.037831299006938934
29
train loss item: 0.4604492783546448
30
train loss item: 1.2274589538574219
31
train loss item: 0.5234971642494202
32
train loss item: 0.07060437649488449
33
train loss item: 0.34911999106407166
34
train loss item: 0.08288205415010452
35
train loss item: 1.4843847751617432
36
train loss item: 0.412441223859787
37
train loss item: 0.2951086461544037
38
train loss item: 0.35814884305000305
39
train loss item: 0.18927021324634552
40
train loss item: 0.13038408756256104
41
train loss item: 0.25209149718284607
42
train loss item: 0.2426779717206955
43
train loss item: 0.163091242313385
44
train loss item: 0.4458717405796051
45
train loss item: 0.08648838847875595
46
train loss item: 0.09379701316356659
47
train loss item: 0.2864455580711365
48
train loss item: 0.20600490272045135
49
train loss item: 0.13225534558296204
50
train loss item: 0.28468048572540283
51
train loss item: 0.6211954355239868
52
train loss item: 0.042709529399871826
53
train loss item: 0.12117563188076019
54
train loss item: 1.3225470781326294
55
train loss item: 0.18778763711452484
56
train loss item: 0.22370173037052155
57
train loss item: 0.21594135463237762
58
train loss item: 0.1416717767715454
59
train loss item: 0.08327490836381912
60
train loss item: 0.6618789434432983
61
train loss item: 1.2069449424743652
62
train loss item: 0.1788993775844574
63
train loss item: 0.3063875436782837
64
train loss item: 0.14027585089206696
65
train loss item: 0.5398833751678467
66
train loss item: 0.34550178050994873
67
train loss item: 0.16428375244140625
68
train loss item: 0.24031199514865875
69
train loss item: 0.30318155884742737
70
train loss item: 0.2160438895225525
71
train loss item: 0.0928834080696106
72
train loss item: 0.149878591299057
73
train loss item: 0.2832622528076172
74
train loss item: 0.04102450609207153
75
train loss item: 0.07558774203062057
76
train loss item: 0.6884016394615173
77
train loss item: 0.7491894364356995
78
train loss item: 0.045890357345342636
79
train loss item: 0.21382726728916168
80
train loss item: 0.08115103095769882
81
train loss item: 0.1568736582994461
82
train loss item: 0.16936637461185455
83
train loss item: 0.38115769624710083
84
train loss item: 0.30041447281837463
85
train loss item: 0.4996604025363922
86
train loss item: 2.8737080097198486
87
train loss item: 0.12842079997062683
88
train loss item: 0.31635913252830505
epoch train loss: 0.35132603481244506
testing phase
test loss item: 0.1774703413248062
test loss item: 0.09207794070243835
test loss item: 0.5919701457023621
test loss item: 0.20851007103919983
test loss item: 0.2317580133676529
test loss item: 0.10643260180950165
test loss item: 1.7239528894424438
test loss item: 0.4867408573627472
test loss item: 0.20401029288768768
test loss item: 0.38342323899269104
test loss item: 0.8519335389137268
test loss item: 0.14391563832759857
test loss item: 0.16278068721294403
test loss item: 0.3251609802246094
test loss item: 0.15480221807956696
test loss item: 0.10586819052696228
test loss item: 0.3026484251022339
test loss item: 0.46890494227409363
test loss item: 0.6204139590263367
test loss item: 0.27681997418403625
test loss item: 0.7760303616523743
test loss item: 0.36446133255958557
test loss item: 0.2955644428730011
test loss item: 0.1704062521457672
test loss item: 0.22294700145721436
test loss item: 0.22584882378578186
test loss item: 0.33606523275375366
test loss item: 0.17801429331302643
test loss item: 0.32637619972229004
test loss item: 0.34558770060539246
test loss item: 0.7919626235961914
test loss item: 0.10234735161066055
test loss item: 0.14186929166316986
test loss item: 0.5854406952857971
test loss item: 0.4412919878959656
test loss item: 0.38020527362823486
test loss item: 0.7737187147140503
test loss item: 1.4410172700881958
test loss item: 0.4748048484325409
test loss item: 0.27642640471458435
test loss item: 0.30900537967681885
test loss item: 0.17721746861934662
test loss item: 0.3506871163845062
test loss item: 0.19738651812076569
test loss item: 0.6212103366851807
test loss item: 0.43998879194259644
test loss item: 0.28861063718795776
test loss item: 0.23522353172302246
test loss item: 0.4551832973957062
test loss item: 0.6565040349960327
test loss item: 0.2724083662033081
test loss item: 0.12064451724290848
test loss item: 0.2270907610654831
test loss item: 0.1303400993347168
test loss item: 0.2951281666755676
test loss item: 0.8530847430229187
test loss item: 0.5226637721061707
test loss item: 0.2360716015100479
test loss item: 0.227804034948349
test loss item: 0.18746183812618256
test loss item: 0.4411785900592804
test loss item: 0.22851848602294922
test loss item: 0.21818210184574127
test loss item: 0.2567252814769745
test loss item: 0.8677397966384888
test loss item: 0.28403255343437195
test loss item: 0.3149048686027527
test loss item: 0.26141199469566345
test loss item: 0.5360561013221741
test loss item: 0.36072537302970886
test loss item: 0.07881831377744675
test loss item: 0.9542148113250732
test loss item: 0.31902050971984863
test loss item: 0.41254016757011414
test loss item: 0.14478877186775208
test loss item: 0.16103552281856537
test loss item: 0.17067672312259674
test loss item: 1.5227311849594116
test loss item: 0.4911806881427765
test loss item: 0.18708300590515137
test loss item: 0.08049710839986801
test loss item: 0.950475811958313
test loss item: 0.8701878190040588
test loss item: 1.0055397748947144
test loss item: 0.21738693118095398
test loss item: 0.21272002160549164
test loss item: 0.10425233840942383
test loss item: 0.1074582114815712
test loss item: 0.1725170761346817
Epoch [86/100], Training Loss: 0.3513, Testing Loss: 0.3933
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 87/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.39037907123565674
1
train loss item: 0.9081569910049438
2
train loss item: 0.20619811117649078
3
train loss item: 0.43620458245277405
4
train loss item: 0.35631126165390015
5
train loss item: 0.29867008328437805
6
train loss item: 0.2394765019416809
7
train loss item: 0.512065052986145
8
train loss item: 0.11891128122806549
9
train loss item: 0.23625995218753815
10
train loss item: 0.3134174346923828
11
train loss item: 0.22146181762218475
12
train loss item: 0.08529148250818253
13
train loss item: 0.4091266691684723
14
train loss item: 0.20733508467674255
15
train loss item: 0.44787049293518066
16
train loss item: 0.03765003755688667
17
train loss item: 0.27594423294067383
18
train loss item: 0.30963096022605896
19
train loss item: 0.23560455441474915
20
train loss item: 0.19517451524734497
21
train loss item: 0.0792158842086792
22
train loss item: 0.6688098907470703
23
train loss item: 0.6754990220069885
24
train loss item: 0.49902209639549255
25
train loss item: 0.13081549108028412
26
train loss item: 0.1850939244031906
27
train loss item: 0.19015277922153473
28
train loss item: 0.034339793026447296
29
train loss item: 0.4511825740337372
30
train loss item: 1.202327013015747
31
train loss item: 0.5176153779029846
32
train loss item: 0.07235034555196762
33
train loss item: 0.3426716923713684
34
train loss item: 0.08364316821098328
35
train loss item: 1.4626669883728027
36
train loss item: 0.41098493337631226
37
train loss item: 0.2915206253528595
38
train loss item: 0.35334956645965576
39
train loss item: 0.18745636940002441
40
train loss item: 0.1308901458978653
41
train loss item: 0.23957639932632446
42
train loss item: 0.24270257353782654
43
train loss item: 0.16217677295207977
44
train loss item: 0.4352409243583679
45
train loss item: 0.08486848324537277
46
train loss item: 0.09687241166830063
47
train loss item: 0.28761541843414307
48
train loss item: 0.20483076572418213
49
train loss item: 0.12819725275039673
50
train loss item: 0.2835574150085449
51
train loss item: 0.6147406101226807
52
train loss item: 0.0429779589176178
53
train loss item: 0.11897197365760803
54
train loss item: 1.2983723878860474
55
train loss item: 0.18615590035915375
56
train loss item: 0.2230249047279358
57
train loss item: 0.2105425000190735
58
train loss item: 0.14092077314853668
59
train loss item: 0.08873803168535233
60
train loss item: 0.6559703946113586
61
train loss item: 1.182530403137207
62
train loss item: 0.17743778228759766
63
train loss item: 0.30707448720932007
64
train loss item: 0.13957685232162476
65
train loss item: 0.5358524918556213
66
train loss item: 0.3390205502510071
67
train loss item: 0.16225872933864594
68
train loss item: 0.2377944439649582
69
train loss item: 0.30263447761535645
70
train loss item: 0.2178535759449005
71
train loss item: 0.09109148383140564
72
train loss item: 0.14943170547485352
73
train loss item: 0.28148555755615234
74
train loss item: 0.039705973118543625
75
train loss item: 0.07500416785478592
76
train loss item: 0.6815745830535889
77
train loss item: 0.743681013584137
78
train loss item: 0.04250134900212288
79
train loss item: 0.21550482511520386
80
train loss item: 0.08265262842178345
81
train loss item: 0.15551139414310455
82
train loss item: 0.16766762733459473
83
train loss item: 0.37534299492836
84
train loss item: 0.29500123858451843
85
train loss item: 0.4941563606262207
86
train loss item: 2.8334412574768066
87
train loss item: 0.12644967436790466
88
train loss item: 0.31687188148498535
epoch train loss: 0.347482148474187
testing phase
test loss item: 0.17830246686935425
test loss item: 0.07801583409309387
test loss item: 0.5880160331726074
test loss item: 0.21312189102172852
test loss item: 0.2312135547399521
test loss item: 0.11106286197900772
test loss item: 1.8099926710128784
test loss item: 0.5515228509902954
test loss item: 0.20439110696315765
test loss item: 0.38439035415649414
test loss item: 0.8439285159111023
test loss item: 0.14835406839847565
test loss item: 0.1717909425497055
test loss item: 0.3309912085533142
test loss item: 0.15426652133464813
test loss item: 0.06705109030008316
test loss item: 0.31937238574028015
test loss item: 0.4640514850616455
test loss item: 0.6526094675064087
test loss item: 0.2987833023071289
test loss item: 0.7672536969184875
test loss item: 0.3903596103191376
test loss item: 0.30138537287712097
test loss item: 0.17893575131893158
test loss item: 0.2237546294927597
test loss item: 0.23410214483737946
test loss item: 0.3452759385108948
test loss item: 0.17982444167137146
test loss item: 0.3307165205478668
test loss item: 0.35017701983451843
test loss item: 0.8114729523658752
test loss item: 0.061507321894168854
test loss item: 0.14776848256587982
test loss item: 0.5798248648643494
test loss item: 0.43336769938468933
test loss item: 0.39199748635292053
test loss item: 0.8066121339797974
test loss item: 1.421584129333496
test loss item: 0.4739726185798645
test loss item: 0.2890619933605194
test loss item: 0.3158847391605377
test loss item: 0.18441593647003174
test loss item: 0.3463594317436218
test loss item: 0.20785902440547943
test loss item: 0.615253210067749
test loss item: 0.46570295095443726
test loss item: 0.29317429661750793
test loss item: 0.25434884428977966
test loss item: 0.46146664023399353
test loss item: 0.6695699691772461
test loss item: 0.2690788209438324
test loss item: 0.12980829179286957
test loss item: 0.2309202253818512
test loss item: 0.13468670845031738
test loss item: 0.2919624447822571
test loss item: 0.8425837159156799
test loss item: 0.54123455286026
test loss item: 0.2387489527463913
test loss item: 0.23890526592731476
test loss item: 0.18552865087985992
test loss item: 0.43526965379714966
test loss item: 0.2542332112789154
test loss item: 0.23258166015148163
test loss item: 0.2611100673675537
test loss item: 0.8788454532623291
test loss item: 0.2874768078327179
test loss item: 0.33606505393981934
test loss item: 0.2681420147418976
test loss item: 0.5276942849159241
test loss item: 0.39070528745651245
test loss item: 0.06302525848150253
test loss item: 1.0189162492752075
test loss item: 0.32805076241493225
test loss item: 0.4425438940525055
test loss item: 0.15535441040992737
test loss item: 0.16791070997714996
test loss item: 0.1785268783569336
test loss item: 1.5028326511383057
test loss item: 0.4977054297924042
test loss item: 0.19205068051815033
test loss item: 0.07809773832559586
test loss item: 0.9737050533294678
test loss item: 0.8978047966957092
test loss item: 0.9998766779899597
test loss item: 0.22783687710762024
test loss item: 0.22131939232349396
test loss item: 0.07626399397850037
test loss item: 0.06792296469211578
test loss item: 0.17084524035453796
Epoch [87/100], Training Loss: 0.3475, Testing Loss: 0.3997
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
Epoch 88/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3814394772052765
1
train loss item: 0.9034237265586853
2
train loss item: 0.20572002232074738
3
train loss item: 0.4362916052341461
4
train loss item: 0.3518649637699127
5
train loss item: 0.28936660289764404
6
train loss item: 0.2390081137418747
7
train loss item: 0.51028972864151
8
train loss item: 0.11889192461967468
9
train loss item: 0.24252302944660187
10
train loss item: 0.3079161047935486
11
train loss item: 0.21341899037361145
12
train loss item: 0.08482962846755981
13
train loss item: 0.3984176814556122
14
train loss item: 0.19770851731300354
15
train loss item: 0.4565886855125427
16
train loss item: 0.03884461522102356
17
train loss item: 0.2744363248348236
18
train loss item: 0.30505451560020447
19
train loss item: 0.24242134392261505
20
train loss item: 0.2099168598651886
21
train loss item: 0.07477559894323349
22
train loss item: 0.6493196487426758
23
train loss item: 0.6595771908760071
24
train loss item: 0.5104773044586182
25
train loss item: 0.1265610009431839
26
train loss item: 0.1724194586277008
27
train loss item: 0.18854597210884094
28
train loss item: 0.03517620638012886
29
train loss item: 0.4507080614566803
30
train loss item: 1.185349702835083
31
train loss item: 0.4979446530342102
32
train loss item: 0.07399360090494156
33
train loss item: 0.34092703461647034
34
train loss item: 0.07281169295310974
35
train loss item: 1.4469763040542603
36
train loss item: 0.4122435450553894
37
train loss item: 0.2728785574436188
38
train loss item: 0.3451084494590759
39
train loss item: 0.1871318519115448
40
train loss item: 0.13171014189720154
41
train loss item: 0.22966268658638
42
train loss item: 0.24646872282028198
43
train loss item: 0.15906773507595062
44
train loss item: 0.432192862033844
45
train loss item: 0.08520526438951492
46
train loss item: 0.09522740542888641
47
train loss item: 0.2969846725463867
48
train loss item: 0.20799249410629272
49
train loss item: 0.12370266765356064
50
train loss item: 0.2889549136161804
51
train loss item: 0.6234805583953857
52
train loss item: 0.04306578263640404
53
train loss item: 0.1183658167719841
54
train loss item: 1.2791086435317993
55
train loss item: 0.1901262402534485
56
train loss item: 0.21527014672756195
57
train loss item: 0.20906232297420502
58
train loss item: 0.13882328569889069
59
train loss item: 0.0875130295753479
60
train loss item: 0.6861456036567688
61
train loss item: 1.159376859664917
62
train loss item: 0.17774267494678497
63
train loss item: 0.31291890144348145
64
train loss item: 0.13769735395908356
65
train loss item: 0.5040367841720581
66
train loss item: 0.3347075283527374
67
train loss item: 0.16092252731323242
68
train loss item: 0.25584182143211365
69
train loss item: 0.29947638511657715
70
train loss item: 0.22071434557437897
71
train loss item: 0.08987703174352646
72
train loss item: 0.15105929970741272
73
train loss item: 0.2872713506221771
74
train loss item: 0.041366685181856155
75
train loss item: 0.07371996343135834
76
train loss item: 0.6821584701538086
77
train loss item: 0.7602813839912415
78
train loss item: 0.04390735924243927
79
train loss item: 0.22707326710224152
80
train loss item: 0.08219286054372787
81
train loss item: 0.15936070680618286
82
train loss item: 0.1646270900964737
83
train loss item: 0.36828792095184326
84
train loss item: 0.291136234998703
85
train loss item: 0.4995229244232178
86
train loss item: 2.798274517059326
87
train loss item: 0.12584184110164642
88
train loss item: 0.31405335664749146
epoch train loss: 0.34520086223322355
testing phase
test loss item: 0.1802617758512497
test loss item: 0.07543965429067612
test loss item: 0.5907436013221741
test loss item: 0.211526557803154
test loss item: 0.22942505776882172
test loss item: 0.10604052245616913
test loss item: 1.7260992527008057
test loss item: 0.4840434789657593
test loss item: 0.20826999843120575
test loss item: 0.3848133683204651
test loss item: 0.8443138599395752
test loss item: 0.14558449387550354
test loss item: 0.16315436363220215
test loss item: 0.32084840536117554
test loss item: 0.155643031001091
test loss item: 0.07071257382631302
test loss item: 0.3054661452770233
test loss item: 0.467651903629303
test loss item: 0.613817572593689
test loss item: 0.2793160676956177
test loss item: 0.7747051119804382
test loss item: 0.3674699664115906
test loss item: 0.2954392731189728
test loss item: 0.1754469871520996
test loss item: 0.22409535944461823
test loss item: 0.2229662984609604
test loss item: 0.3395555019378662
test loss item: 0.1763458102941513
test loss item: 0.32709044218063354
test loss item: 0.3456614911556244
test loss item: 0.7916191816329956
test loss item: 0.06602991372346878
test loss item: 0.14633415639400482
test loss item: 0.5818268060684204
test loss item: 0.4378754198551178
test loss item: 0.38528743386268616
test loss item: 0.7691610455513
test loss item: 1.4280421733856201
test loss item: 0.4751310646533966
test loss item: 0.2788507342338562
test loss item: 0.307304322719574
test loss item: 0.17345818877220154
test loss item: 0.3512903153896332
test loss item: 0.2014371156692505
test loss item: 0.6208650469779968
test loss item: 0.43957316875457764
test loss item: 0.28907787799835205
test loss item: 0.23547165095806122
test loss item: 0.45504051446914673
test loss item: 0.655202329158783
test loss item: 0.27549612522125244
test loss item: 0.12131065130233765
test loss item: 0.23022274672985077
test loss item: 0.13374607264995575
test loss item: 0.296324223279953
test loss item: 0.8476648330688477
test loss item: 0.5183628797531128
test loss item: 0.2379031479358673
test loss item: 0.22980238497257233
test loss item: 0.18819952011108398
test loss item: 0.4428504407405853
test loss item: 0.2280244529247284
test loss item: 0.2177199274301529
test loss item: 0.2554551064968109
test loss item: 0.863697350025177
test loss item: 0.28617435693740845
test loss item: 0.3157775402069092
test loss item: 0.26090481877326965
test loss item: 0.5276228189468384
test loss item: 0.3612782955169678
test loss item: 0.06631295382976532
test loss item: 0.9511703848838806
test loss item: 0.3203839063644409
test loss item: 0.41806700825691223
test loss item: 0.14812298119068146
test loss item: 0.1621619015932083
test loss item: 0.1748579740524292
test loss item: 1.5104186534881592
test loss item: 0.4884989857673645
test loss item: 0.1849985271692276
test loss item: 0.08800510317087173
test loss item: 0.9453752636909485
test loss item: 0.8679637908935547
test loss item: 1.0034608840942383
test loss item: 0.21752454340457916
test loss item: 0.2145739495754242
test loss item: 0.09234429895877838
test loss item: 0.08655819296836853
test loss item: 0.15962092578411102
Epoch [88/100], Training Loss: 0.3452, Testing Loss: 0.3915
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 89/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.37246453762054443
1
train loss item: 0.8985893726348877
2
train loss item: 0.2018556445837021
3
train loss item: 0.43146049976348877
4
train loss item: 0.3519960343837738
5
train loss item: 0.2928214371204376
6
train loss item: 0.23484282195568085
7
train loss item: 0.49788689613342285
8
train loss item: 0.11665895581245422
9
train loss item: 0.23166942596435547
10
train loss item: 0.3052213490009308
11
train loss item: 0.21955206990242004
12
train loss item: 0.08956347405910492
13
train loss item: 0.4000149071216583
14
train loss item: 0.1999978870153427
15
train loss item: 0.44144538044929504
16
train loss item: 0.04729204997420311
17
train loss item: 0.27088579535484314
18
train loss item: 0.30253317952156067
19
train loss item: 0.2312479019165039
20
train loss item: 0.19859755039215088
21
train loss item: 0.07665832340717316
22
train loss item: 0.6624020934104919
23
train loss item: 0.6574416756629944
24
train loss item: 0.48835504055023193
25
train loss item: 0.1276533454656601
26
train loss item: 0.17777711153030396
27
train loss item: 0.18537507951259613
28
train loss item: 0.044088274240493774
29
train loss item: 0.4472990930080414
30
train loss item: 1.162351369857788
31
train loss item: 0.5033081769943237
32
train loss item: 0.06945393979549408
33
train loss item: 0.3361862599849701
34
train loss item: 0.07635443657636642
35
train loss item: 1.4109760522842407
36
train loss item: 0.4041427671909332
37
train loss item: 0.29186955094337463
38
train loss item: 0.3456844985485077
39
train loss item: 0.1825362890958786
40
train loss item: 0.12856940925121307
41
train loss item: 0.23497843742370605
42
train loss item: 0.24012990295886993
43
train loss item: 0.1567642092704773
44
train loss item: 0.4281226098537445
45
train loss item: 0.08944068104028702
46
train loss item: 0.08854147046804428
47
train loss item: 0.2816787362098694
48
train loss item: 0.20061162114143372
49
train loss item: 0.12799565494060516
50
train loss item: 0.27887821197509766
51
train loss item: 0.6041684150695801
52
train loss item: 0.0436849407851696
53
train loss item: 0.11827623844146729
54
train loss item: 1.2474894523620605
55
train loss item: 0.1847739964723587
56
train loss item: 0.2152436524629593
57
train loss item: 0.21057213842868805
58
train loss item: 0.13741303980350494
59
train loss item: 0.07816550135612488
60
train loss item: 0.6363462805747986
61
train loss item: 1.1378971338272095
62
train loss item: 0.1774132400751114
63
train loss item: 0.3020719289779663
64
train loss item: 0.13294477760791779
65
train loss item: 0.5225825905799866
66
train loss item: 0.3451829254627228
67
train loss item: 0.15972840785980225
68
train loss item: 0.23568373918533325
69
train loss item: 0.2932666838169098
70
train loss item: 0.2116423100233078
71
train loss item: 0.08959268033504486
72
train loss item: 0.14505766332149506
73
train loss item: 0.27697494626045227
74
train loss item: 0.039497535675764084
75
train loss item: 0.07115888595581055
76
train loss item: 0.6683030724525452
77
train loss item: 0.710166871547699
78
train loss item: 0.05229270085692406
79
train loss item: 0.2132178544998169
80
train loss item: 0.08267728984355927
81
train loss item: 0.15369191765785217
82
train loss item: 0.16213960945606232
83
train loss item: 0.37591788172721863
84
train loss item: 0.2916426360607147
85
train loss item: 0.48323291540145874
86
train loss item: 2.7680256366729736
87
train loss item: 0.12139199674129486
88
train loss item: 0.30943334102630615
epoch train loss: 0.33990094743752747
testing phase
test loss item: 0.1810452789068222
test loss item: 0.07404641062021255
test loss item: 0.578986406326294
test loss item: 0.21297045052051544
test loss item: 0.23036673665046692
test loss item: 0.11804690957069397
test loss item: 1.7199867963790894
test loss item: 0.49920228123664856
test loss item: 0.20223712921142578
test loss item: 0.37754133343696594
test loss item: 0.8266475200653076
test loss item: 0.14696063101291656
test loss item: 0.16691458225250244
test loss item: 0.32299962639808655
test loss item: 0.1539696902036667
test loss item: 0.06376056373119354
test loss item: 0.3119139075279236
test loss item: 0.4567863345146179
test loss item: 0.6166660785675049
test loss item: 0.28852561116218567
test loss item: 0.758166491985321
test loss item: 0.37419331073760986
test loss item: 0.29614633321762085
test loss item: 0.17788155376911163
test loss item: 0.22179631888866425
test loss item: 0.22752733528614044
test loss item: 0.3401256203651428
test loss item: 0.18085265159606934
test loss item: 0.3257604241371155
test loss item: 0.3423904478549957
test loss item: 0.7837439179420471
test loss item: 0.061699215322732925
test loss item: 0.148151233792305
test loss item: 0.5702663064002991
test loss item: 0.42707347869873047
test loss item: 0.37890565395355225
test loss item: 0.7676323056221008
test loss item: 1.4016014337539673
test loss item: 0.4667853116989136
test loss item: 0.28419750928878784
test loss item: 0.3081619143486023
test loss item: 0.18054331839084625
test loss item: 0.3421504497528076
test loss item: 0.20441696047782898
test loss item: 0.6085349917411804
test loss item: 0.45044228434562683
test loss item: 0.2893732190132141
test loss item: 0.24424010515213013
test loss item: 0.449194073677063
test loss item: 0.6476489901542664
test loss item: 0.2677628695964813
test loss item: 0.12454746663570404
test loss item: 0.22883979976177216
test loss item: 0.13649487495422363
test loss item: 0.289604514837265
test loss item: 0.8290075063705444
test loss item: 0.5177275538444519
test loss item: 0.23595638573169708
test loss item: 0.23258118331432343
test loss item: 0.18484298884868622
test loss item: 0.4303729832172394
test loss item: 0.2395647168159485
test loss item: 0.22561262547969818
test loss item: 0.2560969889163971
test loss item: 0.8634504675865173
test loss item: 0.28697603940963745
test loss item: 0.3239191472530365
test loss item: 0.2619777023792267
test loss item: 0.5188689827919006
test loss item: 0.36121878027915955
test loss item: 0.06593475490808487
test loss item: 0.9573287963867188
test loss item: 0.32359862327575684
test loss item: 0.42928579449653625
test loss item: 0.15388524532318115
test loss item: 0.16665172576904297
test loss item: 0.17668364942073822
test loss item: 1.5015110969543457
test loss item: 0.4890279173851013
test loss item: 0.19355261325836182
test loss item: 0.08655591309070587
test loss item: 0.941771388053894
test loss item: 0.8592188358306885
test loss item: 0.994164764881134
test loss item: 0.22097720205783844
test loss item: 0.21869775652885437
test loss item: 0.08705825358629227
test loss item: 0.07836487144231796
test loss item: 0.16977812349796295
Epoch [89/100], Training Loss: 0.3399, Testing Loss: 0.3903
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 90/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3665167987346649
1
train loss item: 0.8804334402084351
2
train loss item: 0.20059116184711456
3
train loss item: 0.42292118072509766
4
train loss item: 0.3482983708381653
5
train loss item: 0.286262571811676
6
train loss item: 0.23311592638492584
7
train loss item: 0.49358823895454407
8
train loss item: 0.11420878767967224
9
train loss item: 0.23092186450958252
10
train loss item: 0.3001341223716736
11
train loss item: 0.21221239864826202
12
train loss item: 0.08584762364625931
13
train loss item: 0.3903283476829529
14
train loss item: 0.19266517460346222
15
train loss item: 0.4337948262691498
16
train loss item: 0.039181385189294815
17
train loss item: 0.2682230770587921
18
train loss item: 0.2955358326435089
19
train loss item: 0.2311495691537857
20
train loss item: 0.19943109154701233
21
train loss item: 0.07276761531829834
22
train loss item: 0.6372573971748352
23
train loss item: 0.6414178013801575
24
train loss item: 0.4912232756614685
25
train loss item: 0.12452732771635056
26
train loss item: 0.17000217735767365
27
train loss item: 0.18326181173324585
28
train loss item: 0.03609730303287506
29
train loss item: 0.43136969208717346
30
train loss item: 1.139075756072998
31
train loss item: 0.48981013894081116
32
train loss item: 0.06737019121646881
33
train loss item: 0.33266517519950867
34
train loss item: 0.0705578550696373
35
train loss item: 1.3851630687713623
36
train loss item: 0.3968568444252014
37
train loss item: 0.2805572748184204
38
train loss item: 0.3323097825050354
39
train loss item: 0.1814354956150055
40
train loss item: 0.12678159773349762
41
train loss item: 0.227455735206604
42
train loss item: 0.2414472997188568
43
train loss item: 0.15403354167938232
44
train loss item: 0.41940027475357056
45
train loss item: 0.08594417572021484
46
train loss item: 0.08846837282180786
47
train loss item: 0.28166988492012024
48
train loss item: 0.200754776597023
49
train loss item: 0.1243920624256134
50
train loss item: 0.2782033383846283
51
train loss item: 0.5949655175209045
52
train loss item: 0.04187914729118347
53
train loss item: 0.11657287925481796
54
train loss item: 1.2238836288452148
55
train loss item: 0.18608695268630981
56
train loss item: 0.2095278799533844
57
train loss item: 0.21052326261997223
58
train loss item: 0.13408426940441132
59
train loss item: 0.08017334342002869
60
train loss item: 0.6366984248161316
61
train loss item: 1.11027193069458
62
train loss item: 0.17531795799732208
63
train loss item: 0.299518346786499
64
train loss item: 0.13202723860740662
65
train loss item: 0.5022294521331787
66
train loss item: 0.3344034254550934
67
train loss item: 0.1564984917640686
68
train loss item: 0.2393663078546524
69
train loss item: 0.2890632748603821
70
train loss item: 0.20952840149402618
71
train loss item: 0.08727496862411499
72
train loss item: 0.14376096427440643
73
train loss item: 0.2768958508968353
74
train loss item: 0.03875444456934929
75
train loss item: 0.0693913921713829
76
train loss item: 0.662099301815033
77
train loss item: 0.7043570876121521
78
train loss item: 0.046184539794921875
79
train loss item: 0.21384070813655853
80
train loss item: 0.08103731274604797
81
train loss item: 0.1541147232055664
82
train loss item: 0.1594323217868805
83
train loss item: 0.3678632378578186
84
train loss item: 0.28348007798194885
85
train loss item: 0.48163846135139465
86
train loss item: 2.7307260036468506
87
train loss item: 0.12053769081830978
88
train loss item: 0.3042392134666443
epoch train loss: 0.33399873335709734
testing phase
test loss item: 0.17999666929244995
test loss item: 0.07182569056749344
test loss item: 0.5839871168136597
test loss item: 0.21367020905017853
test loss item: 0.23070962727069855
test loss item: 0.11768382042646408
test loss item: 1.7759861946105957
test loss item: 0.530462920665741
test loss item: 0.20277900993824005
test loss item: 0.3785321116447449
test loss item: 0.8297927379608154
test loss item: 0.14946278929710388
test loss item: 0.17124609649181366
test loss item: 0.3280140459537506
test loss item: 0.15306878089904785
test loss item: 0.05618768557906151
test loss item: 0.31885677576065063
test loss item: 0.4558769166469574
test loss item: 0.6324406266212463
test loss item: 0.29954060912132263
test loss item: 0.7581137418746948
test loss item: 0.3871193528175354
test loss item: 0.3023768365383148
test loss item: 0.18068529665470123
test loss item: 0.22098460793495178
test loss item: 0.23235461115837097
test loss item: 0.3441181182861328
test loss item: 0.18047337234020233
test loss item: 0.32900726795196533
test loss item: 0.34313809871673584
test loss item: 0.8025656342506409
test loss item: 0.05419733747839928
test loss item: 0.14835338294506073
test loss item: 0.5698302388191223
test loss item: 0.42650774121284485
test loss item: 0.3812347948551178
test loss item: 0.7852187156677246
test loss item: 1.4131728410720825
test loss item: 0.468046635389328
test loss item: 0.29114073514938354
test loss item: 0.31331703066825867
test loss item: 0.18460486829280853
test loss item: 0.34123513102531433
test loss item: 0.2087414413690567
test loss item: 0.6075707674026489
test loss item: 0.4635838270187378
test loss item: 0.2921994924545288
test loss item: 0.2528393268585205
test loss item: 0.4556300640106201
test loss item: 0.6568918228149414
test loss item: 0.26765838265419006
test loss item: 0.1253027319908142
test loss item: 0.23049019277095795
test loss item: 0.13655154407024384
test loss item: 0.28929024934768677
test loss item: 0.8325212001800537
test loss item: 0.5288508534431458
test loss item: 0.23840737342834473
test loss item: 0.23612341284751892
test loss item: 0.18504653871059418
test loss item: 0.4279046058654785
test loss item: 0.2519824802875519
test loss item: 0.23193128407001495
test loss item: 0.2596912682056427
test loss item: 0.8863033652305603
test loss item: 0.2876474857330322
test loss item: 0.3347722291946411
test loss item: 0.2658732235431671
test loss item: 0.5198363065719604
test loss item: 0.37404143810272217
test loss item: 0.06157133728265762
test loss item: 0.994757354259491
test loss item: 0.3313255310058594
test loss item: 0.4469788372516632
test loss item: 0.1557249128818512
test loss item: 0.16822931170463562
test loss item: 0.1798689216375351
test loss item: 1.5293891429901123
test loss item: 0.49609237909317017
test loss item: 0.19447685778141022
test loss item: 0.08006808906793594
test loss item: 0.9683947563171387
test loss item: 0.8741791248321533
test loss item: 1.014096736907959
test loss item: 0.227365180850029
test loss item: 0.2216872274875641
test loss item: 0.07648870348930359
test loss item: 0.06851982325315475
test loss item: 0.1767321676015854
Epoch [90/100], Training Loss: 0.3340, Testing Loss: 0.3961
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 91/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.36554640531539917
1
train loss item: 0.8604468703269958
2
train loss item: 0.20039591193199158
3
train loss item: 0.4182323217391968
4
train loss item: 0.34361177682876587
5
train loss item: 0.28307586908340454
6
train loss item: 0.2322138547897339
7
train loss item: 0.4882168173789978
8
train loss item: 0.11448384821414948
9
train loss item: 0.2317504584789276
10
train loss item: 0.2958621680736542
11
train loss item: 0.20935185253620148
12
train loss item: 0.0846320390701294
13
train loss item: 0.3836519122123718
14
train loss item: 0.18919731676578522
15
train loss item: 0.4382299780845642
16
train loss item: 0.03918496146798134
17
train loss item: 0.2666642367839813
18
train loss item: 0.2951105833053589
19
train loss item: 0.23153182864189148
20
train loss item: 0.19910503923892975
21
train loss item: 0.07244253158569336
22
train loss item: 0.6288288831710815
23
train loss item: 0.6268157362937927
24
train loss item: 0.4963033199310303
25
train loss item: 0.12279403209686279
26
train loss item: 0.16682744026184082
27
train loss item: 0.18279071152210236
28
train loss item: 0.036609020084142685
29
train loss item: 0.42686617374420166
30
train loss item: 1.1167933940887451
31
train loss item: 0.47752782702445984
32
train loss item: 0.0699358880519867
33
train loss item: 0.3293933570384979
34
train loss item: 0.07114277780056
35
train loss item: 1.3601608276367188
36
train loss item: 0.38876083493232727
37
train loss item: 0.27130720019340515
38
train loss item: 0.33019325137138367
39
train loss item: 0.18405765295028687
40
train loss item: 0.12610182166099548
41
train loss item: 0.22338531911373138
42
train loss item: 0.2429916113615036
43
train loss item: 0.15410006046295166
44
train loss item: 0.41065242886543274
45
train loss item: 0.08410552144050598
46
train loss item: 0.09200771152973175
47
train loss item: 0.2818168103694916
48
train loss item: 0.2011738270521164
49
train loss item: 0.12217315286397934
50
train loss item: 0.27826717495918274
51
train loss item: 0.5873364210128784
52
train loss item: 0.04675744101405144
53
train loss item: 0.11590370535850525
54
train loss item: 1.2021104097366333
55
train loss item: 0.18705175817012787
56
train loss item: 0.20926351845264435
57
train loss item: 0.21033614873886108
58
train loss item: 0.13374702632427216
59
train loss item: 0.0844145119190216
60
train loss item: 0.6466397047042847
61
train loss item: 1.0863745212554932
62
train loss item: 0.17375685274600983
63
train loss item: 0.3004152476787567
64
train loss item: 0.13386034965515137
65
train loss item: 0.4887755811214447
66
train loss item: 0.32551103830337524
67
train loss item: 0.15487219393253326
68
train loss item: 0.244185209274292
69
train loss item: 0.2878788709640503
70
train loss item: 0.20914974808692932
71
train loss item: 0.09048041701316833
72
train loss item: 0.1438559591770172
73
train loss item: 0.2775699496269226
74
train loss item: 0.04470110684633255
75
train loss item: 0.07242245972156525
76
train loss item: 0.6558513045310974
77
train loss item: 0.708833634853363
78
train loss item: 0.045531611889600754
79
train loss item: 0.21806474030017853
80
train loss item: 0.08290709555149078
81
train loss item: 0.15528467297554016
82
train loss item: 0.15784238278865814
83
train loss item: 0.3580104410648346
84
train loss item: 0.27758198976516724
85
train loss item: 0.481887549161911
86
train loss item: 2.6921021938323975
87
train loss item: 0.12106841057538986
88
train loss item: 0.30217838287353516
epoch train loss: 0.33102625742387237
testing phase
test loss item: 0.18162421882152557
test loss item: 0.07713911682367325
test loss item: 0.5779505968093872
test loss item: 0.20969921350479126
test loss item: 0.2224833220243454
test loss item: 0.10408627986907959
test loss item: 1.6826157569885254
test loss item: 0.46362924575805664
test loss item: 0.20244841277599335
test loss item: 0.37239691615104675
test loss item: 0.8250305652618408
test loss item: 0.1454029530286789
test loss item: 0.15988430380821228
test loss item: 0.31827011704444885
test loss item: 0.15251542627811432
test loss item: 0.07852062582969666
test loss item: 0.3008096516132355
test loss item: 0.45176804065704346
test loss item: 0.594154953956604
test loss item: 0.2762885093688965
test loss item: 0.7498217225074768
test loss item: 0.3601635992527008
test loss item: 0.2913917899131775
test loss item: 0.17586268484592438
test loss item: 0.21851478517055511
test loss item: 0.2184930443763733
test loss item: 0.3349973261356354
test loss item: 0.17071817815303802
test loss item: 0.3198758363723755
test loss item: 0.3355487883090973
test loss item: 0.7750357985496521
test loss item: 0.07646990567445755
test loss item: 0.14652685821056366
test loss item: 0.56462562084198
test loss item: 0.42480990290641785
test loss item: 0.3688162863254547
test loss item: 0.7448211908340454
test loss item: 1.412515640258789
test loss item: 0.4605149030685425
test loss item: 0.2759745121002197
test loss item: 0.3035149574279785
test loss item: 0.17290954291820526
test loss item: 0.34130048751831055
test loss item: 0.1988000124692917
test loss item: 0.6006289124488831
test loss item: 0.4323412775993347
test loss item: 0.2825187146663666
test loss item: 0.23454588651657104
test loss item: 0.4407956302165985
test loss item: 0.63447105884552
test loss item: 0.2660492956638336
test loss item: 0.11867330968379974
test loss item: 0.22574742138385773
test loss item: 0.13237950205802917
test loss item: 0.2882317900657654
test loss item: 0.8267766237258911
test loss item: 0.5058238506317139
test loss item: 0.2321639358997345
test loss item: 0.22439327836036682
test loss item: 0.18387924134731293
test loss item: 0.42925506830215454
test loss item: 0.2242751121520996
test loss item: 0.2149563729763031
test loss item: 0.2526317238807678
test loss item: 0.8666000962257385
test loss item: 0.2829560935497284
test loss item: 0.31137987971305847
test loss item: 0.25635719299316406
test loss item: 0.5157023072242737
test loss item: 0.3459109663963318
test loss item: 0.06908540427684784
test loss item: 0.923143208026886
test loss item: 0.3185155391693115
test loss item: 0.41674691438674927
test loss item: 0.14493800699710846
test loss item: 0.16052208840847015
test loss item: 0.17539329826831818
test loss item: 1.5325758457183838
test loss item: 0.4840603768825531
test loss item: 0.1810024231672287
test loss item: 0.08870702981948853
test loss item: 0.9382398128509521
test loss item: 0.839201033115387
test loss item: 1.0120645761489868
test loss item: 0.21566864848136902
test loss item: 0.2088194489479065
test loss item: 0.09688473492860794
test loss item: 0.0979849249124527
test loss item: 0.16076946258544922
Epoch [91/100], Training Loss: 0.3310, Testing Loss: 0.3846
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 92/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3599291145801544
1
train loss item: 0.8542699813842773
2
train loss item: 0.19489693641662598
3
train loss item: 0.4163060784339905
4
train loss item: 0.3406112492084503
5
train loss item: 0.28644049167633057
6
train loss item: 0.22999857366085052
7
train loss item: 0.4728429615497589
8
train loss item: 0.11476508527994156
9
train loss item: 0.224930077791214
10
train loss item: 0.29724666476249695
11
train loss item: 0.21864044666290283
12
train loss item: 0.08664321899414062
13
train loss item: 0.3903612196445465
14
train loss item: 0.19844603538513184
15
train loss item: 0.42452874779701233
16
train loss item: 0.04113643243908882
17
train loss item: 0.2667427361011505
18
train loss item: 0.3021807372570038
19
train loss item: 0.2223207950592041
20
train loss item: 0.18576116859912872
21
train loss item: 0.0769195631146431
22
train loss item: 0.6223064064979553
23
train loss item: 0.6292656660079956
24
train loss item: 0.4712468981742859
25
train loss item: 0.12854814529418945
26
train loss item: 0.17590205371379852
27
train loss item: 0.18353775143623352
28
train loss item: 0.037901267409324646
29
train loss item: 0.4320434629917145
30
train loss item: 1.1020256280899048
31
train loss item: 0.48438015580177307
32
train loss item: 0.06805698573589325
33
train loss item: 0.32441234588623047
34
train loss item: 0.07928399741649628
35
train loss item: 1.330065369606018
36
train loss item: 0.3894446790218353
37
train loss item: 0.29360491037368774
38
train loss item: 0.32974764704704285
39
train loss item: 0.17986319959163666
40
train loss item: 0.12343382090330124
41
train loss item: 0.24184614419937134
42
train loss item: 0.23794397711753845
43
train loss item: 0.1552959382534027
44
train loss item: 0.4097502529621124
45
train loss item: 0.0848553478717804
46
train loss item: 0.08894649893045425
47
train loss item: 0.2690317928791046
48
train loss item: 0.19307298958301544
49
train loss item: 0.12932316958904266
50
train loss item: 0.27126583456993103
51
train loss item: 0.5988638401031494
52
train loss item: 0.04460618644952774
53
train loss item: 0.11552903801202774
54
train loss item: 1.1734287738800049
55
train loss item: 0.17917796969413757
56
train loss item: 0.21600937843322754
57
train loss item: 0.209463968873024
58
train loss item: 0.13514389097690582
59
train loss item: 0.07936075329780579
60
train loss item: 0.6124396324157715
61
train loss item: 1.0739470720291138
62
train loss item: 0.17655450105667114
63
train loss item: 0.29190942645072937
64
train loss item: 0.13248196244239807
65
train loss item: 0.5083304047584534
66
train loss item: 0.34152403473854065
67
train loss item: 0.15346507728099823
68
train loss item: 0.22220516204833984
69
train loss item: 0.28331005573272705
70
train loss item: 0.20617711544036865
71
train loss item: 0.08859113603830338
72
train loss item: 0.13812190294265747
73
train loss item: 0.2686033844947815
74
train loss item: 0.03828050196170807
75
train loss item: 0.07183507084846497
76
train loss item: 0.6394971013069153
77
train loss item: 0.6858733892440796
78
train loss item: 0.04915538430213928
79
train loss item: 0.20410282909870148
80
train loss item: 0.08026312291622162
81
train loss item: 0.14756949245929718
82
train loss item: 0.15738898515701294
83
train loss item: 0.38037559390068054
84
train loss item: 0.2861247658729553
85
train loss item: 0.4645107388496399
86
train loss item: 2.662787675857544
87
train loss item: 0.11730098724365234
88
train loss item: 0.29767826199531555
epoch train loss: 0.328138305857945
testing phase
test loss item: 0.17985861003398895
test loss item: 0.08453089743852615
test loss item: 0.5705762505531311
test loss item: 0.21239475905895233
test loss item: 0.2304663509130478
test loss item: 0.12971295416355133
test loss item: 1.8111321926116943
test loss item: 0.57905113697052
test loss item: 0.197718545794487
test loss item: 0.3685286343097687
test loss item: 0.8173784017562866
test loss item: 0.14809449017047882
test loss item: 0.1725948303937912
test loss item: 0.32612520456314087
test loss item: 0.15116488933563232
test loss item: 0.07646570354700089
test loss item: 0.3228982388973236
test loss item: 0.44035401940345764
test loss item: 0.6562569737434387
test loss item: 0.30724766850471497
test loss item: 0.7314075231552124
test loss item: 0.39750364422798157
test loss item: 0.2974664270877838
test loss item: 0.18434113264083862
test loss item: 0.21648754179477692
test loss item: 0.23775148391723633
test loss item: 0.3444181978702545
test loss item: 0.18399304151535034
test loss item: 0.3227550983428955
test loss item: 0.33854803442955017
test loss item: 0.8066246509552002
test loss item: 0.07897176593542099
test loss item: 0.15167857706546783
test loss item: 0.5533822178840637
test loss item: 0.41296565532684326
test loss item: 0.38723137974739075
test loss item: 0.8011360764503479
test loss item: 1.3978689908981323
test loss item: 0.4527842402458191
test loss item: 0.2957482933998108
test loss item: 0.31555092334747314
test loss item: 0.1836211234331131
test loss item: 0.3304862678050995
test loss item: 0.2092113494873047
test loss item: 0.5852423310279846
test loss item: 0.4743635356426239
test loss item: 0.2844192683696747
test loss item: 0.2633350193500519
test loss item: 0.44945821166038513
test loss item: 0.6608086228370667
test loss item: 0.2541511058807373
test loss item: 0.1301630288362503
test loss item: 0.226761594414711
test loss item: 0.13343530893325806
test loss item: 0.2795294225215912
test loss item: 0.8146176934242249
test loss item: 0.5431387424468994
test loss item: 0.23344582319259644
test loss item: 0.2381587028503418
test loss item: 0.178038090467453
test loss item: 0.4130333662033081
test loss item: 0.2700190246105194
test loss item: 0.23614619672298431
test loss item: 0.25851672887802124
test loss item: 0.9031360149383545
test loss item: 0.2830803692340851
test loss item: 0.3434024751186371
test loss item: 0.2661430239677429
test loss item: 0.5081819295883179
test loss item: 0.402042955160141
test loss item: 0.07226262241601944
test loss item: 1.0283188819885254
test loss item: 0.3263986110687256
test loss item: 0.4549109935760498
test loss item: 0.1587437242269516
test loss item: 0.16704599559307098
test loss item: 0.18369749188423157
test loss item: 1.536532998085022
test loss item: 0.4904880225658417
test loss item: 0.19866524636745453
test loss item: 0.0856720581650734
test loss item: 0.9893643856048584
test loss item: 0.8831413984298706
test loss item: 1.020551323890686
test loss item: 0.22851507365703583
test loss item: 0.2258559763431549
test loss item: 0.08720753341913223
test loss item: 0.07752916216850281
test loss item: 0.18876448273658752
Epoch [92/100], Training Loss: 0.3281, Testing Loss: 0.3983
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6972.00 MB
Epoch 93/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3638378381729126
1
train loss item: 0.8464056253433228
2
train loss item: 0.1950584352016449
3
train loss item: 0.4175878167152405
4
train loss item: 0.3353372812271118
5
train loss item: 0.27609482407569885
6
train loss item: 0.2318083494901657
7
train loss item: 0.47584277391433716
8
train loss item: 0.11251802742481232
9
train loss item: 0.23237964510917664
10
train loss item: 0.28755131363868713
11
train loss item: 0.20547010004520416
12
train loss item: 0.08540505170822144
13
train loss item: 0.3713745176792145
14
train loss item: 0.18538756668567657
15
train loss item: 0.462683767080307
16
train loss item: 0.03927307575941086
17
train loss item: 0.2631291151046753
18
train loss item: 0.29526031017303467
19
train loss item: 0.22880622744560242
20
train loss item: 0.20338843762874603
21
train loss item: 0.07533150166273117
22
train loss item: 0.6459050178527832
23
train loss item: 0.6027026772499084
24
train loss item: 0.5073676109313965
25
train loss item: 0.11980349570512772
26
train loss item: 0.16414952278137207
27
train loss item: 0.18159300088882446
28
train loss item: 0.034867867827415466
29
train loss item: 0.44472426176071167
30
train loss item: 1.0722635984420776
31
train loss item: 0.4611397385597229
32
train loss item: 0.06842562556266785
33
train loss item: 0.31630054116249084
34
train loss item: 0.0700545683503151
35
train loss item: 1.3151518106460571
36
train loss item: 0.3873359262943268
37
train loss item: 0.25731536746025085
38
train loss item: 0.3434024453163147
39
train loss item: 0.18343475461006165
40
train loss item: 0.12584438920021057
41
train loss item: 0.21936962008476257
42
train loss item: 0.24169857800006866
43
train loss item: 0.14948169887065887
44
train loss item: 0.4020754396915436
45
train loss item: 0.08097494393587112
46
train loss item: 0.09093861281871796
47
train loss item: 0.2786141037940979
48
train loss item: 0.19653266668319702
49
train loss item: 0.11739817261695862
50
train loss item: 0.27540507912635803
51
train loss item: 0.5839261412620544
52
train loss item: 0.045774929225444794
53
train loss item: 0.11236867308616638
54
train loss item: 1.1585021018981934
55
train loss item: 0.18415457010269165
56
train loss item: 0.20493696630001068
57
train loss item: 0.2038009911775589
58
train loss item: 0.1321108043193817
59
train loss item: 0.0842549130320549
60
train loss item: 0.6746506094932556
61
train loss item: 1.0364067554473877
62
train loss item: 0.1722891926765442
63
train loss item: 0.30296263098716736
64
train loss item: 0.12768490612506866
65
train loss item: 0.47763168811798096
66
train loss item: 0.3201379179954529
67
train loss item: 0.15433095395565033
68
train loss item: 0.2509596347808838
69
train loss item: 0.2869781255722046
70
train loss item: 0.2083069235086441
71
train loss item: 0.08752566576004028
72
train loss item: 0.13889048993587494
73
train loss item: 0.2771451771259308
74
train loss item: 0.039366163313388824
75
train loss item: 0.07060553133487701
76
train loss item: 0.6391973495483398
77
train loss item: 0.7141869068145752
78
train loss item: 0.04693349450826645
79
train loss item: 0.2265836000442505
80
train loss item: 0.07786282151937485
81
train loss item: 0.15314777195453644
82
train loss item: 0.15238426625728607
83
train loss item: 0.3458079397678375
84
train loss item: 0.27889713644981384
85
train loss item: 0.4796033799648285
86
train loss item: 2.616349697113037
87
train loss item: 0.11493764072656631
88
train loss item: 0.30642592906951904
epoch train loss: 0.32620475424474543
testing phase
test loss item: 0.17349733412265778
test loss item: 0.06946863234043121
test loss item: 0.5809140801429749
test loss item: 0.2018468827009201
test loss item: 0.21869784593582153
test loss item: 0.0966208428144455
test loss item: 1.6389037370681763
test loss item: 0.4446708559989929
test loss item: 0.20359119772911072
test loss item: 0.36989253759384155
test loss item: 0.82923424243927
test loss item: 0.13856111466884613
test loss item: 0.15838338434696198
test loss item: 0.3152221143245697
test loss item: 0.14705809950828552
test loss item: 0.0653369352221489
test loss item: 0.2916848659515381
test loss item: 0.4446789622306824
test loss item: 0.5803897976875305
test loss item: 0.2708195447921753
test loss item: 0.7325705289840698
test loss item: 0.34881311655044556
test loss item: 0.2842116355895996
test loss item: 0.1664506494998932
test loss item: 0.21110127866268158
test loss item: 0.21271571516990662
test loss item: 0.32939770817756653
test loss item: 0.16530635952949524
test loss item: 0.3126407563686371
test loss item: 0.3306518793106079
test loss item: 0.7687129378318787
test loss item: 0.07272055745124817
test loss item: 0.13700024783611298
test loss item: 0.5568472146987915
test loss item: 0.4196094572544098
test loss item: 0.37434864044189453
test loss item: 0.7278518676757812
test loss item: 1.4313130378723145
test loss item: 0.4505326747894287
test loss item: 0.264666348695755
test loss item: 0.29349401593208313
test loss item: 0.17090190947055817
test loss item: 0.3391854763031006
test loss item: 0.18953482806682587
test loss item: 0.5856274366378784
test loss item: 0.4203908145427704
test loss item: 0.2768925130367279
test loss item: 0.23445473611354828
test loss item: 0.4375915825366974
test loss item: 0.6306227445602417
test loss item: 0.26132136583328247
test loss item: 0.11595816165208817
test loss item: 0.2197897881269455
test loss item: 0.12510108947753906
test loss item: 0.2847568094730377
test loss item: 0.8303593993186951
test loss item: 0.4994915723800659
test loss item: 0.2264368236064911
test loss item: 0.21740111708641052
test loss item: 0.1813679188489914
test loss item: 0.4272671937942505
test loss item: 0.21426302194595337
test loss item: 0.21039463579654694
test loss item: 0.24676313996315002
test loss item: 0.8731563091278076
test loss item: 0.2749866545200348
test loss item: 0.3045889735221863
test loss item: 0.24926872551441193
test loss item: 0.508631706237793
test loss item: 0.344378799200058
test loss item: 0.05835622921586037
test loss item: 0.8919453620910645
test loss item: 0.31545525789260864
test loss item: 0.4039447009563446
test loss item: 0.13974808156490326
test loss item: 0.1578463912010193
test loss item: 0.166265070438385
test loss item: 1.5595985651016235
test loss item: 0.479070782661438
test loss item: 0.17637774348258972
test loss item: 0.07338476181030273
test loss item: 0.9389309287071228
test loss item: 0.8257623314857483
test loss item: 1.035744071006775
test loss item: 0.20900993049144745
test loss item: 0.20246416330337524
test loss item: 0.07907455414533615
test loss item: 0.07590210437774658
test loss item: 0.15337131917476654
Epoch [93/100], Training Loss: 0.3262, Testing Loss: 0.3784
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6892.00 MB
Epoch 94/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.35908061265945435
1
train loss item: 0.8240393996238708
2
train loss item: 0.18995477259159088
3
train loss item: 0.4096340537071228
4
train loss item: 0.34171098470687866
5
train loss item: 0.2842938303947449
6
train loss item: 0.23152531683444977
7
train loss item: 0.45932498574256897
8
train loss item: 0.11852812021970749
9
train loss item: 0.22400665283203125
10
train loss item: 0.29070648550987244
11
train loss item: 0.2192927896976471
12
train loss item: 0.08339543640613556
13
train loss item: 0.38508060574531555
14
train loss item: 0.19536423683166504
15
train loss item: 0.4186820089817047
16
train loss item: 0.03929421305656433
17
train loss item: 0.2704659700393677
18
train loss item: 0.3057766258716583
19
train loss item: 0.2204218953847885
20
train loss item: 0.1807023137807846
21
train loss item: 0.07824879884719849
22
train loss item: 0.6180319786071777
23
train loss item: 0.6146882772445679
24
train loss item: 0.4570770859718323
25
train loss item: 0.129797101020813
26
train loss item: 0.1782480776309967
27
train loss item: 0.182534322142601
28
train loss item: 0.037762921303510666
29
train loss item: 0.4305630028247833
30
train loss item: 1.0511001348495483
31
train loss item: 0.4769984781742096
32
train loss item: 0.07231898605823517
33
train loss item: 0.31661638617515564
34
train loss item: 0.08815047144889832
35
train loss item: 1.2833024263381958
36
train loss item: 0.3851635158061981
37
train loss item: 0.28485119342803955
38
train loss item: 0.331223726272583
39
train loss item: 0.18096931278705597
40
train loss item: 0.11927450448274612
41
train loss item: 0.2384660840034485
42
train loss item: 0.23682305216789246
43
train loss item: 0.15708884596824646
44
train loss item: 0.4030076563358307
45
train loss item: 0.08739850670099258
46
train loss item: 0.0944771096110344
47
train loss item: 0.2652074992656708
48
train loss item: 0.1907268464565277
49
train loss item: 0.1220630556344986
50
train loss item: 0.2676786482334137
51
train loss item: 0.5781608819961548
52
train loss item: 0.04794924706220627
53
train loss item: 0.11608058214187622
54
train loss item: 1.1223030090332031
55
train loss item: 0.17562127113342285
56
train loss item: 0.2205498367547989
57
train loss item: 0.20076307654380798
58
train loss item: 0.135832279920578
59
train loss item: 0.08642475306987762
60
train loss item: 0.5963373780250549
61
train loss item: 1.0203739404678345
62
train loss item: 0.17649416625499725
63
train loss item: 0.29116392135620117
64
train loss item: 0.1330242156982422
65
train loss item: 0.5095434188842773
66
train loss item: 0.32927650213241577
67
train loss item: 0.1515890210866928
68
train loss item: 0.2152804732322693
69
train loss item: 0.27984389662742615
70
train loss item: 0.20368142426013947
71
train loss item: 0.0895911455154419
72
train loss item: 0.13862936198711395
73
train loss item: 0.262584924697876
74
train loss item: 0.04636072739958763
75
train loss item: 0.07678636908531189
76
train loss item: 0.6165777444839478
77
train loss item: 0.6716132164001465
78
train loss item: 0.04681067168712616
79
train loss item: 0.2060367614030838
80
train loss item: 0.08895347267389297
81
train loss item: 0.14424733817577362
82
train loss item: 0.15492922067642212
83
train loss item: 0.36451485753059387
84
train loss item: 0.28251564502716064
85
train loss item: 0.44738152623176575
86
train loss item: 2.58426833152771
87
train loss item: 0.11717671155929565
88
train loss item: 0.296345978975296
epoch train loss: 0.3219860294059421
testing phase
test loss item: 0.18213972449302673
test loss item: 0.09106772392988205
test loss item: 0.5574344396591187
test loss item: 0.2121833860874176
test loss item: 0.2237912118434906
test loss item: 0.12778069078922272
test loss item: 1.7334944009780884
test loss item: 0.5427995324134827
test loss item: 0.19791902601718903
test loss item: 0.36013686656951904
test loss item: 0.7967178821563721
test loss item: 0.1467718929052353
test loss item: 0.16733768582344055
test loss item: 0.31821924448013306
test loss item: 0.15054556727409363
test loss item: 0.08269353210926056
test loss item: 0.3139892518520355
test loss item: 0.4293341040611267
test loss item: 0.6259689331054688
test loss item: 0.2958914339542389
test loss item: 0.7109655141830444
test loss item: 0.3835887610912323
test loss item: 0.28789395093917847
test loss item: 0.1846185177564621
test loss item: 0.21278345584869385
test loss item: 0.22985902428627014
test loss item: 0.33822956681251526
test loss item: 0.17933231592178345
test loss item: 0.3136249780654907
test loss item: 0.33124884963035583
test loss item: 0.7760947346687317
test loss item: 0.08821572363376617
test loss item: 0.15377238392829895
test loss item: 0.5392730236053467
test loss item: 0.4032551944255829
test loss item: 0.3728480637073517
test loss item: 0.7676411867141724
test loss item: 1.3677293062210083
test loss item: 0.4394277036190033
test loss item: 0.287602037191391
test loss item: 0.30814290046691895
test loss item: 0.17660515010356903
test loss item: 0.3252260684967041
test loss item: 0.20559948682785034
test loss item: 0.5687780976295471
test loss item: 0.4573360085487366
test loss item: 0.27700307965278625
test loss item: 0.25363317131996155
test loss item: 0.4359697997570038
test loss item: 0.6357699036598206
test loss item: 0.2490050494670868
test loss item: 0.12906546890735626
test loss item: 0.22248195111751556
test loss item: 0.13429118692874908
test loss item: 0.27423253655433655
test loss item: 0.7915108799934387
test loss item: 0.5224648118019104
test loss item: 0.22828835248947144
test loss item: 0.23365911841392517
test loss item: 0.17321808636188507
test loss item: 0.4075795114040375
test loss item: 0.26041170954704285
test loss item: 0.23015311360359192
test loss item: 0.2513793706893921
test loss item: 0.8790906071662903
test loss item: 0.28142961859703064
test loss item: 0.332893967628479
test loss item: 0.2585729956626892
test loss item: 0.4916762113571167
test loss item: 0.3791091740131378
test loss item: 0.07775263488292694
test loss item: 0.9758725166320801
test loss item: 0.3195528984069824
test loss item: 0.44000428915023804
test loss item: 0.15637148916721344
test loss item: 0.1654195636510849
test loss item: 0.18335376679897308
test loss item: 1.5084458589553833
test loss item: 0.4770403206348419
test loss item: 0.19330084323883057
test loss item: 0.0968150645494461
test loss item: 0.9562339782714844
test loss item: 0.849833607673645
test loss item: 1.0048136711120605
test loss item: 0.22067274153232574
test loss item: 0.21824176609516144
test loss item: 0.09647355228662491
test loss item: 0.08864681422710419
test loss item: 0.17453885078430176
Epoch [94/100], Training Loss: 0.3220, Testing Loss: 0.3877
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 95/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3511406481266022
1
train loss item: 0.8118413090705872
2
train loss item: 0.19010727107524872
3
train loss item: 0.40475961565971375
4
train loss item: 0.3264363706111908
5
train loss item: 0.2695935368537903
6
train loss item: 0.23055213689804077
7
train loss item: 0.4566331207752228
8
train loss item: 0.11067269742488861
9
train loss item: 0.22813895344734192
10
train loss item: 0.27865180373191833
11
train loss item: 0.19806762039661407
12
train loss item: 0.08830013871192932
13
train loss item: 0.3628445565700531
14
train loss item: 0.18501678109169006
15
train loss item: 0.4511927664279938
16
train loss item: 0.048428889364004135
17
train loss item: 0.25996533036231995
18
train loss item: 0.2849538028240204
19
train loss item: 0.22536388039588928
20
train loss item: 0.20127108693122864
21
train loss item: 0.07987670600414276
22
train loss item: 0.6159859895706177
23
train loss item: 0.5839983820915222
24
train loss item: 0.49204978346824646
25
train loss item: 0.11576544493436813
26
train loss item: 0.16068531572818756
27
train loss item: 0.1777617633342743
28
train loss item: 0.043960507959127426
29
train loss item: 0.4308100938796997
30
train loss item: 1.0172715187072754
31
train loss item: 0.4520113468170166
32
train loss item: 0.06319428980350494
33
train loss item: 0.30885210633277893
34
train loss item: 0.07214934378862381
35
train loss item: 1.2681851387023926
36
train loss item: 0.3871176540851593
37
train loss item: 0.2467755824327469
38
train loss item: 0.32914623618125916
39
train loss item: 0.17796629667282104
40
train loss item: 0.1249261349439621
41
train loss item: 0.21428513526916504
42
train loss item: 0.24232597649097443
43
train loss item: 0.14616864919662476
44
train loss item: 0.3968525826931
45
train loss item: 0.08071339130401611
46
train loss item: 0.08483133465051651
47
train loss item: 0.27264344692230225
48
train loss item: 0.19091524183750153
49
train loss item: 0.11492538452148438
50
train loss item: 0.26800090074539185
51
train loss item: 0.5811302065849304
52
train loss item: 0.05371510609984398
53
train loss item: 0.10974414646625519
54
train loss item: 1.101158618927002
55
train loss item: 0.18194420635700226
56
train loss item: 0.20141470432281494
57
train loss item: 0.20286092162132263
58
train loss item: 0.13036350905895233
59
train loss item: 0.08168374001979828
60
train loss item: 0.6508688926696777
61
train loss item: 0.9920589327812195
62
train loss item: 0.17161625623703003
63
train loss item: 0.2975754141807556
64
train loss item: 0.12376181036233902
65
train loss item: 0.4626494348049164
66
train loss item: 0.3124696910381317
67
train loss item: 0.15280099213123322
68
train loss item: 0.2529832720756531
69
train loss item: 0.2775488495826721
70
train loss item: 0.20563943684101105
71
train loss item: 0.08870327472686768
72
train loss item: 0.13343572616577148
73
train loss item: 0.2739884853363037
74
train loss item: 0.041694171726703644
75
train loss item: 0.07147131115198135
76
train loss item: 0.6156355738639832
77
train loss item: 0.6860674023628235
78
train loss item: 0.05689065158367157
79
train loss item: 0.2237461358308792
80
train loss item: 0.075454942882061
81
train loss item: 0.15475398302078247
82
train loss item: 0.14924564957618713
83
train loss item: 0.3367336094379425
84
train loss item: 0.28165075182914734
85
train loss item: 0.45969507098197937
86
train loss item: 2.5426247119903564
87
train loss item: 0.10980009287595749
88
train loss item: 0.2980259656906128
epoch train loss: 0.31761449043837825
testing phase
test loss item: 0.17389872670173645
test loss item: 0.07623957097530365
test loss item: 0.5479328036308289
test loss item: 0.20358066260814667
test loss item: 0.2159368395805359
test loss item: 0.10813161730766296
test loss item: 1.6189037561416626
test loss item: 0.4606294333934784
test loss item: 0.19128340482711792
test loss item: 0.354451984167099
test loss item: 0.7765722274780273
test loss item: 0.13933268189430237
test loss item: 0.16293074190616608
test loss item: 0.3079848885536194
test loss item: 0.14473125338554382
test loss item: 0.0650959238409996
test loss item: 0.2947387993335724
test loss item: 0.4264414608478546
test loss item: 0.5787498354911804
test loss item: 0.2756665349006653
test loss item: 0.7117404937744141
test loss item: 0.3535875976085663
test loss item: 0.28050246834754944
test loss item: 0.17070963978767395
test loss item: 0.2057984471321106
test loss item: 0.21708562970161438
test loss item: 0.3236679434776306
test loss item: 0.1675822138786316
test loss item: 0.30654415488243103
test loss item: 0.32138681411743164
test loss item: 0.7357596158981323
test loss item: 0.06420150399208069
test loss item: 0.1414819210767746
test loss item: 0.53304123878479
test loss item: 0.3999268114566803
test loss item: 0.3522813320159912
test loss item: 0.7211843132972717
test loss item: 1.3364405632019043
test loss item: 0.43402841687202454
test loss item: 0.26730281114578247
test loss item: 0.29199811816215515
test loss item: 0.17037180066108704
test loss item: 0.32420963048934937
test loss item: 0.19118431210517883
test loss item: 0.5693288445472717
test loss item: 0.4275111258029938
test loss item: 0.2755129039287567
test loss item: 0.23809948563575745
test loss item: 0.4222719967365265
test loss item: 0.6029523015022278
test loss item: 0.25378361344337463
test loss item: 0.11990963667631149
test loss item: 0.21448108553886414
test loss item: 0.12537163496017456
test loss item: 0.27363893389701843
test loss item: 0.7821044921875
test loss item: 0.48830780386924744
test loss item: 0.22970640659332275
test loss item: 0.22084423899650574
test loss item: 0.17616510391235352
test loss item: 0.40490633249282837
test loss item: 0.22583332657814026
test loss item: 0.21398741006851196
test loss item: 0.2452283650636673
test loss item: 0.8480545878410339
test loss item: 0.2748175859451294
test loss item: 0.3085055649280548
test loss item: 0.24796275794506073
test loss item: 0.48833855986595154
test loss item: 0.3321268856525421
test loss item: 0.06246710568666458
test loss item: 0.8920185565948486
test loss item: 0.3145655691623688
test loss item: 0.40764012932777405
test loss item: 0.1436108499765396
test loss item: 0.1591944694519043
test loss item: 0.16935192048549652
test loss item: 1.4778573513031006
test loss item: 0.4647400975227356
test loss item: 0.18009530007839203
test loss item: 0.0806182250380516
test loss item: 0.9024825096130371
test loss item: 0.8006426692008972
test loss item: 0.9806673526763916
test loss item: 0.20559300482273102
test loss item: 0.20555008947849274
test loss item: 0.08068422973155975
test loss item: 0.07578027248382568
test loss item: 0.15858019888401031
Epoch [95/100], Training Loss: 0.3176, Testing Loss: 0.3699
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 96/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.35542014241218567
1
train loss item: 0.8272839784622192
2
train loss item: 0.18193620443344116
3
train loss item: 0.41083836555480957
4
train loss item: 0.3369424641132355
5
train loss item: 0.2741881310939789
6
train loss item: 0.22134454548358917
7
train loss item: 0.4514329135417938
8
train loss item: 0.10932324826717377
9
train loss item: 0.2175414115190506
10
train loss item: 0.27835649251937866
11
train loss item: 0.21026737987995148
12
train loss item: 0.08331240713596344
13
train loss item: 0.36527082324028015
14
train loss item: 0.18275685608386993
15
train loss item: 0.4189065992832184
16
train loss item: 0.03918951377272606
17
train loss item: 0.25602027773857117
18
train loss item: 0.2914494574069977
19
train loss item: 0.2148563414812088
20
train loss item: 0.18625113368034363
21
train loss item: 0.07181484252214432
22
train loss item: 0.6421523094177246
23
train loss item: 0.5871696472167969
24
train loss item: 0.4575996398925781
25
train loss item: 0.11986380070447922
26
train loss item: 0.1636713147163391
27
train loss item: 0.17055274546146393
28
train loss item: 0.03584112972021103
29
train loss item: 0.4318684935569763
30
train loss item: 0.9990769624710083
31
train loss item: 0.4754803776741028
32
train loss item: 0.06605177372694016
33
train loss item: 0.29917511343955994
34
train loss item: 0.07461146265268326
35
train loss item: 1.2328776121139526
36
train loss item: 0.37724068760871887
37
train loss item: 0.27796676754951477
38
train loss item: 0.3422917425632477
39
train loss item: 0.16664786636829376
40
train loss item: 0.11662702262401581
41
train loss item: 0.21652533113956451
42
train loss item: 0.23325663805007935
43
train loss item: 0.14548839628696442
44
train loss item: 0.3928503096103668
45
train loss item: 0.07823292165994644
46
train loss item: 0.08906474709510803
47
train loss item: 0.2599187195301056
48
train loss item: 0.18013687431812286
49
train loss item: 0.11484083533287048
50
train loss item: 0.2600126266479492
51
train loss item: 0.5588412284851074
52
train loss item: 0.04576689749956131
53
train loss item: 0.1065802052617073
54
train loss item: 1.0740880966186523
55
train loss item: 0.1721719652414322
56
train loss item: 0.20103174448013306
57
train loss item: 0.19238421320915222
58
train loss item: 0.1295498013496399
59
train loss item: 0.08534129709005356
60
train loss item: 0.5636894702911377
61
train loss item: 0.9636693000793457
62
train loss item: 0.1675245314836502
63
train loss item: 0.28689414262771606
64
train loss item: 0.12157733738422394
65
train loss item: 0.5114124417304993
66
train loss item: 0.323212593793869
67
train loss item: 0.14683452248573303
68
train loss item: 0.21377141773700714
69
train loss item: 0.2770759165287018
70
train loss item: 0.1981079876422882
71
train loss item: 0.08355623483657837
72
train loss item: 0.1278192698955536
73
train loss item: 0.2569211423397064
74
train loss item: 0.03820113465189934
75
train loss item: 0.06995386630296707
76
train loss item: 0.5935057997703552
77
train loss item: 0.6514459252357483
78
train loss item: 0.047035302966833115
79
train loss item: 0.2047521471977234
80
train loss item: 0.07911180704832077
81
train loss item: 0.14330580830574036
82
train loss item: 0.14551778137683868
83
train loss item: 0.3621489107608795
84
train loss item: 0.26486849784851074
85
train loss item: 0.4325908124446869
86
train loss item: 2.5178120136260986
87
train loss item: 0.10771935433149338
88
train loss item: 0.2990607023239136
epoch train loss: 0.31187246091077836
testing phase
test loss item: 0.18265214562416077
test loss item: 0.07564333826303482
test loss item: 0.611685037612915
test loss item: 0.21085219085216522
test loss item: 0.2204715758562088
test loss item: 0.10316018760204315
test loss item: 1.6875886917114258
test loss item: 0.47514936327934265
test loss item: 0.2195933312177658
test loss item: 0.3802475333213806
test loss item: 0.8581723570823669
test loss item: 0.14641916751861572
test loss item: 0.1647820770740509
test loss item: 0.3244028389453888
test loss item: 0.150416761636734
test loss item: 0.07219870388507843
test loss item: 0.30538395047187805
test loss item: 0.45121631026268005
test loss item: 0.5876942873001099
test loss item: 0.28993093967437744
test loss item: 0.7403724789619446
test loss item: 0.3683328628540039
test loss item: 0.29793307185173035
test loss item: 0.18030110001564026
test loss item: 0.2137511968612671
test loss item: 0.21904891729354858
test loss item: 0.3427744507789612
test loss item: 0.16259415447711945
test loss item: 0.3179188072681427
test loss item: 0.33409830927848816
test loss item: 0.8065946698188782
test loss item: 0.07198183983564377
test loss item: 0.14912715554237366
test loss item: 0.5626621842384338
test loss item: 0.43161189556121826
test loss item: 0.3823036849498749
test loss item: 0.7390286922454834
test loss item: 1.4935222864151
test loss item: 0.45899683237075806
test loss item: 0.27737128734588623
test loss item: 0.3015204966068268
test loss item: 0.18388713896274567
test loss item: 0.3438064754009247
test loss item: 0.20424002408981323
test loss item: 0.588175356388092
test loss item: 0.43827927112579346
test loss item: 0.2861247658729553
test loss item: 0.2504000961780548
test loss item: 0.460737019777298
test loss item: 0.6570110321044922
test loss item: 0.2679154574871063
test loss item: 0.12074440717697144
test loss item: 0.22660988569259644
test loss item: 0.13739487528800964
test loss item: 0.288998544216156
test loss item: 0.865369975566864
test loss item: 0.5131677985191345
test loss item: 0.23093363642692566
test loss item: 0.22878634929656982
test loss item: 0.1784825176000595
test loss item: 0.434810072183609
test loss item: 0.238268181681633
test loss item: 0.22783277928829193
test loss item: 0.24763882160186768
test loss item: 0.9239239692687988
test loss item: 0.28129810094833374
test loss item: 0.3237839639186859
test loss item: 0.2515464723110199
test loss item: 0.5116464495658875
test loss item: 0.3635857105255127
test loss item: 0.060671232640743256
test loss item: 0.920703113079071
test loss item: 0.3368481993675232
test loss item: 0.4371017813682556
test loss item: 0.15111953020095825
test loss item: 0.16974297165870667
test loss item: 0.1775621771812439
test loss item: 1.638351559638977
test loss item: 0.4961182475090027
test loss item: 0.18348896503448486
test loss item: 0.0811377540230751
test loss item: 0.984900712966919
test loss item: 0.8434867262840271
test loss item: 1.1054223775863647
test loss item: 0.21938051283359528
test loss item: 0.2115330994129181
test loss item: 0.08808859437704086
test loss item: 0.08900964260101318
test loss item: 0.15990673005580902
Epoch [96/100], Training Loss: 0.3119, Testing Loss: 0.3933
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6912.00 MB
Epoch 97/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3433295488357544
1
train loss item: 0.7792370319366455
2
train loss item: 0.1961434930562973
3
train loss item: 0.4296659529209137
4
train loss item: 0.339131623506546
5
train loss item: 0.2672061622142792
6
train loss item: 0.22240732610225677
7
train loss item: 0.4454723298549652
8
train loss item: 0.1152697503566742
9
train loss item: 0.23904268443584442
10
train loss item: 0.2915041446685791
11
train loss item: 0.19045092165470123
12
train loss item: 0.08129783719778061
13
train loss item: 0.3842829763889313
14
train loss item: 0.1875254213809967
15
train loss item: 0.44777849316596985
16
train loss item: 0.04329732432961464
17
train loss item: 0.25229761004447937
18
train loss item: 0.2870224416255951
19
train loss item: 0.22372806072235107
20
train loss item: 0.17908334732055664
21
train loss item: 0.0773540511727333
22
train loss item: 0.608379065990448
23
train loss item: 0.5893259644508362
24
train loss item: 0.4705038368701935
25
train loss item: 0.13077691197395325
26
train loss item: 0.15666157007217407
27
train loss item: 0.19039081037044525
28
train loss item: 0.04113488271832466
29
train loss item: 0.4560924470424652
30
train loss item: 1.0093014240264893
31
train loss item: 0.4386632740497589
32
train loss item: 0.07407323271036148
33
train loss item: 0.3471415936946869
34
train loss item: 0.0637727603316307
35
train loss item: 1.2211323976516724
36
train loss item: 0.40014949440956116
37
train loss item: 0.24063530564308167
38
train loss item: 0.3685668110847473
39
train loss item: 0.20319855213165283
40
train loss item: 0.12038398534059525
41
train loss item: 0.2227880358695984
42
train loss item: 0.24141816794872284
43
train loss item: 0.15590351819992065
44
train loss item: 0.4251907467842102
45
train loss item: 0.08964116871356964
46
train loss item: 0.08751388639211655
47
train loss item: 0.26922163367271423
48
train loss item: 0.20114275813102722
49
train loss item: 0.11785457283258438
50
train loss item: 0.2619837522506714
51
train loss item: 0.5877586007118225
52
train loss item: 0.046068236231803894
53
train loss item: 0.12562420964241028
54
train loss item: 1.0530391931533813
55
train loss item: 0.18753254413604736
56
train loss item: 0.22374755144119263
57
train loss item: 0.20704776048660278
58
train loss item: 0.12894682586193085
59
train loss item: 0.08505958318710327
60
train loss item: 0.680010199546814
61
train loss item: 1.0191590785980225
62
train loss item: 0.17010340094566345
63
train loss item: 0.2913515567779541
64
train loss item: 0.1421537697315216
65
train loss item: 0.4470492899417877
66
train loss item: 0.307765930891037
67
train loss item: 0.15640690922737122
68
train loss item: 0.2390599250793457
69
train loss item: 0.27164411544799805
70
train loss item: 0.20769846439361572
71
train loss item: 0.09435044974088669
72
train loss item: 0.15149642527103424
73
train loss item: 0.2742871940135956
74
train loss item: 0.060174379497766495
75
train loss item: 0.07657436281442642
76
train loss item: 0.6214579343795776
77
train loss item: 0.672187864780426
78
train loss item: 0.045529067516326904
79
train loss item: 0.21993952989578247
80
train loss item: 0.09679029136896133
81
train loss item: 0.15653294324874878
82
train loss item: 0.1582375317811966
83
train loss item: 0.33226120471954346
84
train loss item: 0.3021751344203949
85
train loss item: 0.4680565297603607
86
train loss item: 2.492251396179199
87
train loss item: 0.13242264091968536
88
train loss item: 0.28233596682548523
epoch train loss: 0.3195478549080618
testing phase
test loss item: 0.17250433564186096
test loss item: 0.07356132566928864
test loss item: 0.4838475286960602
test loss item: 0.2041763812303543
test loss item: 0.21246807277202606
test loss item: 0.13091513514518738
test loss item: 1.6663661003112793
test loss item: 0.5153575539588928
test loss item: 0.17449045181274414
test loss item: 0.33117184042930603
test loss item: 0.7016370296478271
test loss item: 0.13985314965248108
test loss item: 0.16456085443496704
test loss item: 0.30666932463645935
test loss item: 0.138093963265419
test loss item: 0.05359278991818428
test loss item: 0.30296894907951355
test loss item: 0.3888324201107025
test loss item: 0.6067383289337158
test loss item: 0.29119357466697693
test loss item: 0.6463914513587952
test loss item: 0.3682830035686493
test loss item: 0.2713693678379059
test loss item: 0.1753336638212204
test loss item: 0.19618763029575348
test loss item: 0.22255447506904602
test loss item: 0.32386285066604614
test loss item: 0.17489315569400787
test loss item: 0.3004932403564453
test loss item: 0.31129515171051025
test loss item: 0.7053658962249756
test loss item: 0.05100987106561661
test loss item: 0.1445290446281433
test loss item: 0.48875734210014343
test loss item: 0.35821017622947693
test loss item: 0.3561861217021942
test loss item: 0.7387608885765076
test loss item: 1.1685712337493896
test loss item: 0.40424618124961853
test loss item: 0.2788737714290619
test loss item: 0.295859694480896
test loss item: 0.1720781773328781
test loss item: 0.29750770330429077
test loss item: 0.19557249546051025
test loss item: 0.5232509970664978
test loss item: 0.4447747766971588
test loss item: 0.26710498332977295
test loss item: 0.2570396661758423
test loss item: 0.3926488161087036
test loss item: 0.5861341953277588
test loss item: 0.2305542677640915
test loss item: 0.12424543499946594
test loss item: 0.20826062560081482
test loss item: 0.12400917708873749
test loss item: 0.25001177191734314
test loss item: 0.705890953540802
test loss item: 0.48513054847717285
test loss item: 0.22113832831382751
test loss item: 0.22258445620536804
test loss item: 0.16643640398979187
test loss item: 0.3704829812049866
test loss item: 0.24463851749897003
test loss item: 0.22226862609386444
test loss item: 0.24590004980564117
test loss item: 0.7884882688522339
test loss item: 0.2729707360267639
test loss item: 0.3175409138202667
test loss item: 0.2521880865097046
test loss item: 0.4476430416107178
test loss item: 0.36509010195732117
test loss item: 0.06515130400657654
test loss item: 0.9403315782546997
test loss item: 0.3078452944755554
test loss item: 0.42449063062667847
test loss item: 0.15003067255020142
test loss item: 0.16171202063560486
test loss item: 0.17403164505958557
test loss item: 1.2756664752960205
test loss item: 0.4498332142829895
test loss item: 0.19278457760810852
test loss item: 0.08363434672355652
test loss item: 0.8566267490386963
test loss item: 0.7995321154594421
test loss item: 0.8568757772445679
test loss item: 0.21083788573741913
test loss item: 0.208543598651886
test loss item: 0.07782340794801712
test loss item: 0.06132499501109123
test loss item: 0.1609712690114975
Epoch [97/100], Training Loss: 0.3195, Testing Loss: 0.3584
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 7012.00 MB
Epoch 98/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.37464240193367004
1
train loss item: 0.8840802907943726
2
train loss item: 0.18060988187789917
3
train loss item: 0.48466166853904724
4
train loss item: 0.40971091389656067
5
train loss item: 0.28201645612716675
6
train loss item: 0.21936790645122528
7
train loss item: 0.49397096037864685
8
train loss item: 0.11494075506925583
9
train loss item: 0.23977303504943848
10
train loss item: 0.30887502431869507
11
train loss item: 0.2273346334695816
12
train loss item: 0.08583511412143707
13
train loss item: 0.3696815073490143
14
train loss item: 0.1856720745563507
15
train loss item: 0.4338717460632324
16
train loss item: 0.04490770399570465
17
train loss item: 0.25234365463256836
18
train loss item: 0.32048436999320984
19
train loss item: 0.21620000898838043
20
train loss item: 0.1908385306596756
21
train loss item: 0.07834732532501221
22
train loss item: 0.6641192436218262
23
train loss item: 0.6034358143806458
24
train loss item: 0.46326324343681335
25
train loss item: 0.14308638870716095
26
train loss item: 0.16998180747032166
27
train loss item: 0.182268887758255
28
train loss item: 0.04162590205669403
29
train loss item: 0.4518125653266907
30
train loss item: 0.9503029584884644
31
train loss item: 0.5261772871017456
32
train loss item: 0.07906043529510498
33
train loss item: 0.3168800473213196
34
train loss item: 0.07701609283685684
35
train loss item: 1.1774942874908447
36
train loss item: 0.41157543659210205
37
train loss item: 0.29077720642089844
38
train loss item: 0.40177619457244873
39
train loss item: 0.1670234501361847
40
train loss item: 0.12227153033018112
41
train loss item: 0.24852193892002106
42
train loss item: 0.23078672587871552
43
train loss item: 0.15251082181930542
44
train loss item: 0.42035940289497375
45
train loss item: 0.083292655646801
46
train loss item: 0.10133577138185501
47
train loss item: 0.2618469297885895
48
train loss item: 0.1765536367893219
49
train loss item: 0.12437033653259277
50
train loss item: 0.26045122742652893
51
train loss item: 0.5927309989929199
52
train loss item: 0.04511454328894615
53
train loss item: 0.12024007737636566
54
train loss item: 1.0215691328048706
55
train loss item: 0.1726498305797577
56
train loss item: 0.21619044244289398
57
train loss item: 0.19272857904434204
58
train loss item: 0.1387558877468109
59
train loss item: 0.09121231734752655
60
train loss item: 0.5416450500488281
61
train loss item: 0.8995343446731567
62
train loss item: 0.1686122566461563
63
train loss item: 0.2907450199127197
64
train loss item: 0.13210052251815796
65
train loss item: 0.5293007493019104
66
train loss item: 0.39965903759002686
67
train loss item: 0.15738728642463684
68
train loss item: 0.21448077261447906
69
train loss item: 0.2937333881855011
70
train loss item: 0.1969936639070511
71
train loss item: 0.08232712745666504
72
train loss item: 0.14092698693275452
73
train loss item: 0.2592322528362274
74
train loss item: 0.04266014322638512
75
train loss item: 0.07150527089834213
76
train loss item: 0.5887578129768372
77
train loss item: 0.662330150604248
78
train loss item: 0.05178143456578255
79
train loss item: 0.2094259262084961
80
train loss item: 0.09131990373134613
81
train loss item: 0.14446501433849335
82
train loss item: 0.1482572853565216
83
train loss item: 0.42884790897369385
84
train loss item: 0.28815579414367676
85
train loss item: 0.44864651560783386
86
train loss item: 2.4388556480407715
87
train loss item: 0.1280745267868042
88
train loss item: 0.3191853165626526
epoch train loss: 0.322003181019191
testing phase
test loss item: 0.2116464525461197
test loss item: 0.13346612453460693
test loss item: 0.6260563135147095
test loss item: 0.22704608738422394
test loss item: 0.24951693415641785
test loss item: 0.17244434356689453
test loss item: 1.738949179649353
test loss item: 0.5104037523269653
test loss item: 0.25369730591773987
test loss item: 0.39864230155944824
test loss item: 0.8860263228416443
test loss item: 0.15257638692855835
test loss item: 0.15941955149173737
test loss item: 0.31708911061286926
test loss item: 0.17759773135185242
test loss item: 0.12842819094657898
test loss item: 0.30255165696144104
test loss item: 0.4631222188472748
test loss item: 0.6120233535766602
test loss item: 0.2862367033958435
test loss item: 0.7362338304519653
test loss item: 0.3698928654193878
test loss item: 0.2911166548728943
test loss item: 0.21286405622959137
test loss item: 0.22115907073020935
test loss item: 0.21871936321258545
test loss item: 0.36613497138023376
test loss item: 0.19488166272640228
test loss item: 0.32583123445510864
test loss item: 0.3461317718029022
test loss item: 0.8366168737411499
test loss item: 0.1352776736021042
test loss item: 0.18740232288837433
test loss item: 0.5692242383956909
test loss item: 0.4479708969593048
test loss item: 0.4235309362411499
test loss item: 0.7624946236610413
test loss item: 1.5127695798873901
test loss item: 0.4664859175682068
test loss item: 0.3029502034187317
test loss item: 0.30894482135772705
test loss item: 0.17212730646133423
test loss item: 0.36493387818336487
test loss item: 0.20968681573867798
test loss item: 0.5853651762008667
test loss item: 0.4318298101425171
test loss item: 0.274974524974823
test loss item: 0.2508067190647125
test loss item: 0.4732721447944641
test loss item: 0.699149489402771
test loss item: 0.2843554615974426
test loss item: 0.1280476599931717
test loss item: 0.2354210466146469
test loss item: 0.14395903050899506
test loss item: 0.2984207570552826
test loss item: 0.9002558588981628
test loss item: 0.5359712839126587
test loss item: 0.23040761053562164
test loss item: 0.2334176003932953
test loss item: 0.18286606669425964
test loss item: 0.46481481194496155
test loss item: 0.2439916431903839
test loss item: 0.22326704859733582
test loss item: 0.24531471729278564
test loss item: 0.9241043925285339
test loss item: 0.2824438512325287
test loss item: 0.32014068961143494
test loss item: 0.2548963725566864
test loss item: 0.5075317025184631
test loss item: 0.4154825210571289
test loss item: 0.11080297827720642
test loss item: 0.9479809999465942
test loss item: 0.32559698820114136
test loss item: 0.43413376808166504
test loss item: 0.16342049837112427
test loss item: 0.1710837185382843
test loss item: 0.2074950635433197
test loss item: 1.600809931755066
test loss item: 0.48573699593544006
test loss item: 0.2147509604692459
test loss item: 0.13301484286785126
test loss item: 1.0039335489273071
test loss item: 0.8856279253959656
test loss item: 1.1070570945739746
test loss item: 0.2192150056362152
test loss item: 0.21571478247642517
test loss item: 0.15215322375297546
test loss item: 0.15586188435554504
test loss item: 0.1742996722459793
Epoch [98/100], Training Loss: 0.3220, Testing Loss: 0.4098
no improvement in test loss for 1 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6992.00 MB
Epoch 99/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.3581794202327728
1
train loss item: 0.8498362898826599
2
train loss item: 0.20830978453159332
3
train loss item: 0.5251716375350952
4
train loss item: 0.38297998905181885
5
train loss item: 0.27315962314605713
6
train loss item: 0.2203391194343567
7
train loss item: 0.5038490295410156
8
train loss item: 0.12369020283222198
9
train loss item: 0.26913976669311523
10
train loss item: 0.33358830213546753
11
train loss item: 0.19962067902088165
12
train loss item: 0.08543238788843155
13
train loss item: 0.42030757665634155
14
train loss item: 0.2066044807434082
15
train loss item: 0.5065218806266785
16
train loss item: 0.0459805466234684
17
train loss item: 0.25338849425315857
18
train loss item: 0.32012298703193665
19
train loss item: 0.22301092743873596
20
train loss item: 0.18324962258338928
21
train loss item: 0.0836135670542717
22
train loss item: 0.7037996053695679
23
train loss item: 0.6479575037956238
24
train loss item: 0.4876244068145752
25
train loss item: 0.15571551024913788
26
train loss item: 0.15453365445137024
27
train loss item: 0.221963033080101
28
train loss item: 0.040491510182619095
29
train loss item: 0.5558671355247498
30
train loss item: 1.0879058837890625
31
train loss item: 0.4684516489505768
32
train loss item: 0.07477250695228577
33
train loss item: 0.4109313488006592
34
train loss item: 0.06733497232198715
35
train loss item: 1.1977523565292358
36
train loss item: 0.4360485076904297
37
train loss item: 0.24165278673171997
38
train loss item: 0.43621569871902466
39
train loss item: 0.23372812569141388
40
train loss item: 0.123716339468956
41
train loss item: 0.26268839836120605
42
train loss item: 0.24707059562206268
43
train loss item: 0.17522573471069336
44
train loss item: 0.5125062465667725
45
train loss item: 0.09981046617031097
46
train loss item: 0.08290638029575348
47
train loss item: 0.2780076861381531
48
train loss item: 0.21645650267601013
49
train loss item: 0.133564293384552
50
train loss item: 0.2564869821071625
51
train loss item: 0.6383860111236572
52
train loss item: 0.049213260412216187
53
train loss item: 0.14748603105545044
54
train loss item: 1.02070951461792
55
train loss item: 0.19282369315624237
56
train loss item: 0.25458577275276184
57
train loss item: 0.2162814736366272
58
train loss item: 0.14181222021579742
59
train loss item: 0.08359260857105255
60
train loss item: 0.7740607857704163
61
train loss item: 1.135916829109192
62
train loss item: 0.181339293718338
63
train loss item: 0.29349225759506226
64
train loss item: 0.16699504852294922
65
train loss item: 0.4463391900062561
66
train loss item: 0.34116441011428833
67
train loss item: 0.17048831284046173
68
train loss item: 0.25528305768966675
69
train loss item: 0.28074613213539124
70
train loss item: 0.2108069807291031
71
train loss item: 0.08347015082836151
72
train loss item: 0.17482706904411316
73
train loss item: 0.2887009382247925
74
train loss item: 0.04050694778561592
75
train loss item: 0.07828497886657715
76
train loss item: 0.6720854640007019
77
train loss item: 0.7151983380317688
78
train loss item: 0.05116541311144829
79
train loss item: 0.2218828648328781
80
train loss item: 0.09517595171928406
81
train loss item: 0.16097451746463776
82
train loss item: 0.17716701328754425
83
train loss item: 0.37261882424354553
84
train loss item: 0.326204776763916
85
train loss item: 0.526696503162384
86
train loss item: 2.4833381175994873
87
train loss item: 0.15932075679302216
88
train loss item: 0.2867700755596161
epoch train loss: 0.3427325137210696
testing phase
test loss item: 0.1683407574892044
test loss item: 0.07135222852230072
test loss item: 0.6181095242500305
test loss item: 0.2021123170852661
test loss item: 0.22589100897312164
test loss item: 0.09674633294343948
test loss item: 1.7421451807022095
test loss item: 0.5283259153366089
test loss item: 0.23103059828281403
test loss item: 0.39855924248695374
test loss item: 0.8656140565872192
test loss item: 0.1405228078365326
test loss item: 0.1696052998304367
test loss item: 0.32372406125068665
test loss item: 0.15215016901493073
test loss item: 0.05570138245820999
test loss item: 0.30101966857910156
test loss item: 0.46461614966392517
test loss item: 0.6235513687133789
test loss item: 0.29448363184928894
test loss item: 0.7461151480674744
test loss item: 0.3712344467639923
test loss item: 0.2961970567703247
test loss item: 0.17261521518230438
test loss item: 0.21103855967521667
test loss item: 0.22036218643188477
test loss item: 0.3480627238750458
test loss item: 0.1665469855070114
test loss item: 0.32172322273254395
test loss item: 0.34615933895111084
test loss item: 0.8186822533607483
test loss item: 0.05947048217058182
test loss item: 0.14015020430088043
test loss item: 0.5662127137184143
test loss item: 0.44074931740760803
test loss item: 0.4099065363407135
test loss item: 0.7769385576248169
test loss item: 1.4839434623718262
test loss item: 0.46982818841934204
test loss item: 0.27220478653907776
test loss item: 0.29815059900283813
test loss item: 0.1722021847963333
test loss item: 0.35883158445358276
test loss item: 0.1984112709760666
test loss item: 0.5964990258216858
test loss item: 0.4418375492095947
test loss item: 0.2830972969532013
test loss item: 0.2562519609928131
test loss item: 0.47885483503341675
test loss item: 0.689537763595581
test loss item: 0.28903278708457947
test loss item: 0.119892917573452
test loss item: 0.23084980249404907
test loss item: 0.12690994143486023
test loss item: 0.29887303709983826
test loss item: 0.8833082318305969
test loss item: 0.5317298173904419
test loss item: 0.24154029786586761
test loss item: 0.2311234474182129
test loss item: 0.18774721026420593
test loss item: 0.45632848143577576
test loss item: 0.2424318492412567
test loss item: 0.21976524591445923
test loss item: 0.24775394797325134
test loss item: 0.9143345952033997
test loss item: 0.27193957567214966
test loss item: 0.3292408883571625
test loss item: 0.25062209367752075
test loss item: 0.5120769143104553
test loss item: 0.4059624671936035
test loss item: 0.048279885202646255
test loss item: 0.9672524333000183
test loss item: 0.3330979347229004
test loss item: 0.42828771471977234
test loss item: 0.14621439576148987
test loss item: 0.1587102711200714
test loss item: 0.17147196829319
test loss item: 1.5740824937820435
test loss item: 0.49031680822372437
test loss item: 0.1761993169784546
test loss item: 0.06828821450471878
test loss item: 0.9915278553962708
test loss item: 0.8800332546234131
test loss item: 1.0838160514831543
test loss item: 0.2231910079717636
test loss item: 0.21202635765075684
test loss item: 0.06720530241727829
test loss item: 0.061818577349185944
test loss item: 0.15378831326961517
Epoch [99/100], Training Loss: 0.3427, Testing Loss: 0.3968
no improvement in test loss for 2 epochs
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Before cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6872.00 MB
Epoch 100/100
torch.Size([2, 21, 1, 360, 360])
0
train loss item: 0.33673861622810364
1
train loss item: 0.73225998878479
2
train loss item: 0.17912258207798004
3
train loss item: 0.38051676750183105
4
train loss item: 0.3224136233329773
5
train loss item: 0.2616681158542633
6
train loss item: 0.21031825244426727
7
train loss item: 0.4052913784980774
8
train loss item: 0.10722576826810837
9
train loss item: 0.21143729984760284
10
train loss item: 0.26358097791671753
11
train loss item: 0.203130841255188
12
train loss item: 0.0796368196606636
13
train loss item: 0.3625323176383972
14
train loss item: 0.18044604361057281
15
train loss item: 0.3907685875892639
16
train loss item: 0.0379277765750885
17
train loss item: 0.24536055326461792
18
train loss item: 0.26915431022644043
19
train loss item: 0.19912634789943695
20
train loss item: 0.16838887333869934
21
train loss item: 0.07514581829309464
22
train loss item: 0.5708519816398621
23
train loss item: 0.5466126799583435
24
train loss item: 0.4267415702342987
25
train loss item: 0.11297410726547241
26
train loss item: 0.16143138706684113
27
train loss item: 0.16662204265594482
28
train loss item: 0.03353632241487503
29
train loss item: 0.39732497930526733
30
train loss item: 0.9377562403678894
31
train loss item: 0.42303797602653503
32
train loss item: 0.06431882828474045
33
train loss item: 0.3127707839012146
34
train loss item: 0.07905954122543335
35
train loss item: 1.1448956727981567
36
train loss item: 0.36280637979507446
37
train loss item: 0.2687002122402191
38
train loss item: 0.3146814703941345
39
train loss item: 0.17172467708587646
40
train loss item: 0.10712934285402298
41
train loss item: 0.20658358931541443
42
train loss item: 0.22834083437919617
43
train loss item: 0.14294905960559845
44
train loss item: 0.3957494795322418
45
train loss item: 0.08582009375095367
46
train loss item: 0.07991689443588257
47
train loss item: 0.2366345226764679
48
train loss item: 0.17890408635139465
49
train loss item: 0.11966834962368011
50
train loss item: 0.24382953345775604
51
train loss item: 0.5381922721862793
52
train loss item: 0.04267508164048195
53
train loss item: 0.10877680778503418
54
train loss item: 0.9714444875717163
55
train loss item: 0.16506047546863556
56
train loss item: 0.20223936438560486
57
train loss item: 0.18512965738773346
58
train loss item: 0.12122897058725357
59
train loss item: 0.0760994628071785
60
train loss item: 0.5919617414474487
61
train loss item: 0.9353930354118347
62
train loss item: 0.15754826366901398
63
train loss item: 0.26261240243911743
64
train loss item: 0.1254768967628479
65
train loss item: 0.4541953504085541
66
train loss item: 0.305484801530838
67
train loss item: 0.13606639206409454
68
train loss item: 0.1971176415681839
69
train loss item: 0.25279322266578674
70
train loss item: 0.18043720722198486
71
train loss item: 0.08129610121250153
72
train loss item: 0.1303679347038269
73
train loss item: 0.2510724663734436
74
train loss item: 0.04155285283923149
75
train loss item: 0.0687473937869072
76
train loss item: 0.5777134299278259
77
train loss item: 0.614962100982666
78
train loss item: 0.0442480742931366
79
train loss item: 0.18786928057670593
80
train loss item: 0.07953570783138275
81
train loss item: 0.13375307619571686
82
train loss item: 0.14793111383914948
83
train loss item: 0.32789847254753113
84
train loss item: 0.266710102558136
85
train loss item: 0.41458794474601746
86
train loss item: 2.3706607818603516
87
train loss item: 0.11181696504354477
88
train loss item: 0.2719612419605255
epoch train loss: 0.2952380098318786
testing phase
test loss item: 0.178779736161232
test loss item: 0.14693428575992584
test loss item: 0.39111071825027466
test loss item: 0.20388220250606537
test loss item: 0.25747430324554443
test loss item: 0.23339536786079407
test loss item: 1.5641216039657593
test loss item: 0.5641278624534607
test loss item: 0.17006030678749084
test loss item: 0.30603399872779846
test loss item: 0.6136148571968079
test loss item: 0.1315547525882721
test loss item: 0.17384573817253113
test loss item: 0.296083003282547
test loss item: 0.15585874021053314
test loss item: 0.12892557680606842
test loss item: 0.2935800552368164
test loss item: 0.3405976891517639
test loss item: 0.6358019113540649
test loss item: 0.30265435576438904
test loss item: 0.5480685830116272
test loss item: 0.3562949299812317
test loss item: 0.24723006784915924
test loss item: 0.18704628944396973
test loss item: 0.17954520881175995
test loss item: 0.23491697013378143
test loss item: 0.3263043761253357
test loss item: 0.23663531243801117
test loss item: 0.28954291343688965
test loss item: 0.30303066968917847
test loss item: 0.6329611539840698
test loss item: 0.15479415655136108
test loss item: 0.16460758447647095
test loss item: 0.42471107840538025
test loss item: 0.3094206750392914
test loss item: 0.3942522704601288
test loss item: 0.727799117565155
test loss item: 0.9370326399803162
test loss item: 0.3528866767883301
test loss item: 0.3045189380645752
test loss item: 0.2844170928001404
test loss item: 0.18021437525749207
test loss item: 0.2688131630420685
test loss item: 0.1792192906141281
test loss item: 0.45366331934928894
test loss item: 0.451357901096344
test loss item: 0.24463976919651031
test loss item: 0.2980068027973175
test loss item: 0.35009506344795227
test loss item: 0.5782672166824341
test loss item: 0.20925068855285645
test loss item: 0.14743606746196747
test loss item: 0.19128981232643127
test loss item: 0.11448758095502853
test loss item: 0.2221316695213318
test loss item: 0.6139001846313477
test loss item: 0.49229946732521057
test loss item: 0.21144363284111023
test loss item: 0.222238227725029
test loss item: 0.15815338492393494
test loss item: 0.33084559440612793
test loss item: 0.26328086853027344
test loss item: 0.2267354279756546
test loss item: 0.23543865978717804
test loss item: 0.6999325156211853
test loss item: 0.25606074929237366
test loss item: 0.3198491930961609
test loss item: 0.24787133932113647
test loss item: 0.3913055956363678
test loss item: 0.44296789169311523
test loss item: 0.1240440383553505
test loss item: 0.9194870591163635
test loss item: 0.2841153144836426
test loss item: 0.4052690267562866
test loss item: 0.16769637167453766
test loss item: 0.16518479585647583
test loss item: 0.18493518233299255
test loss item: 0.9362543821334839
test loss item: 0.4085279703140259
test loss item: 0.2571454644203186
test loss item: 0.1132732629776001
test loss item: 0.7624897360801697
test loss item: 0.7747507691383362
test loss item: 0.6597046256065369
test loss item: 0.20840242505073547
test loss item: 0.21631735563278198
test loss item: 0.12237545847892761
test loss item: 0.10642874985933304
test loss item: 0.21825961768627167
Epoch [100/100], Training Loss: 0.2952, Testing Loss: 0.3452
Best model saved!
After cleanup - Allocated memory: 6377.47 MB, Reserved memory: 6910.00 MB
loss item: 0.34495842456817627
loss item: 0.20346973836421967
loss item: 1.0436428785324097
loss item: 0.7751339673995972
loss item: 0.5133845806121826
loss item: 0.3717556595802307
loss item: 0.19415277242660522
loss item: 0.6949602365493774
loss item: 0.22657886147499084
loss item: 0.16516247391700745
loss item: 0.9054288268089294
loss item: 0.06934972107410431
loss item: 0.8297853469848633
loss item: 0.22803719341754913
loss item: 0.2972104251384735
loss item: 0.2224690169095993
loss item: 0.308676540851593
loss item: 0.5728917121887207
loss item: 0.7177956700325012
loss item: 0.4962638020515442
loss item: 0.2926047742366791
loss item: 0.3069321811199188
loss item: 0.2966139614582062
loss item: 0.26207900047302246
loss item: 0.2612519860267639
loss item: 0.6203857064247131
loss item: 0.7975769639015198
loss item: 0.21899650990962982
loss item: 0.14583325386047363
loss item: 0.4478611350059509
loss item: 0.9240744113922119
loss item: 0.9923661947250366
loss item: 0.13725921511650085
loss item: 0.5378397107124329
loss item: 0.1736198514699936
loss item: 0.17091991007328033
loss item: 0.3123922049999237
loss item: 0.2410195767879486
loss item: 0.39602795243263245
loss item: 0.6009646058082581
loss item: 0.7341359853744507
loss item: 0.28879401087760925
loss item: 0.26988905668258667
loss item: 0.1141018494963646
Val Loss: 0.4256
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.005, epochs: 100, batch size: 2
Hyperparameter tuning prediction finished
UNet6 with 1 100 0.005 2 360 done at Wed Nov 13 23:11:52 CET 2024
UNet6 with 1 100 0.0001 4 360 start at Wed Nov 13 23:11:52 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 0.28402212262153625
UNet6 with 1 100 0.0001 4 360 done at Wed Nov 13 23:12:26 CET 2024
UNet6 with 1 100 0.0005 4 360 start at Wed Nov 13 23:12:26 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 806.2598876953125
UNet6 with 1 100 0.0005 4 360 done at Wed Nov 13 23:13:01 CET 2024
UNet6 with 1 100 0.001 4 360 start at Wed Nov 13 23:13:01 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 100, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: 7438055.5
UNet6 with 1 100 0.001 4 360 done at Wed Nov 13 23:13:39 CET 2024
UNet6 with 1 100 0.005 4 360 start at Wed Nov 13 23:13:39 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 100, batch size: 4
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([4, 21, 1, 360, 360])
0
train loss item: 1.5643571615219116
1
train loss item: 1.1276613473892212
2
train loss item: 0.7444691061973572
3
train loss item: 1.4218745231628418
4
train loss item: 0.671506941318512
5
train loss item: 0.6972736716270447
6
train loss item: 0.8518811464309692
7
train loss item: 0.9649108648300171
8
train loss item: 0.6072947382926941
9
train loss item: 0.7275806665420532
10
train loss item: 0.514886736869812
11
train loss item: 1.669130802154541
12
train loss item: 0.864190936088562
13
train loss item: 0.697853147983551
14
train loss item: 1.2751202583312988
15
train loss item: 2.6530838012695312
16
train loss item: 0.869491696357727
17
train loss item: 3.1080715656280518
18
train loss item: 0.814665675163269
19
train loss item: 0.8781324028968811
20
train loss item: 0.6289806962013245
21
train loss item: 0.5706167221069336
22
train loss item: 1.1159192323684692
23
train loss item: 0.7103851437568665
24
train loss item: 0.5787801742553711
25
train loss item: 1.2970099449157715
26
train loss item: 0.6178616285324097
27
train loss item: 2.576993227005005
28
train loss item: 0.6086803078651428
29
train loss item: 0.6086845397949219
30
train loss item: 2.5186166763305664
31
train loss item: 0.7313673496246338
32
train loss item: 0.8446688652038574
33
train loss item: 0.7343151569366455
34
train loss item: 0.7822253704071045
35
train loss item: 0.6401907205581665
36
train loss item: 0.6844295859336853
37
train loss item: 0.6081058979034424
38
train loss item: 1.7991118431091309
39
train loss item: 0.6202214956283569
40
train loss item: 0.6101059913635254
41
train loss item: 1.052929162979126
42
train loss item: 1.0394039154052734
43
train loss item: 4.189682960510254
44
train loss item: 0.7556139826774597
epoch train loss: 1.1032963951428731
testing phase
test loss item: inf
UNet6 with 1 100 0.005 4 360 done at Wed Nov 13 23:14:14 CET 2024
UNet6 with 1 100 0.0001 8 360 start at Wed Nov 13 23:14:14 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0001 8 360 done at Wed Nov 13 23:14:49 CET 2024
UNet6 with 1 100 0.0005 8 360 start at Wed Nov 13 23:14:49 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0005 8 360 done at Wed Nov 13 23:15:25 CET 2024
UNet6 with 1 100 0.001 8 360 start at Wed Nov 13 23:15:25 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 100, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.001 8 360 done at Wed Nov 13 23:16:01 CET 2024
UNet6 with 1 100 0.005 8 360 start at Wed Nov 13 23:16:01 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 100, batch size: 8
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([8, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
1
train loss item: 1.146369457244873
2
train loss item: 0.6785739064216614
3
train loss item: 0.9042412638664246
4
train loss item: 0.6985678672790527
5
train loss item: 1.2837165594100952
6
train loss item: 0.8019916415214539
7
train loss item: 2.0441067218780518
8
train loss item: 2.4082353115081787
9
train loss item: 0.8419747352600098
10
train loss item: 0.606018602848053
11
train loss item: 0.9218522310256958
12
train loss item: 1.0270822048187256
13
train loss item: 2.1148016452789307
14
train loss item: 0.6061452031135559
15
train loss item: 1.842003345489502
16
train loss item: 0.7694115042686462
17
train loss item: 0.7200125455856323
18
train loss item: 0.6486302018165588
19
train loss item: 1.4041534662246704
20
train loss item: 0.9115896821022034
21
train loss item: 2.5843725204467773
22
train loss item: 0.7556139826774597
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.005 8 360 done at Wed Nov 13 23:16:37 CET 2024
UNet6 with 1 100 0.0001 16 360 start at Wed Nov 13 23:16:37 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0001 16 360 done at Wed Nov 13 23:17:13 CET 2024
UNet6 with 1 100 0.0005 16 360 start at Wed Nov 13 23:17:13 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0005 16 360 done at Wed Nov 13 23:17:52 CET 2024
UNet6 with 1 100 0.001 16 360 start at Wed Nov 13 23:17:52 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 100, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.001 16 360 done at Wed Nov 13 23:18:28 CET 2024
UNet6 with 1 100 0.005 16 360 start at Wed Nov 13 23:18:28 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 100, batch size: 16
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([16, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
1
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
2
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
3
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
4
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
5
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
6
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
7
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
8
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
9
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
10
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
11
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.005 16 360 done at Wed Nov 13 23:19:04 CET 2024
UNet6 with 1 100 0.0001 32 360 start at Wed Nov 13 23:19:04 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0001 32 360 done at Wed Nov 13 23:19:40 CET 2024
UNet6 with 1 100 0.0005 32 360 start at Wed Nov 13 23:19:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0005 32 360 done at Wed Nov 13 23:20:16 CET 2024
UNet6 with 1 100 0.001 32 360 start at Wed Nov 13 23:20:16 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 100, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.001 32 360 done at Wed Nov 13 23:20:55 CET 2024
UNet6 with 1 100 0.005 32 360 start at Wed Nov 13 23:20:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 100, batch size: 32
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([32, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
1
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
2
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
3
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
4
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
5
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.005 32 360 done at Wed Nov 13 23:21:31 CET 2024
UNet6 with 1 100 0.0001 64 360 start at Wed Nov 13 23:21:31 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0001 64 360 done at Wed Nov 13 23:22:10 CET 2024
UNet6 with 1 100 0.0005 64 360 start at Wed Nov 13 23:22:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0005 64 360 done at Wed Nov 13 23:22:46 CET 2024
UNet6 with 1 100 0.001 64 360 start at Wed Nov 13 23:22:46 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 100, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.001 64 360 done at Wed Nov 13 23:23:25 CET 2024
UNet6 with 1 100 0.005 64 360 start at Wed Nov 13 23:23:25 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 100, batch size: 64
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([64, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
1
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
2
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.005 64 360 done at Wed Nov 13 23:24:02 CET 2024
UNet6 with 1 100 0.0001 128 360 start at Wed Nov 13 23:24:02 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0001 128 360 done at Wed Nov 13 23:24:40 CET 2024
UNet6 with 1 100 0.0005 128 360 start at Wed Nov 13 23:24:40 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0005 128 360 done at Wed Nov 13 23:25:16 CET 2024
UNet6 with 1 100 0.001 128 360 start at Wed Nov 13 23:25:17 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 100, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.001 128 360 done at Wed Nov 13 23:25:55 CET 2024
UNet6 with 1 100 0.005 128 360 start at Wed Nov 13 23:25:55 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 100, batch size: 128
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([128, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
1
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.005 128 360 done at Wed Nov 13 23:26:31 CET 2024
UNet6 with 1 100 0.0001 256 360 start at Wed Nov 13 23:26:31 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 100, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0001 256 360 done at Wed Nov 13 23:27:10 CET 2024
UNet6 with 1 100 0.0005 256 360 start at Wed Nov 13 23:27:10 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0005, epochs: 100, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.0005 256 360 done at Wed Nov 13 23:27:46 CET 2024
UNet6 with 1 100 0.001 256 360 start at Wed Nov 13 23:27:46 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.001, epochs: 100, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.001 256 360 done at Wed Nov 13 23:28:25 CET 2024
UNet6 with 1 100 0.005 256 360 start at Wed Nov 13 23:28:25 CET 2024
CUDA is available! Using GPU.
device: cuda
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.005, epochs: 100, batch size: 256
Before cleanup - Allocated memory: 1898.89 MB, Reserved memory: 1904.00 MB
Epoch 1/100
torch.Size([177, 21, 1, 360, 360])
0
train loss item: 1.4056077003479004
train loss item: 1.146369457244873
train loss item: 0.6785739064216614
train loss item: 0.9042412638664246
train loss item: 0.6985678672790527
train loss item: 1.2837165594100952
train loss item: 0.8019916415214539
train loss item: 2.0441067218780518
train loss item: 2.4082353115081787
train loss item: 0.8419747352600098
train loss item: 0.606018602848053
train loss item: 0.9218522310256958
train loss item: 1.0270822048187256
train loss item: 2.1148016452789307
train loss item: 0.6061452031135559
train loss item: 1.842003345489502
train loss item: 0.7694115042686462
train loss item: 0.7200125455856323
train loss item: 0.6486302018165588
train loss item: 1.4041534662246704
train loss item: 0.9115896821022034
train loss item: 2.5843725204467773
train loss item: 0.7556139826774597
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
train loss item: nan
NaN encountered in loss calculation. Skipping this instance.
epoch train loss: 1.1793509695840918
testing phase
UNet6 with 1 100 0.005 256 360 done at Wed Nov 13 23:29:01 CET 2024
SBATCH job finished
