SBATCH job
Started 11/11/2024 09:32:25
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
UNet6 with 1 50 0.0001 64 180 start at Mon Nov 11 09:32:27 CET 2024
Hyperparameter tuning not done yet - start process
data testing folder already prepared - reloading data
Hyperparameter tuning definition and start
training model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 64
Epoch 1/50
loss item: 1.493493914604187
loss item: 0.9461373686790466
loss item: 0.986240565776825
loss item: 1.31035578250885
loss item: 0.6544337868690491
loss item: 0.9961029291152954
loss item: 0.7776771783828735
loss item: 0.6446080803871155
loss item: 0.7268234491348267
loss item: 0.5217307806015015
loss item: 0.6375181078910828
loss item: 0.8290021419525146
loss item: 0.7916938066482544
loss item: 1.1431928873062134
loss item: 1.0727051496505737
loss item: 0.9150186777114868
loss item: 1.432896614074707
loss item: 1.5008679628372192
loss item: 1.0409644842147827
loss item: 1.0771973133087158
loss item: 1.7487432956695557
loss item: 1.8803397417068481
loss item: 1.4427684545516968
loss item: 1.3987103700637817
Epoch [1/50], Training Loss: 0.8770, Testing Loss: 1.2871
Best model saved!
Epoch 2/50
loss item: 0.7888110280036926
loss item: 0.5926857590675354
loss item: 0.6172420978546143
loss item: 0.8392543792724609
loss item: 0.4803789556026459
loss item: 0.6569398641586304
loss item: 0.5236454606056213
loss item: 0.47998544573783875
loss item: 0.5387736558914185
loss item: 0.3987998366355896
loss item: 0.5089696049690247
loss item: 0.6993266940116882
loss item: 0.6467732191085815
loss item: 0.8581051230430603
loss item: 0.8302417993545532
loss item: 0.6955764293670654
loss item: 1.0975018739700317
loss item: 1.134680986404419
loss item: 0.8298959732055664
loss item: 0.8492869138717651
loss item: 1.3446688652038574
loss item: 1.4064799547195435
loss item: 1.0959659814834595
loss item: 1.145577311515808
Epoch [2/50], Training Loss: 0.5937, Testing Loss: 0.9946
Best model saved!
Epoch 3/50
loss item: 0.6360952258110046
loss item: 0.4750222861766815
loss item: 0.5114232301712036
loss item: 0.706106424331665
loss item: 0.41612598299980164
loss item: 0.5480550527572632
loss item: 0.44595566391944885
loss item: 0.43564561009407043
loss item: 0.4583844840526581
loss item: 0.3567875623703003
loss item: 0.4461681544780731
loss item: 0.6171813011169434
loss item: 0.4710064232349396
loss item: 0.5618553161621094
loss item: 0.5668763518333435
loss item: 0.46305200457572937
loss item: 0.7434728145599365
loss item: 0.7548109292984009
loss item: 0.5898196697235107
loss item: 0.5934788584709167
loss item: 0.8919803500175476
loss item: 0.9219287037849426
loss item: 0.7310603260993958
loss item: 0.8410121202468872
Epoch [3/50], Training Loss: 0.5044, Testing Loss: 0.6775
Best model saved!
Epoch 4/50
loss item: 0.580786406993866
loss item: 0.4172186851501465
loss item: 0.4410971403121948
loss item: 0.624891996383667
loss item: 0.3796645402908325
loss item: 0.4832128584384918
loss item: 0.40172091126441956
loss item: 0.41976919770240784
loss item: 0.41087254881858826
loss item: 0.33024168014526367
loss item: 0.4021760821342468
loss item: 0.5547571778297424
loss item: 0.39042919874191284
loss item: 0.44938644766807556
loss item: 0.46097397804260254
loss item: 0.3668055832386017
loss item: 0.5913903713226318
loss item: 0.5987638831138611
loss item: 0.48162946105003357
loss item: 0.48375892639160156
loss item: 0.6833251714706421
loss item: 0.699939489364624
loss item: 0.5783483982086182
loss item: 0.6857213377952576
Epoch [4/50], Training Loss: 0.4539, Testing Loss: 0.5392
Best model saved!
Epoch 5/50
loss item: 0.5325846672058105
loss item: 0.37971821427345276
loss item: 0.3975521922111511
loss item: 0.5710766315460205
loss item: 0.3451986610889435
loss item: 0.4413412809371948
loss item: 0.3671542704105377
loss item: 0.38839003443717957
loss item: 0.3732454180717468
loss item: 0.30743682384490967
loss item: 0.3676193952560425
loss item: 0.49876895546913147
loss item: 0.35155388712882996
loss item: 0.3984425365924835
loss item: 0.40696433186531067
loss item: 0.32776573300361633
loss item: 0.5199787616729736
loss item: 0.5229674577713013
loss item: 0.4247147738933563
loss item: 0.4280763566493988
loss item: 0.5956322550773621
loss item: 0.6045054793357849
loss item: 0.5083746314048767
loss item: 0.6109610795974731
Epoch [5/50], Training Loss: 0.4142, Testing Loss: 0.4750
Best model saved!
Epoch 6/50
loss item: 0.4902521073818207
loss item: 0.34632551670074463
loss item: 0.3573535680770874
loss item: 0.5220403075218201
loss item: 0.3142734169960022
loss item: 0.4027736485004425
loss item: 0.33544716238975525
loss item: 0.35510092973709106
loss item: 0.34309569001197815
loss item: 0.27914172410964966
loss item: 0.3410705029964447
loss item: 0.451214462518692
loss item: 0.32201504707336426
loss item: 0.3625349700450897
loss item: 0.36753880977630615
loss item: 0.2981128692626953
loss item: 0.467981219291687
loss item: 0.4718436598777771
loss item: 0.38470926880836487
loss item: 0.3862086832523346
loss item: 0.5352429747581482
loss item: 0.5369300246238708
loss item: 0.4603720009326935
loss item: 0.5498991012573242
Epoch [6/50], Training Loss: 0.3782, Testing Loss: 0.4286
Best model saved!
Epoch 7/50
loss item: 0.449070543050766
loss item: 0.31396692991256714
loss item: 0.33090123534202576
loss item: 0.4722839891910553
loss item: 0.29362332820892334
loss item: 0.36600250005722046
loss item: 0.3088458776473999
loss item: 0.3205821216106415
loss item: 0.3235666751861572
loss item: 0.25930967926979065
loss item: 0.3181697428226471
loss item: 0.4075382947921753
loss item: 0.2961697280406952
loss item: 0.332141637802124
loss item: 0.3331632614135742
loss item: 0.27625375986099243
loss item: 0.4281710982322693
loss item: 0.4308193027973175
loss item: 0.3502179682254791
loss item: 0.35255399346351624
loss item: 0.5040764212608337
loss item: 0.5031359195709229
loss item: 0.42371758818626404
loss item: 0.5025013089179993
Epoch [7/50], Training Loss: 0.3470, Testing Loss: 0.3944
Best model saved!
Epoch 8/50
loss item: 0.41478076577186584
loss item: 0.2840269207954407
loss item: 0.31456464529037476
loss item: 0.43234917521476746
loss item: 0.27230608463287354
loss item: 0.33372369408607483
loss item: 0.2817155420780182
loss item: 0.29170310497283936
loss item: 0.31087321043014526
loss item: 0.2408626228570938
loss item: 0.2990250587463379
loss item: 0.36450913548469543
loss item: 0.2711484134197235
loss item: 0.30664384365081787
loss item: 0.30683568120002747
loss item: 0.2543248236179352
loss item: 0.3910122811794281
loss item: 0.3934725224971771
loss item: 0.3215877115726471
loss item: 0.321451336145401
loss item: 0.45407330989837646
loss item: 0.4509306848049164
loss item: 0.3858361840248108
loss item: 0.4505479335784912
Epoch [8/50], Training Loss: 0.3200, Testing Loss: 0.3590
Best model saved!
Epoch 9/50
loss item: 0.37726935744285583
loss item: 0.2638907730579376
loss item: 0.3008268177509308
loss item: 0.3946189880371094
loss item: 0.25342071056365967
loss item: 0.308749794960022
loss item: 0.26071614027023315
loss item: 0.26397043466567993
loss item: 0.28851446509361267
loss item: 0.22295530140399933
loss item: 0.28371462225914
loss item: 0.3272567689418793
loss item: 0.252772718667984
loss item: 0.2881331145763397
loss item: 0.2869868278503418
loss item: 0.24116212129592896
loss item: 0.3583039939403534
loss item: 0.3539884686470032
loss item: 0.2893622815608978
loss item: 0.297247052192688
loss item: 0.42643192410469055
loss item: 0.4253295361995697
loss item: 0.35486581921577454
loss item: 0.429135799407959
Epoch [9/50], Training Loss: 0.2955, Testing Loss: 0.3336
Best model saved!
Epoch 10/50
loss item: 0.3562176525592804
loss item: 0.24658431112766266
loss item: 0.2833523750305176
loss item: 0.3707978129386902
loss item: 0.23227500915527344
loss item: 0.2853841781616211
loss item: 0.24071942269802094
loss item: 0.24702055752277374
loss item: 0.2750808000564575
loss item: 0.20796456933021545
loss item: 0.2703777253627777
loss item: 0.2917671799659729
loss item: 0.23462514579296112
loss item: 0.2769210934638977
loss item: 0.2757554352283478
loss item: 0.22843888401985168
loss item: 0.33907604217529297
loss item: 0.3381587862968445
loss item: 0.2703213393688202
loss item: 0.28044742345809937
loss item: 0.3986890912055969
loss item: 0.394622266292572
loss item: 0.33471834659576416
loss item: 0.3886306583881378
Epoch [10/50], Training Loss: 0.2756, Testing Loss: 0.3134
Best model saved!
Epoch 11/50
loss item: 0.31882908940315247
loss item: 0.23187831044197083
loss item: 0.2671101987361908
loss item: 0.3410448431968689
loss item: 0.21736153960227966
loss item: 0.26541218161582947
loss item: 0.22211720049381256
loss item: 0.22493943572044373
loss item: 0.25842249393463135
loss item: 0.20065492391586304
loss item: 0.25411859154701233
loss item: 0.26879462599754333
loss item: 0.21350528299808502
loss item: 0.2523426413536072
loss item: 0.25346866250038147
loss item: 0.21286755800247192
loss item: 0.30084696412086487
loss item: 0.2914333641529083
loss item: 0.23543399572372437
loss item: 0.2515537440776825
loss item: 0.34425076842308044
loss item: 0.3456413447856903
loss item: 0.2918795347213745
loss item: 0.3551536500453949
Epoch [11/50], Training Loss: 0.2559, Testing Loss: 0.2790
Best model saved!
Epoch 12/50
loss item: 0.2933911383152008
loss item: 0.21979469060897827
loss item: 0.25318822264671326
loss item: 0.31348103284835815
loss item: 0.20150519907474518
loss item: 0.2512066960334778
loss item: 0.20804888010025024
loss item: 0.21090880036354065
loss item: 0.24527262151241302
loss item: 0.19055548310279846
loss item: 0.24560366570949554
loss item: 0.24284490942955017
loss item: 0.20782019197940826
loss item: 0.24726347625255585
loss item: 0.24857975542545319
loss item: 0.2082342505455017
loss item: 0.2914704978466034
loss item: 0.2847628891468048
loss item: 0.2266102284193039
loss item: 0.24541020393371582
loss item: 0.3392389714717865
loss item: 0.34022629261016846
loss item: 0.2854323983192444
loss item: 0.34183675050735474
Epoch [12/50], Training Loss: 0.2397, Testing Loss: 0.2722
Best model saved!
Epoch 13/50
loss item: 0.2778523564338684
loss item: 0.2112734466791153
loss item: 0.24237637221813202
loss item: 0.29790595173835754
loss item: 0.19132103025913239
loss item: 0.23565107583999634
loss item: 0.19677647948265076
loss item: 0.20259223878383636
loss item: 0.23809212446212769
loss item: 0.1853790134191513
loss item: 0.23070108890533447
loss item: 0.21772778034210205
loss item: 0.19426165521144867
loss item: 0.23696348071098328
loss item: 0.2381211221218109
loss item: 0.1970297396183014
loss item: 0.27369701862335205
loss item: 0.26530200242996216
loss item: 0.2115013301372528
loss item: 0.2294834554195404
loss item: 0.30381864309310913
loss item: 0.30133822560310364
loss item: 0.2637742757797241
loss item: 0.3146771192550659
Epoch [13/50], Training Loss: 0.2273, Testing Loss: 0.2525
Best model saved!
Epoch 14/50
loss item: 0.25376302003860474
loss item: 0.19984950125217438
loss item: 0.2340281754732132
loss item: 0.2794038653373718
loss item: 0.17892257869243622
loss item: 0.22142232954502106
loss item: 0.18698352575302124
loss item: 0.19272276759147644
loss item: 0.23086340725421906
loss item: 0.18168538808822632
loss item: 0.21588805317878723
loss item: 0.19971537590026855
loss item: 0.19052736461162567
loss item: 0.2285364717245102
loss item: 0.22969216108322144
loss item: 0.1900026798248291
loss item: 0.2629367411136627
loss item: 0.25640928745269775
loss item: 0.20776914060115814
loss item: 0.22123827040195465
loss item: 0.2868363857269287
loss item: 0.2876371443271637
loss item: 0.2552209198474884
loss item: 0.301991730928421
Epoch [14/50], Training Loss: 0.2146, Testing Loss: 0.2432
Best model saved!
Epoch 15/50
loss item: 0.23641440272331238
loss item: 0.1921347677707672
loss item: 0.22959110140800476
loss item: 0.2643583118915558
loss item: 0.16738945245742798
loss item: 0.21032294631004333
loss item: 0.1770804077386856
loss item: 0.1848488450050354
loss item: 0.21988587081432343
loss item: 0.1763652116060257
loss item: 0.2050572782754898
loss item: 0.18719303607940674
loss item: 0.17357033491134644
loss item: 0.20812217891216278
loss item: 0.21231812238693237
loss item: 0.17657716572284698
loss item: 0.2365989089012146
loss item: 0.22661274671554565
loss item: 0.18293221294879913
loss item: 0.2021571844816208
loss item: 0.24952895939350128
loss item: 0.2526344358921051
loss item: 0.22586581110954285
loss item: 0.2788008451461792
Epoch [15/50], Training Loss: 0.2042, Testing Loss: 0.2188
Best model saved!
Epoch 16/50
loss item: 0.22170878946781158
loss item: 0.18473127484321594
loss item: 0.21925415098667145
loss item: 0.2523445188999176
loss item: 0.1604059636592865
loss item: 0.19953922927379608
loss item: 0.17023822665214539
loss item: 0.1758354902267456
loss item: 0.210835263133049
loss item: 0.1715000569820404
loss item: 0.19351188838481903
loss item: 0.17860746383666992
loss item: 0.1691989153623581
loss item: 0.20010022819042206
loss item: 0.20408016443252563
loss item: 0.1698315292596817
loss item: 0.2268010973930359
loss item: 0.22108572721481323
loss item: 0.17838360369205475
loss item: 0.19654227793216705
loss item: 0.24554161727428436
loss item: 0.2458026260137558
loss item: 0.2193751186132431
loss item: 0.27298209071159363
Epoch [16/50], Training Loss: 0.1949, Testing Loss: 0.2125
Best model saved!
Epoch 17/50
loss item: 0.20623871684074402
loss item: 0.17841050028800964
loss item: 0.2123616635799408
loss item: 0.24421915411949158
loss item: 0.15605157613754272
loss item: 0.1921839565038681
loss item: 0.163455531001091
loss item: 0.17057918012142181
loss item: 0.20939478278160095
loss item: 0.17361298203468323
loss item: 0.18798407912254333
loss item: 0.16973930597305298
loss item: 0.16203385591506958
loss item: 0.19489221274852753
loss item: 0.19834256172180176
loss item: 0.16184620559215546
loss item: 0.2170988768339157
loss item: 0.2139686793088913
loss item: 0.17118269205093384
loss item: 0.18896330893039703
loss item: 0.23993344604969025
loss item: 0.2381497174501419
loss item: 0.21438024938106537
loss item: 0.25987204909324646
Epoch [17/50], Training Loss: 0.1887, Testing Loss: 0.2051
Best model saved!
Epoch 18/50
loss item: 0.1936996579170227
loss item: 0.1720411330461502
loss item: 0.2080678790807724
loss item: 0.23666173219680786
loss item: 0.1538955122232437
loss item: 0.1846863180398941
loss item: 0.15868127346038818
loss item: 0.16313397884368896
loss item: 0.20387515425682068
loss item: 0.1726127415895462
loss item: 0.1817948818206787
loss item: 0.1697291135787964
loss item: 0.15020795166492462
loss item: 0.18110863864421844
loss item: 0.18478024005889893
loss item: 0.15325483679771423
loss item: 0.20239479839801788
loss item: 0.19755558669567108
loss item: 0.1584712564945221
loss item: 0.17428816854953766
loss item: 0.21014165878295898
loss item: 0.21430689096450806
loss item: 0.1946212351322174
loss item: 0.23779843747615814
Epoch [18/50], Training Loss: 0.1832, Testing Loss: 0.1882
Best model saved!
Epoch 19/50
loss item: 0.17861713469028473
loss item: 0.166056290268898
loss item: 0.20401059091091156
loss item: 0.2215804010629654
loss item: 0.1557619422674179
loss item: 0.18817643821239471
loss item: 0.1609022617340088
loss item: 0.16523024439811707
loss item: 0.1918420046567917
loss item: 0.16376541554927826
loss item: 0.18288962543010712
loss item: 0.17212137579917908
loss item: 0.15501180291175842
loss item: 0.17993344366550446
loss item: 0.1830352246761322
loss item: 0.1610356569290161
loss item: 0.20958012342453003
loss item: 0.20110151171684265
loss item: 0.1607784777879715
loss item: 0.17550897598266602
loss item: 0.2164154052734375
loss item: 0.22386333346366882
loss item: 0.20088762044906616
loss item: 0.2371683269739151
Epoch [19/50], Training Loss: 0.1792, Testing Loss: 0.1920
no improvement in test loss for 1 epochs
Epoch 20/50
loss item: 0.18510890007019043
loss item: 0.1705961376428604
loss item: 0.19193708896636963
loss item: 0.21693912148475647
loss item: 0.1562720537185669
loss item: 0.18733146786689758
loss item: 0.16449294984340668
loss item: 0.16763344407081604
loss item: 0.18206124007701874
loss item: 0.16220389306545258
loss item: 0.17738492786884308
loss item: 0.1741192489862442
loss item: 0.15550296008586884
loss item: 0.1883266568183899
loss item: 0.1860872060060501
loss item: 0.16801653802394867
loss item: 0.2243632972240448
loss item: 0.22616468369960785
loss item: 0.17195747792720795
loss item: 0.18329815566539764
loss item: 0.24707913398742676
loss item: 0.2643713355064392
loss item: 0.22561676800251007
loss item: 0.23155099153518677
Epoch [20/50], Training Loss: 0.1780, Testing Loss: 0.2060
no improvement in test loss for 2 epochs
Epoch 21/50
loss item: 0.18280772864818573
loss item: 0.17389445006847382
loss item: 0.18295182287693024
loss item: 0.2256159633398056
loss item: 0.1500883549451828
loss item: 0.19101445376873016
loss item: 0.1656131148338318
loss item: 0.1832342892885208
loss item: 0.18539683520793915
loss item: 0.16367456316947937
loss item: 0.1720091700553894
loss item: 0.16780546307563782
loss item: 0.15330414474010468
loss item: 0.19532346725463867
loss item: 0.19382114708423615
loss item: 0.16863766312599182
loss item: 0.22284379601478577
loss item: 0.22072020173072815
loss item: 0.1668408066034317
loss item: 0.1811486929655075
loss item: 0.23089367151260376
loss item: 0.2409815788269043
loss item: 0.21481600403785706
loss item: 0.22962409257888794
Epoch [21/50], Training Loss: 0.1787, Testing Loss: 0.2016
no improvement in test loss for 3 epochs
Epoch 22/50
loss item: 0.18726862967014313
loss item: 0.17714951932430267
loss item: 0.1939592808485031
loss item: 0.21535615622997284
loss item: 0.14126600325107574
loss item: 0.17784413695335388
loss item: 0.15530499815940857
loss item: 0.17712529003620148
loss item: 0.18599660694599152
loss item: 0.15869219601154327
loss item: 0.1586027592420578
loss item: 0.14858627319335938
loss item: 0.14504402875900269
loss item: 0.17907370626926422
loss item: 0.1828482747077942
loss item: 0.15370002388954163
loss item: 0.20093874633312225
loss item: 0.19779688119888306
loss item: 0.15322017669677734
loss item: 0.17263008654117584
loss item: 0.21165554225444794
loss item: 0.21095231175422668
loss item: 0.19246084988117218
loss item: 0.22338974475860596
Epoch [22/50], Training Loss: 0.1731, Testing Loss: 0.1853
Best model saved!
Epoch 23/50
loss item: 0.17545674741268158
loss item: 0.16410107910633087
loss item: 0.18165843188762665
loss item: 0.1992594450712204
loss item: 0.14197812974452972
loss item: 0.17729534208774567
loss item: 0.14681664109230042
loss item: 0.15896451473236084
loss item: 0.18585921823978424
loss item: 0.1752641797065735
loss item: 0.15966184437274933
loss item: 0.15073975920677185
loss item: 0.13759341835975647
loss item: 0.15599504113197327
loss item: 0.16155995428562164
loss item: 0.13875766098499298
loss item: 0.17789028584957123
loss item: 0.1749836802482605
loss item: 0.14268046617507935
loss item: 0.15618900954723358
loss item: 0.19237184524536133
loss item: 0.19224214553833008
loss item: 0.1791619062423706
loss item: 0.20804570615291595
Epoch [23/50], Training Loss: 0.1681, Testing Loss: 0.1681
Best model saved!
Epoch 24/50
loss item: 0.16285105049610138
loss item: 0.14852669835090637
loss item: 0.1896168291568756
loss item: 0.19456064701080322
loss item: 0.15856102108955383
loss item: 0.1897159367799759
loss item: 0.14546731114387512
loss item: 0.14316634833812714
loss item: 0.18911270797252655
loss item: 0.1858392208814621
loss item: 0.15856985747814178
loss item: 0.14859265089035034
loss item: 0.14244122803211212
loss item: 0.16612233221530914
loss item: 0.16241340339183807
loss item: 0.13459986448287964
loss item: 0.18198040127754211
loss item: 0.19063130021095276
loss item: 0.15003736317157745
loss item: 0.1635926216840744
loss item: 0.22760836780071259
loss item: 0.2248808592557907
loss item: 0.1901364028453827
loss item: 0.23365037143230438
Epoch [24/50], Training Loss: 0.1679, Testing Loss: 0.1807
no improvement in test loss for 1 epochs
Epoch 25/50
loss item: 0.15742453932762146
loss item: 0.15950928628444672
loss item: 0.16813135147094727
loss item: 0.20296841859817505
loss item: 0.1554136872291565
loss item: 0.19257941842079163
loss item: 0.16876614093780518
loss item: 0.154588520526886
loss item: 0.17608118057250977
loss item: 0.16563740372657776
loss item: 0.1657690852880478
loss item: 0.15804769098758698
loss item: 0.14070962369441986
loss item: 0.17790895700454712
loss item: 0.17587168514728546
loss item: 0.1483609974384308
loss item: 0.19947849214076996
loss item: 0.20430909097194672
loss item: 0.15084749460220337
loss item: 0.1665469855070114
loss item: 0.24711397290229797
loss item: 0.2516714930534363
loss item: 0.20455950498580933
loss item: 0.22716215252876282
Epoch [25/50], Training Loss: 0.1687, Testing Loss: 0.1912
no improvement in test loss for 2 epochs
Epoch 26/50
loss item: 0.18410885334014893
loss item: 0.18128542602062225
loss item: 0.18643401563167572
loss item: 0.20185039937496185
loss item: 0.16052696108818054
loss item: 0.2223191112279892
loss item: 0.20822295546531677
loss item: 0.16438592970371246
loss item: 0.17282319068908691
loss item: 0.16912147402763367
loss item: 0.16064290702342987
loss item: 0.16258086264133453
loss item: 0.16249386966228485
loss item: 0.2178802788257599
loss item: 0.21272899210453033
loss item: 0.17262043058872223
loss item: 0.24585582315921783
loss item: 0.25879189372062683
loss item: 0.1869717836380005
loss item: 0.19687384366989136
loss item: 0.301945298910141
loss item: 0.3049926459789276
loss item: 0.25499340891838074
loss item: 0.25747132301330566
Epoch [26/50], Training Loss: 0.1812, Testing Loss: 0.2311
no improvement in test loss for 3 epochs
Epoch 27/50
loss item: 0.19960586726665497
loss item: 0.22404584288597107
loss item: 0.16801391541957855
loss item: 0.17789223790168762
loss item: 0.14336003363132477
loss item: 0.22350716590881348
loss item: 0.2111736685037613
loss item: 0.19587896764278412
loss item: 0.14663071930408478
loss item: 0.13050779700279236
loss item: 0.16205212473869324
loss item: 0.15848566591739655
loss item: 0.16868487000465393
loss item: 0.23909416794776917
loss item: 0.23892545700073242
loss item: 0.18506579101085663
loss item: 0.24356403946876526
loss item: 0.25096777081489563
loss item: 0.17403364181518555
loss item: 0.2059403508901596
loss item: 0.23880037665367126
loss item: 0.23870356380939484
loss item: 0.2405790388584137
loss item: 0.27477604150772095
Epoch [27/50], Training Loss: 0.1784, Testing Loss: 0.2249
no improvement in test loss for 4 epochs
Epoch 28/50
loss item: 0.2054741233587265
loss item: 0.25778841972351074
loss item: 0.15340782701969147
loss item: 0.17718605697155
loss item: 0.13998456299304962
loss item: 0.1993643343448639
loss item: 0.19299249351024628
loss item: 0.21124522387981415
loss item: 0.1579212248325348
loss item: 0.13177815079689026
loss item: 0.17128346860408783
loss item: 0.13828633725643158
loss item: 0.14526478946208954
loss item: 0.18887944519519806
loss item: 0.18905101716518402
loss item: 0.16135135293006897
loss item: 0.21025070548057556
loss item: 0.22035855054855347
loss item: 0.15621967613697052
loss item: 0.17678943276405334
loss item: 0.22188615798950195
loss item: 0.22843337059020996
loss item: 0.21562863886356354
loss item: 0.21687759459018707
Epoch [28/50], Training Loss: 0.1781, Testing Loss: 0.1942
no improvement in test loss for 5 epochs
Epoch 29/50
loss item: 0.1708534210920334
loss item: 0.23383693397045135
loss item: 0.15332144498825073
loss item: 0.21573980152606964
loss item: 0.15664523839950562
loss item: 0.15243534743785858
loss item: 0.14431191980838776
loss item: 0.171380877494812
loss item: 0.13614106178283691
loss item: 0.12650303542613983
loss item: 0.18819022178649902
loss item: 0.14143525063991547
loss item: 0.13440842926502228
loss item: 0.15830747783184052
loss item: 0.1578769087791443
loss item: 0.13063475489616394
loss item: 0.18719933927059174
loss item: 0.1963348090648651
loss item: 0.151731938123703
loss item: 0.16068249940872192
loss item: 0.24353840947151184
loss item: 0.23960180580615997
loss item: 0.19694367051124573
loss item: 0.2027609497308731
Epoch [29/50], Training Loss: 0.1659, Testing Loss: 0.1800
no improvement in test loss for 6 epochs
Epoch 30/50
loss item: 0.15572842955589294
loss item: 0.1566087305545807
loss item: 0.14130359888076782
loss item: 0.16503296792507172
loss item: 0.12997567653656006
loss item: 0.1628812700510025
loss item: 0.14093457162380219
loss item: 0.14022718369960785
loss item: 0.13749733567237854
loss item: 0.11858507990837097
loss item: 0.1523776650428772
loss item: 0.12594200670719147
loss item: 0.12419087439775467
loss item: 0.13791519403457642
loss item: 0.14114056527614594
loss item: 0.11898461729288101
loss item: 0.15854094922542572
loss item: 0.15976400673389435
loss item: 0.13239751756191254
loss item: 0.14248026907444
loss item: 0.19034431874752045
loss item: 0.19117744266986847
loss item: 0.16148832440376282
loss item: 0.2009614259004593
Epoch [30/50], Training Loss: 0.1439, Testing Loss: 0.1549
Best model saved!
Epoch 31/50
loss item: 0.14020894467830658
loss item: 0.1437114179134369
loss item: 0.1427527219057083
loss item: 0.17421942949295044
loss item: 0.12072993069887161
loss item: 0.16146758198738098
loss item: 0.1361834555864334
loss item: 0.13179929554462433
loss item: 0.13857848942279816
loss item: 0.12332183122634888
loss item: 0.14215634763240814
loss item: 0.12031560391187668
loss item: 0.11490312218666077
loss item: 0.12945370376110077
loss item: 0.1345359981060028
loss item: 0.11381226778030396
loss item: 0.14629435539245605
loss item: 0.1489519625902176
loss item: 0.12060948461294174
loss item: 0.13057361543178558
loss item: 0.158850759267807
loss item: 0.1614394187927246
loss item: 0.1481667309999466
loss item: 0.17637938261032104
Epoch [31/50], Training Loss: 0.1396, Testing Loss: 0.1403
Best model saved!
Epoch 32/50
loss item: 0.13536907732486725
loss item: 0.1493266224861145
loss item: 0.13374033570289612
loss item: 0.15836362540721893
loss item: 0.10927882790565491
loss item: 0.1377371847629547
loss item: 0.13130086660385132
loss item: 0.13063015043735504
loss item: 0.1415652334690094
loss item: 0.11928792297840118
loss item: 0.13246379792690277
loss item: 0.11868464201688766
loss item: 0.12763412296772003
loss item: 0.1550322324037552
loss item: 0.1545521467924118
loss item: 0.12521259486675262
loss item: 0.17835162580013275
loss item: 0.1891404539346695
loss item: 0.14231233298778534
loss item: 0.15382134914398193
loss item: 0.22921331226825714
loss item: 0.22424018383026123
loss item: 0.18755051493644714
loss item: 0.1989566832780838
Epoch [32/50], Training Loss: 0.1331, Testing Loss: 0.1722
no improvement in test loss for 1 epochs
Epoch 33/50
loss item: 0.14479532837867737
loss item: 0.13809509575366974
loss item: 0.1268908828496933
loss item: 0.14458414912223816
loss item: 0.11344923079013824
loss item: 0.15952254831790924
loss item: 0.1466415375471115
loss item: 0.13393834233283997
loss item: 0.13258840143680573
loss item: 0.12072296440601349
loss item: 0.1392413079738617
loss item: 0.11255326867103577
loss item: 0.11636573076248169
loss item: 0.13782113790512085
loss item: 0.14091309905052185
loss item: 0.12021812051534653
loss item: 0.1537141650915146
loss item: 0.15534022450447083
loss item: 0.12119080871343613
loss item: 0.1342930793762207
loss item: 0.16533511877059937
loss item: 0.16529075801372528
loss item: 0.15451277792453766
loss item: 0.18133507668972015
Epoch [33/50], Training Loss: 0.1344, Testing Loss: 0.1455
no improvement in test loss for 2 epochs
Epoch 34/50
loss item: 0.14622482657432556
loss item: 0.13799020648002625
loss item: 0.1264430582523346
loss item: 0.1684436947107315
loss item: 0.11218290776014328
loss item: 0.15427425503730774
loss item: 0.14875513315200806
loss item: 0.1324264109134674
loss item: 0.12477975338697433
loss item: 0.12333449721336365
loss item: 0.14156007766723633
loss item: 0.1144108772277832
loss item: 0.11900423467159271
loss item: 0.1475682407617569
loss item: 0.1511400192975998
loss item: 0.12054897844791412
loss item: 0.16036440432071686
loss item: 0.16532671451568604
loss item: 0.12425582855939865
loss item: 0.14176739752292633
loss item: 0.18554724752902985
loss item: 0.18684425950050354
loss item: 0.1636711210012436
loss item: 0.1870976984500885
Epoch [34/50], Training Loss: 0.1359, Testing Loss: 0.1544
no improvement in test loss for 3 epochs
Epoch 35/50
loss item: 0.14363200962543488
loss item: 0.14139790832996368
loss item: 0.12633831799030304
loss item: 0.1382492035627365
loss item: 0.11014208197593689
loss item: 0.14816050231456757
loss item: 0.14247779548168182
loss item: 0.13397282361984253
loss item: 0.1309259533882141
loss item: 0.11703667044639587
loss item: 0.12877528369426727
loss item: 0.11007100343704224
loss item: 0.135554239153862
loss item: 0.1769866794347763
loss item: 0.17541082203388214
loss item: 0.13827623426914215
loss item: 0.19483426213264465
loss item: 0.20788204669952393
loss item: 0.1496591866016388
loss item: 0.16555093228816986
loss item: 0.24079802632331848
loss item: 0.23399272561073303
loss item: 0.20272330939769745
loss item: 0.22013118863105774
Epoch [35/50], Training Loss: 0.1309, Testing Loss: 0.1868
no improvement in test loss for 4 epochs
Epoch 36/50
loss item: 0.15468601882457733
loss item: 0.14854617416858673
loss item: 0.11713649332523346
loss item: 0.13490234315395355
loss item: 0.10988853126764297
loss item: 0.16395197808742523
loss item: 0.14350789785385132
loss item: 0.13873052597045898
loss item: 0.12893804907798767
loss item: 0.10768997669219971
loss item: 0.12447676807641983
loss item: 0.10380525887012482
loss item: 0.12220335751771927
loss item: 0.15659913420677185
loss item: 0.15864711999893188
loss item: 0.12971805036067963
loss item: 0.16916319727897644
loss item: 0.17048737406730652
loss item: 0.12762998044490814
loss item: 0.14381718635559082
loss item: 0.18364472687244415
loss item: 0.18208369612693787
loss item: 0.16675974428653717
loss item: 0.19775642454624176
Epoch [36/50], Training Loss: 0.1314, Testing Loss: 0.1590
no improvement in test loss for 5 epochs
Epoch 37/50
loss item: 0.15477406978607178
loss item: 0.15748240053653717
loss item: 0.11760208755731583
loss item: 0.1557605266571045
loss item: 0.10379716753959656
loss item: 0.15111050009727478
loss item: 0.15013141930103302
loss item: 0.14632537961006165
loss item: 0.11729667335748672
loss item: 0.10868395119905472
loss item: 0.1348448544740677
loss item: 0.1077127531170845
loss item: 0.132169708609581
loss item: 0.17344918847084045
loss item: 0.17376412451267242
loss item: 0.13747136294841766
loss item: 0.18881189823150635
loss item: 0.19551308453083038
loss item: 0.14049433171749115
loss item: 0.1612636297941208
loss item: 0.2343142330646515
loss item: 0.2394242286682129
loss item: 0.19467514753341675
loss item: 0.21517731249332428
Epoch [37/50], Training Loss: 0.1338, Testing Loss: 0.1822
no improvement in test loss for 6 epochs
Epoch 38/50
loss item: 0.14771437644958496
loss item: 0.17095474898815155
loss item: 0.13074542582035065
loss item: 0.1340501457452774
loss item: 0.10937178134918213
loss item: 0.13902133703231812
loss item: 0.13737273216247559
loss item: 0.14941787719726562
loss item: 0.1175769791007042
loss item: 0.10444992035627365
loss item: 0.12468551844358444
loss item: 0.10518454015254974
loss item: 0.13121341168880463
loss item: 0.17733322083950043
loss item: 0.17819538712501526
loss item: 0.14034846425056458
loss item: 0.19019104540348053
loss item: 0.1979471743106842
loss item: 0.14188361167907715
loss item: 0.15865103900432587
loss item: 0.21687310934066772
loss item: 0.2182054966688156
loss item: 0.1919253170490265
loss item: 0.21214255690574646
Epoch [38/50], Training Loss: 0.1309, Testing Loss: 0.1796
no improvement in test loss for 7 epochs
Epoch 39/50
loss item: 0.1477169245481491
loss item: 0.16670359671115875
loss item: 0.12245554476976395
loss item: 0.1443873792886734
loss item: 0.1296490877866745
loss item: 0.1409703493118286
loss item: 0.12400055676698685
loss item: 0.1346837878227234
loss item: 0.11982190608978271
loss item: 0.10483512282371521
loss item: 0.14082802832126617
loss item: 0.1052563339471817
loss item: 0.11260291188955307
loss item: 0.12727591395378113
loss item: 0.13014289736747742
loss item: 0.10955968499183655
loss item: 0.142356738448143
loss item: 0.14418116211891174
loss item: 0.11582110822200775
loss item: 0.12886318564414978
loss item: 0.17534036934375763
loss item: 0.1734316200017929
loss item: 0.14747416973114014
loss item: 0.1770176887512207
Epoch [39/50], Training Loss: 0.1318, Testing Loss: 0.1403
no improvement in test loss for 8 epochs
Epoch 40/50
loss item: 0.12331217527389526
loss item: 0.14173589646816254
loss item: 0.11513420194387436
loss item: 0.13702517747879028
loss item: 0.12545719742774963
loss item: 0.12862670421600342
loss item: 0.10886992514133453
loss item: 0.11603069305419922
loss item: 0.11550731211900711
loss item: 0.10233395546674728
loss item: 0.14398066699504852
loss item: 0.10517740994691849
loss item: 0.1057090237736702
loss item: 0.12341891974210739
loss item: 0.12475448846817017
loss item: 0.10376006364822388
loss item: 0.13793496787548065
loss item: 0.14330360293388367
loss item: 0.11139579862356186
loss item: 0.12332026660442352
loss item: 0.17147968709468842
loss item: 0.17278032004833221
loss item: 0.14452746510505676
loss item: 0.16316580772399902
Epoch [40/50], Training Loss: 0.1219, Testing Loss: 0.1355
Best model saved!
Epoch 41/50
loss item: 0.11904493719339371
loss item: 0.1191234290599823
loss item: 0.11200026422739029
loss item: 0.13653312623500824
loss item: 0.12141520529985428
loss item: 0.13739654421806335
loss item: 0.10776665806770325
loss item: 0.10820204019546509
loss item: 0.11478517204523087
loss item: 0.1023268848657608
loss item: 0.145469531416893
loss item: 0.10051644593477249
loss item: 0.10527175664901733
loss item: 0.12398448586463928
loss item: 0.12438932061195374
loss item: 0.10549391061067581
loss item: 0.13824106752872467
loss item: 0.14180795848369598
loss item: 0.1127365231513977
loss item: 0.1230810359120369
loss item: 0.1685521900653839
loss item: 0.17153815925121307
loss item: 0.14056983590126038
loss item: 0.16848134994506836
Epoch [41/50], Training Loss: 0.1187, Testing Loss: 0.1353
Best model saved!
Epoch 42/50
loss item: 0.12127898633480072
loss item: 0.11419691890478134
loss item: 0.11206431686878204
loss item: 0.12684208154678345
loss item: 0.11295126378536224
loss item: 0.1343560367822647
loss item: 0.10538280755281448
loss item: 0.10684460401535034
loss item: 0.11709356307983398
loss item: 0.09926314651966095
loss item: 0.1403563916683197
loss item: 0.11069376766681671
loss item: 0.11306904256343842
loss item: 0.14085756242275238
loss item: 0.1393125057220459
loss item: 0.11489585787057877
loss item: 0.1595621407032013
loss item: 0.1652592420578003
loss item: 0.12454795837402344
loss item: 0.13548879325389862
loss item: 0.19634361565113068
loss item: 0.19733597338199615
loss item: 0.16001692414283752
loss item: 0.1807830035686493
Epoch [42/50], Training Loss: 0.1168, Testing Loss: 0.1523
no improvement in test loss for 1 epochs
Epoch 43/50
loss item: 0.14643308520317078
loss item: 0.11787699908018112
loss item: 0.12631113827228546
loss item: 0.13524679839611053
loss item: 0.10975879430770874
loss item: 0.13665509223937988
loss item: 0.11488889157772064
loss item: 0.1102379560470581
loss item: 0.12017257511615753
loss item: 0.09810628741979599
loss item: 0.12736386060714722
loss item: 0.12292955070734024
loss item: 0.11641532182693481
loss item: 0.14815932512283325
loss item: 0.1459110975265503
loss item: 0.11916391551494598
loss item: 0.1655457615852356
loss item: 0.16834063827991486
loss item: 0.13192568719387054
loss item: 0.13827531039714813
loss item: 0.184307262301445
loss item: 0.18922807276248932
loss item: 0.16152775287628174
loss item: 0.18621836602687836
Epoch [43/50], Training Loss: 0.1222, Testing Loss: 0.1546
no improvement in test loss for 2 epochs
Epoch 44/50
loss item: 0.13623397052288055
loss item: 0.1268892139196396
loss item: 0.13446225225925446
loss item: 0.1668665111064911
loss item: 0.12677524983882904
loss item: 0.16869454085826874
loss item: 0.12080259621143341
loss item: 0.11416281014680862
loss item: 0.13392192125320435
loss item: 0.11032938212156296
loss item: 0.12580770254135132
loss item: 0.14439532160758972
loss item: 0.11916010826826096
loss item: 0.14178970456123352
loss item: 0.13733145594596863
loss item: 0.12372561544179916
loss item: 0.154963880777359
loss item: 0.15528948605060577
loss item: 0.12261267751455307
loss item: 0.13611237704753876
loss item: 0.1967405378818512
loss item: 0.2010985016822815
loss item: 0.15985938906669617
loss item: 0.18710604310035706
Epoch [44/50], Training Loss: 0.1341, Testing Loss: 0.1530
no improvement in test loss for 3 epochs
Epoch 45/50
loss item: 0.1259535700082779
loss item: 0.12974366545677185
loss item: 0.1351684033870697
loss item: 0.16709667444229126
loss item: 0.09970361739397049
loss item: 0.12739156186580658
loss item: 0.10845889151096344
loss item: 0.1199391782283783
loss item: 0.12632888555526733
loss item: 0.11417955160140991
loss item: 0.12409920990467072
loss item: 0.12386604398488998
loss item: 0.12296700477600098
loss item: 0.15393714606761932
loss item: 0.15069732069969177
loss item: 0.1287144124507904
loss item: 0.18525691330432892
loss item: 0.19551531970500946
loss item: 0.14175333082675934
loss item: 0.15388573706150055
loss item: 0.2503434121608734
loss item: 0.26358070969581604
loss item: 0.19674384593963623
loss item: 0.1876821368932724
Epoch [45/50], Training Loss: 0.1252, Testing Loss: 0.1776
no improvement in test loss for 4 epochs
Epoch 46/50
loss item: 0.1327720433473587
loss item: 0.12955811619758606
loss item: 0.13659466803073883
loss item: 0.14029809832572937
loss item: 0.1014910563826561
loss item: 0.14206534624099731
loss item: 0.10947827249765396
loss item: 0.12616121768951416
loss item: 0.12655332684516907
loss item: 0.11139976233243942
loss item: 0.11364634335041046
loss item: 0.11004674434661865
loss item: 0.10381720960140228
loss item: 0.12514588236808777
loss item: 0.12489179521799088
loss item: 0.10839781910181046
loss item: 0.13736562430858612
loss item: 0.1372949331998825
loss item: 0.10979685932397842
loss item: 0.12021804600954056
loss item: 0.15532860159873962
loss item: 0.1595800220966339
loss item: 0.1343940943479538
loss item: 0.16485068202018738
Epoch [46/50], Training Loss: 0.1233, Testing Loss: 0.1318
Best model saved!
Epoch 47/50
loss item: 0.11617913842201233
loss item: 0.11970043182373047
loss item: 0.14880886673927307
loss item: 0.1662922352552414
loss item: 0.09882712364196777
loss item: 0.1284027099609375
loss item: 0.1235889121890068
loss item: 0.11958477646112442
loss item: 0.1271914690732956
loss item: 0.12043273448944092
loss item: 0.13362400233745575
loss item: 0.14446862041950226
loss item: 0.12537506222724915
loss item: 0.15659882128238678
loss item: 0.15183661878108978
loss item: 0.12726004421710968
loss item: 0.18907494843006134
loss item: 0.20698237419128418
loss item: 0.1460479348897934
loss item: 0.15947343409061432
loss item: 0.2771565914154053
loss item: 0.29015278816223145
loss item: 0.20943500101566315
loss item: 0.2026323825120926
Epoch [47/50], Training Loss: 0.1289, Testing Loss: 0.1868
no improvement in test loss for 1 epochs
Epoch 48/50
loss item: 0.14062096178531647
loss item: 0.12236364185810089
loss item: 0.14480231702327728
loss item: 0.14895892143249512
loss item: 0.1130472868680954
loss item: 0.14325827360153198
loss item: 0.11271757632493973
loss item: 0.10717029124498367
loss item: 0.13665920495986938
loss item: 0.14289681613445282
loss item: 0.12242943793535233
loss item: 0.13072097301483154
loss item: 0.10751255601644516
loss item: 0.12480676919221878
loss item: 0.125191330909729
loss item: 0.10540436208248138
loss item: 0.1462446004152298
loss item: 0.1520555019378662
loss item: 0.11885125935077667
loss item: 0.1275484412908554
loss item: 0.1998853087425232
loss item: 0.20299997925758362
loss item: 0.1557682752609253
loss item: 0.1679675430059433
Epoch [48/50], Training Loss: 0.1305, Testing Loss: 0.1445
no improvement in test loss for 2 epochs
Epoch 49/50
loss item: 0.12013763934373856
loss item: 0.1141372099518776
loss item: 0.15613004565238953
loss item: 0.15567906200885773
loss item: 0.11968808621168137
loss item: 0.15774288773536682
loss item: 0.136248379945755
loss item: 0.124318428337574
loss item: 0.12377586960792542
loss item: 0.13766227662563324
loss item: 0.13671085238456726
loss item: 0.14285166561603546
loss item: 0.13287295401096344
loss item: 0.1709938943386078
loss item: 0.16834746301174164
loss item: 0.13542440533638
loss item: 0.19858166575431824
loss item: 0.21513105928897858
loss item: 0.1495843529701233
loss item: 0.16900946199893951
loss item: 0.28178685903549194
loss item: 0.2909097969532013
loss item: 0.21705548465251923
loss item: 0.21556957066059113
Epoch [49/50], Training Loss: 0.1354, Testing Loss: 0.1954
no improvement in test loss for 3 epochs
Epoch 50/50
loss item: 0.15798017382621765
loss item: 0.12124890834093094
loss item: 0.11708202958106995
loss item: 0.1405678242444992
loss item: 0.118984155356884
loss item: 0.16964784264564514
loss item: 0.157669335603714
loss item: 0.13190726935863495
loss item: 0.12042393535375595
loss item: 0.12105634063482285
loss item: 0.12134160846471786
loss item: 0.1338420957326889
loss item: 0.16927552223205566
loss item: 0.23037269711494446
loss item: 0.22083620727062225
loss item: 0.17499130964279175
loss item: 0.262458860874176
loss item: 0.28561797738075256
loss item: 0.195088192820549
loss item: 0.2157345563173294
loss item: 0.34721100330352783
loss item: 0.3468363881111145
loss item: 0.2811470627784729
loss item: 0.2758331596851349
Epoch [50/50], Training Loss: 0.1343, Testing Loss: 0.2505
no improvement in test loss for 4 epochs
loss item: 0.22692927718162537
loss item: 0.18859949707984924
loss item: 0.21219679713249207
loss item: 0.21298149228096008
loss item: 0.15509682893753052
loss item: 0.16677752137184143
Val Loss: 0.3875
done with hyperparameter tuning training
prediction model: UNet6, learning rate: 0.0001, epochs: 50, batch size: 64
Hyperparameter tuning prediction finished
UNet6 with 1 50 0.0001 64 180 done at Mon Nov 11 16:31:35 CET 2024
SBATCH job finished
