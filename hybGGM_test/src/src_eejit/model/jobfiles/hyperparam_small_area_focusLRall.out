SBATCH job
Started 01/11/2024 16:40:57
Working directory /eejit/home/hausw001/HybGGM/hybGGM_test
UNet6 with 0.4 0.3 50 1e-05 64 small start at Fri Nov  1 16:40:58 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 1e-05 batch_size: 64 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0500, Validation Loss: 0.0523
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0496, Validation Loss: 0.0523
Best model saved!
Epoch 3/50
Epoch [3/50], Training Loss: 0.0492, Validation Loss: 0.0523
Epoch 4/50
Epoch [4/50], Training Loss: 0.0488, Validation Loss: 0.0523
Epoch 5/50
Epoch [5/50], Training Loss: 0.0484, Validation Loss: 0.0523
Epoch 6/50
Epoch [6/50], Training Loss: 0.0481, Validation Loss: 0.0523
Epoch 7/50
Epoch [7/50], Training Loss: 0.0478, Validation Loss: 0.0524
Epoch 8/50
Epoch [8/50], Training Loss: 0.0475, Validation Loss: 0.0524
Epoch 9/50
Epoch [9/50], Training Loss: 0.0472, Validation Loss: 0.0524
Epoch 10/50
Epoch [10/50], Training Loss: 0.0469, Validation Loss: 0.0524
Epoch 11/50
Epoch [11/50], Training Loss: 0.0466, Validation Loss: 0.0524
Epoch 12/50
Epoch [12/50], Training Loss: 0.0464, Validation Loss: 0.0524
Epoch 13/50
Epoch [13/50], Training Loss: 0.0461, Validation Loss: 0.0524
Epoch 14/50
Epoch [14/50], Training Loss: 0.0459, Validation Loss: 0.0524
Epoch 15/50
Epoch [15/50], Training Loss: 0.0457, Validation Loss: 0.0524
Epoch 16/50
Epoch [16/50], Training Loss: 0.0454, Validation Loss: 0.0523
Epoch 17/50
Epoch [17/50], Training Loss: 0.0452, Validation Loss: 0.0523
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0450, Validation Loss: 0.0523
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0447, Validation Loss: 0.0522
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0445, Validation Loss: 0.0522
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0443, Validation Loss: 0.0522
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0441, Validation Loss: 0.0521
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0438, Validation Loss: 0.0520
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0436, Validation Loss: 0.0519
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0434, Validation Loss: 0.0518
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0432, Validation Loss: 0.0517
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0430, Validation Loss: 0.0516
Best model saved!
Epoch 28/50
Epoch [28/50], Training Loss: 0.0427, Validation Loss: 0.0515
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0425, Validation Loss: 0.0513
Best model saved!
Epoch 30/50
Epoch [30/50], Training Loss: 0.0423, Validation Loss: 0.0512
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0420, Validation Loss: 0.0510
Best model saved!
Epoch 32/50
Epoch [32/50], Training Loss: 0.0418, Validation Loss: 0.0508
Best model saved!
Epoch 33/50
Epoch [33/50], Training Loss: 0.0415, Validation Loss: 0.0506
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0412, Validation Loss: 0.0504
Best model saved!
Epoch 35/50
Epoch [35/50], Training Loss: 0.0409, Validation Loss: 0.0502
Best model saved!
Epoch 36/50
Epoch [36/50], Training Loss: 0.0406, Validation Loss: 0.0499
Best model saved!
Epoch 37/50
Epoch [37/50], Training Loss: 0.0403, Validation Loss: 0.0497
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0400, Validation Loss: 0.0494
Best model saved!
Epoch 39/50
Epoch [39/50], Training Loss: 0.0397, Validation Loss: 0.0491
Best model saved!
Epoch 40/50
Epoch [40/50], Training Loss: 0.0393, Validation Loss: 0.0487
Best model saved!
Epoch 41/50
Epoch [41/50], Training Loss: 0.0389, Validation Loss: 0.0484
Best model saved!
Epoch 42/50
Epoch [42/50], Training Loss: 0.0385, Validation Loss: 0.0480
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0381, Validation Loss: 0.0476
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0377, Validation Loss: 0.0471
Best model saved!
Epoch 45/50
Epoch [45/50], Training Loss: 0.0373, Validation Loss: 0.0468
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0369, Validation Loss: 0.0463
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0366, Validation Loss: 0.0458
Best model saved!
Epoch 48/50
Epoch [48/50], Training Loss: 0.0361, Validation Loss: 0.0455
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0357, Validation Loss: 0.0449
Best model saved!
Epoch 50/50
Epoch [50/50], Training Loss: 0.0353, Validation Loss: 0.0443
Best model saved!
Test Loss: 0.0273
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 1e-05, Batch size: 64
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 1e-05 64 small done at Fri Nov  1 18:03:57 CET 2024
UNet6 with 0.4 0.3 50 0.0001 64 small start at Fri Nov  1 18:03:57 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.0001 batch_size: 64 model_type: UNet6
Hyperparameter tuning already done and prediction files are there
UNet6 with 0.4 0.3 50 0.0001 64 small done at Fri Nov  1 18:04:02 CET 2024
UNet6 with 0.4 0.3 50 0.001 64 small start at Fri Nov  1 18:04:02 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.001 batch_size: 64 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0500, Validation Loss: 0.0522
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0522, Validation Loss: 0.0522
Epoch 3/50
Epoch [3/50], Training Loss: 0.0454, Validation Loss: 0.0525
Epoch 4/50
Epoch [4/50], Training Loss: 0.0435, Validation Loss: 0.2704
Epoch 5/50
Epoch [5/50], Training Loss: 0.0420, Validation Loss: 0.9479
Epoch 6/50
Epoch [6/50], Training Loss: 0.0411, Validation Loss: 1.5704
Epoch 7/50
Epoch [7/50], Training Loss: 0.0403, Validation Loss: 2.9879
Epoch 8/50
Epoch [8/50], Training Loss: 0.0396, Validation Loss: 1.8268
Epoch 9/50
Epoch [9/50], Training Loss: 0.0390, Validation Loss: 0.4728
Epoch 10/50
Epoch [10/50], Training Loss: 0.0385, Validation Loss: 0.0945
Epoch 11/50
Epoch [11/50], Training Loss: 0.0380, Validation Loss: 0.0557
Epoch 12/50
Epoch [12/50], Training Loss: 0.0375, Validation Loss: 0.0502
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0370, Validation Loss: 0.0513
Epoch 14/50
Epoch [14/50], Training Loss: 0.0365, Validation Loss: 0.0548
Epoch 15/50
Epoch [15/50], Training Loss: 0.0364, Validation Loss: 0.1012
Epoch 16/50
Epoch [16/50], Training Loss: 0.0367, Validation Loss: 0.0855
Epoch 17/50
Epoch [17/50], Training Loss: 0.0354, Validation Loss: 0.2423
Epoch 18/50
Epoch [18/50], Training Loss: 0.0355, Validation Loss: 0.2263
Epoch 19/50
Epoch [19/50], Training Loss: 0.0345, Validation Loss: 0.1348
Epoch 20/50
Epoch [20/50], Training Loss: 0.0345, Validation Loss: 0.1146
Epoch 21/50
Epoch [21/50], Training Loss: 0.0338, Validation Loss: 0.1766
Epoch 22/50
Epoch [22/50], Training Loss: 0.0336, Validation Loss: 0.0676
Epoch 23/50
Epoch [23/50], Training Loss: 0.0335, Validation Loss: 0.0688
Epoch 24/50
Epoch [24/50], Training Loss: 0.0332, Validation Loss: 0.0744
Epoch 25/50
Epoch [25/50], Training Loss: 0.0344, Validation Loss: 0.0826
Epoch 26/50
Epoch [26/50], Training Loss: 0.0341, Validation Loss: 0.0778
Epoch 27/50
Epoch [27/50], Training Loss: 0.0331, Validation Loss: 0.0628
Epoch 28/50
Epoch [28/50], Training Loss: 0.0333, Validation Loss: 0.0583
Epoch 29/50
Epoch [29/50], Training Loss: 0.0326, Validation Loss: 0.0577
Epoch 30/50
Epoch [30/50], Training Loss: 0.0323, Validation Loss: 0.0567
Epoch 31/50
Epoch [31/50], Training Loss: 0.0320, Validation Loss: 0.0539
Epoch 32/50
Epoch [32/50], Training Loss: 0.0318, Validation Loss: 0.0503
Epoch 33/50
Epoch [33/50], Training Loss: 0.0316, Validation Loss: 0.0498
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0314, Validation Loss: 0.0568
Epoch 35/50
Epoch [35/50], Training Loss: 0.0315, Validation Loss: 0.0791
Epoch 36/50
Epoch [36/50], Training Loss: 0.0325, Validation Loss: 0.0655
Epoch 37/50
Epoch [37/50], Training Loss: 0.0307, Validation Loss: 0.0555
Epoch 38/50
Epoch [38/50], Training Loss: 0.0318, Validation Loss: 0.0538
Epoch 39/50
Epoch [39/50], Training Loss: 0.0304, Validation Loss: 0.0543
Epoch 40/50
Epoch [40/50], Training Loss: 0.0309, Validation Loss: 0.0523
Epoch 41/50
Epoch [41/50], Training Loss: 0.0304, Validation Loss: 0.0478
Best model saved!
Epoch 42/50
Epoch [42/50], Training Loss: 0.0302, Validation Loss: 0.0429
Best model saved!
Epoch 43/50
Epoch [43/50], Training Loss: 0.0299, Validation Loss: 0.0420
Best model saved!
Epoch 44/50
Epoch [44/50], Training Loss: 0.0296, Validation Loss: 0.0401
Best model saved!
Epoch 45/50
Epoch [45/50], Training Loss: 0.0293, Validation Loss: 0.0400
Best model saved!
Epoch 46/50
Epoch [46/50], Training Loss: 0.0295, Validation Loss: 0.0396
Best model saved!
Epoch 47/50
Epoch [47/50], Training Loss: 0.0299, Validation Loss: 0.0382
Best model saved!
Epoch 48/50
Epoch [48/50], Training Loss: 0.0299, Validation Loss: 0.0374
Best model saved!
Epoch 49/50
Epoch [49/50], Training Loss: 0.0290, Validation Loss: 0.0380
Epoch 50/50
Epoch [50/50], Training Loss: 0.0291, Validation Loss: 0.0368
Best model saved!
Test Loss: 0.0223
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.001, Batch size: 64
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.001 64 small done at Fri Nov  1 19:26:07 CET 2024
UNet6 with 0.4 0.3 50 0.01 64 small start at Fri Nov  1 19:26:07 CET 2024
current path /eejit/home/hausw001/HybGGM/hybGGM_test
data testing folder already prepared
data testing folder already prepared
Hyperparameter tuning definition and start
testSize: 0.4 trainSize: 0.3 epochs: 50 learning_rate: 0.01 batch_size: 64 model_type: UNet6
Epoch 1/50
Epoch [1/50], Training Loss: 0.0500, Validation Loss: 3990324510720.0000
Best model saved!
Epoch 2/50
Epoch [2/50], Training Loss: 0.0885, Validation Loss: inf
Epoch 3/50
Epoch [3/50], Training Loss: 0.0659, Validation Loss: inf
Epoch 4/50
Epoch [4/50], Training Loss: 0.0478, Validation Loss: 3013266217369.6001
Best model saved!
Epoch 5/50
Epoch [5/50], Training Loss: 0.0460, Validation Loss: 127134754406.4000
Best model saved!
Epoch 6/50
Epoch [6/50], Training Loss: 0.0451, Validation Loss: 2447736627.2000
Best model saved!
Epoch 7/50
Epoch [7/50], Training Loss: 0.0449, Validation Loss: 60847289.6000
Best model saved!
Epoch 8/50
Epoch [8/50], Training Loss: 0.0447, Validation Loss: 4234987.6000
Best model saved!
Epoch 9/50
Epoch [9/50], Training Loss: 0.0446, Validation Loss: 986686.1000
Best model saved!
Epoch 10/50
Epoch [10/50], Training Loss: 0.0445, Validation Loss: 359994.5000
Best model saved!
Epoch 11/50
Epoch [11/50], Training Loss: 0.0444, Validation Loss: 124308.4000
Best model saved!
Epoch 12/50
Epoch [12/50], Training Loss: 0.0442, Validation Loss: 47154.7969
Best model saved!
Epoch 13/50
Epoch [13/50], Training Loss: 0.0441, Validation Loss: 18578.8375
Best model saved!
Epoch 14/50
Epoch [14/50], Training Loss: 0.0440, Validation Loss: 7484.9242
Best model saved!
Epoch 15/50
Epoch [15/50], Training Loss: 0.0439, Validation Loss: 3040.0328
Best model saved!
Epoch 16/50
Epoch [16/50], Training Loss: 0.0438, Validation Loss: 1243.0896
Best model saved!
Epoch 17/50
Epoch [17/50], Training Loss: 0.0437, Validation Loss: 516.7030
Best model saved!
Epoch 18/50
Epoch [18/50], Training Loss: 0.0434, Validation Loss: 214.8647
Best model saved!
Epoch 19/50
Epoch [19/50], Training Loss: 0.0432, Validation Loss: 83.5028
Best model saved!
Epoch 20/50
Epoch [20/50], Training Loss: 0.0429, Validation Loss: 29.9634
Best model saved!
Epoch 21/50
Epoch [21/50], Training Loss: 0.0427, Validation Loss: 12.0340
Best model saved!
Epoch 22/50
Epoch [22/50], Training Loss: 0.0424, Validation Loss: 8.8097
Best model saved!
Epoch 23/50
Epoch [23/50], Training Loss: 0.0420, Validation Loss: 7.9927
Best model saved!
Epoch 24/50
Epoch [24/50], Training Loss: 0.0417, Validation Loss: 5.8301
Best model saved!
Epoch 25/50
Epoch [25/50], Training Loss: 0.0415, Validation Loss: 2.7836
Best model saved!
Epoch 26/50
Epoch [26/50], Training Loss: 0.0412, Validation Loss: 2.1409
Best model saved!
Epoch 27/50
Epoch [27/50], Training Loss: 0.0409, Validation Loss: 3.0222
Epoch 28/50
Epoch [28/50], Training Loss: 0.0405, Validation Loss: 1.5295
Best model saved!
Epoch 29/50
Epoch [29/50], Training Loss: 0.0403, Validation Loss: 3.6580
Epoch 30/50
Epoch [30/50], Training Loss: 0.0400, Validation Loss: 0.6066
Best model saved!
Epoch 31/50
Epoch [31/50], Training Loss: 0.0402, Validation Loss: 0.8703
Epoch 32/50
Epoch [32/50], Training Loss: 0.0402, Validation Loss: 1.4972
Epoch 33/50
Epoch [33/50], Training Loss: 0.0398, Validation Loss: 0.3741
Best model saved!
Epoch 34/50
Epoch [34/50], Training Loss: 0.0392, Validation Loss: 1.4160
Epoch 35/50
Epoch [35/50], Training Loss: 0.0385, Validation Loss: 0.8794
Epoch 36/50
Epoch [36/50], Training Loss: 0.0385, Validation Loss: 1.3655
Epoch 37/50
Epoch [37/50], Training Loss: 0.0387, Validation Loss: 0.0912
Best model saved!
Epoch 38/50
Epoch [38/50], Training Loss: 0.0386, Validation Loss: 0.3137
Epoch 39/50
Epoch [39/50], Training Loss: 0.0380, Validation Loss: 0.2159
Epoch 40/50
Epoch [40/50], Training Loss: 0.0376, Validation Loss: 0.2254
Epoch 41/50
Epoch [41/50], Training Loss: 0.0384, Validation Loss: 1.6322
Epoch 42/50
Epoch [42/50], Training Loss: 0.0381, Validation Loss: 2.0507
Epoch 43/50
Epoch [43/50], Training Loss: 0.0380, Validation Loss: 1.7253
Epoch 44/50
Epoch [44/50], Training Loss: 0.0382, Validation Loss: 1.4417
Epoch 45/50
Epoch [45/50], Training Loss: 0.0376, Validation Loss: 1.1604
Epoch 46/50
Epoch [46/50], Training Loss: 0.0374, Validation Loss: 1.0273
Epoch 47/50
Epoch [47/50], Training Loss: 0.0373, Validation Loss: 0.6433
Epoch 48/50
Epoch [48/50], Training Loss: 0.0366, Validation Loss: 0.4798
Epoch 49/50
Epoch [49/50], Training Loss: 0.0366, Validation Loss: 0.3846
Epoch 50/50
Epoch [50/50], Training Loss: 0.0362, Validation Loss: 0.2808
Test Loss: 0.1838
done with hyperparameter tuning training
Model type: UNet6, Epochs: 50, Learning rate: 0.01, Batch size: 64
Hyperparameter tuning prediction finished
UNet6 with 0.4 0.3 50 0.01 64 small done at Fri Nov  1 20:49:58 CET 2024
SBATCH job finished
